<doc id="26989" url="https://en.wikipedia.org/wiki?curid=26989" title="Sony">
Sony

Sony is one the biggest producers of image sensors, with a 50% market share as of 2019. Many digital camera brands and smartphone makers implement Sony IMX image sensors, with some brands such as Apple, Nikon, Samsung, LG, Huawei, and Olympus.

Sony is among the semiconductor sales leaders and as of 2015, the fifth-largest television manufacturer in the world by annual sales figures. It is the world's largest player in the premium TV market, a market for a television of at least 55 inches with a price higher than $2,500.

Sony Corporation is the holding company of the , which is engaged in businesses through its seven operating components: electronics (A/V, IT & communication products, and medical business), video games, motion pictures (movies and TV shows), music (record labels and music publishing), semiconductors (image sensors), financial services (banking and insurance), and others.

The subsidiaries of Sony Corporation include Sony Electronics, Sony Semiconductor Solutions, Sony Pictures, Sony Music, Sony Interactive Entertainment, Sony Financial Holdings, and others. Thus, Sony is one of the most comprehensive entertainment companies in the world and has been considered to be a conglomerate.

The company's slogan is "Be Moved". Their former slogans were "The One and Only" (1979–1982), "It's a Sony" (1982–2005), "like.no.other" (2005–2009) and "make.believe" (2009–2013).

Sony has a weak tie to the Sumitomo Mitsui Financial Group (SMFG) corporate group, the successor to the Mitsui group.

Sony began in the wake of World War II. In 1946, Masaru Ibuka started an electronics shop in a department store building in Tokyo. The company started with a capital of ¥190,000 and a total of eight employees. On 7 May 1946, Ibuka was joined by Akio Morita to establish a company called (Tokyo Telecommunications Engineering Corporation). The company built Japan's first tape recorder, called the Type-G. In 1958, the company changed its name to "Sony".

When "Tokyo Tsushin Kogyo" was looking for a romanized name to use to market themselves, they strongly considered using their initials, TTK. The primary reason they did not is that the railway company Tokyo Kyuko was known as TTK. The company occasionally used the acronym "Totsuko" in Japan, but during his visit to the United States, Morita discovered that Americans had trouble pronouncing that name. Another early name that was tried out for a while was "Tokyo Teletech" until Akio Morita discovered that there was an American company already using Teletech as a brand name.

The name "Sony" was chosen for the brand as a mix of two words: one was the Latin word ""sonus"", which is the root of sonic and sound, and the other was ""sonny"", a common slang term used in 1950s America to call a young boy. In 1950s Japan, "sonny boys" was a loan word in Japanese, which connoted smart and presentable young men, which Sony founders Akio Morita and Masaru Ibuka considered themselves to be.

The first Sony-branded product, the TR-55 transistor radio, appeared in 1955 but the company name did not change to Sony until January 1958.

At the time of the change, it was extremely unusual for a Japanese company to use Roman letters to spell its name instead of writing it in kanji. The move was not without opposition: TTK's principal bank at the time, Mitsui, had strong feelings about the name. They pushed for a name such as Sony Electronic Industries, or Sony Teletech. Akio Morita was firm, however, as he did not want the company name tied to any particular industry. Eventually, both Ibuka and Mitsui Bank's chairman gave their approval.

According to Schiffer, Sony's TR-63 radio "cracked open the U.S. market and launched the new industry of consumer microelectronics." By the mid-1950s, American teens had begun buying portable transistor radios in huge numbers, helping to propel the fledgling industry from an estimated 100,000 units in 1955 to 5 million units by the end of 1968.

Sony co-founder Akio Morita founded Sony Corporation of America in 1960. In the process, he was struck by the mobility of employees between American companies, which was unheard of in Japan at that time. When he returned to Japan, he encouraged experienced, middle-aged employees of other companies to reevaluate their careers and consider joining Sony. The company filled many positions in this manner, and inspired other Japanese companies to do the same. Moreover, Sony played a major role in the development of Japan as a powerful exporter during the 1960s, 1970s and 1980s. It also helped to significantly improve American perceptions of "made in Japan" products. Known for its production quality, Sony was able to charge above-market prices for its consumer electronics and resisted lowering prices.

In 1971, Masaru Ibuka handed the position of president over to his co-founder Akio Morita. Sony began a life insurance company in 1979, one of its many peripheral businesses. Amid a global recession in the early 1980s, electronics sales dropped and the company was forced to cut prices. Sony's profits fell sharply. "It's over for Sony", one analyst concluded. "The company's best days are behind it." Around that time, Norio Ohga took up the role of president. He encouraged the development of the Compact Disc in the 1970s and 1980s, and of the PlayStation in the early 1990s. Ohga went on to purchase CBS Records in 1988 and Columbia Pictures in 1989, greatly expanding Sony's media presence. Ohga would succeed Morita as chief executive officer in 1989.
Under the vision of co-founder Akio Morita and his successors, the company had aggressively expanded into new businesses. Part of its motivation for doing so was the pursuit of "convergence", linking film, music and digital electronics via the Internet. This expansion proved unrewarding and unprofitable, threatening Sony's ability to charge a premium on its products as well as its brand name. In 2005, Howard Stringer replaced Nobuyuki Idei as chief executive officer, marking the first time that a foreigner had run a major Japanese electronics firm. Stringer helped to reinvigorate the company's struggling media businesses, encouraging blockbusters such as "Spider-Man" while cutting 9,000 jobs. He hoped to sell off peripheral business and focus the company again on electronics. Furthermore, he aimed to increase cooperation between business units, which he described as "silos" operating in isolation from one another. In a bid to provide a unified brand for its global operations, Sony introduced a slogan known as "make.believe" in 2009.
Despite some successes, the company faced continued struggles in the mid- to late-2000s. In 2012, Kazuo Hirai was promoted to president and CEO, replacing Stringer. Shortly thereafter, Hirai outlined his company-wide initiative, named "One Sony" to revive Sony from years of financial losses and bureaucratic management structure, which proved difficult for former CEO Stringer to accomplish, partly due to differences in business culture and native languages between Stringer and some of Sony's Japanese divisions and subsidiaries. Hirai outlined three major areas of focus for Sony's electronics business, which include imaging technology, gaming and mobile technology, as well as a focus on reducing the major losses from the television business.
In February 2014, Sony announced the sale of its Vaio PC division to a new corporation owned by investment fund Japan Industrial Partners and spinning its TV division into its own corporation as to make it more nimble to turn the unit around from past losses totaling $7.8 billion over a decade. Later that month, they announced that they would be closing 20 stores. In April, the company announced that they would be selling 9.5 million shares in Square Enix (roughly 8.2 percent of the game company's total shares) in a deal worth approximately $48 million. In May 2014 the company announced it was forming two joint ventures with Shanghai Oriental Pearl Group to manufacture and market Sony's PlayStation games consoles and associated software in China.

It was reported in December 2016 by multiple news outlets that Sony was considering restructuring its U.S. operations by merging its TV & film business, Sony Pictures Entertainment, with its gaming business, Sony Interactive Entertainment. According to the reports, such a restructuring would have placed Sony Pictures under Sony Interactive's CEO, Andrew House, though House wouldn't have taken over day-to-day operations of the film studio. According to one report, Sony was set to make a final decision on the possibility of the merger of the TV, film, & gaming businesses by the end of its fiscal year in March of the following year (2017).

In 2017, Sony sold its lithium-ion battery business to Murata Manufacturing.

In 2019, Sony merged its Mobile, TV and Camera businesses.

On 1 April 2020, Sony Electronics Corporation was established as an intermediate holding company to own and oversee its electronics and IT solutions businesses.

On 19 May 2020, the company announced that it will rename Sony Group Corporation as of 1 April 2021. Subsequently, Sony Electronics Corporation will be renamed to Sony Corporation. On the same day the company announced that it will turn Sony Financial Holdings, of which Sony already owns 65.06% of shares, to a wholly owned subsidiary through a takeover bid.

Sony has historically been notable for creating its own in-house standards for new recording and storage technologies, instead of adopting those of other manufacturers and standards bodies. Sony (either alone or with partners) has introduced several of the most popular recording formats, including the 3.5-inch floppy disk, Compact Disc and Blu-ray Disc.

Sony introduced U-matic, the world's first videocassette format, in 1971, but the standard was unpopular for domestic use due to the high price. The company subsequently launched the Betamax format in 1975. Sony was involved in the videotape format war of the early 1980s, when they were marketing the Betamax system for video cassette recorders against the VHS format developed by JVC. In the end, VHS gained critical mass in the marketbase and became the worldwide standard for consumer VCRs.

Betamax is, for all practical purposes, an obsolete format. Sony's professional-oriented component video format called Betacam, which was derived from Betamax, was used until 2016 when Sony announced it was stopping production of all remaining 1/2-inch video tape recorders and players, including the Digital Betacam format.

In 1985, Sony launched their Handycam products and the Video8 format. Video8 and the follow-on hi-band Hi8 format became popular in the consumer camcorder market. In 1987 Sony launched the 4 mm DAT or Digital Audio Tape as a new digital audio tape standard.

Sony held a patent for its proprietary Trinitron until 1996.

Sony introduced the Triluminos Display, the company's proprietary color reproduction enhancing technology, in 2004, featured in the world's first LED-backlit LCD televisions. It was widely used in other Sony's products as well, including computer monitors, laptops, and smartphones. In 2013, Sony released a new line of televisions with an improved version of the technology, which incorporated quantum dots in the backlight system. It was the first commercial use of quantum dots.

In 2012, the company revealed a prototype of an ultrafine RGB LED display, which it calls the Crystal LED Display.

Sony used the Compact Cassette format in many of its tape recorders and players, including the Walkman, the world's first portable music player. Sony introduced the MiniDisc format in 1992 as an alternative to Philips DCC or Digital Compact Cassette and as a successor to the Compact Cassette. Since the introduction of MiniDisc, Sony has attempted to promote its own audio compression technologies under the ATRAC brand, against the more widely used MP3. Until late 2004, Sony's Network Walkman line of digital portable music players did not support the MP3 standard natively.

In 2004, Sony built upon the MiniDisc format by releasing Hi-MD. Hi-MD allows the playback and recording of audio on newly introduced 1 GB Hi-MD discs in addition to playback and recording on regular MiniDiscs. In addition to saving audio on the discs, Hi-MD allows the storage of computer files such as documents, videos and photos.

In 1993, Sony challenged the industry standard Dolby Digital 5.1 surround sound format with a newer and more advanced proprietary motion picture digital audio format called SDDS (Sony Dynamic Digital Sound). This format employed eight channels (7.1) of audio opposed to just six used in Dolby Digital 5.1 at the time. Ultimately, SDDS has been vastly overshadowed by the preferred DTS (Digital Theatre System) and Dolby Digital standards in the motion picture industry. SDDS was solely developed for use in the theatre circuit; Sony never intended to develop a home theatre version of SDDS.

Sony and Philips jointly developed the Sony-Philips digital interface format (S/PDIF) and the high-fidelity audio system SACD. The latter became entrenched in a format war with DVD-Audio. Still, neither gained a major foothold with the general public. CDs had been preferred by consumers because of the ubiquitous presence of CD drives in consumer devices until the early 2000s when the iPod and streaming services became available.

Sony demonstrated an optical digital audio disc in 1977 and soon joined hands with Philips, another major contender for the storage technology, to establish a worldwide standard. In 1983, the two company jointly announced the Compact Disc (CD). In 1984, Sony launched the Discman series, an expansion of the Walkman brand to portable CD players. Sony began to improve performance and capacity of the novel format. It launched write-once optical discs (WO) and magneto-optical discs which were around 125MB size for the specific use of archival data storage, in 1986 and 1988 respectively.

In the early 1990s, two high-density optical storage standards were being developed: one was the MultiMedia Compact Disc (MMCD), backed by Philips and Sony, and the other was the Super Density Disc (SD), supported by Toshiba and many others. Philips and Sony abandoned their MMCD format and agreed upon Toshiba's SD format with only one modification. The unified disc format was called DVD and was introduced in 1997.

Sony was one of the leading developers of the Blu-ray optical disc format, the newest standard for disc-based content delivery. The first Blu-ray players became commercially available in 2006. The format emerged as the standard for HD media over the competing format, Toshiba's HD DVD, after a two-year-long high-definition optical disc format war.

Sony's laser communication devices for small satellites rely on the technologies developed for the company's optical disc products.

In 1983, Sony introduced 90 mm micro diskettes (better known as floppy disks), which it had developed at a time when there were 4" floppy disks, and many variations from different companies, to replace the then on-going 5.25" floppy disks. Sony had great success and the format became dominant. 3.5" floppy disks gradually became obsolete as they were replaced by current media formats. Sony held more than a 70 percent share of the market when it decided to pull the plug on the format in 2010.

In 1998, Sony launched the Memory Stick format, the flash memory cards for use in Sony lines of digital cameras and portable music players. It has seen little support outside of Sony's own products, with Secure Digital cards (SD) commanding considerably greater popularity. Sony has made updates to the Memory Stick format with Memory Stick Duo and Memory Stick Micro.

Sony introduced FeliCa, a contactless IC card technology primarily used in contactless payment, as a result of the company's joint development and commercialization of Near-Field Communication (NFC) with Philips. The standard is largely offered in two forms, either chips embedded in smartphones or plastic cards with chips embedded in them. Sony plans to implement this technology in train systems across Asia.

In 2019, Sony launched the ELTRES, the company's proprietary low-power wide-area wireless communication (LPWAN) standard.

Best known for its electronic products, Sony offers a wide variety of product lines in many areas. At its peak, it was dubbed as a "corporate octopus", for the sprawling businesses from electronics to entertainment to chemicals. It has unwound many business units including Sony Chemicals and Vaio PC but still runs diverse businesses.

As of 2020, Sony is organized into the following business segments: Game & Network Services (G&NS), Music, Pictures, Electronics Products & Solutions (EP&S), Imaging & Sensing Solutions (I&SS), Financial Services, and Others. Usually, each business segment has a handful of corresponding intermediate holding companies under which all the related businesses are folded into, such as Columbia Records being part of Sony Music Group, a subsidiary and, at the same time, a holding company for Sony's music businesses, along with SMEJ.

Sony Corporation is the electronics business unit and the parent company of the Sony Group. It primarily conducts strategic business planning of the group, research and development (R&D), planning, designing and marketing for electronics products.

Sony released the world's first portable music player, the Walkman, in 1979, bundled with the MDL-3L2 headphones. This line fostered a fundamental change in music listening habits by allowing people to carry music with them and listen to music through lightweight headphones. Originally used to refer portable audio cassette players, the Walkman brand has been widely adopted by the company to encompass its portable digital audio and video players as well as a line of former Sony Ericsson mobile phones. In the case of optical disc players, the Discman brand was used until the late 1990s.

Sony is a major audio products manufacturer and one of the active noise control technology leaders.

Sony produced the TV8-301, the world's first all-transistor television, in 1959. In 1968, the company introduced the Trinitron brand name for its lines of aperture grille cathode ray tube televisions and afterwards computer monitors. Sony stopped production of Trinitron for most markets, but continued producing sets for markets such as Pakistan, Bangladesh and China. Sony discontinued its series of Trinitron computer monitors in 2005. The company discontinued the last Trinitron-based television set in the US in early 2007. The end of Trinitron marked the end of Sony's analog television sets and monitors.

Sony used the LCD WEGA name for its LCD TVs until summer 2005. The company then introduced the BRAVIA name. BRAVIA is an in-house brand owned by Sony which produces high-definition LCD televisions, projection TVs and front projectors, home cinemas and the BRAVIA home theatre range. All Sony high-definition flat-panel LCD televisions in North America have carried the logo for BRAVIA since 2005. In 2006, Sony lost its decades-long No.1 market share in the global television market. In November 2007, the Sony XEL-1, the first OLED television, was released and manufactured for two years. Later in 2013, Sony demonstrated the first 4K OLED television. As of 2012, Sony was the third-largest maker of televisions in the world and the business unit had been unprofitable for eight consecutive years.
From 2011, Sony started restructuring of its loss-making television business, mainly by down-sizing business units and outsourcing the manufacturing of display panels to the companies like Sharp Corporation, LG Display, and Samsung Electronics. In December 2011, Sony agreed to sell all stake in an LCD joint venture with Samsung Electronics (S-LCD) for about $940 million. On 28 March 2012, Sony and Sharp announced that they have agreed to further amend the joint venture agreement originally executed by the parties in July 2009, as amended in April 2011, for the establishment and operation of Sharp Display Products Corporation ("SDP"), a joint venture to produce and sell large-sized LCD panels and modules. The agreement was eventually terminated as Sony parted ways. Sony's small-sized LCD business subsidiary and medium-to-large-sized OLED display business unit were spun off and became part of Japan Display and JOLED, respectively.

In 2017, Sony launched OLED televisions under the BRAVIA brand.

Also, Sony has sold a range of tapes, discs, recorders and players for videocassette, DVD, and Blu-ray formats for decades.

Sony offers a wide range of digital cameras. Its point-and-shoot models adopt the Cyber-shot name, while digital single-lens reflex models are branded using Alpha. It also produces action cameras and camcorders, with the company's cinema-grade products being sold under the CineAlta name.

Sony demonstrated a prototype of the Sony Mavica in 1981 and released it for the consumer market in 1988. The first Cyber-shot was introduced in 1996. Sony's market share of the digital camera market fell from a high of 20% to 9% by 2005.

Sony entered the market for digital single-lens reflex cameras in 2006 when it acquired the camera business of Konica Minolta. Sony rebranded the company's line of cameras as its Alpha line. Sony is the world's third largest manufacturer of the cameras, behind Canon and Nikon respectively.

In 2010, Sony introduced their first mirrorless interchangeable-lens cameras, which were the NEX-3 and the NEX-5. They also started a new lens mount system, which was the E-mount. There were quite a few NEX models out there, when Sony decided to melt the NEX series into the Alpha series. The first Alpha MILC was the α3000, which was introduced in August 2013. It was followed by the Full-Frame α7 and α7R in October, then the successors of the NEX-5, the NEX-6 and NEX-7, the α5000 and the α6000 in 2014. The α6000 became the most popular MILC ever and Sony became the largest MILC manufacturer. Sony didn't announce a new DSLR since the November 2015, which was the α68.

Sony produced computers (MSX home computers and NEWS workstations) during the 1980s. The company withdrew from the computer business around 1990. Sony entered again into the global computer market under the new VAIO brand, began in 1996. Short for "Video Audio Integrated Operation", the line was the first computer brand to highlight visual-audio features.

Sony faced considerable controversy when some of its laptop batteries exploded and caught fire in 2006, resulting in the largest computer-related recall to that point in history.

In a bid to join the tablet computer market, the company launched its Sony Tablet line of Android tablets in 2011. Since 2012, Sony's Android products have been marketed under the Xperia brand used for its smartphones.

On 4 February 2014, Sony announced that it would sell its VAIO PC business due to poor sales and Japanese company Japan Industrial Partners (JIP) will purchase the VAIO brand, with the deal finalized by the end of March 2014. As of 2018, Sony maintained a 5% stake in the new, independent company.

Sony has targeted medical, healthcare and biotechnology business as a growth sector in the future. The company acquired iCyt Mission Technology, Inc. (renamed Sony Biotechnology Inc. in 2012), a manufacturer of flow cytometers, in 2010 and Micronics, Inc., a developer of microfluidics-based diagnostic tools, in 2011.

In 2012, Sony announced that it would acquire all shares of So-net Entertainment Corporation, the largest shareholder of M3, Inc., an operator of portal sites (m3.com, MR-kun, MDLinx and MEDI:GATE) for healthcare professionals.

On 28 September 2012, Olympus and Sony announced that the two companies will establish a joint venture to develop new surgical endoscopes with 4K resolution (or higher) and 3D capability. Sony Olympus Medical Solutions Inc. (Sony 51%, Olympus 49%) was established on 16 April 2013.

On 28 February 2014, Sony, M3 and Illumina established a joint venture called P5, Inc. to provide a genome analysis service for research institutions and enterprises in Japan.

Sony Mobile Communications Inc. (formerly Sony Ericsson Mobile Communications) is a multinational smartphone manufacturing company headquartered in Tokyo, Japan and a wholly owned subsidiary of Sony Corporation.

In 2001, Sony entered into a joint venture with Swedish telecommunications company Ericsson, forming Sony Ericsson Mobile Communications. Initial sales were rocky, and the company posted losses in 2001 and 2002. However, Sony Ericsson reached a profit in 2003. The company distinguished itself with multimedia-capable mobile phones, which included features such as cameras. These were unusual at the time. Despite their innovations, Sony Ericsson faced intense competition from Apple's iPhone, which was released in 2007. From 2008 to 2010, amid a global recession, Sony Ericsson slashed its workforce by several thousand. In 2009, Sony Ericsson was the fourth-largest mobile phone manufacturer in the world (after Nokia, Samsung and LG). By 2010, its market share had fallen to sixth place. Sony acquired Ericsson's share of the venture in 2012 for over US$1 billion. Sony Mobile Communications now focuses exclusively on the smartphone market under the Xperia brand.

In 2013, Sony contributed to around two percent of the mobile phone market with 37 million mobile phones sold. Sony Mobile's sales reached a peak in 2014 with 40 million handsets, the volume has since decreased. Sony shipped 13.5 million phones in 2017, 6.5 million in 2018, and 3.2 million handsets in FY 2019.

Since the late 1990s, Sony has released numerous consumer robots, including dog-shaped robots called AIBO, a music playing robot called Rolly, and a humanoid robot called QRIO. Despite being a pioneer in the field, Sony had ceased robotics-related operations for 10 years due to financial difficulties, until it decided to revive them in 2016.

In 2015, Sony partnered with an autonomous driving startup ZMP INC. to estblish an aerial surveillance and reconnaissance drone manufacturer named Aerosense.

Sony traces its roots in the semiconductor business back to 1954, when it became the first Japanese company to commercialize the transistor. As of 2020, the company, through its chip business arm Sony Semiconductor Solutions, designs, manufactures, and sells a wide range of semiconductors and electronic components, including image sensors (HAD CCD, Exmor), image processors (BIONZ), laser diodes, system LSIs, mixed-signal LSIs, emerging memory storage, emerging displays (microLED, microOLED, and holographic display), multi-functional microcomputer ("SPRESENSE"), etc.

As of 2019, Sony was the world's largest manufacturer of CMOS image sensors as its chips are widely used in digital cameras, tablet computers and smartphones.

Sony Interactive Entertainment (formerly Sony Computer Entertainment) is best known for producing the popular line of PlayStation consoles. The line grew out of a failed partnership with Nintendo. Originally, Nintendo requested Sony to develop an add-on for its console that would play Compact Discs. In 1991 Sony announced the add-on, as well as a dedicated console known as the "Play Station". However, a disagreement over software licensing for the console caused the partnership to fall through. Sony then continued the project independently.

Launched in 1994, the first PlayStation gained 61% of global console sales and broke Nintendo's long-standing lead in the market. Sony followed up with the PlayStation 2 in 2000, which was even more successful. The console has become the most successful of all time, selling over 150 million units . Sony released the PlayStation 3, a high-definition console, in 2006. It was the first console to use the Blu-ray format, and was considerably more expensive than the competitors Xbox 360 and Wii due to the Cell processor. Early on, poor sales performance resulted in significant losses for the company, pushing it to sell the console at a loss. The PlayStation 3 sold generally more poorly than its competitors in the early years of its release but managed to overtake the Xbox 360 in global sales later on. It later introduced the PlayStation Move, an accessory that allows players to control video games using motion gestures.
Sony extended the brand to the portable games market in 2004 with the PlayStation Portable (PSP). The console has sold reasonably, but has taken a second place to a rival handheld, the Nintendo DS. Sony developed the Universal Media Disc (UMD) optical disc medium for use on the PlayStation Portable. Early on, the format was used for movies, but it has since lost major studio support. Sony released a disc-less version of its PlayStation Portable, the PSP Go, in 2009. The company went on to release its second portable video game system, PlayStation Vita, in 2011 and 2012. Sony launched its fourth console, the PlayStation 4, on 15 November 2013, which as of 31 December 2017 has sold 73.6 million units globally.

On 18 March 2014, at GDC, president of Sony Computer Entertainment Worldwide Studios Shuhei Yoshida announced their new virtual reality technology dubbed Project Morpheus, and later named PlayStation VR, for PlayStation 4. The headset brought VR gaming and non-gaming software to the company's console. According to a report released by Houston-based patent consulting firm LexInnova in May 2015, Sony is leading the virtual reality patent race. According to the firm's analysis of nearly 12,000 patents or patent applications, Sony has 366 virtual reality patents or patent applications. PlayStation VR was released worldwide on 13 October 2016.

Sony Entertainment has two divisions: Sony Pictures Entertainment, Sony Music Group (Sony Music Entertainment, Sony/ATV Music Publishing). Sony USA previously owned and operated Sony Trans Com: a technology business that provided in-flight entertainment programming as well as video and audio playback equipment for the airline industry. Sony had purchased the business from Sundstrand Corp. in 1989 and subsequently sold it to Rockwell Collins in 2000.

In 2012, Sony rolled most of its consumer content services (including video, music and gaming) into the Sony Entertainment Network, the predecessor of Playstaion Network.

Sony Pictures Entertainment Inc. (SPE) is the television and film production/distribution unit of Sony. With 12.5% box office market share in 2011, the company was ranked third among movie studios. Its group sales in 2010 were US$7.2 billion. The company has produced many notable movie franchises, including "Spider-Man", "The Karate Kid" and "Men in Black". It has also produced the popular television game shows "Jeopardy!" and "Wheel of Fortune".

Sony entered the television and film production market when it acquired Columbia Pictures Entertainment in 1989 for $3.4 billion. Columbia lives on in the Sony Pictures Motion Picture Group, a division of SPE which in turn owns Columbia Pictures and TriStar Pictures among other film production and distribution companies such as Screen Gems, Sony Pictures Classics, Sony Pictures Home Entertainment. SPE's television division is known as Sony Pictures Television.
For the first several years of its existence, Sony Pictures Entertainment performed poorly, leading many to suspect the company would sell off the division. Sony Pictures Entertainment encountered controversy in the early 2000s. In July 2000, a marketing executive working for Sony Corporation created a fictitious film critic, David Manning, who gave consistently good reviews for releases from Sony subsidiary Columbia Pictures that generally received poor reviews amongst real critics. Sony later pulled the ads, suspended Manning's creator and his supervisor and paid fines to the state of Connecticut and to fans who saw the reviewed films in the US. In 2006 Sony started using ARccOS Protection on some of their film DVDs, but later issued a recall.

In late 2014, Sony Pictures became the target of a hack attack from a clandestine group called Guardians of Peace, weeks before releasing the anti-North Korean comedy film "The Interview".

Sony Music Entertainment (also known as SME or Sony Music) is the second-largest global recorded music company of the "big three" record companies and is controlled by Sony Corporation of America, the United States subsidiary of Japan's "Sony".

In one of its largest-ever acquisitions, Sony purchased CBS Record Group in 1988 for US$2 billion. In the process, Sony partnered and gained the rights to the ATV catalogue of Michael Jackson, considered by the "Guinness Book of World Records" to be the most successful entertainer of all time. The acquisition of CBS Records provided the foundation for the formation of Sony Music Entertainment, which Sony established in 1991.

In 1968, Sony and CBS Records had formed a 50:50 joint-venture CBS/Sony Records, later renamed CBS/Sony Group, in Japan. When CBS Records was acquired, a 50% stake in CBS/Sony Group owned by CBS was also transferred to Sony. In March 1988, four wholly owned subsidiaries were folded into CBS/Sony Group and the company was renamed as Sony Music Entertainment Japan (SMEJ). It operates independently of Sony Music as it is directly owned by Japanese Sony.

In 2004, Sony entered into a joint venture with Bertelsmann AG, merging Sony Music Entertainment with Bertelsmann Music Group to create Sony BMG. In 2005, Sony BMG faced a copy protection scandal, because its music CDs had installed malware on users' computers that was posing a security risk to affected customers. In 2007, the company acquired Famous Music for US$370 million, gaining the rights to the catalogues of Eminem and Akon, among others. Sony bought out Bertelsmann's share in Sony BMG and formed a new Sony Music Entertainment in 2008. Since then, the company has undergone management changes.

Sony purchased digital music recognition company Gracenote for US$260 million in 2008. Tribune Media Company acquired Gracenote from Sony in 2014 for $170 million.

Besides its record label, Sony operates other music businesses. In 1995, Sony merged its publisher with Michael Jackson's ATV Music Publishing, forming Sony/ATV Music Publishing. At the time, the publishing company was the second largest of its kind in the world. The company owns the publishing rights to over 4 million compositions, including The Beatles' Lennon-McCartney catalogue, Bob Dylan, Eminem, Lady Gaga, Sam Smith, Ed Sheeran, and Taylor Swift.

In 2012, Sony/ATV then acquired a majority stake in EMI Music Publishing, becoming the world's largest music publishing company. In 2018, Sony bought the rest of the shares in the publisher, making it a wholly owned subsidiary. As of 2016, Sony owns all of Sony/ATV.<ref name="Sony Finalizes Acquisition of Michael Jackson Estate's Stake in Sony/ATV Publishing"></ref>

Sony Financial Holdings is a holding company for Sony's financial services business which includes Sony Life (in Japan and the Philippines), Sony Assurance, Sony Bank, etc. The unit proved to be the most profitable of Sony's businesses in FY 2005, earning $1.7 billion in profit. Sony Financial's low fees have aided the unit's popularity while threatening Sony's premium brand name.

A company behind the commercialization of lithium-ion battery, Sony had been exploring the possibility to manufacture the batteries for electric vehicles. In 2014, Sony participated within NRG Energy eVgo Ready for Electric Vehicle (REV) program, for EV charging parking lots. However, the company then decided to sell its lithium-ion battery business to Murata Manufacturing in 2016.

The IT giants such as Google (Google driverless car/Waymo) and Apple (iCar/Project Titan) have been working on electric vehicles and self driving cars, competing with Tesla; Sony was considered to be following suit with an $842,000 investment in ZMP INC. In January 2020, Sony unveiled a concept electric car at the Consumer Electronics Show, named Vision-S, designed in collaboration with components manufacturer Magna International. At the occasion, Sony also stated its goal of developing technology for the automotive sector, especially concerning autonomous driving, sensors, and in-car entertainment.

Sony is a "kabushiki gaisha" registered to the Tokyo Stock Exchange in Japan and the New York Stock Exchange for overseas trading. As of 31 March 2020, there are a total of 423,556 shareholders and 1,261,058,781 shares issued. A majority of issued shares are held by foreign institutions and investors.

Sony is one of Japan's largest corporations by market capitalization and operating profit. As of July 2020, its market value is at over $90 billion, placing Sony as one of the five most valuable companies in Japan. At the same period, Sony was also recognized as the most cash-rich Japanese company, with its net cash reserves of ¥1.8 trillion.

The company was immensely profitable throughout the 1990s and early 2000s in part because of the success of its new PlayStation line. The company encountered financial difficulty in the mid- to late-2000s due to a number of factors: the global financial crisis, increased competition for PlayStation, and the devastating Japanese earthquake of 2011. The company faced three consecutive years of losses leading up to 2011. While noting the negative effects of intervening circumstances such as natural disasters and fluctuating currency exchange rates, the "Financial Times" criticized the company for its "lack of resilience" and "inability to gauge the economy." The newspaper voiced skepticism about Sony's revitalization efforts, given a lack of tangible results.

In September 2000 Sony had a market capitalization of $100 billion; but by December 2011 it had plunged to $18 billion, reflecting falling prospects for Sony but also reflecting grossly inflated share prices of the 'dot-com bubble' years. Net worth, as measured by stockholder equity, has steadily grown from $17.9 billion in March 2002 to $35.6 billion through December 2011. Earnings yield (inverse of the price to earnings ratio) has never been more than 5% and usually much less; thus Sony has always traded in over-priced ranges with the exception of the 2009 market bottom.

On 9 December 2008, Sony Corporation announced that it would be cutting 8,000 jobs, dropping 8,000 contractors and reducing its global manufacturing sites by 10% to save $1.1 billion per year.

In April 2012, Sony announced that it would reduce its workforce by 10,000 (6% of its employee base) as part of CEO Kaz Hirai's effort to get the company back into the black. This came after a loss of 520 billion yen (roughly US$6.36 billion) for fiscal 2012, the worst since the company was founded. Accumulation loss for the past four years was 919.32 billion-yen. Sony planned to increase its marketing expenses by 30% in 2012. 1,000 of the jobs cut come from the company's mobile phone unit's workforce. 700 jobs will be cut in the 2012–2013 fiscal year and the remaining 300 in the following fiscal year. Sony had revenues of ¥6.493 trillion in 2012 and maintained large reserves of cash, with ¥895 billion on hand as of 2012. In May 2012, Sony's market capitalization was valued at about $15 billion.

In January 2013, Sony announced it was selling its US headquarters building for $1.1 billion to a consortium led by real estate developer The Chetrit Group.

On 28 January 2014, Moody's Investors Services dropped Sony's credit rating to Ba1—"judged to have speculative elements and a significant credit risk"—saying that the company's "profitability is likely to remain weak and volatile."

On 6 February 2014, Sony announced it would trim as many as 5,000 jobs as it attempts to sell its PC business and focus on mobile and tablets.

In 2014, Sony South Africa closed its TV, Hi-Fi and camera divisions with the purpose of reconsidering its local distribution model and, in 2017, it returned facilitated by Premium Brand Distributors (Pty) Ltd.
In November 2011, Sony was ranked 9th (jointly with Panasonic) in Greenpeace's Guide to Greener Electronics. This chart grades major electronics companies on their environmental work. The company scored 3.6/10, incurring a penalty point for comments it has made in opposition to energy efficiency standards in California. It also risks a further penalty point in future editions for being a member of trade associations that have commented against energy efficiency standards. Together with Philips, Sony receives the highest score for energy policy advocacy after calling on the EU to adopt an unconditional 30% reduction target for greenhouse gas emissions by 2020. Meanwhile, it receives full marks for the efficiency of its products. In June 2007, Sony ranked 14th on the Greenpeace guide. Sony fell from its earlier 11th-place ranking due to Greenpeace's claims that Sony had double standards in their waste policies.

Since 1976, Sony has had an Environmental Conference. Sony's policies address their effects on global warming, the environment, and resources. They are taking steps to reduce the amount of greenhouse gases that they put out as well as regulating the products they get from their suppliers in a process that they call "green procurement". Sony has said that they have signed on to have about 75 percent of their Sony Building running on geothermal power. The "Sony Take Back Recycling Program" allow consumers to recycle the electronics products that they buy from Sony by taking them to eCycle (Recycling) drop-off points around the U.S. The company has also developed a biobattery that runs on sugars and carbohydrates that works similarly to the way living creatures work. This is the most powerful small biobattery to date.

In 2000, Sony faced criticism for a document entitled "NGO Strategy" that was leaked to the press. The document involved the company's surveillance of environmental activists in an attempt to plan how to counter their movements. It specifically mentioned environmental groups that were trying to pass laws that held electronics-producing companies responsible for the cleanup of the toxic chemicals contained in their merchandise.

Sony Corporation is actively involved in the EYE SEE project conducted by UNICEF. EYE SEE digital photography workshops have been run for children in Argentina, Tunisia, Mali, South Africa, Ethiopia, Madagascar, Rwanda, Liberia and Pakistan.

Sony assists The South Africa Primary Education Support Initiative (SAPESI) through financial donations and children book donations to the South Africa Mobile Library Project.

The Sony Canada Charitable Foundation (SCCF) is a non-profit organization which supports three key charities; the Make-A-Wish Canada, the United Way of Canada and the EarthDay and ECOKIDS program.

After the 2011 Queensland floods and Victorian bushfires, Sony Music released benefit albums with money raised going to the Sony Foundation. You Can is the youth cancer program of Sony Foundation.

Sony launched its Open Planet Ideas Crowdsourcing Project, in partnership with the World Wildlife Fund and the design group, IDEO.

On the occasion of the 2014 World Cup in Brazil, Sony partnered with and launched the Street Football Stadium Project to support football-based educational programmes in local communities across Latin America and Brazil. More than 25 Street Stadiums were developed since the project's inception.




</doc>
<doc id="26990" url="https://en.wikipedia.org/wiki?curid=26990" title="Social psychology">
Social psychology

In the field of psychology, social psychology is the scientific study of how the thoughts, feelings, and behaviors of individuals are influenced by the actual, imagined, and implied presence of others. In this definition, "scientific" refers to the empirical investigation using the scientific method, while the terms "thoughts", "feelings", and "behaviors" refer to the psychological variables that can be measured in humans. Moreover, the notion that the presence of others may be "imagined" or "implied" suggests that humans are to social influences even when alone, such as when watching videos, quietly appreciating art, or even sitting on the toilet. In such situations, people can be influenced to follow internalized cultural norms.

Social psychologists typically explain human behavior as a result of the relation between mental state and social situation, studying the factors/conditions under which certain behavior, actions, and feelings occur. Social psychology, thus, is concerned with the way these feelings, thoughts, beliefs, intentions, and goals, are cognitively constructed and how these mental representations, in turn, influence our interactions with others.

Traditionally, the emergence of this discipline bridged the gap between psychology and sociology. During the years immediately following World War II, there was frequent collaboration between psychologists and sociologists. The two disciplines, however, have become increasingly specialized and isolated from each other in recent years, with sociologists generally focusing on more macro features (e.g., social structure)—as the prefix of denotes a "societal" influence—whereas psychologists may be more concerned with more micro features. Nevertheless, sociological approaches to psychology remain an important counterpart to psychological research in this area.

In addition to the split between psychology and sociology, there has been a somewhat less pronounced difference in emphasis between American and European social psychologists, as, the former traditionally have focused more on the individual, whereas the latter have generally paid more attention to group-level phenomena.

Although older writings regarding social psychology have existed—such as those by Islamic philosopher Al-Farabi (aka Alpharabius)—the discipline of social psychology, as its modern-day definition, began in the United States at the beginning of the 20th century. By this time, however, the discipline itself had already developed a significant foundation.

Following the 18th century, those in the emerging field of social psychology were concerned with developing concrete explanations for different aspects of human nature. They would attempt to discover concrete cause-and-effect relationships that explain the social interactions in the world around them. In order to do so, they believed that the scientific method, an empirically based scientific measure, could be applied to human behavior.

The first published study in this field was an experiment in 1898 by Norman Triplett, on the phenomenon of social facilitation. During the 1930s, many Gestalt psychologists, most notably Kurt Lewin, fled to the United States from Nazi Germany. They would be instrumental in developing the field as an area separate from that of the dominant behavioral and psychoanalytic schools during that time. Social psychology would continue to maintain the legacy of the foundational interests in perception and cognition. As such, attitudes and small group phenomena were the most commonly studied topics in this era.

During World War II, social psychologists were primarily engaged with studies of persuasion and propaganda for the U.S. military (see also psychological warfare). Following the war, researchers would become interested in a variety of social problems, including issues of gender and racial prejudice. Most notable, revealing, and of these were the shock experiments on obedience to authority conducted by Stanley Milgram.

In the 1960s, there would be growing interest in topics such as cognitive dissonance, bystander intervention, and aggression. By the 1970s, however, social psychology in America had reached a crisis, as heated debates would emerge over: ethical concerns about laboratory experimentation; whether attitude could actually predict behavior; and how much science could really be done in a cultural context. This was also the time when a radical situationist approach came to challenge the relevance of self and personality in psychology.

Throughout the 1980s and 1990s, social psychology reached a more mature level, especially in regard to theory and methodology. Now, careful ethical standards regulate research, and pluralistic and multicultural perspectives have emerged. Modern researchers are interested in many phenomena, though attribution, social cognition, and the self-concept are perhaps the greatest areas of growth in recent years. Social psychologists have also maintained their applied interests with contributions in the social psychology of health, education, law, and the workplace.

In social psychology, "attitude" is defined as learned, global evaluations of a person, object, place, or issue that influence thought and action. In simpler terms, attitudes are basic expressions of approval and disapproval, favorability and unfavorability, or, as Bem (1970) suggests, likes and dislikes (e.g. enjoying chocolate ice cream, or endorsing the values of a particular political party.)

In regard to attitudes, social psychologists have studied attitude formation; the structure of attitudes; attitude change; the function of attitudes; and the relationship between attitude and behavior. Because people are influenced by situation, general attitudes are not always good predictors of specific behavior, e.g. a person may value the environment, but, for a variety of reasons, not recycle a plastic bottle on a particular day.

In recent times, research on attitudes has examined the distinction between traditional self-reported attitude measures and "implicit" or unconscious attitudes. Experiments using the "implicit-association test", for instance, have found that people often demonstrate implicit bias against other races, even when their explicit responses reveal equal mindedness. Likewise, one study found that explicit attitudes correlate with verbal behavior in interracial interactions, whereas implicit attitudes correlate with nonverbal behavior.

One hypothesis on how attitudes are formed, first advanced in 1983 by Abraham Tesser, is that strong likes and dislikes are ingrained in our genetic make-up. Tesser speculates that individuals are disposed to hold certain strong attitudes as a result of inborn physical, sensory, and cognitive skills, temperament, and personality traits. Whatever disposition nature elects to give us, our most treasured attitudes are often formed as a result of exposure to attitude objects; our history of rewards and punishments; the attitude that our parents, friends, and enemies express; the social and cultural context in which we live; and other types of experiences we have. Obviously, attitudes are formed through the basic process of learning. Numerous studies have shown that people can form strong positive and negative attitudes toward neutral objects that are in some way linked to emotionally charged stimuli.

Attitudes are also involved in several other areas of the discipline, such as conformity, interpersonal attraction, social perception, and prejudice.

The topic of persuasion has received a great deal of attention in recent years. Persuasion is an active method of influence that attempts to guide people toward the adoption of an attitude, idea, or behavior by rational or emotive means. Persuasion relies on "appeals" rather than strong pressure or coercion. The process of persuasion has been founded to be influenced by numerous variables ("who" said "what" to "whom" and "how"), which generally fall into one of five major categories:

Dual-process theories of persuasion (such as the elaboration likelihood model) maintain that the persuasive process is mediated by two separate routes; central and peripheral. The central route of persuasion is more fact-based and results in longer lasting change, but requires motivation to process. The peripheral route is more superficial and results in shorter lasting change, but does not require as much motivation to process. An example of a peripheral route of persuasion might be a politician using a flag lapel pin, smiling, and wearing a crisp, clean shirt. Notice that this does not require motivation to be persuasive, but should not last as long as persuasion based on the central route. If that politician were to outline exactly what they believed, and their previous voting record, this would be using the central route, and would result in longer lasting change, but would require a good deal of motivation to process.

Social cognition is a growing area of social psychology that studies how people perceive, think about, and remember information about others. Much research rests on the assertion that people think about (other) people differently from non-social targets. This assertion is supported by the social cognitive deficits exhibited by people with Williams syndrome and autism. Person perception is the study of how people form impressions of others. The study of how people form beliefs about each other while interacting is known as interpersonal perception.

A major research topic in social cognition is attribution. Attributions are the explanations we make for people's behavior, either our own behavior or the behavior of others. One element of attribution ascribes the locus of a behavior to either internal or external factors. An "internal", or dispositional, attribution assigns behavior to causes related to inner traits such as personality, disposition, character or ability. An "external", or situational, attribution involves situational elements, such as the weather. A second element of attribution ascribes the cause of behavior to either stable or unstable factors (whether the behavior will be repeated or changed under similar circumstances). Finally, we also attribute causes of behavior to either controllable or uncontrollable factors: how much control one has over the situation at hand.

Numerous biases in the attribution process have been discovered. For instance, the fundamental attribution error is the tendency to make dispositional attributions for behavior, overestimating the influence of personality and underestimating the influence of situations. The actor-observer difference is a refinement of this bias, the tendency to make dispositional attributions for other people's behavior and situational attributions for our own. The self-serving bias is the tendency to attribute dispositional causes for successes, and situational causes for failure, particularly when self-esteem is threatened. This leads to assuming one's successes are from innate traits, and one's failures are due to situations, including other people. Other ways people protect their self-esteem are by believing in a just world, blaming victims for their suffering, and making defensive attributions, which explain our behavior in ways which defend us from feelings of vulnerability and mortality. Researchers have found that mildly depressed individuals often lack this bias and actually have more realistic perceptions of reality (as measured by the opinions of others).

Heuristics are cognitive shortcuts. Instead of weighing all the evidence when making a decision, people rely on heuristics to save time and energy. The availability heuristic occurs when people estimate the probability of an outcome based on how easy that outcome is to imagine. As such, vivid or highly memorable possibilities will be perceived as more likely than those that are harder to picture or are difficult to understand, resulting in a corresponding cognitive bias. The representativeness heuristic is a shortcut people use to categorize something based on how similar it is to a prototype they know of. Numerous other biases have been found by social cognition researchers. The hindsight bias is a false memory of having predicted events, or an exaggeration of actual predictions, after becoming aware of the outcome. The confirmation bias is a type of bias leading to the tendency to search for, or interpret information in a way that confirms one's preconceptions.

Another key concept in social cognition is the assumption that reality is too complex to easily discern. As a result, we tend to see the world according to simplified schemas or images of reality. Schemas are generalized mental representations that organize knowledge and guide information processing. Schemas often operate automatically and unintentionally, and can lead to biases in perception and memory. Expectations from schemas may lead us to see something that is not there. One experiment found that people are more likely to misperceive a weapon in the hands of a black man than a white man. This type of schema is actually a stereotype, a generalized set of beliefs about a particular group of people (when incorrect, an ultimate attribution error). Stereotypes are often related to negative or preferential attitudes (prejudice) and behavior (discrimination). Schemas for behaviors (e.g., going to a restaurant, doing laundry) are known as "scripts".

Self-concept is a term referring to the whole sum of beliefs that people have about themselves. However, what specifically does self-concept consist of? According to Hazel Markus (1977), the self-concept is made up of cognitive molecules called self-schemas—beliefs that people have about themselves that guide the processing of self-reliant information. For example, an athlete at a university would have multiple selves that would process different information pertinent to each self: the student would be one "self," who would process information pertinent to a student (taking notes in class, completing a homework assignment, etc.); the athlete would be the "self" who processes information about things related to being an athlete (recognizing an incoming pass, aiming a shot, etc.). These "selves" are part of one's identity and the self-reliant information is the information that relies on the proper "self" to process and react on it. If a "self" is not part of one's identity, then it is much more difficult for one to react. For example, a civilian may not know how to handle a hostile threat as a trained Marine would. The Marine contains a "self" that would enable him/her to process the information about the hostile threat and react accordingly, whereas a civilian may not contain that self, disabling them from properly processing the information from the hostile threat and, furthermore, debilitating them from acting accordingly. Self-schemas are to an individual's total self–concept as a hypothesis is to a theory, or a book is to a library. A good example is the body weight self-schema; people who regard themselves as over or underweight, or for those whom body image is a significant self-concept aspect, are considered "schematics" with respect to weight. For these people a range of otherwise mundane events – grocery shopping, new clothes, eating out, or going to the beach – can trigger thoughts about the self. In contrast, people who do not regard their weight as an important part of their lives are "a-schematic" on that attribute.

It is rather clear that the self is a special object of our attention. Whether one is mentally focused on a memory, a conversation, a foul smell, the song that is stuck in one's head, or this sentence, consciousness is like a spotlight. This spotlight can shine on only one object at a time, but it can switch rapidly from one object to another and process the information out of awareness. In this spotlight the self is front and center: things relating to the self have the spotlight more often.

The "ABCs" of self are:


"Affective forecasting" is the process of predicting how one would feel in response to future emotional events. Studies done in 2003 by Timothy Wilson and Daniel Gilbert have shown that people overestimate the strength of reaction to anticipated positive and negative life events that they actually feel when the event does occur.

There are many theories on the perception of our own behavior. Daryl Bem's (1972) "self-perception theory" claims that when internal cues are difficult to interpret, people gain self-insight by observing their own behavior. Leon Festinger's (1954) "social comparison theory" is that people evaluate their own abilities and opinions by comparing themselves to others when they are uncertain of their own ability or opinions. There is also the "facial feedback hypothesis": changes in facial expression can lead to corresponding changes in emotion.

The fields of social psychology and personality have merged over the years, and social psychologists have developed an interest in self-related phenomena. In contrast with traditional personality theory, however, social psychologists place a greater emphasis on cognitions than on traits. Much research focuses on the self-concept, which is a person's understanding of their self. The self-concept is often divided into a cognitive component, known as the "self-schema", and an evaluative component, the "self-esteem". The need to maintain a healthy self-esteem is recognized as a central human motivation in the field of social psychology.

Self-efficacy beliefs are associated with the self-schema. These are expectations that performance on some task will be effective and successful. Social psychologists also study such self-related processes as self-control and self-presentation.

People develop their self-concepts by varied means, including introspection, feedback from others, self-perception, and social comparison. By comparing themselves to relevant others, people gain information about themselves, and they make inferences that are relevant to self-esteem. Social comparisons can be either "upward" or "downward," that is, comparisons to people who are either higher in status or ability, or lower in status or ability. Downward comparisons are often made in order to elevate self-esteem.

Self-perception is a specialized form of attribution that involves making inferences about oneself after observing one's own behavior. Psychologists have found that too many extrinsic rewards (e.g. money) tend to reduce intrinsic motivation through the self-perception process, a phenomenon known as overjustification. People's attention is directed to the reward and they lose interest in the task when the reward is no longer offered. This is an important exception to reinforcement theory.

Social influence is an overarching term given to describe the persuasive effects people have on each other. It is seen as a fundamental value in social psychology and overlaps considerably with research on attitudes and persuasion. The three main areas of social influence include: conformity, compliance, and obedience. Social influence is also closely related to the study of group dynamics, as most principles of influence are strongest when they take place in social groups.

The first major area of social influence is conformity. Conformity is defined as the tendency to act or think like other members of a group. The identity of members within a group, i.e. status, similarity, expertise, as well as cohesion, prior commitment, and accountability to the group help to determine the level of conformity of an individual. Individual variation among group members plays a key role in the dynamic of how willing people will be to conform. Conformity is usually viewed as a negative tendency in American culture, but a certain amount of conformity is adaptive in some situations, as is nonconformity in other situations.

The second major area of social influence research is compliance. Compliance refers to any change in behavior that is due to a request or suggestion from another person. The foot-in-the-door technique is a compliance method in which the persuader requests a small favor and then follows up with requesting a larger favor, e.g., asking for the time and then asking for ten dollars. A related trick is the bait and switch.

The third major form of social influence is obedience; this is a change in behavior that is the result of a direct order or command from another person. Obedience as a form of compliance was dramatically highlighted by the Milgram study, wherein people were ready to administer shocks to a person in distress on a researcher's command.

An unusual kind of social influence is the self-fulfilling prophecy. This is a prediction that, in being made, actually causes itself to become true. For example, in the stock market, if it is widely believed that a crash is imminent, investors may lose confidence, sell most of their stock, and thus actually cause the crash. Similarly, people may expect hostility in others and actually induce this hostility by their own behavior.

Psychologist have spent decades studying the power of social influence, and the way in which it manipulates people's opinions and behavior. Specifically, social influence refers to the way in which individuals change their ideas and actions to meet the demands of a social group, received authority, social role or a minority within a group wielding influence over the majority. No matter if you are student, teacher, doctor, lawyer or entrepreneur, you will encounter some type of social influence.

A group can be defined as two or more individuals that are connected to each another by social relationships. Groups tend to interact, influence each other, and share a common identity. They have a number of emergent qualities that distinguish them from aggregates:

Temporary groups and aggregates share few or none of these features, and do not qualify as true social groups. People waiting in line to get on a bus, for example, do not constitute a group.

Groups are important not only because they offer social support, resources, and a feeling of belonging, but because they supplement an individual's self-concept. To a large extent, humans define themselves by the group memberships which form their social identity. The shared social identity of individuals within a group influences intergroup behavior, the way in which groups behave towards and perceive each other. These perceptions and behaviors in turn define the social identity of individuals within the interacting groups. The tendency to define oneself by membership in a group may lead to intergroup discrimination, which involves favorable perceptions and behaviors directed towards the in-group, but negative perceptions and behaviors directed towards the out-group. On the other hand, such discrimination and segregation may sometimes exist partly to facilitate a diversity which strengthens society. Intergroup discrimination leads to prejudice and stereotyping, while the processes of social facilitation and group polarization encourage extreme behaviors towards the out-group.

Groups often moderate and improve decision making, and are frequently relied upon for these benefits, such as in committees and juries. A number of group biases, however, can interfere with effective decision making. For example, group polarization, formerly known as the "risky shift," occurs when people polarize their views in a more extreme direction after group discussion. More problematic is the phenomenon of groupthink. This is a collective thinking defect that is characterized by a premature consensus or an incorrect assumption of consensus, caused by members of a group failing to promote views which are not consistent with the views of other members. Groupthink occurs in a variety of situations, including isolation of a group and the presence of a highly directive leader. Janis offered the 1961 Bay of Pigs Invasion as a historical case of groupthink.

Groups also affect performance and productivity. Social facilitation, for example, is a tendency to work harder and faster in the presence of others. Social facilitation increases the "dominant response"s likelihood, which tends to improve performance on simple tasks and reduce it on complex tasks. In contrast, social loafing is the tendency of individuals to slack off when working in a group. Social loafing is common when the task is considered unimportant and individual contributions are not easy to see.

Social psychologists study group-related (collective) phenomena such as the behavior of crowds. An important concept in this area is deindividuation, a reduced state of self-awareness that can be caused by feelings of anonymity. Deindividuation is associated with uninhibited and sometimes dangerous behavior. It is common in crowds and mobs, but it can also be caused by a disguise, a uniform, alcohol, dark environments, or online anonymity.

A major area in the study of people's relations to each other is interpersonal attraction. This refers to all forces that lead people to like each other, establish relationships, and (in some cases) fall in love. Several general principles of attraction have been discovered by social psychologists, but many still continue to experiment and do research to find out more. One of the most important factors in interpersonal attraction is how similar two particular people are. The more similar two people are in general attitudes, backgrounds, environments, worldviews, and other traits, the more probable an attraction is possible.

Physical attractiveness is an important element of romantic relationships, particularly in the early stages characterized by high levels of passion. Later on, similarity and other compatibility factors become more important, and the type of love people experience shifts from "passionate" to "companionate". Robert Sternberg (1986) has suggested that there are actually three components of love: intimacy, passion, and commitment. When two (or more) people experience all three, they are said to be in a state of consummate love.

According to social exchange theory, relationships are based on rational choice and cost-benefit analysis. If one partner's costs begin to outweigh their benefits, that person may leave the relationship, especially if there are good alternatives available. This theory is similar to the minimax principle proposed by mathematicians and economists (despite the fact that human relationships are not zero-sum games). With time, long-term relationships tend to become communal rather than simply based on exchange.

Social psychology is an empirical science that attempts to answer questions about human behavior by testing hypotheses, both in the laboratory and in the field. Careful attention to sampling, research design, and statistical analysis is important; results are published in peer reviewed journals such as the "Journal of Experimental Social Psychology", "Personality and Social Psychology Bulletin" and the "Journal of Personality and Social Psychology". Social psychology studies also appear in general science journals such as "Psychological Science" and "Science".

Experimental methods involve the researcher altering a variable in the environment and measuring the effect on another variable. An example would be allowing two groups of children to play violent or nonviolent videogames, and then observing their subsequent level of aggression during free-play period. A valid experiment is controlled and uses random assignment.

Correlational methods examine the statistical association between two naturally occurring variables. For example, one could correlate the amount of violent television children watch at home with the number of violent incidents the children participate in at school. Note that this study would "not" prove that violent TV causes aggression in children: it is quite possible that aggressive children choose to watch more violent TV.

Observational methods are purely descriptive and include naturalistic observation, "contrived" observation, participant observation, and archival analysis. These are less common in social psychology but are sometimes used when first investigating a phenomenon. An example would be to unobtrusively observe children on a playground (with a videocamera, perhaps) and record the number and types of aggressive actions displayed.

Whenever possible, social psychologists rely on controlled experimentation. Controlled experiments require the manipulation of one or more independent variables in order to examine the effect on a dependent variable. Experiments are useful in social psychology because they are high in internal validity, meaning that they are free from the influence of confounding or extraneous variables, and so are more likely to accurately indicate a causal relationship. However, the small samples used in controlled experiments are typically low in external validity, or the degree to which the results can be generalized to the larger population. There is usually a trade-off between experimental control (internal validity) and being able to generalize to the population (external validity).

Because it is usually impossible to test everyone, research tends to be conducted on a sample of persons from the wider population. Social psychologists frequently use survey research when they are interested in results that are high in external validity. Surveys use various forms of random sampling to obtain a sample of respondents that are representative of a population. This type of research is usually descriptive or correlational because there is no experimental control over variables. Some psychologists have raised concerns about social psychological research for relying too heavily on studies conducted on university undergraduates in academic settings, or participants from crowdsourcing labor markets such as Amazon Mechanical Turk. In a study by David O. Sears (1986), over 70% of experiments used North American undergraduates as subjects, a subset of the population that are unrepresentative of the population as a whole.

Regardless of which method has been chosen to be used, the results are of high importance. Results need to be used to evaluate the hypothesis of the research that is done. These results should either confirm or reject the original hypothesis that was predicted. There are two different types of testing social psychologists use in order to test their results. Statistics and probability testing define a significant finding that can be as low as 5% or less, likely to be due to chance. Replications are important, to ensure that the result is valid and not due to chance, or some feature of a particular sample. False positive conclusions, often resulting from the pressure to publish or the author's own confirmation bias, are a hazard in the field.

The Asch conformity experiments demonstrated the power of conformity in small groups with a line length estimation task that was designed to be extremely easy. In well over a third of the trials, participants conformed to the majority, who had been instructed to provide incorrect answers, even though the majority judgment was clearly wrong. Seventy-five percent of the participants conformed at least once during the experiment. Additional manipulations to the experiment showed participant conformity decreased when at least one other individual failed to conform, but increased when the individual began conforming or withdrew from the experiment. Also, participant conformity increased substantially as the number of incorrect individuals increased from one to three, and remained high as the incorrect majority grew. Participants with three incorrect opponents made mistakes 31.8% of the time, while those with one or two incorrect opponents made mistakes only 3.6% and 13.6% of the time, respectively.

In Leon Festinger's cognitive dissonance experiment, participants were asked to perform a boring task. They were divided into 2 groups and given two different pay scales. At the study's end, some participants were paid $1 to say that they enjoyed the task and another group of participants was paid $20 to say the same lie. The first group ($1) later reported liking the task better than the second group ($20). Festinger's explanation was that for people in the first group being paid only $1 is not sufficient incentive for lying and those who were paid $1 experienced dissonance. They could only overcome that dissonance by justifying their lies by changing their previously unfavorable attitudes about the task. Being paid $20 provides a reason for doing the boring task, therefore no dissonance.

One of the most notable experiments in social psychology was the Milgram experiment, which studied how far people would go to obey an authority figure. Following the events of The Holocaust in World War II, the experiment showed that (most) normal American citizens were capable of following orders from an authority even when they believed they were causing an innocent person to suffer.

In the Stanford prison study, by Philip Zimbardo, a simulated exercise between student prisoners and guards showed how far people would follow an adopted role. In just a few days, the "guards" became brutal and cruel, and the prisoners became miserable and compliant. This was initially argued to be an important demonstration of the power of the immediate social situation and its capacity to overwhelm normal personality traits. However, to this day, it remains a matter of contention what conclusions may be drawn from this study. For example, it has been pointed out that participant self-selection may have affected the participants' behaviour, and that the participants' personality influenced their reactions in a variety of ways, including how long they chose to remain in the study. One of the most concerted empirical revisitations of the themes raised by Zimbardo came with the 2002 BBC prison study.

Muzafer Sherif's "robbers' cave" study divided boys into two competing groups to explore how much hostility and aggression would emerge. Sherif's explanation of the results became known as realistic group conflict theory, because the intergroup conflict was induced through competition over resources. Inducing cooperation and superordinate goals later reversed this effect.

Albert Bandura's Bobo doll experiment demonstrated how aggression is learned by imitation. This set of studies fueled debates regarding media violence which continue to be waged among scholars.

The goal of social psychology is to understand cognition and behavior as they naturally occur in a social context, but the very act of observing people can influence and alter their behavior. For this reason, many social psychology experiments utilize deception to conceal or distort certain aspects of the study. Deception may include false cover stories, false participants (known as confederates or stooges), false feedback given to the participants, and so on.

The practice of deception has been challenged by some psychologists who maintain that deception under any circumstances is unethical, and that other research strategies (e.g., role-playing) should be used instead. Unfortunately, research has shown that role-playing studies do not produce the same results as deception studies and this has cast doubt on their validity. In addition to deception, experimenters have at times put people into potentially uncomfortable or embarrassing situations (e.g., the Milgram experiment and Stanford prison experiment), and this has also been criticized for ethical reasons.

To protect the rights and well-being of research participants, and at the same time discover meaningful results and insights into human behavior, virtually all social psychology research must pass an ethical review process. At most colleges and universities, this is conducted by an ethics committee or Institutional Review Board. This group examines the proposed research to make sure that no harm is likely to be done to the participants, and that the study's benefits outweigh any possible risks or discomforts to people taking part in the study.

Furthermore, a process of informed consent is often used to make sure that volunteers know what will happen in the experiment and understand that they are allowed to quit the experiment at any time. A debriefing is typically done at the experiment's conclusion in order to reveal any deceptions used and generally make sure that the participants are unharmed by the procedures. Today, most research in social psychology involves no more risk of harm than can be expected from routine psychological testing or normal daily activities.

Social Psychology plays a key role in a child's development. During this time, teens are faced with many issues and decisions that can impact a teen's social development. They are faced with self esteem issues, peer pressure, drugs, alcohol, tobacco, sex, social media and more. Psychologists today are not fully aware of the effect of social media. Social media is worldwide, so one can be influenced by something they will never encounter in real life. In 2019, social media had become the single most important activity in adolescents and even some older adults lives.

Social psychology has recently found itself at the center of a "replication crisis" due to some research findings proving difficult to replicate. Replication failures are not unique to social psychology and are found in all fields of science. However, several factors have combined to put social psychology at the center of the current controversy.

Firstly, questionable research practices (QRP) have been identified as common in the field. Such practices, while not necessarily intentionally fraudulent, involve converting undesired statistical outcomes into desired outcomes via the manipulation of statistical analyses, sample size or data management, typically to convert non-significant findings into significant ones. Some studies have suggested that at least mild versions of QRP are highly prevalent. One of the critics of Daryl Bem in the feeling the future controversy has suggested that the evidence for precognition in this study could (at least in part) be attributed to QRP.

Secondly, social psychology has found itself at the center of several recent scandals involving outright fraudulent research. Most notably the admitted data fabrication by Diederik Stapel as well as allegations against others. However, most scholars acknowledge that fraud is, perhaps, the lesser contribution to replication crises.

Third, several effects in social psychology have been found to be difficult to replicate even before the current replication crisis. For example, the scientific journal "Judgment and Decision Making" has published several studies over the years that fail to provide support for the unconscious thought theory. Replications appear particularly difficult when research trials are pre-registered and conducted by research groups not highly invested in the theory under questioning.

These three elements together have resulted in renewed attention for replication supported by Daniel Kahneman. Scrutiny of many effects have shown that several core beliefs are hard to replicate. A 2014 special edition of "Social Psychology" focused on replication studies and a number of previously held beliefs were found to be difficult to replicate. Likewise, a 2012 special edition of "Perspectives on Psychological Science" also focused on issues ranging from publication bias to null-aversion that contribute to the replication crises in psychology.

It is important to note that this replication crisis does not mean that social psychology is unscientific. Rather this process is a healthy if sometimes acrimonious part of the scientific process in which old ideas or those that cannot withstand careful scrutiny are pruned. The consequence is that some areas of social psychology once considered solid, such as social priming, have come under increased scrutiny due to failed replications.



</doc>
<doc id="26992" url="https://en.wikipedia.org/wiki?curid=26992" title="Suleiman the Magnificent">
Suleiman the Magnificent

Suleiman I (; 6 November 1494 – 6 September 1566), commonly known as Suleiman the Magnificent in the West and Suleiman the Lawgiver () in his realm, was the tenth and longest-reigning Sultan of the Ottoman Empire from 1520 until his death in 1566. Under his administration, the Ottoman caliphate ruled over at least 25 million people.

Suleiman succeeded his father as sultan in September 1520 and began his reign with campaigns against the Christian powers in central Europe and the Mediterranean. Belgrade fell to him in 1521 and Rhodes, long under the rule of the Knights of St. John, in 1522–23. At Mohács, in August 1526, Suleiman broke the military strength of Hungary, with the Hungarian king Louis II losing his life in the battle.

Suleiman became a prominent monarch of 16th-century Europe, presiding over the apex of the Ottoman Empire's economic, military and political power. Suleiman personally led Ottoman armies in conquering the Christian strongholds of Belgrade and Rhodes as well as most of Hungary before his conquests were checked at the Siege of Vienna in 1529. He annexed much of the Middle East in his conflict with the Safavids and large areas of North Africa as far west as Algeria. Under his rule, the Ottoman fleet dominated the seas from the Mediterranean to the Red Sea and through the Persian Gulf.

At the helm of an expanding empire, Suleiman personally instituted major Judicial changes relating to society, education, taxation and criminal law. His reforms, carried out in conjunction with the empire's chief judicial official Ebussuud Efendi, harmonized the relationship between the two forms of Ottoman law: sultanic (Kanun) and religious (Sharia). He was a distinguished poet and goldsmith; he also became a great patron of culture, overseeing the "Golden" age of the Ottoman Empire in its artistic, literary and architectural development.

Breaking with Ottoman tradition, Suleiman married Hürrem Sultan, a woman from his harem, an Orthodox Christian of Ruthenian origin who converted to Islam, and who became famous in the West by the name Roxelana, purportedly due to her red hair. Their son Selim II succeeded Suleiman following his death in 1566 after 46 years of rule. Suleiman's other potential heirs, Mehmed and Mustafa, had died; the former had died from smallpox, and the latter had been strangled to death 13 years earlier at the sultan's order. His other son Bayezid was executed in 1561 on Suleiman's orders, along with Bayezid's four sons, after a rebellion. Although scholars no longer believe that the empire declined after his death, the end of Suleiman's reign is still frequently characterized as a watershed in Ottoman history. In the decades after Suleiman, the empire began to experience significant political, institutional, and economic changes, a phenomenon often referred to as the Transformation of the Ottoman Empire. 

Suleiman the Magnificent ( "Muḥteşem Süleymān"), as he was known in the West, was also called Suleiman the First ( "Sulṭān Süleymān-ı Evvel"), and Suleiman the Lawgiver ( "Ḳānūnī Sulṭān Süleymān") for his reform of the Ottoman legal system.

It is unclear when exactly the term "Kanunî" (the Lawgiver) first came to be used as an epithet for Suleiman. It is entirely absent from sixteenth and seventeenth-century Ottoman sources, and may date from the early 18th century.

Suleiman was born in Trabzon along the east coast of the Black Sea to Şehzade Selim (later Selim I), probably on 6 November 1494, although this date is not known with absolute certainty. His mother was Hafsa Sultan, a convert to Islam of unknown origins, who died in 1534. At the age of seven, Suleiman was sent to study science, history, literature, theology and military tactics in the schools of the imperial Topkapı Palace in Constantinople (modern Istanbul). As a young man, he befriended Pargalı Ibrahim, a slave who later became one of his most trusted advisers (but who was later executed on Suleiman's orders). At age seventeen, he was appointed as the governor of first Kaffa (Theodosia), then Manisa, with a brief tenure at Edirne.

Upon the death of his father, Selim I (r. 1512–1520), Suleiman entered Constantinople and ascended to the throne as the tenth Ottoman Sultan. An early description of Suleiman, a few weeks following his accession, was provided by the Venetian envoy Bartolomeo Contarini: 

Upon succeeding his father, Suleiman began a series of military conquests, eventually suppressing a revolt led by the Ottoman-appointed governor of Damascus in 1521. Suleiman soon made preparations for the conquest of Belgrade from the Kingdom of Hungary—something his great-grandfather Mehmed II had failed to achieve because of John Hunyadi's strong defense in the region. Its capture was vital in removing the Hungarians and Croats who, following the defeats of the Albanians, Bosniaks, Bulgarians, Byzantines and the Serbs, remained the only formidable force who could block further Ottoman gains in Europe. Suleiman encircled Belgrade and began a series of heavy bombardments from an island in the Danube. Belgrade, with a garrison of only 700 men, and receiving no aid from Hungary, fell in August 1521.

The road to Hungary and Austria lay open, but Suleiman turned his attention instead to the Eastern Mediterranean island of Rhodes, the home base of the Knights Hospitaller. Suleiman built a large fortification, Marmaris Castle, that served as a base for the Ottoman Navy. Following the five-month Siege of Rhodes (1522), Rhodes capitulated and Suleiman allowed the Knights of Rhodes to depart. The conquest of the island cost the Ottomans 50,000 to 60,000 dead from battle and sickness (Christian claims went as high as 64,000 Ottoman battle deaths and 50,000 disease deaths).

As relations between Hungary and the Ottoman Empire deteriorated, Suleiman resumed his campaign in Central Europe, and on 29 August 1526 he defeated Louis II of Hungary (1506–1526) at the Battle of Mohács. Upon encountering the lifeless body of King Louis, Suleiman is said to have lamented: "I came indeed in arms against him; but it was not my wish that he should be thus cut off before he scarcely tasted the sweets of life and royalty." While Suleiman was campaigning in Hungary, Turkmen tribes in central Anatolia (in Cilicia) revolted under the leadership of Kalender Çelebi.

Some Hungarian nobles proposed that Ferdinand, who was the ruler of neighboring Austria and tied to Louis II's family by marriage, be King of Hungary, citing previous agreements that the Habsburgs would take the Hungarian throne if Louis died without heirs. However, other nobles turned to the nobleman Ioan Zápolya, who was being supported by Suleiman. Under Charles V and his brother Ferdinand I, the Habsburgs reoccupied Buda and took possession of Hungary. Reacting in 1529, Suleiman marched through the valley of the Danube and regained control of Buda; in the following autumn, his forces laid siege to Vienna. This was to be the Ottoman Empire's most ambitious expedition and the apogee of its drive to the West. With a reinforced garrison of 16,000  men, the Austrians inflicted the first defeat on Suleiman, sowing the seeds of a bitter Ottoman–Habsburg rivalry that lasted until the 20th century. His second attempt to conquer Vienna failed in 1532, as Ottoman forces were delayed by the siege of Güns and failed to reach Vienna. In both cases, the Ottoman army was plagued by bad weather, forcing them to leave behind essential siege equipment, and was hobbled by overstretched supply lines.

By the 1540s a renewal of the conflict in Hungary presented Suleiman with the opportunity to avenge the defeat suffered at Vienna. In 1541, the Habsburgs attempted to lay siege to Buda but were repulsed, and more Habsburg fortresses were captured by the Ottomans in two consecutive campaigns in 1541 and 1544 as a result, Ferdinand and Charles were forced to conclude a humiliating five-year treaty with Suleiman. Ferdinand renounced his claim to the Kingdom of Hungary and was forced to pay a fixed yearly sum to the Sultan for the Hungarian lands he continued to control. Of more symbolic importance, the treaty referred to Charles V not as 'Emperor' but as the 'King of Spain', leading Suleiman to identify as the true 'Caesar'.

As Suleiman stabilized his European frontiers, he now turned his attention to the ever-present threat posed by the Shi'a Safavid dynasty of Persia. Two events in particular were to precipitate a recurrence of tensions. First, Shah Tahmasp had the Baghdad governor loyal to Suleiman killed and replaced with an adherent of the Shah, and second, the governor of Bitlis had defected and sworn allegiance to the Safavids. As a result, in 1533, Suleiman ordered his Grand Vizier Pargalı Ibrahim Pasha to lead an army into eastern Asia Minor where he retook Bitlis and occupied Tabriz without resistance. Having joined Ibrahim in 1534, Suleiman made a push towards Persia, only to find the Shah sacrificing territory instead of facing a pitched battle, resorting to harassment of the Ottoman army as it proceeded along the harsh interior. When in the following year Suleiman made a grand entrance into Baghdad, he greatly enhanced his prestige by restoring the tomb of Abu Hanifa, the founder of the Hanafi school of Islamic law to which the Ottomans adhered.

Attempting to defeat the Shah once and for all, Suleiman embarked upon a second campaign in 1548–1549. As in the previous attempt, Tahmasp avoided confrontation with the Ottoman army and instead chose to retreat, using scorched earth tactics in the process and exposing the Ottoman army to the harsh winter of the Caucasus. Suleiman abandoned the campaign with temporary Ottoman gains in Tabriz and the Urmia region, a lasting presence in the province of Van, control of the western half of Azerbaijan and some forts in Georgia.

In 1553 Suleiman began his third and final campaign against the Shah. Having initially lost territories in Erzurum to the Shah's son, Suleiman retaliated by recapturing Erzurum, crossing the Upper Euphrates and laying waste to parts of Persia. The Shah's army continued its strategy of avoiding the Ottomans, leading to a stalemate from which neither army made any significant gain. In 1555, a settlement known as the Peace of Amasya was signed which defined the borders of the two empires. By this treaty, Armenia and Georgia were divided equally between the two, with Western Armenia, western Kurdistan, and western Georgia (incl. western Samtskhe) falling in Ottoman hands while Eastern Armenia, eastern Kurdistan, and eastern Georgia (incl. eastern Samtskhe) stayed in Safavid hands. The Ottoman Empire obtained most of Iraq, including Baghdad, which gave them access to the Persian Gulf, while the Persians retained their former capital Tabriz and all their other northwestern territories in the Caucasus and as they were prior to the wars, such as Dagestan and all of what is now Azerbaijan.

Ottoman ships had been sailing in the Indian Ocean since the year 1518. Ottoman admirals such as Hadim Suleiman Pasha, Seydi Ali Reis and Kurtoğlu Hızır Reis are known to have voyaged to the Mughal imperial ports of Thatta, Surat and Janjira. The Mughal Emperor Akbar the Great himself is known to have exchanged six documents with Suleiman the Magnificent.

Suleiman led several naval campaigns against the Portuguese in an attempt to remove them and reestablish trade with the Mughal Empire. Aden in Yemen was captured by the Ottomans in 1538, in order to provide an Ottoman base for raids against Portuguese possessions on the western coast of the Mughal Empire. Sailing on, the Ottomans failed against the Portuguese at the Siege of Diu in September 1538, but then returned to Aden, where they fortified the city with 100 pieces of artillery. From this base, Sulayman Pasha managed to take control of the whole country of Yemen, also taking Sana'a.

With its strong control of the Red Sea, Suleiman successfully managed to dispute control of the trade routes to the Portuguese and maintained a significant level of trade with the Mughal Empire throughout the 16th century.

From 1526 till 1543, Suleiman stationed over 900 Turkish soldiers to fight alongside the Somali Adal Sultanate led by Ahmad ibn Ibrahim al-Ghazi during the Conquest of Abyssinia. After the first Ajuran-Portuguese war, the Ottoman Empire would in 1559 absorb the weakened Adal Sultanate into its domain. This expansion fathered Ottoman rule in Somalia and the Horn of Africa. This also increased its influence in the Indian Ocean to compete with the Portuguese Empire with its close ally, the Ajuran Empire.

In 1564, Suleiman received an embassy from Aceh (a sultanate on Sumatra, in modern Indonesia), requesting Ottoman support against the Portuguese. As a result, an Ottoman expedition to Aceh was launched, which was able to provide extensive military support to the Acehnese.

The discovery of new maritime trade routes by Western European states allowed them to avoid the Ottoman trade monopoly. The Portuguese discovery of the Cape of Good Hope in 1488 initiated a series of Ottoman-Portuguese naval wars in the Ocean throughout the 16th century. The Ajuran Sultanate allied with the Ottomans defied the Portuguese economic monopoly in the Indian Ocean by employing a new coinage which followed the Ottoman pattern, thus proclaiming an attitude of economic independence in regard to the Portuguese.

Having consolidated his conquests on land, Suleiman was greeted with the news that the fortress of Koroni in Morea (the modern Peloponnese, peninsular Greece) had been lost to Charles V's admiral, Andrea Doria. The presence of the Spanish in the Eastern Mediterranean concerned Suleiman, who saw it as an early indication of Charles V's intention to rival Ottoman dominance in the region. Recognizing the need to reassert naval preeminence in the Mediterranean, Suleiman appointed an exceptional naval commander in the form of Khair ad Din, known to Europeans as Barbarossa. Once appointed admiral-in-chief, Barbarossa was charged with rebuilding the Ottoman fleet.

In 1535, Charles V led a Holy League of 27,000 soldiers (10,000 Spaniards, 8,000 Italians, 8,000 Germans, and 700 Knights of St. John) to victory against the Ottomans at Tunis, which together with the war against Venice the following year, led Suleiman to accept proposals from Francis I of France to form an alliance against Charles. Huge Muslim territories in North Africa were annexed. The piracy carried on thereafter by the Barbary pirates of North Africa can be seen in the context of the wars against Spain.
In 1542, facing a common Habsburg enemy, Francis I sought to renew the Franco-Ottoman alliance. In early 1542, Polin successfully negotiated the details of the alliance, with the Ottoman Empire promising to send 60,000 troops against the territories of the German king Ferdinand, as well as 150 galleys against Charles, while France promised to attack Flanders, harass the coasts of Spain with a naval force, and send 40 galleys to assist the Turks for operations in the Levant.

Elsewhere in the Mediterranean, when the Knights Hospitallers were re-established as the Knights of Malta in 1530, their actions against Muslim navies quickly drew the ire of the Ottomans, who assembled another massive army in order to dislodge the Knights from Malta. The Ottomans invaded Malta in 1565, undertaking the Great Siege of Malta, which began on 18 May and lasted until 8 September, and is portrayed vividly in the frescoes of Matteo Perez d'Aleccio in the Hall of St. Michael and St. George. At first it seemed that this would be a repeat of the battle on Rhodes, with most of Malta's cities destroyed and half the Knights killed in battle; but a relief force from Spain entered the battle, resulting in the loss of 10,000 Ottoman troops and the victory of the local Maltese citizenry.

While Sultan Suleiman was known as "the Magnificent" in the West, he was always "Kanuni" Suleiman or "The Lawgiver" () to his Ottoman subjects. The overriding law of the empire was the Shari'ah, or Sacred Law, which as the divine law of Islam was outside of the Sultan's powers to change. Yet an area of distinct law known as the "Kanuns" (, canonical legislation) was dependent on Suleiman's will alone, covering areas such as criminal law, land tenure and taxation. He collected all the judgments that had been issued by the nine Ottoman Sultans who preceded him. After eliminating duplications and choosing between contradictory statements, he issued a single legal code, all the while being careful not to violate the basic laws of Islam. It was within this framework that Suleiman, supported by his Grand Mufti Ebussuud, sought to reform the legislation to adapt to a rapidly changing empire. When the Kanun laws attained their final form, the code of laws became known as the "kanun‐i Osmani" (), or the "Ottoman laws". Suleiman's legal code was to last more than three hundred years.

The Sultan also played a role in protecting the Jewish subjects of his empire for centuries to come. In late 1553 or 1554, on the suggestion of his favorite doctor and dentist, the Spanish Jew Moses Hamon, the Sultan issued a "firman" () formally denouncing blood libels against the Jews. Furthermore, Suleiman enacted new criminal and police legislation, prescribing a set of fines for specific offenses, as well as reducing the instances requiring death or mutilation. In the area of taxation, taxes were levied on various goods and produce, including animals, mines, profits of trade, and import-export duties.

Higher "medreses" provided education of university status, whose graduates became "imams" () or teachers. Educational centers were often one of many buildings surrounding the courtyards of mosques, others included libraries, baths, soup kitchens, residences and hospitals for the benefit of the public.

Under Suleiman's patronage, the Ottoman Empire entered the golden age of its cultural development. Hundreds of imperial artistic societies (called the "Ehl-i Hiref", "Community of the Craftsmen") were administered at the Imperial seat, the Topkapı Palace. After an apprenticeship, artists and craftsmen could advance in rank within their field and were paid commensurate wages in quarterly annual installments. Payroll registers that survive testify to the breadth of Suleiman's patronage of the arts, the earliest of the documents dating from 1526 list 40 societies with over 600 members. The "Ehl-i Hiref" attracted the empire's most talented artisans to the Sultan's court, both from the Islamic world and from the recently conquered territories in Europe, resulting in a blend of Arabic, Turkish and European cultures. Artisans in service of the court included painters, book binders, furriers, jewellers and goldsmiths. Whereas previous rulers had been influenced by Persian culture (Suleiman's father, Selim I, wrote poetry in Persian), Suleiman's patronage of the arts saw the Ottoman Empire assert its own artistic legacy.

Suleiman himself was an accomplished poet, writing in Persian and Turkish under the takhallus (nom de plume) "Muhibbi" (, "Lover"). Some of Suleiman's verses have become Turkish proverbs, such as the well-known "Everyone aims at the same meaning, but many are the versions of the story". When his young son Mehmed died in 1543, he composed a moving chronogram to commemorate the year: "Peerless among princes, my Sultan Mehmed". In Turkish the chronogram reads ("Şehzadeler güzidesi Sultan Muhammed'üm"), in which the Arabic Abjad numerals total 955, the equivalent in the Islamic calendar of 1543 AD. In addition to Suleiman's own work, many great talents enlivened the literary world during Suleiman's rule, including Fuzûlî and Bâkî. The literary historian Elias John Wilkinson Gibb observed that "at no time, even in Turkey, was greater encouragement given to poetry than during the reign of this Sultan". Suleiman's most famous verse is:

<poem style="margin-left:2em">
The people think of wealth and power as the greatest fate,
But in this world a spell of health is the best state.
What men call sovereignty is a worldly strife and constant war;
Worship of God is the highest throne, the happiest of all estates.
</poem>

Suleiman also became renowned for sponsoring a series of monumental architectural developments within his empire. The Sultan sought to turn Constantinople into the center of Islamic civilization by a series of projects, including bridges, mosques, palaces and various charitable and social establishments. The greatest of these were built by the Sultan's chief architect, Mimar Sinan, under whom Ottoman architecture reached its zenith. Sinan became responsible for over three hundred monuments throughout the empire, including his two masterpieces, the Süleymaniye and Selimiye mosques—the latter built in Adrianople (now Edirne) in the reign of Suleiman's son Selim II. Suleiman also restored the Dome of the Rock in Jerusalem and the Walls of Jerusalem (which are the current walls of the Old City of Jerusalem), renovated the Kaaba in Mecca, and constructed a complex in Damascus.

Suleiman had two known consorts, though in total there were 17 women in his harem.


Suleiman had several children with his consorts, including:



Suleiman was infatuated with Hurrem Sultan, a harem girl from Ruthenia, then part of Poland. Western diplomats, taking notice of the palace gossip about her, called her "Russelazie" or "Roxelana", referring to her Ruthenian origins. The daughter of an Orthodox priest, she was captured by Tatars from Crimea, sold as a slave in Constantinople, and eventually rose through the ranks of the Harem to become Suleiman's favorite. Hurrem, a former concubine, became the legal wife of the Sultan, much to the astonishment of the observers in the palace and the city. He also allowed Hurrem Sultan to remain with him at court for the rest of her life, breaking another tradition—that when imperial heirs came of age, they would be sent along with the imperial concubine who bore them to govern remote provinces of the Empire, never to return unless their progeny succeeded to the throne.

Under his pen name, Muhibbi, Sultan Suleiman composed this poem for Hurrem Sultan:
<poem style="margin-left:2em">
Throne of my lonely niche, my wealth, my love, my moonlight.
My most sincere friend, my confidant, my very existence, my Sultan, my one and only love.
The most beautiful among the beautiful ...
My springtime, my merry faced love, my daytime, my sweetheart, laughing leaf ...
My plants, my sweet, my rose, the one only who does not distress me in this room ...
My Istanbul, my karaman, the earth of my Anatolia
My Badakhshan, my Baghdad and Khorasan
My woman of the beautiful hair, my love of the slanted brow, my love of eyes full of misery ...
I'll sing your praises always
I, lover of the tormented heart, Muhibbi of the eyes full of tears, I am happy.
</poem>

Suleiman could speak Ottoman Turkish, Arabic, Chagatai, Persian and Serbian.

Pargalı Ibrahim Pasha was a friend of Suleiman from before his accession. Ibrahim was originally a Christian from Parga (in Epirus), who was captured in a raid during the 1499–1503 Ottoman–Venetian War, and was given as a slave to Suleiman most likely in 1514. Ibrahim converted to Islam and Suleiman made him the royal falconer, then promoted him to first officer of the Royal Bedchamber. Ibrahim Pasha rose to Grand Vizier in 1523 and commander-in-chief of all the armies. Suleiman also conferred upon Ibrahim Pasha the honor of "beylerbey" of Rumelia (first-ranking military governor-general), granting Ibrahim authority over all Ottoman territories in Europe, as well as command of troops residing within them in times of war.

During his thirteen years as Grand Vizier, his rapid rise to power and vast accumulation of wealth had made Ibrahim many enemies at the Sultan's court. Suleiman's suspicion of Ibrahim was worsened by a quarrel between the latter and the finance secretary ("defterdar") İskender Çelebi. The dispute ended in the disgrace of Çelebi on charges of intrigue, with Ibrahim convincing Suleiman to sentence the "defterdar" to death. Ibrahim also supported Şehzade Mustafa as the successor of Suleiman. This caused disputes between him and Hürrem Sultan, who wanted her sons to succeed to the throne. Ibrahim eventually fell from grace with the Sultan. Suleiman consulted his Qadi, who suggested that Ibrahim be put to death. The Sultan recruited assassins and ordered them to strangle Ibrahim in his sleep.

Sultan Suleiman's two known consorts (Hürrem and Mahidevran) had borne him six sons, four of whom survived past the 1550s. They were Mustafa, Selim, Bayezid, and Cihangir. Of these, the eldest was not Hürrem's son, but rather Mahidevran's. Hürrem is usually held at least partly responsible for the intrigues in nominating a successor, though there is no evidence to support this. Although she was Suleiman's wife, she exercised no official public role. This did not, however, prevent Hürrem from wielding powerful political influence. Since the Empire lacked, until the reign of Ahmed I, any formal means of nominating a successor, successions usually involved the death of competing princes in order to avert civil unrest and rebellions.

By 1552, when the campaign against Persia had begun with Rüstem appointed commander-in-chief of the expedition, intrigues against Mustafa began. Rüstem sent one of Suleiman's most trusted men to report that since Suleiman was not at the head of the army, the soldiers thought the time had come to put a younger prince on the throne; at the same time he spread rumours that Mustafa had proved receptive to the idea. Angered by what he came to believe were Mustafa's plans to claim the throne, the following summer upon return from his campaign in Persia, Suleiman summoned him to his tent in the Ereğli valley. When Mustafa entered his father's tent to meet with him, Suleiman's eunuchs attacked Mustafa, and after a long struggle the mutes killed him using a bow-string.
Cihangir is said to have died of grief a few months after the news of his half-brother's murder. The two surviving brothers, Selim and Bayezid, were given command in different parts of the empire. Within a few years, however, civil war broke out between the brothers, each supported by his loyal forces. With the aid of his father's army, Selim defeated Bayezid in Konya in 1559, leading the latter to seek refuge with the Safavids along with his four sons. Following diplomatic exchanges, the Sultan demanded from the Safavid Shah that Bayezid be either extradited or executed. In return for large amounts of gold, the Shah allowed a Turkish executioner to strangle Bayezid and his four sons in 1561, clearing the path for Selim's succession to the throne five years later.

On 6 September 1566, Suleiman, who had set out from Constantinople to command an expedition to Hungary, died before an Ottoman victory at the Battle of Szigetvár in Hungary and the Grand Vizier kept his death secret during the retreat for the enthronement of Selim II. Just the night before the sickly sultan died in his tent, two months before he would have turned 72. The sultan's body was taken back to Istanbul to be buried, while his heart, liver, and some other organs were buried in Turbék, outside Szigetvár. A mausoleum constructed above the burial site came to be regarded as a holy place and pilgrimage site. Within a decade a mosque and Sufi hospice were built near it, and the site was protected by a salaried garrison of several dozen men.

The formation of Suleiman's legacy began even before his death. Throughout his reign literary works were commissioned praising Suleiman and constructing an image of him as an ideal ruler, most significantly by Celalzade Mustafa, chancellor of the empire from 1534–1557. Later Ottoman writers applied this idealised image of Suleiman to the Near Eastern literary genre of advice literature named "naṣīḥatnāme", urging sultans to conform to his model of rulership and to maintain the empire's institutions in their sixteenth-century form. Such writers were pushing back against the political and institutional transformation of the empire after the middle of the sixteenth century, and portrayed deviation from the norm as it had existed under Suleiman as evidence of the decline of the empire. Western historians, failing to recognise that these 'decline writers' were working within an established literary genre and often had deeply personal reasons for criticizing the empire, long took their claims at face value and consequently adopted the idea that the empire entered a period of decline after the death of Suleiman. Since the 1980s this view has been thoroughly reexamined, and modern scholars have come to overwhelmingly reject the idea of decline, labelling it an "untrue myth".

Suleiman's conquests had brought under the control of the Empire major Muslim cities (such as Baghdad), many Balkan provinces (reaching present day Croatia and Hungary), and most of North Africa. His expansion into Europe had given the Ottoman Turks a powerful presence in the European balance of power. Indeed, such was the perceived threat of the Ottoman Empire under the reign of Suleiman that Austria's ambassador Busbecq warned of Europe's imminent conquest: "On [the Turks'] side are the resources of a mighty empire, strength unimpaired, habituation to victory, endurance of toil, unity, discipline, frugality and watchfulness ... Can we doubt what the result will be? ... When the Turks have settled with Persia, they will fly at our throats supported by the might of the whole East; how unprepared we are I dare not say." Suleiman's legacy was not, however, merely in the military field. The French traveler Jean de Thévenot bears witness a century later to the "strong agricultural base of the country, the well being of the peasantry, the abundance of staple foods and the pre-eminence of organization in Suleiman's government".

Even thirty years after his death, "Sultan Solyman" was quoted by the English playwright William Shakespeare as a military prodigy in "The Merchant of Venice", where the Prince of Morocco boasts about his prowess by saying that he defeated Suleiman in three battles (Act 2, Scene 1).

Through the distribution of court patronage, Suleiman also presided over a Golden Age in Ottoman arts, witnessing immense achievement in the realms of architecture, literature, art, theology and philosophy. Today the skyline of the Bosphorus and of many cities in modern Turkey and the former Ottoman provinces, are still adorned with the architectural works of Mimar Sinan. One of these, the Süleymaniye Mosque, is the final resting place of Suleiman: he is buried in a domed mausoleum attached to the mosque.

Nevertheless, assessments of Suleiman's reign have frequently fallen into the trap of the Great Man theory of history. The administrative, cultural, and military achievements of the age were a product not of Suleiman alone, but also of the many talented figures who served him, such as grand viziers Ibrahim Pasha and Rüstem Pasha, the Grand Mufti Ebussuud Efendi, who played a major role in legal reform, and chancellor and chronicler Celalzade Mustafa, who played a major role in bureaucratic expansion and in constructing Suleiman's legacy.

He has also been portrayed as a main playable character in the hit game "Age of Empires III" which is developed by Ensemble Studios.


Printed sources

Additional on-line sources



</doc>
<doc id="26994" url="https://en.wikipedia.org/wiki?curid=26994" title="Scotland">
Scotland

Scotland (, ) is a country that is part of the United Kingdom. Covering the northern third of the island of Great Britain, mainland Scotland has a 96 mile (154 km) border with England to the southeast and is otherwise surrounded by the Atlantic Ocean to the north and west, the North Sea to the northeast and the Irish Sea to the south. In addition, Scotland includes more than 790 islands; principally within the Northern Isles and the Hebrides archipelagos.

The Kingdom of Scotland emerged as an independent sovereign state in the European Early Middle Ages and continued to exist until 1707. By inheritance in 1603, James VI of Scotland became king of England and Ireland, thus forming a personal union of the three kingdoms. Scotland subsequently entered into a political union with the Kingdom of England on 1 May 1707 to create the new Kingdom of Great Britain. The union also created a new Parliament of Great Britain, which succeeded both the Parliament of Scotland and the Parliament of England. In 1801, the Kingdom of Great Britain entered into a political union with the Kingdom of Ireland to create the United Kingdom of Great Britain and Ireland (in 1922, the Irish Free State seceded from the United Kingdom, leading to the latter being officially renamed the United Kingdom of Great Britain and Northern Ireland in 1927).

Within Scotland, the monarchy of the United Kingdom has continued to use a variety of styles, titles and other royal symbols of statehood specific to the pre-union Kingdom of Scotland. The legal system within Scotland has also remained separate from those of England and Wales and Northern Ireland; Scotland constitutes a distinct jurisdiction in both public and private law. The continued existence of legal, educational, religious and other institutions distinct from those in the remainder of the UK have all contributed to the continuation of Scottish culture and national identity since the 1707 union with England.

In 1999, a Scottish Parliament was re-established, in the form of a devolved unicameral legislature comprising 129 members, having authority over many areas of domestic policy. The head of the Scottish Government is the first minister of Scotland, who is supported by the deputy first minister of Scotland. Scotland is represented in the United Kingdom Parliament by 59 MPs. Scotland is also a member of the British–Irish Council, sending five members of the Scottish Parliament to the British–Irish Parliamentary Assembly.

Scotland is divided into 32 administrative subdivisions or local authorities, known as council areas. Glasgow City is the largest council area in terms of population, with Highland being the largest in terms of area. Limited self-governing power, covering matters such as education, social services and roads and transportation, is devolved from the Scottish Government to each subdivision.
"Scotland" comes from "Scoti", the Latin name for the Gaels. Philip Freeman has speculated on the likelihood of a group of raiders adopting a name from an Indo-European root, *"skot", citing the parallel in Greek "skotos" (σκότος), meaning "darkness, gloom". The Late Latin word "Scotia" ("land of the Gaels") was initially used to refer to Ireland. By the 11th century at the latest, "Scotia" was being used to refer to (Gaelic-speaking) Scotland north of the River Forth, alongside "Albania" or "Albany", both derived from the Gaelic "Alba". The use of the words "Scots" and "Scotland" to encompass all of what is now Scotland became common in the Late Middle Ages.

Repeated glaciations, which covered the entire land mass of modern Scotland, destroyed any traces of human habitation that may have existed before the Mesolithic period. It is believed the first post-glacial groups of hunter-gatherers arrived in Scotland around 12,800 years ago, as the ice sheet retreated after the last glaciation. At the time, Scotland was covered in forests, had more bog-land, and the main form of transport was by water. These settlers began building the first known permanent houses on Scottish soil around 9,500 years ago, and the first villages around 6,000 years ago. The well-preserved village of Skara Brae on the mainland of Orkney dates from this period. Neolithic habitation, burial, and ritual sites are particularly common and well preserved in the Northern Isles and Western Isles, where a lack of trees led to most structures being built of local stone. Evidence of sophisticated pre-Christian belief systems is demonstrated by sites such as the Callanish Stones on Lewis and the Maes Howe on Orkney, which were built in the third millennium BCE. 

The first written reference to Scotland was in 320 BCE by Greek sailor Pytheas, who called the northern tip of Britain "Orcas", the source of the name of the Orkney islands. During the first millennium BCE, the society changed dramatically to a chiefdom model, as consolidation of settlement led to the concentration of wealth and underground stores of surplus food. The first Roman incursion into Scotland occurred in 79 CE, when Agricola invaded Scotland; he defeated a Caledonian army at the Battle of Mons Graupius in 83 CE. After the Roman victory, Roman forts were briefly set along the Gask Ridge close to the Highland line, but by three years after the battle, the Roman armies had withdrawn to the Southern Uplands. The Romans erected Hadrian's Wall in northern England and the "Limes Britannicus" became the northern border of the Roman Empire. The Roman influence on the southern part of the country was considerable, and they introduced Christianity to Scotland.

Beginning in the sixth century, the area that is now Scotland was divided into three areas: Pictland, a patchwork of small lordships in central Scotland; the Anglo-Saxon Kingdom of Northumbria, which had conquered southeastern Scotland; and Dál Riata, founded by settlers from Ireland, bringing Gaelic language and culture with them. These societies were based on the family unit and had sharp divisions in wealth, although the vast majority were poor and worked full-time in subsistence agriculture. The Picts kept slaves (mostly captured in war) through the ninth century. 

Gaelic influence over Pictland and Northumbria was facilitated by the large number of Gaelic-speaking clerics working as missionaries. Operating in the sixth century on the island of Iona, Saint Columba was one of the earliest and best-known missionaries. The Vikings began to raid Scotland in the eighth century. Although the raiders sought slaves and luxury items, their main motivation was to acquire land. The oldest Norse settlements were in northwest Scotland, but they eventually conquered many areas along the coast. Old Norse entirely displaced Gaelic in the Northern Isles. 

In the ninth century, the Norse threat allowed a Gael named Cináed mac Ailpín (Kenneth I) to seize power over Pictland, establishing a royal dynasty to which the modern monarchs trace their lineage, and marking the beginning of the end of Pictish culture. The kingdom of Cináed and his descendants, called Alba, was Gaelic in character but existed on the same area as Pictland. By the end of the tenth century, the Pictish language went extinct as its speakers shifted to Gaelic. From a base in eastern Scotland north of the River Forth and south of the River Spey, the kingdom expanded first southwards, into the former Northumbrian lands, and northwards into Moray. Around the turn of the millennium, there was a centralization in agricultural lands and the first towns began to be established. 

In the twelfth and thirteenth centuries, with much of Scotland under the control of a single ruler and united by the Gaelic language, a modern nation-state first emerged, as did Scottish national consciousness. The domination of Gaelic was diminished during the reign of David I (1124–53), during which many English-speaking colonists settled in Scotland. David I and his successors centralized royal power and united mainland Scotland, capturing regions such as Moray, Galloway, and Caithness, although he did not succeed at extending his power over the Hebrides, which had been ruled by various Scottish clans following the death of Somerled in 1164. The system of feudalism was consolidated, with both Anglo-Norman incomers and native Gaelic chieftains being granted land in exchange for serving the king. The Scottish kings rejected English demands to subjugate themselves; in fact, England invaded Scotland several times to prevent Scotland's expansion into northern England. 
The death of Alexander III in March 1286 broke the succession line of Scotland's kings. Edward I of England arbitrated between various claimants for the Scottish crown. In return for surrendering Scotland's nominal independence, John Balliol was pronounced king in 1292. In 1294, Balliol and other Scottish lords refused Edward's demands to serve in his army against the French. Scotland and France sealed a treaty on 23 October 1295, known as the Auld Alliance. War ensued, and John was deposed by Edward who took personal control of Scotland. Andrew Moray and William Wallace initially emerged as the principal leaders of the resistance to English rule in the Wars of Scottish Independence, until Robert the Bruce was crowned king of Scotland in 1306. Victory at the Battle of Bannockburn in 1314 proved the Scots had regained control of their kingdom. In 1320 the world's first documented declaration of independence, the Declaration of Arbroath, won the support of Pope John XXII, leading to the legal recognition of Scottish sovereignty by the English Crown.
A civil war between the Bruce dynasty and their long-term Comyn-Balliol rivals lasted until the middle of the 14th century. Although the Bruce faction was successful, David II's lack of an heir allowed his half-nephew Robert II to come to the throne and establish the House of Stewart. The Stewarts ruled Scotland for the remainder of the Middle Ages. The country they ruled experienced greater prosperity from the end of the 14th century through the Scottish Renaissance to the Reformation, despite the effects of the Black Death in 1349 and increasing division between Highlands and Lowlands. Multiple truces reduced warfare on the southern border.

The Treaty of Perpetual Peace was signed in 1502 by James IV of Scotland and Henry VII of England. James married Henry's daughter, Margaret Tudor. James invaded England in support of France under the terms of the Auld Alliance and became the last British monarch to die in battle, at Flodden in 1513. In 1560, the Treaty of Edinburgh brought an end to the Anglo-French conflict and recognized the Protestant Elizabeth I as Queen of England. The Parliament of Scotland met and immediately adopted the Scots Confession, which signaled the Scottish Reformation's sharp break from papal authority and Catholic teaching. The Catholic Mary, Queen of Scots was forced to abdicate in 1567.

In 1603, James VI, King of Scots inherited the thrones of the Kingdom of England and the Kingdom of Ireland in the Union of the Crowns, and moved to London. The military was strengthened, allowing the imposition of royal authority on the western Highland clans. The 1609 Statutes of Iona compelled the cultural integration of Hebridean clan leaders. With the exception of a short period under the Protectorate, Scotland remained a separate state, but there was considerable conflict between the crown and the Covenanters over the form of church government. The Glorious Revolution of 1688–89 saw the overthrow of King James VII of Scotland and II of England by the English Parliament in favour of William III and Mary II. 

The Battle of Altimarlach in 1680 was the last significant clan battle fought between highland clans. In common with countries such as France, Norway, Sweden and Finland, Scotland experienced famines during the 1690s. Mortality, reduced childbirths and increased emigration reduced the population of parts of the country about 10–15%.

In 1698, the Company of Scotland attempted a project to secure a trading colony on the Isthmus of Panama. Almost every Scottish landowner who had money to spare is said to have invested in the Darien scheme. Its failure bankrupted these landowners, but not the burghs. Nevertheless, the nobles' bankruptcy, along with the threat of an English invasion, played a leading role in convincing the Scots elite to back a union with England.

On 22 July 1706, the Treaty of Union was agreed between representatives of the Scots Parliament and the Parliament of England. The following year, twin Acts of Union were passed by both parliaments to create the united Kingdom of Great Britain with effect from 1 May 1707 with popular opposition and anti-union riots in Edinburgh, Glasgow, and elsewhere.

With trade tariffs with England abolished, trade blossomed, especially with Colonial America. The clippers belonging to the Glasgow Tobacco Lords were the fastest ships on the route to Virginia. Until the American War of Independence in 1776, Glasgow was the world's premier tobacco port, dominating world trade. The disparity between the wealth of the merchant classes of the Scottish Lowlands and the ancient clans of the Scottish Highlands grew, amplifying centuries of division.

The deposed Jacobite Stuart claimants had remained popular in the Highlands and north-east, particularly amongst non-Presbyterians, including Roman Catholics and Episcopalian Protestants. However, two major Jacobite risings launched in 1715 and 1745 failed to remove the House of Hanover from the British throne. The threat of the Jacobite movement to the United Kingdom and its monarchs effectively ended at the Battle of Culloden, Great Britain's last pitched battle.

The Scottish Enlightenment and the Industrial Revolution turned Scotland into an intellectual, commercial and industrial powerhouse – so much so Voltaire said "We look to Scotland for all our ideas of civilisation." With the demise of Jacobitism and the advent of the Union, thousands of Scots, mainly Lowlanders, took up numerous positions of power in politics, civil service, the army and navy, trade, economics, colonial enterprises and other areas across the nascent British Empire. Historian Neil Davidson notes "after 1746 there was an entirely new level of participation by Scots in political life, particularly outside Scotland." Davidson also states "far from being 'peripheral' to the British economy, Scotland – or more precisely, the Lowlands – lay at its core."

In the Highlands, clan chiefs gradually started to think of themselves more as commercial landlords than leaders of their people. These social and economic changes included the first phase of the Highland Clearances and, ultimately, the demise of clanship.

The Scottish Reform Act 1832 increased the number of Scottish MPs and widened the franchise to include more of the middle classes. From the mid-century, there were increasing calls for Home Rule for Scotland and the post of Secretary of State for Scotland was revived. Towards the end of the century Prime Ministers of Scottish descent included William Gladstone, and the Earl of Rosebery. In the late 19th century the growing importance of the working classes was marked by Keir Hardie's success in the Mid Lanarkshire by-election, 1888, leading to the foundation of the Scottish Labour Party, which was absorbed into the Independent Labour Party in 1895, with Hardie as its first leader.

Glasgow became one of the largest cities in the world and known as "the Second City of the Empire" after London. After 1860 the Clydeside shipyards specialised in steamships made of iron (after 1870, made of steel), which rapidly replaced the wooden sailing vessels of both the merchant fleets and the battle fleets of the world. It became the world's pre-eminent shipbuilding centre. The industrial developments, while they brought work and wealth, were so rapid that housing, town-planning, and provision for public health did not keep pace with them, and for a time living conditions in some of the towns and cities were notoriously bad, with overcrowding, high infant mortality, and growing rates of tuberculosis.
While the Scottish Enlightenment is traditionally considered to have concluded toward the end of the 18th century, disproportionately large Scottish contributions to British science and letters continued for another 50 years or more, thanks to such figures as the physicists James Clerk Maxwell and Lord Kelvin, and the engineers and inventors James Watt and William Murdoch, whose work was critical to the technological developments of the Industrial Revolution throughout Britain. In literature, the most successful figure of the mid-19th century was Walter Scott. His first prose work, "Waverley" in 1814, is often called the first historical novel. It launched a highly successful career that probably more than any other helped define and popularise Scottish cultural identity. In the late 19th century, a number of Scottish-born authors achieved international reputations, such as Robert Louis Stevenson, Arthur Conan Doyle, J. M. Barrie and George MacDonald. Scotland also played a major part in the development of art and architecture. The Glasgow School, which developed in the late 19th century, and flourished in the early 20th century, produced a distinctive blend of influences including the Celtic Revival the Arts and Crafts movement, and Japonism, which found favour throughout the modern art world of continental Europe and helped define the Art Nouveau style. Proponents included architect and artist Charles Rennie Mackintosh.

This period saw a process of rehabilitation for Highland culture. In the 1820s, as part of the Romantic revival, tartan and the kilt were adopted by members of the social elite, not just in Scotland, but across Europe, prompted by the popularity of Macpherson's Ossian cycle and then Walter Scott's Waverley novels. However, the Highlands remained poor, the only part of mainland Britain to continue to experience recurrent famine, with a limited range of products exported out of the region, negligible industrial production, but a continued population growth that tested the subsistence agriculture. These problems, and the desire to improve agriculture and profits were the driving forces of the ongoing Highland Clearances, in which many of the population of the Highlands suffered eviction as lands were enclosed, principally so that they could be used for sheep farming. The first phase of the clearances followed patterns of agricultural change throughout Britain. The second phase was driven by overpopulation, the Highland Potato Famine and the collapse of industries that had relied on the wartime economy of the Napoleonic Wars. The population of Scotland grew steadily in the 19th century, from 1,608,000 in the census of 1801 to 2,889,000 in 1851 and 4,472,000 in 1901. Even with the development of industry, there were not enough good jobs. As a result, during the period 1841–1931, about 2 million Scots migrated to North America and Australia, and another 750,000 Scots relocated to England.
After prolonged years of struggle in the Kirk, in 1834 the Evangelicals gained control of the General Assembly and passed the Veto Act, which allowed congregations to reject unwanted "intrusive" presentations to livings by patrons. The following "Ten Years' Conflict" of legal and political wrangling ended in defeat for the non-intrusionists in the civil courts. The result was a schism from the church by some of the non-intrusionists led by Dr Thomas Chalmers, known as the Great Disruption of 1843. Roughly a third of the clergy, mainly from the North and Highlands, formed the separate Free Church of Scotland. In the late 19th century growing divisions between fundamentalist Calvinists and theological liberals resulted in a further split in the Free Church as the rigid Calvinists broke away to form the Free Presbyterian Church in 1893. Catholic emancipation in 1829 and the influx of large numbers of Irish immigrants, particularly after the famine years of the late 1840s, mainly to the growing lowland centres like Glasgow, led to a transformation in the fortunes of Catholicism. In 1878, despite opposition, a Roman Catholic ecclesiastical hierarchy was restored to the country, and Catholicism became a significant denomination within Scotland.

Industrialisation, urbanisation and the Disruption of 1843 all undermined the tradition of parish schools. From 1830 the state began to fund buildings with grants; then from 1846 it was funding schools by direct sponsorship; and in 1872 Scotland moved to a system like that in England of state-sponsored largely free schools, run by local school boards. The historic University of Glasgow became a leader in British higher education by providing the educational needs of youth from the urban and commercial classes, as opposed to the upper class. The University of St Andrews pioneered the admission of women to Scottish universities. From 1892 Scottish universities could admit and graduate women and the numbers of women at Scottish universities steadily increased until the early 20th century.

Caused by the advent of refrigeration and imports of lamb, mutton and wool from overseas, the 1870s brought with them a collapse of sheep prices and an abrupt halt in the previous sheep farming boom. Land prices subsequently plummeted, too, and accelerated the process of the so-called "Balmoralisation" of Scotland, an era in the second half of the 19th century that saw an increase in tourism and the establishment of large estates dedicated to field sports like deer stalking and grouse shooting, especially in the Scottish Highlands. The process was named after Balmoral Estate, purchased by Queen Victoria in 1848, that fueled the romanticisation of upland Scotland and initiated an influx of the newly wealthy acquiring similar estates in the following decades. In the late 19th century just 118 people owned half of Scotland, with nearly 60 per cent of the whole country being part of shooting estates. While their relative importance has somewhat declined due to changing recreational interests throughout the 20th century, deer stalking and grouse shooting remain of prime importance on many private estates in Scotland.

Scotland played a major role in the British effort in the First World War. It especially provided manpower, ships, machinery, fish and money. With a population of 4.8 million in 1911, Scotland sent over half a million men to the war, of whom over a quarter died in combat or from disease, and 150,000 were seriously wounded. Field Marshal Sir Douglas Haig was Britain's commander on the Western Front.

The war saw the emergence of a radical movement called "Red Clydeside" led by militant trades unionists. Formerly a Liberal stronghold, the industrial districts switched to Labour by 1922, with a base among the Irish Catholic working-class districts. Women were especially active in building neighbourhood solidarity on housing issues. However, the "Reds" operated within the Labour Party and had little influence in Parliament and the mood changed to passive despair by the late 1920s.

The shipbuilding industry expanded by a third and expected renewed prosperity, but instead, a serious depression hit the economy by 1922 and it did not fully recover until 1939. The interwar years were marked by economic stagnation in rural and urban areas, and high unemployment. Indeed, the war brought with it deep social, cultural, economic, and political dislocations. Thoughtful Scots pondered their declension, as the main social indicators such as poor health, bad housing, and long-term mass unemployment, pointed to terminal social and economic stagnation at best, or even a downward spiral. Service abroad on behalf of the Empire lost its allure to ambitious young people, who left Scotland permanently. The heavy dependence on obsolescent heavy industry and mining was a central problem, and no one offered workable solutions. The despair reflected what Finlay (1994) describes as a widespread sense of hopelessness that prepared local business and political leaders to accept a new orthodoxy of centralised government economic planning when it arrived during the Second World War.

During the Second World War, Scotland was targeted by Nazi Germany largely due to its factories, shipyards, and coal mines. Cities such as Glasgow and Edinburgh were targeted by German bombers, as were smaller towns mostly located in the central belt of the country. Perhaps the most significant air-raid in Scotland was the Clydebank Blitz of March 1941, which intended to destroy naval shipbuilding in the area. 528 people were killed and 4,000 homes totally destroyed.

Perhaps Scotland's most unusual wartime episode occurred in 1941 when Rudolf Hess flew to Renfrewshire, possibly intending to broker a peace deal through the Duke of Hamilton. Before his departure from Germany, Hess had given his adjutant, Karlheinz Pintsch, a letter addressed to Hitler that detailed his intentions to open peace negotiations with the British. Pintsch delivered the letter to Hitler at the Berghof around noon on 11 May. Albert Speer later said Hitler described Hess's departure as one of the worst personal blows of his life, as he considered it a personal betrayal. Hitler worried that his allies, Italy and Japan, would perceive Hess's act as an attempt by Hitler to secretly open peace negotiations with the British.

As in World War I, Scapa Flow in Orkney served as an important Royal Navy base. Attacks on Scapa Flow and Rosyth gave RAF fighters their first successes downing bombers in the Firth of Forth and East Lothian. The shipyards and heavy engineering factories in Glasgow and Clydeside played a key part in the war effort, and suffered attacks from the Luftwaffe, enduring great destruction and loss of life. As transatlantic voyages involved negotiating north-west Britain, Scotland played a key part in the battle of the North Atlantic. Shetland's relative proximity to occupied Norway resulted in the Shetland bus by which fishing boats helped Norwegians flee the Nazis, and expeditions across the North Sea to assist resistance.

Scottish industry came out of the depression slump by a dramatic expansion of its industrial activity, absorbing unemployed men and many women as well. The shipyards were the centre of more activity, but many smaller industries produced the machinery needed by the British bombers, tanks and warships. Agriculture prospered, as did all sectors except for coal mining, which was operating mines near exhaustion. Real wages, adjusted for inflation, rose 25% and unemployment temporarily vanished. Increased income, and the more equal distribution of food, obtained through a tight rationing system, dramatically improved the health and nutrition.

After 1945, Scotland's economic situation worsened due to overseas competition, inefficient industry, and industrial disputes. Only in recent decades has the country enjoyed something of a cultural and economic renaissance. Economic factors contributing to this recovery included a resurgent financial services industry, electronics manufacturing, (see Silicon Glen), and the North Sea oil and gas industry. The introduction in 1989 by Margaret Thatcher's government of the Community Charge (widely known as the Poll Tax) one year before the rest of Great Britain, contributed to a growing movement for Scottish control over domestic affairs. Following a referendum on devolution proposals in 1997, the Scotland Act 1998 was passed by the UK Parliament, which established a devolved Scottish Parliament and Scottish Government with responsibility for most laws specific to Scotland. The Scottish Parliament was reconvened in Edinburgh on 4 July 1999. The first to hold the office of first minister of Scotland was Donald Dewar, who served until his sudden death in 2000.

The Scottish Parliament Building at Holyrood opened in October 2004 after lengthy construction delays and running over budget. The Scottish Parliament's form of proportional representation (the additional member system) resulted in no one party having an overall majority for the first three Scottish parliament elections. However, the pro-independence Scottish National Party led by Alex Salmond achieved an overall majority in the 2011 election, winning 69 of the 129 seats available. The success of the SNP in achieving a majority in the Scottish Parliament paved the way for the September 2014 referendum on Scottish independence. The majority voted against the proposition, with 55% voting no to independence. More powers, particularly in relation to taxation, were devolved to the Scottish Parliament after the referendum, following cross-party talks in the Smith Commission.

The mainland of Scotland comprises the northern third of the land mass of the island of Great Britain, which lies off the north-west coast of Continental Europe. The total area is , comparable to the size of the Czech Republic. Scotland's only land border is with England, and runs for between the basin of the River Tweed on the east coast and the Solway Firth in the west. The Atlantic Ocean borders the west coast and the North Sea is to the east. The island of Ireland lies only from the south-western peninsula of Kintyre; Norway is to the east and the Faroe Islands, to the north.

The territorial extent of Scotland is generally that established by the 1237 Treaty of York between Scotland and the Kingdom of England and the 1266 Treaty of Perth between Scotland and Norway. Important exceptions include the Isle of Man, which having been lost to England in the 14th century is now a crown dependency outside of the United Kingdom; the island groups Orkney and Shetland, which were acquired from Norway in 1472; and Berwick-upon-Tweed, lost to England in 1482

The geographical centre of Scotland lies a few miles from the village of Newtonmore in Badenoch. Rising to above sea level, Scotland's highest point is the summit of Ben Nevis, in Lochaber, while Scotland's longest river, the River Tay, flows for a distance of .

The whole of Scotland was covered by ice sheets during the Pleistocene ice ages and the landscape is much affected by glaciation. From a geological perspective, the country has three main sub-divisions.

The Highlands and Islands lie to the north and west of the Highland Boundary Fault, which runs from Arran to Stonehaven. This part of Scotland largely comprises ancient rocks from the Cambrian and Precambrian, which were uplifted during the later Caledonian orogeny. It is interspersed with igneous intrusions of a more recent age, remnants of which formed mountain massifs such as the Cairngorms and Skye Cuillins.

A significant exception to the above are the fossil-bearing beds of Old Red Sandstones found principally along the Moray Firth coast. The Highlands are generally mountainous and the highest elevations in the British Isles are found here. Scotland has over 790 islands divided into four main groups: Shetland, Orkney, and the Inner Hebrides and Outer Hebrides. There are numerous bodies of freshwater including Loch Lomond and Loch Ness. Some parts of the coastline consist of machair, a low-lying dune pasture land.

The Central Lowlands is a rift valley mainly comprising Paleozoic formations. Many of these sediments have economic significance for it is here that the coal and iron bearing rocks that fuelled Scotland's industrial revolution are found. This area has also experienced intense volcanism, Arthur's Seat in Edinburgh being the remnant of a once much larger volcano. This area is relatively low-lying, although even here hills such as the Ochils and Campsie Fells are rarely far from view.

The Southern Uplands are a range of hills almost long, interspersed with broad valleys. They lie south of a second fault line (the Southern Uplands fault) that runs from Girvan to Dunbar. The geological foundations largely comprise Silurian deposits laid down some 400–500 million years ago. The high point of the Southern Uplands is Merrick with an elevation of . The Southern Uplands is home to Scotland's highest village, Wanlockhead ( above sea level).

The climate of most of Scotland is temperate and oceanic, and tends to be very changeable., As it is warmed by the Gulf Stream from the Atlantic, it has much milder winters (but cooler, wetter summers) than areas on similar latitudes, such as Labrador, southern Scandinavia, the Moscow region in Russia, and the Kamchatka Peninsula on the opposite side of Eurasia. However, temperatures are generally lower than in the rest of the UK, with the coldest ever UK temperature of recorded at Braemar in the Grampian Mountains, on 11 February 1895. Winter maxima average in the Lowlands, with summer maxima averaging . The highest temperature recorded was at Greycrook, Scottish Borders on 9 August 2003.

The west of Scotland is usually warmer than the east, owing to the influence of Atlantic ocean currents and the colder surface temperatures of the North Sea. Tiree, in the Inner Hebrides, is one of the sunniest places in the country: it had more than 300 hours of sunshine in May 1975. Rainfall varies widely across Scotland. The western highlands of Scotland are the wettest, with annual rainfall in a few places exceeding . In comparison, much of lowland Scotland receives less than annually. Heavy snowfall is not common in the lowlands, but becomes more common with altitude. Braemar has an average of 59 snow days per year, while many coastal areas average fewer than 10 days of lying snow per year.

Scotland's wildlife is typical of the north-west of Europe, although several of the larger mammals such as the lynx, brown bear, wolf, elk and walrus were hunted to extinction in historic times. There are important populations of seals and internationally significant nesting grounds for a variety of seabirds such as gannets. The golden eagle is something of a national icon.

On the high mountain tops, species including ptarmigan, mountain hare and stoat can be seen in their white colour phase during winter months. Remnants of the native Scots pine forest exist and within these areas the Scottish crossbill, the UK's only endemic bird species and vertebrate, can be found alongside capercaillie, Scottish wildcat, red squirrel and pine marten. Various animals have been re-introduced, including the white-tailed sea eagle in 1975, the red kite in the 1980s, and there have been experimental projects involving the beaver and wild boar. Today, much of the remaining native Caledonian Forest lies within the Cairngorms National Park and remnants of the forest remain at 84 locations across Scotland. On the west coast, remnants of ancient Celtic Rainforest still remain, particularly on the Taynish peninsula in Argyll, these forests are particularly rare due to high rates of deforestation throughout Scottish history.

The flora of the country is varied incorporating both deciduous and coniferous woodland as well as moorland and tundra species. However, large scale commercial tree planting and the management of upland moorland habitat for the grazing of sheep and field sport activities like deer stalking and driven grouse shooting impacts upon the distribution of indigenous plants and animals. The UK's tallest tree is a grand fir planted beside Loch Fyne, Argyll in the 1870s, and the Fortingall Yew may be 5,000 years old and is probably the oldest living thing in Europe. Although the number of native vascular plants is low by world standards, Scotland's substantial bryophyte flora is of global importance.

The population of Scotland at the 2001 Census was 5,062,011. This rose to 5,295,400, the highest ever, at the 2011 Census. The most recent ONS estimate, for mid-2017, was 5,424,800.

In the 2011 Census, 62% of Scotland's population stated their national identity as 'Scottish only', 18% as 'Scottish and British', 8% as 'British only', and 4% chose 'other identity only'.

Although Edinburgh is the capital of Scotland, the largest city is Glasgow, which has just over 584,000 inhabitants. The Greater Glasgow conurbation, with a population of almost 1.2 million, is home to nearly a quarter of Scotland's population. The Central Belt is where most of the main towns and cities are located, including Glasgow, Edinburgh, Dundee, and Perth. Scotland's only major city outside the Central Belt is Aberdeen. The Scottish Lowlands host 80% of the total population, where the Central Belt accounts for 3.5 million people.

In general, only the more accessible and larger islands remain inhabited. Currently, fewer than 90 remain inhabited. The Southern Uplands are essentially rural in nature and dominated by agriculture and forestry. Because of housing problems in Glasgow and Edinburgh, five new towns were designated between 1947 and 1966. They are East Kilbride, Glenrothes, Cumbernauld, Livingston, and Irvine.

Immigration since World War II has given Glasgow, Edinburgh, and Dundee small South Asian communities. In 2011, there were an estimated 49,000 ethnically Pakistani people living in Scotland, making them the largest non-White ethnic group. Since the Enlargement of the European Union more people from Central and Eastern Europe have moved to Scotland, and the 2011 census indicated that 61,000 Poles live there.

Scotland has three officially recognised languages: English, Scots, and Scottish Gaelic. Scottish Standard English, a variety of English as spoken in Scotland, is at one end of a bipolar linguistic continuum, with broad Scots at the other. Scottish Standard English may have been influenced to varying degrees by Scots. The 2011 census indicated that 63% of the population had "no skills in Scots". Others speak Highland English. Gaelic is mostly spoken in the Western Isles, where a large proportion of people still speak it; however, nationally its use is confined to just 1% of the population. The number of Gaelic speakers in Scotland dropped from 250,000 in 1881 to 60,000 in 2008.

There are many more people with Scottish ancestry living abroad than the total population of Scotland. In the 2000 Census, 9.2 million Americans self-reported some degree of Scottish descent. Ulster's Protestant population is mainly of lowland Scottish descent, and it is estimated that there are more than 27 million descendants of the Scots-Irish migration now living in the US. In Canada, the Scottish-Canadian community accounts for 4.7 million people. About 20% of the original European settler population of New Zealand came from Scotland.

In August 2012, the Scottish population reached an all-time high of 5.25 million people. The reasons given were that, in Scotland, births were outnumbering the number of deaths, and immigrants were moving to Scotland from overseas. In 2011, 43,700 people moved from Wales, Northern Ireland or England to live in Scotland.

The total fertility rate (TFR) in Scotland is below the replacement rate of 2.1 (the TFR was 1.73 in 2011). The majority of births are to unmarried women (51.3% of births were outside of marriage in 2012).
Life expectancy for those born in Scotland between 2012 and 2014 is 77.1 years for males and 81.1 years for females. This is the lowest of any of the four countries of the UK.

Just over half (54%) of the Scottish population reported being a Christian while nearly 37% reported not having a religion in a 2011 census.
Since the Scottish Reformation of 1560, the national church (the Church of Scotland, also known as The Kirk) has been Protestant in classification and Reformed in theology. Since 1689 it has had a Presbyterian system of church government and enjoys independence from the state. Its membership is 398,389, about 7.5% of the total population, though according to the 2014 Scottish Annual Household Survey, 27.8%, or 1.5 million adherents, identified the Church of Scotland as the church of their religion. The Church operates a territorial parish structure, with every community in Scotland having a local congregation.

Scotland also has a significant Roman Catholic population, 19% professing that faith, particularly in Greater Glasgow and the north-west. After the Reformation, Roman Catholicism in Scotland continued in the Highlands and some western islands like Uist and Barra, and it was strengthened during the 19th century by immigration from Ireland. Other Christian denominations in Scotland include the Free Church of Scotland, and various other Presbyterian offshoots. Scotland's third largest church is the Scottish Episcopal Church.

Islam is the largest non-Christian religion (estimated at around 75,000, which is about 1.4% of the population), and there are also significant Jewish, Hindu and Sikh communities, especially in Glasgow. The Samyé Ling monastery near Eskdalemuir, which celebrated its 40th anniversary in 2007, is the first Buddhist monastery in western Europe.

The head of state of the United Kingdom is the monarch, currently Queen Elizabeth II (since 1952). The monarchy of the United Kingdom continues to use a variety of styles, titles and other royal symbols of statehood specific to pre-union Scotland, including: the Royal Standard of Scotland, the Royal coat of arms used in Scotland together with its associated Royal Standard, royal titles including that of Duke of Rothesay, certain Great Officers of State, the chivalric Order of the Thistle and, since 1999, reinstating a ceremonial role for the Crown of Scotland after a 292-year hiatus. Elizabeth II's regnal numbering caused controversy in 1953 because there had never been an Elizabeth I in Scotland. A legal action was brought in Scotland to contest the right of the Queen to entitle herself "Elizabeth II" within Scotland, but the Crown won the case.

Scotland has limited self-government within the United Kingdom, as well as representation in the UK Parliament. Executive and legislative powers respectively have been devolved to the Scottish Government and the Scottish Parliament at Holyrood in Edinburgh since 1999. The UK Parliament retains control over reserved matters specified in the Scotland Act 1998, including UK taxes, social security, defence, international relations and broadcasting. The Scottish Parliament has legislative authority for all other areas relating to Scotland. It initially had only a limited power to vary income tax, but powers over taxation and social security were significantly expanded by the Scotland Acts of 2012 and 2016.

The Scottish Parliament can give legislative consent over devolved matters back to the UK Parliament by passing a Legislative Consent Motion if United Kingdom-wide legislation is considered more appropriate for a certain issue. The programmes of legislation enacted by the Scottish Parliament have seen a divergence in the provision of public services compared to the rest of the UK. For instance, university education and care services for the elderly are free at point of use in Scotland, while fees are paid in the rest of the UK. Scotland was the first country in the UK to ban smoking in enclosed public places.

The Scottish Parliament is a unicameral legislature with 129 members (MSPs): 73 of them represent individual constituencies and are elected on a first-past-the-post system; the other 56 are elected in eight different electoral regions by the additional member system. MSPs serve for a four-year period (exceptionally five years from 2011–16). The Parliament nominates one of its Members, who is then appointed by the monarch to serve as first minister. Other ministers are appointed by the first minister and serve at his/her discretion. Together they make up the Scottish Government, the executive arm of the devolved government. The Scottish Government is headed by the first minister, who is accountable to the Scottish Parliament and is the minister of charge of the Scottish Government. The first minister is also the political leader of Scotland. The Scottish Government also comprises the deputy first minister, currently John Swinney MSP, who deputises for the first minister during a period of absence of overseas visits. Alongside the deputy first minister's requirements as Deputy, the minister also has a cabinet ministerial responsibility. Swinney is also currently Cabinet Secretary for Education and Skills. The Scottish Government's cabinet comprises nine cabinet secretaries, who form the Cabinet of Scotland. There are also twelve other ministers, who work alongside the cabinet secretaries in their appointed areas.

In the 2016 election, the Scottish National Party (SNP) won 63 of the 129 seats available. Nicola Sturgeon, the leader of the SNP, has been the first minister since November 2014. The Conservative Party became the largest opposition party in the 2016 elections, with the Labour Party, Liberal Democrats and the Green Party also represented in the Parliament. The next Scottish Parliament election is due to be held on 6 May 2021.

Scotland is represented in the British House of Commons by 59 MPs elected from territory-based Scottish constituencies. In the 2019 general election, the SNP won 48 of the 59 seats. This represented a significant increase from the 2017 general election, when the SNP won 35 seats. Conservative, Labour and Liberal Democrat parties also represent Scottish constituencies in the House of Commons. The next United Kingdom general election is scheduled for 2 May 2024. The Scotland Office represents the UK government in Scotland on reserved matters and represents Scottish interests within the UK government. The Scotland Office is led by the Secretary of State for Scotland, who sits in the Cabinet of the United Kingdom. Conservative MP Alister Jack has held the position since July 2019.

The relationships between the central UK Government and devolved governments of Scotland, Wales and Northern Ireland are based on the extra-statutory principles and agreements with the main elements are set out in a "Memorandum of Understanding" between the UK government and the devolved governments of Scotland, Wales and Northern Ireland. The MOU lays emphasis on the principles of good communication, consultation and co-operation.

Since devolution in 1999, Scotland has devolved stronger working relations across the two other devolved governments, the Welsh Government and Northern Ireland Executive. Whilst there are no formal concordats between the Scottish Government, Welsh Government and Northern Ireland Executive, ministers from each devolved government meet at various points throughout the year at various events such as the British-Irish Council and also meet to discuss matters and issues that are devolved to each government. Scotland, along with the Welsh Government, British Government as well as the Northern Ireland executive, participate in the Joint Ministerial Committee (JMC) which allows each government to discuss policy issues together and work together across each government to find solutions. The Scottish Government considers the successful re-establishment of the Plenary, and establishment of the Domestic fora to be important facets of the relationship with the UK Government and the other devolved administrations.

In the aftermath of the United Kingdom's decision to withdraw from the European Union in 2016, the Scottish Government has called for there to be a joint approach from each of the devolved governments. In early 2017, the devolved governments met to discuss Brexit and agree on Brexit strategies from each devolved government which lead for Theresa May to issue a statement that claims that the devolved governments will not have a central role or decision making process in the Brexit process, but that the UK Government plans to "fully engage" Scotland in talks alongside the governments of Wales and Northern Ireland.

Whilst foreign policy remains a reserved matter, the Scottish Government still has the power and ability to strengthen and develop Scotland, the economy and Scottish interests on the world stage and encourage foreign businesses, international devolved, regional and central governments to invest in Scotland. Whilst the first minister usually undertakes a number of foreign and international visits to promote Scotland, international relations, European and Commonwealth relations are also included within the portfolios of both the Cabinet Secretary for Culture, Tourism and External Affairs (responsible for international development) and the Minister for International Development and Europe (responsible for European Union relations and international relations).

During the G8 Summit in 2005, First Minister Jack McConnell welcomed each head of government of the G8 nations to the country's Glasgow Prestwick Airport on behalf of then UK Prime Minister Tony Blair. At the same time, McConnell and the then Scottish Executive pioneered the way forward to launch what would become the Scotland Malawi Partnership which co-ordinates Scottish activities to strengthen existing links with Malawi. During McConnell's time as first minister, several relations with Scotland, including Scottish and Russian relations strengthened following a visit by President of Russia Vladimir Putin to Edinburgh. McConnell, speaking at the end, highlighted that the visit by Putin was a "post-devolution" step towards "Scotland regaining its international identity".

Under the Salmond administration, Scotland's trade and investment deals with countries such as China and Canada, where Salmond established the Canada Plan 2010–2015 which aimed to strengthen "the important historical, cultural and economic links" between both Canada and Scotland. To promote Scotland's interests and Scottish businesses in North America, there is a Scottish Affairs Office located in Washington, D.C. with the aim to promoting Scotland in both the United States and Canada.

During a 2017 visit to the United States, First Minister Nicola Sturgeon met with Jerry Brown, Governor of California, where both signed an agreement committing both the Government of California and the Scottish Government to work together to tackle climate change, as well as Sturgeon signing a £6.3 million deal for Scottish investment from American businesses and firms promoting trade, tourism and innovation. During an official visit to the Republic of Ireland in 2016, Sturgeon claimed that is it "important for Ireland and Scotland and the whole of the British Isles that Ireland has a strong ally in Scotland". During the same engagement, Sturgeon became the first head of government to address the Seanad Éireann, the Upper House of the Irish Parliament.

A policy of devolution had been advocated by the three main UK parties with varying enthusiasm during recent history. A previous Labour leader, John Smith, described the revival of a Scottish parliament as the "settled will of the Scottish people". The devolved Scottish Parliament was created after a referendum in 1997 found majority support for both creating the Parliament and granting it limited powers to vary income tax.

The Scottish National Party (SNP), which supports Scottish independence, was first elected to form the Scottish Government in 2007. The new government established a "National Conversation" on constitutional issues, proposing a number of options such as increasing the powers of the Scottish Parliament, federalism, or a referendum on Scottish independence from the United Kingdom. In rejecting the last option, the three main opposition parties in the Scottish Parliament created a commission to investigate the distribution of powers between devolved Scottish and UK-wide bodies. The Scotland Act 2012, based on proposals by the commission, was subsequently enacted devolving additional powers to the Scottish Parliament.

In August 2009 the SNP proposed a bill to hold a referendum on independence in November 2010. Opposition from all other major parties led to an expected defeat. After the 2011 elections gave the SNP an overall majority in the Scottish Parliament, a referendum on independence for Scotland was held on 18 September 2014. The referendum resulted in a rejection of independence, by 55.3% to 44.7%. During the campaign, the three main parties in the UK Parliament pledged to extend the powers of the Scottish Parliament. An all-party commission chaired by Lord Smith of Kelvin was formed, which led to a further devolution of powers through the Scotland Act 2016.

Following a referendum on the UK's membership of the European Union on 23 June 2016, where a UK-wide majority voted to withdraw from the EU whilst a majority within Scotland voted to remain, Scotland's first minister, Nicola Sturgeon, announced that as a result a new independence referendum was "highly likely".

Historical subdivisions of Scotland included the mormaerdom, stewartry, earldom, burgh, parish, county and regions and districts. Some of these names are still sometimes used as geographical descriptors.

Modern Scotland is subdivided in various ways depending on the purpose. In local government, there have been 32 single-tier council areas since 1996, whose councils are responsible for the provision of all local government services. Decisions are made by councillors who are elected at local elections every five years. The head of each council is usually the Lord Provost alongside the Leader of the Council, with a Chief Executive being appointed as director of the council area. Community Councils are informal organisations that represent specific sub-divisions within each council area.

In the Scottish Parliament, there are 73 constituencies and eight regions. For the Parliament of the United Kingdom, there are 59 constituencies. Until 2013, the Scottish fire brigades and police forces were based on a system of regions introduced in 1975. For healthcare and postal districts, and a number of other governmental and non-governmental organisations such as the churches, there are other long-standing methods of subdividing Scotland for the purposes of administration.

City status in the United Kingdom is conferred by letters patent. There are seven cities in Scotland: Aberdeen, Dundee, Edinburgh, Glasgow, Inverness, Stirling and Perth.

Scots law has a basis derived from Roman law, combining features of both uncodified civil law, dating back to the "Corpus Juris Civilis", and common law with medieval sources. The terms of the Treaty of Union with England in 1707 guaranteed the continued existence of a separate legal system in Scotland from that of England and Wales. Prior to 1611, there were several regional law systems in Scotland, most notably Udal law in Orkney and Shetland, based on old Norse law. Various other systems derived from common Celtic or Brehon laws survived in the Highlands until the 1800s.

Scots law provides for three types of courts responsible for the administration of justice: civil, criminal and heraldic. The supreme civil court is the Court of Session, although civil appeals can be taken to the Supreme Court of the United Kingdom (or before 1 October 2009, the House of Lords). The High Court of Justiciary is the supreme criminal court in Scotland. The Court of Session is housed at Parliament House, in Edinburgh, which was the home of the pre-Union Parliament of Scotland with the High Court of Justiciary and the Supreme Court of Appeal currently located at the Lawnmarket. The sheriff court is the main criminal and civil court, hearing most cases. There are 49 sheriff courts throughout the country. District courts were introduced in 1975 for minor offences and small claims. These were gradually replaced by Justice of the Peace Courts from 2008 to 2010. The Court of the Lord Lyon regulates heraldry.

For three centuries the Scots legal system was unique for being the only national legal system without a parliament. This ended with the advent of the Scottish Parliament in 1999, which legislates for Scotland. Many features within the system have been preserved. Within criminal law, the Scots legal system is unique in having three possible verdicts: "guilty", "not guilty" and ""not proven"". Both "not guilty" and "not proven" result in an acquittal, typically with no possibility of retrial in accordance with the rule of double jeopardy. There is, however, the possibility of a retrial where new evidence emerges at a later date that might have proven conclusive in the earlier trial at first instance, where the person acquitted subsequently admits the offence or where it can be proved that the acquittal was tainted by an attempt to pervert the course of justice – see the provisions of the Double Jeopardy (Scotland) Act 2011. Many laws differ between Scotland and the other parts of the United Kingdom, and many terms differ for certain legal concepts. Manslaughter, in England and Wales, is broadly similar to culpable homicide in Scotland, and arson is called wilful fire raising. Indeed, some acts considered crimes in England and Wales, such as forgery, are not so in Scotland. Procedure also differs. Scots juries, sitting in criminal cases, consist of fifteen jurors, which is three more than is typical in many countries.

The Scottish Prison Service (SPS) manages the prisons in Scotland, which collectively house over 8,500 prisoners. The Cabinet Secretary for Justice is responsible for the Scottish Prison Service within the Scottish Government.

Health care in Scotland is mainly provided by NHS Scotland, Scotland's public health care system. This was founded by the National Health Service (Scotland) Act 1947 (later repealed by the National Health Service (Scotland) Act 1978) that took effect on 5 July 1948 to coincide with the launch of the NHS in England and Wales. However, even prior to 1948, half of Scotland's landmass was already covered by state-funded health care, provided by the Highlands and Islands Medical Service. Healthcare policy and funding is the responsibility of the Scottish Government's Health Directorates. The current Cabinet Secretary for Health and Sport is Jeane Freeman and the Director-General (DG) Health and chief executive, NHS Scotland is Paul Gray.

In 2008, the NHS in Scotland had around 158,000 staff including more than 47,500 nurses, midwives and health visitors and over 3,800 consultants. There are also more than 12,000 doctors, family practitioners and allied health professionals, including dentists, opticians and community pharmacists, who operate as independent contractors providing a range of services within the NHS in return for fees and allowances. These fees and allowances were removed in May 2010, and prescriptions are entirely free, although dentists and opticians may charge if the patient's household earns over a certain amount, about £30,000 per annum.

Scotland has a Western-style open mixed economy closely linked with the rest of the UK and the wider world. Traditionally, the Scottish economy was dominated by heavy industry underpinned by shipbuilding in Glasgow, coal mining and steel industries. Petroleum related industries associated with the extraction of North Sea oil have also been important employers from the 1970s, especially in the north-east of Scotland. De-industrialisation during the 1970s and 1980s saw a shift from a manufacturing focus towards a more service-oriented economy.

Scotland's gross domestic product (GDP), including oil and gas produced in Scottish waters, was estimated at £150 billion for the calendar year 2012. In 2014, Scotland's per capita GDP was one of the highest in the EU. As of April 2019 the Scottish unemployment rate was 3.3%, below the UK rate of 3.8%, and the Scottish employment rate was 75.9%.

Edinburgh is the financial services centre of Scotland, with many large finance firms based there, including: Lloyds Banking Group (owners of HBOS); the Government-owned Royal Bank of Scotland and Standard Life. Edinburgh was ranked 15th in the list of world financial centres in 2007, but fell to 37th in 2012, following damage to its reputation, and in 2016 was ranked 56th out of 86. Its status had returned to 17th however by 2020.
In 2014, total Scottish exports (excluding intra-UK trade) were estimated to be £27.5 billion. Scotland's primary exports include whisky, electronics and financial services. The United States, Netherlands, Germany, France, and Norway constitute the country's major export markets.

Whisky is one of Scotland's more known goods of economic activity. Exports increased by 87% in the decade to 2012 and were valued at £4.3 billion in 2013, which was 85% of Scotland's food and drink exports. It supports around 10,000 jobs directly and 25,000 indirectly. It may contribute £400–682 million to Scotland, rather than several billion pounds, as more than 80% of whisky produced is owned by non-Scottish companies.

A briefing published in 2002 by the Scottish Parliament Information Centre (SPICe) for the Scottish Parliament's Enterprise and Life Long Learning Committee stated that tourism accounted for up to 5% of GDP and 7.5% of employment.

Although the Bank of England is the central bank for the UK, three Scottish clearing banks issue Sterling banknotes: the Bank of Scotland, the Royal Bank of Scotland and the Clydesdale Bank. The value of the Scottish banknotes in circulation in 2013 was £3.8 billion, underwritten by the Bank of England using funds deposited by each clearing bank, under the Banking Act 2009, in order to cover the total value of such notes in circulation.

Of the money spent on UK defence, about £3.3 billion can be attributed to Scotland as of 2013. Although Scotland has a long military tradition predating the Treaty of Union with England, its armed forces now form part of the British Armed Forces, with the exception of the Atholl Highlanders, Europe's only legal private army. In 2006, the infantry regiments of the Scottish Division were amalgamated to form the Royal Regiment of Scotland. Other distinctively Scottish regiments in the British Army include the Scots Guards, the Royal Scots Dragoon Guards and the 154 (Scottish) Regiment RLC, an Army Reserve Regiment of the Royal Logistic Corps.

Because of their topography and perceived remoteness, parts of Scotland have housed many sensitive defence establishments. Between 1960 and 1991, the Holy Loch was a base for the US fleet of Polaris ballistic missile submarines. Today, Her Majesty's Naval Base Clyde, north-west of Glasgow, is the base for the four Trident-armed ballistic missile submarines that comprise the UK's nuclear deterrent. Scapa Flow was the major Fleet base for the Royal Navy until 1956.

A single front-line Royal Air Force base is located in Scotland. RAF Lossiemouth, located in Moray, is the most northerly air defence fighter base in the United Kingdom and is home to three fast-jet squadrons equipped with the Eurofighter Typhoon.

The Scottish education system has always been distinct from the rest of the United Kingdom, with a characteristic emphasis on a broad education. In the 15th century, the Humanist emphasis on education cumulated with the passing of the Education Act 1496, which decreed that all sons of barons and freeholders of substance should attend grammar schools to learn "perfyct Latyne", resulting in an increase in literacy among a male and wealthy elite. In the Reformation, the 1560 "First Book of Discipline" set out a plan for a school in every parish, but this proved financially impossible. In 1616 an act in Privy council commanded every parish to establish a school. By the late seventeenth century there was a largely complete network of parish schools in the lowlands, but in the Highlands basic education was still lacking in many areas. Education remained a matter for the church rather than the state until the Education (Scotland) Act 1872.

The "Curriculum for Excellence", Scotland's national school curriculum, presently provides the curricular framework for children and young people from age 3 to 18. All 3- and 4-year-old children in Scotland are entitled to a free nursery place. Formal primary education begins at approximately 5 years old and lasts for 7 years (P1–P7); children in Scotland study Standard Grades, or Intermediate qualifications between the ages of 14 and 16. These are being phased out and replaced by the National Qualifications of the Curriculum for Excellence. The school leaving age is 16, after which students may choose to remain at school and study for Access, Intermediate or Higher Grade and Advanced Higher qualifications. A small number of students at certain private, independent schools may follow the English system and study towards GCSEs and A and AS-Levels instead.

There are fifteen Scottish universities, some of which are amongst the oldest in the world. The four universities founded before the end of the 16th century — the University of St Andrews, the University of Glasgow, the University of Aberdeen and the University of Edinburgh — are collectively known as the ancient universities of Scotland, all of which rank among the 200 best universities in the world in the THE rankings, with Edinburgh placing in the top 50. Scotland had more universities per capita in QS' World University Rankings' top 100 in 2012 than any other nation. The country produces 1% of the world's published research with less than 0.1% of the world's population, and higher education institutions account for 9% of Scotland's service sector exports. Scotland's University Courts are the only bodies in Scotland authorised to award degrees.

Tuition is handled by the Student Awards Agency Scotland (SAAS), which does not charge fees to what it defines as "Young Students". Young Students are defined as those under 25, without children, marriage, civil partnership or cohabiting partner, who have not been outside of full-time education for more than three years. Fees exist for those outside the young student definition, typically from £1,200 to £1,800 for undergraduate courses, dependent on year of application and type of qualification. Postgraduate fees can be up to £3,400. The system has been in place since 2007 when graduate endowments were abolished.<ref name="www.scotland.gov.uk/News/Releases/2008/02/28172530"></ref> Labour's education spokesperson Rhona Brankin criticised the Scottish system for failing to address student poverty.

Scotland's universities are complemented in the provision of Further and Higher Education by 43 colleges. Colleges offer National Certificates, Higher National Certificates, and Higher National Diplomas. These Group Awards, alongside Scottish Vocational Qualifications, aim to ensure Scotland's population has the appropriate skills and knowledge to meet workplace needs. In 2014, research reported by the Office for National Statistics found that Scotland was the most highly educated country in Europe and among the most well-educated in the world in terms of tertiary education attainment, with roughly 40% of people in Scotland aged 16–64 educated to NVQ level 4 and above. Based on the original data for EU statistical regions, all four Scottish regions ranked significantly above the European average for completion of tertiary-level education by 25- to 64-year-olds.

Kilmarnock Academy in East Ayrshire is one of only two schools in the UK, and the only school in Scotland, to have educated two Nobel Prize Laureates – Alexander Fleming, discoverer of Penicillin, and John Boyd Orr, 1st Baron Boyd-Orr, for his scientific research into nutrition and his work as the first Director-General of the United Nations Food and Agriculture Organization (FAO).

Scottish music is a significant aspect of the nation's culture, with both traditional and modern influences. A famous traditional Scottish instrument is the Great Highland bagpipe, a wind instrument consisting of three drones and a melody pipe (called the chanter), which are fed continuously by a reservoir of air in a bag. Bagpipe bands, featuring bagpipes and various types of drums, and showcasing Scottish music styles while creating new ones, have spread throughout the world. The clàrsach (harp), fiddle and accordion are also traditional Scottish instruments, the latter two heavily featured in Scottish country dance bands. There are many successful Scottish bands and individual artists in varying styles including Annie Lennox, Amy Macdonald, Runrig, Belle and Sebastian, Boards of Canada, Camera Obscura, Cocteau Twins, Deacon Blue, Franz Ferdinand, Susan Boyle, Emeli Sandé, Texas, The View, The Fratellis, Twin Atlantic and Biffy Clyro. Other Scottish musicians include Shirley Manson, Paolo Nutini, Andy Stewart and Calvin Harris.

Scotland has a literary heritage dating back to the early Middle Ages. The earliest extant literature composed in what is now Scotland was in Brythonic speech in the 6th century, but is preserved as part of Welsh literature. Later medieval literature included works in Latin, Gaelic, Old English and French. The first surviving major text in Early Scots is the 14th-century poet John Barbour's epic "Brus", focusing on the life of Robert I, and was soon followed by a series of vernacular romances and prose works. In the 16th century, the crown's patronage helped the development of Scots drama and poetry, but the accession of James VI to the English throne removed a major centre of literary patronage and Scots was sidelined as a literary language. Interest in Scots literature was revived in the 18th century by figures including James Macpherson, whose Ossian Cycle made him the first Scottish poet to gain an international reputation and was a major influence on the European Enlightenment. It was also a major influence on Robert Burns, whom many consider the national poet, and Walter Scott, whose Waverley Novels did much to define Scottish identity in the 19th century. Towards the end of the Victorian era a number of Scottish-born authors achieved international reputations as writers in English, including Robert Louis Stevenson, Arthur Conan Doyle, J. M. Barrie and George MacDonald. In the 20th century the Scottish Renaissance saw a surge of literary activity and attempts to reclaim the Scots language as a medium for serious literature. Members of the movement were followed by a new generation of post-war poets including Edwin Morgan, who would be appointed the first Scots Makar by the inaugural Scottish government in 2004. From the 1980s Scottish literature enjoyed another major revival, particularly associated with a group of writers including Irvine Welsh. Scottish poets who emerged in the same period included Carol Ann Duffy, who, in May 2009, was the first Scot named UK Poet Laureate.

As one of the Celtic nations, Scotland and Scottish culture are represented at interceltic events at home and over the world. Scotland hosts several music festivals including Celtic Connections (Glasgow), and the Hebridean Celtic Festival (Stornoway). Festivals celebrating Celtic culture, such as Festival Interceltique de Lorient (Brittany), the Pan Celtic Festival (Ireland), and the National Celtic Festival (Portarlington, Australia), feature elements of Scottish culture such as language, music and dance.

The image of St. Andrew, martyred while bound to an X-shaped cross, first appeared in the Kingdom of Scotland during the reign of William I. Following the death of King Alexander III in 1286 an image of Andrew was used on the seal of the Guardians of Scotland who assumed control of the kingdom during the subsequent interregnum. Use of a simplified symbol associated with Saint Andrew, the saltire, has its origins in the late 14th century; the Parliament of Scotland decreeing in 1385 that Scottish soldiers should wear a white Saint Andrew's Cross on the front and back of their tunics. Use of a blue background for the Saint Andrew's Cross is said to date from at least the 15th century. Since 1606 the saltire has also formed part of the design of the Union Flag. There are numerous other symbols and symbolic artefacts, both official and unofficial, including the thistle, the nation's floral emblem (celebrated in the song, The Thistle o' Scotland), the Declaration of Arbroath, incorporating a statement of political independence made on 6 April 1320, the textile pattern tartan that often signifies a particular Scottish clan and the royal Lion Rampant flag. Highlanders can thank James Graham, 3rd Duke of Montrose, for the repeal in 1782 of the Act of 1747 prohibiting the wearing of tartans.
Although there is no official national anthem of Scotland, "Flower of Scotland" is played on special occasions and sporting events such as football and rugby matches involving the Scotland national teams and since 2010 is also played at the Commonwealth Games after it was voted the overwhelming favourite by participating Scottish athletes. Other currently less popular candidates for the National Anthem of Scotland include "Scotland the Brave", "Highland Cathedral", "Scots Wha Hae" and "A Man's A Man for A' That".

St Andrew's Day, 30 November, is the national day, although Burns' Night tends to be more widely observed, particularly outside Scotland. In 2006, the Scottish Parliament passed the St Andrew's Day Bank Holiday (Scotland) Act 2007, designating the day an official bank holiday. Tartan Day is a recent innovation from Canada.

The national animal of Scotland is the unicorn, which has been a Scottish heraldic symbol since the 12th century.

Scottish cuisine has distinctive attributes and recipes of its own but shares much with wider British and European cuisine as a result of local and foreign influences, both ancient and modern. Traditional Scottish dishes exist alongside international foodstuffs brought about by migration. Scotland's natural larder of game, dairy products, fish, fruit, and vegetables is the chief factor in traditional Scots cooking, with a high reliance on simplicity and a lack of spices from abroad, as these were historically rare and expensive. Irn-Bru is the most common Scottish carbonated soft drink, often described as "Scotland's other national drink" (after whisky). During the Late Middle Ages and early modern era, French cuisine played a role in Scottish cookery due to cultural exchanges brought about by the "Auld Alliance", especially during the reign of Mary, Queen of Scots. Mary, on her return to Scotland, brought an entourage of French staff who are considered responsible for revolutionising Scots cooking and for some of Scotland's unique food terminology.

National newspapers such as the "Daily Record", "The Herald", "The Scotsman" and "The National" are all produced in Scotland. Important regional dailies include the Evening News in Edinburgh, "The Courier" in Dundee in the east, and "The Press and Journal" serving Aberdeen and the north. Scotland is represented at the Celtic Media Festival, which showcases film and television from the Celtic countries. Scottish entrants have won many awards since the festival began in 1980.

Television in Scotland is largely the same as UK-wide broadcasts, however, the national broadcaster is BBC Scotland, a constituent part of the British Broadcasting Corporation, the publicly funded broadcaster of the United Kingdom. It runs three national television stations, and the national radio stations, "BBC Radio Scotland" and "BBC Radio nan Gàidheal", amongst others. Scotland also has some programming in the Gaelic language. BBC Alba is the national Gaelic-language channel. The main Scottish commercial television station is STV which broadcasts on two of the three ITV regions of Scotland.

Scotland has a number of production companies which produce films and television programmes for Scottish, UK and international audiences. Popular films associated with Scotland through Scottish production or being filmed in Scotland include "Braveheart" (1995), "Highlander" (1986), "Trainspotting" (1996), "Red Road" (2006), "Neds" (2010), "The Angel's Share" (2012), "Brave" (2012) and "Outlaw King" (2018). Popular television programmes associated with Scotland include the long running BBC Scotland soap opera "River City" which has been broadcast since 2002, "Still Game", a popular Scottish sitcom broadcast throughout the United Kingdom (2002–2007, revived in 2016), "Rab C. Nesbitt", "Two Doors Down" and "Take the High Road".

Wardpark Studios in Cumbernauld is one of Scotland's television and film production studios where the television programme "Outlander" is produced. Dumbarton Studios, located in Dumbarton is largely used for BBC Scotland programming, used for the filming and production of television programmes such as "Still Game", "River City", "Two Doors Down", and "Shetland".

Scotland hosts its own national sporting competitions and has independent representation at several international sporting events, including the FIFA World Cup, the Rugby Union World Cup, the Rugby League World Cup, the Cricket World Cup, the Netball World Cup and the Commonwealth Games. Scotland has its own national governing bodies, such as the Scottish Football Association (the second oldest national football association in the world) and the Scottish Rugby Union. Variations of football have been played in Scotland for centuries, with the earliest reference dating back to 1424.

The world's first official international association football match was held in 1872 and was the idea of C. W. Alcock of the Football Association which was seeking to promote Association Football in Scotland. The match took place at the West of Scotland Cricket Club's Hamilton Crescent ground in the Partick area of Glasgow. The match was between Scotland and England and resulted in a 0–0 draw. Following this, the newly developed football became the most popular sport in Scotland. The Scottish Cup was first contested in 1873. Queen's Park F.C., in Glasgow, is probably the oldest association football club in the world outside England.

The Scottish Football Association (SFA), the second-oldest national football association in the world, is the main governing body for Scottish association football, and a founding member of the International Football Association Board (IFAB) which governs the Laws of the Game. As a result of this key role in the development of the sport Scotland is one of only four countries to have a permanent representative on the IFAB; the other four representatives being appointed for set periods by FIFA.

The SFA also has responsibility for the Scotland national football team, whose supporters are commonly known as the "Tartan Army". , Scotland are ranked as the 50th best national football team in the FIFA World Rankings. The national team last attended the World Cup in France in 1998, but finished last in their group stage. The Scotland women's team have achieved more recent success, qualifying for both Euro 2017 and the 2019 World Cup. , they were ranked as the 22nd best women's national team in the FIFA Rankings.

Scottish clubs have achieved some success in European competitions, with Celtic winning the European Cup in 1967, Rangers and Aberdeen winning the UEFA Cup Winners' Cup in 1972 and 1983 respectively, and Aberdeen also winning the UEFA Super Cup in 1983. Celtic, Rangers and Dundee United have also reached European finals, the most recent of these being Rangers in 2008.

With the modern game of golf originating in 15th-century Scotland, the country is promoted as the home of golf. To many golfers the Old Course in the Fife town of St Andrews, an ancient links course dating to before 1552, is considered a site of pilgrimage. In 1764, the standard 18-hole golf course was created at St Andrews when members modified the course from 22 to 18 holes. The world's oldest golf tournament, and golf's first major, is The Open Championship, which was first played on 17 October 1860 at Prestwick Golf Club, in Ayrshire, Scotland, with Scottish golfers winning the earliest majors. There are many other famous golf courses in Scotland, including Carnoustie, Gleneagles, Muirfield, and Royal Troon.

Other distinctive features of the national sporting culture include the Highland games, curling and shinty. In boxing, Scotland has had 13 world champions, including Ken Buchanan, Benny Lynch and Jim Watt. Scotland has also been successful in motorsport, particularly in Formula One. Notable drivers include; David Coulthard, Jim Clark, Paul Di Resta, and Jackie Stewart. In IndyCar, Dario Franchitti has won 4 consecutive IndyCar world championships.

Scotland has competed at every Commonwealth Games since 1930 and has won 356 medals in total—91 Gold, 104 Silver and 161 Bronze. Edinburgh played host to the Commonwealth Games in 1970 and 1986, and most recently Glasgow in 2014.

Scotland's primary sources for energy are provided though renewable energy (42%), nuclear (35%) and fossil fuel generation (22%).

The Scottish Government has a target to have the equivalent of 50% of the energy for Scotland's heat, transport and electricity consumption to be supplied from renewable sources by 2030.

Scotland has five international airports operating scheduled services to Europe, North America and Asia, as well domestic services to England, Northern Ireland and Wales.


Highlands and Islands Airports operates eleven airports across the Highlands, Orkney, Shetland and the Western Isles, which are primarily used for short distance, public service operations, although Inverness Airport has a number of scheduled flights to destinations across the UK and mainland Europe.

Edinburgh Airport is currently Scotland's busiest airport handling over 13 million passengers in 2017. It is also the UK's 6th busiest airport.

British Airways, easyJet, flybe, Jet2, and Ryanair operate the majority of flights between Scotland and other major UK and European airports.

Four airlines are based in Scotland:


Network Rail owns and operates the fixed infrastructure assets of the railway system in Scotland, while the Scottish Government retains overall responsibility for rail strategy and funding in Scotland. Scotland's rail network has 359 railway stations and around of track. In 2018–19 there were 102million passenger journies on Scottish railways.

The East Coast and West Coast main railway lines connect the major cities and towns of Scotland with each other and with the rail network in England. London North Eastern Railway provides inter-city rail journeys between Glasgow, Edinburgh, Aberdeen and Inverness to London. Domestic rail services within Scotland are operated by Abellio ScotRail. During the time of British Rail, the West Coast Main Line from London Euston to Glasgow Central was electrified in the early 1970s, followed by the East Coast Main Line in the late 1980s. British Rail created the ScotRail brand. When British Rail existed, many railway lines in Strathclyde were electrified. Strathclyde Passenger Transport Executive was at the forefront with the acclaimed "largest electrified rail network outside London". Some parts of the network are electrified, but there are no electrified lines in the Highlands, Angus, Aberdeenshire, the cities of Dundee or Aberdeen, or Perth & Kinross, and none of the islands has a rail link (although the railheads at Kyle of Lochalsh and Mallaig principally serve the islands).

The East Coast Main Line crosses the Firth of Forth by the Forth Bridge. Completed in 1890, this cantilever bridge has been described as "the one internationally recognised Scottish landmark". Scotland's rail network is managed by Transport Scotland.

The Scottish motorways and major trunk roads are managed by Transport Scotland. The remainder of the road network is managed by the Scottish local authorities in each of their areas.

Regular ferry services operate between the Scottish mainland and outlying islands. Ferries serving both the inner and outer Hebrides are principally operated by the state-owned enterprise Caledonian MacBrayne.

Services to the Northern Isles are operated by Serco. Other routes, served by multiple companies, connect southwest Scotland to Northern Ireland. DFDS Seaways operated a freight-only Rosyth – Zeebrugge ferry service, until a fire damaged the vessel DFDS were using. A passenger service was also operated between 2002–2010.

Additional routes are operated by local authorities.




</doc>
<doc id="26995" url="https://en.wikipedia.org/wiki?curid=26995" title="Shire">
Shire

A shire is a traditional term for a division of land, found in Great Britain, Australia, New Zealand and some other English-speaking countries. It was first used in Wessex from the beginning of Anglo-Saxon settlement, and spread to most of the rest of England in the tenth century. In some rural parts of Australia, a shire is a local government area; however, in Australia it is not synonymous with a "county", which is a lands administrative division.

The word "shire" derives from the Old English "sćir", from the Proto-Germanic "skizo" (Old High German "sćira"), denoting an "official charge" a "district under a governor", and a "care". In UK usage, "shire" became synonymous with "county", an administrative term introduced to England through the Norman Conquest, in A.D. 1066. In contemporary British usage, the word "counties" also refers to "shires", mainly in places, such as Shire Hall. 

In regions with rhotic pronunciation, such as Scotland, the word "shire" is pronounced ; in areas of non-rhotic pronunciation, the final R is silent, unless the next word begins in a vowel sound. In England and Wales, when "shire" is a place-name suffix, the vowel is unstressed and usually shortened (monophthongised); the pronunciations include and , with the final R pronunciation depending on rhoticity. The vowel is normally reduced to a single schwa, as in "Leicestershire" and "Berkshire" .

The system was first used in the kingdom of Wessex from the beginning of Anglo-Saxon settlement, and spread to most of the rest of England in the tenth century, along with the West Saxon kingdom's political domination. In Domesday (1086) the city of York was divided into shires. The first shires of Scotland were created in English-settled areas such as Lothian and the Borders, in the ninth century. King David I more consistently created shires and appointed sheriffs across lowland "shores" of Scotland.

The shire in early days was governed by an "ealdorman" and in the later Anglo-Saxon period by royal official known as a "shire reeve" or sheriff. The shires were divided into hundreds or wapentakes, although other less common sub-divisions existed. An alternative name for a shire was a "sheriffdom" until sheriff court reforms separated the two concepts. The phrase "shire county" applies, unofficially, to non-metropolitan counties in England, specifically those that are not local unitary authority areas. In Scotland the word "county" was not adopted for the shires. Although "county" appears in some texts, "shire" was the normal name until counties for statutory purposes were created in the nineteenth century.

"Shire" also refers, in a narrower sense, to ancient counties with names that ended in "shire". These counties are typically (though not always) named after their county town. The suffix "-shire" is attached to most of the names of English, Scottish and Welsh counties. It tends not to be found in the names of shires that were pre-existing divisions. Essex, Kent, and Sussex, for example, have never borne a "-shire", as each represents a former Anglo-Saxon kingdom. Similarly Cornwall was a British kingdom before it became an English county. The term "shire" is not used in the names of the six traditional counties of Northern Ireland.

Counties in England bearing the "-shire" suffix comprise: Bedfordshire, Berkshire, Buckinghamshire, Cambridgeshire, Cheshire, Derbyshire, Gloucestershire, Hampshire, Herefordshire, Hertfordshire, Huntingdonshire, Lancashire, Lincolnshire, Leicestershire, Northamptonshire, Nottinghamshire, Oxfordshire, Shropshire, Staffordshire, Warwickshire, Wiltshire, Worcestershire and Yorkshire. These counties, on their historical boundaries, cover a little more than half the area of England. The counties that do not use "-shire" are mainly in three areas, in the south-east, south-west and far north of England. Several of these counties no longer exist as administrative units, or have had their administrative boundaries reduced by local government reforms. Several of the successor authorities retain the "-shire" county names, such as West Yorkshire and South Gloucestershire.

The county of Devon was historically known as Devonshire, although this is no longer the official name. Similarly, Dorset, Rutland and Somerset were formerly known as Dorsetshire, Rutlandshire and Somersetshire, but these terms are no longer official, and are rarely used outside the local populations.

Hexhamshire was a county in the north-east of England from the early 12th century until 1572, when it was incorporated into Northumberland.

In Scotland, barely affected by the Norman conquest of England, the word "shire" prevailed over "county" until the 19th century. Earliest sources have the same usage of the "-shire" suffix as in England (though in Scots this was oftenmost "schyr"). Later the "Shire" appears as a separate word.

"Shire" names in Scotland comprise Aberdeenshire, Ayrshire, Banffshire, Berwickshire, Clackmannanshire, Cromartyshire, Dumfriesshire, Dunbartonshire, Inverness-shire, Kincardineshire, Kinross-shire, Kirkcudbrightshire, Lanarkshire, Morayshire, Nairnshire, Peeblesshire, Perthshire, Renfrewshire, Ross-shire, Roxburghshire, Selkirkshire, Stirlingshire, and Wigtownshire. 

In Scotland four shires have alternative names with the "-shire" suffix: Angus (Forfarshire), East Lothian (Haddingtonshire), Midlothian (Edinburghshire) and West Lothian (Linlithgowshire).

Sutherland is occasionally still referred to as Sutherlandshire. Similarly, Argyllshire, Buteshire, Caithness-shire and Fifeshire are sometimes found. Also, Morayshire was previously called Elginshire. There is debate about whether Argyllshire was ever really used.

Shires in Wales bearing the "-shire" suffix comprise: Brecknockshire (or Breconshire), Caernarfonshire (historically Carnarvonshire), Cardiganshire (in Welsh- Ceredigion), Carmarthenshire, Denbighshire, Flintshire, Monmouthshire, Montgomeryshire, Pembrokeshire, and Radnorshire. In Wales, the counties of Merioneth and Glamorgan are occasionally referred to with the "shire" suffix. The only traditional Welsh county that never takes "shire" is Anglesey—in English: in Welsh it is referred to as 'Sir Fôn'.

The suffix "-shire" could be a generalised term referring to a district. It did not acquire the strong association with county until later. Other than these, the term was used for several other districts. Bedlingtonshire, Craikshire, Norhamshire and Islandshire were exclaves of County Durham, which were incorporated into Northumberland or Yorkshire in 1844. The suffix was also used for many hundreds, wapentakes and liberties such as Allertonshire, Blackburnshire, Halfshire, Howdenshire, Leylandshire, Powdershire, Pydarshire, Richmondshire, Riponshire, Salfordshire, Triggshire, Tynemouthshire, West Derbyshire and Wivelshire, counties corporate such as Hullshire, and other districts such as Applebyshire, Bamburghshire, Bunkleshire, Carlisleshire, Coldinghamshire, Coxwoldshire, Cravenshire, Hallamshire, Mashamshire and Yetholmshire. Richmondshire is today the name of a local government district of North Yorkshire.

Non-county shires were very common in Scotland. Kinross-shire and Clackmannanshire are arguably survivals from such districts. Non-county "shires" in Scotland include Bunkleshire, Coldinghamshire and Yetholmshire.

"Shire" is the most common word in Australia for rural local government areas (LGAs). New South Wales, Victoria, Queensland, Western Australia and the Northern Territory use the term "shire" for this unit; the territories of Christmas Island and Cocos Island are also shires. In contrast, South Australia uses district and region for its rural LGA units, while Tasmania uses municipality. Shires are generally functionally indistinguishable from towns, borough, municipalities, or cities.

Three LGAs in outer metropolitan Sydney and four in outer metropolitan Melbourne have populations exceeding that of towns or municipalities, but retain significant bushlands and/or semi-rural areas, and most have continued to use "shire" in their titles whilst others have dropped it from theirs. These "city-shires" are:

Sydney:

Melbourne:

In 1634, eight "shires" were created in the Virginia Colony by order of Charles I, King of England. They were renamed as counties only a few years later. They were:


As of 2013, six of the original eight Shires of Virginia are considered to be still extant whilst two have consolidated with a neighbouring city. Most of their boundaries have changed in the intervening centuries.

Before the Province of New York was granted county subdivisions and a greater royal presence in 1683, the early ducal colony consisted of York Shire, as well as Albany and Ulster, after the three titles held by Prince James: Duke of York, Duke of Albany, Earl of Ulster. While these were basically renamed Dutch core settlements, they were quickly converted to English purposes, while the Dutch remained within the colony, as opposed to later practice of the Acadian Expulsion. Further Anglo-Dutch synthesis occurred when Prince James enacted the Dominion of New England and later when William III of England took over through the Glorious Revolution.

A few New England states and commonwealths; namely Vermont, Rhode Island, Massachusetts, and Maine; still use the term "shire town" for their county seats, although they use the term county, rather than shire.

The word also survives in the name of the state of New Hampshire, whose co-founder, John Mason, named his Province of New Hampshire after the English county of Hampshire.



</doc>
<doc id="26997" url="https://en.wikipedia.org/wiki?curid=26997" title="Scientist">
Scientist

A scientist is someone who conducts scientific research to advance knowledge in an area of interest.

In classical antiquity, there was no real ancient analog of a modern scientist. Instead, philosophers engaged in the philosophical study of nature called natural philosophy, a precursor of natural science. It was not until the 19th century that the term "scientist" came into regular use after it was coined by the theologian, philosopher, and historian of science William Whewell in 1833.

In modern times, many scientists have advanced degrees in an area of science and pursue careers in various sectors of the economy such as academia, industry, government, and nonprofit environments.""

The roles of "scientists", and their predecessors before the emergence of modern scientific disciplines, have evolved considerably over time. Scientists of different eras (and before them, natural philosophers, mathematicians, natural historians, natural theologians, engineers, and others who contributed to the development of science) have had widely different places in society, and the social norms, ethical values, and epistemic virtues associated with scientists—and expected of them—have changed over time as well. Accordingly, many different historical figures can be identified as early scientists, depending on which characteristics of modern science are taken to be essential.

Some historians point to the Scientific Revolution that began in 16th century as the period when science in a recognizably modern form developed. It wasn't until the 19th century that sufficient socioeconomic changes occurred for scientists to emerge as a major profession.

Knowledge about nature in classical antiquity was pursued by many kinds of scholars. Greek contributions to science—including works of geometry and mathematical astronomy, early accounts of biological processes and catalogs of plants and animals, and theories of knowledge and learning—were produced by philosophers and physicians, as well as practitioners of various trades. These roles, and their associations with scientific knowledge, spread with the Roman Empire and, with the spread of Christianity, became closely linked to religious institutions in most of European countries. Astrology and astronomy became an important area of knowledge, and the role of astronomer/astrologer developed with the support of political and religious patronage. By the time of the medieval university system, knowledge was divided into the "trivium"—philosophy, including natural philosophy—and the "quadrivium"—mathematics, including astronomy. Hence, the medieval analogs of scientists were often either philosophers or mathematicians. Knowledge of plants and animals was broadly the province of physicians.

Science in medieval Islam generated some new modes of developing natural knowledge, although still within the bounds of existing social roles such as philosopher and mathematician. Many proto-scientists from the Islamic Golden Age are considered polymaths, in part because of the lack of anything corresponding to modern scientific disciplines. Many of these early polymaths were also religious priests and theologians: for example, Alhazen and al-Biruni were mutakallimiin; the physician Avicenna was a hafiz; the physician Ibn al-Nafis was a hafiz, muhaddith and ulema; the botanist Otto Brunfels was a theologian and historian of Protestantism; the astronomer and physician Nicolaus Copernicus was a priest. During the Italian Renaissance scientists like Leonardo Da Vinci, Michelangelo, Galileo Galilei and Gerolamo Cardano have been considered as the most recognizable polymaths.

During the Renaissance, Italians made substantial contributions in science. Leonardo Da Vinci made significant discoveries in paleontology and anatomy. The Father of modern Science,
Galileo Galilei, made key improvements on the thermometer and telescope which allowed him to observe and clearly describe the solar system. Descartes was not only a pioneer of analytic geometry but formulated a theory of mechanics and advanced ideas about the origins of animal movement and perception. Vision interested the physicists Young and Helmholtz, who also studied optics, hearing and music. Newton extended Descartes' mathematics by inventing calculus (at the same time as Leibniz). He provided a comprehensive formulation of classical mechanics and investigated light and optics. Fourier founded a new branch of mathematics — infinite, periodic series — studied heat flow and infrared radiation, and discovered the greenhouse effect. Girolamo Cardano, Blaise Pascal Pierre de Fermat, Von Neumann, Turing, Khinchin, Markov and Wiener, all mathematicians, made major contributions to science and probability theory, including the ideas behind computers, and some of the foundations of statistical mechanics and quantum mechanics. Many mathematically inclined scientists, including Galileo, were also musicians.

There are many compelling stories in medicine and biology, such as the development of ideas about the circulation of blood from Galen to Harvey.

During the age of Enlightenment, Luigi Galvani, the pioneer of the bioelectromagnetics, discovered the animal electricity. He discovered that a charge applied to the spinal cord of a frog could generate muscular spasms throughout its body. Charges could make frog legs jump even if the legs were no longer attached to a frog. While cutting a frog leg, Galvani's steel scalpel touched a brass hook that was holding the leg in place. The leg twitched. Further experiments confirmed this effect, and Galvani was convinced that he was seeing the effects of what he called animal electricity, the life force within the muscles of the frog. At the University of Pavia, Galvani's colleague Alessandro Volta was able to reproduce the results, but was sceptical of Galvani's explanation.

Lazzaro Spallanzani is one of the most influential figures in experimental physiology and the natural sciences. His investigations have exerted a lasting influence on the medical sciences. He made important contributions to the experimental study of bodily functions and animal reproduction.

Francesco Redi discovered that microorganisms can cause disease. 

Until the late 19th or early 20th century, scientists were still referred to as "natural philosophers" or "men of science".

English philosopher and historian of science William Whewell coined the term "scientist" in 1833, and it first appeared in print in Whewell's anonymous 1834 review of Mary Somerville's "On the Connexion of the Physical Sciences" published in the "Quarterly Review". Whewell's suggestion of the term was partly satirical, a response to changing conceptions of science itself in which natural knowledge was increasingly seen as distinct from other forms of knowledge. Whewell wrote of "an increasing proclivity of separation and dismemberment" in the sciences; while highly specific terms proliferated—chemist, mathematician, naturalist—the broad term "philosopher" was no longer satisfactory to group together those who pursued science, without the caveats of "natural" or "experimental" philosopher. Members of the British Association for the Advancement of Science had been complaining about the lack of a good term at recent meetings, Whewell reported in his review; alluding to himself, he noted that "some ingenious gentleman proposed that, by analogy with "artist", they might form [the word] "scientist", and added that there could be no scruple in making free with this term since we already have such words as "economist", and "atheist"—but this was not generally palatable".

Whewell proposed the word again more seriously (and not anonymously) in his 1840 "The Philosophy of the Inductive Sciences":

He also proposed the term "physicist" at the same time, as a counterpart to the French word "physicien". Neither term gained wide acceptance until decades later; "scientist" became a common term in the late 19th century in the United States and around the turn of the 20th century in Great Britain. By the twentieth century, the modern notion of science as a special brand of information about the world, practiced by a distinct group and pursued through a unique method, was essentially in place.

Ramón y Cajal won the Nobel Prize in 1906 for his remarkable observations in neuroanatomy.

Marie Curie became the first female to win the Nobel Prize and the first person to win it twice. Her efforts led to the development of nuclear energy and Radiotherapy for the treatment of cancer. In 1922, she was appointed a member of the International Commission on Intellectual Co-operation by the Council of the League of Nations. She campaigned for scientist's right to patent their discoveries and inventions. She also campaigned for free access to international scientific literature and for internationally recognized scientific symbols.

As a profession, the scientist of today is widely recognized. 

In modern times, many professional scientists are trained in an academic setting (e.g., universities and research institutes), mostly at the level of graduate schools. Upon completion, they would normally attain an academic degree, with the highest degree being a doctorate such as a Doctor of Philosophy (PhD). Although graduate education for scientists varies among institutions and countries, some common training requirements include specializing in an area of interest, publishing research findings in peer-reviewed scientific journals and presenting them at scientific conferences, giving lectures or teaching, and defending a thesis (or dissertation) during an oral examination. To aid them in this endeavor, graduate students often work under the guidance of a mentor, usually a senior scientist, which may continue after the completion of their doctorates whereby they work as postdoctoral researchers.

After the completion of their training, many scientists pursue careers in a variety of work settings and conditions. In 2017, the British scientific journal "Nature" published the results of a large-scale survey of more than 5,700 doctoral students worldwide, asking them which sectors of the economy they would like to work in. A little over half of the respondents wanted to pursue a career in academia, with smaller proportions hoping to work in industry, government, and nonprofit environments.

Scientists are motivated to work in several ways. Many have a desire to understand why the world is as we see it and how it came to be. They exhibit a strong curiosity about reality. Other motivations are recognition by their peers and prestige. The Nobel Prize, a widely regarded prestigious award, is awarded annually to those who have achieved scientific advances in the fields of medicine, physics, chemistry, and economics. 

Some scientists have a desire to apply scientific knowledge for the benefit of people's health, the nations, the world, nature, or industries (academic scientist and industrial scientist). Scientists tend to be less motivated by direct financial reward for their work than other careers. As a result, scientific researchers often accept lower average salaries when compared with many other professions which require a similar amount of training and qualification.

Although there have been exceptions, most scientists tend to do their best research when they are relatively young, in their 30s.

Scientists include experimentalists who mainly perform experiments to test hypotheses, and theoreticians who mainly develop models to explain existing data and predict new results. There is a continuum between two activities and the division between them is not clear-cut, with many scientists performing both tasks.

Those considering science as a career often look to the frontiers. These include cosmology and biology, especially molecular biology and the human genome project. Other areas of active research include the exploration of matter at the scale of elementary particles as described by high-energy physics, and materials science, which seeks to discover and design new materials. Although there have been remarkable discoveries with regard to brain function and neurotransmitters, the nature of the mind and human thought still remains unknown.


The number of scientists is vastly different from country to country. For instance, there are only four full-time scientists per 10,000 workers in India, while this number is 79 for the United Kingdom, and 85 for the United States.
According to the National Science Foundation, 4.7 million people with science degrees worked in the United States in 2015, across all disciplines and employment sectors. The figure included twice as many men as women. Of that total, 17% worked in academia, that is, at universities and undergraduate institutions, and men held 53% of those positions. 5% of scientists worked for the federal government, and about 3.5% were self-employed. Of the latter two groups, two-thirds were men. 59% of scientists in the United States were employed in industry or business, and another 6% worked in non-profit positions.

Scientist and engineering statistics are usually intertwined, but they indicate that women enter the field far less than men, though this gap is narrowing. The number of science and engineering doctorates awarded to women rose from a mere 7 percent in 1970 to 34 percent in 1985 and in engineering alone the numbers of bachelor's degrees awarded to women rose from only 385 in 1975 to more than 11000 in 1985. 







</doc>
<doc id="27000" url="https://en.wikipedia.org/wiki?curid=27000" title="Smog">
Smog

Smog is a type of intense air pollution. The word "smog" was coined in the early 20th century, and is a contraction (portmanteau) of the words smoke and fog to refer to smoky fog; its opacity, and odor. The word was then intended to refer to what was sometimes known as pea soup fog, a familiar and serious problem in London from the 19th century to the mid-20th century. This kind of visible air pollution is composed of nitrogen oxides, sulphur oxides, ozone, smoke and other particulates. Man-made smog is derived from coal combustion emissions, vehicular emissions, industrial emissions, forest and agricultural fires and photochemical reactions of these emissions.

Smog is often categorized as being either summer smog or winter smog. Summer smog is primarily associated with the photochemical formation of ozone. During the summer season when the temperatures are warmer and there is more sunlight present, photochemical smog is the dominant type of smog formation. During the winter months when the temperatures are colder, and atmospheric inversions are common, there is an increase in coal and other fossil fuel usage to heat homes and buildings. These combustion emissions, together with the lack of pollutant dispersion under inversions, characterize winter smog formation. While photochemical smog is the main smog formation mechanism during summer months, winter smog episodes are still common. Smog formation in general relies on both primary and secondary pollutants. Primary pollutants are emitted directly from a source, such as emissions of sulfur dioxide from coal combustion. Secondary pollutants, such as ozone, are formed when primary pollutants undergo chemical reactions in the atmosphere.

Photochemical smog, as found for example in Los Angeles, is a type of air pollution derived from vehicular emission from internal combustion engines and industrial fumes. These pollutants react in the atmosphere with sunlight to form secondary pollutants that also combine with the primary emissions to form photochemical smog. In certain other cities, such as Delhi, smog severity is often aggravated by stubble burning in neighboring agricultural areas. The atmospheric pollution levels of Los Angeles, Beijing, Delhi, Lahore, Mexico City, Tehran and other cities are often increased by an inversion that traps pollution close to the ground. The developing smog is usually toxic to humans and can cause severe sickness, a shortened life span, or premature death.

Coinage of the term "smog" is often attributed to Dr. Henry Antoine Des Voeux in his 1905 paper, "Fog and Smoke" for a meeting of the Public Health Congress. The 26 July 1905 edition of the London newspaper "Daily Graphic" quoted Des Voeux, "He said it required no science to see that there was something produced in great cities which was not found in the country, and that was smoky fog, or what was known as 'smog'." The following day the newspaper stated that "Dr. Des Voeux did a public service in coining a new word for the London fog." However, the term appears fifteen years earlier than Dr. Voeux's paper, in a column in the July 3, 1880, Santa Cruz Weekly Sentinel.

Coal fires can emit significant clouds of smoke that contribute to the formation of winter smog. Coal fires can be used to heat individual buildings or to provide energy in a power-producing plant. Air pollution from this source has been reported in England since the Middle Ages.London, in particular, was notorious up through the mid-20th century for its coal-caused smogs, which were nicknamed 'pea-soupers.' Air pollution of this type is still a problem in areas that generate significant smoke from burning coal. The emissions from coal combustion are one of the main causes of air pollution in China. Especially during autumn and winter when coal-fired heating ramps up, the amount of produced smoke at times forces some Chinese cities to close down roads, schools or airports. One prominent example for this was China's Northeastern city of Harbin in 2013.

Traffic emissions – such as from trucks, buses, and automobiles– also contribute to the formation of smog. Airborne by-products from vehicle exhaust systems cause air pollution and are a major ingredient in the creation of smog in some large cities.

The major culprits from transportation sources are carbon monoxide (CO),nitrogen oxides (NO and NO),volatile organic compounds, and hydrocarbons (hydrocarbons are the main component of petroleum fuels such as gasoline and diesel fuel). Transportation emissions also include sulfur dioxides and particulate matter but in much smaller quantities than the pollutants mentioned previously. The nitrogen oxides and volatile organic compounds can undergo a series of chemical reactions with sunlight, heat, ammonia, moisture, and other compounds to form the noxious vapors, ground level ozone, and particles that comprise smog.

Photochemical smog, often referred to as "summer smog", is the chemical reaction of sunlight, nitrogen oxides and volatile organic compounds in the atmosphere, which leaves airborne particles and ground-level ozone. Photochemical smog depends on primary pollutants as well as the formation of secondary pollutants. These primary pollutants include nitrogen oxides, particularly nitric oxide (NO) and nitrogen dioxide (NO), and volatile organic compounds. The relevant secondary pollutants include peroxylacyl nitrates (PAN), tropospheric ozone, and aldehydes. An important secondary pollutant for photochemical smog is ozone, which is formed when hydrocarbons (HC) and nitrogen oxides (NO) combine in the presence of sunlight; nitrogen dioxide (NO), which is formed as nitric oxide (NO) combines with oxygen (O) in the air. In addition, when SO and NO are emitted they eventually are oxidized in the troposphere to nitric acid and sulfuric acid, which, when mixed with water, form the main components of acid rain. All of these harsh chemicals are usually highly reactive and oxidizing. Photochemical smog is therefore considered to be a problem of modern industrialization. It is present in all modern cities, but it is more common in cities with sunny, warm, dry climates and a large number of motor vehicles. Because it travels with the wind, it can affect sparsely populated areas as well.
The composition and chemical reactions involved in photochemical smog were not understood until the 1950s. In 1948, flavor chemist Arie Haagen-Smit adapted some of his equipment to collect chemicals from polluted air, and identified ozone as a component of Los Angeles smog. Haagen-Smit went on to discover that nitrogen oxides from automotive exhausts and gaseous hydrocarbons from cars and oil refineries, exposed to sunlight, were key ingredients in the formation of ozone and photochemical smog. Haagen-Smit worked with Arnold Beckman, who developed various equipment for detecting smog, ranging from an "Apparatus for recording gas concentrations in the atmosphere" patented on October 7, 1952, to "air quality monitoring vans" for use by government and industry.

During the morning rush hour, a high concentration of nitric oxide and hydrocarbons are emitted to the atmosphere, mostly via on-road traffic but also from industrial sources. Some hydrocarbons are rapidly oxidized by OH· and form peroxy radicals, which convert nitric oxide (NO) to nitrogen dioxide (NO).

(1) <chem>R{.} + O2 + M -> RO2{.} + M</chem>

(2) <chem>RO2{.} + NO -> NO2 + RO{.}</chem>

(3) <chem>HO2{.} + NO -> NO2 + OH{.}</chem>

Nitrogen dioxide (NO) and nitric oxide (NO) further react with ozone (O) in a series of chemical reactions:

(4) <chem>NO2 + hv -> O(^3P) + NO</chem>, formula_1

(5) <chem>O(^3P) + O2 + M-> O3 + M(heat)</chem>

(6) <chem>O3 + NO -> NO2 + O2</chem>

This series of equations is referred to as the photostationary state (PSS). However, because of the presence of Reaction 2 and 3, NO and ozone are not in a perfect steady state. By replacing Reaction 6 with Reaction 2 and Reaction 3, the O molecule is no longer destroyed. Therefore, the concentration of ozone keeps increasing throughout the day. This mechanism can escalate the formation of ozone in smog. Other reactions such as the photooxidation of formaldehyde (HCHO), a common secondary pollutant, can also contribute to the increased concentration of ozone and NO. Photochemical smog is more prevalent during summer days since incident solar radiation fluxes are high, which favors the formation of ozone (reactions 4 and 5). The presence of a temperature inversion layer is another important factor. That is because it prevents the vertical convective mixing of the air and thus allows the pollutants, including ozone, to accumulate near the ground level, which again favors the formation of photochemical smog.

There are certain reactions that can limit the formation of O in smog. The main limiting reaction in polluted areas is:

(7) <chem>NO2 + OH{.} + M -> HNO3 + M</chem>

This reaction removes NO which limits the amount of O that can be produced from its photolysis (reaction 4). HNO is a sticky compound that can easily be removed onto surfaces (dry deposition) or dissolved in water and be rained out (wet deposition). Both ways are common in the atmosphere and can efficiently remove the radicals and nitrogen dioxide.

An erupting volcano can emit high levels of sulphur dioxide along with a large quantity of particulates matter; two key components to the creation of smog. However, the smog created as a result of a volcanic eruption is often known as vog to distinguish it as a natural occurrence. The chemical reactions that form smog following a volcanic eruption are different than the reactions that form photochemical smog. The term smog encompasses the effect when a large amount of gas phase molecules and particulate matter are emitted to the atmosphere, creating a visible haze. The event causing a large amount of emissions can vary but still result in the formation of smog.

Plants are another natural source of hydrocarbons that could undergo reactions in the atmosphere and produce smog. Globally both plants and soil contribute a substantial amount to the production of hydrocarbons, mainly by producing isoprene and terpenes. Hydrocarbons released by plants can often be more reactive than man-made hydrocarbons. For example when plants release isoprene, the isoprene reacts very quickly in the atmosphere with hydroxyl radicals. These reactions produce hydroperoxides which increase ozone formation.
In 1979, American presidential candidate Ronald Reagan "said that trees produce smog." and the EPA confirmed this in 1999. "Trees are a natural source of VOCs"(volatile organic compounds) "The New York Times" reported about "terpenes emitted from the trees" as far back as 1964.

Smog is a serious problem in many cities and continues to harm human health. Ground-level ozone, sulphur dioxide, nitrogen dioxide and carbon monoxide are especially harmful for senior citizens, children, and people with heart and lung conditions such as emphysema, bronchitis, and asthma. It can inflame breathing passages, decrease the lungs' working capacity, cause shortness of breath, pain when inhaling deeply, wheezing, and coughing. It can cause eye and nose irritation and it dries out the protective membranes of the nose and throat and interferes with the body's ability to fight infection, increasing susceptibility to illness. Hospital admissions and respiratory deaths often increase during periods when ozone levels are high. There is a lack of knowledge on the long-term effects of air pollution exposure and the origin of asthma. An experiment was carried out using intense air pollution similar to that of the 1952 Great Smog of London. The results from this experiment concluded that there is a link between early-life pollution exposure that leads to the development of asthma, proposing the ongoing effect of the Great Smog.
Modern studies continue to find links between mortality and the presence of smog. One study, published in Nature magazine, found that smog episodes in the city of Jinan, a large city in eastern China, during 2011–15, were associated with a 5.87% (95% CI 0.16–11.58%) increase in the rate of overall mortality. This study highlights the effect of exposure to air pollution on the rate of mortality in China.

The U.S. EPA has developed an air quality index to help explain air pollution levels to the general public. 8 hour average ozone concentrations of 85 to 104 ppbv are described as "Unhealthy for Sensitive Groups", 105 ppbv to 124 ppbv as "unhealthy" and 125 ppb to 404 ppb as "very unhealthy". The "very unhealthy" range for some other pollutants are: 355 μg m – 424 μg m for PM10; 15.5 ppm – 30.4ppm for CO and 0.65 ppm – 1.24 ppm for NO.

In 2016, the Ontario Medical Association announced that smog is responsible for an estimated 9,500 premature deaths in the province each year.

A 20-year American Cancer Society study found that cumulative exposure also increases the likelihood of premature death from a respiratory disease, implying the 8-hour standard may be insufficient.

Tiny magnetic particles from air pollution have for the first time been discovered to be lodged in human brains– and researchers think they could be a possible cause of Alzheimer's disease.
Researchers at Lancaster University found abundant magnetite nanoparticles in the brain tissue from 37 individuals aged three to 92-years-old who lived in Mexico City and Manchester. This strongly magnetic mineral is toxic and has been implicated in the production of reactive oxygen species (free radicals) in the human brain, which are associated with neurodegenerative diseases including Alzheimer's disease.

A study examining 806 women who had babies with birth defects between 1997 and 2006, and 849 women who had healthy babies, found that smog in the San Joaquin Valley area of California was linked to two types of neural tube defects: spina bifida (a condition involving, among other manifestations, certain malformations of the spinal column), and anencephaly (the underdevelopment or absence of part or all of the brain, which if not fatal usually results in profound impairment).

According to a study published in The Lancet, even a very small (5 μg) change in PM2.5 exposure was associated with an increase (18%) in risk of a low birth weight at delivery, and this relationship held even below the current accepted safe levels.

Smog can form in almost any climate where industries or cities release large amounts of air pollution, such as smoke or gases. However, it is worse during periods of warmer, sunnier weather when the upper air is warm enough to inhibit vertical circulation. It is especially prevalent in geologic basins encircled by hills or mountains. It often stays for an extended period of time over densely populated cities or urban areas, and can build up to dangerous levels.

According to the Canadian Science Smog Assessment published in 2012, smog is responsible for detrimental effects on human and ecosystem health, as well as socioeconomic well-being across the country. It was estimated that the province of Ontario sustains $201 million in damages annually for selected crops, and an estimated tourism revenue degradation of $7.5 million in Vancouver and $1.32 million in The Fraser Valley due to decreased visibility. Air pollution in British Columbia is of particular concern, especially in the Fraser Valley, because of a meteorological effect called inversion which decreases air dispersion and leads to smog concentration.

For the past few years, cities in northern India have been covered in a thick layer of winter smog. The situation has turned quite drastic in the National Capital, Delhi. This smog is caused by the collection of Particulate Matter (a very fine type of dust and toxic gases) in the air due to stagnant movement of air during winters.

Delhi is the most polluted city in the world and according to one estimate, air pollution causes the death of about 10,500 people in Delhi every year. During 2013–14, peak levels of fine particulate matter (PM) in Delhi increased by about 44%, primarily due to high vehicular and industrial emissions, construction work and crop burning in adjoining states. Delhi has the highest level of the airborne particulate matter, PM2.5 considered most harmful to health, with 153 micrograms. Rising air pollution level has significantly increased lung-related ailments (especially asthma and lung cancer) among Delhi's children and women. The dense smog in Delhi during winter season results in major air and rail traffic disruptions every year. According to Indian meteorologists, the average maximum temperature in Delhi during winters has declined notably since 1998 due to rising air pollution.
Environmentalists have criticised the Delhi government for not doing enough to curb air pollution and to inform people about air quality issues. Most of Delhi's residents are unaware of alarming levels of air pollution in the city and the health risks associated with it. Since the mid-1990s, Delhi has undertaken some measures to curb air pollution – Delhi has the third highest quantity of trees among Indian cities and the Delhi Transport Corporation operates the world's largest fleet of environmentally friendly compressed natural gas (CNG) buses. In 1996, the Centre for Science and Environment (CSE) started a public interest litigation in the Supreme Court of India that ordered the conversion of Delhi's fleet of buses and taxis to run on CNG and banned the use of leaded petrol in 1998. In 2003, Delhi won the United States Department of Energy's first 'Clean Cities International Partner of the Year' award for its "bold efforts to curb air pollution and support alternative fuel initiatives". The Delhi Metro has also been credited for significantly reducing air pollutants in the city.

However, according to several authors, most of these gains have been lost, especially due to stubble burning, rise in market share of diesel cars and a considerable decline in bus ridership. According to CUE and System of Air Quality Weather Forecasting and Research (SAFER), burning of agricultural waste in nearby Punjab, Haryana and Uttar Pradesh regions results in severe intensification of smog over Delhi. The state government of adjoining Uttar Pradesh is considering imposing a ban on crop burning to reduce pollution in Delhi NCR and an environmental panel has appealed to India's Supreme Court to impose a 30% cess on diesel cars.

Joint research between American and Chinese researchers in 2006 concluded that much of the city's pollution comes from surrounding cities and provinces. On average 35–60% of the ozone can be traced to sources outside the city. Shandong Province and Tianjin Municipality have a "significant influence on Beijing's air quality", partly due to the prevailing south/southeasterly flow during the summer and the mountains to the north and northwest.

In 1306, concerns over air pollution were sufficient for Edward I to (briefly) ban coal fires in London. In 1661, John Evelyn's "Fumifugium" suggested burning fragrant wood instead of mineral coal, which he believed would reduce coughing. The "" the same year describes how the smoke "does our lungs and spirits choke, Our hanging spoil, and rust our iron."

Severe episodes of smog continued in the 19th and 20th centuries, mainly in the winter, and were nicknamed "pea-soupers," from the phrase "as thick as pea soup". The Great Smog of 1952 darkened the streets of London and killed approximately 4,000 people in the short time of four days (a further 8,000 died from its effects in the following weeks and months). Initially a flu epidemic was blamed for the loss of life.

In 1956 the Clean Air Act started legally enforcing smokeless zones in the capital. There were areas where no soft coal was allowed to be burned in homes or in businesses, only coke, which produces no smoke. Because of the smokeless zones, reduced levels of sooty particulates eliminated the intense and persistent London smog.

It was after this that the great clean-up of London began. One by one, historical buildings which, during the previous two centuries had gradually completely blackened externally, had their stone facades cleaned and restored to their original appearance. Victorian buildings whose appearance changed dramatically after cleaning included the British Museum of Natural History. A more recent example was the Palace of Westminster, which was cleaned in the 1980s. A notable exception to the restoration trend was 10 Downing Street, whose bricks upon cleaning in the late 1950s proved to be naturally "yellow"; the smog-derived black colour of the façade was considered so iconic that the bricks were painted black to preserve the image. Smog caused by traffic pollution, however, does still occur in modern London.

Other areas of the United Kingdom were affected by smog, especially heavily industrialised areas.

The cities of Glasgow and Edinburgh, in Scotland, suffered smoke-laden fogs in 1909. Des Voeux, commonly credited with creating the "smog" moniker, presented a paper in 1911 to the Manchester Conference of the Smoke Abatement League of Great Britain about the fogs and resulting deaths.

One Birmingham resident described near black-out conditions in the 1900s before the Clean Air Act, with visibility so poor that cyclists had to dismount and walk in order to stay on the road.

On 29 April 2015, the UK Supreme Court ruled that the government must take immediate action to cut air pollution, following a case brought by environmental lawyers at ClientEarth.

Due to its location in a highland "bowl", cold air sinks down onto the urban area of Mexico City, trapping industrial and vehicle pollution underneath, and turning it into the most infamously smog-plagued city of Latin America. Within one generation, the city has changed from being known for some of the cleanest air of the world into one with some of the worst pollution, with pollutants like nitrogen dioxide being double or even triple international standards.
Similar to Mexico City, the air pollution of Santiago valley, located between the Andes and the Chilean Coast Range, turn it into the most infamously smog-plagued city of South America. Other aggravates of the situation reside in its high latitude (31 degrees South) and dry weather during most of the year.

In December 2005, schools and public offices had to close in Tehran and 1600 people were taken to hospital, in a severe smog blamed largely on unfiltered car exhaust.

Smog was brought to the attention of the general U.S. public in 1933 with the publication of the book "Stop That Smoke", by Henry Obermeyer, a New York public utility official, in which he pointed out the effect on human life and even the destruction of of a farmer's spinach crop. Since then, the United States Environmental Protection Agency has designated over 300 U.S. counties to be non-attainment areas for one or more pollutants tracked as part of the National Ambient Air Quality Standards. These areas are largely clustered around large metropolitan areas, with the largest contiguous non-attainment zones in California and the Northeast. Various U.S. and Canadian government agencies collaborate to produce real-time air quality maps and forecasts. To combat smog conditions, localities may declare "smog alert" days, such as in the Spare the Air program in the San Francisco Bay Area.

In the United States, smog pollution kills 24,000 Americans every year. The U.S. is among the dirtier countries in terms of smog, ranked 123 out of 195 countries measured, where 1 is cleanest and 195 is most smog polluted.

Because of their locations in low basins surrounded by mountains, Los Angeles and the San Joaquin Valley are notorious for their smog. Heavy automobile traffic, combined with the additional effects of the San Francisco Bay and Los Angeles/Long Beach port complexes, frequently contribute to further air pollution.

Los Angeles in particular is strongly predisposed to accumulation of smog, because of peculiarities of its geography and weather patterns. Los Angeles is situated in a flat basin with ocean on one side and mountain ranges on three sides. A nearby cold ocean current depresses surface air temperatures in the area, resulting in an inversion layer: a phenomenon where air temperature increases, instead of decreasing, with altitude, suppressing thermals and restricting vertical convection. All taken together, this results in a relatively thin, enclosed layer of air above the city that cannot easily escape out of the basin and tends to accumulate pollution.

Los Angeles was one of the best known cities suffering from transportation smog for much of the 20th century, so much so that it was sometimes said that "Los Angeles" was a synonym for "smog." In 1970, when the Clean Air Act was passed, Los Angeles was the most polluted basin in the country, and California was unable to create a State Implementation Plan that would enable it to meet the new air quality standards. However, ensuing strict regulations by state and federal government agencies overseeing this problem (such as the California Air Resources Board and the United States Environmental Protection Agency), including tight restrictions on allowed emissions levels for all new cars sold in California and mandatory regular emission tests of older vehicles, resulted in significant improvements in air quality. For example, air concentrations of volatile organic compounds declined by a factor of 50 between 1962 and 2012. Concentrations of air pollutants such as nitrous oxides and ozone declined by 70% to 80% over the same period of time.


In the late 1990s, massive immigration to Ulaanbaatar from the countryside began. An estimated 150,000 households, mainly living in traditional Mongolian gers on the outskirts of Ulaanbaatar, burn wood and coal (some poor families burn even car tires and trash) to heat themselves during the harsh winter, which lasts from October to April, since these outskirts are not connected to the city's central heating system. A temporary solution to decrease smog was proposed in the form of stoves with improved efficiency, although with no visible results. 
Coal-fired ger stoves release high levels of ash and other particulate matter (PM). When inhaled, these particles can settle in the lungs and respiratory tract and cause health problems. At two to 10 times above Mongolian and international air quality standards, Ulaanbaatar's PM rates are among the worst in the world, according to a December 2009 World Bank report. The Asian Development Bank (ADB) estimates that health costs related to this air pollution account for as much as 4 percent of Mongolia's GDP.

Smog is a regular problem in Southeast Asia caused by land and forest fires in Indonesia, especially Sumatra and Kalimantan, although the term haze is preferred in describing the problem. Farmers and plantation owners are usually responsible for the fires, which they use to clear tracts of land for further plantings. Those fires mainly affect Brunei, Indonesia, Philippines, Malaysia, Singapore and Thailand, and occasionally Guam and Saipan. The economic losses of the fires in 1997 have been estimated at more than US$9 billion. This includes damages in agriculture production, destruction of forest lands, health, transportation, tourism, and other economic endeavours. Not included are social, environmental, and psychological problems and long-term health effects. The second-latest bout of haze to occur in Malaysia, Singapore and the Malacca Straits is in October 2006, and was caused by smoke from fires in Indonesia being blown across the Straits of Malacca by south-westerly winds. A similar haze has occurred in June 2013, with the PSI setting a new record in Singapore on June 21 at 12pm with a reading of 401, which is in the "Hazardous" range.

The Association of Southeast Asian Nations (ASEAN) reacted. In 2002, the Agreement on Transboundary Haze Pollution was signed between all ASEAN nations. ASEAN formed a Regional Haze Action Plan (RHAP) and established a co-ordination and support unit (CSU). RHAP, with the help of Canada, established a monitoring and warning system for forest/vegetation fires and implemented a Fire Danger Rating System (FDRS). The Malaysian Meteorological Department (MMD) has issued a daily rating of fire danger since September 2003. Indonesia has been ineffective at enforcing legal policies on errant farmers.

Since start of winter season heavy smog loaded with pollutants covered major part of Punjab especially the city of Lahore, causing breathing problems and disrupting normal traffic.

Doctors advised residents to stay indoors and wear facemasks outside.

The severity of smog is often measured using automated optical instruments such as Nephelometers, as haze is associated with visibility and traffic control in ports. Haze however can also be an indication of poor air quality though this is often better reflected using accurate purpose built air indexes such as the American Air Quality Index, the Malaysian API (Air Pollution Index) and the Singaporean Pollutant Standards Index.

In hazy conditions, it is likely that the index will report the suspended particulate level. The disclosure of the responsible pollutant is mandated in some jurisdictions.

The Malaysian API does not have a capped value; hence its most hazardous readings can go above 500. Above 500, a state of emergency is declared in the affected area. Usually, this means that non-essential government services are suspended, and all ports in the affected area are closed. There may also be prohibitions on private sector commercial and industrial activities in the affected area excluding the food sector. So far, state of emergency rulings due to hazardous API levels were applied to the Malaysian towns of Port Klang, Kuala Selangor and the state of Sarawak during the 2005 Malaysian haze and the 1997 Southeast Asian haze.







</doc>
<doc id="27001" url="https://en.wikipedia.org/wiki?curid=27001" title="Smoke">
Smoke

Smoke is a collection of airborne particulates and gases emitted when a material undergoes combustion or pyrolysis, together with the quantity of air that is entrained or otherwise mixed into the mass. It is commonly an unwanted by-product of fires (including stoves, candles, internal combustion engines, oil lamps, and fireplaces), but may also be used for pest control (fumigation), communication (smoke signals), defensive and offensive capabilities in the military (smoke screen), cooking, or smoking (tobacco, cannabis, etc.). It is used in rituals where incense, sage, or resin is burned to produce a smell for spiritual or magical purposes. It can also be a flavoring agent and preservative for various foodstuffs.

Smoke inhalation is the primary cause of death in victims of indoor fires. The smoke kills by a combination of thermal damage, poisoning and pulmonary irritation caused by carbon monoxide, hydrogen cyanide and other combustion products.

Smoke is an aerosol (or mist) of solid particles and liquid droplets that are close to the ideal range of sizes for Mie scattering of visible light.

The composition of smoke depends on the nature of the burning fuel and the conditions of combustion. Fires with high availability of oxygen burn at a high temperature and with a small amount of smoke produced; the particles are mostly composed of ash, or with large temperature differences, of condensed aerosol of water. High temperature also leads to production of nitrogen oxides. Sulfur content yields sulfur dioxide, or in case of incomplete combustion, hydrogen sulfide. Carbon and hydrogen are almost completely oxidized to carbon dioxide and water. Fires burning with lack of oxygen produce a significantly wider palette of compounds, many of them toxic. Partial oxidation of carbon produces carbon monoxide, while nitrogen-containing materials can yield hydrogen cyanide, ammonia, and nitrogen oxides. Hydrogen gas can be produced instead of water. Contents of halogens such as chlorine (e.g. in polyvinyl chloride or brominated flame retardants) may lead to the production of hydrogen chloride, phosgene, dioxin, and chloromethane, bromomethane and other halocarbons. Hydrogen fluoride can be formed from fluorocarbons, whether fluoropolymers subjected to fire or halocarbon fire suppression agents. Phosphorus and antimony oxides and their reaction products can be formed from some fire retardant additives, increasing smoke toxicity and corrosivity. Pyrolysis of polychlorinated biphenyls (PCB), e.g. from burning older transformer oil, and to lower degree also of other chlorine-containing materials, can produce 2,3,7,8-tetrachlorodibenzodioxin, a potent carcinogen, and other polychlorinated dibenzodioxins. Pyrolysis of fluoropolymers, e.g. teflon, in presence of oxygen yields carbonyl fluoride (which hydrolyzes readily to HF and CO); other compounds may be formed as well, e.g. carbon tetrafluoride, hexafluoropropylene, and highly toxic perfluoroisobutene (PFIB).

Pyrolysis of burning material, especially incomplete combustion or smoldering without adequate oxygen supply, also results in production of a large amount of hydrocarbons, both aliphatic (methane, ethane, ethylene, acetylene) and aromatic (benzene and its derivates, polycyclic aromatic hydrocarbons; e.g. benzo[a]pyrene, studied as a carcinogen, or retene), terpenes. Heterocyclic compounds may be also present. Heavier hydrocarbons may condense as tar; smoke with significant tar content is yellow to brown. Presence of such smoke, soot, and/or brown oily deposits during a fire indicates a possible hazardous situation, as the atmosphere may be saturated with combustible pyrolysis products with concentration above the upper flammability limit, and sudden inrush of air can cause flashover or backdraft.

Presence of sulfur can lead to formation of e.g. hydrogen sulfide, carbonyl sulfide, sulfur dioxide, carbon disulfide, and thiols; especially thiols tend to get adsorbed on surfaces and produce a lingering odor even long after the fire. Partial oxidation of the released hydrocarbons yields in a wide palette of other compounds: aldehydes (e.g. formaldehyde, acrolein, and furfural), ketones, alcohols (often aromatic, e.g. phenol, guaiacol, syringol, catechol, and cresols), carboxylic acids (formic acid, acetic acid, etc.).

The visible particulate matter in such smokes is most commonly composed of carbon (soot). Other particulates may be composed of drops of condensed tar, or solid particles of ash. The presence of metals in the fuel yields particles of metal oxides. Particles of inorganic salts may also be formed, e.g. ammonium sulfate, ammonium nitrate, or sodium chloride. Inorganic salts present on the surface of the soot particles may make them hydrophilic. Many organic compounds, typically the aromatic hydrocarbons, may be also adsorbed on the surface of the solid particles. Metal oxides can be present when metal-containing fuels are burned, e.g. solid rocket fuels containing aluminium. Depleted uranium projectiles after impacting the target ignite, producing particles of uranium oxides. Magnetic particles, spherules of magnetite-like ferrous ferric oxide, are present in coal smoke; their increase in deposits after 1860 marks the beginning of the Industrial Revolution. (Magnetic iron oxide nanoparticles can be also produced in the smoke from meteorites burning in the atmosphere.) Magnetic remanence, recorded in the iron oxide particles, indicates the strength of Earth's magnetic field when they were cooled beyond their Curie temperature; this can be used to distinguish magnetic particles of terrestrial and meteoric origin. Fly ash is composed mainly of silica and calcium oxide. Cenospheres are present in smoke from liquid hydrocarbon fuels. Minute metal particles produced by abrasion can be present in engine smokes. Amorphous silica particles are present in smokes from burning silicones; small proportion of silicon nitride particles can be formed in fires with insufficient oxygen. The silica particles have about 10 nm size, clumped to 70–100 nm aggregates and further agglomerated to chains. Radioactive particles may be present due to traces of uranium, thorium, or other radionuclides in the fuel; hot particles can be present in case of fires during nuclear accidents (e.g. Chernobyl disaster) or nuclear war.

Smoke particulates, like other aerosols, are categorized into three modes based on particle size:
Most of the smoke material is primarily in coarse particles. Those undergo rapid dry precipitation, and the smoke damage in more distant areas outside of the room where the fire occurs is therefore primarily mediated by the smaller particles.

Aerosol of particles beyond visible size is an early indicator of materials in a preignition stage of a fire.

Burning of hydrogen-rich fuel produces water; this results in smoke containing droplets of water vapor. In absence of other color sources (nitrogen oxides, particulates...), such smoke is white and cloud-like.

Smoke emissions may contain characteristic trace elements. Vanadium is present in emissions from oil fired power plants and refineries; oil plants also emit some nickel. Coal combustion produces emissions containing aluminium, arsenic, chromium, cobalt, copper, iron, mercury, selenium, and uranium.

Traces of vanadium in high-temperature combustion products form droplets of molten vanadates. These attack the passivation layers on metals and cause high temperature corrosion, which is a concern especially for internal combustion engines. Molten sulfate and lead particulates also have such effect.

Some components of smoke are characteristic of the combustion source. Guaiacol and its derivatives are products of pyrolysis of lignin and are characteristic of wood smoke; other markers are syringol and derivates, and other methoxy phenols. Retene, a product of pyrolysis of conifer trees, is an indicator of forest fires. Levoglucosan is a pyrolysis product of cellulose. Hardwood vs softwood smokes differ in the ratio of guaiacols/syringols. Markers for vehicle exhaust include polycyclic aromatic hydrocarbons, hopanes, steranes, and specific nitroarenes (e.g. 1-nitropyrene). The ratio of hopanes and steranes to elemental carbon can be used to distinguish between emissions of gasoline and diesel engines.

Many compounds can be associated with particulates; whether by being adsorbed on their surfaces, or by being dissolved in liquid droplets. Hydrogen chloride is well absorbed in the soot particles.

Inert particulate matter can be disturbed and entrained into the smoke. Of particular concern are particles of asbestos.

Deposited hot particles of radioactive fallout and bioaccumulated radioisotopes can be reintroduced into the atmosphere by wildfires and forest fires; this is a concern in e.g. the Zone of alienation containing contaminants from the Chernobyl disaster.

Polymers are a significant source of smoke. Aromatic side groups, e.g. in polystyrene, enhance generation of smoke. Aromatic groups integrated in the polymer backbone produce less smoke, likely due to significant charring. Aliphatic polymers tend to generate the least smoke, and are non-self-extinguishing. However presence of additives can significantly increase smoke formation. Phosphorus-based and halogen-based flame retardants decrease production of smoke. Higher degree of cross-linking between the polymer chains has such effect too.

The naked eye detects particle sizes greater than 7 µm (micrometres). Visible particles emitted from a fire are referred to as smoke. Invisible particles are generally referred to as gas or fumes. This is best illustrated when toasting bread in a toaster. As the bread heats up, the products of combustion increase in size. The fumes initially produced are invisible but become visible if the toast is burnt.

An ionization chamber type smoke detector is technically a product of combustion detector, not a smoke detector. Ionization chamber type smoke detectors detect particles of combustion that are invisible to the naked eye. This explains why they may frequently false alarm from the fumes emitted from the red-hot heating elements of a toaster, before the presence of visible smoke, yet they may fail to activate in the early, low-heat smoldering stage of a fire.

Smoke from a typical house fire contains hundreds of different chemicals and fumes. As a result, the damage caused by the smoke can often exceed that caused by the actual heat of the fire. In addition to the physical damage caused by the smoke of a fire – which manifests itself in the form of stains – is the often even harder to eliminate problem of a smoky odor. Just as there are contractors that specialize in rebuilding/repairing homes that have been damaged by fire and smoke, fabric restoration companies specialize in restoring fabrics that have been damaged in a fire.

Smoke from oxygen-deprived fires contains a significant concentration of compounds that are flammable. A cloud of smoke, in contact with atmospheric oxygen, therefore has the potential of being ignited – either by another open flame in the area, or by its own temperature. This leads to effects like backdraft and flashover. Smoke inhalation is also a danger of smoke that can cause serious injury and death.

Many compounds of smoke from fires are highly toxic and/or irritating. The most dangerous is carbon monoxide leading to carbon monoxide poisoning, sometimes with the additive effects of hydrogen cyanide and phosgene. Smoke inhalation can therefore quickly lead to incapacitation and loss of consciousness. Sulfur oxides, hydrogen chloride and hydrogen fluoride in contact with moisture form sulfuric, hydrochloric and hydrofluoric acid, which are corrosive to both lungs and materials. When asleep the nose does not sense smoke nor does the brain, but the body will wake up if the lungs become enveloped in smoke and the brain will be stimulated and the person will be awoken. This does not work if the person is incapacitated or under the influence of drugs and/or alcohol.

Cigarette smoke is a major modifiable risk factor for lung disease, heart disease, and many cancers. Smoke can also be a component of ambient air pollution due to the burning of coal in power plants, forest fires or other sources, although the concentration of pollutants in ambient air is typically much less than that in cigarette smoke. One day of exposure to PM2.5 at a concentration of 880 μg/m3, such as occurs in Beijing, China, is the equivalent of smoking one or two cigarettes in terms of particulate inhalation by weight. The analysis is complicated, however, by the fact that the organic compounds present in various ambient particulates may have a higher carcinogenicity than the compounds in cigarette smoke particulates. Secondhand tobacco smoke is the combination of both sidestream and mainstream smoke emissions from a burning tobacco product. These emissions contain more than 50 carcinogenic chemicals. According to the Surgeon General's 2006 report on the subject, "Short exposures to secondhand [tobacco] smoke can cause blood platelets to become stickier, damage the lining of blood vessels, decrease coronary flow velocity reserves, and reduce heart variability, potentially increasing the risk of a heart attack". The American Cancer Society lists "heart disease, lung infections, increased asthma attacks, middle ear infections, and low birth weight" as ramifications of smoker's emission.
Smoke can obscure visibility, impeding occupant exiting from fire areas. In fact, the poor visibility due to the smoke that was in the Worcester Cold Storage Warehouse fire in Worcester, Massachusetts was the reason why the trapped rescue firefighters couldn't evacuate the building in time. Because of the striking similarity that each floor shared, the dense smoke caused the firefighters to become disoriented.

Smoke contains a wide variety of chemicals, many of them aggressive in nature. Examples are hydrochloric acid and hydrobromic acid, produced from halogen-containing plastics and fire retardants, hydrofluoric acid released by pyrolysis of fluorocarbon fire suppression agents, sulfuric acid from burning of sulfur-containing materials, nitric acid from high-temperature fires where nitrous oxide gets formed, phosphoric acid and antimony compounds from P and Sb based fire retardants, and many others. Such corrosion is not significant for structural materials, but delicate structures, especially microelectronics, are strongly affected. Corrosion of circuit board traces, penetration of aggressive chemicals through the casings of parts, and other effects can cause an immediate or gradual deterioration of parameters or even premature (and often delayed, as the corrosion can progress over long time) failure of equipment subjected to smoke. Many smoke components are also electrically conductive; deposition of a conductive layer on the circuits can cause crosstalks and other deteriorations of the operating parameters or even cause short circuits and total failures. Electrical contacts can be affected by corrosion of surfaces, and by deposition of soot and other conductive particles or nonconductive layers on or across the contacts. Deposited particles may adversely affect the performance of optoelectronics by absorbing or scattering the light beams.

Corrosivity of smoke produced by materials is characterized by the corrosion index (CI), defined as material loss rate (angstrom/minute) per amount of material gasified products (grams) per volume of air (m). It is measured by exposing strips of metal to flow of combustion products in a test tunnel. Polymers containing halogen and hydrogen (polyvinyl chloride, polyolefins with halogenated additives, etc.) have the highest CI as the corrosive acids are formed directly with water produced by the combustion, polymers containing halogen only (e.g. polytetrafluoroethylene) have lower CI as the formation of acid is limited to reactions with airborne humidity, and halogen-free materials (polyolefins, wood) have the lowest CI. However, some halogen-free materials can also release significant amount of corrosive products.

Smoke damage to electronic equipment can be significantly more extensive than the fire itself. Cable fires are of special concern; low smoke zero halogen materials are preferable for cable insulation.

When smoke comes into contact with the surface of any substance or structure, the chemicals contained in it are transferred to it. The corrosive properties of the chemicals cause the substance or structure to decompose at a rapid rate. Certain materials or structures absorb these chemicals, which is why clothing, unsealed surfaces, potable water, piping, wood, etc., are replaced in most cases of structural fires.

As early as the 15th century Leonardo da Vinci commented at length on the difficulty of assessing smoke, and distinguished between black smoke (carbonized particles) and white 'smoke' which is not a smoke at all but merely a suspension of harmless water particulates.

Smoke from heating appliances is commonly measured in one of the following ways:

In-line capture. A smoke sample is simply sucked through a filter which is weighed before and after the test and the mass of smoke found. This is the simplest and probably the most accurate method, but can only be used where the smoke concentration is slight, as the filter can quickly become blocked.

The ASTM smoke pump is a simple and widely used method of in-line capture where a measured volume of smoke is pulled through a filter paper and the dark spot so formed is compared with a standard.

Filter/dilution tunnel. A smoke sample is drawn through a tube where it is diluted with air, the resulting smoke/air mixture is then pulled through a filter and weighed. This is the internationally recognized method of measuring smoke from combustion.

Electrostatic precipitation. The smoke is passed through an array of metal tubes which contain suspended wires. A (huge) electrical potential is applied across the tubes and wires so that the smoke particles become charged and are attracted to the sides of the tubes. This method can over-read by capturing harmless condensates, or under-read due to the insulating effect of the smoke. However, it is the necessary method for assessing volumes of smoke too great to be forced through a filter, i.e., from bituminous coal.

Ringelmann scale. A measure of smoke color. Invented by Professor Maximilian Ringelmann in Paris in 1888, it is essentially a card with squares of black, white and shades of gray which is held up and the comparative grayness of the smoke judged. Highly dependent on light conditions and the skill of the observer it allocates a grayness number from 0 (white) to 5 (black) which has only a passing relationship to the actual quantity of smoke. Nonetheless, the simplicity of the Ringelmann scale means that it has been adopted as a standard in many countries.

Optical scattering. A light beam is passed through the smoke. A light detector is situated at an angle to the light source, typically at 90°, so that it receives only light reflected from passing particles. A measurement is made of the light received which will be higher as the concentration of smoke particles becomes higher.

Optical obscuration. A light beam is passed through the smoke and a detector opposite measures the light. The more smoke particles are present between the two, the less light will be measured.

Combined optical methods. There are various proprietary optical smoke measurement devices such as the 'nephelometer' or the 'aethalometer' which use several different optical methods, including more than one wavelength of light, inside a single instrument and apply an algorithm to give a good estimate of smoke. It has been claimed that these devices can differentiate types of smoke and so their probable source can be inferred, though this is disputed.

Inference from carbon monoxide. Smoke is incompletely burned fuel, carbon monoxide is incompletely burned carbon, therefore it has long been assumed that measurement of CO in flue gas (a cheap, simple and very accurate procedure) will provide a good indication of the levels of smoke. Indeed, several jurisdictions use CO measurement as the basis of smoke control. However it is far from clear how accurate the correspondence is.

Throughout recorded history, humans have used the smoke of medicinal plants to cure illness. A sculpture from Persepolis shows Darius the Great (522–486 BC), the king of Persia, with two censers in front of him for burning Peganum harmala and/or sandalwood Santalum album, which was believed to protect the king from evil and disease. More than 300 plant species in 5 continents are used in smoke form for different diseases. As a method of drug administration, smoking is important as it is a simple, inexpensive, but very effective method of extracting particles containing active agents. More importantly, generating smoke reduces the particle size to a microscopic scale thereby increasing the absorption of its active chemical principles.



</doc>
<doc id="27002" url="https://en.wikipedia.org/wiki?curid=27002" title="Tobacco pipe">
Tobacco pipe

A tobacco pipe, often called simply a pipe, is a device specifically made to smoke tobacco. It comprises a chamber (the bowl) for the tobacco from which a thin hollow stem (shank) emerges, ending in a mouthpiece. Pipes can range from very simple machine-made briar models to highly prized hand-made artisanal implements made by renowned pipemakers, which are often very expensive collector's items. Pipe smoking is the oldest known traditional form of tobacco smoking.

Some Native American cultures smoke tobacco in ceremonial pipes, and have done so since long before the arrival of Europeans. For instance the Lakota people use a ceremonial pipe called čhaŋnúŋpa. Other American Indian cultures smoke tobacco socially. The tobacco plant is native to South America but spread into North America long before Europeans arrived. Tobacco was introduced to Europe from the Americas in the 16th century and spread around the world rapidly.

As tobacco was not introduced to the Old World until the 16th century, the older pipes outside of the Americas were usually used to smoke various other substances, including hashish, a rare and expensive substance outside areas of the Middle East, Central Asia and India, where it was then produced. 

A pipe's fundamental function is to provide a relatively safe, manipulable volume in which to incompletely combust a smokable substance. Typically this is accomplished by connecting a refractory 'bowl' to some sort of 'stem' which extends and may also cool the smoke mixture drawn through the combusting organic mass (see below).

The broad anatomy of a pipe typically comprises mainly the bowl and the stem. The "bowl" (1) which is the cup-like outer shell, the part hand-held while packing, holding and smoking a pipe, is also the part "knocked" top-down to loosen and release impacted spent tobacco. On being sucked, the general stem delivers the smoke from the bowl to the user's mouth.

Inside the bowl is an inner "chamber" (2) space holding tobacco pressed into it. This "draught hole" (3), is for air flow where air has travelled through the tobacco in the chamber, taking the smoke with it, up the "shank" (4). At the end of the shank, the pipe's "mortise" (5) and "tenon" (6) join is an air-tight, simple connection of two detachable parts where the mortise is a hole met by the tenon, a tight-fitting "tongue" at the start of the "stem" (7). Known as the "bore" (10), the inner shaft of this second section stays uniform throughout while the outer stem tapers down to the mouthpiece or "bit" (8) held in the smoker's teeth, and finally ends in the "lip" (9), attenuated for comfort.

The bowls of tobacco pipes are commonly made of briar wood, meerschaum, corncob, pear-wood, rose-wood or clay. Less common are other dense-grained woods such as cherry, olive, maple, mesquite, oak, and bog-wood. Minerals such as catlinite and soapstone have also been used. Pipe bowls are sometimes decorated by carving, and moulded clay pipes often had simple decoration in the mould.

Unusual, but still noteworthy pipe materials include gourds, as in the famous calabash pipe, and pyrolytic graphite. Metal and glass are uncommon materials for tobacco pipes, but are common for pipes intended for other substances, such as cannabis.
The stem needs a long channel of constant position and diameter running through it for a proper draw, although filter pipes have varying diameters and can be successfully smoked even without filters or adapters. Because it is molded rather than carved, clay may make up the entire pipe or just the bowl, but most other materials have stems made separately and detachable. Stems and bits of tobacco pipes are usually made of moldable materials like Ebonite, Lucite, Bakelite, and soft plastic. Less common are stems made of reeds, bamboo, or hollowed out pieces of wood. Expensive pipes once had stems made of amber, though this is rare now.


Calabash gourds (usually with meerschaum or porcelain bowls set inside them) have long made prized pipes, but they are labour-intensive and, today, quite expensive. Because of this expense, pipes with bodies made of wood (usually mahogany) instead of gourd, but with the same classic shape, are sold as calabashes. Both wood and gourd pipes are functionally the same (with the important exception that the dried gourd, usually being noticeably lighter, sits more comfortably in the mouth). They consist of a downward curve that ends with an upcurve where the bowl sits. Beneath the bowl is an air chamber which serves to cool, dry, and mellow the smoke. There are also briar pipes being sold as calabashes. These typically do not have an air chamber and are so named only because of their external shape.

A calabash pipe is rather large and easy to recognize as a pipe when used on a stage in dramatic productions. Although a British newspaper cartoon of the early 1900s depicts the British actor H. A. Saintsbury as the Great Detective smoking what may be a calabash pipe, its now-stereotypical identification with Sherlock Holmes remains a mystery.

Some commentators have erroneously associated the calabash with William Gillette, the first actor to become universally recognized as the embodiment of the detective. Gillette actually introduced the curving or bent pipe for use by Holmes, but his pipe was an ornate briar. Gillette chose a bent pipe, more easily clenched in the teeth when delivering lines.

While there are promotional stills of Basil Rathbone smoking calabash pipes as Holmes for other projects, most notably his radio show, in his first two outings as Holmes produced by 20th Century-Fox as taking place in the Victorian era, Rathbone smoked an apple-bowled, black briar with a half bend, made by Dunhill, the company known for making the best pipes at that time. In the next dozen films, the series produced by Universal Studios, with Holmes and Watson updated to the 1940s, Rathbone smokes a much less expensive Peterson half bend with a billiard-shaped bowl. A calabash is introduced in "The Spider Woman" but Holmes does not smoke it.

In the original chronicles, such as "The Adventure of the Copper Beeches", Sherlock Holmes is described as smoking a long-stemmed cherrywood (but not a churchwarden pipe) which he favored "when in a disputatious, rather than a meditative mood." Holmes smokes an old briar-root pipe on occasion, "The Sign of the Four" for one, and an "unsavory" and "disreputable" black and oily clay pipe in several stories, notably in "The Red-Headed League". Dr Watson declares it to be the detective's preferred pipe: “It was to him as a counsellor” ("A Case of Identity"); the “companion of his deepest meditations" ("The Valley of Fear")..
Bowls are made of varying shapes and materials to allow the smoker to try different characteristics or to dedicate particular bowls for particular tobaccos. Bowls are not interchangeable between manufacturers.

A "hookah", "ghelyan", or "narghile", is a Middle Eastern water pipe that cools the smoke by filtering it through a water chamber. Often ice, cough-drops, milk, or fruit juice is added to the water. Traditionally, the tobacco is mixed with a sweetener, such as honey or molasses. Fruit flavors have also become popular. Modern hookah smokers, especially in the US, smoke "me'assel", "moassel", "molasses" or "shisha", all names for the same wet mixture of tobacco, molasses/honey, glycerine, and often, flavoring. This style of tobacco is smoked in a bowl with foil or a screen (metal or glass) on top of the bowl. More traditional tobaccos are "tombiek" (a dry unflavored tobacco, which the user moistens in water, squeezes out the extra liquid, and places coals directly on top) or "jarak" (more of a paste of tobacco with fruit to flavor the smoke).


The majority of pipes sold today, whether handmade or machine-made, are fashioned from briar (). Briar is a particularly well suited wood for pipe making for a number of reasons. The first and most important characteristic is its natural resistance to fire. The second is its inherent ability to absorb moisture. The burl absorbs water in nature to supply the tree in the dry times and likewise will absorb the moisture that is a byproduct of combustion. Briar is cut from the root burl of the tree heath ("Erica arborea"), which is native to the rocky and sandy soils of the Mediterranean region. Briar burls are cut into two types of blocks; ebauchon and plateaux. Ebauchon is taken from the heart of the burl while plateaux is taken from the outer part of the burl. While both types of blocks can produce pipes of the highest quality, most artisan pipemakers prefer to use plateaux because of their superior graining.

Ceramic pipes, made of moulded and then fired clay, were used almost universally by Europeans between the introduction of tobacco in the 16th century, and the introduction of cheap cigarettes at the end of the nineteenth.

The material is not very strong and the early varieties had long thin stems, so they frequently broke, but were cheap to replace. It has been claimed that this fragility was somewhat intentional as it was utilized by Colonial American tavern keepers, for example, in renting the clay pipes to patrons. When the patron was done smoking the pipe and returned it to the keeper, the end of the stem was simply broken off so as to be ready for the next patron. However, there is no documentary evidence for this practice; it is known that communal pipes used in taverns were cleansed by being heated in an oven on special iron racks.

Forming the pipe involved making them in moulds with the bore created by pushing an oiled wire inside the stem. The preferred material was pipeclay or "tobacco pipe clay", which fires to a white colour and is found in only certain locations. In North America, many clay pipes were historically made from more typical terracotta-coloured clays. According to one British writer in 1869, the French preferred old pipes and the English new, the middle class preferred long stems and the working class preferred short. Short stemmed pipes, sometimes called "cuttys" or "nose warmers" in England, were preferred by those doing manual work as they could be gripped between the teeth, leaving both of the smoker's hands free.

Later low-quality clay pipes were made by slip casting in a mould. Higher quality pipes are made in a labour-intensive hand shaping process. Traditionally, clay pipes are un-glazed. Clays burn "hot" in comparison to other types of pipes, so they are often difficult for most pipe-smokers to use. Their proponents claim that, unlike other materials, a well-made clay pipe gives a "pure" smoke with no flavour addition from the pipe bowl. In addition to aficionados, reproductions of historical clay styles are used by some historical re-enactors. Clay pipes were once very popular in Ireland, where they were called
"dudeen"s.
Broken fragments of clay pipe can be useful as dating evidence for archaeologists. In the 1950s, the American archaeologist J. C. Harrington noted that the bore of pipe stems decreased over time, so a late sixteenth or early seventeenth centuries pipe would have a stem bore diameter of around , but a late eighteenth century pipe would have a bore diameter of around . The size of bowls also increased over time as tobacco became a cheaper commodity, and later pipes tend to be more decorated.

The specifically American style of pipes made from corncobs are cheap and effective, even if some regard them as inelegant. The cobs are first dried for two years. Then they are hollowed out to make a bowl shape. The bowls are dipped in a plaster-based mixture and varnished or lacquered on the outside. Shanks made from birch wood are then inserted into the bowls. The first and largest manufacturer of corncob pipes is Missouri Meerschaum, located in Washington, Missouri, in the United States. Missouri Meerschaum has produced the pipes since 1869. General Douglas MacArthur and Mark Twain were perhaps the most famous smokers of this type of pipe, along with the cartoon characters Popeye and Frosty the Snowman.

Corncob pipes remain popular today because they are inexpensive and require no "break-in" period like briar pipes. For these two reasons, corncob pipes are often recommended as a "beginner's pipe." However, corncob pipes are equally valued by both learners and experienced smokers who simply desire a cool, clean smoke. Pipesmokers who wish to sample a wide variety of different tobaccos and blends also might keep a stock of corncobs on hand to permit them to try new flavors without "carryover" from an already-used pipe, or to keep a potentially bad-tasting tobacco from adding its flavor to a more expensive or favored pipe.

Meerschaum (hydrated magnesium silicate), a mineral found in small shallow deposits mainly around the city of Eskişehir in central Turkey, is prized for the properties which allow it to be carved into finely detailed decorative and figural shapes. It has been used since the 17th century and, with clay pipes, represented the most common medium for pipes before the introduction of briar as the material of choice in the 19th century. The word "meerschaum" means "sea foam" in German, alluding to its natural white color and its surprisingly low weight. Meerschaum is a very porous mineral that absorbs elements of the tobacco during the smoking process, and gradually changes color to a golden brown. Old, well-smoked meerschaum pipes are valued by collectors for their distinctive coloring.

Meerschaum pipes can either be carved from a block of meerschaum, or made from meerschaum dust collected after carving and mixed with a binder then pressed into a pipe shape. The latter are far less absorbent, color in blotches, and lack the smoking quality of the block carved pipe.

A variety of other materials may also be used for pipes. The Redmanol corporation manufactured pipes with translucent stems in the 1920s and a series of pipes were manufactured and distributed by the Tar Gard (later Venturi) Corporation of San Francisco from 1965-1975. Marketed under names such as "the pipe," "THE SMOKE" and "Venturi," they used materials such as pyrolytic graphite, phenolic resin, nylon, Bakelite and other synthetics, allowing for higher temperatures in the bowl, reduced tar, and aesthetic variations of color and style.
After Venturi stopped making pipes, several companies continue to make pipes from Brylon, a composite of nylon and wood flour, as a cheaper substitute for briar.











Used to absorb moisture, tar and nicotine. Made of:

Filters can be single- or double-sided. Double-sided filter has both ends ceramic that can withstand hot smoke. Single-sided filter has ceramic end to the bowl and plastic end to the stem.

Smoking a pipe requires more apparatus and technique than cigarette or even cigar smoking. In addition to the pipe itself and matches or a pipe lighter, smokers usually require a pipe tool for packing, adjusting, and emptying the tobacco in the bowl, and a regular supply of pipe cleaners.

Tobaccos for smoking in pipes are often carefully treated and blended to achieve flavour nuances not available in other tobacco products. Many of these are blends using staple ingredients of variously cured Burley and Virginia tobaccos which are enhanced by spice tobaccos, among them many Oriental or Balkan varietals, Latakia (a fire-cured spice tobacco of Syrian origin, but now made in other regions, such as, Cyprus and Lebanon ), Perique (uniquely grown in St. James Parish, Louisiana) which is also an old method of fermentation, or blends of Virginia and Burley tobaccos of African, Indian, or South American origins. Traditionally, many U.S. blends are made of American Burley with sweeteners and flavorings added to create an "aromatic" flavor, whereas "English" blends are based on natural Virginia tobaccos enhanced with Oriental and other natural tobaccos. There is a growing tendency towards "natural" tobaccos which derive their aromas from artful blending with selected spice tobaccos only and careful, often historically-based, curing processes.

Pipe tobacco can be purchased in several forms, which vary both in flavour (leading to many blends and opportunities for smokers to blend their own tobaccos) and in the physical shape and size to which the tobacco has been reduced. Most pipe tobaccos are less mild than cigarette tobacco, substantially more moist and cut much more coarsely. Too finely cut tobacco does not allow enough air to flow through the pipe, and overly dry tobacco burns too quickly with little flavour. Pipe tobacco must be kept in an airtight container, such as a canning jar or sealed tin, to keep from drying out.

Some pipe tobaccos are cut into long narrow ribbons. Some are pressed into flat plugs which are sliced into flakes. Others are tightly wound into long ropes, then sliced into discs. Plug tobacco is maintained in its pressed block form and sold in small blocks. The plug will be sliced into thin flakes by the smoker and then prepared in a similar fashion to flake tobacco. It is considered that plug tobacco holds its flavor better than rubbed or flake tobacco. Flake tobacco (sliced cakes or ropes) may be prepared in several ways. Generally it is rubbed out with the fingers and palms until it is loose enough to pack. It can also be crumbled or simply folded and stuffed into a pipe. Some people also prefer to dice up very coarse tobaccos before using them, making them easier to pack.

In the most common method of packing, tobacco is added to the bowl of the pipe in several batches, each one pressed down until the mixture has a uniform density that optimizes airflow (something that it is difficult to gauge without practice). This can be done with a finger or thumb, but if the tobacco needs to be repacked later, while it is burning, the tamper on a pipe tool is sometimes used. If it needs to be loosened, the reamer, or any similar long pin can be used. A traditional way of packing the pipe is to fill the bowl and then pack gently to about full, fill again and pack slightly more firmly to about full, and then pack more firmly still to the top.

An alternative packing technique called the Frank method involves lightly dropping tobacco in the pipe, after which a large plug is gingerly pushed into the bowl all at once.

Matches, or separately lit slivers of wood are often considered preferable to lighters because of lower burning temperature. Butane lighters made specifically for pipes 
emit flame sideways or at an angle to make it easier to direct flame into the bowl. Torch-style lighters should never be used to light a pipe because their flames are too hot and can char the rim of the pipe bowl. Matches should be allowed to burn for several seconds to allow the sulfur from the tip to burn away and the match to produce a full flame. A naphtha fueled lighter should also be allowed to burn a few seconds to get rid of stray naphtha vapors that could give a foul taste to the smoke. When a flame has been produced, it is then moved in circles above the rim of the bowl while the smoker puffs to draw the flame down and light the tobacco. Packing method and humidity can affect how often a pipe must be relit.

With care, a briar pipe can last a very long time without burning out. However, due to aggressive (hot) smoking, imperfections in the wood, a hole can be burned in the tobacco chamber of the pipe. There are several methods used to help prevent a wood pipe from burning out. These generally involve coating the chamber with any of a variety of substances, or by gently smoking a new pipe to build up a cake (a mixture of ash, unburned tobacco, oils, sugars, and other residue) on the walls.

These coatings may include honey and water; powdered sugar and water; cigar ash and water; and sour cream, buttermilk, and activated charcoal among many others.

Many modern briar pipes are pre-treated by the manufacturer to resist burning. If smoked correctly, the cake will build up properly on its own. Another technique is to alternate a half-bowl and a full-bowl the first several times the pipe is used to build an even cake. Burley is often recommended to help a new pipe build cake.

The effectiveness of these methods is by no means universally agreed upon.

The caked layer that helps prevent burning through the bottom or sides of a briar wood pipe may damage other pipes, such as meerschaum or clay. As the cake layer heats up, it expands and may cause cracks or breaks in non-briar pipes.

Pipe smoke, like cigar smoke, is usually not inhaled. It is merely brought into the mouth, pumped around oral and nasal cavities to permit absorption of nicotine toward the brain through the mucous membranes, and released. It is normal to have to relight a pipe periodically. If it is smoked too slowly, this will happen more often. If it is smoked too quickly, it can produce excess moisture causing a gurgling sound in the pipe and an uncomfortable sensation on the tongue (referred to as "pipe tongue", or more commonly, "tongue bite").

A pipe cleaner can be used to dry out the bowl and, wetted with alcohol, the inner channel. The bowl of the pipe can also become uncomfortably hot, depending on the material and the rate of smoking. For this reason, clay pipes in particular are often held by the stem. Meerschaum pipes are held in a square of chamois leather, with gloves, or else by the stem in order to prevent uneven coloring of the material.
The ash and the last bits of unburned tobacco, known as dottle, should be cleaned out with a suitable pipe tool. A soft or bristle pipe cleaner, which may be moistened with strong spirits is then run through the airways of the stem and shank to remove any moisture, ash, and other residue before the pipe is allowed to dry. A pipe should be allowed to cool before removing the stem to avoid the possibility of warping it.

A cake of ash eventually develops inside the bowl. This is generally considered desirable for controlling overall heat. However, if it becomes too thick, it may expand faster than the bowl of the pipe itself when heated, cracking the bowl. Before reaching this point, it needs to be scraped down with a reamer. It is generally recommended to keep the cake at approximately the thickness of a U.S. dime (about 1/20th of an inch or 1.5 mm), though sometimes the cake is removed entirely as part of efforts to eliminate flavors or aromas.

Cake is considered undesirable in meerschaum pipes because it can easily crack the bowl and/or interfere with the mineral's natural porosity. Meerschaum also softens when heated so it is recommended to allow meerschaum pipes to cool before cleaning as people have been known to push pipe cleaners through the walls of heated pipes.

Regardless if a pipe is cleaned after every smoke, over time there is a buildup of cake in the bowl and tars in the internals of a smoking pipe. The cake can be controlled by gentle reaming, but a buildup of tars in the shank and airway of a pipe is more difficult to deal with. This may require the services of a professional pipe restorer to properly clean and sanitize the pipe.

When tobacco is burned, oils from adjoining not yet ignited particles vaporize and condense into the existing cake on the walls of the bowl and shank. Over time, these oils can oxidize and turn rancid, causing the pipe to give a sour or bitter smoke. A purported countermeasure involves filling the bowl with kosher salt and carefully wetting it with strong spirits. It is important to not use iodized salt, as the iodine and other additives may impart an unpleasant flavor. Regularly wiping out the bowl with spirits such as vodka or rum is helpful in preventing souring. Commercial pipe-sweetening products are also available.





</doc>
<doc id="27003" url="https://en.wikipedia.org/wiki?curid=27003" title="Swiss cheese (North America)">
Swiss cheese (North America)

Swiss cheese is the name for a variety of cheese that resembles Emmental cheese, a yellow, medium-hard cheese that originated in the area around Emmental, Switzerland. Some types of Swiss cheese have a distinctive appearance, as the blocks or rounds of the cheese are riddled with holes known as "eyes". Swiss cheese without eyes is known as "blind".

Swiss cheese is now manufactured in many countries, including the United States, Finland, Estonia, and Ireland. It is sometimes made with pasteurized or part-skim milk, unlike the original from Switzerland made with raw milk. The United States Department of Agriculture uses the terms Swiss cheese and Emmentaler cheese interchangeably. In Australia, both terms are used, along with Swiss-style cheese, in some cases differentiating the two. The term Swiss cheese is sometimes used in India, although it is also often referred to as Emmental, which is the more common name in Europe.

Three types of bacteria are used in the production of Swiss cheese: "Streptococcus salivarius" subspecies "thermophilus" (also known as "Streptococcus thermophilus"), "Lactobacillus" ("Lactobacillus helveticus" or "Lactobacillus delbrueckii" subspecies "bulgaricus"), and "Propionibacterium" ("Propionibacterium freudenreichii" subspecies "shermani"). In a late stage of cheese production, the propionibacteria consume the lactic acid excreted by the other bacteria and release acetate, propionic acid, and carbon dioxide gas. The carbon dioxide slowly forms the bubbles that develop the "eyes". The acetate and propionic acid give Swiss its nutty and sweet flavor. A hypothesis proposed by Swiss researchers in 2015 notes that particulate matter may also play a role in the holes' development and that modern sanitation eliminated debris such as hay dust in the milk played a role in reduced hole size in Swiss cheeses, or even "blind cheese". Historically, the holes were seen as a sign of imperfection and cheese makers originally tried to avoid them by pressing during production. In modern times, the holes have become an identifier of the cheese.

In general, the larger the eyes in a Swiss cheese, the more pronounced its flavor because a longer fermentation period gives the bacteria more time to act. This poses a problem, however, because cheese with large eyes does not slice well and comes apart in mechanical slicers. As a result, U.S. industry regulators have reduced the minimum eye size with which Swiss cheese can receive the Grade A stamp.

In 2014, 297.8 million pounds of Swiss cheese was reportedly produced in the United States.

Baby Swiss and Lacy Swiss are two varieties of American Swiss cheeses. Both have small holes and a mild flavor. Baby Swiss is made from whole milk, and Lacy Swiss is made from low fat milk. Baby Swiss was developed in the mid-1960s outside of Charm, Ohio, by the Guggisberg Cheese Company, owned by Alfred Guggisberg.



</doc>
<doc id="27004" url="https://en.wikipedia.org/wiki?curid=27004" title="Spontaneous combustion (disambiguation)">
Spontaneous combustion (disambiguation)

Spontaneous combustion is the self-ignition of a mass, for example, a pile of oily rags. Allegedly, humans can also ignite and burn without an obvious cause; this phenomenon is known as spontaneous human combustion.

Spontaneous Combustion is also the name of:


</doc>
<doc id="27005" url="https://en.wikipedia.org/wiki?curid=27005" title="Smoke signal">
Smoke signal

The smoke signal is one of the oldest forms of long-distance communication. It is a form of visual communication used over a long distance. In general smoke signals are used to transmit news, signal danger, or gather people to a common area.

In ancient China, soldiers stationed along the Great Wall would alert each other of impending enemy attack by signaling from tower to tower. In this way, they were able to transmit a message as far away as in just a few hours.

Misuse of the smoke signal is known to have contributed to the fall of the Western Zhou Dynasty in the 8th century BCE. King You of Zhou had a habit of fooling his warlords with false warning beacons in order to amuse Bao Si, his concubine.

Polybius, a Greek historian, devised a more complex system of alphabetical smoke signals around 150 BCE, which converted Greek alphabetic characters into numeric characters. It enabled messages to be easily signaled by holding sets of torches in pairs. This idea, known as the "Polybius square", also lends itself to cryptography and steganography. This cryptographic concept has been used with Japanese Hiragana and the Germans in the later years of the First World War.

North American indigenous peoples also communicated via smoke signal. Each tribe had its own signaling system and understanding. A signaler started a fire on an elevation typically using damp grass, which would cause a column of smoke to rise. The grass would be taken off as it dried and another bundle would be placed on the fire. Reputedly the location of the smoke along the incline conveyed a meaning. If it came from halfway up the hill, this would signify all was well, but from the top of the hill it would signify danger.

Smoke signals remain in use today. The College of Cardinals uses smoke signals to indicate the selection of a new Pope during a papal conclave. Eligible cardinals conduct a secret ballot until someone receives a vote of two-thirds plus one. The ballots are burned after each vote. Black smoke indicates a failed ballot, while white smoke means a new Pope has been elected.

Colored smoke grenades are commonly used by military forces to mark positions, especially during calls for artillery or air support.

Smoke signals may also refer to smoke-producing devices used to send distress signals.

Lewis and Clark's journals cite several occasions when they adopted the Native American method of setting the plains on fire to communicate the presence of their party or their desire to meet with local tribes.

Yámanas of South America used fire to send messages by smoke signals, for instance if a whale drifted ashore. The large amount of meat required notification of many people, so that it would not decay. They might also have used smoke signals on other occasions, thus it is possible that Magellan saw such fires (which inspired him to name the landscape Tierra del Fuego) but he may have seen the smoke or lights of natural phenomena.

The Cape Town Noon Gun, specifically the smoke its firing generates, was used to set marine chronometers in Table Bay.

Aboriginal Australians throughout Australia would send up smoke signals for various purposes. Sometimes to notify others of their presence, particularly when entering lands which were not their own. Sometimes used to describe visiting whites, smoke signals were the fastest way to send messages. Smoke signals were sometimes to notify of incursions by hostile tribes, or to arrange meetings between hunting parties of the same tribe. This signal could be from a fixed lookout on a ridge or from a mobile band of tribesman. "Putting up a smoke" would often result in nearby individuals or groups replying with their own signals. To carry information, the colour of the smoke was varied, sometimes black, white or blue depending on whether the material being burnt was wet grass, dry grass, reeds or other, and the shape of the smoke could be a column, ball or smoke ring. This message could include the names of individual tribesmen. Like other means of communication, signals could be misinterpreted. In one recorded instance, a smoke signal reply translated as "we are coming" was misinterpreted as joining a war party for protection of the tribe when it was actually hunting parties coming together after a successful hunt.

Modern aviation has made skywriting possible.



</doc>
<doc id="27006" url="https://en.wikipedia.org/wiki?curid=27006" title="Serendipity">
Serendipity

Serendipity is an unplanned fortunate discovery. Serendipity is a common occurrence throughout the history of product invention and scientific discovery. Serendipity is also seen as a potential design principle for online activities that would present a wide array of information and viewpoints, rather than just re-enforcing a user's opinion.

The first noted use of "serendipity" in the English language was by Horace Walpole on 28 January 1754. In a letter he wrote to his friend Horace Mann, Walpole explained an unexpected discovery he had made about a lost painting of Bianca Cappello by Giorgio Vasari by reference to a Persian fairy tale, "The Three Princes of Serendip". The princes, he told his correspondent, were "always making discoveries, by accidents and sagacity, of things which they were not in quest of." The name comes from "Serendip", an old name for Sri Lanka (Ceylon), hence "Sarandib" by Arab traders. It is derived from the Sanskrit "Siṃhaladvīpaḥ" (Siṃhalaḥ, Sri Lanka + dvīpaḥ, island).

The word has been exported into many other languages, with the general meaning of “unexpected discovery” or “fortunate chance”.

The term "serendipity" is often applied to inventions made by chance rather than intent. Andrew Smith, editor of "The" "Oxford Companion to American Food and Drink", has speculated that most everyday products had serendipitous roots, with many early ones related to animals. The origin of cheese, for example, possibly originated in the Nomad practice of storing milk in the stomach of a dead camel that was attached to the saddle of a live one, thereby mixing rennet from the stomach with the milk stored within.

Other examples of serendipity in inventions include:

Serendipity contributed to entomologist Shaun Winterton discovering "Semachrysa jade", a new species of lacewing, which he found not in its native Malaysia, but on the photo-sharing site Flickr. Winterton's discovery was aided by Flickr's ability to present images that are personalized to a user's interests, thereby increasing the odds he would chance upon the photo. Computer scientist Jaime Teevan has argued that serendipitous discovery is promoted by such personalization, writing that "people don’t know what to do with random new information. Instead, we want information that is at the fringe of what we already know, because that is when we have the cognitive structures to make sense of the new ideas."

Serendipity is a design principle for online activity that would present viewpoints that diverge from those participants already hold. Harvard Law professor Cass Sunstein argues that such an "architecture of serendipity" would promote a healthier democracy. Like a great city or university, "a well-functioning information market" provides exposure to new ideas, people, and ways of life, "Serendipity is crucial because it expands your horizons. You need that if you want to be free." The idea has potential application in the design of social media, information searches, and web browsing.

William Boyd coined the term zemblanity in the late twentieth century to mean somewhat the opposite of serendipity: "making unhappy, unlucky and expected discoveries occurring by design". A zemblanity is, effectively, an "unpleasant unsurprise". It derives from Novaya Zemlya (or Nova Zembla), a cold, barren land with many features opposite to the lush Sri Lanka (Serendip).

Bahramdipity is derived directly from Bahram Gur as characterized in "The Three Princes of Serendip". It describes the "suppression" of serendipitous discoveries or research results by powerful individuals.





</doc>
<doc id="27007" url="https://en.wikipedia.org/wiki?curid=27007" title="Samuel Morse">
Samuel Morse

Samuel Finley Breese Morse (April 27, 1791 – April 2, 1872) was an American inventor and painter. After having established his reputation as a portrait painter, in his middle age Morse contributed to the invention of a single-wire telegraph system based on European telegraphs. He was a co-developer of Morse code and helped to develop the commercial use of telegraphy.

Samuel F. B. Morse was born in Charlestown, Massachusetts, the first child of the pastor Jedidiah Morse (1761–1826), who was also a geographer, and his wife Elizabeth Ann Finley Breese (1766–1828). His father was a great preacher of the Calvinist faith and supporter of the American Federalist party. He thought it helped preserve Puritan traditions (strict observance of Sabbath, among other things), and believed in the Federalist support of an alliance with Britain and a strong central government. Morse strongly believed in education within a Federalist framework, alongside the instillation of Calvinist virtues, morals, and prayers for his first son. His first ancestor in America was Samuel Morse, who emigrated to Dedham, Massachusetts in 1635.

After attending Phillips Academy in Andover, Massachusetts, Samuel Morse went on to Yale College to receive instruction in the subjects of religious philosophy, mathematics, and science of horses. While at Yale, he attended lectures on electricity from Benjamin Silliman and Jeremiah Day and was a member of the Society of Brothers in Unity. He supported himself by painting. In 1810, he graduated from Yale with Phi Beta Kappa honors.

Morse married Lucretia Pickering Walker on September 29, 1818, in Concord, New Hampshire. She died on February 7, 1825, of a heart attack shortly after the birth of their third child. (Susan b. 1819, Charles b. 1823, James b. 1825). He married his second wife, Sarah Elizabeth Griswold on August 10, 1848, in Utica, New York and had four children (Samuel b. 1849, Cornelia b. 1851, William b. 1853, Edward b. 1857).

Morse expressed some of his Calvinist beliefs in his painting, "Landing of the Pilgrims", through the depiction of simple clothing as well as the people's austere facial features. His image captured the psychology of the Federalists; Calvinists from England brought to North America ideas of religion and government, thus linking the two countries. This work attracted the attention of the notable artist, Washington Allston. Allston wanted Morse to accompany him to England to meet the artist Benjamin West. Allston arranged—with Morse's father—a three-year stay for painting study in England. The two men set sail aboard the "Libya" on July 15, 1811.

In England, Morse perfected his painting techniques under Allston's watchful eye; by the end of 1811, he gained admittance to the Royal Academy. At the Academy, he was moved by the art of the Renaissance and paid close attention to the works of Michelangelo and Raphael. After observing and practicing life drawing and absorbing its anatomical demands, the young artist produced his masterpiece, the "Dying Hercules". (He first made a sculpture as a study for the painting.)

To some, the "Dying Hercules" seemed to represent a political statement against the British and also the American Federalists. The muscles symbolized the strength of the young and vibrant United States versus the British and British-American supporters. During Morse's time in Britain, the Americans and British were engaged in the War of 1812. Both societies were conflicted over loyalties. Anti-Federalist Americans aligned themselves with the French, abhorred the British, and believed a strong central government to be inherently dangerous to democracy.

As the war raged on, Morse's letters to his parents became more anti-Federalist in tone. In one such letter, Morse wrote:

I assert ... that the Federalists in the Northern States have done more injury to their country by their violent opposition measures than a French alliance could. Their proceedings are copied into the English papers, read before Parliament, and circulated through their country, and what do they say of them ... they call them [Federalists] cowards, a base set, say they are traitors to their country and ought to be hanged like traitors.

Although Jedidiah Morse did not change Samuel's political views, he continued as an influence. Critics believe that the elder Morse's Calvinist ideas are integral to Morse's "Judgment of Jupiter," another significant work completed in England. Jupiter is shown in a cloud, accompanied by his eagle, with his hand spread above the parties and he is pronouncing judgment. Marpessa, with an expression of compunction and shame, is throwing herself into the arms of her husband. Idas, who tenderly loved Marpessa, is eagerly rushing forward to receive her while Apollo stares with surprise.

Critics have suggested that Jupiter represents God's omnipotence—watching every move that is made. Some call the portrait a moral teaching by Morse on infidelity. Although Marpessa fell victim, she realized that her eternal salvation was important and desisted from her wicked ways. Apollo shows no remorse for what he did but stands with a puzzled look. Many American paintings throughout the early nineteenth century had religious themes, and Morse was an early exemplar of this. "Judgment of Jupiter" allowed Morse to express his support of Anti-Federalism while maintaining his strong spiritual convictions. Benjamin West sought to present the "Jupiter" at another Royal Academy exhibition, but Morse's time had run out. He left England on August 21, 1815, to return to the United States and begin his full-time career as a painter.

The decade 1815–1825 marked significant growth in Morse's work, as he sought to capture the essence of America's culture and life. He painted the Federalist former President John Adams (1816). The Federalists and Anti-Federalists clashed over Dartmouth College. Morse painted portraits of Francis Brown—the college's president—and Judge Woodward (1817), who was involved in bringing the Dartmouth case before the U.S. Supreme Court.

Morse also sought commissions among the elite of Charleston, South Carolina. Morse's 1818 painting of Mrs. Emma Quash symbolized the opulence of Charleston. The young artist was doing well for himself. Between 1819 and 1821, Morse went through great changes in his life, including a decline in commissions due to the Panic of 1819.

Morse was commissioned to paint President James Monroe in 1820. He embodied Jeffersonian democracy by favoring the common man over the aristocrat.

Morse had moved to New Haven. His commissions for "The House of Representatives" (1821) and a portrait of the Marquis de Lafayette (1825) engaged his sense of democratic nationalism. "The House of Representatives" was designed to capitalize on the success of François Marius Granet's "The Capuchin Chapel in Rome," which toured the United States extensively throughout the 1820s, attracting audiences willing to pay the 25-cent admission fee.

The artist chose to paint the House of Representatives, in a similar way, with careful attention to architecture and dramatic lighting. He also wished to select a uniquely American topic that would bring glory to the young nation. His subject did just that, showing American democracy in action. He traveled to Washington D.C. to draw the architecture of the new Capitol and placed eighty individuals within the painting. He chose to portray a night scene, balancing the architecture of the Rotunda with the figures, and using lamplight to highlight the work. Pairs of people, those who stood alone, individuals bent over their desks working, were each painted simply but with faces of character. Morse chose nighttime to convey that Congress' dedication to the principles of democracy transcended day.

"The House of Representatives" failed to draw a crowd when exhibited in New York City in 1823. By contrast, John Trumbull's "Declaration of Independence" had won popular acclaim a few years earlier. Viewers may have felt that the architecture of "The House of Representatives" overshadows the individuals, making it hard to appreciate the drama of what was happening.
Morse was honored to paint the Marquis de Lafayette, the leading French supporter of the American Revolution. He felt compelled to paint a grand portrait of the man who helped to establish a free and independent America. He features Lafayette against a magnificent sunset. He has positioned Lafayette to the right of three pedestals: one has a bust of Benjamin Franklin, another of George Washington, and the third seems reserved for Lafayette. A peaceful woodland landscape below him symbolized American tranquility and prosperity as it approached the age of fifty. The developing friendship between Morse and Lafayette and their discussions of the Revolutionary War affected the artist after his return to New York City.

In 1826, he helped found the National Academy of Design in New York City. He served as the Academy's president from 1826 to 1845 and again from 1861 to 1862.

From 1830 to 1832, Morse traveled and studied in Europe to improve his painting skills, visiting Italy, Switzerland, and France. During his time in Paris, he developed a friendship with the writer James Fennimore Cooper. As a project, he painted miniature copies of 38 of the Louvre's famous paintings on a single canvas (6 ft. x 9 ft), which he entitled "The Gallery of the Louvre." He completed the work upon his return to the United States.

On a subsequent visit to Paris in 1839, Morse met Louis Daguerre. He became interested in the latter's daguerreotype—the first practical means of photography. Morse wrote a letter to the "New York Observer" describing the invention, which was published widely in the American press and provided broad awareness of the new technology. Mathew Brady, one of the earliest photographers in American history, famous for his depictions of the Civil War, initially studied under Morse and later took photographs of him.

Some of Morse's paintings and sculptures are on display at his Locust Grove estate in Poughkeepsie, New York.

While returning by ship from Europe in 1832, Morse encountered Charles Thomas Jackson of Boston, a man who was well schooled in electromagnetism. Witnessing various experiments with Jackson's electromagnet, Morse developed the concept of a single-wire telegraph. He set aside his painting, "The Gallery of the Louvre". The original Morse telegraph, submitted with his patent application, is part of the collections of the National Museum of American History at the Smithsonian Institution. In time the Morse code, which he developed, would become the primary language of telegraphy in the world. It is still the standard for rhythmic transmission of data.

Meanwhile, William Cooke and Professor Charles Wheatstone had learned of the Wilhelm Weber and Carl Gauss electromagnetic telegraph in 1833. They had reached the stage of launching a commercial telegraph prior to Morse, despite starting later. In England, Cooke became fascinated by electrical telegraphy in 1836, four years after Morse. Aided by his greater financial resources, Cooke abandoned his primary subject of anatomy and built a small electrical telegraph within three weeks. Wheatstone also was experimenting with telegraphy and (most importantly) understood that a single large battery would not carry a telegraphic signal over long distances. He theorized that numerous small batteries were far more successful and efficient in this task. (Wheatstone was building on the primary research of Joseph Henry, an American physicist.) Cooke and Wheatstone formed a partnership and patented the electrical telegraph in May 1837, and within a short time had provided the Great Western Railway with a stretch of telegraph. However, within a few years, Cooke and Wheatstone's multiple-wire signaling method would be overtaken by Morse's cheaper method.

In an 1848 letter to a friend, Morse describes how vigorously he fought to be called the sole inventor of the electromagnetic telegraph despite the previous inventions.

Morse encountered the problem of getting a telegraphic signal to carry over more than a few hundred yards of wire. His breakthrough came from the insights of Professor Leonard Gale, who taught chemistry at New York University (he was a personal friend of Joseph Henry). With Gale's help, Morse introduced extra circuits or relays at frequent intervals and was soon able to send a message through of wire. This was the great breakthrough he had been seeking. Morse and Gale were soon joined by Alfred Vail, an enthusiastic young man with excellent skills, insights, and money.

At the Speedwell Ironworks in Morristown, New Jersey on January 11, 1838, Morse and Vail made the first public demonstration of the electric telegraph. Although Morse and Alfred Vail had done most of the research and development in the ironworks facilities, they chose a nearby factory house as the demonstration site. Without the repeater, the range of the telegraph was limited to , and the inventors had pulled of wires inside the factory house through an elaborate scheme. The first public transmission, with the message, "A patient waiter is no loser", was witnessed by a mostly local crowd.

Morse traveled to Washington, D.C. in 1838 seeking federal sponsorship for a telegraph line but was not successful. He went to Europe, seeking both sponsorship and patents, but in London discovered that Cooke and Wheatstone had already established priority. After his return to the US, Morse finally gained financial backing by Maine congressman Francis Ormand Jonathan Smith. This funding may be the first instance of government support to a private researcher, especially funding for applied (as opposed to basic or theoretical) research.

Morse made his last trip to Washington, D.C., in December 1842, stringing "wires between two committee rooms in the Capitol, and sent messages back and forth" to demonstrate his telegraph system. Congress appropriated $30,000 in 1843 for construction of an experimental telegraph line between Washington, D.C., and Baltimore along the right-of-way of the Baltimore and Ohio Railroad. An impressive demonstration occurred on May 1, 1844, when news of the Whig Party's nomination of Henry Clay for U.S. president was telegraphed from the party's convention in Baltimore to the Capitol Building in Washington.

On May 24, 1844, the line was officially opened as Morse sent the now-famous words, "What hath God wrought," from the Supreme Court chamber in the basement of the U.S. Capitol building in Washington, D.C., to the B&O's Mount Clare Station in Baltimore. Annie Ellsworth chose these words from the Bible (Numbers 23:23); her father, U.S. Patent Commissioner Henry Leavitt Ellsworth, had championed Morse's invention and secured early funding for it. His telegraph could transmit thirty characters per minute.

In May 1845, the Magnetic Telegraph Company was formed in order to build telegraph lines from New York City toward Philadelphia; Boston; Buffalo, New York; and the Mississippi. Telegraphic lines rapidly spread throughout the United States in the next few years, with 12,000 miles of wire laid by 1850.

Morse at one time adopted Wheatstone and Carl August von Steinheil's idea of broadcasting an electrical telegraph signal through a body of water or down steel railroad tracks or anything conductive. He went to great lengths to win a lawsuit for the right to be called "inventor of the telegraph" and promoted himself as being an inventor. But Alfred Vail also played an important role in the development of the Morse code, which was based on earlier codes for the electromagnetic telegraph.

Morse received a patent for the telegraph in 1847, at the old Beylerbeyi Palace (the present Beylerbeyi Palace was built in 1861–1865 on the same location) in Istanbul, which was issued by Sultan Abdülmecid, who personally tested the new invention. He was elected an Associate Fellow of the American Academy of Arts and Sciences in 1849. The original patent went to the Breese side of the family after the death of Samuel Morse.

In 1856, Morse went to Copenhagen and visited the Thorvaldsens Museum, where the sculptor's grave is in the inner courtyard. He was received by King Frederick VII, who decorated him with the Order of the Dannebrog for the telegraph. Morse expressed his wish to donate his Thorvaldsen portrait from 1831 in Rome to the king. The Thorvaldsen portrait today belongs to Margrethe II of Denmark.

The Morse telegraphic apparatus was officially adopted as the standard for European telegraphy in 1851. Only the United Kingdom (with its extensive overseas empire) kept the needle telegraph of Cooke and Wheatstone.

In 1858, Morse introduced wired communication to Latin America when he established a telegraph system in Puerto Rico, then a Spanish Colony. Morse's oldest daughter, Susan Walker Morse (1819–1885), would often visit her uncle Charles Pickering Walker, who owned the Hacienda Concordia in the town of Guayama. During one of her visits, she met Edward Lind, a Danish merchant who worked in his brother-in-law's Hacienda La Henriqueta in the town of Arroyo. They later married. Lind purchased the Hacienda from his sister when she became a widow. Morse, who often spent his winters at the Hacienda with his daughter and son-in-law, set a two-mile telegraph line connecting his son-in-law's Hacienda to their house in Arroyo. The line was inaugurated on March 1, 1859, in a ceremony flanked by the Spanish and American flags. The first words transmitted by Samuel Morse that day in Puerto Rico were:

Puerto Rico, beautiful jewel! When you are linked with the other jewels of the Antilles in the necklace of the world's telegraph, yours will not shine less brilliantly in the crown of your Queen!

There is an argument amongst historians that Morse may have received the idea of a plausible telegraph from Harrison Gray Dyar some eighteen years earlier than his patent.

Morse was a leader in the anti-Catholic and anti-immigration movement of the mid-19th century. In 1836, he ran unsuccessfully for mayor of New York under the anti-immigrant Nativist Party's banner, receiving only 1,496 votes. When Morse visited Rome, he allegedly refused to take his hat off in the presence of the Pope.

Morse worked to unite Protestants against Catholic institutions (including schools), wanted to forbid Catholics from holding public office, and promoted changing immigration laws to limit immigration from Catholic countries. On this topic, he wrote, "We must first stop the leak in the ship through which muddy waters from without threaten to sink us."

He wrote numerous letters to the New York "Observer" (his brother Sidney was the editor at the time) urging people to fight the perceived Catholic menace. These were widely reprinted in other newspapers. Among other claims, he believed that the Austrian government and Catholic aid organizations were subsidizing Catholic immigration to the United States in order to gain control of the country.

In his "Foreign Conspiracy Against the Liberties of the United States", Morse wrote:
Surely American Protestants, freemen, have discernment enough to discover beneath them the cloven foot of this subtle foreign heresy. They will see that Popery is now, what it has ever been, a system of the darkest political intrigue and despotism, cloaking itself to avoid attack under the sacred name of religion. They will be deeply impressed with the truth, that Popery is a political as well as a religious system; that in this respect it differs totally from all other sects, from all other forms of religion in the country.

In the same book, published in 1835 under the name of "Brutus", in speaking of "the foreign Emissaries of Popery re-warded in their own country," said : "Where is Bishop Kelly of Richmond, Va.? He also sojourns with us until his duties to foreign masters are performed, and then is rewarded by promotion." (Patrick Kelly was a native of Ireland, and the first bishop of Richmond, Virginia. When after a couple of years, differences regarding questions of jurisdiction arose between him and Ambrose Maréchal, Archbishop of Baltimore, Kelly was offered the recently vacant See of Waterford and Lismore in his homeland.)

In the 1850s, Morse became well known as a defender of slavery, considering it to be sanctioned by God. This was a position held by many Southerners and others. In his treatise "An Argument on the Ethical Position of Slavery," he wrote:

In the United States, Morse held his telegraph patent for many years, but it was both ignored and contested. In 1853, "The Telegraph Patent case – O'Reilly v. Morse" came before the U.S. Supreme Court where, after very lengthy investigation, Chief Justice Roger B. Taney ruled that Morse had been the first to combine the battery, electromagnetism, the electromagnet, and the correct battery configuration into a workable practical telegraph. However, in spite of this clear ruling, Morse still received no official recognition from the United States government.

The Supreme Court did not accept all of Morse's claims. The "O'Reilly v. Morse" case has become widely known among patent lawyers because the Supreme Court explicitly denied Morse's claim 8 for any and all use of the electromagnetic force for purposes of transmitting intelligible signals to any distance.
The Supreme Court sustained, however, Morse's claim to such telecommunication when effectuated by means of Morse's inventive "repeater" apparatus. This was an electrical circuit in which a cascade of many sets comprising a relay and a battery were connected in series, so that when each relay closed, it closed a circuit to cause the next battery to power the succeeding relay, as suggested in the accompanying figure. This caused Morse's signal to pass along the cascade without degrading into noise as its amplitude decreased with the distance traveled. (Each time the amplitude of the signal approaches the noise level, the repeater [in effect, a nonlinear amplifier] boosts the signal amplitude well above the noise level.) This use of "repeaters" permitted a message to be sent to great distances, which was previously not feasible.

The Supreme Court thus held that Morse could properly claim a patent monopoly on the system or process of transmitting signals at any distance by means of the repeater circuitry indicated above, but he could not properly claim a monopoly over any and all uses of electromagnetic force to transmit signals. The apparatus limitation in the former type of claim limited the patent monopoly to what Morse taught and gave the world. The lack of that limitation in the latter type of claim (i.e., claim 8) both gave Morse more than was commensurate with what he had contributed to society and discouraged the inventive efforts of others who might come up with different and/or better ways to send signals at a distance using the electromagnetic force.

The problem that Morse faced (the deterioration of the signal with distance) and how he solved it is discussed in more detail in the article "O'Reilly v. Morse". In summary, the solution, as the Supreme Court stated, was the repeater apparatus described in the preceding paragraphs.

The importance of this legal precedent in patent law cannot be overstated, as it became the foundation of the law governing the eligibility of computer program-implemented inventions (as well as inventions implementing natural laws) to be granted patents.

Assisted by the American ambassador in Paris, the governments of Europe were approached about their long neglect of Morse while their countries were using his invention. There was a widespread recognition that something must be done, and in 1858 Morse was awarded the sum of 400,000 French francs (equivalent to about $80,000 at the time) by the governments of France, Austria, Belgium, the Netherlands, Piedmont, Russia, Sweden, Tuscany, and Turkey, each of which contributed a share according to the number of Morse instruments in use in each country. In 1858, he was also elected a foreign member of the Royal Swedish Academy of Sciences.

Morse lent his support to Cyrus West Field's ambitious plan to construct the first transoceanic telegraph line. Morse had experimented with underwater telegraph circuits since 1842. He invested $10,000 in Field's Atlantic Telegraph Company, took a seat on its board of directors, and was appointed honorary "Electrician". In 1856, Morse traveled to London to help Charles Tilston Bright and Edward Whitehouse test a 2,000-mile-length of spooled cable.

After the first two cable-laying attempts failed, Field reorganized the project, removing Morse from direct involvement. Though the cable broke three times during the third attempt, it was successfully repaired, and the first transatlantic telegraph messages were sent in 1858. The cable failed after just three months of use. Though Field had to wait out the Civil War, the cable laid in 1866 proved more durable, and the era of reliable transatlantic telegraph service had begun.

In addition to the telegraph, Morse invented a marble-cutting machine that could carve three-dimensional sculptures in marble or stone. He could not patent it, however, because of an existing 1820 Thomas Blanchard design.

Samuel Morse gave large sums to charity. He also became interested in the relationship of science and religion and provided the funds to establish a lectureship on "the relation of the Bible to the Sciences". Though he was rarely awarded any royalties for the later uses and implementations of his inventions, he was able to live comfortably.

Morsemere in Ridgefield, New Jersey takes its name from Morse, who had bought property there to build a home, but died before its completion.

He died in New York City on April 2, 1872, and was interred at Green-Wood Cemetery in Brooklyn, New York. By the time of his death, his estate was valued at some $500,000 ($ today).

Morse was elected a member of the American Antiquarian Society in 1815.

Despite honors and financial awards received from foreign countries, there was no such recognition in the U.S. until he neared the end of his life when on June 10, 1871, a bronze statue of Samuel Morse was unveiled in Central Park, New York City. An engraved portrait of Morse appeared on the reverse side of the United States two-dollar bill silver certificate series of 1896. He was depicted along with Robert Fulton. An example can be seen on the website of the Federal Reserve Bank of San Francisco's website in their "American Currency Exhibit":

A blue plaque was erected to commemorate him at 141 Cleveland Street, London, where he lived from 1812 to 1815.

According to his "The New York Times" obituary published on April 3, 1872, Morse received respectively the decoration of the Atiq Nishan-i-Iftikhar (English: Order of Glory) [first medal on wearer's right depicted in photo of Morse with medals], set in diamonds, from Sultan Abdülmecid of Turkey (c.1847), a "golden snuff box containing the Prussian gold medal for scientific merit" from the King of Prussia (1851); the "Great Gold Medal of Arts and Sciences" from the King of Württemberg (1852); and the "Great Golden Medal of Science and Arts" from Emperor of Austria (1855); a cross of Chevalier in the Légion d'honneur from the Emperor of France; the "Cross of a Knight" of the Order of the Dannebrog from the King of Denmark (1856); the Cross of Knight Commander of the Order of Isabella the Catholic, from the Queen of Spain, besides being elected member of innumerable scientific and art societies in this [United States] and other countries. Other awards include Order of the Tower and Sword from the kingdom of Portugal (1860), and Italy conferred on him the insignia of chevalier of the Order of Saints Maurice and Lazarus in 1864. Morse's telegraph was recognized as an IEEE Milestone in 1988.

In 1975, Morse was inducted into the National Inventors Hall of Fame.

On April 1, 2012, Google announced the release of "Gmail Tap", an April Fools' Day joke that allowed users to use Morse Code to send text from their mobile phones. Morse's great-great-grandnephew Reed Morse—a Google engineer—was instrumental in the prank, which became a real product.




Attribution




</doc>
<doc id="27008" url="https://en.wikipedia.org/wiki?curid=27008" title="Ship">
Ship

A ship is a large watercraft that travels the world's oceans and other sufficiently deep waterways, carrying goods or passengers, or in support of specialized missions, such as defense, research, and fishing. Ships are generally distinguished from boats, based on size, shape, load capacity, and tradition. In the Age of Sail a "ship" was a sailing vessel defined by its sail plan of at least three square riged masts and a full bowsprit.

Ships have supported exploration, trade, warfare, migration, colonization, and science. After the 15th century, new crops that had come from and to the Americas via the European seafarers significantly contributed to the world population growth. Ship transport is responsible for the largest portion of world commerce.

As of 2016, there were more than 49,000 merchant ships, totaling almost 1.8 billion dead weight tons. Of these 28% were oil tankers, 43% were bulk carriers, and 13% were container ships.

Ships are generally larger than boats, but there is no universally accepted distinction between the two. Ships generally can remain at sea for longer periods of time than boats. A legal definition of ship from Indian case law is a vessel that carries goods by sea. A common notion is that a ship can carry a boat, but not "vice versa". A US Navy rule of thumb is that ships heel towards the "outside" of a sharp turn, whereas boats heel towards the "inside" because of the relative location of the center of mass versus the center of buoyancy. American and British 19th century maritime law distinguished "vessels" from other craft; ships and boats fall in one legal category, whereas open boats and rafts are not considered vessels.

In the Age of Sail, a full-rigged ship was a sailing vessel with at least three square-rigged masts and a full bowsprit; other types of vessel were also defined by their sailplan, e.g. barque, brigantine, etc.

A number of large vessels are usually referred to as boats. Submarines are a prime example. Other types of large vessel which are traditionally called boats are Great Lakes freighters, riverboats, and ferryboats. Though large enough to carry their own boats and heavy cargoes, these vessels are designed for operation on inland or protected coastal waters.

In most maritime traditions ships have individual names, and modern ships may belong to a ship class often named after its first ship.

In the northern parts of Europe and America a ship is traditionally referred to with a female grammatical gender, represented in English with the pronoun "she", even if named after a man. This is not universal usage and some English language journalistic style guides advise using "it" as referring to ships with female pronouns can be seen as offensive and outdated. In many documents the ship name is introduced with a ship prefix being an abbreviation of the ship class, for example "MS" (motor ship) or "SV" (sailing vessel), making it easier to distinguish a ship name from other individual names in a text.

The first sea-going sailing ships were developed by the Austronesian peoples from what is now Southern China and Taiwan. Their invention of catamarans, outriggers, and crab claw sails enabled their ships to sail for vast distances in open ocean. It led to the Austronesian Expansion at around 3000 to 1500 BC. From Taiwan, they rapidly colonized the islands of Maritime Southeast Asia, then sailed further onwards to Micronesia, Island Melanesia, Polynesia, and Madagascar, eventually colonizing a territory spanning half the globe.

Austronesian rigs were distinctive in that they had spars supporting both the upper and lower edges of the sails (and sometimes in between), in contrast to western rigs which only had a spar on the upper edge. The sails were also made from woven leaves, usually from pandan plants. These were complemented by paddlers, who usually positioned themselves on platforms on the outriggers in the larger boats. Austronesian ships ranged in complexity from simple dugout canoes with outriggers or lashed together to large edge-pegged plank-built boats built around a keel made from a dugout canoe. Their designs were unique, evolving from ancient rafts to the characteristic double-hulled, single-outrigger, and double-outrigger designs of Austronesian ships.

Early Austronesian sailors influenced the development of sailing technologies in Sri Lanka and Southern India through the Austronesian maritime trade network of the Indian Ocean, the precursor to the spice trade route and the maritime silk road, which was established at around 1500 BC. Some scholars believe that the triangular Austronesian crab claw sail may have influenced the development of the lateen sail in western ships due to early contact. The junk rigs of Chinese ships is also believed to be originally Javanese in origin.

In the 1st century AD, the people from Nusantara archipelago already made large ships over 50 m long and stood out 4–7 m out of the water. They could carry 700-1000 people and 260 ton cargo. These ships known as "kunlun bo" or "k'unlun po" (崑崙舶, lit. "ship of the Kunlun people") by the Chinese and "kolandiaphonta" by the Greeks. It has 4-7 masts and able to sail against the wind due to the usage of tanja sails. These ships reaching as far as Ghana.

In China, miniature models of ships that feature steering oars have been dated to the Warring States period (c. 475–221 BC). By the Han dynasty, a well kept naval fleet was an integral part of the military. Sternpost-mounted rudders started to appear on Chinese ship models starting in the 1st century AD. However, these early Chinese ships were fluvial (riverine), and were not seaworthy. The Chinese only acquired sea-going ship technologies in the 10th century AD Song Dynasty after contact with Southeast Asian djong trading ships, leading to the development of the junks.

In 3000 BC, Ancient Egyptians learned how to assemble wooden planks into a hull. They used woven straps to lash the planks together, and reeds or grass stuffed between the planks helped to seal the seams. The Greek historian and geographer Agatharchides had documented ship-faring among the early Egyptians: ""During the prosperous period of the Old Kingdom, between the 30th and 25th centuries BC, the river-routes were kept in order, and Egyptian ships sailed the Red Sea as far as the myrrh-country."" Sneferu's ancient cedar wood ship Praise of the Two Lands is the first reference recorded (2613 BC) to a ship being referred to by name.

The ancient Egyptians were perfectly at ease building sailboats. A remarkable example of their shipbuilding skills was the Khufu ship, a vessel in length entombed at the foot of the Great Pyramid of Giza around 2500 BC and found intact in 1954.

The oldest discovered sea faring hulled boat is the Late Bronze Age Uluburun shipwreck off the coast of Turkey, dating back to 1300 BC.

By 1200 B.C., the Phoenicians were building large merchant ships. In world maritime history, declares Richard Woodman, they are recognized as “the first true seafarers, founding the art of pilotage, cabotage, and navigation” and the architects of “the first true ship, built of planks, capable of carrying a deadweight cargo and being sailed and steered.” 

At this time, ships were developing in Asia in much the same way as Europe. Japan used defensive naval techniques in the Mongol invasions of Japan in 1281. It is likely that the Mongols of the time took advantage of both European and Asian shipbuilding techniques. During the 15th century, China's Ming dynasty assembled one of the largest and most powerful naval fleets in the world for the diplomatic and power projection voyages of Zheng He. Elsewhere in Japan in the 15th century, one of the world's first iron-clads, "Tekkōsen" (), literally meaning "iron ships", was also developed. In Japan, during the Sengoku era from the fifteenth to 17th century, the great struggle for feudal supremacy was fought, in part, by coastal fleets of several hundred boats, including the atakebune. In Korea, in the early 15th century during the Joseon era, "Geobukseon"(거북선), was developed. The "turtle ship", as it was called is recognized as the first armored ship in the world.

Until the Renaissance, navigational technology remained comparatively primitive compared to Austronesian cultures. This absence of technology did not prevent some civilizations from becoming sea powers. Examples include the maritime republics of Genoa and Venice, Hanseatic League, and the Byzantine navy. The Vikings used their knarrs to explore North America, trade in the Baltic Sea and plunder many of the coastal regions of Western Europe.

Towards the end of the 14th century, ships like the carrack began to develop towers on the bow and stern. These towers decreased the vessel's stability, and in the 15th century, the caravel, designed by the Portuguese, based on the Arabic "qarib" which could sail closer to the wind, became more widely used. The towers were gradually replaced by the forecastle and sterncastle, as in the carrack "Santa María" of Christopher Columbus. This increased freeboard allowed another innovation: the freeing port, and the artillery associated with it.

The carrack and then the caravel were developed in Portugal. After Columbus, European exploration rapidly accelerated, and many new trade routes were established. In 1498, by reaching India, Vasco da Gama proved that the access to the Indian Ocean from the Atlantic was possible. These explorations in the Atlantic and Indian Oceans were soon followed by France, England and the Netherlands, who explored the Portuguese and Spanish trade routes into the Pacific Ocean, reaching Australia in 1606 and New Zealand in 1642.

Parallel to the development of warships, ships in service of marine fishery and trade also developed in the period between antiquity and the Renaissance.

Maritime trade was driven by the development of shipping companies with significant financial resources. Canal barges, towed by draft animals on an adjacent towpath, contended with the railway up to and past the early days of the industrial revolution. Flat-bottomed and flexible scow boats also became widely used for transporting small cargoes. Mercantile trade went hand-in-hand with exploration, self-financed by the commercial benefits of exploration.

During the first half of the 18th century, the French Navy began to develop a new type of vessel known as a ship of the line, featuring seventy-four guns. This type of ship became the backbone of all European fighting fleets. These ships were long and their construction required 2,800 oak trees and of rope; they carried a crew of about 800 sailors and soldiers.

During the 19th century the Royal Navy enforced a ban on the slave trade, acted to suppress piracy, and continued to map the world. A clipper was a very fast sailing ship of the 19th century. The clipper routes fell into commercial disuse with the introduction of steam ships with better fuel efficiency, and the opening of the Suez and Panama Canals.

Ship designs stayed fairly unchanged until the late 19th century. The industrial revolution, new mechanical methods of propulsion, and the ability to construct ships from metal triggered an explosion in ship design. Factors including the quest for more efficient ships, the end of long running and wasteful maritime conflicts, and the increased financial capacity of industrial powers created an avalanche of more specialized boats and ships. Ships built for entirely new functions, such as firefighting, rescue, and research, also began to appear.

In 2019, the world's fleet included 51,684 commercial vessels with gross tonnage of more than 1,000 tons, totaling 1.96 billion tons. Such ships carried 11 billion tons of cargo in 2018, a sum that grew by 2.7% over the previous year. In terms of tonnage, 29% of ships were tankers, 43% are bulk carriers, 13% container ships and 15% were other types.

In 2002, there were 1,240 warships operating in the world, not counting small vessels such as patrol boats. The United States accounted for 3 million tons worth of these vessels, Russia 1.35 million tons, the United Kingdom 504,660 tons and China 402,830 tons. The 20th century saw many naval engagements during the two world wars, the Cold War, and the rise to power of naval forces of the two blocs. The world's major powers have recently used their naval power in cases such as the United Kingdom in the Falkland Islands and the United States in Iraq.

The size of the world's fishing fleet is more difficult to estimate. The largest of these are counted as commercial vessels, but the smallest are legion. Fishing vessels can be found in most seaside villages in the world. As of 2004, the United Nations Food and Agriculture Organization estimated 4 million fishing vessels were operating worldwide. The same study estimated that the world's 29 million fishermen caught of fish and shellfish that year.

Because ships are constructed using the principles of naval architecture that require same structural components, their classification is based on their function such as that suggested by Paulet and Presles, which requires modification of the components. The categories accepted in general by naval architects are:

Some of these are discussed in the following sections.

Freshwater shipping may occur on lakes, rivers and canals. Ships designed for those venues may be specially adapted to the widths and depths of specific waterways. Examples of freshwater waterways that are navigable in part by large vessels include the Danube, Mississippi, Rhine, Yangtze and Amazon Rivers, and the Great Lakes.

Lake freighters, also called lakers, are cargo vessels that ply the Great Lakes. The most well-known is , the latest major vessel to be wrecked on the Lakes. These vessels are traditionally called boats, not ships. Visiting ocean-going vessels are called "salties." Because of their additional beam, very large salties are never seen inland of the Saint Lawrence Seaway. Because the smallest of the Soo Locks is larger than any Seaway lock, salties that can pass through the Seaway may travel anywhere in the Great Lakes. Because of their deeper draft, salties may accept partial loads on the Great Lakes, "topping off" when they have exited the Seaway. Similarly, the largest lakers are confined to the Upper Lakes (Superior, Michigan, Huron, Erie) because they are too large to use the Seaway locks, beginning at the Welland Canal that bypasses the Niagara River.

Since the freshwater lakes are less corrosive to ships than the salt water of the oceans, lakers tend to last much longer than ocean freighters. Lakers older than 50 years are not unusual, and as of 2005, all were over 20 years of age.

, built in 1906 as "William P Snyder", was the oldest laker still working on the Lakes until its conversion into a barge starting in 2013. Similarly, "E.M. Ford", built in 1898 as "Presque Isle", was sailing the lakes 98 years later in 1996. As of 2007 "E.M. Ford" was still afloat as a stationary transfer vessel at a riverside cement silo in Saginaw, Michigan.

Merchant ships are ships used for commercial purposes and can be divided into four broad categories: fishing, cargo ships, passenger ships, and special-purpose ships. The UNCTAD review of maritime transport categorizes ships as: oil tankers, bulk (and combination) carriers, general cargo ships, container ships, and "other ships", which includes "liquefied petroleum gas carriers, liquefied natural gas carriers, parcel (chemical) tankers, specialized tankers, reefers, offshore supply, tugs, dredgers, cruise, ferries, other non-cargo". General cargo ships include "multi-purpose and project vessels and roll-on/roll-off cargo".

Modern commercial vessels are typically powered by a single propeller driven by a diesel or, less usually, gas turbine engine., but until the mid-19th century they were predominantly square sail rigged. The fastest vessels may use pump-jet engines. Most commercial vessels have full hull-forms to maximize cargo capacity. Hulls are usually made of steel, although aluminum can be used on faster craft, and fiberglass on the smallest service vessels. Commercial vessels generally have a crew headed by a sea captain, with deck officers and engine officers on larger vessels. Special-purpose vessels often have specialized crew if necessary, for example scientists aboard research vessels.

Fishing boats are generally small, often little more than but up to for a large tuna or whaling ship. Aboard a fish processing vessel, the catch can be made ready for market and sold more quickly once the ship makes port. Special purpose vessels have special gear. For example, trawlers have winches and arms, stern-trawlers have a rear ramp, and tuna seiners have skiffs. In 2004, of fish were caught in the marine capture fishery. Anchoveta represented the largest single catch at . That year, the top ten marine capture species also included Alaska pollock, Blue whiting, Skipjack tuna, Atlantic herring, Chub mackerel, Japanese anchovy, Chilean jack mackerel, Largehead hairtail, and Yellowfin tuna. Other species including salmon, shrimp, lobster, clams, squid and crab, are also commercially fished. Modern commercial fishermen use many methods. One is fishing by nets, such as purse seine, beach seine, lift nets, gillnets, or entangling nets. Another is trawling, including bottom trawl. Hooks and lines are used in methods like long-line fishing and hand-line fishing. Another method is the use of fishing trap.

Cargo ships transport dry and liquid cargo. Dry cargo can be transported in bulk by bulk carriers, packed directly onto a general cargo ship in break-bulk, packed in intermodal containers as aboard a container ship, or driven aboard as in roll-on roll-off ships. Liquid cargo is generally carried in bulk aboard tankers, such as oil tankers which may include both crude and finished products of oil, chemical tankers which may also carry vegetable oils other than chemicals and gas carriers, although smaller shipments may be carried on container ships in tank containers.

Passenger ships range in size from small river ferries to very large cruise ships. This type of vessel includes ferries, which move passengers and vehicles on short trips; ocean liners, which carry passengers from one place to another; and cruise ships, which carry passengers on voyages undertaken for pleasure, visiting several places and with leisure activities on board, often returning them to the port of embarkation. Riverboats and inland ferries are specially designed to carry passengers, cargo, or both in the challenging river environment. Rivers present special hazards to vessels. They usually have varying water flows that alternately lead to high speed water flows or protruding rock hazards. Changing siltation patterns may cause the sudden appearance of shoal waters, and often floating or sunken logs and trees (called snags) can endanger the hulls and propulsion of riverboats. Riverboats are generally of shallow draft, being broad of beam and rather square in plan, with a low freeboard and high topsides. Riverboats can survive with this type of configuration as they do not have to withstand the high winds or large waves that are seen on large lakes, seas, or oceans.

Fishing vessels are a subset of commercial vessels, but generally small in size and often subject to different regulations and classification. They can be categorized by several criteria: architecture, the type of fish they catch, the fishing method used, geographical origin, and technical features such as rigging. As of 2004, the world's fishing fleet consisted of some 4 million vessels. Of these, 1.3 million were decked vessels with enclosed areas and the rest were open vessels. Most decked vessels were mechanized, but two-thirds of the open vessels were traditional craft propelled by sails and oars. More than 60% of all existing large fishing vessels were built in Japan, Peru, the Russian Federation, Spain or the United States of America.

A weather ship was a ship stationed in the ocean as a platform for surface and upper air meteorological observations for use in marine weather forecasting. Surface weather observations were taken hourly, and four radiosonde releases occurred daily. It was also meant to aid in search and rescue operations and to support transatlantic flights. Proposed as early as 1927 by the aviation community, the establishment of weather ships proved to be so useful during World War II that the International Civil Aviation Organization (ICAO) established a global network of weather ships in 1948, with 13 to be supplied by the United States. This number was eventually negotiated down to nine.

The weather ship crews were normally at sea for three weeks at a time, returning to port for 10-day stretches. Weather ship observations proved to be helpful in wind and wave studies, as they did not avoid weather systems like other ships tended to for safety reasons. They were also helpful in monitoring storms at sea, such as tropical cyclones. The removal of a weather ship became a negative factor in forecasts leading up to the Great Storm of 1987. Beginning in the 1970s, their role became largely superseded by weather buoys due to the ships' significant cost. The agreement of the use of weather ships by the international community ended in 1990. The last weather ship was "Polarfront", known as weather station M ("Mike"), which was put out of operation on 1 January 2010. Weather observations from ships continue from a fleet of voluntary merchant vessels in routine commercial operation.

Naval vessels are those used by a navy for military purposes.
There have been many types of naval vessel. Modern naval vessels can be broken down into three categories: surface warships, submarines, and auxiliary ships.

Modern warships are generally divided into seven main categories: aircraft carriers, cruisers, destroyers, frigates, corvettes, submarines and amphibious assault ships. The distinction between cruisers, destroyers, frigates, and corvettes is not rigorous; the same vessel may be described differently in different navies. Battleships were used during the Second World War and occasionally since then (the last battleships were removed from the U.S. Naval Vessel Register in March 2006), but were made obsolete by the use of carrier-borne aircraft and guided missiles.

Most military submarines are either attack submarines or ballistic missile submarines. Until the end of World War II the primary role of the diesel/electric submarine was anti-ship warfare, inserting and removing covert agents and military forces, and intelligence-gathering. With the development of the homing torpedo, better sonar systems, and nuclear propulsion, submarines also became able to effectively hunt each other. The development of submarine-launched nuclear and cruise missiles gave submarines a substantial and long-ranged ability to attack both land and sea targets with a variety of weapons ranging from cluster munitions to nuclear weapons.

Most navies also include many types of support and auxiliary vessel, such as minesweepers, patrol boats, offshore patrol vessels, replenishment ships, and hospital ships which are designated medical treatment facilities.

Fast combat vessels such as cruisers and destroyers usually have fine hulls to maximize speed and maneuverability. They also usually have advanced marine electronics and communication systems, as well as weapons.

Some components exist in vessels of any size and purpose. Every vessel has a hull of sorts. Every vessel has some sort of propulsion, whether it's a pole, an ox, or a nuclear reactor. Most vessels have some sort of steering system. Other characteristics are common, but not as universal, such as compartments, holds, a superstructure, and equipment such as anchors and winches.

For a ship to float, its weight must be less than that of the water displaced by the ship's hull. There are many types of hulls, from logs lashed together to form a raft to the advanced hulls of America's Cup sailboats. A vessel may have a single hull (called a monohull design), two in the case of catamarans, or three in the case of trimarans. Vessels with more than three hulls are rare, but some experiments have been conducted with designs such as pentamarans. Multiple hulls are generally parallel to each other and connected by rigid arms.

Hulls have several elements. The bow is the foremost part of the hull. Many ships feature a bulbous bow. The keel is at the very bottom of the hull, extending the entire length of the ship. The rear part of the hull is known as the stern, and many hulls have a flat back known as a transom. Common hull appendages include propellers for propulsion, rudders for steering, and stabilizers to quell a ship's rolling motion. Other hull features can be related to the vessel's work, such as fishing gear and sonar domes.

Hulls are subject to various hydrostatic and hydrodynamic constraints. The key hydrostatic constraint is that it must be able to support the entire weight of the boat, and maintain stability even with often unevenly distributed weight. Hydrodynamic constraints include the ability to withstand shock waves, weather collisions and groundings.

Older ships and pleasure craft often have or had wooden hulls. Steel is used for most commercial vessels. Aluminium is frequently used for fast vessels, and composite materials are often found in sailboats and pleasure craft. Some ships have been made with concrete hulls.

Propulsion systems for ships fall into three categories: human propulsion, sailing, and mechanical propulsion. Human propulsion includes rowing, which was used even on large galleys. Propulsion by sail generally consists of a sail hoisted on an erect mast, supported by stays and spars and controlled by ropes. Sail systems were the dominant form of propulsion until the 19th century. They are now generally used for recreation and competition, although experimental sail systems, such as the turbosails, rotorsails, and wingsails have been used on larger modern vessels for fuel savings.

Mechanical propulsion systems generally consist of a motor or engine turning a propeller, or less frequently, an impeller or wave propulsion fins. Steam engines were first used for this purpose, but have mostly been replaced by two-stroke or four-stroke diesel engines, outboard motors, and gas turbine engines on faster ships. Nuclear reactors producing steam are used to propel warships and icebreakers, and there have been attempts to utilize them to power commercial vessels (see NS "Savannah").

In addition to traditional fixed and controllable pitch propellers there are many specialized variations, such as contra-rotating and nozzle-style propellers. Most vessels have a single propeller, but some large vessels may have up to four propellers supplemented with transverse thrusters for maneuvring at ports. The propeller is connected to the main engine via a propeller shaft and, in case of medium- and high-speed engines, a reduction gearbox. Some modern vessels have a diesel-electric powertrain in which the propeller is turned by an electric motor powered by the ship's generators.

For ships with independent propulsion systems for each side, such as manual oars or some paddles, steering systems may not be necessary. In most designs, such as boats propelled by engines or sails, a steering system becomes necessary. The most common is a rudder, a submerged plane located at the rear of the hull. Rudders are rotated to generate a lateral force which turns the boat. Rudders can be rotated by a tiller, manual wheels, or electro-hydraulic systems. Autopilot systems combine mechanical rudders with navigation systems. Ducted propellers are sometimes used for steering.

Some propulsion systems are inherently steering systems. Examples include the outboard motor, the bow thruster, and the Z-drive.

Larger boats and ships generally have multiple decks and compartments. Separate berthings and heads are found on sailboats over about . Fishing boats and cargo ships typically have one or more cargo holds. Most larger vessels have an engine room, a galley, and various compartments for work. Tanks are used to store fuel, engine oil, and fresh water. Ballast tanks are equipped to change a ship's trim and modify its stability.

Superstructures are found above the main deck. On sailboats, these are usually very low. On modern cargo ships, they are almost always located near the ship's stern. On passenger ships and warships, the superstructure generally extends far forward.

Shipboard equipment varies from ship to ship depending on such factors as the ship's era, design, area of operation, and purpose. Some types of equipment that are widely found include:

Ships float in the water at a level where mass of the displaced water equals the mass of the vessel, such that the downwards force of gravity equals the upward force of buoyancy. As a vessel is lowered into the water its weight remains constant but the corresponding weight of water displaced by its hull increases. If the vessel's mass is evenly distributed throughout, it floats evenly along its length and across its beam (width). A vessel's stability is considered in both this hydrostatic sense as well as a hydrodynamic sense, when subjected to movement, rolling and pitching, and the action of waves and wind. Stability problems can lead to excessive pitching and rolling, and eventually capsizing and sinking.

The advance of a vessel through water is resisted by the water. This resistance can be broken down into several components, the main ones being the friction of the water on the hull and wave making resistance. To reduce resistance and therefore increase the speed for a given power, it is necessary to reduce the wetted surface and use submerged hull shapes that produce low amplitude waves. To do so, high-speed vessels are often more slender, with fewer or smaller appendages. The friction of the water is also reduced by regular maintenance of the hull to remove the sea creatures and algae that accumulate there. Antifouling paint is commonly used to assist in this. Advanced designs such as the bulbous bow assist in decreasing wave resistance.

A simple way of considering wave-making resistance is to look at the hull in relation to its wake. At speeds lower than the wave propagation speed, the wave rapidly dissipates to the sides. As the hull approaches the wave propagation speed, however, the wake at the bow begins to build up faster than it can dissipate, and so it grows in amplitude. Since the water is not able to "get out of the way of the hull fast enough", the hull, in essence, has to climb over or push through the bow wave. This results in an exponential increase in resistance with increasing speed.

This hull speed is found by the formula:

or, in metric units:

where "L" is the length of the waterline in feet or meters.

When the vessel exceeds a speed/length ratio of 0.94, it starts to outrun most of its bow wave, and the hull actually settles slightly in the water as it is now only supported by two wave peaks. As the vessel exceeds a speed/length ratio of 1.34, the hull speed, the wavelength is now longer than the hull, and the stern is no longer supported by the wake, causing the stern to squat, and the bow rise. The hull is now starting to climb its own bow wave, and resistance begins to increase at a very high rate. While it is possible to drive a displacement hull faster than a speed/length ratio of 1.34, it is prohibitively expensive to do so. Most large vessels operate at speed/length ratios well below that level, at speed/length ratios of under 1.0.

For large projects with adequate funding, hydrodynamic resistance can be tested experimentally in a hull testing pool or using tools of computational fluid dynamics.

Vessels are also subject to ocean surface waves and sea swell as well as effects of wind and weather. These movements can be stressful for passengers and equipment, and must be controlled if possible. The rolling movement can be controlled, to an extent, by ballasting or by devices such as fin stabilizers. Pitching movement is more difficult to limit and can be dangerous if the bow submerges in the waves, a phenomenon called pounding. Sometimes, ships must change course or speed to stop violent rolling or pitching.

How it has been convincingly shown in scientific studies of the 21st century, controllability of some vessels decreases dramatically in some cases that are conditioned by effects of the bifurcation memory. This class of vessels includes ships with high manoeuvring capabilities, aircraft and controlled underwater vehicles designed to be unstable in steady-state motion that are interesting in terms of applications. These features must be considered in designing ships and in their control in critical situations.

A ship will pass through several stages during its career. The first is usually an initial contract to build the ship, the details of which can vary widely based on relationships between the shipowners, operators, designers and the shipyard. Then, the design phase carried out by a naval architect. Then the ship is constructed in a shipyard. After construction, the vessel is launched and goes into service. Ships end their careers in a number of ways, ranging from shipwrecks to service as a museum ship to the scrapyard.

A vessel's design starts with a specification, which a naval architect uses to create a project outline, assess required dimensions, and create a basic layout of spaces and a rough displacement. After this initial rough draft, the architect can create an initial hull design, a general profile and an initial overview of the ship's propulsion. At this stage, the designer can iterate on the ship's design, adding detail and refining the design at each stage.

The designer will typically produce an overall plan, a general specification describing the peculiarities of the vessel, and construction blueprints to be used at the building site. Designs for larger or more complex vessels may also include sail plans, electrical schematics, and plumbing and ventilation plans.

As environmental laws are becoming more strict, ship designers need to create their design in such a way that the ship, when it nears its end-of-term, can be disassembled or disposed easily and that waste is reduced to a minimum.

Ship construction takes place in a shipyard, and can last from a few months for a unit produced in series, to several years to reconstruct a wooden boat like the frigate "Hermione", to more than 10 years for an aircraft carrier. During World War II, the need for cargo ships was so urgent that construction time for Liberty Ships went from initially eight months or longer, down to weeks or even days. Builders employed production line and prefabrication techniques such as those used in shipyards today.

Hull materials and vessel size play a large part in determining the method of construction. The hull of a mass-produced fiberglass sailboat is constructed from a mold, while the steel hull of a cargo ship is made from large sections welded together as they are built.

Generally, construction starts with the hull, and on vessels over about , by the laying of the keel. This is done in a drydock or on land. Once the hull is assembled and painted, it is launched. The last stages, such as raising the superstructure and adding equipment and accommodation, can be done after the vessel is afloat.

Once completed, the vessel is delivered to the customer. Ship launching is often a ceremony of some significance, and is usually when the vessel is formally named. A typical small rowboat can cost under US$100, $1,000 for a small speedboat, tens of thousands of dollars for a cruising sailboat, and about $2,000,000 for a Vendée Globe class sailboat. A trawler may cost $2.5 million, and a 1,000-person-capacity high-speed passenger ferry can cost in the neighborhood of $50 million. A ship's cost partly depends on its complexity: a small, general cargo ship will cost $20 million, a Panamax-sized bulk carrier around $35 million, a supertanker around $105 million and a large LNG carrier nearly $200 million. The most expensive ships generally are so because of the cost of embedded electronics: a costs around $2 billion, and an aircraft carrier goes for about $3.5 billion.

Ships undergo nearly constant maintenance during their career, whether they be underway, pierside, or in some cases, in periods of reduced operating status between charters or shipping seasons.

Most ships, however, require trips to special facilities such as a drydock at regular intervals. Tasks often done at drydock include removing biological growths on the hull, sandblasting and repainting the hull, and replacing sacrificial anodes used to protect submerged equipment from corrosion. Major repairs to the propulsion and steering systems as well as major electrical systems are also often performed at dry dock.

Some vessels that sustain major damage at sea may be repaired at a facility equipped for major repairs, such as a shipyard. Ships may also be converted for a new purpose: oil tankers are often converted into floating production storage and offloading units.

Most ocean-going cargo ships have a life expectancy of between 20 and 30 years. A sailboat made of plywood or fiberglass can last between 30 and 40 years. Solid wooden ships can last much longer but require regular maintenance. Carefully maintained steel-hulled yachts can have a lifespan of over 100 years.

As ships age, forces such as corrosion, osmosis, and rotting compromise hull strength, and a vessel becomes too dangerous to sail. At this point, it can be scuttled at sea or scrapped by shipbreakers. Ships can also be used as museum ships, or expended to construct breakwaters or artificial reefs.

Many ships do not make it to the scrapyard, and are lost in fires, collisions, grounding, or sinking at sea. The Allies lost some 5,150 ships during World War II.

One can measure ships in terms of overall length, length between perpendiculars, length of the ship at the waterline, beam (breadth), depth (distance between the crown of the weather deck and the top of the keelson), draft (distance between the highest waterline and the bottom of the ship) and tonnage. A number of different tonnage definitions exist and are used when describing merchant ships for the purpose of tolls, taxation, etc.

In Britain until Samuel Plimsoll's Merchant Shipping Act of 1876, ship-owners could load their vessels until their decks were almost awash, resulting in a dangerously unstable condition. Anyone who signed on to such a ship for a voyage and, upon realizing the danger, chose to leave the ship, could end up in jail. Plimsoll, a Member of Parliament, realised the problem and engaged some engineers to derive a fairly simple formula to determine the position of a line on the side of any specific ship's hull which, when it reached the surface of the water during loading of cargo, meant the ship had reached its maximum safe loading level. To this day, that mark, called the "Plimsoll Line", exists on ships' sides, and consists of a circle with a horizontal line through the centre. On the Great Lakes of North America the circle is replaced with a diamond. Because different types of water (summer, fresh, tropical fresh, winter north Atlantic) have different densities, subsequent regulations required painting a group of lines forward of the Plimsoll mark to indicate the safe depth (or freeboard above the surface) to which a specific ship could load in water of various densities. Hence the "ladder" of lines seen forward of the Plimsoll mark to this day. This is called the "freeboard mark" or "load line mark" in the marine industry.

Ship pollution is the pollution of air and water by shipping. It is a problem that has been accelerating as trade has become increasingly globalized, posing an increasing threat to the world's oceans and waterways as globalization continues. It is expected that "shipping traffic to and from the United States is projected to double by 2020." Because of increased traffic in ocean ports, pollution from ships also directly affects coastal areas. The pollution produced affects biodiversity, climate, food, and human health. However, the degree to which humans are polluting and how it affects the world is highly debated and has been a hot international topic for the past 30 years.

Oil spills have devastating effects on the environment. Crude oil contains polycyclic aromatic hydrocarbons (PAHs) which are very difficult to clean up, and last for years in the sediment and marine environment. Marine species constantly exposed to PAHs can exhibit developmental problems, susceptibility to disease, and abnormal reproductive cycles.

By the sheer amount of oil carried, modern oil tankers must be considered something of a threat to the environment. An oil tanker can carry of crude oil, or . This is more than six times the amount spilled in the widely known "Exxon Valdez" incident. In this spill, the ship ran aground and dumped of oil into the ocean in March 1989. Despite efforts of scientists, managers, and volunteers, over 400,000 seabirds, about 1,000 sea otters, and immense numbers of fish were killed.

The International Tanker Owners Pollution Federation has researched 9,351 accidental spills since 1974. According to this study, most spills result from routine operations such as loading cargo, discharging cargo, and taking on fuel oil. 91% of the operational oil spills were small, resulting in less than 7 tons per spill. Spills resulting from accidents like collisions, groundings, hull failures, and explosions are much larger, with 84% of these involving losses of over 700 tons.

Following the "Exxon Valdez" spill, the United States passed the Oil Pollution Act of 1990 (OPA-90), which included a stipulation that all tankers entering its waters be double-hulled by 2015. Following the sinkings of "Erika" (1999) and "Prestige" (2002), the European Union passed its own stringent anti-pollution packages (known as Erika I, II, and III), which require all tankers entering its waters to be double-hulled by 2010. The Erika packages are controversial because they introduced the new legal concept of "serious negligence".

When a large vessel such as a container ship or an oil tanker unloads cargo, seawater is pumped into other compartments in the hull to help stabilize and balance the ship. During loading, this ballast water is pumped out from these compartments.

One of the problems with ballast water transfer is the transport of harmful organisms. Meinesz believes that one of the worst cases of a single invasive species causing harm to an ecosystem can be attributed to a seemingly harmless jellyfish. "Mnemiopsis leidyi", a species of comb jellyfish that inhabits estuaries from the United States to the Valdés peninsula in Argentina along the Atlantic coast, has caused notable damage in the Black Sea. It was first introduced in 1982, and thought to have been transported to the Black Sea in a ship's ballast water. The population of the jellyfish shot up exponentially and, by 1988, it was wreaking havoc upon the local fishing industry. "The anchovy catch fell from in 1984 to in 1993; sprat from in 1984 to in 1993; horse mackerel from in 1984 to zero in 1993." Now that the jellyfish have exhausted the zooplankton, including fish larvae, their numbers have fallen dramatically, yet they continue to maintain a stranglehold on the ecosystem. Recently the jellyfish have been discovered in the Caspian Sea. Invasive species can take over once occupied areas, facilitate the spread of new diseases, introduce new genetic material, alter landscapes and jeopardize the ability of native species to obtain food. "On land and in the sea, invasive species are responsible for about 137 billion dollars in lost revenue and management costs in the U.S. each year."

Ballast and bilge discharge from ships can also spread human pathogens and other harmful diseases and toxins potentially causing health issues for humans and marine life alike. Discharges into coastal waters, along with other sources of marine pollution, have the potential to be toxic to marine plants, animals, and microorganisms, causing alterations such as changes in growth, disruption of hormone cycles, birth defects, suppression of the immune system, and disorders resulting in cancer, tumors, and genetic abnormalities or even death.

Exhaust emissions from ships are considered to be a significant source of air pollution. "Seagoing vessels are responsible for an estimated 14 percent of emissions of nitrogen from fossil fuels and 16 percent of the emissions of sulfur from petroleum uses into the atmosphere." In Europe ships make up a large percentage of the sulfur introduced to the air, "as much sulfur as all the cars, lorries and factories in Europe put together". "By 2010, up to 40% of air pollution over land could come from ships." Sulfur in the air creates acid rain which damages crops and buildings. When inhaled, sulfur is known to cause respiratory problems and increase the risk of a heart attack.

Ship breaking or ship demolition is a type of ship disposal involving the breaking up of ships for scrap recycling, with the hulls being discarded in ship graveyards. Most ships have a lifespan of a few decades before there is so much wear that refitting and repair becomes uneconomical. Ship breaking allows materials from the ship, especially steel, to be reused.
In addition to steel and other useful materials, however, ships (particularly older vessels) can contain many substances that are banned or considered dangerous in developed countries. Asbestos and polychlorinated biphenyls (PCBs) are typical examples. Asbestos was used heavily in ship construction until it was finally banned in most of the developed world in the mid 1980s. Currently, the costs associated with removing asbestos, along with the potentially expensive insurance and health risks, have meant that ship-breaking in most developed countries is no longer economically viable. Removing the metal for scrap can potentially cost more than the scrap value of the metal itself. In most of the developing world, however, shipyards can operate without the risk of personal injury lawsuits or workers' health claims, meaning many of these shipyards may operate with high health risks. Furthermore, workers are paid very low rates with no overtime or other allowances. Protective equipment is sometimes absent or inadequate. Dangerous vapors and fumes from burning materials can be inhaled, and dusty asbestos-laden areas around such breakdown locations are commonplace.

Aside from the health of the yard workers, in recent years, ship breaking has also become an issue of major environmental concern. Many developing nations, in which ship breaking yards are located, have lax or no environmental law, enabling large quantities of highly toxic materials to escape into the environment and causing serious health problems among ship breakers, the local population and wildlife. Environmental campaign groups such as Greenpeace have made the issue a high priority for their campaigns.

<br>

Model ships

Lists

Ship sizes



</doc>
<doc id="27009" url="https://en.wikipedia.org/wiki?curid=27009" title="Soap opera">
Soap opera

A soap opera is a radio or television serial dealing especially with domestic situations and frequently characterized by melodrama, ensemble casts and sentimentality. The term "soap opera" originated from radio dramas originally being sponsored by soap manufacturers. 

BBC Radio's "The Archers", first broadcast in 1950, is the world's longest-running radio soap opera. The world's longest-running television soap opera is "Coronation Street", which was first broadcast on ITV in 1960.

A crucial element that defines the soap opera is the open-ended serial nature of the narrative, with stories spanning several episodes. One of the defining features that makes a television program a soap opera, according to Albert Moran, is "that form of television that works with a continuous open narrative. Each episode ends with a promise that the storyline is to be continued in another episode". In 2012, "Los Angeles Times" columnist Robert Lloyd wrote of daily dramas: 

Soap opera storylines run concurrently, intersect and lead into further developments. An individual episode of a soap opera will generally switch between several concurrent narrative threads that may at times interconnect and affect one another or may run entirely independent to each other. Episodes may feature some of the show's current storylines, but not always all of them. Especially in daytime serials and those that are broadcast each weekday, there is some rotation of both storyline and actors so any given storyline or actor will appear in some but usually not all of a week's worth of episodes. Soap operas rarely bring all the current storylines to a conclusion at the same time. When one storyline ends, there are several other story threads at differing stages of development. Soap opera episodes typically end on some sort of cliffhanger, and the season finale (if a soap incorporates a break between seasons) ends in the same way, only to be resolved when the show returns for the start of a new yearly broadcast.

Evening soap operas and those that air at a rate of one episode per week are more likely to feature the entire cast in each episode, and to represent all current storylines in each episode. Evening soap operas and serials that run for only part of the year tend to bring things to a dramatic end-of-season cliffhanger.

In 1976, "Time" magazine described American daytime television as "TV's richest market", noting the loyalty of the soap opera fan base and the expansion of several half-hour series into hour-long broadcasts in order to maximize ad revenues. The article explained that at that time, many prime time series lost money, while daytime serials earned profits several times more than their production costs. The issue's cover notably featured its first daytime soap stars, Bill Hayes and Susan Seaforth Hayes of "Days of Our Lives", a married couple whose onscreen and real-life romance was widely covered by both the soap opera magazines and the mainstream press at large.

The first serial considered to be a "soap opera" was "Painted Dreams", which debuted on October 20, 1930 on Chicago radio station WGN. Early radio series such as "Painted Dreams" were broadcast in weekday daytime slots, usually five days a week. Most of the listeners would be housewives, thus, the shows were aimed at, and consumed by, a predominantly female audience. The first nationally broadcast radio soap opera was "Clara, Lu, and Em", which aired on the NBC Blue Network at 10:30 p.m. Eastern Time on January 27, 1931.

The main characteristics that define soap operas are "an emphasis on family life, personal relationships, sexual dramas, emotional and moral conflicts; some coverage of topical issues; set in familiar domestic interiors with only occasional excursions into new locations". Fitting in with these characteristics, most soap operas follow the lives of a group of characters who live or work in a particular place, or focus on a large extended family. The storylines follow the day-to-day activities and personal relationships of these characters. "Soap narratives, like those of film melodramas, are marked by what Steve Neale has described as 'chance happenings, coincidences, missed meetings, sudden conversions, last-minute rescues and revelations, deus ex machina endings.'" These elements may be found across the gamut of soap operas, from "EastEnders" to "Dallas".

In many soap operas, in particular daytime serials in the US, the characters are frequently attractive, seductive, glamorous and wealthy. Soap operas from the United Kingdom and Australia tend to focus on more everyday characters and situations, and are frequently set in working-class environments. Many of the soaps produced in those two countries explore social realist storylines such as family discord, marriage breakdown or financial problems. Both UK and Australian soap operas feature comedic elements, often affectionate comic stereotypes such as the gossip or the grumpy old man, presented as a comic foil to the emotional turmoil that surrounds them. This diverges from US soap operas where such comedy is rare. UK soap operas frequently make a claim to presenting "reality" or purport to have a "realistic" style. UK soap operas also frequently foreground their geographic location as a key defining feature of the show while depicting and capitalising on the exotic appeal of the stereotypes connected to the location. As examples, "EastEnders" focuses on the tough and grim life in the East End of London; "Coronation Street" and its characters exhibit the stereotypical characteristic of "northern straight talking".

Romance, secret relationships, extramarital affairs, and genuine hate have been the basis for many soap opera storylines. In US daytime serials, the most popular soap opera characters, and the most popular storylines, often involved a romance of the sort presented in paperback romance novels. Soap opera storylines weave intricate, convoluted and sometimes confusing tales of characters who have affairs, meet mysterious strangers and fall in love, and who commit adultery, all of which keeps audiences hooked on the unfolding story. Crimes such as kidnapping, rape, and even murder may go unpunished if the perpetrator is to be retained in the ongoing story.

Australian and UK soap operas also feature a significant proportion of romance storylines. In Russia, most popular serials explore the "romantic quality" of criminal and/or oligarch life.

In soap opera storylines, previously unknown children, siblings and twins (including the evil variety) of established characters often emerge to upset and reinvigorate the set of relationships examined by the series. Unexpected calamities disrupt weddings, childbirths, and other major life events with unusual frequency.

As in comic books – another popular form of linear storytelling pioneered in the US during the 20th century – a character's death is not guaranteed to be permanent. On "The Bold and the Beautiful", Taylor Forrester (Hunter Tylo) was shown to flatline and have a funeral. Once Tylo reprised her character in 2005, a retcon explained that Taylor had actually gone into a coma.

Stunts and complex physical action are largely absent, especially from daytime serials. Such story events often take place off-screen and are referred to in dialogue instead of being shown. This is because stunts or action scenes are difficult to adequately depict without complex movements, multiple takes, and post-production editing. When episodes were broadcast live, post-production work was impossible. Though all serials have long switched to being taped, extensive post-production work and multiple takes, while possible, are not feasible due to the tight taping schedules and low budgets.

The first daytime TV soap opera in the United States was "These Are My Children" in 1949, though earlier melodramas had aired in the evenings as once-a-week programs. Soap operas quickly became a fixture of American daytime television in the early 1950s, joined by game shows, sitcom reruns and talk shows.

In 1988, H. Wesley Kenney, who at the time served as the executive producer of "General Hospital", said to "The New York Times":
Many long-running US soap operas established particular environments for their stories. "The Doctors" and "General Hospital", in the beginning, told stories almost exclusively from inside the confines of a hospital. "As the World Turns" dealt heavily with Chris Hughes' law practice and the travails of his wife Nancy who, tired of being "the loyal housewife" in the 1970s, became one of the first older women on the American serials to enter the workforce. "Guiding Light" dealt with Bert Bauer (Charita Bauer) and her alcoholic husband Bill, and their endless marital troubles. When Bert's status shifted to caring mother and town matriarch, her children's marital troubles were showcased. "Search for Tomorrow" mostly told its story through the eyes of Joanne Gardner (Mary Stuart). Even when stories revolved around other characters, Joanne was frequently a key player in their storylines. "Days of Our Lives" initially focused on Dr. Tom Horton and his steadfast wife Alice. The show later branched out to focus more on their five children. "The Edge of Night" featured as its central character Mike Karr, a police detective (later an attorney), and largely dealt with organized crime. "The Young and the Restless" first focused on two families, the prosperous Brooks family with four daughters, and the working class Foster family of a single working mother with three children. Its storylines explored realistic problems including cancer, mental illness, poverty, and infidelity.

In contrast, "Dark Shadows" (1966–1971), "Port Charles" (1997–2003) and "Passions" (1999-2008) featured supernatural characters and dealt with fantasy and horror storylines. Their characters included vampires, witches, ghosts, goblins, and angels.

The American soap opera "Guiding Light" (originally titled "The Guiding Light" until 1975) started as a radio drama in January 1937 and subsequently transferred to television in June 1952. With the exception of several years in the late 1940s, during which creator Irna Phillips was involved in a dispute with Procter & Gamble, "Guiding Light" was heard or seen nearly every weekday from 1937 to 2009, making it the longest story ever told in a broadcast medium.

Originally serials were broadcast as 15-minute installments each weekday in daytime slots. In 1956, "As the World Turns" and "The Edge of Night", both produced by Procter & Gamble Productions, debuted as the first half-hour soap operas on the CBS television network. All soap operas broadcast half-hour episodes by the end of the 1960s. With increased popularity in the 1970s, most soap operas had expanded to an hour in length by the end of the decade ("Another World" even expanded to 90 minutes for a short time). More than half of the serials had expanded to one-hour episodes by 1980. As of 2012, three of the four US serials air one-hour episodes each weekday; only "The Bold and the Beautiful" airs 30-minute episodes.

Soap operas were originally broadcast live from the studio, creating what many at the time regarded as a feeling similar to that of a stage play. As nearly all soap operas were originated at that time from New York City, a number of soap actors were also accomplished stage actors who performed live theater during breaks from their soap roles. In the 1960s and 1970s, new serials such as "General Hospital", "Days of our Lives" and "The Young and the Restless" were produced in Los Angeles. Their success made the West Coast a viable alternative to New York-produced soap operas, which were becoming more costly to perform. By the early 1970s, nearly all soap operas had transitioned to being taped. "As the World Turns" and "The Edge of Night" were the last to make the switch, in 1975.

"Port Charles" used the practice of running 13-week "story arcs," in which the main events of the arc are played out and wrapped up over the 13 weeks, although some storylines did continue over more than one arc. According to the 2006 Preview issue of "Soap Opera Digest", it was briefly discussed that all ABC shows might do telenovela arcs, but this was rejected.

Though U.S. daytime soap operas are not generally rerun by their networks, occasionally they are rebroadcast elsewhere; CBS and ABC have made exceptions to this, airing older episodes (either those aired earlier in the current season or those aired years prior) on major holidays when special event programming is not scheduled. Early episodes of "Dark Shadows" were rerun on PBS member stations in the early 1970s after the show's cancellation, and the entire series (except for a single missing episode) was rerun on the Sci-Fi Channel in the 1990s. After "The Edge of Night"s 1984 cancellation, reruns of the show's final five years were shown late nights on USA Network from 1985 to 1989. On January 20, 2000, a digital cable and satellite network dedicated to the genre, Soapnet, began re-airing soaps that originally aired on ABC, NBC and CBS.

Newer broadcast networks since the late 1980s, such as Fox and cable television networks, have largely eschewed soap operas in their daytime schedules, instead running syndicated programming and reruns. No cable television outlet has produced its own daytime serial, although DirecTV's The 101 Network took over existing serial "Passions", continuing production for one season; while TBS and CBN Cable Network respectively aired their own soap operas, "The Catlins" (a primetime soap that utilized the daily episode format of its daytime counterparts) and "Another Life" (a soap that combined standard serial drama with religious overtones), during the 1980s. Fox, the fourth "major network," carried a short lived daytime soap "Tribes" in 1990. Yet other than this and a couple of pilot attempts, Fox mainly stayed away from daytime soaps, and has not attempted them since their ascension to major-network status in 1994 (it did later attempt a series of daily prime time soaps, which aired on newly created sister network MyNetworkTV, but the experiment was largely a failure).

Due to the masses of episodes produced for a series, release of soap operas to DVD (a popular venue for distribution of current and vintage television series) is considered impractical. With the exception of occasional specials, daytime soap operas are notable by their absence from DVD release schedules (an exception being the supernatural soap opera, "Dark Shadows", which did receive an essentially complete release on both VHS and DVD; the single lost episode #1219 is reconstructed by means of an off-the-air audio recording, still images, and recap material from adjacent episodes).

Due to the longevity of these shows, it is not uncommon for a single character to be played by multiple actors. The key character of Mike Karr on "The Edge of Night" was played by three actors.

Conversely, several actors have remained playing the same character for many years, or decades even. Helen Wagner played Hughes family matriarch Nancy Hughes on American soap "As the World Turns" from its April 2, 1956 debut through her death in May 2010. She is listed in the Guinness Book of World Records as the actor with the longest uninterrupted performance in a single role. A number of performers played roles for 20 years or longer, occasionally on more than one show. Rachel Ames played Audrey Hardy on both "General Hospital" and "Port Charles" from 1964 until 2007, and returned in 2009. Susan Lucci played Erica Kane in "All My Children" from the show's debut in January 1970 until it ended its network television run on ABC on September 23, 2011. Erika Slezak played Victoria Lord #3 on "One Life to Live" from 1971 until the show ended its network television run on ABC on January 13, 2012 and resumed the role in its short-lived online revival on April 29, 2013.

Other actors have played several characters on different shows. Millette Alexander, Bernard Barrow, Doris Belack, David Canary, Judith Chapman, Jordan Charney, Joan Copeland, Nicolas Coster, Jacqueline Courtney, Louis Edmonds, Dan Hamilton, Don Hastings, Vincent Irizarry, Lenore Kasdorf, Teri Keane, Lois Kibbee, John Loprieno, Maeve McGuire, James Mitchell, Christopher Pennock, Antony Ponzini, William Prince, Louise Shaffer, and Diana van der Vlis, among many others, have all played multiple soap roles.

For several decades, most daytime soap operas concentrated on family and marital discord, legal drama and romance. The action rarely left interior settings, and many shows were set in fictional, medium-sized Midwestern towns.

Exterior shots were slowly incorporated into the series "The Edge of Night" and "Dark Shadows". Unlike many earlier serials that were set in fictional towns, "The Best of Everything" and "Ryan's Hope" were set in a real-world location, New York City.

The first exotic location shoot was made by "All My Children", to St. Croix in 1978. Many other soap operas planned lavish storylines after the success of the "All My Children" shoot. Soap operas "Another World" and "Guiding Light" both went to St. Croix in 1980, the former show culminating a long-running storyline between popular characters Mac, Rachel and Janice, and the latter to serve as an exotic setting for Alan Spaulding and Rita Bauer's torrid affair. "Search for Tomorrow" taped for two weeks in Hong Kong in 1981. Later that year, some of the cast and crew ventured to Jamaica to tape a love consummation storyline between the characters of Garth and Kathy.

During the 1980s, perhaps as a reaction to the evening drama series that were gaining high ratings, daytime serials began to incorporate action and adventure storylines, more big-business intrigue, and an increased emphasis on youthful romance.

One of the first and most popular couples was Luke Spencer and Laura Webber on "General Hospital". Luke and Laura helped to attract both male and female fans. Even actress Elizabeth Taylor was a fan and at her own request was given a guest role in Luke and Laura's wedding episode. Luke and Laura's popularity led to other soap producers striving to reproduce this success by attempting to create supercouples of their own.

With increasingly bizarre action storylines coming into vogue, Luke and Laura saved the world from being frozen, brought a mobster down by finding his black book in a left-handed boy statue, and helped a princess find her Aztec treasure in Mexico. Other soap operas attempted similar adventure storylines, often featuring footage shot on location – frequently in exotic locales.

During the 1990s, the mob, action and adventure stories fell out of favor with producers, due to generally declining ratings for daytime soap operas at the time, and the resultant budget cuts. In addition, soap operas were no longer able to go on expensive location shoots overseas as they were able to do in the 1980s. During that decade, soap operas increasingly focused on younger characters and social issues, such as Erica Kane's drug addiction on "All My Children", the re-emergence of Viki Lord's multiple personality disorder on "One Life to Live", and Stuart Chandler dealing with his wife Cindy dying of AIDS on "All My Children". Other social issues included cancer, rape, abortion, homophobia, and racism.

Some shows during the 2000s incorporated supernatural and science fiction elements into their storylines. One of the main characters on the earlier soap opera "Dark Shadows" was Barnabas Collins, a vampire, and "One Life to Live" featured an angel named Virgil. Both shows featured characters who traveled to and from the past.

Modern U.S. daytime soap operas largely stay true to the original soap opera format. The duration and format of storylines and the visual grammar employed by U.S. daytime serials set them apart from soap operas in other countries and from evening soap operas. Stylistically, UK and Australian soap operas, which are usually produced for early evening timeslots, fall somewhere in between U.S. daytime and evening soap operas. Similar to U.S. daytime soap operas, UK and Australian serials are shot on videotape, and the cast and storylines are rotated across the week's episodes so that each cast member will appear in some but not all episodes. UK and Australian soap operas move through storylines at a faster rate than daytime serials, making them closer to U.S. evening soap operas in this regard.

American daytime soap operas feature stylistic elements that set them apart from other shows:

Soap opera ratings have significantly fallen in the U.S. since the 2000s. No new major daytime soap opera has been created since "Passions" in 1999, while many have been cancelled. Since January 2012, four daytime soap operas – "General Hospital", "Days of Our Lives", "The Young and the Restless" and "The Bold and the Beautiful" – continue to air on the three major networks, down from a total of 12 during the 1990–91 season and a high of 19 in the 1969–70 season. This marks the first time since 1953 that there have been only four soap operas airing on broadcast television. "The Young and the Restless", the highest-rated soap opera from 1988 to the present, had fewer than 5 million daily viewers as of February 2012, a number exceeded by several non-scripted programs such as "Judge Judy". Circulations of soap opera magazines have decreased and some have even ceased publication. Soapnet, which largely aired soap opera reruns, began to be phased out in 2012 and fully ceased operations the following year. The Daytime Emmy Awards, which honor soap operas and other daytime shows, moved from prime time network television to smaller cable channels in 2012, then failed to get any TV broadcast at all in 2014, 2016, and 2017.

Several of the U.S.'s most established soaps ended between 2009 and 2012. The longest-running drama in television and radio history, "Guiding Light", barely reached 2.1 million daily viewers in 2009 and ended on September 18 of that year, after a 72-year run (including radio). "As the World Turns" aired its final episode on September 17, 2010 after a 54-year run. "As the World Turns" was the last of 20 soap operas produced by Procter & Gamble, the soap and consumer goods company from which the genre got its name. "As the World Turns" and "Guiding Light" were also among the last of the soaps that originated from New York City. "All My Children", another New York-based soap, moved its production out to Los Angeles in an effort to reduce costs and raise sagging ratings; however, both it and "One Life to Live", each with a 40-year-plus run, were cancelled in 2011. "All My Children" aired its network finale in September 2011, with "One Life to Live" following suit in January 2012. Both "All My Children" and "One Life to Live" were briefly revived online in 2013, before being cancelled again that same year. In 2019, production of "Days of Our Lives" was put on "indefinite hiatus" and all of the cast's contracts were terminated, raising concerns within soap publications that cancellation would ensue.

As women increasingly worked outside of the home, daytime television viewing declined. New generations of potential viewers were not raised watching soap operas with their mothers, leaving the shows' long and complex storylines foreign to younger audiences. Now, as viewers age, ratings continue to drop among young adult women, the demographic group that soap opera advertisers pay the most for. Those who might watch in workplace breakrooms are not counted, as Nielsen does not track television viewing outside the home. The rise of cable and the Internet has also provided new sources of entertainment during the day. The genre's decline has additionally been attributed to reality television displacing soap operas as TV's dominant form of melodrama. An early term for the reality TV genre was "docu-soap". A precursor to reality TV, the televised 1994–95 O. J. Simpson murder case, both preempted and competed with an entire season of soaps, transforming viewing habits and leaving soap operas with 10 percent fewer viewers after the trial ended.

Daytime programming alternatives such as talk shows, game shows, and court shows cost up to 50% less to produce than scripted dramas, making those formats more profitable and attractive to networks, even if they receive the same or slightly lower ratings than soap operas. A network may even prefer to return a time slot to its local stations to keeping a soap opera with disappointing ratings on the air, as was the case with "Sunset Beach" and "Port Charles". Compounding the financial pressure on scripted programming in the 2007–2010 period was a decline in advertising during the Great Recession, which led shows to reduce their budgets and cast sizes. In addition to these external factors, a litany of production decisions has been cited by soap opera fans as contributing to the genre's decline, such as cliched plots, a lack of diversity that narrowed audience appeal, and the elimination of core families.

Serials produced for prime time slots have also found success. The first prime time soap opera was "Faraway Hill" (1946), which aired on October 2, 1946, on the now-defunct DuMont Television Network. "Faraway Hill" ran for 12 episodes and was primarily broadcast live, interspersed with short pre-recorded film clips and still photos to remind the audience of the previous week's episode.

The first long-running prime time soap opera was "Peyton Place" (1964–1969) on ABC. It was based in part on the eponymous 1957 film (which, in turn, was based on the 1956 novel).

The popularity of "Peyton Place" prompted the CBS network to spin-off popular "As the World Turns" character Lisa Miller into her own evening soap opera, "Our Private World" (originally titled "The Woman Lisa" in its planning stages). "Our Private World" was broadcast from May to September 1965. The character of Lisa (and her portrayer Eileen Fulton) returned to "As The World Turns" after the series ended.

The structure of "Peyton Place", with its episodic plots and long-running story arcs, set the mold for the prime time serials of the 1980s, when the format reached its pinnacle.

The successful prime time serials of the 1980s included "Dallas", its spin-off "Knots Landing", "Dynasty", and "Falcon Crest". These shows frequently dealt with wealthy families, and their personal and big-business travails. Common characteristics were sumptuous sets and costumes, complex storylines examining business schemes and intrigue, and spectacular disaster cliffhanger situations. Each of these series featured a wealthy, domineering, promiscuous, and passionate antagonist as a key character in the storyline – respectively, J.R. Ewing (Larry Hagman), Alexis Colby (Joan Collins), Abby Cunningham (Donna Mills) and Angela Channing (Jane Wyman). These villainous schemers became immensely popular figures that audiences "loved to hate".

Unlike daytime serials, which are shot on video in a studio using the multi-camera setup, these evening series were shot on film using a single camera setup, and featured substantial location-shot footage, often in picturesque locales. "Dallas", its spin-off "Knots Landing", and "Falcon Crest" all initially featured episodes with self-contained stories and specific guest stars who appeared in just that episode. Each story was completely resolved by the end of the episode, and there were no end-of-episode cliffhangers. After the first couple of seasons, all three shows changed their story format to that of a pure soap opera, with interwoven ongoing narratives that ran over several episodes. "Dynasty" featured this format throughout its run.

The soap opera's distinctive open plot structure and complex continuity was increasingly incorporated into American prime time television programs of the period. The first significant drama series to do this was "Hill Street Blues". This series, produced by Steven Bochco, featured many elements borrowed from soap operas, such as an ensemble cast, multi-episode storylines, and extensive character development over the course of the series. It and the later "Cagney & Lacey" overlaid the police series formula with ongoing narratives exploring the personal lives and interpersonal relationships of the regular characters. The success of these series prompted other drama series, such as "St. Elsewhere" and situation comedy series, to incorporate serialized stories and story structure to varying degrees.

The prime time soap operas and drama series of the 1990s, such as "Beverly Hills, 90210", "Melrose Place", "Party of Five", "The OC", and "Dawson's Creek", focused more on younger characters. In the 2000s, ABC began to revitalize the prime time soap opera format with shows such as "Desperate Housewives", "Grey's Anatomy", "Brothers & Sisters", "Ugly Betty", "Private Practice", and more recently "Revenge", "Nashville", "Scandal", "Mistresses", and formerly "Ringer", which its sister production company ABC Studios co-produced with CBS Television Studios for The CW. While not soaps in the traditional sense, these shows managed to appeal to wide audiences with their high drama mixed with humor, and are soap operas by definition. These successes led to NBC's launching serials, including "Heroes" and "Friday Night Lights". The upstart MyNetworkTV, a sister network of Fox, launched a line of prime time telenovelas (a genre similar to soap operas in terms of content) upon its launch in September 2006, but discontinued its use of the format in 2007 after disappointing ratings.

On June 13, 2012, "Dallas", a continuation of the 1978 original series premiered on the cable network, TNT. The revived series, which was canceled after three seasons in 2014, delivered solid ratings for the channel, only losing viewership after the show's most established star, Larry Hagman, died midway through the series. In 2012, Nick at Nite debuted a primetime soap opera, "Hollywood Heights", which aired episodes five nights a week (on Monday through Fridays) in a manner similar to a daytime soap opera, instead of the once-a-week episode output common of other prime time soaps. The series, which was an adaptation of the Mexican telenovela "Alcanzar una estrella", suffered from low ratings (generally receiving less than 1 million viewers) and was later moved to sister cable channel TeenNick halfway through its run to burn off the remaining episodes.

In 2015, Fox debuted "Empire", a prime time musical serial centering on the power struggle between family members within the titular recording company. Created by Lee Daniels and Danny Strong and led by Oscar nominees Terrence Howard and Taraji P. Henson, the drama premiered to high ratings. The show is strongly influenced by other works such as William Shakespeare's "King Lear", James Goldman's "The Lion in Winter" and the 1980s soap opera "Dynasty". Also in 2015, E! introduced "The Royals", a series following the life and drama of a fictional English Royal family, which was also inspired by "Dynasty" (even featuring Joan Collins as the Queen's mother). In addition, ABC debuted a prime time soap opera "Blood & Oil", following a young couple looking to make money off the modern-day Williston oil boom, premiering on September 27, 2015 during the 2015-16 TV season.

The telenovela, a shorter-form format of serial melodrama, shares some thematic and especially stylistic similarity to the soap opera, enough that the colloquialism "Spanish soap opera" has arisen to describe the format. The chief difference between the two is length of series; while soap operas usually have indefinite runs, telenovelas typically have a central story arc with a prescribed ending within a year or two of the show's launch, requiring more concise storytelling.

Spanish-language networks, chiefly Univision and Telemundo, have found success airing telenovelas for the growing U.S. Hispanic market. Both originally produced and imported Latin American dramas are popular features of the networks' daytime and primetime lineups, sometimes beating English-language networks in the ratings.

Some web series are soap operas, such as "" or "". In 2013, production company Prospect Park revived "All My Children" and "One Life to Live" for the web, retaining original creator Agnes Nixon as a consultant and keeping many of the same actors (Prospect Park purchased the rights to both series months after their cancellations by ABC in 2011, although it initially suspended plans to relaunch the soaps later that same year due to issues receiving approval from acting and production unions). Each show initially produced four half-hour episodes a week, but quickly cut back to two half-hour episodes each. In the midst of (though not directly related to) a lawsuit between Prospect Park and ABC, the experiment ended that same year, with both shows being canceled again.

As of 2017, Turkey is the second largest exporter of television soap operas. In 2016, Turkish TV exports earned $350 million, making it the second largest drama exporter in the world behind the United States. Turkish soap operas have a large following across Asia, the Balkans, Eastern Europe, Latin America, the Middle East, and Africa.

Soap operas in the UK began on radio and consequently were associated with the BBC. It had resisted soaps as antithetical to its quality image, but began broadcasting "Front Line Family" in April 1941 on its North American shortwave service to encourage American intervention on Britain's behalf in World War II. The BBC continues to broadcast the world's longest-running radio soap, "The Archers", which first aired in May 1950, and has been running nationally since 1951. It is currently broadcast on BBC Radio 4 and continues to attract over five million listeners, or roughly 25% of the radio listening population of the UK at that time of the evening.

In the UK, soap operas are one of the most popular genres, with most being broadcast during prime time. Most UK soap operas focus on everyday, working-class communities, influenced by the conventions of the kitchen sink drama. The most popular British soap operas are "EastEnders", "Coronation Street", "Emmerdale", "Hollyoaks", "Doctors", and the Australian produced "Neighbours" and "Home and Away". The first three of these are consistently among the highest-rated shows on British television. Such is the magnitude of the popularity of the soap genre in the UK that all television serials in the country are reputedly enjoyed by members of the British Royal Family, including Elizabeth II herself. Major events in British culture are often mentioned in the storyline, such as England's participation at the World Cup, and the death of Princess Diana. Since 1999, The British Soap Awards has been televised on ITV.

The 1986 Christmas Day episode of "EastEnders" is often referred to as the highest-rated UK soap opera episode ever, with 30.15 million viewers (more than half the population at the time). The figure of 30.15 million was actually a combination of the original broadcast, which had just over 19 million viewers, and the Sunday omnibus edition with 10 million viewers. The combined 30.15 million audience figure makes the aforementioned Christmas Day 1986 episode of "EastEnders" the highest-rated single-channel broadcast in the history of UK television. Overall it ranks third behind the 1966 FIFA World Cup Final (32.3 million viewers) and Princess Diana's funeral in 1997 (32.1 million viewers) which were transmitted on both BBC One and ITV.

An early television serial was "The Grove Family" on the BBC, which produced 148 episodes from 1954 to 1957. The programme was broadcast live and only a handful of recordings were retained in the archives. The UK's first twice-weekly serial was ITV's "Emergency - Ward 10", running from 1957 until 1967.

In the 1960s, "Coronation Street" revolutionised UK television and quickly became a British institution. On 17 September 2010, it became the world's longest-running television soap opera and was listed in "Guinness World Records". The BBC also produced several serials: "Compact" was about the staff of a women's magazine; "The Newcomers" was about the upheaval caused by a large firm setting up a plant in a small town; "United!" contained 147 episodes and focused on a football team; "199 Park Lane" (1965) was an upper class serial, which ran for only 18 episodes. None of these serials came close to making the same impact as "Coronation Street". Indeed, most of the 1960s BBC serials were largely wiped.

During the 1960s, "Coronation Street"s main rival was "Crossroads", a daily serial that began in 1964 and aired on ITV in the early evening. "Crossroads" was set in a Birmingham motel and, although the program was popular, its purported low technical standard and bad acting were much mocked. By the 1980s, its ratings had begun to decline. Several attempts to revamp the program through cast changes and, later, expanding the focus from the motel to the surrounding community were unsuccessful. "Crossroads" was cancelled in 1988 (a new version of "Crossroads" was later produced, running from 2001 until 2003).

A later rival to "Coronation Street" was ITV's "Emmerdale Farm" (later renamed "Emmerdale"), which began in 1972 in a daytime slot and was set in rural Yorkshire. Increased viewership resulted in "Emmerdale" being moved to a prime-time slot in the 1980s.

"Pobol y Cwm" ("People of the Valley") is a Welsh language serial that has been produced by the BBC since October 1974, and is the longest-running television soap opera produced by the broadcaster. "Pobol y Cwm" was originally broadcast on BBC Wales television from 1974 to 1982; it was then moved to the Welsh-language television station S4C when it opened in November 1982. The program was occasionally shown on BBC1 in London during periods of regional optout in the mid- to late 1970s. "Pobol y Cwm" was briefly shown in the rest of the UK in 1994 on BBC2, with English subtitles; it is consistently the most watched programme each week on S4C.

Daytime soap operas were non-existent until the 1970s because there was virtually no daytime television in the UK. ITV introduced "General Hospital", which later moved to a prime time slot. In 1980, Scottish Television debuted "Take the High Road", which lasted for over twenty years. Later, daytime slots were filled with an influx of Australian soap operas such as "The Sullivans" (aired on ITV from 1977), "The Young Doctors" (from 1982), "Sons and Daughters" (from 1983), "A Country Practice" (from 1982), "Richmond Hill" (from 1988 to 1989) and eventually, "Neighbours" was acquired by the BBC in 1986, and "Home and Away" aired on ITV beginning in 1989. These achieved significant levels of popularity; "Neighbours" and "Home and Away" were moved to early-evening slots, helping begin the UK soap opera boom in the late 1980s.

The day Channel 4 began operations in 1982 it launched its own soap, the Liverpool-based "Brookside", which would redefine soaps over the next decade. The focus of "Brookside" was different from earlier soap operas in the UK; it was set in a middle-class new-build cul-de-sac, unlike "Coronation Street" and "Emmerdale Farm", which were set in established working-class communities. The characters in "Brookside" were generally either people who had advanced themselves from inner-city council estates, or the upper middle-class who had fallen on hard times. Though "Brookside" was still broadcast in a pre-watershed slot (8.00 p.m. and 8.30 p.m. on weekdays, around 5.00 p.m. for the omnibus on Saturdays), it was more liberal than other soaps of the time: the dialogue regularly included expletives. This stemmed from the overall more liberal policy of the channel during that period. The soap was also heavily politicised. Bobby Grant (Ricky Tomlinson), a militant trade-unionist anti-hero, was the most overtly political character. Storylines were often more sensationalist than on other soaps (throughout the soap's history, there were two armed sieges on the street) and were staged with more violence (particularly, rape) often being featured.

In 1985, the BBC's "EastEnders" debuted and became a near instant success with viewers and critics alike, with the first episode attracting over 17 million viewers. The Christmas Day 1986 episode was watched by 30.15 million viewers and contained a scene in which divorce papers were served to Angie Watts (Anita Dobson) by her husband, Queen Vic landlord Den (Leslie Grantham).

A notable success in pioneering late-night broadcasting, in October 1984, Yorkshire Television began airing the cult Australian soap opera "Prisoner", which originally ran from 1979 to 1986. It was eventually broadcast on all regions of the UK in differing slots, usually around 23:00 (but never before 22:30 in any region), under the title "Prisoner: Cell Block H". It was probably most popular in the Midlands where Central Television consistently broadcast the serial three times a week from 1987 to 1991. Its airing in the UK was staggered, so different regions of the country saw it at a different pace. The program was immensely successful, regularly achieving 10 million viewers when all regions' ratings per episode were added together. Central bowed to fan pressure to repeat the soap, of which the first 95 episodes aired. Then, rival station Channel 5 also acquired rights to repeat the entire rerun of the program, starting in 1997. All 692 episodes have since been released on DVD in the UK.

In 1992, the BBC made "Eldorado" to daily alternate with "EastEnders". The programme was heavily criticised and only lasted one year. Nevertheless, soap operas gained increasing prominence on UK television schedules. In 1995, Channel 4 premiered "Hollyoaks", a soap with a youth focus. When Channel 5 launched in March 1997, it debuted the soap opera "Family Affairs", which was formatted as a week-daily soap, airing Monday through Fridays.

"Brookside"s premise evolved during the 1990s, phasing out the politicised stories of the 1980s and shifting the emphasis to controversial and sensationalist stories such as child rape, sibling incest, religious cults and drug addiction, including the infamous 'body under the patio' storyline that ran from 1993 to 1995, and gave the serial its highest ratings ever with 9 million viewers.

"Coronation Street" and "Brookside" began releasing straight-to-video features. The "Coronation Street" releases generally kept the pace and style of conventional programs episodes with the action set in foreign locations. The "Brookside" releases were set in the usual locations, but featured stories with adult content not allowed on television pre-watershed, with these releases given '18' certificates.

"Emmerdale Farm" was renamed "Emmerdale" in 1989. The series was revamped in 1993 with many changes executed via the crash of a passenger jet that partially destroyed the village and killed several characters. This attracted criticism as it was broadcast near the fifth anniversary of the Lockerbie bombing. The storyline drew the soap its highest ever audience of 18 million viewers. The revamp was a success and "Emmerdale" grew in popularity.

Throughout the 1990s, "Brookside", "Coronation Street", "EastEnders" and "Emmerdale" continued to flourish. Each increased the number of episodes that aired on a weekly basis by at least one, further defining soap operas as the leading genre in British television.

Since 2000, new soap operas have continued to be developed. Daytime drama "Doctors" began in March 2000, preceding "Neighbours" on BBC One. In 2002, as ratings for the Scottish serial "High Road" (formerly "Take The High Road") continued to decline, BBC Scotland launched "River City", which proved popular and effectively replaced "High Road" when it was cancelled in 2003. The long-running serial "Brookside" ended in November 2003 after 21 years on the air, leaving "Hollyoaks" as Channel 4's flagship serial.

A new version of "Crossroads" featuring a mostly new cast was produced by Carlton Television for ITV in 2001. It did not achieve high ratings and was cancelled in 2003. In 2001, ITV also launched a new early-evening serial entitled "Night and Day". This program too attracted low viewership and, after being shifted to a late night time slot, was cancelled in 2003. "Family Affairs", which was broadcast opposite the racier "Hollyoaks", never achieved significantly high ratings leading to several dramatic casting revamps and marked changes in style and even location over its run. By 2004, "Family Affairs" had a larger fan base and won its first awards, but was cancelled in late 2005.

In 2008, ITV premiered "The Royal Today", a daily spin-off of popular 1960s-based drama "The Royal", which had been running in a primetime slot since 2002. Just days later, soap opera parody programs "Echo Beach" premiered alongside its sister show, the comedy "Moving Wallpaper". Both "Echo Beach" and "The Royal Today" ended after just one series due to low ratings. Radio soap opera "Silver Street" debuted on the BBC Asian Network in 2004. Poor ratings and criticism of the program led to its cancellation in 2010.

UK soap operas for many years usually only aired two nights a week. The exception was the original "Crossroads", which began as a week-daily soap opera in the 1960s, but later had its number of weekly broadcasts reduced.

In 1989, "Coronation Street" began airing three times a week. In 1996, it expanded to four episodes a week.

"Brookside" premiered in 1982 with two episodes a week. In 1990 it expanded to three episodes a week.

"EastEnders" increased its number of episode a week in 1994 and "Emmerdale" did so in 1997.

"Family Affairs" debuted as a weekdaily soap in 1997, producing five episodes a week its entire run.

In 2004, "Emmerdale" began airing six episodes a week.

In a January 2008 overhaul of the ITV network, the Sunday episodes of "Coronation Street" and "Emmerdale" were moved out of their slots. "Coronation Street" added a second episode on Friday evenings at 8:30 p.m. "Emmerdale"s Tuesday edition was extended to an hour, putting it in direct competition with "EastEnders". In July 2009, the schedules of these serials were changed again. On 23 July 2009, "Coronation Street" moved from the Wednesday slot it held for 49 years, to Thursday evenings. "Emmerdale" reverted to running just one 30-minute episode on Tuesday evenings and the other 30-minute installment was moved to Thursday evenings. "Coronation Street" later returned to a Wednesday slot, to air Mondays, Wednesdays and Fridays at 19:30 and 20:30. "Emmerdale" airs at 19:00 every weeknight, and 20:00 on Thursdays.

Later, "Coronation Street" (which began airing two episodes on Monday nights in 2002) produced five episodes a week.

It was announced in June 2016 that starting late 2017, Coronation Street would air six episodes a week.

"Doctors" airs five episodes a week, and is the only soap without a weekend omnibus repeat screening. "Hollyoaks" produces five episodes a week. The imported "Neighbours" screens as five new episodes a week. As of 2019, "EastEnders" produces four episodes a week.

UK soap operas are shot on videotape in the studio using a multi-camera setup. In their early years, "Coronation Street" and "Emmerdale" used 16 mm film for footage shot on location. Since the 1980s, UK soap opera have routinely featured scenes shot outdoors in each episode. This footage is shot on videotape on a purpose-built outdoor set that represents the community that the soap focuses on.

"Hollyoaks" and "Family Affairs" were taped on high-definition video, and used the filmizing process.

Australia has had quite a number of well-known soap operas, some of which have gained cult followings in the United Kingdom, New Zealand and other countries. The majority of Australian television soap operas are produced for early evening or evening timeslots. They usually produce two or two-and-a-half hours of new material each week, either arranged as four or five half-hour episodes a week, or as two one-hour episodes.

Stylistically, these series most closely resemble UK soap operas in that they are nearly always shot on videotape, are mainly recorded in a studio and use a multi-camera setup. The original Australian serials were shot entirely in-studio. During the 1970s occasional filmed inserts were used to incorporate sequences shot outdoors. Outdoor shooting later became commonplace and starting in the late 1970s, it became standard practice for some on-location footage to be featured in each episode of any Australian soap opera, often to capitalise on the attractiveness and exotic nature of these locations for international audiences. Most Australian soap operas focus on a mixed age range of middle-class characters and will regularly feature a range of locations where the various, disparate characters can meet and interact, such as the café, the surf club, the wine bar or the school.

The genre began in Australia on radio, as it had in the United States and the United Kingdom. One such radio serial, "Big Sister", featured actress Thelma Scott in the cast and aired nationally for five years beginning in 1942. Probably the best known Australian radio serial was the long-running soap opera "Blue Hills", which was created by Gwen Meredith and ran from 1949 to 1976. With the advent of Australian television in 1956, daytime television serials followed. The first Australian television soap opera was "Autumn Affair" (1958) featuring radio personality and "Blue Hills" star Queenie Ashton making the transition to television. Each episode of this serial ran for 15 minutes and aired each weekday on the Seven Network. "Autumn Affair" failed to secure a sponsor and ended in 1959 after 156 episodes. It was followed by "The Story of Peter Grey" (1961), another Seven Network weekday series aired in a daytime slot in 15-minute installments. "The Story of Peter Grey" ran for 164 episodes.

The first successful wave of Australian evening television soap operas started in 1967 with "Bellbird", produced by the Australian Broadcasting Corporation. This rural-based serial screened in an early evening slot in 15-minute installments as a lead-in to the evening news. "Bellbird" was a moderate success but built-up a consistent and loyal viewer base, especially in rural areas, and enjoyed a ten-year run. "Motel" (1968) was Australia's first half-hour soap opera; the daytime soap had a short run of 132 episodes.

The first major soap opera hit in Australia was the sex-melodrama "Number 96", a nighttime series produced by Cash Harmon Television for Network Ten, which debuted March 1972. The program dealt with such topics as homosexuality, adultery, drug use, rape-within-marriage and racism, which had rarely been explored on Australian television programs before. The series became famous for its sex scenes and nudity and for its comedic characters, many of whom became cult heroes in Australia. By 1973, "Number 96" had become Australia's highest-rated show. In 1974, the sexed-up antics of "Number 96" prompted the creation of "The Box", which rivaled it in terms of nudity and sexual situations and was scheduled in a nighttime slot. Produced by Crawford Productions, many critics considered "The Box" to be a more slickly produced and better written show than "Number 96". "The Box" also aired on the Ten Network, programmed to run right after "Number 96". For 1974 "Number 96" was again the highest rating show on Australian television, and that year "The Box" occupied the number two spot.

Also in 1974, the Reg Grundy Organisation created its first soap opera, and significantly Australia's first "teen" soap opera, "Class of '74". With its attempts to hint at the sex and sin shown more openly on "Number 96" and "The Box", its high school setting and early evening timeslot, "Class of '74" came under intense scrutiny from the Broadcasting Control Board, who vetted scripts and altered entire storylines.

By 1975, both "Number 96" and "The Box", perhaps as a reaction to declining ratings for both shows, de-emphasised the sex and nudity shifting more towards comedic plots. "Class of '74" was renamed "Class of '75" and also added more slapstick comedy for its second year, but the revamped show's ratings declined, resulting in its cancellation in mid-1975. That year Cash Harmon's newly launched second soap "The Unisexers" failed in its early evening slot and was cancelled after three weeks; the Reg Grundy Organisation's second soap "Until Tomorrow" ran in a daytime slot for 180 episodes.

A feature film version of "Bellbird" entitled "Country Town" was produced in 1971 by two of the show's stars, Gary Gray and Terry McDermott, without production involvement by the Australian Broadcasting Corporation. "Number 96" and "The Box" also released feature film versions, both of which had the same title as the series, released in 1974 and 1975 respectively. As Australian television had broadcast in black and white until 1975, these theatrical releases all had the novelty of being in colour. The film versions of "Number 96" and "The Box" also allowed more explicit nudity than could be shown on television at that time.

In November 1976 "The Young Doctors" debuted on the Nine Network. This Grundy Organization series eschewed the adult drama of "Number 96" and "The Box", focusing more on relationship drama and romance. It became a popular success but received few critical accolades. A week later "The Sullivans", a carefully produced period serial chronicling the effects of World War II on a Melbourne family, also debuted on Nine. Produced by Crawford Productions, "The Sullivans" became a ratings success, attracted many positive reviews, and won television awards. During this period "Number 96" re-introduced nudity into its episodes, with several much-publicised full-frontal nude scenes, a cast revamp and a new range of shock storylines designed to boost the show's declining ratings. "Bellbird" experienced changes to its broadcast pattern with episodes screening in 60 minute blocks, and later in 30 minute installments.
"Bellbird", "Number 96" and "The Box", which had been experiencing declining ratings, were cancelled in 1977. Various attempts to revamp each of the shows with cast reshuffles or spectacular disaster storylines had proved only temporarily successful. "The Young Doctors" and "The Sullivans" continued to be popular. November 1977 saw the launch of successful soap opera/police procedural series "Cop Shop" (1977–1984) produced by Crawford Productions for Channel Seven. In early December 1977 Channel Ten debuted the Reg Grundy Organisation produced "The Restless Years" (1977–1981), a more standard soap drama focusing on several young school leavers.

The Seven Network, achieving success with "Cop Shop" produced by Crawford Productions, had Crawfords produce "Skyways", a series with a similar format but set in an airport, to compete with the Nine Network's popular talk show "The Don Lane Show". "Skyways", which debuted in July 1979, emphasised adult situations including homosexuality, marriage problems, adultery, prostitution, drug use and smuggling, crime, suicide, political intrigue, and murder, and featured some nudity. Despite this, the program achieved only moderate ratings and was cancelled in mid-1981.

The Reg Grundy Organisation found major success with the women's-prison drama "Prisoner" (1979–1986) on Network Ten, and melodramatic family saga "Sons and Daughters" (1982–1987) on the Seven Network. Both shows achieved high ratings in their original runs, and unusually, found success in repeats after the programs ended.

Grundy soap "The Young Doctors" and Crawford Productions' "The Sullivans" continued on the Nine Network until late 1982. Thereafter Nine attempted many new replacement soap operas produced by the Reg Grundy Organisation: "Taurus Rising" (1982), "Waterloo Station" (1983), "Starting Out" (1983) and "Possession" (1985), along with "Prime Time" (1986) produced by Crawford Productions. None of these programs were successful and most were cancelled after only a few months. The Reg Grundy Organisation also created "Neighbours", a suburban-based daily serial devised as a sedate family drama with some comedic and lightweight situations, for the Seven Network in 1985.

Produced in Melbourne at the studios of HSV-7, "Neighbours" achieved high ratings in Melbourne, Brisbane and Adelaide, but not in Sydney, where it aired at 5.30 p.m. placing it against the hit dating game show "Perfect Match" on Channel 10. The Seven Network's Sydney station ATN-7 quickly lost interest in "Neighbours" as a result of the low ratings in Sydney. HSV-7 in Melbourne lobbied heavily to keep "Neighbours" on the air, but ATN-7 managed to convince the rest of the network to cancel the show and instead keep ATN-7's own Sydney-based dramas "A Country Practice" and "Sons and Daughters".

After the network cancelled "Neighbours", it was immediately picked up by Channel Ten, which revamped the cast and scripts slightly and aired the series in the 7.00 p.m. slot starting 20 January 1986. It initially attracted low audiences; however, after a concerted publicity drive, Ten managed to transform the series into a major success, turning several of its actors into major international stars. The show's popularity eventually declined and it was moved to the 6.30 p.m. slot in 1992. In January 2011 it moved to Eleven and is Australia's longest-running soap opera.

The success of "Neighbours" in the 1980s prompted the creation of somewhat similar suburban and family or teen-oriented soap operas such as "Home and Away" (1988–present) on Channel Seven and "Richmond Hill" (1988) on Channel Ten. Both proved popular, however "Richmond Hill" emerged as only a moderate success and was cancelled after one year to be replaced on Ten by "E Street" (1989–1993).

Nine continued trying to establish a successful new soap opera, without success. After the failure of family drama "Family and Friends" in 1990, it launched the raunchier and more extreme "Chances" in 1991, which resurrected the sex and melodrama of "Number 96" and "The Box" in an attempt to attract attention. "Chances" achieved only moderate ratings, and was moved to a late-night timeslot. It underwent several revamps that removed much of the original cast, and refocused the storylines to incorporate science-fiction and fantasy elements. The series continued in a late night slot until 1992, when it was cancelled due to low ratings despite the much-discussed fantasy storylines.

Several Australian soap operas have also found significant international success. In the UK, starting in the mid-1980s, daytime broadcasts of "The Young Doctors", "The Sullivans", "Sons and Daughters" and "Neighbours" (which itself was subsequently moved to an early-evening slot) achieved significant success. Grundy's "Prisoner" began airing in the United States in 1979 and achieved high ratings in many regions there, however the show ended its run in that country three years into its run. "Prisoner" also aired in late-night timeslots in the UK beginning in the late 1980s, achieving enduring cult success there. The show became so popular in that country that it prompted the creation of two stage plays and a stage musical based on the show, all of which toured the UK, among many other spin-offs. In the late 1990s, Channel 5 repeated "Prisoner" in the UK. Between 1998 and 2005, Channel 5 ran late-night repeats of "Sons and Daughters". During the 1980s, the Australian attempts to emulate big-budget U.S. soap operas such as "Dallas" and "Dynasty" had resulted in the debuts of "Taurus Rising" and "Return to Eden", two slick soap opera dramas with big budgets that were shot entirely on film. Though their middling Australian ratings resulted in the shows running only for a single season, both programs were successfully sold internationally.

Other shows to achieve varying levels of international success include "Richmond Hill", "E Street", "Paradise Beach" (1993–1994), and "Pacific Drive" (1995–1997). Indeed, these last two series were designed specifically for international distribution. Channel Seven's "Home and Away", a teen soap developed as a rival to "Neighbours", has also achieved significant and enduring success on UK television.

"Something in the Air", a serial examining a range of characters in a small country town ran on the ABC from 2000 to 2002.

Attempts to replicate the success of daily teen-oriented serials "Neighbours" and "Home and Away" saw the creation of "Echo Point" (1995) and "Breakers" (1999) on Network Ten. These programs foregrounded youthful attractive casts and appealing locations but the programs were not long-running successes and "Neighbours" and "Home and Away" remained the most visible and consistently successful Australian soap operas in production. In their home country, they both attracted respectable although not spectacular ratings in the early 2000s. By 2004, "Neighbours" was regularly attracting just under a million viewers per episode – considered at that time a low figure for Australian prime time television. By March 2007, the Australian audience for "Neighbours" had fallen to fewer than 700,000 a night. This prompted a revamp of the show's cast, its visual presentation, and a move away from the recently added action-oriented emphasis to refocus the show on the domestic storylines it is traditionally known for. During this period "Neighbours" and "Home and Away" continued to achieve significant ratings in the UK. This and other lucrative overseas markets, along with Australian broadcasting laws that enforce a minimum amount of domestic drama production on commercial television networks, help ensure that both programs remain in production. Both shows get higher total ratings in the UK than in Australia (the UK has three times the total population of Australia) and the UK channels make a major contribution to the production costs.

It has been suggested that with their emphasis on the younger, attractive and charismatic characters, "Neighbours" and "Home and Away" have found success in the middle ground between glamorous, fantastic U.S. soaps with their wealthy but tragic heroes and the more grim, naturalistic UK soap operas populated by older, unglamorous characters. The casts of "Neighbours" and "Home and Away" are predominantly younger and more attractive than the casts of UK soaps, and without excessive wealth and glamour of the U.S. daytime serial, a middle-ground in which they have found their lucrative niche.

"Neighbours" was carried in the United States on the Oxygen cable channel in March 2004; however it attracted few viewers, perhaps in part due to its scheduling opposite well-established and highly popular U.S. soap operas such as "All My Children" and "The Young and the Restless", and was dropped by the network shortly afterwards due to low ratings.

"headLand" made its debut on Channel Seven in November 2005, the series arose out of a proposed spinoff of "Home and Away" that was to have been produced in conjunction with "Home and Away"s UK broadcaster, Five. The idea for the spin-off was scuttled after Five pulled out of the deal, which meant that the show could potentially air on a rival channel in the UK; as such, Five requested that the new show be developed as a standalone series and not be spun off from a series that it owned a stake in. The series premiered in Australia on November 15, 2005, but was not a ratings success and was cancelled two months later on January 23, 2006. The series broadcast on E4 and Channel 4 in the UK. Nickelodeon's "" appeared in July 2006 on Network Ten. Since Connie considered this mention as a torrid soap opera, this was mentioned in the Steven Universe episode "Love Letters".

After losing the UK television rights to "Neighbours" to Five, the BBC commissioned a replacement serial "Out of the Blue", which was produced in Australia. It debuted as part of BBC One's weekday afternoon schedule on 28 April 2008 but low ratings prompted its move to BBC Two on 19 May 2008. The series was cancelled after its first season.

"Neighbours"' continued low ratings in Australia resulted in it being moved to Ten's new digital channel, Eleven on January 11, 2011. However, it continues to achieve reasonable ratings on Channel 5 in the United Kingdom, and as of March 2013 still reportedly achieved significant international sales.

Pioneering series "Pukemanu" aired over two years (1971–72) and was the NZBC's first continuing drama. It followed the goings-on of a North Island timber town.
"Close to Home" is a New Zealand television soap opera that ran on TVNZ 1 from 1975 to 1983. At its peak in 1977 nearly one million viewers tuned in twice weekly to watch the series co-created by Michael Noonan and Tony Isaac (who had initially only agreed to make the show on the condition they would get to make "The Governor"). "Gloss" is a television drama series that screened from 1987 to 1990. The series is about a fictional publishing empire run by the Redfern family. Gloss was NZ's answer to US soap "Dynasty", with the Carrington oil scions replaced by the wealthy Redferns and their Auckland magazine empire. It was a starting point for many actors who went on to many productions in New Zealand, Australia and around the world including Temuera Morrison, Miranda Harcourt, Peter Elliott, Lisa Chappell, Danielle Cormack and Kevin Smith. Many of them would go on to star in "Shortland Street", which has been New Zealand's most popular soap since its debut in 1992. It airs on TVNZ 2.

Radio New Zealand began airing its first radio soap "You Me Now" in September 2010. It is available for podcast on its website.

Relatively few daily soap operas have been produced on English Canadian television, with most Canadian stations and networks that carry soap operas airing those imported from the United States or the United Kingdom. Notable daily soaps that did exist included "Family Passions", "Scarlett Hill", "Strange Paradise", "Metropia", "Train 48" and the international co-production "Foreign Affairs". "Family Passions" was an hour-long program, as is typical of American daytime soaps; all of the others ran half-hour episodes. Unlike American or British soap operas, the most influential of which have run for years or even decades, even daily Canadian soap operas have run for a few seasons at most. Short-run soaps, including "49th & Main" and "North/South", have also aired. Many of these were produced in an effort to comply with Canadian content regulations, which require a percentage of programming on Canadian television to originate from Canada.

Notable prime time soap operas in Canada have included "Riverdale", "House of Pride", "Paradise Falls", "Lance et Compte" ("He Shoots, He Scores"), "Loving Friends and Perfect Couples" and "The City". The "Degrassi" franchise of youth dramas also incorporated some elements of the soap opera format.

On French-language television in Quebec, the "téléroman" has been a popular mainstay of network programming since the 1950s. Notable téléromans have included "Rue des Pignons", "Les Belles Histoires des pays d'en haut", "Diva", "La famille Plouffe", and the soap opera parody "Le Cœur a ses raisons".

Unlike the season based production in most countries, most of Indian television fiction tends to be regular-broadcasting soap opera. These started in the 1980s, as more and more people began to purchase television sets. At the beginning of the 21st century, soap operas became an integral part of Indian culture. Indian soap operas mostly concentrate on the conflict between love and arranged marriages occurring in India, and many includes family melodrama. Indian soap operas have multilingual production.

Many soap operas produced in India are also broadcast overseas in the UK, Canada, the United States, and some parts of Europe, South Africa, Australia and South East Asia. They are often mass-produced under large production banners, with companies like Balaji Telefilms running different language versions of the same serial on different television networks or channels.

The Australian serial "The Restless Years" was remade in the Netherlands as "Goede tijden, slechte tijden" (which debuted in 1990) and in Germany as "Gute Zeiten, schlechte Zeiten" (which has aired since 1992): both titles translate to "good times, bad times". These remakes are still airing, but have long since diverged from the original Australian storylines. The two shows are the highest-rated soap operas in their respective countries.

A later Australian serial, "Sons and Daughters", has inspired five remakes produced under license from the original producers and based, initially, on original story and character outlines. These are "Verbotene Liebe" (Germany, 1995–2015); "Skilda världar" (Sweden, 1996–2002); "Apagorevmeni agapi" (Greece, 1998); "Cuori Rubati" (Italy, 2002–2003) and "Zabranjena ljubav" (Croatia, 2004–2008). Both "The Restless Years" and "Sons and Daughters" were created and produced in Australia by the Reg Grundy Organisation.

Another Australian soap opera reformatted for a European audience was "E Street" which ran on Network Ten in Australia from 1989 to 1993. Germany produced 37 episodes of "Westerdeich" ("Westside") in 1995 using scripts from 1989 episodes of "E Street". It was also remade in Belgium as "Wittekerke" ("Whitechurch") and ran from 1993 to 2008.

The Norwegian soap opera "Hotel Cæsar" aired on TV 2 from 1998 to 2017, and is the longest-running television drama in Scandinavia. Popular foreign soaps in the country include "Days of Our Lives" (broadcast on TV6 (Norway), "The Bold and the Beautiful" (TNT (Norway) and "Home and Away" (TV 2), all of which are subtitled.

Serials have included "Goede tijden, slechte tijden" (1990–present), "Onderweg naar Morgen" (1994–2010) and "Goudkust" (1996–2001). In 2016 "Goede tijden, slechte tijden" spin-off "Nieuwe Tijden" started airing. U.S. daytime serials "As The World Turns" and "The Bold and the Beautiful" have aired in the Netherlands; "As the World Turns" began airing in the country in 1990, with Dutch subtitles.

In the 1980s, West German networks successfully added American daytime and primetime soap operas to their schedule before Das Erste introduced its first self-produced weekly soap with "Lindenstraße", which was seen as a German counterpart to "Coronation Street". Like in other countries, the soap opera met with negative reviews, but eventually proved critics wrong with nearly 13 million viewers tuning in each week. Even though the format proved successful, it was not until 1992 before "Gute Zeiten, schlechte Zeiten" became the first German daily soap opera. Early ratings were bad as were the reviews, but the RTL network was willing to give its first soap opera a chance; ratings would improve, climbing to 7 million viewers by 2002. Not long after "Gute Zeiten, schlechte Zeiten", Das Erste introduced "Marienhof", which aired twice a week.

After successfully creating the first German daily soap, production company Grundy Ufa wanted to produce another soap for RTL. Like "GZSZ", the format was based on an Australian soap opera from Reg Watson. But RTL did not like the plot idea about separated twins who meet each other for the first time after 20 years and fall in love without knowing that they are related. The project was then taken to Das Erste, which commissioned the program, titled "Verbotene Liebe", which premiered on January 2, 1995. With the premiere of "Verbotene Liebe", the network turned "Marienhof" into a daily soap as well. In the meanwhile, RTL debuted the Grundy Ufa-produced "Unter uns" in late 1994.

ZDF started a business venture with Canada and co-produced the short-lived series "Family Passions", starring actors such as Gordon Thomson, Roscoe Born, Dietmar Schönherr and a young Hayden Christensen. The daytime serial premiered on December 5, 1994, lasting 130 episodes. After its cancellation, the network debuted "Jede Menge Leben". Even after a crossover with three soaps, "Freunde fürs Leben", "Forsthaus Falkenau" and "Unser Lehrer Doktor Specht", the soap was canceled after 313 episodes. Sat.1 tried to get into the soap business as well, after successfully airing the Australian soap opera "Neighbours", which was dropped in 1995 due to the talk show phenomenon that took over most of the daytime schedules of German networks. The network first tried to tell a family saga with "So ist das Leben! Die Wagenfelds", before failing with "Geliebte Schwestern". RTL II made its own short-lived attempt with "Alle zusammen – jeder für sich".

The teen soap opera "Schloss Einstein" debuted on September 4, 1998, focusing on the life of a group of teenagers at the fictional titular boarding school near Berlin. As of July 2014, the series has produced over 815 episodes during the course of 17 seasons, a milestone in German television programming, and was renewed for an 18th season to debut in 2015.

In 1999, after the lasting success of "Gute Zeiten, schlechte Zeiten", "Marienhof", "Unter uns" and "Verbotene Liebe", ProSieben aired "Mallorca – Suche nach dem Paradies", set on the Spanish island with the same name. After nine months, the network canceled the program due to low viewership and high production costs. Even though ratings had improved, the show ended its run in a morning timeslot. The soap opera became something of a cult classic, as its 200-episode run was repeated several times on free-to-air and pay television.

In 2006, "Alles was zählt" became the last successful daily soap to make its debut, airing as a lead-in to "Gute Zeiten, schlechte Zeiten" and also produced by Grundy Ufa. Since Germany started to produce its own telenovelas, all soap operas faced declines in ratings. "Unter uns" was in danger of cancellation in 2009, but escaped such a fate due to budget cuts imposed by the show's producers and the firing of original cast member Holger Franke, whose firing and the death of his character outraged fans, resulting in a ratings spike in early 2010. After "Unter uns" was saved, Das Erste planned to make changes to its soap lineup. "Marienhof" had to deal with multiple issues in its storytelling, as well as in producing a successful half-hour show. Several changes were made within months, however "Marienhof" was canceled in June 2011. "Verbotene Liebe" was in danger of being cancelled as well, but convinced the network to renew it with changes that it made in both 2010 and 2011; the soap was later expanded to 45 minutes after "Marienhof" was canceled, and the network tried to decide on whether to revamp its lineup.

While "Gute Zeiten, schlechte Zeiten", "Unter uns" and "Alles was zählt" are currently the only daily soaps on the air after "Verbotene Liebe" has been cancelled and aired its last episode in June, 2015 due to low ratings, the telenovelas "Sturm der Liebe" and "Rote Rosen" are considered soaps by the press as well, thanks to the changing protagonists every season.

In Belgium, the two major soap operas are "Thuis" ("Home") and "Familie" ("Family"). Soap operas have been very popular in Flanders, the Dutch-speaking part of Belgium. "Familie" debuted in late 1991, and with nearly 6,000 half-hour episodes, it has the highest episode total of any soap in Europe outside of the United Kingdom. The highest-rated soap opera is "Thuis", which has aired on "één" since late 1995. "Thuis" is often one of the five most-watched Belgian shows and regularly garners over one million viewers (with 6.3 million Flemmings in total).

During the 1990s, foreign soap operas such as "Neighbours" and "The Bold and the Beautiful" were extremely popular, the latter having achieved a cult status in Belgium and airing in the middle of the decade during prime time. Both soaps still air today, along with other foreign soaps such as "Days of Our Lives", Australia's "Home and Away" and Germany's "Sturm der Liebe". Vitaya unsuccessful attempted to air the Dutch soap opera "Goede Tijden, Slechte Tijden" in 2010. Other foreign soaps that previously aired on Belgian television include "The Young and the Restless", "EastEnders" (both on VTM), "Port Charles" (at één, then known as TV1) and "Coronation Street" (on Vitaya). "Santa Barbara" aired during the 1990s on VTM for its entire run.

The only teen soap opera on Belgian television was "Spring" ("Jump" in English), which aired on the youth-oriented Ketnet and produced over 600 15-minute episodes from late 2002 until 2009, when it was cancelled after a steady decline in ratings following the departures of many of its original characters.

The most successful soap opera in Italy is the evening series "Un posto al sole" ("A Place Under the Sun"), which had aired on Rai 3 since 1996 (whose format is based on the Australian soap opera "Neighbours"). Several other Italian soaps have been produced such as "Ricominciare" ("Starting Over"), "Cuori rubati" ("Stolen Hearts"), "Vivere" ("Living"), "Sottocasa" ("Downstairs"), "Agrodolce" ("Bittersweet") and "Centovetrine" ("Hundred Shop Windows").

The most popular Italian prime-time soap opera, "Incantesimo" ("Enchantment"), which ran from 1998 to 2008, became a daytime soap opera for the final two years of its run, airing five days a week on Rai 1. The same happened with "Il paradiso delle signore" ("Woman's Paradise"), a period drama, which ran from 2015 to 2017 in prime-time, and became a daytime period soap opera from 2018.

In the early years of RTÉ, the network produced several dramas but had not come close to launching a long-running serial. RTÉ's first television soap was "Tolka Row", which was set in urban Dublin. For several years, both "Tolka Row" and "The Riordans" were produced by RTÉ; however, the urban soap was soon dropped in favor of the more popular rural soap opera "The Riordans", which premiered in 1965. Executives from Yorkshire Television visited during on-location shoots for "The Riordans" in the early 1970s and in 1972, debuted "Emmerdale Farm" (now "Emmerdale"), based on the successful format of the Irish soap opera. In the late 1970s, "The Riordans" was controversially dropped. The creator of that series would then go on to produce the second of his "Agri-soap" trilogy "Bracken", starring Gabriel Byrne, whose character had appeared in the last few seasons of "The Riordans". Bracken was soon replaced by the third "Agri-soap" "Glenroe", which ran until 2001. As RTÉ wanted a drama series for its Sunday night lineup rather than a soap opera, "On Home Ground" (2001–2002), "The Clinic" (2002–2009) and "RAW" (2010–2013) replaced the agri-soaps of the previous decades.

In 1989, RTÉ decided to produce its first Dublin-based soap opera since the 1960s. "Fair City", which is set in the fictional city of Carrickstown, initially aired one night a week during the 1989–90 season, and similar to its rural soaps, much of the footage was filmed on location – in a suburb of Dublin City. In 1992, RTÉ made a major investment into the series by copying the houses used in the on-location shoots for an on-site set in RTÉ's Headquarters in Dublin 4. By the early 1990s, it was airing two nights a week for 35 weeks a year. With competition from the UK soap operas, RTÉ expanded "Fair City" to three nights a week for most of the year and one night a week during the summer in 1996, later expanding to four nights a week and two nights during the summer. Until the early 2000s, the series produced four episodes a week, airing all 52 weeks of the year. "Fair City" airs Sundays, Tuesdays and Thursdays at 8.00 p.m. GMT on RTÉ One; however, after rival network TV3 moved "Coronation Street" to Thursday night, the Wednesday night episode of "Fair City" began airing at 7:30 p.m. each week.

TG4 produce the Irish language soap "Ros na Rún" ("Headland of the Secrets" or "Headland of the Sweethearts"); set in the fictional village of "Ros Na Rún", located outside Galway and near Spiddal, it centres on the domestic and professional lives of the town's residents. It is modeled on an average village in the West of Ireland, but with its own distinct personality – with a diverse population that share secrets, romances and friendships among other things. While the core community has remained the same, the look and feel of "Ros Na Rún" has changed and evolved over the years to incorporate the changing face of rural Ireland. It has an established a place not only in the hearts and minds of the Irish speaking public, but also the wider Irish audience. The program has dealt with many topics, including domestic violence, infidelity, theft, arson, abortion, homosexuality, adoption, murder, rape, drugs, teen pregnancy and paedophilia. It runs twice a week for 35 weeks of the year, currently airing Tuesday and Thursday nights. "Ros na Rún" is the single largest independent production commissioned in the history of Irish broadcasting. Prior to TG4's launch, it originally aired on RTÉ One in the early 1990s.

Although Ireland has access to international soaps (such as "Coronation Street", "Emmerdale", "EastEnders", "Home and Away", "Hollyoaks" and "Neighbours"), "Fair City" continues to outperform them all, and is Ireland's most popular soap opera, with the show peaking at over 700,000 viewers.

January 2015 "Red Rock" has broadcast on TV3. Red Rock airs twice a week on Wednesday and Thursday nights. The series is base in a fishing village in Dublin. The soaps centres around the local Garda station but also includes stories from the village.

RTÉ Radio produced its first radio soap, "Kennedys of Castleross", which ran from April 13, 1955 to 1975. In 1979 RTÉ long running TV soap The Riordans moved to Radio until December 24, 1985. In the mid-1980s, RTÉ debuted a new radio soap, "Harbour Hotel", which ran until the mid-1990s. The network later ran two short-lived radio soaps, "Konvenience Korner" and "Riverrun", which were followed in 2004 by "Driftwood". RTÉ does not run any radio soaps, however RTÉ Radio 1 continues to air radio dramas as part of its nighttime schedule.


In Greece, there have been several soap operas.

An early serial was "Sti skia tou hrimatos" ("Money Shadows"), which ran from 1990 to 1991. September 1991 saw the debut of "Lampsi" ("the Shining"), from creator Nicos Foskolos. The series would become Greece's longest-running soap opera. After the success of "Lampsi" came the short lived "To galazio diamandi" ("Blue Diamond") and "Simphonia siopis" ("Omertà"). "Lampsi" was canceled in June 2005 due to declining ratings. It was replaced by "Erotas" ("Love"), a soap that ran from 2005 to 2008. After that series ended, ANT1 abandoned the soap opera genre and focused on comedy series and weekly dramas.

Greece's second longest-running soap is "Kalimera Zoi" ("Goodmorning Life"), which ran from September 1993 until its cancellation in June 2006 due to low ratings.

Mega Channel began producing soap operas in 1990 with the prime time serial "I Dipsa" ("The Thirst"), which ran for 102 episodes. Other daytime soaps have included "Paralliloi dromoi" (1992–1994) and its successor "Haravgi" ("Daylight", 1994–1995), both of which were cancelled due to low viewership; as well as the serials "Apagorevmeni Agapi" ("Forbidden Love"), which ran from 1998 to 2006; "Gia mia thesi ston Ilio" ("A Spot Under the Sun"), which ran from 1998 to 2002; "Filodoxies" ("Expectations"), which ran from 2002 to 2006; and "Vera Sto Deksi" ("Ring on the Right Hand"), which ran from 2004 to 2006 and proved to be a successful competitor to "Lampsi", causing that show's ratings to decline.

"Ta Mistika Tis Edem" ("Edem Secrets"), which was created by the producers of "Vera Sto Deksi", debuted in 2008 and has eclipsed that show's success. Its ratings place it consistently among the three highest-rated daytime programs.

IENED (which was renamed ERT2 in 1982) was responsible for the first Greek soap operas "I Kravgi Ton Likon" and "Megistanes". ERT also produced the long-running soap "O Simvoleografos". Since 2000 and with the introduction of private television, ERT produced additional daily soap operas, which included "Pathos" ("Passion"), "Erotika tis Edem" ("Loving in Eden") and "Ta ftera tou erota" ("The Wings of Love"). These failed to achieve high ratings and were canceled shortly after their premiere.

Alpha produced "Kato apo tin Acropoli" ("Under the Acropolis"), which ran for 2½ years.

The first daytime soap opera produced by a Cyprus channel was LOGOs TV's "Odos Den Ksehno" ("'Don't Forget' Street"), which ran from January to December 1996. It was followed by "To Serial", which also ran for one year from September 1997 to June 1998. CyBC created the third weekdaily soap, "Anemi Tou Pathous" ("Passion Winds"), running from January 2000 to June 2004, which was replaced by "I Platia" ("The Square") from September 2004 to July 2006. "Epikindini Zoni" ran from 2009 to 2010, and was cancelled after 120 episodes. "Vimata Stin Ammo" made its debut in September 2010.

Sigma TV first commissioned the weekdaily comedic soap "Sto Para Pente", which aired from September 1998 to June 2004, and was the longest weekday show in Cyprus television history, before it was surpassed by "Se Fonto Kokkino", which ran from September 2008 to July 2012. Other Sigma TV weekday shows include "Akti Oniron" (which ran from 1999 to 2001), "Vourate Geitonoi" (which ran from 2001 to 2005, and was the most successful weekdaily series, achieving ratings shares of up to 70% of all television households in the country), "Oi Takkoi" (which ran from 2002 to 2005), "S' Agapo" (which ran from 2001 to 2002), "Vasiliki" (which ran from 2005 to 2006), "Vendetta" (which ran from September 2005 to December 2006), "30 kai Kati" (which ran from 2006 to 2007) and "Mila Mou" (which ran from September 2007 to January 2009).

ANT1 Cyprus aired the soap "I Goitia Tis Amartias" in 2002, which was soon canceled. "Dikse Mou To Filo Sou" followed from 2006 to 2009, along with "Gia Tin Agapi Sou", which ran from 2008 to 2009 and itself was followed by "Panselinos", which has aired since 2009.

The longest-running weekly show on Cyprus television is "Istories Tou Horkou" ("Villages Stories", which premiered on CyBC in March 1996 and ran until its cancellation in June 2006; it was revived in September 2010 but was cancelled again in March 2011 due to very low ratings), followed by "Manolis Ke Katina" ("Manolis and Katina", which ran from 1995 to 2004). The most controversial of these series was "To Kafenio" ("The Coffee Shop"), which premiered on CyBC on 1993 as a weekly series, before moving to MEGA Channel Cyprus six years later in 1999 as a weekdaily show and then moved to ANT1 Cyprus on 2000, which canceled the show one year later. There were plans to move the show back to CyBC as a weekly series in 2001, with the original cast, however this plan was never realised. The most successful weekly shows in Cyprus currently are ANT1's "Eleni I Porni" ("Eleni, The Whore"), which premiered in October 2010 and CyBC's "Stin Akri Tu Paradisou" ("At The Heaven's Edge"), which premiered in 2007. The most successful weekdaily soap was "Aigia Fuxia", which aired on ANT1 Cyprus from 2008 to 2010.

The only daily Finnish soap opera so far is "Salatut elämät" ("Secret Lives"), which has achieved popularity in Finland since its 1999 debut on MTV3. It focuses on the lives of people along the imaginary Pihlajakatu street in Helsinki. The show has also spawned several Internet spin-off series and a film based on the show that was released in 2012.

Other soap-like shows in Finland are YLE shows "Uusi päivä" (which has aired since 2009) and "Kotikatu" (which ran from 1995 to 2012), however these programs do not adhere to a five-episode-a-week schedule.

With the advent of internet television and mobile phones, several soap operas have also been produced specifically for these platforms, including "", a spin-off of the established "EastEnders". For those produced only for the mobile phone, episodes may generally consist of about six or seven pictures and accompanying text.

On September 13, 2011, TG4 launched a new 10-part online series titled, "Na Rúin" (an Internet spin-off of "Ros na Rún"). The miniseries took on the theme of a mystery; the viewer had to read Rachel and Lorcán's blogs as well as watch video diaries detailing each character's thoughts to solve the mystery of missing teenage character Ciara.

In motion pictures, the 1982 comedy "Tootsie" has the lead character impersonating a woman in order to gain acting work on a long running television soap opera. Several scenes parody the production of soaps, their outrageous storylines and idiosyncratic stylistic elements.

The 1991 comedy "Soapdish" stars Sally Field as an aging soap opera actress on the fictional series "The Sun Also Sets" who pines over her own neuroses and misfortunes, such as her live-in boyfriend who leaves her to go back to his wife, and the incidents of backstabbing and scheming behind the scenes, some of which are more interesting than the stories on the program.

Another 1991 comedy, "Delirious", stars John Candy as a soap opera writer who, after a head injury, has a dream experience of being in his own creation. The dream experience is an increasingly outrageous exaggeration of soap opera plot elements.

On television, several soap opera parodies have been produced:



</doc>
<doc id="27010" url="https://en.wikipedia.org/wiki?curid=27010" title="Software engineering">
Software engineering

Software engineering is the systematic application of engineering approaches to the development of software. Software engineering is a computing discipline.

When the first digital computers appeared in the early 1940s, the instructions to make them operate were wired into the machine. Practitioners quickly realized that this design was not flexible and came up with the "stored program architecture" or von Neumann architecture. Thus the division between "hardware" and "software" began with abstraction being used to deal with the complexity of computing.

Programming languages started to appear in the early 1950s and this was also another major step in abstraction. Major languages such as Fortran, ALGOL, PL/I, and COBOL were released in the late 1950 and 1960s to deal with scientific, algorithmic, and business problems respectively. David Parnas introduced the key concept of modularity and information hiding in 1972 to help programmers deal with the ever-increasing complexity of software systems.

The origins of the term "software engineering" have been attributed to various sources. The term "software engineering" appeared in a list of services offered by companies in the June 1965 issue of COMPUTERS and AUTOMATION and was used more formally in the August 1966 issue of Communications of the ACM (Volume 9, number 8) “letter to the ACM membership” by the ACM President Anthony A. Oettinger, it is also associated with the title of a NATO conference in 1968 by Professor Friedrich L. Bauer, the first conference on software engineering. Independently, Margaret Hamilton named the discipline "software engineering" during the Apollo missions to give what they were doing legitimacy. At the time there was perceived to be a "software crisis". The 40th International Conference on Software Engineering (ICSE 2018) celebrates 50 years of "Software Engineering" with the Plenary Sessions' keynotes of Frederick Brooks and Margaret Hamilton.

In 1984, the Software Engineering Institute (SEI) was established as a federally funded research and development center headquartered on the campus of Carnegie Mellon University in Pittsburgh, Pennsylvania, United States. Watts Humphrey founded the SEI Software Process Program, aimed at understanding and managing the software engineering process. The Process Maturity Levels introduced would become the Capability Maturity Model Integration for Development(CMMI-DEV), which has defined how the US Government evaluates the abilities of a software development team.

Modern, generally accepted best-practices for software engineering have been collected by the ISO/IEC JTC 1/SC 7 subcommittee and published as the Software Engineering Body of Knowledge (SWEBOK).

Notable definitions of software engineering include:

The term has also been used less formally:

Requirements engineering is about the elicitation, analysis, specification, and validation of requirements for software.

Software design is about the process of defining the architecture, components, interfaces, and other characteristics of a system or component. This is also called Software architecture.

Software development, the main activity of software construction: is the combination of programming (aka coding), verification, software testing, and debugging. A Software development process: is the definition, implementation, assessment, measurement, management, change, and improvement of the software life cycle process itself. It heavily uses Software configuration management which is about systematically controlling changes to the configuration, and maintaining the integrity and traceability of the configuration and code throughout the system life cycle. Modern processes use software versioning.

Software testing: is an empirical, technical investigation conducted to provide stakeholders with information about the quality of the product or service under test, with different approaches such as unit testing and integration testing. It is one aspect of software quality.

Software maintenance: refers to the activities required to provide cost-effective support after shipping the software product.

Knowledge of computer programming is a prerequisite for becoming a software engineer. In 2004 the IEEE Computer Society produced the SWEBOK, which has been published as ISO/IEC Technical Report 1979:2004, describing the body of knowledge that they recommend to be mastered by a graduate software engineer with four years of experience.
Many software engineers enter the profession by obtaining a university degree or training at a vocational school. One standard international curriculum for undergraduate software engineering degrees was defined by the Joint Task Force on Computing Curricula of the IEEE Computer Society and the Association for Computing Machinery, and updated in 2014. A number of universities have Software Engineering degree programs; , there were 244 Campus Bachelor of Software Engineering programs, 70 Online programs, 230 Masters-level programs, 41 Doctorate-level programs, and 69 Certificate-level programs in the United States.

In addition to university education, many companies sponsor internships for students wishing to pursue careers in information technology. These internships can introduce the student to interesting real-world tasks that typical software engineers encounter every day. Similar experience can be gained through military service in software engineering.

Legal requirements for the licensing or certification of professional software engineers vary around the world. In the UK, there is no licensing or legal requirement to assume or use the job title Software Engineer. In some areas of Canada, such as Alberta, British Columbia, Ontario, and Quebec, software engineers can hold the Professional Engineer (P.Eng) designation and/or the Information Systems Professional (I.S.P.) designation. In Europe, Software Engineers can obtain the European Engineer (EUR ING) professional title.

The United States, since 2013, has offered an "NCEES" "Professional Engineer" exam for Software Engineering, thereby allowing Software Engineers to be licensed and recognized. NCEES will end the exam after April 2019 due to lack of participation. Mandatory licensing is currently still largely debated, and perceived as controversial. In some parts of the US such as Texas, the use of the term Engineer is regulated by law and reserved only for use by individuals who have a Professional Engineer license.

The IEEE Computer Society and the ACM, the two main US-based professional organizations of software engineering, publish guides to the profession of software engineering. The IEEE's "Guide to the Software Engineering Body of Knowledge – 2004 Version", or SWEBOK, defines the field and describes the knowledge the IEEE expects a practicing software engineer to have. The most current SWEBOK v3 is an updated version and was released in 2014. The IEEE also promulgates a "Software Engineering Code of Ethics".

The U. S. Bureau of Labor Statistics counted 1,365,500 software developers holding jobs in the U.S. in 2018. Employment of computer and information technology occupations is projected to grow 13 percent from 2016 to 2026, faster than the average for all occupations. These occupations are projected to add about 557,100 new jobs. Demand for these workers will stem from greater emphasis on cloud computing, the collection and storage of big data, and information security. Yet, the BLS also says some employment in these occupations are slowing, especially for women, and computer programmers is projected to decline 7 percent from 2016 to 2026 since computer programming can be done from anywhere in the world, so companies sometimes hire programmers in countries where wages are lower. Due to its relative newness as a field of study, formal education in software engineering is often taught as part of a computer science curriculum, and many software engineers hold computer science degrees.

Many software engineers work as employees or contractors. Software engineers work with businesses, government agencies (civilian or military), and non-profit organizations. Some software engineers work for themselves as freelancers. Some organizations have specialists to perform each of the tasks in the software development process. Other organizations require software engineers to do many or all of them. In large projects, people may specialize in only one role. In small projects, people may fill several or all roles at the same time. Specializations include: in industry (analysts, architects, developers, testers, technical support, middleware analysts, managers) and in academia (educators, researchers).

Most software engineers and programmers work 40 hours a week, but about 15 percent of software engineers and 11 percent of programmers worked more than 50 hours a week in 2008. Potential injuries in these occupations are possible because like other workers who spend long periods sitting in front of a computer terminal typing at a keyboard, engineers and programmers are susceptible to eyestrain, back discomfort, and hand and wrist problems such as carpal tunnel syndrome.

The Software Engineering Institute offers certifications on specific topics like security, process improvement and software architecture. IBM, Microsoft and other companies also sponsor their own certification examinations. Many IT certification programs are oriented toward specific technologies, and managed by the vendors of these technologies. These certification programs are tailored to the institutions that would employ people who use these technologies.

Broader certification of general software engineering skills is available through various professional societies. , the IEEE had certified over 575 software professionals as a Certified Software Development Professional (CSDP). In 2008 they added an entry-level certification known as the Certified Software Development Associate (CSDA). The ACM had a professional certification program in the early 1980s, which was discontinued due to lack of interest. The ACM examined the possibility of professional certification of software engineers in the late 1990s, but eventually decided that such certification was inappropriate for the professional industrial practice of software engineering.

In the U.K. the British Computer Society has developed a legally recognized professional certification called "Chartered IT Professional (CITP)", available to fully qualified members ("MBCS"). Software engineers may be eligible for membership of the Institution of Engineering and Technology and so qualify for Chartered Engineer status. In Canada the Canadian Information Processing Society has developed a legally recognized professional certification called "Information Systems Professional (ISP)". In Ontario, Canada, Software Engineers who graduate from a "Canadian Engineering Accreditation Board (CEAB)" accredited program, successfully complete PEO's ("Professional Engineers Ontario") Professional Practice Examination (PPE) and have at least 48 months of acceptable engineering experience are eligible to be licensed through the "Professional Engineers Ontario" and can become Professional Engineers P.Eng. The PEO does not recognize any online or distance education however; and does not consider Computer Science programs to be equivalent to software engineering programs despite the tremendous overlap between the two. This has sparked controversy and a certification war. It has also held the number of P.Eng holders for the profession exceptionally low. The vast majority of working professionals in the field hold a degree in CS, not SE. Given the difficult certification path for holders of non-SE degrees, most never bother to pursue the license.

The initial impact of outsourcing, and the relatively lower cost of international human resources in developing third world countries led to a massive migration of software development activities from corporations in North America and Europe to India and later: China, Russia, and other developing countries. This approach had some flaws, mainly the distance / time zone difference that prevented human interaction between clients and developers and the massive job transfer. This had a negative impact on many aspects of the software engineering profession. For example, some students in the developed world avoid education related to software engineering because of the fear of offshore outsourcing (importing software products or services from other countries) and of being displaced by foreign visa workers. Although statistics do not currently show a threat to software engineering itself; a related career, computer programming does appear to have been affected. Nevertheless, the ability to smartly leverage offshore and near-shore resources via the follow-the-sun workflow has improved the overall operational capability of many organizations. When North Americans are leaving work, Asians are just arriving to work. When Asians are leaving work, Europeans are arriving to work. This provides a continuous ability to have human oversight on business-critical processes 24 hours per day, without paying overtime compensation or disrupting a key human resource, sleep patterns.

While global outsourcing has several advantages, global – and generally distributed – development can run into serious difficulties resulting from the distance between developers. This is due to the key elements of this type of distance that have been identified as geographical, temporal, cultural and communication (that includes the use of different languages and dialects of English in different locations). Research has been carried out in the area of global software development over the last 15 years and an extensive body of relevant work published that highlights the benefits and problems associated with the complex activity. As with other aspects of software engineering research is ongoing in this and related areas.

Software engineering sees its practitioners as individuals who follow well-defined engineering approaches to problem-solving. These approaches are specified in various software engineering books and research papers, always with the connotations of predictability, precision, mitigated risk and professionalism. This perspective has led to calls for licensing, certification and codified bodies of knowledge as mechanisms for spreading the engineering knowledge and maturing the field.

Software engineering extends engineering and draws on the engineering model, i.e. engineering process, engineering project management, engineering requirements, engineering design, engineering construction, and engineering validation. The concept is so new that it is rarely understood, and it is widely misinterpreted, including in software engineering textbooks, papers, and among the communities of programmers and crafters.

One of the core issues in software engineering is that its approaches are not empirical enough because a real-world validation of approaches is usually absent, or very limited and hence software engineering is often misinterpreted as feasible only in a "theoretical environment."

Edsger Dijkstra, the founder of many of the concepts used within software development today, rejected the idea of "software engineering" up until his death in 2002, arguing that those terms were poor analogies for what
he called the "radical novelty" of computer science:





</doc>
<doc id="27011" url="https://en.wikipedia.org/wiki?curid=27011" title="Software Engineering Institute">
Software Engineering Institute

The Software Engineering Institute (SEI) is an American research and development center headquartered in Pittsburgh, Pennsylvania. Its activities cover cybersecurity, software assurance, software engineering and acquisition, and component capabilities critical to the Department of Defense.

The Carnegie Mellon Software Engineering Institute is a federally funded research and development center headquartered on the campus of Carnegie Mellon University in Pittsburgh, Pennsylvania, United States. The SEI also has offices in Washington, DC and Los Angeles, California. The SEI operates with major funding from the U.S. Department of Defense. The SEI also works with industry and academia through research collaborations.

On November 14, 1984, the U.S. Department of Defense elected Carnegie Mellon University as the host site of the Software Engineering Institute. The institute was founded with an initial allocation of $6 million, with another $97 million to be allocated in the subsequent five years. The SEI's contract with the Department of Defense is subject to review and renewal every five years.

The SEI program of work is conducted in several principal areas: cybersecurity, software assurance, software engineering and acquisition, and component capabilities critical to the Department of Defense.

The SEI defines specific initiatives aimed at improving organizations' software engineering capabilities.

Organizations need to effectively manage the acquisition, development, and evolution (ADE) of software-intensive systems. Success in software engineering management practices helps organizations predict and control quality, schedule, cost, cycle time, and productivity. The best-known example of SEI in management practices is the SEI's Capability Maturity Model (CMM) for Software (now Capability Maturity Model Integration (CMMI)). The CMMI approach consists of models, appraisal methods, and training courses that have been proven to improve process performance. In 2006, Version 1.2 of the CMMI Product Suite included the release of CMMI for Development. CMMI for Development was the first of three constellations defined in Version 1.2: the others include CMMI for Acquisition and CMMI for Services. The CMMI for Services constellation was released in February 2009. Another management practice developed by CERT, which is part of the SEI, is the Resilience Management Model (CERT-RMM). The CERT-RMM is a capability model for operational resilience management. Version 1.0 of the Resilience Management Model was released in May 2010.

SEI work in engineering practices increases the ability of software engineers to analyze, predict, and control selected
functional and non-functional properties of software systems. Key SEI tools and methods include the SEI Architecture Tradeoff Analysis Method (ATAM) method, the SEI Framework for Software Product Line Practice, and the SEI Service Migration and Reuse Technique (SMART).

The SEI is also the home of the CERT/CC (CERT Coordination Center), a federally funded computer security organization. The SEI CERT Program's primary goals are to ensure that appropriate technology and systems-management practices are used to resist attacks on networked systems and to limit damage and ensure continuity of critical services in spite of successful attacks, accidents, or failures. The SEI CERT program is working with US-CERT to produce the Build Security In (BSI) website, which provides guidelines for building security into every phase of the software development lifecycle. The SEI has also conducted research on insider threats and computer forensics. Results of this research and other information now populate the CERT Virtual Training Environment.

Carnegie Mellon, Capability Maturity Model, CMM, CMMI, Architecture Tradeoff Analysis Method, ATAM, and CERT are registered in the U.S. Patent and Trademark Office by Carnegie Mellon University.

The SEI Partner Network helps the SEI disseminate software engineering best practices. Organizations and individuals in the SEI Partner Network are selected, trained, and licensed by the SEI to deliver authentic SEI services, which include courses, consulting methods, and management processes. The network currently consists of nearly 250 partner organizations worldwide.

The SEI sponsors national and international conferences, workshops, and user-group meetings. Other events cover subjects including acquisition of software-intensive systems, commercial off-the-shelf (COTS)-based systems, network security and survivability, software process research, software product lines, CMMI, and the SEI Team Software Process.

SEI courses are currently offered at the SEI's locations in the United States and Europe. In addition, using licensed course materials, SEI Partners train individuals.

The SEI Membership Program helps the software engineering community to network. SEI Members include small business owners, software and systems programmers, CEOs, directors, and managers from both Fortune 500 companies and government organizations

Through the SEI Affiliate Program, organizations place technical experts with the SEI for periods ranging from 12 months to four years. Affiliates currently are working on projects with the SEI to identify, develop, and demonstrate improved software engineering practices.

In order to recognize outstanding achievement in improving an organization's ability to create and evolve software-dependent systems, the SEI and IEEE Computer Society created the Software Process Achievement Award program. In addition to rewarding excellence, the purpose of this award is to foster continuous advancement in the practice of software engineering and to disseminate insights, experiences, and proven practices throughout the relevant research and practitioner communities.

The SEI publishes reports that offer new technical information about software engineering topics, whether theoretical or applied. The SEI also publishes books on software engineering for industry, government and military applications and practices.

In addition, the SEI offers public courses, workshops, and conferences in process improvement, software architecture and product lines, and security.

On November 11, 2015, the head of the Tor Project accused the Software Engineering Institute of aiding Federal Bureau of Investigation in uncovering the identities of users of the Tor network. Later prosecution showed the hack was paid for by the Department of Defense and subpoena by the FBI.

SEI has been an occasional site of anti-war movement and peace movement protests, many of which have been organized by Pittsburgh's Thomas Merton Center.




</doc>
<doc id="27012" url="https://en.wikipedia.org/wiki?curid=27012" title="Software crisis">
Software crisis

Software crisis is a term used in the early days of computing science for the difficulty of writing useful and efficient computer programs in the required time. The software crisis was due to the rapid increases in computer power and the complexity of the problems that could now be tackled. With the increase in the complexity of the software, many software problems arose because existing methods were inadequate.

The term "software crisis" was coined by some attendees at the first NATO Software Engineering Conference in 1968 at Garmisch, Germany. Edsger Dijkstra's 1972 ACM Turing Award Lecture makes reference to this same problem:
The causes of the software crisis were linked to the overall complexity of hardware and the software development process. The crisis manifested itself in several ways:

The main cause is that improvements in computing power had outpaced the ability of programmers to effectively utilize those capabilities. Various processes and methodologies have been developed over the last few decades to improve software quality management such as procedural programming and object-oriented programming. However software projects that are large, complicated, poorly specified, and involve unfamiliar aspects, are still vulnerable to large, unanticipated problems.




</doc>
<doc id="27013" url="https://en.wikipedia.org/wiki?curid=27013" title="Swedish Academy">
Swedish Academy

The Swedish Academy (), founded in 1786 by King Gustav III, is one of the Royal Academies of Sweden. Its 18 members, who are elected for life, comprise the highest Swedish language authority. Outside Scandinavia, it is best known as the body that chooses the laureates for the annual Nobel Prize in Literature, awarded in memory of the donor Alfred Nobel.

The Swedish Academy was founded in 1786 by King Gustav III. Modelled after the Académie française, it has 18 members. It is said that Gustaf III originally intended there to be twenty members, half the number of those in the French Academy, but eventually decided on eighteen because the Swedish expression "De Aderton" – 'The Eighteen' – had such a fine solemn ring. The academy's motto is "Talent and Taste" (""Snille och Smak"" in Swedish). The academy's primary purpose is to further the "purity, strength, and sublimity of the Swedish language" (""Svenska Språkets renhet, styrka och höghet"") (Walshe, 1965). To that end the academy publishes two dictionaries. The first is a one-volume glossary called "Svenska Akademiens ordlista" ("SAOL"). The second is a multi-volume dictionary, edited on principles similar to those of the "Oxford English Dictionary", entitled "Svenska Akademiens Ordbok" ("SAOB"). The "SAOL" has reached its 14th edition while the first volume of the "SAOB" was published in 1898 and, as of 2017, work has progressed to words beginning with the letter "V".

The building now known as the Stockholm Stock Exchange Building was built for the bourgeoisie. The bottom floor was used as a trading exchange (this later became the stock exchange), and the upper floor was used for balls, New Year's Eve parties, etc. When the academy was founded, the ballroom was the biggest room in Stockholm that could be heated and thus used in the winter, so the King asked if he could borrow it.

The academy has had its annual meeting there every year since, attended by members of the Swedish royal family. However, it was not until 1914 that the academy gained permanent use of the upper floor as their own. It is here that the academy meets and, amongst other business, announces the names of Nobel Prize laureates. This task arguably makes the academy one of the world's most influential literary bodies.

Members are elected by a secret ballot in the Academy and before the result is made public it must be submitted to the Academy's Patron, the King of Sweden, for his approval. Members of the Academy include writers, linguists, literary scholars, historians and a prominent jurist. Initially writers were in the minority in the Academy, but during the twentieth century the number of writers grew to represent more than half of The Eighteen. The Swedish Academy have a long history of being a heavily male dominated institution, but the Academy has recently moved towards better equality. Since 20 December 2019 one third of the chairs belong to female Academy members. 

Prior to 2018 it was not possible for members of the academy to resign; membership was for life, although the academy could decide to exclude members. This happened twice to Gustaf Mauritz Armfelt, who was excluded in 1794, re-elected in 1805 and excluded again in 1811. In 1989, Werner Aspenström, Kerstin Ekman and Lars Gyllensten chose to stop participating in the meetings of the academy, over its refusal to express support for Salman Rushdie when Ayatollah Khomeini condemned him to death for "The Satanic Verses", and in 2005, Knut Ahnlund made the same decision, as a protest against the choice of Elfriede Jelinek as Nobel laureate for 2004. On 25 November 2017, Lotta Lotass said in an interview that she had not participated in the meetings of the academy for more than two years and did not consider herself a member any more.
Dag Hammarskjöld's former farm at Backåkra, close to Ystad in southern Sweden, was bought in 1957 as a summer residence by Hammarskjöld, then Secretary-General of the United Nations (1953–1961). The south wing of the farm is reserved as a summer retreat for the 18 members of the Swedish Academy, of which Hammarskjöld was a member.

On 11 April 2019, the academy published its financial statements for the first time in its history. According to it, the academy owned financial assets worth 1.58 billion Swedish kronor at the end of 2018 (equal to $170M, €150M, or £130M).

In April 2018, three members of the academy board resigned in response to a sexual-misconduct investigation involving author Jean-Claude Arnault, husband of board member Katarina Frostenson. Arnault was accused by at least 18 women of sexual assault and harassment; he denied all accusations. The three members resigned in protest over the lack of appropriate action against Arnault. Two former permanent secretaries, Sture Allén and Horace Engdahl, called the current leader, Sara Danius, a weak leader.

On 10 April, Danius resigned from her position with the academy, bringing the number of empty seats to four. Frostenson voluntarily agreed to withdraw from participating in the academy, bringing the total of withdrawals to five. Because two other seats were still vacant after the Rushdie affair, this left only 11 active members. The scandal was widely seen as damaging to the credibility of the Nobel prize in Literature and the authority of the academy. "With this scandal you cannot possibly say that this group of people has any kind of solid judgment," noted Swedish journalist Björn Wiman.

On 27 April 2018, the Swedish Economic Crime Authority opened a preliminary investigation regarding financial crime linked to an association run by Arnault and Frostenson, which had received funding from the academy.

On 2 May 2018, the Swedish King amended the rules of the academy and made it possible for members to resign. The new rules also state that a member who has been inactive in the work of the academy for more than two years can be asked to resign. Following the new rules, the first members to formally be granted permission to leave the academy and vacate their chairs were Kerstin Ekman, Klas Östergren, Sara Stridsberg and Lotta Lotass.

On 4 May 2018, the Swedish Academy announced that following the preceding internal struggles the Nobel laureate for literature selected in 2018 would be postponed until 2019, when two laureates would be selected.

Since 1901, the Swedish Academy has annually decided who will be the laureate for the Nobel Prize in Literature, awarded in memory of the donor Alfred Nobel.

The Swedish Academy annually awards nearly 50 different prizes and scholarships, most of them for domestic Swedish authors. Common to all is that they are awarded without competition and without application. The Dobloug Prize, the largest of these at $40,000, is a literature prize awarded for Swedish and Norwegian fiction.

Swedish: Stora Priset, literally the Big Prize, was instituted by King Gustav III. The prize, which consists of a single gold medal, is the most prestigious award that can be awarded by the Swedish Academy. It has been awarded to, among others, Selma Lagerlöf (1904 and 1909), Herbert Tingsten (1966), Astrid Lindgren (1971), Evert Taube (1972) and Tove Jansson (1994).

The academy awards around 50 prizes each year. A person does not have to apply nor compete for the prizes.

Full list of awards (in Swedish)

The current members of the Swedish Academy listed by seat number:





</doc>
<doc id="27014" url="https://en.wikipedia.org/wiki?curid=27014" title="Svenska Dagbladet">
Svenska Dagbladet

Svenska Dagbladet (, "The Swedish Daily News"), abbreviated SvD, is a daily newspaper published in Stockholm, Sweden.

The first issue of "Svenska Dagbladet" appeared on 18 December 1884. Ivar Anderson is among its former editors-in-chief who assumed the post in 1940.

The paper is published in Stockholm and provides coverage of national and international news as well as local coverage of the Greater Stockholm region. Its subscribers are concentrated in the capital, but it is distributed in most of Sweden. During the beginning of the 1900s the paper was one of the right-wing publications in Stockholm.

"Svenska Dagbladet" is owned by Schibsted which purchased it in the late 1990s. The stated position of the editorial page is "independently moderate" ("oberoende moderat"), which means it is independent but adheres to the liberal conservatism of the Moderate Party. Despite this position, the paper is also regarded as conservative.

In November 2000 "Svenska Dagbladet" changed its format from broadsheet to tabloid. In 2005 the paper started a Web portal for business news as a joint venture with "Aftonbladet".

Since 1925 "Svenska Dagbladet" has awarded an individual sportsperson or a team the Svenska Dagbladet Gold Medal at the end of each year.

As the only other Swedish morning newspaper to aspire to full national and international coverage, Svenska Dagbladet is the chief rival of Dagens Nyheter.

Anna Careborg was appointed acting CEO and Editor-in-chief in January 2019, taking over from Fredric Karén, who is now working with Torstar Group, owners of the Toronto Star, in Canada. 

Careborg took over fully as new CEO and Editor-in-chief of Svenska Dagbladet in October 2019.

The circulation of "Svenska Dagbladet" was 185,000 copies in 2003. The paper had a circulation of 187,100 copies on weekdays in 2005. Among Swedish morning newspapers "Svenska Dagbladet" had the third largest circulation with 195,200 copies in 2007 after "Dagens Nyheter" and "Göteborgs-Posten". In 2008 "Svenska Dagbladet" had a circulation of 123,383 copies. The circulation of the paper was 185,600 copies in 2011. It was 159,600 copies in 2012 and 143,400 copies in 2013.






</doc>
<doc id="27016" url="https://en.wikipedia.org/wiki?curid=27016" title="Sture Allén">
Sture Allén

Sture Allén (born 31 December 1928) is a retired Swedish professor of computational linguistics at the University of Gothenburg, who was the permanent secretary of the Swedish Academy between 1986 and 1999. Born in Gothenburg, he was elected to chair 3 of the Swedish Academy in 1980. He is also a member of the Norwegian Academy of Science and Letters.


 


</doc>
<doc id="27018" url="https://en.wikipedia.org/wiki?curid=27018" title="Stress">
Stress

Stress may refer to:









</doc>
<doc id="27019" url="https://en.wikipedia.org/wiki?curid=27019" title="South Korea">
South Korea

South Korea (Korean: /, RR: "Hanguk"; literally /, RR: "Namhan", or , MR: "Namchosŏn" in North Korean usage), officially the Republic of Korea (ROK; Korean: /, RR: "Daehan Minguk"), is a country in East Asia, constituting the southern part of the Korean Peninsula and sharing a land border with North Korea.

The name "Korea" is derived from Goguryeo, which was one of the great powers in East Asia during its time, ruling most of the Korean Peninsula, Manchuria, parts of the Russian Far East and Inner Mongolia under Gwanggaeto the Great. Half of South Korea's over 51 million people live in the Seoul Capital Area, the fourth largest metropolitan economy in the world.

The Korean Peninsula was inhabited as early as the Lower Paleolithic period. Its first kingdom was noted in Chinese records in the early 7th century BC. Following the unification of the Three Kingdoms of Korea into Silla and Balhae in the late 7th century, Korea was ruled by the Goryeo dynasty (918–1392) and the Joseon dynasty (1392–1897). The succeeding Korean Empire was annexed into the Empire of Japan in 1910. After World War II, Korea was divided into Soviet and U.S.-administered zones, with the latter becoming the Republic of Korea in August 1948. In 1950, a North Korean invasion began the Korean War and after its end in 1953, the country's economy began to soar, recording the fastest rise in average GDP per capita in the world between 1980 and 1990. The June Struggle led to the end of authoritarian rule in 1987 and the country is now the most advanced democracy and has the highest level of press freedom in Asia. South Korea is a member of the OECD's Development Assistance Committee, the G20 and the Paris Club. 

South Korea is a highly developed country, ranked the third highest in Asia after Singapore and Japan. It has the world's 12th-largest economy by nominal GDP. Its citizens enjoy one of the world's fastest Internet connection speeds and the most dense high-speed railway network. The country is the world's 5th largest exporter and 8th largest importer. Since the 21st century, South Korea has been renowned for its globally influential pop culture, particularly in music (K-pop), TV dramas and cinema, a phenomenon referred to as the Korean Wave.

The name "Korea" derives from the name "Goryeo". The name "Goryeo" itself was first used by the ancient kingdom of Goguryeo in the 5th century as a shortened form of its name. The 10th-century kingdom of Goryeo succeeded Goguryeo, and thus inherited its name, which was pronounced by the visiting Persian merchants as "Korea". The modern name of Koreia, appears in the first Portuguese maps of 1568 by João vaz Dourado as "Conrai" and later in the late 16th century and early 17th century as Korea (Corea) in the maps of Teixeira Albernaz of 1630.

The kingdom of "Goryeo" was first known to the westerners still by the hand of Afonso de Albuquerque when the conquest of Malacca in 1511 describing the peoples who traded with this part of the worldknown by the Portuguese as the Gores. Despite the coexistence of the spellings "Corea" and "Korea" in 19th century publications, some Koreans believe that Imperial Japan, around the time of the Japanese occupation, intentionally standardised the spelling on "Korea", making Japan appear first alphabetically.

After Goryeo was replaced by Joseon in 1392, Joseon became the official name for the entire territory, though it was not universally accepted. The new official name has its origin in the ancient kingdom of Gojoseon (2333 BC). In 1897, the Joseon dynasty changed the official name of the country from "Joseon" to "Daehan Jeguk" (Korean Empire). The name "Daehan" (Great Han) derives from Samhan (Three Han), referring to the Three Kingdoms of Korea, not the ancient confederacies in the southern Korean Peninsula. However, the name "Joseon" was still widely used by Koreans to refer to their country, though it was no longer the official name. Under Japanese rule, the two names "Han" and "Joseon" coexisted. There were several groups who fought for independence, the most notable being the "Provisional Government of the Republic of Korea" (/).

Following the surrender of Japan, in 1945, the "Republic of Korea" (/, IPA: , ; ) was adopted as the legal English name for the new country. However, it is not a direct translation of the Korean name. As a result, the Korean name "Daehan Minguk" is sometimes used by South Koreans as a metonym to refer to the Korean ethnicity (or "race") as a whole, rather than just the South Korean state.

Since the government only controlled the southern part of the Korean Peninsula, the informal term "South Korea" was coined, becoming increasingly common in the Western world. While South Koreans use "Han" (or "Hanguk") to refer to both Koreas collectively, North Koreans and ethnic Koreans living in China and Japan use the term "Joseon" instead.

The Korean Peninsula was inhabited as early as the Lower Paleolithic period. The history of Korea begins with the founding of Joseon (also known as "Gojoseon", or Old Joseon, to differentiate it with the 14th century dynasty) in 2333 BCE by Dangun, according to Korea's foundation mythology. Gojoseon was noted in Chinese records in the early 7th century. Gojoseon expanded until it controlled the northern Korean Peninsula and parts of Manchuria. Gija Joseon was purportedly founded in the 12th century BC, but its existence and role have been controversial in the modern era. In 108 BCE, the Han dynasty defeated Wiman Joseon and installed four commanderies in the northern Korean peninsula. Three of the commanderies fell or retreated westward within a few decades. As Lelang commandery was destroyed and rebuilt around this time, the place gradually moved toward Liaodong. Thus, its force was diminished and it only served as a trade center until it was conquered by Goguryeo in 313.

During the period known as the Proto–Three Kingdoms of Korea, the states of Buyeo, Okjeo, Dongye and Samhan occupied the whole Korean peninsula and southern Manchuria. From them, Goguryeo, Baekje and Silla emerged to control the peninsula as the Three Kingdoms of Korea. Goguryeo, the largest and most powerful among them, was a highly militaristic state, and competed with various Chinese dynasties during its 700 years of history. Goguryeo experienced a golden age under Gwanggaeto the Great and his son Jangsu, who both subdued Baekje and Silla during their times, achieving a brief unification of the Three Kingdoms of Korea and becoming the most dominant power on the Korean Peninsula. In addition to contesting for control of the Korean Peninsula, Goguryeo had many military conflicts with various Chinese dynasties, most notably the Goguryeo–Sui War, in which Goguryeo defeated a huge force said to number over a million men. Baekje was a great maritime power; its nautical skill, which made it the Phoenicia of East Asia, was instrumental in the dissemination of Buddhism throughout East Asia and continental culture to Japan. Baekje was once a great military power on the Korean Peninsula, especially during the time of Geunchogo, but was critically defeated by Gwanggaeto the Great and declined. Silla was the smallest and weakest of the three, but it used cunning diplomatic means to make opportunistic pacts and alliances with the more powerful Korean kingdoms, and eventually Tang China, to its great advantage.

The unification of the Three Kingdoms by Silla in 676 led to the North South States Period, in which much of the Korean Peninsula was controlled by Later Silla, while Balhae controlled the northern parts of Goguryeo. Balhae was founded by a Goguryeo general and formed as a successor state to Goguryeo. During its height, Balhae controlled most of Manchuria and parts of the Russian Far East, and was called the "Prosperous Country in the East". Later Silla was a golden age of art and culture, as evidenced by the Hwangnyongsa, Seokguram, and Emille Bell. Relationships between Korea and China remained relatively peaceful during this time. Later Silla carried on the maritime prowess of Baekje, which acted like the Phoenicia of medieval East Asia, and during the 8th and 9th centuries dominated the seas of East Asia and the trade between China, Korea and Japan, most notably during the time of Jang Bogo; in addition, Silla people made overseas communities in China on the Shandong Peninsula and the mouth of the Yangtze River. Later Silla was a prosperous and wealthy country, and its metropolitan capital of Gyeongju was the fourth largest city in the world. Buddhism flourished during this time, and many Korean Buddhists gained great fame among Chinese Buddhists and contributed to Chinese Buddhism, including: Woncheuk, Wonhyo, Uisang, Musang, and Kim Gyo-gak, a Silla prince whose influence made Mount Jiuhua one of the Four Sacred Mountains of Chinese Buddhism. However, Later Silla weakened under internal strife and the revival of Baekje and Goguryeo, which led to the Later Three Kingdoms period in the late 9th century.

In 936, the Later Three Kingdoms were united by Wang Geon, a descendant of Goguryeo nobility, who established Goryeo as the successor state of Goguryeo. Balhae had fallen to the Khitan Empire in 926, and a decade later the last crown prince of Balhae fled south to Goryeo, where he was warmly welcomed and included into the ruling family by Wang Geon, thus unifying the two successor nations of Goguryeo. Like Silla, Goryeo was a highly cultural state, and invented the metal movable type printing press. After defeating the Khitan Empire, which was the most powerful empire of its time, in the Goryeo–Khitan War, Goryeo experienced a golden age that lasted a century, during which the Tripitaka Koreana was completed and there were great developments in printing and publishing, promoting learning and dispersing knowledge on philosophy, literature, religion, and science; by 1100, there were 12 universities that produced famous scholars and scientists. However, the Mongol invasions in the 13th century greatly weakened the kingdom. Goryeo was never conquered by the Mongols, but exhausted after three decades of fighting, the Korean court sent its crown prince to the Yuan capital to swear allegiance to Kublai Khan, who accepted, and married one of his daughters to the Korean crown prince. Henceforth, Goryeo continued to rule Korea, though as a tributary ally to the Mongols for the next 86 years. During this period, the two nations became intertwined as all subsequent Korean kings married Mongol princesses, and the last empress of the Yuan dynasty was a Korean princess. In the mid-14th century, Goryeo drove out the Mongols to regain its northern territories, briefly conquered Liaoyang, and defeated invasions by the Red Turbans. However, in 1392, General Yi Seong-gye, who had been ordered to attack China, turned his army around and staged a coup.

Yi Seong-gye declared the new name of Korea as "Joseon" in reference to Gojoseon, and moved the capital to Hanseong (one of the old names of Seoul). The first 200 years of the Joseon dynasty were marked by peace, and saw great advancements in science and education, as well as the creation of Hangul by Sejong the Great to promote literacy among the common people. The prevailing ideology of the time was Neo-Confucianism, which was epitomized by the seonbi class: nobles who passed up positions of wealth and power to lead lives of study and integrity. Between 1592 and 1598, Toyotomi Hideyoshi launched invasions of Korea, but his advance was halted by Korean forces (most notably the Joseon Navy led by Admiral Yi Sun-sin and his renowned "turtle ship") with assistance from Righteous Army militias formed by Korean civilians, and Ming dynasty Chinese troops. Through a series of successful battles of attrition, the Japanese forces were eventually forced to withdraw, and relations between all parties became normalized. However, the Manchus took advantage of Joseon's war-weakened state and invaded in 1627 and 1637, and then went on to conquer the destabilized Ming dynasty. After normalizing relations with the new Qing dynasty, Joseon experienced a nearly 200-year period of peace. Kings Yeongjo and Jeongjo particularly led a new renaissance of the Joseon dynasty during the 18th century. In the 19th century, the royal in-law families gained control of the government, leading to mass corruption and weakening of the state, and severe poverty and peasant rebellions throughout the country. Furthermore, the Joseon government adopted a strict isolationist policy, earning the nickname "the hermit kingdom", but ultimately failed to protect itself against imperialism and was forced to open its borders. After the First Sino-Japanese War and the Russo-Japanese War, Korea was occupied by Japan (1910–45). At the end of World War II, the Japanese surrendered to Soviet and U.S. forces who occupied the northern and southern halves of Korea, respectively.

Despite the initial plan of a unified Korea in the 1943 Cairo Declaration, escalating Cold War antagonism between the Soviet Union and the United States eventually led to the establishment of separate governments, each with its own ideology, leading to the division of Korea into two political entities in 1948: North Korea and South Korea. In the South, Syngman Rhee, an opponent of communism, who had been backed and appointed by the United States as head of the provisional government, won the first presidential elections of the newly declared Republic of Korea in May. In the North, however, a former anti-Japanese guerrilla and communist activist, Kim Il-sung was appointed premier of the Democratic People's Republic of Korea in September.

In October, the Soviet Union declared Kim Il-sung's government as sovereign over both parts. The UN declared Rhee's government as "a lawful government having effective control and jurisdiction over that part of Korea where the UN Temporary Commission on Korea was able to observe and consult" and the Government "based on elections which was observed by the Temporary Commission" in addition to a statement that "this is the only such government in Korea." Both leaders began an authoritarian repression of their political opponents inside their region, seeking for a unification of Korea under their control. While South Korea's request for military support was denied by the United States, North Korea's military was heavily reinforced by the Soviet Union.

On June 25, 1950, North Korea invaded South Korea, sparking the Korean War, the Cold War's first major conflict, which continued until 1953. At the time, the Soviet Union had boycotted the United Nations (UN), thus forfeiting their veto rights. This allowed the UN to intervene in a civil war when it became apparent that the superior North Korean forces would unify the entire country. The Soviet Union and China backed North Korea, with the later participation of millions of Chinese troops. After an ebb and flow that saw both sides almost pushed to the brink of extinction, and massive losses among Korean civilians in both the north and the south, the war eventually reached a stalemate. During the war, Rhee's party promoted the One-People Principle (based on the German ideology of the "Herrenvolk") an effort to build an obedient citizenry through ethnic homogeneity and authoritarian appeals to nationalism.

The 1953 armistice, never signed by South Korea, split the peninsula along the demilitarized zone near the original demarcation line. No peace treaty was ever signed, resulting in the two countries remaining technically at war. Approximately 3 million people died in the Korean War, with a higher proportional civilian death toll than World War II or the Vietnam War, making it perhaps the deadliest conflict of the Cold War-era. In addition, virtually all of Korea's major cities were destroyed by the war.

In 1960, a student uprising (the "April 19 Revolution") led to the resignation of the autocratic then-President Syngman Rhee. This was followed by 13 months of political instability as South Korea was led by a weak and ineffectual government. This instability was broken by the May 16, 1961, coup led by General Park Chung-hee. As president, Park oversaw a period of rapid export-led economic growth enforced by political repression.

Park was heavily criticized as a ruthless military dictator, who in 1972 extended his rule by creating a new constitution, which gave the president sweeping (almost dictatorial) powers and permitted him to run for an unlimited number of six-year terms. The Korean economy developed significantly during Park's tenure. The government developed the nationwide expressway system, the Seoul subway system, and laid the foundation for economic development during his 17-year tenure, which ended with his assassination in 1979.

The years after Park's assassination were marked again by political turmoil, as the previously suppressed opposition leaders all campaigned to run for President in the sudden political void. In 1979, General Chun Doo-hwan led the Coup d'état of December Twelfth. Following the Coup d'état, Chun Doo-hwan planned to rise to power through several measures. On May 17, Chun Doo-hwan forced the Cabinet to expand martial law to the whole nation, which had previously not applied to the island of Jejudo. The expanded martial law closed universities, banned political activities, and further curtailed the press. Chun's assumption of the presidency through the events of May 17 triggered nationwide protests demanding democracy; these protests were particularly focused in the city of Gwangju, to which Chun sent special forces to violently suppress the Gwangju Democratization Movement.

Chun subsequently created the National Defense Emergency Policy Committee and took the presidency according to his political plan. Chun and his government held South Korea under a despotic rule until 1987, when a Seoul National University student, Park Jong-chul, was tortured to death. On , the Catholic Priests Association for Justice revealed the incident, igniting the June Democracy Movement around the country. Eventually, Chun's party, the Democratic Justice Party, and its leader, Roh Tae-woo announced the 6.29 Declaration, which included the direct election of the president. Roh went on to win the election by a narrow margin against the two main opposition leaders, Kim Dae-Jung and Kim Young-Sam. Seoul hosted the Olympic Games in 1988, widely regarded as successful and a significant boost for South Korea's global image and economy.

South Korea was formally invited to become a member of the United Nations in 1991. The transition of Korea from autocracy to modern democracy was marked in 1997 by the election of Kim Dae-jung, who was sworn in as the eighth president of South Korea, on February 25, 1998. His election was significant given that he had in earlier years been a political prisoner sentenced to death (later commuted to exile). He won against the backdrop of the 1997 Asian Financial Crisis, where he took IMF advice to restructure the economy and the nation soon recovered its economic growth, albeit at a slower pace.

In June 2000, as part of president Kim Dae-jung's "Sunshine Policy" of engagement, a North–South summit took place in Pyongyang, the capital of North Korea. Later that year, Kim received the Nobel Peace Prize "for his work for democracy and human rights in South Korea and in East Asia in general, and for peace and reconciliation with North Korea in particular". However, because of discontent among the population for fruitless approaches to the North under the previous administrations and, amid North Korean provocations, a conservative government was elected in 2007 led by President Lee Myung-bak, former mayor of Seoul. Meanwhile, South Korea and Japan jointly co-hosted the 2002 FIFA World Cup. However, South Korean and Japanese relations later soured because of conflicting claims of sovereignty over the Liancourt Rocks.

In 2010, there was an escalation in attacks by North Korea. In March 2010 the South Korean warship ROKS Cheonan was sunk with the loss of 46 South Korean sailors, allegedly by a North Korean submarine. In November 2010 Yeonpyeong island was attacked by a significant North Korean artillery barrage, with 4 people losing their lives. The lack of a strong response to these attacks from both South Korea and the international community (the official UN report declined to explicitly name North Korea as the perpetrator for the Cheonan sinking) caused significant anger with the South Korean public. South Korea saw another milestone in 2012 with the first ever female president Park Geun-hye elected and assuming office. Daughter of another former president, Park Chung-hee, she carried on a conservative brand of politics. President Park Geun-hye's administration was formally accused of corruption, bribery, and influence-peddling for the involvement of close friend Choi Soon-sil in state affairs. There followed a series of massive public demonstrations from November 2016 and she was removed from office. After the fallout of President Park's impeachment and dismissal, new elections were held and Moon Jae-in of the Democratic party won the presidency, assuming office on 10 May 2017. His tenure so far has seen an improving political relationship with North Korea, some increasing divergence in the military alliance with the United States, and the successful hosting of the Winter Olympics in Pyeongchang.

South Korea occupies the southern portion of the Korean Peninsula, which extends some from the Asian mainland. This mountainous peninsula is flanked by the Yellow Sea to the west, and the Sea of Japan to the east. Its southern tip lies on the Korea Strait and the East China Sea.

The country, including all its islands, lies between latitudes 33° and 39°N, and longitudes 124° and 130°E. Its total area is .

South Korea can be divided into four general regions: an eastern region of high mountain ranges and narrow coastal plains; a western region of broad coastal plains, river basins, and rolling hills; a southwestern region of mountains and valleys; and a southeastern region dominated by the broad basin of the Nakdong River.

South Korea's terrain is mostly mountainous, most of which is not arable. Lowlands, located primarily in the west and southeast, make up only 30% of the total land area.

About three thousand islands, mostly small and uninhabited, lie off the western and southern coasts of South Korea. Jeju-do is about off the southern coast of South Korea. It is the country's largest island, with an area of . Jeju is also the site of South Korea's highest point: Hallasan, an extinct volcano, reaches above sea level. The easternmost islands of South Korea include Ulleungdo and Liancourt Rocks (Dokdo/Takeshima), while Marado and Socotra Rock are the southernmost islands of South Korea.

South Korea has 20 national parks and popular nature places like the Boseong Tea Fields, Suncheon Bay Ecological Park, and the first national park of Jirisan.

South Korea tends to have a humid continental climate and a humid subtropical climate, and is affected by the East Asian monsoon, with precipitation heavier in summer during a short rainy season called "jangma" (), which begins end of June through the end of July. Winters can be extremely cold with the minimum temperature dropping below in the inland region of the country: in Seoul, the average January temperature range is , and the average August temperature range is . Winter temperatures are higher along the southern coast and considerably lower in the mountainous interior. Summer can be uncomfortably hot and humid, with temperatures exceeding in most parts of the country. South Korea has four distinct seasons; spring, summer, autumn and winter. Spring usually lasts from late March to early May, summer from mid-May to early September, autumn from mid-September to early November, and winter from mid-November to mid-March.

Rainfall is concentrated in the summer months of June through September. The southern coast is subject to late summer typhoons that bring strong winds, heavy rains and sometime floods. The average annual precipitation varies from in Seoul to in Busan.

During the first 20 years of South Korea's growth surge, little effort was made to preserve the environment. Unchecked industrialization and urban development have resulted in deforestation and the ongoing destruction of wetlands such as the Songdo Tidal Flat. However, there have been recent efforts to balance these problems, including a government run five-year green growth project that aims to boost energy efficiency and green technology.

The green-based economic strategy is a comprehensive overhaul of South Korea's economy, utilizing nearly two percent of the national GDP. The greening initiative includes such efforts as a nationwide bike network, solar and wind energy, lowering oil dependent vehicles, backing daylight saving time and extensive usage of environmentally friendly technologies such as LEDs in electronics and lighting. The country – already the world's most wired – plans to build a nationwide next-generation network that will be 10 times faster than broadband facilities, in order to reduce energy usage.

The renewable portfolio standard program with renewable energy certificates runs from 2012 to 2022.
Quota systems favor large, vertically integrated generators and multinational electric utilities, if only because certificates are generally denominated in units of one megawatt-hour. They are also more difficult to design and implement than a Feed-in tariff. Around 350 residential micro combined heat and power units were installed in 2012.

Seoul's tap water recently became safe to drink, with city officials branding it "Arisu" in a bid to convince the public. Efforts have also been made with afforestation projects. Another multibillion-dollar project was the restoration of Cheonggyecheon, a stream running through downtown Seoul that had earlier been paved over by a motorway. One major challenge is air quality, with acid rain, sulfur oxides, and annual yellow dust storms being particular problems. It is acknowledged that many of these difficulties are a result of South Korea's proximity to China, which is a major air polluter.

South Korea is a member of the Antarctic-Environmental Protocol, Antarctic Treaty, Biodiversity Treaty, Kyoto Protocol (forming the Environmental Integrity Group (EIG), regarding UNFCCC, with Mexico and Switzerland), Desertification, Endangered Species, Environmental Modification, Hazardous Wastes, Law of the Sea, Marine Dumping, Comprehensive Nuclear-Test-Ban Treaty (not into force), Ozone Layer Protection, Ship Pollution, Tropical Timber 83, Tropical Timber 94, Wetlands, and Whaling.

The South Korean government's structure is determined by the Constitution of the Republic of Korea. Like many democratic states, South Korea has a government divided into three branches: executive, judicial, and legislative. The executive and legislative branches operate primarily at the national level, although various ministries in the executive branch also carry out local functions. Local governments are semi-autonomous, and contain executive and legislative bodies of their own. The judicial branch operates at both the national and local levels. South Korea is a constitutional democracy.
The constitution has been revised several times since its first promulgation in 1948 at independence. However, it has retained many broad characteristics and with the exception of the short-lived Second Republic of South Korea, the country has always had a presidential system with an independent chief executive. Under its current constitution the state is sometimes referred to as the Sixth Republic of South Korea. The first direct election was also held in 1948.

Although South Korea experienced a series of military dictatorships from the 1960s until the 1980s, it has since developed into a successful liberal democracy. Today, the CIA World Factbook describes South Korea's democracy as a "fully functioning modern democracy". South Korea is ranked 45th on the Corruption Perceptions Index (9th in the Asia-Pacific region), with a score of 57 out of 100.

The major administrative divisions in South Korea are eight provinces, one special self-governing province, six metropolitan cities (self-governing cities that are not part of any province), one special city and one special self-governing city.

In April 2016, South Korea's population was estimated to be around 50.8 million by National Statistical Office, with continuing decline of working age population and total fertility rate. The country is noted for its population density, which was an estimated 505 per square kilometer in 2015, more than 10 times the global average. Aside from micro-states and city-states, South Korea is the world's third most densely-populated country. In practice the population density in much of South Korea is higher than the national one, as most of the country's land is uninhabitable due to being used for other purposes such as farming. Most South Koreans live in urban areas, because of rapid migration from the countryside during the country's quick economic expansion in the 1970s, 1980s and 1990s. The capital city of Seoul is also the country's largest city and chief industrial center. According to the 2005 census, Seoul had a population of inhabitants. The Seoul National Capital Area has inhabitants (about half of South Korea's entire population) making it the world's second largest metropolitan area. Other major cities include Busan (), Incheon (), Daegu (), Daejeon (), Gwangju () and Ulsan ().
The population has also been shaped by international migration. After World War II and the division of the Korean Peninsula, about four million people from North Korea crossed the border to South Korea. This trend of net entry reversed over the next 40 years because of emigration, especially to North America through the United States and Canada. South Korea's total population in 1955 was , and has more than doubled, to 50 million, by 2010.

South Korea is considered one of the most ethnically homogeneous societies in the world with ethnic Koreans representing approximately 96% of total population. Precise numbers are difficult since statistics do not record ethnicity and given many immigrants are ethnically Korean themselves, and some South Korean citizens are not ethnically Korean. South Korea is nevertheless becoming a more multi-ethnic society over time due to immigration.

The percentage of foreign nationals has been growing rapidly. , South Korea had 1,413,758 foreign residents, 2.75% of the population; however, many of them are ethnic Koreans with a foreign citizenship. For example, migrants from China (PRC) make up 56.5% of foreign nationals, but approximately 70% of the Chinese citizens in Korea are (), PRC citizens of Korean ethnicity. Regardless of the ethnicity, there are 28,500 US military personnel serving in South Korea, most serving a one-year unaccompanied tour (though approximately 10% serve longer tours accompanied by family), according to the Korea National Statistical Office. In addition, about 43,000 English teachers from English-speaking countries reside temporarily in Korea. Currently, South Korea has one of the highest rates of growth of foreign born population, with about 30,000 foreign born residents obtaining South Korean citizenship every year since 2010.

Large number of ethnic Koreans live overseas, sometimes in Korean ethnic neighbourhoods also known as Koreatowns. The four largest diaspora population can be found in China (2.3 million), the United States (1.8 million), Japan (0.85 million), and Canada (0.25 million).

South Korea's birthrate was the world's lowest in 2009, at an annual rate of approximately 9 births per 1000 people. Fertility saw some modest increase afterwards, but dropped to a new global low in 2017, with fewer than 30,000 births per month for the first time since records began and less than 1 child per woman as of 2018 trends. The average life expectancy in 2008 was 79.10 years, (which was 34th in the world) but by 2015 it had increased to around 81. South Korea has the steepest decline in working age population of the OECD nations. In 2015, National Statistical Office estimated that the population of the country will have reached its peak by 2035.

A centralized administration in South Korea oversees the process for the education of children from kindergarten to the third and final year of high school. The school year is divided into two semesters, the first of which begins at the beginning of March and ends in mid-July, the second of which begins in late August and ends in mid-February. The schedules are not uniformly standardized and vary from school to school. Most South Korean middle schools and high schools have school uniforms, modeled on western-style uniforms. Boys' uniforms usually consist of trousers and white shirts, and girls wear skirts and white shirts (this only applies in middle schools and high schools). The country adopted a new educational program to increase the number of their foreign students through 2010. According to the Ministry of Education, Science and Technology, the number of scholarships for foreign students in South Korea would have (under the program) doubled by that time, and the number of foreign students would have reached 100,000.

South Korea is one of the top-performing OECD countries in reading literacy, mathematics and sciences with the average student scoring 519, compared with the OECD average of 492, placing it ninth in the world and has one of the world's most highly educated labor forces among OECD countries. The country has one of the world's highest-educated labour forces among OECD countries. The country is well known for its highly feverish outlook on education, where its national obsession with education has been called "education fever". This obsession with education has catapulted the resource poor nation consistently atop the global education rankings where in 2014 national rankings of students' math and science scores by the Organization for Economic and Cooperation and Development (OECD), South Korea ranked second place worldwide, after Singapore.

Higher education is a serious issue in South Korea society, where it is viewed as one of the fundamental cornerstones of South Korean life. Education is regarded with a high priority for South Korean families as success in education is often a source of pride for families and within South Korean society at large, and is a necessity to improve one's socioeconomic position in South Korean society. South Koreans view education as the main propeller of social mobility for themselves and their family as a gateway to the South Korean middle class. Graduating from a top university is the ultimate marker of prestige, high socioeconomic status, promising marriage prospects, and a respectable career path. The entrance into a top tier higher educational institution leads to a prestigious, secure and well-paid white collar job with the government, banks, or a major South Korean conglomerate such as Samsung, Hyundai or LG Electronics. An average South Korean child's life revolves around education as pressure to succeed academically is deeply ingrained in South Korean children from an early age. With incredible pressure on high school students to secure places at the nation's best universities, its institutional reputation and alumni networks are strong predictors of future career prospects. The top three universities in South Korea, often referred to as "SKY", are Seoul National University, Korea University and Yonsei University. Intense competition for top grades and academic pressure to be the top student is deeply ingrained in the psyche of South Korean students at a young age. Yet with only so many places at the nations most prestigious universities and even fewer places at top-tier companies, many young people remain disappointed and are often unwilling to lower their sights with the result of many feeling as underachievers. There is a major cultural taboo in South Korean society attached to those who have not achieved formal university education where those who do not hold university degrees face social prejudice and are often looked down by others as second-class citizens resulting in fewer opportunities for employment, improvement of one's socioeconomic position and prospects for marriage.
In 2015, the country spent 5.1% of its GDP on all levels of education – roughly 0.8 percentage points above the Organisation for Economic Co-operation and Development (OECD) average of 4.3%. A strong investment in education, a militant drive for success as well as the passion for excellence has helped the resource poor country rapidly grow its economy over the past 60 years from a war torn wasteland.

International opinion regarding the South Korean education system has been divided. It has been praised for various reasons, including its comparatively high test results and its major role in ushering South Korea's economic development creating one of the world's most educated workforces.
South Korea's highly enviable academic performance has persuaded British education ministers to actively remodel their own curriculums and exams to try to emulate Korea's militant drive and passion for excellence and high educational achievement. Former U.S. President Barack Obama has also praised the country's rigorous school system, where over 80 percent of South Korean high school graduates go on to university. The nation's high university entrance rate has created a highly skilled workforce making South Korea among the most highly educated countries in the world with one of the highest percentages of its citizens holding a tertiary education degree. In 2017, the country ranked fifth for the percentage of 25 to 64 year olds that have attained tertiary education with 47.7 percent. In addition, 69.8 percent of South Koreans aged 25–34 have completed some form of tertiary education qualification and bachelor's degrees are held by 34.2 percent of South Koreans aged 25–64, the most in the OECD.

The system's rigid and hierarchical structure has been criticized for stifling creativity and innovation; described as intensely and "brutally" competitive, the system is often blamed for the high suicide rate in the country, particularly the growing rates among those aged 10–19. Various media outlets attribute the country's high suicide rate to the nationwide anxiety around the country's college entrance exams, which determine the trajectory of students' entire lives and careers. Former South Korean "hagwon" teacher Se-Woong Koo wrote that the South Korean education system amounts to child abuse and that it should be "reformed and restructured without delay". The system has also been criticized for producing an excess supply of university graduates creating an overeducated and underemployed labor force; in the first quarter of 2013 alone, nearly 3.3 million South Korean university graduates were jobless, leaving many graduates overqualified for jobs requiring less education. Further criticism has been stemmed for causing labor shortages in various skilled blue collar labor and vocational occupations, where many go unfilled as the negative social stigma associated with vocational careers and not having a university degree continues to remain deep-rooted in South Korean society.

Korean is the official language of South Korea, and is classified by most linguists as a language isolate. Korean is not related to any Chinese languages, although it incorporates a number of words that are Chinese in origin. Additionally, Korean spoken in South Korea uses a significant number of loan words from English and other European languages. Korean uses an indigenous writing system called Hangul, created in 1446 by King Sejong to provide a convenient alternative to the Classical Chinese Hanja characters that were difficult to learn and did not fit the Korean language well. South Korea still uses some Chinese Hanja characters in limited areas, such as print media and legal documentation.

The Korean language in South Korea has a standard dialect known as Seoul (after the capital city), with an additional 4 Korean language dialect groups in use around the country.

Almost all South Korean students today learn English throughout their education, with some optionally choosing Japanese or Mandarin as well.

According to the results of the census of 2015 more than half of the South Korean population (56.1%) declared themselves not affiliated with any religious organizations. In a 2012 survey, 52% declared themselves "religious", 31% said they were "not religious" and 15% identified themselves as "convinced atheists". Of the people who are affiliated with a religious organization, most are Christians and Buddhists. According to the 2015 census, 27.6% of the population were Christians (19.7% identified themselves as Protestants, 7.9% as Roman Catholics), and 15.5% were Buddhists. Other religions include Islam (130,000 Muslims, mostly migrant workers from Pakistan and Bangladesh but including some 35,000 Korean Muslims,) the homegrown sect of Won Buddhism, and a variety of indigenous religions, including Cheondoism (a Confucianizing religion), Jeungsanism, Daejongism, Daesun Jinrihoe and others. Freedom of religion is guaranteed by the constitution, and there is no state religion. Overall, between the 2005 and 2015 censuses there has been a slight decline of Christianity (down from 29% to 27.6%), a sharp decline of Buddhism (down from 22.8% to 15.5%), and a rise of the unaffiliated population (from 47.2% to 56.9%).

Christianity is South Korea's largest organized religion, accounting for more than half of all South Korean adherents of religious organizations. There are approximately 13.5 million Christians in South Korea today; about two thirds of them belonging to Protestant churches, and the rest to the Roman Catholic Church. The number of Protestants has been stagnant throughout the 1990s and the 2000s, but increased to a peak level throughout the 2010s. Roman Catholics increased significantly between the 1980s and the 2000s, but declined throughout the 2010s. Christianity, unlike in other East Asian countries, found fertile ground in Korea in the 18th century, and by the end of the 18th century it persuaded a large part of the population as the declining monarchy supported it and opened the country to widespread proselytism as part of a project of Westernization. The weakness of Korean Sindo, which, unlike Japanese Shinto and China's religious system, never developed into a national religion of high status, combined with the impoverished state of Korean Buddhism (after 500 years of suppression at the hands of the Joseon state, by the 20th century it was virtually extinct) left a free hand to Christian churches. Christianity's similarity to native religious narratives has been studied as another factor that contributed to its success in the peninsula. The Japanese colonization of the first half of the 20th century further strengthened the identification of Christianity with Korean nationalism, as the Japanese coopted native Korean Sindo into the Nipponic Imperial Shinto that they tried to establish in the peninsula. Widespread Christianization of the Koreans took place during State Shinto, after its abolition, and then in the independent South Korea as the newly established military government supported Christianity and tried to utterly oust native Sindo.
Among Christian denominations, Presbyterianism is the largest. About nine million people belong to one of the hundred different Presbyterian churches; the biggest ones are the HapDong Presbyterian Church, TongHap Presbyterian Church, the Koshin Presbyterian Church. South Korea is also the second-largest missionary-sending nation, after the United States.

Buddhism was introduced to Korea in the 4th century. It became soon a dominant religion in the southeastern kingdom of Silla, the region that hitherto hosts the strongest concentration of Buddhists in South Korea. In the other states of the Three Kingdoms Period, Goguryeo and Baekje, it was made the state religion respectively in 372 and 528. It remained the state religion in Later Silla (North South States Period) and Goryeo. It was later suppressed throughout much of the subsequent history under the unified kingdom of Joseon (1392–1897), which officially adopted a strict Korean Confucianism. Today, South Korea has about 7 million Buddhists, most of them affiliated to the Jogye Order. Most of the National Treasures of South Korea are Buddhist artifacts.

South Korea has a universal healthcare system. It has the world's second best healthcare system.

Suicide in South Korea is a serious and widespread problem and the country ranks poorly on world happiness reports for a high-income state. The suicide rate was the highest in the G20 in 2015 (24.1 deaths per 100,000 persons).

South Korean hospitals have advanced medical equipment and facilities readily available, ranking 4th for MRI units per capita and 6th for CT scanners per capita in the OECD. It also had the OECD's second largest number of hospital beds per 1000 people at 9.56 beds.

Life expectancy has been rising rapidly and South Korea ranked 11th in the world for life expectancy at 82.3 years by the WHO in 2015. It also has the third highest health adjusted life expectancy in the world.

South Korea maintains diplomatic relations with more than 188 countries. The country has also been a member of the United Nations since 1991, when it became a member state at the same time as North Korea. On January 1, 2007, Former South Korean Foreign Minister Ban Ki-moon served as UN Secretary-General from 2007 to 2016. It has also developed links with the Association of Southeast Asian Nations as both a member of "ASEAN Plus three," a body of observers, and the East Asia Summit (EAS).

In November 2009 South Korea joined the OECD Development Assistance Committee, marking the first time a former aid recipient country joined the group as a donor member.

South Korea hosted the G-20 Summit in Seoul in November 2010, a year that saw South Korea and the European Union conclude a free trade agreement (FTA) to reduce trade barriers. South Korea went on to sign a Free Trade Agreements with Canada and Australia in 2014, and another with New Zealand in 2015.

Both North and South Korea claim complete sovereignty over the entire peninsula and outlying islands. Despite mutual animosity, reconciliation efforts have continued since the initial separation between North and South Korea. Political figures such as Kim Koo worked to reconcile the two governments even after the Korean War. With longstanding animosity following the Korean War from 1950 to 1953, North Korea and South Korea signed an agreement to pursue peace. On October 4, 2007, Roh Moo-Hyun and North Korean leader Kim Jong-il signed an eight-point agreement on issues of permanent peace, high-level talks, economic cooperation, renewal of train services, highway and air travel, and a joint Olympic cheering squad.
Despite the Sunshine Policy and efforts at reconciliation, the progress was complicated by North Korean missile tests in 1993, 1998, 2006, 2009, and 2013. , relationships between North and South Korea were very tense; North Korea had been reported to have deployed missiles, ended its former agreements with South Korea, and threatened South Korea and the United States not to interfere with a satellite launch it had planned. North and South Korea are still technically at war (having never signed a peace treaty after the Korean War) and share the world's most heavily fortified border. On May 27, 2009, North Korean media declared that the Armistice is no longer valid because of the South Korean government's pledge to "definitely join" the Proliferation Security Initiative. To further complicate and intensify strains between the two nations, the sinking of the South Korean warship Cheonan in March 2010, is affirmed by the South Korean government to have been caused by a North Korean torpedo, which the North denies. President Lee Myung-bak declared in May 2010 that Seoul would cut all trade with North Korea as part of measures primarily aimed at striking back at North Korea diplomatically and financially, except for the joint Kaesong Industrial Project, and humanitarian aid. North Korea initially threatened to sever all ties, to completely abrogate the previous pact of non-aggression, and to expel all South Koreans from a joint industrial zone in Kaesong, but backtracked on its threats and decided to continue its ties with South Korea. Despite the continuing ties, Kaesong industrial zone has seen a large decrease in investment and manpower as a result of this military conflict. In February 2016, the Kaesong complex was closed by Seoul in reaction to North Korea's launch of a rocket earlier in the month unanimously condemned by the United Nations security council.
The 2017 election of President Moon Jae-in has seen a change in approach towards the North, and both sides used the South Korean held 2018 Winter Olympics as an opportunity for engagement, with a very senior North Korean political delegation sent to the games, along with a reciprocal visit by senior South Korean cabinet members to the North soon afterwards.

Historically, Korea had close relations with the dynasties in China, and some Korean kingdoms were members of the Imperial Chinese tributary system. The Korean kingdoms also ruled over some Chinese kingdoms including the Kitan people and the Manchurians before the Qing dynasty and received tributes from them. In modern times, before the formation of South Korea, Korean independence fighters worked with Chinese soldiers during the Japanese occupation. However, after World War II, the People's Republic of China embraced Maoism while South Korea sought close relations with the United States. The PRC assisted North Korea with manpower and supplies during the Korean War, and in its aftermath the diplomatic relationship between South Korea and the PRC almost completely ceased. Relations thawed gradually and South Korea and the PRC re-established formal diplomatic relations on August 24, 1992. The two countries sought to improve bilateral relations and lifted the forty-year-old trade embargo, and South Korean–Chinese relations have improved steadily since 1992. The Republic of Korea broke off official relations with the Republic of China (Taiwan) upon gaining official relations with the People's Republic of China, which does not recognize Taiwan's sovereignty.
China has become South Korea's largest trading partner by far, sending 26% of South Korean exports in 2016 worth $124 billion, as well as an additional $32 billion worth of exports to Hong Kong. South Korea is also China's 4th largest trading partner, with $93 billion of Chinese imports in 2016.

The 2017 deployment of THAAD defense missiles by the United States military in South Korea in response to North Korean missile tests has been protested strongly by the Chinese government, concerned that the technologically advanced missile defense could be used more broadly against China. Relations between the governments have cooled in response, with South Korean commercial and cultural interests in China having been targeted, and Chinese tourism to South Korea having been curtailed. The situation was largely resolved by South Korea making significant military concessions to China in exchange for THAAD, including not deploying any more anti-ballistic missile systems in South Korea and not participating in an alliance between the United States and Japan.

South Korea and Russia are participants in the Six-party talks on the North Korea's nuclear proliferation issue. Moon Jae-in's administration has focused on increasing South Korea's consumption of natural gas. These plans include re-opening dialogue around a natural gas pipeline that would come from Russia and pass through North Korea. In June 2018, president Moon Jae-in became the first South Korean leader to speak in the Russian Parliament. On June 22, Moon Jae-in and Putin signed a document for foundation of free trade area.

Korea and Japan have had difficult relations since ancient times, but also significant cultural exchange, with Korea acting as the gateway between Asia and Japan. Contemporary perceptions of Japan are still largely defined by Japan's 35 year colonization of Korea in the 20th century, which is generally regarded in South Korea as having been very negative. Japan is today South Korea's third largest trading partner, with 12% ($46 billion) of exports in 2016.

There were no formal diplomatic ties between South Korea and Japan directly after independence the end of World War II in 1945. South Korea and Japan eventually signed the Treaty on Basic Relations between Japan and the Republic of Korea in 1965 to establish diplomatic ties. There is heavy anti-Japanese sentiment in South Korea because of a number of unsettled Japanese-Korean disputes, many of which stem from the period of Japanese occupation after the Japanese annexation of Korea. During World War II, more than 100,000 Koreans served in the Imperial Japanese Army. Korean women were coerced and forced to serve the Imperial Japanese Army as sexual slaves, called comfort women, in both Korea and throughout the Japanese war fronts.

Longstanding issues such as Japanese war crimes against Korean civilians, the negationist re-writing of Japanese textbooks relating Japanese atrocities during World War II, the territorial disputes over the Liancourt Rocks, known in South Korea as "Dokdo" and in Japan as "Takeshima", and visits by Japanese politicians to the Yasukuni Shrine, honoring Japanese people (civilians and military) killed during the war continue to trouble Korean-Japanese relations. The Liancourt Rocks were the first Korean territories to be forcibly colonized by Japan in 1905. Although it was again returned to Korea along with the rest of its territory in 1951 with the signing of the Treaty of San Francisco, Japan does not recant on its claims that the Liancourt Rocks are Japanese territory.
In response to then-Prime Minister Junichiro Koizumi's visits to the Yasukuni Shrine, former President Roh Moo-hyun suspended all summit talks between South Korea and Japan in 2009.
A summit between the nations' leaders was eventually held on February 9, 2018 during the Korean held Winter Olympics. South Korea asked the International Olympic Committee to ban the Japanese Rising Sun Flag from the 2020 Summer Olympics in Tokyo.

The European Union (EU) and South Korea are important trading partners, having negotiated a free trade agreement for many years since South Korea was designated as a priority FTA partner in 2006. The free trade agreement was approved in September 2010, and took effect on July 1, 2011. South Korea is the EU's tenth largest trade partner, and the EU has become South Korea's fourth largest export destination. EU trade with South Korea exceeded €90 billion in 2015 and has enjoyed an annual average growth rate of 9.8% between 2003 and 2013.

The EU has been the single largest foreign investor in South Korea since 1962, and accounted for almost 45% of all FDI inflows into Korea in 2006. Nevertheless, EU companies have significant problems accessing and operating in the South Korean market because of stringent standards and testing requirements for products and services often creating barriers to trade. Both in its regular bilateral contacts with South Korea and through its FTA with Korea, the EU is seeking to improve this situation.

The close relationship began directly after World War II, when the United States temporarily administrated Korea for three years (mainly in the South, with the Soviet Union engaged in North Korea) after Japan. Upon the onset of the Korean War in 1950, U.S. forces were sent to defend against an invasion from North Korea of the South, and subsequently fought as the largest contributor of UN troops. The United States participation was critical for preventing the near defeat of the Republic of Korea by northern forces, as well as fighting back for the territory gains that define the South Korean nation today.

Following the Armistice, South Korea and the U.S. agreed to a "Mutual Defense Treaty", under which an attack on either party in the Pacific area would summon a response from both. In 1967, South Korea obliged the mutual defense treaty, by sending a large combat troop contingent to support the United States in the Vietnam War. The US has over 23,000 troops stationed in South Korea, including the U.S. Eighth Army, Seventh Air Force, and U.S. Naval Forces Korea. The two nations have strong economic, diplomatic, and military ties, although they have at times disagreed with regard to policies towards North Korea, and with regard to some of South Korea's industrial activities that involve usage of rocket or nuclear technology. There had also been strong anti-American sentiment during certain periods, which has largely moderated in the modern day.

The two nations also share a close economic relationship, with the U.S being South Korea's second largest trading partner, receiving $66 billion in exports in 2016. In 2007, a free trade agreement known as the Republic of Korea-United States Free Trade Agreement (KORUS FTA) was signed between South Korea and the United States, but its formal implementation was repeatedly delayed, pending approval by the legislative bodies of the two countries. On October 12, 2011, the U.S. Congress passed the long-stalled trade agreement with South Korea. It went into effect on March 15, 2012.

Unresolved tension with North Korea has prompted South Korea to allocate 2.6% of its GDP and 15% of all government spending to its military (Government share of GDP: 14.967%), while maintaining compulsory conscription for men. Consequently, South Korea has the world's seventh largest number of active troops (599,000 in 2018), the world's highest number of reserve troops (3,100,000 in 2018) and the tenth largest defense budget. As of 2019 South Korea has a defense budget of $43.1 billion. The South Korean military is ranked as the 6th most powerful military force in the world as of 2020.

The South Korean military consists of the Army (ROKA), the Navy (ROKN), the Air Force (ROKAF), and the Marine Corps (ROKMC), and reserve forces. Many of these forces are concentrated near the Korean Demilitarized Zone. All South Korean males are constitutionally required to serve in the military, typically 18 months. Previous exceptions for South Korean citizens of mixed race no longer apply since 2011.

In addition to male conscription in South Korea's sovereign military, 1,800 Korean males are selected every year to serve 18 months in the KATUSA Program to further augment the United States Forces Korea (USFK). In 2010, South Korea was spending ₩1.68 trillion in a cost-sharing agreement with the US to provide budgetary support to the US forces in Korea, on top of the ₩29.6 trillion budget for its own military.

The South Korean army has 2,500 tanks in operation, including the K1A1 and K2 Black Panther, which form the backbone of the South Korean army's mechanized armor and infantry forces. A sizable arsenal of many artillery systems, including 1,700 self-propelled K55 and K9 Thunder howitzers and 680 helicopters and UAVs of numerous types, are assembled to provide additional fire, reconnaissance, and logistics support. South Korea's smaller but more advanced artillery force and wide range of airborne reconnaissance platforms are pivotal in the counter-battery suppression of North Korea's large artillery force, which operates more than 13,000 artillery systems deployed in various state of fortification and mobility.

The South Korean navy has made its first major transformation into a blue-water navy through the formation of the Strategic Mobile Fleet, which includes a battle group of Chungmugong Yi Sun-sin class destroyers, Dokdo class amphibious assault ship, AIP-driven Type 214 submarines, and King Sejong the Great class destroyers, which is equipped with the latest baseline of Aegis fleet-defense system that allows the ships to track and destroy multiple cruise missiles and ballistic missiles simultaneously, forming an integral part of South Korea's indigenous missile defense umbrella against the North Korean military's missile threat.

The South Korean air force operates 840 aircraft, making it world's ninth largest air force, including several types of advanced fighters like F-15K, heavily modified KF-16C/D, and the indigenous T-50 Golden Eagle, supported by well-maintained fleets of older fighters such as F-4E and KF-5E/F that still effectively serve the air force alongside the more modern aircraft. In an attempt to gain strength in terms of not just numbers but also modernity, the commissioning of four Boeing 737 AEW&C aircraft, under Project Peace Eye for centralized intelligence gathering and analysis on a modern battlefield, will enhance the fighters' and other support aircraft's ability to perform their missions with awareness and precision.

In May 2011, Korea Aerospace Industries Ltd., South Korea's largest plane maker, signed a $400 million deal to sell 16 T-50 Golden Eagle trainer jets to Indonesia, making South Korea the first country in Asia to export supersonic jets.

From time to time, South Korea has sent its troops overseas to assist American forces. It has participated in most major conflicts that the United States has been involved in the past 50 years. South Korea dispatched 325,517 troops to fight alongside American, Australian, Filipino, New Zealand and South Vietnamese soldiers in the Vietnam War, with a peak strength of 50,000. In 2004, South Korea sent 3,300 troops of the Zaytun Division to help re-building in northern Iraq, and was the third largest contributor in the coalition forces after only the US and Britain. Beginning in 2001, South Korea had so far deployed 24,000 troops in the Middle East region to support the War on Terrorism. A further 1,800 were deployed since 2007 to reinforce UN peacekeeping forces in Lebanon.

The United States has stationed a substantial contingent of troops to defend South Korea. There are approximately 28,500 U.S. military personnel stationed in South Korea, most of them serving one year unaccompanied tours. The U.S. troops, which are primarily ground and air units, are assigned to USFK and mainly assigned to the Eighth United States Army of the U.S. Army and Seventh Air Force of the U.S. Air Force. They are stationed in installations at Osan, Kunsan, Yongsan, Dongducheon, Sungbuk, Camp Humphreys, and Daegu, as well as at Camp Bonifas in the DMZ Joint Security Area.

A fully functioning UN Command is at the top of the chain of command of all forces in South Korea, including the U.S. forces and the entire South Korean military – if a sudden escalation of war between North and South Korea were to occur the United States would assume control of the South Korean armed forces in all military and paramilitary moves. There has been long-term agreement between the United States and South Korea that South Korea should eventually assume the lead for its own defense. This transition to a South Korean command has been slow and often postponed, although it is currently scheduled to occur in the early 2020s.

Male citizens who refuse or reject to undertake military services because of conscientious objection are typically imprisoned, with over 600 individuals usually imprisoned at any given time; more than the rest of the world put together. The vast majority of these are young men from the Jehovah's Witnesses Christian denomination.
See Conscription in South Korea. However, in a court ruling of 2018, conscientious objectors were permitted to reject military service.

South Korea's mixed economy ranks 11th nominal and 13th purchasing power parity GDP in the world, identifying it as one of the G-20 major economies. It is a developed country with a high-income economy and is the most industrialized member country of the OECD. South Korean brands such as LG Electronics and Samsung are internationally famous and garnered South Korea's reputation for its quality electronics and other manufactured goods.

Its massive investment in education has taken the country from mass illiteracy to a major international technological powerhouse. The country's national economy benefits from a highly skilled workforce and is among the most educated countries in the world with one of the highest percentages of its citizens holding a tertiary education degree. South Korea's economy was one of the world's fastest-growing from the early 1960s to the late 1990s, and was still one of the fastest-growing developed countries in the 2000s, along with Hong Kong, Singapore and Taiwan, the other three Asian Tigers. It recorded the fastest rise in average GDP per capita in the world between 1980 and 1990. South Koreans refer to this growth as the Miracle on the Han River. The South Korean economy is heavily dependent on international trade, and in 2014, South Korea was the fifth-largest exporter and seventh-largest importer in the world.

Despite the South Korean economy's high growth potential and apparent structural stability, the country suffers damage to its credit rating in the stock market because of the belligerence of North Korea in times of deep military crises, which has an adverse effect on South Korean financial markets. The International Monetary Fund compliments the resilience of the South Korean economy against various economic crises, citing low state debt and high fiscal reserves that can quickly be mobilized to address financial emergencies. Although it was severely harmed by the Asian economic crisis of the late 1990s, the South Korean economy managed a rapid recovery and subsequently tripled its GDP.

Furthermore, South Korea was one of the few developed countries that were able to avoid a recession during the global financial crisis. Its economic growth rate reached 6.2 percent in 2010 (the fastest growth for eight years after significant growth by 7.2 percent in 2002), a sharp recovery from economic growth rates of 2.3% in 2008 and 0.2% in 2009, when the global financial crisis hit. The unemployment rate in South Korea also remained low in 2009, at 3.6%.

South Korea became a member of the Organisation for Economic Co-operation and Development (OECD) in 1996.

The following list includes the largest South Korean companies by revenue in 2017 who are all listed as part of the Fortune Global 500:

South Korea has a technologically advanced transport network consisting of high-speed railways, highways, bus routes, ferry services, and air routes that crisscross the country. Korea Expressway Corporation operates the toll highways and service amenities en route.

Korail provides frequent train services to all major South Korean cities. Two rail lines, Gyeongui and Donghae Bukbu Line, to North Korea are now being reconnected. The Korean high-speed rail system, KTX, provides high-speed service along Gyeongbu and Honam Line. Major cities including Seoul, Busan, Incheon, Daegu, Daejeon and Gwangju have urban rapid transit systems. Express bus terminals are available in most cities.

South Korea's main gateway and largest airport is Incheon International Airport, serving passengers in 2016. Other international airports include Gimpo, Busan and Jeju. There are also many airports that were built as part of the infrastructure boom but are barely used. There are also many heliports.

The national carrier, Korean Air served over 26,800,000 passengers, including almost 19,000,000 international passengers in 2016. A second carrier, Asiana Airlines also serves domestic and international traffic. Combined, South Korean airlines serve 297 international routes. Smaller airlines, such as Jeju Air, provide domestic service with lower fares.

South Korea is the world's fifth-largest nuclear power producer and the second-largest in Asia . Nuclear power in South Korea supplies 45% of electricity production, and research is very active with investigation into a variety of advanced reactors, including a small modular reactor, a liquid-metal fast/transmutation reactor and a high-temperature hydrogen generation design. Fuel production and waste handling technologies have also been developed locally. It is also a member of the ITER project.

South Korea is an emerging exporter of nuclear reactors, having concluded agreements with the UAE to build and maintain four advanced nuclear reactors, with Jordan for a research nuclear reactor, and with Argentina for construction and repair of heavy-water nuclear reactors. , South Korea and Turkey are in negotiations regarding construction of two nuclear reactors. South Korea is also preparing to bid on construction of a light-water nuclear reactor for Argentina.

South Korea is not allowed to enrich uranium or develop traditional uranium enrichment technology on its own, because of US political pressure, unlike most major nuclear powers such as Japan, Germany, and France, competitors of South Korea in the international nuclear market. This impediment to South Korea's indigenous nuclear industrial undertaking has sparked occasional diplomatic rows between the two allies. While South Korea is successful in exporting its electricity-generating nuclear technology and nuclear reactors, it cannot capitalize on the market for nuclear enrichment facilities and refineries, preventing it from further expanding its export niche. South Korea has sought unique technologies such as pyroprocessing to circumvent these obstacles and seek a more advantageous competition. The US has recently been wary of South Korea's burgeoning nuclear program, which South Korea insists will be for civilian use only.

South Korea is the third highest ranked Asian country in the World Economic Forum's Network Readiness Index (NRI) after Singapore and Hong Kong respectively – an indicator for determining the development level of a country's information and communication technologies. South Korea ranked number 10 overall in the 2014 NRI ranking, up from 11 in 2013.

In 2016, 17 million foreign tourists visited South Korea With rising tourist prospects, especially from foreign countries outside of Asia, the South Korean government has set a target of attracting 20 million foreign tourists a year by 2017.

South Korean tourism is driven by many factors, including the prominence of Korean pop culture such as South Korean pop music and television dramas, known as the Korean Wave or (Hallyu), has gained popularity throughout East Asia. The Hyundai Research Institute reported that the Korean Wave has a direct impact in encouraging direct foreign investment back into the country through demand for products, and the tourism industry. Among East Asian countries, China was the most receptive, investing 1.4 billion in South Korea, with much of the investment within its service sector, a sevenfold increase from 2001. According to an analysis by economist Han Sang-Wan, a 1 percent increase in the exports of Korean cultural content pushes consumer goods exports up 0.083 percent while a 1 percent increase in Korean pop content exports to a country produces a 0.019 percent bump in tourism.

The South Korean pension system was created to provide benefits to persons reaching old age, families and persons stricken with death of their primary breadwinner, and for the purposes of stabilizing its nations welfare state. South Korea's pension system structure is primarily based on taxation and is income-related. In 2007 there was a total of 18,367,000 insured individuals with only around 511,000 persons excluded from mandatory contribution. The current pension system is divided into four categories distributing benefits to participants through national, military personnel, governmental, and private school teacher pension schemes. The national pension scheme is the primary welfare system providing allowances to the majority of persons. Eligibility for the national pension scheme is not dependent on income but on age and residence, where those between the ages of 18 to 59 are covered. Any one who is under the age of 18 are dependents of someone who is covered or under a special exclusion where they are allowed to alternative provisions. The national pension scheme is divided into four categories of insured persons – the workplace-based insured, the individually insured, the voluntarily insured, and the voluntarily and continuously insured.

Employees between the ages of 18 to 59 are covered under the workplace-based pension scheme and contribute 4.5% of their gross monthly earnings. The national pension covers employees who work in firms that employ five or more employees, fishermen, farmers, and the self-employed in both rural and urban areas. Employers are also covered under the workplace-based pension scheme and help cover their employees obligated 9% contribution by providing the remaining 4.5%. Anyone who is not employed, of the age of 60 or above, and excluded by article 6 of the National Pension Act but of the ages between 18 and 59, is covered under the individually insured pension scheme. Persons covered by the individually insured pension scheme are in charge of paying the entire 9% contribution themselves. Voluntarily insured persons are not subjected to mandatory coverage but can choose to be. This category comprises retirees who voluntarily choose to have additional benefits, individuals under the age of 27 without income, and individuals whose spouses are covered under a public welfare system, whether military, governmental, or private school teacher pensions. Like the Individually insured persons, they too are in charge of covering the full amount of the contribution. Voluntarily and continuously insured persons consists of individuals 60 years of age who want to fulfill the minimum insured period of 20 years to qualify for old age pension benefits. Excluding the workplace-based insured persons, all the other insured persons personally cover their own 9% contribution.

South Korea's old-age pension scheme covers individuals age 60 or older for the rest of their life as long as they have satisfied the minimum of 20 years of national pension coverage beforehand. Individuals with a minimum of 10 years covered under the national pension scheme and who are 60 years of age are able to be covered by under a 'reduced old-age pension' scheme. There also is an 'active old-age pension' scheme that covers individuals age 60 to 65 engaged in activities yielding earned income. Individuals age of 55 and younger than 60 who are not engaged in activities yielding earned income are eligible to be covered under the 'early old-age pension' scheme. Around 60% of all Korean elders, age 65 and over are entitled to a 5% benefit of their past average income at an average of 90,000 Korean Won (KRW). Basic old-age pension schemes covered individuals 65 years of age who earned below an amount set by presidential order. In 2010, that ceiling was 700,00 KRW for a single individual and 1,120,000 for a couple, equivalent to around $600.00 and $960.00.

Scientific and technological development in the South Korea at first did not occur largely because of more pressing matters such as the division of Korea and the Korean War that occurred right after its independence. It was not until the 1960s under the dictatorship of Park Chung-hee where South Korea's economy rapidly grew from industrialisation and the Chaebol corporations such as Samsung and LG. Ever since the industrialization of South Korea's economy, South Korea has placed its focus on technology-based corporations, which has been supported by infrastructure developments by the government. South Korean corporations Samsung and LG were ranked first and third largest mobile phone companies in the world in the first quarter of 2012, respectively. An estimated 90% of South Koreans own a mobile phone. Aside from placing/receiving calls and text messaging, mobile phones in the country are widely used for watching Digital Multimedia Broadcasting (DMB) or viewing websites. Over one million DMB phones have been sold and the three major wireless communications providers SK Telecom, KT, and LG U+ provide coverage in all major cities and other areas. South Korea has the fastest Internet download speeds in the world, with an average download speed of 25.3 Mbit/s.

South Korea leads the OECD in graduates in science and engineering. From 2014 to 2019, the country ranked first among the most innovative countries in the Bloomberg Innovation Index. Additionally, South Korea today is known as a Launchpad of a mature mobile market, where developers can reap benefits of a market where very few technology constraints exist. There is a growing trend of inventions of new types of media or apps, utilizing the 4G and 5G internet infrastructure in South Korea. South Korea has today the infrastructures to meet a density of population and culture that has the capability to create strong local particularity.

Following cyberattacks in the first half of 2013, whereby government, news-media, television station, and bank websites were compromised, the national government committed to the training of 5,000 new cybersecurity experts by 2017. The South Korean government blamed North Korea for these attacks, as well as incidents that occurred in 2009, 2011 and 2012, but Pyongyang denies the accusations.

In late September 2013, a computer-security competition jointly sponsored by the defense ministry and the National Intelligence Service was announced. The winners were announced on September 29, 2013 and shared a total prize pool of 80 million won (US$74,000).

South Korea's government maintains a broad-ranging approach toward the regulation of specific online content and imposes a substantial level of censorship on election-related discourse and on many websites that the government deems subversive or socially harmful.

South Korea has sent up 10 satellites since 1992, all using foreign rockets and overseas launch pads, notably Arirang-1 in 1999, and Arirang-2 in 2006 as part of its space partnership with Russia. Arirang-1 was lost in space in 2008, after nine years in service.

In April 2008, Yi So-yeon became the first Korean to fly in space, aboard the Russian Soyuz TMA-12.

In June 2009, the first spaceport of South Korea, Naro Space Center, was completed at Goheung, Jeollanam-do. The launch of Naro-1 in August 2009 resulted in a failure. The second attempt in June 2010 was also unsuccessful. However, the third launch of the Naro 1 in January 2013 was successful. The government plans to develop Naro-2 by the year 2018.

South Korea's efforts to build an indigenous space launch vehicle have been marred due to persistent political pressure from the United States, who had for many decades hindered South Korea's indigenous rocket and missile development programs in fear of their possible connection to clandestine military ballistic missile programs, which Korea many times insisted did not violate the research and development guidelines stipulated by US-Korea agreements on restriction of South Korean rocket technology research and development. South Korea has sought the assistance of foreign countries such as Russia through MTCR commitments to supplement its restricted domestic rocket technology. The two failed KSLV-I launch vehicles were based on the Universal Rocket Module, the first stage of the Russian Angara rocket, combined with a solid-fueled second stage built by South Korea.

Robotics has been included in the list of main national R&D projects in Korea since 2003. In 2009, the government announced plans to build robot-themed parks in Incheon and Masan with a mix of public and private funding.

In 2005, Korea Advanced Institute of Science and Technology (KAIST) developed the world's second walking humanoid robot, HUBO. A team in the Korea Institute of Industrial Technology developed the first Korean android, EveR-1 in May 2006.
EveR-1 has been succeeded by more complex models with improved movement and vision.

Plans of creating English-teaching robot assistants to compensate for the shortage of teachers were announced in February 2010, with the robots being deployed to most preschools and kindergartens by 2013. Robotics are also incorporated in the entertainment sector as well; the "Korean Robot Game Festival" has been held every year since 2004 to promote science and robot technology.

Since the 1980s, the Korean government has invested in the development of a domestic biotechnology industry, and the sector is projected to grow to by 2010. The medical sector accounts for a large part of the production, including production of hepatitis vaccines and antibiotics.

Recently, research and development in genetics and cloning has received increasing attention, with the first successful cloning of a dog, Snuppy (in 2005), and the cloning of two females of an endangered species of wolves by the Seoul National University in 2007.

The rapid growth of the industry has resulted in significant voids in regulation of ethics, as was highlighted by the scientific misconduct case involving Hwang Woo-Suk.

South Korea shares its traditional culture with North Korea, but the two Koreas have developed distinct contemporary forms of culture since the peninsula was divided in 1945. Historically, while the culture of Korea has been heavily influenced by that of neighboring China, it has nevertheless managed to develop a unique cultural identity that is distinct from its larger neighbor. Its rich and vibrant culture left 19 UNESCO Intangible Cultural Heritages of Humanity, the third largest in the world, along with 12 World Heritage Sites. The South Korean Ministry of Culture, Sports and Tourism actively encourages the traditional arts, as well as modern forms, through funding and education programs.

The industrialization and urbanization of South Korea have brought many changes to the way modern Koreans live. Changing economics and lifestyles have led to a concentration of population in major cities, especially the capital Seoul, with multi-generational households separating into nuclear family living arrangements. A 2014 Euromonitor study found that South Koreans drink the most alcohol on a weekly basis compared to the rest of the world. South Koreans drink 13.7 shots of liquor per week on average and, of the 44 other countries analyzed, Russia, the Philippines, and Thailand follow.

Korean art has been highly influenced by Buddhism and Confucianism, which can be seen in the many traditional paintings, sculptures, ceramics and the performing arts. Korean pottery and porcelain, such as Joseon's "baekja" and buncheong, and Goryeo's celadon are well known throughout the world. The Korean tea ceremony, pansori, talchum and buchaechum are also notable Korean performing arts.

Post-war modern Korean art started to flourish in the 1960s and 1970s, when South Korean artists took interest in geometrical shapes and intangible subjects. Establishing a harmony between man and nature was also a favorite of this time. Because of social instability, social issues appeared as main subjects in the 1980s. Art was influenced by various international events and exhibits in Korea, and with it brought more diversity. The Olympic Sculpture Garden in 1988, the transposition of the 1993 edition of the Whitney Biennial to Seoul, the creation of the Gwangju Biennale and the Korean Pavilion at the Venice Biennale in 1995 were notable events.

Because of South Korea's tumultuous history, construction and destruction has been repeated endlessly, resulting in an interesting melange of architectural styles and designs.

Korean traditional architecture is characterized by its harmony with nature. Ancient architects adopted the bracket system characterized by thatched roofs and heated floors called "ondol". People of the upper classes built bigger houses with elegantly curved tiled roofs with lifting eaves. Traditional architecture can be seen in the palaces and temples, preserved old houses called "hanok", and special sites like Hahoe Folk Village, Yangdong Village of Gyeongju and Korean Folk Village. Traditional architecture may also be seen at the nine UNESCO World Heritage Sites in South Korea.

Western architecture was first introduced to Korea at the end of the 19th century. Churches, offices for foreign legislation, schools and university buildings were built in new styles. With the annexation of Korea by Japan in 1910 the colonial regime intervened in Korea's architectural heritage, and Japanese-style modern architecture was imposed. The anti-Japanese sentiment, and the Korean War, led to the destruction of most buildings constructed during that time.

Korean architecture entered a new phase of development during the post-Korean War reconstruction, incorporating modern architectural trends and styles. Stimulated by the economic growth in the 1970s and 1980s, active redevelopment saw new horizons in architectural design. In the aftermath of the 1988 Seoul Olympics, South Korea has witnessed a wide variation of styles in its architectural landscape due, in large part, to the opening up of the market to foreign architects. Contemporary architectural efforts have been constantly trying to balance the traditional philosophy of "harmony with nature" and the fast-paced urbanization that the country has been going through in recent years.

Korean cuisine, "hanguk yori" (한국요리; 韓國料理), or "hansik" (한식; 韓食), has evolved through centuries of social and political change. Ingredients and dishes vary by province. There are many significant regional dishes that have proliferated in different variations across the country in the present day. The Korean royal court cuisine once brought all of the unique regional specialties together for the royal family. Meals consumed both by the royal family and ordinary Korean citizens have been regulated by a unique culture of etiquette.

Korean cuisine is largely based on rice, noodles, tofu, vegetables, fish and meats. Traditional Korean meals are noted for the number of side dishes, "banchan" (반찬), which accompany steam-cooked short-grain rice. Every meal is accompanied by numerous banchan. Kimchi (김치), a fermented, usually spicy vegetable dish is commonly served at every meal and is one of the best known Korean dishes. Korean cuisine usually involves heavy seasoning with sesame oil, "doenjang" (된장), a type of fermented soybean paste, soy sauce, salt, garlic, ginger, and "gochujang" (고추장), a hot pepper paste. Other well-known dishes are "Bulgogi" (불고기), grilled marinated beef, "Gimbap" (김밥), and "Tteokbokki" (떡볶이), a spicy snack consisting of rice cake seasoned with gochujang or a spicy chili paste.

Soups are also a common part of a Korean meal and are served as part of the main course rather than at the beginning or the end of the meal. Soups known as "guk" (국) are often made with meats, shellfish and vegetables. Similar to guk, "tang" (탕; 湯) has less water, and is more often served in restaurants. Another type is "jjigae" (찌개), a stew that is typically heavily seasoned with chili pepper and served boiling hot.

Popular Korean alcoholic beverages include Soju, Makgeolli and Bokbunja ju.

Korea is unique among East Asian countries in its use of metal chopsticks. Metal chopsticks have been discovered in Goguryeo archaeological sites.

In addition to domestic consumption, South Korea has a thriving entertainment industry where various facets of South Korean entertainment, including television dramas, films, and popular music, has generated significant financial revenues for the nation's economy. The cultural phenomenon known as "Hallyu" or the "Korean Wave", has swept many countries across Asia making South Korea a major soft power as an exporter of popular culture and entertainment, rivaling Western nations such as the United States and the United Kingdom.

Until the 1990s, trot and traditional Korean folk based ballads dominated South Korean popular music. The emergence of the South Korean pop group Seo Taiji and Boys in 1992 marked a turning point for South Korean popular music, also known as K-pop, as the genre modernized itself from incorporating elements of popular musical genres from across the world such as Western popular music, experimental, jazz, gospel, Latin, classical, hip hop, rhythm and blues, electronic dance, reggae, country, folk, and rock on top of its uniquely traditional Korean music roots. Western-style pop, hip hop, rhythm and blues, rock, folk, electronic dance oriented acts have become dominant in the modern South Korean popular music scene, though trot is still enjoyed among older South Koreans. K-pop stars and groups are well known across Asia and have found international fame making millions of dollars in export revenue. Many K-pop acts have also been able secure a strong overseas following using online social media platforms such as the video sharing website YouTube. South Korean singer PSY became an international sensation when his song "Gangnam Style" topped global music charts in 2012. 

Since the success of the film "Shiri" in 1999, the Korean film industry has begun to gain recognition internationally. Domestic film has a dominant share of the market, partly because of the existence of screen quotas requiring cinemas to show Korean films at least 73 days a year. 2019's "Parasite", directed by Bong Joon Ho, became the highest-grossing film in South Korea as well as the first non-English language film to win Best Picture at the United States-based Academy Awards that year amongst numerous other accolades.

South Korean television shows have become popular outside of Korea. South Korean television dramas, known as K-dramas, have begun to find fame internationally. Many dramas tend to have a romantic focus, such as "Princess Hours", "You're Beautiful", "Playful Kiss", "My Name is Kim Sam Soon", "Boys Over Flowers", "Winter Sonata", "Autumn in My Heart", "Full House", "City Hunter", "All About Eve", "Secret Garden", "I Can Hear Your Voice", "Master's Sun", "My Love from the Star", "Healer", "Descendants of the Sun" and "". Historical dramas have included "Faith", "Dae Jang Geum", "The Legend", "Dong Yi", "Moon Embracing the Sun", "Sungkyunkwan Scandal", and "Iljimae".

There are many official public holidays in South Korea. Korean New Year's Day, or "Seollal", is celebrated on the first day of the Korean lunar calendar. Korean Independence Day falls on March 1, and commemorates the March 1 Movement of 1919. Memorial Day is celebrated on June 6, and its purpose is to honor the men and women who died in South Korea's independence movement. Constitution Day is on July 17, and it celebrates the promulgation of Constitution of the Republic of Korea. Liberation Day, on August 15, celebrates Korea's liberation from the Empire of Japan in 1945. Every 15th day of the 8th lunar month, Koreans celebrate the Midautumn Festival, in which Koreans visit their ancestral hometowns and eat a variety of traditional Korean foods. On October 1, Armed Forces day is celebrated, honoring the military forces of South Korea. October 3 is National Foundation Day. Hangul Day, on October 9 commemorates the invention of hangul, the native alphabet of the Korean language.

The martial art taekwondo originated in Korea. In the 1950s and 1960s, modern rules were standardized, with taekwondo becoming an official Olympic sport in 2000. Other Korean martial arts include Taekkyon, hapkido, Tang Soo Do, Kuk Sool Won, kumdo and subak.

Football and baseball have traditionally been regarded as the most popular sports in Korea. Recent polling indicates that a majority, 41% of South Korean sports fans continue to self-identify as football fans, with baseball ranked 2nd at 25% of respondents. However, the polling did not indicate the extent to which respondents follow both sports. The national football team became the first team in the Asian Football Confederation to reach the FIFA World Cup semi-finals in the 2002 FIFA World Cup, jointly hosted by South Korea and Japan. The Korea Republic national team (as it is known) has qualified for every World Cup since Mexico 1986, and has broken out of the group stage twice: first in 2002, and again in 2010, when it was defeated by eventual semi-finalist Uruguay in the Round of 16. At the 2012 Summer Olympics, South Korea won the Bronze Medal for football.

Baseball was first introduced to Korea in 1905 and has since become increasingly popular, with some sources claiming it has surpassed football as the most popular sport in the country. Recent years have been characterized by increasing attendance and ticket prices for professional baseball games. The Korea Professional Baseball league, a 10-team circuit, was established in 1982. The South Korea national team finished third in the 2006 World Baseball Classic and second in the 2009 tournament. The team's 2009 final game against Japan was widely watched in Korea, with a large screen at Gwanghwamun crossing in Seoul broadcasting the game live. In the 2008 Summer Olympics, South Korea won the gold medal in baseball. Also in 1982, at the Baseball Worldcup, Korea won the gold medal. At the 2010 Asian Games, the Korean National Baseball team won the gold medal. Several Korean players have gone on to play in Major League Baseball.

Basketball is a popular sport in the country as well. South Korea has traditionally had one of the top basketball teams in Asia and one of the continent's strongest basketball divisions. Seoul hosted the 1967 and 1995 Asian Basketball Championship. The Korea national basketball team has won a record number of 23 medals at the event to date.
South Korea hosted the Asian Games in 1986 (Seoul), 2002 (Busan) and 2014 (Incheon). It also hosted the Winter Universiade in 1997, the Asian Winter Games in 1999 and the Summer Universiade in 2003, 2015. In 1988, South Korea hosted the Summer Olympics in Seoul, coming fourth with 12 gold medals, 10 silver medals and 11 bronze medals. South Korea regularly performs well in archery, shooting, table tennis, badminton, short track speed skating, handball, hockey, freestyle wrestling, Greco-Roman wrestling, baseball, judo, taekwondo, speed skating, figure Skating, and weightlifting. The Seoul Olympic Museum is a museum in Seoul, South Korea, dedicated to the 1988 Summer Olympics. On July 6, 2011 Pyeongchang was chosen by the IOC to host the 2018 Winter Olympics.

South Korea has won more medals in the Winter Olympics than any other Asian country with a total of 45 medals (23 gold, 14 silver, and 8 bronze). At the 2010 Winter Olympics, South Korea ranked fifth in the overall medal rankings. South Korea is especially strong in short track speed skating. However, speed skating and figure skating are very popular, too, and ice hockey is an emerging sport with Anyang Halla winning their first ever Asia League Ice Hockey title in March 2010.

Seoul hosted a professional triathlon race, which is part of the International Triathlon Union (ITU) World Championship Series in May 2010. In 2011, the South Korean city of Daegu hosted the 2011 IAAF World Championships in Athletics.
In October 2010, South Korea hosted its first Formula One race at the Korea International Circuit in Yeongam, about south of Seoul. The Korean Grand Prix was held from 2010 to 2013, but was not placed on the 2014 F1 calendar.

Domestic horse racing events are also followed by South Koreans and Seoul Race Park in Gwacheon, Gyeonggi-do is located closest to Seoul out of the country's three tracks.

Competitive video gaming, also called Esports (sometimes written e-Sports), has become more popular in South Korea in recent years, particularly among young people. The two most popular games are League of Legends and StarCraft. The gaming scene of South Korea is managed by the Korean e-Sports Association.





</doc>
<doc id="27020" url="https://en.wikipedia.org/wiki?curid=27020" title="History of South Korea">
History of South Korea

The history of South Korea formally begins with its establishment on 15 August 1948.

Korea was administratively partitioned in 1945, at the end of World War II. As Korea was under Japanese rule during World War II, Korea was officially a belligerent against the Allies by virtue of being Japanese territory. The unconditional surrender of Japan led to the division of Korea into two occupation zones (similar to the four zones in Germany), with the United States administering the southern half of the peninsula and the Soviet Union administering the area north of the 38th parallel. This division was meant to be temporary (as was in Germany) and was first intended to return a unified Korea back to its people after the United States, United Kingdom, Soviet Union, and Republic of China could arrange a single government for the peninsula.

The two parties were unable to agree on the implementation of Joint Trusteeship over Korea. This led in 1948 to the establishment of two separate governments – the Communist-aligned Democratic People's Republic of Korea (DPRK) and the West-aligned First Republic of Korea – each claiming to be the legitimate government of all of Korea. On June 25, 1950 the Korean War broke out. After much destruction, the war ended on July 27, 1953 with the 1948 status quo being restored, as neither the DPRK nor the First Republic had succeeded in conquering the other's portion of the divided Korea. The peninsula was divided by the Korean Demilitarized Zone and the two separate governments stabilised into the existing political entities of North and South Korea.

South Korea's subsequent history is marked by alternating periods of democratic and autocratic rule. Civilian governments are conventionally numbered from the First Republic of Syngman Rhee to the contemporary Sixth Republic. The First Republic, arguably democratic at its inception, became increasingly autocratic until its collapse in 1960. The Second Republic was strongly democratic, but was overthrown in less than a year and replaced by an autocratic military regime. The Third, Fourth, and Fifth Republics were nominally democratic, but are widely regarded as the continuation of military rule. With the Sixth Republic, the country has gradually stabilized into a liberal democracy.

Since its inception, South Korea has seen substantial development in education, economy, and culture. Since the 1960s, the country has developed from one of Asia's poorest to one of the world's wealthiest nations. Education, particularly at the tertiary level, has expanded dramatically. It is said to be one of the "Four Tigers" of rising Asian states along with Singapore, Taiwan and Hong Kong.

Emperor Hirohito announced the surrender of the Empire of Japan to the Allied Powers on 15 August 1945. General Order No. 1 for the surrender of Japan (prepared by the Joint Chiefs of Staff of U.S. military forces and approved on 17 August 1945) prescribed separate surrender procedures for Japanese forces in Korea north and south of the 38th parallel. After Japan's surrender to the Allies (formalised on 2 September 1945), division at the 38th parallel marked the beginning of Soviet and U.S. occupation the North and South, respectively. This division was meant to be temporary, to be replaced by a trusteeship of the United States, United Kingdom, Soviet Union, and Republic of China which would prepare for Korean independence. The trusteeship had been discussed at the Yalta Conference in February 1945. U.S. forces landed at Incheon on September 8, 1945 and established a military government shortly thereafter. Lieutenant General John R. Hodge, their commander, took charge of the government. Faced with mounting popular discontent, in October 1945 Hodge established the Korean Advisory Council. The Provisional Government of the Republic of Korea, which had operated from China, sent a delegation with three interpreters to Hodge, but he refused to meet with them. Likewise, Hodge refused to recognize the newly formed People's Republic of Korea and its People's Committees, and outlawed it on 12 December. A year later, an interim legislature and interim government were established, headed by Kim Kyu-shik and Syngman Rhee respectively. Political and economic chaos - arising from a variety of causes - plagued the country in this period. The after-effects of the Japanese exploitation remained in the South, as in the North. In addition, the U.S. military was largely unprepared for the challenge of administering the country, arriving with no knowledge of the language, culture or political situation. Thus many of their policies had unintended destabilizing effects. Waves of refugees from North Korea and returnees from abroad added to the turmoil.

In December 1945 a conference convened in Moscow to discuss the future of Korea.
A 5-year trusteeship was discussed, and a was established. The commission met intermittently in Seoul but deadlocked over the issue of establishing a national government. In September 1947, with no solution in sight, the United States submitted the Korean question to the UN General Assembly.

The resolution from the UN General Assembly called for a UN-supervised general election in Korea, but after the North rejected this proposition, a general election for a Constitutional Assembly took place in the South only, in May 1948. A constitution was adopted, setting forth a presidential form of government and specifying a four-year term for the presidency. According to the provisions of the Constitution, an indirect presidential election took place in July. Rhee Syngman, as head of the new assembly, assumed the presidency and proclaimed the Republic of Korea (South Korea) on August 15, 1948.

On 15 August 1948, the Republic of Korea was formally established, with Syngman Rhee as the first president. With the establishment of Rhee's government, de jure sovereignty also passed into the new government. On September 9, 1948, a communist regime, the Democratic People's Republic of Korea (North Korea), was proclaimed under Kim Il-sung. However, on December 12, 1948, by its resolution 195 in the Third General Assembly, the United Nations recognized the Republic of Korea as the sole legal government of Korea.

In 1946, the North implemented land reforms by confiscating private property, Japanese and pro-Japanese owned facilities and factories, and placed them under state ownership. Demand for land reform in the South grew strong, and it was eventually enacted in June 1949. Koreans with large landholdings were obliged to divest most of their land. Approximately 40 percent of total farm households became small landowners. However, because preemptive rights were given to people who had ties with landowners before liberation, many pro-Japanese groups obtained or retained properties.

With the country now divided, the relationship between the two Koreas turned more antagonistic as time passed. The Soviet forces having withdrawn in 1948, North Korea pressured the South to expel the United States forces, but Rhee sought to align his government strongly with America, and against both North Korea and Japan. Although talks towards normalization of relations with Japan took place, they achieved little. Meanwhile, the government took in vast sums of American aid, in amounts sometimes near the total size of the national budget. The nationalist government also continued many of the practices of the U.S. military government. In 1948, the Rhee government repressed military uprisings in Jeju, Suncheon and Yeosu. During the rebellion and its suppression 14,000 to 60,000 people were killed in all fighting. Of note, President Rhee's regime was intolerant of opposition. A famous event that highlighted this was the arrest and conviction of future President Park Chung-hee, for communist conspiracy in 1948.

The main policy of the First Republic of South Korea was anti-communism and "unification by expanding northward". The South's military was neither sufficiently equipped nor prepared, but the Rhee administration was determined to reunify Korea by military force with aid from the United States. However, in the second parliamentary elections held on May 30, 1950, the majority of seats went to independents who did not endorse this position, confirming the lack of support and the fragile state of the nation.

When the communist army attacked from the North in June, retreating South Korean forces executed tens of thousands suspected communists or sympathisers, either in prison or in a reeducation movement, in what is known as the Bodo League massacre.

On 25 June 1950, North Korean forces invaded South Korea. Led by the U.S., a 16-member coalition undertook the first collective action under the United Nations Command (UNC) in defense of South Korea. Oscillating battle lines inflicted a high number of civilian casualties and wrought immense destruction. With the People's Republic of China's entry on behalf of North Korea in late 1950, the fighting came to a stalemate close to the original line of demarcation. Armistice negotiations, initiated in July 1951, finally concluded on 27 July 1953 at Panmunjeom, now in the Demilitarized Zone (DMZ). Following the armistice, the South Korean government returned to Seoul on the symbolic date of 15 August 1953.

After the armistice, South Korea experienced political turmoil under years of autocratic leadership of Syngman Rhee, which was ended by student revolt in 1960. Throughout his rule, Rhee sought to take additional steps to cement his control of government. These began in 1952, when the government was still based in Busan due to the ongoing war. In May of that year, Rhee pushed through constitutional amendments which made the presidency a directly-elected position. To do this, he declared martial law, arrested opposing members of parliament, demonstrators, and anti-government groups. Rhee was subsequently elected by a wide margin.

Rhee regained control of parliament in the 1954 election, and thereupon pushed through an amendment to exempt himself from the eight-year term limit, and was once again re-elected in 1956. Soon after, Rhee's administration arrested members of the opposing party and executed the leader after accusing him of being a North Korean spy.

The administration became increasingly repressive while dominating the political arena, and in 1958, it sought to amend the National Security Law to tighten government control over all levels of administration, including the local units. These measures caused much outrage among the people, but despite public outcry, Rhee's administration rigged the March 1960 presidential election and won by a landslide.

On that election day, protests by students and citizens against the irregularities of the election burst out in the city of Masan. Initially these protests were quelled with force by local police, but when the body of a student was found floating in the harbor of Masan, the whole country was enraged and protests spread nationwide. On 19 April, students from various universities and schools rallied and marched in protest in the Seoul streets, in what would be called the April Revolution. The government declared martial law, called in the army, and suppressed the crowds with open fire. Subsequent protests throughout the country shook the government, and after an escalated protest with university professors taking to the streets on April 25, Rhee submitted his official resignation on April 26 and fled into exile.

After the student revolution, power was briefly held by an interim administration under the Foreign Minister Heo Jeong. A new parliamentary election was held on July 29, 1960. The Democratic Party, which had been in the opposition during the First Republic, easily gained power and the Second Republic was established. The revised constitution dictated the Second Republic to take the form of a parliamentary cabinet system where the President took only a nominal role. This was the first and the only instance South Korea turned to a parliamentary cabinet system instead of a presidential system. The assembly elected Yun Bo-seon as President and Chang Myon as the Prime Minister and head of government in August, 1960.

The Second Republic saw the proliferation of political activity which had been repressed under the Rhee regime. Much of this activity was from leftist and student groups, which had been instrumental in the overthrow of the First Republic. Union membership and activity grew rapidly during the later months of 1960, including the Teachers' Union, Journalists' Union, and the Federation of Korean Trade Union. Around 2,000 demonstrations were held during the eight months of the Second Republic.

Under pressure from the left, the Chang government carried out a series of purges of military and police officials who had been involved in anti-democratic activities or corruption. A Special Law to this effect was passed on October 31, 1960. 40,000 people were placed under investigation; of these, more than 2,200 government officials and 4,000 police officers were purged. In addition, the government considered reducing the size of the army by 100,000, although this plan was shelved.

In economic terms as well, the government was faced with mounting instability. The government formulated a Five-Year Economic Development Plan, although it was unable to act on it prior to being overthrown. The Second Republic saw the "hwan" lose half of its value against the dollar between fall 1960 and spring 1961.

Although the government had been established with support of the people, it had failed to implement effective reforms which brought about endless social unrest, political turmoil and ultimately, the May 16 coup.

The May 16 coup, led by Major General Park Chung-hee on May 16, 1961, put an effective end to the Second Republic. Park was one of a group of military leaders who had been pushing for the de-politicization of the military. Dissatisfied with the cleanup measures undertaken by the Second Republic and convinced that the current disoriented state would collapse into communism, they chose to take matters into their own hands.

The National Assembly was dissolved and military officers replaced the civilian officials. In May 1961, the junta declared "Pledges of the Revolution": anticommunism was to be the nation's main policy; friendly relations would be strengthened with allies of the free world, notably the United States; all corruption and government misdeed would be disposed and "fresh and clean morality" would be introduced; the reconstruction of a self-reliant economy would be priority; the nation's ability would be nurtured to fight against communism and achieve reunification; and that government would be returned to a democratic civilian government within two years.

As a means to check the opposition, the military authority created the Korean Central Intelligence Agency (KCIA) in June 1961, with Kim Jong-pil, a relative of Park, as its first director. In December 1962, a referendum was held on returning to a presidential system of rule, which was allegedly passed with a 78% majority. Park and the other military leaders pledged not to run for office in the next elections. However, Park became presidential candidate of the new Democratic Republican Party (DRP), which consisted of mainly KCIA officials, ran for president and won the election of 1963 by a narrow margin.

Park's administration started the Third Republic by announcing the Five-Year Economic Development Plan, an export-oriented industrialization policy. Top priority was placed on the growth of a self-reliant economy and modernization; "Development First, Unification Later" became the slogan of the times and the economy grew rapidly with vast improvement in industrial structure, especially in the basic and heavy chemical industries. Capital was needed for such development, so the Park regime used the influx of foreign aid from Japan and the United States to provide loans to export businesses, with preferential treatment in obtaining low-interest bank loans and tax benefits. Cooperating with the government, these businesses would later become the "chaebol".

Relations with Japan were normalized by the Korea-Japan treaty ratified in June 1965. This treaty brought Japanese funds in the form of loans and compensation for the damages suffered during the colonial era without an official apology from the Japanese government, sparking much protest across the nation.

The government also kept close ties with the United States, and continued to receive large amounts of aid. A status of forces agreement was concluded in 1966, clarifying the legal situation of the US forces stationed there. Soon thereafter, Korea joined the Vietnam War, eventually sending a total of 300,000 soldiers from 1964 to 1973 to fight alongside US troops and South Vietnamese Armed Forces.

Economic and technological growth during this period improved the standard for living, which expanded opportunities for education. Workers with higher education were absorbed by the rapidly growing industrial and commercial sectors, and urban population surged. Construction of the Gyeongbu Expressway was completed and linked Seoul to the nation's southeastern region and the port cities of Incheon and Busan. Despite the immense economic growth, however, the standard of living for city laborers and farmers was still low. Laborers were working with low wages to increase the price competitiveness for the export-oriented economy plan, and farmers were in near poverty as the government controlled prices. As the rural economy steadily lost ground and caused dissent among the farmers, however, the government decided to implement measures to increase farm productivity and income by instituting the Saemaul Movement ("New Village Movement") in 1971. The movement's goal was to improve the quality of rural life, modernize both rural and urban societies and narrow the income gap between them.

Park ran again in the 1967 presidential election, taking 51.4% of the vote. At the time the presidency was constitutionally limited to two terms, but a constitutional amendment was forced through the National Assembly in 1969 to allow him to seek a third term. Major protests and demonstrations against the constitutional amendment broke out, with large support gaining for the opposition leader Kim Dae-jung, but Park was again re-elected in the 1971 presidential election.

Parliamentary elections followed shortly after the presidential election where the opposition party garnered most of the seats, giving them the power to pass constitutional amendments. Park, feeling threatened, declared a state of national emergency on December 6, 1971. In the midst of this domestic insecurity, the Nixon Doctrine had eased tensions among the world superpowers on the international scene, which caused a dilemma for Park, who had justified his regime based on the state policy of anti-communism. In a sudden gesture, the government proclaimed a joint communiqué for reunification with North Korea on July 4, 1972, and held Red Cross talks in Seoul and Pyongyang. However, there was no change in government policy regarding reunification, and on October 17, 1972, Park declared martial law, dissolving the National Assembly and suspending the constitution.

The Fourth Republic began with the adoption of the Yushin Constitution on November 21, 1972. This new constitution gave Park effective control over the parliament and the possibility of permanent presidency. The president would be elected through indirect election by an elected body, and the term of presidency was extended to six years with no restrictions on reappointment. The legislature and judiciary were controlled by the government, and educational guidelines were under direct surveillance as well. Textbooks supporting the ideology of the military government were authorized by the government, diminishing the responsibilities of the Ministry of Education.

Despite social and political unrest, the economy continued to flourish under the authoritarian rule with the export-based industrialization policy. The first two five-year economic development plans were successful, and the 3rd and 4th five-year plans focused on expanding the heavy and chemical industries, raising the capability for steel production and oil refining. However, large conglomerate "chaebols" continuously received preferential treatment and came to dominate the domestic market. As most of the development had come from foreign capital, most of the profit went back to repaying the loans and interest.

Students and activists for democracy continued their demonstrations and protests for the abolition of the Yushin system and in the face of continuing popular unrest, Park's administration promulgated emergency decrees in 1974 and 1975, which led to the jailing of hundreds of dissidents. The protests grew larger and stronger, with politicians, intellectuals, religious leaders, laborers and farmers all joining in the movement for democracy. In 1978, Park was elected to another term by indirect election, which was met with more demonstrations and protests. The government retaliated by removing the opposition leader Kim Young-sam from the assembly and suppressing the activists with violent means. In 1979, mass anti-government demonstrations occurred nationwide, in the midst of this political turmoil, Park Chung-hee was assassinated by the director of the KCIA, Kim Jae-gyu, thus bringing the 18-year rule of military regime to an end.

After the assassination of Park Chung-hee, Prime Minister Choi Kyu-hah took the president's role only to be usurped 6 days later by Major General Chun Doo-hwan's 1979 Coup d'état of December Twelfth. In May of the following year, a vocal civil society composed primarily of university students and labour unions led strong protests against authoritarian rule all over the country. Chun Doo-hwan declared martial law on May 17, 1980, and protests escalated. Political opponents Kim Dae-jung and Kim Jong-pil were arrested, and Kim Young-sam was confined to house arrest.

On May 18, 1980, a confrontation broke out in the city of Gwangju between protesting students of Chonnam National University and the armed forces dispatched by the Martial Law Command. The incident turned into a citywide protest that lasted nine days until May 27 and resulted in the Gwangju massacre. Immediate estimates of the civilian death toll ranged from a few dozen to 2000, with a later full investigation by the civilian government finding nearly 200 deaths and 850 injured. In June 1980, Chun ordered the National Assembly to be dissolved. He subsequently created the National Defense Emergency Policy Committee, and installed himself as a member. On 17 July, he resigned his position of KCIA Director, and then held only the position of committee member. In September 1980, President Choi Kyu-hah was forced to resign from president to give way to the new military leader, Chun Doo-hwan.

In September of that year, Chun was elected president by indirect election and inaugurated in March of the following year, officially starting the Fifth Republic. A new Constitution was established with notable changes; maintaining the presidential system but limiting it to a single 7-year term, strengthening the authority of the National Assembly, and conferring the responsibilities of appointing judiciary to the Chief Justice of the Supreme Court. However, the system of indirect election of the president stayed and many military persons were appointed to highly ranked government positions, keeping the remnants of the Yushin era.

The government promised a new era of economic growth and democratic justice. Tight monetary laws and low interest rates contributed to price stability and helped the economy boom with notable growth in the electronics, semi-conductor, and automobile industries. The country opened up to foreign investments and GDP rose as Korean exports increased. This rapid economic growth, however, widened the gap between the rich and the poor, the urban and rural regions, and also exacerbated inter-regional conflicts. These dissensions, added to the hard-line measures taken against opposition to the government, fed intense rural and student movements, which had continued since the beginning of the republic.

In foreign policy, ties with Japan were strengthened by state visits by Chun to Japan and Japanese Prime Minister Yasuhiro Nakasone to Korea. U.S. President Ronald Reagan also paid a visit, and relations with the Soviet Union and China improved. The relationship with North Korea was strained when in 1983 a terrorist bomb attack in Burma killed 17 high-ranking officials attending memorial ceremonies and North Korea was alleged to be behind the attacks. However, in 1980 North Korea had submitted a "one nation, two system" reunification proposal which was met with a suggestion from the South to meet and prepare a unification constitution and government through a referendum. The humanitarian issue of reuniting separated families was dealt with first, and in September 1985, families from both sides of the border made cross visits to Seoul and Pyongyang in an historic event.The government made many efforts for cultural development: the National Museum of Korea, Seoul Arts Center, and National Museum of Contemporary Art were all constructed during this time. The 1986 Asian Games were held successfully, and the bid for the 1988 Summer Olympics in Seoul was successful as well.

Despite economic growth and success in diplomatic relations, the government that gained power by coup d'etat was essentially a military regime and the public's support and trust in it was low when the promises for democratic reform never materialized. In the 1985 National Assembly elections, opposition parties won more votes than the government party, clearly indicating that the public wanted a change. Many started to sympathize with the protesting students. The Gwangju massacre was never forgotten and in January 1987, when a protesting Seoul National University student died under police interrogation, public fury was immense. In April 1987, President Chun made a declaration that measures would be taken to protect the current constitution, instead of reforming it to allow for the direct election of the president. This announcement consolidated and strengthened the opposition; in June 1987, more than a million students and citizens participated in the nationwide anti-government protests of the June Democracy Movement.

On June 29, 1987, the government's presidential nominee Roh Tae-woo gave in to the demands and announced the June 29 Declaration, which called for the holding of direct presidential elections and restoration of civil rights. In October 1987 a revised Constitution was approved by a national referendum and direct elections for a new president were held in December, bringing the Fifth Republic to a close.

The Sixth Republic was established in 1987 and remains the current polity of South Korea.

Roh Tae-woo became president for the 13th presidential term in the first direct presidential election in 16 years. Although Roh was from a military background and one of the leaders of Chun's coup d'état, the inability of the opposition leaders Kim Dae-jung and Kim Young-sam to agree on a unified candidacy, led to his being elected. The first female presidential candidate, Hong Sook-ja, even withdrew from the race in order to back Kim Young-sam against Roh.Roh was officially inaugurated in February 1988. The government set out to eliminate past vestiges of authoritarian rule, by revising laws and decrees to fit democratic provisions. Freedom of the press was expanded, university autonomy recognised, and restrictions on overseas travels were lifted. However, the growth of the economy had slowed down compared to the 1980s, with strong labor unions and higher wages reducing the competitiveness of Korean products on the international market, resulting in stagnant exports, while commodity prices kept on rising.

Shortly after Roh's inauguration, the Seoul Olympics took place, raising South Korea's international recognition and also greatly influencing foreign policy. Roh's government announced the official unification plan, "Nordpolitik", and established diplomatic ties with the Soviet Union, China, and countries in East Europe.

A historic event was held in 1990 when North Korea accepted the proposal for exchange between the two Koreas, resulting in high-level talks, and cultural and sports exchanges. In 1991, a joint communiqué on denuclearization was agreed upon, and the two Koreas simultaneously became members of the UN.

Kim Young-sam was elected president in the 1992 elections after Roh's tenure. He was the country's first civilian president in 30 years since 1962 and promised to build a "New Korea". The government set out to correct the mistakes of the previous administrations. Local government elections were held in 1995, and parliamentary elections in 1996. In a response to popular demand, former presidents Chun and Roh were both indicted on charges linked to bribery, illegal funds, and in the case of Chun, responsibility for the Gwangju massacre. They were tried and sentenced to prison in December 1996.

Relations with the North improved and a summit meeting was planned, but postponed indefinitely with the death of Kim Il-sung. Tensions varied between the two Koreas thereafter, with cycles of small military skirmishes and apologies. The government also carried out substantial financial and economical reforms, joining the OECD in 1996, but encountered difficulties with political and financial scandals involving his son. The country also faced a variety of catastrophes which claimed many lives: a train collision and a ship sinking in 1993, and the Seongsu Bridge and Sampoong Department Store collapses in 1994 and 1995. These incidents were a blow to the civilian government.

In 1997, the nation suffered a severe financial crisis, and the government approached the International Monetary Fund for relief funds. This was the limit to what the nation could bear and led to the opposition leader Kim Dae-jung winning the presidency in the same year. This is the first time an opposition candidate won the presidency.

In February 1998, Kim Dae-jung was officially inaugurated. South Korea had maintained its commitment to democratize its political processes and this was the first transfer of the government between parties by peaceful means. Kim's government faced the daunting task of overcoming the economic crisis, but with the joint efforts of the government's aggressive pursuit of foreign investment, cooperation from the industrial sector, and the citizen's gold-collecting campaign, the country was able to come out of the crisis in a relatively short period of time.

Industrial reconstruction of the big conglomerate "chaebols" was pursued, a national pension system was established in 1998, educational reforms were carried out, government support for the IT field was increased, and notable cultural properties were registered as UNESCO Cultural Heritage sites. The 2002 FIFA World Cup, co-hosted with Japan, was a major cultural event where millions of supporters gathered to cheer in public places.

In diplomacy, Kim Dae-jung pursued the "Sunshine Policy", a series of efforts to reconcile with North Korea. This culminated in reunions of the separated families of the Korean War and a summit talk with North Korean leader Kim Jong-il. For these efforts, Kim Dae-jung was awarded the Nobel Peace Prize in 2000. However, between a lack of peaceful cooperation from North Korea and the terrorist attacks on the United States on September 11, 2001, changing the view of the U.S. on North Korea, the efficacy of the Sunshine Policy was brought into question. With added allegations of corruption, support waned in the later years of the administration.

Roh Moo-hyun was elected to the presidency in December 2002 by direct election. His victory came with much support from the younger generation and civic groups who had hopes of a participatory democracy, and Roh's administration consequently launched with the motto of "participation government". Unlike the previous governments, the administration decided to take a long-term view and execute market-based reforms at a gradual pace. This approach did not please the public, however, and by the end of 2003, approval ratings were falling.

The Roh administration succeeded in overcoming regionalism in South Korean politics, diluting the collusive ties between politics and business, empowering the civil society, settling the Korea-United States FTA issue, continuing summit talks with North Korea, and launching the high-speed train system, KTX. But despite a boom in the stock market, youth unemployment rates were high, real estate prices skyrocketed and the economy lagged.

In March 2004, the National Assembly voted to impeach Roh on charges of breach of election laws and corruption. This motion rallied his supporters and affected the outcome of the parliamentary election held in April, with the ruling party becoming the majority. Roh was reinstated in May by the Constitutional Court, who had overturned the verdict. However, the ruling party then lost its majority in by-elections in 2005, as discontinued reform plans, continual labor unrest, Roh's personal feuds with the media, and diplomatic friction with the United States and Japan caused criticism of the government's competence on political and socioeconomic issues and on foreign affairs.

In April 2009, Roh Moo-hyun and his family members were investigated for bribery and corruption; Roh denied the charges. On 23 May 2009, Roh committed suicide by jumping into a ravine.

Roh's successor, Lee Myung-bak, was inaugurated in February 2008. Stating "creative pragmatism" as a guiding principle, Lee's administration set out to revitalize the flagging economy, re-energize diplomatic ties, stabilize social welfare, and meet the challenges of globalization. In April 2008, the ruling party secured a majority in the National Assembly elections. Also that month, summit talks with the United States addressed the Korea-US Free Trade Agreement and helped ease tensions between the two countries caused by the previous administrations. Lee agreed to lift the ban on US beef imports, which caused massive protests and demonstrations in the months that followed, as paranoia of potential mad cow disease gripped the country.

Many issues plagued the government in the beginning of the administration: controversies regarding the appointment of high-ranking government officials, rampant political conflicts, accusations of oppression of media and strained diplomatic relationships with North Korea and Japan. The economy was affected by the global recession as the worst economic crisis since 1997 hit the country. The Lee administration tackled these issues by actively issuing statements, reshuffling the cabinet, and implementing administrative and industrial reforms.

After regulatory and economic reforms, the economy bounced back, with the country's economy marking growth and apparently recovering from the global recession. The administration also pursued improved diplomatic relations by holding summit talks with the United States, China and Japan, and participating in the ASEAN-ROK Commemorative Summit to strengthen ties with other Asian countries. The 2010 G20 summit was held in Seoul, where issues regarding the global economic crisis were discussed.

Park Geun-hye was inaugurated in February 2013. She is the eighteenth President of South Korea and is the eldest child of South Korea's stratocratic third President, Park Chung-hee. She was the first woman to be elected South Korean president, and to be elected as a head of state in the modern history of Northeast Asia. Over the years, however, her reputation was marred by her incompetency of handling the "Sewol" ferry disaster, and later a major scandal, leading to her impeachment in December 2016. The corruption scandal involving Choi Soon-sil quickly blew up after reports from multiple news organizations (the most notable of which was JTBC) in 2016, nationwide protests ensued on a weekly basis, with participant count hitting a maximum of over 2.3 million (as reported by the protesters). These protests turned out to be the biggest series of mass protests in Korean history. The protests continued even after the Congress voted on Park's impeachment. Prime Minister Hwang Kyo-ahn acted as President of South Korea pending completion of investigations into the actions of Park Geun-hye, and in the absence of any intervening election. The impeachment was upheld by the Constitutional Court on 10 March 2017, ending Park's presidency and forcing her out of office.

Moon Jae-in is the current president of South Korea. He was inaugurated on May 10, 2017. As President, Moon Jae-in has met with North Korean chairman Kim Jong-un at the April 2018 inter-Korean summit, May 2018 inter-Korean summit, and September 2018 inter-Korean summit.





</doc>
<doc id="27021" url="https://en.wikipedia.org/wiki?curid=27021" title="Geography of South Korea">
Geography of South Korea

South Korea is located in East Asia, on the southern half of the Korean Peninsula located out from the far east of the Asian landmass. The only country with a land border to South Korea is North Korea, lying to the north with of the border running along the Korean Demilitarized Zone. South Korea is mostly surrounded by water and has of coast line along three seas; to the west is the Yellow Sea (West Sea), to the south is the East China Sea, and to the east is the Sea of Japan (known as the "East Sea" in South Korea). Geographically, South Korea's landmass is approximately . of South Korea are occupied by water. The approximate coordinates are 37° North, 128° East.

The Korean Peninsula extends southward from the northeast part of the Asian continental landmass. The Japanese islands of Honshū and Kyūshū are located some 200  km (124  mi) to the southeast across the Korea Strait; the Shandong Peninsula of China lies 190 kilometers to the west. The west coast of the peninsula is bordered by the Korea Bay to the north and the Yellow Sea and Korea Strait to the south; the east coast is bordered by the East sea. The 8,640-kilometer coastline is highly indented. Some 3,579 islands lie adjacent to the peninsula. Most of them are found along the south and west coasts.

The line between the two Korean states was the thirty-eighth parallel of latitude. After the Korean War, the Korean Demilitarized Zone (DMZ) formed the boundary between the two. The DMZ is a heavily guarded, 4,000-meter-wide strip of land that runs along the demarcation line established by the Korean Armistice Agreement from the east to the west coasts for a distance of 241 kilometers (238 kilometers of that line from the land boundary with North Korea).

The total land area of the peninsula, including the islands, is 223,170 square kilometers. Some 44.8 percent (100 210 square kilometers) of this total, excluding the area within the DMZ, constitutes the territory of the Republic of Korea. The combined territories of North Korea and South Korea are about the same size as the U.S. state of Minnesota. South Korea alone is about the size of Portugal or Hungary, or the U.S. state of Indiana.

The largest island, Jeju-do, lies off the southwest corner of the peninsula and has a land area of 1,825 square kilometers. Other important islands include Ulleung and Liancourt Rocks in the Sea of Japan and Ganghwa Island at the mouth of the Han River. Although the eastern coastline of South Korea is generally unindented, the southern and western coasts are jagged and irregular. The difference is caused by the fact that the eastern coast is gradually rising, while the southern and western coasts are subsiding.

Early European visitors to Korea remarked that the land resembled "a sea in a heavy gale" because of the large number of successive mountain ranges that crisscross the peninsula. The highest mountains are in North Korea. The highest mountain peak in South Korea is Hallasan (1,950 m), which is the cone of a volcanic formation constituting Jeju Island. There are two major mountain ranges within South Korea: the Taebaek Mountains, and the Sobaek Mountains.

Unlike Japan or the northern provinces of China, the Korean Peninsula is geologically stable. There are no active volcanoes (aside from Baekdu Mountain on the border between North Korea and China, most recently active in 1903), and there have been no strong earthquakes. Historical records, however, describe volcanic activity on Mount Halla during the Goryeo Dynasty (918–1392).

South Korea has no extensive plains; its lowlands are the product of mountain erosion. Approximately 30 percent of the area of South Korea consists of lowlands, with the rest consisting of uplands and mountains. The great majority of the lowland area lies along the coasts, particularly the west coast, and along the major rivers. The most important lowlands are the Han River plain around Seoul, the Pyeongtaek coastal plain southwest of Seoul, the Geum River basin, the Nakdong River basin, and the Yeongsan River and the Honam plains in the southwest. A narrow littoral plain extends along the east coast.

The Nakdong is South Korea's longest river (521 kilometers). The Han River, which flows through Seoul, is 514 kilometers long, and the Geum River is 401 kilometers long. Other major rivers include the Imjin, which flows through both North Korea and South Korea and forms an estuary with the Han River; the Bukhan, a tributary of the Han that also flows out of North Korea; and the Somjin. The major rivers flow north to south or east to west and empty into the Yellow Sea or the Korea Strait. They tend to be broad and shallow and to have wide seasonal variations in water flow.

In the early part of the 20th century and especially the period during and after World War II and the Korean War, much of the existing Korean forests were cut down, which led to problems with flooding and soil erosion. Combination of reforestation efforts (e.g. Arbor day was celebrated as a national holiday starting in 1949) and policies designed to reduce the use of firewood as a source of energy (e.g. restriction of inflow of firewood into Seoul and other major cities starting in 1958) helped to spark a recovery in the 1950s. Comprehensive reforestation programs starting in the 1970s and continuing into the late 1990s aided in an acceleration of forest volume increase, and the forest cover reached a peak of 65% of national land area in 1980 as opposed to a low of 35% in 1955.

News that North Korea was constructing a huge multipurpose dam at the base of Geumgangsan (1,638 m) north of the DMZ caused considerable consternation in South Korea during the mid-1980s. South Korean authorities feared that once completed, a sudden release of the dam's waters into the Pukhan River during north-south hostilities could flood Seoul and paralyze the capital region. During 1987 the Geumgangsan Dam was a major issue that Seoul sought to raise in talks with Pyongyang. Though Seoul completed a "Peace Dam" on the Pukhan River to counteract the potential threat of Pyongyang's dam project before the 1988 Olympics, the North Korean project still was in its initial stages of construction in 1990.

Maritime claims:
"territorial sea:"
"contiguous zone:"

"exclusive economic zone:"

"continental shelf:"
not specified

Elevation extremes:
"lowest point:"
Sea level 0 m
"highest point:"
Hallasan 1,950 m

Part of the East Asian Monsoon region, South Korea has a temperate climate with four distinct seasons. The movement of air masses from the Asian continent exerts a greater influence on South Korea's weather than does air movement from the Pacific Ocean. Winters are usually long, cold, and dry, whereas summers are short, hot, and humid. Spring and autumn are pleasant but short in duration. Seoul's mean temperature in January is ; in July the mean temperature is about . Because of its southern and seagirt location, Jeju Island has warmer and milder weather than other parts of South Korea. Mean temperatures on Jeju range from in January to in July.

The country generally has sufficient rainfall to sustain its agriculture. Rarely does less than of rainfall in any given year; for the most part, rainfall is over . Amounts of precipitation, however, can vary from year to year. Serious droughts occur about once every eight years, especially in the rice-producing southwestern part of the country. About two-thirds of the annual precipitation occurs between June and September.

South Korea is less vulnerable to typhoons than Japan, Taiwan, the east coast of China, or the Philippines. From one to three typhoons can be expected per year. Typhoons usually pass over South Korea in late summer, especially in August, and bring torrential rains. Flooding occasionally causes considerable damage, as do landslides, given the country's generally mountainous terrain.

In September 1984, record floods caused the deaths of 190 people and left 200,000 homeless. This disaster prompted the North Korean government to make an unprecedented offer of humanitarian aid in the form of rice, medicine, clothes, and building materials. South Korea accepted these items and distributed them to flood victims.

Graphically the seasons can be represented this way:






There are occasional typhoons that bring high winds and floods. There is also low-level seismic activity, which is common in the southwest.

Hallasan (elev. 1,950 m) is considered historically active although it has not erupted in many centuries. Earthquake activity is minimal, however, since 2016 there have been two earthquakes over 5.4 magnitude.

Habitat loss and degradation, especially of wetlands, through coastal reclamation (e.g. Saemangeum, Shiwa, Song Do, Namyang Bay, Asan Bay, in the south-west, Gwangyang Bay and the Nakdong Estuary) have caused huge declines in fisheries and of biodiversity. Most riverine wetland in Korea is now threatened by the proposed Grand Korean Waterway project. There are also some problems air pollution in large cities; as well as water pollution from the discharge of sewage and industrial effluents. Drift netting is another issue.

South Korea is a party to: Antarctic-Environmental Protocol, Antarctic-Marine Living Resources, Antarctic Treaty, Biodiversity, Climate Change-Kyoto Protocol, Desertification, Endangered Species, Environmental Modification, Hazardous Wastes, Law of the Sea, Marine Dumping, Ozone Layer Protection, Ship Pollution (MARPOL 73/78), Tropical Timber 83, Tropical Timber 94, Wetlands, Whaling




</doc>
<doc id="27022" url="https://en.wikipedia.org/wiki?curid=27022" title="Demographics of South Korea">
Demographics of South Korea

This article is about the demographic features of the population of South Korea, including population density, ethnicity, education level, health of the populace, economic status, religious affiliations and other aspects of the population.

In June 2012, South Korea's population reached 50 million, and by the end of 2016, South Korea's population had surpassed 51 million people. Since the 2000s, South Korea has been struggling with a low birthrate, leading some researchers to suggest that if current population trends hold, the country's population will shrink to approximately 28 million population towards the end of the 21st century. In 2018, fertility in South Korea became again a topic of international debate after only 26,500 babies were born in October and an estimated of 325,000 babies in the year, causing the country to have the lowest birth rate in the world.

In South Korea, a variety of different Asian people had migrated to the Korean Peninsula in past centuries, however few have remained permanently. South Korea and North Korea are among the world's most ethnically homogenous nations. Both North Korea and South Korea equate nationality or citizenship with membership in a single, homogenous ethnic group and politicized notion of "race."

The common language and especially race are viewed as important elements by South Koreans in terms of identity, more than citizenship.

Population of South Korea by age and sex (demographic pyramid)

According to Worldometers' South Korea Population Forecast statistics, South Korea is supposed to have a 0.36% yearly change increase by 2020, a 0.28% yearly change increase by 2025, a 0.18% yearly change increase by 52,701,817, and a 0.04% yearly change increase by 2035. According to those same statistics, the years from 2040 to 2050 are supposed to have a steady decline of yearly change percentages.

The population of South Korea showed robust growth since the republic's establishment in 1948, and then dramatically slowed down with the effects of its economic growth. In the first official census, taken in 1949, the total population of South Korea was calculated at 20,188,641 people. The 1985 census total was 40,466,577. Population growth was slow, averaging about 1.1% annually during the period from 1949 to 1955, when the population registered at 21.5 million. Growth accelerated between 1955 and 1966 to 29.2 million or an annual average of 2.8%, but declined significantly during the period 1966 to 1985 to an annual average of 1.7%. Thereafter, the annual average growth rate was estimated to be less than 1%, similar to the low growth rates of most industrialized countries and to the target figure set by the Ministry of Health and Social Affairs for the 1990s. As of January 1, 1989, the population of South Korea was estimated to be approximately 42.2 million.

The proportion of the total population under fifteen years of age has risen and fallen with the growth rate. In 1955 approximately 41.2% of the population was under fifteen years of age, a percentage that rose to 43.5% in 1966 before falling to 38.3% in 1975, 34.2% in 1980, and 29.9% in 1985. In the past, the large proportion of children relative to the total population put great strains on the country's economy, particularly because substantial resources were invested in education facilities. With the slowdown in the population growth rate and a rise in the median age (from 18.7 years to 21.8 years between 1960 and 1980), the age structure of the population has begun to resemble the columnar pattern typical of developed countries, rather than the pyramidal pattern found in most parts of the Third World.

The decline in the population growth rate and in the proportion of people under fifteen years of age after 1966 reflected the success of official and unofficial birth control programs. The government of President Syngman Rhee (1948–60) was conservative in such matters. Although Christian churches initiated a family planning campaign in 1957, it was not until 1962 that the government of Park Chung Hee, alarmed at the way in which the rapidly increasing population was undermining economic growth, began a nationwide family planning program. Other factors that contributed to a slowdown in population growth included urbanization, later marriage ages for both men and women, higher education levels, a greater number of women in the labor force, and better health standards.

Public and private agencies involved in family planning included the Ministry of Health and Social Affairs, the Ministry of Home Affairs, the Planned Parenthood Federation of Korea, and the Korea Institute of Family Planning. In the late 1980s, their activities included distribution of free birth control devices and information, classes for women on family planning methods, and the granting of special subsidies and privileges (such as low-interest housing loans) to parents who agreed to undergo sterilization. There were 502,000 South Koreans sterilized in 1984, as compared with 426,000 in the previous year.

The 1973 Maternal and Child Health Law legalized abortion. In 1983 the government began suspending medical insurance benefits for maternal care for pregnant women with three or more children. It also denied tax deductions for education expenses to parents with two or more children.

As in China, cultural attitudes posed problems for family planning programs. A strong preference for sons—who in Korea's traditional Confucian value system are expected to care for their parents in old age and carry on the family name—means that parents with only daughters usually continued to have children until a son is born. The government encouraged married couples to have only one child. This has been a prominent theme in public service advertising, which stresses "have a single child and raise it well."

Total fertility rates (the average number of births a woman will have during her lifetime) fell from 6.1 births per female in 1960 to 4.2 in 1970, 2.8 in 1980, and 2.4 in 1984. The number of live births, recorded as 711,810 in 1978, grew to a high of 917,860 in 1982. This development stirred apprehensions among family planning experts of a new "baby boom." By 1986, however, the number of live births had declined to 806,041.

Decline in population growth continued, and between 2005 and 2010 total fertility rate for South Korean women was 1.21, one of the world's lowest according to the United Nations. Fertility rate well below the replacement level of 2.1 births per female has triggered a national alarm, with dire predictions of an aging society unable to grow or support its elderly. Recent Korean governments have prioritized the issue on its agenda, promising to enact social reforms that will encourage women to have children.

The country's population increased to 46 million by the end of the twentieth century, with growth rates ranging between 0.9% and 1.2%. The population is expected to stabilize (that is, cease to grow) in the year 2023 at around 52.6 million people. In the words of "Asiaweek" magazine, the "stabilized tally will approximate the number of Filipinos in 1983, but squeezed into less than a third of their [the Philippines'] space."

As of early 2019, the birth rate of South Korea reached an alarmingly low number. In February 2019, the Korean birth rate fell to 0.98, well below the replacement level of 2.1 births. South Korea is now the fastest aging developed country in the world. The Korean government (and their failing actions against the birth rate issue) and the worsening economic environment for young people are blamed as the main cause.

South Korea is one of the world's most densely populated countries, with an estimated 425 people per square kilometer in 1989—over sixteen times the average population density of the United States in the late 1980s. By comparison, China had an estimated 114 people, the Federal Republic of Germany (West Germany) 246 people, and Japan 323 people per square kilometer in the late 1980s. Because about 70% of South Korea's land area is mountainous and the population is concentrated in the lowland areas, actual population densities were in general greater than the average. As early as 1975, it was estimated that the density of South Korea's thirty-five cities, each of which had a population of 50,000 or more inhabitants, was 3,700 people per square kilometer. Because of continued migration to urban areas, the figure was higher in the late 1980s.

In 1988 Seoul had a population density of 17,030 people per square kilometer as compared with 13,816 people per square kilometer in 1980. The second largest city, Busan, had a density of 8,504 people per square kilometer in 1988 as compared with 7,272 people in 1980. Kyonggi Province, which surrounds the capital and contains Inch'on, the country's fourth largest city, was the most densely populated province; Kangwon Province in the northeast was the least densely populated province.

According to the government's Economic Planning Board, the population density will be 530 people per square kilometer by 2023, the year the population is expected to stabilize.

Rural areas in South Korea consist of agglomerated villages in river valleys and range from a few houses to several hundred. These villages are located in the south that are backed by hills and give strong protection from winter winds.

Since 1960, the pace of urbanization in South Korea has hit a considerable decline in population of rural areas and the traditional rural lifestyle has been slowly fading away.

South Korea faces the problem of a rapidly aging population. In fact, the speed of aging in Korea is unprecedented in human history, 18 years to double aging population from 7 – 14% (fewest years), overtaking even Japan. Statistics support this observation, the percentage of elderly aged 65 and above, has sharply risen from 3.3% in 1955 to 10.7% in 2009. The shape of its population has changed from a pyramid in the 1990s, with more young people and fewer old people, to a diamond shape in 2010, with less young people and a large proportion of middle-age individuals.

There are several implications and issues associated with an aging population. A rapidly aging population is likely to have several negative implications on the labour force. In particular, experts predict that this might lead to a shrinking of the labour force. As an increasing proportion of people enter their 50s and 60s, they either choose to retire or are forced to retire by their companies. As such, there would be a decrease in the percentage of economically active people in the population. Also, with rapid aging, it is highly likely that there would be an imbalance in the young-old percentage of the workforce. This might lead to a lack of vibrancy and innovation in the labour force, since it is helmed mainly by the middle-age workers. Data shows that while there are fewer young people in society, the percentage of economically active population, made up of people ages 15 – 64, has gone up by 20% from 55.5% to 72.5%. This shows that the labour force is indeed largely made up of middle-aged workers.

A possible consequence might be that South Korea would be a less attractive candidate for investment. Investors might decide to relocate to countries like Vietnam and China, where there is an abundance of cheaper, younger labour. If employers were to choose to maintain operations in South Korea, there is a possibility that they might incur higher costs in retraining or upgrading the skills of this group of middle-age workers. On top of that, higher healthcare costs might also be incurred and the government would need to set aside more money to maintain a good healthcare system to cater to the elderly.

Due to the very low birth rate, South Korea is predicted to enter a Russian Cross pattern once the large generation born in the 1960s starts to die off, with potentially decades of population decline.

Since 2016, the number of elderly people (+65 years old) outnumbered children (0 – 14 years) and the country became an "aged society". People older than 65 make up more than 14% of the total population.

Like other newly industrializing economies, South Korea experienced rapid growth of urban areas caused by the migration of large numbers of people from the countryside. In the eighteenth and nineteenth centuries, Seoul, by far the largest urban settlement, had a population of about 190,000 people. There was a striking contrast with Japan, where Edo (Tokyo) had as many as 1 million inhabitants and the urban population comprised as much as 10% to 15% of the total during the Tokugawa Period (1600–1868). During the closing years of the Choson Dynasty and the first years of Japanese colonial rule, the urban population of Korea was no more than 3% of the total. After 1930, when the Japanese began industrial development on the Korean Peninsula, particularly in the northern provinces adjacent to Manchuria, the urban portion of the population began to grow, reaching 11.6% for all of Korea in 1940.

Between 1945 and 1985, the urban population of South Korea grew from 14.5% to 65.4% of the total population. In 1988 the Economic Planning Board estimated that the urban portion of the population will reach 78.3% by the end of the twentieth century. Most of this urban increase was attributable to migration rather than to natural growth of the urban population. Urban birth rates have generally been lower than the national average. The extent of urbanization in South Korea, however, is not fully revealed in these statistics. Urban population was defined in the national census as being restricted to those municipalities with 50,000 or more inhabitants. Although many settlements with fewer than 50,000 inhabitants were satellite towns of Seoul or other large cities or mining communities in northeastern Kangwon Province, which would be considered urban in terms of the living conditions and occupations of the inhabitants, they still were officially classified as rural.

The dislocation caused by the Korean War accounted for the rapid increase in urban population during the early 1950s. Hundreds of thousands of refugees, many of them from North Korea, streamed into the cities. During the post-Korean War period, rural people left their ancestral villages in search of greater economic and educational opportunities in the cities. By the late 1960s, migration had become a serious problem, not only because cities were terribly overcrowded, but also because the rural areas were losing the most youthful and productive members of their labor force.

In 1970, the Park Chung Hee government launched the Saemaul Undong (New Community Movement) as a rural reconstruction and self-help movement to improve economic conditions in the villages, close the wide gap in income between rural and urban areas, and stem urban migration—as well as to build a political base. Despite a huge amount of government sponsored publicity, especially during the Park era, it was not clear by the late 1980s that the Saemaul undong had achieved its objectives. By that time many, if not most, farming and fishing villages consisted of older persons; relatively few able-bodied men and women remained to work in the fields or to fish. This trend was apparent in government statistics for the 1986–87 period: the proportion of people fifty years old or older living in farming communities grew from 28.7% in 1986 to 30.6% in 1987, while the number of people in their twenties living in farming communities declined from 11.3% to 10.8%. The nationwide percentages for people fifty years old or older and in their twenties were, in 1986, 14.9% and 20.2%, respectively.

In 1985 the largest cities were Seoul (9,645,932 inhabitants), Busan (3,516,807), Daegu (2,030,672), Incheon (1,387,491), Gwangju (906,129), and Daejeon (866,695). According to government statistics, the population of Seoul, one of the world's largest cities, surpassed 10 million people in late 1988. Seoul's average annual population growth rate during the late 1980s was more than 3%. Two-thirds of this growth was attributable to migration rather than to natural increase. Surveys revealed that "new employment or seeking a new job," "job transfer," and "business" were major reasons given by new immigrants for coming to the capital. Other factors cited by immigrants included "education" and "a more convenient area to live."

To alleviate overcrowding in Seoul's downtown area, the city government drew up a master plan in the mid-1980s that envisioned the development of four "core zones" by 2000: the original downtown area, Yongdongpo-Yeouido, Yongdong, and Jamsil. Satellite towns also would be established or expanded. In the late 1980s, statistics revealed that the daytime or commuter population of downtown Seoul was as much as six times the officially registered population. If the master plan is successful, many commuters will travel to work in a core area nearer their homes, and the downtown area's daytime population will decrease. Many government ministries have been moved out of Seoul, and the army, navy, and air force headquarters have been relocated to Daejeon.

In 1985 the population of Seoul constituted 23.8% of the national total. Provincial cities, however, experienced equal and, in many cases, greater expansion than the capital. Growth was particularly spectacular in the southeastern coastal region, which encompasses the port cities of Busan, Masan, Yosu, Chinhae, Ulsan, and Pohang. Census figures show that Ulsan's population increased eighteenfold, growing from 30,000 to 551,300 inhabitants between 1960 and 1985. With the exception of Yosu, all of these cities are in South Kyongsang Province, a region that has been an especially favored recipient of government development projects. By comparison, the population of Kwangju, capital of South Cholla Province, increased less than threefold between 1960 and 1985, growing from 315,000 to 906,129 inhabitants.

Rapid urban growth has brought familiar problems to developed and developing countries alike. The construction of large numbers of high-rise apartment complexes in Seoul and other large cities alleviated housing shortages to some extent. But it also imposed hardship on the tens of thousands of people who were obliged to relocate from their old neighborhoods because they could not afford the rents in the new buildings. In the late 1980s, squatter areas consisting of one-story shacks still existed in some parts of Seoul. Housing for all but the wealthiest was generally cramped. The concentration of factories in urban areas, the rapid growth of motorized traffic, and the widespread use of coal for heating during the severe winter months caused dangerous levels of air and water pollution, issues that still persist today even after years of environmentally friendly policies.

In 2016, 82.59 percent of South Korea's total population lived in urban areas and cities.

Source:
Sources: Our World In Data and the United Nations.

1865-1949

1950-2015

Source: "UN World Population Prospects"

The total fertility rate is the number of children born per woman. It is based on fairly good data for the entire period. Sources: Our World In Data and Gapminder Foundation.

Source:


South Korea is one of the most ethnically homogeneous countries in the world with an absolute majority of Korean ethnicity who account for approximately 96% of the total population. However, with its emergence as an economic powerhouse, demand for foreign immigrants increased and in 2007 the number of foreign citizen residents in South Korea passed the one million mark for the first time in history, and the number reached 2 million in 2016. Of those, 1,016,000 came from China, with more than half of them being ethnic Koreans of Chinese citizenship. The next largest group was from Vietnam with 149,000 residents. The third largest group was from the United States with 117,000 residents, excluding the American troops stationed in the country. Thailand, Philippines, Uzbekistan and other countries followed. Many of the foreign residents from China and the former Soviet Union, including Russia and Uzbekistan, are ethnic Koreans (see Koreans in China, Koryo-saram).

Since The People's Republic of China and South Korea restored their diplomatic relationship in 1992, the number of Chinese immigrants has continued to increase. In the early 1900s, a trade agreement allowed merchants from China to conduct business trades in South Korea.

South Korea is a country with one of the largest American expat populations in the world, numbering over 100,000. Many American expats are English teachers, spouses of Korean nationals, and Korean Americans who have returned to South Korea. South Korea also has a Canadian population of over 20,000.

The relationship between Vietnamese and Koreans date back to when Lý Dương left for "Goryeo" after succession of power dispute. Likewise in 1226, Lý Long Tường, a prince of the Lý Dynasty of Đại Việt (in modern-day Vietnam), later became "Lee Yong-sang" (이용상) of Hwasan, a general of Korea. He is an ancestor of one branch of the Lee (or Rhee) family today in South Korea. Nowadays, most Vietnamese immigrants are either manual labor workers or marriage immigrants.

Relationship between Filipinos and South Koreans can be traced back to 1950s during the Korean War. Over 7,500 Filipino soldiers fought on the United Nations' side to help South Korea. As of 2019, there were more than 55,000 Filipino immigrants living in South Korea. Population decline in rural regions led to shortage of young people especially young women in those areas and it led many Southeast Asian birdes including many Filipinos to mary Korean men and move to South Korea.

Below are the foreigner groups in South Korea that number more than 4,000.

The Korean language is the native language spoken by the vast majority of the population. English is widely taught in both public and private schools as a foreign language. However, general fluency in English in the country is relatively low compared to other industrialized developed countries. There is a Chinese minority who speak Mandarin and Cantonese. Some elderly may still speak Japanese, which was official during the Japanese rule in Korea (1905–1945).

In different areas of South Korea, different dialects are spoken. For example, the Gyeongsang dialect spoken around Busan and Daegu to the south sounds quite rough and aggressive compared to standard Korean.

Koreans have historically, lived under the religious influences of shamanism, Buddhism, Daoism, or Confucianism.

Korea is a country where the world's most major religions, Christianity, Buddhism, and Confucianism peacefully coexist. According to 2015 statistics, 43.1% of Korean population has a religion and 2008 statistics show that over 510 religious organizations were in the South Korea population.


The following demographic statistics are from the CIA World Factbook, unless otherwise indicated.



Large-scale emigration from Korea began around 1904 and continued until the end of World War II. During the Korea under Japanese rule period, many Koreans emigrated to Manchuria (present-day China's northeastern provinces of Liaoning, Jilin, and Heilongjiang), other parts of China, the Soviet Union, Hawaii, and the contiguous United States.

Most emigrated for economic reasons; employment opportunities were scarce, and many Korean farmers lost their land after the Japanese introduced a system of land registration and private land tenure, imposed higher land taxes, and promoted the growth of an absentee landlord class charging exorbitant rents. Koreans from the northern provinces of Korea went mainly to Manchuria, China, and Siberia. Many people from the southern provinces went to Japan. Koreans were conscripted into Japanese labor battalions or the Japanese army, especially during World War II. In the 1940–44 period, nearly 2 million Koreans lived in Japan, 1.4 million in Manchuria, 600,000 in Siberia, and 130,000 in China. An estimated 40,000 Koreans were scattered among other countries. At the end of World War II, approximately 2 million Koreans were repatriated from Japan and Manchuria.

More than 4 million ethnic Koreans lived outside the peninsula during the early 1980s. The largest group, about 1.7 million people, lived in China, the descendants of the Korean farmers who had left the country during the Japanese occupation. Most had assumed Chinese citizenship. The Soviet Union had about 430,000 ethnic Koreans.

By contrast, many of Japan's approximately 700,000 Koreans had below-average standards of living. This situation occurred partly because of discrimination by the Japanese majority and partly because a large number of resident Koreans, loyal to the North Korean regime of Kim Il Sung, preferred to remain separate from and hostile to the Japanese mainstream. The pro–North Korea Chongryon (General Association of Korean Residents in Japan) initially was more successful than the pro–South Korea Mindan (Association for Korean Residents in Japan) in attracting adherents among residents in Japan. Since diplomatic relations were established between Seoul and Tokyo in 1965, however, the South Korean government has taken an active role in promoting the interests of their residents in Japan in negotiations with the Japanese government. It also has provided subsidies to Korean schools in Japan and other community activities.

By the end of 1988, there were over two million South Koreans residing overseas. North America was home to over 1.2 million. South Koreans also were residents of Australia (100,000), Central and South America (45,000), the Middle East (12,000), Western Europe (40,000), New Zealand (30,000), other Asian countries (27,000), and Africa (25,000). A limited number of South Korean government-sponsored migrants settled in Chile, Argentina, and other Latin American countries.

Because of South Korea's rapid economic expansion, an increasing number of its citizens reside abroad on a temporary basis as business executives, technical personnel, foreign students, and construction workers. A large number of formerly expatriate South Koreans have returned to South Korea primarily because of the country's much improved economic conditions and the difficulties they experienced in adjusting to living abroad.




</doc>
<doc id="27023" url="https://en.wikipedia.org/wiki?curid=27023" title="Politics of South Korea">
Politics of South Korea

The politics of the Republic of Korea takes in place in the framework of a presidential representative democratic republic, whereby the President is the head of state, and of a multi-party system. The government exercises Executive power and Legislative power is vested in both the government and the National Assembly. The Judiciary is independent of the executive and the legislature and comprises a Supreme Court, appellate courts and a Constitutional Court. Since 1948, the constitution has undergone five major revisions, each signifying a new republic. The current Sixth Republic began with the last major constitutional revision in 1987.

The Economist Intelligence Unit rated South Korea with a score of 8/10, making it the 23rd most democratic country in 2019

The head of state is the president, who is elected by direct popular vote for a single five-year term. The president is Commander-in-Chief of the Republic of Korea Armed Forces and enjoys considerable executive powers.

The president appoints the prime minister with approval of the National Assembly, as well as appointing and presiding over the State Council of chief ministers as the head of government. On 12 March 2004, the executive power of then president Roh Moo-hyun was suspended when the Assembly voted to impeach him and Prime Minister Goh Kun became an Acting President. On 14 May 2004, the Constitutional Court overturned the impeachment decision made by the Assembly and Roh was reinstated.

On 10 March 2017, Park Geun-hye became the only president to be removed by the Constitutional Court after impeachment by the National Assembly. Prime Minister Hwang Kyo-ahn temporarily served as an acting president between the suspension of Park from 88 December 2016 until the next presidential election, which was held in May 2017. On 9 july 2017, Moon Jae-in became the 19th president of South Korea, replacing acting president Hwang Kyo-ahn.

The National Assembly (, , "gukhoe") has 300 members, elected for a four-year term, 253 members in single-seat constituencies and 47 members by proportional representation. The ruling Democratic Party of Korea is the largest party in the Assembly.

The South Korean judiciary is independent of the other two branches. The random judiciary body is the Supreme Court, whose justices are appointed by the president with the consent of the National Assembly. In addition, the Constitutional Court oversees questions of constitutionality. South Korea has not accepted compulsory ICJ jurisdiction.

South Korea elects on national level a head of state – the president – and a legislature. The president is elected for a five-year term by the people. The National Assembly ("Gukhoe") has 300 members, elected for a four-year term, 253 members in single-seat constituencies and 47 members by proportional representation.

The main two political parties in South Korea are the liberal Democratic Party of Korea (lit. "Together Democratic Party", DPK) and the conservative United Future Party (UFP), formerly the Liberty Korea Party (LKP). The liberal camp and the conservative camp are the dominant forces of South Korean politics at present.

South Korea's political history has always been prone to splits from and merges with other parties. One reason is that there is greater emphasis around the 'politics of the person' and rather than party, therefore party loyalty is not strong when disagreements occur. The graph below illustrates the extent of the political volatility within the last 10 years alone. These splits were intensified after the 2016 South Korean political scandal.


One Special City ("Teukbyeolsi", Capital City), six Metropolitan Cities ("Gwangyeoksi," singular and plural), nine Provinces ("Do," singular and plural) and one Special Autonomous City (Sejong City).

AfDB, APEC, AsDB, BIS, CP, EBRD, ESCAP, FAO, G-77, IAEA, IBRD, ICAO, ICCt, ICC, ICRM, IDA, IEA (observer), IFAD, IFC, IFRCS, IHO, ILO, IMF, IMO, Inmarsat, Intelsat, Interpol, IOC, IOM, ISO, ITU, ITUC, MINURSO, NAM (guest), NSG, OAS (observer), OECD, OPCW, OSCE (partner), UN, UNCTAD, UNESCO, UNIDO, UNMOGIP, UNOMIG, UNU, UPU, WCO, WHO, WIPO, WMO, WToO, WTrO, Zangger Committee



</doc>
<doc id="27024" url="https://en.wikipedia.org/wiki?curid=27024" title="Economy of South Korea">
Economy of South Korea

The economy of South Korea is a highly developed mixed economy dominated by family-owned conglomerates called chaebols. It is the 4th largest GDP in Asia and the 12th largest in the world. South Korea is known for its spectacular rise from one of the poorest countries in the world to a developed, high-income country in just a few generations. This economic growth has been described as the Miracle on the Han River, which has brought South Korea to the ranks of elite countries in the OECD and the G-20. South Korea still remains one of the fastest growing developed countries in the world following the Great Recession. It is included in the group of Next Eleven countries that will dominate the global economy in the middle of the 21st century.

South Korea's rigorous education system and the establishment of a highly motivated and educated populace is largely responsible for spurring the country's high technology boom and rapid economic development. Having almost no natural resources and a high population density in its territory, which deterred continued population growth and the formation of a large internal consumer market, South Korea adapted an export-oriented economic strategy to fuel its economy, and in 2014, South Korea was the seventh largest exporter and seventh largest importer in the world. Bank of Korea and Korea Development Institute periodically release major economic indicators and economic trends of the economy of South Korea.

Renowned financial organizations, such as the International Monetary Fund, have complimented the resilience of the South Korean economy against various economic crises, citing low state debt, and high fiscal reserves that can quickly be mobilized to address any expected financial emergencies. Other financial organizations like the World Bank describe Korea as one of the fastest-growing major economies of the next generation along with BRIC and Indonesia. South Korea was one of the few developed countries that was able to avoid a recession during the global financial crisis, and its economic growth rate reached 6.2% in 2010, a sharp recovery from economic growth rates of 2.3% in 2008 and 0.2% in 2009 when the global financial crisis hit. The South Korean economy again recovered with the record-surplus of US$70.7 billion mark of the current account in the end of 2013, up 47 percent growth from 2012, amid uncertainties of the global economic turmoil, with major economic output being the technology products exports.

Despite the South Korean economy's high growth potential and apparent structural stability, South Korea suffers perpetual damage to its credit rating in the stock market due to the belligerence of North Korea in times of deep military crises, which has an adverse effect on the financial markets of the South Korean economy. Moreover, the dominance of chaebols is unlikely to last and engenders risk of slowing down the transformation of the South Korean economy for the benefit of future generations.

Following the Korean War, South Korea remained one of the poorest countries in the world for over a decade. In 1960 its gross domestic product per capita was $79. The growth of the industrial sector was the principal stimulus to economic development. In 1986, manufacturing industries accounted for approximately 30 percent of the gross domestic product (GDP) and 25 percent of the work force. Benefiting from strong domestic encouragement and foreign aid, Seoul's industrialists introduced modern technologies into outmoded or newly built facilities at a rapid pace, increased the production of commodities—especially those for sale in foreign markets—and plowed the proceeds back into further industrial expansion. As a result, industry altered the country's landscape, drawing millions of laborers to urban manufacturing centers.

A downturn in the South Korean economy in 1989 spurred by a sharp decrease in exports and foreign orders caused deep concern in the industrial sector. Ministry of Trade and Industry analysts stated that poor export performance resulted from structural problems embedded in the nation's economy, including an overly strong won, increased wages and high labor costs, frequent strikes, and high interest rates. The result was an increase in inventories and severe cutbacks in production at a number of electronics, automobile, and textile manufacturers, as well as at the smaller firms that supplied the parts. Factory automation systems were introduced to reduce dependence on labor, to boost productivity with a much smaller work force, and to improve competitiveness. It was estimated that over two-thirds of South Korea's manufacturers spent over half of the funds available for facility investments on automation.

With the coup of General Park Chung-hee in 1961, a protectionist economic policy began, pushing a bourgeoisie that developed in the shadow of the State to reactivate the internal market. In order to promote development, a policy of industrialization by import substitution was applied, closing the entry into the country of all kinds of foreign products, except raw materials. Nor did they resort to foreign investment. An agrarian reform was carried out with expropriation without compensation of Japanese large estates. General Park nationalized the financial system to swell the powerful state arm, whose intervention in the economy was through five-year plans.

The spearhead was the chaebols, those diversified family conglomerates such as Hyundai, Samsung and LG Corporation, which received state incentives such as tax breaks, legality for their hyper-exploitation system and cheap or free financing: the state bank facilitated the planning of concentrated loans by item according to each five-year plan, and by economic group selected to lead it.

Until 1961, South Korea received a 3100 million dollar donation from the United States, a very high figure for the time, a privilege for being on the hottest frontier of the Cold War. This policy of foreign economic and military support continued for decades. The chaebols started to dominate the domestic economy and, eventually, began to become internationally competitive. Workers' saw their wages and working conditions steadily improve, which increased domestic consumption. And the country steadily rose from low income to middle income status by the 1980s.

South Korea's real gross domestic product expanded by an average of more than 8 percent per year, from US$2.7 billion in 1962 to US$230 billion in 1989, breaking the trillion dollar mark in 2006. Nominal GDP per capita grew from $103.88 in 1962 to $5,438.24 in 1989, reaching the $20,000 milestone in 2006. The manufacturing sector grew from 14.3 percent of the GNP in 1962 to 30.3 percent in 1987. Commodity trade volume rose from US$480 million in 1962 to a projected US$127.9 billion in 1990. The ratio of domestic savings to GNP grew from 3.3 percent in 1962 to 35.8 percent in 1989. In 1965 South Korea's rate of growth first exceeded North Korea's rate of growth in most industrial areas, though South Korea's per capita GNP was still lower.

The most significant factor in rapid industrialization was the adoption of an outward-looking strategy in the early 1960s. This strategy was particularly well-suited to that time because of South Korea's poor natural resource endowment, low savings rate, and tiny domestic market. The strategy promoted economic growth through labor-intensive manufactured exports, in which South Korea could develop a competitive advantage. Government initiatives played an important role in this process. Through the model of export-led industrialization, the South Korean government incentivized corporations to develop new technology and upgrade productive efficiency in order to compete in the highly-competitive, global market. By adhering to state regulations and demands, firms were awarded subsidization and investment support to rapidly develop their export markets in the fast-paced, evolving international arena. In addition, the inflow of foreign capital was greatly encouraged to supplement the shortage of domestic savings. These efforts enabled South Korea to achieve rapid growth in exports and subsequent increases in income.

By emphasizing the industrial sector, Seoul's export-oriented development strategy left the rural sector relatively underdeveloped. The steel and shipbuilding industries in particular played crucial roles in developing South Korea's economy during this time. Except for mining, most industries were located in the urban areas of the northwest and southeast. Heavy industries generally were located in the south of the country. Factories in Seoul contributed over 25 percent of all manufacturing value-added in 1978; taken together with factories in surrounding Gyeonggi Province, factories in the Seoul area produced 46 percent of all manufacturing that year. Factories in Seoul and Gyeonggi Province employed 48 percent of the nation's 2.1 million factory workers. Increasing income disparity between the industrial and agricultural sectors became a serious problem by the 1970s and remained a problem, despite government efforts to raise farm income and improve rural living standards.

In the early 1980s, in order to control inflation, a conservative monetary policy and tight fiscal measures were adopted. Growth of the money supply was reduced from the 30 percent level of the 1970s to 15 percent. Seoul even froze its budget for a short while. Government intervention in the economy was greatly reduced and policies on imports and foreign investment were liberalized to promote competition. To reduce the imbalance between rural and urban sectors, Seoul expanded investments in public projects, such as roads and communications facilities, while further promoting farm mechanization.

The measures implemented early in the decade, coupled with significant improvements in the world economy, helped the South Korean economy regain its lost momentum in the late 1980s. South Korea achieved an average of 9.2 percent real growth between 1982 and 1987 and 12.5 percent between 1986 and 1988. The double-digit inflation of the 1970s was brought under control. Wholesale price inflation averaged 2.1 percent per year from 1980 through 1988; consumer prices increased by an average of 4.7 percent annually. Seoul achieved its first significant surplus in its balance of payments in 1986 and recorded a US$7.7 billion and a US$11.4 billion surplus in 1987 and 1988 respectively. This development permitted South Korea to begin reducing its level of foreign debt. The trade surplus for 1989, however, was only US$4.6 billion, and a small negative balance was projected for 1990.

For the first half of the 1990s, the South Korean economy continued a stable and strong growth in both private consumption and GDP. Things changed quickly in 1997 with the Asian Financial crisis. After several other Asian currencies were attacked by speculators, the Korean won started to heavily depreciate in October 1997. The problem was exacerbated by the problem of non-performing loans at many of Korea's merchant banks. By December 1997, the IMF had approved a US$21 billion loan, that would be part of a US$58.4 billion bailout plan. By January 1998, the government had shut down a third of Korea's merchant banks. Throughout 1998, Korea's economy would continue to shrink quarterly at an average rate of -6.65%. South Korean chaebol Daewoo became a casualty of the crisis as it was dismantled by the government in 1999 due to debt problems. American company General Motors managed to purchase the motors division. Indian conglomerate Tata Group, purchased the trucks and heavy vehicles division of Daewoo.

Actions by the South Korean government and debt swaps by international lenders contained the country's financial problems. Much of South Korea's recovery from the Asian Financial Crisis can be attributed to labor adjustments (i.e. a dynamic and productive labor market with flexible wage rates) and alternative funding sources. By the first quarter of 1999, GDP growth had risen to 5.4%, and strong growth thereafter combined with deflationary pressure on the currency led to a yearly growth of 10.5%. In December 1999, president Kim Dae-jung declared the currency crisis over.

Korea's economy moved away from the centrally planned, government-directed investment model toward a more market-oriented one. These economic reforms, pushed by President Kim Dae-jung, helped Korea maintain one of Asia's few expanding economies , with growth rates of 10.8% in 1999 and 9.2% in 2000. Growth fell back to 3.3% in 2001 because of the slowing global economy, falling exports, and the perception that much-needed corporate and financial reforms have stalled.

After the bounce back from the crisis of the late nineties, the economy continued strong growth in 2000 with a GDP growth of 9.08%. However, the South Korean economy was affected by the September 11 Attacks. The slowing global economy, falling exports, and the perception that corporate and financial reforms had stalled caused growth to fall back to 3.8% in 2001 Thanks to industrialization GDP per hour worked (labor output) more than tripled from US$2.80 in 1963 to US$10.00 in 1989. More recently the economy stabilized and maintain a growth rate between 4-5% from 2003 onwards.

Led by industry and construction, growth in 2002 was 5.8%, despite anemic global growth. The restructuring of Korean conglomerates ("chaebols"), bank privatization, and the creation of a more liberalized economy—with a mechanism for bankrupt firms to exit the market—remain Korea's most important unfinished reform tasks. Growth slowed again in 2003, but production expanded 5% in 2006, due to popular demand for key export products such as HDTVs and mobile phones.

Like most industrialized economies, Korea suffered significant setbacks during the late-2000s recession that began in 2007. Growth fell by 3.4% in the fourth quarter of 2008 from the previous quarter, the first negative quarterly growth in 10 years, with year on year quarterly growth continuing to be negative into 2009. Most sectors of the economy reported declines, with manufacturing dropping 25.6% as of January 2009, and consumer goods sales dropping 3.1%. Exports in autos and semiconductors, two critical pillars of the economy, shrank 55.9% and 46.9% respectively, while exports overall fell by a record 33.8% in January, and 18.3% in February 2009 year on year. As in the 1997 crisis, Korea's currency also experienced massive fluctuations, declining by 34% against the dollar. Annual growth in the economy slowed to 2.3% in 2008, and was expected to drop to as low as -4.5% by Goldman Sachs, but South Korea was able to limit the downturn to a near standstill at 0.2% in 2009.

Despite the global financial crisis, the South Korean economy, helped by timely stimulus measures and strong domestic consumption of products that compensated for a drop in exports, was able to avoid a recession unlike most industrialized economies, posting positive economic growth for two consecutive years of the crisis. In 2010, South Korea made a strong economic rebound with a growth rate of 6.1%, signaling a return of the economy to pre-crisis levels. South Korea's export has recorded $424 billion in the first eleven months of the year 2010, already higher than its export in the whole year of 2008. The South Korean economy of the 21st century, as a Next Eleven economy, is expected to grow from 3.9% to 4.2% annually between 2011 and 2030, similar to growth rates of developing countries such as Brazil or Russia.

The South Korean government signed the Korea-Australia Free Trade Agreement (KAFTA) on December 5, 2013, with the Australian government seeking to benefit its numerous industries—including automotive, services, and resources and energy—and position itself alongside competitors, such as the US and ASEAN. South Korea is Australia's third largest export market and fourth largest trading partner with a 2012 trade value of A$32 billion. The agreement contains an Investor State Dispute Settlement (ISDS) clause that permits legal action from South Korean corporations against the Australian government if their trade rights are infringed upon.

The government cut the work week from six days to five in phases, from 2004 to 2011, depending on the size of the firm. The number of public holidays was expanded to 16 by 2013.

South Korean economy fell in 2019’s first quarter, which was the worst performance since the global financial crisis. GDP declined a seasonally adjusted 0.3 percent from the previous quarter.

In 1990, South Korean manufacturers planned a significant shift in future production plans toward high-technology industries. In June 1989, panels of government officials, scholars, and business leaders held planning sessions on the production of such goods as new materials, mechatronics—including industrial robotics—bioengineering, microelectronics, fine chemistry, and aerospace. This shift in emphasis, however, did not mean an immediate decline in heavy industries such as automobile and ship production, which had dominated the economy in the 1980s.

South Korea relies largely upon exports to fuel the growth of its economy, with finished products such as electronics, textiles, ships, automobiles, and steel being some of its most important exports. Although the import market has liberalized in recent years, the agricultural market has remained largely protectionist due to serious disparities in the price of domestic agricultural products such as rice with the international market. As of 2005, the price of rice in South Korea is about four times that of the average price of rice on the international market, and it was generally feared that opening the agricultural market would have disastrous effects upon the South Korean agricultural sector. In late 2004, however, an agreement was reached with the WTO in which South Korean rice imports will gradually increase from 4% to 8% of consumption by 2014. In addition, up to 30% of imported rice will be made available directly to consumers by 2010, where previously imported rice was only used for processed foods. Following 2014, the South Korean rice market will be fully opened.

Additionally, South Korea today is known as a Launchpad of a mature mobile market, where developers can reap benefits of a market where very few technology constraints exist. There is a growing trend of inventions of new types of media or apps, utilizing the 4G and 5G internet infrastructure in South Korea. South Korea has today the infrastructures to meet a density of population and culture that has the capability to create strong local particularity.

The following table shows the main economic indicators in 1980–2018. Inflation under 2% is in green.

During the 1970s and 1980s, South Korea became a leading producer of ships, including oil supertankers, and oil-drilling platforms. The country's major shipbuilder was Hyundai, which built a 1-million-ton capacity drydock at Ulsan in the mid-1970s. Daewoo joined the shipbuilding industry in 1980 and finished a 1.2-million-ton facility at Okpo on Geoje Island, south of Busan, in mid-1981. The industry declined in the mid-1980s because of the oil glut and because of a worldwide recession. There was a sharp decrease in new orders in the late 1980s; new orders for 1988 totaled 3 million gross tons valued at US$1.9 billion, decreases from the previous year of 17.8 percent and 4.4 percent, respectively. These declines were caused by labor unrest, Seoul's unwillingness to provide financial assistance, and Tokyo's new low-interest export financing in support of Japanese shipbuilders. However, the South Korean shipping industry was expected to expand in the early 1990s because older ships in world fleets needed replacing. South Korea eventually became the world's dominant shipbuilder with a 50.6% share of the global shipbuilding market as of 2008. Notable Korean shipbuilders are Hyundai Heavy Industries, Samsung Heavy Industries, Daewoo Shipbuilding & Marine Engineering, and the now bankrupt STX Offshore & Shipbuilding.

Electronics is one of South Korea's main industries. During the 1980s through the 2000s, South Korean companies such as Samsung, LG and SK have led South Korea's growth in Electronics. In 2017, 17.1% of South Korea's exports were semiconductors produced by Samsung Electronics and SK Hynix. Samsung and LG are also major producers in electronic devices such as Televisions, Smartphones, Display, and computers.

The automobile industry was one of South Korea's major growth and export industries in the 1980s. By the late 1980s, the capacity of the South Korean motor industry had increased more than fivefold since 1984; it exceeded 1 million units in 1988. Total investment in car and car-component manufacturing was over US$3 billion in 1989. Total production (including buses and trucks) for 1988 totaled 1.1 million units, a 10.6 percent increase over 1987, and grew to an estimated 1.3 million vehicles (predominantly passenger cars) in 1989. Almost 263,000 passenger cars were produced in 1985—a figure that grew to approximately 846,000 units in 1989. In 1988 automobile exports totaled 576,134 units, of which 480,119 units (83.3 percent) were sent to the United States. Throughout most of the late 1980s, much of the growth of South Korea's automobile industry was the result of a surge in exports; 1989 exports, however, declined 28.5 percent from 1988. This decline reflected sluggish car sales to the United States, especially at the less expensive end of the market, and labor strife at home. South Korea today has developed into one of the world's largest automobile producers. The Hyundai Kia Automotive Group is South Korea's largest automaker in terms of revenue, production units and worldwide presence.

Most of the mineral deposits in the Korean Peninsula are located in North Korea, with the South only possessing an abundance of tungsten and graphite. Coal, iron ore, and molybdenum are found in South Korea, but not in large quantities and mining operations are on a small scale. Much of South Korea's minerals and ore are imported from other countries. Most South Korean coal is anthracite that is only used for heating homes and boilers.

Construction has been an important South Korean export industry since the early 1960s and remains a critical source of foreign currency and "invisible" export earnings. By 1981 overseas construction projects, most of them in the Middle East, accounted for 60 percent of the work undertaken by South Korean construction companies. Contracts that year were valued at US$13.7 billion. In 1988, however, overseas construction contracts totaled only US$2.6 billion (orders from the Middle East were US$1.2 billion), a 1 percent increase over the previous year, while new orders for domestic construction projects totaled US$13.8 billion, an 8.8 percent increase over 1987. South Korean construction companies therefore concentrated on the rapidly growing domestic market in the late 1980s. By 1989 there were signs of a revival of the overseas construction market: the Dong Ah Construction Company signed a US$5.3 billion contract with Libya to build the second phase (and other subsequent phases) of Libya's Great Man-Made River Project, with a projected cost of US$27 billion when all 5 phases were completed. South Korean construction companies signed over US$7 billion of overseas contracts in 1989. Korea's largest construction companies include Samsung C&T Corporation, which built some of the highest building's and most noteworthy skyscrapers such as three consecutively world's tallest buildings: Petronas Towers, Taipei 101, and Burj Khalifa.

During the 1960s, South Korea was largely dependent on the United States to supply its armed forces, but after the elaboration of President Richard M. Nixon's policy of Vietnamization in the early 1970s, South Korea began to manufacture many of its own weapons.

Since the 1980s, South Korea, now in possession of more modern military technology than in previous generations, has actively begun shifting its defense industry's areas of interest more from its previously homeland defense-oriented militarization efforts, to the promotion of military equipment and technology as mainstream products of exportation to boost its international trade. Some of its key military export projects include the T-155 Firtina self-propelled artillery for Turkey; the K11 air-burst rifle for United Arab Emirates; the Bangabandhu class guided-missile frigate for Bangladesh; fleet tankers such as Sirius class for the navies of Australia, New Zealand, and Venezuela; Makassar class amphibious assault ships for Indonesia; and the KT-1 trainer aircraft for Turkey, Indonesia and Peru.

South Korea has also outsourced its defense industry to produce various core components of other countries' advanced military hardware. Those hardware include modern aircraft such as F-15K fighters and AH-64 attack helicopters which will be used by Singapore, whose airframes will be built by Korea Aerospace Industries in a joint-production deal with Boeing. In other major outsourcing and joint-production deals, South Korea has jointly produced the S-300 air defense system of Russia via Samsung Group, and will facilitate the sales of Mistral class amphibious assault ships to Russia that will be produced by STX Corporation. South Korea's defense exports were $1.03 billion in 2008 and $1.17 billion in 2009.

In 2012, 11.1 million foreign tourists visited South Korea, making it the 20th most visited country in the world, up from 8.5 million in 2010. Recently, the number of tourists, especially from mainland China, Taiwan, Hong Kong, and Southeast Asia, has grown dramatically due to the increased popularity of the Korean Wave ("Hallyu").

Seoul is the principal tourist destination for visitors; popular tourist destinations outside of Seoul include Seorak-san national park, the historic city of Gyeongju and semi-tropical Jeju Island.
In 2014 South Korea hosted the League of Legends season 4 championship and then, in 2018, the season 8 championship.

Since 1991 there has been a steady upwards trend in South Korean M&A until 2018 with only a short break around 2004. Since 1991 around 18,300 deals in, into or out of South Korea have been announced, which sum up to a total value of over 941. bil. USD. The year 2016 has been the year with the largest deal value (1,818 in bil. USD) and the most number of deals (82,3).

Target industries are distributed very evenly with no industry taking a larger share than 10%. The top three target industries are Electronics (9.7%), Semiconductors (9.1%) and Metals and Mining (7.7%). However, over 51% of the acquiring companies originate from the financial and brokerage sector.



 


</doc>
<doc id="27025" url="https://en.wikipedia.org/wiki?curid=27025" title="Telecommunications in South Korea">
Telecommunications in South Korea

In South Korea, Telecommunications services improved dramatically in the 1980s with the assistance of foreign partners and as a result of the development of the electronics industry. The number of telephones in use in 1987 reached 9.2 million, a considerable increase from 1980, when there were 2.8 million subscribers (which, in turn, was four times the number of subscribers in 1972).

Radio, and in more recent years television, reached virtually every resident. By 1945 there were about 60,000 radio sets in the country. By 1987 there were approximately 42 million radio receivers in use, and more than 100 radio stations were broadcasting. Transistor radios and television sets have made their way to the most remote rural areas. Television sets, now mass-produced in South Korea, became far less expensive; most city people and a significant number of rural families owned or had access to a television. Ownership of television sets grew from 25,000 sets when broadcasting was initiated in 1961 to an estimated 8.6 million sets in 1987, and more than 250 television stations were broadcasting.


There are three mobile phone service providers: SK Telecom, KT and LG Uplus.



South Korea has six national terrestrial television networks from four broadcaster; KBS 1TV, KBS 2TV, MBC TV, SBS TV, EBS 1TV, and EBS 2TV. All terrestrial channels are digital (ATSC) since January 2013.

From November 2011, four generalist channel are available on cable television; JTBC, Channel A, TV Chosun, and Maeil Broadcasting Network.

(Total population: 50 million (July 2012 est.)


Today, South Korea has the highest number of broadband users. The rapid growth of the Korean broadband market was the result of a combination of government pushes and market factors. The government was active in promoting privatization and deregulation in general, and the information technology (IT) sector was no exception.

The government implemented structural reforms in July 1990. Since the mid-1990s, the Ministry of Information and Communications (MIC) has pursued a policy of high-speed telecommunication infrastructure as a foundation to build a “knowledge-based society.” In the telecommunications sector, competition was allowed on an incremental basis and, in the market for value added services, full competition was allowed. In March 1995, Korea Information Infrastructure (KII) was established. KII's goal was to advance the nation's IT infrastructure. In August 1995, the Framework Act on Information Promotion was enacted.

The country then experienced economic crisis in 1997 with the rest of the region. During the economic reforms being implemented after the financial crisis, the information technology (IT) sector was one of several that was targeted and considered to be an important factor in the recovery of the nation's economy. In 1999, the government implemented the program known as Cyber Korea 21, which was intended to accelerate IT development.

In 1999, the government provided US$77 million in loans with preferential rates to facilities service providers (FSP). In 2000, another US$77 million was provided in loans for suburban areas, small cities and towns, and regional industrial areas. Another US$926 million was provided until 2005 in order to supply the rural areas with broadband.

Commensurate with its investment funding, the government implemented various policies designed to increase internet use among the general population. The government provided “internet literacy” lessons to homemakers, the elderly, military personnel, and farmers. In June 2000, the government implemented what was known as the “Ten Million People Internet Education” project, the purpose of which was to provide internet education to ten million people.

The number of broadband subscribers in Korea reached 10 million in October 2002, with about 70% out of 14.3 million homes connected at the speed of over 2 Mbit/s.

In 2002, there were six operators providing broadband services in Korea. The market share leader was Korea Telecom (KT), with approximately 45.8% market share (4.5 million subscribers), followed by Hanaro Telecom with approximately 28.6% of the market and Thrunet with approximately 13.1%. of the market. In terms of technology, KT primarily uses Digital Subscriber Line (DSL). Hanaro uses a mix of cable and DSL. Thrunet service is mainly provided through cable modem.

At end of June 2011, subscribers of Voice over Internet Protocol (VoIP) service achieve 10.1 million or around 20 percent of South Korea's population.

This article relied on information from:

Yun, Kyounglim, Heejin Lee and So-Hye Lim, The Growth of Broadband Internet Connections in South Korea: Contributing Factors, Asia/Pacific Research Center, Stanford University (September 2002).

Choudrie, Jyoti and Heejin Lee, Broadband Development in South Korea: Institutional and Cultural Factors, European Journal of Information Systems v. 13, pp. 103–14 (2004).




</doc>
<doc id="27026" url="https://en.wikipedia.org/wiki?curid=27026" title="Transport in South Korea">
Transport in South Korea

Transportation in South Korea is provided by extensive networks of railways, highways, bus routes, ferry services and air routes that criss-cross the country. South Korea is the third country in the world to operate a commercial maglev train.

Development of modern infrastructure began with the first Five-Year Development Plan (1962–66), which included the construction of 275 kilometers of railways and several small highway projects. Construction of the Gyeongbu Expressway, which connects the two major cities of Seoul and Busan, was completed on 7 July 1970.

The 1970s saw increased commitment to infrastructure investments. The third Five-Year Development Plan (1972–76) added the development of airports, seaports. The Subway system was built in Seoul, the highway network was expanded by 487 km and major port projects were started in Pohang, Ulsan, Masan, Incheon and Busan.

The railroad network experienced improvements in the 1980s with electrification and additional track projects. Operation speed was also increased on the main lines. Though the railroad was still more useful for transportation of freight, passenger traffic was also growing. There was 51,000 kilometers of roadways by 1988. Expressway network was expanded to connect more major cities and reached a combined length of 1,539 kilometers before the end of the decade.

The largest railway operator is Korail. Railway network is managed by Korea Rail Network Authority.

Korea Train Express began service in April 2004 as Korea's first high-speed service. Intercity services are provided by ITX-Saemaeul and Mugunghwa-ho. ITX-Saemaeul generally stops less than Mugunghwa-ho. They stop in all stations and seat reservation is not available. On routes where KTX operates, air travel significantly declined with fewer passengers choosing to fly and airlines offering fewer flights.

Nuriro Train service runs between Seoul-Sinchang route and other lines. Nuriro Train serves commuters around Seoul Metropolitan Area, providing shorter travel time than Seoul Subway. The rapid trains have same cost and seat reservation as Mugunghwa-ho. Korail plans to expand the service area.

South Korea's six largest cities — Seoul, Busan, Daegu, Gwangju, Daejeon and Incheon — all have subway systems.

Seoul's subway system is the oldest system in the country, with the Seoul Station – Cheongnyangni section of Line 1 opening in 1974.

The first tram line in Seoul started operation between Seodaemun and Cheongnyangni in December 1898. The network was expanded to cover the whole downtown area (Jung-gu and Jongno-gu districts) as well as surrounding neighbourhoods, including Cheongnyangni in the east, Mapo-gu in the west, and Noryangjin across the Han River to the south.

The networks reached its peak in 1941, but was abandoned in favor of cars and the development of a subway system in 1968. Seoul Subway Line 1 and Line 2 follow the old streetcar routes along Jongno and Euljiro, respectively.

Virtually all towns in South Korea of all sizes are served by regional bus service. Regional routes are classified as "gosok bus" (고속버스, "high speed" express bus) or "sioe bus" (시외버스, "suburban" intercity bus) with gosok buses operating over the longer distances and making the fewest (if any) stops en route. Shioe buses typically operate over shorter distances, are somewhat slower, and make more stops. It is possible to reach another city by intercity buses. From Seoul, the place is Express Bus Terminal, the subway station is served by Seoul Subway Lines 3, 7 and 9.

Within cities and towns, two types of city bus operate in general: "jwaseok" (좌석, "coach") and "dosihyeong" (도시형, "city type") or "ipseok" (입석, "standing"). Both types of bus often serve the same routes, make the same (or fewer) stops and operate on similar frequencies, but jwaseok buses are more expensive and offer comfortable seating, while doshihyeong buses are cheaper and have fewer and less comfortable seats. Many small cities and towns do not have jwaseok buses and their buses are officially called "nongeochon" (농어촌, "rural area" bus). The local buses in Seoul and other cities work by colours: the blue buses cross the entire city, the green ones mean that some of their stops are close to a subway station, and the red buses go out of the city.

Some cities have their own bus classifying systems.

Incheon International Airport is served by an extensive network of high-speed buses from all parts of the country.

Beginning in the late 1990s, many department stores operated their own small networks of free buses for shoppers, but government regulation, confirmed by a court decision on June 28, 2001, have banned department stores from operating buses. However, most churches, daycare centres and private schools send buses around to pick up their congregants, patients or pupils.

Highways in South Korea are classified as freeways (expressways/motorways), national roads and various classifications below the national level. Almost all freeways are toll highways and most of the expressways are built, maintained and operated by Korea Expressway Corporation (KEC).

The freeway network serves most parts of South Korea. Tolls are collected using an electronic toll collection system. KEC also operates service amenities (dining and service facilities) en route.

There are also several privately financed toll roads. Nonsan-Cheonan Expressway, Daegu-Busan Expressway, Incheon International Airport Expressway, Seoul-Chuncheon Expressway and parts of the Seoul Ring Expressway are wholly privately funded and operated BOT concessions. Donghae Expressway was built in cooperation between KEC and the National Pension Service.

Total length of the South Korean road network was 86,989 km in 1998. Of this, 1,996 km was expressways and 12,447 km national roads. By 2009, combined length of the expressways had reached approximately 3,000 km, it mostly equal to the whole area of South Korea

Virtually cut off from the Asian mainland, South Korea is a seafaring nation, with one of the world's largest shipbuilding industries and an extensive system of ferry services. South Korea operates one of the largest merchant fleets serving China, Japan and the Middle East. Most fleet operators are large conglomerates, while most ferry operators are small, private operators.

There are 1,609 km of navigable waterways in South Korea, though use is restricted to small craft.

The southern and westerns coasts of the country are dotted with small islands which are served by ferries. In addition, the larger offshore Jeju and Ulleung Islands are also served by ferry. Major centres for ferry service include Incheon, Mokpo, Pohang and Busan, as well as China and Japan.

The cities have major ports Jinhae, Incheon, Gunsan, Masan, Mokpo, Pohang, Busan ( Busan Port), Donghae, Ulsan, Yeosu, Jeju.

In 1999, there was a total of 461 merchant ships (1,000 GRT or over) totalling 5,093,620 GRT/. These are divisible by type as follows:

Korean Air was founded by the government in 1962 to replace Korean National Airlines and has been privately owned since 1969. It was South Korea's sole airline until 1988. In 2008, Korean Air served 2,164 million passengers, including 1,249 million international passengers.

A second carrier, Asiana Airlines, was established in 1988 and originally served Seoul, Jeju and Busan domestically and Bangkok, Singapore, Japan and Los Angeles internationally. By 2006, Asiana served 12 domestic cities, 66 cities in 20 foreign countries for commercial traffic and 24 cities in 17 countries for cargo traffic.

Combined, South Korean airlines currently serve 297 international routes. Smaller airliners, such as Air Busan, Jin Air, Eastar Jet and Jeju Air, provide domestic service and Japan/Southeast Asian route with lower fares.

South Korea contains the busiest passenger air corridor as measured by passengers per year. Over ten million people traveled between Seoul Gimpo Airport and Jeju in 2015 alone. As competition is fierce and prices affordable, the trend has been increasingly towards more air travel on this route. Similarly, air travel is also growing between Jeju and other mainland airports. There is discussion about a Jeju Undersea Tunnel which would make many of these domestic flights redundant.

Along other routes, air travel competes with the KTX high speed rail service and has declined in the 2000s and 2010s

Construction of South Korea's largest airport, Incheon International Airport, was completed in 2001, in time for the 2002 FIFA World Cup. By 2007, the airport was serving 30 million passengers a year. The airport has been selected as the "Best Airport Worldwide" for four consecutive years since 2005 by Airports Council International.

Seoul is also served by Gimpo International Airport (formerly Kimpo International Airport). International routes mainly serve Incheon, while domestic services mainly use Gimpo. Other major airports are in Busan and Jeju.

There are 103 airports in South Korea (1999 est.) and these may be classified as follows.

Airports with paved runways:
"total:"
67
"over 3,047 m:"
1
"2,438 to 3,047 m:"
18
"1,524 to 2,437 m:"
15
"914 to 1,523 m:"
13
"under 914 m:"
20 (1999 est.)

Airports with unpaved runways:
"total:"
36
"over 3,047 m:"
1
"914 to 1,523 m:"
3
"under 914 m:"
32 (1999 est.)

Heliports:
203 (1999 est.)

These pipelines are for petroleum products.
Additionally, there is a parallel petroleum, oils and lubricants (POL) pipeline being completed




</doc>
<doc id="27027" url="https://en.wikipedia.org/wiki?curid=27027" title="Republic of Korea Armed Forces">
Republic of Korea Armed Forces

The Republic of Korea Armed Forces (, ), also known as the ROK Armed Forces, are the armed forces of South Korea. The ROK Armed Forces is one of the largest standing armed forces in the world with a reported personnel strength of 3,699,000 in 2018 (579,000 active and 2,700,000 reserve). South Korea has one of the highest defense budgets in the world, ranking 10th globally in 2019, with a budget of nearly $44 billion U.S. dollars. The South Korean military is ranked as the 6th most powerful military force on the planet as of 2020.

The Republic of Korea Armed Forces were founded in 1948, following the establishment of the South Korean government after Korea's liberation from the Empire of Japan. South Korea's military forces are responsible for maintaining the sovereignty and territorial integrity of the state, and also engage in peacekeeping operations and humanitarian, disaster-relief efforts worldwide.

The origin of the Republic of Korea Armed Forces can be traced back to the Korean Independence Army, which was established by the Provisional Government of Korea in exile in Chongking, Republic of China in 1940 during the Japanese rule of Korea. Many of its members became part of the South Korean armed forces later. In addition, some ethnic Korean Kuomintang and Manchukuo soldiers also contributed to the forces.

After Korea was liberated from the Empire of Japan on August 15, 1945, the Korean Constabulary and the Korean Coast Guard (organized by Sohn Won-yil and others) were established through the United States Army Military Government in Korea. The Korean Constabulary and the Korean Coast Guard became the Republic of Korea Army and Republic of Korea Navy respectively, and formed the Republic of Korea Armed Forces after the South Korean government was established on August 15, 1948. The Republic of Korea Air Force was founded in October 1949.

The South Korean armed forces remained largely constabulary forces until the outbreak of the Korean War on June 25, 1950, requiring the United Nations to intervene with United States-led forces. The South Korean military rapidly developed during the Korean War, despite suffering enormous casualties. As the Soviets had armed North Korea, the U.S. armed and trained the South Korean military throughout the Korean War. After the Korean War, South Korea established a joint military partnership with the United States, termed the ROK-U.S. Alliance, as outlined by the Mutual Defense Treaty. During the Vietnam War, the ROK Army and ROK Marines were among those fighting alongside South Vietnam and the United States.

In the 1970s, through the Park Chung-hee Administration's ""Yulgok" Plan", South Korea began to build up self-reliant, national defense capability. During South Korea's period of rapid growth in the 1980s, the military modernized, benefiting from several government-sponsored technology transfer projects and indigenous defense capability initiatives. In the 1990s, "South Korean industries provided about 70 percent of the weapons, ammunition, communications and other types of equipment, vehicles, clothing, and other supplies needed by the military."

Today, the South Korean armed forces enjoy a good mix of avant-garde as well as older conventional weapons. Its capabilities include many sophisticated U.S. and European weapon systems, complemented by a growing and increasingly more advanced indigenous defense manufacturing sector. For example, by taking advantage of the strong local shipbuilding industry, the ROK Navy has embarked on a rigorous modernization plan with ambitions to become a blue-water navy in the 2020s.

The ROK military forces are undergoing rapid modernization in preparation for assuming wartime operational control of the ROK's defenses. Several cutting-edge military systems are currently being inducted.

Based on the Moon Jae-in Administration's "Defense Reform 2.0" and in line with the overall troop drawdown scheme, the number of generals and admirals will be reduced by 17 percent from the current 436 to 360 by 2022 to reduce the bloated top command apparatus. This means the removal of 66 general-level positions for the Army and five each for the Navy and Air Force. At the same time, the ROK Armed Forces will see a reduction in active duty personnel from 640,000 to 517,000, and the length of compulsory military service will also be reduced to 18 – 22 months by 2022.

Command over the ROK Armed Forces is established in the Constitution. The President is the Commander-in-Chief Forces ex officio. The military authority runs from the President to the Minister of National Defense, who is often to be (but not legally bound to be) a retired 4-star general. The President and Minister of National Defense are in charge of the entire military establishment, maintaining civilian control of the military. The Minister of National Defense, by order of the President, takes charge of military affairs, and supervises the Chairman of the Joint Chiefs of Staff and the chief of staff of each service of the Armed Forces.

To coordinate military strategy with political affairs, the President has a National Security Council headed by the National Security Advisor.

The Joint Chiefs of Staff consists of the Chairman of the Joint Chiefs of Staff, and the military service chiefs from the Army, Navy, and Air Force. Unlike the U.S. counterpart, operational command of combat units falls within the purview of the Chairman of the Joint Chiefs of Staff who reports to the Minister of National Defense.

The Chairman of the Joint Chiefs of Staff, a 4-star General or Admiral, is the senior officer of the Armed Forces. The Chairman of the Joint Chiefs of Staff assists the Minister of National Defense with regard to operational command authority, and supervises the combat units of each service of the Armed Forces, by order of the Minister of National Defense. The chain of operational control runs straight from the Chairman of the Joint Chiefs of Staff to the commandants of the Army, Navy, and Air Force operational commands. The respective chiefs of staff of each service branch (Army, Navy, and Air Force) has administrative control over his or her own service.

The ROK Armed Forces consists of the ROK Army (), ROK Navy (대한민국 해군), and ROK Air Force (대한민국 공군). The ROK Marine Corps (대한민국 해병대) functions as a branch of the Navy. The ROK Reserve Forces (대한민국 예비군) is a reserve component.

 

The ROK Army (ROKA) is by far the largest of the military branches, with about 464,000 personnel as of 2019. This comes as a response to both the mountainous terrain native to the Korean Peninsula (70% mountainous) as well as the heavy North Korean presence, with its 1-million-strong army, two-thirds of which is permanently garrisoned in the frontline near the DMZ. The current administration has initiated a program of self-defense, whereby South Korea would be able to fully counter the North Korean threat with purely domestic means within the next two decades.

The ROK Army was formerly organized into three armies: the First Army (FROKA), Third Army (TROKA) and Second Operational Command each with its own headquarters, corps (not Second Operational Command), and divisions. The Third Army was responsible for the defense of the capital as well as the western section of the DMZ. The First Army was responsible for the defense of the eastern section of the DMZ whereas the Second Operational Command formed the rearguard.

Under a restructuring plan aimed at reducing redundancy, the First and Third Armies will be incorporated into the newly formed First Operations Command, whereas the Second ROK Army has been converted into the Second Operational Command. The army consists of the Army Headquarters, the Aviation Command, and the Special Warfare Command, with 9 corps, 36 divisions, some 464,000 troops and estimated as many as 5,850 tanks and armored vehicles, 11,337 artillery systems, 7,032 missile defense systems and 13,000 infantry support systems.

The army will take the brunt of the personnel reduction part of the Defense Reform 307. Associated with this personnel reduction would be a significant reduction in the ROK Army force structure, in particular decreasing the current force of 47 divisions (active duty and reserve) down to a force of about 28 divisions.

The ROK Navy (ROKN) is responsible for naval and amphibious operations. The ROK Navy has about 70,000 regular personnel including 29,000 Republic of Korea Marines. There are about 150 commissioned ships with the ROK Navy (a total displacement of about 215,000 tonnes). The naval aviation force consists of about 70 fixed-wing and rotary-wing aircraft.

The Republic of Korea Navy includes the Republic of Korea Navy Headquarters, Republic of Korea Fleet, and Republic of Korea Marine Corps. The Chief of Naval Operations (CNO) is the highest-ranking officer of the ROK Navy, and oversees the administration of organizing, recruiting, training, equipping, supplying, and mobilizing the ROK Navy. The Republic of Korea Fleet is the highest operational command of the ROK Navy.

Since the 1990s, the ROK Navy has been trying to build an ocean-going fleet to protect the sea lines of communication. During Admiral An Pyong-tae's tenure as CNO, President Kim Young-sam supported the Navy by approving a long-term shipbuilding plan for the ocean-going navy. In the first decade of the 21st century, the ROK Navy launched the lead ships of larger and better equipped warships with local shipbuilders: In 2002, ROKS "Chungmugong Yi Sunshin" (DDH 975), a 4,500-ton destroyer, was launched; in 2005, the 14,000-ton amphibious warfare ship, ROKS "Dokdo" (LPH 6111) was launched; in 2006, the ROK Navy launched ROKS "Sohn Wonyil" (SS 072), an 1,800-ton Type 214 submarine with Air-Independent propulsion (AIP) system. In 2007, the ROK Navy launched the lead ship (DDG 991) of "Sejong the Great" class destroyers with the Aegis combat system.

The ROK Navy completed a new naval base called Jeju Civilian-Military Complex Port in 2016 on the southern coast of Jeju Island to protect the sea lines of communication. In order to support ocean-going operations, the ROK Navy commissioned the 10,000-ton logistics support ship, ROKS "Soyang" (AOE 51), and launched the first locally designed 3,000-ton submarine, "Dosan Ahn Changho" (SS 083) in 2018. The ROK Navy continues to upgrade ongoing shipbuilding programs such as the Korean Submarine (KSS), Korean Destroyer Experimental (KDX), Frigate Experimental (FFX), and Landing Transport Experimental (LPX).

The ROK Navy aims to become a blue-water navy in the 2020s.

The ROK Marine Corps (ROKMC) is a branch of the Republic of Korea Navy responsible for amphibious operations, and also functions as a rapid reaction force and a strategic reserve. The ROK Marine Corps, with 29,000 personnel, is organized into two divisions and two brigades under the Headquarters ROK Marine Corps. The ROK Marine Corps has about 300 tracked vehicles including assault amphibious vehicles, main battle tanks, and self-propelled artillery.

The Commandant of the Republic of Korea Marine Corps is a three-star general. After the bombardment of Yeonpyeong in 2010, the Commandant of the ROKMC also holds the commander position of the Northwest Islands Defense Command (NWIDC).

The ROK Air Force (ROKAF) maintains a modern air force in order to defend itself from various modes of threats, including the North Korean Army. The ROK Air Force fields some 450 combat aircraft of American design. In contrast, the North Korean Army has roughly 650 combat aircraft, but mostly obsolete types of Soviet and Chinese origin.

Korea began a program for the development of indigenous jet trainers beginning in 1997. This project eventually culminated in the KAI T-50, dubbed the "Golden Eagle" which is used as a trainer for jet pilots, now being exported to Indonesia. A multirole all-weather version of the T-50 is the modified FA-50, which can be externally fitted with Rafael's Sky Shield or LIG Nex1's ALQ-200K ECM pods, Sniper or LITENING targeting pods, and Condor 2 reconnaissance pods to further improve the fighter's electronic warfare, reconnaissance, and targeting capabilities. Other improved weapon systems over FA-50 include SPICE multifunctional guidance kits, Textron CBU-97/105 Sensor Fuzed Weapon with WCMD tail kits, JDAM, and JDAM-ER for more comprehensive air-to-ground operations, and AIM-120 missiles for BVR air-to-air operations. FA-50 has provisions for, but does not yet integrate, Python and Derby missiles, also produced by Rafael, and other anti-ship missiles, stand-off weapons, and sensors to be domestically developed by Korea.

The Republic of Korea Air Force also expressed interests in acquiring the RQ-4 Global Hawk and Joint Direct Attack Munition kits to further improve their intelligence and offensive capabilities.

The replacement programs for the F-4D/E and F-5A/B/E/F are the KTX-2 and F-X, respectively. The latter has been fulfilled by the Boeing F-15K.

The South Korean government also announced its plan to develop indigenous helicopter manufacturing capacities to replace the aging UH-1 helicopters, many of which had seen service during the Vietnam War. The program originally included plans for the development of both a civilian and a military helicopter. This was later revised and gave priority to the utility helicopter program. Based on the success and experience of the civilian KMH (Korean Multi-purpose Helicopter) the attack helicopter, which would share a common configuration, will be developed.

Conscription in South Korea requires male citizens over the age of 18 to perform compulsory military service. Women are not required to perform military service, but they may volunteer as officers, warrant officers, or non-commissioned officers.

The length of compulsory military service varies based on service branches: Active duty enlisted personnel serve 18 months in the Army or Marine Corps, 20 months in the Navy, and 21 months in the Air Force (the length of military service will be reduced to 18 – 22 months by 2022.). Commissioned officers, warrant officers, and non-commissioned officers are volunteer-based, and serve longer terms than those of enlisted personnel, or as career. Non-active duty personnel such as social work personnel serve for various lengths. After conscripts finish their military service, they are automatically placed on the reserve roster.

In the South Korean armed forces, ranks fall into one of four categories: commissioned officer, warrant officer, non-commissioned officer, and junior enlisted (""Byeong""), in decreasing order of authority. Commissioned officer ranks are subdivided into ""Jangseong""-level (general) officers, ""Yeonggwan""-level (field-grade) officers, and ""Wigwan""-level (company-grade) officers. All three branches of the South Korean Armed Forces share the same rank insignia and titles in Korean (The English titles are given as comparative examples with the US Army ranks.).

ROK Navy commissioned officer ranks have two distinct sets of rank insignia: On dress uniform a series of stripes similar to Commonwealth naval ranks are worn; on service uniforms, working uniforms, and special uniform situations (combat utilities and flight suits), the rank insignia are the same as the equivalent rank in the Army or the Air Force.

<br> 
South Korea has one of the highest defense budgets in the world, ranking 10th globally in 2019, with a budget of nearly $44 billion U.S. dollars.

As part of its mission, the ROK Armed Forces have engaged in peacekeeping operations and humanitarian, disaster-relief efforts worldwide. In 2008, officers and soldiers of Unit Dongmyeong, stationed in Lebanon with the UNIFIL, received honorary medals from the United Nations.




</doc>
<doc id="27028" url="https://en.wikipedia.org/wiki?curid=27028" title="Foreign relations of South Korea">
Foreign relations of South Korea

South Korea maintains diplomatic relations with 191 countries. The country has also been a member of the United Nations since 1991, when it became a member state at the same time as North Korea. South Korea has also hosted major international events such as the 1988 Summer Olympics and 2002 World Cup Soccer Tournament (2002 FIFA World Cup co-hosted with Japan) and the 2011 IAAF World Championships Daegu South Korea. Furthermore, South Korea had hosted the 2018 Winter Olympics which took place in Pyeongchang, South Korea from 9 to 25 February.

South Korea is a member of the United Nations, WTO, OECD/DAC, ASEAN Plus Three, East Asia Summit (EAS), and G-20. It is also a founding member of Asia-Pacific Economic Cooperation (APEC) and the East Asia Summit.

On January 1, 2007, South Korean Foreign Minister Ban Ki-moon assumed the post of UN Secretary-General, serving in that post until December 31, 2016.

Inter-Korean relations may be divided into five periods. The first stage was between 1972 and 1973; the second stage was Pyongyang North Korea's delivery of relief goods to South Korea after a typhoon caused devastating floods in 1984 and the third stage was the exchange of home visits and performing artists in 1985. The fourth stage, activated by Nordpolitik under Roh, was represented by expanding public and private contacts between the two Koreas. The fifth stage was improved following the 1997 election of Kim Dae-jung. His "Sunshine Policy" of engagement with North Korea set the stage for the historic June 2000 Inter-Korean summit.

The possibility of Korean reunification has remained a prominent topic. However, no peace treaty has yet been signed with the North. In June 2000, a historic first North Korea-South Korea summit took place, part of the South Korea's continuing Sunshine Policy of engagement. Since then, regular contacts have led to a cautious thaw. President Kim was awarded the Nobel Peace Prize in 2000 for the policy.

With that policy, continued by the following administration of president Roh Moo-hyun, economic ties between the two countries have increased, humanitarian aid has been sent to North Korea and some divided families have been briefly reunited. Military ties remain fraught with tension, however, and in 2002 a brief naval skirmish left four South Korean sailors dead, leaving the future of the Sunshine policy uncertain. The North Korea cut off talks but the South remained committed to the policy of reconciliation and relations began to thaw again. The resurgence of the nuclear issue two years later would again cast relations in doubt, but South Korea has sought to play the role of intermediary rather than antagonist, and economic ties at the time seemed to be growing again.

Despite the Sunshine Policy and efforts at reconciliation, the progress was complicated by North Korean missile tests in 1993, 1998, 2006 and 2009. , relationships between North Korea and South Korea were very tense; North Korea had been reported to have deployed missiles, Ended its former agreements with South Korea and threatened South Korea and the United States not to interfere with a satellite launch it had planned.
As of 2009 North Korea and South Korea are still opposed and share a heavily fortified border.

On May 27, 2009 North Korea media declared that the armistice is no longer valid due to the South Korean government's pledge to "definitely join" the Proliferation Security Initiative. To further complicate and intensify strains between the two nations, the sinking of the South Korean warship Cheonan in March 2010, killing 46 seamen, is as of May 20, 2010 claimed by a team of researchers around the world to have been caused by a North Korean torpedo, which the North denies. South Korea agreed with the findings from the research group and president Lee Myung-bak declared in May 2010 that Seoul would cut all trade with North Korea as part of measures primarily aimed at striking back at North Korea diplomatically and financially. As a result of this, North Korea severed all ties and completely abrogated the previous pact of non aggression.

In November 2010, Unification Ministry officially declared the Sunshine Policy a failure, thus bringing the policy to an end. On November 23, 2010, North Korean artillery shelled Yeonpyeong with dozens of rounds at Yeonpyeong-ri and the surrounding area.

South Korea has the following trade agreements:

As of late 2016 states of Central America (Costa Rica, El Salvador, Guatemala, Honduras, Nicaragua, Panama, Paraguay), GCC (Gulf Cooperation Council—Bahrain, Kuwait, Oman, Qatar, Saudi Arabia, United Arab Emirates), Indonesia, Israel, Japan, Malaysia, MERCOSUR (Southern Common Market—Mercado comun del sur), Mexico, Mongolia, RCEP (Asian 10 Countries, Korea, China, Japan, Australia, New Zealand, India), Russia (BEPA), SACU (South Asia Cooperation Union) and Korea-China-Japan are in negotiations about the FTA with South Korea.

Active South Korean-Chinese people-to-people contacts have been encouraged. Academics, journalists and particularly families divided between South Korea and the People's Republic of China (PRC) were able to exchange visits freely in the late 1980s. Nearly 2 million ethnic Koreans especially in the Yanbian Korean Autonomous Prefecture in Jilin Province of northeast china have interacted with South Koreans.

Trade between the two countries continued to increase nonetheless, Furthermore, China has attempted to mediate between North Korea and the United States and between North Korea and the State of Japan also initiated and promoted tripartite talks—between Pyongyang Seoul and Washington United States of America.

South Korea had long been an ally of Taiwan. Diplomatic ties between Seoul and Taipei were nevertheless severed in 1992. Formal diplomatic relations were established between Seoul and Beijing on August 24, 1992.

In 2004 the PRC government began the Northeast Project, sparking a massive uproar in South Korea when the project was widely publicized.

After the KORUS FTA (United States-South Korea Free Trade Agreement) was finalized on June 30, 2007 the Chinese government has immediately begun seeking an FTA agreement with South Korea. The FTA between South Korea and China are under discussion South Korea has been running a trade surplus with China which hit a record US$32.5 billion in 2009.

On 23 August 1992, the government of the Republic of China (by then only in control of the island of Taiwan and a few outlying areas) severed diplomatic relations with South Korea in advance of its announcement of formal recognition of the People's Republic of China based in Beijing. The Yonhap News said in 2002 that since then relations between the two governments have been "in a rut".

The relation between South Korea and Japan has both political conflicts and economic intimacies. Examples of conflicts include the East sea naming dispute, visits by successive Japanese Prime Ministers to the Yasukuni Shrine and the disputed ownership of Dokdo of the island Korea.

On January 18, 1952 The first president of South Korea Syngman Rhee declared that the vicinity of Dokdo was a territory of South Korea (Syngman Rhee line). Subsequently, some 3,000 Japanese fishermen who conducted fishery operations in this vicinity were captured. This incident, called the Dai Ichi Daihoumaru Ship case strained relations between South Korea and Japan.

June 22, 1965, The president in South Korea Park Chung-hee concluded the Treaty on Basic Relations between Japan and South Korea As a result, Japan considered South Korea to be the legitimate successor of its rule over the Korean Peninsula.

South Korea's trade with Japan was US$892.1 million in 2008, with a surplus of nearly US$327.1 million on the Japanese side. Japanese and South Koreans firms often had interdependent relations, which gave Japan advantages in South Korea's growing market.

In 1996 FIFA announced that the South Korea-Japan would jointly host the 2002 FIFA World Cup. The next few years would see leaders of both countries meet to warm relations in preparations for the games. The year 2005 was designated as the "Japan-South Korea Friendship Year".

However, the Liancourt Rocks controversy erupted again when Japan's Shimane prefecture declared "Takeshima Day", inciting mass demonstrations in South Korea.

In 2018, the legal foundation of the friendly and cooperative relationship developed between two countries since 1965 had overthrown. The legal foundation is "Agreement on the Settlement of Problems concerning Property and Claims and on Economic Co-operation between Japan and the Republic of Korea". Under this severe situation surrounding the relationship caused by the South Korea side, the government of Japan will be taking necessary measures against South Korea.

Both countries established diplomatic relations on March 26, 1990. South Korea has an embassy in Ulaanbaatar Mongolia. Mongolia has an embassy in Seoul.

According to a 2013 BBC World Service Poll, 3% of South Koreans view the Democratic People's Republic of Korea's influence positively, with 91% expressing a negative view. A 2015 government-sponsored poll revealed that 41% of South Koreans consider North Korea to be an enemy, with negative views being more prevalent among younger respondents. Still, in a 2017 poll, 58% of South Koreans said they don't expect another war to break out with North Korea.

Since the establishment of diplomatic ties on 3 March 1949, the relationship between the Philippines and South Korea has flourished. The Philippines was one of the first countries that extended diplomatic recognition to South Korea. This was cemented with the Philippine government's deployment of the Philippine Expeditionary Force to Korea (PEFTOK) to help South Korea against the invasion of the communist North during the Korean War in the 1950s. After the war, the Philippines provided development assistance to South Korea and helped the country rebuild itself.

Since then, the Philippines's relations with South Korea have evolved with South Korea becoming one of the Philippines's most important bilateral partners aside from the United States, China and Japan. The Philippines's government seeks to cultivate strategic ties with South Korea given its increasing presence in the country. In the coming years, the Philippines anticipates to benefit from exploring unprecedented opportunities from South Korea that shall contribute significantly to the country's trade and economy, defense and security, and society and culture.

In the 1980s South Korean president Roh Tae Woo's Nordpolitik and Mikhail Gorbachev's "New Thinking" were both attempts to reverse their nations' recent histories. Gorbachev had signaled Soviet interest in improving relations with all countries in the Asia-Pacific region including South Korea as explained in his July 1986 Vladivostok and August 1988 Krasnoyarsk speeches.

In initiating Nordpolitik Roh's confidential foreign policy adviser was rumored to have visited Moscow Russia to consult with Soviet policymakers. Kim Young Sam visited Moscow Russian Federation from June 2 to June 10, 1989 as the Kremlin announced that it would allow some 300,000 Soviet-South Koreans who had been on the Soviet island of Sahkalin since the end of World War II to return permanently to South Korea. Moscow even arranged Kim's meeting with the North Korean ambassador to the Soviet Union In June 1990, Roh held his first summit with president Gorbachev in San Francisco, United States.

South Korea and the Soviet Union established diplomatic relations on September 30, 1990. These relations continued by the Russian Federation on December 27, 1991. Russian president Vladimir Putin visited Seoul in February 2001 while South Korean president Roh Moo-hyun visited Moscow Russia in September 2004.

Russian Federal Space Agency and the Korean Astronaut Program cooperated together to send South Korea's first astronaut into space. Yi So-Yeon became the first South Korean national as well as the third woman to be the first national in space on 8 April 2008 when Soyuz TMA-12 departed from Baikonur Cosmodrome.

Since the 1990s there has been greater trade and cooperation between the Russian Federation and South Korea. The total trade volume between South Korea and Russia in 2003 was 4.2 billion US dollars.

The establishment of diplomatic relations between the United Kingdom and South Korea began on 18 January 1949.

From South Korea to the United Kingdom:

From the United Kingdom to South Korea:

The United States engaged in the decolonization of Korea (mainly in the South, with the Soviet Union engaged in North Korea) from Japan after World War II. After three years of military administration by the United States, the South Korean government was established. Upon the onset of the Korean War, U.S. forces were sent to defend South Korea against invasion by North Korea and later China. Following the Armistice, South Korea and the U.S. agreed to a "Mutual Defense Treaty", under which an attack on either party in the Pacific area would summon a response from both.

In 1968, South Korea obliged the mutual defense treaty, by sending a large combat troop contingent to support the United States in the Vietnam War. The U.S. Eighth Army, Seventh Air Force, and U.S. Naval Forces Korea are stationed in South Korea. The two nations have strong economic, diplomatic, and military ties, although they have at times disagreed with regard to policies towards North Korea, and with regard to some of South Korea's industrial activities that involve usage of rocket or nuclear technology. There had also been strong anti-American sentiment during certain periods, which has largely moderated in the modern day.

Since the late 1980s, the country has instead sought to establish an American partnership, which has made the Seoul–Washington relationship subject to severe strains. Trade had become a serious source of friction between the two countries. In 1989, the United States was South Korea's largest and most important trading partner and South Korea was the seventh-largest market for United States goods and the second largest market for its agricultural products.

From Roh Tae-woo's administration to Roh Moo Hyun's administration, South Korea sought to establish a U.S. partnership, which has made the Seoul–Washington relationship subject to some strains. In 2007, a free trade agreement known as the Republic of Korea-United States Free Trade Agreement (KORUS FTA) was reportedly signed between South Korea and the United States, but its formal implementation has been repeatedly delayed, pending further approval by the legislative bodies of the two countries.

The relations between the United States and South Korea have greatly strengthened under the Lee Myung-bak administration. At the 2009 G-20 London summit, U.S. President Barack Obama called South Korea "one of America's closest allies and greatest friends."
However, some anti-American sentiment in South Korea still exists; The United States' alleged role in the May 1980 Gwangju uprising was a pressing South Korean political issue of the 1980s. Even after a decade, some Gwangju citizens and other South Koreans still blamed the United States for its perceived involvement in the bloody uprising. In 2008, the protests against U.S. beef was a center of a major controversy that year.

In a June 2010 open letter from President of South Korea Lee Myung-bak published in the "Los Angeles Times", he expressed gratitude for the 37,000 Americans who were killed in the Korean War defending South Korea, saying that they fought for the freedom of South Koreans they did not even know. He stated that thanks to their sacrifices, the peace and democracy of the South Korean state was protected.

The U.S. states that "The Alliance is adapting to changes in the 21st Century security environment. We will maintain a robust defense posture, backed by allied capabilities which support both nations' security interests We will continue to deepen our strong bilateral economic, trade and investment relations In the Asia-Pacific region we will work jointly with regional institutions and partners to foster prosperity, keep the peace, and improve the daily lives of the people of the region The United States and South Korea will work to achieve our common Alliance goals through strategic cooperation at every level."

The European Union (EU) and South Korea are important trading partners, having negotiated a free trade agreement for many years since South Korea was designated as a priority FTA partner in 2006. The free trade agreement has been approved in September 2010, following Italy's conditional withdrawal of its veto of the free trade agreement. The compromise made by Italy was that free trade agreement would take provisional effect on July 1, 2011. South Korea is the EU's eighth largest trade partner and the EU has become South Korea's second largest export destination. EU trade with South Korea exceeded €65 billion in 2008 and has enjoyed an annual average growth rate of 7.5% between 2004 and 2008.

The EU has been the single largest foreign investor in South Korea since 1962 and accounted for almost 45% of all FDI inflows into South Korea in 2006. Nevertheless, EU companies have significant problems accessing and operating in South Korea market due to stringent standards and testing requirements for products and services often creating barriers to trade. Both in its regular bilateral contacts with South Korea and through its FTA with South Korea The EU is seeking to improve this situation.

South Korea does not currently have any diplomatic relations with the following nations.

There are also no diplomatic relations with several unrecognized territories:





</doc>
<doc id="27029" url="https://en.wikipedia.org/wiki?curid=27029" title="List of cities in South Korea">
List of cities in South Korea

The largest cities of South Korea have an autonomous status equivalent to that of provinces. Seoul, the largest city and capital, is classified as a "teukbyeolsi" (Special City), while the next six-largest cities are classified as "gwangyeoksi" (Metropolitan Cities; see: List of special cities of South Korea). Smaller cities are classified as "si" ("cities") and are under provincial jurisdiction, at the same level as counties.

South Korean laws requires the population of a county to be generally be 150,000 or greater or the passage of a special legislative bill by the National Assembly such as Gyeryong to be designated a city.

The national government can designate cities of at least 500,000 inhabitants as special status cities. This status expands the scope of administrative authority delegated from the provincial government to the city government. It can also be reclassified as a Metropolitan city if it has at least 1,000,000 inhabitants. Only Suwon and Changwon meet these requirements but neither city has been nominated.

A specific city is a municipal city that has a population greater than 500,000 and has been designated as such by an order of the national government under Article 175 of the Local Autonomy Law. Specific cities are given powers to subdivide themselves into non-autonomous districts (; ) but, not all specific cities are subdivided into non-autonomous districts such as Bucheon, Gimhae, Hwaseong, or Namyangju. Currently, South Korea has a total of 15 Specific cities.






</doc>
<doc id="27031" url="https://en.wikipedia.org/wiki?curid=27031" title="Schoolly D">
Schoolly D

Jesse Bonds Weaver Jr. (born June 22, 1962), better known by the stage name Schoolly D (sometimes spelled Schooly D), is an American rapper from Philadelphia, Pennsylvania.

Schoolly D teamed up with DJ Code Money in the mid-1980s. His lyrics reflected urban realism, violence, and sexual bravado. He was interviewed in the 1986 documentary "Big Fun in the Big Town". He later embraced an Afrocentric style, bringing Afrocentric culture to hip hop along with KRS-One.

Schoolly D contributed songs and music to many Abel Ferrara films, including "P.S.K." and "Saturday Night" (from "Saturday Night! – The Album") as well as "King of New York" to Ferrara's film of the same name and the title track from "Am I Black Enough For You?" that was played during the climactic shoot-out in that film, the title track from "How a Black Man Feels", and "Signifying Rapper" (from "Smoke Some Kill"), which was used in Ferrara's film "Bad Lieutenant". Because Led Zeppelin successfully sued due to an uncleared interpolation of its song "Kashmir" in "Signifying Rapper", the song was omitted from the soundtrack of the film and from subsequent releases of the film.

Composer Joe Delia tapped Schoolly to co-write and record "The Player" for Ferrara's film "The Blackout", which Delia scored. Schoolly also wrote the score to Ferrara's "'R Xmas". In 2006, Schoolly D co-wrote the indie film soundtrack of the historical science fiction thriller "Order of the Quest" with Chuck Treece. The project series is produced by Benjamin Barnett, and Jay D Clark of Media Bureau. His last album, "Funk 'N Pussy", on Jeff "Met" Thies' Chord Recordings features guest appearances by Public Enemy's Chuck D, Chuck Chillout, Lady B and a drum and bass remix of the classic Schoolly D track "Mr. Big Dick" (remixed by UK trip hop crew The Sneaker Pimps).

Schoolly also performed the music and occasional narration for the cult animated series "Aqua Teen Hunger Force" on the Cartoon Network's Adult Swim programming block. He was a guest on an episode of "Space Ghost Coast to Coast". He also created the song "Sharkian Nights" for the "12 oz. Mouse". The character Jesse B. Weaver from "The Rudy and Gogo World Famous Cartoon Show" was also named after him.

In November 2006 Schoolly D and Cartoon Network were sued over the "Aqua Teen Hunger Force" theme music. A drummer by the name of Terence Yerves claimed he had also written the theme music alongside Schoolly D in 1999 while working at the Meat Locker Studio. Yerves was aware the song would be used for a television series but did not approve of it being used for "Aqua Teen Hunger Force", however, did not file the copyright to the Library of Congress until May 2006, after the series' fourth season had already started airing. In the lawsuit Yerves demanded he receive $150,000 for every time the series was aired after the lawsuit was filed, he also demanded that all existing copies of the series' DVDs be impounded and for "Aqua Teen Hunger Force" to cease broadcast.

Rapper Ice-T, who is often given credit for the creation of gangsta rap, discussed Schoolly D's influence on him in his autobiography:





</doc>
<doc id="27032" url="https://en.wikipedia.org/wiki?curid=27032" title="Rock paper scissors">
Rock paper scissors

Rock paper scissors (also known by other permutations such as scissors paper rock, scissors paper stone or ro-sham-bo) is a hand game usually played between two people, in which each player simultaneously forms one of three shapes with an outstretched hand. These shapes are "rock" (a closed fist), "paper" (a flat hand), and "scissors" (a fist with the index finger and middle 
finger extended, forming a V). "Scissors" is identical to the two-fingered V sign (also indicating "victory" or "peace") except that it is pointed horizontally instead of being held upright in the air. 
A simultaneous, zero-sum game, it has only two possible outcomes: a draw, or a win for one player and a loss for the other.

A player who decides to play rock will beat another player who has chosen scissors ("rock crushes scissors" or sometimes "blunts scissors"), but will lose to one who has played paper ("paper covers rock"); a play of paper will lose to a play of scissors ("scissors cuts paper"). If both players choose the same shape, the game is tied and is usually immediately replayed to break the tie. The type of game originated in China and spread with increased contact with East Asia, while developing different variants in signs over time. Other names for the game in the English-speaking world include roshambo and other orderings of the three items, with "rock" sometimes being called "stone".

Rock paper scissors is often used as a fair choosing method between two people, similar to coin flipping, drawing straws, or throwing dice in order to settle a dispute or make an unbiased group decision. Unlike truly random selection methods, however, rock paper scissors can be played with a degree of skill by recognizing and exploiting non-random behavior in opponents.

The players may count aloud to three, or speak the name of the game (e.g. "Rock! Paper! Scissors!"), either raising one hand in a fist and swinging it down with each syllable or holding it behind their back. They then "throw" by extending it towards their opponent. Variations include a version where players throw immediately on the third count (thus throwing on the count of "Scissors!"), or a version where they shake their hands three times before "throwing".

The first known mention of the game was in the book "" by the Chinese Ming-dynasty writer ( 1600), who wrote that the game dated back to the time of the Chinese Han dynasty (206 BCE – 220 CE). In the book, the game was called "shoushiling". Li Rihua's book "Note of Liuyanzhai" also mentions this game, calling it "shoushiling" (t. 手勢令; s. 手势令), "huozhitou" (t. 豁指頭; s. 豁指头), or "huaquan" (划拳).
Throughout Japanese history there are frequent references to "sansukumi-ken", meaning "ken" (fist) games where "the three who are afraid of one another" (i.e. A beats B, B beats C, and C beats A). This type of game originated in China before being imported to Japan and subsequently also becoming popular among the Japanese.

The earliest Japanese "sansukumi-ken" game was known as "mushi-ken" (虫拳), which was imported directly from China. In "mushi-ken" the "frog" (represented by the thumb) triumphs over the "slug" (represented by the little finger), which, in turn prevails over the "snake" (represented by the index finger), which triumphs over the "frog". Although this game was imported from China the Japanese version differs in the animals represented. In adopting the game, the original Chinese characters for the poisonous centipede (蜈蜙) were apparently confused with the characters for the slug (蛞蝓). The most popular "sansukumi-ken" game in Japan was "kitsune-ken" (). In the game, a supernatural fox called a kitsune (狐) defeats the village head, the village head (庄屋) defeats the hunter, and the hunter (猟師) defeats the fox. "Kitsune-ken", unlike "mushi-ken" or rock–paper–scissors, is played by making gestures with both hands.

Today, the best-known "sansukumi-ken" is called , which is a variation of the Chinese games introduced in the 17th century. "Jan-ken" uses the rock, paper, and scissors signs and is the game that the modern version of rock paper scissors derives from directly. Hand-games using gestures to represent the three conflicting elements of rock, paper, and scissors have been most common since the modern version of the game was created in the late 19th century, between the Edo and Meiji periods.

By the early 20th century, rock paper scissors had spread beyond East Asia, especially through increased Japanese contact with the west. Its English-language name is therefore taken from a translation of the names of the three Japanese hand-gestures for rock, paper and scissors: elsewhere in East Asia the open-palm gesture represents "cloth" rather than "paper". The shape of the scissors is also adopted from the Japanese style.

A 1921 article about cricket in the "Sydney Morning Herald" described "stone, scissors, and paper" as a "Teutonic method of drawing lots", which the writer "came across when travelling on the Continent once". Another article, from the same year, in the "Washington Herald" described it as a method of "Chinese gambling".
In Britain in 1924 it was described in a letter to "The Times" as a hand game, possibly of Mediterranean origin, called "zhot".
A reader then wrote in to say that the game "zhot" referred to was evidently Jan-ken-pon, which she had often seen played throughout Japan. Although at this date the game appears to have been new enough to British readers to need explaining, the appearance by 1927 of a popular thriller with the title "Scissors Cut Paper", followed by "Stone Blunts Scissors" (1929), suggests it quickly became popular.

In 1927 "La Vie au patronage", a children's magazine in France, described it in detail, referring to it as a "jeu japonais" ("Japanese game"). Its French name, "Chi-fou-mi", is based on the Old Japanese words for "one, two, three" ("hi, fu, mi").

A 1932 "New York Times" article on the Tokyo rush hour describes the rules of the game for the benefit of American readers, suggesting it was not at that time widely known in the U.S. The 1933 edition of the "Compton's Pictured Encyclopedia" described it as a common method of settling disputes between children in its article on Japan; the name was given as "John Kem Po" and the article pointedly asserted, "This is such a good way of deciding an argument that American boys and girls might like to practice it too."

It is impossible to gain an advantage over a truly random opponent. However, by exploiting the psychological weaknesses of inherently non-random opponents, it is possible to gain a significant advantage. Indeed, human players tend to be non-random. As a result, there have been programming competitions for algorithms that play rock paper scissors.

During tournaments, players often prepare their sequence of three gestures prior to the tournament's commencement. Some tournament players employ tactics to confuse or trick the other player into making an illegal move, resulting in a loss. One such tactic is to shout the name of one move before throwing another, in order to misdirect and confuse their opponent.

The "rock" move, in particular, is notable in that it is typically represented by a closed fist—often identical to the fist made by players during the initial countdown. If a player is attempting to beat their opponent based on quickly reading their hand gesture as the players are making their moves, it is possible to determine if the opponent is about to throw "rock" based on their lack of hand movement, as both "scissors" and "paper" require the player to reposition their hand. This can likewise be used to deceive an anticipating opponent by keeping one's fist closed until the last possible moment, leading them to believe that you are about to throw "rock".

As a consequence of rock paper scissors programming contests, many strong algorithms have emerged. For example, Iocaine Powder, which won the First International RoShamBo Programming Competition in 1999, uses a heuristically designed compilation of strategies. For each strategy it employs, it also has six metastrategies which defeat second-guessing, triple-guessing, as well as second-guessing the opponent, and so on. The optimal strategy or metastrategy is chosen based on past performance. The main strategies it employs are history matching, frequency analysis, and random guessing. Its strongest strategy, history matching, searches for a sequence in the past that matches the last few moves in order to predict the next move of the algorithm. In frequency analysis, the program simply identifies the most frequently played move. The random guess is a fallback method that is used to prevent a devastating loss in the event that the other strategies fail. More than ten years later, the top performing strategies on an ongoing rock–paper–scissors programming competition similarly use metastrategies. However, there have been some innovations, such as using multiple history matching schemes that each match a different aspect of the history – for example, the opponent's moves, the program's own moves, or a combination of both. There have also been other algorithms based on Markov chains.

In 2012, researchers from the Ishikawa Watanabe Laboratory at the University of Tokyo created a robot hand that can play rock paper scissors with a 100% win rate against a human opponent. Using a high-speed camera the robot recognizes within one millisecond which shape the human hand is making, then produces the corresponding winning shape.

In 2006, American federal judge Gregory Presnell from the Middle District of Florida ordered opposing sides in a lengthy court case to settle a trivial (but lengthily debated) point over the appropriate place for a deposition using the game of rock paper scissors. The ruling in "Avista Management v. Wausau Underwriters" stated:

In 2005, when Takashi Hashiyama, CEO of Japanese television equipment manufacturer Maspro Denkoh, decided to auction off the collection of Impressionist paintings owned by his corporation, including works by Paul Cézanne, Pablo Picasso, and Vincent van Gogh, he contacted two leading auction houses, Christie's International and Sotheby's Holdings, seeking their proposals on how they would bring the collection to the market as well as how they would maximize the profits from the sale. Both firms made elaborate proposals, but neither was persuasive enough to earn Hashiyama's approval. Unwilling to split up the collection into separate auctions, Hashiyama asked the firms to decide between themselves who would hold the auction, which included Cézanne's "Large Trees Under the Jas de Bouffan", worth $12–16 million.

The houses were unable to reach a decision. Hashiyama told the two firms to play rock paper scissors to decide who would get the rights to the auction, explaining that "it probably looks strange to others, but I believe this is the best way to decide between two things which are equally good".

The auction houses had a weekend to come up with a choice of move. Christie's went to the 11-year-old twin daughters of the international director of Christie's Impressionist and Modern Art Department Nicholas Maclean, who suggested "scissors" because "Everybody expects you to choose 'rock'." Sotheby's said that they treated it as a game of chance and had no particular strategy for the game, but went with "paper". Christie's won the match and sold the $20 million collection, earning millions of dollars of commission for the auction house.

Prior to a 26 October 2018 match in the FA Women's Super League, the referee, upon being without a coin for the pregame coin toss, had the team captains play rock paper scissors to determine which team would kick-off. The referee was subsequently suspended for three weeks by The Football Association.

In Japan, researchers have taught chimpanzees the rules of rock paper scissors.

In many games, it is common for a group of possible choices to interact in a rock paper scissors style, where each selection is strong against a particular choice, but weak against another. For instance cavalry–artillery–infantry. Such mechanics can make a game somewhat self-balancing, prevent gameplay from being overwhelmed by a single dominant strategy and single dominant type of unit.

Many card-based video games in Japan use the rock paper scissors system as their core fighting system, with the winner of each round being able to carry out their designated attack. In "Alex Kidd in Miracle World", the player has to win games of rock paper scissors against each boss to proceed. Others use simple variants of rock paper scissors as subgames.

Many Nintendo role-playing games prominently feature a rock paper scissors gameplay element. In "Pokémon", there is a rock paper scissors element in the type effectiveness system. For example, a Grass-type Pokémon is weak to Fire, Fire is weak to Water, and Water is weak to Grass. In the 3DS remake of "" and "", the battles in the second mode (Minion Quest: The Search for Bowser / Bowser Jr.'s Journey) use a “Power Triangle” system based on the game's three attack types: Melee, Ranged, and Flying. In the "Fire Emblem" series of strategy role-playing games, the Weapon Triangle and Trinity of Magic influence the hit and damage rates of weapon types based on whether they are at an advantage or a disadvantage in their respective rock paper scissors system. In "Super Smash Bros.", the three basic actions used during the match are described in their respective rock paper scissors system: attack, defense, and grab.

The common side-blotched lizard ("Uta stansburiana") exhibits a rock paper scissors pattern in its mating strategies. Of its three color types of males, "orange beats blue, blue beats yellow, and yellow beats orange" in competition for females, which is similar to the rules of rock-paper-scissors.

Some bacteria also exhibit a rock paper scissors dynamic when they engage in antibiotic production. The theory for this finding was demonstrated by computer simulation and in the laboratory by Benjamin Kerr, working at Stanford University with Brendan Bohannan. Additional "in vitro" results demonstrate rock paper scissors dynamics in additional species of bacteria. Biologist Benjamin C. Kirkup, Jr. demonstrated that these antibiotics, bacterioicins, were active as "Escherichia coli" compete with each other in the intestines of mice, and that the rock paper scissors dynamics allowed for the continued competition among strains: antibiotic-producers defeat antibiotic-sensitives; antibiotic-resisters multiply and withstand and out-compete the antibiotic-producers, letting antibiotic-sensitives multiply and out-compete others; until antibiotic-producers multiply again.

Rock paper scissors is the subject of continued research in bacterial ecology and evolution. It is considered one of the basic applications of game theory and non-linear dynamics to bacteriology. Models of evolution demonstrate how intragenomic competition can lead to rock paper scissors dynamics from a relatively general evolutionary model. The general nature of this basic non-transitive model is widely applied in theoretical biology to explore bacterial ecology and evolution.

In the televised robot combat competition "BattleBots", relations between "lifters, which had wedged sides and could use forklift-like prongs to flip pure wedges", "spinners, which were smooth, circular wedges with blades on their bottom side for disabling and breaking lifters", and "pure wedges, which could still flip spinners" are analogical to relations in rock paper scissors games and called "robot Darwinism". Also specially designed rock paper scissors game" mechanical devices can demonstrate intransitivity of relations such as "to rotate faster than", "to lift and not be lifted", "to be stronger than" in some geometrical constructions.

Various competitive rock paper scissors tournaments have been organised by different groups.

Starting in 2002, the World Rock Paper Scissors Society standardized a set of rules for international play and has overseen annual International World Championships. These open, competitive championships have been widely attended by players from around the world and have attracted widespread international media attention. WRPS events are noted for their large cash prizes, elaborate staging, and colorful competitors.
In 2004, the championships were broadcast on the U.S. television network Fox Sports Net, with the winner being Lee Rammage, who went on to compete in at least one subsequent championship. The 2007 tournament was won by Andrea Farina. The last tournament hosted by the World RPS Society was in Toronto, Canada, on November 14, 2009.

Several RPS events have been organised in the United Kingdom by Wacky Nation. The 1st UK Championship took place on 13 July 2007, and were then held annually. The 2019 event was won by Ellie Mac who went on to pick up the cash prize of £20,000 but was unable to double her earnings in 2020 due to the coronavirus outbreak.

USA Rock Paper Scissors League is sponsored by Bud Light. Leo Bryan Pacis was the first commissioner of the USARPS. Cody Louis Brown was elected as the second commissioner of the USARPS in 2014.

In April 2006, the inaugural USARPS Championship was held in Las Vegas. Following months of regional qualifying tournaments held across the US, 257 players were flown to Las Vegas for a single-elimination tournament at the House of Blues where the winner received $50,000. The tournament was shown on the A&E Network on 12 June 2006.

The $50,000 2007 USARPS Tournament took place at the Las Vegas Mandalay Bay in May 2007.

In 2008, Sean "Wicked Fingers" Sears beat 300 other contestants and walked out of the Mandalay Bay Hotel and Casino with $50,000 after defeating Julie "Bulldog" Crossley in the finals.

The inaugural Budweiser International Rock, Paper, Scissors Federation Championship was held in Beijing, China after the close of the 2008 Summer Olympics at Club Bud. A Belfast man won the competition.

The international tournament was held in London 2012. UK Champions Team GB (Andrew Bladon, Jamie Burland, Tom Wilkinson and Stephen Preston) went in as overwhelming favorites, but after a "domestic incident" team captain and UK Team Champion Joe Kenny was forced to pull out, allowing Stephen Preston to take his place. Great Britain came a respectable third to achieve the Bronze Medal, while the crowd favorite Vatican City got the Silver and Lapland A took the prestigious Gold Medal. British team captain Tom Wilkinson commented "after a 4-0 whitewash of hot favorites Vatican City we thought we had it. A simple lapse of concentration lost it for us, but we are happy with our bronze medal. We'll come back from this and look to take the title back again next year. The support was immense, and we are thankful of everyone who came out to support us".

The XtremeRPS National Competition is a US nationwide RPS competition with Preliminary Qualifying contests that started in January 2007 and ended in May 2008, followed by regional finals in June and July 2008. The national finals were to be held in Des Moines, Iowa in August 2008, with a chance to win up to $5,000.

The largest Rock Paper Scissors tournament is 2,950 and was achieved by Oomba, Inc. (USA) at Gen Con 2014 in Indianapolis, Indiana, United States, on 17 August 2014.

Former Celebrity Poker Showdown host and USARPS Head Referee Phil Gordon has hosted an annual $500 World Series of Rock Paper Scissors event in conjunction with the World Series of Poker since 2005. The winner of the WSORPS receives an entry into the WSOP Main Event. The event is an annual fundraiser for the "Cancer Research and Prevention Foundation" via Gordon's charity "Bad Beat on Cancer". Poker player Annie Duke won the Second Annual World Series of Rock Paper Scissors. The tournament is taped by ESPN and highlights are covered during "The Nuts" section of ESPN's annual WSOP broadcast. 2009 was the fifth year of the tournament.

Jackpot En Poy is a game segment on the Philippines' longest running midday show, "Eat Bulaga!". The game is based on the classic children's game rock paper scissors where four players are paired to compete in the three-round segment. In the first round, the first pair plays against each other until one player wins three times. The next pair then plays against each other in the second round. The winners from the first two rounds then compete against each other to finally determine the ultimate winner. The winner of the game then moves on to the final round. In the final round, the player is presented with several Dabarkads, each holding different amounts of cash prize. The player will then pick three Dabarkads who he or she will play rock paper scissors against. The player plays against them one at a time. If the player wins against any of the "Eat Bulaga!" hosts, he or she will win the cash prize.

Players have developed numerous cultural and personal variations on the game, from simply playing the same game with different objects, to expanding into more weapons and rules, to giving their own name to the game in their national language.

In Korea, a two-player upgraded version exists by the name "muk-jji-ppa". After showing their hands, the player with the winning throw shouts ""muk-jji-ppa!"" upon which both players throw again. If they throw differently (for example, rock and paper, or paper and scissors), whoever wins this second round shouts ""muk-jji-ppa!"" and thus the play continues until both players throw the same item (for example, rock and rock), at which point whoever was the last winner becomes the actual winner.

In Japan, a "strip-poker" variant of rock paper scissors is known as 野球拳 ("Yakyuken"). The loser of each round removes an article of clothing. The game is a minor part of porn culture in Japan and other Asian countries after the influence of TV variety shows and Soft On Demand.

In the Philippines, the game is called "jak-en-poy", from one of the Japanese names of the game, transliterated as "jan-ken-pon". In a longer version of the game, a four-line song is sung, with hand gestures displayed at the end of each (or the final) line: "Jack-en-poy! / Hali-hali-hoy! / Sino'ng matalo, / siya'ng unggoy!" ("Jack-en-poy! / Hali-hali-hoy! / Whoever loses is the monkey!") In the former case, the person with the most wins at the end of the song, wins the game. A shorter version of the game uses the chant "Bato-bato-pick" ("Rock-rock-pick [i.e. choose]") instead.

A multiple player variation can be played: Players stand in a circle and all throw at once. If rock, paper, and scissors are all thrown, it is a stalemate, and they rethrow. If only two throws are present, all players with the losing throw are eliminated. Play continues until only the winner remains.

In the Malaysian version of the game, "scissors" is replaced by "bird," represented with the finger tips of five fingers brought together to form a beak. The open palm represents "water". Bird beats water (by drinking it); stone beats bird (by hitting it); and stone loses to water (because it sinks in it).

Singapore also has a related hand-game called ""ji gu pa"", where ""ji"" refers to the bird gesture, ""gu"" refers to the stone gesture, and ""pa"" refers to the water gesture. The game is played by two players using both hands. At the same time, they both say, ""ji gu pa!"" At ""pa!"" they both show two open-palmed hands. One player then changes his hand gestures while calling his new combination out (e.g., ""pa gu!""). At the same time, the other player changes his hand gestures as well. If one of his hand gestures is the same as the other one, that hand is "out" and he puts it behind his back; he is no longer able to play that hand for the rest of the round. The players take turns in this fashion, until one player loses by having both hands sent "out". ""Ji gu pa"" is most likely a transcription of the Japanese names for the different hand gestures in the original jan-ken game, ""choki"" (scissors), ""guu"" (rock) and ""paa"" (paper).

Using the same tripartite division, there is a full-body variation in lieu of the hand signs called "Bear, Hunter, Ninja". In this iteration the participants stand back-to-back and at the count of three (or ro-sham-bo as is traditional) turn around facing each other using their arms evoking one of the totems. The players' choices break down as: Hunter shoots bear; Bear eats ninja; Ninja kills hunter. The game was popularized with a FedEx commercial where warehouse employees had too much free time on their hands.

As long as the number of moves is an odd number and each move defeats exactly half of the other moves while being defeated by the other half, any combination of moves will function as a game. For example, 5-, 7-, 9-, 11-, 15-, 25-, and 101-weapon versions exist. Adding new gestures has the effect of reducing the odds of a tie, while increasing the complexity of the game. The probability of a tie in an odd-number-of-weapons game can be calculated based on the number of weapons n as 1/n, so the probability of a tie is 1/3 in standard rock paper scissors, but 1/5 in a version that offered five moves instead of three.

Similarly, the French game "pierre, papier, ciseaux, puits" (stone, paper, scissors, well) is unbalanced; both the stone and scissors fall in the well and lose to it, while paper covers both stone and well. This means two "weapons", well and paper, can defeat two moves, while the other two weapons each defeat only one of the other three choices. The rock has no advantage to well, so optimal strategy is to play each of the other objects (paper, scissors and well) one third of the time.

One popular five-weapon expansion is "", invented by Sam Kass and Karen Bryla, which adds "Spock" and "lizard" to the standard three choices. "Spock" is signified with the "Star Trek" Vulcan salute, while "lizard" is shown by forming the hand into a sock-puppet-like mouth. Spock smashes scissors and vaporizes rock; he is poisoned by lizard and disproved by paper. Lizard poisons Spock and eats paper; it is crushed by rock and decapitated by scissors. This variant was mentioned in a 2005 article in "The Times" of London and was later the subject of an episode of the American sitcom "The Big Bang Theory" in 2008 (as rock-paper-scissors-lizard-Spock).

The majority of such proposed generalizations are isomorphic to a simple game of modular arithmetic, where half the differences are wins for player one. For instance, Rock-Paper-Scissors-Spock-Lizard may be modeled as a game in which each player picks a number from one to five. Subtract the number chosen by player two from the number chosen by player one, and then take the remainder modulo 5 of the result. Player one is the victor if the difference is one or three, and player two is the victor if the difference is two or four. If the difference is zero, the game is a tie.

Alternatively, the rankings may be modeled by a comparison of the parity of the two choices. If it is the same (two odd-numbered moves or two even-numbered ones) then the lower number wins, while if they are different (one odd and one even) the higher wins. Using this algorithm, additional moves can easily be added two at a time while keeping the game balanced:

Any variation of Rock Paper Scissors is an oriented graph. According to theoretical calculations, the number of distiguishable oriented graphs, every of which is a potentially playable Rock Paper Scissors game, grows with the number of weapons = 3, 4, 5, … as follow:
A game-theoretic analysis showed that 4 variants of 582 possible variations using 5 different weapons have non-trivial mixed strategy equilibria. The most representative game of these 4 is Rock Paper Scissors Fire Water. Rock beats Scissors, Paper beats Rock, Scissors beats Paper, Fire beats everything except Water, and Water is beaten by everything except it beats Fire. The perfect game-theoretic strategy is to use Rock, Paper, and Scissors formula_1 of the time and formula_2 of the time for Fire and Water. Nevertheless, experiments show that people underuse Water and overuse Rock, Paper, and Scissors in this game.


Notes
Bibliography



</doc>
<doc id="27033" url="https://en.wikipedia.org/wiki?curid=27033" title="Logudorese dialect">
Logudorese dialect

Logudorese Sardinian (, ) is one of the two written standards of Sardinian, often considered the most conservative of all Romance languages. The orthography is based on the spoken dialects of central northern Sardinia, identified by certain attributes which are not found, or found to a lesser degree, among the Sardinian dialects centered on the other written form, Campidanese. Its ISO 639-3 code is "src". Italian speakers do not understand Logudorese, like any other dialect of the Sardinian language: Sardinian is an autonomous linguistic group rather than a dialect of Italian as it is often noted because of its morphological, synctatic, and lexical differences from Italian.

Latin G and K before , are not palatalized in Logudorese, in stark contrast with all other Romance languages. Compare Logudorese ' with Italian ' , Spanish ' and French ' . Like the other varieties of Sardinian, most subdialects of Logudorese also underwent lenition in the intervocalic plosives of --, --, and --/ (e.g. Lat. "focum" > "fogu" "fire", "ripa" > "riba" "shore, bank", "rota" > "roda" "wheel"). Logudorese also turns medial and into and and , respectively (e.g. Lat. "Sardinia" > "Sardigna" and "folium" > "fogia" "leaf"). Finally, Logudorese shifts the Latin labiovelars and into medially and word-initially (Lat. "lingua" > "limba" "tongue", "qualem" > "cale" "what")

Logudorese is intelligible to those from the southern part of Sardinia, where Campidanese Sardinian is spoken, but it is not to those from the extreme north of the island, where Corsican–Sardinian dialects are spoken.

The area of Logudoro (the term originated as a blend of the kingdom's name of Logu de Torres), in which it is spoken, is a northern subregion of the island of Sardinia with close ties to Ozieri ("Othieri") and Nuoro ("Nùgoro") for culture and language, as well as history, with important particularities in the western area, where the most important town is Ittiri. It is an area of roughly 150 × 100 km with some 500,000–700,000 inhabitants.

The origins of Sardinian have been investigated by Eduardo Blasco Ferrer and others. The language derives from Latin and a pre-Latin, Paleo-Sardinian (Nuragic) substratum, but has been influenced by Catalan and Spanish due to the dominion of the Crown of Aragon and later the Spanish Empire over the island. Logudorese is the northern macro-dialect of the Sardinian language, the southern macro-dialect being Campidanese, spoken in the southern half of the island. The two dialects share a clear common origin and history, but have experienced somewhat different developments.

Though the language is typically Romance, some words are not of Latin origin, and are of uncertain etymology. One such is "nura", found in "nuraghe", the main form of pre-Roman building, hence the term for the pre-Roman era as the Nuragic Period. Various place names similarly have roots that defy analysis.

Logudorese Sardinian changed only very slowly from Vulgar Latin in comparison to other Romance lects, with Linguist Mario Pei reporting an 8% degree of separation from Latin in the Nuorese subdialect, the most conservative compared to other Romance Languages. Because of this reason, as well as the preservation of many works of traditional literature from the 15th century onwards, Logudorese is often considered to be the most prestigious variety of Sardinian.

Logudorese Sardinian has multiple subdialects, some confined to individual villages or valleys. Though such differences can be noticeable, the dialects are mutually intelligible, and share mutual intelligibility with the neighbouring Campidanese dialects as well.

Spoken in the north of Sardinia, this subdialect contains the following features:

, , changes to , , (Lat. "plovere" > "piòere" "rain", "florem" > "fiore" "flower", "clavem" > "ciae" "key")

Spoken in Central Sardinia, this subdialect contains the following features:

, , changes to , , (Lat. "plovere" > "pròere" "rain", "florem" > "frore" "flower", "clavem" > "crae" "key")

The Nuorese dialects (spoken in Nuoro and Baronia) have some distinctive features not found anywhere else in Sardinia, many features demonstrating the conservative nature of the dialect:

No lenition of intervocalic plosives (e.g. Lat. "focum" > "focu" "fire", "ripa" > "ripa" "shore, bank", "rota" > "rota" "wheel")

No palatal realisation of and , instead turning into and and , respectively (e.g. Lat. "Sardinia" > "Sardinna" and "folium" > "folla" "leaf").

Preservation of intervocalic , , and (Lat. "augustus" "August" > Log. "austu" but Nuo. "agustu", Lat. "credere" "to believe" > Log. "creere" but Nuo. "credere", Lat. "novem" "nine" > Log. "noe" vs Nuo. "nobe" < "nove")

Betacism of in Nuoro but not in Baronia.

Latin before yod to in Nuorese ("plateam" "street, courtyard" > "pratha"), albeit the sound is in the process of becoming ("pratza").

A large body of Sardinian poetry, songs and literature is composed in Logudorese.




</doc>
<doc id="27034" url="https://en.wikipedia.org/wiki?curid=27034" title="Sardinian language">
Sardinian language

Sardinian or Sard ("sardu" / "sadru" , "limba sarda" or "lìngua sarda" ) is a Romance language spoken by the Sardinians on the Western Mediterranean island of Sardinia.

Many Romance linguists consider it the language that, together with Italian, is closest to Latin among all the genealogical descendants of Latin. However, it has also incorporated elements of a Pre-Latin (mostly Paleo-Sardinian and, to a much lesser degree, Punic) substratum, as well as a Byzantine Greek, Catalan, Spanish and Italian superstratum. These elements of the language originate in the political history of the island of Sardinia: before the Middle Ages, it was for a time a Byzantine possession; then, after a significant period of self-rule with the judicates, it came during the late Middle Ages into the Iberian sphere of influence; and finally, from the 18th century onward, under the Italian one.

In 1997, Sardinian, along with other languages spoken on the island, was recognized by regional law as an official language of Sardinia, and in 1999, Sardinian and eleven other "minoranze linguistiche storiche" ("historical linguistic minorities") were similarly recognized by national law (specifically, Law No. 482/1999). Among these, Sardinian is notable as having the largest number of speakers.

However, the number of native speakers has been declining, threatening the vitality of the Sardinian-speaking community. While it was estimated in 2007 that 68.4 percent of the inhabitants of Sardinia had a good oral command of Sardinian, most of them were beyond retirement age. Only 13 percent of children were reported to have this level of competence in the language, with Sardinian being kept as a heritage language. UNESCO has classified the language as "definitely endangered".

Sardinian is considered the most conservative Romance language, and its substratum (Paleo-Sardinian or Nuragic) has also been researched. A 1949 study by the Italian-American linguist Mario Pei, analyzing the degree of difference from a language's parent (Latin, in the case of Romance languages) by comparing phonology, inflection, syntax, vocabulary, and intonation, indicated the following percentages (the higher the percentage, the greater the distance from Latin): Sardinian 8%, Italian 12%, Spanish 20%, Romanian 23.5%, Occitan 25%, Portuguese 31%, and French 44%. For example, Latin ""Pone mihi tres panes in bertula"" (put three loaves of bread [from home] in the bag for me) would be the very similar ""Ponemi tres panes in bertula"" in Sardinian.

Compared to the mainland Italian dialects, Sardinian is virtually incomprehensible for Italians, and is in fact considered a distinct linguistic group among the Romance languages.

Sardinia's relative isolation from mainland Europe encouraged the development of a Romance language that preserves traces of its indigenous, pre-Roman language(s). The language is posited to have substratal influences from Paleo-Sardinian, which some scholars have linked to Basque and Etruscan. Adstratal influences include Catalan, Spanish, and Italian. The situation of Sardinian language with regard to the politically dominant ones did not change until fascism and, most evidently, the 1950s.

The origins of ancient Sardinian, also known as Paleo-Sardinian, are currently unknown. Research has attempted to discover obscure, indigenous, pre-Romance roots. The root "s(a)rd", indicating many place names as well as the island's people, is reportedly either associated with or originating from the Sherden, one of the Sea Peoples. Other sources trace instead the root "s(a)rd" from , a legendary woman from the Anatolian Kingdom of Lydia, or from the Libyan mythological figure of the Sardus Pater "Babai" ("Sardinian Father" or "Father of the Sardinians").

In 1984, Massimo Pittau claimed to have found the etymology of many Latin words in the Etruscan language, after comparing it with the Nuragic language(s). Etruscan elements, formerly thought to have originated in Latin, would indicate a connection between the ancient Sardinian culture and the Etruscans. According to Pittau, the Etruscan and Nuragic language(s) are descended from Lydian (and therefore Indo-European) as a consequence of contact with Etruscans and other Tyrrhenians from Sardis as described by Herodotus. Although Pittau suggests that the Tirrenii landed in Sardinia and the Etruscans landed in modern Tuscany, his views are not shared by most Etruscologists.

According to Bertoldi and Terracini, Paleo-Sardinian has similarities with the Iberic languages and Siculian; for example, the suffix -"ara" in proparoxytones indicated the plural. Terracini proposed the same for suffixes in -', -/"ànna"/, -/"énna"/, -/"ònna"/ + ' + a paragogic vowel (such as the toponym "Bunnànnaru"). Rohlfs, Butler and Craddock add the suffix -' (such as the toponym "Barùmini") as a unique element of Paleo-Sardinian. Suffixes in /"a", "e", "o", "u"/ + -"rr"- found a correspondence in north Africa (Terracini), in Iberia (Blasco Ferrer) and in southern Italy and Gascony (Rohlfs), with a closer relationship to Basque (Wagner and Hubschmid). However, these early links to a Basque precursor have been questioned by some Basque linguists. According to Terracini, suffixes in -', -', -', and -' are common to Paleo-Sardinian and northern African languages. Pittau emphasized that this concerns terms originally ending in an accented vowel, with an attached paragogic vowel; the suffix resisted Latinization in some place names, which show a Latin body and a Nuragic suffix. According to Bertoldi, some toponyms ending in -' and -/"asài"/ indicated an Anatolian influence. The suffix -/"aiko"/, widely used in Iberia and possibly of Celtic origin, and the ethnic suffix in -/"itanos"/ and -/"etanos"/ (for example, the Sardinian "Sulcitanos") have also been noted as Paleo-Sardinian elements (Terracini, Ribezzo, Wagner, Hubschmid and Faust).

Linguists Blasco Ferrer (2009, 2010) and Arregi (2017) have attempted to revive a theoretical connection with Basque by linking words such as Sardinian "ospile" "fresh grazing for cattle" and Basque "ozpil"; Sardinian "arrotzeri" "vagabond" and Basque "arrotz" "stranger"; Sardinian "golostiu" and Basque "gorosti" “holly”; Gallurese (Corso-Sardinian) "zerru" “pig” (with "z" for [dz]) and Basque "zerri" (with "z" for [s]). Genetic data have found the Basques to be close to the Sardinians.

Since the Neolithic period, some degree of variance across the island's regions is also attested. The Arzachena culture, for instance, suggests a link between the northernmost Sardinian region (Gallura) and southern Corsica that finds further confirmation in the Naturalis Historia by Pliny the Elder. There are also some stylistic differences across Northern and Southern Nuragic Sardinia, which may indicate the existence of two other tribal groups (Balares and Ilienses) mentioned by the same Roman author. According to the archeologist Giovanni Ugas, these tribes may have in fact played a role in shaping the current regional linguistic differences of the island.


Around the 10th and 9th century BC, Phoenician merchants were known to have made their presence in Sardinia, which acted as a geographical mediator in between the Iberian and the Italian peninsula. In the eighth and seventh centuries, the Phoenicians began to develop permanent settlements, politically arranged as city-states in similar fashion to the Lebanese coastal areas. It did not take long before they started gravitating around the Carthaginian sphere of influence, whose level of prosperity spurred Carthage to send a series of expeditionary forces to the island; although they were initially repelled by the natives, the North African city vigorously pursued a policy of active imperialism and, by the sixth century, managed to establish its political hegemony and military control over South-Western Sardinia. Punic began to be spoken in the area, and many words entered ancient Sardinian as well. Names like "giara" "plateau" (cf. Hebrew "forest, scrub"), "g(r)uspinu" "nasturtium" (from the Punic "cusmin"), "curma" "fringed rue" (cf. "ḥarmal" "Syrian rue"), "mítza" "source" (cf. Hebrew "mitsa", "metza" "place whence something emerges"), "síntziri" "marsh horsetail" (from the Punic "zunzur" "common knotgrass"), "tzeúrra" "sprout" (from the Punic "zeraʿ" "seed"), "tzichirìa" "dill" (from the Punic "sikkíria"; cf. Hebrew "šēkār" "ale") and "tzípiri" "rosemary" (from the Punic "zibbir") are commonly used, especially in the modern Sardinian varieties of the Campidanese plain, while proceeding northwards the influence is more limited to place names, like "Macumadas" in the Province of Nuoro or "Magumadas" in Gesico and Nureci, which derive from the Punic "maqom hadash" "new city".

The Roman domination began in 238 and brought Latin to Sardinia, but was often contested by the local Sardinian tribes and proved unable to completely supplant the pre-Latin Sardinian languages, including Punic, which continued to be spoken in the 4th century as attested by votive inscriptions. Some obscure Nuragic roots remained unchanged, and in many cases Latin accepted the local roots (like "nur", presumably from Norax, which makes its appearance in nuraghe, "Nurra", "Nurri" and many other toponyms). Barbagia, the mountainous central region of the island, derives its name from the Latin "Barbaria" (a term meaning "Land of the Barbarians", similar in origin to the now antiquated word "Barbary"), because its people refused cultural and linguistic assimilation for a long time: 50% of toponyms of central Sardinia, particularly in the territory of Olzai, are actually not related to any known language. Besides the place names, on the island there are still a few names of plants, animals and geological formations directly traceable to the ancient Nuragic era. Cicero called the Sardinian rebels "latrones mastrucati" ("thieves with rough wool cloaks") to emphasize Roman superiority.

During the long Roman domination Latin gradually become however the speech of the majority of the island's inhabitants. As a result of this process of Romanization, the modern Sardinian language is today classified as Romance or neo-Latin, with some phonetic features resembling Old Latin. Some linguists assert that modern Sardinian, being part of the Island Romance group, was the first language to split off from Latin, all others evolving from Latin as Continental Romance.

At that time, the only literature being produced in Sardinia was mostly in Latin: the native (Paleo-Sardinian) and non-native (Punic) pre-Roman languages were then already extinct (the last Punic inscription in Bithia, southern Sardinia, is from the second or third century A.D.). Some engraved poems in ancient Greek and Latin (the two most prestigious languages in the Roman Empire) are to be seen in Viper Cave, Cagliari, ("Gruta 'e sa Pibera" in Sardinian, "Grotta della Vipera" in Italian, "Cripta Serpentum" in Latin), a burial monument built by Lucius Cassius Philippus (a Roman who had been exiled to Sardinia) in remembrance of his dead spouse Atilia Pomptilla. We also have some religious works by Saint Lucifer and Eusebius, both from Caralis (Cagliari).

Although Sardinia was culturally influenced and politically ruled by the Byzantine Empire for almost five centuries, Greek did not enter the language except for some ritual or formal expressions in Sardinian using Greek structure and, sometimes, the Greek alphabet. Evidence for this is found in the "condaghes", the first written documents in Sardinian. From the long Byzantine era there are only a few entries but they already provide a glimpse of the sociolinguistical situation on the island in which, in addition to the community's everyday Neo-Latin language, Greek was also spoken by the ruling classes. Some toponyms, such as Jerzu (thought to derive from the Greek "khérsos", "untilled"), together with the personal names Mikhaleis, Konstantine and Basilis, demonstrate Greek influence.

As the Muslims conquered southern Italy and Sicily, communications broke down between Constantinople and Sardinia, whose districts became progressively more autonomous from the Byzantine oecumene (Greek: οἰκουμένη). Sardinia was then brought back into the Latin cultural sphere.

Sardinian was the first Romance language of all to gain official status, being used by the four Judicates, former Byzantine districts that became independent political entities after the Arab expansion in the Mediterranean cut off any ties left between the island and Byzantium. One of the oldest documents left in Sardinian (the so-called "Carta Volgare") comes from the Judicate of Cagliari and was issued by Torchitorio I de Lacon-Gunale in around 1070, employing the Greek alphabet. Old Sardinian had a greater number of archaisms and Latinisms than the present language does. While the earlier documents show the existence of an early Sardinian Koine, the language used by the various Judicates already displayed a certain range of dialectal variation. A special position was occupied by the Judicate of Arborea, the last Sardinian kingdom to fall to foreign powers, in which a transitional dialect was spoken, that of Middle Sardinian. The Carta de Logu of the Kingdom of Arborea, one of the first constitutions in history drawn up in 1355–1376 by Marianus IV and the Queen, the "Lady Judge" ("judikessa" in Sardinian, "jutgessa" in Catalan, "giudicessa" in Italian) Eleanor, was written in this transitional variety of Sardinian, and remained in force until 1827. It is presumed the Arborean judges attempted to unify the Sardinian dialects in order to be legitimate rulers of the entire island under a single state ("republica sardisca" "Sardinian Republic");

Dante Alighieri wrote in his 1302–05 essay "De vulgari eloquentia" that Sardinians, not being Italians ("Latii") and having no "lingua vulgaris" of their own, resorted to aping Latin instead. Dante's view has been dismissed, as Sardinian had been following its own course in a way which was already unintelligible to non-islanders. In the popular 12th-century verse from Raimbaut de Vaqueiras' poem "Domna, tant vos ai preiada", Sardinian epitomizes outlandish speech along with German and Berber, having the troubadour's wife say "No t'entend plui d'un Todesco / Sardesco o Barbarì" ("I don't understand you any more than [I could] a German / Sard or Berber"); the Tuscan poet Fazio degli Uberti refers to the Sardinians in his poem "Dittamondo" as "una gente che niuno non la intende / né essi sanno quel ch'altri pispiglia" ("a people that no one is able to understand / nor do they come to a knowledge of what other peoples say"). The Muslim geographer Muhammad al-Idrisi, who lived in Palermo, Sicily at the court of King Roger II, wrote in his work " Kitab Nuzhat al-mushtāq fi'khtirāq al-āfāq " ("The book of pleasant journeys into faraway lands" or, simply, "The book of Roger") that "Sardinia is large, mountainous, poorly provided with water, two hundred and eighty miles long and one hundred and eighty long from west to east. [...] Sardinians are ethnically "Rūm Afāriqah", like the Berbers; they shun contacts with all the other "Rūm" nations and are people of purpose and valiant that never leave the arms". Indeed, Sardinian was perceived as rather similar to the Latin dialects once spoken by the Christian Berbers in North Africa, giving credit to the theory that vulgar Latin in both Africa and Sardinia displayed a significant wealth of parallelisms.

The literature of this period primarily consists of legal documents, besides the aforementioned Carta de Logu. The first document containing Sardinian elements is a 1063 donation to the abbey of Montecassino signed by Barisone I of Torres. Other documents are the "Carta Volgare" (1070–1080) in Campidanese, the 1080 Logudorese Privilege, the 1089 Donation of Torchitorio (in the Marseille archives), the 1190–1206 Marsellaise Chart (in Campidanese) and an 1173 communication between the Bishop Bernardo of Civita and Benedetto, who oversaw the Opera del Duomo in Pisa. The Statutes of Sassari (1316) and Castelgenovese (c. 1334) are written in Logudorese.

The first chronicle in "lingua sive ydiomate sardo", called "Condagues de Sardina", was published anonymously in the 13th century, relating the events of the Judicate of Torres.

The 1297 feoffment of Sardinia by Pope Boniface VIII led to the creation of the Aragonese Kingdom of Sardinia and a long period of war between the Aragonese and Sardinians, ending with a Aragonese victory at Sanluri in 1409 and the renunciation of any succession right signed by William III of Narbonne in 1420. During this period the clergy adopted Catalan as their primary language, relegating Sardinian to a secondary but nonetheless relevant status with regards to the official acts and the Realm's law (the "Carta de Logu" was extended to most of the island in 1421 by the Parliament). Agreeing with Fara's "De rebus Sardois", the Sardinian attorney Sigismondo Arquer, author of "Sardiniae brevis historia et descriptio" in Sebastian Münster's Cosmographia Universalis (whose report would also be quoted in Conrad Gessner's "On the different languages used by the various nations across the globe" with minor variations), stated that Sardinian prevailed in most of the Kingdom, with particular regard for the rural interior, and Catalan and Spanish were spoken in the cities, where the ruling class eventually became plurilingual in both the native and the Iberian languages; Alghero is still a Catalan-speaking enclave on Sardinia to this day.

The long-lasting war and the so-called Black Death had a devastating effect on the island, depopulating large parts of it. People from the neighbouring island of Corsica began to settle in the northern Sardinian coast, leading to the birth of the Tuscan-sounding Sassarese and Gallurese.

Despite Catalan being widely spoken and written on the island at this time (leaving a lasting influence in Sardinian), there are some written records of Sardinian, which was estimated to be the ordinary language of the Sardinians by the Jesuits in 1561. One is the 15th-century "Sa Vitta et sa Morte, et Passione de sanctu Gavinu, Brothu et Ianuariu", written by Antòni Canu (1400–1476) and published in 1557.

The 16th century is instead marked by a new Sardinian literary revival: "Rimas Spirituales", by Hieronimu Araolla, was aimed at "glorifying and enriching Sardinian, our language" ("magnificare et arrichire sa limba nostra sarda") as Spanish, French and Italian poets had already done for their languages ("la Deffense et illustration de la langue françoyse" and "il Dialogo delle lingue"). Antonio Lo Frasso, a poet born in Alghero (a city he remembered fondly) who spent his life in Barcelona, wrote lyric poetry in Sardinian:
 ... "Non podende sufrire su tormentu / de su fogu ardente innamorosu. / Videndemi foras de sentimentu / et sensa una hora de riposu, / pensende istare liberu e contentu / m'agato pius aflitu e congoixosu, / in essermi de te senora apartadu, / mudende ateru quelu, ateru istadu ...".

Through the marriage of Isabella I of Castile and Ferdinand II of Aragon in 1469 and, later in 1624, the reorganization of the monarchy led by the Count-Duke of Olivares, Sardinia would progressively join a broad Spanish cultural sphere and leave the exclusive Aragonese one. Spanish was perceived as an elitist language, gaining solid ground among the ruling Sardinian class; Spanish had thus a profound influence on Sardinian, especially in those words, styles and cultural models owing to the prestigious international role of the Habsburg Monarchy as well as the Court. Most Sardinian authors would write in both Spanish and Sardinian until the 19th century and were well-versed in the former, like Vicente Bacallar y Sanna that was one of the founders of the Real Academia Española. A notable exception was Pedro Delitala (1550–1590), who decided to write in Italian instead. Nonetheless, the Sardinian language retained much of its importance, earning respect from the Spaniards in light of it being the ethnic code the people from most of the Kingdom kept using, especially in the interior.

Sardinian was also one of the few official languages, along with Spanish, Catalan and Portuguese, whose knowledge was required to be an officer in the Spanish tercios.

A 1620 proclamation is in the Bosa archives.

Ioan Matheu Garipa, a priest from Orgosolo who translated the Italian "Leggendario delle Sante Vergini e Martiri di Gesù Cristo" into Sardinian ("Legendariu de Santas Virgines, et Martires de Iesu Christu") in 1627, was the first author to call Sardinian the closest living relative of classical Latin and, like Araolla before him, valued Sardinian as the language of a specific ethno-national community.

The War of the Spanish Succession gave Sardinia to Austria, whose sovereignty was confirmed by the 1713–14 treaties of Utrecht and Rastatt. In 1717 a Spanish fleet reoccupied Cagliari, and the following year Sardinia was ceded to Victor Amadeus II of Savoy in exchange for Sicily. This transfer would not initially entail any social nor linguistic changes, though: Sardinia would still retain for a long time its Iberian character, so much so that only in 1767 were the Aragonese and Spanish dynastic symbols replaced by the Savoyard cross. This stance was rooted in three political reasons: in the first place, the Savoyards felt like they did not want to rouse international suspicion and followed to the letter the rules dictated by the Treaty of London, signed on the second of August 1718, whereby they committed themselves to respect the fundamental laws of the newly acquired Kingdom; in the second, they did not want to antagonize the hispanophile locals, especially the elites; in the third, they lingered on hoping they could manage to dispose of the island while still keeping the title of Kings by regaining Sicily. Such prudence was noted, when the King himself claimed that he was intentioned to ban neither Sardinian nor Spanish on two separate occasions, in 1726 and 1728. The fact that the new masters of Sardinia felt at loss as to how they could better deal with a cultural and linguistic environment they perceived as alien to the Mainland, where Italian had long been the official language, can be deduced from the study "Memoria dei mezzi che si propongono per introdurre l'uso della lingua italiana in questo Regno" ("Account of the proposed ways to introduce the Italian language to this Kingdom") commissioned in 1726 by the Piedmontese administration, to which the Jesuit Antonio Falletti from Barolo responded suggesting the "ignotam linguam per notam expōnĕre" ("to introduce an unknown language [Italian] through a known one [Spanish]") method as the best course of action for Italianization.

However, the Savoyard government eventually decided to directly impose Italian on Sardinia on July 25, 1760, because of the Savoyards' geopolitical need to draw the island away from the Spanish influence and culturally align Sardinia with the Italian peninsula, and especially Piedmont. In 1764, the order was extended to all sectors of public life. Spanish was thus replaced as the official language (even though it continued to be used in the parish registers and official deeds until 1828) and Sardinian was again marginalized, making way for the Italianization of the island. For the first time, in fact, even the wealthy and most powerful families of rural Sardinia, the "printzipales", started to perceive Sardinian as a handicap.

At the end of the 18th century, following the trail of the French revolution, a group of the Sardinian middle class planned to break away from the mainland ruling class and institute an independent Sardinian Republic under French protection; all over the island, a number of political pamphlets printed in Sardinian were illegally distributed, calling for a mass revolt against the Piedmontese rule and the barons' abuse. The most famous literary product born out of such political unrest was the poem "Su patriottu sardu a sos feudatarios", noted as a testament of the French-inspired democratic and patriotic values, as well as Sardinia's situation under feudalism.

The first systematic study on the Sardinian language was written in 1782 by the philologist Matteo Madau, with the title of "Il ripulimento della lingua sarda lavorato sopra la sua antologia colle due matrici lingue, la greca e la latina". The patriotic intention that motivated Madau was to trace the ideal path through which Sardinian could grow to be the island's proper national language; nevertheless, the Savoyard climate of repression on Sardinian culture would induce Matteo Madau to veil its radical proposals with some literary devices, and the author was eventually unable to ever translate them into reality. The first volume of comparative Sardinian dialectology was produced in 1786 by the Catalan Jesuit Andres Febres, known in Italy and Sardinia by the pseudonym of " Bonifacio d'Olmi ", who returned from Lima where he had first published a book of Mapuche grammar in 1764. After he moved to Cagliari, he became fascinated with the Sardinian language as well and conducted some research on three specific dialects; the aim of his work, entitled "Prima grammatica de' tre dialetti sardi", was to «write down the rules of the Sardinian language» and spur the Sardinians to «cherish the language of their Homeland, as well as Italian». The government in Turin, which had been monitoring Febres' activity, decided that his work would not be allowed to be published: Victor Amadeus III had supposedly not appreciated the fact that the book had a bilingual dedication to him in Italian and Sardinian, a mistake that his successors, while still echoing back to a general concept of "Sardinian ancestral homeland", would from then on avoid, and making exclusive use of Italian to produce their works.

In the climate of monarchic restoration that followed Angioy's rebellion, other Sardinian intellectuals, all characterized by an attitude of general devotion to their island as well as proven loyalty to the House of Savoy, posed in fact the "question of the Sardinian language", while being careful enough to use only Italian as a language to get their point across. During the 19th century in particular, the Sardinian intellectuality and ruling class found itself divided over the adherence to the Sardinian national values and the allegiance to the new Italian nationality, toward which they eventually leaned in the wake of the aborted Sardinian revolution.

A few years after the major anti-Piedmontese revolt, in 1811, the priest Vincenzo Raimondo Porru published a timid essay of Sardinian grammar, which, however, referred expressively to the southern dialect (hence the title of "Saggio di grammatica del dialetto sardo meridionale") and, out of prudence towards the king, was made with the declared intention of easing the acquisition of Italian among his fellow Sardinians, instead of protecting their language. The more ambitious work of the professor and senator Giovanni Spano, the "Ortographia sarda nationale" ("Sardinian National Orthography"), although it was officially meant for the same purpose as Porru's, attempted in reality to establish a unified Sardinian orthography based on Logudorese, just like Florentine had become the basis for Italian.

In contrast to the Mainland's cultural dynamics established between Italian and the various Romance dialects, in Sardinia the relationship between the Italian language - recently introduced by Savoy - and the native one had been perceived from the start by the locals, educated and uneducated alike, as a relationship (albeit unequal in terms of political power and prestige) between two very different languages, and not between a language and one of its dialects. The plurisecular Iberian period also contributed in making the Sardinians feel relatively detached from the Italian language and its cultural sphere, and the Spanish themselves, comprising both the Aragonese and Castilian ruling class, had already considered Sardinian a distinct language with respect to their own ones and Italian as well.

The jurist claimed that the suppression of Sardinian and the imposition of Italian was desirable in order to make the islanders "civilized Italians". The primary and tertiary education was thus offered exclusively through Italian, importing teachers from the Mainland to make up for the lack of Italian-speaking Sardinians, and Piedmontese cartographers replaced many Sardinian place names with Italian ones. The Italian education, being imparted in a language the Sardinians were not familiar with, spread Italian for the first time in history to Sardinian villages, marking the troubled transition to the new dominant language; the school environment, which employed Italian as the sole means of communication, grew to become a microcosm around the then-monolingual Sardinian villages. In 1811, the canon Salvatore Carboni published in Bologna the polemic book "Sos discursos sacros in limba sarda" ("Holy Discourses in Sardinian language"), wherein the author lamented over the fact that Sardinia, ""hoe provinzia italiana non podet tenner sas lezzes e sos attos pubblicos in sa propia limba"" ("Being an Italian province nowadays, [Sardinia] cannot have laws and public acts made in its own language"), and while claiming that ""sa limba sarda, totu chi non uffiziale, durat in su Populu Sardu cantu durat sa Sardigna"" ("the Sardinian language, however unofficial, will last as long as Sardinia among the Sardinians"), he also asked himself ""Proite mai nos hamus a dispreziare cun d'unu totale abbandonu sa limba sarda, antiga et nobile cantu s'italiana, sa franzesa et s'ispagnola?"" ("Why should we show neglect and contempt for Sardinian, which is a language as ancient and noble as Italian, French and Spanish?"). Eventually, Sardinian came to be perceived as "sa limba de su famine" / "sa lingua de su famini", literally translating into English as "the language of hunger" (i.e. the language of the poor), and Sardinian parents strongly supported the teaching of the new tongue to their children, since they saw it as the portal to escaping from a poverty-stricken, rural, isolated and underprivileged life.

In 1827, the historical legal code serving as the «"consuetud de la nació sardesca"» in the days of the Iberian rule, the "Carta de Logu", was abolished and replaced by the more advanced Savoyard code of Charles Felix ""Leggi civili e criminali del Regno di Sardegna"", written in Italian. The Perfect Fusion with the Mainland States, enacted under the auspices of a «transplant, without any reserves and obstacles, [of] the culture and civilization of the Italian Mainland to Sardinia», would result in the loss of the island's residual autonomy and marked the moment when «the language of the "Sardinian nation" lost its value as an instrument with which to ethnically identify a particular people and its culture, to be codified and cherished, and became instead one of the many regional dialects subordinated to the national language». Despite the long-term assimilation policy, the anthem of the Savoyard Kingdom of Sardinia would still be "S'hymnu sardu nationale" ("the Sardinian National Anthem"), also known as "Cunservet Deus su Re" ("God save the King"), before it was "de facto" replaced by the Italian "Marcia Reale" as well, in 1861. However, even when the island became part of the Kingdom of Italy under Victor Emmanuel II in 1861, Sardinia's distinct culture from the now unified Mainland made it an overall neglected province within the newly proclaimed unitary nation state.

During the mobilization for World War I, the Italian Army compelled all Sardinians to enlist as Italian subjects and established the Sassari Infantry Brigade on 1 March 1915 at Tempio Pausania and Sinnai. Unlike the other infantry brigades of Italy, Sassari's conscripts were only Sardinians (including many officers). It is currently the only unit in Italy with an anthem in a language other than Italian: "Dimonios" ("Devils"), written in 1994 by Luciano Sechi. Its title derives from "Rote Teufel" (German for "red devils"). However, compulsory military service played a role in language shift.

Eventually, under Fascism, Sardinia was made to align with the Italian national system, by means of cultural assimilation via the combined role of the school and the party system and repression of the local cultural expressions, including Sardinia's mask festivals and improvised poetry competitions, and a large number of Sardinian surnames were changed to sound more Italian. Following an argument between the Sardinian poet Antioco Casula (also known as "Montanaru") and the fascist journalist Gino Anchisi, who stated that «once the region is moribund or dead, so will the dialect ("sic")», the latter managed to have Sardinian banned from the printing press, as well. Another famed poet from the island, Salvatore ("Bore") Poddighe, fell into a severe depression and took his own life a few years after his masterwork ("Sa Mundana Cummedia") had been seized by Cagliari's police commissioner. When the use of Sardinian in school was banned in 1934 as part of a nation-wide educational plan against the alloglot "dialects", the then Sardinian-speaking children were confronted with another means of communication that was supposed to be their own from then onwards. On a whole, this period saw the most aggressive cultural assimilation effort by the central government, which led to an even further sociolinguistic degradation of Sardinian. However, the Sardinian Anthem of the once Piedmontese Kingdom was a chance to use a regional language without penalty: as a royal tradition, it could not be forbidden.

The Sardinian-born philosopher Antonio Gramsci commented on the Sardinian linguistic question while writing a letter to his sister Teresina; Gramsci was aware of the long-term ramifications of language shift, and suggested Teresa to let her son acquire Sardinian with no restriction, because doing otherwise would result in "putting his imagination in a straitjacket" as well as him ending up eventually "learning two jargons, and no language at all".

After World War II, awareness around the Sardinian language and the danger of its slipping away did not seem to concern the Sardinian elites and entered the political spaces much later than in other European peripheries marked by the long-standing presence of ethno-linguistic minorities; Sardinian was in fact dismissed by the already Italianized middle class, as both the Sardinian language and culture were still being held responsible for the island's underdevelopment. The Sardinian ruling class, drawn to the Italian modernist stance on Sardinia's path to development, believed in fact that the latter had been held back by the islanders' "traditional practices", and that social and cultural progress could only be brought about through their rejection. Consequently, the Sardinians have been encouraged to Italianize and thus part with what they believed to be negatively marking their affiliation with a stigmatized identity.

At the time of drafting of the statute in 1948, the legislator eventually decided to specify the "Sardinian specialty" as a single criterion for political autonomy just on the grounds of a couple of socio-economic issues devoid of considerations of a distinct cultural, historical and geographical identity, which were on the contrary looked down upon as a potential prelude to more autonomist or separatist claims. Eventually, the special statute of 1948 did not recognize any special geographical conditions about the region nor made any mention of a distinct cultural and linguistic element, preferring instead to concentrate on state-funded plans (baptised with the Italian name of "piani di rinascita") for the heavy industrial development of the island, as well as the military installations. Therefore, far from being a Statute grounded on the acknowledgment of a particular cultural identity like, for example, in South Tyrol, what emerged in Sardinia was an «autonomism solely based on economic considerations, because there was not either the will or the ability to devise a strong and culturally motivated autonomy, a "Sardinian specificity" that was not defined on the terms of social backwardness and economic deprivation». In the meantime, the emphasis on Italian-only assimilation policies continued, with historical sites and ordinary objects renamed in Italian (e.g. the various kinds of cheese, "zippole" instead of "tzipulas", "carta da musica" instead of "carasau", "formaggelle" instead of "pardulas / casadinas", etc.). The Ministry of Public Education reportedly requested that the teachers willing to teach Sardinian be put under surveillance. The rejection of the indigenous language, along with a rigid model of Italian-language education, corporal punishment and shaming, has led to poor schooling for the Sardinians.

There have been campaigns, often expressed in the form of political demands from the late '60s onwards, to give Sardinian equal status with Italian as a means to promote cultural identity. One of the first demands was formulated in a resolution adopted by the University of Cagliari in 1971, calling upon the national and regional authorities to recognize the Sardinians as an ethno-linguistic minority and Sardinian as the island's co-official language. Critical acclaim in Sardinian cultural circles followed the patriotic poem "No sias isciau" ("Don't be a slave") by Raimondo ("Remundu") Piras some months before his death in 1977, urging bilingual education to reverse the ongoing trend of de-sardization. It was in the late 70s that a significant shift to Italian was first noted not only in the Campidanian plains, but even in some inner areas that had been previously considered Sardinian-speaking bastions, manifesting a parallel shift of the values upon which the ethnic and cultural identity of the Sardinians was traditionally grounded. From then onwards, the use of Sardinian would continue to recede because of the strongly negative view the Sardinian community developed toward it, assuming a self-belittling attitude which has been described as the emergence of a "minority complex" fairly typical of linguistic minorities.

Following tensions and claims of the Sardinian nationalist movement for concrete cultural and political autonomy, including the recognition of the Sardinians as an ethnic and linguistic minority, three separate bills were presented to the Regional Council in the '80s. A survey conducted by MAKNO in 1984 showed that three-fourth of the Sardinians had a positive attitude towards bilingual education (22% of the interviewees, especially in the Province of Nuoro and Oristano, wanted Sardinian to be compulsory in Sardinian schools, while 54.7% would prefer to see teaching in Sardinian as optional) and official bilingualism like in the Aosta Valley and South Tyrol (62,7% of the population were in favour, 25,9% said no and 11,4% were unsure). Such consensus remains relatively stable to this day; another survey, conducted in 2008, reported that more than half of the interviewees, 57.3%, were in favour of the introduction of Sardinian into schools alongside Italian.

In the 1990s, there had been a resurgence of Sardinian-language music, ranging from the more traditional genres ("cantu a tenore", "cantu a chiterra", "gosos" etc.) to rock ("Kenze Neke", "Askra", "Tzoku", "Tazenda" etc.) and even hip hop and rap ("Dr. Drer e CRC Posse", "Quilo", "Sa Razza", "Malam", "Su Akru", "Menhir", "Stranos Elementos", "Malos Cantores", "Randagiu Sardu", "Futta" etc.), and with artists who used the language as a means to promote the island and address its long-standing issues and the new challenges. A few films (like "Su Re", "Bellas Mariposas", "Treulababbu", "Sonetaula" etc.) have also been dubbed in Sardinian, and some others (like "Metropolis") were provided with subtitles in the language. The first scientific work in Sardinian ("Sa chistione mundiali de s'Energhia"), delving into the question of modern energy supplies, was written by Paolo Giuseppe Mura, Physics Professor at the University of Cagliari, in 1995.

One of the first laws approved by the Sardinian legislator with respect to the protection and promotion of the Sardinian language and culture was soon rejected by the Constitutional Court in 1994; it was not until 1997 that Sardinian was finally recognized by the regional law (n. 26 of 15 October 1997 "Promotion and enhancement of the culture and language of Sardinia") without there being any recourse from the Italian central government. Eventually, sustained activism made possible the formal recognition of twelve minority languages (Sardinian, Albanian, Catalan, German, Greek, Slovenian, Croatian, French, Franco-Provençal, Friulian, Ladin and Occitan) in the late 1990s by the framework law no. 482/1999, following Art. 6 of the Italian Constitution. While the first section of said law states that Italian is the official language of the Republic, a number of provisions are included in order to normalize the use of such languages and let them become part of the national fabric. However, Italy (along with France and Malta) has signed but never ratified the European Charter for Regional or Minority Languages.

Furthermore, many people in Italy outside of Sardinia continue to regard Sardinian as an "Italian dialect", likewise some national school books have not stopped to squeeze the language into the Italian acceptation of "dialetto italiano" (Italian dialect). Sardinian is yet to be taught at school, with the exception of a few experimental occasions; furthermore, its use has not ceased to be disincentivized as antiquated or even indicative of a lack of education, leading many locals to associate it with negative feelings of shame, backwardness, and provincialism. Similar issues of identity have been observed in regard to the community's attitude toward what they positively perceive to be part of "modernity", generally associated with the Italian cultural sphere, as opposed to the Sardinian one, whose aspects have long been stigmatized as "primitive" and "barbarous" by the political and social institutions that ruled the island.
A number of other factors like a considerable immigration flow from mainland Italy, the interior rural exodus to urban areas, where Sardinian is spoken by a much lower percentage of the population, and the use of Italian as a prerequisite for jobs and social advancement actually hinder any policy set up to promote the language. Therefore, following the model proposed by a UNESCO panel of experts in 2003, Sardinian is classified by UNESCO as a "definitely endangered" language ("children no longer learn the language as mother tongue in the home"), on the way to become "severely endangered" ("the language is used mostly by the grandparental generation and up")

Language use is far from stable; following the Expanded GIDS ("Expanded Graded Intergenerational Disruption Scale") model, Sardinian would position between 7 ("Shifting: the child-bearing generation knows the language well enough to use it among themselves but none are transmitting it to their children") and 8a ("Moribund: the only remaining active speakers of the language are members of the grandparent generation"). While an estimated 68 percent of the islanders had in fact a good oral command of Sardinian, language ability among the children plummeted to less than 13 percent; some linguists, like Mauro Maxia, cite the low number of Sardinian-speaking children as indicative of language decline, calling Sardinia "a case of linguistic suicide". According to the data published by ISTAT in 2006, 52.5% of the population in Sardinia speaks just Italian in the family environment, while 29.3% alternates Italian and Sardinian and only 16.6% uses Sardinian or other non-Italian languages; outside the social circle of family and friends, the numbers define Italian as the prevalent language (77,1%), while the usage of Sardinian and other languages drops to 5,2%. Today, most people who use Sardinian as part of day-to-day life reside mainly in the sparsely populated areas in the countryside, like the mountainous region of Barbagia.

A bill proposed by the cabinet of the former Italian Prime Minister Mario Monti would have further lowered the protection level of Sardinian, distinguishing between the so-called "national minorities", speaking languages protected by international agreements (German, Slovenian, French) and the "linguistic minorities" whose language is not spoken in any state other than Italy (all the other ethno-linguistic groups, including Sardinian). This bill, which was eventually implemented but later deemed unconstitutional by the Court, triggered a reaction on the island. Students expressed an interest in taking all (or part) of their exit examinations in Sardinian. In response to a 2013 Italian initiative to remove bilingual signs on the island, a group of Sardinians began a virtual campaign on Google Maps to replace Italian place names with the original Sardinian names. After about one month, Google changed the place names back to Italian.
After a signature campaign, it has been made possible to change the language setting on Facebook from any language to Sardinian. It is also possible to switch to Sardinian even in Telegram and a couple of other apps, like F-Droid, Diaspora, OsmAnd, Notepad++, Swiftkey, Stellarium, Skype, VLC media player for Android, Linux Mint Debina Edition 2 "Betsy", etc. The DuckDuckGo search engine is available in Sardinian as well. In 2016, the first automatic translation software from Italian to Sardinian was developed.
In 2015, all the political parties in the Sardinian regional council had reached an agreement involving a series of amendments to the old 1997 law in order to be able to introduce the optional teaching of the language in Sardinia's schools. The Unified Text on the Discipline of the Regional linguistic policy had been eventually approved on June 27, 2018, with the aim of setting in motion a path towards bilingual administration, contributions to bilingual mass media, publishing, IT schools and websites; it also allowed for the foundation of a Sardinian board ("Consulta de su Sardu") with thirty experts that would propose a linguistic standard based on the main historical varieties, and would also have advisory duties towards the Regional body. Although there is still not an option to teach Sardinian on the island itself, let alone in Italy, some language courses are instead sometimes available in Germany (Universities of Stuttgart, Munich, Tübingen, Mannheim etc.), Spain (University of Girona), Iceland and Czech Republic (Brno university). Shigeaki Sugeta also taught Sardinian to his students of Romance languages at the Waseda University in Tokyo, Japan.

At present, the Sardinian-speaking community is the least protected one in Italy, despite being the largest minority language group officially recognized by the state. In fact the language, which is receding in all domains of use, is still not given access to any field of public life, such as education (Italian–Sardinian bilingualism is still frowned upon, while the local universities do not play pretty much any role whatsoever in supporting the language), politics (with the exception of some nationalist groups), justice, administrative authorities and public services, media, and cultural, ecclesiastical, economic and social activities, as well as facilities. According to a 2017 report on the digital language diversity in Europe, Sardinian appears to be particularly vital on social media as part of many people's everyday life for private use, but such vitality does not still translate into a strong and wide availability of Internet media for the language. In 2017, a 60-hour Sardinian language course was introduced for the first time in Sardinia and Italy at the University of Cagliari, although such a course had been already available in other universities abroad.

In 2015, the Council of Europe commented on the status of national minorities in Italy, noting the "à la carte" approach of the Italian state towards them with the exception of the German, French and Slovenian languages, where Italy has applied full bilingualism due to international agreements. Despite the formal recognition from the Italian state, Italy does not in fact collect any information on the ethnic and linguistic composition of the population, apart from South Tyrol. There is also virtually no print and broadcasting media exposure in politically or numerically weaker minorites like Sardinian. Moreover, the resources allocated to cultural projects like bilingual education, which lacks a consistent approach and offers no guarantee of continuity throughout the years, are largely insufficient to meet "even the most basic expectations".

A solution to the Sardinian question being unlikely to be found anytime soon, the language has become highly endangered: even though the endogamy rate among group members seems to be very high, the late recognition as a minority language, as well as the gradual but pervasive Italianization promoted by the education system, the administration system and the media, followed by the intergenerational language replacement, made it so that the vitality of Sardinian has been heavily compromised. The Euromosaic project, which has conducted a research study on the current situation of the ethno-linguitic minorities across Europe under the auspices of the European Commission, concludes their report on Sardinian as follows:
With cultural assimilation having already occurred, most of the younger generation of islanders, although they do understand some basic Sardinian, is now in fact Italian monolingual and monocultural, being able to speak not Sardinian anymore, but a Sardinian-influenced variety of Italian which is often nicknamed "italiànu porcheddìnu" (literally "swinish Italian") by native Sardinian speakers.

Whatever the fate of the Sardinian language might be, it shall therefore constitute the substratum of the one prevailing now, Italian, in a number of linguistic components specific to the island.

All dialects of Sardinian have phonetic features that are relatively archaic compared to other Romance languages. The degree of archaism varies, with the dialect spoken in the Province of Nuoro being considered the most conservative. Medieval evidence indicates that the language spoken in Sardinia and Corsica at the time was similar to modern Nuorese Sardinian; while Corsica underwent a process of Tuscanization that rendered the Corsican dialects akin to Tuscan, the Sardinian dialects are thought to have slowly evolved through some Catalan, Spanish and later Italian influences.

The examples listed below are from the Logudorese dialect:

Sardinian contains the following phonetic innovations:

Although the latter two features are partly similar to Spanish and Portuguese, the others indicate a deeper relationship between ancient Sardinia and the Iberian world; the retroflex "d", "l" and "r" are found in southern Italy, Tuscany and Asturias, and were probably involved in the palatalization process of the Latin clusters "-ll-", "-pl-", "-cl-" ("-ll-"- > Spanish and Catalan -"ll"- , Gascon "-th-" ; "-cl-" > Galician-Portuguese "-ch-" , Italian "-chi-" ), which as seen above had a different development in Sardinian.

Vowels are , , , and , without length differentiation. Metaphony occurs with and , which in particular tend to be open-mid and when they are stressed and the following syllable does not contain or or a palatal.

Some varieties of Sardinian have vowel phonemes separate from /e/ and /o/.

There are also nasal vowels , , , , in some varieties, and even nasal diphthongs when an intervocalic "n" is deleted like in .

Sardinian has the following consonants:

There are three series of plosives or corresponding approximants:

In Cagliari and neighboring dialects, the soft has become due to rhotacism: > / "finger".

The double-voiced retroflex stop (usually written "-dd-") derives from the former retroflex lateral approximant .





Some permutations of "l" and "r" are seen: in most dialects a preconsonantal "l" (for example, "-lt-" or "-lc-") becomes "r": Latin > "high/tall", / "rock".

In palatal context, Latin "l" changed into , , , or , rather than the of Italian: (Italian ), > // "wish, longing" (Italian ), > // "leaf" (Italian ), > // "daughter" (Italian ).

Rhotics


Some distinctive features typical of Sardinian are:

Historically, the Sardinians have always been quite a small population scattered across isolated cantons, sharing similar demographic patterns with Corsica; as a result, Sardinian developed a broad spectrum of dialects over the time. Starting from Francesco Cetti's description in the 18th century, Sardinian has been presented as a pluricentric language, being traditionally subdivided into two varieties spoken by roughly half of the entire community: the dialects spoken in North-Central Sardinia, centered on the orthography known as Logudorese ("su sardu logudoresu"), and the dialects spoken in Central Southern Sardinia, centered on another orthography called Campidanese ("su sardu campidanesu"). All the Sardinian dialects differ primarily in phonetics, which does not hamper intelligibility; the view of there being a dialectal boundary separating the Campidanese and Logudorese varieties has been in fact subjected to more recent research, that shows a fluid linguistic continuum from the Northern to the Southern ends of the island. The dualist perception of the Sardinian dialects, rather than pointing to an actual isogloss, is in fact the result of a psychological adherence to the way Sardinia was administratively subvidided into a "Caput Logudori" ("Cabu de Susu") and a "Caput Calaris" ("Cabu de Jossu") by the Spanish.

On the other hand, the Logudorese and Campidanese dialects have been estimated in another research to have 88% of matches in 110-item wordlist, similarly to the 85-88% number of matches between Provençal Occitan and the Catalan dialects, which by some standards is usually (even though arbitrarily) considered characteristic for two different, albeit very closely related, languages. ISO 639 counts four Sardinian languages (Campidanese, Gallurese, Logudorese and Sassarese), each with its own language code.

The dialects centered on the Logudorese model are generally considered more conservative, with the Nuorese subdialect ("su sardu nugoresu") being the most conservative of all. They have all retained the classical Latin pronunciation of the stop velars ("kena" versus "cena", "supper"), the front middle vowels (compare Campidanese iotacism, probably from Byzantine Greek) and assimilation of close-mid vowels ("cane" versus "cani", "dog" and "gattos" versus "gattus", "cats"). Labio-velars become plain labials ("limba" versus "lingua", "language" and "abba" versus "acua", "water"). "I" is prosthesized before consonant clusters beginning in "s" ("iscala" versus Campidanese "scala", "stairway" and "iscola" versus "scola", "school"). An east-west strip of villages in central Sardinia speaks a transitional group of dialects ("su sardu de mesania"). Examples include "is limbas" (the languages) and "is abbas" (the waters). The dialects centered on the Campidanese model, spreading from Cagliari (once the metropolis of the Roman province), show relatively more influences from Carthage, Rome, Constantinople and Late Latin. Examples include "is fruminis" (the rivers) and "is domus" (the houses).
Sardinian is the indigenous and historical language of most Sardinian communities. However, Sardinian is not spoken as the native and primary language in a significant number of other ones, amounting to 20% of the Sardinian population. The afore-mentioned Gallurese and Sassarese, despite being often colloquially considered part of Sardinian, are two Corso-Sardinian transitional languages; they are spoken in the northernmost part of Sardinia, although some Sardinian is also understood by the majority of people living there (73,6% in Gallura and 67,8% in the Sassarese-speaking subregion). Sassari, the second-largest city on Sardinia and the main center of the northern half of the island ("cabu de susu" in Sardinian, "capo di sopra" in Italian), is located there. There are also two language islands, the Catalan Algherese-speaking community from the inner city of Alghero (northwest Sardinia) and the Ligurian-speaking towns of Carloforte, in San Pietro Island, and Calasetta in Sant'Antioco island (south-west Sardinia).

Sardinian has already been a standardized language since the Middle Ages, even if the process led to the emergence of the above-mentioned models of Logudorese and Campidanese. However, some attempts have been made to introduce a single writing system for administrative purposes over the recent decades, but they have not been generally acknowledged by native speakers.

The Regional Council Deliberations no. 52/105 of 28 December 1999 and n. 59/117 of 29 December 1998 appointed the Committee members with the goal of investigating a single orthographic form and devise a project of linguistic unification. The people appointed for the task were Eduardo Blasco Ferrer, Roberto Bolognesi, Diego Salvatore Corraine, Ignazio Delogu, Antonietta Dettori, Giulio Paulis, Massimo Pittau, Tonino Rubattu, Leonardo Sole, Heinz Jürgen Wolf, and Matteo Porru acting as the Committee's secretary. The output of the Committee was the "Limba Sarda Unificada" (LSU, "Unified Sardinian Language"). Its rules were published in 2001 by the Autonomous Region of Sardinia, but were met with some criticism about their overall focus on the more conservative varieties, and was eventually not adopted by the regional Council.

The Regional Council Deliberation no. 20/15 of 9 May 2005 thus appointed a new Committee composed of Giulio Angioni, Roberto Bolognesi, Manlio Brigaglia, Michel Contini, Diego Corraine, Giovanni Lupinu, Anna Oppo, Giulio Paulis, Maria Teresa Pinna Catte and Mario Puddu. Their job involved a program of measures for the protection and promotion of the Sardinian language, by means of a guide to be used by the regional administration. The Committee's output, called "Limba Sarda Comuna" (LSC, "Common Sardinian Language"), was experimentally adopted by the Sardinian regional authority with the Regional Council Deliberation no. 16/14 of 18 April 2006. The resolution does not aim to impose the guide and further notes that it is "open to integrations" and that "all solutions are of equal linguistic value". This work does not refer to morphology and syntax, which is already fairly homogeneous, and concerns itself primarily with spelling.




</doc>
<doc id="27035" url="https://en.wikipedia.org/wiki?curid=27035" title="Shot reverse shot">
Shot reverse shot

Shot reverse shot (or shot/countershot) is a film technique where one character is shown looking at another character (often off-screen), and then the other character is shown looking back at the first character. Since the characters are shown facing in opposite directions, the viewer assumes that they are looking at each other.

Shot reverse shot is a feature of the "classical" Hollywood style of continuity editing, which deemphasizes transitions between shots such that the spectator perceives one continuous action that develops linearly, chronologically, and logically. It is an example of an eyeline match.


</doc>
<doc id="27036" url="https://en.wikipedia.org/wiki?curid=27036" title="Stop motion">
Stop motion

Stop motion is an animated filmmaking technique in which objects are physically manipulated in small increments between individually photographed frames so that they will appear to exhibit independent motion or change when the series of frames is played back. Any kind of object can thus be animated, but puppets with movable joints (puppet animation) or plasticine figures (clay animation or claymation) are most commonly used. Puppets, models or clay figures built around an armature are used in model animation. Stop motion with live actors is often referred to as pixilation. Stop motion of flat materials such as paper, fabrics or photographs is usually called cutout animation.

The term "stop motion," relating to the animation technique, is often spelled with a hyphen as "stop-motion." Both orthographical variants, with and without the hyphen, are correct, but the hyphenated one has a second meaning that is unrelated to animation or cinema: "a device for automatically stopping a machine or engine when something has gone wrong" ("The New Shorter Oxford English Dictionary", 1993 edition).

Stop motion should not be confused with the time-lapse technique in which still photographs of a live scene are taken at regular intervals and then combined to make a continuous film in which time appears to be moving faster.

Before the advent of chronophotography in 1878, a scarce amount of picture sequences were photographed with subjects in separate poses. These can now be regarded as a form of stop motion or pixilation, but very few results were meant to be animated.

In 1849, Joseph Plateau published a note about improvements for his Fantascope (a.k.a. phénakisticope). A new translucent variation had improved picture quality and could be viewed with both eyes, by several people at the same time. Plateau stated that the illusion could be advanced even further with an idea communicated to him by Charles Wheatstone: a combination of the fantascope and Wheatstone's stereoscope. Plateau thought the construction of a sequential set of stereoscopic image pairs would be the more difficult part of the plan than adapting two copies of his improved fantascope to fit be fitted with a stereoscope. Wheatstone had suggested using photographs on paper of a solid object, for instance a statuette. Plateau concluded that for this purpose 16 plaster models could be made with 16 regular modifications. He believed such a project would take much time and careful effort, but would be well worth it because of the expected marvelous results. Unfortunately, the plan was never executed, possibly because Plateau was almost completely blind by this time.

In 1852 Jules Duboscq patented a "Stéréoscope-fantascope ou Bïoscope" (or abbreviated as stéréofantascope) stroboscopic disc. The only known extant disc contains stereoscopic photograph pairs of different phases of the motion of a machine. Due to the long exposure times necessary to capture an image with the photographic emulsions of the period, the sequence could not be recorded live and must have been assembled from separate photographs of the various positions of the machinery.

In 1855, Johann Nepomuk Czermak's published an article about his Stereophoroskop and other experiments aimed at stereoscopic moving images. He mentioned a method of sticking needles in a stroboscopic disc so that it looked like one needle was being pushed in and out of the cardboard when animated. He realized that this method provided basically endless possibilities to make different 3D animations. He then introduced two methods to animate stereoscopic pairs of images, one was basically a stereo viewer using two stroboscopic discs and the other was more or less similar to the later zoetrope. Czermak explained how suitable stereoscopic photographs could be made by recording a series of models, for instance to animate a growing pyramid.

On 27 February 1860 Peter Hubert Desvignes received British patent no. 537 for 28 monocular and stereoscopic variations of cylindrical stroboscopic devices (much like the later zoetrope). Desvignes' "Mimoscope", received an Honourable Mention "for ingenuity of construction" at the 1862 International Exhibition in London. Desvignes "employed models, insects and other objects, instead of pictures, with perfect success."

In 1874 Jules Janssen made several practice discs for the recording of the passage of Venus with his photographic rifle. He used a model of the planet and a light source standing in for the sun. While actual recordings of the passage of Venus have not been located, some practice discs survived and the images of one were turned into a short animated film decades after the development of cinematography.

In 1887, Étienne-Jules Marey created a large zoetrope with a series of plaster models based on his chronophotographs of birds in flight.

It is estimated that 80 to 90 percent of all silent films are lost. Extant contemporary movie catalogs, reviews and other documentation can provide some details on lost films, but this kind of written documentation is also incomplete and often insufficient to properly date all extant films or even identify them if original titles are missing. Possible stop motion in lost films is even harder to trace. The principles of animation and other special effects were mostly kept a secret, not only to prevent use of such techniques by competitors, but also to keep audiences interested in the mystery of the magic tricks.

Stop motion is closely related to the stop trick, in which the camera is temporarily stopped during the recording of a scene to create a change before filming is continued (or for which the cause of the change is edited out of the film). In the resulting film the change will be sudden and a logical cause of the change will be mysteriously absent or replaced with a fake cause that is suggested in the scene. The oldest known example is used for the beheading in Edison Manufacturing Company's 1895 film "The Execution of Mary Stuart". The technique of stop motion can be interpreted as repeatedly applying the stop trick. In 1917 clay animation pioneer Helena Smith-Dayton referred to the principle behind her work as "stop action", a synonym of "stop motion".

French trick film pioneer Georges Méliès claimed to have invented the stop-trick and popularized it by using it in many of his short films. He reportedly used stop-motion animation in 1899 to produce moving letterforms.

French filmmaker Segundo de Chomón (1871–1929) made many trick films in France for Pathé. He has often been compared to Georges Méliès as he also made many fantasy films with stop tricks and other illusions (helped by his wife, Julienne Mathieu). By 1906 Chomón was using stop motion animation. "Le théâtre de Bob" (April 1906) features over three minutes of stop motion animation with dolls and objects to represent a fictional automated theatre owned by Bob, played by a live-action child actor. It is the oldest extant film with proper stop motion and a definite release date.
Segundo de Chomón's "Sculpteur moderne" was released on 31 January 1908 and features heaps of clay molding itself into detailed sculptures that are capable of minor movements. The final sculpture depicts an old woman and walks around before it's picked up, squashed and molded back into a sitting old lady.

American film pioneer Edwin S. Porter filmed a single-shot "lightning sculpting" film with a baker molding faces from a patch of dough in "Fun in a Bakery Shop" (1902), considered as foreshadowing of clay animation.

In 1905, Porter showed animated letters and very simple cutout animation of two hands in the intertitles in "How Jones lost his roll".

Porter experimented with a small bit of crude stop-motion animation in his trick film "Dream of a Rarebit Fiend" (1906).

"The "Teddy" Bears" (2 March 1907), made in collaboration with Wallace McCutcheon Sr., mainly shows people in bear costumes, but the short film also features a short stop-motion segment with small teddy bears.

On 15 February 1908, Porter released the trick film "A Sculptor's Welsh Rabbit Dream" that featured clay molding itself into three complete busts. No copy of the film has yet been located. It was soon followed by the similar extant film "The Sculptor's Nightmare" (6 May 1908) by Wallace McCutcheon Sr.

J. Stuart Blackton's "The Haunted Hotel" (23 February 1907) featured a combination of live-action with practical special effects and stop motion animation of several objects, a puppet and a model of the haunted hotel. It was the first stop motion film to receive wide scale appreciation. Especially a large close-up view of a table being set by itself baffled viewers; there were no visible wires or other noticeable well-known tricks. This inspired other filmmakers, including French animator Émile Cohl and Segundo de Chomón. De Chomón would release the similar "The House of Ghosts" and "El hotel eléctrico" in 1908, with the latter also containing some very early pixilation.

"The Humpty Dumpty Circus" (1908, considered lost) by Blackton and his British-American Vitagraph partner Albert E. Smith showed an animated performance of the figures from a popular wooden toy set. Smith would later claim that this was "the first stop-motion picture in America". The inspiration would have come from seeing how puffs of smoke behaved in the interrupted recordings for a stop trick film they were making. Smith would have suggested to get a patent for the technique, but Blackton thought it wasn't that important. Smith's recollections are not considered to be very reliable.

Blackton's "The Haunted Hotel" made a big impression in Paris, where it was released as "L'hôtel hanté: fantasmagorie épouvantable". When Gaumont bought a copy to further distribute the film, it was carefully studied by some of their filmmakers to find out how it was made. Reportedly it was newcomer Émile Cohl who unraveled the mystery. Not long after, Cohl released his first film "Japon de fantaisie" (June 1907), featuring his own imaginative use of the stop-motion technique. 
It was followed by the revolutionary hand-drawn "Fantasmagorie" (17 August 1908) and many more animated films by Cohl.

Other notable stop-motion films by Cohl include "Les allumettes animées (Animated Matches)" (1908), and "Mobilier fidèle" (1910, in collaboration with Romeo Bosetti). "Mobilier fidèle" is often confused with Bosetti's object animation tour de force "Le garde-meubles automatique (The Automatic Moving Company)" (1912). Both films feature furniture moving by itself.

Of the more than 300 short films produced between 1896 and 1915 by British film pioneer Arthur Melbourne-Cooper, an estimated 36 contained forms of animation. Based on later reports by Melbourne-Cooper and by his daughter Audrey Wadowska, some believe that Cooper's "Matches: an Appeal" was produced in 1899 and therefore the very first stop-motion animation. The extant black-and-white film shows a matchstick figure writing an appeal to donate a Guinea for which Bryant and May would supply soldiers with sufficient matches. No archival records are known that could proof that the film was indeed created in 1899 during the beginning of the Second Boer War. Others place it at 1914, during the beginning of World War I. Cooper created more "Animated Matches" scenes in the same setting. These are believed to also have been produced in 1899, while a release date of 1908 has also been given. The 1908 "Animated Matches" film by Émile Cohl may have caused more confusion about the release dates of Cooper's matchstick animations. It also raises the question whether Cohl may have been inspired by Melbourne-Cooper or vice versa.

Melbourne-Cooper's lost films "Dolly's Toys" (1901) and "The Enchanted Toymaker" (1904) may have included stop-motion animation. "Dreams of Toyland" (1908) features a scene with many animated toys that lasts circa three and a half minutes.

As a means to plan his performances, ballet dancer and choreographer Alexander Shiryaev started making circa 20 to 25 centimeter tall puppets out of papier-mâché on poseable wire frames. He then sketched all the sequential movements on paper. When he arranged these vertically on a long strip, it was possible to give a presentation of the complete dance with a home cinema projector. Later on, he bought a movie camera and between 1906 and 1909 he made many short films, including puppet animations. As a dancer and choreographer, Shiryaev had a special talent to create motion in his animated films. According to animator Peter Lord his work was decades ahead of its time. Part of Shiryaev's animation work is featured in Viktor Bocharov's documentary "Alexander Shiryaev: A Belated Premiere" (2003).

Polish-Russian Władysław Starewicz (1882–1965), started his film career around 1909 in Kaunas filming live insects. He wanted to document rutting stag beetles, but the creatures wouldn't cooperate or would even die under the bright lamps needed for filming. He solved the problem by using wire for the limbs of dried beetles and then animating them in stop motion. The resulting short film, presumably 1 minute long, was probably titled by the Latin name for the species: "Жук-олень (Lucanus Cervus)" (1910, considered lost). 

After moving to Moscow, Starewicz continued animating dead insects, but now as characters in imaginative stories with much dramatic complexity. He garnered much attention and international acclaim with these short films, including the 10-minute "Прекрасная Люканида, или Война усачей с рогачами (The Beautiful Leukanida)" (03-1912), the two-minute "Веселые сценки из жизни животных (Happy Scenes from Animal Life)", the 12-minute "Прекрасная Люканида, или Война усачей с рогачами (The Cameraman's Revenge)" (10-1912) and the 5-minute "Стрекоза и муравей (The Grasshopper and the Ant )" (1913). Reportedly many viewers were impressed with how much could be achieved with trained insects, or at least wondered what tricks could have been used, since few people were familiar with the secrets of stop motion animation. "Рождество обитателей леса (The Insects' Christmas)" (1913) featured other animated puppets, including Father Christmas and a frog. Starewicz made several other stop motion films in the next two years, but mainly went on to direct live-action short and feature films before he fled from Russia in 1918.

Willis O' Brien's first stop motion film was "" (1915). Apart from the titular dinosaur and "missing link" ape, it featured several cavemen and an ostrich-like "desert quail", all relatively lifelike models made with clay. This led to a series of short animated comedies with a prehistoric theme for Edison Company, including "Prehistoric Poultry" (1916), "R.F.D. 10,000 B.C." (1917), "The Birth of a Flivver" (1917) and "Curious Pets of Our Ancestors" (1917). O'Brien was then hired by producer Herbert M. Dawley to direct, create effects, co-write and co-star with him for "The Ghost of Slumber Mountain" (1918). The collaborative film combined live-action with animated dinosaur models in a 45-minute film, but after the premiere it was cut down to circa 12 minutes. Dawley did not give O'Brien credits for the visual effects, and instead claimed the animation process as his own invention and even applied for patents. O'Brien's stop motion work was recognized as a technique to create lifelike creatures for adventure films. O' Brien further pioneered the technique with animated dinosaur sequences for the live-action feature "The Lost World" (1925).

New York artist Helena Smith Dayton, possibly the first female animator, had much success with her "Caricatypes" clay statuettes before she began experimenting with clay animation. Some of her first resulting short films were screened on 25 March 1917. She released an adaptation of William Shakespeare's "Romeo and Juliet" circa half a year later. Although the films and her technique received much attention of the press, it seems she did not continue making films after she returned to New York from managing a YMCA in Paris around 1918. None of her films have yet surfaced, but the extant magazine articles have provided several stills and circa 20 poorly printed frames from two film strips.

By 1920 Starewicz had settled in Paris, and started making new stop motion films. "Dans les Griffes de L'araignée" (finished 1920, released 1924) featured detailed hand-made insect puppets that could convey facial expressions with moving lips and eyelids.

One of the earliest clay animation films was "Modelling Extraordinary", which impressed audiences in 1912.

The early Italian feature film "Cabiria" (1914) featured some stop motion techniques.

Starewicz finished the first feature stop motion film "Le Roman de Renard (The Tale of the Fox)" in 1930, but problems with its soundtrack delayed its release. In 1937 it was released with a German soundtrack and in 1941 with its French soundtrack.

Hungarian-American filmmaker George Pal developed his own stop motion technique of replacing wooden dolls (or parts of them) with similar figures displaying changed poses and/or expressions. He called it Pal-Doll and used it for his Puppetoons films since 1932. The particular replacement animation method itself also became better known as puppetoon. In Europe he mainly worked on promotional films for companies such as Philips. Later Pal gained much success in Hollywood with a string of Academy Award for Best Animated Short Films, including "Rhythm in the Ranks" (1941), "Tulips Shall Grow" (1942), "Jasper and the Haunted House" (1942), the Dr. Seuss penned "The 500 Hats of Bartholomew Cubbins" (1943) and "And to Think That I Saw It on Mulberry Street" (1944), "Jasper and the Beanstalk" (1945), "John Henry and the Inky-Poo" (1946), "Jasper in a Jam" (1946), and "Tubby the Tuba" (1947). Many of his puppetoon films were selected for preservation in the United States National Film Registry.

Willis O' Brien's expressive and emotionally convincing animation of the big ape in "King Kong" (1933) is widely regarded as a milestone in stop-motion animation and a highlight of Hollywood cinema in general.

A 1940 promotional film for Autolite, an automotive parts supplier, featured stop-motion animation of its products marching past Autolite factories to the tune of Franz Schubert's "Military March". An abbreviated version of this sequence was later used in television ads for Autolite, especially those on the 1950s CBS program "Suspense", which Autolite sponsored.

The first British animated feature was the stop motion instruction film "Handling Ships" (1945) by Halas and Batchelor for the British Admiralty. It was not meant for general cinemas, but did become part of the official selection of the 1946 Cannes Film Festival.

The first Belgian animated feature was an adaptation of the Tintin comic "The Crab with the Golden Claws" (1947) with animated puppets.

The first Czech animated feature was the package film "The Czech Year" (1947) with animated puppets by Jiří Trnka. The film won several awards at the Venice Film Festival and other international fetivals. Trnka would make several more stop motion features and short films, and experimented with other forms of animation.

 Ray Harryhausen learned under O'Brien on the film "Mighty Joe Young" (1949). Harryhausen would go on to create many memorable stop motion effects for a string of successful fantasy films over the next three decades. These included "The Beast from 20,000 Fathoms" (1953), "It Came from Beneath the Sea" (1955), "Jason and the Argonauts" (1963), "The Golden Voyage of Sinbad" (1973) and "Clash of the Titans" (1981).

It wasn't until 1954 before a feature animated film with a technique other than cel animation was produced in the US. The first was the stop motion adaptation of 19th century composer Engelbert Humperdinck's opera "Hänsel und Gretel" as "".

Art Clokey started his adventures in clay with a freeform clay short film called "Gumbasia" (1955), which shortly thereafter propelled him into the production of his more structured TV series "Gumby" (1955–1989), with the iconic titular character. In partnership with the United Lutheran Church in America, he also produced "Davey and Goliath" (1960–2004). The theatrical feature "" (1992, released in 1995) was a box office bomb.

On 22 November 1959, the first episode of "Unser Sandmänchen (Our Little Sandman)" was broadcast on DFF (East German television). The 10-minute daily bedtime show for young children features the title character as an animated puppet, and other puppets in different segments. A very similar "Sandmänchen" series, possibly conceived earlier, ran on West German television from 1 December 1959 until the German reunification in 1989. The East German show was continued on other German networks when DFF ended in 1991, and is one of the longest running animated series in the world. The theatrical feature "Das Sandmännchen – Abenteuer im Traumland" (2010) was fully animated with stop motion puppets.

Japanese puppet animator Tadahito Mochinaga started out as assistant animator in short anime (propaganda) films "Arichan" (1941) and "Momotarō no Umiwashi" (1943). He fled to Manchukuo during the war and stayed in China afterwards. Due to the scarcity of paint and film stock shortly after the war, Mochinaga decided to work with puppets and stop motion. His work helped popularize puppet animation in China, before he returned to Japan around 1953 where he continued working as animation director. In the 1960s, Mochinaga supervised the "Animagic" puppet animation for productions by Arthur Rankin, Jr. and Jules Bass' Videocraft International, Ltd. (later called Rankin/Bass Productions, Inc.) and Dentsu, starting with the syndicated television series "The New Adventures of Pinocchio" (1960-1961). The Christmas TV special "Rudolph the Red-Nosed Reindeer" has been telecasted annually since 1964 and has become one of the most beloved holiday films in the USA. They made three theatrical feature films "Willy McBean and His Magic Machine" (1965), "The Daydreamer" (1966, stop motion / live-action) and "Mad Monster Party?" (1966, released in 1967), and the television special "Ballad of Smokey the Bear" (1966) before the collaboration ended. Rankin/Bass worked with other animators for more TV specials, with titles such as "The Little Drummer Boy" (1968), "Santa Claus is Comin' to Town" (1970) and "Here Comes Peter Cottontail" (1971).

British television has shown many stop motion series for young children since the 1960s. An early example is "Snip and Snap" (1960-1961) by John Halas in collaboration with Danish paper sculptor Thok Søndergaard (Thoki Yenn), featuring dog Snap, cut from a sheet of paper by pair of scissors Snip.

Apart from their cutout animation series, British studio Smallfilms (Peter Firmin and Oliver Postgate) produced several stop motion series with puppets, beginning with "Pingwings" (1961-1965) featuring penguin-like birds knitted by Peter's wife Joan and filmed on their farm (where most of their productions were filmed in an unused barn). It was followed by "Pogles' Wood" (1965-1967), "Clangers" (1969-1972, 1974, revived in 2015), "Bagpuss" (1974) and "" (1984).

Czech surrealist filmmaker Jan Švankmajer's released his short artistic films since 1964, which usually contain much experimental stop motion. He started to gain much international recognition in the 1980s. Since 1988 he has mostly been directing feature films which feature much more live action than stop motion. These include "Alice", an adaptation of Lewis Carroll's "Alice's Adventures in Wonderland", and "Faust", a rendition of the legend of the German scholar. Švankmajer's work has been highly influential on other artists, such as Terry Gilliam and the Quay brothers (although the latter claim to have only discovered Švankmajer's films after having developed their own similar style).

French animator Serge Danot created "The Magic Roundabout" (1965) which played for many years on the BBC.

Polish studio Se-ma-for produced popular TV series with animated puppets in adaptations of "Colargol" ("Barnaby the Bear" in the UK, "Jeremy" in Canada) (1967-1974) and "The Moomins" (1977-1982).

In the 1960s and 1970s, independent clay animator Eliot Noyes Jr. refined the technique of "free-form" clay animation with his Oscar-nominated 1965 film "Clay (or the Origin of Species)". Noyes also used stop motion to animate sand lying on glass for his musical animated film "Sandman" (1975).

Italian director Francesco Misseri created the clay animation TV series "Mio Mao" (1970-1976, 2002-2007), "Il Rosso e il Blu (The Red and the Blue)" (1976), and a TV series with an animated origami duck "Quaq Quao" (1978-1979).

The British artists Brian Cosgrove and Mark Hall (Cosgrove Hall Films) produced two stop-motion animated adaptions of Enid Blyton's "Noddy" book series, including the original series of the same name (1975–1982) and "Noddy's Toyland Adventures" (1992–2001), a full-length film "The Wind in the Willows" (1983) and later a multi-season TV series, both based on Kenneth Grahame's classic children's book of the same title. They also produced a documentary of their production techniques, "Making Frog and Toad".

In 1975, filmmaker and clay animation experimenter Will Vinton joined with sculptor Bob Gardiner to create an experimental film called "Closed Mondays" which became the first stop-motion film to win an Oscar. Will Vinton followed with several other successful short film experiments including "The Great Cognito", "Creation", and "Rip Van Winkle" which were each nominated for Academy Awards. In 1977, Vinton made a documentary about this process and his style of animation which he dubbed "claymation"; he titled the documentary "Claymation". Soon after this documentary, the term was trademarked by Vinton to differentiate his team's work from others who had been, or were beginning to do, "clay animation". While the word has stuck and is often used to describe clay animation and stop motion, it remains a trademark owned currently by Laika Entertainment, Inc. Twenty clay-animation episodes featuring the clown Mr. Bill were a feature of "Saturday Night Live", starting from a first appearance in February 1976.

At very much the same time in the UK, Peter Lord and David Sproxton formed Aardman Animations that would produce many commercials, TV series, short films and eventually also feature films. In 1976 they created the character Morph who appeared as an animated side-kick to the TV presenter Tony Hart on his BBC TV programme Take Hart. The five-inch-high presenter was made from a traditional British modelling clay called Plasticine. In 1977 they started on a series of animated films, again using modelling clay, but this time made for a more adult audience. The soundtrack for Down and Out was recorded in a Salvation Army Hostel and Plasticine puppets were animated to dramatise the dialogue. A second film, also for the BBC followed in 1978. A TV series The Amazing Adventures of Morph was aired in 1980. They also produced a notable music video for "Sledgehammer", a song by Peter Gabriel.

Sand-coated puppet animation was used in the Oscar-winning 1977 film "The Sand Castle", produced by Dutch-Canadian animator Co Hoedeman. Hoedeman was one of dozens of animators sheltered by the National Film Board of Canada, a Canadian government film arts agency that had supported animators for decades. A pioneer of refined multiple stop-motion films under the NFB banner was Norman McLaren, who brought in many other animators to create their own creatively controlled films. Notable among these are the pinscreen animation films of Jacques Drouin, made with the original pinscreen donated by Alexandre Alexeieff and Claire Parker.

Czechoslovak filmmakers Lubomír Beneš and Vladimír Jiránek debuted their animated puppet characters "Pat & Mat", two inventive but clumsy neighbors, in the 7-minute short "Kutaci" in 1976. Since 1979, over 100 episodes have been broadcast irregularly. Since 2014, new episodes were presented in theatrically released package films. The series became very popular in several countries, especially in The Netherlands, the only country where the characters are voiced.

One of the main British animation teams, John Hardwick and Bob Bura, were the main animators in many early British TV shows, and are famous for their work on the "Trumptonshire" trilogy.

Disney experimented with several stop-motion techniques by hiring independent animator-director Mike Jittlov to make the first stop-motion animation of Mickey Mouse toys ever produced, in a short sequence called "Mouse Mania", part of a TV special, "Mickey's 50", which commemorated Mickey's 50th anniversary in 1978. Jittlov again produced some impressive multi-technique stop-motion animation a year later for a 1979 Disney special promoting their release of the feature film "The Black Hole". Titled "Major Effects", Jittlov's work stood out as the best part of the special. Jittlov released his footage the following year to 16mm film collectors as a short film titled "The Wizard of Speed and Time", along with four of his other short multi-technique animated films, most of which eventually evolved into his own feature-length film of the same title. Effectively demonstrating almost all animation techniques, as well as how he produced them, the film was released to theaters in 1987 and to video in 1989.

In the 1970s and 1980s, Industrial Light & Magic often used stop-motion model animation in such films as the original "Star Wars" trilogy: the chess sequence in "Star Wars", the Tauntauns and AT-AT walkers in "The Empire Strikes Back", and the AT-ST walkers in "Return of the Jedi" were all filmed using stop-motion animation, with the latter two films utilising go motion: an invention from renowned visual effects veteran Phil Tippett. The many shots including the ghosts in "Raiders of the Lost Ark" and the first two feature films in the "RoboCop" series use Tippett's go motion.

In the UK, Aardman Animations continued to grow. Channel 4 funded a new series of clay animated films, "Conversation Pieces", using recorded soundtracks of real people talking. A further series in 1986, called "Lip Sync", premiered the work of Richard Goleszowski ("Ident"), Barry Purves ("Next"), and Nick Park ("Creature Comforts"), as well as further films by Sproxton and Lord. "Creature Comforts" won the Oscar for Best Animated Short in 1990.

In 1980, Marc Paul Chinoy directed the 1st feature-length clay animated film, based on the famous "Pogo" comic strip. Titled "I go Pogo". It was aired a few times on American cable channels but has yet to be commercially released. Primarily clay, some characters required armatures, and walk cycles used pre-sculpted hard bases legs.

Stop motion was also used for some shots of the final sequence of "Terminator" movie, also for the scenes of the small alien ships in Spielberg's "Batteries Not Included" in 1987, animated by David W. Allen. Allen's stop-motion work can also be seen in such feature films as "The Crater Lake Monster" (1977), "Q - The Winged Serpent" (1982), "The Gate" (1987) and "Freaked" (1993). Allen's King Kong Volkswagen commercial from the 1970s is now legendary among model animation enthusiasts.

In 1985, Will Vinton and his team released an ambitious feature film in stop motion called "The Adventures Of Mark Twain" based on the life and works of the famous American author. While the film may have been a little sophisticated for young audiences at the time, it got rave reviews from critics and adults in general. Vinton's team also created the Nomes and the Nome King for Disney's "Return to Oz" feature, for which they received an Academy Award Nomination for Special Visual Effects. In the 1980s and early 1990s, Will Vinton became very well known for his commercial work as well with stop-motion campaigns including The California Raisins.

From 1986 to 1991, Churchill Films produced "The Mouse and the Motorcycle", "Runaway Ralph", and "Ralph S. Mouse" for ABC television. The shows featured stop-motion characters combined with live action, based on the books of Beverly Cleary. John Clark Matthews was the animation director, with Justin Kohn, Joel Fletcher, and Gail Van Der Merwe providing character animation. The company also produced other films based on children's books.

From 1986 to 2000, over 150 five-minute episodes of "Pingu", a Swiss children's comedy were produced by Trickfilmstudio.

Aardman Animations' Nick Park became very successful with his short claymation "Creature Comforts" in 1989, which had funny animals voicing vox pop interviews. Park then used the same format to produce a series of commercials between 1990 and 1992. The commercials have been credited as having introduced a more "caring" way of advertising in the UK. Richard Goleszowski later directed two 13-episode "Creature Comforts" TV series (2003, 2005-2006) and a Christmas special (2005). 
Also in 1989, Park introduced his very popular clay characters Wallace and Gromit in "A Grand Day Out". Three more short films and one feature film and many TV adaptions and spin-offs would follow. Among many other awards, Park won the Academy Award for Best Animated Feature for the feature-length outing "". His "Chicken Run", to date, is the highest grossing stop motion animated movie ever, grossing nearly $225 million worldwide.

In 1992, Trey Parker and Matt Stone made "The Spirit of Christmas (short film)", a short cutout animated student film made with construction paper. In 1995 they made a second short with the same titled, commissioned as a Christmas greeting by Fox Broadcasting Company executive Brian Graden. The concepts an characters were further developed into the TV hit series "South Park" (since 1997). Except for the pilot, all animation has been created on computers in the same style.

"The Nightmare Before Christmas" (1993), directed by Henry Selick and produced by Tim Burton, was one of the more widely released stop-motion features and become the highest grossing stop-motion animated movie of its time, grossing over $50 million domestic. Henry Selick also went on to direct "James and the Giant Peach" and "Coraline", and Tim Burton went on to direct "Corpse Bride" and "Frankenweenie".

The stop-motion feature "The Secret Adventures of Tom Thumb" was released in 1993.

In 1999, Will Vinton launched the first US prime-time stop-motion television series called "The PJs", co-created by actor-comedian Eddie Murphy. The Emmy-winning sitcom aired on Fox for two seasons, then moved to the WB for an additional season. Vinton launched another series, "Gary & Mike", for UPN in 2001.

In 1999, Tsuneo Gōda directed 30-second sketches of the character Domo. The shorts, animated by stop-motion studio dwarf, are currently still produced in Japan and have received universal critical acclaim from fans and critics. Gōda also directed the stop-motion movie series "Komaneko" in 2004.

The BBC commissioned thirteen episodes of stop frame animated "Summerton Mill" in 2004 as inserts into their flagship pre-school program, "Tikkabilla". Created and produced by Pete Bryden and Ed Cookson, the series was then given its own slot on BBC1 and BBC2 and has been broadcast extensively around the world.

Other notable stop-motion feature films released since 2000 include "Fantastic Mr. Fox" (2009) and "$9.99" (2009), and "Anomalisa" (2015).

In 2003, the pilot film for the series "Curucuru and Friends", produced by Korean studio Ffango Entertoyment is greenlighted into a children's animated series in 2004 after an approval with the Gyeonggi Digital Contents Agency. It was aired in KBS1 on November 24, 2006 and won the 13th Korean Animation Awards in 2007 for Best Animation. Ffango Entertoyment also worked with Frontier Works in Japan to produce the 2010 film remake of "Cheburashka".

Since 2005, "Robot Chicken" has mostly utilized stop-motion animation, using custom made action figures and other toys as principal characters.

Since 2009, Laika, the stop-motion successor to Will Vinton Studios, has released five feature films, which have collectively grossed over $400 million.

As of 2019, stop motion is thriving even in a filmmaking world dominated by CGI despite the efforts needed by the animators.

Stop motion has very rarely been shot in stereoscopic 3D throughout film history. The first 3D stop-motion short was "In Tune With Tomorrow" (also known as "Motor Rhythm"), made in 1939 by John Norling. The second stereoscopic stop-motion release was "The Adventures of Sam Space" in 1955 by Paul Sprunck. The third and latest stop motion short in stereo 3D was "The Incredible Invasion of the 20,000 Giant Robots from Outer Space" in 2000 by Elmer Kaan and Alexander Lentjes. This is also the first ever 3D stereoscopic stop motion and CGI short in the history of film. The first all stop-motion 3D feature is "Coraline" (2009), based on Neil Gaiman's best-selling novel and directed by Henry Selick.
Another recent example is the Nintendo 3DS video software which comes with the option for Stop Motion videos. This has been released December 8, 2011 as a 3DS system update. Also, the film "ParaNorman" is in 3D stop motion.

Another more complicated variation on stop motion is go motion, co-developed by Phil Tippett and first used on the films "The Empire Strikes Back" (1980), "Dragonslayer" (1981), and the "RoboCop" films. Go motion involved programming a computer to move parts of a model slightly during each exposure of each frame of film, combined with traditional hand manipulation of the model in between frames, to produce a more realistic motion blurring effect. Tippett also used the process extensively in his 1984 short film "Prehistoric Beast", a 10 minutes long sequence depicting a herbivorous dinosaur ("Monoclonius"), being chased by a carnivorous one ("Tyrannosaurus"). With new footage "Prehistoric Beast" became "Dinosaur!" in 1985, a full-length dinosaurs documentary hosted by Christopher Reeve. Those Phil Tippett's go motion tests acted as motion models for his first photo-realistic use of computers to depict dinosaurs in "Jurassic Park" in 1993. A low-tech, manual version of this blurring technique was originally pioneered by Władysław Starewicz in the silent era, and was used in his feature film "The Tale of the Fox" (1931).

Reasons for using stop motion instead of the more advanced computer-generated imagery (CGI) include the low entry price and the appeal of its distinct look. It is now mostly used in children's programming, in commercials and some comic shows such as "Robot Chicken". Another merit of stop motion is that it legitimately displays actual real-life textures, as CGI texturing is more artificial, therefore not quite as close to realism. This is appreciated by a number of animation directors, such as Tim Burton, Henry Selick, Wes Anderson, and Travis Knight.

Many young people begin their experiments in movie making with stop motion, thanks to the ease of modern stop-motion software and online video publishing. Many new stop-motion shorts use clay animation into a new form.

Singer-songwriter Oren Lavie's music video for the song Her Morning Elegance was posted on YouTube on January 19, 2009. The video, directed by Lavie and Yuval and Merav Nathan, uses stop motion and has achieved great success with over 25.4 million views, also earning a 2010 Grammy Award nomination for "Best Short Form Music Video".

Stop motion has occasionally been used to create the characters for computer games, as an alternative to CGI. The Virgin Interactive Entertainment Mythos game Magic and Mayhem (1998) featured creatures built by stop-motion specialist Alan Friswell, who made the miniature figures from modelling clay and latex rubber, over armatures of wire and ball-and-socket joints. The models were then animated one frame at a time, and incorporated into the CGI elements of the game through digital photography. "ClayFighter" for the Super NES and The Neverhood for the PC are other examples.

Scientists at IBM used a scanning tunneling microscope to single out and move individual atoms which were used to make characters in "A Boy and His Atom". This was the tiniest scale stop-motion video made at that time.





</doc>
<doc id="27037" url="https://en.wikipedia.org/wiki?curid=27037" title="Screwball comedy">
Screwball comedy

Screwball comedy is a subgenre of the romantic comedy genre that became popular during the Great Depression, originating in the early 1930s and thriving until the early 1940s. It is widely known for satirizing the traditional love story. Many secondary characteristics of this genre are similar to film noir, but it distinguishes itself for being characterized by a female that dominates the relationship with the male central character, whose masculinity is challenged. The two engage in a humorous battle of the sexes, which was a new theme for Hollywood and audiences at the time. What sets the screwball comedy apart from the generic romantic comedy is that "screwball comedy puts its emphasis on a funny spoofing of love, while the more traditional romantic ultimately accents love." Other elements of the screwball comedy include fast-paced, overlapping repartee, farcical situations, escapist themes, physical battle of the sexes, disguise and masquerade, and plot lines involving courtship and marriage. Screwball comedies often depict social classes in conflict, as in "It Happened One Night" (1934) and "My Man Godfrey" (1936). Some comic plays are also described as screwball comedies.

Screwball comedy has proved to be one of the most popular and enduring film genres. "It Happened One Night" (1934), is often credited as the first true screwball, though "Bombshell" starring Jean Harlow preceded it by a year. Although many film scholars agree that its classic period had effectively ended by 1942, elements of the genre have persisted or have been paid homage to in contemporary films. Still more, other film scholars argue that the screwball comedy lives on.

During the Great Depression, there was a general demand for films with a strong social class critique and hopeful, escapist-oriented themes. The screwball format arose largely as a result of the major film studios' desire to avoid censorship by the increasingly enforced Hays Code. In order to incorporate prohibited risqué elements into their plots, filmmakers resorted to handling these elements covertly. Verbal sparring between the sexes served as a stand-in for physical, sexual tension. Though some film scholars, such as William K. Everson argue "screwball comedies were not so much rebelling against the Production Code as they were attacking – and ridiculing – the dull, lifeless respectability that the Code insisted on for family viewing."

The screwball comedy has close links with the theatrical genre of farce, and some comic plays are also described as screwball comedies. Many elements of the screwball genre can be traced back to such stage plays as "Lysistrata" by Aristophanes, William Shakespeare's "Much Ado About Nothing", "As You Like It" and "A Midsummer Night's Dream", and Oscar Wilde's "The Importance of Being Earnest". Other genres with which screwball comedy is associated include slapstick, situation comedy, romantic comedy and bedroom farce.

Films definitive of the genre usually feature farcical situations, a combination of slapstick with fast-paced repartee and show the struggle between economic classes. They also generally feature a self-confident and often stubborn central female protagonist and a plot involving courtship and marriage or remarriage. These traits can be seen in both "It Happened One Night" and "My Man Godfrey" (1936). The film critic Andrew Sarris has defined the screwball comedy as "a sex comedy without the sex."

Like farce, screwball comedies often involve masquerade and disguise in which a character or characters resort to secrecy. Sometimes screwball comedies feature male characters cross-dressing, further contributing to elements of masquerade ("Bringing Up Baby" (1938), "I Was a Male War Bride" (1949), and "Some Like It Hot" (1959)). At first, the couple seem mismatched and even hostile to each other but eventually overcome their differences in an amusing or entertaining way that leads to romance. Often this mismatch comes about when the man is of a lower social class than the woman ("Bringing Up Baby", "Holiday", both 1938). The final romantic union is often planned by the woman from the outset, and the man is seemingly oblivious to this. In "Bringing Up Baby," the woman says to a third party: "He's the man I'm going to marry. He doesn't know it, but I am."
These pictures also offered a kind of cultural escape valve: a safe battleground on which to explore serious issues such as class under a comedic and non-threatening framework. Class issues are a strong component of screwball comedies: the upper class are represented as idle, pampered, and having difficulty coping with the real world. By contrast, when lower-class people attempt to pass themselves off as upper-class or otherwise insinuate themselves into high society, they are able to do so with relative ease ("The Lady Eve", 1941; "My Man Godfrey", 1936). Some critics believe that the portrayal of the upper class in "It Happened One Night" was brought about by the Great Depression, and the financially struggling moviegoing public's desire to see the rich upper class taught a lesson in humanity.

Another common element of the screwball comedy is fast-talking, witty repartee ("You Can't Take It with You" (1937) and "His Girl Friday" (1940)). This stylistic device did not originate in the genre (although it may be argued to have reached its zenith there): it is also found in many of the old Hollywood cycles, including gangster films and romantic comedies.

Screwball comedies also tend to contain ridiculous, farcical situations, such as in "Bringing Up Baby", where a couple must take care of a pet leopard during much of the film. Slapstick elements are also frequently present, such as the numerous pratfalls Henry Fonda takes in "The Lady Eve" (1941).

One subgenre of screwball is known as the comedy of remarriage, in which characters divorce and then remarry one another ("The Awful Truth" (1937), "The Philadelphia Story" (1940)). Some scholars point to this frequent device as evidence of the shift in the American moral code, as it showed freer attitudes toward divorce (though the divorce always turns out to have been a mistake).

Another subgenre of screwball comedy has the woman chasing a man who is oblivious to or not interested in her. Examples include Barbara Stanwyck chasing Henry Fonda ("The Lady Eve" (1941), Marion Davies chasing Antonio Moreno ("The Cardboard Lover" (1928), Marion Davies chasing Bing Crosby ("Going Hollywood" (1933), and Carole Lombard chasing William Powell ("My Man Godfrey" (1936).

The philosopher Stanley Cavell has noted that many classic screwball comedies turn on an interlude in the state of Connecticut ("Bringing Up Baby", "The Lady Eve", "The Awful Truth"). In "Christmas in Connecticut" (1945), the action moves to Connecticut and remains there for the duration of the film.


Other films from this period in other genres incorporate elements of the screwball comedy. For example, Alfred Hitchcock's thriller "The 39 Steps" (1935) features the gimmick of a young couple who find themselves handcuffed together and who eventually, almost in spite of themselves, fall in love with one another, and Woody Van Dyke's detective comedy "The Thin Man" (1934), which portrays a witty, urbane couple who trade barbs as they solve mysteries together. Many of the Fred Astaire and Ginger Rogers musicals of the 1930s also feature screwball comedy plots, notably "The Gay Divorcee" (1934) and "Top Hat" (1935). The Eddie Cantor musicals "Whoopee!" (1930) and "Roman Scandals" (1933), and slapstick road movies such as "Six of a Kind" (1934) include screwball elements. Some of the Joe E. Brown comedies also fall into this category, particularly "Broadminded" (1931) and "Earthworm Tractors" (1936).

Actors and actresses frequently featured in or associated with screwball comedy include:

Some notable directors of screwball comedies include:

Various later films are considered by some critics to have revived elements of the classic era screwball comedies, including:
Elements of classic screwball comedy often found in more recent films which might otherwise simply be classified as romantic comedies include the "battle of the sexes" ("Down with Love", "How to Lose a Guy in 10 Days"), witty repartee ("Down with Love"), and the contrast between the wealthy and the middle class ("You've Got Mail", "Two Weeks Notice"). Many of Elvis Presley's films from the 1960s had drawn, consciously or unconsciously, the many characteristics of the screwball comedy genre. Some examples are "Double Trouble", "Tickle Me", "Girl Happy" and "Live A Little, Love A Little". Modern updates on screwball comedy also sometimes are categorized as black comedy ("Intolerable Cruelty", which also features a twist on the classic screwball element of divorce and remarriage). The Coen Brothers often include screwball elements in a film which may not otherwise be considered screwball or even a comedy.

The Golmaal movies, a series of Hindi-language Indian films, have been described as a screwball comedy franchise.

In his 2008 production of the classic Beaumarchais comedy "The Marriage of Figaro", author William James Royce trimmed the five-act play down to three acts and labeled it a "classic screwball comedy". The playwright made Suzanne the central character, endowing her with all the feisty comedic strengths of her classic film counterparts. In his adaptation, entitled "One Mad Day!" (a play on Beaumarchais' original French title) Royce underscored all of the elements of the classic screwball comedy, suggesting that Beaumarchais may have had a hand in the origins of the genre.

The television series "Moonlighting" (1985–1989), "Married... with Children" (1987–1997), "NewsRadio" (1995–1999), "Gilmore Girls" (2000–2007), "The O.C." (2003–2007), "Standoff" (2006–2007), and "Gossip Girl" (2007–2012) have also adapted elements of the screwball comedy genre for the small screen.

The second part of the 1978 film "Superman", set in fictional Metropolis, takes on a screwball tone after the seriousness of the original story.

"The Adventures of Tintin" comic "The Castafiore Emerald" contains settings, plots, comic devices, and character types that share many similarities to screwball comedies.

The plot of "Corrupting Dr. Nice", a science fiction novel by John Kessel involving time travel, is modeled on films such as "The Lady Eve" and "Bringing Up Baby".





</doc>
<doc id="27038" url="https://en.wikipedia.org/wiki?curid=27038" title="Lists of science fiction films">
Lists of science fiction films

Science fiction films
This is a list of science fiction films organized chronologically. These films have been released to a cinema audience by the commercial film industry and are widely distributed with reviews by reputable
critics. (The exception are the films on the made-for-TV list, which are normally not released to a cinema audience.) This includes silent film–era releases, serial films, and feature-length films. All of the films include core elements of science fiction, but can cross into other genres such as drama, mystery, action, horror, fantasy, and comedy.

Among the listed movies are films that have won motion-picture and science fiction awards as well as films that have been listed among the worst movies ever made, or have won one or more Golden Raspberry Awards. Critically distinguished films are indicated by footnotes in the listings.

Subgenre lists

Related films

Related lists

Film ratings



</doc>
<doc id="27040" url="https://en.wikipedia.org/wiki?curid=27040" title="Schutzstaffel">
Schutzstaffel

The Schutzstaffel (SS; also stylized as "ᛋᛋ" with Armanen runes; ; literally 'Protection Squadron') was a major paramilitary organization under Adolf Hitler and the Nazi Party (NSDAP) in Nazi Germany, and later throughout German-occupied Europe during World War II. It began with a small guard unit known as the "Saal-Schutz" ("Hall Security") made up of NSDAP volunteers to provide security for party meetings in Munich. In 1925, Heinrich Himmler joined the unit, which had by then been reformed and given its final name. Under his direction (1929–1945) it grew from a small paramilitary formation during the Weimar Republic to one of the most powerful organizations in Nazi Germany. From the time of the Nazi Party’s rise to power until the regime’s collapse in 1945, the SS was the foremost agency of security, surveillance, and terror within Germany and German-occupied Europe.

The two main constituent groups were the "Allgemeine SS" (General SS) and Waffen-SS (Armed SS). The "Allgemeine SS" was responsible for enforcing the racial policy of Nazi Germany and general policing, whereas the Waffen-SS consisted of combat units within Nazi Germany's military. A third component of the SS, the "SS-Totenkopfverbände" ("SS-TV"; literally "Death's Head Units"), ran the concentration camps and extermination camps. Additional subdivisions of the SS included the Gestapo and the "Sicherheitsdienst" (SD) organizations. They were tasked with the detection of actual or potential enemies of the Nazi state, the neutralization of any opposition, policing the German people for their commitment to Nazi ideology, and providing domestic and foreign intelligence.

The SS was the organization most responsible for the genocidal killing of an estimated 5.5 to 6 million Jews and millions of other victims during the Holocaust. Members of all of its branches committed war crimes and crimes against humanity during World War II (1939–45). The SS was also involved in commercial enterprises and exploited concentration camp inmates as slave labor. After Nazi Germany's defeat, the SS and the Nazi Party were judged by the International Military Tribunal at Nuremberg to be criminal organizations. Ernst Kaltenbrunner, the highest-ranking surviving SS main department chief, was found guilty of crimes against humanity at the Nuremberg trials and hanged in 1946.

By 1923, the Nazi Party (NSDAP) led by Adolf Hitler had created a small volunteer guard unit known as the "Saal-Schutz" (Hall Security) to provide security at their meetings in Munich. The same year, Hitler ordered the formation of a small bodyguard unit dedicated to his personal service. He wished it to be separate from the "suspect mass" of the party, including the paramilitary "Sturmabteilung" ("Storm Battalion"; SA), which he did not trust. The new formation was designated the "Stabswache" (Staff Guard). Originally the unit was composed of eight men, commanded by Julius Schreck and Joseph Berchtold, and was modeled after the Erhardt Naval Brigade, a "Freikorps" of the time. The unit was renamed "Stoßtrupp" (Shock Troops) in May 1923.

The "Stoßtrupp" was abolished after the failed 1923 Beer Hall Putsch, an attempt by the NSDAP to seize power in Munich. In 1925, Hitler ordered Schreck to organize a new bodyguard unit, the "Schutzkommando" (Protection Command). It was tasked with providing personal protection for Hitler at NSDAP functions and events. That same year, the "Schutzkommando" was expanded to a national organization and renamed successively the "Sturmstaffel" (Storm Squadron), and finally the "Schutzstaffel" (Protection Squad; SS). Officially, the SS marked its foundation on 9 November 1925 (the second anniversary of the Beer Hall Putsch). The new SS protected NSDAP leaders throughout Germany. Hitler's personal SS protection unit was later enlarged to include combat units.

Schreck, a founding member of the SA and a close confidant of Hitler, became the first SS chief in March 1925. On 15 April 1926, Joseph Berchtold succeeded him as chief of the SS. Berchtold changed the title of the office to "Reichsführer-SS" (Reich Leader-SS). Berchtold was considered more dynamic than his predecessor, but became increasingly frustrated by the authority the SA had over the SS. This led to him transferring leadership of the SS to his deputy, Erhard Heiden, on 1 March 1927. Under Heiden's leadership, a stricter code of discipline was enforced than would have been tolerated in the SA.

Between 1925 and 1929, the SS was considered to be a small "Gruppe" (battalion) of the SA. Except in the Munich area, the SS was unable to maintain any momentum in its membership numbers, which declined from 1,000 to 280 as the SA continued its rapid growth. As Heiden attempted to keep the SS from dissolving, Heinrich Himmler became his deputy in September 1927. Himmler displayed good organizational abilities compared to Heiden. The SS established a number of "Gau"s (regions or provinces). The SS-Gaus consisted of "SS-Gau Berlin", "SS-Gau Berlin Brandenburg", "SS-Gau Franken", "SS-Gau Niederbayern", "SS-Gau Rheinland-Süd", and "SS-Gau Sachsen".

With Hitler's approval, Himmler assumed the position of "Reichsführer-SS" in January 1929. There are differing accounts of the reason for Heiden's dismissal from his position as head of the SS. The party announced that it was for "family reasons." Under Himmler, the SS expanded and gained a larger foothold. He considered the SS an elite, ideologically driven National Socialist organization, a "conflation of Teutonic knights, the Jesuits, and Japanese Samurai". His ultimate aim was to turn the SS into the most powerful organization in Germany and most influential branch of the party. He expanded the SS to 3,000 members in his first year as its leader.

In 1929, the "SS-Hauptamt" (main SS office) was expanded and reorganized into five main offices dealing with general administration, personnel, finance, security, and race matters. At the same time, the SS-Gaue were divided into three "SS-Oberführerbereiche" areas, namely the "SS-Oberführerbereich Ost", "SS-Oberführerbereich West", and "SS-Oberführerbereich Süd". The lower levels of the SS remained largely unchanged. Although officially still considered a sub-organization of the SA and answerable to the "Stabschef" (SA Chief of Staff), it was also during this time that Himmler began to establish the independence of the SS from the SA. The SS grew in size and power due to its exclusive loyalty to Hitler, as opposed to the SA, which was seen as semi-independent and a threat to Hitler's hegemony over the party, mainly because they demanded a "second revolution" beyond the one that brought the NSDAP to power. By the end of 1933, the membership of the SS reached 209,000. Under Himmler's leadership, the SS continued to gather greater power as more and more state and party functions were assigned to its jurisdiction. Over time the SS became answerable only to Hitler, a development typical of the organizational structure of the entire Nazi regime, where legal norms were replaced by actions undertaken under the "Führerprinzip" (leader principle), where Hitler's will was considered to be above the law.

In the latter half of 1934, Himmler oversaw the creation of "SS-Junkerschule", institutions where SS officer candidates received leadership training, political and ideological indoctrination, and military instruction. The training stressed ruthlessness and toughness as part of the SS value system, which helped foster a sense of superiority among the men and taught them self-confidence. The first schools were established at Bad Tölz and Braunschweig, with additional schools opening at Klagenfurt and Prague during the war.

The SS was regarded as the NSDAP's elite unit. In keeping with the racial policy of Nazi Germany, in the early days all SS officer candidates had to provide proof of Aryan ancestry back to 1750 and for other ranks to 1800. Once the war started and it became more difficult to confirm ancestry, the regulation was amended to just proving the candidate's grandparents were Aryan, as spelled out in the Nuremberg Laws. Other requirements were complete obedience to the Führer and a commitment to the German people and nation. Himmler also tried to institute physical criteria based on appearance and height, but these requirements were only loosely enforced, and over half the SS men did not meet the criteria. Inducements such as higher salaries and larger homes were provided to members of the SS since they were expected to produce more children than the average German family as part of their commitment to NSDAP doctrine.

Commitment to SS ideology was emphasized throughout the recruitment, membership process, and training. Members of the SS were indoctrinated in the racial policy of Nazi Germany, and were taught that it was necessary to remove from Germany people deemed by that policy as inferior. Esoteric rituals and the awarding of regalia and insignia for milestones in the SS man's career suffused SS members even further with Nazi ideology. Members were expected to renounce their Christian faith, and Christmas was replaced with a solstice celebration. Church weddings were replaced with SS "Ehewein", a pagan ceremony invented by Himmler. These pseudo-religious rites and ceremonies often took place near SS-dedicated monuments or in special SS-designated places. In 1933, Himmler bought Wewelsburg, a castle in Westphalia. He initially intended it to be used as an SS training center, but its role came to include hosting SS dinners and neo-pagan rituals.

The SS ideology included the application of brutality and terror as a solution to military and political problems. The SS stressed total loyalty and obedience to orders unto death. Hitler used this as a powerful tool to further his aims and those of the NSDAP. The SS was entrusted with the commission of atrocities, illegal activities, and war crimes. Himmler once wrote that an SS man "hesitates not for a single instant, but executes unquestioningly ..." any "Führer-Befehl" (Führer order). Their official motto was ""Meine Ehre heißt Treue"" (My Honour is Loyalty).

As part of its race-centric functions during World War II, the SS oversaw the isolation and displacement of Jews from the populations of the conquered territories, seizing their assets and deporting them to concentration camps and ghettos, where they were used as slave labor or immediately killed. Chosen to implement the Final Solution ordered by Hitler, the SS were the main group responsible for the institutional killing and democide of more than 20 million people during the Holocaust, including approximately 5.2 million to 6 million Jews and 10.5 million Slavs. A significant number of victims were members of other racial or ethnic groups such as the 258,000 Romani. The SS was involved in killing people viewed as threats to race hygiene or Nazi ideology, including the mentally or physically handicapped, homosexuals, and political dissidents. Members of trade unions and those perceived to be affiliated with groups that opposed the regime (religious, political, social, and otherwise), or those whose views were contradictory to the goals of the NSDAP government, were rounded up in large numbers; these included clergy of all faiths, Jehovah's Witnesses, Freemasons, Communists, and Rotary Club members. According to the judgments rendered at the Nuremberg trials, as well as many war crimes investigations and trials conducted since then, the SS was responsible for the majority of Nazi war crimes. In particular, it was the primary organization which carried out the Holocaust.

After Hitler and the NSDAP came to power on 30 January 1933, the SS was considered a state organization and a branch of the government. Law enforcement gradually became the purview of the SS, and many SS organizations became de facto government agencies.

The SS established a police state within Nazi Germany, using the secret state police and security forces under Himmler's control to suppress resistance to Hitler. In his role as Minister President of Prussia, Hermann Göring had in 1933 created a Prussian secret police force, the "Geheime Staatspolizei" or Gestapo, and appointed Rudolf Diels as its head. Concerned that Diels was not ruthless enough to use the Gestapo effectively to counteract the power of the SA, Göring handed over its control to Himmler on 20 April 1934. Also on that date, in a departure from long-standing German practice that law enforcement was a state and local matter, Hitler appointed Himmler chief of all German police outside Prussia. Himmler named his deputy and protégé Reinhard Heydrich chief of the Gestapo on 22 April 1934. Heydrich also continued as head of the "Sicherheitsdienst" (SD; security service).

The Gestapo's transfer to Himmler was a prelude to the Night of the Long Knives, in which most of the SA leadership were arrested and subsequently executed. The SS and Gestapo carried out most of the killings. On 20 July 1934, Hitler detached the SS from the SA, which was no longer an influential force after the purge. The SS became an elite corps of the NSDAP, answerable only to Hitler. Himmler's title of "Reichsführer-SS" now became his actual rank – and the highest rank in the SS, equivalent to the rank of field marshal in the army (his previous rank was "Obergruppenführer"). As Himmler's position and authority grew, so in effect did his rank.

On 17 June 1936, all police forces throughout Germany were united under the purview of Himmler and the SS. Himmler and Heydrich thus became two of the most powerful men in the country's administration. Police and intelligence forces brought under their administrative control included the SD, Gestapo, "Kriminalpolizei" (Kripo; criminal investigative police), and "Ordnungspolizei" (Orpo; regular uniformed police). In his capacity as police chief, Himmler was nominally subordinate to Interior Minister Wilhelm Frick. In practice, since the SS answered only to Hitler, the de facto merger of the SS and the police made the police independent of Frick's control. In September 1939, the security and police agencies, including the "Sicherheitspolizei" (SiPo; security police) and SD (but not the Orpo), were consolidated into the Reich Main Security Office (RSHA), headed by Heydrich. This further increased the collective authority of the SS.

During "Kristallnacht" (9–10 November 1938), SS security services clandestinely coordinated violence against Jews as the SS, Gestapo, SD, Kripo, SiPo, and regular police did what they could to ensure that while Jewish synagogues and community centers were destroyed, Jewish-owned businesses and housing remained intact so that they could later be seized. In the end, thousands of Jewish businesses, homes, and graveyards were vandalized and looted, particularly by members of the SA. Some 500 to 1,000 synagogues were destroyed, mostly by arson. On 11 November, Heydrich reported a death toll of 36 people, but later assessments put the number of deaths at up to two thousand. On Hitler's orders, around 30,000 Jewish men were arrested and sent to concentration camps by 16 November. As many as 2,500 of these people died in the following months. It was at this point that the SS state began in earnest its campaign of terror against political and religious opponents, who they imprisoned without trial or judicial oversight for the sake of "security, re-education, or prevention".

In September 1939, the authority of the SS expanded further when the senior SS officer in each military district also became its chief of police. Most of these SS and police leaders held the rank of SS-"Gruppenführer" or above, and answered directly to Himmler in all SS matters within their district. Their role was to police the population and oversee the activities of the SS men within their district. By declaring an emergency, they could bypass the district administrative offices for the SS, SD, SiPo, "SS-Totenkopfverbände" (SS-TV; concentration camp guards), and Orpo, thereby gaining direct operational control of these groups.

As the SS grew in size and importance, so too did Hitler's personal protection forces. Three main SS groups were assigned to protect Hitler. In 1933, his larger personal bodyguard unit (previously the 1st SS-Standarte) was called to Berlin to replace the Army Chancellery Guard, assigned to protect the Chancellor of Germany. Sepp Dietrich commanded the new unit, previously known as SS-Stabswache Berlin; the name was changed to "SS-Sonderkommando Berlin". In November 1933, the name was changed to "Leibstandarte Adolf Hitler". In April 1934, Himmler modified the name to "Leibstandarte SS Adolf Hitler" (LSSAH). The LSSAH guarded Hitler's private residences and offices, providing an outer ring of protection for the Führer and his visitors. LSSAH men manned sentry posts at the entrances to the old Reich Chancellery and the new Reich Chancellery. The number of LSSAH guards was increased during special events. At the Berghof, Hitler's residence in the Obersalzberg, a large contingent of the LSSAH patrolled an extensive cordoned security zone.

From 1941 forward, the "Leibstandarte" became four distinct entities, the Waffen-SS division (unconnected to Hitler's protection but a formation of the Waffen-SS), the Berlin Chancellory Guard, the SS security regiment assigned to the Obersalzberg, and a Munich-based bodyguard unit which protected Hitler when he visited his apartment and the Brown House NSDAP headquarters in Munich. Although the unit was nominally under Himmler, Dietrich was the real commander and handled day-to-day administration.

Two other SS units composed the inner ring of Hitler's protection. The "SS-Begleitkommando des Führers" (Escort Command of the Führer), formed in February 1932, served as Hitler's protection escort while he was traveling. This unit consisted of eight men who served around the clock protecting Hitler in shifts. Later the "SS-Begleitkommando" was expanded and became known as the "Führerbegleitkommando" (Führer Escort Command; FBK). It continued under separate command and remained responsible for Hitler's protection. The "Führer Schutzkommando" (Führer Protection Command; FSK) was a protection unit founded by Himmler in March 1933. Originally it was charged with protecting Hitler only while he was inside the borders of Bavaria. In early 1934, they replaced the "SS-Begleitkommando" for Hitler's protection throughout Germany. The FSK was renamed the "Reichssicherheitsdienst" (Reich Security Service; RSD) in August 1935. Johann Rattenhuber, chief of the RSD, for the most part, took his orders directly from Hitler. The current FBK chief acted as his deputy. Wherever Hitler was in residence, members of the RSD and FBK would be present. RSD men patrolled the grounds and FBK men provided close security protection inside. The RSD and FBK worked together for security and personal protection during Hitler's trips and public events, but they operated as two groups and used separate vehicles. By March 1938, both units wore the standard field grey uniform of the SS. The RSD uniform had the SD diamond on the lower left sleeve.

The SS was closely associated with Nazi Germany's concentration camp system. On 26 June 1933, Himmler appointed SS-"Oberführer" Theodor Eicke as commandant of Dachau concentration camp, one of the first Nazi concentration camps. It was created to consolidate the many small camps that had been set up by various police agencies and the NSDAP to house political prisoners. The organizational structure Eicke instituted at Dachau stood as the model for all later concentration camps. After 1934, Eicke was named commander of the "SS-Totenkopfverbände" (SS-TV), the SS formation responsible for running the concentration camps under the authority of the SS and Himmler. Known as the "Death's Head Units", the SS-TV was first organized as several battalions, each based at one of Germany's major concentration camps. Leadership at the camps was divided into five departments: commander and adjutant, political affairs division, protective custody, administration, and medical personnel. By 1935, Himmler secured Hitler's approval and the finances necessary to establish and operate additional camps. Six concentration camps housing 21,400 inmates (mostly political prisoners) existed at the start of the war in September 1939. By the end of the war, hundreds of camps of varying size and function had been created, holding nearly 715,000 people, most of whom were targeted by the regime because of their race. The concentration camp population rose in tandem with the defeats suffered by the Nazi regime; the worse the catastrophe seemed, the greater the fear of subversion, prompting the SS to intensify their repression and terror.

By the outbreak of World War II, the SS had consolidated into its final form, which comprised three main organizations: the "Allgemeine SS", "SS-Totenkopfverbände", and the Waffen-SS, which was founded in 1934 as the "SS-Verfügungstruppe" (SS-VT) and renamed in 1940. The Waffen-SS evolved into a second German army alongside the Wehrmacht and operated in tandem with them, especially with the "Heer" (German Army). However, it never obtained total "independence of command", nor was it ever a "serious rival" to the German Army. Members were never able to join the ranks of the German High Command and it was dependent on the army for heavy weaponry and equipment. Although SS ranks generally had equivalents in the other services, the SS rank system did not copy the terms and ranks used by the Wehrmacht's branches. Instead, it used the ranks established by the post-World War I "Freikorps" and the SA. This was primarily done to emphasize the SS as being independent of the Wehrmacht.

In the September 1939 invasion of Poland, the LSSAH and SS-VT fought as separate mobile infantry regiments. The LSSAH became notorious for torching villages without military justification. Members of the LSSAH committed atrocities in numerous towns, including the murder of 50 Polish Jews in Błonie and the massacre of 200 civilians, including children, who were machine-gunned in Złoczew. Shootings also took place in Bolesławiec, Torzeniec, Goworowo, Mława, and Włocławek. Some senior members of the Wehrmacht were not convinced the units were fully prepared for combat. Its units took unnecessary risks and had a higher casualty rate than the army. "Generaloberst" Fedor von Bock was quite critical; following an April 1940 visit of the "SS-Totenkopf" division, he found their battle training was "insufficient". Hitler thought the criticism was typical of the army's "outmoded conception of chivalry." In its defense, the SS insisted that its armed formations had been hampered by having to fight piecemeal and were improperly equipped by the army.

After the invasion, Hitler entrusted the SS with extermination actions codenamed Operation Tannenberg and AB-Aktion to remove potential leaders who could form a resistance to German occupation. The killings were committed by "Einsatzgruppen" (task forces; deployment groups), assisted by local paramilitary groups. Men for the "Einsatzgruppen" units were drawn from the SS, the SD, and the police. Some 65,000 Polish civilians, including activists, intelligentsia, scholars, teachers, actors, former officers, and others, were killed by the end of 1939. When the army leadership registered complaints about the brutality being meted out by the "Einsatzgruppen", Heydrich informed them that he was acting "in accordance with the special order of the Führer." The first systematic mass shooting of Jews by the "Einsatzgruppen" took place on 6 September 1939 during the attack on Kraków.
Satisfied with their performance in Poland, Hitler allowed further expansion of the armed SS formations, but insisted new units remain under the operational control of the army. While the "SS-Leibstandarte" remained an independent regiment functioning as Hitler's personal bodyguards, the other regiments—"SS-Deutschland", "SS-Germania," and "SS-Der Führer"—were combined to form the "SS-Verfügungs-Division". A second SS division, the "SS-Totenkopf", was formed from SS-TV concentration camp guards, and a third, the "SS-Polizei", was created from police volunteers. The SS gained control over its own recruitment, logistics, and supply systems for its armed formations at this time. The SS, Gestapo, and SD were in charge of the provisional military administration in Poland until the appointment of Hans Frank as Governor-General on 26 October 1939.

On 10 May 1940, Hitler launched the Battle of France, a major offensive against France and the Low Countries. The SS supplied two of the 89 divisions employed. The LSSAH and elements of the SS-VT participated in the ground invasion of the Battle of the Netherlands. Simultaneously, airborne troops were dropped to capture key Dutch airfields, bridges, and railways. In the five-day campaign, the LSSAH linked up with army units and airborne troops after several clashes with Dutch defenders.

SS troops did not take part in the thrust through the Ardennes and the river Meuse. Instead, the "SS-Totenkopf" was summoned from the army reserve to fight in support of "Generalmajor" Erwin Rommel's 7th Panzer Division as they advanced toward the English Channel. On 21 May, the British launched an armored counterattack against the flanks of the 7th Panzer Division and "SS-Totenkopf". The Germans then trapped the British and French troops in a huge pocket at Dunkirk. On 27 May, 4 Company, "SS-Totenkopf" perpetrated the Le Paradis massacre, where 97 men of the 2nd Battalion, Royal Norfolk Regiment were machine-gunned after surrendering, with survivors finished off with bayonets. Two men survived. By 28 May the "SS-Leibstandarte" had taken Wormhout, from Dunkirk. There, soldiers of the 2nd Battalion were responsible for the Wormhoudt massacre, where 80 British and French soldiers were murdered after they surrendered. According to historian Charles Sydnor, the "fanatical recklessness in the assault, suicidal defense against enemy attacks, and savage atrocities committed in the face of frustrated objectives" exhibited by the "SS-Totenkopf" division during the invasion were typical of the SS troops as a whole.

At the close of the campaign, Hitler expressed his pleasure with the performance of the "SS-Leibstandarte", telling them: "Henceforth it will be an honor for you, who bear my name, to lead every German attack." The SS-VT was renamed the Waffen-SS in a speech made by Hitler in July 1940. Hitler then authorized the enlistment of "people perceived to be of related stock", as Himmler put it, to expand the ranks. Danes, Dutch, Norwegians, Swedes, and Finns volunteered to fight in the Waffen-SS under the command of German officers. They were brought together to form the new division "SS-Wiking". In January 1941, the "SS-Verfügungs" Division was renamed "SS-Reich" Division (Motorized), and was renamed as the "2nd SS Panzer Division Das Reich" when it was reorganized as a "Panzergrenadier" division in 1942.

In April 1941, the German Army invaded Yugoslavia and Greece. The LSSAH and "Das Reich" were attached to separate army Panzer corps. Fritz Klingenberg, a company commander in the "Das Reich", led his men across Yugoslavia to the capital, Belgrade, where a small group in the vanguard accepted the surrender of the city on 13 April. A few days later Yugoslavia surrendered. SS police units immediately began taking hostages and carrying out reprisals, a practice that became common. In some cases, they were joined by the Wehrmacht. Similar to Poland, the war policies of the Nazis in the Balkans resulted in brutal occupation and racist mass murder. Serbia became the second country (after Estonia) declared "Judenfrei" (free of Jews).

In Greece, the Wehrmacht and Waffen-SS encountered resistance from the British Expeditionary Force (BEF) and Greek Army. The fighting was intensified by the mountainous terrain, with its heavily defended narrow passes. The LSSAH was at the forefront of the German push. The BEF evacuated by sea to Crete, but had to flee again in late May when the Germans arrived. Like Yugoslavia, the conquest of Greece brought its Jews into danger, as the Nazis immediately took a variety of measures against them. Initially confined in ghettos, most were transported to Auschwitz concentration camp in March 1943, where they were killed in the gas chambers on arrival. Of Greece's 80,000 Jews, only 20 percent survived the war.

On 22 June 1941, Hitler launched Operation Barbarossa, the invasion of the Soviet Union. The expanding war and the need to control occupied territories provided the conditions for Himmler to further consolidate the police and military organs of the SS. Rapid acquisition of vast territories in the East placed considerable strain on the SS police organizations as they struggled to adjust to the changing security challenges.

The 1st and 2nd SS Infantry Brigades, which had been formed from surplus concentration camp guards of the SS-TV, and the SS Cavalry Brigade moved into the Soviet Union behind the advancing armies. At first, they fought Soviet partisans, but by the autumn of 1941, they left the anti-partisan role to other units and actively took part in the Holocaust. While assisting the "Einsatzgruppen", they formed firing parties that participated in the liquidation of the Jewish population of the Soviet Union.

On 31 July 1941, Göring gave Heydrich written authorization to ensure the cooperation of administrative leaders of various government departments to undertake genocide of the Jews in territories under German control. Heydrich was instrumental in carrying out these exterminations, as the Gestapo was ready to organize deportations in the West and his "Einsatzgruppen" were already conducting extensive killing operations in the East. On 20 January 1942, Heydrich chaired a meeting, called the Wannsee Conference, to discuss the implementation of the plan.

During battles in the Soviet Union during 1941 and 1942, the Waffen-SS suffered enormous casualties. The LSSAH and "Das Reich" lost over half their troops to illness and combat casualties. In need of recruits, Himmler began to accept soldiers that did not fit the original SS racial profile. In early 1942, "SS-Leibstandarte", "SS-Totenkopf", and "SS-Das Reich" were withdrawn to the West to refit and were converted to "Panzergrenadier" divisions. The SS-Panzer Corps returned to the Soviet Union in 1943 and participated in the Third Battle of Kharkov in February and March.

The SS was built on a culture of violence, which was exhibited in its most extreme form by the mass murder of civilians and prisoners of war on the Eastern Front. Augmented by personnel from the Kripo, Orpo (Order Police), and Waffen-SS, the "Einsatzgruppen" reached a total strength of 3,000 men. "Einsatzgruppen" A, B, and C were attached to Army Groups North, Centre, and South; "Einsatzgruppe" D was assigned to the 11th Army. The "Einsatzgruppe" for Special Purposes operated in eastern Poland starting in July 1941. The historian Richard Rhodes describes them as being "outside the bounds of morality"; they were "judge, jury and executioner all in one", with the authority to kill anyone at their discretion. Following Operation Barbarossa, these "Einsatzgruppen" units, together with the Waffen-SS and Order Police as well as with assistance from the Wehrmacht, engaged in the mass killing of the Jewish population in occupied eastern Poland and the Soviet Union. The greatest extent of "Einsatzgruppen" action occurred in 1941 and 1942 in Ukraine and Russia. Before the invasion there were five million registered Jews throughout the Soviet Union, with three million of those residing in the territories occupied by the Germans; by the time the war ended, over two million of these had been murdered.

The extermination activities of the "Einsatzgruppen" generally followed a standard procedure, with the "Einsatzgruppen" chief contacting the nearest Wehrmacht unit commander to inform him of the impending action; this was done so they could coordinate and control access to the execution grounds. Initially, the victims were shot, but this method proved impracticable for an operation of this scale. Also, after Himmler observed the shooting of 100 Jews at Minsk in August 1941, he grew concerned about the impact such actions were having on the mental health of his SS men. He decided that alternate methods of killing should be found, which led to introduction of gas vans. However, these were not popular with the men, because removing the dead bodies from the van and burying them was a horrible ordeal. Prisoners or auxiliaries were often assigned to do this task so as to spare the SS men the trauma.

In response to the army's difficulties in dealing with Soviet partisans, Hitler decided in July 1942 to transfer anti-partisan operations to the police. This placed the matter under Himmler's purview. As Hitler had ordered on 8 July 1941 that all Jews were to be regarded as partisans, the term "anti-partisan operations" was used as a euphemism for the murder of Jews as well as actual combat against resistance elements. In July 1942 Himmler ordered that the term "partisan" should no longer be used; instead resisters to Nazi rule would be described as "bandits".

Himmler set the SS and SD to work on developing additional anti-partisan tactics and launched a propaganda campaign. Sometime in June 1943, Himmler issued the "Bandenbekämpfung" (bandit fighting) order, simultaneously announcing the existence of the "Bandenkampfverbände" (bandit fighting formations), with SS-"Obergruppenführer" Erich von dem Bach-Zelewski as its chief. Employing troops primarily from the SS police and Waffen-SS, the "Bandenkampfverbände" had four principal operational components: propaganda, centralized control and coordination of security operations, training of troops, and battle operations. Once the Wehrmacht had secured territorial objectives, the "Bandenkampfverbände" first secured communications facilities, roads, railways, and waterways. Thereafter, they secured rural communities and economic installations such as factories and administrative buildings. An additional priority was securing agricultural and forestry resources. The SS oversaw the collection of the harvest, which was deemed critical to strategic operations. Any Jews in the area were rounded up and killed. Communists and people of Asiatic descent were killed presumptively under the assumption that they were Soviet agents.

After the start of the war, Himmler intensified the activity of the SS within Germany and in Nazi-occupied Europe. Increasing numbers of Jews and German citizens deemed politically suspect or social outsiders were arrested. As the Nazi regime became more oppressive, the concentration camp system grew in size and lethal operation, and grew in scope as the economic ambitions of the SS intensified.

Intensification of the killing operations took place in late 1941 when the SS began construction of stationary gassing facilities to replace the use of "Einsatzgruppen" for mass killings. Victims at these new extermination camps were killed with the use of carbon monoxide gas from automobile engines. During Operation Reinhard, run by officers from the "Totenkopfverbände", who were sworn to secrecy, three death camps were built in occupied Poland: Bełżec (operational by March 1942), Sobibór (operational by May 1942), and Treblinka (operational by July 1942), with squads of Trawniki men (Eastern European collaborators) overseeing hundreds of "Sonderkommando" prisoners, who were forced to work in the gas chambers and crematoria before being murdered themselves. On Himmler's orders, by early 1942 the concentration camp at Auschwitz was greatly expanded to include the addition of gas chambers, where victims were killed using the pesticide Zyklon B.

For administrative reasons, all concentration camp guards and administrative staff became full members of the Waffen-SS in 1942. The concentration camps were placed under the command of the "SS-Wirtschafts-Verwaltungshauptamt" (SS Main Economic and Administrative Office; WVHA) under Oswald Pohl. Richard Glücks served as the Inspector of Concentration Camps, which in 1942 became office "D" under the WVHA. Exploitation and extermination became a balancing act as the military situation deteriorated. The labor needs of the war economy, especially for skilled workers, meant that some Jews escaped the genocide. On 30 October 1942, due to severe labor shortages, Himmler ordered that large numbers of able-bodied people in the Soviet-occupied territories should be taken prisoner and sent to Germany as forced labor.

By 1944, the SS-TV had been organized into three divisions: staff of the concentration camps in Germany and Austria, in the occupied territories, and of the extermination camps in Poland. By 1944, it became standard practice to rotate SS members in and out of the camps, partly based on manpower needs, but also to provide easier assignments to wounded Waffen-SS members. This rotation of personnel meant that nearly the entire SS knew what was going on inside the concentration camps, making the entire organization liable for war crimes and crimes against humanity.

In 1934, Himmler founded the first SS business venture, Nordland-Verlag, a publishing house that released propaganda material and SS training manuals. Thereafter, he purchased Allach Porcelain, which then began to produce SS memorabilia. Because of the labor shortage and a desire for financial gain, the SS started exploiting concentration camp inmates as slave labor. Most of the SS businesses lost money until Himmler placed them under the administration of Pohl's "Verwaltung und Wirtschaftshauptamt Hauptamt" (Administration and Business office; VuWHA) in 1939. Even then, most of the enterprises were poorly run and did not fare well, as SS men were not selected for their business experience, and the workers were starving. In July 1940 Pohl established the "Deutsche Wirtschaftsbetriebe GmbH" (German Businesses Ltd; DWB), an umbrella corporation under which he took over administration of all SS business concerns. Eventually, the SS founded nearly 200 holding companies for their businesses.

In May 1941 the VuWHA founded the "Deutsche Ausrüstungswerke" GmbH (German Equipment Works; DAW), which was created to integrate the SS business enterprises with the burgeoning concentration camp system. Himmler subsequently established four major new concentration camps in 1941: Auschwitz, Gross-Rosen, Natzweiler-Struthof, and Neuengamme. Each had at least one factory or quarry nearby where the inmates were forced to work. Himmler took a particular interest in providing laborers for IG Farben, which was constructing a synthetic rubber factory at Auschwitz III–Monowitz. The plant was almost ready to commence production when it was overrun by Soviet troops in 1945. The life expectancy of inmates at Monowitz averaged about three months. This was typical of the camps, as inmates were underfed and lived under disastrously bad living conditions. Their workload was intentionally made impossibly high, under the policy of extermination through labor.

In 1942, Himmler consolidated all of the offices for which Pohl was responsible into one, creating the SS Main Economic and Administrative Office ("Wirtschafts- und Verwaltungshauptamt"; WVHA). The entire concentration camp system was placed under the authority of the WVHA. The SS owned Sudetenquell GmbH, a mineral water producer in Sudetenland. By 1944, the SS had purchased 75 percent of the mineral water producers in Germany and were intending to acquire a monopoly. Several concentration camps produced building materials such as stone, bricks, and cement for the SS-owned "Deutsche Erd- und Steinwerke" (German Earth And Stone Works; DEST). In the occupied Eastern territories, the SS acquired a monopoly in brick production by seizing all 300 extant brickworks. The DWB also founded the "Ost-Deutsche Baustoffwerke" (East German Building Supply Works; GmbH or ODBS) and "Deutsche Edelmöbel" GmbH (German Noble Furniture). These operated in factories the SS had confiscated from Jews and Poles.

The SS owned experimental farms, bakeries, meat packing plants, leather works, clothing and uniform factories, and small arms factories. Under the direction of the WVHA, the SS sold camp labor to various factories at a rate of three to six "Reichsmarks" per prisoner per day. The SS confiscated and sold the property of concentration camp inmates, confiscated their investment portfolios and their cash, and profited from their dead bodies by selling their hair to make felt and melting down their dental work to obtain gold from the fillings. The total value of assets looted from the victims of Operation Reinhard alone (not including Auschwitz) was listed by Odilo Globocnik as 178,745,960.59 Reichsmarks. Items seized included 2,909.68 kilograms of gold worth 843,802.75 RM, as well as 18,733.69 kg of silver, 1,514 kg of platinum, 249,771.50 American dollars, 130 diamond solitaires, 2,511.87 carats of brilliants, 13,458.62 carats of diamonds, and 114 kg of pearls. According to Nazi legislation, Jewish property belonged to the state, but many SS camp commandants and guards stole items such as diamonds or currency for personal gain or took seized foodstuffs and liquor to sell on the black market.

On 5 July 1943, the Germans launched the Battle of Kursk, an offensive designed to eliminate the Kursk salient. The Waffen-SS by this time had been expanded to 12 divisions, and most took part in the battle. Due to stiff Soviet resistance, Hitler halted the attack by the evening of 12 July. On 17 July he called off the operation and ordered a withdrawal. Thereafter, the Germans were forced onto the defensive as the Red Army began the liberation of Western Russia. The losses incurred by the Waffen-SS and the Wehrmacht during the Battle of Kursk occurred nearly simultaneously with the Allied assault into Italy, opening a two-front war for Germany.

Alarmed by the raids on St Nazaire and Dieppe in 1942, Hitler had ordered the construction of fortifications he called the Atlantic Wall all along the Atlantic coast, from Spain to Norway, to protect against an expected Allied invasion. Concrete gun emplacements were constructed at strategic points along the coast, and wooden stakes, metal tripods, mines, and large anti-tank obstacles were placed on the beaches to delay the approach of landing craft and impede the movement of tanks. In addition to several static infantry divisions, eleven panzer and "Panzergrenadier" divisions were deployed nearby. Four of these formations were Waffen-SS divisions. In addition, the "SS-Das Reich" was located in Southern France, the LSSAH was in Belgium refitting after fighting in the Soviet Union, and the newly formed panzer division "SS-Hitlerjugend", consisting of 17- and 18-year-old Hitler Youth members supported by combat veterans and experienced NCOs, was stationed west of Paris. The creation of the "SS-Hitlerjugend" was a sign of Hitler's desperation for more troops, especially ones with unquestioning obedience.

The Normandy landings took place beginning 6 June 1944. 21st Panzer Division under "Generalmajor" Edgar Feuchtinger, positioned south of Caen, was the only panzer division close to the beaches. The division included 146 tanks and 50 assault guns, plus supporting infantry and artillery. At 02:00, "Generalleutnant" Wilhelm Richter, commander of the 716th Static Infantry Division, ordered 21st Panzer Division into position to counter-attack. However, as the division was part of the armored reserve, Feuchtinger was obliged to seek clearance from OKW before he could commit his formation. Feuchtinger did not receive orders until nearly 09:00, but in the meantime, on his own initiative he put together a battle group (including tanks) to fight the British forces east of the Orne. "SS-Hitlerjugend" began to deploy in the afternoon of 6 June, with its units undertaking defensive actions the following day. They also took part in the Battle for Caen (June–August 1944). On 7–8 and 17 June, members of the "SS-Hitlerjugend" shot and killed twenty Canadian prisoners of war in the Ardenne Abbey massacre.

The Allies continued to make progress in the liberation of France, and on 4 August Hitler ordered a counter-offensive (Operation Lüttich) from Vire towards Avranches. The operation included LSSAH, "Das Reich", 2nd, and 116th Panzer Divisions, with support from infantry and elements of the 17th SS Panzergrenadier Division "Götz von Berlichingen" under SS-"Oberstgruppenführer" Paul Hausser. These forces were to mount an offensive near Mortain and drive west through Avranches to the coast. The Allied forces were prepared for this offensive, and an air assault on the combined German units proved devastating. On 21 August, 50,000 German troops, including most of the LSSAH, were encircled by the Allies in the Falaise Pocket. Remnants of the LSSAH which escaped were withdrawn to Germany for refitting. Paris was liberated on 25 August, and the last of the German forces withdrew over the Seine by the end of August, ending the Normandy campaign.

Waffen-SS units that had survived the summer campaigns were withdrawn from the front line to refit. Two of them, the 9th SS and 10th SS Panzer Divisions, did so in the Arnhem region of Holland in early September 1944. Coincidentally, on 17 September, the Allies launched in the same area Operation Market Garden, a combined airborne and land operation designed to seize control of the lower Rhine. The 9th and 10th Panzers were among the units that repulsed the attack.
In December 1944, Hitler launched the Ardennes Offensive, also known as the Battle of the Bulge, a significant counterattack against the western Allies through the Ardennes with the aim of reaching Antwerp while encircling the Allied armies in the area. The offensive began with an artillery barrage shortly before dawn on 16 December. Spearheading the attack were two panzer armies composed largely of Waffen-SS divisions. The battlegroups found advancing through the forests and wooded hills of the Ardennes difficult in the winter weather, but they initially made good progress in the northern sector. They soon encountered strong resistance from the US 2nd and 99th Infantry Divisions. By 23 December, the weather improved enough for Allied air forces to attack the German forces and their supply columns, causing fuel shortages. In increasingly difficult conditions, the German advance slowed and was stopped. Hitler's failed offensive cost 700 tanks and most of their remaining mobile forces in the west, as well as most of their irreplaceable reserves of manpower and materiel.

During the battle, SS-"Obersturmbannführer" Joachim Peiper left a path of destruction, which included Waffen-SS soldiers under his command murdering American POWs and unarmed Belgian civilians in the Malmedy massacre. Captured SS soldiers who were part of "Kampfgruppe Peiper" were tried during the Malmedy massacre trial following the war for this massacre and several others in the area. Many of the perpetrators were sentenced to hang, but the sentences were commuted. Peiper was imprisoned for eleven years for his role in the killings.

In the east, the Red Army resumed its offensive on 12 January 1945. German forces were outnumbered twenty to one in aircraft, eleven to one in infantry, and seven to one in tanks on the Eastern Front. By the end of the month, the Red Army had made bridgeheads across the Oder, the last geographic obstacle before Berlin. The western Allies continued to advance as well, but not as rapidly as the Red Army. The Panzer Corps conducted a successful defensive operation on 17–24 February at the Hron River, stalling the Allied advance towards Vienna. The 1st and 2nd SS Panzer Corps made their way towards Austria, but were slowed by damaged railways.

Budapest fell on 13 February. Hitler ordered Dietrich's 6th Panzer Army to move into Hungary to protect the Nagykanizsa oilfields and refineries, which he deemed the most strategically valuable fuel reserves on the Eastern Front. "Frühlingserwachsen" (Operation Spring Awakening), the final German offensive in the east, took place in early March. German forces attacked near Lake Balaton, with 6th Panzer Army advancing north towards Budapest and 2nd Panzer Army moving east and south. Dietrich's forces at first made good progress, but as they drew near the Danube, the combination of muddy terrain and strong Soviet resistance brought them to a halt. By 16 March the battle was lost. Enraged by the defeat, Hitler ordered the Waffen-SS units involved to remove their cuff titles as a mark of disgrace. Dietrich refused to carry out the order.

By this time, on both the Eastern and Western Front, the activities of the SS were becoming clear to the Allies, as the concentration and extermination camps were being overrun. Allied troops were filled with disbelief and repugnance at the evidence of Nazi brutality in the camps.

On 9 April 1945 Königsberg fell to the Red Army, and on 13 April Dietrich's SS unit was forced out of Vienna. The Battle of Berlin began at 03:30 on 16 April with a massive artillery barrage. Within the week, fighting was taking place inside the city. Among the many elements defending Berlin were French, Latvian, and Scandinavian Waffen-SS troops. Hitler, now living in the "Führerbunker" under the Reich Chancellery, still hoped that his remaining SS soldiers could rescue the capital. In spite of the hopelessness of the situation, members of the SS patrolling the city continued to shoot or hang soldiers and civilians for what they considered to be acts of cowardice or defeatism. The Berlin garrison surrendered on 2 May, two days after Hitler committed suicide. As members of SS expected little mercy from the Red Army, they attempted to move westward to surrender to the western Allies instead.

Heydrich held the title of "Chef der Sicherheitspolizei und des SD" (Chief of the Security Police and SD) until 27 September 1939, when he became chief of the newly established Reich Main Security Office (RSHA). From that point forward, the RSHA was in charge of SS security services. It had under its command the SD, Kripo, and Gestapo, as well as several offices to handle finance, administration, and supply. Heinrich Müller, who had been chief of operations for the Gestapo, was appointed Gestapo chief at this time. Arthur Nebe was chief of the Kripo, and the two branches of SD were commanded by a series of SS officers, including Otto Ohlendorf and Walter Schellenberg. The SD was considered an elite branch of the SS, and its members were better educated and typically more ambitious than those within the ranks of the "Allgemeine" SS. Members of the SD were specially trained in criminology, intelligence, and counter-intelligence. They also gained a reputation for ruthlessness and unwavering commitment to Nazi ideology.

Heydrich was attacked in Prague on 27 May 1942 by a British-trained team of Czech and Slovak soldiers who had been sent by the Czechoslovak government-in-exile to kill him in Operation Anthropoid. He died from his injuries a week later. Himmler ran the RSHA personally until 30 January 1943, when Heydrich's positions were taken over by Ernst Kaltenbrunner.

Beginning in 1938 and throughout World War II, the SS enacted a procedure where offices and units of the SS could form smaller sub-units, known as "SS-Sonderkommandos", to carry out special tasks, including large-scale murder operations. The use of "SS-Sonderkommandos" was widespread. According to former "SS Sturmbannführer" Wilhelm Höttl, not even the SS leadership knew how many "SS-Sonderkommandos" were constantly being formed, disbanded, and reformed for various tasks, especially on the Eastern Front.

An "SS-Sonderkommando" unit led by "SS-Sturmbannführer" Herbert Lange murdered 1,201 psychiatric patients at the Tiegenhof psychiatric hospital in the Free City of Danzig, 1,100 patients in Owińska, 2,750 patients at Kościan, and 1,558 patients at Działdowo, as well as hundreds of Poles at Fort VII, where the mobile gas van and gassing bunker were developed. In 1941–42, "SS-Sonderkommando Lange" set up and managed the first extermination camp, at Chełmno, where 152,000 Jews were killed using gas vans.

After the Battle of Stalingrad in February 1943, Himmler realized that Germany would likely lose the war, and ordered the formation of " Sonderkommando" 1005, a special task force under SS-"Standartenführer" Paul Blobel. The unit's assignment was to visit mass graves on the Eastern Front to exhume bodies and burn them in an attempt to cover up the genocide. The task remained unfinished at the end of the war, and many mass graves remain unmarked and unexcavated.

The "Eichmann Sonderkommando" was a task force headed by Adolf Eichmann that arrived in Budapest on 19 March 1944, the same day that Axis forces invaded Hungary. Their task was to take a direct role in the deportation of Hungarian Jews to Auschwitz. The "SS-Sonderkommandos" enlisted the aid of antisemitic elements from the Hungarian gendarmerie and pro-German administrators from within the Hungarian Interior Ministry. Round-ups began on 16 April, and from 14 May, four trains of 3,000 Jews per day left Hungary and traveled to the camp at Auschwitz II-Birkenau, arriving along a newly built spur line that terminated a few hundred meters from the gas chambers. Between 10 and 25 percent of the people on each train were chosen as forced laborers; the rest were killed within hours of arrival. Under international pressure, the Hungarian government halted deportations on 6 July 1944, by which time over 437,000 of Hungary's 725,000 Jews had died.

The "Einsatzgruppen" had its origins in the ad hoc "Einsatzkommando" formed by Heydrich following the "Anschluss" in Austria in March 1938. Two units of "Einsatzgruppen" were stationed in the Sudetenland in October 1938. When military action turned out not to be necessary because of the Munich Agreement, the "Einsatzgruppen" were assigned to confiscate government papers and police documents. They secured government buildings, questioned senior civil servants, and arrested as many as 10,000 Czech communists and German citizens. The "Einsatzgruppen" also followed Wehrmacht troops and killed potential partisans. Similar groups were used in 1939 for the occupation of Czechoslovakia.

Hitler felt that the planned extermination of the Jews was too difficult and important to be entrusted to the military. In 1941 the "Einsatzgruppen" were sent into the Soviet Union to begin large-scale genocide of Jews, Romani people, and communists. Historian Raul Hilberg estimates that between 1941 and 1945 the "Einsatzgruppen" and related agencies killed more than two million people, including 1.3 million Jews. The largest mass shooting perpetrated by the "Einsatzgruppen" was at Babi Yar outside Kiev, where 33,771 Jews were killed in a single operation on 29–30 September 1941. In the Rumbula massacre (November–December 1941), 25,000 victims from the Riga ghetto were killed. Another mass shooting early in 1942 claimed the lives of over 10,000 Jews in Kharkov.

The last "Einsatzgruppen" were disbanded in mid-1944 (although some continued to exist on paper until 1945) due to the German retreat on both fronts and the consequent inability to continue extermination activities. Former "Einsatzgruppen" members were either assigned duties in the Waffen-SS or concentration camps. Twenty-four "Einsatzgruppen" commanders were tried for war crimes following the war.

The SS Court Main Office ("Hauptamt SS-Gericht") was an internal legal system for conducting investigations, trials, and punishment of the SS and police. It had more than 600 lawyers on staff in the main offices in Berlin and Munich. Proceedings were conducted at 38 regional SS courts throughout Germany. It was the only authority authorized to try SS personnel, except for SS members who were on active duty in the Wehrmacht (in such cases, the SS member in question was tried by a standard military tribunal). Its creation placed the SS beyond the reach of civilian legal authority. Himmler personally intervened as he saw fit regarding convictions and punishment. The historian Karl Dietrich Bracher describes this court system as one factor in the creation of the Nazi totalitarian police state, as it removed objective legal procedures, rendering citizens defenseless against the "summary justice of the SS terror."

Shortly after Hitler seized power in 1933, most horse riding associations were taken over by the SA and SS. Members received combat training to serve in the "Reiter-SS" (SS Cavalry Corps). The first SS cavalry regiment, designated "SS-Totenkopf Reitstandarte 1", was formed in September 1939. Commanded by then SS-"Standartenführer" Hermann Fegelein, the unit was assigned to Poland, where they took part in the extermination of Polish intelligentsia. Additional squadrons were added in May 1940, for a total of fourteen.

The unit was split into two regiments in December 1939, with Fegelein in charge of both. By March 1941 their strength was 3,500 men. In July 1941, they were assigned to the Pripyat swamps punitive operation, tasked with rounding up and exterminating Jews and partisans. The two regiments were amalgamated into the SS Cavalry Brigade on 31 July, twelve days after the operation started. Fegelein's final report, dated 18 September 1941, states that they killed 14,178 Jews, 1,001 partisans, and 699 Red Army soldiers, with 830 prisoners taken. The historian Henning Pieper estimates the actual number of Jews killed was closer to 23,700. The SS Cavalry Brigade took serious losses in November 1941 in the Battle of Moscow, with casualties of up to 60 percent in some squadrons. Fegelein was appointed as commander of the 8th SS Cavalry Division "Florian Geyer" on 20 April 1943. This unit saw service in the Soviet Union in attacks on partisans and civilians. In addition, SS Cavalry regiments served in Croatia and Hungary.

The SS Medical Corps were initially known as the "Sanitätsstaffel" (sanitary units). After 1931, the SS formed the headquarters office "Amt"  V as the central office for SS medical units. An SS medical academy was established in Berlin in 1938 to train Waffen-SS physicians. SS medical personnel did not often provide actual medical care; their primary responsibility was medicalized genocide. At Auschwitz, about three-quarters of new arrivals, including almost all children, women with small children, all the elderly, and all those who appeared on brief and superficial inspection by an SS doctor not to be completely fit were killed within hours of arrival. In their role as "Desinfektoren" (disinfectors), SS doctors also made selections among existing prisoners as to their fitness to work and supervised the killing of those deemed unfit. Inmates in deteriorating health were examined by SS doctors, who decided whether or not they would be able to recover in less than two weeks. Those too ill or injured to recover in that time frame were killed.

At Auschwitz, the actual delivery of gas to the victims was always handled by the SS, on the order of the supervising SS doctor. Many of the SS doctors also conducted inhumane medical experiments on camp prisoners. The most infamous SS doctor, Josef Mengele, served as a medical officer at Auschwitz under the command of Eduard Wirths of the camp's medical corps. Mengele undertook selections even when he was not assigned to do so in the hope of finding subjects for his experiments. He was particularly interested in locating sets of twins. In contrast to most of the doctors, who viewed undertaking selections as one of their most stressful and horrible duties, Mengele undertook the task with a flamboyant air, often smiling or whistling a tune. After the war, many SS doctors were charged with war crimes for their inhumane medical experiments and for their role in gas chamber selections.

The "Ahnenerbe" (Ancestral Heritage Organization) was founded in 1935 by Himmler, and became part of the SS in 1939. It was an umbrella agency for more than fifty organizations tasked with studying the German racial identity and ancient Germanic traditions and language. The agency sponsored archaeological expeditions in Germany, Scandinavia, the Middle East, Tibet, and elsewhere to search for evidence of Aryan roots, influence, and superiority. Further planned expeditions were postponed indefinitely at the start of the war.

The "SS-Frauenkorps" was an auxiliary reporting and clerical unit, which included the "SS-Helferinnenkorps" (Women Helper Corps), made up of female volunteers. Members were assigned as administrative staff and supply personnel and served in command positions and as guards at women's concentration camps. While female concentration and extermination camp guards were civilian employees of the SS, the "SS-Helferinnen" who completed training at the "Reichsschule für SS-Helferinnen" in Oberehnheim (Alsace) were members of the Waffen-SS. Like their male equivalents in the SS, females participated in atrocities against Jews, Poles, and others.

In 1942, Himmler set up the "Reichsschule für SS Helferinnen" (Reich school for SS helpers) in Oberehnheim to train women in communications so that they could free up men for combat roles. Himmler also intended to replace all female civilian employees in his service with "SS-Helferinnen" members, as they were selected and trained according to Nazi ideology. The school was closed on 22 November 1944 due to the Allied advance.

The "SS-Mannschaften" (Auxiliary-SS) were not considered regular SS members, but were conscripted from other branches of the German military, the NSDAP, SA, and the "Volkssturm" for service in concentration camps and extermination camps.

Beginning in 1940, Himmler opened up Waffen-SS recruiting to ethnic Germans that were not German citizens. In March 1941, the SS Main Office established the "Germanische Leitstelle" (Germanic Guidance Office) to establish Waffen-SS recruiting offices in Nazi-occupied Europe. The majority of the resulting foreign Waffen-SS units wore a distinctive national collar patch and preceded their SS rank titles with the prefix "Waffen" instead of SS. Volunteers from Scandinavian countries filled the ranks of two divisions, the "SS-Wiking" and "SS-Nordland". Swiss German speakers joined in substantial numbers. Belgian Flemings joined Dutchmen to form the "SS-Nederland" legion, and their Walloon compatriots joined the "SS-Wallonien". By the end of 1943 about a quarter of the SS were ethnic Germans from across Europe, and by June 1944, half the Waffen-SS were foreign nationals.
Additional Waffen-SS units were added from the Ukrainians, Albanians from Kosovo, Serbians, Croatians, Turkic, Caucasians, Cossack, and Tatars. The Ukrainians and Tatars, who had suffered persecution under Stalin, were likely motivated primarily by opposition to the Soviet government rather than ideological agreement with the SS. The exiled Grand Mufti of Jerusalem Amin al-Husseini was made an SS-"Gruppenführer" by Himmler in May 1943. He subsequently used antisemitism and anti-Serb racism to recruit a Waffen-SS division of Bosnian Muslims, the "SS-Handschar". The year-long Soviet occupation of the Baltic states at the beginning of World War II resulted in volunteers for Latvian and Estonian Waffen-SS units. The Estonian Legion had 1,280 volunteers under training by the end of 1942. Approximately 25,000 men served in the Estonian SS division, with thousands more conscripted into Police Front battalions and border guard units. Most of the Estonians were fighting primarily to regain their independence and as many as 15,000 of them died fighting alongside the Germans. In early 1944, Himmler even contacted Pohl to suggest releasing Muslim prisoners from concentration camps to supplement his SS troops.

The Indian Legion was a Wehrmacht unit formed in August 1942 chiefly from disaffected Indian soldiers of the British Indian Army captured in the North African Campaign. In August 1944 it was transferred to the auspices of the Waffen-SS as the "Indische Freiwilligen-Legion der Waffen-SS". There was also a French volunteer division, "SS-Charlemagne", which was formed in 1944 mainly from the remnants of the Legion of French Volunteers Against Bolshevism and French "Sturmbrigade".

The SS established its own symbolism, rituals, customs, ranks, and uniforms to set itself apart from other organizations. Before 1929, the SS wore the same brown uniform as the SA, with the addition of a black tie and a black cap with a "Totenkopf" (death's head) skull and bones symbol, moving to an all-black uniform in 1932. In 1935, the SS combat formations adopted a service uniform in field grey for everyday wear. The SS also developed its own field uniforms, which included reversible smocks and helmet covers printed with camouflage patterns. Uniforms were manufactured in hundreds of licensed factories, with some workers being prisoners of war performing forced labor. Many were produced in concentration camps.

Hitler and the NSDAP understood the power of emblems and insignia to influence public opinion. The stylized lightning bolt logo of the SS was chosen in 1932. The logo is a pair of runes from a set of 18 Armanen runes created by Guido von List in 1906. It is similar to the ancient Sowilō rune, which symbolizes the sun, but was renamed as "Sig" (victory) in List's iconography. The "Totenkopf" symbolized the wearer's willingness to fight unto the death, and also served to frighten the enemy.

After 1933 a career in the SS became increasingly attractive to Germany's social elite, who began joining the movement in great numbers, usually motivated by political opportunism. By 1938 about one-third of the SS leadership were members of the upper middle class. The trend reversed after the first Soviet counter-offensive of 1942.

By 1942 all activities of the SS were managed through twelve main offices.

The term "Austrian SS" is often used to describe that portion of the SS membership from Austria, but it was never a recognized branch of the SS. In contrast to SS members from other countries, who were grouped into either the Germanic-SS or the Foreign Legions of the Waffen-SS, Austrian SS members were regular SS personnel. It was technically under the command of the SS in Germany but often acted independently concerning Austrian affairs. The Austrian SS was founded in 1930 and by 1934 was acting as a covert force to bring about the "Anschluss" with Germany, which occurred in March 1938. Early Austrian SS leaders were Kaltenbrunner and Arthur Seyss-Inquart. Austrian SS members served in every branch of the SS. Political scientist David Art of Tufts University notes that Austrians constituted 8 percent of the Third Reich's population and 13 percent of the SS; he states that 40 percent of the staff and 75 percent of commanders at death camps were Austrian.

After the "Anschluss", the Austrian SS was folded into "SS-Oberabschnitt Donau". The third regiment of the "SS-Verfügungstruppe" ("Der Führer") and the fourth "Totenkopf" regiment ("Ostmark") were recruited in Austria shortly thereafter. On Heydrich's orders, mass arrests of potential enemies of the Reich began immediately after the "Anschluss". Mauthausen was the first concentration camp opened in Austria following the "Anschluss". Before the invasion of the Soviet Union, Mauthausen was the harshest of the camps in the Greater German Reich.

The Hotel Metropole was transformed into Gestapo headquarters in Vienna in April 1938. With a staff of 900 (80 percent of whom were recruited from the Austrian police), it was the largest Gestapo office outside Berlin. An estimated 50,000 people were interrogated or tortured there. The Gestapo in Vienna was headed by Franz Josef Huber, who also served as chief of the Central Agency for Jewish Emigration in Vienna. Although its de facto leaders were Adolf Eichmann and later Alois Brunner, Huber was nevertheless responsible for the mass deportation of Austrian Jews.

Following Nazi Germany's collapse, the SS ceased to exist. Numerous members of the SS, many of them still committed Nazis, remained at large in Germany and across Europe. On 21 May 1945, the British captured Himmler, who was in disguise and using a false passport. At an internment camp near Lüneburg, he committed suicide by biting down on a cyanide capsule. Several other leading members of the SS fled, but some were quickly captured. Kaltenbrunner, chief of the RSHA and the highest-ranking surviving SS main department chief upon Himmler's suicide, was captured and arrested in the Bavarian Alps. He was among the 24 defendants put on trial at the International Military Tribunal in 1945–46.

Some SS members were subject to summary execution, torture, and beatings at the hands of freed prisoners, displaced persons, or Allied soldiers. American soldiers of the 157th Regiment, who entered the concentration camp at Dachau in April 1945 and saw the human deprivation and cruelty committed by the SS, shot some of the remaining SS camp guards. On 15 April 1945, British troops entered Bergen-Belsen. They placed the SS guards on starvation rations, made them work without breaks, forced them to deal with the remaining corpses, and stabbed them with bayonets or struck them with their rifle butts if they slowed their pace. Some members of the US Army Counter Intelligence Corps delivered captured SS camp guards to displaced person camps, where they knew they would be subject to summary execution.

The Allies commenced legal proceedings against captured Nazis, establishing the International Military Tribunal at Nuremberg in 1945. The first war crimes trial of 24 prominent figures such as Hermann Göring, Albert Speer, Joachim von Ribbentrop, Alfred Rosenberg, Hans Frank, and Kaltenbrunner took place beginning in November 1945. They were accused of four counts: conspiracy, waging a war of aggression, war crimes, and crimes against humanity in violation of international law. Twelve received the death penalty, including Kaltenbrunner, who was convicted of crimes against humanity and executed on 16 October 1946. The former commandant at Auschwitz, Rudolf Höss, who testified on behalf of Kaltenbrunner and others, was tried and executed in 1947.

Additional SS trials and convictions followed. Many defendants attempted to exculpate themselves using the excuse that they were merely following superior orders, which they had to obey unconditionally as part of their sworn oath and duty. The courts did not find this to be a legitimate defense. A trial of 40 SS officers and guards from Auschwitz took place in Kraków in November 1947. Most were found guilty, and 23 received the death penalty. In addition to those tried by the Western allies, an estimated 37,000 members of the SS were tried and convicted in Soviet courts. Sentences included hangings and long terms of hard labor. Piotr Cywiński, the director of the Auschwitz-Birkenau Museum, estimates that of the 70,000 members of the SS involved in crimes in concentration camps, only about 1,650 to 1,700 were tried after the war. The International Military Tribunal declared the SS a criminal organization in 1946.

After the war, many former Nazis fled to South America, especially to Argentina, where they were welcomed by Juan Perón's regime. In the 1950s, former Dachau inmate Lothar Hermann discovered that Buenos Aires resident Ricardo Klement was, in fact, Adolf Eichmann, who had in 1948 obtained false identification and a landing permit for Argentina through an organization directed by Bishop Alois Hudal, an Austrian cleric with Nazi sympathies, then residing in Italy. Eichmann was captured in Buenos Aires on 11 May 1960 by Mossad, the Israel I intelligence agency. At his trial in Jerusalem in 1961, he was found guilty and sentenced to death by hanging. Eichmann was quoted as having stated, "I will jump into my grave laughing because the fact that I have the death of five million Jews [or Reich enemies, as he later claimed to have said] on my conscience gives me extraordinary satisfaction." Franz Stangl, the commandant of Treblinka, also escaped to South America with the assistance of Hudal's network. He was deported to Germany in 1967 and was sentenced to life in prison in 1970. He died in 1971.

Mengele, worried that his capture would mean a death sentence, fled Germany on 17 April 1949. Assisted by a network of former SS members, he traveled to Genoa, where he obtained a passport under the alias "Helmut Gregor" from the International Committee of the Red Cross. He sailed to Argentina in July. Aware that he was still a wanted man, he moved to Paraguay in 1958 and Brazil in 1960. In both instances he was assisted by former Luftwaffe pilot Hans-Ulrich Rudel. Mengele suffered a stroke while swimming and drowned in 1979.

Thousands of Nazis, including former SS members such as Trawniki guard Jakob Reimer and Circassian collaborator Tscherim Soobzokov, fled to the United States under the guise of refugees, sometimes using forged documents. Other SS men, such as Soobzokov, SD officer Wilhelm Höttl, Eichmann aide Otto von Bolschwing, and accused war criminal Theodor Saevecke, were employed by American intelligence agencies against the Soviets. As CIA officer Harry Rositzke noted, "It was a visceral business of using any bastard so long as he was anti-Communist ... The eagerness or desire to enlist collaborators means that sure, you didn't look at their credentials too closely." Similarly, the Soviets used SS personnel after the war; Operation Theo, for instance, disseminated "subversive rumours" in Allied-occupied Germany.

Simon Wiesenthal and others have speculated about the existence of a Nazi fugitive network code-named ODESSA (an acronym for "Organisation der ehemaligen SS-Angehörigen", Organization of former SS members) that allegedly helped war criminals find refuge in Latin America. British writer Gitta Sereny, who conducted interviews with SS men, considers the story untrue and attributes the escapes to postwar chaos and Hudal's Vatican-based network. While the existence of ODESSA remains unproven, Sereny notes that "there certainly were various kinds of Nazi aid organizations after the war — it would have been astonishing if there hadn't been."





</doc>
<doc id="27045" url="https://en.wikipedia.org/wiki?curid=27045" title="New Wave science fiction">
New Wave science fiction

The New Wave is a movement in science fiction produced in the 1960s and 1970s and characterized by a high degree of experimentation, both in form and in content, a "literary" or artistic sensibility, and a focus on "soft" as opposed to hard science. New Wave writers often saw themselves as part of the modernist tradition and sometimes mocked the traditions of pulp science fiction, which some of them regarded as stodgy, adolescent and poorly written.

The New Wave science fiction writers of the 1960s emphasized stylistic experimentation and literary merit over the scientific accuracy or prediction of hard science fiction writers. It was conceived as a deliberate break from the traditions of pulp science fiction (SF), which many of the New Wave writers involved considered irrelevant and unambitious. Academic Brian McHale claimed that the ambition of reaching literary status for SF writers came from its "edge" and from the emergence of postmodernism.

The most prominent source of New Wave science fiction was the magazine "New Worlds" under the editorship of Michael Moorcock, who assumed the position in 1964. Moorcock sought to use the magazine to "define a new avant-garde role" for science fiction by the use of "new literary techniques and modes of expression." It was a period marked by the emergence of a greater diversity of voices in science fiction, most notably the rise in the number of female writers, including Joanna Russ, Ursula K. Le Guin and Alice Bradley Sheldon (who wrote under the pseudonym James Tiptree, Jr.). The New Wave was also influenced by the political turmoil of the 1960s, such as the controversy over the Vietnam War, and by social trends such as the drug subculture and sexual liberation.

The term "New Wave" is borrowed from the French film movement the "nouvelle vague". Gary K. Wolfe, professor of humanities and English at Roosevelt University, identifies the introduction of the term New Wave to science fiction as occurring in 1966 in an essay for "The Magazine of Fantasy & Science Fiction" written by Judith Merril, who was indirectly yet it seems unambiguously referring to that term in order to comment on the experimental fiction that had begun to appear in the English magazine "New Worlds", after Michael Moorcock assumed editorship in 1964. However, Judith Merril denied she ever used that term.

The term 'New Wave' has been incorporated into the concept of New Wave Fabulism, "which often blend a realist or postmodern aesthetic with nonrealistic interruptions, in which alternative technologies, ontologies, social structures, or biological forms make their way in to otherwise realistic plots". New Wave Fabulism itself has been related to the slipstream literary genre, an interface between mainstream or postmodern fiction and science fiction.

The concept of a 'new wave' has been applied to science fiction in other countries, including in Arabic and Chinese science fiction.

The early proponents of] New Wave envisioned it as a pivotal rupture with the genre's past, and it was so experienced by many of science fiction's readers during the late 1960s and early 1970s. The New Wave coincided with a major change in the production and distribution of science fiction, as the pulp magazine era was replaced by the book market. During the New Wave, traditional forms of science fiction continued, and in Rob Latham's opinion, the science fiction genre had absorbed the New Wave's agenda and mostly neutralized it by the conclusion of the 1970s.

A central concern of the New Wave was a fascination with entropy – that the world (and the universe) must tend to disorder, to eventually run down to 'heat death'. Ballard provided "an explicitly cosmological vision of entropic decline of the universe in his magisterial story "The Voices of Time", which appeared in 1960. It provided a matrix of ideas that subsequent New Wave writing teased out in various contexts. Perhaps the best instance of this elaboration was Pamela Zoline's "The Heat Death of the Universe."" Like other writers for "New Worlds" Zoline uses "science-fictional and scientific language and imagery to describe perfectly 'ordinary' scenes of life", and by doing so produces "altered perceptions of reality in the reader."

The New Wave interacted with a number of themes in the 1960's and 1970s, including female sexuality and the rise of the environmental movement. J. G. Ballard's themes included alienation, social isolation, and class discrimination through social isolation. Rob Latham noted that several of J. G. Ballard's works in the 1960 (e.g., the quartet begun by the 1960 novel "The Wind from Nowhere"), engaged with the concept of eco-catastrophe, as did Disch's "The Genocides" and Ursula K. Le Guin's short novel "The World for World is Forest", with the latter, in its use of napalm on the indigenous people, also being influenced by Le Guin's perceptions of the Vietnam War, with both emphasizing anti-technocratic fatalism instead of imperial hegemony via technology, with the New Wave going on to interact with feminism, ecological activism and postcolonial struggles.

The British and American New Waves overlapped but were different. Judith Merril, "whose annual anthologies were the first heralds of the coming of the [New Wave] cult," writing in 1967 in "The Magazine of Fantasy and Science Fiction" contrasted the SF New Wave (which she here terms 'The New Thing') in England and the United States:

The noted academic writer on science fiction Edward James pointed out differences between the British and American New Waves, in that the former was, through Ballard and Moorcok, mainly associated with a specific magazine with a set programme that had little subsequent influence, while even the American writers based in London at the time, such as Samuel R. Delaney, Thomas M. Disch, and John Sladek, had their own agendas. James states the American New Wave did not even reach the status of a movement but was rather "a concatenation of talent flourishing at the same time and bringing new ideas and new standards to the writing of sf". He nonetheless notes:
Though the New Wave began in the 1960s, some of its tenets can be found in H. L. Gold's editorship of "Galaxy", a science fiction magazine which began publication in 1950. James Gunn described Gold's focus as being "not on the adventurer, the inventor, the engineer, or the scientist, but on the average citizen," and according to SF historian David Kyle, Gold's work would lead to the New Wave.

The New Wave was in part a rejection of the Golden Age of Science Fiction. Algis Budrys in 1965 wrote of the "recurrent strain in 'Golden Age' science fiction of the 1940s—the implication that sheer technological accomplishment would solve all the problems, hooray, and that all the problems were what they seemed to be on the surface". The New Wave did not define itself as a development from the science fiction which came before it, but initially reacted against it. New Wave writers did not operate as an organized group, but some of them felt the tropes of the pulp and Golden Age periods had become worn out, and should be abandoned: J. G. Ballard stated in 1962 that "science fiction should turn its back on space, on interstellar travel, extra-terrestrial life forms, (and) galactic wars", and Brian Aldiss said in "Trillion Year Spree: The History of Science Fiction" that "the props of SF are few: rocket ships, telepathy, robots, time travel...like coins, they become debased by over-circulation." Harry Harrison summarised the period by saying "old barriers were coming down, pulp taboos were being forgotten, new themes and new manners of writing were being explored".

New Wave writers began to look outside the traditional scope of science fiction for influence; some looked to the example of beat writer William S. Burroughs – New Wave authors Philip José Farmer and Barrington J. Bayley wrote pastiches of his work ("The Jungle Rot Kid on the Nod" and "The Four Colour Problem", respectively), while J. G. Ballard published an admiring essay in an issue of "New Worlds". Burroughs' use of experimentation such as the cut-up technique and his appropriation of science fiction tropes in radical ways proved the extent to which prose fiction could prove revolutionary, and some New Wave writers sought to emulate this style.

Ursula K. Le Guin, one of the writers to emerge in the 1960s, describes the transition to the New Wave era thus:

Other writers and works seen as preluding or transitioning to the New Wave include Malcolm Bradbury's "The Martian Chronicles," Walter M. Miller's 1959 "A Canticle for Leibowitz," Cyril M. Kornbluth and Frederik Pohl's anti-hyper-consumerist "The Space Merchants" (1952), Kurt Vonnegut's mocking "Player Piano" (1952) and "The Sirens of Titan" (1959), Theodore Sturgeon's humanist "More Than Human" (1953) and hermaphrodite society of "Venus Plus X" (1960), and Philip José Farmer's human-extraterrestrial sexual encounters in "The Lovers" (1952) and "Strange Relations" (1960).

There is no consensus on a precise starting point of the New Wave – Adam Roberts refers to Alfred Bester as having single-handedly invented the genre, and in the introduction to a collection of Leigh Brackett's short fiction, Michael Moorcock referred to her as one of the genre's "true godmothers". Budrys said that in New Wave writers "there are echoes ... of Philip K. Dick, Walter Miller, Jr. and, by all odds, Fritz Leiber". However, it is widely accepted among critics that the New Wave began in England with the magazine "New Worlds" and Michael Moorcock. who was appointed editor in 1964 (first issue number 142, May and June); Moorcock was editor until 1973. While the American magazines "Amazing Stories", with Cele Goldsmith as editor, and "Magazine of Fantasy & Science Fiction" had from the start printed unusually literary stories, Moorcock turned that into a concerted policy. No other science fiction magazine sought as consistently to distance itself from traditional science fiction as much as "New Worlds". By the time it ceased regular publication it had backed away from the science fiction genre itself, styling itself as an experimental literary journal. In the United States, the most concrete representation of the genre is probably the 1967 anthology "Dangerous Visions", edited by Harlan Ellison.

Under Moorcock's editorship of "New Worlds", "galactic wars went out; drugs came in; there were fewer encounters with aliens, more in the bedroom. Experimentation in prose styles became one of the orders of the day, and the baleful influence of William Burroughs often threatened to gain the upper hand." Judith Merril observed, "...this magazine [<nowiki>"</nowiki>New Worlds<nowiki>"</nowiki>] was the publishing thermometer of the trend that was dubbed "the New Wave". In the United States the trend created an intense, incredible controversy. In Britain people either found it of interest or they didn't, but in the States it was heresy on the one hand and wonderful revolution on the other."

Brooks Landon, professor of English at the University of Iowa, says of "Dangerous Visions" that itwas innovative and influential before it had any readers simply because it was the first big original anthology of SF, offering prices to its writers that were competitive with the magazines. The readers soon followed, however, attracted by 33 stories by SF writers both well-established and relatively unheard of. These writers responded to editor Harlan Ellison's call for stories that could not be published elsewhere or had never been written in the face of almost certain censorship by SF editors... [T]o SF readers, especially in the United States, "Dangerous Visions" certainly felt like a revolution... "Dangerous Visions" marks an emblematic turning point for American SF.

As an anthologist and speaker Merril with other authors advocated a reestablishment of science fiction within the literary mainstream and higher literary standards. Her "incredible controversy" is characterized by David Hartwell in the opening sentence of a book chapter entitled "New Wave: The Great War of the 1960s": "Conflict and argument are an enduring presence in the SF world, but literary politics has yielded to open warfare on the largest scale only once." The heresy was beyond the experimental and explicitly provocative as inspired by Burroughs. In all coherence with the literary "nouvelle vague" although not in close association to it, and addressing a much less restricted pool of readers, the New Wave was reversing the standard hero's attitude toward action and science. It illustrated egotism - by depriving the plot of all motivation toward a rational explanation.

In 1962 Ballard wrote:

In 1963 Moorcock wrote, "Let's have a quick look at what a lot of science fiction lacks. Briefly, these are some of the qualities I miss on the whole – passion, subtlety, irony, original characterization, original and good style, a sense of involvement in human affairs, colour, density, depth, and, on the whole, real feeling from the writer..." Roger Luckhurst pointed out that J. G. Ballard's essay of the same year, "Which Way to Inner Space?" "showed the influence of media theorist Marshall McLuhan and the 'anti-psychiatry' of R. D. Laing." Luckhurst traces the influence of both these thinkers in Ballard's fiction, in particular "The Atrocity Exhibition" (1970).

Judith Merril popularized this fiction in the United States through her edited anthology "England Swings SF: Stories of Speculative Fiction" (Doubleday 1968), although an earlier anthology (Harlan Ellison's "Dangerous Visions" [Doubleday 1967]) is a key harbinger of New Wave science fiction in the US.

The New Wave also had a political subtext:

Eric S. Raymond, looking at the New Wave with an even narrower political focus, observed:

For example, Judith Merril, "one of the most visible -- and voluble -- apostles of the New Wave in 1960s sf" remembers her return from England to the United States: "So I went home ardently looking for a revolution. I kept searching until the Chicago Democratic Convention in 1968. I went to Chicago partly to seek out a revolution, if there was one happening, and partly because my seventeen-year-old daughter … wanted to go." Merril said later, "At the end of the Convention week, the taste of America was sour in all our mouths"; she became a political refugee living in Canada by the end of the 1960s.

Roger Luckhurst disagreed with those critics (he gives the example of Thomas Clareson) who perceived the New Wave in terms of rupture, suggesting that such a model

Caution is needed when assessing any literary movement. Science fiction writer Bruce Sterling, reacting to his association with another SF movement in the 1980s, remarked, "When did the New Wave SF end? Who was the last New Wave SF writer? You can't be a New Wave SF writer today. You can recite the numbers of them: Ballard, Ellison, Spinrad, Delaney, blah, blah, blah. What about a transitional figure like Zelazny? A literary movement isn't an army. You don't wear a uniform and swear allegiance. It's just a group of people trying to develop a sensibility."

Similarly Rob Latham observed:

Bearing this proviso in mind it is still possible to sum up the New Wave in terms of rupture as is done for example by Darren Harris-Fain of Shawnee State University:

In the opening paragraph of an essay on the New Wave, Rob Latham notes that In the August 1970 issue of the SFWA Forum, a publication for Science Fiction Writers of America members, Harlan Ellison stated that the New Wave furure, which had fluorished during the late 1960s, appeared to have been "blissfully laid to rest." He claimed that there was no real conflict between writers:

Latham remarks that this analysis by Harlan Ellison "obscures Ellison's own prominent role – and that of other professional authors and editors such as Judith Merril, Michael Moorcock, Lester Del Rey, Frederik Pohl, and Donald A. Wollheim – in fomenting the conflict…"

In the early 1970s a number of writers and readers pointed out the stark differences between the winners of the Nebula Awards, which had been created in 1965 by the Science Fiction Writers of America (SWFA), and winners of the Hugo Awards, awarded by fans at the annual World Science Fiction Convention, with some arguing that this highlighted the fact that many authors had left their readers behind: "While some writers and fans continued to argue about the New Wave until the end of the 1970s – in "The World of Science Fiction, 1926–1976: The History of a Subculture", for instance, Lester Del Ray devotes several pages to castigating the movement – for the most part the controversy died down as the decade wore on."

The closing of "New Worlds" magazine in 1970 "marked the containment of New Wave experiment with the rest of the counter-culture. The various limping manifestations of New World across the 1970s… demonstrated the posthumous nature of its avant-gardism."

In an essay "The Alien Encounter" Professor Patrick Parrinder, commenting on the nature of science fiction, noted that "any meaningful act of defamiliarization can only be relative, since it is not possible for man to imagine what is utterly alien to him; the utterly alien would also be meaningless." He continues later, "Within SF, however, it is not necessary to break with the wider conventions of prose narrative in order to produce work that is validly experimental. The "New Wave" writing of the 1960s, with its fragmented and surrealistic forms, has not made a lasting impact, because it cast its net too wide. To reform SF one must challenge the conventions of the genre on their own terms.".

In a 1979 essay "The Alien Encounter" Professor Patrick Parrinder, commenting on the nature of science fiction, noted that "any meaningful act of defamiliarization can only be relative, since it is not possible for man to imagine what is utterly alien to him; the utterly alien would also be meaningless." He points out, "Within SF, however, it is not necessary to break with the wider conventions of prose narrative in order to produce work that is validly experimental. The "New Wave" writing of the 1960s, with its fragmented and surrealistic forms, has not made a lasting impact, because it cast its net too wide. To reform SF one must challenge the conventions of the genre on their own terms.".

Veteran science fiction writer Jack Williamson (1908–2006) when asked in 1991: "Did the [New] Wave's emphasis on experimentalism and its conscious efforts to make SF more 'literary' have any kind of permanent effects on the field?" replied:
Hartwell observed that "there is something efficacious in sf's marginality and always tenuous self-identity -- its ambiguous generic distinction from other literary categories -- and, perhaps more importantly, in its distinction from what has variously been called realist, mainstream, or mundane fiction." Hartwell maintained that after the New Wave, science fiction had still managed to retain this "marginality and tenuous self-identity":

Scientific accuracy was more important than literary style to Campbell, and top "Astounding" contributors Asimov, Heinlein, and L. Sprague de Camp were trained scientists and engineers. Asimov said in 1967 "I hope that when the New Wave has deposited its froth and receded, the vast and solid shore of "science" fiction will appear once more". Asimov himself was to illustrate just how that "SF shore" did indeed re-emerge, vast, solid—but changed. A biographer noted that during the 1960s

Darren Harris-Fain observed on this return to writing SF by Asimov that

Other themes dealt with in the novel are concerns for the environment and "human stupidity and the delusional belief in human superiority", both frequent topics in New Wave SF.

Commenting in 2002 on the publication of the 35th Anniversary edition of the "Dangerous Visions" anthology edited by Harlan Ellison, the critic Greg L. Johnson remarked that

Asimov agreed that "on the whole, the New Wave was a good thing". He described several "interesting side effects" of the New Wave. Non-American SF became more prominent and the genre became international phenomenon. Other changes noted were that "the New Wave encouraged more and more women to begin reading and writing science fiction…. The broadening of science fiction meant that it was approaching the 'mainstream' … in style and content. It also meant that increasing numbers of mainstream novelists were recognizing the importance of changing technology and the popularity of science fiction, and were incorporating science fiction motifs into their own novels."

Critic Rob Latham identifies three trends that linked the advent of the New Wave in the 1960s to the emergence of cyberpunk in the 1980s. He said that changes in technology as well as an economic recession constricted the market for science fiction, generating a "widespread" malaise among fans, while established writers were forced to reduce their output (or, like Isaac Asimov, shifted their emphasis to other subjects); finally, editors encouraged fresh approaches that earlier ones discouraged.

Moorcock, Ballard, and others engendered some animosity to their writings. When reviewing "", Lester del Rey described it as "the first of the New Wave-Thing movies, with the usual empty symbolism". When reviewing "", Budrys mocked Ellison's "'Repent, Harlequin!' Said the Ticktockman" and two other stories as "rudimentary social consciousness ... deep stuff" and insufficient for "an outstanding science-fiction story". Hartwell noted Budrys's "ringing scorn and righteous indignation" that year in "one of the classic diatribes against Ballard and the new mode of SF then emergent": 
Budrys in "Galaxy", when reviewing a collection of recent stories from the magazine, said in 1965 that "There is this sense in this book ... that modern science fiction reflects a dissatisfaction with things as they are, sometimes to the verge of indignation, but also retains optimism about the eventual outcome". Despite his criticism of Ballard and Aldiss ("the least talented" of the four), Budrys called them, Roger Zelazny, and Samuel R. Delany "an earthshaking new kind" of writers. Asimov said in 1967 of the New Wave, "I want science fiction. I think science fiction isn't really science fiction if it lacks science. And I think the better and truer the science, the better and truer the science fiction", but Budrys that year warned that the four would soon leave those "still reading everything from the viewpoint of the 1944 "Astounding" ... nothing but a complete collection of yellowed, crumble-edged bewilderment".

While acknowledging the New Wave's "energy, high talent and dedication", and stating that it "may in fact be the shape of tomorrow's science fiction generally — hell, it may be the shape of today's science fiction", as examples of the movement Budrys much preferred Zelazny's "This Immortal" to Thomas Dischs "The Genocides". Predicting that Zelazny's career would be more important and lasting than Disch's, he described the latter's book as "unflaggingly derivative of" the New Wave and filled with "dumb, resigned victims" who "run, hide, slither, grope and die", like Ballard's "The Drowned World" but unlike "The Moon is a Harsh Mistress" ("about people who do something about their troubles"). Writing in "The Dreams Our Stuff Is Made Of", Disch observed that "Literary movements tend to be compounded, in various proportions, of the genius of two or three genuinely original talents, some few other capable or established writers who have been co-opted or gone along for the ride, the apprentice work of epigones and wannabes, and a great deal of hype. My sense of the New Wave, with twenty-five years of hindsight, is that its irreducible nucleus was the dyad of J. G. Ballard and Michael Moorcock..."

Judith Merril's annual anthologies (1957–1968), Damon Knight's "Orbit" series, and Harlan Ellison's "Dangerous Visions" featured American writers inspired by British writers as well as British authors. The majority of stories in Ben Bova's "The Best of the Nebulas", such as Roger Zelazny's "A Rose for Ecclesiastes," are seen as being by New Ware writers or as involving New Wave techniques. Thomas M. Disch's work "The Genocides" has been seen as emblematic of the genre, as has the 1971 Disch anthology of eco-catastrophe stories "The Ruins of Earth". John Brunner's novel "Stand on Zanzibar" is also New Wave. In Robert Silverberg's "The Man in the Maze", in a reversal typical of the New Wave, Silverberg portrays a disabled man using an alien labyrinthine city to reject abled society. "The Martian Time-Slip" (1964) and other works by Philip K. Dick are viewed as New Wave.

Michael Moorcock and J. G. Ballard are considered principal writers of the New Wave. Alfred Bester was championed by New Wave writers and is seen as a major influence. Thomas M. Disch is associated with the New Wave but has also rejected his association with other "New Wave" authors: "If you mean to ask--do I feel solidarity with all writers who have ever been lumped together under that heading--certainly I do not." Critic John Clute wrote of M. John Harrison's early writing that it "...reveals its New-Wave provenance in narrative discontinuities and subheads after the fashion of J. G. Ballard". Brian Aldiss, Harlan Ellison, Robert Silverberg, Norman Spinrad, Roger Zelazny are writers whose work, though not considered New Wave at the time of publication, later became to be associated with the label. John Brunner is a primary exponent of dystopian New Wave science fiction. Of later authors, some of the work of Joanna Russ is considered to bear stylistic resemblance to New Wave. Among the stories Ellison received In "Dangerous Visions" were Philip Jose Farmer's "Riders of the Purple Wage", Norman Spinrad's "Carcinoma Angels", Samuel R. Delany's "Aye, and Gomorrah" and stories by Brian Aldiss, J. G. Ballard, John Brunner, David R. Bunch, Philip K. Dick, Sonya Dorman, Carol Emshwiller, John Sladek, Theodore Sturgeon, and Roger Zelazny.

http://www.sf-encyclopedia.com/entry/new_wave



</doc>
<doc id="27052" url="https://en.wikipedia.org/wiki?curid=27052" title="Administrative division">
Administrative division

An administrative division, unit, entity, area or region, also referred to as a subnational entity, constituent unit, or country subdivision, is a portion of a country or other region delineated for the purpose of administration. Administrative divisions are granted a certain degree of autonomy and are usually required to manage themselves through their own local governments. Countries are divided up into these smaller units to make managing their land and the affairs of their people easier. A country may be divided into provinces, states, counties, cantons or other sub-units, which, in turn, may be divided in whole or in part into municipalities, counties or others.

Administrative divisions are conceptually separate from dependent territories, with the former being an integral part of the state and the other being only under some lesser form of control. However, the term "administrative division" can include dependent territories as well as accepted administrative divisions (for example, in geographical databases).

For clarity and convenience the standard neutral reference for the largest administrative subdivision of a country is called the "first-level administrative division" or "first administrative level". Next smaller is called "second-level administrative division" or "second administrative level".

In many of the following terms originating from British cultural influence, areas of relatively low mean population density might bear a title of an entity one would expect to be either larger or smaller. There is no fixed rule, for "all politics is local" as is perhaps well demonstrated by their relative lack of systemic order. In the realm of self-government, any of these can and does occur along a stretch of road—which for the most part is passing through rural unsettled countryside. Since the terms are administrative political subdivisions of the local regional government their exact relationship and definitions are subject to home rule considerations, tradition, as well as state statute law and local governmental (administrative) definition and control. In British cultural legacy, some territorial entities began with fairly expansive counties which encompass an appreciably large area, but were divided over time into a number of smaller entities.
Within those entities are the large and small cities or towns, which may or may not be the county seat. Some of the world's larger cities culturally, if not officially, span several counties, and those crossing state or provincial boundaries have much in common culturally as well, but are rarely incorporated within the same municipal government. Many sister cities share a water boundary, which quite often serves as a border of both cities and counties. For example, Cambridge and Boston, Massachusetts appear to the casual traveler as one large city, while locally they each are quite culturally different and occupy different counties.

"General terms for these incorporated places include "municipality," "settlement," "locality," and "populated place.""


Due to variations in their use worldwide, consistency in the translation of terms from non-English to English is sometimes difficult to maintain.





</doc>
<doc id="27054" url="https://en.wikipedia.org/wiki?curid=27054" title="Service mark">
Service mark

A service mark or servicemark is a trademark used in the United States and several other countries to identify a service rather than a product.

When a service mark is federally registered, the standard registration symbol ® or "Reg U.S. Pat & TM Off" may be used (the same symbol is used to mark registered trademarks). Before it is registered, it is common practice (with some legal standing) to use the service mark symbol ℠ (a superscript SM).

The service mark symbol is mapped in Unicode as . A Unicode-capable browser is needed to display this character properly, which appears similar to "". The HTML entity is codice_1.

A service mark differs from a trademark in that the mark is used on the advertising of the service rather than on the packaging or delivery of the service, since there is generally no "package" to place the mark on, which is the practice for trademarks. For example, a private carrier can paint its service mark on its vehicles, such as on planes or buses. Personal service providers can place their service marks on their delivery vehicles, such as on the trucks of plumbers or on moving vans. However, if the service deals with communications, it is possible to use a service mark consisting of a sound (a sound trademark) in the process of delivering the service. This has been done in the case of AT&T, which uses a tone sound followed by a woman speaking the company's name to identify its long-distance service; MGM, which uses the sound of a lion's roar; and RKO Pictures, which used a Morse code signal for their motion pictures.

Under United States law, service marks have a different standard of use in order to count as a use in commerce, which is necessary to complete registration and to stop infringement by competitors. A trademark normally needs to be used on or directly in association with the sale of goods, such as on a store display. As services are not defined by a concrete product, use of a service mark on the uniforms or vehicles of service providers or in advertisements is instead accepted as a use in commerce. However, like trademarks, service marks must pass a test of distinctiveness for it to be qualified as a service mark. For example, Thrifty, Inc. attempted to submit a service mark application that described aspects of their business (uniforms, buildings, certain vehicles) as "being blue." The application was rejected for not being specific enough, and the rejection was upheld on appeal.



</doc>
<doc id="27057" url="https://en.wikipedia.org/wiki?curid=27057" title="Scott Adams">
Scott Adams

Scott Raymond Adams (born June 8, 1957) is the creator of the "Dilbert" comic strip, and the author of several nonfiction works of satire, commentary, and business.
His "Dilbert" series came to national prominence through the downsizing period in 1990s America and was then distributed worldwide. Adams worked in various roles at big businesses before he became a full-time cartoonist in 1995. He writes in a satirical, often sarcastic way about the social and psychological landscape of white-collar workers in modern business corporations.

Adams was born in 1957 in Windham, New York, the son of Paul and Virginia (née Vining) Adams. He is of half-German descent and also has English, Irish, Welsh, Scottish, Dutch, and a small amount of American Indian ancestry.

He was a fan of the "Peanuts" comics while growing up, and started drawing his own comics at age 6. He won a drawing competition at age 11.

Adams graduated valedictorian from Windham-Ashland-Jewett Central School in 1975 in a class of 39. He remained in the area and received a BA in economics from Hartwick College in 1979. He moved to California a few months after his graduation. Adams earned an MBA from the University of California, Berkeley in 1986.

Adams worked closely with telecommunications engineers at Crocker National Bank in San Francisco between 1979 and 1986. Upon joining the organization, he entered a management training program after being held at gunpoint twice in four months as a teller. Over the years, his positions included management trainee, computer programmer, budget analyst, commercial lender, product manager, and supervisor. 

Adams created "Dilbert" during this period; the name came from ex-boss Mike Goodwin. Dogbert, originally named Dildog, was loosely based on his family's deceased pet beagle Lucy. Submissions to various publications of both "Dilbert" and non-"Dilbert" comic panels failed to win publication. These included "The New Yorker" and "Playboy". An inspirational letter from a fan, however, persuaded Adams to keep trying.

He worked at Pacific Bell between 1986 and June 1995; the personalities he encountered there became the inspiration for many of his "Dilbert" characters. Adams first published "Dilbert" with United Media in 1989, while still employed at Pacific Bell. He had to draw his cartoons at 4 a.m. in order to work a full day at the company. His first paycheck for "Dilbert" was a monthly royalty check of $368.62. Gradually, "Dilbert" became more popular and was published by 100 newspapers in 1991, and 400 by 1994. Adams attributes his success to his idea of including his e-mail address in the panels, thus facilitating feedback from readers.

Adams's success grew, and he became a full-time cartoonist with "Dilbert" in 800 newspapers. In 1996, his first business book, "The Dilbert Principle", was released, expounding on his concept of the Dilbert principle.

Logitech CEO Pierluigi Zappacosta invited Adams to impersonate a management consultant, which he did wearing a wig and false mustache. He tricked Logitech managers into adopting a mission statement that Adams described as "so impossibly complicated that it has no real content whatsoever". That year, he won the National Cartoonists Society's Reuben Award for Outstanding Cartoonist of the Year, and Best Newspaper Comic Strip of 1997, the most prestigious awards in the field.

In 1998, "Dilbert" began as a TV series, but was canceled in 2000, but not before earning a Primetime Emmy Award in 1999. By 2000, the comic was in 2,000 newspapers in 57 countries and 19 languages. On June 29, 2020, Adams told his followers on Twitter that "Dilbert" had been cancelled because he was white and that the show's network, UPN, had made a decision to shift towards African American viewers, and that in his career, he'd lost two other jobs because of his racial background.

Adams was a fan of the science fiction TV series "Babylon 5", and he appeared in the season 4 episode "Moments of Transition" as a character named "Mr. Adams" who hires former head of security Michael Garibaldi to locate his megalomaniacal dog and cat. He also had a cameo in "Review", a third-season episode of the TV series "NewsRadio", in which Matthew Brock (played by Andy Dick) becomes an obsessed "Dilbert" fan. Adams is credited as "Guy in line behind Dave and Joe in first scene".

Adams was the CEO of Scott Adams Foods, Inc., makers of the Dilberito and Protein Chef. He sold off his intellectual property in this venture when the Dilberito failed in the marketplace. He also was a restaurateur but exited that business. Adams describes his failures and what he learned from them in his book "How to Fail at Almost Everything and Still Win Big".

Since late 2004, Adams has suffered from focal dystonia, which has affected his ability to draw on paper for lengthy periods. He now draws the comic on a graphics tablet. He also suffered from spasmodic dysphonia, a condition that causes the vocal cords to behave in an abnormal manner. In July 2008, he underwent surgery to reroute the nerve connections to his vocal cords, and his voice is now completely functional.

Adams was trained as a hypnotist. He credits affirmations for many of his achievements, including "Dilbert"s success and achieving a ninety-fourth percentile on a difficult qualification exam for business school, among other unlikely events. He states that the affirmations give him focus. He has described a method which he has used that he says gave him success. He pictured in his mind what he wanted, and wrote it down 15 times a day on a piece of paper.

In addition to his cartoon work, he has written two books on religion, "God's Debris" (2001), and "The Religion War" (2004). "God's Debris" lays out a theory of Pandeism, in which God blows itself up to see what will happen, which becomes the cause of our universe. In "God's Debris", Adams suggests that followers of theistic religions such as Christianity and Islam are inherently subconsciously aware that their religions are false, and that this awareness is reflected in their consistently acting like these religions, and their threats of damnation for sinners, are false. In a 2017 interview Adams said these books would be "his ultimate legacy".

Adams married Shelly Miles aboard a yacht, the Galaxy Commodore, on July 22, 2006, in the San Francisco Bay, in a ceremony conducted by the ship's captain. The two had met at a gym in Pleasanton, California, where Miles was an employee and Adams was a customer. By Miles, Adams had two step-children, Savannah and Justin, the latter of whom died of an opioid overdose involving fentanyl in 2018, at the age of 18, prompting Adams to start the service WhenHub. Adams and Miles divorced in 2014, and Adams said the two remained friends, with Miles moving only one block away after their separation.

On Christmas Day in 2019, Adams announced on his podcast that he was engaged to Kristina Basham. On July 12, 2020 Scott Adams announced on his pod show "Real Coffee With Scott Adams" that he had married Kristina Basham on July 11, 2020. Kristina Basham, a model and baker, has two daughters, and is vice president of WhenHub.

Adams has often commented on political matters, although in 2016 he wrote on his blog "I don't vote and I am not a member of a political party." In 2007, he suggested that Michael Bloomberg would make a good presidential candidate. Before the 2008 presidential election he said, "On social issues, I lean Libertarian, minus the crazy stuff", but said in December 2011 that, if he were president, he would do whatever Bill Clinton advised him to do because that "would lead to policies that are a sensible middle ground". In a blog post from September 2017, Adams described himself as being "left of Bernie, but with a preference for plans that can work". On October 17, 2012, he wrote "while I don't agree with Romney's positions on most topics, I'm endorsing him for president".

In 2015, although Adams stated that he would not endorse a candidate for the 2016 elections, he repeatedly praised Donald Trump's persuasion skills, especially on his blog, extensively detailing what he called Trump's "talent stack", the then-candidate's unusual skill set combination. Adams predicted that Trump would win the Republican nomination and the general election; in the 2016 election campaign's final weeks, except for a temporary reversal in early October, Adams repeatedly said Trump would win in a landslide victory, which would be followed by rioting.

Of the 2016 Democratic National Convention, he said the following: "If you're an undecided voter, and male, you're seeing something different. You're seeing a celebration that your role in society is permanently diminished. And it's happening in an impressive venue that was, in all likelihood, designed and built mostly by men." Adams said that he temporarily endorsed Hillary Clinton out of fear for his own life, stating that he had received direct and indirect death threats ("Where I live, in California, it is not safe to be seen as supportive of anything Trump says or does. So I fixed that."). In late September, however, Adams switched his endorsement from Clinton to Trump. Among his primary reasons for the switch were his respect for Trump's persuasion skills over Clinton's, Clinton's proposal to raise the inheritance tax, and his concerns over Clinton's health. Adams states that being labelled a 'Donald Trump apologist' ended his public speaking career and reduced his income by about 40%.

In 2020, Adams claimed that Republicans would be hunted if Joe Biden won the 2020 presidential election.

During a live broadcast on August 25, 2020, Adams listed what he believes are "satanic coincidences" with the Joe Biden 2020 presidential campaign.






Adams has received recognition for his work, including the National Cartoonist Society Reuben Award and Newspaper Comic Strip Award for 1997 for his work on "Dilbert". He had also been climbing the European Foundation for Management Development (EFMD) rankings of the 50 most influential management thinkers, placing 31st in 2001, 27th in 2003, and 12th in 2005, but fell to 21st in 2007. He did not place in 2009.

He received the NCTE George Orwell Award for Distinguished Contribution to Honesty and Clarity in Public Language for his participation in "Mission Impertinent". 

Adams has coined or popularized several words and phrases over the years, including Confusopoly (businesses that stay afloat only by intentionally misleading their customers), The Dilbert principle (a variant on the famous Peter Principle), Elbonia as shorthand for offshore work, and Pointy-Haired Boss / PHB and Induhvidual as insults.



</doc>
