<doc id="1140" url="https://en.wikipedia.org/wiki?curid=1140" title="Amplitude modulation">
Amplitude modulation

Amplitude modulation (AM) is a modulation technique used in electronic communication, most commonly for transmitting messages with a radio carrier wave. In amplitude modulation, the amplitude (signal strength) of the carrier wave is varied in proportion to that of the message signal, such as the sound level to be reproduced by a loudspeaker. This technique contrasts with angle modulation, in which either the frequency of the carrier wave is varied in frequency modulation, or its phase, as in phase modulation.

AM was the earliest modulation method used for transmitting audio in radio broadcasting. It was developed during the first quarter of the 20th century beginning with Roberto Landell de Moura and Reginald Fessenden's radiotelephone experiments in 1900. This original form of AM is sometimes called double-sideband amplitude modulation (DSBAM), because the standard method produces sidebands on either side of the carrier frequency. Single-sideband modulation uses bandpass filters to eliminate one of the sidebands and possibly the carrier signal, which improves the ratio of message power to total transmission power, reduces power handling requirements of line repeaters, and permits better bandwidth utilization of the transmission medium.

AM remains in use in many forms of communication in addition to AM broadcasting: shortwave radio, amateur radio, two-way radios, VHF aircraft radio, citizens band radio, and in computer modems in the form of QAM.

In electronics and telecommunications, modulation means varying some aspect of a continuous wave carrier signal with an information-bearing modulation waveform, such as an audio signal which represents sound, or a video signal which represents images. In this sense, the carrier wave, which has a much higher frequency than the message signal, "carries" the information. At the receiving station, the message signal is extracted from the modulated carrier by demodulation.

In amplitude modulation, the amplitude or "strength" of the carrier oscillations is varied. For example, in AM radio communication, a continuous wave radio-frequency signal (a sinusoidal carrier wave) has its amplitude modulated by an audio waveform before transmission. The audio waveform modifies the amplitude of the carrier wave and determines the "envelope" of the waveform. In the frequency domain, amplitude modulation produces a signal with power concentrated at the carrier frequency and two adjacent sidebands. Each sideband is equal in bandwidth to that of the modulating signal, and is a mirror image of the other. Standard AM is thus sometimes called "double-sideband amplitude modulation" (DSBAM). Single-sideband amplitude modulation 

A disadvantage of all amplitude modulation techniques, not only standard AM, is that the receiver amplifies and detects noise and electromagnetic interference in equal proportion to the signal. Increasing the received signal-to-noise ratio, say, by a factor of 10 (a 10 decibel improvement), thus would require increasing the transmitter power by a factor of 10. This is in contrast to frequency modulation (FM) and digital radio where the effect of such noise following demodulation is strongly reduced so long as the received signal is well above the threshold for reception. For this reason AM broadcast is not favored for music and high fidelity broadcasting, but rather for voice communications and broadcasts (sports, news, talk radio etc.).

AM is also inefficient in power usage; at least two-thirds of the power is concentrated in the carrier signal. The carrier signal contains none of the original information being transmitted (voice, video, data, etc.). However its presence provides a simple means of demodulation using envelope detection, providing a frequency and phase reference to extract the modulation from the sidebands. In some modulation systems based on AM, a lower transmitter power is required through partial or total elimination of the carrier component, however receivers for these signals are more complex because they must provide a precise carrier frequency reference signal (usually as shifted to the intermediate frequency) from a greatly reduced "pilot" carrier (in reduced-carrier transmission or DSB-RC) to use in the demodulation process. Even with the carrier totally eliminated in double-sideband suppressed-carrier transmission, carrier regeneration is possible using a Costas phase-locked loop. This does not work for single-sideband suppressed-carrier transmission (SSB-SC), leading to the characteristic "Donald Duck" sound from such receivers when slightly detuned. Single-sideband AM is nevertheless used widely in amateur radio and other voice communications because it has power and bandwidth efficiency (cutting the RF bandwidth in half compared to standard AM). On the other hand, in medium wave and short wave broadcasting, standard AM with the full carrier allows for reception using inexpensive receivers. The broadcaster absorbs the extra power cost to greatly increase potential audience.

An additional function provided by the carrier in standard AM, but which is lost in either single or double-sideband suppressed-carrier transmission, is that it provides an amplitude reference. In the receiver, the automatic gain control (AGC) responds to the carrier so that the reproduced audio level stays in a fixed proportion to the original modulation. On the other hand, with suppressed-carrier transmissions there is "no" transmitted power during pauses in the modulation, so the AGC must respond to peaks of the transmitted power during peaks in the modulation. This typically involves a so-called "fast attack, slow decay" circuit which holds the AGC level for a second or more following such peaks, in between syllables or short pauses in the program. This is very acceptable for communications radios, where compression of the audio aids intelligibility. However it is absolutely undesired for music or normal broadcast programming, where a faithful reproduction of the original program, including its varying modulation levels, is expected.

A simple form of amplitude modulation is the transmission of speech signals from the traditional analog telephone set using a common battery local loop. The direct current provided by the central office battery is a carrier with a frequency of 0 Hz, that is modulated by a microphone ("transmitter") in the telephone set according to the acoustic signal from the mouth of the speaker. The result is a varying amplitude direct current, whose AC-component is the speech signal extracted at the central office for transmission to another subscriber.

A simple form of digital amplitude modulation which can be used for transmitting binary data is on-off keying, the simplest form of "amplitude-shift keying", in which ones and zeros are represented by the presence or absence of a carrier. On-off keying is likewise used by radio amateurs to transmit Morse code where it is known as continuous wave (CW) operation, even though the transmission is not strictly "continuous." A more complex form of AM, quadrature amplitude modulation is now more commonly used with digital data, while making more efficient use of the available bandwidth.

In 1982, the International Telecommunication Union (ITU) designated the types of amplitude modulation:

Although AM was used in a few crude experiments in multiplex telegraph and telephone transmission in the late 1800s, the practical development of amplitude modulation is synonymous with the development between 1900 and 1920 of "radiotelephone" transmission, that is, the effort to send sound (audio) by radio waves. The first radio transmitters, called spark gap transmitters, transmitted information by wireless telegraphy, using different length pulses of carrier wave to spell out text messages in Morse code. They couldn't transmit audio because the carrier consisted of strings of damped waves, pulses of radio waves that declined to zero, that sounded like a buzz in receivers. In effect they were already amplitude modulated.

The first AM transmission was made by Canadian researcher Reginald Fessenden on 23 December 1900 using a spark gap transmitter with a specially designed high frequency 10 kHz interrupter, over a distance of 1 mile (1.6 km) at Cobb Island, Maryland, US. His first transmitted words were, "Hello. One, two, three, four. Is it snowing where you are, Mr. Thiessen?". The words were barely intelligible above the background buzz of the spark.

Fessenden was a significant figure in the development of AM radio. He was one of the first researchers to realize, from experiments like the above, that the existing technology for producing radio waves, the spark transmitter, was not usable for amplitude modulation, and that a new kind of transmitter, one that produced sinusoidal "continuous waves", was needed. This was a radical idea at the time, because experts believed the impulsive spark was necessary to produce radio frequency waves, and Fessenden was ridiculed. He invented and helped develop one of the first continuous wave transmitters - the Alexanderson alternator, with which he made what is considered the first AM public entertainment broadcast on Christmas Eve, 1906. He also discovered the principle on which AM is based, heterodyning, and invented one of the first detectors able to rectify and receive AM, the electrolytic detector or "liquid baretter", in 1902. Other radio detectors invented for wireless telegraphy, such as the Fleming valve (1904) and the crystal detector (1906) also proved able to rectify AM signals, so the technological hurdle was generating AM waves; receiving them was not a problem.

Early experiments in AM radio transmission, conducted by Fessenden, Valdemar Poulsen, Ernst Ruhmer, Quirino Majorana, Charles Herrold, and Lee de Forest, were hampered by the lack of a technology for amplification. The first practical continuous wave AM transmitters were based on either the huge, expensive Alexanderson alternator, developed 1906–1910, or versions of the Poulsen arc transmitter (arc converter), invented in 1903. The modifications necessary to transmit AM were clumsy and resulted in very low quality audio. Modulation was usually accomplished by a carbon microphone inserted directly in the antenna or ground wire; its varying resistance varied the current to the antenna. The limited power handling ability of the microphone severely limited the power of the first radiotelephones; many of the microphones were water-cooled.

The 1912 discovery of the amplifying ability of the Audion vacuum tube, invented in 1906 by Lee de Forest, solved these problems. The vacuum tube feedback oscillator, invented in 1912 by Edwin Armstrong and Alexander Meissner, was a cheap source of continuous waves and could be easily modulated to make an AM transmitter. Modulation did not have to be done at the output but could be applied to the signal before the final amplifier tube, so the microphone or other audio source didn't have to handle high power. Wartime research greatly advanced the art of AM modulation, and after the war the availability of cheap tubes sparked a great increase in the number of radio stations experimenting with AM transmission of news or music. The vacuum tube was responsible for the rise of AM radio broadcasting around 1920, the first electronic mass entertainment medium. Amplitude modulation was virtually the only type used for radio broadcasting until FM broadcasting began after World War 2.

At the same time as AM radio began, telephone companies such as AT&T were developing the other large application for AM: sending multiple telephone calls through a single wire by modulating them on separate carrier frequencies, called "frequency division multiplexing".

John Renshaw Carson in 1915 did the first mathematical analysis of amplitude modulation, showing that a signal and carrier frequency combined in a nonlinear device would create two sidebands on either side of the carrier frequency, and passing the modulated signal through another nonlinear device would extract the original baseband signal. His analysis also showed only one sideband was necessary to transmit the audio signal, and Carson patented single-sideband modulation (SSB) on 1 December 1915. This more advanced variant of amplitude modulation was adopted by AT&T for longwave transatlantic telephone service beginning 7 January 1927. After WW2 it was developed by the military for aircraft communication.

The carrier wave (sine wave) of frequency "f" and amplitude "A" is expressed by

The message signal, such as an audio signal that is used for modulating the carrier, is "m"("t"), and has a frequency "f", much lower than "f":

where "m" is the amplitude sensitivity, "M" is the amplitude of modulation. If "m" < 1, "(1 + m(t)/A)" is always positive for undermodulation. If "m" > 1 then overmodulation occurs and reconstruction of message signal from the transmitted signal would lead in loss of original signal. Amplitude modulation results when the carrier "c(t)" is multiplied by the positive quantity "(1 + m(t)/A)":

In this simple case "m" is identical to the modulation index, discussed below. With "m" = 0.5 the amplitude modulated signal "y"("t") thus corresponds to the top graph (labelled "50% Modulation") in figure 4.

Using prosthaphaeresis identities, "y"("t") can be shown to be the sum of three sine waves:

Therefore, the modulated signal has three components: the carrier wave "c(t)" which is unchanged in frequency, and two sidebands with frequencies slightly above and below the carrier frequency "f".

A useful modulation signal "m(t)" is usually more complex than a single sine wave, as treated above. However, by the principle of Fourier decomposition, "m(t)" can be expressed as the sum of a set of sine waves of various frequencies, amplitudes, and phases. Carrying out the multiplication of "1 + m(t)" with "c(t)" as above, the result consists of a sum of sine waves. Again, the carrier "c(t)" is present unchanged, but each frequency component of "m" at "f" has two sidebands at frequencies "f + f" and "f - f". The collection of the former frequencies above the carrier frequency is known as the upper sideband, and those below constitute the lower sideband. The modulation "m(t)" may be considered to consist of an equal mix of positive and negative frequency components, as shown in the top of Fig. 2. One can view the sidebands as that modulation "m(t)" having simply been shifted in frequency by "f" as depicted at the bottom right of Fig. 2.
The short-term spectrum of modulation, changing as it would for a human voice for instance, the frequency content (horizontal axis) may be plotted as a function of time (vertical axis), as in Fig. 3. It can again be seen that as the modulation frequency content varies, an upper sideband is generated according to those frequencies shifted "above" the carrier frequency, and the same content mirror-imaged in the lower sideband below the carrier frequency. At all times, the carrier itself remains constant, and of greater power than the total sideband power.

The RF bandwidth of an AM transmission (refer to Figure 2, but only considering positive frequencies) is twice the bandwidth of the modulating (or "baseband") signal, since the upper and lower sidebands around the carrier frequency each have a bandwidth as wide as the highest modulating frequency. Although the bandwidth of an AM signal is narrower than one using frequency modulation (FM), it is twice as wide as single-sideband techniques; it thus may be viewed as spectrally inefficient. Within a frequency band, only half as many transmissions (or "channels") can thus be accommodated. For this reason analog television employs a variant of single-sideband (known as vestigial sideband, somewhat of a compromise in terms of bandwidth) in order to reduce the required channel spacing.

Another improvement over standard AM is obtained through reduction or suppression of the carrier component of the modulated spectrum. In Figure 2 this is the spike in between the sidebands; even with full (100%) sine wave modulation, the power in the carrier component is twice that in the sidebands, yet it carries no unique information. Thus there is a great advantage in efficiency in reducing or totally suppressing the carrier, either in conjunction with elimination of one sideband (single-sideband suppressed-carrier transmission) or with both sidebands remaining (double sideband suppressed carrier). While these suppressed carrier transmissions are efficient in terms of transmitter power, they require more sophisticated receivers employing synchronous detection and regeneration of the carrier frequency. For that reason, standard AM continues to be widely used, especially in broadcast transmission, to allow for the use of inexpensive receivers using envelope detection. Even (analog) television, with a (largely) suppressed lower sideband, includes sufficient carrier power for use of envelope detection. But for communications systems where both transmitters and receivers can be optimized, suppression of both one sideband and the carrier represent a net advantage and are frequently employed.

A technique used widely in broadcast AM transmitters is an application of the Hapburg carrier, first proposed in the 1930s but impractical with the technology then available. During periods of low modulation the carrier power would be reduced and would return to full power during periods of high modulation levels. This has the effect of reducing the overall power demand of the transmitter and is most effective on speech type programmes. Various trade names are used for its implementation by the transmitter manufacturers from the late 80's onwards.

The AM modulation index is a measure based on the ratio of the modulation excursions of the RF signal to the level of the unmodulated carrier. It is thus defined as:

where formula_6 and formula_7 are the modulation amplitude and carrier amplitude, respectively; the modulation amplitude is the peak (positive or negative) change in the RF amplitude from its unmodulated value. Modulation index is normally expressed as a percentage, and may be displayed on a meter connected to an AM transmitter.

So if formula_8, carrier amplitude varies by 50% above (and below) its unmodulated level, as is shown in the first waveform, below. For formula_9, it varies by 100% as shown in the illustration below it. With 100% modulation the wave amplitude sometimes reaches zero, and this represents full modulation using standard AM and is often a target (in order to obtain the highest possible signal-to-noise ratio) but mustn't be exceeded. Increasing the modulating signal beyond that point, known as overmodulation, causes a standard AM modulator (see below) to fail, as the negative excursions of the wave envelope cannot become less than zero, resulting in distortion ("clipping") of the received modulation. Transmitters typically incorporate a limiter circuit to avoid overmodulation, and/or a compressor circuit (especially for voice communications) in order to still approach 100% modulation for maximum intelligibility above the noise. Such circuits are sometimes referred to as a vogad.

However it is possible to talk about a modulation index exceeding 100%, without introducing distortion, in the case of double-sideband reduced-carrier transmission. In that case, negative excursions beyond zero entail a reversal of the carrier phase, as shown in the third waveform below. This cannot be produced using the efficient high-level (output stage) modulation techniques (see below) which are widely used especially in high power broadcast transmitters. Rather, a special modulator produces such a waveform at a low level followed by a linear amplifier. What's more, a standard AM receiver using an envelope detector is incapable of properly demodulating such a signal. Rather, synchronous detection is required. Thus double-sideband transmission is generally "not" referred to as "AM" even though it generates an identical RF waveform as standard AM as long as the modulation index is below 100%. Such systems more often attempt a radical reduction of the carrier level compared to the sidebands (where the useful information is present) to the point of double-sideband suppressed-carrier transmission where the carrier is (ideally) reduced to zero. In all such cases the term "modulation index" loses its value as it refers to the ratio of the modulation amplitude to a rather small (or zero) remaining carrier amplitude.

Modulation circuit designs may be classified as low- or high-level (depending on whether they modulate in a low-power domain—followed by amplification for transmission—or in the high-power domain of the transmitted signal).

In modern radio systems, modulated signals are generated via digital signal processing (DSP). With DSP many types of AM are possible with software control (including DSB with carrier, SSB suppressed-carrier and independent sideband, or ISB). Calculated digital samples are converted to voltages with a digital-to-analog converter, typically at a frequency less than the desired RF-output frequency. The analog signal must then be shifted in frequency and linearly amplified to the desired frequency and power level (linear amplification must be used to prevent modulation distortion).
This low-level method for AM is used in many Amateur Radio transceivers.

AM may also be generated at a low level, using analog methods described in the next section.

High-power AM transmitters (such as those used for AM broadcasting) are based on high-efficiency class-D and class-E power amplifier stages, modulated by varying the supply voltage.

Older designs (for broadcast and amateur radio) also generate AM by controlling the gain of the transmitter's final amplifier (generally class-C, for efficiency). The following types are for vacuum tube transmitters (but similar options are available with transistors):


The simplest form of AM demodulator consists of a diode which is configured to act as envelope detector. Another type of demodulator, the product detector, can provide better-quality demodulation with additional circuit complexity.





</doc>
<doc id="1141" url="https://en.wikipedia.org/wiki?curid=1141" title="Augustin-Jean Fresnel">
Augustin-Jean Fresnel

Augustin-Jean Fresnel ( or ; ; 10 May 178814 July 1827) was a French civil engineer and physicist whose research in optics led to the almost unanimous acceptance of the wave theory of light, excluding any remnant of Newton's corpuscular theory, from the late 1830s until the end of the 19th century. He is perhaps better known for inventing the catadioptric (reflective/refractive) Fresnel lens and for pioneering the use of "stepped" lenses to extend the visibility of lighthouses, saving countless lives at sea. The simpler dioptric (purely refractive) stepped lens, first proposed by Count Buffon and independently reinvented by Fresnel, is used in screen magnifiers and in condenser lenses for overhead projectors.

By expressing Huygens's principle of secondary waves and Young's principle of interference in quantitative terms, and supposing that simple colors consist of sinusoidal waves, Fresnel gave the first satisfactory explanation of diffraction by straight edges, including the first satisfactory wave-based explanation of rectilinear propagation. Part of his argument was a proof that the addition of sinusoidal functions of the same frequency but different phases is analogous to the addition of forces with different directions. By further supposing that light waves are purely transverse, Fresnel explained the nature of polarization, the mechanism of chromatic polarization, and the transmission and reflection coefficients at the interface between two transparent isotropic media. Then, by generalizing the direction-speed-polarization relation for calcite, he accounted for the directions and polarizations of the refracted rays in doubly-refractive crystals of the "biaxial" class (those for which Huygens's secondary wavefronts are not axisymmetric). The period between the first publication of his pure-transverse-wave hypothesis, and the submission of his first correct solution to the biaxial problem, was less than a year.

Later, he coined the terms "linear polarization", "circular polarization", and "elliptical polarization", explained how optical rotation could be understood as a difference in propagation speeds for the two directions of circular polarization, and (by allowing the reflection coefficient to be complex) accounted for the change in polarization due to total internal reflection, as exploited in the Fresnel rhomb. Defenders of the established corpuscular theory could not match his quantitative explanations of so many phenomena on so few assumptions.

Fresnel had a lifelong battle with tuberculosis, to which he succumbed at the age of 39. Although he did not become a public celebrity in his lifetime, he lived just long enough to receive due recognition from his peers, including (on his deathbed) the Rumford Medal of the Royal Society of London, and his name is ubiquitous in the modern terminology of optics and waves. After the wave theory of light was subsumed by Maxwell's electromagnetic theory in the 1860s, some attention was diverted from the magnitude of Fresnel's contribution. In the period between Fresnel's unification of physical optics and Maxwell's wider unification, a contemporary authority, Humphrey Lloyd, described Fresnel's transverse-wave theory as "the noblest fabric which has ever adorned the domain of physical science, Newton's system of the universe alone excepted."

Augustin-Jean Fresnel (also called Augustin Jean or simply Augustin), born in Broglie, Normandy, on 10 May 1788, was the second of four sons of the architect Jacques Fresnel (1755–1805) and his wife Augustine, "née" Mérimée (1755–1833). In 1790, following the Revolution, Broglie became part of the département of Eure. The family moved twice – in 1789/90 to Cherbourg, and in 1794 to Jacques's home town of Mathieu, where Madame Fresnel would spend 25 years as a widow, outliving two of her sons.

The first son, Louis (1786–1809), was admitted to the École Polytechnique, became a lieutenant in the artillery, and was killed in action at Jaca, Spain, the day before his 23rd birthday. The third, Léonor (1790–1869), followed Augustin into civil engineering, succeeded him as secretary of the Lighthouse Commission, and helped to edit his collected works. The fourth, Fulgence Fresnel (1795–1855), became a noted linguist, diplomat, and orientalist, and occasionally assisted Augustin with negotiations. Léonor apparently was the only one of the four who married.

Their mother's younger brother, Jean François "Léonor" Mérimée (1757–1836), father of the writer Prosper Mérimée (1803–1870), was a paint artist who turned his attention to the chemistry of painting. He became the Permanent Secretary of the École des Beaux-Arts and (until 1814) a professor at the École Polytechnique, and was the initial point of contact between Augustin and the leading optical physicists of the day .

The Fresnel brothers were initially home-schooled by their mother. The sickly Augustin was considered the slow one, not inclined to memorization; but the popular story that he hardly began to read until the age of eight is disputed. At the age of nine or ten he was undistinguished except for his ability to turn tree-branches into toy bows and guns that worked far too well, earning himself the title "l'homme de génie" (the man of genius) from his accomplices, and a united crackdown from their elders.

In 1801, Augustin was sent to the "École Centrale" at Caen, as company for Louis. But Augustin lifted his performance: in late 1804 he was accepted into the École Polytechnique, being placed 17th in the entrance examination. As the detailed records of the École Polytechnique begin in 1808, we know little of Augustin's time there, except that he made few if any friends and – in spite of continuing poor health – excelled in drawing and geometry: in his first year he took a prize for his solution to a geometry problem posed by Adrien-Marie Legendre. Graduating in 1806, he then enrolled at the École Nationale des Ponts et Chaussées (National School of Bridges and Roads, also known as "ENPC" or "École des Ponts"), from which he graduated in 1809, entering the service of the Corps des Ponts et Chaussées as an "ingénieur ordinaire aspirant" (ordinary engineer in training). Directly or indirectly, he was to remain in the employment of the "Corps des Ponts" for the rest of his life.

Augustin Fresnel's parents were Roman Catholics of the Jansenist sect, characterized by an extreme Augustinian view of original sin. Religion took first place in the boys' home-schooling. In 1802, Mme Fresnel reportedly said:

Augustin remained a Jansenist. He indeed regarded his intellectual talents as gifts from God, and considered it his duty to use them for the benefit of others. Plagued by poor health, and determined to do his duty before death thwarted him, he shunned pleasures and worked to the point of exhaustion. According to his fellow engineer Alphonse Duleau, who helped to nurse him through his final illness, Fresnel saw the study of nature as part of the study of the power and goodness of God. He placed virtue above science and genius. Yet in his last days he needed "strength of soul," not against death alone, but against "the interruption of discoveries… of which he hoped to derive useful applications."

Jansenism is considered heretical by the Roman Catholic Church , and may be part of the explanation why Fresnel, in spite of his scientific achievements and his royalist credentials, never gained a permanent academic teaching post; his only teaching appointment was at the Athénée in the winter of 1819–20. Be that as it may, the brief article on Fresnel in the old "Catholic Encyclopedia" does not mention his Jansenism, but describes him as "a deeply religious man and remarkable for his keen sense of duty."

Fresnel was initially posted to the western département of Vendée. There, in 1811, he anticipated what became known as the Solvay process for producing soda ash, except that recycling of the ammonia was not considered. That difference may explain why leading chemists, who learned of his discovery through his uncle Léonor, eventually thought it uneconomic.

About 1812, Fresnel was sent to Nyons, in the southern département of Drôme, to assist with the imperial highway that was to connect Spain and Italy. It is from Nyons that we have the first evidence of his interest in optics. On 15 May 1814, while work was slack due to Napoleon's defeat, Fresnel wrote a ""P.S."" to his brother Léonor, saying in part:

At the end of 1814 he still had no information on the subject. (Concerning the name "Institute", note that the French "Académie des Sciences" was merged with other "académies" to form the "Institut de France" in 1795. In 1816 the "Académie des Sciences" regained its name and autonomy, but remained part of the institute.)

In March 1815, perceiving Napoleon's return from Elba as "an attack on civilization", Fresnel departed without leave, hastened to Toulouse and offered his services to the royalist resistance, but soon found himself on the sick list. Returning to Nyons in defeat, he was threatened and had his windows broken. During the Hundred Days he was placed on suspension, which he was eventually allowed to spend at his mother's house in Mathieu. There he used his enforced leisure to begin his optical experiments.

The appreciation of Fresnel's reconstruction of physical optics might be assisted by an overview of the fragmented state in which he found the subject. In this subsection, optical phenomena that were unexplained or whose explanations were disputed are named in bold type.

The corpuscular theory of light, favored by Isaac Newton and accepted by nearly all of Fresnel's seniors, easily explained rectilinear propagation: the corpuscles obviously moved very fast, so that their paths were very nearly straight. The wave theory, as developed by Christiaan Huygens in his "Treatise on Light" (1690), explained rectilinear propagation on the assumption that each point crossed by a traveling wavefront becomes the source of a secondary wavefront. Given the initial position of a traveling wavefront, any later position (according to Huygens) was the common tangent surface (envelope) of the secondary wavefronts emitted from the earlier position. As the extent of the common tangent was limited by the extent of the initial wavefront, the repeated application of Huygens's construction to a plane wavefront of limited extent (in a uniform medium) gave a straight, parallel beam. While this construction indeed predicted rectilinear propagation, it was difficult to reconcile with the common observation that wavefronts on the surface of water can bend around obstructions, and with the similar behavior of sound waves – causing Newton to maintain, to the end of his life, that if light consisted of waves it would "bend and spread every way" into the shadows.

Huygens's theory neatly explained the law of ordinary reflection and the law of ordinary refraction ("Snell's law"), provided that the secondary waves traveled slower in denser media (those of higher refractive index). The corpuscular theory, with the hypothesis that the corpuscles were subject to forces acting perpendicular to surfaces, explained the same laws equally well, albeit with the implication that light traveled "faster" in denser media; that implication was wrong, but could not be directly disproven with the technology of Newton's time or even Fresnel's time .

Similarly inconclusive was stellar aberration—that is, the apparent change in the position of a star due to the velocity of the earth across the line of sight (not to be confused with stellar parallax, which is due to the "displacement" of the earth across the line of sight). Identified by James Bradley in 1728, stellar aberration was widely taken as confirmation of the corpuscular theory. But it was equally compatible with the wave theory, as Euler noted in 1746 – tacitly assuming that the aether (the supposed wave-bearing medium) near the earth was not disturbed by the motion of the earth.

The outstanding strength of Huygens's theory was his explanation of the birefringence (double refraction) of "Iceland crystal" (transparent calcite), on the assumption that the secondary waves are spherical for the ordinary refraction (which satisfies Snell's law) and spheroidal for the "extraordinary" refraction (which does not). In general, Huygens's common-tangent construction implies that rays are "paths of least time" between successive positions of the wavefront, in accordance with Fermat's principle. In the special case of isotropic media, the secondary wavefronts must be spherical, and Huygens's construction then implies that the rays are perpendicular to the wavefront; indeed, the law of "ordinary" refraction can be separately derived from that premise, as Ignace-Gaston Pardies did before Huygens.

Although Newton rejected the wave theory, he noticed its potential to explain colors, including the colors of "thin plates" (e.g., "Newton's rings", and the colors of skylight reflected in soap bubbles), on the assumption that light consists of "periodic" waves, with the lowest frequencies (longest wavelengths) at the red end of the spectrum, and the highest frequencies (shortest wavelengths) at the violet end. In 1672 he published a heavy hint to that effect, but contemporary supporters of the wave theory failed to act on it: Robert Hooke treated light as a periodic sequence of pulses but did not use frequency as the criterion of color, while Huygens treated the waves as individual pulses without any periodicity; and Pardies died young in 1673. Newton himself tried to explain colors of thin plates using the corpuscular theory, by supposing that his corpuscles had the wavelike property of alternating between "fits of easy transmission" and "fits of easy reflection", the distance between like "fits" depending on the color and the medium and, awkwardly, on the angle of refraction or reflection into that medium. More awkwardly still, this theory required thin plates to reflect only at the back surface, although "thick" plates manifestly reflected also at the front surface. It was not until 1801 that Thomas Young, in the Bakerian Lecture for that year, cited Newton's hint, and accounted for the colors of a thin plate as the combined effect of the front and back reflections, which reinforce or cancel each other according to the "wavelength" and the thickness. Young similarly explained the colors of "striated surfaces" (e.g., gratings) as the wavelength-dependent reinforcement or cancellation of reflections from adjacent lines. He described this reinforcement or cancellation as interference.

Neither Newton nor Huygens satisfactorily explained diffraction—the blurring and fringing of shadows where, according to rectilinear propagation, they ought to be sharp. Newton, who called diffraction "inflexion", supposed that rays of light passing close to obstacles were bent ("inflected"); but his explanation was only qualitative. Huygens's common-tangent construction, without modifications, could not accommodate diffraction at all. Two such modifications were proposed by Young in the same 1801 Bakerian Lecture: first, that the secondary waves near the edge of an obstacle could diverge into the shadow, but only weakly, due to limited reinforcement from other secondary waves; and second, that diffraction by an edge was caused by interference between two rays: one reflected off the edge, and the other inflected while passing near the edge. The latter ray would be undeviated if sufficiently far from the edge, but Young did not elaborate on that case. These were the earliest suggestions that the degree of diffraction depends on wavelength. Later, in the 1803 Bakerian Lecture, Young ceased to regard inflection as a separate phenomenon, and produced evidence that diffraction fringes "inside" the shadow of a narrow obstacle were due to interference: when the light from one side was blocked, the internal fringes disappeared. But Young was alone in such efforts until Fresnel entered the field.

Huygens, in his investigation of double refraction, noticed something that he could not explain: when light passes through two similarly oriented calcite crystals at normal incidence, the ordinary ray emerging from the first crystal suffers only the ordinary refraction in the second, while the extraordinary ray emerging from the first suffers only the extraordinary refraction in the second; but when the second crystal is rotated 90° about the incident rays, the roles are interchanged, so that the ordinary ray emerging from the first crystal suffers only the extraordinary refraction in the second, and vice versa. This discovery gave Newton another reason to reject the wave theory: rays of light evidently had "sides". Corpuscles could have sides (or "poles", as they would later be called); but waves of light could not, because (so it seemed) any such waves would need to be longitudinal (with vibrations in the direction of propagation). Newton offered an alternative "Rule" for the extraordinary refraction, which rode on his authority through the 18th century, although he made "no known attempt to deduce it from any principles of optics, corpuscular or otherwise."

In 1808 the extraordinary refraction of calcite was investigated experimentally, with unprecedented accuracy, by Étienne-Louis Malus, and found to be consistent with Huygens's spheroid construction, not Newton's "Rule". Malus, encouraged by Pierre-Simon Laplace, then sought to explain this law in corpuscular terms: from the known relation between the incident and refracted ray directions, Malus derived the corpuscular velocity (as a function of direction) that would satisfy Maupertuis's "least action" principle. But, as Young pointed out, the existence of such a velocity law was guaranteed by Huygens's spheroid, because Huygens's construction leads to Fermat's principle, which becomes Maupertuis's principle if the ray speed is replaced by the reciprocal of the particle speed! The corpuscularists had not found a "force" law that would yield the alleged velocity law, except by a circular argument in which a force acting at the "surface" of the crystal inexplicably depended on the direction of the (possibly subsequent) velocity "within" the crystal. Worse, it was doubtful that any such force would satisfy the conditions of Maupertuis's principle. In contrast, Young proceeded to show that "a medium more easily compressible in one direction than in any direction perpendicular to it, as if it consisted of an infinite number of parallel plates connected by a substance somewhat less elastic" admits spheroidal longitudinal wavefronts, as Huygens supposed.

But Malus, in the midst of his experiments on double refraction, noticed something else: when a ray of light is reflected off a non-metallic surface at the appropriate angle, it behaves like "one" of the two rays emerging from a calcite crystal. It was Malus who coined the term polarization to describe this behavior, although the polarizing angle became known as Brewster's angle after its dependence on the refractive index was determined experimentally by David Brewster in 1815. Malus also introduced the term "plane of polarization". In the case of polarization by reflection, his "plane of polarization" was the plane of the incident and reflected rays; in modern terms, this is the plane "normal" to the "electric" vibration. In 1809, Malus further discovered that the intensity of light passing through "two" polarizers is proportional to the squared cosine of the angle between their planes of polarization (Malus's law), whether the polarizers work by reflection or double refraction, and that "all" birefringent crystals produce both extraordinary refraction and polarization. As the corpuscularists started trying to explain these things in terms of polar "molecules" of light, the wave-theorists had "no working hypothesis" on the nature of polarization, prompting Young to remark that Malus's observations "present greater difficulties to the advocates of the undulatory theory than any other facts with which we are acquainted."

Malus died in February 1812, at the age of 36, shortly after receiving the Rumford Medal for his work on polarization.

In August 1811, François Arago reported that if a thin plate of mica was viewed against a white polarized backlight through a calcite crystal, the two images of the mica were of complementary colors (the overlap having the same color as the background). The light emerging from the mica was ""de"polarized" in the sense that there was no orientation of the calcite that made one image disappear; yet it was not ordinary (""un"polarized") light, for which the two images would be of the same color. Rotating the calcite around the line of sight changed the colors, though they remained complementary. Rotating the mica changed the "saturation" (not the hue) of the colors. This phenomenon became known as chromatic polarization. Replacing the mica with a much thicker plate of quartz, with its faces perpendicular to the optic axis (the axis of Huygens's spheroid or Malus's velocity function), produced a similar effect, except that rotating the quartz made no difference. Arago tried to explain his observations in "corpuscular" terms.

In 1812, as Arago pursued further qualitative experiments and other commitments, Jean-Baptiste Biot reworked the same ground using a gypsum lamina in place of the mica, and found empirical formulae for the intensities of the ordinary and extraordinary images. The formulae contained two coefficients, supposedly representing colors of rays "affected" and "unaffected" by the plate – the "affected" rays being of the same color mix as those reflected by amorphous thin plates of proportional, but lesser, thickness.

Arago protested, declaring that he had made some of the same discoveries but had not had time to write them up. In fact the overlap between Arago's work and Biot's was minimal, Arago's being only qualitative and wider in scope (attempting to include polarization by reflection). But the dispute triggered a notorious falling-out between the two men.

Later that year, Biot tried to explain the observations as an oscillation of the alignment of the "affected" corpuscles at a frequency proportional to that of Newton's "fits", due to forces depending on the alignment. This theory became known as "mobile polarization". To reconcile his results with a sinusoidal oscillation, Biot had to suppose that the corpuscles emerged with one of two permitted orientations, namely the extremes of the oscillation, with probabilities depending on the phase of the oscillation. Corpuscular optics was becoming expensive on assumptions. But in 1813, Biot reported that the case of quartz was simpler: the observable phenomenon (now called optical rotation or "optical activity" or sometimes "rotary polarization") was a gradual rotation of the polarization direction with distance, and could be explained by a corresponding rotation ("not" oscillation) of the corpuscles.

Early in 1814, reviewing Biot's work on chromatic polarization, Young noted that the periodicity of the color as a function of the plate thickness – including the factor by which the period exceeded that for a reflective thin plate, and even the effect of obliquity of the plate (but not the role of polarization)—could be explained by the wave theory in terms of the different propagation times of the ordinary and extraordinary waves through the plate. But Young was then the only public defender of the wave theory.

In summary, in the spring of 1814, as Fresnel tried in vain to guess what polarization was, the corpuscularists thought that they knew, while the wave-theorists (if we may use the plural) literally had no idea. Both theories claimed to explain rectilinear propagation, but the wave explanation was overwhelmingly regarded as unconvincing. The corpuscular theory could not rigorously link double refraction to surface forces; the wave theory could not yet link it to polarization. The corpuscular theory was weak on thin plates and silent on gratings; the wave theory was strong on both, but under-appreciated. Concerning diffraction, the corpuscular theory did not yield quantitative predictions, while the wave theory had begun to do so by considering diffraction as a manifestation of interference, but had only considered two rays at a time. Only the corpuscular theory gave even a vague insight into Brewster's angle, Malus's law, or optical rotation. Concerning chromatic polarization, the wave theory explained the periodicity far better than the corpuscular theory, but had nothing to say about the role of polarization; and its explanation of the periodicity was largely ignored. And Arago had founded the study of chromatic polarization, only to lose the lead, controversially, to Biot. Such were the circumstances in which Arago first heard of Fresnel's interest in optics.

Fresnel's letters from later in 1814 reveal his interest in the wave theory, including his awareness that it explained the constancy of the speed of light and was at least compatible with stellar aberration. Eventually he compiled what he called his "rêveries" (musings) into an essay and submitted it via Léonor Mérimée to André-Marie Ampère, who did not respond directly. But on 19 December, Mérimée dined with Ampère and Arago, with whom he was acquainted through the École Polytechnique; and Arago promised to look at Fresnel's essay.

In mid 1815, on his way home to Mathieu to serve his suspension, Fresnel met Arago in Paris and spoke of the wave theory and stellar aberration. He was informed that he was trying to break down open doors (""il enfonçait des portes ouvertes""), and directed to classical works on optics.

On 12 July 1815, as Fresnel was about to leave Paris, Arago left him a note on a new topic:

Fresnel would not have ready access to these works outside Paris, and could not read English. But, in Mathieu – with a point-source of light made by focusing sunlight with a drop of honey, a crude micrometer of his own construction, and supporting apparatus made by a local locksmith – he began his own experiments. His technique was novel: whereas earlier investigators had projected the fringes onto a screen, Fresnel soon abandoned the screen and observed the fringes in space, through a lens with the micrometer at its focus, allowing more accurate measurements while requiring less light.

Later in July, after Napoleon's final defeat, Fresnel was reinstated with the advantage of having backed the winning side. He requested a two-month leave of absence, which was readily granted because roadworks were in abeyance.

On 23 September he wrote to Arago, beginning "I think I have found the explanation and the law of colored fringes which one notices in the shadows of bodies illuminated by a luminous point." In the same paragraph, however, Fresnel implicitly acknowledged doubt about the novelty of his work: noting that he would need to incur some expense in order to improve his measurements, he wanted to know "whether this is not useless, and whether the law of diffraction has not already been established by sufficiently exact experiments." He explained that he had not yet had a chance to acquire the items on his reading lists, with the apparent exception of "Young's book", which he could not understand without his brother's help.  Not surprisingly, he had retraced many of Young's steps.

In a memoir sent to the institute on 15 October 1815, Fresnel mapped the external and internal fringes in the shadow of a wire. He noticed, like Young before him, that the internal fringes disappeared when the light from one side was blocked, and concluded that "the vibrations of two rays that cross each other under a very small angle can contradict each other…" But, whereas Young took the disappearance of the internal fringes as "confirmation" of the principle of interference, Fresnel reported that it was the internal fringes that first drew his attention to the principle. To explain the diffraction pattern, Fresnel constructed the internal fringes by considering the intersections of circular wavefronts emitted from the two edges of the obstruction, and the external fringes by considering the intersections between direct waves and waves reflected off the nearer edge. For the external fringes, to obtain tolerable agreement with observation, he had to suppose that the reflected wave was inverted; and he noted that the predicted paths of the fringes were hyperbolic. In the part of the memoir that most clearly surpassed Young, Fresnel explained the ordinary laws of reflection and refraction in terms of interference, noting that if two parallel rays were reflected or refracted at other than the prescribed angle, they would no longer have the same phase in a common perpendicular plane, and every vibration would be cancelled by a nearby vibration. He noted that his explanation was valid provided that the surface irregularities were much smaller than the wavelength.

On 10 November, Fresnel sent a supplementary note dealing with Newton's rings and with gratings, including, for the first time, "transmission" gratings – although in that case the interfering rays were still assumed to be "inflected", and the experimental verification was inadequate because it used only two threads.

As Fresnel was not a member of the institute, the fate of his memoir depended heavily on the report of a single member. The reporter for Fresnel's memoir turned out to be Arago (with Poinsot as the other reviewer). On 8 November, Arago wrote to Fresnel:

Fresnel was troubled, wanting to know more precisely where he had collided with Young. Concerning the curved paths of the "colored bands", Young had noted the hyperbolic paths of the fringes in the two-source interference pattern, corresponding roughly to Fresnel's "internal" fringes, and had described the hyperbolic fringes that appear "on the screen" within rectangular shadows. He had not mentioned the curved paths of the "external" fringes of a shadow; but, as he later explained, that was because Newton had already done so. Newton evidently thought the fringes were "caustics". Thus Arago erred in his belief that the curved paths of the fringes were fundamentally incompatible with the corpuscular theory.

Arago's letter went on to request more data on the external fringes. Fresnel complied, until he exhausted his leave and was assigned to Rennes in the département of Ille-et-Vilaine. At this point Arago interceded with Gaspard de Prony, head of the École des Ponts, who wrote to Louis-Mathieu Molé, head of the Corps des Ponts, suggesting that the progress of science and the prestige of the Corps would be enhanced if Fresnel could come to Paris for a time. He arrived in March 1816, and his leave was subsequently extended through the middle of the year.

Meanwhile, in an experiment reported on 26 February 1816, Arago verified Fresnel's prediction that the internal fringes were shifted if the rays on one side of the obstacle passed through a thin glass lamina. Fresnel correctly attributed this phenomenon to the lower wave velocity in the glass. Arago later used a similar argument to explain the colors in the scintillation of stars.

Fresnel's updated memoir was eventually published in the March 1816 issue of "Annales de Chimie et de Physique", of which Arago had recently become co-editor. That issue did not actually appear until May. In March, Fresnel already had competition: Biot read a memoir on diffraction by himself and his student Claude Pouillet, containing copious data and arguing that the regularity of diffraction fringes, like the regularity of Newton's rings, must be linked to Newton's "fits". But the new link was not rigorous, and Pouillet himself would become a distinguished early adopter of the wave theory.

On 24 May 1816, Fresnel wrote to Young (in French), acknowledging how little of his own memoir was new. But in a "supplement" signed on 14 July and read the next day, Fresnel noted that the internal fringes were more accurately predicted by supposing that the two interfering rays came from some distance "outside" the edges of the obstacle. To explain this, he divided the incident wavefront at the obstacle into what we now call "Fresnel zones", such that the secondary waves from each zone were spread over half a cycle when they arrived at the observation point. The zones on one side of the obstacle largely canceled out in pairs, except the first zone, which was represented by an "efficacious ray". This approach worked for the internal fringes, but the superposition of the efficacious ray and the direct ray did "not" work for the "external" fringes.

The contribution from the "efficacious ray" was thought to be only "partly" canceled, for reasons involving the dynamics of the medium: where the wavefront was continuous, symmetry forbade oblique vibrations; but near the obstacle that truncated the wavefront, the asymmetry allowed some sideways vibration towards the geometric shadow. This argument showed that Fresnel had not (yet) fully accepted Huygens's principle, which would have permitted oblique radiation from all portions of the front.

In the same supplement, Fresnel described his well-known double mirror, comprising two flat mirrors joined at an angle of slightly less than 180°, with which he produced a two-slit interference pattern from two virtual images of the same slit. A conventional double-slit experiment required a preliminary "single" slit to ensure that the light falling on the double slit was "coherent" (synchronized). In Fresnel's version, the preliminary single slit was retained, and the double slit was replaced by the double mirror – which bore no physical resemblance to the double slit and yet performed the same function. This result (which had been announced by Arago in the March issue of the "Annales") made it hard to believe that the two-slit pattern had anything to do with corpuscles being deflected as they passed near the edges of the slits.

But 1816 was the "Year Without a Summer": crops failed; hungry farming families lined the streets of Rennes; the central government organized "charity workhouses" for the needy; and in October, Fresnel was sent back to Ille-et-Vilaine to supervise charity workers in addition to his regular road crew. According to Arago,

Fresnel's letters from December 1816 reveal his consequent anxiety. To Arago he complained of being "tormented by the worries of surveillance, and the need to reprimand…" And to Mérimée he wrote: "I find nothing more tiresome than having to manage other men, and I admit that I have no idea what I'm doing."

On 17 March 1817, the Académie des Sciences announced that diffraction would be the topic for the biannual physics "Grand Prix" to be awarded in 1819. The deadline for entries was set at 1 August 1818 to allow time for replication of experiments. Although the wording of the problem referred to rays and inflection and did not invite wave-based solutions, Arago and Ampère encouraged Fresnel to enter.

In the fall of 1817, Fresnel, supported by de Prony, obtained a leave of absence from the new head of the Corp des Ponts, Louis Becquey, and returned to Paris. He resumed his engineering duties in the spring of 1818; but from then on he was based in Paris, first on the Canal de l'Ourcq, and then (from May 1819) with the cadastre of the pavements.

On 15 January 1818, in a different context (revisited below), Fresnel showed that the addition of sinusoidal functions of the same frequency but different phases is analogous to the addition of forces with different directions. His method was similar to the phasor representation, except that the "forces" were plane vectors rather than complex numbers; they could be added, and multiplied by scalars, but not (yet) multiplied and divided by each other. The explanation was algebraic rather than geometric.

Knowledge of this method was assumed in a preliminary note on diffraction, dated 19 April 1818 and deposited on 20 April, in which Fresnel outlined the elementary theory of diffraction as found in modern textbooks. He restated Huygens's principle in combination with the superposition principle, saying that the vibration at each point on a wavefront is the sum of the vibrations that would be sent to it at that moment by all the elements of the wavefront in any of its previous positions, all elements acting separately . For a wavefront partly obstructed in a previous position, the summation was to be carried out over the unobstructed portion. In directions other than the normal to the primary wavefront, the secondary waves were weakened due to obliquity, but weakened much more by destructive interference, so that the effect of obliquity alone could be ignored. For diffraction by a straight edge, the intensity as a function of distance from the geometric shadow could then be expressed with sufficient accuracy in terms of what are now called the normalized Fresnel integrals:

The same note included a table of the integrals, for an upper limit ranging from 0 to 5.1 in steps of 0.1, computed with a mean error of 0.0003, plus a smaller table of maxima and minima of the resulting intensity.

In his final "Memoir on the diffraction of light", deposited on 29 July and bearing the Latin epigraph ""Natura simplex et fecunda"" ("Nature simple and fertile"), Fresnel slightly expanded the two tables without changing the existing figures, except for a correction to the first minimum of intensity. For completeness, he repeated his solution to "the problem of interference", whereby sinusoidal functions are added like vectors. He acknowledged the directionality of the secondary sources and the variation in their distances from the observation point, chiefly to explain why these things make negligible difference in the context, provided of course that the secondary sources do not radiate in the retrograde direction. Then, applying his theory of interference to the secondary waves, he expressed the intensity of light diffracted by a single straight edge (half-plane) in terms of integrals which involved the dimensions of the problem, but which could be converted to the normalized forms above. With reference to the integrals, he explained the calculation of the maxima and minima of the intensity (external fringes), and noted that the calculated intensity falls very rapidly as one moves into the geometric shadow. The last result, as Olivier Darrigol says, "amounts to a proof of the rectilinear propagation of light in the wave theory, indeed the first proof that a modern physicist would still accept."

For the experimental testing of his calculations, Fresnel used red light with a wavelength of 638nm, which he deduced from the diffraction pattern in the simple case in which light incident on a single slit was focused by a cylindrical lens. For a variety of distances from the source to the obstacle and from the obstacle to the field point, he compared the calculated and observed positions of the fringes for diffraction by a half-plane, a slit, and a narrow strip – concentrating on the minima, which were visually sharper than the maxima. For the slit and the strip, he could not use the previously computed table of maxima and minima; for each combination of dimensions, the intensity had to be expressed in terms of sums or differences of Fresnel integrals and calculated from the table of integrals, and the extrema had to be calculated anew. The agreement between calculation and measurement was better than 1.5% in almost every case.

Near the end of the memoir, Fresnel summed up the difference between Huygens's use of secondary waves and his own: whereas Huygens says there is light only where the secondary waves exactly agree, Fresnel says there is complete darkness only where the secondary waves exactly cancel out.

The judging committee comprised Laplace, Biot, and Poisson (all corpuscularists), Gay-Lussac (uncommitted), and Arago, who eventually wrote the committee's report. Although entries in the competition were supposed to be anonymous to the judges, Fresnel's must have been recognizable by the content. There was only one other entry, of which neither the manuscript nor any record of the author has survived. That entry (identified as "no.1") was mentioned only in the last paragraph of the judges' report, noting that the author had shown ignorance of the relevant earlier works of Young and Fresnel, used insufficiently precise methods of observation, overlooked known phenomena, and made obvious errors. In the words of John Worrall, "The competition facing Fresnel could hardly have been less stiff." We may infer that the committee had only two options: award the prize to Fresnel ("no. 2"), or withhold it.

The committee deliberated into the new year. Then Poisson, exploiting a case in which Fresnel's theory gave easy integrals, predicted that if a circular obstacle were illuminated by a point-source, there should be (according to the theory) a bright spot in the center of the shadow, illuminated as brightly as the exterior. This seems to have been intended as a "reductio ad absurdum". Arago, undeterred, assembled an experiment with an obstacle 2mm in diameter – and there, in the center of the shadow, was Poisson's spot.

The unanimous report of the committee, read at the meeting of the Académie on 15 March 1819, awarded the prize to "the memoir marked no. 2, and bearing as epigraph: "Natura simplex et fecunda"." At the same meeting, after the judgment was delivered, the president of the Académie opened a sealed note accompanying the memoir, revealing the author as Fresnel. The award was announced at the public meeting of the Académie a week later, on 22 March.

Arago's verification of Poisson's counter-intuitive prediction passed into folklore as if it had decided the prize. That view, however, is not supported by the judges' report, which gave the matter only two sentences in the penultimate paragraph. Neither did Fresnel's triumph immediately convert Laplace, Biot, and Poisson to the wave theory, for at least four reasons. First, although the professionalization of science in France had established common standards, it was one thing to acknowledge a piece of research as meeting those standards, and another thing to regard it as conclusive. Second, it was possible to interpret Fresnel's integrals as rules for combining "rays". Arago even encouraged that interpretation, presumably in order to minimize resistance to Fresnel's ideas. Even Biot began teaching the Huygens-Fresnel principle without committing himself to a wave basis. Third, Fresnel's theory did not adequately explain the mechanism of generation of secondary waves or why they had any significant angular spread; this issue particularly bothered Poisson. Fourth, the question that most exercised optical physicists at that time was not diffraction, but polarization – on which Fresnel had been working, but was yet to make his critical breakthrough.

An "emission" theory of light was one that regarded the propagation of light as the transport of some kind of matter. While the corpuscular theory was obviously an emission theory, the converse did not follow: in principle, one could be an emissionist without being a corpuscularist. This was convenient because, beyond the ordinary laws of reflection and refraction, emissionists never managed to make testable quantitative predictions from a theory of forces acting on corpuscles of light. But they "did" make quantitative predictions from the premises that rays were countable objects, which were conserved in their interactions with matter (except absorbent media), and which had particular orientations with respect to their directions of propagation. According to this framework, polarization and the related phenomena of double refraction and partial reflection involved altering the orientations of the rays and/or selecting them according to orientation, and the state of polarization of a beam (a bundle of rays) was a question of how many rays were in what orientations: in a fully polarized beam, the orientations were all the same. This approach, which Jed Buchwald has called "selectionism", was pioneered by Malus and diligently pursued by Biot.

Fresnel, in contrast, decided to introduce polarization into interference experiments.

In July or August 1816, Fresnel discovered that when a birefringent crystal produced two images of a single slit, he could "not" obtain the usual two-slit interference pattern, even if he compensated for the different propagation times. A more general experiment, suggested by Arago, found that if the two beams of a double-slit device were separately polarized, the interference pattern appeared and disappeared as the polarization of one beam was rotated, giving full interference for parallel polarizations, but no interference for perpendicular polarizations . These experiments, among others, were eventually reported in a brief memoir published in 1819 and later translated into English.

In a memoir drafted on 30 August 1816 and revised on 6 October, Fresnel reported an experiment in which he placed two matching thin laminae in a double-slit apparatus – one over each slit, with their optic axes perpendicular – and obtained two interference patterns offset in opposite directions, with perpendicular polarizations. This, in combination with the previous findings, meant that each lamina split the incident light into perpendicularly polarized components with different velocities – just like a normal (thick) birefringent crystal, and contrary to Biot's "mobile polarization" hypothesis.

Accordingly, in the same memoir, Fresnel offered his first attempt at a wave theory of chromatic polarization. When polarized light passed through a crystal lamina, it was split into ordinary and extraordinary waves (with intensities described by Malus's law), and these were perpendicularly polarized and therefore did not interfere, so that no colors were produced (yet). But if they then passed through an "analyzer" (second polarizer), their polarizations were brought into alignment (with intensities again modified according to Malus's law), and they would interfere. This explanation, by itself, predicts that if the analyzer is rotated 90°, the ordinary and extraordinary waves simply switch roles, so that if the analyzer takes the form of a calcite crystal, the two images of the lamina should be of the same hue (this issue is revisited below). But in fact, as Arago and Biot had found, they are of complementary colors. To correct the prediction, Fresnel proposed a phase-inversion rule whereby "one" of the constituent waves of "one" of the two images suffered an additional 180° phase shift on its way through the lamina. This inversion was a weakness in the theory relative to Biot's, as Fresnel acknowledged, although the rule specified which of the two images had the inverted wave. Moreover, Fresnel could deal only with special cases, because he had not yet solved the problem of superposing sinusoidal functions with arbitrary phase differences due to propagation at different velocities through the lamina.

He solved that problem in a "supplement" signed on 15 January 1818 (mentioned above). In the same document, he accommodated Malus's law by proposing an underlying law: that if polarized light is incident on a birefringent crystal with its optic axis at an angle "θ" to the "plane of polarization", the ordinary and extraordinary vibrations (as functions of time) are scaled by the factors cos"θ" and sin"θ", respectively. Although modern readers easily interpret these factors in terms of perpendicular components of a "transverse" oscillation, Fresnel did not (yet) explain them that way. Hence he still needed the phase-inversion rule. He applied all these principles to a case of chromatic polarization not covered by Biot's formulae, involving "two" successive laminae with axes separated by 45°, and obtained predictions that disagreed with Biot's experiments (except in special cases) but agreed with his own.

Fresnel applied the same principles to the standard case of chromatic polarization, in which "one" birefringent lamina was sliced parallel to its axis and placed between a polarizer and an analyzer. If the analyzer took the form of a thick calcite crystal with its axis in the plane of polarization, Fresnel predicted that the intensities of the ordinary and extraordinary images of the lamina were respectively proportional to

where formula_5 is the angle from the initial plane of polarization to the optic axis of the lamina, formula_6 is the angle from the initial plane of polarization to the plane of polarization of the final ordinary image, and formula_7 is the phase lag of the extraordinary wave relative to the ordinary wave due to the difference in propagation times through the lamina. The terms in formula_7 are the frequency-dependent terms and explain why the lamina must be "thin" in order to produce discernible colors: if the lamina is too thick, formula_9 will pass through too many cycles as the frequency varies through the visible range, and the eye (which divides the visible spectrum into only three bands) will not be able to resolve the cycles.

From these equations it is easily verified that formula_10 for all formula_11 so that the colors are complementary. Without the phase-inversion rule, there would be a "plus" sign in front of the last term in the second equation, so that the formula_7-dependent term would be the same in both equations, implying (incorrectly) that the colors were of the same hue.

These equations were included in an undated note that Fresnel gave to Biot, to which Biot added a few lines of his own. If we substitute

then Fresnel's formulae can be rewritten as

which are none other than Biot's empirical formulae of 1812, except that Biot interpreted formula_17 and formula_18 as the "unaffected" and "affected" selections of the rays incident on the lamina. If Biot's substitutions were accurate, they would imply that his experimental results were more fully explained by Fresnel's theory than by his own.

Arago delayed reporting on Fresnel's works on chromatic polarization until June 1821, when he used them in a broad attack on Biot's theory. In his written response, Biot protested that Arago's attack went beyond the proper scope of a report on the nominated works of Fresnel. But Biot also claimed that the substitutions for formula_17 and formula_20 and therefore Fresnel's expressions for formula_21 and formula_22 were empirically wrong because when Fresnel's intensities of spectral colors were mixed according to Newton's rules, the squared cosine and sine functions varied too smoothly to account for the observed sequence of colors. That claim drew a written reply from Fresnel, who disputed whether the colors changed as abruptly as Biot claimed, and whether the human eye could judge color with sufficient objectivity for the purpose. On the latter question, Fresnel pointed out that different observers may give different names to the same color. Furthermore, he said, a single observer can only compare colors side by side; and even if they are judged to be the same, the identity is of sensation, not necessarily of composition. Fresnel's oldest and strongest point – that thin crystals were subject to the same laws as thick ones and did not need or allow a separate theory – Biot left unanswered.  Arago and Fresnel were seen to have won the debate.

Moreover, by this time Fresnel had a new, simpler derivation of his equations on chromatic polarization.

In the draft memoir of 30 August 1816, Fresnel mentioned two hypotheses – one of which he attributed to Ampère – by which the non-interference of orthogonally-polarized beams could be explained if polarized light waves were "partly" transverse. But Fresnel could not develop either of these ideas into a comprehensive theory. According to his later account, both he and Ampère realized as early as September 1816 that the non-interference of orthogonally-polarized beams, together with the phase-inversion rule in chromatic polarization, would be most easily explained if the waves were "purely" transverse. But that would raise a new difficulty: as natural light seemed to be "un"polarized and its waves were therefore presumed to be longitudinal, one would need to explain how the longitudinal component of vibration disappeared on polarization, and why it did not reappear when polarized light was reflected or refracted obliquely by a glass plate.

Independently, on 12 January 1817, Young wrote to Arago (in English) noting that a transverse vibration would constitute a polarization, and that if two longitudinal waves crossed at a significant angle, they could not cancel without leaving a residual transverse vibration. Young repeated this idea in an article published in a supplement to the "Encyclopædia Britannica" in February 1818, in which he added that Malus's law would be explained if polarization consisted in a transverse motion.

Thus Fresnel, by his own testimony, may not have been the first person to suspect that light waves could have a transverse "component", or that "polarized" waves were exclusively transverse. And it was Young, not Fresnel, who first "published" the idea that polarization depends on the orientation of a transverse vibration. But these incomplete theories had not reconciled the nature of polarization with the apparent existence of "unpolarized" light; that achievement was to be Fresnel's alone.

In a note that Buchwald dates in the summer of 1818, Fresnel entertained the idea that unpolarized waves could have vibrations of the same energy and obliquity, with their orientations distributed uniformly about the wave-normal, and that the degree of polarization was the degree of "non"-uniformity in the distribution. Two pages later he noted, apparently for the first time in writing, that his phase-inversion rule and the non-interference of orthogonally-polarized beams would be easily explained if the vibrations of fully polarized waves were "perpendicular to the normal to the wave"—that is, purely transverse.

But if he could account for "lack" of polarization by averaging out the transverse component, he did not also need to assume a longitudinal component. It was enough to suppose that light waves are "purely" transverse, hence "always" polarized in the sense of having a particular transverse orientation, and that the "unpolarized" state of natural or "direct" light is due to rapid and random variations in that orientation, in which case two "coherent" portions of "unpolarized" light will still interfere because their orientations will be synchronized.

It is not known exactly when Fresnel made this last step, because there is no relevant documentation from 1820 or early 1821 (perhaps because he was too busy working on lighthouse-lens prototypes; see below). But he first "published" the idea in a paper on ""Calcul des teintes…"" ("calculation of hues…"), serialized in Arago's "Annales" for May, June, and July 1821. In the first installment, Fresnel described "direct" (unpolarized) light as "the rapid succession of systems of waves polarized in all directions", and gave the modern explanation of chromatic polarization. In the second installment, he revealed the suspicion that he and Ampère had harbored since 1816, and the difficulty it raised. He continued:

According to this new view, he wrote, ""the act of polarization consists not in creating transverse motions, but in decomposing them in two fixed, mutually perpendicular directions, and in separating the two components"".

While selectionists could insist on interpreting Fresnel's diffraction integrals in terms of discrete, countable rays, they could not do the same with his theory of polarization. For a selectionist, the state of polarization of a beam concerned the distribution of orientations over the "population" of rays, and that distribution was presumed to be static. For Fresnel, the state of polarization of a beam concerned the variation of a displacement over "time". That displacement might be constrained but was "not" static, and rays were geometric constructions, "not" countable objects. The conceptual gap between the wave theory and selectionism had become unbridgeable.

The other difficulty posed by pure transverse waves, of course, was the apparent implication that the aether was an elastic "solid", except that, unlike other elastic solids, it was incapable of transmitting longitudinal waves. The wave theory was cheap on assumptions, but its latest assumption was expensive on credulity. If that assumption was to be widely entertained, its explanatory power would need to be impressive.

In the second installment of "Calcul des teintes" (June 1821), Fresnel supposed, by analogy with sound waves, that the density of the aether in a refractive medium was inversely proportional to the square of the wave velocity, and therefore directly proportional to the square of the refractive index. For reflection and refraction at the surface between two isotropic media of different indices, Fresnel decomposed the transverse vibrations into two perpendicular components, now known as the "s" and "p" components, which are parallel to the "surface" and the "plane" of incidence, respectively; in other words, the "s" and "p" components are respectively "square" and "parallel" to the plane of incidence. For the "s" component, Fresnel supposed that the interaction between the two media was analogous to an elastic collision, and obtained a formula for what we now call the "reflectivity": the ratio of the reflected intensity to the incident intensity. The predicted reflectivity was non-zero at all angles.

The third installment (July 1821) was a short "postscript" in which Fresnel announced that he had found, by a "mechanical solution", a formula for the reflectivity of the "p" component, which predicted that "the reflectivity was zero at the Brewster angle". So polarization by reflection had been accounted for – but with the proviso that the direction of vibration in Fresnel's model was "perpendicular" to the plane of polarization as defined by Malus. (On the ensuing controversy, see "Plane of polarization".) For other angles of incidence, the technology of the time did not allow the "s" and "p" reflectivities to be measured accurately enough to test Fresnel's formulae. But the formulae could be rewritten in terms of what we now call the "reflection coefficient": the signed ratio of the reflected amplitude to the incident amplitude. Then, if the plane of polarization of the incident ray was at 45° to the plane of incidence, the tangent of the corresponding angle for the reflected ray was obtainable from the "ratio" of the two reflection coefficients, and this angle could be measured. Fresnel measured it for a range of angles of incidence, for glass and water, and the agreement between the calculated and measured angles was better than 1.5° in all cases.

Fresnel gave details of the "mechanical solution" in a memoir read to the Académie des Sciences on 7 January 1823. Conservation of energy was combined with continuity of the "tangential" vibration at the interface. The resulting formulae for the reflection coefficients and reflectivities became known as the "Fresnel equations". The reflection coefficients for the "s" and "p" polarizations are most succinctly expressed as

where formula_5 and formula_26 are the angles of incidence and refraction; these equations are known respectively as "Fresnel's sine law" and "Fresnel's tangent law". By allowing the coefficients to be "complex", Fresnel even accounted for the different phase shifts of the "s" and "p" components due to total internal reflection.

This success inspired James MacCullagh and Augustin-Louis Cauchy, beginning in 1836, to analyze reflection from metals by using the Fresnel equations with a complex refractive index. The same technique is applicable to non-metallic opaque media. With these generalizations, the Fresnel equations can predict the appearance of a wide variety of objects under illumination – for example, in computer graphics .

In a memoir dated 9 December 1822, Fresnel coined the terms "linear polarization" (French: "polarisation rectiligne") for the simple case in which the perpendicular components of vibration are in phase or 180° out of phase, "circular polarization" for the case in which they are of equal magnitude and a quarter-cycle (±90°) out of phase, and "elliptical polarization" for other cases in which the two components have a fixed amplitude ratio and a fixed phase difference. He then explained how optical rotation could be understood as a species of birefringence. Linearly-polarized light could be resolved into two circularly-polarized components rotating in opposite directions. If these components propagated at slightly different speeds, the phase difference between them – and therefore the direction of their linearly-polarized resultant – would vary continuously with distance.

These concepts called for a redefinition of the distinction between polarized and unpolarized light. Before Fresnel, it was thought that polarization could vary in direction, and in degree (e.g., due to variation in the angle of reflection off a transparent body), and that it could be a function of color (chromatic polarization), but not that it could vary in "kind". Hence it was thought that the degree of polarization was the degree to which the light could be suppressed by an analyzer with the appropriate orientation. Light that had been converted from linear to elliptical or circular polarization (e.g., by passage through a crystal lamina, or by total internal reflection) was described as partly or fully "depolarized" because of its behavior in an analyzer. "After" Fresnel, the defining feature of polarized light was that the perpendicular components of vibration had a fixed ratio of amplitudes and a fixed difference in phase. By that definition, elliptically or circularly polarized light is "fully" polarized although it cannot be fully suppressed by an analyzer alone. The conceptual gap between the wave theory and selectionism had widened again.

By 1817 it had been discovered by Brewster, but not adequately reported, that plane-polarized light was partly depolarized by total internal reflection if initially polarized at an acute angle to the plane of incidence. Fresnel rediscovered this effect and investigated it by including total internal reflection in a chromatic-polarization experiment. With the aid of his "first" theory of chromatic polarization, he found that the apparently depolarized light was a mixture of components polarized parallel and perpendicular to the plane of incidence, and that the total reflection introduced a phase difference between them. Choosing an appropriate angle of incidence (not yet exactly specified) gave a phase difference of 1/8 of a cycle (45°). Two such reflections from the "parallel faces" of "two coupled prisms" gave a phase difference of 1/4 of a cycle (90°). These findings were contained in a memoir submitted to the Académie on 10 November 1817 and read a fortnight later. An undated marginal note indicates that the two coupled prisms were later replaced by a single "parallelepiped in glass"—now known as a "Fresnel rhomb".

This was the memoir whose "supplement", dated January 1818, contained the method of superposing sinusoidal functions and the restatement of Malus's law in terms of amplitudes. In the same supplement, Fresnel reported his discovery that optical rotation could be emulated by passing the polarized light through a Fresnel rhomb (still in the form of "coupled prisms"), followed by an ordinary birefringent lamina sliced parallel to its axis, with the axis at 45° to the plane of reflection of the Fresnel rhomb, followed by a second Fresnel rhomb at 90° to the first. In a further memoir read on 30 March, Fresnel reported that if polarized light was fully "depolarized" by a Fresnel rhomb – now described as a parallelepiped – its properties were not further modified by a subsequent passage through an optically rotating medium or device.

The connection between optical rotation and birefringence was further explained in 1822, in the memoir on elliptical and circular polarization. This was followed by the memoir on reflection, read in January 1823, in which Fresnel quantified the phase shifts in total internal reflection, and thence calculated the precise angle at which a Fresnel rhomb should be cut in order to convert linear polarization to circular polarization. For a refractive index of 1.51, there were two solutions: about 48.6° and 54.6°.

When light passes through a slice of calcite cut perpendicular to its optic axis, the difference between the propagation times of the ordinary and extraordinary waves has a second-order dependence on the angle of incidence. If the slice is observed in a highly convergent cone of light, that dependence becomes significant, so that a chromatic-polarization experiment will show a pattern of concentric rings. But most minerals, when observed in this manner, show a more complicated pattern of rings involving two foci and a lemniscate curve, as if they had "two" optic axes. The two classes of minerals naturally become known as "uniaxal" and "biaxal"—or, in later literature, "uniaxial" and "biaxial".

In 1813, Brewster observed the simple concentric pattern in "beryl, emerald, ruby &c." The same pattern was later observed in calcite by Wollaston, Biot, and Seebeck.  Biot, assuming that the concentric pattern was the general case, tried to calculate the colors with his theory of chromatic polarization, and succeeded better for some minerals than for others. In 1818, Brewster belatedly explained why: seven of the twelve minerals employed by Biot had the lemniscate pattern, which Brewster had observed as early as 1812; and the minerals with the more complicated rings also had a more complicated law of refraction.

In a uniform crystal, according to Huygens's theory, the secondary wavefront that expands from the origin in unit time is the "ray-velocity surface"—that is, the surface whose "distance" from the origin in any direction is the ray velocity in that direction. In calcite, this surface is two-sheeted, consisting of a sphere (for the ordinary wave) and an oblate spheroid (for the extraordinary wave) touching each other at opposite points of a common axis—touching at the north and south poles, if we may use a geographic analogy. But according to Malus's "corpuscular" theory of double refraction, the ray velocity was proportional to the reciprocal of that given by Huygens's theory, in which case the velocity law was of the form

where formula_28 and formula_29 were the ordinary and extraordinary ray velocities "according to the corpuscular theory", and formula_30 was the angle between the ray and the optic axis. By Malus's definition, the plane of polarization of a ray was the plane of the ray and the optic axis if the ray was ordinary, or the perpendicular plane (containing the ray) if the ray was extraordinary. In Fresnel's model, the direction of vibration was normal to the plane of polarization. Hence, for the sphere (the ordinary wave), the vibration was along the lines of latitude (continuing the geographic analogy); and for the spheroid (the extraordinary wave), the vibration was along the lines of longitude.

On 29 March 1819, Biot presented a memoir in which he proposed simple generalizations of Malus's rules for a crystal with "two" axes, and reported that both generalizations seemed to be confirmed by experiment. For the velocity law, the squared sine was replaced by the "product" of the sines of the angles from the ray to the two axes ("Biot's sine law"). And for the polarization of the ordinary ray, the plane of the ray and the axis was replaced by the plane bisecting the dihedral angle between the two planes each of which contained the ray and one axis ("Biot's dihedral law"). Biot's laws meant that a biaxial crystal with axes at a small angle, cleaved in the plane of those axes, behaved nearly like a uniaxial crystal at near-normal incidence; this was fortunate because gypsum, which had been used in chromatic-polarization experiments, is biaxial.

Until Fresnel turned his attention to biaxial birefringence, it was assumed that one of the two refractions was ordinary, even in biaxial crystals. But, in a memoir submitted on 19 November 1821, Fresnel reported two experiments on topaz showing that "neither refraction" was ordinary in the sense of satisfying Snell's law; that is, neither ray was the product of spherical secondary waves.

The same memoir contained Fresnel's first attempt at the biaxial velocity law. For calcite, if we interchange the equatorial and polar radii of Huygens's oblate spheroid while preserving the polar direction, we obtain a "prolate" spheroid touching the sphere at the equator. A plane through the center/origin cuts this prolate spheroid in an ellipse whose major and minor semi-axes give the magnitudes of the extraordinary and ordinary ray velocities in the direction normal to the plane, and (said Fresnel) the directions of their respective vibrations. The direction of the optic axis is the normal to the plane for which the ellipse of intersection reduces to a "circle". So, for the biaxial case, Fresnel simply replaced the prolate spheroid with a triaxial ellipsoid, which he called the "ellipsoid of elasticity", to be sectioned by a plane in the same way. In general there would be "two" planes passing through the center of the ellipsoid and cutting it in a circle, and the normals to these planes would give "two" optic axes. From the geometry, Fresnel deduced Biot's sine law (with the ray velocities replaced by their reciprocals).

The "ellipsoid of elasticity" indeed gave the correct ray velocities, although the initial experimental verification was only approximate. But it did not give the correct directions of vibration, for the biaxial case or even for the uniaxial case, because the vibrations in Fresnel's model were tangential to the wavefront, which is "not" generally normal to the ray (for an extraordinary ray). This mistake was corrected in an "extract" that Fresnel read to the Académie a week later, on 26 November. Starting with Huygens's spheroid, Fresnel obtained the 4th-degree "surface of elasticity" which, when sectioned by a plane as above, would yield the "wave-normal velocities" for a wavefront in that plane, together with their vibration directions. For the biaxial case, he generalized the surface to allow three unequal principal dimensions. But he retained the former "ellipsoid of elasticity" as an approximation, from which he deduced Biot's dihedral law.

Fresnel's initial derivation of the "surface of elasticity" had been purely geometric, and not deductively rigorous. His first attempt at a "mechanical" derivation, contained in a "supplement" dated 13 January 1822, assumed that (i) there were three mutually perpendicular directions in which a displacement produced a reaction in the same direction, (ii) the reaction was otherwise a linear function of the displacement, and (iii) the radius of the surface in any direction was the square root of the component, "in that direction", of the reaction to a unit displacement in that direction. The last assumption recognized the requirement that if a wave was to maintain a fixed direction of propagation and a fixed direction of vibration, the reaction must not be outside the plane of those two directions.

In the same supplement, Fresnel considered how he might find, for the biaxial case, the secondary wavefront that expands from the origin in unit time – that is, the surface that reduces to Huygens's sphere and spheroid in the uniaxial case. He noted that this "wave surface" ("surface de l'onde") is tangential to all possible plane wavefronts that could have crossed the origin one unit of time ago, and he listed the mathematical conditions that it must satisfy. But he doubted the feasibility of deriving the surface "from" those conditions.

In a "second supplement", Fresnel eventually exploited two related facts: (i) the "wave surface" was also the ray-velocity surface, which could be obtained by sectioning what he had mistakenly called the "ellipsoid of elasticity"; and (ii) the "wave surface" intersected each plane of symmetry of the ellipsoid in two curves: a circle and an ellipse. Thus he found that the "wave surface" is described by the 4th-degree equation

where formula_32 and formula_33 are the propagation speeds in directions normal to the coordinate axes for vibrations along the axes (the ray and wave-normal speeds being the same in those special cases). Later commentators put the equation in the more compact and memorable form

Earlier in the "second supplement", Fresnel modeled the medium as an array of point-masses and found that the force-displacement relation was described by a symmetric matrix, confirming the existence of three mutually perpendicular axes on which the displacement produced a parallel force. Later in the document, he noted that in a biaxial crystal, unlike a uniaxial crystal, the directions in which there is only one wave-normal velocity are not the same as those in which there is only one ray velocity. Nowadays we refer to the former directions as the "optic" axes or "binormal" axes, and the latter as the "ray" axes or "biradial" axes .

Fresnel's "second supplement" was signed on 31 March 1822 and submitted the next day – less than a year after the publication of his pure-transverse-wave hypothesis, and just less than a year after the demonstration of his prototype eight-panel lighthouse lens .

Fresnel still wanted a mechanical foundation for the surface of elasticity, and a rigorous treatment of Biot's dihedral law. He attended to these matters in his "second memoir" on double refraction, a consolidation and re-ordering of his work on the subject, published in the "Recueils" of the Académie des Sciences for 1824; this was not actually printed until late 1827, a few months after his death. Having confirmed the three perpendicular axes on which a displacement produced a parallel reaction, and thence constructed the surface of elasticity, he showed that Biot's dihedral law is exact provided that the binormals are taken as the optic axes, and the wave-normal direction as the direction of propagation.

As early as 1822, Fresnel discussed his perpendicular axes with Cauchy. Acknowledging Fresnel's influence, Cauchy went on to develop the first rigorous theory of elasticity of non-isotropic solids (1827), hence the first rigorous theory of transverse waves therein (1830) — which he promptly tried to apply to optics. The ensuing difficulties drove a long competitive effort to find an accurate mechanical model of the aether. Fresnel's own model was not dynamically rigorous; for example, it deduced the reaction to a shear strain by considering the displacement of one particle while all others were fixed, and it assumed that the stiffness determined the wave velocity as in a stretched string, whatever the direction of the wave-normal. But it was enough to enable the wave theory to do what selectionist theory could not: generate testable formulae covering a comprehensive range of optical phenomena, from "mechanical" assumptions.

In 1815, Brewster reported that colors appear when a slice of isotropic material, placed between crossed polarizers, is mechanically stressed. Brewster himself immediately and correctly attributed this phenomenon to stress-induced birefringence — now known as "photoelasticity".

In a memoir read in September 1822, Fresnel announced that he had verified Brewster's diagnosis more directly, by compressing a combination of glass prisms so severely that one could actually see a double image through it. In his experiment, Fresnel lined up seven 45°-90°-45° prisms, short side to short side, with their 90° angles pointing in alternating directions. Two half-prisms were added at the ends to make the whole assembly rectangular. The prisms were separated by thin films of turpentine ("térébenthine") to suppress internal reflections, allowing a clear line of sight along the row. When the four prisms with similar orientations were compressed in a vise, from apex to base across the line of sight, an object viewed through the assembly produced two images with perpendicular polarizations, with an apparent spacing of 1.5mm at one metre.

At the end of that memoir, Fresnel predicted that one could use an analogous arrangement of prisms, without compression, to verify that optical rotation is a form of birefringence. If the prisms were cut from monocrystalline quartz with their optic axes aligned along the row, and with alternating directions of optical rotation, an object seen by looking along the common optic axis would give two images, which would seem unpolarized if viewed through an analyzer alone; but if viewed through a Fresnel rhomb, they would be polarized at ±45° to the plane of reflection (because they would initially be circularly polarized in opposite directions). In the memoir of December 1822, in which he introduced the term "circular polarization", he reported that he had confirmed this prediction. To obtain a visible separation of the images, he needed only one 14°-152°-14° prism and two half-prisms; he merely remarked in passing that one could increase the separation by increasing the number of prisms.

For the supplement to Riffault's translation of Thomson's "System of Chemistry", Fresnel was chosen to contribute the article on light. The resulting 137-page essay, titled "De la Lumière" ("On Light"), was apparently finished in June 1821 and published by February 1822. With sections covering the nature of light, diffraction, thin-film interference, reflection and refraction, double refraction and polarization, chromatic polarization, and modification of polarization by reflection, it made a comprehensive case for the wave theory to a readership that was not restricted to physicists.

To examine Fresnel's first memoir and supplements on double refraction, the Académie des Sciences appointed Ampère, Arago, Fourier, and Poisson. Their report, of which Arago was clearly the main author, was delivered at the meeting of 19 August 1822. Then, in the words of Émile Verdet, as translated by Ivor Grattan-Guinness:

Whether Laplace was announcing his conversion to the wave theory – at the age of 73 – is uncertain. Grattan-Guinness entertained the idea. Buchwald, noting that Arago failed to explain that the "ellipsoid of elasticity" did not give the correct planes of polarization, suggests that Laplace may have merely regarded Fresnel's theory as a successful generalization of Malus's ray-velocity law, embracing Biot's laws.

In the following year, Poisson, who did not sign Arago's report, disputed the possibility of transverse waves in the aether. Starting from assumed equations of motion of a fluid medium, he noted that they did not give the correct results for partial reflection and double refraction – as if that were Fresnel's problem rather than his own – and that the predicted waves, even if they were initially transverse, became more longitudinal as they propagated. In reply Fresnel noted, "inter alia", that the equations in which Poisson put so much faith did not even predict viscosity. The implication was clear: given that the behavior of light had not been satisfactorily explained except by transverse waves, it was not the responsibility of the wave-theorists to abandon transverse waves in deference to pre-conceived notions about the aether; rather, it was the responsibility of the aether modelers to produce a model that accommodated transverse waves. According to Robert H. Silliman, Poisson eventually accepted the wave theory shortly before his death in 1840.

Among the French, Poisson's reluctance was an exception. According to Eugene Frankel, "in Paris no debate on the issue seems to have taken place after 1825. Indeed, almost the entire generation of physicists and mathematicians who came to maturity in the 1820s – Pouillet, Savart, Lamé, Navier, Liouville, Cauchy – seem to have adopted the theory immediately." Fresnel's other prominent French opponent, Biot, appeared to take a neutral position in 1830, and eventually accepted the wave theory – possibly by 1846 and certainly by 1858.

In 1826, the British astronomer John Herschel, who was working on a book-length article on light for the "Encyclopædia Metropolitana", addressed three questions to Fresnel concerning double refraction, partial reflection, and their relation to polarization. The resulting article, titled simply "Light", was highly sympathetic to the wave theory, although not entirely free of selectionist language. It was circulating privately by 1828 and was published in 1830. Meanwhile, Young's translation of Fresnel's "De la Lumière" was published in installments from 1827 to 1829. George Biddell Airy, the former Lucasian Professor at Cambridge and future Astronomer Royal, unreservedly accepted the wave theory by 1831. In 1834 he famously calculated the diffraction pattern of a circular aperture from the wave theory, thereby explaining the limited angular resolution of a perfect telescope . By the end of the 1830s, the only prominent British physicist who held out against the wave theory was Brewster, whose objections included the difficulty of explaining photochemical effects and (in his opinion) dispersion.

A German translation of "De la Lumière" was published in installments in 1825 and 1828. The wave theory was adopted by Fraunhofer in the early 1820s and by Franz Ernst Neumann in the 1830s, and then began to find favor in German textbooks.

The economy of assumptions under the wave theory was emphasized by William Whewell in his "History of the Inductive Sciences", first published in 1837. In the corpuscular system, "every new class of facts requires a new supposition," whereas in the wave system, a hypothesis devised in order to explain one phenomenon is then found to explain or predict others. In the corpuscular system there is "no unexpected success, no happy coincidence, no convergence of principles from remote quarters"; but in the wave system, "all tends to unity and simplicity."

Hence, in 1850, when Foucault and Fizeau found by experiment that light travels more slowly in water than in air, in accordance with the wave explanation of refraction and contrary to the corpuscular explanation, the result came as no surprise.

Fresnel was not the first person to focus a lighthouse beam using a lens. That distinction apparently belongs to the London glass-cutter Thomas Rogers, who proposed the idea to Trinity House in 1788. The first Rogers lenses, 53cm in diameter and 14cm thick at the center, were installed at the Old Lower Lighthouse at Portland Bill in 1789. Further samples followed at Howth Baily, North Foreland, and at least four other locations. But much of the light was wasted by absorption in the glass.

Nor was Fresnel the first to suggest replacing a convex lens with a series of concentric annular prisms, to reduce weight and absorption. In 1748, Count Buffon proposed grinding such prisms as steps in a single piece of glass. In 1790 (although secondary sources give the date as 1773 or 1788), the Marquis de Condorcet suggested that it would be easier to make the annular sections separately and assemble them on a frame; but even that was impractical at the time. These designs were intended not for lighthouses, but for burning glasses. Brewster, however, proposed a system similar to Condorcet's in 1811, and by 1820 was advocating its use in British lighthouses.

Meanwhile, on 21 June 1819, Fresnel was temporarily seconded by the "Commission des Phares" (Commission of Lighthouses) on the recommendation of Arago (a member of the commission since 1813), to review possible improvements in lighthouse illumination. The commission had been established by Napoleon in 1811, and placed under the Corps des Ponts – Fresnel's employer.

By the end of August 1819, unaware of the Buffon-Condorcet-Brewster proposal, Fresnel made his first presentation to the commission, recommending what he called "lentilles à échelons" (lenses by steps) to replace the reflectors then in use, which reflected only about half of the incident light. One of the assembled commissioners, Jacques Charles, recalled Buffon's suggestion. Fresnel was disappointed to discover that he had again "broken through an open door". But, whereas Buffon's version was biconvex and in one piece, Fresnel's was plano-convex and made of multiple prisms for easier construction. With an official budget of 500 francs, Fresnel approached three manufacturers. The third, François Soleil, found a way to remove defects by reheating and remolding the glass. Arago assisted Fresnel with the design of a modified Argand lamp with concentric wicks (a concept that Fresnel attributed to Count Rumford), and accidentally discovered that fish glue was heat-resistant, making it suitable for use in the lens. The prototype, with a lens panel 55cm square, containing 97 polygonal (not annular) prisms, was finished in March 1820 – and so impressed the commission that Fresnel was asked for a full eight-panel version. Completed a year later, in spite of insufficient funding, this model had panels 76cm square. In a public spectacle on the evening of 13 April 1821, it was demonstrated by comparison with the most recent reflectors, which it suddenly rendered obsolete.

Fresnel's next lens was a rotating apparatus with eight "bull's-eye" panels, made in annular arcs by Saint-Gobain, giving eight rotating beams – to be seen by mariners as a periodic flash. Above and behind each main panel was a smaller, sloping bull's-eye panel of trapezoidal outline with trapezoidal elements. This refracted the light to a sloping plane mirror, which then reflected it horizontally, 7 degrees ahead of the main beam, increasing the duration of the flash. Below the main panels were 128 small mirrors arranged in four rings, stacked like the slats of a louver or Venetian blind. Each ring, shaped like a frustum of a cone, reflected the light to the horizon, giving a fainter steady light between the flashes. The official test, conducted on the unfinished "Arc de Triomphe" on 20 August 1822, was witnessed by the commission – and by Louis and his entourage – from 32km away. The apparatus was stored at Bordeaux for the winter, and then reassembled at Cordouan Lighthouse under Fresnel's supervision. On 25 July 1823, the world's first lighthouse Fresnel lens was lit. It was about this time that Fresnel started coughing up blood.

In May 1824, Fresnel was promoted to secretary of the "Commission des Phares", becoming the first member of that body to draw a salary. He was also an examiner (not a teacher) at the École Polytechnique since 1821; but poor health, long hours during the examination season, and anxiety about judging others induced him to resign that post in late 1824, to save his energy for his lighthouse work.

In the same year he designed the first "fixed" lens – for spreading light evenly around the horizon while minimizing waste above or below. Ideally the curved refracting surfaces would be segments of toroids about a common vertical axis, so that the dioptric panel would look like a cylindrical drum. If this was supplemented by reflecting (catoptric) rings above and below the refracting (dioptric) parts, the entire apparatus would look like a beehive. The second Fresnel lens to enter service was indeed a fixed lens, of third order, installed at Dunkirk by 1 February 1825. However, due to the difficulty of fabricating large toroidal prisms, this apparatus had a 16-sided polygonal plan.

In 1825 Fresnel extended his fixed-lens design by adding a rotating array outside the fixed array. Each panel of the rotating array was to refract part of the fixed light from a horizontal fan into a narrow beam.

Also in 1825, Fresnel unveiled the "Carte des Phares" (Lighthouse Map), calling for a system of 51 lighthouses plus smaller harbor lights, in a hierarchy of lens sizes (called "orders", the first order being the largest), with different characteristics to facilitate recognition: a constant light (from a fixed lens), one flash per minute (from a rotating lens with eight panels), and two per minute (sixteen panels).

In late 1825, to reduce the loss of light in the reflecting elements, Fresnel proposed to replace each mirror with a catadioptric prism, through which the light would travel by refraction through the first surface, then total internal reflection off the second surface, then refraction through the third surface. The result was the lighthouse lens as we now know it. In 1826 he assembled a small model for use on the Canal Saint-Martin, but he did not live to see a full-sized version.

The first fixed lens with toroidal prisms was a first-order apparatus designed by Alan Stevenson under the influence of Léonor Fresnel, and fabricated by Isaac Cookson & Co. from French glass; it entered service at the Isle of May, Scotland, on 22 September 1836. The first large catadioptric lenses were made in 1842 for the lighthouses at Gravelines and Île Vierge; these were fixed third-order lenses whose catadioptric rings (made in segments) were one metre in diameter. Stevenson's first-order Skerryvore lens, lit in 1844, was only partly catadioptric; it was similar to the Cordouan lens except that the lower slats were replaced by French-made catadioptric prisms, while mirrors were retained at the top. The first "fully" catadioptric first-order lens, installed at Ailly in 1852, also gave eight rotating beams plus a fixed light at the bottom; but its top section had eight catadioptric panels focusing the light about 4 degrees ahead of the main beams, in order to lengthen the flashes. The first fully catadioptric lens with "purely revolving" beams – also of first order – was installed at Saint-Clément-des-Baleines in 1854, and marked the completion of Augustin Fresnel's original "Carte des Phares".

Production of one-piece stepped lenses (roughly as envisaged by Buffon) eventually became profitable. By the 1870s, in the United States, such lenses were made of pressed glass and used with small lights on ships and piers. Similar lenses are used in "Fresnel lanterns" for stage lighting. Lenses with finer steps serve as condensers in overhead projectors. Still finer steps can be found in low-cost plastic "sheet" magnifiers.

Fresnel was elected to the "Société Philomathique de Paris" in April 1819, and in 1822 became one of the editors of the Société's "Bulletin des Sciences". As early as May 1817, at Arago's suggestion, Fresnel applied for membership of the Académie des Sciences, but received only one vote. The successful candidate on that occasion was Joseph Fourier. In November 1822, Fourier's elevation to Permanent Secretary of the Académie created a vacancy in the physics section, which was filled in February 1823 by Pierre Louis Dulong, with 36 votes to Fresnel's 20. But in May 1823, after another vacancy was left by the death of Jacques Charles, Fresnel's election was unanimous. In 1824, Fresnel was made a "chevalier de la Légion d'honneur" (Knight of the Legion of Honour).

Meanwhile, in Britain, the wave theory was yet to take hold; Fresnel wrote to Thomas Young in November 1824, saying in part:

But "the praise of English scholars" soon followed. On 9 June 1825, Fresnel was made a Foreign Member of the Royal Society of London. In 1827 he was awarded the society's Rumford Medal for the year 1824, "For his Development of the Undulatory Theory as applied to the Phenomena of Polarized Light, and for his various important discoveries in Physical Optics."

A monument to Fresnel at his birthplace was dedicated on 14 September 1884 with a speech by , Permanent Secretary of the Académie des Sciences.  "" is among the 72 names embossed on the Eiffel Tower (on the south-east side, fourth from the left). In the 19th century, as every lighthouse in France acquired a Fresnel lens, every one acquired a bust of Fresnel, seemingly watching over the coastline that he had made safer. The lunar features "Promontorium Fresnel" and "Rimae Fresnel" were later named after him.
Fresnel's health, which had always been poor, deteriorated in the winter of 1822–1823, increasing the urgency of his original research, and (in part) preventing him from contributing an article on polarization and double refraction for the "Encyclopædia Britannica". The memoirs on circular and elliptical polarization and optical rotation, and on the detailed derivation of the Fresnel equations and their application to total internal reflection, date from this period. In the spring he recovered enough, in his own view, to supervise the lens installation at Cordouan. Soon afterwards, it became clear that his condition was tuberculosis.

In 1824 he was advised that if he wanted to live longer, he needed to scale back his activities. Perceiving his lighthouse work to be his most important duty, he resigned as an examiner at the École Polytechnique, and closed his scientific notebooks. His last note to the Académie, read on 13 June 1825, described the first radiometer and attributed the observed repulsive force to a temperature difference. Although his fundamental research ceased, his advocacy did not; as late as August or September 1826, he found the time to answer Herschel's queries on the wave theory. It was Herschel who recommended Fresnel for the Royal Society's Rumford Medal.

Fresnel's cough worsened in the winter of 1826–1827, leaving him too ill to return to Mathieu in the spring. The Académie meeting of 30 April 1827 was the last that he attended. In early June he was carried to Ville-d'Avray, 12km west of Paris. There his mother joined him. On 6 July, Arago arrived to deliver the Rumford Medal. Sensing Arago's distress, Fresnel whispered that "the most beautiful crown means little, when it is laid on the grave of a friend." Fresnel did not have the strength to reply to the Royal Society. He died eight days later, on Bastille Day.

He is buried at Père Lachaise Cemetery, Paris. The is partly eroded away; the legible part says, when translated, "To the memory of Augustin Jean Fresnel, member of the Institute of France".

Fresnel's "second memoir" on double refraction was not printed until late 1827, a few months after his death. Until then, the best published source on his work on double refraction was an extract of that memoir, printed in 1822. His final treatment of partial reflection and total internal reflection, read to the Académie in January 1823, was thought to be lost until it was rediscovered among the papers of the deceased Joseph Fourier (1768–1830), and was printed in 1831. Until then, it was known chiefly through an extract printed in 1823 and 1825. The memoir introducing the parallelepiped form of the Fresnel rhomb, read in March 1818, was mislaid until 1846, and then attracted such interest that it was soon republished in English. Most of Fresnel's writings on polarized light before 1821 – including his first theory of chromatic polarization (submitted 7 October 1816) and the crucial "supplement" of January 1818 — were not published in full until his "Oeuvres complètes" ("complete works") began to appear in 1866. The "supplement" of July 1816, proposing the "efficacious ray" and reporting the famous double-mirror experiment, met the same fate, as did the "first memoir" on double refraction.

Publication of Fresnel's collected works was itself delayed by the deaths of successive editors. The task was initially entrusted to Félix Savary, who died in 1841. It was restarted twenty years later by the Ministry of Public Instruction. Of the three editors eventually named in the "Oeuvres", Sénarmont died in 1862, Verdet in 1866, and Léonor Fresnel in 1869, by which time only two of the three volumes had appeared. At the beginning of vol. 3 (1870), the completion of the project is described in a long footnote by "J. Lissajous."

Not included in the "Oeuvres" are two short notes by Fresnel on magnetism, which were discovered among Ampère's manuscripts. In response to Ørsted's discovery of electromagnetism in 1820, Ampère initially supposed that the field of a permanent magnet was due to a macroscopic circulating current. Fresnel suggested instead that there was a "microscopic" current circulating around each particle of the magnet. In his first note, he argued that microscopic currents, unlike macroscopic currents, would explain why a hollow cylindrical magnet does not lose its magnetism when cut longitudinally. In his second note, dated 5 July 1821, he further argued that a macroscopic current had the counterfactual implication that a permanent magnet should be hot, whereas microscopic currents circulating around the molecules might avoid the heating mechanism. He was not to know that the fundamental units of permanent magnetism are even smaller than molecules . The two notes, together with Ampère's acknowledgment, were eventually published in 1885.

Fresnel's essay "Rêveries" of 1814 has not survived. While its content would have been interesting to historians, its quality may perhaps be gauged from the fact that Fresnel himself never referred to it in his maturity.

More disturbing is the fate of the late article "Sur les Différents Systèmes relatifs à la Théorie de la Lumière" ("On the Different Systems relating to the Theory of Light"), which Fresnel wrote for the newly launched English journal "European Review". This work seems to have been similar in scope to the essay "De la Lumière" of 1821/22, except that Fresnel's views on double refraction, circular and elliptical polarization, optical rotation, and total internal reflection had developed since then. The manuscript was received by the publisher's agent in Paris in early September 1824, and promptly forwarded to London. But the journal failed before Fresnel's contribution could be published. Fresnel tried unsuccessfully to recover the manuscript. The editors of his collected works were also unable to find it, and admitted that it was probably lost.

In 1810, Arago found experimentally that the degree of refraction of starlight does not depend on the direction of the earth's motion relative to the line of sight. In 1818, Fresnel showed that this result could be explained by the wave theory, on the hypothesis that if an object with refractive index formula_35 moved at velocity formula_36 relative to the external aether (taken as stationary), then the velocity of light inside the object gained the additional component formula_37. He supported that hypothesis by supposing that if the density of the external aether was taken as unity, the density of the internal aether was formula_38, of which the excess, namely formula_39, was dragged along at velocity formula_36, whence the "average" velocity of the internal aether was formula_37. The factor in parentheses, which Fresnel originally expressed in terms of wavelengths, became known as the "Fresnel drag coefficient". 

In his analysis of double refraction, Fresnel supposed that the different refractive indices in different directions within the "same medium" were due to a directional variation in elasticity, not density (because the concept of mass per unit volume is not directional). But in his treatment of partial reflection, he supposed that the different refractive indices of "different media" were due to different aether densities, not different elasticities. The latter decision is puzzling in the context of double refraction, but makes sense in the earlier context of aether drag.

In 1846, George Gabriel Stokes pointed out that there was no need to divide the aether inside a moving object into two portions; all of it could be considered as moving at a common velocity. Then, if the aether was conserved while its density changed in proportion to formula_38, the resulting velocity of the aether inside the object was equal to Fresnel's additional velocity component.

Conversely, Fresnel could have started with the required additional velocity component, equated it to aether drag, combined that with conservation of aether, and arrived at the relation between refractive index and aether density, thereby justifying his choice in the case of partial reflection.

The analogy between light waves and transverse waves in elastic solids does not predict "dispersion" — that is, the frequency-dependence of the speed of propagation, which enables prisms to produce spectra and causes lenses to suffer from chromatic aberration. Fresnel, in "De la Lumière" and in the second supplement to his first memoir on double refraction, suggested that dispersion could be accounted for if the particles of the medium exerted forces on each other over distances that were significant fractions of a wavelength. Later, more than once, Fresnel referred to the demonstration of this result as being contained in a note appended to his "second memoir" on double refraction. But no such note appeared in print, and the relevant manuscripts found after his death showed only that, around 1824, he was comparing refractive indices (measured by Fraunhofer) with a theoretical formula, the meaning of which was not fully explained. One obvious possibility is that the explanation of the formula was given in the appended note, which should be counted as another lost work.

In the 1830s, Fresnel's suggestion was taken up by Cauchy, Powell, and Kelland, and it was indeed found to be tolerably consistent with the variation of refractive indices with wavelength over the visible spectrum, for a variety of transparent media . These investigations were enough to show that the wave theory was at least "compatible" with dispersion. However, if the model of dispersion was to be accurate over a wider range of frequencies, it needed to be modified so as to take account of resonances within the medium .

The analytical complexity of Fresnel's derivation of the ray-velocity surface was an implicit challenge to find a shorter path to the result. This was answered by MacCullagh in 1830, and by William Rowan Hamilton in 1832.

Hamilton went further, establishing two properties of the surface that Fresnel, in the short time given to him, had overlooked: (i) at each of the four points where the inner and outer sheets of the surface make contact, the surface has a tangent cone (tangential to both sheets), hence a cone of normals, indicating that a cone of wave-normal directions corresponds to a single ray-velocity vector; and (ii) around each of these points, the outer sheet has a circle of contact with a tangent plane, indicating that a cone of ray directions corresponds to a single wave-normal velocity vector. As Hamilton noted, these properties respectively imply that (i) a narrow beam propagating inside the crystal in the direction of the single ray velocity will, on exiting the crystal through a flat surface, break into a hollow cone ("external conical refraction"), and (ii) a narrow beam striking a flat surface of the crystal in the appropriate direction (corresponding to that of the single internal wave-normal velocity) will, on entering the crystal, break into a hollow cone ("internal conical refraction").

Thus a new pair of phenomena, "qualitatively" different from anything previously observed or suspected, had been predicted by mathematics as consequences of Fresnel's theory. The prompt experimental confirmation of those predictions by Humphrey Lloyd brought Hamilton a prize that had never come to Fresnel: immediate fame.

Within a century of Fresnel's initial stepped-lens proposal, more than 10,000 lights with Fresnel lenses were protecting lives and property around the world. Concerning the other benefits, the science historian Theresa H. Levitt has remarked:
In the history of physical optics, Fresnel's successful revival of the wave theory nominates him as the pivotal figure between Newton, who held that light consisted of corpuscles, and James Clerk Maxwell, who established that light waves are electromagnetic. Whereas Albert Einstein described Maxwell's work as "the most profound and the most fruitful that physics has experienced since the time of Newton," commentators of the era between Fresnel and Maxwell made similarly strong statements about Fresnel:



What Whewell called the "true theory" has since undergone two major revisions. The first, by Maxwell, specified the physical fields whose variations constitute the waves of light. Without the benefit of this knowledge, Fresnel managed to construct the world's first coherent theory of light, showing in retrospect that his methods are applicable to multiple types of waves. The second revision, initiated by Einstein's explanation of the photoelectric effect, supposed that the energy of light waves was divided into quanta, which were eventually identified with particles called photons. But photons did not exactly correspond to Newton's corpuscles; for example, Newton's explanation of ordinary refraction required the corpuscles to travel faster in media of higher refractive index, which photons do not. Neither did photons displace waves; rather, they led to the paradox of wave–particle duality. Moreover, the phenomena studied by Fresnel, which included nearly all the optical phenomena known at his time, are still most easily explained in terms of the "wave" nature of light. So it was that, as late as 1927, the astronomer Eugène Michel Antoniadi declared Fresnel to be "the dominant figure in optics."

The works of Fresnel that have been fully or partly translated into English, as identified in the above Bibliography, are Arago & Fresnel 1819, and Fresnel 1818a, 1818b, 1822a, 1822b, and 1827. (Modern readers will find much of 1818a to be cryptic, because it deals with linear and circular polarization and optical rotation but is not yet expressed in terms of transverse waves.)

The most detailed secondary source on Fresnel in English is apparently Buchwald 1989 —in which Fresnel, although not named in the title, is clearly the central character.

On lighthouse lenses, this article heavily cites Levitt 2013, Elton 2009, and Thomas Tag at the U.S. Lighthouse Society (see "External links" below). All three authors deal not only with Fresnel's contributions but also with later innovations that are not mentioned here.

By comparison with the volume and impact of his scientific and technical writings, biographical information on Fresnel is remarkably scarce. There is no book-length critical biography of him, and anyone who proposes to write one must confront the fact that the letters published in his "Oeuvres complètes"—contrary to the title—are heavily redacted. In the words of Robert H. Silliman (1967, p. 6n): "By an unhappy judgment of the editors, dictated in part, one suspects, by political expediency, the letters appear in fragmentary form, preserving almost nothing beyond the technical discussions of Fresnel and his correspondents." It is not clear from the secondary sources whether the manuscripts of those letters are still extant.



</doc>
<doc id="1143" url="https://en.wikipedia.org/wiki?curid=1143" title="Abbot">
Abbot

Abbot (From the Aramaic "Abba" meaning "father") is an ecclesiastical title given to the male head of a monastery in various western religious traditions, including Christianity. The office may also be given as an honorary title to a clergyman who is not the head of a monastery. The female equivalent is abbess.

The title had its origin in the monasteries of Egypt and Syria, spread through the eastern Mediterranean, and soon became accepted generally in all languages as the designation of the head of a monastery. The word is derived from the Aramaic ' meaning "father" or ', meaning "my father" (it still has this meaning in contemporary Israeli Hebrew - אבא) In the Septuagint, it was written as "abbas". At first it was employed as a respectful title for any monk, but it was soon restricted by canon law to certain priestly superiors. At times it was applied to various priests, e.g. at the court of the Frankish monarchy the ' ("of the palace"') and ' ("of the camp") were chaplains to the Merovingian and Carolingian sovereigns’ court and army respectively. The title of abbot came into fairly general use in western monastic orders whose members include priests.

An abbot (from , ', from " ("father"), from " (), from '/' (, "father"); compare '; "") is the head and chief governor of a community of monks, called also in the East "hegumen" or "archimandrite". The English version for a female monastic head is abbess.

In Egypt, the first home of monasticism, the jurisdiction of the abbot, or archimandrite, was but loosely defined. Sometimes he ruled over only one community, sometimes over several, each of which had its own abbot as well. Saint John Cassian speaks of an abbot of the Thebaid who had 500 monks under him. By the Rule of St Benedict, which, until the Cluniac reforms, was the norm in the West, the abbot has jurisdiction over only one community. The rule, as was inevitable, was subject to frequent violations; but it was not until the foundation of the Cluniac Order that the idea of a supreme abbot, exercising jurisdiction over all the houses of an order, was definitely recognised.

Monks, as a rule, were laymen, nor at the outset was the abbot any exception. For the reception of the sacraments, and for other religious offices, the abbot and his monks were commanded to attend the nearest church. This rule proved inconvenient when a monastery was situated in a desert or at a distance from a city, and necessity compelled the ordination of some monks. This innovation was not introduced without a struggle, ecclesiastical dignity being regarded as inconsistent with the higher spiritual life, but, before the close of the 5th century, at least in the East, abbots seem almost universally to have become deacons, if not priests. The change spread more slowly in the West, where the office of abbot was commonly filled by laymen till the end of the 7th century. The ecclesiastical leadership exercised by abbots despite their frequent lay status is proved by their attendance and votes at ecclesiastical councils. Thus at the first Council of Constantinople, AD 448, 23 archimandrites or abbots sign, with 30 bishops.

The second Council of Nicaea, AD 787, recognized the right of abbots to ordain their monks to the inferior orders below the diaconate, a power usually reserved to bishops.

Abbots used to be subject to episcopal jurisdiction, and continued generally so, in fact, in the West till the 11th century. The Code of Justinian (lib. i. tit. iii. de Ep. leg. xl.) expressly subordinates the abbot to episcopal oversight. The first case recorded of the partial exemption of an abbot from episcopal control is that of Faustus, abbot of Lerins, at the council of Arles, AD 456; but the exorbitant claims and exactions of bishops, to which this repugnance to episcopal control is to be traced, far more than to the arrogance of abbots, rendered it increasingly frequent, and, in the 6th century, the practice of exempting religious houses partly or altogether from episcopal control, and making them responsible to the pope alone, received an impulse from Pope Gregory the Great. These exceptions, introduced with a good object, had grown into a widespread evil by the 12th century, virtually creating an "imperium in imperio," and depriving the bishop of all authority over the chief centres of influence in his diocese.

In the 12th century, the abbots of Fulda claimed precedence of the archbishop of Cologne. Abbots more and more assumed almost episcopal state, and in defiance of the prohibition of early councils and the protests of St Bernard and others, adopted the episcopal insignia of mitre, ring, gloves and sandals.

It has been maintained that the right to wear mitres was sometimes granted by the popes to abbots before the 11th century, but the documents on which this claim is based are not genuine (J. Braun, "Liturgische Gewandung", p. 453). The first undoubted instance is the bull by which Alexander II in 1063 granted the use of the mitre to Egelsinus, abbot of the monastery of St Augustine at Canterbury. The mitred abbots in England were those of Abingdon, St Alban's, Bardney, Battle, Bury St Edmunds, St Augustine's Canterbury, Colchester, Croyland, Evesham, Glastonbury, Gloucester, St Benet's Hulme, Hyde, Malmesbury, Peterborough, Ramsey, Reading, Selby, Shrewsbury, Tavistock, Thorney, Westminster, Winchcombe, and St Mary's York. Of these the precedence was yielded to the abbot of Glastonbury, until in AD 1154 Adrian IV (Nicholas Breakspear) granted it to the abbot of St Alban's, in which monastery he had been brought up. Next after the abbot of St Alban's ranked the abbot of Westminster and then Ramsey. Elsewhere, the mitred abbots that sat in the Estates of Scotland were of Arbroath, Cambuskenneth, Coupar Angus, Dunfermline, Holyrood, Iona, Kelso, Kilwinning, Kinloss, Lindores, Paisley, Melrose, Scone, St Andrews Priory and Sweetheart. To distinguish abbots from bishops, it was ordained that their mitre should be made of less costly materials, and should not be ornamented with gold, a rule which was soon entirely disregarded, and that the crook of their pastoral staff (the crosier) should turn inwards instead of outwards, indicating that their jurisdiction was limited to their own house.

The adoption of certain episcopal insignia (pontificalia) by abbots was followed by an encroachment on episcopal functions, which had to be specially but ineffectually guarded against by the Lateran council, AD 1123. In the East abbots, if in priests' orders and with the consent of the bishop, were, as we have seen, permitted by the second Nicene council, AD 787, to confer the tonsure and admit to the order of reader; but gradually abbots, in the West also, advanced higher claims, until we find them in AD 1489 permitted by Innocent IV to confer both the subdiaconate and diaconate. Of course, they always and everywhere had the power of admitting their own monks and vesting them with the religious habit.

The power of the abbot was paternal but absolute, limited, however, by the canon law. One of the main goals of monasticism was the purgation of self and selfishness, and obedience was seen as a path to that perfection. It was sacred duty to execute the abbot's orders, and even to act without his orders was sometimes considered a transgression. Examples among the Egyptian monks of this submission to the commands of the superiors, exalted into a virtue by those who regarded the entire crushing of the individual will as a goal, are detailed by Cassian and others, e.g. a monk watering a dry stick, day after day, for months, or endeavoring to remove a huge rock immensely exceeding his powers.

When a vacancy occurred, the bishop of the diocese chose the abbot out of the monks of the monastery, but the right of election was transferred by jurisdiction to the monks themselves, reserving to the bishop the confirmation of the election and the benediction of the new abbot. In abbeys exempt from the archbishop's diocesan jurisdiction, the confirmation and benediction had to be conferred by the pope in person, the house being taxed with the expenses of the new abbot's journey to Rome. It was necessary that an abbot should be at least 30 years of age, of legitimate birth, a monk of the house for at least 10 years, unless it furnished no suitable candidate, when a liberty was allowed of electing from another monastery, well instructed himself, and able to instruct others, one also who had learned how to command by having practised obedience. In some exceptional cases an abbot was allowed to name his own successor. Cassian speaks of an abbot in Egypt doing this; and in later times we have another example in the case of St Bruno. Popes and sovereigns gradually encroached on the rights of the monks, until in Italy the pope had usurped the nomination of all abbots, and the king in France, with the exception of Cluny, Premontré and other houses, chiefs of their order. The election was for life, unless the abbot was canonically deprived by the chiefs of his order, or when he was directly subject to them, by the pope or the bishop, and also in England it was for a term of 8–12 years.

The ceremony of the formal admission of a Benedictine abbot in medieval times is thus prescribed by the consuetudinary of Abingdon. The newly elected abbot was to put off his shoes at the door of the church, and proceed barefoot to meet the members of the house advancing in a procession. After proceeding up the nave, he was to kneel and pray at the topmost step of the entrance of the choir, into which he was to be introduced by the bishop or his commissary, and placed in his stall. The monks, then kneeling, gave him the kiss of peace on the hand, and rising, on the mouth, the abbot holding his staff of office. He then put on his shoes in the vestry, and a chapter was held, and the bishop or his delegate preached a suitable sermon.

Before the late modern era, the abbot was treated with the utmost reverence by the brethren of his house. When he appeared either in church or chapter all present rose and bowed. His letters were received kneeling, as were those of the pope and the king. No monk might sit in his presence, or leave it without his permission, reflecting the hierarchical etiquette of families and society. The highest place was assigned to him, both in church and at table. In the East he was commanded to eat with the other monks. In the West the Rule of St Benedict appointed him a separate table, at which he might entertain guests and strangers. Because this permission opened the door to luxurious living, Synods of Aachen (816–819), decreed that the abbot should dine in the refectory, and be content with the ordinary fare of the monks, unless he had to entertain a guest. These ordinances proved, however, generally ineffectual to secure strictness of diet, and contemporaneous literature abounds with satirical remarks and complaints concerning the inordinate extravagance of the tables of the abbots. When the abbot condescended to dine in the refectory, his chaplains waited upon him with the dishes, a servant, if necessary, assisting them. When abbots dined in their own private hall, the Rule of St Benedict charged them to invite their monks to their table, provided there was room, on which occasions the guests were to abstain from quarrels, slanderous talk and idle gossiping.
The ordinary attire of the abbot was according to rule to be the same as that of the monks. But by the 10th century the rule was commonly set aside, and we find frequent complaints of abbots dressing in silk, and adopting sumptuous attire. Some even laid aside the monastic habit altogether, and assumed a secular dress. With the increase of wealth and power, abbots had lost much of their special religious character, and become great lords, chiefly distinguished from lay lords by celibacy. Thus we hear of abbots going out to hunt, with their men carrying bows and arrows; keeping horses, dogs and huntsmen; and special mention is made of an abbot of Leicester, c. 1360, who was the most skilled of all the nobility in hare hunting. In magnificence of equipage and retinue the abbots vied with the first nobles of the realm. They rode on mules with gilded bridles, rich saddles and housings, carrying hawks on their wrist, followed by an immense train of attendants. The bells of the churches were rung as they passed. They associated on equal terms with laymen of the highest distinction, and shared all their pleasures and pursuits. This rank and power was, however, often used most beneficially. For instance, we read of Richard Whiting, the last abbot of Glastonbury, judicially murdered by Henry VIII, that his house was a kind of well-ordered court, where as many as 300 sons of noblemen and gentlemen, who had been sent to him for virtuous education, had been brought up, besides others of a lesser rank, whom he fitted for the universities. His table, attendance and officers were an honour to the nation. He would entertain as many as 500 persons of rank at one time, besides relieving the poor of the vicinity twice a week. He had his country houses and fisheries, and when he travelled to attend parliament his retinue amounted to upwards of 100 persons. The abbots of Cluny and Vendôme were, by virtue of their office, cardinals of the Roman church.

In the process of time, the title abbot was extended to clerics who had no connection with the monastic system, as to the principal of a body of parochial clergy; and under the Carolingians to the chief chaplain of the king, ', or military chaplain of the emperor, ' It even came to be adopted by purely secular officials. Thus the chief magistrate of the republic at Genoa was called "".

Lay abbots (M. Lat. ', ', ', ', ' or ', ', or sometimes simply ') were the outcome of the growth of the feudal system from the 8th century onwards. The practice of commendation, by which—to meet a contemporary emergency—the revenues of the community were handed over to a lay lord, in return for his protection,
early suggested to the emperors and kings the expedient of rewarding their warriors with rich abbeys held "in commendam."

During the Carolingian epoch, the custom grew up of granting these as regular heritable fiefs or benefices, and by the 10th century, before the great Cluniac reform, the system was firmly established. Even the abbey of St Denis was held in commendam by Hugh Capet. The example of the kings was followed by the feudal nobles, sometimes by making a temporary concession permanent, sometimes without any form of commendation whatever. In England the abuse was rife in the 8th century, as may be gathered from the acts of the council of Cloveshoe. These lay abbacies were not merely a question of overlordship, but implied the concentration in lay hands of all the rights, immunities and jurisdiction of the foundations, i.e. the more or less complete secularization of spiritual institutions. The lay abbot took his recognized rank in the feudal hierarchy, and was free to dispose of his fief as in the case of any other. The enfeoffment of abbeys differed in form and degree. Sometimes the monks were directly subject to the lay abbot; sometimes he appointed a substitute to perform the spiritual functions, known usually as dean (), but also as abbot (', ', ").

When the great reform of the 11th century had put an end to the direct jurisdiction of the lay abbots, the honorary title of abbot continued to be held by certain of the great feudal families, as late as the 13th century and later, with the head of the community retaining the title of dean. The connection of the lesser lay abbots with the abbeys, especially in the south of France, lasted longer; and certain feudal families retained the title of () for centuries, together with certain rights over the abbey lands or revenues. The abuse was not confined to the West. John, patriarch of Antioch, at the beginning of the 12th Century, informs us that in his time most monasteries had been handed over to laymen, ", for life, or for part of their lives, by the emperors.

Giraldus Cambrensis reported ("Itinerary", ii.iv) the common customs of lay abbots in the late 12th-century Church of Wales:
In conventual cathedrals, where the bishop occupied the place of the abbot, the functions usually devolving on the superior of the monastery were performed by a prior.

In the Roman Catholic Church, abbots continue to be elected by the monks of an abbey to lead them as their religious superior in those orders and monasteries that make use of the term (some orders of monks, as the Carthusians for instance, have no abbots, only priors). A monastery must have been granted the status of an abbey by the pope, and such monasteries are normally raised to this level after showing a degree of stability—a certain number of monks in vows, a certain number of years of establishment, a certain firmness to the foundation in economic, vocational and legal aspects. Prior to this, the monastery would be a mere priory, headed by a prior who acts as superior but without the same degree of legal authority that an abbot has.
The abbot is chosen by the monks from among the fully professed monks. Once chosen, he must request blessing: the blessing of an abbot is celebrated by the bishop in whose diocese the monastery is or, with his permission, another abbot or bishop. The ceremony of such a blessing is similar in some aspects to the consecration of a bishop, with the new abbot being presented with the mitre, the ring, and the crosier as symbols of office and receiving the laying on of hands and blessing from the celebrant. Though the ceremony installs the new abbot into a position of legal authority, it does not confer further sacramental authority- it is not a further degree of Holy Orders (although some abbots have been ordained to the episcopacy).

Once he has received this blessing, the abbot not only becomes father of his monks in a spiritual sense, but their major superior under canon law, and has the additional authority to confer the ministries of acolyte and lector (formerly, he could confer the minor orders, which are not sacraments, that these ministries have replaced). The abbey is a species of "exempt religious" in that it is, for the most part, answerable to the pope, or to the abbot primate, rather than to the local bishop.

The abbot wears the same habit as his fellow monks, though by tradition he adds to it a pectoral cross.

Territorial abbots follow all of the above, but in addition must receive a mandate of authority from the pope over the territory around the monastery for which they are responsible.

In some monastic families, there is a hierarchy of precedence or authority among abbots. In some cases, this is the result of an abbey being considered the "mother" of several "daughter" abbeys founded as dependent priories of the "mother." In other cases, abbeys have affiliated in networks known as "congregations." Some monastic families recognize one abbey as the motherhouse of the entire order.


The title abbé (French; Ital. "abate"), as commonly used in the Catholic Church on the European continent, is the equivalent of the English "Father" (parallel etymology), being loosely applied to all who have received the tonsure. This use of the title is said to have originated in the right conceded to the king of France, by the concordat between Pope Leo X and Francis I (1516), to appoint commendatory abbots (') to most of the abbeys in France. The expectation of obtaining these sinecures drew young men towards the church in considerable numbers, and the class of abbés so formed - ' they were sometimes called, and sometimes (ironically) "" ("abbés of holy hope; or in a jeu de mots, "of St. Hope") - came to hold a recognized position. The connection many of them had with the church was of the slenderest kind, consisting mainly in adopting the title of abbé, after a remarkably moderate course of theological study, practising celibacy and wearing distinctive dress, a short dark-violet coat with narrow collar. Being men of presumed learning and undoubted leisure, many of the class found admission to the houses of the French nobility as tutors or advisers. Nearly every great family had its abbé. The class did not survive the Revolution; but the courtesy title of abbé, having long lost all connection in people's minds with any special ecclesiastical function, remained as a convenient general term applicable to any clergyman.

In the Eastern Orthodox and Eastern Catholic Churches, the abbot is referred to as the "hegumen". The Superior of a monastery of nuns is called the "Hēguménē". The title of "archimandrite" (literally the head of the enclosure) used to mean something similar.

In the East, the principle set forth in the "Corpus Juris Civilis" still applies, whereby most abbots are immediately subject to the local bishop. Those monasteries which enjoy the status of being "stauropegic" will be subject only to a primate or his Synod of Bishops and not the local bishop.

Although currently in the Western Church the title "abbot" is given only abbots of monasteries, the title archimandrite is given to "monastics" (i.e., celibate) priests in the East, even when not attached to a monastery, as an honor for service, similar to the title of monsignor in the Western/Latin Rite of the Catholic Church. In the Orthodox Church, only monastics are permitted to be elevated to the rank of archimandrite. Married priests are elevated to the parallel rank of Archpriest or Protopresbyter. Normally there are no celibate priests who are not monastics in the Orthodox Church, with the exception of married priests who have been widowed. Since the time of Catherine II the ranks of Abbot and Archimandrite have been given as honorary titles in the Russian Church, and may be given to any monastic, even if he does not in fact serve as the superior of a monastery. In Greek practice the title or function of Abbot corresponds to a person who serves as the head of a monastery, although the title of the Archimandrite may be given to any celibate priest who could serve as the head of a monastery.

In the German Evangelical Church, the German title of "Abt" (abbot) is sometimes bestowed, like the French "abbé", as an honorary distinction, and survives to designate the heads of some monasteries converted at the Reformation into collegiate foundations.
Of these the most noteworthy is Loccum Abbey in Hanover, founded as a Cistercian house in 1163 by Count Wilbrand of Hallermund, and reformed in 1593. The abbot of Loccum, who still carries a pastoral staff, takes precedence over all the clergy of Hanover, and was "ex officio" a member of the consistory of the kingdom. The governing body of the abbey consists of the abbot, prior and the "convent", or community, of "Stiftsherren" (canons).

In the Church of England, the Bishop of Norwich, by royal decree given by Henry VIII, also holds the honorary title of "Abbot of St. Benet." This title hails back to England's separation from the See of Rome, when King Henry, as supreme head of the newly independent church, took over all of the monasteries, mainly for their possessions, except for St. Benet, which he spared because the abbot and his monks possessed no wealth, and lived like simple beggars, deposing the incumbent Bishop of Norwich and seating the abbot in his place, thus the dual title still held to this day.

Additionally, at the enthronement of the Archbishop of Canterbury, there is a threefold enthronement, once in the throne the chancel as the diocesan bishop of Canterbury, once in the Chair of St. Augustine as the Primate of All England, and then once in the chapter-house as Titular Abbot of Canterbury.

There are several Benedictine abbeys throughout the Anglican Communion. Most of them have mitred abbots.

"The Abbot" is one of the archetypes traditionally illustrated in scenes of "Danse Macabre".

The lives of numerous abbots make up a significant contribution to Christian hagiography, one of the most well-known being the "Life of St. Benedict of Nursia" by St. Gregory the Great.

During the years 1106–1107 AD, Daniel, a Russian Orthodox abbot, made a pilgrimage to the Holy Land and recorded his experiences. His diary was much-read throughout Russia, and at least seventy-five manuscript copies survive. Saint Joseph, Abbot of Volokolamsk, Russia (1439–1515), wrote a number of influential works against heresy, and about monastic and liturgical discipline, and Christian philanthropy.

In the "Tales of Redwall" series, the creatures of Redwall are led by an abbot or abbess. These "abbots" are appointed by the brothers and sisters of Redwall to serve as a superior and provide paternal care, much like real abbots.

"The Abbot" was a nickname of RZA from the Wu-Tang Clan.





</doc>
<doc id="1144" url="https://en.wikipedia.org/wiki?curid=1144" title="Ardipithecus">
Ardipithecus

Ardipithecus is a genus of an extinct hominine that lived during the Late Miocene and Early Pliocene epochs in the Afar Depression, Ethiopia. Originally described as one of the earliest ancestors of humans after they diverged from the chimpanzees, the relation of this genus to human ancestors and whether it is a hominin is now a matter of debate. Two fossil species are described in the literature: "A. ramidus", which lived about 4.4 million years ago during the early Pliocene, and "A. kadabba", dated to approximately 5.6 million years ago (late Miocene). Behavioral analysis showed that "Ardipithecus" could be very similar to chimpanzees, indicating that the early human ancestors were very chimpanzee-like in behavior.

"A. ramidus" was named in September 1994. The first fossil found was dated to 4.4 million years ago on the basis of its stratigraphic position between two volcanic strata: the basal Gaala Tuff Complex (G.A.T.C.) and the Daam Aatu Basaltic Tuff (D.A.B.T.). The name "Ardipithecus ramidus" stems mostly from the Afar language, in which "Ardi" means "ground/floor" and "ramid" means "root". The "pithecus" portion of the name is from the Greek word for "ape".

Like most hominids, but unlike all previously recognized hominins, it had a grasping hallux or big toe adapted for locomotion in the trees. It is not confirmed how much other features of its skeleton reflect adaptation to bipedalism on the ground as well. Like later hominins, "Ardipithecus" had reduced canine teeth.

In 1992–1993 a research team headed by Tim White discovered the first "A. ramidus" fossils—seventeen fragments including skull, mandible, teeth and arm bones—from the Afar Depression in the Middle Awash river valley of Ethiopia. More fragments were recovered in 1994, amounting to 45% of the total skeleton. This fossil was originally described as a species of "Australopithecus", but White and his colleagues later published a note in the same journal renaming the fossil under a new genus, "Ardipithecus". Between 1999 and 2003, a multidisciplinary team led by Sileshi Semaw discovered bones and teeth of nine "A. ramidus" individuals at As Duma in the Gona area of Ethiopia's Afar Region. The fossils were dated to between 4.35 and 4.45 million years old.

"Ardipithecus ramidus" had a small brain, measuring between 300 and 350 cm. This is slightly smaller than a modern bonobo or female common chimpanzee brain, but much smaller than the brain of australopithecines like Lucy (~400 to 550 cm) and roughly 20% the size of the modern "Homo sapiens" brain. Like common chimpanzees, "A. ramidus" was much more prognathic than modern humans.

The teeth of "A. ramidus" lacked the specialization of other apes, and suggest that it was a generalized omnivore and frugivore (fruit eater) with a diet that did not depend heavily on foliage, fibrous plant material (roots, tubers, etc.), or hard and or abrasive food. The size of the upper canine tooth in "A. ramidus" males was not distinctly different from that of females. Their upper canines were less sharp than those of modern common chimpanzees in part because of this decreased upper canine size, as larger upper canines can be honed through wear against teeth in the lower mouth. The features of the upper canine in "A. ramidus" contrast with the sexual dimorphism observed in common chimpanzees, where males have significantly larger and sharper upper canine teeth than females.

The less pronounced nature of the upper canine teeth in "A. ramidus" has been used to infer aspects of the social behavior of the species and more ancestral hominids. In particular, it has been used to suggest that the last common ancestor of hominids and African apes was characterized by relatively little aggression between males and between groups. This is markedly different from social patterns in common chimpanzees, among which intermale and intergroup aggression are typically high. Researchers in a 2009 study said that this condition "compromises the living chimpanzee as a behavioral model for the ancestral hominid condition."

"A. ramidus" existed more recently than the most recent common ancestor of humans and chimpanzees (CLCA or "Pan"-"Homo" LCA) and thus is not fully representative of that common ancestor. Nevertheless, it is in some ways unlike chimpanzees, suggesting that the common ancestor differs from the modern chimpanzee. After the chimpanzee and human lineages diverged, both underwent substantial evolutionary change. Chimp feet are specialized for grasping trees; "A. ramidus" feet are better suited for walking. The canine teeth of "A. ramidus" are smaller, and equal in size between males and females, which suggests reduced male-to-male conflict, increased pair-bonding, and increased parental investment. "Thus, fundamental reproductive and social behavioral changes probably occurred in hominids long before they had enlarged brains and began to use stone tools," the research team concluded.

On October 1, 2009, paleontologists formally announced the discovery of the relatively complete "A. ramidus" fossil skeleton first unearthed in 1994. The fossil is the remains of a small-brained 50-kilogram (110 lb) female, nicknamed "Ardi", and includes most of the skull and teeth, as well as the pelvis, hands, and feet. It was discovered in Ethiopia's harsh Afar desert at a site called Aramis in the Middle Awash region. Radiometric dating of the layers of volcanic ash encasing the deposits suggest that Ardi lived about 4.3-4.5 million years ago. This date, however, has been questioned by others. Fleagle and Kappelman suggest that the region in which Ardi was found is difficult to date radiometrically, and they argue that Ardi should be dated at 3.9 million years.<ref name="10.1038/nature09709"></ref>

The fossil is regarded by its describers as shedding light on a stage of human evolution about which little was known, more than a million years before Lucy ("Australopithecus afarensis"), the iconic early human ancestor candidate who lived 3.2 million years ago, and was discovered in 1974 just away from Ardi's discovery site. However, because the "Ardi" skeleton is no more than 200,000 years older than the earliest fossils of "Australopithecus", and may in fact be younger than they are, some researchers doubt that it can represent a direct ancestor of "Australopithecus".

Some researchers infer from the form of her pelvis and limbs and the presence of her abductable hallux, that "Ardi" was a facultative biped: bipedal when moving on the ground, but quadrupedal when moving about in tree branches. "A. ramidus" had a more primitive walking ability than later hominids, and could not walk or run for long distances. The teeth suggest omnivory, and are more generalised than those of modern apes.

"Ardipithecus kadabba" is "known only from teeth and bits and pieces of skeletal bones", and is dated to approximately 5.6 million years ago. It has been described as a "probable chronospecies" (i.e. ancestor) of "A. ramidus". Although originally considered a subspecies of "A. ramidus", in 2004 anthropologists Yohannes Haile-Selassie, Gen Suwa, and Tim D. White published an article elevating "A. kadabba" to species level on the basis of newly discovered teeth from Ethiopia. These teeth show "primitive morphology and wear pattern" which demonstrate that "A. kadabba" is a distinct species from "A. ramidus".

The specific name comes from the Afar word for "basal family ancestor".

Due to several shared characteristics with chimpanzees, its closeness to ape divergence period, and due to its fossil incompleteness, the exact position of "Ardipithecus" in the fossil record is a subject of controversy. Primatologist Esteban Sarmiento had systematically compared and concluded that there is not sufficient anatomical evidence to support an exclusively human lineage. Sarmiento noted that "Ardipithecus" does not share any characteristics exclusive to humans, and some of its characteristics (those in the wrist and basicranium) suggest it diverged from humans prior to the human–gorilla last common ancestor. His comparative (narrow allometry) study in 2011 on the molar and body segment lengths (which included living primates of similar body size) noted that some dimensions including short upper limbs, and metacarpals are reminiscent of humans, but other dimensions such as long toes and relative molar surface area are great ape-like. Sarmiento concluded that such length measures can change back and forth during evolution and are not very good indicators of relatedness (homoplasy).

However, some later studies still argue for its classification in the human lineage. In 2014 it was reported that the hand bones of "Ardipithecus", "Australopithecus sediba" and "A. afarensis" have the third metacarpal styloid process, which is absent in other apes. Unique brain organisations (such as lateral shift of the carotid foramina, mediolateral abbreviation of the lateral tympanic, and a shortened, trapezoidal basioccipital element) in "Ardipithecus" are also found only in the "Australopithecus" and "Homo". Comparison of the tooth root morphology with those of the earlier "Sahelanthropus" also indicated strong resemblance, also pointing to inclusion to the human line.

Evolutionary tree according to a 2019 study:
The "Ardipithecus" length measures are good indicators of function and together with dental isotope data and the fauna and flora from the fossil site indicate "Ardipithecus" was mainly a terrestrial quadruped collecting a large portion of its food on the ground. Its arboreal behaviors would have been limited and suspension from branches solely from the upper limbs rare. A comparative study in 2013 on carbon and oxygen stable isotopes within modern and fossil tooth enamel revealed that "Ardipithecus" fed both arboreally (on trees) and on the ground in a more open habitat, unlike chimpanzees.

In 2015, Australian anthropologists Gary Clark and Maciej Henneberg said that "Ardipithecus" adults have a facial anatomy more similar to chimpanzee subadults than adults, with a less-projecting face and smaller canines (large canines in primate males are used to compete within mating hierarchies), and attributed this to a decrease in craniofacial growth in favour of brain growth. This is only seen in humans, so they argued that the species may show the first trend towards human social, parenting and sexual psychology. Previously, it was assumed that such ancient human ancestors behaved much like chimps, but this is no longer considered to be a viable comparison. This view has yet to be corroborated by more detailed studies of the growth of "A.ramidus". The study also provides support for Stephen Jay Gould's theory in "Ontogeny and Phylogeny" that the paedomorphic (childlike) form of early hominin craniofacial morphology results from dissociation of growth trajectories.

Clark and Henneberg also argued that such shortening of the skull—which may have caused a descension of the larynx—as well as lordosis—allowing better movement of the larynx—increased vocal ability, significantly pushing back the origin of language to well before the evolution of "Homo". They argued that self domestication was aided by the development of vocalization, living in a pro-social society. They conceded that chimps and "A. ramidus" likely had the same vocal capabilities, but said that "A. ramidus" made use of more complex vocalizations, and vocalized at the same level as a human infant due to selective pressure to become more social. This would have allowed their society to become more complex. They also noted that the base of the skull stopped growing with the brain by the end of juvenility, whereas in chimps it continues growing with the rest of the body into adulthood; and considered this evidence of a switch from a gross skeletal anatomy trajectory to a neurological development trajectory due to selective pressure for sociability. Nonetheless, their conclusions are highly speculative.

According to Scott Simpson, the Gona Project's physical anthropologist, the fossil evidence from the Middle Awash indicates that both "A. kadabba" and "A. ramidus" lived in "a mosaic of woodland and grasslands with lakes, swamps and springs nearby," but further research is needed to determine which habitat "Ardipithecus" at Gona preferred.




</doc>
<doc id="1146" url="https://en.wikipedia.org/wiki?curid=1146" title="Assembly line">
Assembly line

An assembly line is a manufacturing process (often called a "progressive assembly") in which parts (usually interchangeable parts) are added as the semi-finished assembly moves from workstation to workstation where the parts are added in sequence until the final assembly is produced. By mechanically moving the parts to the assembly work and moving the semi-finished assembly from work station to work station, a finished product can be assembled faster and with less labor than by having workers carry parts to a stationary piece for assembly.

Assembly lines are common methods of assembling complex items such as automobiles and other transportation equipment, household appliances and electronic goods.

Workers in charge of the works of assembly line are called assemblers.

Assembly lines are designed for the sequential organization of workers, tools or machines, and parts. The motion of workers is minimized to the extent possible. All parts or assemblies are handled either by conveyors or motorized vehicles such as fork lifts, or gravity, with no manual trucking. Heavy lifting is done by machines such as overhead cranes or forklifts. Each worker typically performs one simple operation unless job rotation strategies are applied.

According to Henry Ford:

Designing assembly lines is a well-established mathematical challenge, referred to as assembly line balancing problem. In the simple assembly line balancing problem the aim is to assign a set of tasks which need to be performed on the work-piece to a sequence of workstations. Each task requires a given task duration for completion. The assignment of tasks to stations is typically limited by two constraints: (1) a precedence graph which indicates what other tasks need to be completed before a particular tasks can be initiated (e.g. not putting in a screw before drilling the hole) and (2) a cycle time which restricts the sum of task processing times which can be completed at each workstation before the work-piece is moved to the next station by they conveyor belt. Major planning problems for operating assembly lines include supply chain integration, inventory control and production scheduling.

Consider the assembly of a car: assume that certain steps in the assembly line are to install the engine, install the hood, and install the wheels (in that order, with arbitrary interstitial steps); only one of these steps can be done at a time. In traditional production, only one car would be assembled at a time. If engine installation takes 20 minutes, hood installation takes five minutes, and wheels installation takes 10 minutes, then a car can be produced every 35 minutes.

In an assembly line, car assembly is split between several stations, all working simultaneously. When a station is finished with a car, it passes it on to the next. By having three stations, three cars can be operated on at the same time, each at a different stage of assembly.

After finishing its work on the first car, the engine installation crew can begin working on the second car. While the engine installation crew works on the second car, the first car can be moved to the hood station and fitted with a hood, then to the wheels station and be fitted with wheels. After the engine has been installed on the second car, the second car moves to the hood assembly. At the same time, the third car moves to the engine assembly. When the third car's engine has been mounted, it then can be moved to the hood station; meanwhile, subsequent cars (if any) can be moved to the engine installation station.

Assuming no loss of time when moving a car from one station to another, the longest stage on the assembly line determines the throughput (20 minutes for the engine installation) so a car can be produced every 20 minutes, once the first car taking 35 minutes has been produced.

Before the Industrial Revolution, most manufactured products were made individually by hand. A single craftsman or team of craftsmen would create each part of a product. They would use their skills and tools such as files and knives to create the individual parts. They would then assemble them into the final product, making cut-and-try changes in the parts until they fit and could work together (craft production).

Division of labor was practiced in China, where state-run monopolies mass-produced metal agricultural implements, china, armor, and weapons centuries before mass production appeared in Europe on the eve of the Industrial Revolution. Adam Smith discussed the division of labour in the manufacture of pins at length in his book "The Wealth of Nations" (published in 1776).

The Venetian Arsenal, dating to about 1104, operated similar to a production line. Ships moved down a canal and were fitted by the various shops they passed. At the peak of its efficiency in the early 16th century, the Arsenal employed some 16,000 people who could apparently produce nearly one ship each day, and could fit out, arm, and provision a newly built galley with standardized parts on an assembly-line basis. Although the Arsenal lasted until the early Industrial Revolution, production line methods did not become common even then.

The Industrial Revolution led to a proliferation of manufacturing and invention. Many industries, notably textiles, firearms, clocks and watches, horse-drawn vehicles, railway locomotives, sewing machines, and bicycles, saw expeditious improvement in materials handling, machining, and assembly during the 19th century, although modern concepts such as industrial engineering and logistics had not yet been named.

The automatic flour mill built by Oliver Evans in 1785 was called the beginning of modern bulk material handling by Roe (1916). Evans's mill used a leather belt bucket elevator, screw conveyors, canvas belt conveyors, and other mechanical devices to completely automate the process of making flour. The innovation spread to other mills and breweries.

Probably the earliest industrial example of a linear and continuous assembly process is the Portsmouth Block Mills, built between 1801 and 1803. Marc Isambard Brunel (father of Isambard Kingdom Brunel), with the help of Henry Maudslay and others, designed 22 types of machine tools to make the parts for the rigging blocks used by the Royal Navy. This factory was so successful that it remained in use until the 1960s, with the workshop still visible at HM Dockyard in Portsmouth, and still containing some of the original machinery.

One of the earliest examples of an almost modern factory layout, designed for easy material handling, was the Bridgewater Foundry. The factory grounds were bordered by the Bridgewater Canal and the Liverpool and Manchester Railway. The buildings were arranged in a line with a railway for carrying the work going through the buildings. Cranes were used for lifting the heavy work, which sometimes weighed in the tens of tons. The work passed sequentially through to erection of framework and final assembly.

The first flow assembly line was initiated at the factory of Richard Garrett & Sons, Leiston Works in Leiston in the English county of Suffolk for the manufacture of portable steam engines. The assembly line area was called 'The Long Shop' on account of its length and was fully operational by early 1853. The boiler was brought up from the foundry and put at the start of the line, and as it progressed through the building it would stop at various stages where new parts would be added. From the upper level, where other parts were made, the lighter parts would be lowered over a balcony and then fixed onto the machine on the ground level. When the machine reached the end of the shop, it would be completed.

During the early 19th century, the development of machine tools such as the screw-cutting lathe, metal planer, and milling machine, and of toolpath control via jigs and fixtures, provided the prerequisites for the modern assembly line by making interchangeable parts a practical reality.

Steam powered conveyor lifts began being used for loading and unloading ships some time in the last quarter of the 19th century. Hounshell (1984) shows a sketch of an electric powered conveyor moving cans through a filling line in a canning factory.

The meatpacking industry of Chicago is believed to be one of the first industrial assembly lines (or dis-assembly lines) to be utilized in the United States starting in 1867. Workers would stand at fixed stations and a pulley system would bring the meat to each worker and they would complete one task. Henry Ford and others have written about the influence of this slaughterhouse practice on the later developments at Ford Motor Company.

According to Domm, the implementation of mass production of an automobile via an assembly line may be credited to Ransom Olds, who used it to build the first mass-produced automobile, the Oldsmobile Curved Dash. Olds patented the assembly line concept, which he put to work in his Olds Motor Vehicle Company factory in 1901.

At Ford Motor Company, the assembly line was introduced by William "Pa" Klann upon his return from visiting Swift & Company's slaughterhouse in Chicago and viewing what was referred to as the "disassembly line", where carcasses were butchered as they moved along a conveyor. The efficiency of one person removing the same piece over and over without himself moving caught his attention. He reported the idea to Peter E. Martin, soon to be head of Ford production, who was doubtful at the time but encouraged him to proceed. Others at Ford have claimed to have put the idea forth to Henry Ford, but Pa Klann's slaughterhouse revelation is well documented in the archives at the Henry Ford Museum and elsewhere, making him an important contributor to the modern automated assembly line concept. Ford was appreciative, having visited the highly automated 40-acre Sears mail order handling facility around 1906. At Ford, the process was an evolution by trial and error of a team consisting primarily of Peter E. Martin, the factory superintendent; Charles E. Sorensen, Martin's assistant; Clarence W. Avery; C. Harold Wills, draftsman and toolmaker; Charles Ebender; and József Galamb. Some of the groundwork for such development had recently been laid by the intelligent layout of machine tool placement that Walter Flanders had been doing at Ford up to 1908.

The moving assembly line was developed for the Ford Model T and began operation on October 7, 1913, at the Highland Park Ford Plant, and continued to evolve after that, using time and motion study. The assembly line, driven by conveyor belts, reduced production time for a Model T to just 93 minutes by dividing the process into 45 steps. Producing cars quicker than paint of the day could dry, it had an immense influence on the world.

In 1922, Ford (through his ghostwriter Crowther) said of his 1913 assembly line:

Charles E. Sorensen, in his 1956 memoir "My Forty Years with Ford", presented a different version of development that was not so much about individual "inventors" as a gradual, logical development of industrial engineering:

As a result of these developments in method, Ford's cars came off the line in three-minute intervals, or six feet per minute. This was much faster than previous methods, increasing production by eight to one (requiring 12.5 man-hours before, 1 hour 33 minutes after), while using less manpower. It was so successful, paint became a bottleneck. Only japan black would dry fast enough, forcing the company to drop the variety of colors available before 1914, until fast-drying Duco lacquer was developed in 1926.

The assembly line technique was an integral part of the diffusion of the automobile into American society. Decreased costs of production allowed the cost of the Model T to fall within the budget of the American middle class. In 1908, the price of a Model T was around $825, and by 1912 it had decreased to around $575. This price reduction is comparable to a reduction from $15,000 to $10,000 in dollar terms from the year 2000. In 1914, an assembly line worker could buy a Model T with four months' pay.

Ford's complex safety procedures—especially assigning each worker to a specific location instead of allowing them to roam about—dramatically reduced the rate of injury. The combination of high wages and high efficiency is called "Fordism", and was copied by most major industries. The efficiency gains from the assembly line also coincided with the take-off of the United States. The assembly line forced workers to work at a certain pace with very repetitive motions which led to more output per worker while other countries were using less productive methods.

In the automotive industry, its success was dominating, and quickly spread worldwide. Ford France and Ford Britain in 1911, Ford Denmark 1923, Ford Germany and Ford Japan 1925; in 1919, Vulcan (Southport, Lancashire) was the first native European manufacturer to adopt it. Soon, companies had to have assembly lines, or risk going broke by not being able to compete; by 1930, 250 companies which did not had disappeared.

The massive demand for military hardware in World War II prompted assembly-line techniques in shipbuilding and aircraft production. Thousands of Liberty Ships were built making extensive use of prefabrication, enabling ship assembly to be completed in weeks or even days. After having produced fewer than 3,000 planes for the United States Military in 1939, American aircraft manufacturers built over 300,000 planes in World War II. Vultee pioneered the use of the powered assembly line for aircraft manufacturing. Other companies quickly followed. As William S. Knudsen (having worked at Ford, GM and the National Defense Advisory Commission) observed, "We won because we smothered the enemy in an avalanche of production, the like of which he had never seen, nor dreamed possible."

In his 1922 autobiography, Henry Ford mentions several benefits of the assembly line including:

The gains in productivity allowed Ford to increase worker pay from $1.50 per day to $5.00 per day once employees reached three years of service on the assembly line. Ford continued on to reduce the hourly work week while continuously lowering the Model T price. These goals appear altruistic; however, it has been argued that they were implemented by Ford in order to reduce high employee turnover: when the assembly line was introduced in 1913, it was discovered that "every time the company wanted to add 100 men to its factory personnel, it was necessary to hire 963" in order to counteract the natural distaste the assembly line seems to have inspired.

Sociological work has explored the social alienation and boredom that many workers feel because of the repetition of doing the same specialized task all day long.

One of capitalism's most famous critics, Karl Marx, expressed in his "Entfremdung" theory the belief that in order to achieve job satisfaction workers need to see themselves in the objects they have created, that products should be "mirrors in which workers see their reflected essential nature." Marx viewed labour as a chance for us to externalize facets of our personality. Marxists argue that specialization makes it very difficult for any worker to feel they may be contributing to the real needs of humanity. The repetitive nature of specialized tasks causes, they say, a feeling of disconnection between what a worker does all day, who they really are, and what they would ideally be able to contribute to society. Marx also argued that specialised jobs are insecure, since the worker is expendable as soon as costs rise and technology can replace more expensive human labour.

Since workers have to stand in the same place for hours and repeat the same motion hundreds of times per day repetitive stress injuries are a possible pathology of occupational safety. Industrial noise also proved dangerous. When it was not too high, workers were often prohibited from talking. Charles Piaget, a skilled worker at the LIP factory, recalled that beside being prohibited from speaking, the semi-skilled workers had only 25 centimeters in which to move. Industrial ergonomics later tried to minimize physical trauma.




</doc>
<doc id="1148" url="https://en.wikipedia.org/wiki?curid=1148" title="Adelaide">
Adelaide

Adelaide ( , is the capital city of the state of South Australia, and the fifth-most populous city of Australia. The demonym is used to denote the city and the residents of Adelaide.

Adelaide is situated on the Adelaide Plains north of the Fleurieu Peninsula, between the Gulf St Vincent in the west and the Mount Lofty Ranges in the east. Its metropolitan area extends from the coast to the foothills of the Mount Lofty Ranges, and stretches from Gawler in the north to Sellicks Beach in the south.

Named in honour of Queen Adelaide, consort to King William IV, the city was founded in 1836 as the planned capital for the only freely-settled British province in Australia. Colonel William Light, one of Adelaide's founding fathers, designed the city centre and chose its location close to the River Torrens, in the area originally inhabited by the Kaurna people and known as "Tarndanyangga" ("place of the red kangaroo"). Light's design, now listed as national heritage, set out the city centre in a grid layout known as "Light's Vision", interspaced by wide boulevards and large public squares, and entirely surrounded by parklands.

Early colonial Adelaide was shaped by the diversity and wealth of its free settlers, in contrast to the convict history of other Australian cities. Until the post-war era, it was Australia's third-largest city. It has been noted for its leading examples of religious freedom and progressive political reforms, and became known as the "City of Churches" due to its diversity of faiths. Today, Adelaide is noted for and sporting events, its food and wine, its coastline and hills, and its large defence and manufacturing sectors. Adelaide's quality of life has ranked consistently highly in various measures through the 21st century.

As South Australia's government and commercial centre, Adelaide is the site of many governmental and financial institutions. Most of these are concentrated in the city centre along the cultural boulevards of North Terrace and King William Street.

Before its proclamation as a British settlement in 1836, the area around Adelaide was inhabited by the indigenous Kaurna people, one of many Aboriginal nations in South Australia. The city and parklands area was known as Tarntanya, or Tarndanyangga in the Kaurna language. The surrounding area was an open grassy plain with patches of trees and shrub which had been managed by hundreds of generations. Kaurna country encompassed the plains which stretched north and south of Tarntanya as well as the wooded foothills of the Mt Lofty Ranges. The River Torrens was known as the Karrawirra Pari (red gum forest river). About 300 Kaurna populated the Adelaide area, and were referred to by the settlers as the Cowandilla.

The Kaurna language was a complex one, reflecting their sophisticated culture and deep environmental knowledge. Within a few decades of European settlement of South Australia, Kaurna culture and language were almost completely destroyed. Extensive documentation by early missionaries and other researchers has enabled a modern revival of both, which has included a commitment by local and state governments to rename or include Kaurna names for many local places.

South Australia was officially established as a British Province in England in February 1836. The first Governor 
proclaimed the commencement of colonial government in South Australia on 28 December 1836, near The Old Gum Tree in what is now the suburb of Glenelg North. The event is commemorated in South Australia as Proclamation Day. The site of the colony's capital was surveyed and laid out by Colonel William Light, the first Surveyor-General of South Australia, with his own original, unique, topographically sensitive design.
Claims of the design being by the architect George Strickland Kingston have been thoroughly debunked. The city was named after Adelaide of Saxe-Meiningen, queen consort to King William IV at the time.

Adelaide was established as a planned colony of free immigrants, promising civil liberties and freedom from religious persecution, based upon the ideas of Edward Gibbon Wakefield. Wakefield had read accounts of Australian settlement while in prison in London for attempting to abduct an heiress, and realised that the eastern colonies suffered from a lack of available labour, due to the practice of giving land grants to all arrivals. Wakefield's idea was for the Government to survey and sell the land at a rate that would maintain land values high enough to be unaffordable for labourers and journeymen. Funds raised from the sale of land were to be used to bring out working-class emigrants, who would have to work hard for the monied settlers to ever afford their own land. As a result of this policy, Adelaide does not share the convict settlement history of other Australian cities like Sydney, Brisbane and Hobart.

As it was believed that in a colony of free settlers there would be little crime, no provision was made for a gaol in Colonel Light's 1837 plan. But by mid-1837 the "South Australian Register" was warning of escaped convicts from New South Wales and tenders for a temporary gaol were sought. Following a burglary, a murder, and two attempted murders in Adelaide during March 1838, Governor Hindmarsh created the South Australian Police Force (now the South Australia Police) in April 1838 under 21-year-old Henry Inman. The first sheriff, Samuel Smart, was wounded during a robbery, and on 2 May 1838 one of the offenders, Michael Magee, became the first person to be hanged in South Australia. William Baker Ashton was appointed governor of the temporary gaol in 1839, and in 1840 George Strickland Kingston was commissioned to design Adelaide's new gaol. Construction of Adelaide Gaol commenced in 1841.

Adelaide's early history was marked by economic uncertainty and questionable leadership. The first governor of South Australia, John Hindmarsh, clashed frequently with others, in particular the Resident Commissioner, James Hurtle Fisher. The rural area surrounding Adelaide was surveyed by Light in preparation to sell a total of over of land. Adelaide's early economy started to get on its feet in 1838 with the arrival of livestock from Victoria, New South Wales and Tasmania. Wool production provided an early basis for the South Australian economy. By 1860, wheat farms had been established from Encounter Bay in the south to Clare in the north.

George Gawler took over from Hindmarsh in late 1838 and, despite being under orders from the "Select Committee on South Australia" in Britain not to undertake any public works, promptly oversaw construction of a governor's house, the Adelaide Gaol, police barracks, a hospital, a customs house and a wharf at Port Adelaide. Gawler was recalled and replaced by George Edward Grey in 1841. Grey slashed public expenditure against heavy opposition, although its impact was negligible at this point: silver was discovered in Glen Osmond that year, agriculture was well underway, and other mines sprung up all over the state, aiding Adelaide's commercial development. The city exported meat, wool, wine, fruit and wheat by the time Grey left in 1845, contrasting with a low point in 1842 when one-third of Adelaide houses were abandoned.

Trade links with the rest of the Australian states were established after the Murray River was successfully navigated in 1853 by Francis Cadell, an Adelaide resident. South Australia became a self-governing colony in 1856 with the ratification of a new constitution by the British parliament. Secret ballots were introduced, and a bicameral parliament was elected on 9 March 1857, by which time 109,917 people lived in the province.

In 1860 the Thorndon Park reservoir was opened, finally providing an alternative water source to the now turbid River Torrens. Gas street lighting was implemented in 1867, the University of Adelaide was founded in 1874, the South Australian Art Gallery opened in 1881 and the Happy Valley Reservoir opened in 1896. In the 1890s Australia was affected by a severe economic depression, ending a hectic era of land booms and tumultuous expansionism. Financial institutions in Melbourne and banks in Sydney closed. The national fertility rate fell and immigration was reduced to a trickle. The value of South Australia's exports nearly halved. Drought and poor harvests from 1884 compounded the problems, with some families leaving for Western Australia. Adelaide was not as badly hit as the larger gold-rush cities of Sydney and Melbourne, and silver and lead discoveries at Broken Hill provided some relief. Only one year of deficit was recorded, but the price paid was retrenchments and lean public spending. Wine and copper were the only industries not to suffer a downturn.

Adelaide was Australia's third largest city for most of the 20th century. Electric street lighting was introduced in 1900 and electric trams were transporting passengers in 1909. 28,000 men were sent to fight in World War I. Historian F. W. Crowley examined the reports of visitors in the early 20th century, noting that "many visitors to Adelaide admired the foresighted planning of its founders", as well as pondering the riches of the young city. Adelaide enjoyed a postwar boom, entering a time of relative prosperity. Its population grew, and it became the third most populous metropolitan area in the country, after Sydney and Melbourne. Its prosperity was short-lived, with the return of droughts and the Great Depression of the 1930s. It later returned to fortune under strong government leadership. Secondary industries helped reduce the state's dependence on primary industries. World War II brought industrial stimulus and diversification to Adelaide under the Playford Government, which advocated Adelaide as a safe place for manufacturing due to its less vulnerable location. Shipbuilding was expanded at the nearby port of Whyalla.

The South Australian Government in this period built on former wartime manufacturing industries but neglected cultural facilities which meant South Australia's economy lagged behind. International manufacturers like General Motors Holden and Chrysler made use of these factories around the Adelaide area in suburbs like Elizabeth, completing its transformation from an agricultural service centre to a 20th-century city. The Mannum–Adelaide pipeline brought River Murray water to Adelaide in 1955 and an airport opened at West Beach in 1955. Flinders University and the Flinders Medical Centre were established in the 1960s at Bedford Park, south of the city. Today, Flinders Medical Centre is one of the largest teaching hospitals in South Australia. In the post-war years around the early 1960s Adelaide was surpassed by Brisbane as Australia's third largest city.

The Dunstan Governments of the 1970s saw something of an Adelaide 'cultural revival', establishing a wide array of social reforms. The city became noted for its progressivism as South Australia became the first Australian state or territory to decriminalise homosexuality between consenting adults in 1975. It also became a centre for the arts, building upon the biennial "Adelaide Festival of Arts" that commenced in 1960. Adelaide hosted the Formula One Australian Grand Prix between 1985 and 1996 on a street circuit in the city's east parklands; it moved to Melbourne in 1996. The State Bank collapsed in 1991 during an economic recession; the effects lasted until 2004, when Standard & Poor's reinstated South Australia's AAA credit rating. Since 1999, the Adelaide 500 Supercars race has made use of sections of the former Formula One circuit. Adelaide's tallest building, built in 1988, was originally known as the State Bank Building. In 1991 it was renamed the Santos Building and in 2006 it was renamed Westpac House, and it is currently the 160th tallest building in Australia.

In the early years of the 21st century, a significant increase in the state government's spending on Adelaide's infrastructure occurred. The Rann government invested A$535 million in a major upgrade of the Adelaide Oval to enable Australian Football League to be played in the city centre and more than A$2 billion to build a new Royal Adelaide Hospital on land adjacent to the Adelaide Railway Station. The Glenelg tramline was extended through the city to Hindmarsh down to East Terrace and the suburban railway line extended south to Seaford.

Following a period of stagnation in the 1990s and 2000s, Adelaide began several major developments and redevelopments. The Adelaide Convention Centre was redeveloped and expanded at a cost of A$350 million beginning in 2012. Three historic buildings were adapted for modern use: the Torrens Building in Victoria Square as the Adelaide campus for Carnegie Mellon University, University College London, and Torrens University; the Stock Exchange building as the Science Exchange of the Royal Institution Australia; and the Glenside Psychiatric Hospital as the Adelaide Studios of the SA Film Corporation. The government also invested more than A$2 billion to build a desalination plant, powered by renewable energy, as an 'insurance policy' against droughts affecting Adelaide's water supply. The Adelaide Festival, Fringe, and Womadelaide became annual events.

Adelaide is north of the Fleurieu Peninsula, on the Adelaide Plains between the Gulf St Vincent and the low-lying Mount Lofty Ranges. The city stretches from the coast to the foothills, and from Gawler at its northern extent to Sellicks Beach in the south. According to the Regional Development Australia, an Australian government planning initiative, the "Adelaide Metropolitan Region" has a total land area of , while a more expansive definition by the Australian Bureau of Statistics defines a "Greater Adelaide" statistical area totalling . The city sits at an average elevation of above sea level. Mount Lofty, east of the Adelaide metropolitan region in the Adelaide Hills at an elevation of , is the tallest point of the city and in the state south of Burra.
Much of Adelaide was bushland before British settlement, with some variation – sandhills, swamps and marshlands were prevalent around the coast. The loss of the sandhills to urban development had a particularly destructive effect on the coastline due to erosion. Where practical, the government has implemented programs to rebuild and vegetate sandhills at several of Adelaide's beachside suburbs. Much of the original vegetation has been cleared with what is left to be found in reserves such as the Cleland Conservation Park and Belair National Park. A number of creeks and rivers flow through the Adelaide region. The largest are the Torrens and Onkaparinga catchments. Adelaide relies on its many reservoirs for water supply with the Happy Valley Reservoir supplying around 40% and the much larger Mount Bold Reservoir 10% of Adelaide's domestic requirements respectively.

Adelaide and its surrounding area is one of the most seismically active regions in Australia. On 1 March 1954 at 3:40 am Adelaide experienced its largest recorded earthquake to date, with the epicentre 12 km from the city centre at Darlington, and a reported magnitude of 5.6. There have been smaller earthquakes in 2010, 2011, 2014, 2017, and 2018.

Adelaide is a planned city, designed by the first Surveyor-General of South Australia, Colonel William Light. His plan, sometimes referred to as "Light's Vision" (also the name of a statue of him on Montefiore Hill), arranged Adelaide in a grid, with in the Adelaide city centre and a ring of parks, known as the Adelaide Parklands, surrounding it. Light's selection of the location for the city was initially unpopular with the early settlers, as well as South Australia's first governor, John Hindmarsh, due to its distance from the harbour at Port Adelaide, and the lack of fresh water there. Light successfully persisted with his choice of location against this initial opposition. Recent evidence suggests that Light worked closely with George Kingston as well as a team of men to set out Adelaide, using various templates for city plans going back to Ancient Greece, including Italian Renaissance designs and the similar layouts of the American cities Philadelphia and Savannah–which, like Adelaide, follow the same layout of a central city square, four complementing city squares surrounding it and a parklands area that surround the city centre.

The benefits of Light's design are numerous: Adelaide has had wide multi-lane roads from its beginning, an easily navigable cardinal direction grid layout and an expansive green ring around the city centre. There are two sets of ring roads in Adelaide that have resulted from the original design. The inner ring route (A21) borders the parklands, and the outer route (A3/A13/A16/A17) completely bypasses the inner city via (in clockwise order) Grand Junction Road, Hampstead Road, Ascot Avenue, Portrush Road, Cross Road and South Road.

Suburban expansion has to some extent outgrown Light's original plan. Numerous former outlying villages and "country towns", as well as the satellite city of Elizabeth, have been enveloped by its suburban sprawl. Expanding developments in the Adelaide Hills region led to the construction of the South Eastern Freeway to cope with growth, which has subsequently led to new developments and further improvements to that transport corridor. Similarly, the booming development in Adelaide's South led to the construction of the Southern Expressway.

New roads are not the only transport infrastructure developed to cope with the urban growth. The O-Bahn Busway is an example of a unique solution to Tea Tree Gully's transport woes in the 1980s. The development of the nearby suburb of Golden Grove in the late 1980s is an example of well-thought-out urban planning.

In the 1960s, a Metropolitan Adelaide Transport Study Plan was proposed to cater for the future growth of the city. The plan involved the construction of freeways, expressways and the upgrade of certain aspects of the public transport system. The then premier Steele Hall approved many parts of the plan and the government went as far as purchasing land for the project. The later Labor government elected under Don Dunstan shelved the plan, but allowed the purchased land to remain vacant, should the future need for freeways arise. In 1980, the Liberal party won government and premier David Tonkin committed his government to selling off the land acquired for the MATS plan, ensuring that even when needs changed, the construction of most MATS-proposed freeways would be impractical. Some parts of this land have been used for transport, (e.g. the O-Bahn Busway and Southern Expressway), while most has been progressively subdivided for residential use.

In 2008, the SA Government announced plans for a network of transport-oriented developments across the Adelaide metropolitan area and purchased a 10 hectare industrial site at Bowden for $52.5 million as the first of these developments. The site covers 102,478 square metres, or about 10 hectares, and is bounded by Park Terrace to the south, the Adelaide to Outer Harbour railway line to the west, Drayton Street to the north and Sixth and Seventh Streets to the east.

Historically, Adelaide's suburban residential areas have been characterised by single-storey detached houses built on blocks. A relative lack of suitable, locally-available timber for construction purposes led to the early development of a brick-making industry, as well as the use of stone, for houses and other buildings. By 1891 68% of houses were built of stone, 15% of timber, and 10% of brick, with brick also being widely used in stone houses for quoins, door and window surrounds, and chimneys and fireplaces.

There is a wide variety in the styles of these houses. Until the 1960s most of the more substantial houses were built of red brick, though many front walls were of ornamental stone. Then cream bricks became fashionable, and in the 1970s, deep red and brown bricks became popular. Until the 1970s, roofs tended to be clad with (painted) corrugated iron or tiles (cement or clay, usually red "terracotta"). Since then, Colorbond corrugated steel has dominated. Most roofs are pitched; flat roofs are not common. Up to the 1970s, most houses were of "double brick" construction on concrete footings, with timber floors laid on joists supported by "dwarf walls". Later houses have mainly been of "brick veneer" construction – structural timber or, more recently, lightweight steel frame on a concrete slab foundation, lined with Gyprock, and with an outer skin of brickwork, to cope with Adelaide's reactive soils, particularly Keswick Clay, black earth and some red-brown earth soils. The use of precast concrete panels for floor and wall construction has also increased. In addition to this, a significant factor in Adelaide's suburban history is the role of the South Australian Housing Trust.

Adelaide has a hot-summer Mediterranean climate (Köppen climate classification: Csa). The city has hot, dry summers and cool winters with moderate rainfall. Most precipitation falls in the winter months, leading to the suggestion that the climate be classified as a "cold monsoon". Rainfall is unreliable, light and infrequent throughout summer, although heavy falls can occur. In contrast, the winter has fairly reliable rainfall with June being the wettest month of the year, averaging around 80 mm. Frosts are occasional, with the most notable occurrences in July 1908 and July 1982. Hail is also common in winter. Adelaide is a windy city with significant wind chill in winter, which makes the temperature seem colder than it actually is. Snowfall in the metropolitan area is extremely uncommon, although light and sporadic falls in the nearby hills and at Mount Lofty occur during winter. Dewpoints in the summer typically range from . There are usually several days in summer where the temperature reaches or above; the frequency of these temperatures has been increasing in recent years.

The average sea temperature ranges from in August to in February.

Adelaide has been consistently listed in the world's top 10 most liveable cities through the 2010s by The Economist Intelligence Unit, although it dropped to tenth place in 2018 after holding fifth position in the previous three years. It was ranked the most liveable city in Australia by the Property Council of Australia, based on surveys of residents’ views of their own city, between 2010 and 2013, dropping to second place in 2014. Greener spaces for sustainable living is an initiative that has proven to create happier residents and is one of the factors that contributes to Adelaide making the top 10 of the world's most liveable cities. For a relatively small city it boasts 29 large public parks as well as a botanical garden in the heart of the city. The reduction of Adelaide's tree canopy cover over recent years due to excessive tree removal for new construction has led to the creation of an urban heat island, an increase in the cost of housing and a decrease of overall state of well-being.

Adelaide, as the capital of South Australia, is the seat of the Government of South Australia as well as the bicameral Parliament of South Australia, which consists of the lower house known as the House of Assembly and the upper house known as the Legislative Council. General elections are held every four years, the last being the 2018 election. As Adelaide is South Australia's capital and most populous city, the State Government co-operates extensively with the City of Adelaide. In 2006, the Ministry for the City of Adelaide was created to facilitate the State Government's collaboration with the Adelaide City Council and the Lord Mayor to improve Adelaide's image. The State Parliament's Capital City Committee is also involved in the governance of the City of Adelaide, being primarily concerned with the planning of Adelaide's urban development and growth.

Reflecting South Australia's status as Australia's most centralised state, Adelaide elects a substantial majority of the South Australian House of Assembly. Of the 47 seats in the chamber, 34 seats (three-quarters of the legislature) are based in Adelaide, and two rural seats include Adelaide suburbs.

The Adelaide metropolitan area is divided between nineteen local government areas. At its centre, the City of Adelaide administers the Adelaide city centre, North Adelaide, and the surrounding Adelaide Parklands. It is the oldest municipal authority in Australia and was established in 1840, when Adelaide and Australia's first mayor, James Hurtle Fisher, was elected. From 1919 onwards, the City has had a Lord Mayor, the current being Lord Mayor "The Right Honourable" Sandy Verschoor.

Adelaide's inhabitants are known as Adelaideans.

Compared with Australia's four other major state capitals, Adelaide is growing at a much slower rate. In 2017, it had a metropolitan population (including suburbs) of more than 1,345,777, making it Australia's fifth-largest city. Some 77% of the population of South Australia are residents of the Adelaide metropolitan area, making South Australia one of the most centralised states.

Major areas of population growth in recent years have been in outer suburbs such as Mawson Lakes and Golden Grove. Adelaide's inhabitants occupy 366,912 houses, 57,695 semi-detached, row terrace or town houses and 49,413 flats, units or apartments.

About one sixth (17.1%) of the population had university qualifications. The number of Adelaideans with vocational qualifications (such as tradespersons) fell from 62.1% of the labour force in the 1991 census to 52.4% in the 2001 census.

Adelaide is ageing more rapidly than other Australian capital cities. More than a quarter (27.5%) of Adelaide's population is aged 55 years or older, in comparison to the national average of 25.6%. Adelaide has the lowest number of children (under-15-year-olds), who comprised 17.7% of the population, compared to the national average of 19.3%.

At the 2016 census, the most commonly nominated ancestries were: 
Overseas-born Adelaideans composed 31.8% of the total population at the 2016 census. The five largest groups of overseas-born were from England (6.2%), India (2%), China (1.8%), Italy (1.3%) and Vietnam (1.1%).

Suburbs including Newton, Payneham and Campbelltown in the east and Torrensville, West Lakes and Fulham to the west, have large Greek and Italian communities. The Italian consulate is located in the eastern suburb of Payneham. Large Vietnamese populations are settled in the north-western suburbs of Woodville, Kilkenny, Pennington, Mansfield Park and Athol Park and also Parafield Gardens and Pooraka in Adelaide's north. Migrants from India and Sri Lanka have settled into inner suburban areas of Adelaide including the inner northern suburbs of Blair Athol, Kilburn and Enfield and the inner southern suburbs of Plympton, Park Holme and Kurralta Park.

Suburbs such as Para Hills, Salisbury, Ingle Farm and Blair Athol in the north and Findon, West Croydon and Seaton and other Western suburbs have sizeable Afghan communities. Chinese migrants favour settling in the eastern and north eastern suburbs including Kensington Gardens, Greenacres, Modbury and Golden Grove. Mawson Lakes has a large international student population, due to its proximity to the University of South Australia campus.

1.4% of the population, or 18,403 people, identified as Indigenous Australians (Aboriginal Australians and Torres Strait Islanders) in 2016.

At the 2016 census, 75.4% of the population spoke English at home. The other languages most commonly spoken at home were Italian (2.1%), Standard Mandarin (2.1%), Greek (1.7%) Vietnamese (1.4%), and Cantonese (0.7%).

Adelaide was founded on a vision of religious tolerance that attracted a wide variety of religious practitioners. This led to it being known as "The City of Churches". But approximately 28% of the population expressed no religious affiliation in the 2011 Census, compared with the national average of 22.3%, making Adelaide one of Australia's least religious cities. Over half of the population of Adelaide identifies as Christian, with the largest denominations being Catholic (21.3%), Anglican (12.6%), Uniting Church (7.6%) and Eastern Orthodox (3.5%).

The Jewish community of the city dates back to 1840. Eight years later, 58 Jews lived in the city. A synagogue was built in 1871, when 435 Jews lived in the city. Many took part in the city councils, such as Judah Moss Solomon (1852–66) and others after him. Three Jews have been elected to the position of city mayor. In 1968, the Jewish population of Adelaide numbered about 1,200; in 2001, according to the Australian census, 979 persons declared themselves to be Jewish by religion. In 2011, over 1,000 Jews were living in the city, operating an orthodox and a reform school, in addition to a virtual Jewish museum.

The "Afghan" community in Australia first became established in the 1860s when camels and their Pathan, Punjabi, Baluchi and Sindhi handlers began to be used to open up settlement in the continent's arid interior. Until eventually superseded by the advent of the railways and motor vehicles, camels played an invaluable economic and social role in transporting heavy loads of goods to and from isolated settlements and mines. This is acknowledged by the name of The Ghan, the passenger train operating between Adelaide, Alice Springs, and Darwin. The Central Adelaide Mosque is regarded as Australia's oldest permanent mosque; an earlier mosque at Marree in northern South Australia, dating from 1861 to 1862 and subsequently abandoned or demolished, has now been rebuilt.

South Australia's largest employment sectors are health care and social assistance, surpassing manufacturing in SA as the largest employer since 2006–07. In 2009–10, manufacturing in SA had average annual employment of 83,700 persons compared with 103,300 for health care and social assistance. Health care and social assistance represented nearly 13% of the state average annual employment. The Adelaide Hills wine region is an iconic and viable economic region for both the state and country in terms of wine production and sale. The 2014 vintage is reported as consisting of red grapes crushed valued at A$8,196,142 and white grapes crushed valued at $14,777,631.

The retail trade is the second largest employer in SA (2009–10), with 91,900 jobs, and 12 per cent of the state workforce.

Manufacturing, defence technology, high-tech electronic systems and research, commodity export and corresponding service industries all play a role in the SA economy. Almost half of all cars produced in Australia were made in Adelaide at the General Motors Holden plant in Elizabeth. The site ceased operating in November 2017.

The collapse of the State Bank in 1992 resulted in large levels of state public debt (as much as A$4 billion). The collapse meant that successive governments enacted lean budgets, cutting spending, which was a setback to the further economic development of the city and state. The debt has more recently been reduced with the State Government once again receiving a AAA+ Credit Rating.

The global media conglomerate News Corporation was founded in, and until 2004 incorporated in, Adelaide and it is still considered its 'spiritual' home by Rupert Murdoch. Australia's largest oil company, Santos, prominent South Australian brewery, Coopers, and national retailer Harris Scarfe also call Adelaide their home.

The city has been chosen to be the site of the new Australian space center. South Australia is already home to over 80 organisations which employ 800 people in the space sector. The Prime Minister Scott Morrison stated the "agency will act as a launching pad to triple Australia's space economy to $12 billion and create up to 20,000 jobs by 2030."

Adelaide is home to a large proportion of Australia's defence industries, which contribute over A$1 billion to South Australia's Gross State Product. The principal government military research institution, the Defence Science and Technology Organisation, and other defence technology organisations such as BAE Systems Australia and Lockheed Martin Australia, are north of Salisbury and west of Elizabeth in an area now called "Edinburgh Parks", adjacent to RAAF Base Edinburgh.

Others, such as Saab Systems and Raytheon, are in or near Technology Park. ASC Pty Ltd, is based in the industrial suburb of Osborne and is also a part of Technology Park. South Australia was charged with constructing Australia's "Collins" class submarines and more recently the A$6 billion contract to construct the Royal Australian Navy's new air-warfare destroyers.

, Greater Adelaide had an unemployment rate of 7.4% with a youth unemployment rate of 15%.

The median weekly individual income for people aged 15 years and over was $447 per week in 2006, compared with $466 nationally. The median family income was $1,137 per week, compared with $1,171 nationally. Adelaide's housing and living costs are substantially lower than that of other Australian cities, with housing being notably cheaper. The median Adelaide house price is half that of Sydney and two-thirds that of Melbourne. The three-month trend unemployment rate to March 2007 was 6.2%. The Northern suburbs' unemployment rate is disproportionately higher than the other regions of Adelaide at 8.3%, while the East and South are lower than the Adelaide average at 4.9% and 5.0% respectively.

Over the decade March 2001 – March 2010, Metropolitan Adelaide median house prices approximately tripled. (approx. 285% – approx. 11%p.a. compounding)
In the five years March 2007 – March 2012, prices increased by approx. 27% – approx. 5%p.a. compounding. March 2012 – March 2017 saw a further increase of 19% – approx. 3.5%p.a. compounding.

In summary:
Each quarter, The Alternative and Direct Investment Securities Association (ADISA) publishes a list of median house sale prices by suburb and Local Government Area. (Previously, this was done by REISA) Due to the small sizes of many of Adelaide's suburbs, the low volumes of sales in these suburbs, and (over time) the huge variations in the numbers of sales in a suburb in a quarter, statistical analysis of "the most expensive suburb" is unreliable; the suburbs appearing in the "top 10 most expensive suburbs this quarter" list is constantly varying. Quarterly Reports for the last two years can be found on the REISA website.

Education forms an increasingly important part of the city's economy, with the South Australian Government and educational institutions attempting to position Adelaide as "Australia's education hub" and marketing it as a "Learning City." The number of international students studying in Adelaide has increased rapidly in recent years to 30,726 in 2015, of which 1,824 were secondary school students. In addition to the city's existing institutions, foreign institutions have been attracted to set up campuses to increase its attractiveness as an education hub. Adelaide is the birthplace of three Nobel laureates, more than any other Australian city: physicist William Lawrence Bragg and pathologists Howard Florey and Robin Warren, all of whom completed secondary and tertiary education at St Peter's College and the University of Adelaide.

At the level of primary and secondary education, there are two systems of school education. There is a public system operated by the South Australian Government and a private system of independent and Catholic schools. All schools provide education under the South Australian Certificate of Education (SACE) or, to a lesser extent, the International Baccalaureate (IB), with Adelaide having the highest number of IB schools in Australia.

There are three public universities local to Adelaide, as well as one private university and three constituent colleges of foreign universities. Flinders University of South Australia, the University of Adelaide, the University of South Australia and Torrens University Australia—part of the Laureate International Universities are based in Adelaide. The University of Adelaide was ranked in the top 150 universities worldwide. Flinders ranked in the top 250 and Uni SA in the top 300. Torrens University Australia is part of an international network of over 70 higher education institutions in more than 30 countries worldwide. The historic Torrens Building in Victoria Square houses Carnegie Mellon University's Heinz College Australia, and University College London's School of Energy and Resources (Australia), and constitute the city's international university precinct.

The University of Adelaide, with 25,000 students, is Australia's third-oldest university and a member of the leading "Group of Eight". It has five campuses throughout the state, including two in the city-centre, and a campus in Singapore. The University of South Australia, with 37,000 students, has two North Terrace campuses, three other campuses in the metropolitan area and campuses at Whyalla and Mount Gambier. Flinders University, with 25,184 domestic and international students, is in the southern suburb of Bedford Park, alongside the Flinders Medical Centre, another campus in neighbouring Tonsley, and maintains a small city campus in Victoria Square. The plaza on the Bedford Park campus was revamped in 2014 and officially re-opened in 2016.

There are several South Australian TAFE (Technical and Further Education) campuses in the metropolitan area that provide a range of vocational education and training. The Adelaide College of the Arts, as a school of TAFE SA, provides nationally recognised training in visual and performing arts.

In addition to the universities, Adelaide is home to a number of research institutes, including the Royal Institution of Australia, established in 2009 as a counterpart to the two-hundred-year-old Royal Institution of Great Britain. Many of the organisations involved in research tend to be geographically clustered throughout the Adelaide metropolitan area:

While established as a British province, and very much English in terms of its culture, Adelaide attracted immigrants from other parts of Europe early on, including German and other European non-conformists escaping religious persecution. The first German Lutherans arrived in 1838 bringing with them the vine cuttings that they used to found the acclaimed wineries of the Barossa Valley.

The Royal Adelaide Show is an annual agricultural show and state fair, established in 1839 and now a huge event held in the Adelaide Showground annually.

Adelaide's arts scene flourished in the 1960s and 1970s with the support of successive premiers from both major political parties. The renowned Adelaide Festival of Arts was established in 1960 under Thomas Playford, which in the same year spawned an unofficial uncurated series of performances and exhibits which grew into the Adelaide Fringe. Construction of the Adelaide Festival Centre began under Steele Hall in 1970 and was completed under the subsequent government of Don Dunstan, who also established the South Australian Film Corporation in 1972 and the State Opera of South Australia in 1976.

Over time, the Adelaide Festival expanded to include Adelaide Writers' Week and WOMADelaide, and other separate festivals were established, such as the Adelaide Cabaret Festival (2002), the Adelaide Festival of Ideas (1999), the Adelaide Film Festival (2013), FEAST (1999, a queer culture) and Tasting Australia (1997, a food and wine affair). With the Festival, the Fringe, WOMADelaide, Writers' Week and the Adelaide 500 street motor racing event (along with evening music concerts) all happening in early March, the period has become known colloquially as "Mad March".

In 2014, Ghil'ad Zuckermann founded the Adelaide Language Festival.

There are many international cultural fairs, most notably the German Schützenfest and Greek Glendi. Adelaide is home to the Adelaide Christmas Pageant, the world's largest Christmas parade.

As the state capital, Adelaide is home to a great number of cultural institutions with many along the boulevard of North Terrace. The Art Gallery of South Australia, with around 35,000 works, holds Australia's second largest state-based collection. Adjacent are the South Australian Museum and State Library of South Australia, while the Adelaide Botanic Garden, National Wine Centre and Tandanya National Aboriginal Cultural Institute are nearby in the East End of the city. In the back of the State Library lies the Migration Museum, Australia's oldest museum of its kind.

Further west, the Lion Arts Centre is home to ACE Open, which showcases contemporary art, Dance Hub SA and other studio and arts industry office spaces. The Mercury Cinema and JamFactory (ceramics and design gallery) are just around the corner.

The Adelaide Festival Centre (which includes the Dunstan Playhouse, Festival Theatre and Space Theatre), on the banks of the Torrens, is the focal point for much of the cultural activity in the city and home to the State Theatre Company of South Australia. Other live music and theatre venues include the Adelaide Entertainment Centre; Adelaide Oval; Memorial Drive Park; Thebarton Theatre; Adelaide Town Hall; Her Majesty's Theatre; Queen's Theatre; Holden Theatres and the Hopgood Theatre.

The Lion Arts Factory, within the Lion Arts Centre, hosts contemporary music in a wide range of genres, as does "The Gov" in Hindmarsh. The city also has numerous smaller theatres, pubs and cabaret bars which host performances.

In 2015, it was said that there were now more live music venues per capita in Adelaide than any other capital city in the southern hemisphere, "Lonely Planet" labelled Adelaide "Australia's live music city", and the city was recognised as a "City of Music" by the UNESCO Creative Cities Network.

In addition to its own WOMADelaide, Adelaide attracts several touring music festivals, including Creamfields, Laneway and Groovin'.

Adelaide has produced musical groups and individuals who have achieved national and international fame. These include the Adelaide Symphony Orchestra, the Adelaide Youth Orchestra, rock bands The Angels, Cold Chisel, The Superjesus, Wolf & Cub, roots/blues group The Audreys, internationally acclaimed metal acts I Killed The Prom Queen and Double Dragon, popular Australian hip-hop outfit Hilltop Hoods, pop acts like Sia, Orianthi, Guy Sebastian, and Wes Carr, as well as internationally successful tribute act, The Australian Pink Floyd Show.

Noted rocker Jimmy Barnes (formerly lead vocalist with Cold Chisel) spent most of his youth in the northern suburb of Elizabeth. Paul Kelly grew up in Adelaide and was head prefect at Rostrevor College. The first "Australian Idol" winner, Guy Sebastian, hails from the north-eastern suburb of Golden Grove.

Adelaide plays host to two of Australia's leading contemporary dance companies. The Australian Dance Theatre and Dance Hub SA (formerly Leigh Warren & Dancers) contribute to state festivals and perform nationally and internationally. Restless Dance Theatre is also based in Adelaide and is nationally recognised for working with disabled and non-disabled dancers to use movement as a means of expression.

Newspapers in Adelaide are dominated by News Corporation publications—Adelaide being the birthplace of News Corporation itself. The only South Australian daily newspaper is "The Advertiser", published by News Corporation six days a week. The same group publishes a Sunday paper, the "Sunday Mail".

There are eleven suburban community newspapers published weekly, known collectively as the "Messenger Newspapers", also published by a subsidiary of News Corporation. "The Independent Weekly" was a small independent newspaper providing an alternative view, but ceased publishing its print edition in November 2010 and now exists as a digital daily newsletter only, "InDaily". "The Adelaide Review" is a free paper published monthly, and other independent magazine-style papers are published, but are not as widely available.

Adelaide is served by numerous digital free-to-air television channels:


All of the five Australian national television networks broadcast both high-definition digital and standard-definition digital television services in Adelaide. They share three transmission towers on the ridge near the summit of Mount Lofty. There are two other transmission sites at 25 Grenfell Street, Adelaide and Elizabeth Downs. The two government-funded stations are run by the Australian Broadcasting Corporation (ABC South Australia) and the Special Broadcasting Service (SBS). The Seven Network and Network Ten both own their Adelaide stations (SAS-7 and ADS-10 respectively). Adelaide's NWS-9 is part of the Nine Network. Adelaide also has a community television station, Channel 44.

As part of a nationwide phase-out of analogue television in Australia, Adelaide's analogue television service was shut down on 2 April 2013.

The Foxtel pay TV service is also available via cable or satellite to the entire metropolitan area.

All the major broadcasting networks also operate online on-demand television services, alongside internet-only services such as Stan, Fetch TV, Netflix, YouTube, Disney+, and Kayo Sports.

There are 20 radio stations that serve the metropolitan area, as well as four stations that serve only parts of the metropolitan area; six commercial stations, six community stations, six national stations and two narrowcast stations.

DAB+ digital radio has been broadcasting in metropolitan Adelaide since 20 May 2009, and currently offers a choice of 41 stations all operated by the existing licensed radio broadcasters, which includes high-quality simulcast of all AM and FM stations.

The main sports played professionally in Adelaide are Australian Rules football, association football (soccer), cricket, netball, and basketball. Adelaide is the home of two Australian Football League teams: the Adelaide Football Club and Port Adelaide Football Club, and one A-League soccer team, Adelaide United. A local Australian rules football league, the SANFL, is made up of 10 teams from around Adelaide. The SANFL has been in operation since 1877 when it began as the South Australian Football Association (SAFL) before changing its name to the SANFL in 1927. The SANFL is the oldest surviving football league of any code played in Australia.
Adelaide has developed a strong culture of attracting crowds to major sporting events. Until the completion of the 2012–14 renovation and upgrade of the Adelaide Oval, most large sporting events took place at either AAMI Stadium (the then home base of the Adelaide Crows, and the then Port Adelaide's home game venue), or the historic Adelaide Oval, home of the Southern Redbacks and the Adelaide Strikers cricket teams. Since completion of the upgrade, home games for Adelaide Crows and Port Adelaide now take place at Adelaide Oval.

Since 1884, Adelaide Oval has also hosted an international cricket test every summer, along with a number of One Day International cricket matches. Memorial Drive Park, adjacent to the Adelaide Oval, used to host Davis Cup and other major tennis events, including the Australian Open and the Adelaide International. Adelaide's professional association football team, Adelaide United, play in the A-League. Founded in 2003, their home ground is Hindmarsh Stadium, which has a capacity of 17,000 and is one of the few purpose-built soccer stadia in Australia. Prior to United's foundation, Adelaide City and West Adelaide represented the city in the National Soccer League. The two sides, which contest the Adelaide derby against one another, now play in the National Premier Leagues South Australia.

For two years, 1997 and 1998, Adelaide was represented in Australia's top level rugby league, after the New South Wales Rugby League had played a single game per season at the Adelaide Oval for five years starting in 1991. The Adelaide Rams were formed and played in the breakaway Super League (SL) competition in 1997 before moving to the new National Rugby League in 1998. Initially playing at the Adelaide Oval, the club moved to the more suitable Hindmarsh Stadium late in the 1998 season. As part of a peace deal with the Australian Rugby League to end the Super League war, the club's owners News Limited (who were also owners of the SL) suddenly closed the club only weeks before the start of the 1999 season.

Adelaide has two professional basketball teams, the men's team being the Adelaide 36ers which plays in the National Basketball League (NBL) and the women's team, the Adelaide Lightning which plays in the Women's National Basketball League (WNBL). Both teams play their home games at the Titanium Security Arena. Adelaide has a professional netball team, the Adelaide Thunderbirds, which plays in the national netball competition, the Suncorp Super Netball championship, with home games played at Priceline Stadium. The Thunderbirds occasionally play games or finals at the Titanium Security Arena, while international netball matches are usually played at the 10,500 seat Adelaide Entertainment Centre. The Titanium Security Arena has a capacity of 8,000 and is the largest purpose-built basketball stadium in Australia.

Since 1999 Adelaide and its surrounding areas have hosted the Tour Down Under bicycle race, organised and directed by Adelaide-based Michael Turtur. Turtur won an Olympic gold medal for Australia in the 4000m Team pursuit at the 1984 Los Angeles Olympics. The Tour Down Under is the largest cycling event outside Europe and was the first event outside Europe to be granted UCI ProTour status. Adelaide maintains a franchise in the Australian Baseball League, the Adelaide Bite. They have been playing since 2009, and their home stadium (until 2016) was Norwood Oval. From 2016 the team moved to the Diamond Sports Stadium located near the Adelaide International Airport due to renovations at Norwood. Its name stems from the local Great Australian Bight, and from the abundance of local Great White Sharks. Adelaide also has an Ice Hockey team, Adelaide Adrenaline in the Australian Ice Hockey League (AIHL). It was national champions in 2009 and plays its games at the IceArenA.

The Australian Grand Prix for World Championship Formula One racing was hosted by Adelaide from 1985 to 1995 on the Adelaide Street Circuit which was laid out in the city's East End as well as the eastern parklands including the Victoria Park Racecourse. The Grand Prix became a source of pride, and losing the event to Melbourne in a surprise announcement in mid-1993 left a void that has since been filled with the highly successful Clipsal 500 for V8 Supercar racing, held on a modified version of the same street circuit. The Classic Adelaide, a rally of classic sporting vehicles, is also held in the city and its surrounds.

Adelaide formerly had three horse racing venues. Victoria Park, Cheltenham Park Racecourse, both of which have now closed, and Morphettville Racecourse that remains the home of the South Australian Jockey Club. It also has Globe Derby Park for Harness racing that opened in 1969, and by 1973 had become Adelaide's premier harness racing venue taking over from the Wayville Showgrounds, as well as Greyhound Park for greyhound racing that opened in 1972.

The World Solar Challenge race attracts teams from around the world, most of which are fielded by universities or corporations, although some are fielded by high schools. The race has a 20-years' history spanning nine races, with the inaugural event taking place in 1987. Adelaide hosted the 2012 World Bowls Championships at Lockleys Bowling Club, becoming the third city in the world to have held the championships twice, having previously hosted the event in 1996.

Dirt track speedway is also popular in Adelaide with three operating speedways. Adelaide Motorsport Park, located adjacent to the Adelaide International Raceway road racing circuit at Virginia ( north of the city centre) has been in continuous operation since 1979 after the closure of the popular Rowley Park Speedway. Gillman Speedway located in the semi-industrial suburb of Gillman, has been in operation since 1998 and caters to Motorcycle speedway and Sidecars, while the Sidewinders Speedway located in Wingfield is also a motorcycle speedway dedicated to Under-16 riders and has been in operation since 1978. In 2016 backed my South Australia's Peregrine Group owners of OTR (On the run service stations and 24/7-hour convenient stores) opened up a multi-purpose facility; a state-of-the-art motorsporting park and a hotel alongside its newer OTR service station outside a small township of Tailem Bend currently named The Bend Motorsport Park. Design for thrill seekers and rev-heads the facility currently host South Australia's second V8 Supercars motoring event during a round in August and hopes to bring in other major international motoring events such as SBK Superbikes and other well established FIA motoring events.

Adelaide is home to the Great Southern Slam, the world's largest roller derby tournament. The tournament has been held biennially over Australia's Queen's Birthday holiday weekend since 2010. In 2014 and 2016 the tournament featured 45 teams playing in two divisions. In 2018 the tournament has expanded to 48 teams competing in three divisions.

Being centrally located on the Australian mainland, Adelaide forms a strategic transport hub for east–west and north–south routes. The city itself has a metropolitan public transport system managed by and known as the Adelaide Metro. The Adelaide Metro consists of a contracted bus system including the O-Bahn Busway, 6 commuter rail lines (diesel and electric), and a small tram network operating between inner suburb Hindmarsh, the city centre, and seaside Glenelg. Tramways were largely dismantled in the 1950s, but saw a revival in the 2010s with upgrades and extensions. A proposal to significantly extend the tram network called AdeLINK is dormant following a change of state government.

Road transport in Adelaide has historically been easier than many of the other Australian cities, with a well-defined city layout and wide multiple-lane roads from the beginning of its development. Adelaide was known as a "twenty-minute city", with commuters having been able to travel from metropolitan outskirts to the city proper in roughly twenty minutes. However, such arterial roads often experience traffic congestion as the city grows.
The Adelaide metropolitan area has one freeway and four expressways. In order of construction, they are:


The Adelaide metropolitan area has two commercial airports, Adelaide International Airport and Parafield Airport. Adelaide Airport, in Adelaide's south-western suburbs, serves in excess of 8 million passengers annually. Parafield Airport, Adelaide's second airport north of the city centre, is used for small aircraft, pilot training and recreational aviation purposes. Parafield Airport served as Adelaide's main aerodrome until the opening of the Adelaide Airport in February 1955. Adelaide airport serves many international and domestic destinations including all Australian state capitals.

Adelaide is also home to a military airport, known as Edinburgh Airport, located in the northern suburbs. It was built in 1955 in a joint initiative with the UK for weapon development.

Adelaide's two largest hospitals are the Royal Adelaide Hospital (RAH) in the city centre, a teaching hospital affiliated with the University of Adelaide (800 beds), and the Flinders Medical Centre (580 beds) in Bedford Park, affiliated with Flinders University. The RAH also operates additional campuses for specialist care throughout the suburbs including the Hampstead Rehabilitation Centre (150 beds) in Northfield and the Glenside Campus (129 beds) for acute mental health services. Other major public hospitals are the Women's and Children's Hospital (305 beds), in North Adelaide; the Queen Elizabeth Hospital (340 beds) in Woodville; Modbury Hospital (178 beds) in Modbury; and the Lyell McEwin Hospital (198 beds) in Elizabeth. Numerous private hospitals are also located throughout the city, with the largest operators being not-for-profits Adelaide Community Healthcare Alliance (3 hospitals) and Calvary Care (4 hospitals).

In 2017, the RAH was relocated from the city's East End to a new AU$2.3 billion facility built over former railyards in the West End. The state-of-the-art hospital forms part of a new biomedical precinct called BioMed City that colocates the South Australian Health and Medical Research Institute (SAHMRI), the University of Adelaide Health and Medical Sciences building, the University of South Australia's Health Innovation Building, and the state's Dental Hospital. SAHMRI is building a $300 million second facility due to be completed by 2022 to house the Australian Bragg Centre with Australia's first proton therapy unit. There are also plans for the Women's and Children's Hospital to be relocated to the precinct adjacent the RAH by 2024.
The largest provider of community health care within Adelaide is the not-for-profit Royal District Nursing Service (RDNS), which provides out of hospital care and hospital avoidance care.

Adelaide's energy requirements were originally met by the Adelaide Electric Supply Company, which was nationalised by the Playford government in 1946, becoming the Electricity Trust of South Australia (ETSA). Despite significant public opposition and the Labor party's anti-privatisation stance which left the Liberal party one vote short of the numbers needed to pass the legislation, ETSA was privatised by the Olsen Government in 1999 by way of a 200-year lease for the distribution network (ETSA Utilities, later renamed SA Power Networks) and the outright purchase of ETSA Power by the Cheung Kong Holdings for $3.5 billion (11 times ETSA's annual earnings) after Labor MP Trevor Crothers resigned from the party and voted with the government.

The electricity retail market was opened to competition in 2003 and although competition was expected to result in lower retail costs, prices increased by 23.7% in the market's first year. In 2004 the privatisation was deemed to be a failure with consumers paying 60% more for their power and with the state government estimated to lose $3 billion in power generation net income in the first ten years of privatisation. In 2012, the industry came under scrutiny for allegedly reducing supply by shutting down generators during periods of peak demand to force prices up. Increased media attention also revealed that in 2009 the state government had approved a 46% increase in retail prices to cover expected increases in the costs of generation while generation costs had in fact fallen 35% by 2012. South Australia has the highest retail price for electricity in the country.

Privatisation led to competition from a variety of companies who now separately provide for the generation, transmission, distribution and retail sales of gas and electricity. Electricity generation comes from a range of technologies and operators. ElectraNet operates the high-voltage electricity transmission network. SA Power Networks distributes electricity to end users. The largest electricity and gas retailing companies are also the largest generating companies.

The largest fossil fuel power stations are the Torrens Island Power Station gas-fired plant operated by AGL Energy and the Pelican Point Power Station operated by Engie. South Australia also has wind and solar power and connections to the national grid. Gas is supplied from the Moomba Gas Processing Plant in the Cooper Basin via the Moomba Adelaide Pipeline System and the SEAGas pipeline from Victoria.

In 2011, South Australia generated 18% of its electricity from wind power, and had 51% of the installed capacity of wind generators in Australia.

Due to almost universal blackouts within the city during September 2016, the state worked with Tesla to produce the world's largest electricity battery at Hornsdale Power Reserve which has increased that state's electrical security to the extent in which large blackouts are no longer an event.

The provision of water services is by the government-owned SA Water. Adelaide's water is supplied from its seven reservoirs: Mount Bold, Happy Valley, Myponga, Millbrook, Hope Valley, Little Para and South Para. The yield from these reservoir catchments can be as little as 10% of the city's requirements (90GL per annum) in drought years and about 60% in average years. The remaining demand is met by the pumping of water from the River Murray.

A sea-water desalination plant capable of supplying 100GL per annum was built during the 2001–2009 drought; however, it operated at about 8% of its capacity until 2019. In December 2018, the State and Federal Governments agreed to fund a $2m study to determine how the plant could be used to reduce reliance on river water, in an effort to help save the Murray River basin and mouth (including the Coorong) from further ecological damage.

AdelaideFree WiFi is a citywide free WiFi network covering most of the inner city areas of Adelaide, primarily the Adelaide CBD and Northern Adelaide precincts. It was officially launched at the Adelaide Central Markets on Tuesday 25 June 2014. It is provided by Internode, with infrastructure provided by outdoor Cisco WiFi N access points attached to the top of lighting poles, as well as inside cafes and businesses across the city.






</doc>
<doc id="1152" url="https://en.wikipedia.org/wiki?curid=1152" title="Alan Garner">
Alan Garner

Alan Garner (born 17 October 1934) is an English novelist best known for his children's fantasy novels and his retellings of traditional British folk tales. Much of his work is rooted in the landscape, history and folklore of his native county of Cheshire, North West England, being set in the region and making use of the native Cheshire dialect.

Born in Congleton, Garner grew up around the nearby town of Alderley Edge, and spent much of his youth in the wooded area known locally as "The Edge", where he gained an early interest in the folklore of the region. Studying at Manchester Grammar School and then briefly at Oxford University, in 1957 he moved to the village of Blackden, where he bought and renovated an Early Modern Period (circa 1590) building known as Toad Hall. His first novel, "The Weirdstone of Brisingamen", was published in 1960. A children's fantasy novel set on the Edge, it incorporated elements of local folklore in its plot and characters. Garner completed a sequel, "The Moon of Gomrath" (1963), but left the third book of the trilogy he had envisioned. Instead he wrote several fantasy novels, "Elidor" (1965), "The Owl Service" (1967) and "Red Shift" (1973).

Turning away from fantasy as a genre, Garner produced "The Stone Book Quartet" (1979), a series of four short novellas detailing a day in the life of four generations of his family. He also published a series of British folk tales which he had rewritten in a series of books entitled "Alan Garner's Fairy Tales of Gold" (1979), "Alan Garner's Book of British Fairy Tales" (1984) and "A Bag of Moonshine" (1986). In his subsequent novels, "Strandloper" (1996) and "Thursbitch" (2003), he continued writing tales revolving around Cheshire, although without the fantasy elements which had characterised his earlier work. In 2012, he finally published a third book in the Weirdstone trilogy, "Boneland".

Garner was born in the front room of his grandmother's house in Congleton, Cheshire, on 17 October 1934. He was raised in nearby Alderley Edge, a well-to-do village that had effectively become a suburb of Manchester. His "rural working-class family", had been connected to Alderley Edge since at least the sixteenth century, and could be traced back to the death of William Garner in 1592. Garner has stated that his family had passed on "a genuine oral tradition" involving folk tales about The Edge, which included a description of a king and his army of knights who slept under it, guarded by a wizard. In the mid-nineteenth century Alan's great-great grandfather Robert had carved the face of a bearded wizard onto the face of a cliff next to a well, known locally at that time as the Wizard's Well.

Robert Garner and his other relatives had all been craftsmen, and, according to Garner, each successive generation had tried to "improve on, or do something different from, the previous generation". Garner's grandfather, Joseph Garner, "could read, but didn't and so was virtually unlettered". Instead he taught his grandson the folk tales he knew about The Edge. Garner later remarked that as a result he was "aware of [the Edge's] magic" as a child, and he and his friends often played there. The story of the king and the wizard living under the hill played an important part in his life, becoming, he explained, "deeply embedded in my psyche" and heavily influencing his later novels.

Garner faced several life-threatening childhood illnesses, which left him bed ridden for much of the time. He attended a local village school, where he found that, despite being praised for his intelligence, he was punished for speaking in his native Cheshire dialect; for instance, when he was six his primary school teacher washed his mouth out with soapy water. Garner then won a place at Manchester Grammar School, where he received his secondary education; entry was means-tested, resulting in his school fees being waived. Rather than focusing his interest on creative writing, it was here that he excelled at sprinting. He used to go jogging along the highway, and later claimed that in doing so he was sometimes accompanied by the mathematician Alan Turing, who shared his fascination with the Disney film "Snow White and the Seven Dwarfs". Garner was then conscripted into national service, serving for a time with the Royal Artillery while posted to Woolwich in Southeast London.

At school, Garner had developed a keen interest in the work of Aeschylus and Homer, as well as the Ancient Greek language. Thus, he decided to pursue the study of Classics at Magdalen College, Oxford, passing his entrance exams in January 1953; at the time he had thoughts of becoming a professional academic. He was the first member of his family to receive anything more than a basic education, and he noted that this removed him from his "cultural background" and led to something of a schism with other members of his family, who "could not cope with me, and I could not cope with" them. Looking back, he remarked, "I soon learned that it was not a good idea to come home excited over irregular verbs". In 1955, he joined the university theatrical society, playing the role of Mark Antony in a performance of William Shakespeare's "Antony and Cleopatra" where he co-starred alongside Dudley Moore and where Kenneth Baker was the stage manager. In August 1956, he decided that he wished to devote himself to novel writing, and decided to abandon his university education without taking a degree; he left Oxford in late 1956. He nevertheless felt that the academic rigour which he learned during his university studies has remained "a permanent strength through all my life".

Aged 22, Garner was out cycling when he came across a hand-painted sign announcing that an agricultural cottage in Toad Hall – a Late Medieval building situated in Blackden, seven miles from Alderley Edge – was on sale for £510. Although he personally could not afford it, he was lent the money by the local Oddfellow lodge, enabling him to purchase and move into the cottage in June 1957. In the late nineteenth century the Hall had been divided into two agricultural labourers' cottages, but Garner was able to purchase the second for £150 about a year later; he proceeded to knock down the dividing walls and convert both halves back into a single home.

Garner had begun writing his first novel, "The Weirdstone of Brisingamen: A Tale of Alderley", in September 1956. However it was while at Toad Hall that he finished the book. Set in Alderley Edge, it revolved around two children, Susan and Colin, who are sent to live in the area with their mother's old nurse maid, Bess, and her husband, Gowther Mossock. Setting about to explore the Edge, they discover a race of malevolent creatures, the "svart alfar", who dwell in the Edge's abandoned mines and who seem intent on capturing them, until they are rescued by the wizard Cadellin who reveals that the forces of darkness are massing at the Edge in search of the eponymous "weirdstone of Brisingamen". Whilst engaged in writing in his spare time, Garner attempted to gain employment as a teacher, but soon gave that up, believing that "I couldn't write and teach; the energies were too similar", and so began working as a general labourer for four years, remaining unemployed for much of that time.

Garner sent his debut novel to the publishing company Collins, where it was picked up by the company's head, Sir William Collins, who was on the look out for new fantasy novels following on from the recent commercial and critical success of J. R. R. Tolkien's "The Lord of the Rings" (1954–55). Garner, who went on to become a personal friend of Collins, would later relate that "Billy Collins saw a title with funny-looking words in it on the stockpile, and he decided to publish it." On its release in 1960, "The Weirdstone of Brisingamen" proved to be a critical and commercial success, later being described as "a tour de force of the imagination, a novel that showed almost every writer who came afterwards what it was possible to achieve in novels ostensibly published for children." Garner himself however would later denounce this novel as "a fairly bad book" in 1968.

With his first book published, Garner abandoned his work as a labourer and gained a job as a freelance television reporter, living a "hand to mouth" lifestyle on a "shoestring" budget. He also worked on a sequel to "The Weirdstone of Brisingamen", which would be known as "The Moon of Gomrath". "The Moon of Gomrath" also revolves around the adventures of Colin and Susan, with the latter being possessed by a malevolent creature called the Brollachan who has recently entered the world. With the help of the wizard Cadellin, the Brollachan is exorcised, but Susan's soul also leaves her body, being sent to another dimension, leading Colin to find a way to bring it back. Critic Neil Philip characterised it as "an artistic advance" but "a less satisfying story". In a 1989 interview, Garner stated that he had left scope for a third book following the adventures of Colin and Susan, envisioning a trilogy, but that he had intentionally decided not to write it, instead moving on to write something different. However "Boneland", the conclusion to the sequence, was belatedly published in August 2012.

In 1962 Garner began work on a radio play named "Elidor", which would result in the completion of a novel of the same name. Set in contemporary Manchester, "Elidor" tells the story of four children who enter into a derelict Victorian church, in which they find a portal to the magical realm of Elidor. Here, they are entrusted by King Malebron to help rescue four treasures which have been stolen by the forces of evil who are attempting to take control of the kingdom. Successfully doing so, the children return to Manchester with the treasures, but are pursued by the malevolent forces who need them to seal their victory.

Before writing "Elidor", Garner had seen a dinner service set which could be arranged to make pictures of either flowers or owls. Inspired by this design, he produced his fourth novel, "The Owl Service". The story was also heavily influenced by the Medieval Welsh tale of Math fab Mathonwy from, the "Mabinogion". "The Owl Service" was critically acclaimed, winning both the Carnegie Medal and Guardian Children's Fiction Prize. It also sparked discussions among critics as to whether Garner should properly be considered a children's writer, given that this book in particular was deemed equally suitable for an adult readership.

It took Garner six years to write his next novel, "Red Shift". In this, he provided three intertwined love stories, one set in the present, another during the English Civil War, and the third in the second century CE. Philip referred to it as "a complex book but not a complicated one: the bare lines of story and emotion stand clear".
Academic specialist in children's literature Maria Nikolajeva characterised "Red Shift" as "a difficult book" for an unprepared reader, identifying its main themes as those of "loneliness and failure to communicate". Ultimately, she thought that repeated re-readings of the novel bring about the realisation that "it is a perfectly realistic story with much more depth and psychologically more credible than the most so-called "realistic" juvenile novels."

From 1976 to 1978, Garner published a series of four novellas, which have come to be collectively known as "The Stone Book" quartet: "The Stone Book", "Granny Reardun", "The Aimer Gate", and "Tom Fobble's Day". Each focused on a day in the life of a child in the Garner family, each from a different generation.
In a 1989 interview, Garner noted that although writing "The Stone Book Quartet" had been "exhausting", it had been "the most rewarding of everything" he'd done to date. Philip described the quartet as "a complete command of the material he had been working and reworking since the start of his career".
Garner pays particular attention to language, and strives to render the cadence of the Cheshire tongue in modern English. This he explains by the sense of anger he felt on reading "Sir Gawain and the Green Knight": the footnotes would not have been needed by his father.

In 1981, the literary critic Neil Philip published an analysis of Garner's novels as "A Fine Anger", which was based on his doctoral thesis, produced for the University of London in 1980. In this study he noted that ""The Stone Book" quartet marks a watershed in Garner's writing career, and provides a suitable moment for an evaluation of his work thus far."

In 1996, Garner's novel "Strandloper" was published. His collection of essays and public talks, "The Voice That Thunders", contains much autobiographical material (including an account of his life with bipolar disorder), as well as critical reflection upon folklore and language, literature and education, the nature of myth and time. In "The Voice That Thunders" he reveals the commercial pressure placed upon him during the decade-long drought which preceded "Strandloper" to 'forsake "literature", and become instead a "popular" writer, cashing in on my established name by producing sequels to, and making series of, the earlier books'. Garner feared that "making series ... would render sterile the existing work, the life that produced it, and bring about my artistic and spiritual death" and felt unable to comply.

Garner's novel "Thursbitch" was published in 2003. Garner's novel, "Boneland", was published in 2012, nominally completing a trilogy begun some 50 years earlier with "The Weirdstone of Brisingamen".

In August 2018 Garner published his only set of memoirs, "Where Shall We Run To?", which describes his childhood during the Second World War.

With his first wife Ann Cook he had three children. In 1972 he married for a second time, this time to Griselda Greaves, a teacher and critic with whom he had two children. In a 2014 interview conducted with Mike Pitts for "British Archaeology" magazine, Garner stated that "I don't have anything to do with the literary world. I avoid writers. I don't like them. Most of my close personal friends are professional archaeologists."

Although Garner's early work is often labelled as "children's literature", Garner himself rejects such a description, informing one interviewer that "I certainly have never written for children" but that instead he has always written purely for himself. Neil Philip, in his critical study of Garner's work (1981), commented that up till that point, "Everything Alan Garner has published has been published for children", although he went on to relate that "It may be that Garner's is a case" where the division between children's and adult's literature is "meaningless" and that his fiction is instead "enjoyed by a type of person, no matter what their age."

Philip offered the opinion that the "essence of his work" was "the struggle to render the complex in simple, bare terms; to couch the abstract in the concrete and communicate it directly to the reader". He added that Garner's work is "intensely autobiographical, in both obvious and subtle ways". Highlighting Garner's use of mythological and folkloric sources, Philip stated that his work explores "the disjointed and troubled psychological and emotional landscape of the twentieth century through the symbolism of myth and folklore." He also expressed the opinion that "Time is Garner's most consistent theme".

The English author and academic Charles Butler noted that Garner was attentive to the "geological, archaeological and cultural history of his settings, and careful to integrate his fiction with the physical reality beyond the page." As a part of this, Garner had included maps of Alderley Edge in both "The Weirdstone of Brisingamen" and "The Moon of Gomrath". Garner has spent much time investigating the areas that he deals with in his books; writing in the "Times Literary Supplement" in 1968, Garner commented that in preparation for writing his book "Elidor":

In a paper published in the "Children's Literature Association Quarterly", Maria Nikolajeva characterised Garner as "one of the most controversial" authors of modern children's literature.

In the fiftieth anniversary edition of "The Weirdstone of Brisingamen", published by HarperCollins in 2010, several notable British fantasy novelists praised Garner and his work. Susan Cooper related that "The power and range of Alan Garner's astounding talent has grown with every book he's written", whilst David Almond called him one of Britain's "greatest writers" whose works "really matter". Philip Pullman, the author of the "His Dark Materials" trilogy, went further when he remarked that:

Another British fantasy writer, Neil Gaiman, claimed that "Garner's fiction is something special" in that it was "smart and challenging, based in the here and the now, in which real English places emerged from the shadows of folklore, and in which people found themselves walking, living and battling their way through the dreams and patterns of myth." Praise also came from Nick Lake, the editorial director of HarperCollins Children's Books, who proclaimed that "Garner is, quite simply, one of the greatest and most influential writers this country has ever produced."

The biennial Hans Christian Andersen Award conferred by the International Board on Books for Young People is the highest recognition available to a writer or illustrator of children's books. Garner was the sole runner-up for the writing award in 1978.

Garner was appointed Officer of the Order of the British Empire (OBE) for services to literature in the 2001 New Year's Honours list. He received the British Fantasy Society's occasional Karl Edward Wagner Award in 2003 and the World Fantasy Award for Life Achievement in 2012. In January 2011, the University of Warwick awarded the degree of Doctor of Letters (honoris causa). On that occasion he gave a half-hour interview about his work. He has also been awarded honorary doctorates from the University of Salford (2011) and the University of Huddersfield in (2012).

He has been recognised several times for particular works.




</doc>
<doc id="1154" url="https://en.wikipedia.org/wiki?curid=1154" title="August 2">
August 2





</doc>
<doc id="1155" url="https://en.wikipedia.org/wiki?curid=1155" title="Atlantic (disambiguation)">
Atlantic (disambiguation)

The Atlantic Ocean is the second largest of the world's oceans, that separates the old world from the new world.

Atlantic may also refer to:


















</doc>
<doc id="1158" url="https://en.wikipedia.org/wiki?curid=1158" title="Algebraic number">
Algebraic number

An algebraic number is any complex number (including real numbers) that is a root of a non-zero polynomial (that is, a value which causes the polynomial to equal 0) in one variable with rational coefficients (or equivalently—by clearing denominators—with integer coefficients).

All integers and rational numbers are algebraic, as are all roots of integers. Real and complex numbers that are not algebraic, such as and , are called transcendental numbers.

While the set of complex numbers is uncountable, the set of algebraic numbers is countable and has measure zero in the Lebesgue measure as a subset of the complex numbers, and in this sense almost all complex numbers are transcendental.



The sum, difference, product and quotient (if the denominator is nonzero) of two algebraic numbers is again algebraic (this fact can be demonstrated using the resultant), and the algebraic numbers therefore form a field (sometimes denoted by formula_1, though this usually denotes the adele ring). Every root of a polynomial equation whose coefficients are "algebraic numbers" is again algebraic. This can be rephrased by saying that the field of algebraic numbers is algebraically closed. In fact, it is the smallest algebraically closed field containing the rationals, and is therefore called the algebraic closure of the rationals.

The set of "real" algebraic numbers itself forms a field.

All numbers that can be obtained from the integers using a finite number of complex additions, subtractions, multiplications, divisions, and taking th roots where is a positive integer (radical expressions), are algebraic. The converse, however, is not true: There are algebraic numbers that cannot be obtained in this manner. These numbers are roots of polynomials of degree 5 or higher, a result of Galois theory (see Quintic equations and the Abel–Ruffini theorem). An example is , where the unique real root is 

where 

is the generalized hypergeometric function.

Algebraic numbers are all numbers that can be defined explicitly or implicitly in terms of polynomials, starting from the rational numbers. One may generalize this to "closed-form numbers", which may be defined in various ways. Most broadly, all numbers that can be defined explicitly or implicitly in terms of polynomials, exponentials, and logarithms are called "elementary numbers", and these include the algebraic numbers, plus some transcendental numbers. Most narrowly, one may consider numbers "explicitly" defined in terms of polynomials, exponentials, and logarithms – this does not include all algebraic numbers, but does include some simple transcendental numbers such as or ln 2.

An algebraic integer is an algebraic number that is a root of a polynomial with integer coefficients with leading coefficient 1 (a monic polynomial). Examples of algebraic integers are , and . Therefore, the algebraic integers constitute a proper superset of the integers, as the latter are the roots of monic polynomials for all In this sense, algebraic integers are to algebraic numbers what integers are to rational numbers.

The sum, difference and product of algebraic integers are again algebraic integers, which means that the algebraic integers form a ring. The name "algebraic integer" comes from the fact that the only rational numbers that are algebraic integers are the integers, and because the algebraic integers in any number field are in many ways analogous to the integers. If is a number field, its ring of integers is the subring of algebraic integers in , and is frequently denoted as . These are the prototypical examples of Dedekind domains.




</doc>
<doc id="1160" url="https://en.wikipedia.org/wiki?curid=1160" title="Automorphism">
Automorphism

In mathematics, an automorphism is an isomorphism from a mathematical object to itself. It is, in some sense, a symmetry of the object, and a way of mapping the object to itself while preserving all of its structure. The set of all automorphisms of an object forms a group, called the automorphism group. It is, loosely speaking, the symmetry group of the object. (read: Symmetric group)

In the context of abstract algebra, a mathematical object is an algebraic structure such as a group, ring, or vector space. An automorphism is simply a bijective homomorphism of an object with itself. (The definition of a homomorphism depends on the type of algebraic structure; see, for example, group homomorphism, ring homomorphism, and linear operator).

The identity morphism (identity mapping) is called the trivial automorphism in some contexts. Respectively, other (non-identity) automorphisms are called nontrivial automorphisms.

The exact definition of an automorphism depends on the type of "mathematical object" in question and what, precisely, constitutes an "isomorphism" of that object. The most general setting in which these words have meaning is an abstract branch of mathematics called category theory. Category theory deals with abstract objects and morphisms between those objects.

In category theory, an automorphism is an endomorphism (i.e., a morphism from an object to itself) which is also an isomorphism (in the categorical sense of the word).

This is a very abstract definition since, in category theory, morphisms aren't necessarily functions and objects aren't necessarily sets. In most concrete settings, however, the objects will be sets with some additional structure and the morphisms will be functions preserving that structure.

If the automorphisms of an object form a set (instead of a proper class), then they form a group under composition of morphisms. This group is called the automorphism group of .

The automorphism group of an object "X" in a category "C" is denoted Aut("X"), or simply Aut("X") if the category is clear from context.


One of the earliest group automorphisms (automorphism of a group, not simply a group of automorphisms of points) was given by the Irish mathematician William Rowan Hamilton in 1856, in his icosian calculus, where he discovered an order two automorphism, writing:
so that formula_1 is a new fifth root of unity, connected with the former fifth root formula_2 by relations of perfect reciprocity.

In some categories—notably groups, rings, and Lie algebras—it is possible to separate automorphisms into two types, called "inner" and "outer" automorphisms.

In the case of groups, the inner automorphisms are the conjugations by the elements of the group itself. For each element "a" of a group "G", conjugation by "a" is the operation given by (or "a""ga"; usage varies). One can easily check that conjugation by "a" is a group automorphism. The inner automorphisms form a normal subgroup of Aut("G"), denoted by Inn("G"); this is called Goursat's lemma.

The other automorphisms are called outer automorphisms. The quotient group is usually denoted by Out("G"); the non-trivial elements are the cosets that contain the outer automorphisms.

The same definition holds in any unital ring or algebra where "a" is any invertible element. For Lie algebras the definition is slightly different.




</doc>
<doc id="1162" url="https://en.wikipedia.org/wiki?curid=1162" title="Accordion">
Accordion

Accordions (from 19th-century German "Akkordeon", from "Akkord"—"musical chord, concord of sounds") are a family of box-shaped musical instruments of the bellows-driven free-reed aerophone type, colloquially referred to as a squeezebox. A person who plays the accordion is called an "accordionist". The concertina and bandoneón are related. The harmonium and American reed organ are in the same family, but are typically larger than an accordion and sit on a surface or the floor.

The accordion is played by compressing or expanding the bellows while pressing buttons or keys, causing "pallets" to open, which allow air to flow across strips of brass or steel, called "reeds". These vibrate to produce sound inside the body. Valves on opposing reeds of each note are used to make the instrument's reeds sound louder without air leaking from each reed block. The performer normally plays the melody on buttons or keys on the right-hand manual, and the accompaniment, consisting of bass and pre-set chord buttons, on the left-hand manual.

The accordion is widely spread across the world because of the waves of immigration from Europe to the Americas and other regions. In some countries (for example Brazil, Colombia, Dominican Republic, Mexico and Panama) it is used in popular music (for example Gaucho, Forró and Sertanejo in Brazil, Vallenato in Colombia, and norteño in Mexico), whereas in other regions (such as Europe, North America and other countries in South America) it tends to be more used for dance-pop and folk music and is often used in folk music in Europe, North America and South America.

In Europe and North America, some popular music acts also make use of the instrument. Additionally, the accordion is used in cajun, zydeco, jazz music and in both solo and orchestral performances of classical music. The piano accordion is the official city instrument of San Francisco, California. Many conservatories in Europe have classical accordion departments. The oldest name for this group of instruments is "harmonika", from the Greek "harmonikos", meaning "harmonic, musical". Today, native versions of the name "accordion" are more common. These names refer to the type of accordion patented by Cyrill Demian, which concerned "automatically coupled chords on the bass side".

Accordions have many configurations and types. What may be easy to do with one type of accordion could be technically challenging or impossible with another, and proficiency with one layout may not translate to another.

The most obvious difference between accordions is their right-hand manuals. Piano accordions use a piano-style musical keyboard, while button accordions use a buttonboard. Button accordions are furthermore differentiated by their usage of a chromatic or diatonic buttonboard for the right-hand manual.

Accordions may be either bisonoric, producing different pitches depending on the direction of bellows movement, or unisonoric, producing the same pitch in both directions. Piano accordions are unisonoric. Chromatic button accordions also tend to be unisonoric, while diatonic button accordions tend to be bisonoric, though notable exceptions exist.

Accordion size is not standardized, and may vary significantly from model to model. Accordions vary not only in their dimensions and weight, but also in number of buttons or keys present in the right- and left-hand manuals. For example, piano accordions may have as few as 12 bass buttons, or up to 120 (and even beyond this in rare cases). Accordions also vary by their available registers and by their specific tuning and voicing.

Despite these differences, all accordions share a number of common components.

The bellows is the most recognizable part of the instrument, and the primary means of articulation. The production of sound in an accordion is in direct proportion to the motion of the bellows by the player. In a sense, the role of the bellows can be compared to the role of moving a violin's bow on bowed strings. For a more direct analogy, the bellows can be compared to the role of breathing for a singer. The bellows is located between the right- and left-hand manuals, and is made from pleated layers of cloth and cardboard, with added leather and metal. It is used to create pressure and vacuum, driving air across the internal reeds and producing sound by their vibrations, applied pressure increases the volume.

The keyboard touch is not expressive and does not affect dynamics: all expression is effected through the bellows. Bellows effects include:

The accordion's body consists of two wooden boxes joined together by the bellows. These boxes house reed chambers for the right- and left-hand manuals. Each side has grilles in order to facilitate the transmission of air in and out of the instrument, and to allow the sound to project better. The grille for the right-hand manual is usually larger and is often shaped for decorative purposes. The right-hand manual is normally used for playing the melody and the left-hand manual for playing the accompaniment; however, skilled players can reverse these roles and play melodies with the left hand.

The size and weight of an accordion varies depending on its type, layout and playing range, which can be as small as to have only one or two rows of basses and a single octave on the right-hand manual, to the standard 120-bass accordion and through to large and heavy 160-bass free-bass converter models.

The accordion is an aerophone. The manual mechanism of the instrument either enables the air flow, or disables it:

The term "accordion" covers a wide range of instruments, with varying components. All instruments have reed ranks of some format, apart from reedless digital accordions. Not all have switches to change registers or ranks, as some have only one treble register and one bass register. The most typical accordion is the piano accordion, which is used for many musical genres. Another type of accordion is the button accordion, which is used in musical traditions including Cajun, Conjunto and Tejano music, Swiss and Austro-German Alpine music, and Argentinian tango music. The Helikon-style accordion has multiple flared horns projecting out of the left side to strengthen the bass tone. The word "Helikon" refers to a deep-pitched tuba.

Different systems exist for the right-hand manual of an accordion, which is normally used for playing the melody (while it can also play chords). Some use a button layout arranged in one way or another, while others use a piano-style keyboard. Each system has different claimed benefits by those who prefer it. They are also used to define one accordion or another as a different "type":

Different systems are also in use for the left-hand manual, which is normally used for playing the accompaniment. These almost always use distinct bass buttons and often have buttons with concavities or studs to help the player navigate the layout despite not being able to see the buttons while playing. There are three general categories:


Inside the accordion are the reeds that generate the instrument tones. These are organized in different sounding "banks", which can be further combined into "registers" producing differing "timbres". All but the smaller accordions are equipped with switches that control which combination of reed banks operate, organized from high to low registers. Each register stop produces a separate sound timbre, many of which also differ in octaves or in how different octaves are combined. See the accordion reed ranks and switches article for further explanation and audio samples. All but the smallest accordions usually have treble switches. The larger and more expensive accordions often also have bass switches to give options for the reed bank on the bass side.

In describing or pricing an accordion, the first factor is size, expressed in number of keys on either side. For a piano type, this could for one example be 37/96, meaning 37 treble keys (three octaves plus one note) on the treble side and 96 bass keys. A second aspect of size is the width of the white keys, which means that even accordions with the same number of keys have keyboards of different lengths, ranging from for a child's accordion to for an adult-sized instrument. After size, the price and weight of an accordion is largely dependent on the number of reed ranks on either side, either on a cassotto or not, and to a lesser degree on the number of combinations available through register switches.

Price is also affected by the use of costly woods, luxury decorations, and features such as a palm switch, grille mute, and so on. Some accordion makers sell the same model in a range of different models, from a less-expensive base model to a more costly luxury model. Typically, the register switches are described as "Reeds: 5 + 3", meaning five reeds on the treble side and three on the bass, and "Registers: 13 + M, 7", meaning 13 register buttons on the treble side plus a special "master" that activates all ranks, like the "tutti" or "full organ" switch on an organ, and seven register switches on the bass side. Another factor affecting the price is the presence of electronics, such as condenser microphones, volume and tone controls, or MIDI sensors and connections.

The larger piano and chromatic button accordions are usually heavier than other smaller squeezeboxes, and are equipped with two shoulder straps to make it easier to balance the weight and increase bellows control while sitting, and avoid dropping the instrument while standing. Other accordions, such as the diatonic button accordion, have only a single shoulder strap and a right hand thumb strap. All accordions have a (mostly adjustable) leather strap on the left-hand manual to keep the player's hand in position while drawing the bellows. There are also straps above and below the bellows to keep it securely closed when the instrument is not playing.

In the 2010s, a range of electronic and digital accordions are made. They have an electronic sound module which creates the accordion sound, and most use MIDI systems to encode the keypresses and transmit them to the sound module. A digital accordion can have hundreds of sounds, which can include different types of accordions and even non-accordion sounds, such as pipe organ, piano, or guitar. Sensors are used on the buttons and keys, such as magnetic reed switches. Sensors are also used on the bellows to transmit the pushing and pulling of the bellows to the sound module. Digital accordions may have features not found in acoustic instruments, such as a piano-style sustain pedal, a modulation control for changing keys, and a portamento effect.

As an electronic instrument, these types of accordions are plugged into a PA system or keyboard amplifier to produce sound. Some digital accordions have a small internal speaker and amplifier, so they can be used without a PA system or keyboard amplifier, at least for practicing and small venues like coffeehouses. One benefit of electronic accordions is that they can be practiced with headphones, making them inaudible to other people nearby. On a digital accordion, the volume of the right-hand keyboard and the left-hand buttons can be independently adjusted.

Acoustic-digital hybrid accordions also exist. They are acoustic accordions (with reeds, bellows, and so on), but they also contain sensors, electronics, and MIDI connections, which provides a wider range of sound options. An acoustic-digital hybrid may be manufactured in this form, or it may be an acoustic accordion which has had aftermarket electronics sensors and connections added. Several companies sell aftermarket electronics kits, but they are typically installed by professional accordion technicians, due to the complex and delicate nature of the internal parts of an accordion.

Various hybrid accordions have been created between instruments of different buttonboards and actions. Many remain curiosities – only a few have remained in use:

The accordion's basic form is believed to have been invented in Berlin, in 1822, by Christian Friedrich Ludwig Buschmann, although one instrument has been recently discovered that appears to have been built earlier.

The earliest history of the accordion in Russia is poorly documented. Nevertheless, according to Russian researchers, the earliest known simple accordions were made in Tula, Russia, by and around 1830, after they received an early accordion from Germany. By the late 1840s, the instrument was already very widespread; together the factories of the two masters were producing 10,000 instruments a year. By 1866, over 50,000 instruments were being produced yearly by Tula and neighbouring villages, and by 1874 the yearly production was over 700,000. By the 1860s, Novgorod, Vyatka and Saratov governorates also had significant accordion production. By the 1880s, the list included Oryol, Ryazan, Moscow, Tver, Vologda, Kostroma, Nizhny Novgorod and Simbirsk, and many of these places created their own varieties of the instrument.

The accordion is one of several European inventions of the early 19th century that use free reeds driven by a bellows. An instrument called "accordion" was first patented in 1829 by Cyrill Demian, of Armenian origin, in Vienna. Demian's instrument bore little resemblance to modern instruments. It only had a left hand buttonboard, with the right hand simply operating the bellows. One key feature for which Demian sought the patent was the sounding of an entire chord by depressing one key. His instrument also could sound two different chords with the same key, one for each bellows direction (a "bisonoric" action). At that time in Vienna, mouth harmonicas with "Kanzellen" (chambers) had already been available for many years, along with bigger instruments driven by hand bellows. The diatonic key arrangement was also already in use on mouth-blown instruments. Demian's patent thus covered an accompanying instrument: an accordion played with the left hand, opposite to the way that contemporary chromatic hand harmonicas were played, small and light enough for travelers to take with them and used to accompany singing. The patent also described instruments with both bass and treble sections, although Demian preferred the bass-only instrument owing to its cost and weight advantages.

The accordion was introduced from Germany into Britain in about the year 1828. The instrument was noted in "The Times" in 1831 as one new to British audiences and was not favourably reviewed, but nevertheless it soon became popular. It had also become popular with New Yorkers by the mid-1840s.

After Demian's invention, other accordions appeared, some featuring only the right-handed keyboard for playing melodies. It took English inventor Charles Wheatstone to bring both chords and keyboard together in one squeezebox. His 1844 patent for what he called a "concertina" also featured the ability to easily tune the reeds from the outside with a simple tool.
The musician Adolph Müller described a great variety of instruments in his 1833 book "Schule für Accordion". At the time, Vienna and London had a close musical relationship, with musicians often performing in both cities in the same year, so it is possible that Wheatstone was aware of this type of instrument and may have used them to put his key-arrangement ideas into practice.

Jeune's "flutina" resembles Wheatstone's concertina in internal construction and tone colour, but it appears to complement Demian's accordion functionally. The flutina is a one-sided bisonoric melody-only instrument whose keys are operated with the right hand while the bellows is operated with the left. When the two instruments are combined, the result is quite similar to diatonic button accordions still manufactured today.

Further innovations followed and continue to the present. Various buttonboard and keyboard systems have been developed, as well as voicings (the combination of multiple tones at different octaves), with mechanisms to switch between different voices during performance, and different methods of internal construction to improve tone, stability and durability. Modern accordions may incorporate electronics such as condenser microphones and tone and volume controls, so that the accordion can be plugged into a PA system or keyboard amplifier for live shows. Some 2010s-era accordions may incorporate MIDI sensors and circuitry, enabling the accordion to be plugged into a synth module and produce accordion sounds or other synthesized instrument sounds, such as piano or organ.

The accordion has traditionally been used to perform folk or ethnic music, popular music, and transcriptions from the operatic and light-classical music repertoire. It was also used by the Kikuyu tribe in Kenya and is the main instrument in the traditional Mwomboko dance. Today the instrument is sometimes heard in contemporary pop styles, such as rock and pop-rock, and occasionally even in serious classical music concerts, as well as advertisements.

The accordion's popularity spread rapidly: it has mostly been associated with the common people, and was propagated by Europeans who emigrated around the world. The accordion in both button and piano forms became a favorite of folk musicians and has been integrated into traditional music styles all over the world: see the list of music styles that incorporate the accordion.

Early jazz accordionist include Charles Melrose, who recorded "Wailing Blues/Barrel House Stomp" (1930, Voc. 1503) with the Cellar Boys; Buster Moten, who played second piano and accordion in the Bennie Moten orchestra; and Jack Cornell, who did recordings with Irving Mills. Later jazz accordionists from the United States include Steve Bach, Milton DeLugg, Orlando DiGirolamo, Dominic Frontiere, Guy Klucevsek, Yuri Lemeshev, Frank Marocco, John Serry Sr., Lee Tomboulian, and Art Van Damme. French jazz accordionists include Richard Galliano, Bernard Lubat, and Vincent Peirani. Norwegian jazz accordionists include Asmund Bjørken, Stian Carstensen, Gabriel Fliflet, Frode Haltli, and Eivin One Pedersen.

While the accordion's left hand preset chord buttons are limited to triads and seventh chords (for the dominant seventh chord and the diminished seventh chord), jazz accordionists expand the range of chord possibilities by using more than one chord button simultaneously, or by using combinations of a chord button and a bass note other than the typical root of the chord. An example of the former technique is used to play a minor seventh chord. To play an "a minor" seventh chord (with an added ninth), the "a minor" and "e minor" preset buttons are pressed simultaneously, along with an "A" bassnote. An example of the latter technique is used to play the half-diminished chord. To play an "e" half-diminished seventh chord, a "g minor" preset button is pressed along with an "E" bassnote.

The accordion appeared in popular music from the 1900s to the 1960s. This half-century is often called the "golden age of the accordion". Five players, Pietro Frosini, the two brothers Count Guido Deiro and Pietro Deiro and Slovenian brothers Vilko Ovsenik and Slavko Avsenik, Charles Magnante were major influences at this time.

Most vaudeville theaters closed during the Great Depression, but accordionists during the 1930s–1950s taught and performed for radio. Included among this group was the concert virtuoso John Serry, Sr. During the 1950s through the 1980s the accordion received significant exposure on television with performances by Myron Floren on "The Lawrence Welk Show". In the late 1950s and early 1960s, the accordion declined in popularity due to the rise of rock and roll. The first accordionist to appear and perform at the Newport Jazz Festival was Angelo DiPippo. He can be seen playing his accordion in the motion picture "The Godfather". He also composed and performed with his accordion on part of the soundtrack of Woody Allen's movie "To Rome With Love". He was featured twice on "The Tonight Show" with Johnny Carson.
Richard Galliano is an internationally known accordionist whose repertoire covers jazz, tango nuevo, latin, and classical. Some popular bands use the instrument to create distinctive sounds. A notable example is Grammy Award-winning parodist "Weird Al" Yankovic, who plays the accordion on many of his musical tracks, particularly his polkas. Yankovic was trained in the accordion as a child.

The accordion has also been used in the rock genre, most notably by John Linnell of They Might Be Giants, featuring more prominently in the band's earlier works. The instrument is still frequently used during live performances, and continues to make appearances in their studio albums. Accordion is also used in the music of the Dropkick Murphys and Gogol Bordello.

Accordionists in heavy metal music make their most extensive appearances in the folk metal subgenre, and are otherwise generally rare. Full-time accordionists in folk metal seem even rarer, but they are still utilized for studio work, as flexible keyboardists are usually more accessible for live performances. The Finnish symphonic folk-metal band Turisas used to have a full-time accordionist, employing classical and polka sensibilities alongside a violinist. One of their accordionists, Netta Skog, is now a member of Ensiferum, another folk-metal band. Another Finnish metal band, Korpiklaani, invokes a type of Finnish polka called humppa, and also has a full-time accordionist. Sarah Kiener, the former hurdy-gurdy player for the Swiss melodic-death-folk metal band Eluveitie, played a Helvetic accordion known as a "zugerörgeli".

Although best known as a folk instrument, it has grown in popularity among classical composers. The earliest surviving concert piece is "", written in 1836 by Louise Reisner of Paris. Other composers, including the Russian Pyotr Ilyich Tchaikovsky, the Italian Umberto Giordano, and the American Charles Ives, wrote works for the diatonic button accordion.
The first composer to write specifically for the chromatic accordion was Paul Hindemith. In 1922, the Austrian Alban Berg included an accordion in "Wozzeck", Op. 7. In 1937 the first accordion concerto was composed in Russia. Other notable composers have written for the accordion during the first half of the 20th century. Included among this group was the Italian-American John Serry Sr., whose "Concerto for Free Bass Accordion" was completed in 1964. In addition, the American accordionist Robert Davine composed his "Divertimento for Flute, Clarinet, Bassoon and Accordion" as a work for chamber orchestra. American composer William P. Perry featured the accordion in his orchestral suite "Six Title Themes in Search of a Movie" (2008). The experimental composer Howard Skempton began his musical career as an accordionist, and has written numerous solo works for it. In his work "Drang" (1999), British composer John Palmer pushed the expressive possibilities of the accordion/bayan. Luciano Berio wrote "Sequenza XIII" (1995) for accordionist Teodoro Anzellotti. Accordionists like Mogens Ellegaard, Joseph Macerollo, Friedrich Lips, Hugo Noth, Stefan Hussong, Italo Salizzato, Teodoro Anzellotti, Mie Miki, and Geir Draugsvoll, encouraged composers to write new music for the accordion (solo and chamber music) and also started playing baroque music on the free bass accordion.

French composer Henri Dutilleux used an accordion in both his late song cycles "Correspondances" (2003) and "Le Temps l'Horloge" (2009). Russian-born composer Sofia Gubaidulina has composed solos, concertos, and chamber works for accordion. Astor Piazzolla's concert tangos are performed widely. Piazzolla performed on the bandoneon, but his works are performed on either bandoneon or accordion.

The earliest mention of the novel accordion instrument in Australian music occurs in the 1830s.
The accordion initially competed against cheaper and more convenient reed instruments such as mouth organ, concertina and melodeon.
Frank Fracchia was an Australian accordion composer and copies of his works "My dear, can you come out tonight" and "Dancing with you" are preserved in Australian libraries.
Other Australian composers who arranged music for accordion include Reginald Stoneham.
The popularity of the accordion peaked in the late 1930s and continued until the 1950s.
The accordion was particularly favoured by buskers.

The accordion is a traditional instrument in Bosnia and Herzegovina. It is the dominant instrument used in sevdalinka, a traditional genre of folk music from Bosnia and Herzegovina. It is also considered a national instrument of the country.

The accordion was brought to Brazil by settlers and immigrants from Europe, especially from Italy and Germany, who mainly settled in the south (Rio Grande do Sul, Santa Catarina and Parana). The first instrument brought was a "Concertina" (a 120 button chromatic accordion). The instrument was popular in the 1950s, and was common to find several accordions in the same house. There are many different configurations and tunes which were adapted from the cultures that came from Europe.

Accordion is the official symbol instrument of the Rio Grande do Sul state, where was voted by unanimity in the deputy chamber.
During the boom of accordions there were around 65 factories in Brazil, where most of them (52) in the south, in Rio Grande do Sul state, with only 7 outside the south. One of the most famous and genuinely Brazilian brands was Acordeões Todeschini from Bento Gonçalves-RS, closed in 1973. The Todeschini accordion is very appreciated today and survives with very few maintainers. The most notable musicians of button accordions are Renato Borghetti, Adelar Bertussi, Albino Manique and Edson Dutra.

Compared to many other countries, the instrument is very popular in mainstream pop music. In some parts of the country, such as the northeast it is the most popular melodic instrument. As opposed to most European folk accordions, a very dry tuning is usually used in Brazil. Outside the south, the accordion (predominantly the piano accordion) is used in almost all styles of Forró (in particular in the subgenres of Xote and Baião) as the principal instrument, Luiz Gonzaga (the "King of the Baião") and Dominguinhos being among the notable musicians in this style from the northeast. In this musical style the typical combination is a trio of accordion, triangle and zabumba (a type of drum).

This style has gained popularity recently, in particular among the student population of the southeast of the country (in the Forró Universitário genre, with important exponents today being Falamansa, and trios such as Trio Dona Zefa, Trio Virgulino and Trio Alvorada). Moreover, the accordion is the principal instrument in Junina music (music of the São João Festival), with Mario Zan having been a very important exponent of this music. It is an important instrument in Sertanejo (and Caipira) music, which originated in the midwest and southeast of Brazil, and subsequently has gained popularity throughout the country.

The accordion is also a traditional instrument in Colombia, commonly associated with the vallenato and cumbia genres. The accordion has been used by tropipop musicians such as Carlos Vives, Andrés Cabas, Fonseca (singer) and Bacilos, as well as rock musicians such as Juanes and pop musicians as Shakira. Vallenato, who emerged in the early twentieth century in a city known as Valledupar, and have come to symbolize the folk music of Colombia.

Every year in April, Colombia holds one of the most important musical festivals in the country: the Vallenato Legend Festival. The festival holds contests for best accordion player. Once every decade, the "King of Kings" accordion competition takes place, where winners of the previous festivals compete for the highest possible award for a vallenato accordion player: the "Pilonera Mayor" prize. This is the world's largest competitive accordion festival.

Norteño heavily relies on the accordion; it is a genre related to polka. Ramón Ayala, known in Mexico as the "King of the Accordion", is a norteño musician. Cumbia, which features the accordion, is also popular with musicians such as Celso Piña, creating a more contemporary style. U.S.-born Mexican musician Julieta Venegas incorporates the sound of the instrument into rock, pop and folk. She was influenced by her fellow Chicanos Los Lobos who also use the music of the accordion.

According to Barbara Demick in "Nothing to Envy", the accordion is known as "the people's instrument" and all North Korean teachers were expected to learn the accordion.

The most expensive accordions are typically fully hand-made, particularly the reeds; completely hand-made reeds have a better tonal quality than even the best automatically-manufactured ones. Some accordions have been modified by individuals striving to bring a more pure sound out of low-end instruments, such as the ones improved by Yutaka Usui, a Japanese craftsman.

The manufacture of an accordion is only a partly automated process. In a sense, all accordions are handmade, since there is always some hand assembly of the small parts required. The general process involves making the individual parts, assembling the subsections, assembling the entire instrument, and final decorating and packaging.

Famous centres of production are the Italian cities of Stradella and Castelfidardo, with many small and medium size manufacturers especially at the latter. Castelfidardo honours the memory of Paolo Soprani who was one of the first large-scale producers. has built accordions in the French town of Tulle since 1919, and the company is now the last complete-process manufacturer of accordions in France. German companies such as Hohner and Weltmeister made large numbers of accordions, but production diminished by the end of the 20th century. Hohner still manufactures its top-end models in Germany, and "Weltmeister" instruments are still handmade by HARMONA Akkordeon GmbH in Klingenthal.





</doc>
<doc id="1164" url="https://en.wikipedia.org/wiki?curid=1164" title="Artificial intelligence">
Artificial intelligence

Artificial intelligence (AI), sometimes called machine intelligence, is intelligence demonstrated by machines, unlike the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of "intelligent agents": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. Colloquially, the term "artificial intelligence" is often used to describe machines (or computers) that mimic "cognitive" functions that humans associate with the human mind, such as "learning" and "problem solving".

As machines become increasingly capable, tasks considered to require "intelligence" are often removed from the definition of AI, a phenomenon known as the AI effect. A quip in Tesler's Theorem says "AI is whatever hasn't been done yet." For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology. Modern machine capabilities generally classified as AI include successfully understanding human speech, competing at the highest level in strategic game systems (such as chess and Go), autonomously operating cars, intelligent routing in content delivery networks, and military simulations.
Artificial intelligence was founded as an academic discipline in 1955, and in the years since has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an "AI winter"), followed by new approaches, success and renewed funding. For most of its history, AI research has been divided into sub-fields that often fail to communicate with each other. These sub-fields are based on technical considerations, such as particular goals (e.g. "robotics" or "machine learning"), the use of particular tools ("logic" or artificial neural networks), or deep philosophical differences. Sub-fields have also been based on social factors (particular institutions or the work of particular researchers).
The traditional problems (or goals) of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception and the ability to move and manipulate objects. General intelligence is among the field's long-term goals. Approaches include statistical methods, computational intelligence, and traditional symbolic AI. Many tools are used in AI, including versions of search and mathematical optimization, artificial neural networks, and methods based on statistics, probability and economics. The AI field draws upon computer science, information engineering, mathematics, psychology, linguistics, philosophy, and many other fields.
The field was founded on the assumption that human intelligence "can be so precisely described that a machine can be made to simulate it". This raises philosophical arguments about the mind and the ethics of creating artificial beings endowed with human-like intelligence. These issues have been explored by myth, fiction and philosophy since antiquity. Some people also consider AI to be a danger to humanity if it progresses unabated. Others believe that AI, unlike previous technological revolutions, will create a risk of mass unemployment.
In the twenty-first century, AI techniques have experienced a resurgence following concurrent advances in computer power, large amounts of data, and theoretical understanding; and AI techniques have become an essential part of the technology industry, helping to solve many challenging problems in computer science, software engineering and operations research.

Thought-capable artificial beings appeared as storytelling devices in antiquity, and have been common in fiction, as in Mary Shelley's "Frankenstein" or Karel Čapek's "R.U.R. (Rossum's Universal Robots)". These characters and their fates raised many of the same issues now discussed in the ethics of artificial intelligence.
The study of mechanical or "formal" reasoning began with philosophers and mathematicians in antiquity. The study of mathematical logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as "0" and "1", could simulate any conceivable act of mathematical deduction. This insight, that digital computers can simulate any process of formal reasoning, is known as the Church–Turing thesis. Along with concurrent discoveries in neurobiology, information theory and cybernetics, this led researchers to consider the possibility of building an electronic brain. Turing proposed changing the question from whether a machine was intelligent, to "whether or not it is possible for machinery to show intelligent behaviour". The first work that is now generally recognized as AI was McCullouch and Pitts' 1943 formal design for Turing-complete "artificial neurons".
The field of AI research was born at a workshop at Dartmouth College in 1956, where the term "Artificial Intelligence" was coined by John McCarthy to distinguish the field from cybernetics and escape the influence of the cyberneticist Norbert Wiener. Attendees Allen Newell (CMU), Herbert Simon (CMU), John McCarthy (MIT), Marvin Minsky (MIT) and Arthur Samuel (IBM) became the founders and leaders of AI research. They and their students produced programs that the press described as "astonishing": computers were learning checkers strategies (c. 1954) (and by 1959 were reportedly playing better than the average human), solving word problems in algebra, proving logical theorems (Logic Theorist, first run c. 1956) and speaking English. By the middle of the 1960s, research in the U.S. was heavily funded by the Department of Defense and laboratories had been established around the world. AI's founders were optimistic about the future: Herbert Simon predicted, "machines will be capable, within twenty years, of doing any work a man can do". Marvin Minsky agreed, writing, "within a generation ... the problem of creating 'artificial intelligence' will substantially be solved".
They failed to recognize the difficulty of some of the remaining tasks. Progress slowed and in 1974, in response to the criticism of Sir James Lighthill and ongoing pressure from the US Congress to fund more productive projects, both the U.S. and British governments cut off exploratory research in AI. The next few years would later be called an "AI winter", a period when obtaining funding for AI projects was difficult.
In the early 1980s, AI research was revived by the commercial success of expert systems, a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S and British governments to restore funding for academic research. However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting hiatus began.

The development of metal–oxide–semiconductor (MOS) very-large-scale integration (VLSI), in the form of complementary MOS (CMOS) transistor technology, enabled the development of practical artificial neural network (ANN) technology in the 1980s. A landmark publication in the field was the 1989 book "Analog VLSI Implementation of Neural Systems" by Carver A. Mead and Mohammed Ismail.
In the late 1990s and early 21st century, AI began to be used for logistics, data mining, medical diagnosis and other areas. The success was due to increasing computational power (see Moore's law and transistor count), greater emphasis on solving specific problems, new ties between AI and other fields (such as statistics, economics and mathematics), and a commitment by researchers to mathematical methods and scientific standards. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.
In 2011, a "Jeopardy!" quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest "Jeopardy!" champions, Brad Rutter and Ken Jennings, by a significant margin. Faster computers, algorithmic improvements, and access to large amounts of data enabled advances in machine learning and perception; data-hungry deep learning methods started to dominate accuracy benchmarks around 2012. The Kinect, which provides a 3D body–motion interface for the Xbox 360 and the Xbox One, uses algorithms that emerged from lengthy AI research as do intelligent personal assistants in smartphones. In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. In the 2017 Future of Go Summit, AlphaGo won a three-game match with Ke Jie, who at the time continuously held the world No. 1 ranking for two years. This marked the completion of a significant milestone in the development of Artificial Intelligence as Go is a relatively complex game, more so than Chess.

According to Bloomberg's Jack Clark, 2015 was a landmark year for artificial intelligence, with the number of software projects that use AI within Google increased from a "sporadic usage" in 2012 to more than 2,700 projects. Clark also presents factual data indicating the improvements of AI since 2012 supported by lower error rates in image processing tasks. He attributes this to an increase in affordable neural networks, due to a rise in cloud computing infrastructure and to an increase in research tools and datasets. Other cited examples include Microsoft's development of a Skype system that can automatically translate from one language to another and Facebook's system that can describe images to blind people. In a 2017 survey, one in five companies reported they had "incorporated AI in some offerings or processes". Around 2016, China greatly accelerated its government funding; given its large supply of data and its rapidly increasing research output, some observers believe it may be on track to becoming an "AI superpower". However, it has been acknowledged that reports regarding artificial intelligence have tended to be exaggerated.

Computer science defines AI research as the study of "intelligent agents": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. A more elaborate definition characterizes AI as "a system's ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation."

A typical AI analyzes its environment and takes actions that maximize its chance of success. An AI's intended utility function (or goal) can be simple ("1 if the AI wins a game of Go, 0 otherwise") or complex ("Perform actions mathematically similar to ones that succeeded in the past"). Goals can be explicitly defined or induced. If the AI is programmed for "reinforcement learning", goals can be implicitly induced by rewarding some types of behavior or punishing others. Alternatively, an evolutionary system can induce goals by using a "fitness function" to mutate and preferentially replicate high-scoring AI systems, similar to how animals evolved to innately desire certain goals such as finding food. Some AI systems, such as nearest-neighbor, instead of reason by analogy, these systems are not generally given goals, except to the degree that goals are implicit in their training data. Such systems can still be benchmarked if the non-goal system is framed as a system whose "goal" is to successfully accomplish its narrow classification task.

AI often revolves around the use of algorithms. An algorithm is a set of unambiguous instructions that a mechanical computer can execute. A complex algorithm is often built on top of other, simpler, algorithms. A simple example of an algorithm is the following (optimal for first player) recipe for play at tic-tac-toe:


Many AI algorithms are capable of learning from data; they can enhance themselves by learning new heuristics (strategies, or "rules of thumb", that have worked well in the past), or can themselves write other algorithms. Some of the "learners" described below, including Bayesian networks, decision trees, and nearest-neighbor, could theoretically, (given infinite data, time, and memory) learn to approximate any function, including which combination of mathematical functions would best describe the world. These learners could therefore derive all possible knowledge, by considering every possible hypothesis and matching them against the data. In practice, it is seldom possible to consider every possibility, because of the phenomenon of "combinatorial explosion", where the time needed to solve a problem grows exponentially. Much of AI research involves figuring out how to identify and avoid considering a broad range of possibilities unlikely to be beneficial. For example, when viewing a map and looking for the shortest driving route from Denver to New York in the East, one can in most cases skip looking at any path through San Francisco or other areas far to the West; thus, an AI wielding a pathfinding algorithm like A* can avoid the combinatorial explosion that would ensue if every possible route had to be ponderously considered.

The earliest (and easiest to understand) approach to AI was symbolism (such as formal logic): "If an otherwise healthy adult has a fever, then they may have influenza". A second, more general, approach is Bayesian inference: "If the current patient has a fever, adjust the probability they have influenza in such-and-such way". The third major approach, extremely popular in routine business AI applications, are analogizers such as SVM and nearest-neighbor: "After examining the records of known past patients whose temperature, symptoms, age, and other factors mostly match the current patient, X% of those patients turned out to have influenza". A fourth approach is harder to intuitively understand, but is inspired by how the brain's machinery works: the artificial neural network approach uses artificial "neurons" that can learn by comparing itself to the desired output and altering the strengths of the connections between its internal neurons to "reinforce" connections that seemed to be useful. These four main approaches can overlap with each other and with evolutionary systems; for example, neural nets can learn to make inferences, to generalize, and to make analogies. Some systems implicitly or explicitly use multiple of these approaches, alongside many other AI and non-AI algorithms; the best approach is often different depending on the problem.

Learning algorithms work on the basis that strategies, algorithms, and inferences that worked well in the past are likely to continue working well in the future. These inferences can be obvious, such as "since the sun rose every morning for the last 10,000 days, it will probably rise tomorrow morning as well". They can be nuanced, such as "X% of families have geographically separate species with color variants, so there is a Y% chance that undiscovered black swans exist". Learners also work on the basis of "Occam's razor": The simplest theory that explains the data is the likeliest. Therefore, according to Occam's razor principle, a learner must be designed such that it prefers simpler theories to complex theories, except in cases where the complex theory is proven substantially better.
Settling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data, but penalizing the theory in accordance with how complex the theory is. Besides classic overfitting, learners can also disappoint by "learning the wrong lesson". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses. A real-world example is that, unlike humans, current image classifiers don't determine the spatial relationship between components of the picture; instead, they learn abstract patterns of pixels that humans are oblivious to, but that linearly correlate with images of certain types of real objects. Faintly superimposing such a pattern on a legitimate image results in an "adversarial" image that the system misclassifies.
Compared with humans, existing AI lacks several features of human "commonsense reasoning"; most notably, humans have powerful mechanisms for reasoning about "naïve physics" such as space, time, and physical interactions. This enables even young children to easily make inferences like "If I roll this pen off a table, it will fall on the floor". Humans also have a powerful mechanism of "folk psychology" that helps them to interpret natural-language sentences such as "The city councilmen refused the demonstrators a permit because they advocated violence" (A generic AI has difficulty discerning whether the ones alleged to be advocating violence are the councilmen or the demonstrators). This lack of "common knowledge" means that AI often makes different mistakes than humans make, in ways that can seem incomprehensible. For example, existing self-driving cars cannot reason about the location nor the intentions of pedestrians in the exact way that humans do, and instead must use non-human modes of reasoning to avoid accidents.

The cognitive capabilities of current architectures are very limited, using only a simplified version of what intelligence is really capable of. For instance, the human mind has come up with ways to reason beyond measure and logical explanations to different occurrences in life. What would have been otherwise straightforward, an equivalently difficult problem may be challenging to solve computationally as opposed to using the human mind. This gives rise to two classes of models: structuralist and functionalist. The structural models aim to loosely mimic the basic intelligence operations of the mind such as reasoning and logic. The functional model refers to the correlating data to its computed counterpart.

The overall research goal of artificial intelligence is to create technology that allows computers and machines to function in an intelligent manner. The general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention.

Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, AI research had developed methods for dealing with uncertain or incomplete information, employing concepts from probability and economics.

These algorithms proved to be insufficient for solving large reasoning problems because they experienced a "combinatorial explosion": they became exponentially slower as the problems grew larger. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.

Knowledge representation and knowledge engineering are central to classical AI research. Some "expert systems" attempt to gather explicit knowledge possessed by experts in some narrow domain. In addition, some projects attempt to gather the "commonsense knowledge" known to the average person into a database containing extensive knowledge about the world. Among the things a comprehensive commonsense knowledge base would contain are: objects, properties, categories and relations between objects; situations, events, states and time; causes and effects; knowledge about knowledge (what we know about what other people know); and many other, less well researched domains. A representation of "what exists" is an ontology: the set of objects, relations, concepts, and properties formally described so that software agents can interpret them. The semantics of these are captured as description logic concepts, roles, and individuals, and typically implemented as classes, properties, and individuals in the Web Ontology Language. The most general ontologies are called upper ontologies, which attempt to provide a foundation for all other knowledge by acting as mediators between domain ontologies that cover specific knowledge about a particular knowledge domain (field of interest or area of concern). Such formal knowledge representations can be used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining "interesting" and actionable inferences from large databases), and other areas.

Among the most difficult problems in knowledge representation are:

Intelligent agents must be able to set goals and achieve them. They need a way to visualize the future—a representation of the state of the world and be able to make predictions about how their actions will change it—and be able to make choices that maximize the utility (or "value") of available choices.

In classical planning problems, the agent can assume that it is the only system acting in the world, allowing the agent to be certain of the consequences of its actions. However, if the agent is not the only actor, then it requires that the agent can reason under uncertainty. This calls for an agent that can not only assess its environment and make predictions but also evaluate its predictions and adapt based on its assessment.

Multi-agent planning uses the cooperation and competition of many agents to achieve a given goal. Emergent behavior such as this is used by evolutionary algorithms and swarm intelligence.

Machine learning (ML), a fundamental concept of AI research since the field's inception, is the study of computer algorithms that improve automatically through experience.

Unsupervised learning is the ability to find patterns in a stream of input, without requiring a human to label the inputs first. Supervised learning includes both classification and numerical regression, which requires a human to label the input data first. Classification is used to determine what category something belongs in, and occurs after a program sees a number of examples of things from several categories. Regression is the attempt to produce a function that describes the relationship between inputs and outputs and predicts how the outputs should change as the inputs change. Both classifiers and regression learners can be viewed as "function approximators" trying to learn an unknown (possibly implicit) function; for example, a spam classifier can be viewed as learning a function that maps from the text of an email to one of two categories, "spam" or "not spam". Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization. In reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent uses this sequence of rewards and punishments to form a strategy for operating in its problem space.

Natural language processing (NLP) allows machines to read and understand human language. A sufficiently powerful natural language processing system would enable natural-language user interfaces and the acquisition of knowledge directly from human-written sources, such as newswire texts. Some straightforward applications of natural language processing include information retrieval, text mining, question answering and machine translation. Many current approaches use word co-occurrence frequencies to construct syntactic representations of text. "Keyword spotting" strategies for search are popular and scalable but dumb; a search query for "dog" might only match documents with the literal word "dog" and miss a document with the word "poodle". "Lexical affinity" strategies use the occurrence of words such as "accident" to assess the sentiment of a document. Modern statistical NLP approaches can combine all these strategies as well as others, and often achieve acceptable accuracy at the page or paragraph level. Beyond semantic NLP, the ultimate goal of "narrative" NLP is to embody a full understanding of commonsense reasoning. By 2019, transformer-based deep learning architectures could generate coherent text.

Machine perception is the ability to use input from sensors (such as cameras (visible spectrum or infrared), microphones, wireless signals, and active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Applications include speech recognition, facial recognition, and object recognition. Computer vision is the ability to analyze visual input. Such input is usually ambiguous; a giant, fifty-meter-tall pedestrian far away may produce the same pixels as a nearby normal-sized pedestrian, requiring the AI to judge the relative likelihood and reasonableness of different interpretations, for example by using its "object model" to assess that fifty-meter pedestrians do not exist.

AI is heavily used in robotics. Advanced robotic arms and other industrial robots, widely used in modern factories, can learn from experience how to move efficiently despite the presence of friction and gear slippage. A modern mobile robot, when given a small, static, and visible environment, can easily determine its location and map its environment; however, dynamic environments, such as (in endoscopy) the interior of a patient's breathing body, pose a greater challenge. Motion planning is the process of breaking down a movement task into "primitives" such as individual joint movements. Such movement often involves compliant motion, a process where movement requires maintaining physical contact with an object. Moravec's paradox generalizes that low-level sensorimotor skills that humans take for granted are, counterintuitively, difficult to program into a robot; the paradox is named after Hans Moravec, who stated in 1988 that "it is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility". This is attributed to the fact that, unlike checkers, physical dexterity has been a direct target of natural selection for millions of years.

Moravec's paradox can be extended to many forms of social intelligence. Distributed multi-agent coordination of autonomous vehicles remains a difficult problem. Affective computing is an interdisciplinary umbrella that comprises systems which recognize, interpret, process, or simulate human affects. Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal affect analysis (see multimodal sentiment analysis), wherein AI classifies the affects displayed by a videotaped subject.

In the long run, social skills and an understanding of human emotion and game theory would be valuable to a social agent. The ability to predict the actions of others by understanding their motives and emotional states would allow an agent to make better decisions. Some computer systems mimic human emotion and expressions to appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction. Similarly, some virtual assistants are programmed to speak conversationally or even to banter humorously; this tends to give naïve users an unrealistic conception of how intelligent existing computer agents actually are.

Historically, projects such as the Cyc knowledge base (1984–) and the massive Japanese Fifth Generation Computer Systems initiative (1982–1992) attempted to cover the breadth of human cognition. These early projects failed to escape the limitations of non-quantitative symbolic logic models and, in retrospect, greatly underestimated the difficulty of cross-domain AI. Nowadays, most current AI researchers work instead on tractable "narrow AI" applications (such as medical diagnosis or automobile navigation). Many researchers predict that such "narrow AI" work in different individual domains will eventually be incorporated into a machine with artificial general intelligence (AGI), combining most of the narrow skills mentioned in this article and at some point even exceeding human ability in most or all these areas. Many advances have general, cross-domain significance. One high-profile example is that DeepMind in the 2010s developed a "generalized artificial intelligence" that could learn many diverse Atari games on its own, and later developed a variant of the system which succeeds at . Besides transfer learning, hypothetical AGI breakthroughs could include the development of reflective architectures that can engage in decision-theoretic metareasoning, and figuring out how to "slurp up" a comprehensive knowledge base from the entire unstructured Web. Some argue that some kind of (currently-undiscovered) conceptually straightforward, but mathematically difficult, "Master Algorithm" could lead to AGI. Finally, a few "emergent" approaches look to simulating human intelligence extremely closely, and believe that anthropomorphic features like an artificial brain or simulated child development may someday reach a critical point where general intelligence emerges.

Many of the problems in this article may also require general intelligence, if machines are to solve the problems as well as people do. For example, even specific straightforward tasks, like machine translation, require that a machine read and write in both languages (NLP), follow the author's argument (reason), know what is being talked about (knowledge), and faithfully reproduce the author's original intent (social intelligence). A problem like machine translation is considered "AI-complete", because all of these problems need to be solved simultaneously in order to reach human-level machine performance.

No established unifying theory or paradigm guides AI research. Researchers disagree about many issues. A few of the most long standing questions that have remained unanswered are these: should artificial intelligence simulate natural intelligence by studying psychology or neurobiology? Or is human biology as irrelevant to AI research as bird biology is to aeronautical engineering?
Can intelligent behavior be described using simple, elegant principles (such as logic or optimization)? Or does it necessarily require solving a large number of unrelated problems?

In the 1940s and 1950s, a number of researchers explored the connection between neurobiology, information theory, and cybernetics. Some of them built machines that used electronic networks to exhibit rudimentary intelligence, such as W. Grey Walter's turtles and the Johns Hopkins Beast. Many of these researchers gathered for meetings of the Teleological Society at Princeton University and the Ratio Club in England. By 1960, this approach was largely abandoned, although elements of it would be revived in the 1980s.

When access to digital computers became possible in the mid-1950s, AI research began to explore the possibility that human intelligence could be reduced to symbol manipulation. The research was centered in three institutions: Carnegie Mellon University, Stanford and MIT, and as described below, each one developed its own style of research. John Haugeland named these symbolic approaches to AI "good old fashioned AI" or "GOFAI". During the 1960s, symbolic approaches had achieved great success at simulating high-level "thinking" in small demonstration programs. Approaches based on cybernetics or artificial neural networks were abandoned or pushed into the background.
Researchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with artificial general intelligence and considered this the goal of their field.

Economist Herbert Simon and Allen Newell studied human problem-solving skills and attempted to formalize them, and their work laid the foundations of the field of artificial intelligence, as well as cognitive science, operations research and management science. Their research team used the results of psychological experiments to develop programs that simulated the techniques that people used to solve problems. This tradition, centered at Carnegie Mellon University would eventually culminate in the development of the Soar architecture in the middle 1980s.

Unlike Simon and Newell, John McCarthy felt that machines did not need to simulate human thought, but should instead try to find the essence of abstract reasoning and problem-solving, regardless whether people used the same algorithms. His laboratory at Stanford (SAIL) focused on using formal logic to solve a wide variety of problems, including knowledge representation, planning and learning. Logic was also the focus of the work at the University of Edinburgh and elsewhere in Europe which led to the development of the programming language Prolog and the science of logic programming.

Researchers at MIT (such as Marvin Minsky and Seymour Papert) found that solving difficult problems in vision and natural language processing required ad hoc solutions—they argued that no simple and general principle (like logic) would capture all the aspects of intelligent behavior. Roger Schank described their "anti-logic" approaches as "scruffy" (as opposed to the "neat" paradigms at CMU and Stanford). Commonsense knowledge bases (such as Doug Lenat's Cyc) are an example of "scruffy" AI, since they must be built by hand, one complicated concept at a time.

When computers with large memories became available around 1970, researchers from all three traditions began to build knowledge into AI applications. This "knowledge revolution" led to the development and deployment of expert systems (introduced by Edward Feigenbaum), the first truly successful form of AI software. A key component of the system architecture for all expert systems is the knowledge base, which stores facts and rules that illustrate AI. The knowledge revolution was also driven by the realization that enormous amounts of knowledge would be required by many simple AI applications.

By the 1980s, progress in symbolic AI seemed to stall and many believed that symbolic systems would never be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into "sub-symbolic" approaches to specific AI problems. Sub-symbolic methods manage to approach intelligence without specific representations of knowledge.

This includes embodied, situated, behavior-based, and nouvelle AI. Researchers from the related field of robotics, such as Rodney Brooks, rejected symbolic AI and focused on the basic engineering problems that would allow robots to move and survive. Their work revived the non-symbolic point of view of the early cybernetics researchers of the 1950s and reintroduced the use of control theory in AI. This coincided with the development of the embodied mind thesis in the related field of cognitive science: the idea that aspects of the body (such as movement, perception and visualization) are required for higher intelligence.

Within developmental robotics, developmental learning approaches are elaborated upon to allow robots to accumulate repertoires of novel skills through autonomous self-exploration, social interaction with human teachers, and the use of guidance mechanisms (active learning, maturation, motor synergies, etc.).

Interest in neural networks and "connectionism" was revived by David Rumelhart and others in the middle of the 1980s. Artificial neural networks are an example of soft computing—they are solutions to problems which cannot be solved with complete logical certainty, and where an approximate solution is often sufficient. Other soft computing approaches to AI include fuzzy systems, Grey system theory, evolutionary computation and many statistical tools. The application of soft computing to AI is studied collectively by the emerging discipline of computational intelligence.

Much of traditional GOFAI got bogged down on "ad hoc" patches to symbolic computation that worked on their own toy models but failed to generalize to real-world results. However, around the 1990s, AI researchers adopted sophisticated mathematical tools, such as hidden Markov models (HMM), information theory, and normative Bayesian decision theory to compare or to unify competing architectures. The shared mathematical language permitted a high level of collaboration with more established fields (like mathematics, economics or operations research). Compared with GOFAI, new "statistical learning" techniques such as HMM and neural networks were gaining higher levels of accuracy in many practical domains such as data mining, without necessarily acquiring a semantic understanding of the datasets. The increased successes with real-world data led to increasing emphasis on comparing different approaches against shared test data to see which approach performed best in a broader context than that provided by idiosyncratic toy models; AI research was becoming more scientific. Nowadays results of experiments are often rigorously measurable, and are sometimes (with difficulty) reproducible. Different statistical learning techniques have different limitations; for example, basic HMM cannot model the infinite possible combinations of natural language. Critics note that the shift from GOFAI to statistical learning is often also a shift away from explainable AI. In AGI research, some scholars caution against over-reliance on statistical learning, and argue that continuing research into GOFAI will still be necessary to attain general intelligence.



AI is relevant to any intellectual task. Modern artificial intelligence techniques are pervasive and are too numerous to list here. Frequently, when a technique reaches mainstream use, it is no longer considered artificial intelligence; this phenomenon is described as the AI effect.

High-profile examples of AI include autonomous vehicles (such as drones and self-driving cars), medical diagnosis, creating art (such as poetry), proving mathematical theorems, playing games (such as Chess or Go), search engines (such as Google search), online assistants (such as Siri), image recognition in photographs, spam filtering, predicting flight delays, prediction of judicial decisions, targeting online advertisements, and energy storage

With social media sites overtaking TV as a source for news for young people and news organizations increasingly reliant on social media platforms for generating distribution, major publishers now use artificial intelligence (AI) technology to post stories more effectively and generate higher volumes of traffic.

AI can also produce Deepfakes, a content-altering technology. ZDNet reports, "It presents something that did not actually occur," Though 88% of Americans believe Deepfakes can cause more harm than good, only 47% of them believe they can be targeted. The boom of election year also opens public discourse to threats of videos of falsified politician media.

There are three philosophical questions related to AI:







Machines with intelligence have the potential to use their intelligence to prevent harm and minimize the risks; they may have the ability to use ethical reasoning to better choose their actions in the world. As such, there is a need for policy making to devise policies for and regulate artificial intelligence and robotics. Research in this area includes machine ethics, artificial moral agents, friendly AI and discussion towards building a human rights framework is also in talks.

Joseph Weizenbaum in "Computer Power and Human Reason" wrote that AI applications cannot, by definition, successfully simulate genuine human empathy and that the use of AI technology in fields such as customer service or psychotherapy was deeply misguided. Weizenbaum was also bothered that AI researchers (and some philosophers) were willing to view the human mind as nothing more than a computer program (a position now known as computationalism). To Weizenbaum these points suggest that AI research devalues human life.

Wendell Wallach introduced the concept of artificial moral agents (AMA) in his book "Moral Machines" For Wallach, AMAs have become a part of the research landscape of artificial intelligence as guided by its two central questions which he identifies as "Does Humanity Want Computers Making Moral Decisions" and "Can (Ro)bots Really Be Moral". For Wallach, the question is not centered on the issue of "whether" machines can demonstrate the equivalent of moral behavior, unlike the "constraints" which society may place on the development of AMAs.

The field of machine ethics is concerned with giving machines ethical principles, or a procedure for discovering a way to resolve the ethical dilemmas they might encounter, enabling them to function in an ethically responsible manner through their own ethical decision making. The field was delineated in the AAAI Fall 2005 Symposium on Machine Ethics: "Past research concerning the relationship between technology and ethics has largely focused on responsible and irresponsible use of technology by human beings, with a few people being interested in how human beings ought to treat machines. In all cases, only human beings have engaged in ethical reasoning. The time has come for adding an ethical dimension to at least some machines. Recognition of the ethical ramifications of behavior involving machines, as well as recent and potential developments in machine autonomy, necessitate this. In contrast to computer hacking, software property issues, privacy issues and other topics normally ascribed to computer ethics, machine ethics is concerned with the behavior of machines towards human users and other machines. Research in machine ethics is key to alleviating concerns with autonomous systems—it could be argued that the notion of autonomous machines without such a dimension is at the root of all fear concerning machine intelligence. Further, investigation of machine ethics could enable the discovery of problems with current ethical theories, advancing our thinking about Ethics." Machine ethics is sometimes referred to as machine morality, computational ethics or computational morality. A variety of perspectives of this nascent field can be found in the collected edition "Machine Ethics" that stems from the AAAI Fall 2005 Symposium on Machine Ethics.

Political scientist Charles T. Rubin believes that AI can be neither designed nor guaranteed to be benevolent. He argues that "any sufficiently advanced benevolence may be indistinguishable from malevolence." Humans should not assume machines or robots would treat us favorably because there is no "a priori" reason to believe that they would be sympathetic to our system of morality, which has evolved along with our particular biology (which AIs would not share). Hyper-intelligent software may not necessarily decide to support the continued existence of humanity and would be extremely difficult to stop. This topic has also recently begun to be discussed in academic publications as a real source of risks to civilization, humans, and planet Earth.

One proposal to deal with this is to ensure that the first generally intelligent AI is 'Friendly AI' and will be able to control subsequently developed AIs. Some question whether this kind of check could actually remain in place.

Leading AI researcher Rodney Brooks writes, "I think it is a mistake to be worrying about us developing malevolent AI anytime in the next few hundred years. I think the worry stems from a fundamental error in not distinguishing the difference between the very real recent advances in a particular aspect of AI and the enormity and complexity of building sentient volitional intelligence."

Lethal autonomous weapons are of concern. Currently, 50+ countries are researching battlefield robots, including the United States, China, Russia, and the United Kingdom. Many people concerned about risk from superintelligent AI also want to limit the use of artificial soldiers and drones.

If an AI system replicates all key aspects of human intelligence, will that system also be sentient—will it have a mind which has conscious experiences? This question is closely related to the philosophical problem as to the nature of human consciousness, generally referred to as the hard problem of consciousness.

David Chalmers identified two problems in understanding the mind, which he named the "hard" and "easy" problems of consciousness. The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this "feels" or why it should feel like anything at all. Human information processing is easy to explain, however human subjective experience is difficult to explain.

For example, consider what happens when a person is shown a color swatch and identifies it, saying "it's red". The easy problem only requires understanding the machinery in the brain that makes it possible for a person to know that the color swatch is red. The hard problem is that people also know something else—they also know "what red looks like". (Consider that a person born blind can know that something is red without knowing what red looks like.) Everyone knows subjective experience exists, because they do it every day (e.g., all sighted people know what red looks like). The hard problem is explaining how the brain creates it, why it exists, and how it is different from knowledge and other aspects of the brain.

Computationalism is the position in the philosophy of mind that the human mind or the human brain (or both) is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind-body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.

The philosophical position that John Searle has named "strong AI" states: "The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds." Searle counters this assertion with his Chinese room argument, which asks us to look "inside" the computer and try to find where the "mind" might be.

If a machine can be created that has intelligence, could it also "feel"? If it can feel, does it have the same rights as a human? This issue, now known as "robot rights", is currently being considered by, for example, California's Institute for the Future, although many critics believe that the discussion is premature. Some critics of transhumanism argue that any hypothetical robot rights would lie on a spectrum with animal rights and human rights. The subject is profoundly discussed in the 2010 documentary film "Plug & Pray", and many sci fi media such as Star Trek Next Generation, with the character of Commander Data, who fought being disassembled for research, and wanted to "become human", and the robotic holograms in Voyager.

Are there limits to how intelligent machines—or human-machine hybrids—can be? A superintelligence, hyperintelligence, or superhuman intelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. "Superintelligence" may also refer to the form or degree of intelligence possessed by such an agent.

If research into Strong AI produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to recursive self-improvement. The new intelligence could thus increase exponentially and dramatically surpass humans. Science fiction writer Vernor Vinge named this scenario "singularity". Technological singularity is when accelerating progress in technologies will cause a runaway effect wherein artificial intelligence will exceed human intellectual capacity and control, thus radically changing or even ending civilization. Because the capabilities of such an intelligence may be impossible to comprehend, the technological singularity is an occurrence beyond which events are unpredictable or even unfathomable.

Ray Kurzweil has used Moore's law (which describes the relentless exponential improvement in digital technology) to calculate that desktop computers will have the same processing power as human brains by the year 2029, and predicts that the singularity will occur in 2045.

Robot designer Hans Moravec, cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in Aldous Huxley and Robert Ettinger.

Edward Fredkin argues that "artificial intelligence is the next stage in evolution", an idea first proposed by Samuel Butler's "Darwin among the Machines" as far back as 1863, and expanded upon by George Dyson in his book of the same name in 1998.

The long-term economic effects of AI are uncertain. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit, if productivity gains are redistributed. A February 2020 European Union white paper on artificial intelligence advocated for artificial intelligence for economic benefits, including "improving healthcare (e.g. making diagnosis more precise, enabling better prevention of diseases), increasing the efficiency of farming, contributing to climate change mitigation and adaptation, [and] improving the efficiency of production systems through predictive maintenance", while acknowledging potential risks.

The relationship between automation and employment is complicated. While automation eliminates old jobs, it also creates new jobs through micro-economic and macro-economic effects. Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; "The Economist" states that "the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution" is "worth taking seriously". Subjective estimates of the risk vary widely; for example, Michael Osborne and Carl Benedikt Frey estimate 47% of U.S. jobs are at "high risk" of potential automation, while an OECD report classifies only 9% of U.S. jobs as "high risk". Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy. Author Martin Ford and others go further and argue that many jobs are routine, repetitive and (to an AI) predictable; Ford warns that these jobs may be automated in the next couple of decades, and that many of the new jobs may not be "accessible to people with average capability", even with retraining. Economists point out that in the past technology has tended to increase rather than reduce total employment, but acknowledge that "we're in uncharted territory" with AI.

The potential negative effects of AI and automation were a major issue for Andrew Yang's 2020 presidential campaign in the United States. Irakli Beridze, Head of the Centre for Artificial Intelligence and Robotics at UNICRI, United Nations, has expressed that "I think the dangerous applications for AI, from my point of view, would be criminals or large terrorist organizations using it to disrupt large processes or simply do pure harm. [Terrorists could cause harm] via digital warfare, or it could be a combination of robotics, drones, with AI and other things as well that could be really dangerous. And, of course, other risks come from things like job losses. If we have massive numbers of people losing jobs and don't find a solution, it will be extremely dangerous. Things like lethal autonomous weapons systems should be properly governed — otherwise there's massive potential of misuse."

Widespread use of artificial intelligence could have unintended consequences that are dangerous or undesirable. Scientists from the Future of Life Institute, among others, described some short-term research goals to see how AI influences the economy, the laws and ethics that are involved with AI and how to minimize AI security risks. In the long-term, the scientists have proposed to continue optimizing function while minimizing possible security risks that come along with new technologies.

Some are concerned about algorithmic bias, that AI programs may unintentionally become biased after processing data that exhibits bias. Algorithms already have numerous applications in legal systems. An example of this is COMPAS, a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist. ProPublica claims that the average COMPAS-assigned recidivism risk level of black defendants is significantly higher than the average COMPAS-assigned risk level of white defendants.

Physicist Stephen Hawking, Microsoft founder Bill Gates, and SpaceX founder Elon Musk have expressed concerns about the possibility that AI could evolve to the point that humans could not control it, with Hawking theorizing that this could "spell the end of the human race".

In his book "", philosopher Nick Bostrom provides an argument that artificial intelligence will pose a threat to humankind. He argues that sufficiently intelligent AI, if it chooses actions based on achieving some goal, will exhibit convergent behavior such as acquiring resources or protecting itself from being shut down. If this AI's goals do not fully reflect humanity's—one example is an AI told to compute as many digits of pi as possible—it might harm humanity in order to acquire more resources or prevent itself from being shut down, ultimately to better achieve its goal. Bostrom also emphasizes the difficulty of fully conveying humanity's values to an advanced AI. He uses the hypothetical example of giving an AI the goal to make humans smile to illustrate a misguided attempt. If the AI in that scenario were to become superintelligent, Bostrom argues, it may resort to methods that most humans would find horrifying, such as inserting "electrodes into the facial muscles of humans to cause constant, beaming grins" because that would be an efficient way to achieve its goal of making humans smile. In his book "Human Compatible", AI researcher Stuart J. Russell echoes some of Bostrom's concerns while also proposing an approach to developing provably beneficial machines focused on uncertainty and deference to humans, possibly involving inverse reinforcement learning.

Concern over risk from artificial intelligence has led to some high-profile donations and investments. A group of prominent tech titans including Peter Thiel, Amazon Web Services and Musk have committed $1 billion to OpenAI, a nonprofit company aimed at championing responsible AI development. The opinion of experts within the field of artificial intelligence is mixed, with sizable fractions both concerned and unconcerned by risk from eventual superhumanly-capable AI. Other technology industry leaders believe that artificial intelligence is helpful in its current form and will continue to assist humans. Oracle CEO Mark Hurd has stated that AI "will actually create more jobs, not less jobs" as humans will be needed to manage AI systems. Facebook CEO Mark Zuckerberg believes AI will "unlock a huge amount of positive things," such as curing disease and increasing the safety of autonomous cars. In January 2015, Musk donated $10 million to the Future of Life Institute to fund research on understanding AI decision making. The goal of the institute is to "grow wisdom with which we manage" the growing power of technology. Musk also funds companies developing artificial intelligence such as DeepMind and Vicarious to "just keep an eye on what's going on with artificial intelligence. I think there is potentially a dangerous outcome there."

For the danger of uncontrolled advanced AI to be realized, the hypothetical AI would have to overpower or out-think all of humanity, which a minority of experts argue is a possibility far enough in the future to not be worth researching. Other counterarguments revolve around humans being either intrinsically or convergently valuable from the perspective of an artificial intelligence.

The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI); it is therefore related to the broader regulation of algorithms. The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally, including in the European Union. Regulation is considered necessary to both encourage AI and manage associated risks. Regulation of AI through mechanisms such as review boards can also be seen as social means to approach the AI control problem.

Thought-capable artificial beings appeared as storytelling devices since antiquity,
and have been a persistent theme in science fiction.

A common trope in these works began with Mary Shelley's "Frankenstein", where a human creation becomes a threat to its masters. This includes such works as and "" (both 1968), with HAL 9000, the murderous computer in charge of the "Discovery One" spaceship, as well as "The Terminator" (1984) and "The Matrix" (1999). In contrast, the rare loyal robots such as Gort from "The Day the Earth Stood Still" (1951) and Bishop from "Aliens" (1986) are less prominent in popular culture.

Isaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the "Multivac" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during lay discussions of machine ethics; while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.

Transhumanism (the merging of humans and machines) is explored in the manga "Ghost in the Shell" and the science-fiction series "Dune". In the 1980s, artist Hajime Sorayama's Sexy Robots series were painted and published in Japan depicting the actual organic human form with lifelike muscular metallic skins and later "the Gynoids" book followed that was used by or influenced movie makers including George Lucas and other creatives. Sorayama never considered these organic robots to be real part of nature but always an unnatural product of the human mind, a fantasy existing in the mind even when realized in actual form.

Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's "R.U.R.", the films "A.I. Artificial Intelligence" and "Ex Machina", as well as the novel "Do Androids Dream of Electric Sheep?", by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.



</doc>
<doc id="1166" url="https://en.wikipedia.org/wiki?curid=1166" title="Afro Celt Sound System">
Afro Celt Sound System

Their albums have been released through Peter Gabriel's Real World Records, and they have frequently performed at WOMAD festivals worldwide. Their sales on the label are exceeded only by Gabriel himself. Their recording contract with Real World was for five albums, of which "Volume 5: Anatomic" was the last.

After a number of festival dates in 2007, the band went on hiatus. In 2010, they regrouped to play a number of shows (including a return to WOMAD), releasing a re-mastered retrospective titled "Capture."

On 20 May 2014, Afro Celt Sound System announced the upcoming release of a new album, "Born". In January 2016, a posting to that website revealed that due to a dispute with Emmerson, who announced his departure from the band in 2015, there were two active versions of the band, a version led by Emmerson and a separate line-up headed by James McNally and Martin Russell. Emmerson's version of the band released the album "The Source" in 2016. The dispute ended on 21 December 2016, with an announcement on social media.

The band released their eighth studio album, "Flight", on November 23, 2018

The inspiration behind the project dates back to 1991, when Simon Emmerson, a Grammy Award-nominated British producer and guitarist, collaborated with Afro-pop star Baaba Maal. While making an album with Maal in Senegal, Emmerson was struck by the similarity between one African melody and a traditional Irish air. Back in London, Irish musician Davy Spillane told Emmerson about a belief that nomadic Celts lived in Africa or India before they migrated to Western Europe. Whether or not the theory was true, Emmerson was intrigued by the two countries' musical affinities.

In an experiment that would prove successful, Emmerson brought two members of Baaba Maal's band together with traditional Irish musicians to see what kind of music the two groups would create. Adding a dash of modern sound, Emmerson also brought in English dance mixers for an electronic beat. "People thought I was mad when I touted the idea," Emmerson told Jim Carroll of "The Irish Times". "At the time, I was out of favour with the London club scene. I was broke and on income support but the success was extraordinary".

Jamming in the studios at Real World, musician Peter Gabriel's recording facilities in Wiltshire, England, the diverse group of musicians recorded the basis of their first album in one week. This album, "", was released by Real World Records in 1996, and marked the debut of the Afro Celt Sound System.

"Prior to that first album being made, none of us knew if it would work," musician James McNally told Larry Katz of the Boston Herald. "We were strangers who didn't even speak the same language. But we were bowled over by this communication that took place beyond language." McNally, who grew up second-generation Irish in London, played whistles, keyboards, piano, bodhran, and bamboo flute.

"Sound Magic" has now sold over 300,000 copies. The band performed at festivals, raves, and dance clubs and regularly included two African musicians, Moussa Sissokho on talking drum and djembe and N'Faly Kouyate on vocals, kora and balafon.

Just as the second album was getting off the ground, one of the group's core musicians, 27-year-old keyboardist Jo Bruce, (son of Cream bass player Jack Bruce), died suddenly of an asthma attack. The band was devastated, and the album was put on hold. Then Irish pop star Sinéad O'Connor came to the rescue, collaborating with the band and helping them cope with their loss. "[O'Connor] blew into the studio on a windy November night and blew away again leaving us something incredibly emotional and powerful," McNally told Katz. "We had this track we didn't know what to do with. Sinéad scribbled a few lyrics and bang! She left us completely choked up." So taken was the band with O'Connor's song, "Release," that they used the name for the title of their album. "" hit the music stores in 1999, and by the spring of 2000 it had sold more than half a million copies worldwide.

In 2000, the group was nominated for a Grammy Award in the Best World Music category. The band, composed at the time of eight members from six countries (England, Senegal, Guinea, Ireland, France and Kenya), took pride in its ability to bring people together through music. "We can communicate anywhere at any corner of the planet and feel that we're at home," McNally told Patrick MacDonald of The Seattle Times". "We're breaking down categories of world music and rock music and black music. We leave a door open to communicate with each other's traditions. And it's changed our lives".

In 2001, the group released "", which climbed to number one on Billboard's Top World Music Albums chart. Featuring guest spots by Peter Gabriel and Robert Plant, the album also incorporated a heightened African sound. "On the first two records, the pendulum swung more toward the Celtic, London club side of the equation," Emmerson told the Irish Times's Carroll. "For this one, we wanted to have more African vocals and input than we'd done before." Again the Afro Celt Sound System met with success. Chuck Taylor of Billboard magazine praised the album as "a cultural phenomenon that bursts past the traditional boundaries of contemporary music." The single "When You're Falling", with vocals by Gabriel, became a radio hit in the United States.

In 2003, for the "Seed" album, they changed their name to Afrocelts. They reverted to the longer band name for their subsequent albums, "Pod", a compilation of new mixes of songs from the first four albums, "" (their fifth studio album), and "Capture - Afro Celt Sound System 1995-2010".

They played a number of shows to promote "Volume 5: Anatomic" in 2006 and summer 2007, ending with a gig in Korea, before taking an extended break to work on side projects, amongst them "The Imagined Village" featuring Simon Emmerson and Johnny Kalsi. Starting in the summer of 2010, the band performed a series of live shows to promote a new 2-CD album, "Capture - Afro Celt Sound System 1995-2010", released on 6 September 2010 on Real World Records. Further performances continue to the present day, and a new album-in-progress titled "Born" was announced on their website in 2014. Following the split (see below), Emmerson's version of the band released the album The Source in 2016.

During 2015, the band had split into two formations, one of them including Simon Emmerson, N'Faly Kouyate and Johnny Kalsi, the other one James McNally and Martin Russell. The split was announced on the band's website in January 2016. The dispute officially ended with an announcement on social media on 21 December 2016. "Simon Emmerson, James McNally and Martin Russell are pleased to announce that they have been able to set aside their differences and come to an amicable agreement to bring their dispute to an end. Going forward, McNally, Russell and Emmerson have agreed that Emmerson will continue to perform as Afro Celt Sound System and McNally and Russell will work under a new name to be announced in due course.
While McNally, Russell and Emmerson will no longer be performing or working together they recognise, and are grateful for each other's contribution to Afro Celt Sound System over the past two decades and will be working with the extensive community of musicians that make up the long standing Afro Celt Sound System family."

When Afro Celt Sound System formed in the mid-1990s during the Real World Recording Week, the difference between a guest artist and a band member was virtually non-existent. However, over time, a combination of people became most often associated with the name Afro Celt Sound System (while "Volume 5: Anatomic" only lists Emmerson, McNally, Ó Lionáird and Russell as regulars). The divided grouping of the band into two versions, both operating under the name Afro Celt Sound System, began in January 2016 and was resolved in December 2016 after McNally and Russell agreed to work under a different name from Emmerson.

Russell/McNally version

Other musicians who have performed or recorded with Afro Celt Sound System include: Jimmy Mahon, Demba Barry, Babara Bangoura, Iarla Ó Lionáird, Peter Gabriel, Robert Plant, Pete Lockett, Sinéad O'Connor, Pina Kollar, Dorothee Munyaneza, Sevara Nazarkhan, Simon Massey, Jesse Cook, Martin Hayes, Eileen Ivers, Mundy, Mairéad Ní Mhaonaigh and Ciarán Tourish of Altan, Ronan Browne, Michael McGoldrick, Myrdhin, Shooglenifty, Mairead Nesbitt, Nigel Eaton, Davy Spillane, Jonas Bruce, Heather Nova, Julie Murphy and Ayub Ogada, Caroline Lavelle, Ross Ainslie.


They also recorded the soundtrack for the PC game "Magic and Mayhem", released in 1998.



</doc>
<doc id="1167" url="https://en.wikipedia.org/wiki?curid=1167" title="Ancient philosophy">
Ancient philosophy

This page lists some links to ancient philosophy, namely philosophical thought extending as far as early post-classical history (c. 600 CE). 

Genuine philosophical thought, depending upon original individual insights, arose in many cultures roughly contemporaneously. Karl Jaspers termed the intense period of philosophical development beginning around the 7th century and concluding around the 3rd century BCE an Axial Age in human thought.

In Western philosophy, the spread of Christianity in the Roman Empire marked the ending of Hellenistic philosophy and ushered in the beginnings of medieval philosophy, whereas in Eastern philosophy, the spread of Islam through the Arab Empire marked the end of Old Iranian philosophy and ushered in the beginnings of early Islamic philosophy.

Chinese philosophy is the dominant philosophical thought in China and other countries within the East Asian cultural sphere that share a common language, including Japan, Korea, and Vietnam.

The Hundred Schools of Thought were philosophers and schools that flourished from the 6th century to 221 BCE, an era of great cultural and intellectual expansion in China. Even though this period – known in its earlier part as the Spring and Autumn period and the Warring States period – in its latter part was fraught with chaos and bloody battles, it is also known as the Golden Age of Chinese philosophy because a broad range of thoughts and ideas were developed and discussed freely. The thoughts and ideas discussed and refined during this period have profoundly influenced lifestyles and social consciousness up to the present day in East Asian countries. The intellectual society of this era was characterized by itinerant scholars, who were often employed by various state rulers as advisers on the methods of government, war, and diplomacy. This period ended with the rise of the Qin Dynasty and the subsequent purge of dissent. The Book of Han lists ten major schools, they are:

The founder of the Qin Dynasty, who implemented Legalism as the official philosophy, quashed Mohist and Confucianist schools. Legalism remained influential until the emperors of the Han Dynasty adopted Daoism and later Confucianism as official doctrine. These latter two became the determining forces of Chinese thought until the introduction of Buddhism.

Confucianism was particularly strong during the Han Dynasty, whose greatest thinker was Dong Zhongshu, who integrated Confucianism with the thoughts of the Zhongshu School and the theory of the Five Elements. He also was a promoter of the New Text school, which considered Confucius as a divine figure and a spiritual ruler of China, who foresaw and started the evolution of the world towards the Universal Peace. In contrast, there was an Old Text school that advocated the use of Confucian works written in ancient language (from this comes the denomination "Old Text") that were so much more reliable. In particular, they refuted the assumption of Confucius as a godlike figure and considered him as the greatest sage, but simply a human and mortal.

The 3rd and 4th centuries saw the rise of the "Xuanxue" (mysterious learning), also called "Neo-Taoism". The most important philosophers of this movement were Wang Bi, Xiang Xiu and Guo Xiang. The main question of this school was whether Being came before Not-Being (in Chinese, "ming" and "wuming"). A peculiar feature of these Taoist thinkers, like the Seven Sages of the Bamboo Grove, was the concept of "feng liu" (lit. wind and flow), a sort of romantic spirit which encouraged following the natural and instinctive impulse.

Buddhism arrived in China around the 1st century AD, but it was not until the Northern and Southern, Sui and Tang Dynasties that it gained considerable influence and acknowledgement. At the beginning, it was considered a sort of Taoist sect, and there was even a theory about Laozi, founder of Taoism, who went to India and taught his philosophy to Buddha. Mahayana Buddhism was far more successful in China than its rival Hinayana, and both Indian schools and local Chinese sects arose from the 5th century. Two chiefly important monk philosophers were Sengzhao and Daosheng. But probably the most influential and original of these schools was the Chan sect, which had an even stronger impact in Japan as the Zen sect.






See also: "Christian philosophy"


The ancient Indian philosophy is a fusion of two ancient traditions: the Vedic tradition and the Sramana tradition.

Indian philosophy begins with the "Vedas" wherein questions pertaining to laws of nature, the origin of the universe and the place of man in it are asked. In the famous Rigvedic "Hymn of Creation" (Nasadiya Sukta) the poet asks:

In the Vedic view, creation is ascribed to the self-consciousness of the primeval being ("Purusha"). This leads to the inquiry into "the one being" that underlies the diversity of empirical phenomena and the origin of all things. Cosmic order is termed "rta" and causal law by "karma". Nature ("prakriti") is taken to have three qualities ("sattva", "rajas", and "tamas").

Jainism and Buddhism are continuation of the Sramana school of thought. The Sramanas cultivated a pessimistic worldview of the samsara as full of suffering and advocated renunciation and austerities. They laid stress on philosophical concepts like Ahimsa, Karma, Jnana, Samsara and Moksa. Cārvāka (Sanskrit: चार्वाक) (atheist) philosophy, also known as Lokāyata, it is a system of Hindu philosophy that assumes various forms of philosophical skepticism and religious indifference. It is named after its founder, Cārvāka, author of the Bārhaspatya-sūtras.

In classical times, these inquiries were systematized in six schools of philosophy. Some of the questions asked were:

The six schools of Indian philosophy are:






See also: "Dualism, Dualism (philosophy of mind)"

While there are ancient relations between the Indian Vedas and the Iranian Avesta, the two main families of the Indo-Iranian philosophical traditions were characterized by fundamental differences in their implications for the human being's position in society and their view of man's role in the universe. The first charter of human rights by Cyrus the Great as understood in the Cyrus cylinder is often seen as a reflection of the questions and thoughts expressed by Zarathustra and developed in Zoroastrian schools of thought of the Achaemenid Era of Iranian history.

Ideas and tenets of Zoroastrian schools of Early Persian philosophy are part of many works written in Middle Persian and of the extant scriptures of the zoroastrian religion in Avestan language. Among these are treatises such as the Shikand-gumanic Vichar by Mardan-Farrux Ohrmazddadan, selections of Denkard, Wizidagīhā-ī Zātspram ("Selections of Zātspram") as well as older passages of the book Avesta, the Gathas which are attributed to Zarathustra himself and regarded as his "direct teachings".

Anacharsis







See also: "Jewish philosophy"








</doc>
<doc id="1168" url="https://en.wikipedia.org/wiki?curid=1168" title="Anaximander">
Anaximander

Anaximander (; "Anaximandros"; ), was a pre-Socratic Greek philosopher who lived in Miletus, a city of Ionia (in modern-day Turkey). He belonged to the Milesian school and learned the teachings of his master Thales. He succeeded Thales and became the second master of that school where he counted Anaximenes and, arguably, Pythagoras amongst his pupils.

Little of his life and work is known today. According to available historical documents, he is the first philosopher known to have written down his studies, although only one fragment of his work remains. Fragmentary testimonies found in documents after his death provide a portrait of the man.

Anaximander was an early proponent of science and tried to observe and explain different aspects of the universe, with a particular interest in its origins, claiming that nature is ruled by laws, just like human societies, and anything that disturbs the balance of nature does not last long. Like many thinkers of his time, Anaximander's philosophy included contributions to many disciplines. In astronomy, he attempted to describe the mechanics of celestial bodies in relation to the Earth. In physics, his postulation that the indefinite (or apeiron) was the source of all things led Greek philosophy to a new level of conceptual abstraction. His knowledge of geometry allowed him to introduce the gnomon in Greece. He created a map of the world that contributed greatly to the advancement of geography. He was also involved in the politics of Miletus and was sent as a leader to one of its colonies.

Anaximander, son of Praxiades, was born in the third year of the 42nd Olympiad (610 BC). According to Apollodorus of Athens, Greek grammarian of the 2nd century BC, he was sixty-four years old during the second year of the 58th Olympiad (547–546 BC), and died shortly afterwards.

Establishing a timeline of his work is now impossible, since no document provides chronological references. Themistius, a 4th-century Byzantine rhetorician, mentions that he was the "first of the known Greeks to publish a written document on nature." Therefore, his texts would be amongst the earliest written in prose, at least in the Western world. By the time of Plato, his philosophy was almost forgotten, and Aristotle, his successor Theophrastus and a few doxographers provide us with the little information that remains. However, we know from Aristotle that Thales, also from Miletus, precedes Anaximander. It is debatable whether Thales actually was the teacher of Anaximander, but there is no doubt that Anaximander was influenced by Thales' theory that everything is derived from water. One thing that is not debatable is that even the ancient Greeks considered Anaximander to be from the Monist school which began in Miletus, with Thales followed by Anaximander and which ended with Anaximenes. 3rd-century Roman rhetorician Aelian depicts Anaximander as leader of the Milesian colony to Apollonia on the Black Sea coast, and hence some have inferred that he was a prominent citizen. Indeed, "Various History" (III, 17) explains that philosophers sometimes also dealt with political matters. It is very likely that leaders of Miletus sent him there as a legislator to create a constitution or simply to maintain the colony's allegiance.

Anaximander lived the final few years of his life as a subject of the Persian Achaemenid Empire.

Anaximander's theories were influenced by the Greek mythical tradition, and by some ideas of Thales – the father of philosophy – as well as by observations made by older civilizations in the Near East, especially Babylon. All these were developed rationally. In his desire to find some universal principle, he assumed, like traditional religion, the existence of a cosmic order; and his ideas on this used the old language of myths which ascribed divine control to various spheres of reality. This was a common practice for the Greek philosophers in a society which saw gods everywhere, and therefore could fit their ideas into a tolerably elastic system.

Some scholars see a gap between the existing mythical and the new rational way of thought which is the main characteristic of the archaic period (8th to 6th century BC) in the Greek city-states. This has given rise to the phrase "Greek miracle". But if we follow carefully the course of Anaximander's ideas, we will notice that there was not such an abrupt break as initially appears. The basic elements of nature (water, air, fire, earth) which the first Greek philosophers believed made up the universe in fact represent the primordial forces imagined in earlier ways of thinking. Their collision produced what the mythical tradition had called cosmic harmony. In the old cosmogonies – Hesiod (8th – 7th century BC) and Pherecydes (6th century BC) – Zeus establishes his order in the world by destroying the powers which were threatening this harmony (the Titans). Anaximander claimed that the cosmic order is not monarchic but geometric, and that this causes the equilibrium of the earth, which is lying in the centre of the universe. This is the projection on nature of a new political order and a new space organized around a centre which is the static point of the system in the society as in nature. In this space there is "isonomy" (equal rights) and all the forces are symmetrical and transferable. The decisions are now taken by the assembly of "demos" in the "agora" which is lying in the middle of the city.

The same "rational" way of thought led him to introduce the abstract "apeiron" (indefinite, infinite, boundless, unlimited) as an origin of the universe, a concept that is probably influenced by the original Chaos (gaping void, abyss, formless state) from which everything else appeared in the mythical Greek cosmogony. It also takes notice of the mutual changes between the four elements. Origin, then, must be something else unlimited in its source, that could create without experiencing decay, so that genesis would never stop.

The "Refutation" attributed to Hippolytus of Rome (I, 5), and the later 6th century Byzantine philosopher Simplicius of Cilicia, attribute to Anaximander the earliest use of the word "apeiron" ( "infinite" or "limitless") to designate the original principle. He was the first philosopher to employ, in a philosophical context, the term "archē" (), which until then had meant beginning or origin.

"That Anaximander called this something by the name of is the natural interpretation of what Theophrastos says; the current statement that the term was introduced by him appears to be due to a misunderstanding."

And "Hippolytos, however, is not an independent authority, and the only question is what Theophrastos wrote."

For him, it became no longer a mere point in time, but a source that could perpetually give birth to whatever will be. The indefiniteness is spatial in early usages as in Homer (indefinite sea) and as in Xenophanes (6th century BC) who said that the earth went down indefinitely (to "apeiron") i.e. beyond the imagination or concept of men.

Burnet (1930) in "Early Greek Philosophy" says:

"Nearly all we know of Anaximander’s system is derived in the last resort from Theophrastos, who certainly knew his book. He seems once at least to have quoted Anaximander's own words, and he criticised his style. Here are the remains of what he said of him in the First Book:

"Anaximander of Miletos, son of Praxiades, a fellow-citizen and associate of Thales, said that the material cause and first element of things was the Infinite, he being the first to introduce this name of the material cause. He says it is neither water nor any other of the so-called elements, but a substance different from them which is infinite" [apeiron, or ] "from which arise all the heavens and the worlds within them.—Phys, Op. fr. 2 (Dox. p. 476 ; R. P. 16)."

Burnet's quote from the "First Book" is his translation of Theophrastos' "Physic Opinion" fragment 2 as it appears in p. 476 of "Historia Philosophiae Graecae" (1898) by Ritter and Preller and section 16 of "Doxographi Graeci" (1879) by Diels.

By ascribing the "Infinite" with a "material cause", Theophrastos is following the Aristotelian tradition of "nearly always discussing the facts from the point of view of his own system".

Aristotle writes ("Metaphysics", I.III 3–4) that the Pre-Socratics were searching for the element that constitutes all things. While each pre-Socratic philosopher gave a different answer as to the identity of this element (water for Thales and air for Anaximenes), Anaximander understood the beginning or first principle to be an endless, unlimited primordial mass ("apeiron"), subject to neither old age nor decay, that perpetually yielded fresh materials from which everything we perceive is derived. He proposed the theory of the "apeiron" in direct response to the earlier theory of his teacher, Thales, who had claimed that the primary substance was water. The notion of temporal infinity was familiar to the Greek mind from remote antiquity in the religious concept of immortality, and Anaximander's description was in terms appropriate to this conception. This "archē" is called "eternal and ageless". (Hippolytus (?), "Refutation", I,6,I;DK B2)""Aristotle puts things in his own way regardless of historical considerations, and it is difficult to see that it is more of an anachronism to call the Boundless “ intermediate between the elements ” than to say that it is " distinct from the elements.” Indeed, if once we introduce the elements at all, the former description is the more adequate of the two. At any rate, if we refuse to understand these passages as referring to Anaximander, we shall have to say that Aristotle paid a great deal of attention to some one whose very name has been lost, and who not only agreed with some of Anaximander’s views, but also used some of his most characteristic expressions. We may add that in one or two places Aristotle certainly seems to identify the “ intermediate ” with the something “ distinct from ” the elements".""It is certain that he [Anaximander] cannot have said anything about elements, which no one thought of before Empedokles, and no one could think of before Parmenides. The question has only been mentioned because it has given rise to a lengthy controversy, and because it throws light on the historical value of Aristotle’s statements. From the point of view of his own system, these may be justified; but we shall have to remember in other cases that, when he seems to attribute an idea to some earlier thinker, we are not bound to take what he says in an historical sense."For Anaximander, the principle of things, the constituent of all substances, is nothing determined and not an element such as water in Thales' view. Neither is it something halfway between air and water, or between air and fire, thicker than air and fire, or more subtle than water and earth. Anaximander argues that water cannot embrace all of the opposites found in nature — for example, water can only be wet, never dry — and therefore cannot be the one primary substance; nor could any of the other candidates. He postulated the "apeiron" as a substance that, although not directly perceptible to us, could explain the opposites he saw around him."If Thales had been right in saying that water was the fundamental reality, it would not be easy to see how anything else could ever have existed. One side of the opposition, the cold and moist, would have had its way unchecked, and the warm and dry would have been driven from the field long ago. We must, then, have something not itself one of the warring opposites, something more primitive, out of which they arise, and into which they once more pass away."Anaximander explains how the four elements of ancient physics (air, earth, water and fire) are formed, and how Earth and terrestrial beings are formed through their interactions. Unlike other Pre-Socratics, he never defines this principle precisely, and it has generally been understood (e.g., by Aristotle and by Saint Augustine) as a sort of primal chaos. According to him, the Universe originates in the separation of opposites in the primordial matter. It embraces the opposites of hot and cold, wet and dry, and directs the movement of things; an entire host of shapes and differences then grow that are found in "all the worlds" (for he believed there were many)."Anaximander taught, then, that there was an eternal. The indestructible something out of which everything arises, and into which everything returns; a boundless stock from which the waste of existence is continually made good, “elements.”. That is only the natural development of the thought we have ascribed to Thales, and there can be no doubt that Anaximander at least formulated it distinctly. Indeed, we can still follow to some extent the reasoning which led him to do so. Thales had regarded water as the most likely thing to be that of which all others are forms; Anaximander appears to have asked how the primary substance could be one of these particular things. His argument seems to be preserved by Aristotle, who has the following passage in his discussion of the Infinite: ""Further, there cannot be a single, simple body which is infinite, either, as some hold, one distinct from the elements, which they then derive from it, or without this qualification. For there are some who make this. (i.e. a body distinct from the elements). the infinite, and not air or water, in order that the other things may not be destroyed by their infinity. They are in opposition one to another. air is cold, water moist, and fire hot. and therefore, if any one of them were infinite, the rest would have ceased to be by this time. Accordingly they say that what is infinite is something other than the elements, and from it the elements arise.'⁠—Aristotle Physics. F, 5 204 b 22 (Ritter and Preller (1898) Historia Philosophiae Graecae, section 16 b).""Anaximander maintains that all dying things are returning to the element from which they came ("apeiron"). The one surviving fragment of Anaximander's writing deals with this matter. Simplicius transmitted it as a quotation, which describes the balanced and mutual changes of the elements:
Whence things have their origin,
Thence also their destruction happens,
According to necessity;
For they give to each other justice and recompense
For their injustice
In conformity with the ordinance of Time.
Simplicius mentions that Anaximander said all these "in poetic terms", meaning that he used the old mythical language. The goddess Justice (Dike) keeps the cosmic order. This concept of returning to the element of origin was often revisited afterwards, notably by Aristotle, and by the Greek tragedian Euripides: "what comes from earth must return to earth." Friedrich Nietzsche, in his "Philosophy in the Tragic Age of the Greeks", stated that Anaximander viewed "... all coming-to-be as though it were an illegitimate emancipation from eternal being, a wrong for which destruction is the only penance." Physicist Max Born, in commenting upon Werner Heisenberg's arriving at the idea that the elementary particles of quantum mechanics are to be seen as different manifestations, different quantum states, of one and the same “primordial substance,”' proposed that this primordial substance be called "apeiron".

Anaximander's bold use of non-mythological explanatory hypotheses considerably distinguishes him from previous cosmology writers such as Hesiod. It confirms that pre-Socratic philosophers were making an early effort to demystify physical processes. His major contribution to history was writing the oldest prose document about the Universe and the origins of life; for this he is often called the "Father of Cosmology" and founder of astronomy. However, pseudo-Plutarch states that he still viewed celestial bodies as deities.

Anaximander was the first to conceive a mechanical model of the world. In his model, the Earth floats very still in the centre of the infinite, not supported by anything. It remains "in the same place because of its indifference", a point of view that Aristotle considered ingenious, but false, in "On the Heavens". Its curious shape is that of a cylinder with a height one-third of its diameter. The flat top forms the inhabited world, which is surrounded by a circular oceanic mass.

Anaximander's realization that the Earth floats free without falling and does not need to be resting on something has been indicated by many as the first cosmological revolution and the starting point of scientific thinking. Karl Popper calls this idea "one of the boldest, most revolutionary, and most portentous ideas in the whole history of human thinking." Such a model allowed the concept that celestial bodies could pass under the Earth, opening the way to Greek astronomy.

At the origin, after the separation of hot and cold, a ball of flame appeared that surrounded Earth like bark on a tree. This ball broke apart to form the rest of the Universe. It resembled a system of hollow concentric wheels, filled with fire, with the rims pierced by holes like those of a flute. Consequently, the Sun was the fire that one could see through a hole the same size as the Earth on the farthest wheel, and an eclipse corresponded with the occlusion of that hole. The diameter of the solar wheel was twenty-seven times that of the Earth (or twenty-eight, depending on the sources) and the lunar wheel, whose fire was less intense, eighteen (or nineteen) times. Its hole could change shape, thus explaining lunar phases. The stars and the planets, located closer, followed the same model.

Anaximander was the first astronomer to consider the Sun as a huge mass, and consequently, to realize how far from Earth it might be, and the first to present a system where the celestial bodies turned at different distances. Furthermore, according to Diogenes Laertius (II, 2), he built a celestial sphere. This invention undoubtedly made him the first to realize the obliquity of the Zodiac as the Roman philosopher Pliny the Elder reports in "Natural History" (II, 8). It is a little early to use the term ecliptic, but his knowledge and work on astronomy confirm that he must have observed the inclination of the celestial sphere in relation to the plane of the Earth to explain the seasons. The doxographer and theologian Aetius attributes to Pythagoras the exact measurement of the obliquity.

According to Simplicius, Anaximander already speculated on the plurality of worlds, similar to atomists Leucippus and Democritus, and later philosopher Epicurus. These thinkers supposed that worlds appeared and disappeared for a while, and that some were born when others perished. They claimed that this movement was eternal, "for without movement, there can be no generation, no destruction".

In addition to Simplicius, Hippolytus reports Anaximander's claim that from the infinite comes the principle of beings, which themselves come from the heavens and the worlds (several doxographers use the plural when this philosopher is referring to the worlds within, which are often infinite in quantity). Cicero writes that he attributes different gods to the countless worlds.

This theory places Anaximander close to the Atomists and the Epicureans who, more than a century later, also claimed that an infinity of worlds appeared and disappeared. In the timeline of the Greek history of thought, some thinkers conceptualized a single world (Plato, Aristotle, Anaxagoras and Archelaus), while others instead speculated on the existence of a series of worlds, continuous or non-continuous (Anaximenes, Heraclitus, Empedocles and Diogenes).

Anaximander attributed some phenomena, such as thunder and lightning, to the intervention of elements, rather than to divine causes. In his system, thunder results from the shock of clouds hitting each other; the loudness of the sound is proportionate with that of the shock. Thunder without lightning is the result of the wind being too weak to emit any flame, but strong enough to produce a sound. A flash of lightning without thunder is a jolt of the air that disperses and falls, allowing a less active fire to break free. Thunderbolts are the result of a thicker and more violent air flow.

He saw the sea as a remnant of the mass of humidity that once surrounded Earth. A part of that mass evaporated under the sun's action, thus causing the winds and even the rotation of the celestial bodies, which he believed were attracted to places where water is more abundant. He explained rain as a product of the humidity pumped up from Earth by the sun. For him, the Earth was slowly drying up and water only remained in the deepest regions, which someday would go dry as well. According to Aristotle's "Meteorology" (II, 3), Democritus also shared this opinion.

Anaximander speculated about the beginnings and origin of animal life, and that humans came from other animals in waters. He claimed that animals sprang out of the sea long ago, born trapped in a spiny bark, but as they got older, the bark would dry up and animals would be able to break it. As the early humidity evaporated, dry land emerged and, in time, humankind had to adapt. The 3rd century Roman writer Censorinus reports:

Anaximander put forward the idea that humans had to spend part of this transition inside the mouths of big fish to protect themselves from the Earth's climate until they could come out in open air and lose their scales. He thought that, considering humans' extended infancy, we could not have survived in the primeval world in the same manner we do presently.

Both Strabo and Agathemerus (later Greek geographers) claim that, according to the geographer Eratosthenes, Anaximander was the first to publish a map of the world. The map probably inspired the Greek historian Hecataeus of Miletus to draw a more accurate version. Strabo viewed both as the first geographers after Homer.

Maps were produced in ancient times, also notably in Egypt, Lydia, the Middle East, and Babylon. Only some small examples survived until today. The unique example of a world map comes from late Babylonian tablet BM 92687 later than 9th century BC but is based probably on a much older map. These maps indicated directions, roads, towns, borders, and geological features. Anaximander's innovation was to represent the entire inhabited land known to the ancient Greeks.

Such an accomplishment is more significant than it at first appears. Anaximander most likely drew this map for three reasons. First, it could be used to improve navigation and trade between Miletus's colonies and other colonies around the Mediterranean Sea and Black Sea. Second, Thales would probably have found it easier to convince the Ionian city-states to join in a federation in order to push the Median threat away if he possessed such a tool. Finally, the philosophical idea of a global representation of the world simply for the sake of knowledge was reason enough to design one.

Surely aware of the sea's convexity, he may have designed his map on a slightly rounded metal surface. The centre or “navel” of the world ( "omphalós gẽs") could have been Delphi, but is more likely in Anaximander's time to have been located near Miletus. The Aegean Sea was near the map's centre and enclosed by three continents, themselves located in the middle of the ocean and isolated like islands by sea and rivers. Europe was bordered on the south by the Mediterranean Sea and was separated from Asia by the Black Sea, the Lake Maeotis, and, further east, either by the Phasis River (now called the Rioni) or the Tanais. The Nile flowed south into the ocean, separating Libya (which was the name for the part of the then-known African continent) from Asia.

The "Suda" relates that Anaximander explained some basic notions of geometry. It also mentions his interest in the measurement of time and associates him with the introduction in Greece of the gnomon. In Lacedaemon, he participated in the construction, or at least in the adjustment, of sundials to indicate solstices and equinoxes. Indeed, a gnomon required adjustments from a place to another because of the difference in latitude.

In his time, the gnomon was simply a vertical pillar or rod mounted on a horizontal plane. The position of its shadow on the plane indicated the time of day. As it moves through its apparent course, the Sun draws a curve with the tip of the projected shadow, which is shortest at noon, when pointing due south. The variation in the tip's position at noon indicates the solar time and the seasons; the shadow is longest on the winter solstice and shortest on the summer solstice.

The invention of the gnomon itself cannot be attributed to Anaximander because its use, as well as the division of days into twelve parts, came from the Babylonians. It is they, according to Herodotus' Histories (II, 109), who gave the Greeks the art of time measurement. It is likely that he was not the first to determine the solstices, because no calculation is necessary. On the other hand, equinoxes do not correspond to the middle point between the positions during solstices, as the Babylonians thought. As the "Suda" seems to suggest, it is very likely that with his knowledge of geometry, he became the first Greek to accurately determine the equinoxes.

In his philosophical work "De Divinatione" (I, 50, 112), Cicero states that Anaximander convinced the inhabitants of Lacedaemon to abandon their city and spend the night in the country with their weapons because an earthquake was near. The city collapsed when the top of the Taygetus split like the stern of a ship. Pliny the Elder also mentions this anecdote (II, 81), suggesting that it came from an "admirable inspiration", as opposed to Cicero, who did not associate the prediction with divination.

Bertrand Russell in the "History of Western Philosophy" interprets Anaximander's theories as an assertion of the necessity of an appropriate balance between earth, fire, and water, all of which may be independently seeking to aggrandize their proportions relative to the others. Anaximander seems to express his belief that a natural order ensures balance between these elements, that where there was fire, ashes (earth) now exist. His Greek peers echoed this sentiment with their belief in natural boundaries beyond which not even the gods could operate.

Friedrich Nietzsche, in "Philosophy in the Tragic Age of the Greeks", claimed that Anaximander was a pessimist who asserted that the primal being of the world was a state of indefiniteness. In accordance with this, anything definite has to eventually pass back into indefiniteness. In other words, Anaximander viewed "...all coming-to-be as though it were an illegitimate emancipation from eternal being, a wrong for which destruction is the only penance". ("Ibid.", § 4) The world of individual objects, in this way of thinking, has no worth and should perish.

Martin Heidegger lectured extensively on Anaximander, and delivered a lecture entitled "Anaximander's Saying" which was subsequently included in "Off the Beaten Track". The lecture examines the ontological difference and the oblivion of Being or "Dasein" in the context of the Anaximander fragment. Heidegger's lecture is, in turn, an important influence on the French philosopher Jacques Derrida.

According to the "Suda":







</doc>
<doc id="1169" url="https://en.wikipedia.org/wiki?curid=1169" title="APL">
APL

APL is an abbreviation, acronym, or initialism that may refer to:







</doc>
<doc id="1170" url="https://en.wikipedia.org/wiki?curid=1170" title="Architect">
Architect

An architect is a person who plans, designs and oversees the construction of buildings. To practice architecture means to provide services in connection with the design of buildings and the space within the site surrounding the buildings that have human occupancy or use as their principal purpose. Etymologically, the term "architect" derives from the Latin "architectus", which derives from the Greek ("arkhi-", chief + "tekton", builder), i.e., chief builder.

Professionally, an architect's decisions affect public safety, and thus the architect must undergo specialized training consisting of advanced education and a "practicum" (or internship) for practical experience to earn a license to practice architecture. Practical, technical, and academic requirements for becoming an architect vary by jurisdiction.

Throughout ancient and medieval history, most of the architectural design and construction was carried out by artisans—such as stone masons and carpenters, rising to the role of master builder. Until modern times, there was no clear distinction between architect and engineer. In Europe, the titles "architect" and "engineer" were primarily geographical variations that referred to the same person, often used interchangeably. It is suggested that various developments in technology and mathematics allowed the development of the professional 'gentleman' architect, separate from the hands-on craftsman. Paper was not used in Europe for drawing until the 15th century but became increasingly available after 1500. Pencils were used more often for drawing by 1600. The availability of both allowed pre-construction drawings to be made by professionals. Concurrently, the introduction of linear perspective and innovations such as the use of different projections to describe a three-dimensional building in two dimensions, together with an increased understanding of dimensional accuracy, helped building designers communicate their ideas. However, the development was gradual. Until the 18th-century, buildings continued to be designed and set out by craftsmen with the exception of high-status projects.

In most developed countries, only those qualified with an appropriate license, certification, or registration with a relevant body (often governmental) may legally practice architecture. Such licensure usually requires a university degree, successful completion of exams, as well as a training period. Representation of oneself as an architect through the use of terms and titles is restricted to licensed individuals by law, although in general, derivatives such as architectural designer are often not legally protected.

To practice architecture implies the ability to practice independently of supervision. The term "building design professional" (or "design professional)", by contrast, is a much broader term that includes professionals who practice independently under an alternate profession, such as engineering professionals, or those who assist in the practice of architecture under the supervision of a licensed architect such as intern architects. In many places, independent, non-licensed individuals may perform design services outside the professional restrictions, such design houses and other smaller structures.

In the architectural profession, technical and environmental knowledge, design and construction management, and an understanding of business are as important as design. However, the design is the driving force throughout the project and beyond. An architect accepts a commission from a client. The commission might involve preparing feasibility reports, building audits, the design of a building or of several buildings, structures, and the spaces among them. The architect participates in developing the requirements the client wants in the building. Throughout the project (planning to occupancy), the architect coordinates a design team. Structural, mechanical, and electrical engineers and other specialists, are hired by the client or the architect, who must ensure that the work is coordinated to construct the design.

The architect, once hired by a client, is responsible for creating a design concept that both meets the requirements of that client and provides a facility suitable to the required use. The architect must meet with, and question, the client in order to ascertain all the requirements (and nuances) of the planned project. 

Often the full brief is not entirely clear at the beginning: entailing a degree of risk in the design undertaking. The architect may make early proposals to the client, which may rework the very terms of the brief. The "program" (or brief) is essential to producing a project that meets all the needs of the owner. This then is a guide for the architect in creating the design concept.

Design proposal(s) are generally expected to be both imaginative and pragmatic. Depending on the place, time, finance, culture, and available crafts and technology in which the design takes place, the precise extent and nature of these expectations will vary.

Foresight is a prerequisite as designing buildings is a very complex and demanding undertaking. 

Any design concept must at a very early stage in its generation take into account a great number of issues and variables which include qualities of space(s), the end-use and life-cycle of these proposed spaces, connections, relations, and aspects between spaces including how they are put together as well as the impact of proposals on the immediate and wider locality. Selection of appropriate materials and technology must be considered, tested and reviewed at an early stage in the design to ensure there are no setbacks (such as higher-than-expected costs) which may occur later. The site and its environs, as well as the culture and history of the place, will also influence the design. The design must also countenance increasing concerns with environmental sustainability. The architect may introduce (intentionally or not), to greater or lesser degrees, aspects of mathematics and architecture, new or current architectural theory, or references to architectural history.

A key part of the design is that the architect often consults with engineers, surveyors and other specialists throughout the design, ensuring that aspects such as the structural supports and air conditioning elements are coordinated in the scheme as a whole. The control and planning of construction costs are also a part of these consultations. Coordination of the different aspects involves a high degree of specialized communication, including advanced computer technology such as BIM (Building Information Modeling), CAD, and cloud-based technologies.

At all times in the design, the architect reports back to the client who may have reservations or recommendations, introducing a further variable into the design.

Architects deal with local and federal jurisdictions about regulations and building codes. The architect might need to comply with local planning and zoning laws, such as required setbacks, height limitations, parking requirements, transparency requirements (windows), and land use. Some established jurisdictions require adherence to design and historic preservation guidelines. Health and safety risks form a vital part of the current design, and in many jurisdictions, design reports and records are required which include ongoing considerations such as materials and contaminants, waste management and recycling, traffic control and fire safety.

Previously, architects employed drawings to illustrate and generate design proposals. While conceptual sketches are still widely used by architects, computer technology has now become the industry standard. However, design may include the use of photos, collages, prints, linocuts, 3D scanning technology and other media in design production. 
Increasingly, computer software such as BIM is shaping how architects work. BIM technology allows for the creation of a virtual building that serves as an information database for the sharing of design and building information throughout the life-cycle of the building's design, construction and maintenance.

As current buildings are now known to be high emitters of carbon into the atmosphere, increasing controls are being placed on buildings and associated technology to reduce emissions, increase energy efficiency, and make use of renewable energy sources. Renewable energy sources may be developed within the proposed building or via local or national renewable energy providers. As a result, the architect is required to remain abreast of current regulations that are continually tightening. Some new developments exhibit extremely low energy use.
However, the architect is also increasingly required to provide initiatives in a wider environmental sense, such as making provision for low-energy transport, natural daylighting instead of artificial lighting, natural ventilation instead of air conditioning, pollution, and waste management, use of recycled materials and employment of materials which can be easily recycled in the future.

As the design becomes more advanced and detailed, specifications and detail designs are made of all the elements and components of the building. Techniques in the production of a building are continually advancing which places a demand on the architect to ensure that he or she remains up to date with these advances.

Depending on the client's needs and the jurisdiction's requirements, the spectrum of the architect's services during construction stages may be extensive (detailed document preparation and construction review) or less involved (such as allowing a contractor to exercise considerable design-build functions).

Architects typically put projects to tender on behalf of their clients, advise on the award of the project to a general contractor, facilitate and then administer a contract of agreement which is often between the client and the contractor. This contract is legally binding and covers a very wide range of aspects including the insurances and commitments of all stakeholders, the status of the design documents, provisions for the architect's access, and procedures for the control of the works as they proceed. Depending on the type of contract utilized, provisions for further sub-contract tenders may be required. The architect may require that some elements are covered by a warranty which specifies the expected life and other aspects of the material, product or work.

In most jurisdictions, prior notification to the relevant local authority must be given before commencement on site, thus giving the local authority notice to carry out independent inspections. The architect will then review and inspect the progress of the work in coordination with the local authority.

The architect will typically review contractor shop drawings and other submittals, prepare and issue site instructions, and provide Certificates for Payment to the contractor (see also Design-bid-build) which is based on the work done to date as well as any materials and other goods purchased or hired. In the United Kingdom and other countries, a quantity surveyor is often part of the team to provide cost consulting. With very large, complex projects, an independent construction manager is sometimes hired to assist in the design and to manage construction.

In many jurisdictions, mandatory certification or assurance of the completed work or part of works is required. This demand for certification entails a high degree of risk - therefore, regular inspections of the work as it progresses on site is required to ensure that is in compliance with the design itself as well as with all relevant statutes and permissions.

Recent decades have seen the rise of specializations within the profession. Many architects and architectural firms focus on certain project types (for example, healthcare, retail, public housing, event management), technological expertise or project delivery methods. Some architects specialize as building code, building envelope, sustainable design, technical writing, historic preservation(US) or conservation (UK), accessibility and other forms of specialist consultants.

Many architects elect to move into real estate (property) development, corporate facilities planning, project management, construction management, interior design, city planning, or other related fields.

Although there are variations from place to place, most of the world's architects are required to register with the appropriate jurisdiction. To do so, architects are typically required to meet three common requirements: education, experience, and examination.

Educational requirements generally consist of a university degree in architecture. The experience requirement for degree candidates is usually satisfied by a practicum or internship (usually two to three years, depending on jurisdiction). Finally, a Registration Examination or a series of exams is required prior to licensure.

Professionals engaged in the design and supervision of construction projects prior to the late 19th century were not necessarily trained in a separate architecture program in an academic setting. Instead, they often trained under established architects. Prior to modern times, there was no distinction between architects, engineers and often artists, and the title used varied depending on geographical location. They often carried the title of master builder or surveyor after serving a number of years as an apprentice (such as Sir Christopher Wren). The formal study of architecture in academic institutions played a pivotal role in the development of the profession as a whole, serving as a focal point for advances in architectural technology and theory.

Architects' fee structures are typically based on a percentage of construction value, as a rate per unit area of the proposed construction, hourly rates or a fixed lump sum fee. Combinations of these structures are also common. Fixed fees are usually based on a project's allocated construction cost and can range between 4 and 12% of new construction cost, for commercial and institutional projects, depending on a project's size and complexity. Residential projects range from 12 to 20%. Renovation projects typically command higher percentages, as high as 15-20%.

Overall billings for architectural firms range widely, depending on location and economic climate. Billings have traditionally been dependent on the local economic conditions but, with rapid globalization, this is becoming less of a factor for larger international firms. Salaries also vary, depending on experience, position within the firm (staff architect, partner, or shareholder, etc.), and the size and location of the firm.

A number of national professional organizations exist to promote career and business development in architecture.


A wide variety of prizes is awarded by national professional associations and other bodies, recognizing accomplished architects, their buildings, structures, and professional careers.

The most lucrative award an architect can receive is the Pritzker Prize, sometimes termed the "Nobel Prize for architecture." Other prestigious architectural awards are the Royal Gold Medal, the AIA Gold Medal (USA), AIA Gold Medal (Australia), and the Praemium Imperiale.

Architects in the UK, who have made contributions to the profession through design excellence or architectural education, or have in some other way advanced the profession, might until 1971 be elected Fellows of the Royal Institute of British Architects and can write FRIBA after their name if they feel so inclined. Those elected to chartered membership of the RIBA after 1971 may use the initials RIBA but cannot use the old ARIBA and FRIBA. An Honorary Fellow may use the initials, Hon. FRIBA. and an International Fellow may use the initials Int. FRIBA. Architects in the US, who have made contributions to the profession through design excellence or architectural education, or have in some other way advanced the profession, are elected Fellows of the American Institute of Architects and can write FAIA after their name. Architects in Canada, who have made outstanding contributions to the profession through contribution to research, scholarship, public service, or professional standing to the good of architecture in Canada, or elsewhere, may be recognized as a Fellow of the Royal Architectural Institute of Canada and can write FRAIC after their name. In Hong Kong, those elected to chartered membership may use the initial HKIA, and those who have made a special contribution after nomination and election by The Hong Kong Institute of Architects (HKIA), may be elected as fellow members of HKIA and may use FHKIA after their name.

Architects in the Philippines and Filipino communities overseas (whether they are Filipinos or not), especially those who also profess other jobs at the same time, are addressed and introduced as "Architect", rather than "Sir/Madam" in speech or "Mr./Mrs./Ms." ("G./Gng./Bb." in Filipino) before surnames. That word is used either in itself or before the given name or surname.


</doc>
<doc id="1171" url="https://en.wikipedia.org/wiki?curid=1171" title="Abbreviation">
Abbreviation

An abbreviation (from Latin "brevis", meaning "short" ) is a shortened form of a word or phrase, by any method. It may consist of a group of letters, or words taken from the full version of the word or phrase; for example, the word "abbreviation" can itself be represented by the abbreviation "abbr.", "abbrv.", or "abbrev."; "NBM", for nil (or nothing) by mouth is an abbreviated medical instruction. It may also consist of initials only, a mixture of initials and words, or words or letters representing words in another language (for example, e.g., i.e. or RSVP). Some types of abbreviations are acronyms (which are pronounceable), initialisms (using initials only), or grammatical contractions or crasis.

An abbreviation is a shortening by any of these, or other, methods. 
Acronyms, initialisms, contractions and crasis share some semantic and phonetic functions, and all four are connected by the term "abbreviation" in loose parlance.

A contraction is a reduction of size by the drawing together of the parts; a contraction of a word or words is made by omitting certain letters or syllables and bringing together the first and last letters or elements, such as "I'm" . A contraction may be regarded as a type of abbreviation, but not vice versa.

Abbreviations have a long history, created so that spelling out a whole word could be avoided. This might be done to save time and space, and also to provide secrecy. In both Greece and Rome the reduction of words to single letters was common. In Roman inscriptions, "Words were commonly abbreviated by using the initial letter or letters of words, and most inscriptions have at least one abbreviation". However, "some could have more than one meaning, depending on their context. (For example, can be an abbreviation for many words, such as , , , , , , and .)"

Abbreviations in English were frequently used from its earliest days. Manuscripts of copies of the old English poem "Beowulf" used many abbreviations, for example the Tironian et () or for "and", and for "since", so that "not much space is wasted". The standardisation of English in the 15th through 17th centuries included such a growth in the use of abbreviations. At first, abbreviations were sometimes represented with various suspension signs, not only periods. For example, sequences like ‹er› were replaced with ‹ɔ›, as in ‹mastɔ› for "master" and ‹exacɔbate› for "exacerbate". While this may seem trivial, it was symptomatic of an attempt by people manually reproducing academic texts to reduce the copy time.
In the Early Modern English period, between the 15th and 17th centuries, the thorn (letter) was used for "th", as in ('the'). However, in modern times, was often misread and wrongly rewritten as , as in .

During the growth of philological linguistic theory in academic Britain, abbreviating became very fashionable. For example J. R. R. Tolkien, his friend C. S. Lewis and other members of the Oxford literary group were known as the Inklings. Likewise, a century earlier in Boston, a fad of abbreviation started that swept the United States, with the globally popular term OK generally credited as a remnant of its influence.

Over the years, however, the lack of convention in some style guides has made it difficult to determine which two-word abbreviations should be abbreviated with periods and which should not. This question is considered below,

Widespread use of electronic communication through mobile phones and the Internet during the 1990s allowed for a marked rise in colloquial abbreviation. This was due largely to increasing popularity of textual communication services such as instant- and text messaging. The original SMS, supported message lengths of 160 characters at most (using the GSM 03.38 character set), for instance. This brevity gave rise to an informal abbreviation scheme sometimes called Textese, with which 10% or more of the words in a typical SMS message are abbreviated. More recently Twitter, a popular social networking service, began driving abbreviation use with 140 character message limits.

In modern English, there are several conventions for abbreviations, and the choice may be confusing. The only rule universally accepted is that one should be "consistent", and to make this easier, publishers express their preferences in a style guide. Questions which arise include those in the following subsections.

If the original word was capitalized then the first letter of its abbreviation should retain the capital, for example Lev. for "Leviticus". When a word is abbreviated to more than a single letter and was originally spelled with lower case letters then there is no need for capitalization. However, when abbreviating a phrase where only the first letter of each word is taken, then all letters should be capitalized, as in YTD for "year-to-date", PCB for "printed circuit board" and FYI for "for your information". However, see the following section regarding abbreviations that have become common vocabulary: these are no longer written with capital letters.

A period (full stop) is often used to signify an abbreviation, but opinion is divided as to when and if this should happen.

According to Hart's Rules, the traditional rule is that abbreviations (in the narrow sense that includes only words with the ending, and not the middle, dropped) terminate with a full stop, whereas contractions (in the sense of words missing a middle part) do not, but there are exceptions. Fowler's Modern English Usage says full stops are used to mark both abbreviations and contractions, but recommends against this practice: advising them only for abbreviations and lower-case initialisms and not for upper-case initialisms and contractions.

In American English, the period is usually included regardless of whether or not it is a contraction, e.g. "Dr." or "Mrs.". In some cases, periods are optional, as in either "US" or "U.S." for "United States", "EU" or "E.U." for "European Union", and "UN" or "U.N." for "United Nations". There are some house styles, however—American ones included—that remove the periods from almost all abbreviations. For example:

Acronyms that were originally capitalized (with or without periods) but have since entered the vocabulary as generic words are no longer written with capital letters nor with any periods. Examples are sonar, radar, lidar, laser, snafu, and scuba.

Today, spaces are generally not used between single-letter abbreviations of words in the same phrase, so one almost never encounters "U. S."

When an abbreviation appears at the end of a sentence, only one period is used: "The capital of the United States is Washington, D.C".

There is a question about how to pluralize abbreviations, particularly acronyms. Some writers tend to pluralize abbreviations by addding (apostrophe s), as in "two PC's have broken screens", although this notation typically indicates possessive case. However, this style is not preferred by many style guides. For instance, Kate Turabian, writing about style in academic writings, allows for an apostrophe to form plural acronyms "only when an abbreviation contains internal periods or both capital and lowercase letters". Turabian would therefore prefer "DVDs" and "URLs" and "Ph.D.'s", while the Modern Language Association explicitly says, "do not use an apostrophe to form the plural of an abbreviation". Also, the American Psychological Association specifically says, "without an apostrophe".

However, the 1999 style guide for "The New York Times" states that the addition of an apostrophe is necessary when pluralizing all abbreviations, preferring "PC's, TV's and VCR's".

Following those who would generally omit the apostrophe, to form the plural of run batted in, simply add an s to the end of RBI.


For all other rules, see below:

To form the plural of an abbreviation, a number, or a capital letter used as a noun, simply add a lowercase "s" to the end. Apostrophes following decades and single letters are also common.

To indicate the plural of the abbreviation or symbol of a unit of measure, the same form is used as in the singular.

When an abbreviation contains more than one full point, "Hart's Rules" recommends putting the "s" after the final one.
However, subject to any house style or consistency requirement, the same plurals may be rendered less formally as:

According to "Hart's Rules", an apostrophe may be used in rare cases where clarity calls for it, for example when letters or symbols are referred to as objects.
However, the apostrophe can be dispensed with if the items are set in italics or quotes:

In Latin, and continuing to the derivative forms in European languages as well as English, single-letter abbreviations had the plural being a doubling of the letter for note-taking. Most of these deal with writing and publishing. A few longer abbreviations use this as well.

Publications based in the U.S. tend to follow the style guides of "The Chicago Manual of Style" and the Associated Press. The U.S. Government follows a style guide published by the U.S. Government Printing Office. The National Institute of Standards and Technology sets the style for abbreviations of units.

Many British publications follow some of these guidelines in abbreviation:


Writers often use shorthand to denote units of measure. Such shorthand can be an abbreviation, such as "in" for "inch" or can be a symbol such as "km" for "kilometre/kilometer".

In the International System of Units (SI) manual the word "symbol" is used consistently to define the shorthand used to represent the various SI units of measure. The manual also defines the way in which units should be written, the principal rules being:

A syllabic abbreviation is usually formed from the initial syllables of several words, such as "Interpol" = International" + police". It is a variant of the acronym. Syllabic abbreviations are usually written using lower case, sometimes starting with a capital letter, and are always pronounced as words rather than letter by letter. Syllabic abbreviations should be distinguished from portmanteaus, which combine two words without necessarily taking whole syllables from each.

Syllabic abbreviations are not widely used in English. Some UK government ministries such as Ofcom (Office of Communications") and Oftel (Office of Telecommunications") use this style.

New York City has various neighborhoods named by syllabic abbreviation, such as Tribeca (Triangle below Canal Street") and SoHo (South of Houston Street"). This usage has spread into other American cities, giving SoMa, San Francisco (South of Market") and LoDo, Denver (Lower Downtown"), amongst others.

Partially syllabic abbreviations are preferred by the US Navy, as it increases readability amidst the large number of initialisms that would otherwise have to fit into the same acronyms. Hence "DESRON 6" is used (in the full capital form) to mean "Destroyer Squadron 6", while "COMNAVAIRLANT" would be "Commander, Naval Air Force (in the) Atlantic."

Syllabic abbreviations prevailed in Nazi Germany and the Soviet Union for naming a plethora of new bureaucratic organisations. For example, "Gestapo" stands for Geheime Staats-Polizei", or "secret state police". Similarly, Leninist organisations such as the "Comintern" ("Communist International") and "Komsomol" (Kommunisticheskii Soyuz Molodyozhi", or "Communist youth union") used Russian language syllabic abbreviations. This has given syllabic abbreviations negative connotations in some countries, (as in Orwell's Newspeak), notwithstanding that such abbreviations were used in Germany even before the Nazis came to power, e.g., "" for "Schutzpolizei", and are still used, e.g. "" for "".

In the modern Russian language words like "Minoborony" (from Ministerstvo oborony — Ministry of Defence) and "Minobrnauki" (from Ministerstvo obrazovaniya i nauki — Ministry of Education and Science) are still commonly used.

In Belarus there is "Beltelecom" (Belarus Telecommunication) and Belsat (Belarus Satellite).

Syllabic abbreviations were also typical for the German language used in the German Democratic Republic, e.g. "Stasi" for Staatssicherheit" ("state security", the secret police) or "Vopo" for "Volkspolizist" ("people's policeman"). Other uses are in company or product names such as Aldi, from the name of the founder, Theo Albrecht, and the German word Diskont" (discount) or Haribo, from the name of the founder and the headquarters of the company, Hans Riegl Bonn.

Syllabic abbreviations are more common in Spanish; examples abound in organization names such as Pemex for Petróleos Mexicanos" ("Mexican Petroleums") or Fonafifo for Fondo Nacional de Financimiento Forestal" (National Forestry Financing Fund).

In Southeast Asian languages, especially in Malay languages, syllabic abbreviations are also common; examples include Petronas (for Petroliam Nasional", "National Petroleum"), its Indonesian equivalent Pertamina (from its original name Perusahaan Pertambangan Minyak dan Gas Bumi Negara", "State Oil and Natural Gas Mining Company"), and Kemenhub (from "Kementerian Perhubungan", "Ministry of Transportation")

East Asian languages whose writing systems use Chinese characters form abbreviations similarly by using key Chinese characters from a term or phrase. For example, in Japanese the term for the United Nations, "kokusai rengō" (国際連合) is often abbreviated to "kokuren" (国連). (Such abbreviations are called (略語) in Japanese; see also Japanese abbreviated and contracted words). The syllabic abbreviation is frequently used for universities: for instance, "Tōdai" (東大) for "Tōkyō daigaku" (東京大学, University of Tokyo) and is used similarly in Chinese: "Běidà" (北大) for "Běijīng Dàxué" (北京大学, Peking University). The English phrase "Gung ho" originated as a Chinese abbreviation.





</doc>
<doc id="1174" url="https://en.wikipedia.org/wiki?curid=1174" title="Aphrodite">
Aphrodite

Aphrodite is an ancient Greek goddess associated with love, beauty, pleasure, passion and procreation. She was syncretized with the Roman goddess . Aphrodite's major symbols include myrtles, roses, doves, sparrows, and swans. The cult of Aphrodite was largely derived from that of the Phoenician goddess Astarte, a cognate of the East Semitic goddess Ishtar, whose cult was based on the Sumerian cult of Inanna. Aphrodite's main cult centers were Cythera, Cyprus, Corinth, and Athens. Her main festival was the Aphrodisia, which was celebrated annually in midsummer. In Laconia, Aphrodite was worshipped as a warrior goddess. She was also the patron goddess of prostitutes, an association which led early scholars to propose the concept of "sacred prostitution" in Greco-Roman culture, an idea which is now generally seen as erroneous.

In Hesiod's "Theogony", Aphrodite is born off the coast of Cythera from the foam (') produced by Uranus's genitals, which his son Cronus has severed and thrown into the sea. In Homer's "Iliad", however, she is the daughter of Zeus and Dione. Plato, in his "Symposium" 180e, asserts that these two origins actually belong to separate entities: Aphrodite Ourania (a transcendent, "Heavenly" Aphrodite) and Aphrodite Pandemos (Aphrodite common to "all the people"). Aphrodite had many other epithets, each emphasizing a different aspect of the same goddess, or used by a different local cult. Thus she was also known as Cytherea ("Lady of Cythera") and Cypris"' ("Lady of Cyprus"), because both locations claimed to be the place of her birth.

In Greek mythology, Aphrodite was married to Hephaestus, the god of blacksmiths and metalworking. Despite this, Aphrodite was frequently unfaithful to him and had many lovers; in the "Odyssey", she is caught in the act of adultery with Ares, the god of war. In the "First Homeric Hymn to Aphrodite", she seduces the mortal shepherd Anchises. Aphrodite was also the surrogate mother and lover of the mortal shepherd Adonis, who was killed by a wild boar. Along with Athena and Hera, Aphrodite was one of the three goddesses whose feud resulted in the beginning of the Trojan War and she plays a major role throughout the "Iliad". Aphrodite has been featured in Western art as a symbol of female beauty and has appeared in numerous works of Western literature. She is a major deity in modern Neopagan religions, including the Church of Aphrodite, Wicca, and Hellenismos.

Hesiod derives "Aphrodite" from () "sea-foam", interpreting the name as "risen from the foam", but most modern scholars regard this as a spurious folk etymology. Early modern scholars of classical mythology attempted to argue that Aphrodite's name was of Greek or Indo-European origin, but these efforts have now been mostly abandoned. Aphrodite's name is generally accepted to be of non-Greek, probably Semitic, origin, but its exact derivation cannot be determined.

Scholars in the late nineteenth and early twentieth centuries, accepting Hesiod's "foam" etymology as genuine, analyzed the second part of Aphrodite's name as *"-odítē" "wanderer" or *"-dítē" "bright". Michael Janda, also accepting Hesiod's etymology, has argued in favor of the latter of these interpretations and claims the story of a birth from the foam as an Indo-European mytheme. Similarly, Krzysztof Tomasz Witczak proposes an Indo-European compound ' "very" and ' "to shine", also referring to Eos. Other scholars have argued that these hypotheses are unlikely since Aphrodite's attributes are entirely different from those of both Eos and the Vedic deity Ushas.

A number of improbable non-Greek etymologies have also been suggested. One Semitic etymology compares Aphrodite to the Assyrian "barīrītu", the name of a female demon that appears in Middle Babylonian and Late Babylonian texts. Hammarström looks to Etruscan, comparing "(e)prϑni" "lord", an Etruscan honorific loaned into Greek as πρύτανις. This would make the theonym in origin an honorific, "the lady". Most scholars reject this etymology as implausible, especially since Aphrodite actually appears in Etruscan in the borrowed form "Apru" (from Greek , clipped form of "Aphrodite"). The medieval "Etymologicum Magnum" (c. 1150) offers a highly contrived etymology, deriving "Aphrodite" from the compound "habrodíaitos" (), "she who lives delicately", from "habrós" and "díaita". The alteration from "b" to "ph" is explained as a "familiar" characteristic of Greek "obvious from the Macedonians".

The cult of Aphrodite in Greece was imported from, or at least influenced by, the cult of Astarte in Phoenicia, which, in turn, was influenced by the cult of the Mesopotamian goddess known as "Ishtar" to the East Semitic peoples and as "Inanna" to the Sumerians. Pausanias states that the first to establish a cult of Aphrodite were the Assyrians, followed by the Paphians of Cyprus and then the Phoenicians at Ascalon. The Phoenicians, in turn, taught her worship to the people of Cythera.

Aphrodite took on Inanna-Ishtar's associations with sexuality and procreation. Furthermore, she was known as Ourania (Οὐρανία), which means "heavenly", a title corresponding to Inanna's role as the Queen of Heaven. Early artistic and literary portrayals of Aphrodite are extremely similar on Inanna-Ishtar. Like Inanna-Ishtar, Aphrodite was also a warrior goddess; the second-century AD Greek geographer Pausanias records that, in Sparta, Aphrodite was worshipped as "Aphrodite Areia", which means "warlike". He also mentions that Aphrodite's most ancient cult statues in Sparta and on Cythera showed her bearing arms. Modern scholars note that Aphrodite's warrior-goddess aspects appear in the oldest strata of her worship and see it as an indication of her Near Eastern origins.

Nineteenth century classical scholars had a general aversion to the idea that ancient Greek religion was at all influenced by the cultures of the Near East, but, even Friedrich Gottlieb Welcker, who argued that Near Eastern influence on Greek culture was largely confined to material culture, admitted that Aphrodite was clearly of Phoenician origin. The significant influence of Near Eastern culture on early Greek religion in general, and on the cult of Aphrodite in particular, is now widely recognized as dating to a period of orientalization during the eighth century BC, when archaic Greece was on the fringes of the Neo-Assyrian Empire.

Some early comparative mythologists opposed to the idea of a Near Eastern origin argued that Aphrodite originated as an aspect of the Greek dawn goddess Eos and that she was therefore ultimately derived from the Proto-Indo-European dawn goddess *"Héusōs" (properly Greek Eos, Latin Aurora, Sanskrit Ushas). Most modern scholars have now rejected the notion of a purely Indo-European Aphrodite, but it is possible that Aphrodite, originally a Semitic deity, may have been influenced by the Indo-European dawn goddess. Both Aphrodite and Eos were known for their erotic beauty and aggressive sexuality and both had relationships with mortal lovers. Both goddesses were associated with the colors red, white, and gold. Michael Janda etymologizes Aphrodite's name as an epithet of Eos meaning "she who rises from the foam [of the ocean]" and points to Hesiod's "Theogony" account of Aphrodite's birth as an archaic reflex of Indo-European myth. Aphrodite rising out of the waters after Cronus defeats Uranus as a mytheme would then be directly cognate to the Rigvedic myth of Indra defeating Vrtra, liberating Ushas. Another key similarity between Aphrodite and the Indo-European dawn goddess is her close kinship to the Greek sky deity, since both of the main claimants to her paternity (Zeus and Uranus) are sky deities.

Aphrodite's most common cultic epithet was "Ourania", meaning "heavenly", but this epithet almost never occurs in literary texts, indicating a purely cultic significance. Another common name for Aphrodite was "Pandemos" ("For All the Folk"). In her role as Aphrodite Pandemos, Aphrodite was associated with "Peithō" (), meaning "persuasion", and could be prayed to for aid in seduction. The character of Pausanias in Plato's "Symposium", takes differing cult-practices associated with different epithets of the goddess to claim that Ourania and Pandemos are, in fact, separate goddesses. He asserts that "Aphrodite Ourania" is the celestial Aphrodite, born from the sea foam after Cronus castrated Uranus, and the older of the two goddesses. According to the "Symposium", "Aphrodite Ourania" is the inspiration of male homosexual desire, specifically the ephebic eros, and pederasty. "Aphrodite Pandemos", by contrast, is the younger of the two goddesses: the common Aphrodite, born from the union of Zeus and Dione, and the inspiration of heterosexual desire and sexual promiscuity, the "lesser" of the two loves. "Paphian" (Παφία), was one of her epithets, after the Paphos in Cyprus where she had emerged from the sea at her birth.

Among the Neoplatonists and, later, their Christian interpreters, Ourania is associated with spiritual love, and Pandemos with physical love (desire). A representation of Ourania with her foot resting on a tortoise came to be seen as emblematic of discretion in conjugal love; it was the subject of a chryselephantine sculpture by Phidias for Elis, known only from a parenthetical comment by the geographer Pausanias.

One of Aphrodite's most common literary epithets is "Philommeidḗs" (), which means "smile-loving", but is sometimes mistranslated as "laughter-loving". This epithet occurs throughout both of the Homeric epics and the "First Homeric Hymn to Aphrodite". Hesiod references it once in his "Theogony" in the context of Aphrodite's birth, but interprets it as "genital-loving" rather than "smile-loving". Monica Cyrino notes that the epithet may relate to the fact that, in many artistic depictions of Aphrodite, she is shown smiling. Other common literary epithets are "Cypris" and "Cythereia", which derive from her associations with the islands of Cyprus and Cythera respectively.

On Cyprus, Aphrodite was sometimes called "Eleemon" ("the merciful"). In Athens, she was known as "Aphrodite en kopois" ("Aphrodite of the Gardens"). At Cape Colias, a town along the Attic coast, she was venerated as "Genetyllis" "Mother". The Spartans worshipped her as "Potnia" "Mistress", "Enoplios" "Armed", "Morpho" "Shapely", "Ambologera" "She who Postpones Old Age". Across the Greek world, she was known under epithets such as "Melainis" "Black One", "Skotia" "Dark One", "Androphonos" "Killer of Men", "Anosia" "Unholy", and "Tymborychos" "Gravedigger", all of which indicate her darker, more violent nature.

A male version of Aphrodite known as Aphroditus was worshipped in the city of Amathus on Cyprus. Aphroditus was depicted with the figure and dress of a woman, but had a beard, and was shown lifting his dress to reveal an erect phallus. This gesture was believed to be an apotropaic symbol, and was thought to convey good fortune upon the viewer. Eventually, the popularity of Aphroditus waned as the mainstream, fully feminine version of Aphrodite became more popular, but traces of his cult are preserved in the later legends of Hermaphroditus.

Aphrodite's main festival, the Aphrodisia, was celebrated across Greece, but particularly in Athens and Corinth. In Athens, the Aphrodisia was celebrated on the fourth day of the month of Hekatombaion in honor of Aphrodite's role in the unification of Attica. During this festival, the priests of Aphrodite would purify the temple of Aphrodite Pandemos on the southwestern slope of the Acropolis with the blood of a sacrificed dove. Next, the altars would be anointed and the cult statues of Aphrodite Pandemos and Peitho would be escorted in a majestic procession to a place where they would be ritually bathed. Aphrodite was also honored in Athens as part of the Arrhephoria festival. The fourth day of every month was sacred to Aphrodite.

Pausanias records that, in Sparta, Aphrodite was worshipped as "Aphrodite Areia", which means "warlike". This epithet stresses Aphrodite's connections to Ares, with whom she had extramarital relations. Pausanias also records that, in Sparta and on Cythera, a number of extremely ancient cult statues of Aphrodite portrayed her bearing arms. Other cult statues showed her bound in chains.

Aphrodite was the patron goddess of prostitutes of all varieties, ranging from "pornai" (cheap street prostitutes typically owned as slaves by wealthy pimps) to "hetairai" (expensive, well-educated hired companions, who were usually self-employed and sometimes provided sex to their customers). The city of Corinth was renowned throughout the ancient world for its many "hetairai", who had a widespread reputation for being among the most skilled, but also the most expensive, prostitutes in the Greek world. Corinth also had a major temple to Aphrodite located on the Acrocorinth and was one of the main centers of her cult. Records of numerous dedications to Aphrodite made by successful courtesans have survived in poems and in pottery inscriptions. References to Aphrodite in association with prostitution are found in Corinth as well as on the islands of Cyprus, Cythera, and Sicily. Aphrodite's Mesopotamian precursor Inanna-Ishtar was also closely associated with prostitution.

Scholars in the nineteenth and twentieth centuries believed that the cult of Aphrodite may have involved ritual prostitution, an assumption based on ambiguous passages in certain ancient texts, particularly a fragment of a "skolion" by the Boeotian poet Pindar, which mentions prostitutes in Corinth in association with Aphrodite. Modern scholars now dismiss the notion of ritual prostitution in Greece as a "historiographic myth" with no factual basis.

During the Hellenistic period, the Greeks identified Aphrodite with the ancient Egyptian goddesses Hathor and Isis. Aphrodite was the patron goddess of the Lagid queens and Queen Arsinoe II was identified as her mortal incarnation. Aphrodite was worshipped in Alexandria and had numerous temples in and around the city. Arsinoe II introduced the cult of Adonis to Alexandria and many of the women there partook in it. The Tessarakonteres, a gigantic catamaran galley designed by Archimedes for Ptolemy IV Philopator, had a circular temple to Aphrodite on it with a marble statue of the goddess herself. In the second century BC, Ptolemy VIII Physcon and his wives Cleopatra II and Cleopatra III dedicated a temple to Aphrodite Hathor at Philae. Statuettes of Aphrodite for personal devotion became common in Egypt starting in the early Ptolemaic times and extending until long after Egypt became a Roman province.

The ancient Romans identified Aphrodite with their goddess Venus, who was originally a goddess of agricultural fertility, vegetation, and springtime. According to the Roman historian Livy, Aphrodite and Venus were officially identified in the third century BC when the cult of "Venus Erycina" was introduced to Rome from the Greek sanctuary of Aphrodite on Mount Eryx in Sicily. After this point, Romans adopted Aphrodite's iconography and myths and applied them to Venus. Because Aphrodite was the mother of the Trojan hero Aeneas in Greek mythology and Roman tradition claimed Aeneas as the founder of Rome, Venus became venerated as "Venus Genetrix", the mother of the entire Roman nation. Julius Caesar claimed to be directly descended from Aeneas's son Iulus and became a strong proponent of the cult of Venus. This precedent was later followed by his nephew Augustus and the later emperors claiming succession from him.

This syncretism greatly impacted Greek worship of Aphrodite. During the Roman era, the cults of Aphrodite in many Greek cities began to emphasize her relationship with Troy and Aeneas. They also began to adopt distinctively Roman elements, portraying Aphrodite as more maternal, more militaristic, and more concerned with administrative bureaucracy. She was claimed as a divine guardian by many political magistrates. Appearances of Aphrodite in Greek literature also vastly proliferated, usually showing Aphrodite in a characteristically Roman manner.

Aphrodite is usually said to have been born near her chief center of worship, Paphos, on the island of Cyprus, which is why she is sometimes called "Cyprian", especially in the poetic works of Sappho. The Sanctuary of Aphrodite Paphia, marking her birthplace, was a place of pilgrimage in the ancient world for centuries. Other versions of her myth have her born near the island of Cythera, hence another of her names, "Cytherea". Cythera was a stopping place for trade and culture between Crete and the Peloponesus, so these stories may preserve traces of the migration of Aphrodite's cult from the Middle East to mainland Greece.

According to the version of her birth recounted by Hesiod in his "Theogony", Cronus severed Uranus' genitals and threw them behind him into the sea. The foam from his genitals gave rise to Aphrodite (hence her name, which Hesiod interprets as "foam-arisen"), while the Giants, the Erinyes (furies), and the Meliae emerged from the drops of his blood. Hesiod states that the genitals "were carried over the sea a long time, and white foam arose from the immortal flesh; with it a girl grew." Hesiod's account of Aphrodite's birth following Uranus's castration is probably derived from "The Song of Kumarbi", an ancient Hittite epic poem in which the god Kumarbi overthrows his father Anu, the god of the sky, and bites off his genitals, causing him to become pregnant and give birth to Anu's children, which include Ishtar and her brother Teshub, the Hittite storm god.

In the "Iliad", Aphrodite is described as the daughter of Zeus and Dione. Dione's name appears to be a feminine cognate to "Dios" and "Dion", which are oblique forms of the name "Zeus". Zeus and Dione shared a cult at Dodona in northwestern Greece. In "Theogony", Hesiod describes Dione as an Oceanid.

Aphrodite is consistently portrayed as a nubile, infinitely desirable adult, having had no childhood. She is often depicted nude. In the "Iliad", Aphrodite is the apparently unmarried consort of Ares, the god of war, and the wife of Hephaestus is a different goddess named Charis. Likewise, in Hesiod's "Theogony", Aphrodite is unmarried and the wife of Hephaestus is Aglaea, the youngest of the three Charites.

In Book Eight of the "Odyssey", however, the blind singer Demodocus describes Aphrodite as the wife of Hephaestus and tells how she committed adultery with Ares during the Trojan War. The sun-god Helios saw Aphrodite and Ares having sex in Hephaestus's bed and warned Hephaestus, who fashioned a net of gold. The next time Ares and Aphrodite had sex together, the net trapped them both. Hephaestus brought all the gods into the bedchamber to laugh at the captured adulterers, but Apollo, Hermes, and Poseidon had sympathy for Ares and Poseidon agreed to pay Hephaestus for Ares's release. Humiliated, Aphrodite returned to Cyprus, where she was attended by the Charites. This narrative probably originated as a Greek folk tale, originally independent of the "Odyssey".

Later stories were invented to explain Aphrodite's marriage to Hephaestus. In the most famous story, Zeus hastily married Aphrodite to Hephaestus in order to prevent the other gods from fighting over her. In another version of the myth, Hephaestus gave his mother Hera a golden throne, but when she sat on it, she became trapped and he refused to let her go until she agreed to give him Aphrodite's hand in marriage. Hephaestus was overjoyed to be married to the goddess of beauty, and forged her beautiful jewelry, including a "strophion" () known as the (), a saltire-shaped undergarment (usually translated as "girdle"), which accentuated her breasts and made her even more irresistible to men. Such "strophia" were commonly used in depictions of the Near Eastern goddesses Ishtar and Atargatis.

Aphrodite is almost always accompanied by Eros, the god of lust and sexual desire. In his "Theogony", Hesiod describes Eros as one of the four original primeval forces born at the beginning of time, but, after the birth of Aphrodite from the sea foam, he is joined by Himeros and, together, they become Aphrodite's constant companions. In early Greek art, Eros and Himeros are both shown as idealized handsome youths with wings. The Greek lyric poets regarded the power of Eros and Himeros as dangerous, compulsive, and impossible for anyone to resist. In modern times, Eros is often seen as Aphrodite's son, but this is actually a comparatively late innovation. A "scholion" on Theocritus's "Idylls" remarks that the sixth-century BC poet Sappho had described Eros as the son of Aphrodite and Uranus, but the first surviving reference to Eros as Aphrodite's son comes from Apollonius of Rhodes's "Argonautica", written in the third century BC, which makes him the son of Aphrodite and Ares. Later, the Romans, who saw Venus as a mother goddess, seized on this idea of Eros as Aphrodite's son and popularized it, making it the predominant portrayal in works on mythology until the present day.

Aphrodite's main attendants were the three Charites, whom Hesiod identifies as the daughters of Zeus and Eurynome and names as Aglaea ("Splendor"), Euphrosyne ("Good Cheer"), and Thalia ("Abundance"). The Charites had been worshipped as goddesses in Greece since the beginning of Greek history, long before Aphrodite was introduced to the pantheon. Aphrodite's other set of attendants was the three Horae (the "Hours"), whom Hesiod identifies as the daughters of Zeus and Themis and names as Eunomia (“Good Order”), Dike (“Justice”), and Eirene (“Peace”). Aphrodite was also sometimes accompanied by Harmonia, her daughter by Ares, and Hebe, the daughter of Zeus and Hera.

The fertility god Priapus was usually considered to be Aphrodite's son by Dionysus, but he was sometimes also described as her son by Hermes, Adonis, or even Zeus. A "scholion" on Apollonius of Rhodes's "Argonautica" states that, while Aphrodite was pregnant with Priapus, Hera envied her and applied an evil potion to her belly while she was sleeping to ensure that the child would be hideous. When Aphrodite gave birth, she was horrified to see that the child had a massive, permanently erect penis, a potbelly, and a huge tongue. Aphrodite abandoned the infant to die in the wilderness, but a herdsman found him and raised him, later discovering that Priapus could use his massive penis to aid in the growth of plants.

The "First Homeric Hymn to Aphrodite" (Hymn 5), which was probably composed sometime in the mid-seventh century BC, describes how Zeus once became annoyed with Aphrodite for causing deities to fall in love with mortals, so he caused her to fall in love with Anchises, a handsome mortal shepherd who lived in the foothills beneath Mount Ida near the city of Troy. Aphrodite appears to Anchises in the form of a tall, beautiful, mortal virgin while he is alone in his home. Anchises sees her dressed in bright clothing and gleaming jewelry, with her breasts shining with divine radiance. He asks her if she is Aphrodite and promises to build her an altar on top of the mountain if she will bless him and his family.

Aphrodite lies and tells him that she is not a goddess, but the daughter of one of the noble families of Phrygia. She claims to be able to understand the Trojan language because she had a Trojan nurse as a child and says that she found herself on the mountainside after she was snatched up by Hermes while dancing in a celebration in honor of Artemis, the goddess of virginity. Aphrodite tells Anchises that she is still a virgin and begs him to take her to his parents. Anchises immediately becomes overcome with mad lust for Aphrodite and swears that he will have sex with her. Anchises takes Aphrodite, with her eyes cast downwards, to his bed, which is covered in the furs of lions and bears. He then strips her naked and makes love to her.

After the lovemaking is complete, Aphrodite reveals her true divine form. Anchises is terrified, but Aphrodite consoles him and promises that she will bear him a son. She prophesies that their son will be the demigod Aeneas, who will be raised by the nymphs of the wilderness for five years before going to Troy to become a nobleman like his father. The story of Aeneas's conception is also mentioned in Hesiod's "Theogony" and in Book II of Homer's "Iliad".

The myth of Aphrodite and Adonis is probably derived from the ancient Sumerian legend of Inanna and Dumuzid. The Greek name ("Adōnis", ) is derived from the Canaanite word "ʼadōn", meaning "lord". The earliest known Greek reference to Adonis comes from a fragment of a poem by the Lesbian poetess Sappho (c. 630 – c. 570 BC), in which a chorus of young girls asks Aphrodite what they can do to mourn Adonis's death. Aphrodite replies that they must beat their breasts and tear their tunics. Later references flesh out the story with more details. According to the retelling of the story found in the poem "Metamorphoses" by the Roman poet Ovid (43 BC – 17/18 AD), Adonis was the son of Myrrha, who was cursed by Aphrodite with insatiable lust for her own father, King Cinyras of Cyprus, after Myrrha's mother bragged that her daughter was more beautiful than the goddess. Driven out after becoming pregnant, Myrrha was changed into a myrrh tree, but still gave birth to Adonis.

Aphrodite found the baby, and took him to the underworld to be fostered by Persephone. She returned for him once he was grown and discovered him to be strikingly handsome. Persephone wanted to keep Adonis, resulting in a custody battle between the two goddesses over whom should rightly possess Adonis. Zeus settled the dispute by decreeing that Adonis would spend one third of the year with Aphrodite, one third with Persephone, and one third with whomever he chose. Adonis chose to spend that time with Aphrodite. Then, one day, while Adonis was hunting, he was wounded by a wild boar and bled to death in Aphrodite's arms.

In different versions of the story, the boar was either sent by Ares, who was jealous that Aphrodite was spending so much time with Adonis, or by Artemis, who wanted revenge against Aphrodite for having killed her devoted follower Hippolytus. The story also provides an etiology for Aphrodite's associations with certain flowers. Reportedly, as she mourned Adonis's death, she caused anemones to grow wherever his blood fell, and declared a festival on the anniversary of his death. In one version of the story, Aphrodite injured herself on a thorn from a rose bush and the rose, which had previously been white, was stained red by her blood. According to Lucian's "On the Syrian Goddess", each year during the festival of Adonis, the Adonis River in Lebanon (now known as the Abraham River) ran red with blood.

The myth of Adonis is associated with the festival of the Adonia, which was celebrated by Greek women every year in midsummer. The festival, which was evidently already celebrated in Lesbos by Sappho's time, seems to have first become popular in Athens in the mid-fifth century BC. At the start of the festival, the women would plant a "garden of Adonis", a small garden planted inside a small basket or a shallow piece of broken pottery containing a variety of quick-growing plants, such as lettuce and fennel, or even quick-sprouting grains such as wheat and barley. The women would then climb ladders to the roofs of their houses, where they would place the gardens out under the heat of the summer sun. The plants would sprout in the sunlight, but wither quickly in the heat. Then the women would mourn and lament loudly over the death of Adonis, tearing their clothes and beating their breasts in a public display of grief.

In Hesiod's "Works and Days", Zeus orders Aphrodite to make Pandora, the first woman, physically beautiful and sexually attractive, so that she may become "an evil men will love to embrace". Aphrodite "spills grace" over Pandora's head and equips her with "painful desire and knee-weakening anguish", thus making her the perfect vessel for evil to enter the world. Aphrodite's attendants, Peitho, the Charites, and the Horae, adorn Pandora with gold and jewelry.

According to one myth, Aphrodite aided Hippomenes, a noble youth who wished to marry Atalanta, a maiden who was renowned throughout the land for her beauty, but who refused to marry any man unless he could outrun her in a footrace. Atalanta was an exceedingly swift runner and she beheaded all of the men who lost to her. Aphrodite gave Hippomenes three golden apples from the Garden of the Hesperides and instructed him to toss them in front of Atalanta as he raced her. Hippomenes obeyed Aphrodite's order and Atalanta, seeing the beautiful, golden fruits, bent down to pick up each one, allowing Hippomenes to outrun her. In the version of the story from Ovid's "Metamorphoses", Hippomenes forgets to repay Aphrodite for her aid, so she causes the couple to become inflamed with lust while they are staying at the temple of Cybele. The couple desecrate the temple by having sex in it, leading Cybele to turn them into lions as punishment.

The myth of Pygmalion is first mentioned by the third-century BC Greek writer Philostephanus of Cyrene, but is first recounted in detail in Ovid's "Metamorphoses". According to Ovid, Pygmalion was an exceedingly handsome sculptor from the island of Cyprus, who was so sickened by the immorality of women that he refused to marry. He fell madly and passionately in love with the ivory cult statue he was carving of Aphrodite and longed to marry it. Because Pygmalion was extremely pious and devoted to Aphrodite, the goddess brought the statue to life. Pygmalion married the girl the statue became and they had a son named Paphos, after whom the capital of Cyprus received its name. Pseudo-Apollodorus later mentions "Metharme, daughter of Pygmalion, king of Cyprus".

Aphrodite generously rewarded those who honored her, but also punished those who disrespected her, often quite brutally. A myth described in Apollonius of Rhodes's "Argonautica" and later summarized in the "Bibliotheca" of Pseudo-Apollodorus tells how, when the women of the island of Lemnos refused to sacrifice to Aphrodite, the goddess cursed them to stink horribly so that their husbands would never have sex with them. Instead, their husbands started having sex with their Thracian slave-girls. In anger, the women of Lemnos murdered the entire male population of the island, as well as all the Thracian slaves. When Jason and his crew of Argonauts arrived on Lemnos, they mated with the sex-starved women under Aphrodite's approval and repopulated the island. From then on, the women of Lemnos never disrespected Aphrodite again.

In Euripides's tragedy "Hippolytus", which was first performed at the City Dionysia in 428 BC, Theseus's son Hippolytus worships only Artemis, the goddess of virginity, and refuses to engage in any form of sexual contact. Aphrodite is infuriated by his prideful behavior and, in the prologue to the play, she declares that, by honoring only Artemis and refusing to venerate her, Hippolytus has directly challenged her authority. Aphrodite therefore causes Hippolytus's stepmother, Phaedra, to fall in love with him, knowing Hippolytus will reject her. After being rejected, Phaedra commits suicide and leaves a suicide note to Theseus telling him that she killed herself because Hippolytus attempted to rape her. Theseus prays to Poseidon to kill Hippolytus for his transgression. Poseidon sends a wild bull to scare Hippolytus's horses as he is riding by the sea in his chariot, causing the horses to bolt and smash the chariot against the cliffs, dragging Hippolytus to a bloody death across the rocky shoreline. The play concludes with Artemis vowing to kill Aphrodite's own mortal beloved (presumably Adonis) in revenge.

Glaucus of Corinth angered Aphrodite by refusing to let his horses for chariot racing mate, since doing so would hinder their speed. During the chariot race at the funeral games of King Pelias, Aphrodite drove his horses mad and they tore him apart. Polyphonte was a young woman who chose a virginal life with Artemis instead of marriage and children, as favoured by Aphrodite. Aphrodite cursed her, causing her to have children by a bear. The resulting offspring, Agrius and Oreius, were wild cannibals who incurred the hatred of Zeus. Ultimately, he transformed all the members of the family into birds of ill omen.

The myth of the Judgement of Paris is mentioned briefly in the "Iliad", but is described in depth in an epitome of the "Cypria", a lost poem of the Epic Cycle, which records that all the gods and goddesses as well as various mortals were invited to the marriage of Peleus and Thetis (the eventual parents of Achilles). Only Eris, goddess of discord, was not invited. She was annoyed at this, so she arrived with a golden apple inscribed with the word καλλίστῃ (kallistēi, "for the fairest"), which she threw among the goddesses. Aphrodite, Hera, and Athena all claimed to be the fairest, and thus the rightful owner of the apple.

The goddesses chose to place the matter before Zeus, who, not wanting to favor one of the goddesses, put the choice into the hands of Paris, a Trojan prince. After bathing in the spring of Mount Ida where Troy was situated, the goddesses appeared before Paris for his decision. In the extant ancient depictions of the Judgement of Paris, Aphrodite is only occasionally represented nude, and Athena and Hera are always fully clothed. Since the Renaissance, however, Western paintings have typically portrayed all three goddesses as completely naked.

All three goddesses were ideally beautiful and Paris could not decide between them, so they resorted to bribes. Hera tried to bribe Paris with power over all Asia and Europe, and Athena offered wisdom, fame and glory in battle, but Aphrodite promised Paris that, if he were to choose her as the fairest, she would let him marry the most beautiful woman on earth. This woman was Helen, who was already married to King Menelaus of Sparta. Paris selected Aphrodite and awarded her the apple. The other two goddesses were enraged and, as a direct result, sided with the Greeks in the Trojan War.

Aphrodite plays an important and active role throughout the entirety of Homer's "Iliad". In Book III, she rescues Paris from Menelaus after he foolishly challenges him to a one-on-one duel. She then appears to Helen in the form of an old woman and attempts to persuade her to have sex with Paris, reminding her of his physical beauty and athletic prowess. Helen immediately recognizes Aphrodite by her beautiful neck, perfect breasts, and flashing eyes and chides the goddess, addressing her as her equal. Aphrodite sharply rebukes Helen, reminding her that, if she vexes her, she will punish her just as much as she has favored her already. Helen demurely obeys Aphrodite's command.

In Book V, Aphrodite charges into battle to rescue her son Aeneas from the Greek hero Diomedes. Diomedes recognizes Aphrodite as a "weakling" goddess and, thrusting his spear, nicks her wrist through her "ambrosial robe". Aphrodite borrows Ares's chariot to ride back to Mount Olympus. Zeus chides her for putting herself in danger, reminding her that "her specialty is love, not war." According to Walter Burkert, this scene directly parallels a scene from Tablet VI of the "Epic of Gilgamesh" in which Ishtar, Aphrodite's Akkadian precursor, cries to her mother Antu after the hero Gilgamesh rejects her sexual advances, but is mildly rebuked by her father Anu. In Book XIV of the "Iliad", during the "Dios Apate" episode, Aphrodite lends her "kestos himas" to Hera for the purpose of seducing Zeus and distracting him from the combat while Poseidon aids the Greek forces on the beach. In the "Theomachia" in Book XXI, Aphrodite again enters the battlefield to carry Ares away after he is wounded.

Aphrodite's most prominent avian symbol was the dove, which was originally an important symbol of her Near Eastern precursor Inanna-Ishtar. (In fact, the ancient Greek word for "dove", "peristerá", may be derived from a Semitic phrase "peraḥ Ištar", meaning "bird of Ishtar".) Aphrodite frequently appears with doves in ancient Greek pottery and the temple of Aphrodite Pandemos on the southwest slope of the Athenian Acropolis was decorated with relief sculptures of doves with knotted fillets in their beaks. Votive offerings of small, white, marble doves were also discovered in the temple of Aphrodite at Daphni. In addition to her associations with doves, Aphrodite was also closely linked with sparrows and she is described riding in a chariot pulled by sparrows in Sappho's "Ode to Aphrodite".

Because of her connections to the sea, Aphrodite was associated with a number of different types of water fowl, including swans, geese, and ducks. Aphrodite's other symbols included the sea, conch shells, and roses. The rose and myrtle flowers were both sacred to Aphrodite. Her most important fruit emblem was the apple, but she was also associated with pomegranates, possibly because the red seeds suggested sexuality or because Greek women sometimes used pomegranates as a method of birth control. In Greek art, Aphrodite is often also accompanied by dolphins and Nereids.

A scene of Aphrodite rising from the sea appears on the back of the Ludovisi Throne ( 460 BC), which was probably originally part of a massive altar that was constructed as part of the Ionic temple to Aphrodite in the Greek polis of Locri Epizephyrii in Magna Graecia in southern Italy. The throne shows Aphrodite rising from the sea, clad in a diaphanous garment, which is drenched with seawater and clinging to her body, revealing her upturned breasts and the outline of her navel. Her hair hangs dripping as she reaches to two attendants standing barefoot on the rocky shore on either side of her, lifting her out of the water. Scenes with Aphrodite appear in works of classical Greek pottery, including a famous white-ground "kylix" by the Pistoxenos Painter dating the between 470 and 460 BC, showing her riding on a swan or goose.

In BC, the Athenian sculptor Praxiteles carved the marble statue "Aphrodite of Knidos", which Pliny the Elder later praised as the greatest sculpture ever made. The statue showed a nude Aphrodite modestly covering her pubic region while resting against a water pot with her robe draped over it for support. The "Aphrodite of Knidos" was the first full-sized statue to depict Aphrodite completely naked and one of the first sculptures that was intended to be viewed from all sides. The statue was purchased by the people of Knidos in around 350 BC and proved to be tremendously influential on later depictions of Aphrodite. The original sculpture has been lost, but written descriptions of it as well several depictions of it on coins are still extant and over sixty copies, small-scale models, and fragments of it have been identified.

The Greek painter Apelles of Kos, a contemporary of Praxiteles, produced the panel painting "Aphrodite Anadyomene" ("Aphrodite Rising from the Sea"). According to Athenaeus, Apelles was inspired to paint the painting after watching the courtesan Phryne take off her clothes, untie her hair, and bathe naked in the sea at Eleusis. The painting was displayed in the Asclepeion on the island of Kos. The "Aphrodite Anadyomene" went unnoticed for centuries, but Pliny the Elder records that, in his own time, it was regarded as Apelles's most famous work.

During the Hellenistic and Roman periods, statues depicting Aphrodite proliferated; many of these statues were modeled at least to some extent on Praxiteles's "Aphrodite of Knidos". Some statues show Aphrodite crouching naked; others show her wringing water out of her hair as she rises from the sea. Another common type of statue is known as "Aphrodite Kallipygos", the name of which is Greek for "Aphrodite of the Beautiful Buttocks"; this type of sculpture shows Aphrodite lifting her "peplos" to display her buttocks to the viewer while looking back at them from over her shoulder. The ancient Romans produced massive numbers of copies of Greek sculptures of Aphrodite and more sculptures of Aphrodite have survived from antiquity than of any other deity.

Early Christians frequently adapted pagan iconography to suit Christian purposes. In the Early Middle Ages, Christians adapted elements of Aphrodite/Venus's iconography and applied them to Eve and prostitutes, but also female saints and even the Virgin Mary. Christians in the east reinterpreted the story of Aphrodite's birth as a metaphor for baptism; in a Coptic stele from the sixth century AD, a female orant is shown wearing Aphrodite's conch shell as a sign that she is newly baptized. Throughout the Middle Ages, villages and communities across Europe still maintained folk tales and traditions about Aphrodite/Venus and travelers reported a wide variety of stories. Numerous Roman mosaics of Venus survived in Britain, preserving memory of the pagan past. In North Africa in the late fifth century AD, Fulgentius of Ruspe encountered mosaics of Aphrodite and reinterpreted her as a symbol of the sin of Lust, arguing that she was shown naked because "the sin of lust is never cloaked" and that she was often shown "swimming" because "all lust suffers shipwreck of its affairs." He also argued that she was associated with doves and conchs because these are symbols of copulation, and that she was associated with roses because "as the rose gives pleasure, but is swept away by the swift movement of the seasons, so lust is pleasant for a moment, but is swept away forever."

While Fulgentius had appropriated Aphrodite as a symbol of Lust, Isidore of Seville ( 560–636) interpreted her as a symbol of marital procreative sex and declared that the moral of the story of Aphrodite's birth is that sex can only be holy in the presence of semen, blood, and heat, which he regarded as all being necessary for procreation. Meanwhile, Isidore denigrated Aphrodite/Venus's son Eros/Cupid as a "demon of fornication" ("daemon fornicationis"). Aphrodite/Venus was best known to Western European scholars through her appearances in Virgil's "Aeneid" and Ovid's "Metamorphoses". Venus is mentioned in the Latin poem "Pervigilium Veneris" ("The Eve of Saint Venus"), written in the third or fourth century AD, and in Giovanni Boccaccio's "Genealogia Deorum Gentilium".

Since the Late Middle Ages. the myth of the "Venusberg" (German; French "Mont de Vénus", "Mountain of Venus") - a subterranean realm ruled by Venus, hidden underneath Christian Europe - became a motif of European folklore rendered in various legends and epics. In German folklore of the 16th century, the narrative becomes associated with the minnesinger Tannhäuser, and in that form the myth was taken up in later literature and opera.

Aphrodite is the central figure in Sandro Botticelli's painting "Primavera", which has been described as "one of the most written about, and most controversial paintings in the world", and "one of the most popular paintings in Western art". The story of Aphrodite's birth from the foam was a popular subject matter for painters during the Italian Renaissance, who were attempting to consciously reconstruct Apelles of Kos's lost masterpiece "Aphrodite Anadyomene" based on the literary "ekphrasis" of it preserved by Cicero and Pliny the Elder. Artists also drew inspiration from Ovid's description of the birth of Venus in his "Metamorphoses". Sandro Botticelli's "The Birth of Venus" ( 1485) was also partially inspired by a description by Poliziano of a relief on the subject. Later Italian renditions of the same scene include Titian's "Venus Anadyomene" ( 1525) and Raphael's painting in the "Stufetta del cardinal Bibbiena" (1516). Titian's biographer Giorgio Vasari identified all of Titian's paintings of naked women as paintings of "Venus", including an erotic painting from 1534, which he called the "Venus of Urbino", even though the painting does not contain any of Aphrodite/Venus's traditional iconography and the woman in it is clearly shown in a contemporary setting, not a classical one.
Jacques-Louis David's final work was his 1824 "magnum opus", "Mars Being Disarmed by Venus", which combines elements of classical, Renaissance, traditional French art, and contemporary artistic styles. While he was working on the painting, David described it, saying, "This is the last picture I want to paint, but I want to surpass myself in it. I will put the date of my seventy-five years on it and afterwards I will never again pick up my brush." The painting was exhibited first in Brussels and then in Paris, where over 10,000 people came to see it. Jean-Auguste-Dominique Ingres's painting "Venus Anadyomene" was one of his major works. Louis Geofroy described it as a "dream of youth realized with the power of maturity, a happiness that few obtain, artists or others." Théophile Gautier declared: "Nothing remains of the marvelous painting of the Greeks, but surely if anything could give the idea of antique painting as it was conceived following the statues of Phidias and the poems of Homer, it is M. Ingres's painting: the "Venus Anadyomene" of Apelles has been found." Other critics dismissed it as a piece of unimaginative, sentimental kitsch, but Ingres himself considered it to be among his greatest works and used the same figure as the model for his later 1856 painting "La Source".

Paintings of Venus were favorites of the late nineteenth-century Academic artists in France. In 1863, Alexandre Cabanel won widespread critical acclaim at the Paris Salon for his painting "The Birth of Venus", which the French emperor Napoleon III immediately purchased for his own personal art collection. Édouard Manet's 1865 painting "Olympia" parodied the nude Venuses of the Academic painters, particularly Cabanel's "Birth of Venus". In 1867, the English Academic painter Frederic Leighton displayed his "Venus Disrobing for the Bath" at the Academy. The art critic J. B. Atkinson praised it, declaring that "Mr Leighton, instead of adopting corrupt Roman notions regarding Venus such as Rubens embodied, has wisely reverted to the Greek idea of Aphrodite, a goddess worshipped, and by artists painted, as the perfection of female grace and beauty." A year later, the English painter Dante Gabriel Rossetti, a founding member of the Pre-Raphaelite Brotherhood, painted "Venus Verticordia" (Latin for "Aphrodite, the Changer of Hearts"), showing Aphrodite as a nude red-headed woman in a garden of roses. Though he was reproached for his "outré" subject matter, Rossetti refused to alter the painting and it was soon purchased by J. Mitchell of Bradford. In 1879, William Adolphe Bouguereau exhibited at the Paris Salon his own "Birth of Venus", which imitated the classical tradition of "contrapposto" and was met with widespread critical acclaim, rivalling the popularity of Cabanel's version from nearly two decades prior.
William Shakespeare's erotic narrative poem "Venus and Adonis" (1593), a retelling of the courtship of Aphrodite and Adonis from Ovid's "Metamorphoses", was the most popular of all his works published within his own lifetime. Six editions of it were published before Shakespeare's death (more than any of his other works) and it enjoyed particularly strong popularity among young adults. In 1605, Richard Barnfield lauded it, declaring that the poem had placed Shakespeare's name "in fames immortall Booke". Despite this, the poem has received mixed reception from modern critics; Samuel Taylor Coleridge defended it, but Samuel Butler complained that it bored him and C. S. Lewis described an attempted reading of it as "suffocating".

Aphrodite appears in Richard Garnett's short story collection "The Twilight of the Gods and Other Tales" (1888), in which the gods' temples have been destroyed by Christians. Stories revolving around sculptures of Aphrodite were common in the late nineteenth and early twentieth centuries. Examples of such works of literature include the novel "The Tinted Venus: A Farcical Romance" (1885) by Thomas Anstey Guthrie and the short story "The Venus of Ille" (1887) by Prosper Mérimée, both of which are about statues of Aphrodite that come to life. Another noteworthy example is "Aphrodite in Aulis" by the Anglo-Irish writer George Moore, which revolves around an ancient Greek family who moves to Aulis. The French writer Pierre Louÿs titled his erotic historical novel "" (1896) after the Greek goddess. The novel enjoyed widespread commercial success, but scandalized French audiences due to its sensuality and its decadent portrayal of Greek society.

In the early twentieth century, stories of Aphrodite were used by feminist poets, such as Amy Lowell and Alicia Ostriker. Many of these poems dealt with Aphrodite's legendary birth from the foam of the sea. Other feminist writers, including Claude Cahun, Thit Jensen, and Anaïs Nin also made use of the myth of Aphrodite in their writings. Ever since the publication of Isabel Allende's book "Aphrodite: A Memoir of the Senses" in 1998, the name "Aphrodite" has been used as a title for dozens of books dealing with all topics even superficially connected to her domain. Frequently these books do not even mention Aphrodite, or mention her only briefly, but make use of her name as a selling point.

In 1938, Gleb Botkin, a Russian immigrant to the United States, founded the Church of Aphrodite, a neopagan religion centered around the worship of a mother goddess, whom its practitioners identified as Aphrodite. The Church of Aphrodite's theology was laid out in the book "In Search of Reality", published in 1969, two years before Botkin's death. The book portrayed Aphrodite in a drastically different light than the one in which the Greeks envisioned her, instead casting her as "the sole Goddess of a somewhat Neoplatonic Pagan monotheism". It claimed that the worship of Aphrodite had been brought to Greece by the mystic teacher Orpheus, but that the Greeks had misunderstood Orpheus's teachings and had not realized the importance of worshipping Aphrodite alone.

Aphrodite is a major deity in Wicca, a contemporary nature-based syncretic Neopagan religion. Wiccans regard Aphrodite as one aspect of the Goddess and she is frequently invoked by name during enchantments dealing with love and romance. Wiccans regard Aphrodite as the ruler of human emotions, erotic spirituality, creativity, and art. As one of the twelve Olympians, Aphrodite is a major deity within Hellenismos (Hellenic Polytheistic Reconstructionism), a Neopagan religion which seeks to authentically revive and recreate the religion of ancient Greece in the modern world. Unlike Wiccans, Hellenists are usually strictly polytheistic or pantheistic. Hellenists venerate Aphrodite primarily as the goddess of romantic love, but also as a goddess of sexuality, the sea, and war. Her many epithets include "Sea Born", "Killer of Men", "She upon the Graves", "Fair Sailing", and "Ally in War".




</doc>
<doc id="1175" url="https://en.wikipedia.org/wiki?curid=1175" title="April 1">
April 1

It is the first day of the second quarter of the year, and the midway point of the first half of the year.





</doc>
<doc id="1176" url="https://en.wikipedia.org/wiki?curid=1176" title="Antisymmetric relation">
Antisymmetric relation

In mathematics, a homogeneous relation "R" on set "X" is antisymmetric if there is no pair of "distinct" elements of "X" each of which is related by "R" to the other. More formally, "R" is antisymmetric precisely if for all "a" and "b" in "X"
or, equivalently,

The divisibility relation on the natural numbers is an important example of an antisymmetric relation. In this context, antisymmetry means that the only way each of two numbers can be divisible by the other is if the two are, in fact, the same number; equivalently, if "n" and "m" are distinct and "n" is a factor of "m", then "m" cannot be a factor of "n". For example, 12 is divisible by 4, but 4 is not divisible by 12.

The usual order relation ≤ on the real numbers is antisymmetric: if for two real numbers "x" and "y" both inequalities "x" ≤ "y" and "y" ≤ "x" hold then "x" and "y" must be equal. Similarly, the subset order ⊆ on the subsets of any given set is antisymmetric: given two sets "A" and "B", if every element in "A" also is in "B" and every element in "B" is also in "A", then "A" and "B" must contain all the same elements and therefore be equal:
A real-life example of a relation that is typically antisymmetric is "paid the restaurant bill of" (understood as restricted to a given occasion). Typically some people pay their own bills, while others pay for their spouses or friends. As long as no two people pay each other's bills, the relation is antisymmetric.

Partial and total orders are antisymmetric by definition. A relation can be both symmetric and antisymmetric (in this case, it must be coreflexive), and there are relations which are neither symmetric nor antisymmetric (e.g., the "preys on" relation on biological species).

Antisymmetry is different from asymmetry: a relation is asymmetric if, and only if, it is antisymmetric and irreflexive.




</doc>
<doc id="1177" url="https://en.wikipedia.org/wiki?curid=1177" title="Aleister Crowley">
Aleister Crowley

Aleister Crowley (; born Edward Alexander Crowley; 12 October 1875 – 1 December 1947) was an English occultist, ceremonial magician, poet, painter, novelist, and mountaineer. He founded the religion of Thelema, identifying himself as the prophet entrusted with guiding humanity into the Æon of Horus in the early 20th century. A prolific writer, he published widely over the course of his life.

Born to a wealthy family in Royal Leamington Spa, Warwickshire, Crowley rejected his parents' fundamentalist Christian Plymouth Brethren faith to pursue an interest in Western esotericism. He was educated at Trinity College at the University of Cambridge, where he focused his attentions on mountaineering and poetry, resulting in several publications. Some biographers allege that here he was recruited into a British intelligence agency, further suggesting that he remained a spy throughout his life. In 1898 he joined the esoteric Hermetic Order of the Golden Dawn, where he was trained in ceremonial magic by Samuel Liddell MacGregor Mathers and Allan Bennett. Moving to Boleskine House by Loch Ness in Scotland, he went mountaineering in Mexico with Oscar Eckenstein, before studying Hindu and Buddhist practices in India. He married Rose Edith Kelly and in 1904 they honeymooned in Cairo, Egypt, where Crowley claimed to have been contacted by a supernatural entity named Aiwass, who provided him with "The Book of the Law", a sacred text that served as the basis for Thelema. Announcing the start of the Æon of Horus, "The Book" declared that its followers should "Do what thou wilt" and seek to align themselves with their True Will through the practice of magick.

After an unsuccessful attempt to climb Kanchenjunga and a visit to India and China, Crowley returned to Britain, where he attracted attention as a prolific author of poetry, novels, and occult literature. In 1907, he and George Cecil Jones co-founded an esoteric order, the A∴A∴, through which they propagated Thelema. After spending time in Algeria, in 1912 he was initiated into another esoteric order, the German-based Ordo Templi Orientis (O.T.O.), rising to become the leader of its British branch, which he reformulated in accordance with his Thelemite beliefs. Through the O.T.O., Thelemite groups were established in Britain, Australia, and North America. Crowley spent the First World War in the United States, where he took up painting and campaigned for the German war effort against Britain, later revealing that he had infiltrated the pro-German movement to assist the British intelligence services. In 1920 he established the Abbey of Thelema, a religious commune in Cefalù, Sicily where he lived with various followers. His libertine lifestyle led to denunciations in the British press, and the Italian government evicted him in 1923. He divided the following two decades between France, Germany, and England, and continued to promote Thelema until his death.

Crowley gained widespread notoriety during his lifetime, being a recreational drug experimenter, bisexual, and an individualist social critic. Crowley has remained a highly influential figure over Western esotericism and the counterculture, and continues to be considered a prophet in Thelema. He is the subject of various biographies and academic studies.

Crowley was born as Edward Alexander Crowley at 30 Clarendon Square in Royal Leamington Spa, Warwickshire, on 12 October 1875. His father, Edward Crowley (1829–1887), was trained as an engineer, but his share in a lucrative family brewing business, Crowley's Alton Ales, had allowed him to retire before his son was born. His mother, Emily Bertha Bishop (1848–1917), came from a Devonshire-Somerset family and had a strained relationship with her son; she described him as "the Beast", a name that he revelled in. The couple had been married at London's Kensington Registry Office in November 1874, and were evangelical Christians. Crowley's father had been born a Quaker, but had converted to the Exclusive Brethren, a faction of a Christian fundamentalist group known as the Plymouth Brethren, with Emily joining him upon marriage. Crowley's father was particularly devout, spending his time as a travelling preacher for the sect and reading a chapter from the Bible to his wife and son after breakfast every day. Following the death of their baby daughter in 1880, in 1881 the Crowleys moved to Redhill, Surrey. At the age of 8, Crowley was sent to H.T. Habershon's evangelical Christian boarding school in Hastings, and then to Ebor preparatory school in Cambridge, run by the Reverend Henry d'Arcy Champney, whom Crowley considered a sadist.

In March 1887, when Crowley was 11, his father died of tongue cancer. Crowley described this as a turning point in his life, and he always maintained an admiration of his father, describing him as "my hero and my friend". Inheriting a third of his father's wealth, he began misbehaving at school and was harshly punished by Champney; Crowley's family removed him from the school when he developed albuminuria. He then attended Malvern College and Tonbridge School, both of which he despised and left after a few terms. He became increasingly sceptical regarding Christianity, pointing out inconsistencies in the Bible to his religious teachers, and went against the Christian morality of his upbringing by smoking, masturbating, and having sex with prostitutes from whom he contracted gonorrhea. Sent to live with a Brethren tutor in Eastbourne, he undertook chemistry courses at Eastbourne College. Crowley developed interests in chess, poetry, and mountain climbing, and in 1894 climbed Beachy Head before visiting the Alps and joining the Scottish Mountaineering Club. The following year he returned to the Bernese Alps, climbing the Eiger, Trift, Jungfrau, Mönch, and Wetterhorn.

Having adopted the name of Aleister over Edward, in October 1895 Crowley began a three-year course at Trinity College, Cambridge, where he was entered for the Moral Science Tripos studying philosophy. With approval from his personal tutor, he changed to English literature, which was not then part of the curriculum offered. Crowley spent much of his time at university engaged in his pastimes, becoming president of the chess club and practising the game for two hours a day; he briefly considered a professional career as a chess player. Crowley also embraced his love of literature and poetry, particularly the works of Richard Francis Burton and Percy Bysshe Shelley. Many of his own poems appeared in student publications such as "The Granta", "Cambridge Magazine", and "Cantab". He continued his mountaineering, going on holiday to the Alps to climb every year from 1894 to 1898, often with his friend Oscar Eckenstein, and in 1897 he made the first ascent of the Mönch without a guide. These feats led to his recognition in the Alpine mountaineering community.

Crowley had his first significant mystical experience while on holiday in Stockholm in December 1896. Several biographers, including Lawrence Sutin, Richard Kaczynski, and Tobias Churton, believed that this was the result of Crowley's first same-sex sexual experience, which enabled him to recognise his bisexuality. At Cambridge, Crowley maintained a vigorous sex life with women—largely with female prostitutes, from one of whom he caught syphilis—but eventually he took part in same-sex activities, despite their illegality. In October 1897, Crowley met Herbert Charles Pollitt, president of the Cambridge University Footlights Dramatic Club, and the two entered into a relationship. They broke apart because Pollitt did not share Crowley's increasing interest in Western esotericism, a break-up that Crowley would regret for many years.

In 1897, Crowley travelled to Saint Petersburg in Russia, later claiming that he was trying to learn Russian as he was considering a future diplomatic career there.

In October 1897, a brief illness triggered considerations of mortality and "the futility of all human endeavour", and Crowley abandoned all thoughts of a diplomatic career in favour of pursuing an interest in the occult. In March 1898, he obtained A.E. Waite's "The Book of Black Magic and of Pacts", and then Karl von Eckartshausen's "The Cloud Upon the Sanctuary", furthering his occult interests.
In 1898 Crowley privately published 100 copies of his poem "Aceldama: A Place to Bury Strangers In", but it was not a particular success. That same year he published a string of other poems, including "White Stains", a Decadent collection of erotic poetry that was printed abroad lest its publication be prohibited by the British authorities. In July 1898, he left Cambridge, not having taken any degree at all despite a "first class" showing in his 1897 exams and consistent "second class honours" results before that.

In August 1898, Crowley was in Zermatt, Switzerland, where he met the chemist Julian L. Baker, and the two began discussing their common interest in alchemy. Back in London, Baker introduced Crowley to George Cecil Jones, Baker's brother in-law, and a fellow member of the occult society known as the Hermetic Order of the Golden Dawn, which had been founded in 1888. Crowley was initiated into the Outer Order of the Golden Dawn on 18 November 1898 by the group's leader, Samuel Liddell MacGregor Mathers. The ceremony took place in the Golden Dawn's Isis-Urania Temple held at London's Mark Masons Hall, where Crowley took the magical motto and name "Frater Perdurabo", which he interpreted as "I shall endure to the end".

Crowley moved into his own luxury flat at 67–69 Chancery Lane and soon invited a senior Golden Dawn member, Allan Bennett, to live with him as his personal magical tutor. Bennett taught Crowley more about ceremonial magic and the ritual use of drugs, and together they performed the rituals of the "Goetia", until Bennett left for South Asia to study Buddhism. In November 1899, Crowley purchased Boleskine House in Foyers on the shore of Loch Ness in Scotland. He developed a love of Scottish culture, describing himself as the "Laird of Boleskine", and took to wearing traditional highland dress, even during visits to London. He continued writing poetry, publishing "Jezebel and Other Tragic Poems", "Tales of Archais", "Songs of the Spirit", "Appeal to the American Republic", and "Jephthah" in 1898–99; most gained mixed reviews from literary critics, although "Jephthah" was considered a particular critical success.

Crowley soon progressed through the lower grades of the Golden Dawn, and was ready to enter the group's inner Second Order. He was unpopular in the group; his bisexuality and libertine lifestyle had gained him a bad reputation, and he had developed feuds with some of the members, including W. B. Yeats. When the Golden Dawn's London lodge refused to initiate Crowley into the Second Order, he visited Mathers in Paris, who personally admitted him into the Adeptus Minor Grade. A schism had developed between Mathers and the London members of the Golden Dawn, who were unhappy with his autocratic rule. Acting under Mathers' orders, Crowley—with the help of his mistress and fellow initiate Elaine Simpson—attempted to seize the Vault of the Adepts, a temple space at 36 Blythe Road in West Kensington, from the London lodge members. When the case was taken to court, the judge ruled in favour of the London lodge, as they had paid for the space's rent, leaving both Crowley and Mathers isolated from the group.

In 1900, Crowley travelled to Mexico via the United States, settling in Mexico City and starting a relationship with a local woman. Developing a love of the country, he continued experimenting with ceremonial magic, working with John Dee's Enochian invocations. He later claimed to have been initiated into Freemasonry while there, and he wrote a play based on Richard Wagner's "Tannhäuser" as well as a series of poems, published as "Oracles" (1905). Eckenstein joined him later that year, and together they climbed several mountains, including Iztaccihuatl, Popocatepetl, and Colima, the latter of which they had to abandon owing to a volcanic eruption. Leaving Mexico, Crowley headed to San Francisco before sailing for Hawaii aboard the "Nippon Maru". On the ship he had a brief affair with a married woman named Mary Alice Rogers; saying he had fallen in love with her, he wrote a series of poems about the romance, published as "Alice: An Adultery" (1903).
Briefly stopping in Japan and Hong Kong, Crowley reached Ceylon, where he met with Allan Bennett, who was there studying Shaivism. The pair spent some time in Kandy before Bennett decided to become a Buddhist monk in the Theravada tradition, travelling to Burma to do so. Crowley decided to tour India, devoting himself to the Hindu practice of "Rāja yoga", from which he claimed to have achieved the spiritual state of "dhyana". He spent much of this time studying at the Meenakshi Temple in Madura. At this time he also composed and also wrote poetry which was published as "The Sword of Song" (1904). He contracted malaria, and had to recuperate from the disease in Calcutta and Rangoon. In 1902, he was joined in India by Eckenstein and several other mountaineers: Guy Knowles, H. Pfannl, V. Wesseley, and Jules Jacot-Guillarmod. Together the Eckenstein-Crowley expedition attempted K2, which had never been climbed. On the journey, Crowley was afflicted with influenza, malaria, and snow blindness, and other expedition members were also struck with illness. They reached an altitude of before turning back.

Having arrived in Paris in November 1902 he socialised with friend and future brother-in-law, the painter Gerald Kelly, and through him became a fixture of the Parisian arts scene. Whilst there, Crowley wrote a series of poems on the work of an acquaintance, the sculptor Auguste Rodin. These poems were later published as "Rodin in Rime" (1907). One of those frequenting this milieu was W. Somerset Maugham, who after briefly meeting Crowley later used him as a model for the character of Oliver Haddo in his novel "The Magician" (1908). Returning to Boleskine in April 1903, in August Crowley wed Gerald's sister Rose Edith Kelly in a "marriage of convenience" to prevent her entering an arranged marriage; the marriage appalled the Kelly family and damaged his friendship with Gerald. Heading on a honeymoon to Paris, Cairo, and then Ceylon, Crowley fell in love with Rose and worked to prove his affections. While on his honeymoon, he wrote her a series of love poems, published as "Rosa Mundi and other Love Songs" (1906), as well as authoring the religious satire "Why Jesus Wept" (1904).

In February 1904, Crowley and Rose arrived in Cairo. Claiming to be a prince and princess, they rented an apartment in which Crowley set up a temple room and began invoking ancient Egyptian deities, while studying Islamic mysticism and Arabic. According to Crowley's later account, Rose regularly became delirious and informed him "they are waiting for you." On 18 March, she explained that "they" were the god Horus, and on 20 March proclaimed that "the Equinox of the Gods has come". She led him to a nearby museum, where she showed him a seventh-century BCE mortuary stele known as the Stele of Ankh-ef-en-Khonsu; Crowley thought it important that the exhibit's number was 666, the Number of the Beast in Christian belief, and in later years termed the artefact the "Stele of Revealing."

According to Crowley's later statements, on 8 April he heard a disembodied voice that claimed to be that of Aiwass, the messenger of Horus, or Hoor-Paar-Kraat. Crowley said that he wrote down everything the voice told him over the course of the next three days, and titled it "Liber AL vel Legis" or "The Book of the Law". The book proclaimed that humanity was entering a new Aeon, and that Crowley would serve as its prophet. It stated that a supreme moral law was to be introduced in this Aeon, "Do what thou wilt shall be the whole of the Law," and that people should learn to live in tune with their Will. This book, and the philosophy that it espoused, became the cornerstone of Crowley's religion, Thelema. Crowley said that at the time he had been unsure what to do with "The Book of the Law". Often resenting it, he said that he ignored the instructions which the text commanded him to perform, which included taking the Stele of Revealing from the museum, fortifying his own island, and translating the book into all the world's languages. According to his account, he instead sent typescripts of the work to several occultists he knew, putting the manuscript away and ignoring it.

Returning to Boleskine, Crowley came to believe that Mathers had begun using magic against him, and the relationship between the two broke down. On 28 July 1905, Rose gave birth to Crowley's first child, a daughter named Lilith, with Crowley writing the pornographic "Snowdrops From a Curate's Garden" to entertain his recuperating wife. He also founded a publishing company through which to publish his poetry, naming it the Society for the Propagation of Religious Truth in parody of the Society for Promoting Christian Knowledge. Among its first publications were Crowley's "Collected Works", edited by Ivor Back. His poetry often received strong reviews (either positive or negative), but never sold well. In an attempt to gain more publicity, he issued a reward of £100 for the best essay on his work. The winner of this was J. F. C. Fuller, a British Army officer and military historian, whose essay, "The Star in the West" (1907), heralded Crowley's poetry as some of the greatest ever written.

Crowley decided to climb Kanchenjunga in the Himalayas of Nepal, widely recognised as the world's most treacherous mountain. Assembling a team consisting of Jacot-Guillarmod, Charles Adolphe Reymond, Alexis Pache, and Alcesti C. Rigo de Righi, the expedition was marred by much argument between Crowley and the others, who thought that he was reckless. They eventually mutinied against Crowley's control, with the other climbers heading back down the mountain as nightfall approached despite Crowley's warnings that it was too dangerous. Subsequently, Pache and several porters were killed in an accident, something for which Crowley was widely blamed by the mountaineering community.

Spending time in Moharbhanj, where he took part in big-game hunting and wrote the homoerotic work "The Scented Garden", Crowley met up with Rose and Lilith in Calcutta before being forced to leave India after non-lethally shooting two men who tried to mug him. Briefly visiting Bennett in Burma, Crowley and his family decided to tour Southern China, hiring porters and a nanny for the purpose. Crowley smoked opium throughout the journey, which took the family from Tengyueh through to Yungchang, Tali, Yunnanfu, and then Hanoi. On the way he spent much time on spiritual and magical work, reciting the "Bornless Ritual", an invocation to his Holy Guardian Angel, on a daily basis.

While Rose and Lilith returned to Europe, Crowley headed to Shanghai to meet old friend Elaine Simpson, who was fascinated by "The Book of the Law"; together they performed rituals in an attempt to contact Aiwass. Crowley then sailed to Japan and Canada, before continuing to New York City, where he unsuccessfully solicited support for a second expedition up Kanchenjunga. Upon arrival in Britain, Crowley learned that his daughter Lilith had died of typhoid in Rangoon, something he later blamed on Rose's increasing alcoholism. Under emotional distress, his health began to suffer, and he underwent a series of surgical operations. He began short-lived romances with actress Vera "Lola" Neville (née Snepp) and author Ada Leverson, while Rose gave birth to Crowley's second daughter, Lola Zaza, in February 1907.

With his old mentor George Cecil Jones, Crowley continued performing the Abramelin rituals at the Ashdown Park Hotel in Coulsdon, Surrey. Crowley claimed that in doing so he attained "samadhi", or union with Godhead, thereby marking a turning point in his life. Making heavy use of hashish during these rituals, he wrote an essay on "The Psychology of Hashish" (1909) in which he championed the drug as an aid to mysticism. He also claimed to have been contacted once again by Aiwass in late October and November 1907, adding that Aiwass dictated two further texts to him, "Liber VII" and "Liber Cordis Cincti Serpente", both of which were later classified in the corpus of The Holy Books of Thelema. Crowley wrote down more Thelemic Holy Books during the last two months of the year, including "Liber LXVI", "Liber Arcanorum", "Liber Porta Lucis, Sub Figura X", "Liber Tau", "Liber Trigrammaton" and "Liber DCCCXIII vel Ararita", which he again claimed to have received from a preternatural source. Crowley stated that in June 1909, when the manuscript of "The Book of the Law" was rediscovered at Boleskine, he developed the opinion that Thelema represented objective truth.

Crowley's inheritance was running out. Trying to earn money, he was hired by George Montagu Bennett, the Earl of Tankerville, to help protect him from witchcraft; recognising Bennett's paranoia as being based in his cocaine addiction, Crowley took him on holiday to France and Morocco to recuperate. In 1907, he also began taking in paying students, whom he instructed in occult and magical practice. Victor Neuburg, whom Crowley met in February 1907, became his sexual partner and closest disciple; in 1908 the pair toured northern Spain before heading to Tangier, Morocco. The following year Neuburg stayed at Boleskine, where he and Crowley engaged in sadomasochism. Crowley continued to write prolifically, producing such works of poetry as "Ambergris", "Clouds Without Water", and "Konx Om Pax", as well as his first attempt at an autobiography, "The World's Tragedy". Recognising the popularity of short horror stories, Crowley wrote his own, some of which were published, and he also published several articles in "Vanity Fair", a magazine edited by his friend Frank Harris. He also wrote "Liber 777", a book of magical and Qabalistic correspondences that borrowed from Mathers and Bennett.

In November 1907, Crowley and Jones decided to found an occult order to act as a successor to the Hermetic Order of the Golden Dawn, being aided in doing so by Fuller. The result was the A∴A∴. The group's headquarters and temple were situated at 124 Victoria Street in central London, and their rites borrowed much from those of the Golden Dawn, but with an added Thelemic basis. Its earliest members included solicitor Richard Noel Warren, artist Austin Osman Spare, Horace Sheridan-Bickers, author George Raffalovich, Francis Henry Everard Joseph Feilding, engineer Herbert Edward Inman, Kenneth Ward, and Charles Stansfeld Jones. In March 1909, Crowley began production of a biannual periodical titled "The Equinox". He billed this periodical, which was to become the "Official Organ" of the A∴A∴, as "The Review of Scientific Illuminism".

Crowley had become increasingly frustrated with Rose's alcoholism, and in November 1909 he divorced her on the grounds of his own adultery. Lola was entrusted to Rose's care; the couple remained friends and Rose continued to live at Boleskine. Her alcoholism worsened, and as a result she was institutionalised in September 1911.

In November 1909, Crowley and Neuburg travelled to Algeria, touring the desert from El Arba to Aumale, Bou Saâda, and then Dā'leh Addin, with Crowley reciting the Quran on a daily basis. During the trip he invoked the thirty aethyrs of Enochian magic, with Neuburg recording the results, later published in "The Equinox" as "The Vision and the Voice". Following a mountaintop sex magic ritual, Crowley also performed an invocation to the demon Choronzon involving blood sacrifice, considering the results to be a watershed in his magical career. Returning to London in January 1910, Crowley found that Mathers was suing him for publishing Golden Dawn secrets in "The Equinox"; the court found in favour of Crowley. The case was widely reported in the press, with Crowley gaining wider fame. Crowley enjoyed this, and played up to the sensationalist stereotype of being a Satanist and advocate of human sacrifice, despite being neither.

The publicity attracted new members to the A∴A∴, among them Frank Bennett, James Bayley, Herbert Close, and James Windram. The Australian violinist Leila Waddell soon became Crowley's lover. Deciding to expand his teachings to a wider audience, Crowley developed the Rites of Artemis, a public performance of magic and symbolism featuring A∴A∴ members personifying various deities. It was first performed at the A∴A∴ headquarters, with attendees given a fruit punch containing peyote to enhance their experience. Various members of the press attended, and reported largely positively on it. In October and November 1910, Crowley decided to stage something similar, the Rites of Eleusis, at Caxton Hall, Westminster; this time press reviews were mixed. Crowley came under particular criticism from West de Wend Fenton, editor of "The Looking Glass" newspaper, who called him "one of the most blasphemous and cold-blooded villains of modern times". Fenton's articles suggested that Crowley and Jones were involved in homosexual activity; Crowley did not mind, but Jones unsuccessfully sued for libel. Fuller broke off his friendship and involvement with Crowley over the scandal, and Crowley and Neuburg returned to Algeria for further magical workings.

"The Equinox" continued publishing, and various books of literature and poetry were also published under its imprint, like Crowley's "Ambergris", "The Winged Beetle", and "The Scented Garden", as well as Neuburg's "The Triumph of Pan" and Ethel Archer's "The Whirlpool". In 1911, Crowley and Waddell holidayed in Montigny-sur-Loing, where he wrote prolifically, producing poems, short stories, plays, and 19 works on magic and mysticism, including the two final Holy Books of Thelema. In Paris, he met Mary Desti, who became his next "Scarlet Woman", with the two undertaking magical workings in St. Moritz; Crowley believed that one of the Secret Chiefs, Ab-ul-Diz, was speaking through her. Based on Desti's statements when in trance, Crowley wrote the two-volume "Book 4" (1912–13) and at the time developed the spelling "magick" in reference to the paranormal phenomenon as a means of distinguishing it from the stage magic of illusionists.

In early 1912, Crowley published "The Book of Lies", a work of mysticism that biographer Lawrence Sutin described as "his greatest success in merging his talents as poet, scholar, and magus". The German occultist Theodor Reuss later accused him of publishing some of the secrets of his own occult order, the Ordo Templi Orientis (O.T.O.), within "The Book". Crowley convinced Reuss that the similarities were coincidental, and the two became friends. Reuss appointed Crowley as head of the O.T.O's British branch, the Mysteria Mystica Maxima (MMM), and at a ceremony in Berlin Crowley adopted the magical name of Baphomet and was proclaimed "X° Supreme Rex and Sovereign Grand Master General of Ireland, Iona, and all the Britons". With Reuss' permission, Crowley set about advertising the MMM and re-writing many O.T.O. rituals, which were then based largely on Freemasonry; his incorporation of Thelemite elements proved controversial in the group. Fascinated by the O.T.O's emphasis on sex magic, Crowley devised a magical working based on anal sex and incorporated it into the syllabus for those O.T.O. members who had been initiated into the eleventh degree.

In March 1913 Crowley acted as producer for "The Ragged Ragtime Girls", a group of female violinists led by Waddell, as they performed at London's Old Tivoli theatre. They subsequently performed in Moscow for six weeks, where Crowley had a sadomasochistic relationship with the Hungarian Anny Ringler. In Moscow, Crowley continued to write plays and poetry, including "Hymn to Pan", and the Gnostic Mass, a Thelemic ritual that became a key part of O.T.O. liturgy. Churton suggested that Crowley had travelled to Moscow on the orders of British intelligence to spy on revolutionary elements in the city. In January 1914 Crowley and Neuburg settled into an apartment in Paris, where the former was involved in the controversy surrounding Jacob Epstein's new monument to Oscar Wilde. Together Crowley and Neuburg performed the six-week "Paris Working", a period of intense ritual involving strong drug use in which they invoked the gods Mercury and Jupiter. As part of the ritual, the couple performed acts of sex magic together, at times being joined by journalist Walter Duranty. Inspired by the results of the Working, Crowley wrote "Liber Agapé", a treatise on sex magic. Following the Paris Working, Neuburg began to distance himself from Crowley, resulting in an argument in which Crowley cursed him.

By 1914 Crowley was living a hand-to-mouth existence, relying largely on donations from A∴A∴ members and dues payments made to O.T.O. In May he transferred ownership of Boleskine House to the MMM for financial reasons, and in July he went mountaineering in the Swiss Alps. During this time the First World War broke out.
After recuperating from a bout of phlebitis, Crowley set sail for the United States aboard the RMS "Lusitania" in October 1914. Arriving in New York City, he moved into a hotel and began earning money writing for the American edition of "Vanity Fair" and undertaking freelance work for the famed astrologer Evangeline Adams. In the city, he continued experimenting with sex magic, through the use of masturbation, female prostitutes, and male clients of a Turkish bathhouse; all of these encounters were documented in his diaries.

Professing to be of Irish ancestry and a supporter of Irish independence from Great Britain, Crowley began to espouse support for Germany in their war against Britain. He became involved in New York's pro-German movement, and in January 1915 German spy George Sylvester Viereck employed him as a writer for his propagandist paper, "The Fatherland", which was dedicated to keeping the US neutral in the conflict. In later years, detractors denounced Crowley as a traitor to Britain for this action. In reality, Crowley was a double agent, working for the British intelligence services to infiltrate and undermine Germany's operation in New York. Many of his articles in "The Fatherland" were hyperbolic, for instance comparing Wilhelm II to Jesus Christ; in July 1915 he orchestrated a publicity stunt—reported on by "The New York Times"—in which he declared independence for Ireland in front of the Statue of Liberty; the real intention was to make the German lobby appear ridiculous in the eyes of the American public. It has been argued that he encouraged the German Navy to destroy the "Lusitania", informing them that it would ensure the US stayed out of the war, while in reality hoping that it would bring the US into the war on Britain's side.

Crowley entered into a relationship with Jeanne Robert Foster, with whom he toured the West Coast. In Vancouver, headquarters of the North American O.T.O., he met with Charles Stansfeld Jones and Wilfred Talbot Smith to discuss the propagation of Thelema on the continent. In Detroit he experimented with Peyote at Parke-Davis, then visited Seattle, San Francisco, Santa Cruz, Los Angeles, San Diego, Tijuana, and the Grand Canyon, before returning to New York. There he befriended Ananda Coomaraswamy and his wife Alice Richardson; Crowley and Richardson performed sex magic in April 1916, following which she became pregnant and then miscarried. Later that year he took a "magical retirement" to a cabin by Lake Pasquaney owned by Evangeline Adams. There, he made heavy use of drugs and undertook a ritual after which he proclaimed himself "Master Therion". He also wrote several short stories based on J.G. Frazer's "The Golden Bough" and a work of literary criticism, "The Gospel According to Bernard Shaw".

In December he moved to New Orleans, his favourite US city, before spending February 1917 with evangelical Christian relatives in Titusville, Florida. Returning to New York City, he moved in with artist and A∴A∴ member Leon Engers Kennedy in May, learning of his mother's death. After the collapse of "The Fatherland", Crowley continued his association with Viereck, who appointed him contributing editor of arts journal "The International". Crowley used it to promote Thelema, but it soon ceased publication. He then moved to the studio apartment of Roddie Minor, who became his partner and Scarlet Woman. Through their rituals, which Crowley called "The Amalantrah Workings", he believed that they were contacted by a preternatural entity named Lam. The relationship soon ended.

In 1918, Crowley went on a magical retreat in the wilderness of Esopus Island on the Hudson River. Here, he began a translation of the "Tao Te Ching", painted Thelemic slogans on the riverside cliffs, and—he later claimed—experienced past life memories of being Ge Xuan, Pope Alexander VI, Alessandro Cagliostro, and Eliphas Levi. Back in New York City, he moved to Greenwich Village, where he took Leah Hirsig as his lover and next Scarlet Woman. He took up painting as a hobby, exhibiting his work at the Greenwich Village Liberal Club and attracting the attention of the "New York Evening World". With the financial assistance of sympathetic Freemasons, Crowley revived "The Equinox" with the first issue of volume III, known as "The Blue Equinox". He spent mid-1919 on a climbing holiday in Montauk before returning to London in December.

Now destitute and back in London, Crowley came under attack from the tabloid "John Bull", which labelled him traitorous "scum" for his work with the German war effort; several friends aware of his intelligence work urged him to sue, but he decided not to. When he was suffering from asthma, a doctor prescribed him heroin, to which he soon became addicted. In January 1920, he moved to Paris, renting a house in Fontainebleau with Leah Hirsig; they were soon joined in a "ménage à trois" by Ninette Shumway, and also (in living arrangement) by Leah's newborn daughter Anne "Poupée" Leah. Crowley had ideas of forming a community of Thelemites, which he called the Abbey of Thelema after the Abbaye de Thélème in François Rabelais' satire "Gargantua and Pantagruel". After consulting the "I Ching", he chose Cefalù (on Sicily, Italy) as a location, and after arriving there, began renting the old Villa Santa Barbara as his Abbey on 2 April.
Moving to the commune with Hirsig, Shumway, and their children Hansi, Howard, and Poupée, Crowley described the scenario as "perfectly happy ... my idea of heaven." They wore robes, and performed rituals to the sun god Ra at set times during the day, also occasionally performing the Gnostic Mass; the rest of the day they were left to follow their own interests. Undertaking widespread correspondences, Crowley continued to paint, wrote a commentary on "The Book of the Law", and revised the third part of "Book 4". He offered a libertine education for the children, allowing them to play all day and witness acts of sex magic. He occasionally travelled to Palermo to visit rent boys and buy supplies, including drugs; his heroin addiction came to dominate his life, and cocaine began to erode his nasal cavity. There was no cleaning rota, and wild dogs and cats wandered throughout the building, which soon became unsanitary. Poupée died in October 1920, and Ninette gave birth to a daughter, Astarte Lulu Panthea, soon afterwards.

New followers continued to arrive at the Abbey to be taught by Crowley. Among them was film star Jane Wolfe, who arrived in July 1920, where she was initiated into the A∴A∴ and became Crowley's secretary. Another was Cecil Frederick Russell, who often argued with Crowley, disliking the same-sex sexual magic that he was required to perform, and left after a year. More conducive was the Australian Thelemite Frank Bennett, who also spent several months at the Abbey. In February 1922, Crowley returned to Paris for a retreat in an unsuccessful attempt to kick his heroin addiction. He then went to London in search of money, where he published articles in "The English Review" criticising the Dangerous Drugs Act 1920 and wrote a novel, "Diary of a Drug Fiend", completed in July. On publication, it received mixed reviews; he was lambasted by the "Sunday Express", which called for its burning and used its influence to prevent further reprints.

Subsequently, a young Thelemite named Raoul Loveday moved to the Abbey with his wife Betty May; while Loveday was devoted to Crowley, May detested him and life at the commune. She later said that Loveday was made to drink the blood of a sacrificed cat, and that they were required to cut themselves with razors every time they used the pronoun "I". Loveday drank from a local polluted stream, soon developing a liver infection resulting in his death in February 1923. Returning to London, May told her story to the press. "John Bull" proclaimed Crowley "the wickedest man in the world" and "a man we'd like to hang", and although Crowley deemed many of their accusations against him to be slanderous, he was unable to afford the legal fees to sue them. As a result, "John Bull" continued its attack, with its stories being repeated in newspapers throughout Europe and in North America. The Fascist government of Benito Mussolini learned of Crowley's activities, and in April 1923 he was given a deportation notice forcing him to leave Italy; without him, the Abbey closed.

Crowley and Hirsig went to Tunis, where, dogged by continuing poor health, he unsuccessfully tried again to give up heroin, and began writing what he termed his "autohagiography", "The Confessions of Aleister Crowley". They were joined in Tunis by the Thelemite Norman Mudd, who became Crowley's public relations consultant. Employing a local boy, Mohammad ben Brahim, as his servant, Crowley went with him on a retreat to Nefta, where they performed sex magic together. In January 1924, Crowley travelled to Nice, France, where he met with Frank Harris, underwent a series of nasal operations, and visited the Institute for the Harmonious Development of Man and had a positive opinion of its founder, George Gurdjieff. Destitute, he took on a wealthy student, Alexander Zu Zolar, before taking on another American follower, Dorothy Olsen. Crowley took Olsen back to Tunisia for a magical retreat in Nefta, where he also wrote "To Man" (1924), a declaration of his own status as a prophet entrusted with bringing Thelema to humanity. After spending the winter in Paris, in early 1925 Crowley and Olsen returned to Tunis, where he wrote "The Heart of the Master" (1938) as an account of a vision he experienced in a trance. In March Olsen became pregnant, and Hirsig was called to take care of her; she miscarried, following which Crowley took Olsen back to France. Hirsig later distanced herself from Crowley, who then denounced her.

According to Crowley, Reuss had named him head of the O.T.O. upon his death, but this was challenged by a leader of the German O.T.O., Heinrich Tränker. Tränker called the Hohenleuben Conference in Thuringia, Germany, which Crowley attended. There, prominent members like Karl Germer and Martha Küntzel championed Crowley's leadership, but other key figures like Albin Grau, Oskar Hopfer, and Henri Birven backed Tränker by opposing it, resulting in a split in the O.T.O. Moving to Paris, where he broke with Olsen in 1926, Crowley went through a large number of lovers over the following years, with whom he experimented in sex magic. Throughout, he was dogged by poor health, largely caused by his heroin and cocaine addictions. In 1928, Crowley was introduced to young Englishman Israel Regardie, who embraced Thelema and became Crowley's secretary for the next three years. That year, Crowley also met Gerald Yorke, who began organising Crowley's finances but never became a Thelemite. He also befriended the homosexual journalist Tom Driberg; Driberg did not accept Thelema either. It was here that Crowley also published one of his most significant works, "Magick in Theory and Practice", which received little attention at the time.

In December 1928 Crowley met the Nicaraguan Maria Teresa Sanchez. Crowley was deported from France by the authorities, who disliked his reputation and feared that he was a German agent. So that she could join him in Britain, Crowley married Sanchez in August 1929. Now based in London, Mandrake Press agreed to publish his autobiography in a limited edition six-volume set, also publishing his novel "Moonchild" and book of short stories "The Stratagem". Mandrake went into liquidation in November 1930, before the entirety of Crowley's "Confessions" could be published. Mandrake's owner P.R. Stephenson meanwhile wrote "The Legend of Aleister Crowley", an analysis of the media coverage surrounding him.

In April 1930, Crowley moved to Berlin, where he took Hanni Jaegar as his magical partner; the relationship was troubled. In September he went to Lisbon in Portugal to meet the poet Fernando Pessoa. There, he decided to fake his own death, doing so with Pessoa's help at the Boca do Inferno rock formation. He then returned to Berlin, where he reappeared three weeks later at the opening of his art exhibition at the Gallery Neumann-Nierendorf. Crowley's paintings fitted with the fashion for German Expressionism; few of them sold, but the press reports were largely favourable. In August 1931, he took Bertha Busch as his new lover; they had a violent relationship, and often physically assaulted one another. He continued to have affairs with both men and women while in the city, and met with famous people like Aldous Huxley and Alfred Adler. After befriending him, in January 1932 he took the communist Gerald Hamilton as a lodger, through whom he was introduced to many figures within the Berlin far left; it is possible that he was operating as a spy for British intelligence at this time, monitoring the communist movement.

Crowley left Busch and returned to London, where he took Pearl Brooksmith as his new Scarlet Woman. Undergoing further nasal surgery, it was here in 1932 that he was invited to be guest of honour at Foyles' Literary Luncheon, also being invited by Harry Price to speak at the National Laboratory of Psychical Research. In need of money, he launched a series of court cases against people whom he believed had libelled him, some of which proved successful. He gained much publicity for his lawsuit against Constable and Co for publishing Nina Hamnett's "Laughing Torso" (1932)—a book he claimed libelled him by referring to his occult practice as black magic—but lost the case. The court case added to Crowley's financial problems, and in February 1935 he was declared bankrupt. During the hearing, it was revealed that Crowley had been spending three times his income for several years.

Crowley developed a friendship with Deidre Patricia Doherty; she offered to bear his child, who was born in May 1937. Named Randall Gair, Crowley nicknamed him Aleister Atatürk. He died in a car accident in 2002 at the age of 65. Crowley continued to socialise with friends, holding curry parties in which he cooked particularly spicy food for them. In 1936, he published his first book in six years, "The Equinox of the Gods", which contained a facsimile of "The Book of the Law" and was considered to be volume III, number 3, of "The Equinox" periodical. The work sold well, resulting in a second print run. In 1937 he gave a series of public lectures on yoga in Soho. Crowley was now living largely off contributions supplied by the O.T.O.'s Agape Lodge in California, led by rocket scientist John Whiteside "Jack" Parsons. Crowley was intrigued by the rise of Nazism in Germany, and influenced by his friend Martha Küntzel believed that Adolf Hitler might convert to Thelema; when the Nazis abolished the German O.T.O. and imprisoned Germer, who fled to the US, Crowley then lambasted Hitler as a black magician.

When the Second World War broke out, Crowley wrote to the Naval Intelligence Division offering his services, but they declined. He associated with a variety of figures in Britain's intelligence community at the time, including Dennis Wheatley, Roald Dahl, Ian Fleming, and Maxwell Knight, and claimed to have been behind the "V for Victory" sign first used by the BBC; this has never been proven.
In 1940, his asthma worsened, and with his German-produced medication unavailable, he returned to using heroin, once again becoming addicted. As the Blitz hit London, Crowley relocated to Torquay, where he was briefly hospitalised with asthma, and entertained himself with visits to the local chess club. Tiring of Torquay, he returned to London, where he was visited by American Thelemite Grady McMurtry, to whom Crowley awarded the title of "Hymenaeus Alpha". He stipulated that though Germer would be his immediate successor, McMurty should succeed Germer as head of the O.T.O. after the latter's death. With O.T.O. initiate Lady Frieda Harris, Crowley developed plans to produce a tarot card set, designed by him and painted by Harris. Accompanying this was a book, published in a limited edition as "The Book of Thoth" by Chiswick Press in 1944. To aid the war effort, he wrote a proclamation on the rights of humanity, "Liber Oz", and a poem for the liberation of France, "Le Gauloise". Crowley's final publication during his lifetime was a book of poetry, "Olla: An Anthology of Sixty Years of Song". Another of his projects, "Aleister Explains Everything", was posthumously published as "Magick Without Tears".

In April 1944 Crowley briefly moved to Aston Clinton in Buckinghamshire, where he was visited by the poet Nancy Cunard, before relocating to Hastings in Sussex, where he took up residence at the Netherwood boarding house. He took a young man named Kenneth Grant as his secretary, paying him in magical teaching rather than wages. He was also introduced to John Symonds, whom he appointed to be his literary executor; Symonds thought little of Crowley, later publishing negative biographies of him. Corresponding with the illusionist Arnold Crowther, it was through him that Crowley was introduced to Gerald Gardner, the future founder of Gardnerian Wicca. They became friends, with Crowley authorising Gardner to revive Britain's ailing O.T.O. Another visitor was Eliza Marian Butler, who interviewed Crowley for her book "The Myth of the Magus". Other friends and family also spent time with him, among them Doherty and Crowley's son Aleister Atatürk. On 1 December 1947, Crowley died at Netherwood of chronic bronchitis aggravated by pleurisy and myocardial degeneration, aged 72. His funeral was held at a Brighton crematorium on 5 December; about a dozen people attended, and Louis Wilkinson read excerpts from the Gnostic Mass, "The Book of the Law", and "Hymn to Pan". The funeral generated press controversy, and was labelled a Black Mass by the tabloids. Crowley's ashes were sent to Karl Germer in the US, who buried them in his garden in Hampton, New Jersey.

Crowley's belief system, Thelema, has been described by scholars as a religion, and more specifically as both a new religious movement, and as a "magico-religious doctrine". It has also been characterised as a form of esotericism and modern Paganism. Although holding "The Book of the Law"—which was composed in 1904—as its central text, Thelema took shape as a complete system in the years after 1904.

In his autobiography, Crowley claimed that his purpose in life had been to "bring oriental wisdom to Europe and to restore paganism in a purer form", although what he meant by "paganism" was unclear.
Crowley's thought was not always cohesive, and was influenced by a variety of sources, ranging from eastern religious movements and practices like Hindu yoga and Buddhism, scientific naturalism, and various currents within Western esotericism, among them ceremonial magic, alchemy, astrology, Rosicrucianism, Kabbalah, and the Tarot. He was steeped in the esoteric teachings he had learned from the Hermetic Order of the Golden Dawn, although pushed further with his own interpretations and strategies than the Golden Dawn had done. Crowley incorporated concepts and terminology from South Asian religious traditions like yoga and Tantra into his Thelemic system, believing that there was a fundamental underlying resemblance between Western and Eastern spiritual systems.
The historian Alex Owen noted that Crowley adhered to the "modus operandi" of the Decadent movement throughout his life.

Crowley believed that the twentieth century marked humanity's entry to the Aeon of Horus, a new era in which humans would take increasing control of their destiny. He believed that this Aeon follows on from the Aeon of Osiris, in which paternalistic religions like Christianity, Islam, and Buddhism dominated the world, and that this in turn had followed the Aeon of Isis, which had been maternalistic and dominated by goddess worship. He believed that Thelema was the proper religion of the Aeon of Horus, and also deemed himself to be the prophet of this new Aeon. Thelema revolves around the idea that human beings each have their own True Will that they should discover and pursue, and that this exists in harmony with the Cosmic Will that pervades the universe. Crowley referred to this process of searching and discovery of one's True Will to be "the Great Work" or the attaining of the "knowledge and conversation of the Holy Guardian Angel". His favoured method of doing so was through the performance of the Abramelin operation, a ceremonial magic ritual obtained from a 17th-century grimoire. The moral code of "Do What Thou Wilt" is believed by Thelemites to be the religion's ethical law, although the historian of religion Marco Pasi noted that this was not anarchistic or libertarian in structure, as Crowley saw individuals as part of a wider societal organism.

Crowley believed in the objective existence of magic, which he chose to spell "Magick", an older archaic spelling of the word. He provided various different definitions of this term over his career. In his book "Magick in Theory and Practice", Crowley defined Magick as "the Science and Art of causing change to occur in conformity with Will". He also told his disciple Karl Germer that "Magick is getting into communication with individuals who exist on a higher plane than ours. Mysticism is the raising of oneself to their level." Crowley saw Magick as a third way between religion and science, giving "The Equinox" the subtitle of "The Method of Science; the Aim of Religion". Within that journal he expressed positive sentiments toward science and the scientific method, and urged magicians to keep detailed records of their magical experiments, "The more scientific the record is, the better." His understanding of magic was also influenced by the work of the anthropologist James Frazer, in particular the view that magic was a precursor to science in a cultural evolutionary framework. Unlike Frazer, however, Crowley did not see magic as a survival from the past that required eradication, but rather he believed that magic had to be adapted to suit the new age of science. In Crowley's alternative schema, old systems of "magic" had to decline (per Frazer's framework) so that science and magic could synthesize into "magick", which would simultaneously accept the existence of the supernatural and an experimental method. Crowley deliberately adopted an exceptionally broad definition of magick that included almost all forms of technology as magick, adopting an instrumentalist interpretation of magic, science, and technology.

Sexuality played an important role in Crowley's ideas about magick and his practice of it, and has been described as being central to Thelema. He outlined three forms of sex magick—the autoerotic, homosexual, and heterosexual—and argued that such acts could be used to focus the magician's will onto a specific goal such as financial gain or personal creative success. For Crowley, sex was treated as a sacrament, with the consumption of sexual fluids interpreted as a Eucharist. This was often manifested as the Cakes of Light, a biscuit containing either menstrual blood or a mixture of semen and vaginal fluids. The Gnostic Mass is the central religious ceremony within Thelema.

Crowley's theological beliefs were not clear. The historian Ronald Hutton noted that some of Crowley's writings could be used to argue that he was an atheist, while some support the idea that he was a polytheist, and others would bolster the idea that he was a mystical monotheist. On the basis of the teachings in "The Book of the Law", Crowley described a pantheon of three deities taken from the ancient Egyptian pantheon: Nuit, Hadit, and Ra-Hoor-Khuit. In 1928, he made the claim that all "true" deities were "derived" from this trinity. Jason Josephson-Storm has argued that Crowley built on 19th-century attempts to link early Christianity to pre-Christian religions, such as Frazer's "Golden Bough", to synthesize Christian theology and Neopaganism while remaining critical of institutional and traditional Christianity.

Both during his life and after it, Crowley has been widely described as a Satanist, usually by detractors. Crowley stated he did not consider himself a Satanist, nor did he worship Satan, as he did not accept the Christian world view in which Satan was believed to exist. He nevertheless used Satanic imagery, for instance by describing himself as "the Beast 666" and referring to the Whore of Babylon in his work, while in later life he sent "Antichristmas cards" to his friends. In his writings, Crowley occasionally identified Aiwass as Satan and designated him as "Our Lord God the Devil" at one occasion. The scholar of religion Gordan Djurdjevic stated that Crowley "was emphatically not" a Satanist, "if for no other reason than simply because he did not identify himself as such". Crowley nevertheless expressed strong anti-Christian sentiment, stating that he hated Christianity "as Socialists hate soap", an animosity probably stemming from his experiences among the Plymouth Brethren. He was nevertheless influenced by the King James Bible, especially the Book of Revelations, the impact of which can be seen in his writings. He was also accused of advocating human sacrifice, largely because of a passage in "Book 4" in which he stated that "A male child of perfect innocence and high intelligence is the most satisfactory victim" and added that he had sacrificed about 150 every year. This was a tongue-in-cheek reference to ejaculation, something not realised by his critics, thus reflecting their own "ignorance and prejudice" toward Crowley.

Crowley considered himself to be one of the outstanding figures of his time. The historian Ronald Hutton stated that in Crowley's youth, he was "a self-indulgent and flamboyant young man" who "set about a deliberate flouting and provocation of social and religious norms", while being shielded from an "outraged public opinion" by his inherited wealth. Hutton also described Crowley as having both an "unappeasable desire" to take control of any organisation that he belonged to, and "a tendency to quarrel savagely" with those who challenged him. Crowley biographer Martin Booth asserted that Crowley was "self-confident, brash, eccentric, egotistic, highly intelligent, arrogant, witty, wealthy, and, when it suited him, cruel". Similarly, Richard Spence noted that Crowley was "capable of immense physical and emotional cruelty". Biographer Lawrence Sutin noted that Crowley exhibited "courage, skill, dauntless energy, and remarkable focus of will" while at the same time showing a "blind arrogance, petty fits of bile, [and] contempt for the abilities of his fellow men". The Thelemite Lon Milo DuQuette noted that Crowley "was by no means perfect" and "often alienated those who loved him dearest."

Crowley enjoyed being outrageous and flouting conventional morality, with John Symonds noting that he "was in revolt against the moral and religious values of his time". Crowley's political thought was studied by academic Marco Pasi, who noted that for Crowley, socio-political concerns were subordinate to metaphysical and spiritual ones. He was neither on the political left nor right but perhaps best categorised as a "conservative revolutionary" despite not being affiliated with the German-based conservative revolutionary movement. Pasi described Crowley's affinity to the extreme ideologies of Nazism and Marxism–Leninism, which aimed to violently overturn society: "What Crowley liked about Nazism and communism, or at least what made him curious about them, was the anti-Christian position and the revolutionary and socially subversive implications of these two movements. In their subversive powers, he saw the possibility of an annihilation of old religious traditions, and the creation of a void that Thelema, subsequently, would be able to fill." Crowley described democracy as an "imbecile and nauseating cult of weakness", and commented that "The Book of the Law" proclaimed that "there is the master and there is the slave; the noble and the serf; the 'lone wolf' and the herd". In this attitude he was influenced by the work of Friedrich Nietzsche and by Social Darwinism. Although he had contempt for most of the British aristocracy, he regarded himself as an aristocrat and styled himself as Laird Boleskine, once describing his ideology as "aristocratic communism".

Crowley was bisexual, and exhibited a sexual preference for women, with his relationships with men being fewer and clustered in the early part of his life. In particular he had an attraction toward "exotic women", and claimed to have fallen in love on multiple occasions; Kaczynski stated that "when he loved, he did so with his whole being, but the passion was typically short-lived". Even in later life, Crowley was able to attract young bohemian women to be his lovers, largely due to his charisma. He applied the term "Scarlet Woman" to various female lovers whom he believed played an important role in his magical work. During homosexual anal intercourse, he usually played the passive role, which Booth believed "appealed to his masochistic side". An underlying theme in many of his writings is that spiritual enlightenment arises through transgressing socio-sexual norms.

Crowley advocated complete sexual freedom for both men and women. He argued that homosexual and bisexual people should not suppress their sexual orientation, commenting that a person "must not be ashamed or afraid of being homosexual if he happens to be so at heart; he must not attempt to violate his own true nature because of public opinion, or medieval morality, or religious prejudice which would wish he were otherwise." On other issues he adopted a more conservative attitude; he opposed abortion on moral grounds, believing that no woman following her True Will would ever desire one.

Biographer Lawrence Sutin stated that "blatant bigotry is a persistent minor element in Crowley's writings". Sutin thought Crowley "a spoiled scion of a wealthy Victorian family who embodied many of the worst John Bull racial and social prejudices of his upper-class contemporaries", noting that he "embodied the contradiction that writhed within many Western intellectuals of the time: deeply held racist viewpoints courtesy of society, coupled with a fascination with people of colour". Crowley is said to have insulted his close Jewish friend Victor Benjamin Neuburg, using anti-Semitic slurs, and he had mixed opinions about Jews as a group. Although he praised their "sublime" poetry and stated that they exhibited "imagination, romance, loyalty, probity and humanity", he also thought that centuries of persecution had led some Jews to exhibit "avarice, servility, falseness, cunning and the rest". He was also known to praise various ethnic and cultural groups, for instance he thought that the Chinese people exhibited a "spiritual superiority" to the English, and praised Muslims for exhibiting "manliness, straightforwardness, subtlety, and self-respect".

Both critics of Crowley and adherents of Thelema have accused Crowley of sexism. Booth described Crowley as exhibiting a "general misogyny", something the biographer believed arose from Crowley's bad relationship with his mother. Sutin noted that Crowley "largely accepted the notion, implicitly embodied in Victorian sexology, of women as secondary social beings in terms of intellect and sensibility". The scholar of religion Manon Hedenborg White noted that some of Crowley's statements are "undoubtedly misogynist by contemporary standards", but characterized Crowley's attitude toward women as complex and multi-faceted. Crowley's comments on women's role varied dramatically within his written work, even that produced in similar periods. Crowley described women as "moral inferiors" who had to be treated with "firmness, kindness and justice", while also arguing that Thelema was essential to women's emancipation.

Biographers Richard Spence and Tobias Churton have suggested that Crowley was a spy for the British secret services and that among other things he joined the Golden Dawn under the command of them to monitor the activities of Mathers, who was known to be a Carlist. Spence suggested that the conflict between Mathers and the London lodge for the temple was part of an intelligence operation to undermine Mathers' authority. Spence has suggested that the purpose of Crowley's trip to Mexico might have been to explore Mexican oil prospects for British intelligence. Spence has suggested that this trip to China was orchestrated as part of a British intelligence scheme to monitor the region's opium trade. Churton suggested that Crowley had travelled to Moscow on the orders of British intelligence to spy on revolutionary elements in the city.

Crowley has remained an influential figure, both amongst occultists and in popular culture, particularly that of Britain, but also of other parts of the world. In 2002, a BBC poll placed Crowley seventy-third in a list of the 100 Greatest Britons. Richard Cavendish has written of him that "In native talent, penetrating intelligence and determination, Aleister Crowley was the best-equipped magician to emerge since the seventeenth century." The scholar of esotericism Egil Asprem described him as "one of the most well-known figures in modern occultism". The scholar of esotericism Wouter Hanegraaff asserted that Crowley was an extreme representation of "the dark side of the occult", adding that he was "the most notorious occultist magician of the twentieth century". The philosopher John Moore opined that Crowley stood out as a "Modern Master" when compared with other prominent occult figures like George Gurdjieff, P. D. Ouspensky, Rudolf Steiner, or Helena Blavatsky, also describing him as a "living embodiment" of Oswald Spengler's "Faustian Man".
Biographer Tobias Churton considered Crowley "a pioneer of consciousness research". Hutton noted that Crowley had "an important place in the history of modern Western responses to Oriental spiritual traditions", while Sutin thought that he had made "distinctly original contributions" to the study of yoga in the West.

Thelema continued to develop and spread following Crowley's death. In 1969, the O.T.O. was reactivated in California under the leadership of Grady Louis McMurtry; in 1985 its right to the title was unsuccessfully challenged in court by a rival group, the Society Ordo Templi Orientis, led by Brazilian Thelemite Marcelo Ramos Motta.
Another American Thelemite is the filmmaker Kenneth Anger, who had been influenced by Crowley's writings from a young age. In the United Kingdom, Kenneth Grant propagated a tradition known as Typhonian Thelema through his organisation, the Typhonian O.T.O., later renamed the Typhonian Order.
Also in Britain, an occultist known as Amado Crowley claimed to be Crowley's son; this has been refuted by academic investigation. Amado argued that Thelema was a false religion created by Crowley to hide his true esoteric teachings, which Amado claimed to be propagating.

Several Western esoteric traditions other than Thelema were also influenced by Crowley, with Djurdjevic observing that "Crowley's influence on twentieth-century and contemporary esotericism has been enormous". Gerald Gardner, founder of Gardnerian Wicca, made use of much of Crowley's published material when composing the Gardnerian ritual liturgy, and the Australian witch Rosaleen Norton was also heavily influenced by Crowley's ideas. More widely, Crowley became "a dominant figure" in the modern Pagan community. L. Ron Hubbard, the American founder of Scientology, was involved in Thelema in the early 1940s (with Jack Parsons), and it has been argued that Crowley's ideas influenced some of Hubbard's work. The scholars of religion Asbjørn Dyrendel, James R. Lewis, and Jesper Petersen noted that despite the fact that Crowley was not a Satanist, he "in many ways embodies the pre-Satanist esoteric discourse on Satan and Satanism through his lifestyle and his philosophy", with his "image and ought" becoming an "important influence" on the later development of religious Satanism. For instance, two prominent figures in religious Satanism, Anton LaVey and Michael Aquino, were influenced by Crowley's work.

Crowley also had a wider influence in British popular culture. After his time in Cefalù which had brought him to public attention in Britain, various "literary Crowleys" appeared; characters in fiction based upon him. One of the earliest was the character of the poet Shelley Arabin in John Buchan's 1926 novel "The Dancing Floor". In his novel "The Devil Rides Out", the writer Dennis Wheatley used Crowley as a partial basis for the character of Damien Morcata, a portly bald defrocked priest who engages in black magic. The occultist Dion Fortune used Crowley as a basis for characters in her books "The Secrets of Doctor Taverner" (1926) and "The Winged Bull" (1935). He was included as one of the figures on the cover art of The Beatles' album "Sgt. Pepper's Lonely Hearts Club Band" (1967), and his motto of "Do What Thou Wilt" was inscribed on the vinyl of Led Zeppelin's album "Led Zeppelin III" (1970). Led Zeppelin co-founder Jimmy Page bought Boleskine in 1971, and part of the band's film "The Song Remains the Same" was filmed in the grounds. He sold it in 1992. Though David Bowie makes but a fleeting reference to Crowley in the lyrics of his song "Quicksand" (1971), it has been suggested that the lyrics of Bowie's No. 1 hit single Let's Dance (1983) may substantially paraphrase Crowley's 1923 poem "Lyric of Love to Leah". Ozzy Osbourne and his lyricist Bob Daisley wrote a song titled "Mr. Crowley" (1980). Crowley began to receive scholarly attention from academics in the late 1990s.



</doc>
<doc id="1178" url="https://en.wikipedia.org/wiki?curid=1178" title="Afterlife">
Afterlife

The afterlife (also referred to as life after death or the world to come or reincarnation) is an existence some believe that the essential part of an individual's identity or their stream of consciousness continues to have after the death of their physical body. According to various ideas about the afterlife, the essential aspect of the individual that lives on after death may be some partial element, or the entire soul or spirit, of an individual, which carries with it and may confer personal identity or, on the contrary nirvana. Belief in an afterlife is in contrast to the belief in oblivion after death.

In some views, this continued existence often takes place in a spiritual realm, and in other popular views, the individual may be reborn into this world and begin the life cycle over again, likely with no memory of what they have done in the past. In this latter view, such rebirths and deaths may take place over and over again continuously until the individual gains entry to a spiritual realm or otherworld. Major views on the afterlife derive from religion, esotericism and metaphysics.

Some belief systems, such as those in the Abrahamic tradition, hold that the dead go to a specific plane of existence after death, as determined by God, or other divine judgment, based on their actions or beliefs during life. In contrast, in systems of reincarnation, such as those in the Indian religions, the nature of the continued existence is determined directly by the actions of the individual in the ended life.
Theists generally believe some afterlife awaits people when they die. Members of some generally non-theistic religions tend to believe in an afterlife but without reference to a deity. The Sadducees were an ancient Jewish sect that generally believed that there was a God but no afterlife.

Many religions, whether they believe in the soul's existence in another world like Christianity, Islam, and many pagan belief systems, or reincarnation like many forms of Hinduism and Buddhism, believe that one's status in the afterlife is a reward or punishment for their conduct during life.

Reincarnation is the philosophical or religious concept that an aspect of a living being starts a new life in a different physical body or form after each death. It is also called rebirth or transmigration and is a part of the Saṃsāra doctrine of cyclic existence. It is a central tenet of all major Indian religions, namely Buddhism, Hinduism, Jainism, and Sikhism. The idea of reincarnation is found in many ancient cultures, and a belief in rebirth/metempsychosis was held by historic Greek figures, such as Pythagoras, Socrates, and Plato. It is also a common belief of various ancient and modern religions such as Spiritism, Theosophy, and Eckankar. It is found as well in many tribal societies around the world, in places such as Australia, East Asia, Siberia, and South America.

Although the majority of denominations within the Abrahamic religions of Judaism, Christianity, and Islam do not believe that individuals reincarnate, particular groups within these religions do refer to reincarnation; these groups include the mainstream historical and contemporary followers of Kabbalah, the Cathars, Alawites, the Druze, and the Rosicrucians. The historical relations between these sects and the beliefs about reincarnation that were characteristic of Neoplatonism, Orphism, Hermeticism, Manicheanism, and Gnosticism of the Roman era as well as the Indian religions have been the subject of recent scholarly research. Unity Church and its founder Charles Fillmore teach reincarnation.

Rosicrucians speak of a life review period occurring immediately after death and before entering the afterlife's planes of existence (before the silver cord is broken), followed by a judgment, more akin to a final review or end report over one's life.

Heaven, the heavens, seven heavens, pure lands, Tian, Jannah, Valhalla, or the Summerland, is a common religious, cosmological, or transcendent place where beings such as gods, angels, jinn, saints, or venerated ancestors are said to originate, be enthroned, or live. According to the beliefs of some religions, heavenly beings can descend to earth or incarnate, and earthly beings can ascend to heaven in the afterlife, or in exceptional cases enter heaven alive.

Heaven is often described as a "higher place", the holiest place, a paradise, in contrast to hell or the underworld or the "low places", and universally or conditionally accessible by earthly beings according to various standards of divinity, goodness, piety, faith or other virtues or right beliefs or simply the will of God. Some believe in the possibility of a heaven on Earth in a world to come.

In Hinduism, heaven is considered as "Svarga loka". There are seven positive regions the soul can go to after death and seven negative regions. After completing its stay in the respective region, the soul is subjected to rebirth in different living forms according to its "karma". This cycle can be broken after a soul achieves "Moksha" or "Nirvana". Any place of existence, either of humans, souls or deities, outside the tangible world (heaven, hell, or other) is referred to as otherworld.

Hell, in many religious and folkloric traditions, is a place of torment and punishment in the afterlife. Religions with a linear divine history often depict hell as an eternal destination, while religions with a cyclic history often depict a hell as an intermediary period between incarnations. Typically, these traditions locate hell in another dimension or under the earth's surface and often include entrances to hell from the land of the living. Other afterlife destinations include purgatory and limbo.

Traditions that do not conceive of the afterlife as a place of punishment or reward merely describe hell as an abode of the dead, the grave, a neutral place (for example, sheol or Hades) located under the surface of earth.

The afterlife played an important role in Ancient Egyptian religion, and its belief system is one of the earliest known in recorded history. When the body died, parts of its soul known as "ka" (body double) and the "ba" (personality) would go to the Kingdom of the Dead. While the soul dwelt in the Fields of Aaru, Osiris demanded work as restitution for the protection he provided. Statues were placed in the tombs to serve as substitutes for the deceased.

Arriving at one's reward in afterlife was a demanding ordeal, requiring a sin-free heart and the ability to recite the spells, passwords and formulae of the Book of the Dead. In the Hall of Two Truths, the deceased's heart was weighed against the "Shu" feather of truth and justice taken from the headdress of the goddess Ma'at. If the heart was lighter than the feather, they could pass on, but if it were heavier they would be devoured by the demon Ammit.

Egyptians also believed that being mummified and put in a sarcophagus (an ancient Egyptian "coffin" carved with complex symbols and designs, as well as pictures and hieroglyphs) was the only way to have an afterlife. Only if the corpse had been properly embalmed and entombed in a mastaba, could the dead live again in the Fields of Yalu and accompany the Sun on its daily ride. Due to the dangers the afterlife posed, the Book of the Dead was placed in the tomb with the body as well as food, jewellery, and 'curses'. They also used the "opening of the mouth".

Ancient Egyptian civilization was based on religion; their belief in the rebirth after death became the driving force behind their funeral practices. Death was simply a temporary interruption, rather than complete cessation, of life, and that eternal life could be ensured by means like piety to the gods, preservation of the physical form through mummification, and the provision of statuary and other funerary equipment. Each human consisted of the physical body, the "ka", the "ba", and the "akh". The Name and Shadow were also living entities. To enjoy the afterlife, all these elements had to be sustained and protected from harm.

On 30 March 2010, a spokesman for the Egyptian Culture Ministry claimed it had unearthed a large red granite door in Luxor with inscriptions by User, a powerful adviser to the 18th dynasty Queen Hatshepsut who ruled between 1479 BC and 1458 BC, the longest of any woman. It believes the false door is a 'door to the Afterlife'. According to the archaeologists, the door was reused in a structure in Roman Egypt.

The Greek god Hades is known in Greek mythology as the king of the underworld, a place where souls live after death. The Greek god Hermes, the messenger of the gods, would take the dead soul of a person to the underworld (sometimes called Hades or the House of Hades). Hermes would leave the soul on the banks of the River Styx, the river between life and death.

Charon, also known as the ferry-man, would take the soul across the river to Hades, if the soul had gold: Upon burial, the family of the dead soul would put coins under the deceased's tongue. Once crossed, the soul would be judged by Aeacus, Rhadamanthus and King Minos. The soul would be sent to Elysium, Tartarus, Asphodel Fields, or the Fields of Punishment. The Elysian Fields were for the ones that lived pure lives. It consisted of green fields, valleys and mountains, everyone there was peaceful and contented, and the Sun always shone there. Tartarus was for the people that blasphemed against the gods, or were simply rebellious and consciously evil.

The Asphodel Fields were for a varied selection of human souls: Those whose sins equalled their goodness, were indecisive in their lives, or were not judged. The Fields of Punishment were for people that had sinned often, but not so much as to be deserving of Tartarus. In Tartarus, the soul would be punished by being burned in lava, or stretched on racks. Some heroes of Greek legend are allowed to visit the underworld. The Romans had a similar belief system about the afterlife, with Hades becoming known as Pluto. In the ancient Greek myth about the Labours of Heracles, the hero Heracles had to travel to the underworld to capture Cerberus, the three-headed guard dog, as one of his tasks.

In "Dream of Scipio", Cicero describes what seems to be an out of body experience, of the soul traveling high above the Earth, looking down at the small planet, from far away.

In Book VI of Virgil's "Aeneid", the hero, Aeneas, travels to the underworld to see his father. By the River Styx, he sees the souls of those not given a proper burial, forced to wait by the river until someone buries them. While down there, along with the dead, he is shown the place where the wrongly convicted reside, the fields of sorrow where those who committed suicide and now regret it reside, including Aeneas' former lover, the warriors and shades, Tartarus (where the titans and powerful non-mortal enemies of the Olympians reside) where he can hear the groans of the imprisoned, the palace of Pluto, and the fields of Elysium where the descendants of the divine and bravest heroes reside. He sees the river of forgetfulness, Lethe, which the dead must drink to forget their life and begin anew. Lastly, his father shows him all of the future heroes of Rome who will live if Aeneas fulfills his destiny in founding the city.

The Poetic and Prose Eddas, the oldest sources for information on the Norse concept of the afterlife, vary in their description of the several realms that are described as falling under this topic. The most well-known are:

The teachings of the Bahá'í Faith state that the nature of the afterlife is beyond the understanding of those living, just as an unborn fetus cannot understand the nature of the world outside of the womb. The Bahá'í writings state that the soul is immortal and after death it will continue to progress until it finally attains God's presence. In Bahá'í belief, souls in the afterlife will continue to retain their individuality and consciousness and will be able to recognize and communicate spiritually with other souls whom they have made deep profound friendships with, such as their spouses.

The Bahá'í scriptures also state there are distinctions between souls in the afterlife, and that souls will recognize the worth of their own deeds and understand the consequences of their actions. It is explained that those souls that have turned toward God will experience gladness, while those who have lived in error will become aware of the opportunities they have lost. Also, in the Baha'i view, souls will be able to recognize the accomplishments of the souls that have reached the same level as themselves, but not those that have achieved a rank higher than them.

Mainstream Christianity professes belief in the Nicene Creed, and English versions of the Nicene Creed in current use include the phrase: "We look for the resurrection of the dead, and the life of the world to come."

When questioned by the Sadducees about the resurrection of the dead (in a context relating to who one's spouse would be if one had been married several times in life), Jesus said that marriage will be irrelevant after the resurrection as the resurrected will be like the angels in heaven.

Jesus also maintained that the time would come when the dead would hear the voice of the Son of God, and all who were in the tombs would come out, who have done good deeds to the resurrection of life, but those who have done wicked deeds to the resurrection of condemnation.

The Book of Enoch describes Sheol as divided into four compartments for four types of the dead: the faithful saints who await resurrection in Paradise, the merely virtuous who await their reward, the wicked who await punishment, and the wicked who have already been punished and will not be resurrected on Judgment Day. The Book of Enoch is considered apocryphal by most denominations of Christianity and all denominations of Judaism.

The book of 2 Maccabees gives a clear account of the dead awaiting a future resurrection and judgment, plus prayers and offerings for the dead to remove the burden of sin.
The author of Luke recounts the story of Lazarus and the rich man, which shows people in Hades awaiting the resurrection either in comfort or torment. The author of the Book of Revelation writes about God and the angels versus Satan and demons in an epic battle at the end of times when all souls are judged. There is mention of ghostly bodies of past prophets, and the transfiguration.

The non-canonical Acts of Paul and Thecla speak of the efficacy of prayer for the dead, so that they might be "translated to a state of happiness".

Hippolytus of Rome pictures the underworld (Hades) as a place where the righteous dead, awaiting in the bosom of Abraham their resurrection, rejoice at their future prospect, while the unrighteous are tormented at the sight of the "lake of unquenchable fire" into which they are destined to be cast.

Gregory of Nyssa discusses the long-before believed possibility of purification of souls after death.

Pope Gregory I repeats the concept, articulated over a century earlier by Gregory of Nyssa that the saved suffer purification after death, in connection with which he wrote of "purgatorial flames".

The noun "purgatorium" (Latin: place of cleansing) is used for the first time to describe a state of painful purification of the saved after life. The same word in adjectival form ("purgatorius -a -um", cleansing), which appears also in non-religious writing, was already used by Christians such as Augustine of Hippo and Pope Gregory I to refer to an after-death cleansing.

During the Age of Enlightenment, theologians and philosophers presented various philosophies and beliefs. A notable example is Emanuel Swedenborg who wrote some 18 theological works which describe in detail the nature of the afterlife according to his claimed spiritual experiences, the most famous of which is "Heaven and Hell". His report of life there covers a wide range of topics, such as marriage in heaven (where all angels are married), children in heaven (where they are raised by angel parents), time and space in heaven (there are none), the after-death awakening process in the World of Spirits (a place halfway between Heaven and Hell and where people first wake up after death), the allowance of a free will choice between Heaven or Hell (as opposed to being sent to either one by God), the eternity of Hell (one could leave but would never want to), and that all angels or devils were once people on earth.

The "Spiritual Combat", a written work by Lorenzo Scupoli, states that four assaults are attempted by the "evil one" at the hour of death. The Catholic conception of the afterlife teaches that after the body dies, the soul is judged, the righteous and free of sin enter Heaven. However, those who die in unrepented mortal sin go to hell. In the 1990s, the Catechism of the Catholic Church defined hell not as punishment imposed on the sinner but rather as the sinner's self-exclusion from God. Unlike other Christian groups, the Catholic Church teaches that those who die in a state of grace, but still carry venial sin go to a place called Purgatory where they undergo purification to enter Heaven.

Despite popular opinion, Limbo, which was elaborated upon by theologians beginning in the Middle Ages, was never recognized as a dogma of the Catholic Church, yet, at times, it has been a very popular theological theory within the Church. Limbo is a theory that unbaptized but innocent souls, such as those of infants, virtuous individuals who lived before Jesus Christ was born on earth, or those that die before baptism exist in neither Heaven or Hell proper. Therefore, these souls neither merit the beatific vision, nor are subjected to any punishment, because they are not guilty of any personal sin although they have not received baptism, so still bear original sin. So they are generally seen as existing in a state of natural, but not supernatural, happiness, until the end of time.

In other Christian denominations it has been described as an intermediate place or state of confinement in oblivion and neglect.

The notion of purgatory is associated particularly with the Catholic Church. In the Catholic Church, all those who die in God's grace and friendship, but still imperfectly purified, are indeed assured of their eternal salvation; but after death they undergo purification, so as to achieve the holiness necessary to enter the joy of heaven or the final purification of the elect, which is entirely different from the punishment of the damned. The tradition of the church, by reference to certain texts of scripture, speaks of a "cleansing fire" although it is not always called purgatory.

Anglicans of the Anglo-Catholic tradition generally also hold to the belief. John Wesley, the founder of Methodism, believed in an intermediate state between death and the resurrection of the dead and in the possibility of "continuing to grow in holiness there", but Methodism does not officially affirm this belief and denies the possibility of helping by prayer any who may be in that state.

The Orthodox Church is intentionally reticent on the afterlife, as it acknowledges the mystery especially of things that have not yet occurred. Beyond the second coming of Jesus, bodily resurrection, and final judgment, all of which is affirmed in the Nicene Creed (325 CE), Orthodoxy does not teach much else in any definitive manner. Unlike Western forms of Christianity, however, Orthodoxy is traditionally non-dualist and does not teach that there are two separate literal locations of heaven and hell, but instead acknowledges that "the 'location' of one's final destiny—heaven or hell—as being figurative."

Instead, Orthodoxy teaches that the final judgment is simply one's uniform encounter with divine love and mercy, but this encounter is experienced multifariously depending on the extent to which one has been transformed, partaken of divinity, and is therefore compatible or incompatible with God. "The monadic, immutable, and ceaseless object of eschatological encounter is therefore the love and mercy of God, his glory which infuses the heavenly temple, and it is the subjective human reaction which engenders multiplicity or any division of experience." For instance, St. Isaac the Syrian observes that "those who are punished in Gehenna, are scourged by the scourge of love. ... The power of love works in two ways: it torments sinners ... [as] bitter regret. But love inebriates the souls of the sons of Heaven by its delectability." In this sense, the divine action is always, immutably, and uniformly love and if one experiences this love negatively, the experience is then one of self-condemnation because of free will rather than condemnation by God.

Orthodoxy therefore uses the description of Jesus' judgment in John 3:19–21 as their model: "19 And this is the judgment: the light has come into the world, and people loved the darkness rather than the light because their works were evil. 20 For everyone who does wicked things hates the light and does not come to the light, lest his works should be exposed. 21 But whoever does what is true comes to the light, so that it may be clearly seen that his works have been carried out in God." As a characteristically Orthodox understanding, then, Fr. Thomas Hopko writes, "[I]t is precisely the presence of God's mercy and love which cause the torment of the wicked. God does not punish; he forgives... . In a word, God has mercy on all, whether all like it or not. If we like it, it is paradise; if we do not, it is hell. Every knee will bend before the Lord. Everything will be subject to Him. God in Christ will indeed be "all and in all," with boundless mercy and unconditional pardon. But not all will rejoice in God's gift of forgiveness, and that choice will be judgment, the self-inflicted source of their sorrow and pain."

Moreover, Orthodoxy includes a prevalent tradition of "apokatastasis", or the restoration of all things in the end. This has been taught most notably by Origen, but also many other Church fathers and Saints, including Gregory of Nyssa. The Second Council of Constantinople (553 CE) affirmed the orthodoxy of Gregory of Nyssa while simultaneously condemning Origen's brand of universalism because it taught the restoration back to our pre-existent state, which Orthodoxy doesn't teach. It is also a teaching of such eminent Orthodox theologians as Olivier Clément, Metropolitan Kallistos Ware, and Bishop Hilarion Alfeyev. Although apokatastasis is not a dogma of the church but instead a theologoumenon, it is no less a teaching of the Orthodox Church than its rejection. As Met. Kallistos Ware explains, "It is heretical to say that all must be saved, for this is to deny free will; but, it is legitimate to hope that all may be saved," as insisting on torment without end also denies free will.

Joseph F. Smith of The Church of Jesus Christ of Latter-day Saints presents an elaborate vision of the afterlife. It is revealed as the scene of an extensive missionary effort by righteous spirits in paradise to redeem those still in darkness—a spirit prison or "hell" where the spirits of the dead remain until judgment. It is divided into two parts: Spirit Prison and Paradise. Together these are also known as the Spirit World (also Abraham's Bosom; see Luke 16:19–25). They believe that Christ visited spirit prison (1 Peter 3:18–20) and opened the gate for those who repent to cross over to Paradise. This is similar to the Harrowing of Hell doctrine of some mainstream Christian faiths. Both Spirit Prison and Paradise are temporary according to Latter-day Saint beliefs. After the resurrection, spirits are assigned "permanently" to three degrees of heavenly glory, determined by how they lived – Celestial, Terrestrial, and Telestial. (1 Cor 15:44–42; Doctrine and Covenants, Section 76) Sons of Perdition, or those who have known and seen God and deny it, will be sent to the realm of Satan, which is called Outer Darkness, where they shall live in misery and agony forever. However, according to Mormon faith, since most persons lack the amount of knowledge to commit the Eternal sin, they are incapable of becoming sons of perdition.

The Celestial Kingdom is believed to be a place where the righteous can live eternally with their families. Progression does not end once one has entered the Celestial Kingdom, but it extends eternally. According to "True to the Faith" (a handbook on doctrines in the LDS faith), "The celestial kingdom is the place prepared for those who have "received the testimony of Jesus" and been "made perfect through Jesus the mediator of the new covenant, who wrought out this perfect atonement through the shedding of his own blood" (D&C 76:51, 69). To inherit this gift, we must receive the ordinances of salvation, keep the commandments, and repent of our sins."

Jehovah's Witnesses occasionally use terms such as "afterlife" to refer to any hope for the dead, but they understand Ecclesiastes 9:5 to preclude belief in an immortal soul. Individuals judged by God to be wicked, such as in the Great Flood or at Armageddon, are given no hope of an afterlife. However, they believe that after Armageddon there will be a bodily resurrection of "both righteous and unrighteous" dead (but not the "wicked"). Survivors of Armageddon and those who are resurrected are then to gradually restore earth to a paradise. After Armageddon, unrepentant sinners are punished with eternal death (non-existence).

The Seventh-day Adventist Church's beliefs regarding the afterlife differ from other Christian churches. Rather than ascend to Heaven or descend to Hell, Adventists believe the dead "remain unconscious until the return of Christ in judgement". The concept that the dead remain dead until resurrection is one of the fundamental believes of Seventh-day Adventist. Adventists believe that death is an unconscious state (a “sleep”). This is based on Matt. 9:24; Mark 5:39; John 11:11-14; 1 Cor. 15:51, 52; 1 Thess. 4:13-17; 2 Peter 3:4; Eccl. 9:5, 6, 10. At death, all consciousness ends. The dead person does not know anything and does not do anything. They believe that death is creation, only in reverse. Ecclesiastes 12:7. When a person dies, the body turns to dust again, and the spirit goes back to God, who gave it. The spirit of every person who dies—whether saved or unsaved—returns to God at death. The spirit that returns to God at death is the breath of life. 

The Islamic belief in the afterlife as stated in the Quran is descriptive. The Arabic word for Paradise is "Jannah" and Hell is "Jahannam". Their level of comfort while in the grave (according to some commentators) depends wholly on their level of "iman" or faith in the one almighty creator or supreme being (God or Allah). In order for one to achieve proper, firm and healthy "iman" one must practice righteous deeds or else his level of "iman" chokes and shrinks and eventually can wither away if one does not practice Islam long enough, hence the depth of practicing Islam is good deeds. One may also acquire "tasbih" and recite the names of Allah in such manner as "Subahann Allah" or "Glory be to Allah" over and over again to acquire good deeds, all for the cause to reach absolute beliefe to elevate the spiritual entity that will find its creator (source). This ultimate goal is recited in one of the most prominent verses in Quraan, the first Sura in the Quraan, named Alfateha in the 5th verse "Ehdina al serata al mostaqeem" meaning "guide us to the straight path", and the following verses follows describing this path as "The way of those on whom you have bestowed your grace, not the way of those who earned your anger, nor of those who went astray".

In the Quran, Allah gives warning about grievous punishment to those who do not believe in the afterlife ("Akhirah"), and admonishes mankind that Hell is prepared for those who deny the meeting with god.

Islam teaches that the purpose of Man's entire creation is to worship God alone, which includes being kind to other human beings and life, including animals, and to trees, by not oppressing them. Islam teaches that the life we live on Earth is nothing but a test for us and to determine each individual's ultimate abode, be it Hell or Paradise in the afterlife, which is eternal and everlasting.

"Jannah" and "Jahannam" both have different levels. "Jannah" has eight gates and seven levels. The higher the level the better it is and the happier you are. "Jahannam" possess 7 deep terrible layers. The lower the layer the worse it is. Individuals will arrive at both everlasting places during Judgment Day, which commences after the Angel Israfil blows the trumpet the second time. Islam teaches the continued existence of the soul and a transformed physical existence after death. Muslims believe there will be a day of judgment when all humans will be judged by God and assigned between the eternal destinations of Paradise and Hell.

In the 20th century, discussions about the afterlife address the interconnection between human action and divine judgment, the need for moral rectitude, and the eternal consequences of human action in this life and world.

A central doctrine of the Quran is the Last Day, on which the world will come to an end and God will raise all people and jinn from the dead to be judged. The Last Day is also called the Day of Standing Up, Day of Separation, Day of Reckoning, Day of Awakening, Day of Judgment, The Encompassing Day or The Hour.

Until the Day of Judgment, deceased souls remain in their graves awaiting the resurrection. However, they begin to feel immediately a taste of their destiny to come. Those bound for hell will suffer in their graves, while those bound for heaven will be in peace until that time.

The resurrection that will take place on the Last Day is physical, and is explained by suggesting that God will re-create the decayed body (17:100: "Could they not see that God who created the heavens and the earth is able to create the like of them?").

On the Last Day, resurrected humans and jinn will be judged by God according to their deeds. One's eternal destination depends on balance of good to bad deeds in life. They are either granted admission to Paradise, where they will enjoy spiritual and physical pleasures forever, or condemned to Hell to suffer spiritual and physical torment for eternity. The day of judgment is described as passing over Hell on a narrow bridge (as thin as human hair and sharper than a razor) in order to enter Paradise. Those who fall, weighted by their bad deeds, will go to Hell.

In Islam, Believers are those who believed in oneness of God and did not associate any partners with him or did not give the attributes of God to any other entity. It is an established belief that if a believer goes to hell for his sins being greater than his good deeds, he will not remain in hell forever. When punishment for his sins will be over, God will forgive him and grant him heaven.

Quran 4:48 says "Indeed, Allah does not forgive association with Him, but He forgives what is less than that for whom He wills. And he who associates others with Allah has certainly fabricated a tremendous sin".

Ahmadi believe that the afterlife is not material but of a spiritual nature. According to Mirza Ghulam Ahmad, the founder of Ahmadiyya religion, the soul will give birth to another rarer entity and will resemble the life on this earth in the sense that this entity will bear a similar relationship to the soul as the soul bears relationship with the human existence on earth. On earth, if a person leads a righteous life and submits to the will of God, his or her tastes become attuned to enjoying spiritual pleasures as opposed to carnal desires. With this, an "embryonic soul" begins to take shape. Different tastes are said to be born which a person given to carnal passions finds no enjoyment. For example, sacrifice of one's own rights over that of others becomes enjoyable, or that forgiveness becomes second nature. In such a state a person finds contentment and peace at heart and at this stage, according to Ahmadiyya beliefs, it can be said that a soul within the soul has begun to take shape.

The Sufi scholar Ibn 'Arabi defined Barzakh as the intermediate realm or "isthmus." It is between the world of corporeal bodies and the world of spirits, and is a means of contact between the two worlds. Without it, there would be no contact between the two and both would cease to exist. He described it as simple and luminous, like the world of spirits, but also able to take on many different forms just like the world of corporeal bodies can. In broader terms Barzakh, "is anything that separates two things". It has been called the dream world in which the dreamer is in both life and death.

Sheol, in the Hebrew Bible, is a place of darkness (Job x. 21, 22) to which all the dead go, both the righteous and the unrighteous, regardless of the moral choices made in life, (Gen. xxxvii. 36; Ezek. xxxii.; Isa. xiv.; Job xxx. 23), a place of stillness, (Ps. lxxxviii. 13, xciv. 17; Eccl. ix. 10), at the longest possible distance from heaven, (Job xi. 8; Amos ix. 2; Ps. cxxxix. 8).

The inhabitants of Sheol are the "shades" ("rephaim"), entities without personality or strength. Under some circumstances they are thought to be able to be contacted by the living, as the Witch of Endor contacts the shade of Samuel for Saul, but such practices are forbidden (Deuteronomy 18:10).

While the Hebrew Bible appears to describe Sheol as the permanent place of the dead, in the Second Temple period (roughly 500 BC – 70 AD) a more diverse set of ideas developed. In some texts, Sheol is considered to be the home of both the righteous and the wicked, separated into respective compartments; in others, it was considered a place of punishment, meant for the wicked dead alone. When the Hebrew scriptures were translated into Greek in ancient Alexandria around 200 BC, the word "Hades" (the Greek underworld) was substituted for Sheol. This is reflected in the New Testament where Hades is both the underworld of the dead and the personification of the evil it represents.

The Talmud offers a number of thoughts relating to the afterlife. After death, the soul is brought for judgment. Those who have led pristine lives enter immediately into the "Olam Haba" or world to come. Most do not enter the world to come immediately, but now experience a period of review of their earthly actions and they are made aware of what they have done wrong. Some view this period as being a "re-schooling", with the soul gaining wisdom as one's errors are reviewed. Others view this period to include spiritual discomfort for past wrongs. At the end of this period, not longer than one year, the soul then takes its place in the world to come. Although discomforts are made part of certain Jewish conceptions of the afterlife, the concept of "eternal damnation", so prevalent in other religions, is not a tenet of the Jewish afterlife. According to the Talmud, extinction of the soul is reserved for a far smaller group of malicious and evil leaders, either whose very evil deeds go way beyond norms, or who lead large groups of people to utmost evil. This is also part of Maimonides' 13 principles of faith.

Maimonides describes the "Olam Haba" in spiritual terms, relegating the prophesied physical resurrection to the status of a future miracle, unrelated to the afterlife or the Messianic era. According to Maimonides, an afterlife continues for the soul of every human being, a soul now separated from the body in which it was "housed" during its earthly existence.

The Zohar describes Gehenna not as a place of punishment for the wicked but as a place of spiritual purification for souls.

Although there is no reference to reincarnation in the Talmud or any prior writings, according to rabbis such as Avraham Arieh Trugman, reincarnation is recognized as being part and parcel of Jewish tradition. Trugman explains that it is through oral tradition that the meanings of the Torah, its commandments and stories, are known and understood. The classic work of Jewish mysticism, the Zohar, is quoted liberally in all Jewish learning; in the Zohar the idea of reincarnation is mentioned repeatedly. Trugman states that in the last five centuries the concept of reincarnation, which until then had been a much hidden tradition within Judaism, was given open exposure.

Shraga Simmons commented that within the Bible itself, the idea [of reincarnation] is intimated in Deut. 25:5–10, Deut. 33:6 and Isaiah 22:14, 65:6.

Yirmiyahu Ullman wrote that reincarnation is an "ancient, mainstream belief in Judaism". The Zohar makes frequent and lengthy references to reincarnation. Onkelos, a righteous convert and authoritative commentator of the same period, explained the verse, "Let Reuben live and not die ..." (Deuteronomy 33:6) to mean that Reuben should merit the World to Come directly, and not have to die again as a result of being reincarnated. Torah scholar, commentator and kabbalist, Nachmanides (Ramban 1195–1270), attributed Job's suffering to reincarnation, as hinted in Job's saying "God does all these things twice or three times with a man, to bring back his soul from the pit to ... the light of the living' (Job 33:29, 30)."

Reincarnation, called "gilgul", became popular in folk belief, and is found in much Yiddish literature among Ashkenazi Jews. Among a few kabbalists, it was posited that some human souls could end up being reincarnated into non-human bodies. These ideas were found in a number of Kabbalistic works from the 13th century, and also among many mystics in the late 16th century. Martin Buber's early collection of stories of the Baal Shem Tov's life includes several that refer to people reincarnating in successive lives.

Among well known (generally non-kabbalist or anti-kabbalist) rabbis who rejected the idea of reincarnation are Saadia Gaon, David Kimhi, Hasdai Crescas, Yedayah Bedershi (early 14th century), Joseph Albo, Abraham ibn Daud, the Rosh and Leon de Modena. Saadia Gaon, in Emunoth ve-Deoth (Hebrew: "beliefs and opinions") concludes Section VI with a refutation of the doctrine of metempsychosis (reincarnation). While rebutting reincarnation, Saadia Gaon further states that Jews who hold to reincarnation have adopted non-Jewish beliefs. By no means do all Jews today believe in reincarnation, but belief in reincarnation is not uncommon among many Jews, including Orthodox.

Other well-known rabbis who are reincarnationists include Yonassan Gershom, Abraham Isaac Kook, Talmud scholar Adin Steinsaltz, DovBer Pinson, David M. Wexelman, Zalman Schachter, and many others. Reincarnation is cited by authoritative biblical commentators, including Ramban (Nachmanides), Menachem Recanti and Rabbenu Bachya.

Among the many volumes of Yitzchak Luria, most of which come down from the pen of his primary disciple, Chaim Vital, are insights explaining issues related to reincarnation. His "Shaar HaGilgulim", "The Gates of Reincarnation", is a book devoted exclusively to the subject of reincarnation in Judaism.

Rabbi Naftali Silberberg of The Rohr Jewish Learning Institute notes that "Many ideas that originate in other religions and belief systems have been popularized in the media and are taken for granted by unassuming Jews."

Buddhists maintain that rebirth takes place without an unchanging self or soul passing from one form to another. The type of rebirth will be conditioned by the moral tone of the person's actions (kamma or karma). For example, if a person has committed harmful actions of body, speech and mind based on greed, hatred and delusion, rebirth in a lower realm, i.e. an animal, a hungry ghost or a hell realm, is to be expected. On the other hand, where a person has performed skillful actions based on generosity, loving-kindness (metta), compassion and wisdom, rebirth in a happy realm, i.e. human or one of the many heavenly realms, can be expected.

Yet the mechanism of rebirth with kamma is not deterministic. It depends on various levels of kamma. The most important moment that determines where a person is reborn into is the last thought moment. At that moment, heavy kamma would ripen if there were performed, if not then near death kamma, if not then habitual kamma, finally if none of the above happened, then residual kamma from previous actions can ripen. According to Theravada Buddhism, there are 31 realms of existence that one can be reborn into.

Pure Land Buddhism of Mahayana believes in a special place apart from the 31 planes of existence called Pure Land. It is believed that each Buddha has their own pure land, created out of their merits for the sake of sentient beings who recall them mindfully to be able to be reborn in their pure land and train to become a Buddha there. Thus the main practice of pure land Buddhism is to chant a Buddha's name.

In Tibetan Buddhism the Tibetan Book of the Dead explains the intermediate state of humans between death and reincarnation. The deceased will find the bright light of wisdom, which shows a straightforward path to move upward and leave the cycle of reincarnation. There are various reasons why the deceased do not follow that light. Some had no briefing about the intermediate state in the former life. Others only used to follow their basic instincts like animals. And some have fear, which results from foul deeds in the former life or from insistent haughtiness. In the intermediate state the awareness is very flexible, so it is important to be virtuous, adopt a positive attitude, and avoid negative ideas. Ideas which are rising from subconsciousness can cause extreme tempers and cowing visions. In this situation they have to understand, that these manifestations are just reflections of the inner thoughts. No one can really hurt them, because they have no more material body. The deceased get help from different Buddhas who show them the path to the bright light. The ones who do not follow the path after all will get hints for a better reincarnation. They have to release the things and beings on which or whom they still hang from the life before. It is recommended to choose a family where the parents trust in the Dharma and to reincarnate with the will to care for the welfare of all beings.

"Life is cosmic energy of the universe and after death it merges in universe again and as the time comes to find the suitable place for the entity died in the life condition it gets born. There are 10 life states of any life: Hell, hunger, anger, animality, rapture, humanity, learning, realization, bodhisatva and buddhahood. The life dies in which life condition it reborn in the same life condition."

The Upanishads describe reincarnation ("punarjanma") (see also: samsara). The Bhagavad Gita, an important Hindu script, talks extensively about the afterlife. Here, Krishna says that just as a man discards his old clothes and wears new ones; similarly the soul discards the old body and takes on a new one. In Hinduism, the belief is that the body is nothing but a shell, the soul inside is immutable and indestructible and takes on different lives in a cycle of birth and death. The end of this cycle is called "mukti" (Sanskrit: मुक्ति) and staying finally with supreme God forever; is "moksha" (Sanskrit: मोक्ष) or salvation.

The Garuda Purana deals solely with what happens to a person after death. The God of Death Yama sends his representatives to collect the soul from a person's body whenever he is due for death and they take the soul to Yama. A record of each person's timings & deeds performed by him is kept in a ledger by Yama's assistant, Chitragupta.

According to the Garuda Purana, a soul after leaving the body travels through a very long and dark tunnel towards the South. This is why an oil lamp is lit and kept beside the head of the corpse, to light the dark tunnel and allow the soul to travel comfortably.

The soul, called "atman" leaves the body and reincarnates itself according to the deeds or "karma" performed by one in last birth. Rebirth would be in form of animals or other lower creatures if one performed bad karmas and in human form in a good family with joyous lifetime if the person was good in last birth. In between the two births a human is also required to either face punishments for bad karmas in "naraka" or hell or enjoy for the good karmas in "swarga" or heaven for good deeds. Whenever his or her punishments or rewards are over he or she is sent back to earth, also known as "Mrutyulok" or human world. A person stays with the God or ultimate power when he discharges only & only "yajna karma" (means work done for satisfaction of supreme lord only) in last birth and the same is called as "moksha" or "nirvana", which is the ultimate goal of a self realised soul. "Atma" moves with "Parmatma" or the greatest soul. According to Bhagavad Gita an "Atma" or soul never dies, what dies is the body only made of five elements—Earth, Water, Fire, Air, and Sky. Soul is believed to be indestructible. None of the five elements can harm or influence it. Hinduism through Garuda Purana also describes in detail various types of "narkas" or Hells where a person after death is punished for his bad "karmas" and dealt with accordingly.

Hindus also believe in "karma". "Karma" is the accumulated sums of one's good or bad deeds. "Satkarma" means good deeds, "vikarma" means bad deeds. According to Hinduism the basic concept of karma is 'As you sow, you shall reap'. So, if a person has lived a good life, they will be rewarded in the afterlife. Similarly their sum of bad deeds will be mirrored in their next life. Good karma brings good rewards and bad karmas lead to bad results. There is no judgment here. People accumulate karma through their actions and even thoughts. In Bhagavad Gita when Arjuna hesitates to kill his kith and kin the lord reprimands him saying thus

"Do you believe that you are the doer of the action. No. You are merely an instrument in MY hands. Do you believe that the people in front of you are living? Dear Arjuna, they are already dead. As a "kshatriya" (warrior) it is your duty to protect your people and land. If you fail to do your duty, then you are not adhering to dharmic principles."

Jainism also believes in the afterlife. They believe that the soul takes on a body form based on previous karmas or actions performed by that soul through eternity. Jains believe the soul is eternal and that the freedom from the cycle of reincarnation is the means to attain eternal bliss.

The essential doctrine of Sikhism is to experience the divine through simple living, meditation and contemplation while being alive. Sikhism also has the belief of being in union with God while living. Accounts of afterlife are considered to be aimed at the popular prevailing views of the time so as to provide a referential framework without necessarily establishing a belief in the afterlife. Thus while it is also acknowledged that living the life of a householder is above the metaphysical truth, Sikhism can be considered agnostic to the question of an afterlife. Some scholars also interpret the mention of reincarnation to be naturalistic akin to the biogeochemical cycles.

But if one analyses the Sikh Scriptures carefully, one may find that on many occasions the afterlife and the existence of heaven and hell are mentioned in "Guru Granth Sahib" and in "Dasam Granth", so from that it can be concluded that Sikhism does believe in the existence of heaven and hell; however, heaven and hell are created to temporarily reward and punish, and one will then take birth again until one merges in God. According to the Sikh scriptures, the human form is the closet form to God and the best opportunity for a human being to attain salvation and merge back with God. Sikh Gurus said that nothing dies, nothing is born, everything is ever present, and it just changes forms. Like standing in front of a wardrobe, you pick up a dress and wear it and then you discard it. You wear another one. Thus, in the view of Sikhism, your soul is never born and never dies. Your soul is a part of God and hence lives forever.

Traditional African religions are diverse in their beliefs in an afterlife. Hunter-gatherer societies such as the Hadza have no particular belief in an afterlife, and the death of an individual is a straightforward end to their existence. Ancestor cults are found throughout Sub-Saharan Africa, including cultures like the Yombe, Beng, Yoruba and Ewe, "[T]he belief that the dead come back into life and are reborn into their families is given concrete expression in the personal names that are given to children...What is reincarnated are some of the dominant characteristics of the ancestor and not his soul. For each soul remains distinct and each birth represents a new soul." The Yoruba, Dogon and LoDagoa have eschatological ideas similar to Abrahamic religions, "but in most African societies, there is a marked absence of such clear-cut notions of heaven and hell, although there are notions of God judging the soul after death." In some societies like the Mende, multiple beliefs coexist. The Mende believe that people die twice: once during the process of joining the secret society, and again during biological death after which they become ancestors. However, some Mende also believe that after people are created by God they live ten consecutive lives, each in progressively descending worlds. One cross-cultural theme is that the ancestors are part of the world of the living, interacting with it regularly.

It is common for families to participate in ceremonies for children at a shrine, yet have a Buddhist funeral at the time of death. In old Japanese legends, it is often claimed that the dead go to a place called "yomi" (黄泉), a gloomy underground realm with a river separating the living from the dead mentioned in the legend of Izanami and Izanagi. This "yomi" very closely resembles the Greek Hades; however, later myths include notions of resurrection and even Elysium-like descriptions such as in the legend of Okuninushi and Susanoo. Shinto tends to hold negative views on death and corpses as a source of pollution called "kegare". However, death is also viewed as a path towards apotheosis in Shintoism as can be evidenced by how legendary individuals become enshrined after death. Perhaps the most famous would be Emperor Ojin who was enshrined as Hachiman the God of War after his death.

Some Unitarian Universalists believe in universalism: that all souls will ultimately be saved and that there are no torments of hell. Unitarian Universalists differ widely in their theology hence there is no exact same stance on the issue. Although Unitarians historically believed in a literal hell, and Universalists historically believed that everyone goes to heaven, modern Unitarian Universalists can be categorized into those believing in a heaven, reincarnation and oblivion. Most Unitarian Universalists believe that heaven and hell are symbolic places of consciousness and the faith is largely focused on the worldly life rather than any possible afterlife.

According to Edgar Cayce, the afterlife consisted of nine realms equated with the nine planets of astrology. The first, symbolized by Saturn, was a level for the purification of the souls. The second, Mercury's realm, gives us the ability to consider problems as a whole. The third of the nine soul realms is ruled by Earth and is associated with the Earthly pleasures. The fourth realm is where we find out about love and is ruled by Venus. The fifth realm is where we meet our limitations and is ruled by Mars. The sixth realm is ruled by Neptune, and is where we begin to use our creative powers and free ourselves from the material world. The seventh realm is symbolized by Jupiter, which strengthens the soul's ability to depict situations, to analyze people and places, things, and conditions. The eighth afterlife realm is ruled by Uranus and develops psychic ability. The ninth afterlife realm is symbolized by Pluto, the astrological realm of the unconscious. This afterlife realm is a transient place where souls can choose to travel to other realms or other solar systems, it is the souls liberation into eternity, and is the realm that opens the doorway from our solar system into the cosmos.

Mainstream Spiritualists postulate a series of seven realms that are not unlike Edgar Cayce's nine realms ruled by the planets. As it evolves, the soul moves higher and higher until it reaches the ultimate realm of spiritual oneness. The first realm, equated with hell, is the place where troubled souls spend a long time before they are compelled to move up to the next level. The second realm, where most souls move directly, is thought of as an intermediate transition between the lower planes of life and hell and the higher perfect realms of the universe. The third level is for those who have worked with their karmic inheritance. The fourth level is that from which evolved souls teach and direct those on Earth. The fifth level is where the soul leaves human consciousness behind. At the sixth plane, the soul is finally aligned with the cosmic consciousness and has no sense of separateness or individuality. Finally, the seventh level, the goal of each soul, is where the soul transcends its own sense of "soulfulness" and reunites with the World Soul and the universe.

The Wiccan afterlife is most commonly described as The Summerland. Here, souls rest, recuperate from life, and reflect on the experiences they had during their lives. After a period of rest, the souls are reincarnated, and the memory of their previous lives is erased. Many Wiccans see The Summerland as a place to reflect on their life actions. It is not a place of reward, but rather the end of a life journey at an end point of incarnations.

Zoroastrianism states that the "urvan", the disembodied spirit, lingers on earth for three days before departing downward to the kingdom of the dead that is ruled by Yima. For the three days that it rests on Earth, righteous souls sit at the head of their body, chanting the Ustavaiti Gathas with joy, while a wicked person sits at the feet of the corpse, wails and recites the Yasna. Zoroastrianism states that for the righteous souls, a beautiful maiden, which is the personification of the soul's good thoughts, words and deeds, appears. For a wicked person, a very old, ugly, naked hag appears. After three nights, the soul of the wicked is taken by the demon Vizaresa (Vīzarəša), to Chinvat bridge, and is made to go to darkness (hell).

Yima is believed to have been the first king on earth to rule, as well as the first man to die. Inside of Yima's realm, the spirits live a shadowy existence, and are dependent on their own descendants which are still living on Earth. Their descendants are to satisfy their hunger and clothe them, through rituals done on earth.

Rituals which are done on the first three days are vital and important, as they protect the soul from evil powers and give it strength to reach the underworld. After three days, the soul crosses Chinvat bridge which is the Final Judgment of the soul. Rashnu and Sraosha are present at the final judgment. The list is expanded sometimes, and include Vahman and Ormazd. Rashnu is the yazata who holds the scales of justice. If the good deeds of the person outweigh the bad, the soul is worthy of paradise. If the bad deeds outweigh the good, the bridge narrows down to the width of a blade-edge, and a horrid hag pulls the soul in her arms, and takes it down to hell with her.

Misvan Gatu is the "place of the mixed ones" where the souls lead a gray existence, lacking both joy and sorrow. A soul goes here if his/her good deeds and bad deeds are equal, and Rashnu's scale is equal.

The Society for Psychical Research was founded in 1882 with the express intention of investigating phenomena relating to Spiritualism and the afterlife. Its members continue to conduct scientific research on the paranormal to this day. Some of the earliest attempts to apply scientific methods to the study of phenomena relating to an afterlife were conducted by this organization. Its earliest members included noted scientists like William Crookes, and philosophers such as Henry Sidgwick and William James.

Parapsychological investigation of the afterlife includes the study of haunting, apparitions of the deceased, instrumental trans-communication, electronic voice phenomena, and mediumship. Research also includes the study of the near death experience. Scientists who have worked in this area include Raymond Moody, Susan Blackmore, Charles Tart, William James, Ian Stevenson, Michael Persinger, Pim van Lommel and Penny Sartori among others.

A study conducted in 1901 by physician Duncan MacDougall sought to measure the weight lost by a human when the soul "departed the body" upon death. MacDougall weighed dying patients in an attempt to prove that the soul was material, tangible and thus measurable. Although MacDougall's results varied considerably from "21 grams", for some people this figure has become synonymous with the measure of a soul's mass. The title of the 2003 movie "21 Grams" is a reference to MacDougall's findings. His results have never been reproduced, and are generally regarded either as meaningless or considered to have had little if any scientific merit.

Frank Tipler has argued that physics can explain immortality, although such arguments are not falsifiable and, in Karl Popper's views, they do not qualify as science.

After 25 years of parapsychological research Susan Blackmore came to the conclusion that, according to her experiences, there is not enough empirical evidence for many of these cases.

There is a view based on the philosophical question of personal identity, termed open individualism by Daniel Kolak. It concludes that individual conscious experience is illusory, and because consciousness continues after death in all conscious beings, "you" do not die. This position has been supported by notable physicists such as Erwin Schrödinger and Freeman Dyson.

Certain problems arise with the idea of a particular person continuing after death. Peter van Inwagen, in his argument regarding resurrection, notes that the materialist must have some sort of physical continuity. John Hick also raises some questions regarding personal identity in his book, "Death and Eternal Life" using an example of a person ceasing to exist in one place while an exact replica appears in another. If the replica had all the same experiences, traits, and physical appearances of the first person, we would all attribute the same identity to the second, according to Hick.

In the panentheistic model of process philosophy and theology the writers Alfred North Whitehead and Charles Hartshorne rejected that the universe was made of substance, instead reality is composed of living experiences (occasions of experience). According to Hartshorne people do not experience subjective (or personal) immortality in the afterlife, but they do have objective immortality because their experiences live on forever in God, who contains all that was. However other process philosophers such as David Ray Griffin have written that people may have subjective experience after death.

Whether or not science can itself falsify the existence of an afterlife, neuroscientists philosophically opining on the mind–body problem have generally separated into three camps. The first, known as mind-body dualism, holds that consciousness is separate from the mind. The second, panpsychism states that all beings in the universe are conscious at different levels. Others lean towards a physicalist position. In this view, consciousness derives from and/or is reducible to physical phenomena such as neuronal activity occurring in the brain. Some say that if physicalism is true, then once the brain stops functioning at brain death, consciousness presumably fails to survive and ceases to exist.

Psychological proposals for the origin of a belief in an afterlife include cognitive disposition, cultural learning, and as an intuitive religious idea. In one study, children were able to recognize the ending of physical, mental, and perceptual activity in death, but were hesitant to conclude the ending of will, self, or emotion in death.

In 2008, a large-scale study conducted by the University of Southampton involving 2060 patients from 15 hospitals in the United Kingdom, United States and Austria was launched. The AWARE (AWAreness during REsuscitation) study examined the broad range of mental experiences in relation to death. In a large study, researchers also tested the validity of conscious experiences for the first time using objective markers, to determine whether claims of awareness compatible with out-of-body experiences correspond with real or hallucinatory events. The results revealed that 40% of those who survived a cardiac arrest were aware during the time that they were clinically dead and before their hearts were restarted. One patient also had a verified out-of-body experience (over 80% of patients did not survive their cardiac arrest or were too sick to be interviewed), but his cardiac arrest occurred in a room without markers. Dr. Parnia in the interview stated, "The evidence thus far suggests that in the first few minutes after death, consciousness is not annihilated." The study continues in AWARE II, which is set to be completed in September 2020.

Studies have also been done on the widely reported phenomenon of Near Death Experiences. Experiencers commonly report being transported to a different “realm” or “plane of existence” and they have been shown to display a lasting positive aftereffects on most experiencers.


 


</doc>
<doc id="1181" url="https://en.wikipedia.org/wiki?curid=1181" title="Astrometry">
Astrometry

Astrometry is the branch of astronomy that involves precise measurements of the positions and movements of stars and other celestial bodies. The information obtained by astrometric measurements provides information on the kinematics and physical origin of the Solar System and our galaxy, the Milky Way.

The history of astrometry is linked to the history of star catalogues, which gave astronomers reference points for objects in the sky so they could track their movements. This can be dated back to Hipparchus, who around 190 BC used the catalogue of his predecessors Timocharis and Aristillus to discover Earth's precession. In doing so, he also developed the brightness scale still in use today. Hipparchus compiled a catalogue with at least 850 stars and their positions. Hipparchus's successor, Ptolemy, included a catalogue of 1,022 stars in his work the "Almagest", giving their location, coordinates, and brightness.

In the 10th century, Abd al-Rahman al-Sufi carried out observations on the stars and described their positions, magnitudes and star color; furthermore, he provided drawings for each constellation, which are depicted in his "Book of Fixed Stars". Ibn Yunus observed more than 10,000 entries for the Sun's position for many years using a large astrolabe with a diameter of nearly 1.4 metres. His observations on eclipses were still used centuries later in Simon Newcomb's investigations on the motion of the Moon, while his other observations of the motions of the planets Jupiter and Saturn inspired Laplace's "Obliquity of the Ecliptic" and "Inequalities of Jupiter and Saturn". In the 15th century, the Timurid astronomer Ulugh Beg compiled the "Zij-i-Sultani", in which he catalogued 1,019 stars. Like the earlier catalogs of Hipparchus and Ptolemy, Ulugh Beg's catalogue is estimated to have been precise to within approximately 20 minutes of arc.

In the 16th century, Tycho Brahe used improved instruments, including large mural instruments, to measure star positions more accurately than previously, with a precision of 15–35 arcsec. Taqi al-Din measured the right ascension of the stars at the Constantinople Observatory of Taqi ad-Din using the "observational clock" he invented. When telescopes became commonplace, setting circles sped measurements

James Bradley first tried to measure stellar parallaxes in 1729. The stellar movement proved too insignificant for his telescope, but he instead discovered the aberration of light and the nutation of the Earth's axis. His cataloguing of 3222 stars was refined in 1807 by Friedrich Bessel, the father of modern astrometry. He made the first measurement of stellar parallax: 0.3 arcsec for the binary star 61 Cygni.

Being very difficult to measure, only about 60 stellar parallaxes had been obtained by the end of the 19th century, mostly by use of the filar micrometer. Astrographs using astronomical photographic plates sped the process in the early 20th century. Automated plate-measuring machines and more sophisticated computer technology of the 1960s allowed more efficient compilation of star catalogues. In the 1980s, charge-coupled devices (CCDs) replaced photographic plates and reduced optical uncertainties to one milliarcsecond. This technology made astrometry less expensive, opening the field to an amateur audience.

In 1989, the European Space Agency's Hipparcos satellite took astrometry into orbit, where it could be less affected by mechanical forces of the Earth and optical distortions from its atmosphere. Operated from 1989 to 1993, Hipparcos measured large and small angles on the sky with much greater precision than any previous optical telescopes. During its 4-year run, the positions, parallaxes, and proper motions of 118,218 stars were determined with an unprecedented degree of accuracy. A new "Tycho catalog" drew together a database of 1,058,332 to within 20-30 mas (milliarcseconds). Additional catalogues were compiled for the 23,882 double/multiple stars and 11,597 variable stars also analyzed during the Hipparcos mission.

Today, the catalogue most often used is USNO-B1.0, an all-sky catalogue that tracks proper motions, positions, magnitudes and other characteristics for over one billion stellar objects. During the past 50 years, 7,435 Schmidt camera plates were used to complete several sky surveys that make the data in USNO-B1.0 accurate to within 0.2 arcsec.

Apart from the fundamental function of providing astronomers with a reference frame to report their observations in, astrometry is also fundamental for fields like celestial mechanics, stellar dynamics and galactic astronomy. In observational astronomy, astrometric techniques help identify stellar objects by their unique motions. It is instrumental for keeping time, in that UTC is essentially the atomic time synchronized to Earth's rotation by means of exact astronomical observations. Astrometry is an important step in the cosmic distance ladder because it establishes parallax distance estimates for stars in the Milky Way.

Astrometry has also been used to support claims of extrasolar planet detection by measuring the displacement the proposed planets cause in their parent star's apparent position on the sky, due to their mutual orbit around the center of mass of the system. Astrometry is more accurate in space missions that are not affected by the distorting effects of the Earth's atmosphere. NASA's planned Space Interferometry Mission (SIM PlanetQuest) (now cancelled) was to utilize astrometric techniques to detect terrestrial planets orbiting 200 or so of the nearest solar-type stars. The European Space Agency's Gaia Mission, launched in 2013, applies astrometric techniques in its stellar census. In addition to the detection of exoplanets, it can also be used to determine their mass.

Astrometric measurements are used by astrophysicists to constrain certain models in celestial mechanics. By measuring the velocities of pulsars, it is possible to put a limit on the asymmetry of supernova explosions. Also, astrometric results are used to determine the distribution of dark matter in the galaxy.

Astronomers use astrometric techniques for the tracking of near-Earth objects. Astrometry is responsible for the detection of many record-breaking Solar System objects. To find such objects astrometrically, astronomers use telescopes to survey the sky and large-area cameras to take pictures at various determined intervals. By studying these images, they can detect Solar System objects by their movements relative to the background stars, which remain fixed. Once a movement per unit time is observed, astronomers compensate for the parallax caused by Earth's motion during this time and the heliocentric distance to this object is calculated. Using this distance and other photographs, more information about the object, including its orbital elements, can be obtained.

50000 Quaoar and 90377 Sedna are two Solar System objects discovered in this way by Michael E. Brown and others at Caltech using the Palomar Observatory's Samuel Oschin telescope of and the Palomar-Quest large-area CCD camera. The ability of astronomers to track the positions and movements of such celestial bodies is crucial to the understanding of the Solar System and its interrelated past, present, and future with others in the Universe.

A fundamental aspect of astrometry is error correction. Various factors introduce errors into the measurement of stellar positions, including atmospheric conditions, imperfections in the instruments and errors by the observer or the measuring instruments. Many of these errors can be reduced by various techniques, such as through instrument improvements and compensations to the data. The results are then analyzed using statistical methods to compute data estimates and error ranges.







</doc>
<doc id="1182" url="https://en.wikipedia.org/wiki?curid=1182" title="Athena">
Athena

Athena or Athene, often given the epithet Pallas, is an ancient Greek goddess associated with wisdom, handicraft, and warfare who was later syncretized with the Roman goddess Minerva. Athena was regarded as the patron and protectress of various cities across Greece, particularly the city of Athens, from which she most likely received her name. She's usually shown in art wearing a helmet and holding a spear. Her major symbols include owls, olive trees, snakes, and the Gorgoneion.

From her origin as an Aegean palace goddess, Athena was closely associated with the city. She was known as "Polias" and "Poliouchos" (both derived from "polis", meaning "city-state"), and her temples were usually located atop the fortified acropolis in the central part of the city. The Parthenon on the Athenian Acropolis is dedicated to her, along with numerous other temples and monuments. As the patron of craft and weaving, Athena was known as "Ergane". She's also a warrior goddess, and was believed to lead soldiers into battle as "Athena Promachos". Her main festival in Athens was the Panathenaia, which was celebrated during the month of Hekatombaion in midsummer and was the most important festival on the Athenian calendar.

In Greek mythology, Athena was believed to have been born from the head of her father Zeus. In the founding myth of Athens, Athena bested Poseidon in a competition over patronage of the city by creating the first olive tree. She's known as "Athena Parthenos" "Athena the Virgin," but in one archaic Attic myth, the god Hephaestus tried and failed to rape her, resulting in Gaia giving birth to Erichthonius, an important Athenian founding hero. Athena was the patron goddess of heroic endeavor; she was believed to have aided the heroes Perseus, Heracles, Bellerophon, and Jason. Along with Aphrodite and Hera, Athena was one of the three goddesses whose feud resulted in the beginning of the Trojan War.

She plays an active role in the "Iliad", in which she assists the Achaeans and, in the "Odyssey", she is the divine counselor to Odysseus. In the later writings of the Roman poet Ovid, Athena was said to have competed against the mortal Arachne in a weaving competition, afterwards transforming Arachne into the first spider; Ovid also describes how she transformed Medusa into a Gorgon after witnessing her being raped by Poseidon in her temple. Since the Renaissance, Athena has become an international symbol of wisdom, the arts, and classical learning. Western artists and allegorists have often used Athena as a symbol of freedom and democracy.

Athena is associated with the city of Athens. The name of the city in ancient Greek is (), a plural toponym, designating the place where—according to myth—she presided over the "Athenai", a sisterhood devoted to her worship. In ancient times, scholars argued whether Athena was named after Athens or Athens after Athena. Now scholars generally agree that the goddess takes her name from the city; the ending -"ene" is common in names of locations, but rare for personal names. Testimonies from different cities in ancient Greece attest that similar city goddesses were worshipped in other cities and, like Athena, took their names from the cities where they were worshipped. For example, in Mycenae there was a goddess called Mykene, whose sisterhood was known as "Mykenai", whereas at Thebes an analogous deity was called Thebe, and the city was known under the plural form "Thebai" (or Thebes, in English, where the 's' is the plural formation). The name "Athenai" is likely of Pre-Greek origin because it contains the presumably Pre-Greek morpheme "*-ān-".

In his dialogue "Cratylus", the ancient Greek philosopher Plato (428–347 BC) gives some rather imaginative etymologies of Athena's name, based on the theories of the ancient Athenians and his own etymological speculations:

Thus, Plato believed that Athena's name was derived from Greek , —which the later Greeks rationalised as from the deity's (, ) mind (, ). The second-century AD orator Aelius Aristides attempted to derive natural symbols from the etymological roots of Athena's names to be "aether", "air", "earth", and "moon".

Athena was originally the Aegean goddess of the palace, who presided over household crafts and protected the king. A single Mycenaean Greek inscription /Athana potnia/ appears at Knossos in the Linear B tablets from the Late Minoan II-era "Room of the Chariot Tablets"; these comprise the earliest Linear B archive anywhere. Although "Athana potnia" is often translated "Mistress Athena", it could also mean "the "Potnia" of Athana", or "the Lady of Athens". However, any connection to the city of Athens in the Knossos inscription is uncertain. A sign series appears in the still undeciphered corpus of Linear A tablets, written in the unclassified Minoan language. This could be connected with the Linear B Mycenaean expressions and or ("Diwia", "of Zeus" or, possibly, related to a homonymous goddess), resulting in a translation "Athena of Zeus" or "divine Athena". Similarly, in the Greek mythology and epic tradition, Athena figures as a daughter of Zeus (; "cfr." Dyeus). However, the inscription quoted seems to be very similar to "", quoted as SY Za 1 by Jan Best. Best translates the initial , which is recurrent in line beginnings, as "I have given".

A Mycenean fresco depicts two women extending their hands towards a central figure, who is covered by an enormous figure-eight shield; this may depict the warrior-goddess with her "palladion", or her palladion in an aniconic representation. In the "Procession Fresco" at Knossos, which was reconstructed by the Mycenaeans, two rows of figures carrying vessels seem to meet in front of a central figure, which is probably the Minoan precursor to Athena. The early twentieth-century scholar Martin Persson Nilsson argued that the Minoan snake goddess figurines are early representations of Athena.

Nilsson and others have claimed that, in early times, Athena was either an owl herself or a bird goddess in general. In the third book of the "Odyssey", she takes the form of a sea-eagle. Proponents of this view argue that she dropped her prophylactic owl-mask before she lost her wings. "Athena, by the time she appears in art," Jane Ellen Harrison remarks, "has completely shed her animal form, has reduced the shapes she once wore of snake and bird to attributes, but occasionally in black-figure vase-paintings she still appears with wings."

It is generally agreed that the cult of Athena preserves some aspects of the Proto-Indo-European transfunctional goddess. The cult of Athena may have also been influenced by those of Near Eastern warrior goddesses such as the East Semitic Ishtar and the Ugaritic Anat, both of whom were often portrayed bearing arms. Classical scholar Charles Penglase notes that Athena closely resembles Inanna in her role as a "terrifying warrior goddess" and that both goddesses were closely linked with creation. Athena's birth from the head of Zeus may be derived from the earlier Sumerian myth of Inanna's descent into and return from the Underworld.

Plato notes that the citizens of Sais in Egypt worshipped a goddess known as Neith, whom he identifies with Athena. Neith was the ancient Egyptian goddess of war and hunting, who was also associated with weaving; her worship began during the Egyptian Pre-Dynastic period. In Greek mythology, Athena was reported to have visited mythological sites in North Africa, including Libya's Triton River and the Phlegraean plain. Based on these similarities, the Sinologist Martin Bernal created the "Black Athena" hypothesis, which claimed that Neith was brought to Greece from Egypt, along with "an enormous number of features of civilization and culture in the third and second millennia". The "Black Athena" hypothesis stirred up widespread controversy near the end of the twentieth century, but it has now been widely rejected by modern scholars.

In her aspect of "Athena Polias", Athena was venerated as the goddess of the city and the protectress of the citadel. In Athens, the Plynteria, or "Feast of the Bath", was observed every year at the end of the month of Thargelion. The festival lasted for five days. During this period, the priestesses of Athena, or "plyntrídes", performed a cleansing ritual within the Erechtheion, a sanctuary devoted to Athena and Poseidon. Here Athena's statue was undressed, her clothes washed, and body purified. Athena was worshipped at festivals such as Chalceia as "Athena Ergane", the patroness of various crafts, especially weaving. She was also the patron of metalworkers and was believed to aid in the forging of armor and weapons. During the late fifth century BC, the role of goddess of philosophy became a major aspect of Athena's cult.

As "Athena Promachos", she was believed to lead soldiers into battle. Athena represented the disciplined, strategic side of war, in contrast to her brother Ares, the patron of violence, bloodlust, and slaughter—"the raw force of war". Athena was believed to only support those fighting for a just cause and was thought to view war primarily as a means to resolve conflict. The Greeks regarded Athena with much higher esteem than Ares. Athena was especially worshipped in this role during the festivals of the Panathenaea and Pamboeotia, both of which prominently featured displays of athletic and military prowess. As the patroness of heroes and warriors, Athena was believed to favor those who used cunning and intelligence rather than brute strength.

In her aspect as a warrior maiden, Athena was known as "Parthenos" ( "virgin"), because, like her fellow goddesses Artemis and Hestia, she was believed to remain perpetually a virgin. Athena's most famous temple, the Parthenon on the Athenian Acropolis, takes its name from this title. According to Karl Kerényi, a scholar of Greek mythology, the name "Parthenos" is not merely an observation of Athena's virginity, but also a recognition of her role as enforcer of rules of sexual modesty and ritual mystery. Even beyond recognition, the Athenians allotted the goddess value based on this pureness of virginity, which they upheld as a rudiment of female behavior. Kerényi's study and theory of Athena explains her virginal epithet as a result of her relationship to her father Zeus and a vital, cohesive piece of her character throughout the ages. This role is expressed in a number of stories about Athena. Marinus of Neapolis reports that when Christians removed the statue of the goddess from the Parthenon, a beautiful woman appeared in a dream to Proclus, a devotee of Athena, and announced that the ""Athenian Lady"" wished to dwell with him.

Athena was not only the patron goddess of Athens, but also other cities, including Argos, Sparta, Gortyn, Lindos, and Larisa. The various cults of Athena were all branches of her panhellenic cult and often proctored various initiation rites of Grecian youth, such as the passage into citizenship by young men or the passage of young women into marriage. These cults were portals of a uniform socialization, even beyond mainland Greece. Athena was frequently equated with Aphaea, a local goddess of the island of Aegina, originally from Crete and also associated with Artemis and the nymph Britomartis. In Arcadia, she was assimilated with the ancient goddess Alea and worshiped as Athena Alea. Sanctuaries dedicated to Athena Alea were located in the Laconian towns of Mantineia and Tegea. The temple of Athena Alea in Tegea was an important religious center of ancient Greece. The geographer Pausanias was informed that the "temenos" had been founded by Aleus.

Athena had a major temple on the Spartan Acropolis, where she was venerated as Poliouchos and "Khalkíoikos" ("of the Brazen House", often latinized as "Chalcioecus"). This epithet may refer to the fact that cult statue held there may have been made of bronze, that the walls of the temple itself may have been made of bronze, or that Athena was the patron of metal-workers. Bells made of terracotta and bronze were used in Sparta as part of Athena's cult. An Ionic-style temple to Athena Polias was built at Priene in the fourth century BC. It was designed by Pytheos of Priene, the same architect who designed the Mausoleum at Halicarnassus. The temple was dedicated by Alexander the Great and an inscription from the temple declaring his dedication is now held in the British Museum.

Athena was known as "Atrytone" ( "the Unwearying"), "Parthenos" ( "Virgin"), and "Promachos" ( "she who fights in front"). The epithet "Polias" (Πολιάς "of the city"), refers to Athena's role as protectress of the city. The epithet "Ergane" (Εργάνη "the Industrious") pointed her out as the patron of craftsmen and artisans. Burkert notes that the Athenians sometimes simply called Athena "the Goddess", "hē theós" (ἡ θεός), certainly an ancient title. After serving as the judge at the trial of Orestes in which he was acquitted of having murdered his mother Clytemnestra, Athena won the epithet "Areia" (Αρεία).

Athena was sometimes given the epithet "Hippia" (Ἵππια "of the horses", "equestrian"), referring to her invention of the bit, bridle, chariot, and wagon. The Greek geographer Pausanias mentions in his "Guide to Greece" that the temple of Athena "Chalinitis" ("the bridler") in Corinth was located near the tomb of Medea's children. Other epithets include Ageleia, Itonia and "Aethyia", under which she was worshiped in Megara. The word "aíthyia" () signifies a "diver", also some diving bird species (possibly the shearwater) and figuratively, a "ship", so the name must reference Athena teaching the art of shipbuilding or navigation. In a temple at Phrixa in Elis, reportedly built by Clymenus, she was known as "Cydonia" (Κυδωνία).

The Greek biographer Plutarch (AD 46–120) refers to an instance during the Parthenon's construction of her being called "Athena Hygieia" (Ὑγίεια, i. e. personified "Health") after inspiring a physician to a successful course of treatment.

In Homer's epic works, Athena's most common epithet is "Glaukopis" (), which usually is translated as, "bright-eyed" or "with gleaming eyes". The word is a combination of "glaukós" (, meaning "gleaming, silvery", and later, "bluish-green" or "gray") and "ṓps" (, "eye, face"). The word "glaúx" (, "little owl") is from the same root, presumably according to some, because of the bird's own distinctive eyes. Athena was clearly associated with the owl from very early on; in archaic images, she is frequently depicted with an owl perched on her hand. Through its association with Athena, the owl evolved into the national mascot of the Athenians and eventually became a symbol of wisdom.

In the "Iliad" (4.514), the "Odyssey" (3.378), the "Homeric Hymns", and in Hesiod's "Theogony", Athena is also given the curious epithet "Tritogeneia" (Τριτογένεια), whose significance remains unclear. It could mean various things, including "Triton-born", perhaps indicating that the homonymous sea-deity was her parent according to some early myths. One myth relates the foster father relationship of this Triton towards the half-orphan Athena, whom he raised alongside his own daughter Pallas. Kerényi suggests that "Tritogeneia did not mean that she came into the world on any particular river or lake, but that she was born of the water itself; for the name Triton seems to be associated with water generally." In Ovid's "Metamorphoses", Athena is occasionally referred to as "Tritonia".

Another possible meaning may be "triple-born" or "third-born", which may refer to a triad or to her status as the third daughter of Zeus or the fact she was born from Metis, Zeus, and herself; various legends list her as being the first child after Artemis and Apollo, though other legends identify her as Zeus' first child. Several scholars have suggested a connection to the Rigvedic god Trita, who was sometimes grouped in a body of three mythological poets. Michael Janda has connected the myth of Trita to the scene in the "Iliad" in which the "three brothers" Zeus, Poseidon, and Hades divide the world between them, receiving the "broad sky", the sea, and the underworld respectively. Janda further connects the myth of Athena being born of the head (i. e. the uppermost part) of Zeus, understanding "Trito-" (which perhaps originally meant "the third") as another word for "the sky". In Janda's analysis of Indo-European mythology, this heavenly sphere is also associated with the mythological body of water surrounding the inhabited world ("cfr." Triton's mother, Amphitrite).

Yet another possible meaning is mentioned in Diogenes Laertius' biography of Democritus, that Athena was called "Tritogeneia" because three things, on which all mortal life depends, come from her.

In the classical Olympian pantheon, Athena was regarded as the favorite daughter of Zeus, born fully armed from his forehead. The story of her birth comes in several versions. The earliest mention is in Book V of the "Iliad", when Ares accuses Zeus of being biased in favor of Athena because ""autos egeinao"" (literally "you fathered her", but probably intended as "you gave birth to her").

In the version recounted by Hesiod in his "Theogony", Zeus married the goddess Metis, who is described as the "wisest among gods and mortal men", and engaged in sexual intercourse with her. After learning that Metis was pregnant, however, he became afraid that the unborn offspring would try to overthrow him, because Gaia and Ouranos had prophesied that Metis would bear children wiser than their father. In order to prevent this, Zeus tricked Metis into letting him swallow her, but it was too late because Metis had already conceived. A later account of the story from the "Bibliotheca" of Pseudo-Apollodorus, written in the second century AD, makes Metis Zeus's unwilling sexual partner, rather than his wife. According to this version of the story, Metis transformed into many different shapes in effort to escape Zeus, but Zeus successfully raped her and swallowed her.

After swallowing Metis, Zeus took six more wives in succession until he married his seventh and present wife, Hera. Then Zeus experienced an enormous headache. He was in such pain that he ordered someone (either Prometheus, Hephaestus, Hermes, Ares, or Palaemon, depending on the sources examined) to cleave his head open with the "labrys", the double-headed Minoan axe. Athena leaped from Zeus's head, fully grown and armed. The "First Homeric Hymn to Athena" states in lines 9–16 that the gods were awestruck by Athena's appearance and even Helios, the god of the sun, stopped his chariot in the sky. Pindar, in his "Seventh Olympian Ode", states that she "cried aloud with a mighty shout" and that "the Sky and mother Earth shuddered before her."

Hesiod states that Hera was so annoyed at Zeus for having given birth to a child on his own that she conceived and bore Hephaestus by herself, but in "Imagines" 2. 27 (trans. Fairbanks), the third-century AD Greek rhetorician Philostratus the Elder writes that Hera "rejoices" at Athena's birth "as though Athena were her daughter also." The second-century AD Christian apologist Justin Martyr takes issue with those pagans who erect at springs images of Kore, whom he interprets as Athena: "They said that Athena was the daughter of Zeus not from intercourse, but when the god had in mind the making of a world through a word ("logos") his first thought was Athena." According to a version of the story in a scholium on the "Iliad" (found nowhere else), when Zeus swallowed Metis, she was pregnant with Athena by the Cyclops Brontes. The "Etymologicum Magnum" instead deems Athena the daughter of the Daktyl Itonos. Fragments attributed by the Christian Eusebius of Caesarea to the semi-legendary Phoenician historian Sanchuniathon, which Eusebius thought had been written before the Trojan war, make Athena instead the daughter of Cronus, a king of Byblos who visited "the inhabitable world" and bequeathed Attica to Athena.

Athena's epithet "Pallas" is derived either from , meaning "to brandish [as a weapon]", or, more likely, from and related words, meaning "youth, young woman". On this topic, Walter Burkert says "she is the Pallas of Athens, "Pallas Athenaie", just as Hera of Argos is "Here Argeie"." In later times, after the original meaning of the name had been forgotten, the Greeks invented myths to explain its origin, such as those reported by the Epicurean philosopher Philodemus and the "Bibliotheca" of Pseudo-Apollodorus, which claim that "Pallas" was originally a separate entity, whom Athena had slain in combat.

In one version of the myth, Pallas was the daughter of the sea-god Triton; she and Athena were childhood friends, but Athena accidentally killed her during a friendly sparring match. Distraught over what she had done, Athena took the name Pallas for herself as a sign of her grief. In another version of the story, Pallas was a Gigante; Athena slew him during the Gigantomachy and flayed off his skin to make her cloak, which she wore as a victory trophy. In an alternative variation of the same myth, Pallas was instead Athena's father, who attempted to assault his own daughter, causing Athena to kill him and take his skin as a trophy.

The "palladion" was a statue of Athena that was said to have stood in her temple on the Trojan Acropolis. Athena was said to have carved the statue herself in the likeness of her dead friend Pallas. The statue had special talisman-like properties and it was thought that, as long as it was in the city, Troy could never fall. When the Greeks captured Troy, Cassandra, the daughter of Priam, clung to the palladion for protection, but Ajax the Lesser violently tore her away from it and dragged her over to the other captives. Athena was infuriated by this violation of her protection. Although Agamemnon attempted to placate her anger with sacrifices, Athena sent a storm at Cape Kaphereos to destroy almost the entire Greek fleet and scatter all of the surviving ships across the Aegean.

In a founding myth reported by Pseudo-Apollodorus, Athena competed with Poseidon for the patronage of Athens. They agreed that each would give the Athenians one gift and that Cecrops, the king of Athens, would determine which gift was better. Poseidon struck the ground with his trident and a salt water spring sprang up; this gave the Athenians access to trade and water. Athens at its height was a significant sea power, defeating the Persian fleet at the Battle of Salamis—but the water was salty and undrinkable. In an alternative version of the myth from Vergil's "Georgics", Poseidon instead gave the Athenians the first horse. Athena offered the first domesticated olive tree. Cecrops accepted this gift and declared Athena the patron goddess of Athens. The olive tree brought wood, oil, and food, and became a symbol of Athenian economic prosperity. Robert Graves was of the opinion that "Poseidon's attempts to take possession of certain cities are political myths", which reflect the conflict between matriarchal and patriarchal religions.

Pseudo-Apollodorus records an archaic legend, which claims that Hephaestus once attempted to rape Athena, but she pushed him away, causing him to ejaculate on her thigh. Athena wiped the semen off using a tuft of wool, which she tossed into the dust, impregnating Gaia and causing her to give birth to Erichthonius. Athena adopted Erichthonius as her son and raised him. The Roman mythographer Hyginus records a similar story in which Hephaestus demanded Zeus to let him marry Athena since he was the one who had smashed open Zeus's skull, allowing Athena to be born. Zeus agreed to this and Hephaestus and Athena were married, but, when Hephaestus was about to consummate the union, Athena vanished from the bridal bed, causing him to ejaculate on the floor, thus impregnating Gaia with Erichthonius.

The geographer Pausanias records that Athena placed the infant Erichthonius into a small chest ("cista"), which she entrusted to the care of the three daughters of Cecrops: Herse, Pandrosos, and Aglauros of Athens. She warned the three sisters not to open the chest, but did not explain to them why or what was in it. Aglauros, and possibly one of the other sisters, opened the chest. Differing reports say that they either found that the child itself was a serpent, that it was guarded by a serpent, that it was guarded by two serpents, or that it had the legs of a serpent. In Pausanias's story, the two sisters were driven mad by the sight of the chest's contents and hurled themselves off the Acropolis, dying instantly, but an Attic vase painting shows them being chased by the serpent off the edge of the cliff instead.

Erichthonius was one of the most important founding heroes of Athens and the legend of the daughters of Cecrops was a cult myth linked to the rituals of the Arrhephoria festival. Pausanias records that, during the Arrhephoria, two young girls known as the "Arrhephoroi", who lived near the temple of Athena Polias, would be given hidden objects by the priestess of Athena, which they would carry on their heads down a natural underground passage. They would leave the objects they had been given at the bottom of the passage and take another set of hidden objects, which they would carry on their heads back up to the temple. The ritual was performed in the dead of night and no one, not even the priestess, knew what the objects were. The serpent in the story may be the same one depicted coiled at Athena's feet in Pheidias's famous statue of the "Athena Parthenos" in the Parthenon. Many of the surviving sculptures of Athena show this serpent.

Herodotus records that a serpent lived in a crevice on the north side of the summit of the Athenian Acropolis and that the Athenians left a honey cake for it each month as an offering. On the eve of the Second Persian invasion of Greece in 480 BC, the serpent did not eat the honey cake and the Athenians interpreted it as a sign that Athena herself had abandoned them. Another version of the myth of the Athenian maidens is told in "Metamorphoses" by the Roman poet Ovid (43 BC17 AD); in this late variant Hermes falls in love with Herse. Herse, Aglaulus, and Pandrosus go to the temple to offer sacrifices to Athena. Hermes demands help from Aglaulus to seduce Herse. Aglaulus demands money in exchange. Hermes gives her the money the sisters have already offered to Athena. As punishment for Aglaulus's greed, Athena asks the goddess Envy to make Aglaulus jealous of Herse. When Hermes arrives to seduce Herse, Aglaulus stands in his way instead of helping him as she had agreed. He turns her to stone.

According to Pseudo-Apollodorus's "Bibliotheca", Athena advised Argos, the builder of the "Argo", the ship on which the hero Jason and his band of Argonauts sailed, and aided in the ship's construction. Pseudo-Apollodorus also records that Athena guided the hero Perseus in his quest to behead Medusa. She and Hermes, the god of travelers, appeared to Perseus after he set off on his quest and gifted him with tools he would need to kill the Gorgon. Athena gave Perseus a polished bronze shield to view Medusa's reflection rather than looking at her directly and thereby avoid being turned to stone. Hermes gave him an adamantine scythe to cut off Medusa's head. When Perseus swung his blade to behead Medusa, Athena guided it, allowing his scythe to cut it clean off. According to Pindar's "Thirteenth Olympian Ode", Athena helped the hero Bellerophon tame the winged horse Pegasus by giving him a bit.

In ancient Greek art, Athena is frequently shown aiding the hero Heracles. She appears in four of the twelve metopes on the Temple of Zeus at Olympia depicting Heracles's Twelve Labors, including the first, in which she passively watches him slay the Nemean lion, and the tenth, in which she is shown actively helping him hold up the sky. She is presented as his "stern ally", but also the "gentle... acknowledger of his achievements." Artistic depictions of Heracles's apotheosis show Athena driving him to Mount Olympus in her chariot and presenting him to Zeus for his deification. In Aeschylus's tragedy "Orestes", Athena intervenes to save Orestes from the wrath of the Erinyes and presides over his trial for the murder of his mother Clytemnestra. When half the jury votes to acquit and the other half votes to convict, Athena casts the deciding vote to acquit Orestes and declares that, from then on, whenever a jury is tied, the defendant shall always be acquitted.

In "The Odyssey", Odysseus' cunning and shrewd nature quickly wins Athena's favour. For the first part of the poem, however, she largely is confined to aiding him only from "afar", mainly by implanting thoughts in his head during his journey home from Troy. Her guiding actions reinforce her role as the "protectress of heroes," or, as mythologian Walter Friedrich Otto dubbed her, the "goddess of nearness," due to her mentoring and motherly probing. It is not until he washes up on the shore of the island of the Phaeacians, where Nausicaa is washing her clothes that Athena arrives personally to provide more tangible assistance. She appears in Nausicaa's dreams to ensure that the princess rescues Odysseus and plays a role in his eventual escort to Ithaca. Athena appears to Odysseus upon his arrival, disguised as a herdsman; she initially lies and tells him that Penelope, his wife, has remarried and that he is believed to be dead, but Odysseus lies back to her, employing skillful prevarications to protect himself. Impressed by his resolve and shrewdness, she reveals herself and tells him what he needs to know in order to win back his kingdom. She disguises him as an elderly beggar so that he will not be recognized by the suitors or Penelope, and helps him to defeat the suitors. Athena also appears to Odysseus's son Telemachus. Her actions lead him to travel around to Odysseus's comrades and ask about his father. He hears stories about some of Odysseus's journey. Athena's push for Telemachos's journey helps him grow into the man role, that his father once held. She also plays a role in ending the resultant feud against the suitors' relatives. She instructs Laertes to throw his spear and to kill Eupeithes, the father of Antinous.

The Gorgoneion appears to have originated as an apotropaic symbol intended to ward off evil. In a late myth invented to explain the origins of the Gorgon, Medusa is described as having been a young priestess who served in the temple of Athena in Athens. Poseidon lusted after Medusa, and raped her in the temple of Athena, refusing to allow her vow of chastity to stand in his way. Upon discovering the desecration of her temple, Athena transformed Medusa into a hideous monster with serpents for hair whose gaze would turn any mortal to stone.

In his "Twelfth Pythian Ode", Pindar recounts the story of how Athena invented the "aulos", a kind of flute, in imitation of the lamentations of Medusa's sisters, the Gorgons, after she was beheaded by the hero Perseus. According to Pindar, Athena gave the aulos to mortals as a gift. Later, the comic playwright Melanippides of Melos ( 480-430 BC) embellished the story in his comedy "Marsyas", claiming that Athena looked in the mirror while she was playing the aulos and saw how blowing into it puffed up her cheeks and made her look silly, so she threw the aulos away and cursed it so that whoever picked it up would meet an awful death. The aulos was picked up by the satyr Marsyas, who was later killed by Apollo for his hubris. Later, this version of the story became accepted as canonical and the Athenian sculptor Myron created a group of bronze sculptures based on it, which was installed before the western front of the Parthenon in around 440 BC.

A myth told by the early third-century BC Hellenistic poet Callimachus in his "Hymn" 5 begins with Athena bathing in a spring on Mount Helicon at midday with one of her favorite companions, the nymph Chariclo. Chariclo's son Tiresias happened to be hunting on the same mountain and came to the spring searching for water. He inadvertently saw Athena naked, so she struck him blind to ensure he would never again see what man was not intended to see. Chariclo intervened on her son's behalf and begged Athena to have mercy. Athena replied that she could not restore Tiresias's eyesight, so, instead, she gave him the ability to understand the language of the birds and thus foretell the future.

The fable of Arachne appears in Ovid's "Metamorphoses" (8 AD) (vi.5–54 and 129–145), which is nearly the only extant source for the legend. The story does not appear to have been well known prior to Ovid's rendition of it and the only earlier reference to it is a brief allusion in Virgil's "Georgics", (29 BC) (iv, 246) that does not mention Arachne by name. According to Ovid, Arachne (whose name means "spider" in ancient Greek) was the daughter of a famous dyer in Tyrian purple in Hypaipa of Lydia, and a weaving student of Athena. She became so conceited of her skill as a weaver that she began claiming that her skill was greater than that of Athena herself. Athena gave Arachne a chance to redeem herself by assuming the form of an old woman and warning Arachne not to offend the deities. Arachne scoffed and wished for a weaving contest, so she could prove her skill.

Athena wove the scene of her victory over Poseidon in the contest for the patronage of Athens. Athena's tapestry also depicted the 12 Olympian gods and defeat of mythological figures who challenged their authority. Arachne's tapestry featured twenty-one episodes of the deities' infidelity, including Zeus being unfaithful with Leda, with Europa, and with Danaë. It represented the unjust and discrediting behavior of the gods towards mortals. Athena admitted that Arachne's work was flawless, but was outraged at Arachne's offensive choice of subject, which displayed the failings and transgressions of the deities. Finally, losing her temper, Athena destroyed Arachne's tapestry and loom, striking it with her shuttle. Athena then struck Arachne across the face with her staff four times. Arachne hanged herself in despair, but Athena took pity on her and brought her back from the dead in the form of a spider.

The myth of the Judgement of Paris is mentioned briefly in the "Iliad", but is described in depth in an epitome of the "Cypria", a lost poem of the Epic Cycle, which records that all the gods and goddesses as well as various mortals were invited to the marriage of Peleus and Thetis (the eventual parents of Achilles). Only Eris, goddess of discord, was not invited. She was annoyed at this, so she arrived with a golden apple inscribed with the word καλλίστῃ (kallistēi, "for the fairest"), which she threw among the goddesses. Aphrodite, Hera, and Athena all claimed to be the fairest, and thus the rightful owner of the apple.

The goddesses chose to place the matter before Zeus, who, not wanting to favor one of the goddesses, put the choice into the hands of Paris, a Trojan prince. After bathing in the spring of Mount Ida where Troy was situated, the goddesses appeared before Paris for his decision. In the extant ancient depictions of the Judgement of Paris, Aphrodite is only occasionally represented nude, and Athena and Hera are always fully clothed. Since the Renaissance, however, western paintings have typically portrayed all three goddesses as completely naked.

All three goddesses were ideally beautiful and Paris could not decide between them, so they resorted to bribes. Hera tried to bribe Paris with power over all Asia and Europe, and Athena offered fame and glory in battle, but Aphrodite promised Paris that, if he were to choose her as the fairest, she would let him marry the most beautiful woman on earth. This woman was Helen, who was already married to King Menelaus of Sparta. Paris selected Aphrodite and awarded her the apple. The other two goddesses were enraged and, as a direct result, sided with the Greeks in the Trojan War.

In Books V–VI of the "Iliad", Athena aids the hero Diomedes, who, in the absence of Achilles, proves himself to be the most effective Greek warrior. Several artistic representations from the early sixth century BC may show Athena and Diomedes, including an early sixth-century BC shield band depicting Athena and an unidentified warrior riding on a chariot, a vase painting of a warrior with his charioteer facing Athena, and an inscribed clay plaque showing Diomedes and Athena riding in a chariot. Numerous passages in the "Iliad" also mention Athena having previously served as the patron of Diomedes's father Tydeus. When the Trojan women go to the temple of Athena on the Acropolis to plead her for protection from Diomedes, Athena ignores them.

In Book XXII of the "Iliad", while Achilles is chasing Hector around the walls of Troy, Athena appears to Hector disguised as his brother Deiphobus and persuades him to hold his ground so that they can fight Achilles together. Then, Hector throws his spear at Achilles and misses, expecting Deiphobus to hand him another, but Athena disappears instead, leaving Hector to face Achilles alone without his spear. In Sophocles's tragedy "Ajax", she punishes Odysseus's rival Ajax the Great, driving him insane and causing him to massacre the Achaeans' cattle, thinking that he is slaughtering the Achaeans themselves. Even after Odysseus himself expresses pity for Ajax, Athena declares, "To laugh at your enemies - what sweeter laughter can there be than that?" (lines 78–9). Ajax later commits suicide as a result of his humiliation.

Athena appears frequently in classical Greek art, including on coins and in paintings on ceramics. She is especially prominent in works produced in Athens. In classical depictions, Athena is usually portrayed standing upright, wearing a full-length chiton. She is most often represented dressed in armor like a male soldier and wearing a Corinthian helmet raised high atop her forehead. Her shield bears at its centre the aegis with the head of the gorgon ("gorgoneion") in the center and snakes around the edge. Sometimes she is shown wearing the aegis as a cloak. As Athena Promachos, she is shown brandishing a spear. Scenes in which Athena was represented include her birth from the head of Zeus, her battle with the Gigantes, the birth of Erichthonius, and the Judgement of Paris.

The "Mourning Athena" or "Athena Meditating" is a famous relief sculpture dating to around 470-460 BC that has been interpreted to represent Athena Polias. The most famous classical depiction of Athena was the "Athena Parthenos", a now-lost gold and ivory statue of her in the Parthenon created by the Athenian sculptor Phidias. Copies reveal that this statue depicted Athena holding her shield in her left hand with Nike, the winged goddess of victory, standing in her right. Athena Polias is also represented in a Neo-Attic relief now held in the Virginia Museum of Fine Arts, which depicts her holding an owl in her hand and wearing her characteristic Corinthian helmet while resting her shield against a nearby "herma". The Roman goddess Minerva adopted most of Athena's Greek iconographical associations, but was also integrated into the Capitoline Triad.

Early Christian writers, such as Clement of Alexandria and Firmicus, denigrated Athena as representative of all the things that were detestable about paganism; they condemned her as "immodest and immoral". During the Middle Ages, however, many attributes of Athena were given to the Virgin Mary, who, in fourth century portrayals, was often depicted wearing the Gorgoneion. Some even viewed the Virgin Mary as a warrior maiden, much like Athena Parthenos; one anecdote tells that the Virgin Mary once appeared upon the walls of Constantinople when it was under siege by the Avars, clutching a spear and urging the people to fight. During the Middle Ages, Athena became widely used as a Christian symbol and allegory, and she appeared on the family crests of certain noble houses.

During the Renaissance, Athena donned the mantle of patron of the arts and human endeavor; allegorical paintings involving Athena were a favorite of the Italian Renaissance painters. In Sandro Botticelli's painting "Pallas and the Centaur", probably painted sometime in the 1480s, Athena is the personification of chastity, who is shown grasping the forelock of a centaur, who represents lust. Andrea Mantegna's 1502 painting "Minerva Expelling the Vices from the Garden of Virtue" uses Athena as the personification of Graeco-Roman learning chasing the vices of medievalism from the garden of modern scholarship. Athena is also used as the personification of wisdom in Bartholomeus Spranger's 1591 painting "The Triumph of Wisdom" or "Minerva Victorious over Ignorance".

During the sixteenth and seventeenth centuries, Athena was used as a symbol for female rulers. In his book "A Revelation of the True Minerva" (1582), Thomas Blennerhassett portrays Queen Elizabeth I of England as a "new Minerva" and "the greatest goddesse nowe on earth". A series of paintings by Peter Paul Rubens depict Athena as Marie de' Medici's patron and mentor; the final painting in the series goes even further and shows Marie de' Medici with Athena's iconography, as the mortal incarnation of the goddess herself. The German sculptor Jean-Pierre-Antoine Tassaert later portrayed Catherine II of Russia as Athena in a marble bust in 1774. During the French Revolution, statues of pagan gods were torn down all throughout France, but statues of Athena were not. Instead, Athena was transformed into the personification of freedom and the republic and a statue of the goddess stood in the center of the Place de la Revolution in Paris. In the years following the Revolution, artistic representations of Athena proliferated.

A statue of Athena stands directly in front of the Austrian Parliament Building in Vienna, and depictions of Athena have influenced other symbols of western freedom, including the Statue of Liberty and Britannia. For over a century, a full-scale replica of the Parthenon has stood in Nashville, Tennessee. In 1990, the curators added a gilded forty-two-foot (12.5 m) tall replica of Phidias's "Athena Parthenos", built from concrete and fiberglass. The state seal of California bears the image of Athena kneeling next to a brown grizzly bear. Athena has occasionally appeared on modern coins, as she did on the ancient Athenian drachma. Her head appears on the $50 1915-S Panama-Pacific commemorative coin.

One of Sigmund Freud's most treasured possessions was a small, bronze sculpture of Athena, which sat on his desk. Freud once described Athena as "a woman who is unapproachable and repels all sexual desires - since she displays the terrifying genitals of the Mother." Feminist views on Athena are sharply divided; some feminists regard her as a symbol of female empowerment, while others regard her as "the ultimate patriarchal sell out... who uses her powers to promote and advance men rather than others of her sex." In contemporary Wicca, Athena is venerated as an aspect of the Goddess and some Wiccans believe that she may bestow the "Owl Gift" ("the ability to write and communicate clearly") upon her worshippers. Due to her status as one of the twelve Olympians, Athena is a major deity in Hellenismos, a Neopagan religion which seeks to authentically revive and recreate the religion of ancient Greece in the modern world.

Athena is a natural patron of universities: At Bryn Mawr College in Pennsylvania a statue of Athena (a replica of the original bronze one in the arts and archaeology library) resides in the Great Hall. It is traditional at exam time for students to leave offerings to the goddess with a note asking for good luck, or to repent for accidentally breaking any of the college's numerous other traditions. Pallas Athena is the tutelary goddess of the international social fraternity Phi Delta Theta. Her owl is also a symbol of the fraternity.






</doc>
<doc id="1183" url="https://en.wikipedia.org/wiki?curid=1183" title="Amber Diceless Roleplaying Game">
Amber Diceless Roleplaying Game

The Amber Diceless Roleplaying Game is a role-playing game created and written by Erick Wujcik, set in the fictional universe created by author Roger Zelazny for his "Chronicles of Amber". The game is unusual in that no dice are used in resolving conflicts or player actions; instead a simple diceless system of comparative ability, and narrative description of the action by the players and gamemaster, is used to determine how situations are resolved.

"Amber DRPG" was created in the 1980s, and is much more focused on relationships and roleplaying than most of the roleplaying games of that era. Most "Amber" characters are members of the two ruling classes in the "Amber" multiverse, and are much more advanced in matters of strength, endurance, psyche, warfare and sorcery than ordinary beings. This often means that the only individuals who are capable of opposing a character are from his or her family, a fact that leads to much suspicion and intrigue.

Erick Wujcik offered to design an Amber role-playing game for West End Games, who agreed to look at his work. Wujcik intended to integrate the feel of the "Amber" setting from the novels into a role-playing game, and playtested his system for a few months at the Michigan Gaming Center where he decided to try it out as a diceless game. West End was not interested in a diceless role-playing game, so Wujcik acquired the RPG rights to "Amber" and took the game to R. Talsorian Games, until he withdrew over creative differences. Wujcik then founded Phage Press, and published "Amber Diceless Role-playing" in 1991.

The original 256-page game book was published in 1991 by Phage Press, covering material from the first five novels (the "Corwin Cycle") and some details – sorcery and the Logrus – from the remaining five novels (the "Merlin Cycle"), in order to allow players to roleplay characters from the Courts of Chaos. Some details were changed slightly to allow more player choice – for example, players can be full Trump Artists without having walked the Pattern or the Logrus, which Merlin says is impossible; and players' psychic abilities are far greater than those shown in the books.
A 256-page companion volume, "Shadow Knight", was published in 1993. This supplemental rule book includes the remaining elements from the Merlin novels, such as Broken Patterns, and allows players to create Constructs such as Merlin's Ghostwheel. The book presents the second series of novels not as additions to the series' continuity but as an example of a roleplaying campaign with Merlin, Luke, Julia, Jurt and Coral as the PCs. The remainder of the book is a collection of essays on the game, statistics for the new characters and an update of the older ones in light of their appearance in the second series, and (perhaps most usefully for GMs) plot summaries of each of the ten books. The book includes some material from the short story "The Salesman's Tale," and some unpublished material cut from "Prince of Chaos", notably Coral's pregnancy by Merlin.

Both books were translated into French and published by Jeux Descartes in 1994 and 1995.

A third book, "Rebma", was promised. Cover art was commissioned and pre-orders were taken, but it was never published. Wujcik also expressed a desire to create a book giving greater detail to the Courts of Chaos. The publishing rights to the "Amber DRPG" games were acquired in 2004 by Guardians of Order, who took over sales of the game and announced their intention to release a new edition of the game. However, no new edition was released before Guardians of Order went out of business in 2006. The two existing books are now out-of-print, but they have been made available as PDF downloads.

In June 2007 a new publishing company, headed by Edwin Voskamp and Eric Todd, was formed with the express purpose of bringing "Amber DRPG" back into print. The new company is named "Diceless by Design".

In May 2010, "Rite Publishing" secured a license from Diceless by Design to use the rules system with a new setting in the creation of a new product to be written by industry and system veteran Jason Durall. The project Lords of Gossamer & Shadow (Diceless) was funded via Kickstarter in May 2013. In Sept 2013 the project was completed, and on in Nov 2013 Lords of Gossamer and Shadow (Diceless) was released publicly in full-color Print and PDF, along with additional supplements and continued support.

The game is set in the multiverse described in Zelazny's "Chronicles of Amber". The first book assumes that gamemasters will set their campaigns after the Patternfall war; that is, after the end of the fifth book in the series, "The Courts of Chaos", but uses material from the following books to describe those parts of Zelazny's cosmology that were featured there in more detail. The "Amber" multiverse consists of Amber, a city at one pole of the universe wherein is found the Pattern, the symbol of Order; The Courts of Chaos, an assembly of worlds at the other pole where can be found the Logrus, the manifestation of Chaos, and the Abyss, the source or end of all reality; and Shadow, the collection of all possible universes (shadows) between and around them. Inhabitants of either pole can use one or both of the Pattern and the Logrus to travel through Shadow.

It is assumed that players will portray the children of the main characters from the books – the ruling family of Amber, known as the Elder Amberites – or a resident of the Courts. However, since some feel that being the children of the main characters is too limiting, it is fairly common to either start with King Oberon's death "before" the book begins and roleplay the Elder Amberites as they vie for the throne; or to populate Amber from scratch with a different set of Elder Amberites. The former option is one presented in the book; the latter is known in the Amber community as an "Amethyst" game. A third option is to have the players portray Corwin's children, in an Amber-like city built around Corwin's pattern; this is sometimes called an "Argent" game, since one of Corwin's heraldic colours is Silver.

Characters in "Amber DRPG" are represented by four attributes: "Psyche", "Strength", "Endurance" and "Warfare".
The attributes run from −25 (normal human level), through −10 (normal level for a denizen of the Courts of Chaos) and 0 (normal level for an inhabitant of Amber), upwards without limit. Scores above 0 are "ranked", with the highest score being ranked 1st, the next-highest 2nd, and so on. The character with 1st rank in each attribute is considered "superior" in that attribute, being considered to be substantially better than the character with 2nd rank even if the difference in scores is small. All else being equal, a character with a higher rank in an attribute will always win a contest based on that attribute.

A character's ability scores are purchased during character creation in an auction; players get 100 character points, and bid on each attribute in turn. The character who bids the most for an attribute is "ranked" first and is considered superior to all other characters in that attribute. Unlike conventional auctions, bids are non-refundable; if one player bids 65 for psyche and another wins with a bid of 66, then the character with 66 is "superior" to the character with 65 even though there is only one bid difference. Instead, lower bidding characters are ranked in ascending order according to how much they have bid, the characters becoming progressively weaker in that attribute as they pay less for it. After the auction, players can secretly pay extra points to raise their ranks, but they can only pay to raise their scores to an existing rank. Further, a character with a bid-for rank is considered to have a slight advantage over character with a bought-up rank.

The Auction simulates a 'history' of competition between the descendants of Oberon for player characters who have not had dozens of decades to get to know each other. Through the competitive Auction, characters may begin the game vying for standings. The auction serves to introduce some unpredictability into character creation without the need to resort to dice, cards, or other randomizing devices. A player may intend, for example, to create a character who is a strong, mighty warrior, but being "outplayed" in the auction may result in lower attribute scores than anticipated, therefore necessitating a change of character concept. Since a player cannot control another player's bids, and since all bids are non-refundable, the auction involves a considerable amount of strategizing and prioritization by players. A willingness to spend as many points as possible on an attribute may improve your chances of a high ranking, but too reckless a spending strategy could leave a player with few points to spend on powers and objects. In a hotly contested auction, such as for the important attribute of warfare, the most valuable skill is the ability to force one's opponents to back down. With two or more equally determined players, this can result in a "bidding war" where the attribute is driven up by increments to large sums. An alternative strategy is to try to cow other players into submission with a high opening bid. Most players bid low amounts between one and ten points in an initial bid in order to feel out the competition and to save points for other uses. A high enough opening bid could signal a player's determination to be first ranked in that attribute, thereby dissuading others from competing.

Characters with high psyche are presented as having strong telepathic abilities, being able to hypnotise and even mentally dominate any character with lesser psyche with whom they can make eye-contact. This is likely due to three scenes in the "Chronicles": first, when Eric paralyzes Corwin with an attack across the Trump and refuses to desist because one or the other would be dominated; second, when Corwin faces the demon Strygalldwir, it is able to wrestle mentally with him when their gazes meet; and third, when Fiona is able to keep Brand immobile in the final battle at the Courts of Chaos. However, in general, the books only feature mental battles when there is some reason for mind-to-mind contact (for example, Trump contact) and magic or Trump is involved in all three of the above conflicts, so it is not clear whether Zelazny intended his characters to have such a power; the combination of Brand's "living trump" powers and his high Psyche (as presented in the roleplaying game) would have guaranteed him victory over Corwin. "Shadow Knight" does address this inconsistency somewhat, by presenting the "living trump" abilities as somewhat limited.

Characters in "Amber DRPG" have access to the powers seen in the "Chronicles of Amber": "Pattern", "Logrus", "Shape-shifting", "Trump", and "magic".


Each of the first four powers is available in an advanced form.

While a character with Pattern, Logrus or Conjuration can acquire virtually any object, players can choose to spend character points to obtain objects with particular virtues – unbreakability, or a mind of their own. Since they have paid points for the items, they are a part of the character's legend, and cannot lightly be destroyed. Similarly, a character can find any possible universe, but they can spend character points to know of or inhabit shadows which are (in some sense) "real" and therefore useful. The expansion, "Shadow Knight", adds Constructs – artifacts with connections to shadows.

Unspent character points become good stuff – a good luck for the character. Players are also allowed to overspend (in moderation), with the points becoming bad stuff – bad luck which the Gamemaster should inflict on the character. Stuff governs how non-player characters perceive and respond to the character: characters with good stuff will often receive friendly or helpful reactions, while characters with bad stuff are often treated with suspicion or hostility.

As well as representing luck, stuff can be seen as representing a character's outlook on the universe: characters with good stuff seeing the multiverse as a cheerful place, while characters with bad stuff see it as hostile.

In any given fair conflict between two characters, the character with the higher score in the relevant attribute will eventually win. The key words here are "fair" and "eventually" – if characters' ranks are close, and the weaker character has obtained some advantage, then the weaker character can escape defeat or perhaps prevail. Close ranks result in longer contests while greater difference between ranks result in fast resolution. Alternatively, if characters' attribute ranks are close, the weaker character can try to change the relevant attribute by changing the nature of the conflict. For example, if two characters are wrestling the relevant attribute is Strength; a character could reveal a weapon, changing it to Warfare; they could try to overcome the other character's mind using a power, changing it to Psyche; or they could concentrate their strength on defense, changing it to Endurance. If there is a substantial difference between characters' ranks, the conflict is generally over before the weaker character can react.

"Amber DRPG" advises gamemasters to change rules as they see fit – even to the point of adding or removing powers or attributes.

In the June 1992 edition of "Dragon" (Issue 182), both Lester Smith and Allen Varney published reviews of this game.

Loyd Blankenship reviewed "Amber" in "Pyramid" #2 (July/Aug., 1993), and stated that ""Amber" is a valuable resource to a GM - even if he isn't running an "Amber" game. For gamers who have an aspiring actor or actress lurking within their breast, or for someone running a campaign via electronic mail or message base, "Amber" should be given serious consideration."

Despite the game's out-of-print status, a thriving convention scene exists supporting the game. Amber conventions, known as "Ambercons", are held yearly in Massachusetts, Michigan, Portland (United States), Milton Keynes (England), Belfast (Northern Ireland) and Modena, Italy. Additionally, Phage Press published 12 volumes of a dedicated "Amber DRPG" magazine called "Amberzine". Some "Amberzine" issues are still available from Phage Press.





</doc>
<doc id="1184" url="https://en.wikipedia.org/wiki?curid=1184" title="Athene (disambiguation)">
Athene (disambiguation)

Athene or Athena is the shrewd companion of heroes and the goddess of heroic endeavour in Greek mythology.

Athene may also refer to:




</doc>
<doc id="1187" url="https://en.wikipedia.org/wiki?curid=1187" title="Alloy">
Alloy

An alloy is a combination of metals or metals combined with one or more other elements. For example, combining the metallic elements gold and copper produces red gold, gold and silver becomes white gold, and silver combined with copper produces sterling silver. Elemental iron, combined with non-metallic carbon or silicon, produces alloys called steel or silicon steel. The resulting mixture forms a substance with properties that often differ from those of the pure metals, such as increased strength or hardness. Unlike other substances that may contain metallic bases but do not behave as metals, such as aluminium oxide (sapphire), beryllium aluminium silicate (emerald) or sodium chloride (salt), an alloy will retain all the properties of a metal in the resulting material, such as electrical conductivity, ductility, opaqueness, and luster. Alloys are used in a wide variety of applications, from the steel alloys, used in everything from buildings to automobiles to surgical tools, to exotic titanium-alloys used in the aerospace industry, to beryllium-copper alloys for non-sparking tools. In some cases, a combination of metals may reduce the overall cost of the material while preserving important properties. In other cases, the combination of metals imparts synergistic properties to the constituent metal elements such as corrosion resistance or mechanical strength. Examples of alloys are steel, solder, brass, pewter, duralumin, bronze and amalgams.

An alloy may be a solid solution of metal elements (a single phase, where all metallic grains (crystals) are of the same composition) or a mixture of metallic phases (two or more solutions, forming a microstructure of different crystals within the metal). Intermetallic compounds are alloys with a defined stoichiometry and crystal structure. Zintl phases are also sometimes considered alloys depending on bond types (see Van Arkel–Ketelaar triangle for information on classifying bonding in binary compounds).

Alloys are defined by a metallic bonding character. The alloy constituents are usually measured by mass percentage for practical applications, and in atomic fraction for basic science studies. Alloys are usually classified as substitutional or interstitial alloys, depending on the atomic arrangement that forms the alloy. They can be further classified as homogeneous (consisting of a single phase), or heterogeneous (consisting of two or more phases) or intermetallic.

An alloy is a mixture of chemical elements, which forms an impure substance (admixture) that retains the characteristics of a metal. An alloy is distinct from an impure metal in that, with an alloy, the added elements are well controlled to produce desirable properties, while impure metals such as wrought iron are less controlled, but are often considered useful. Alloys are made by mixing two or more elements, at least one of which is a metal. This is usually called the primary metal or the base metal, and the name of this metal may also be the name of the alloy. The other constituents may or may not be metals but, when mixed with the molten base, they will be soluble and dissolve into the mixture.
The mechanical properties of alloys will often be quite different from those of its individual constituents. A metal that is normally very soft (malleable), such as aluminium, can be altered by alloying it with another soft metal, such as copper. Although both metals are very soft and ductile, the resulting aluminium alloy will have much greater strength. Adding a small amount of non-metallic carbon to iron trades its great ductility for the greater strength of an alloy called steel. Due to its very-high strength, but still substantial toughness, and its ability to be greatly altered by heat treatment, steel is one of the most useful and common alloys in modern use. By adding chromium to steel, its resistance to corrosion can be enhanced, creating stainless steel, while adding silicon will alter its electrical characteristics, producing silicon steel.

Like oil and water, a molten metal may not always mix with another element. For example, pure iron is almost completely insoluble with copper. Even when the constituents are soluble, each will usually have a saturation point, beyond which no more of the constituent can be added. Iron, for example, can hold a maximum of 6.67% carbon. Although the elements of an alloy usually must be soluble in the liquid state, they may not always be soluble in the solid state. If the metals remain soluble when solid, the alloy forms a solid solution, becoming a homogeneous structure consisting of identical crystals, called a phase. If as the mixture cools the constituents become insoluble, they may separate to form two or more different types of crystals, creating a heterogeneous microstructure of different phases, some with more of one constituent than the other. However, in other alloys, the insoluble elements may not separate until after crystallization occurs. If cooled very quickly, they first crystallize as a homogeneous phase, but they are supersaturated with the secondary constituents. As time passes, the atoms of these supersaturated alloys can separate from the crystal lattice, becoming more stable, and forming a second phase that serves to reinforce the crystals internally.

Some alloys, such as electrum—an alloy of silver and gold—occur naturally. Meteorites are sometimes made of naturally occurring alloys of iron and nickel, but are not native to the Earth. One of the first alloys made by humans was bronze, which is a mixture of the metals tin and copper. Bronze was an extremely useful alloy to the ancients, because it is much stronger and harder than either of its components. Steel was another common alloy. However, in ancient times, it could only be created as an accidental byproduct from the heating of iron ore in fires (smelting) during the manufacture of iron. Other ancient alloys include pewter, brass and pig iron. In the modern age, steel can be created in many forms. Carbon steel can be made by varying only the carbon content, producing soft alloys like mild steel or hard alloys like spring steel. Alloy steels can be made by adding other elements, such as chromium, molybdenum, vanadium or nickel, resulting in alloys such as high-speed steel or tool steel. Small amounts of manganese are usually alloyed with most modern steels because of its ability to remove unwanted impurities, like phosphorus, sulfur and oxygen, which can have detrimental effects on the alloy. However, most alloys were not created until the 1900s, such as various aluminium, titanium, nickel, and magnesium alloys. Some modern superalloys, such as incoloy, inconel, and hastelloy, may consist of a multitude of different elements.

As a noun, the term alloy is used to describe a mixture of atoms in which the primary constituent is a metal. When used as a verb, the term refers to the act of mixing a metal with other elements. The primary metal is called the "base", the "matrix", or the "solvent". The secondary constituents are often called "solutes". If there is a mixture of only two types of atoms (not counting impurities) such as a copper-nickel alloy, then it is called a "binary alloy." If there are three types of atoms forming the mixture, such as iron, nickel and chromium, then it is called a "ternary alloy." An alloy with four constituents is a "quaternary alloy," while a five-part alloy is termed a "quinary alloy." Because the percentage of each constituent can be varied, with any mixture the entire range of possible variations is called a "system". In this respect, all of the various forms of an alloy containing only two constituents, like iron and carbon, is called a "binary system," while all of the alloy combinations possible with a ternary alloy, such as alloys of iron, carbon and chromium, is called a "ternary system".

An alloy is technically an impure metal, but when referring to alloys, the term "impurities" usually denotes undesirable elements. Such impurities are introduced from the base metals and alloying elements, but are removed during processing. For instance, sulfur is a common impurity in steel. Sulfur combines readily with iron to form iron sulfide, which is very brittle, creating weak spots in the steel. Lithium, sodium and calcium are common impurities in aluminium alloys, which can have adverse effects on the structural integrity of castings. Conversely, otherwise pure-metals that simply contain unwanted impurities are often called "impure metals" and are not usually referred to as alloys. Oxygen, present in the air, readily combines with most metals to form metal oxides; especially at higher temperatures encountered during alloying. Great care is often taken during the alloying process to remove excess impurities, using fluxes, chemical additives, or other methods of extractive metallurgy.

In practice, some alloys are used so predominantly with respect to their base metals that the name of the primary constituent is also used as the name of the alloy. For example, 14 karat gold is an alloy of gold with other elements. Similarly, the silver used in jewelry and the aluminium used as a structural building material are also alloys.

The term "alloy" is sometimes used in everyday speech as a synonym for a particular alloy. For example, automobile wheels made of an aluminium alloy are commonly referred to as simply "alloy wheels", although in point of fact steels and most other metals in practical use are also alloys. Steel is such a common alloy that many items made from it, like wheels, barrels, or girders, are simply referred to by the name of the item, assuming it is made of steel. When made from other materials, they are typically specified as such, (i.e.: "bronze wheel", "plastic barrel", or "wood girder").

Alloying a metal is done by combining it with one or more other elements. The most common and oldest alloying process is performed by heating the base metal beyond its melting point and then dissolving the solutes into the molten liquid, which may be possible even if the melting point of the solute is far greater than that of the base. For example, in its liquid state, titanium is a very strong solvent capable of dissolving most metals and elements. In addition, it readily absorbs gases like oxygen and burns in the presence of nitrogen. This increases the chance of contamination from any contacting surface, and so must be melted in vacuum induction-heating and special, water-cooled, copper crucibles. However, some metals and solutes, such as iron and carbon, have very high melting-points and were impossible for ancient people to melt. Thus, alloying (in particular, interstitial alloying) may also be performed with one or more constituents in a gaseous state, such as found in a blast furnace to make pig iron (liquid-gas), nitriding, carbonitriding or other forms of case hardening (solid-gas), or the cementation process used to make blister steel (solid-gas). It may also be done with one, more, or all of the constituents in the solid state, such as found in ancient methods of pattern welding (solid-solid), shear steel (solid-solid), or crucible steel production (solid-liquid), mixing the elements via solid-state diffusion.

By adding another element to a metal, differences in the size of the atoms create internal stresses in the lattice of the metallic crystals; stresses that often enhance its properties. For example, the combination of carbon with iron produces steel, which is stronger than iron, its primary element. The electrical and thermal conductivity of alloys is usually lower than that of the pure metals. The physical properties, such as density, reactivity, Young's modulus of an alloy may not differ greatly from those of its base element, but engineering properties such as tensile strength, ductility, and shear strength may be substantially different from those of the constituent materials. This is sometimes a result of the sizes of the atoms in the alloy, because larger atoms exert a compressive force on neighboring atoms, and smaller atoms exert a tensile force on their neighbors, helping the alloy resist deformation. Sometimes alloys may exhibit marked differences in behavior even when small amounts of one element are present. For example, impurities in semiconducting ferromagnetic alloys lead to different properties, as first predicted by White, Hogan, Suhl, Tian Abrie and Nakamura.
Some alloys are made by melting and mixing two or more metals. Bronze, an alloy of copper and tin, was the first alloy discovered, during the prehistoric period now known as the Bronze Age. It was harder than pure copper and originally used to make tools and weapons, but was later superseded by metals and alloys with better properties. In later times bronze has been used for ornaments, bells, statues, and bearings. Brass is an alloy made from copper and zinc.

Unlike pure metals, most alloys do not have a single melting point, but a melting range during which the material is a mixture of solid and liquid phases (a slush). The temperature at which melting begins is called the solidus, and the temperature when melting is just complete is called the liquidus. For many alloys there is a particular alloy proportion (in some cases more than one), called either a eutectic mixture or a peritectic composition, which gives the alloy a unique and low melting point, and no liquid/solid slush transition.

Alloying elements are added to a base metal, to induce hardness, toughness, ductility, or other desired properties. Most metals and alloys can be work hardened by creating defects in their crystal structure. These defects are created during plastic deformation by hammering, bending, extruding, et cetera, and are permanent unless the metal is recrystallized. Otherwise, some alloys can also have their properties altered by heat treatment. Nearly all metals can be softened by annealing, which recrystallizes the alloy and repairs the defects, but not as many can be hardened by controlled heating and cooling. Many alloys of aluminium, copper, magnesium, titanium, and nickel can be strengthened to some degree by some method of heat treatment, but few respond to this to the same degree as does steel.

The base metal iron of the iron-carbon alloy known as steel, undergoes a change in the arrangement (allotropy) of the atoms of its crystal matrix at a certain temperature (usually between and , depending on carbon content). This allows the smaller carbon atoms to enter the interstices of the iron crystal. When this diffusion happens, the carbon atoms are said to be in "solution" in the iron, forming a particular single, homogeneous, crystalline phase called austenite. If the steel is cooled slowly, the carbon can diffuse out of the iron and it will gradually revert to its low temperature allotrope. During slow cooling, the carbon atoms will no longer be as soluble with the iron, and will be forced to precipitate out of solution, nucleating into a more concentrated form of iron carbide (FeC) in the spaces between the pure iron crystals. The steel then becomes heterogeneous, as it is formed of two phases, the iron-carbon phase called cementite (or carbide), and pure iron ferrite. Such a heat treatment produces a steel that is rather soft. If the steel is cooled quickly, however, the carbon atoms will not have time to diffuse and precipitate out as carbide, but will be trapped within the iron crystals. When rapidly cooled, a diffusionless (martensite) transformation occurs, in which the carbon atoms become trapped in solution. This causes the iron crystals to deform as the crystal structure tries to change to its low temperature state, leaving those crystals very hard but much less ductile (more brittle).

While the high strength of steel results when diffusion and precipitation is prevented (forming martensite), most heat-treatable alloys are precipitation hardening alloys, that depend on the diffusion of alloying elements to achieve their strength. When heated to form a solution and then cooled quickly, these alloys become much softer than normal, during the diffusionless transformation, but then harden as they age. The solutes in these alloys will precipitate over time, forming intermetallic phases, which are difficult to discern from the base metal. Unlike steel, in which the solid solution separates into different crystal phases (carbide and ferrite), precipitation hardening alloys form different phases within the same crystal. These intermetallic alloys appear homogeneous in crystal structure, but tend to behave heterogeneously, becoming hard and somewhat brittle.

When a molten metal is mixed with another substance, there are two mechanisms that can cause an alloy to form, called "atom exchange" and the "interstitial mechanism". The relative size of each element in the mix plays a primary role in determining which mechanism will occur. When the atoms are relatively similar in size, the atom exchange method usually happens, where some of the atoms composing the metallic crystals are substituted with atoms of the other constituent. This is called a "substitutional alloy". Examples of substitutional alloys include bronze and brass, in which some of the copper atoms are substituted with either tin or zinc atoms respectively. 

In the case of the interstitial mechanism, one atom is usually much smaller than the other and can not successfully substitute for the other type of atom in the crystals of the base metal. Instead, the smaller atoms become trapped in the spaces between the atoms of the crystal matrix, called the "interstices". This is referred to as an "interstitial alloy". Steel is an example of an interstitial alloy, because the very small carbon atoms fit into interstices of the iron matrix. 

Stainless steel is an example of a combination of interstitial and substitutional alloys, because the carbon atoms fit into the interstices, but some of the iron atoms are substituted by nickel and chromium atoms.

The use of alloys by humans started with the use of meteoric iron, a naturally occurring alloy of nickel and iron. It is the main constituent of iron meteorites. As no metallurgic processes were used to separate iron from nickel, the alloy was used as it was. Meteoric iron could be forged from a red heat to make objects such as tools, weapons, and nails. In many cultures it was shaped by cold hammering into knives and arrowheads. They were often used as anvils. Meteoric iron was very rare and valuable, and difficult for ancient people to work.

Iron is usually found as iron ore on Earth, except for one deposit of native iron in Greenland, which was used by the Inuit people. Native copper, however, was found worldwide, along with silver, gold, and platinum, which were also used to make tools, jewelry, and other objects since Neolithic times. Copper was the hardest of these metals, and the most widely distributed. It became one of the most important metals to the ancients. Around 10,000 years ago in the highlands of Anatolia (Turkey), humans learned to smelt metals such as copper and tin from ore. Around 2500 BC, people began alloying the two metals to form bronze, which was much harder than its ingredients. Tin was rare, however, being found mostly in Great Britain. In the Middle East, people began alloying copper with zinc to form brass. Ancient civilizations took into account the mixture and the various properties it produced, such as hardness, toughness and melting point, under various conditions of temperature and work hardening, developing much of the information contained in modern alloy phase diagrams. For example, arrowheads from the Chinese Qin dynasty (around 200 BC) were often constructed with a hard bronze-head, but a softer bronze-tang, combining the alloys to prevent both dulling and breaking during use.

Mercury has been smelted from cinnabar for thousands of years. Mercury dissolves many metals, such as gold, silver, and tin, to form amalgams (an alloy in a soft paste or liquid form at ambient temperature). Amalgams have been used since 200 BC in China for gilding objects such as armor and mirrors with precious metals. The ancient Romans often used mercury-tin amalgams for gilding their armor. The amalgam was applied as a paste and then heated until the mercury vaporized, leaving the gold, silver, or tin behind. Mercury was often used in mining, to extract precious metals like gold and silver from their ores.

Many ancient civilizations alloyed metals for purely aesthetic purposes. In ancient Egypt and Mycenae, gold was often alloyed with copper to produce red-gold, or iron to produce a bright burgundy-gold. Gold was often found alloyed with silver or other metals to produce various types of colored gold. These metals were also used to strengthen each other, for more practical purposes. Copper was often added to silver to make sterling silver, increasing its strength for use in dishes, silverware, and other practical items. Quite often, precious metals were alloyed with less valuable substances as a means to deceive buyers. Around 250 BC, Archimedes was commissioned by the King of Syracuse to find a way to check the purity of the gold in a crown, leading to the famous bath-house shouting of "Eureka!" upon the discovery of Archimedes' principle.

The term pewter covers a variety of alloys consisting primarily of tin. As a pure metal, tin is much too soft to use for most practical purposes. However, during the Bronze Age, tin was a rare metal in many parts of Europe and the Mediterranean, so it was often valued higher than gold. To make jewellery, cutlery, or other objects from tin, workers usually alloyed it with other metals to increase strength and hardness. These metals were typically lead, antimony, bismuth or copper. These solutes were sometimes added individually in varying amounts, or added together, making a wide variety of objects, ranging from practical items such as dishes, surgical tools, candlesticks or funnels, to decorative items like ear rings and hair clips.

The earliest examples of pewter come from ancient Egypt, around 1450 BC. The use of pewter was widespread across Europe, from France to Norway and Britain (where most of the ancient tin was mined) to the Near East. The alloy was also used in China and the Far East, arriving in Japan around 800 AD, where it was used for making objects like ceremonial vessels, tea canisters, or chalices used in shinto shrines.

The first known smelting of iron began in Anatolia, around 1800 BC. Called the bloomery process, it produced very soft but ductile wrought iron. By 800 BC, iron-making technology had spread to Europe, arriving in Japan around 700 AD. Pig iron, a very hard but brittle alloy of iron and carbon, was being produced in China as early as 1200 BC, but did not arrive in Europe until the Middle Ages. Pig iron has a lower melting point than iron, and was used for making cast-iron. However, these metals found little practical use until the introduction of crucible steel around 300 BC. These steels were of poor quality, and the introduction of pattern welding, around the 1st century AD, sought to balance the extreme properties of the alloys by laminating them, to create a tougher metal. Around 700 AD, the Japanese began folding bloomery-steel and cast-iron in alternating layers to increase the strength of their swords, using clay fluxes to remove slag and impurities. This method of Japanese swordsmithing produced one of the purest steel-alloys of the ancient world.

While the use of iron started to become more widespread around 1200 BC, mainly because of interruptions in the trade routes for tin, the metal was much softer than bronze. However, very small amounts of steel, (an alloy of iron and around 1% carbon), was always a byproduct of the bloomery process. The ability to modify the hardness of steel by heat treatment had been known since 1100 BC, and the rare material was valued for the manufacture of tools and weapons. Because the ancients could not produce temperatures high enough to melt iron fully, the production of steel in decent quantities did not occur until the introduction of blister steel during the Middle Ages. This method introduced carbon by heating wrought iron in charcoal for long periods of time, but the absorption of carbon in this manner is extremely slow thus the penetration was not very deep, so the alloy was not homogeneous. In 1740, Benjamin Huntsman began melting blister steel in a crucible to even out the carbon content, creating the first process for the mass production of tool steel. Huntsman's process was used for manufacturing tool steel until the early 1900s.

The introduction of the blast furnace to Europe in the Middle Ages meant that people could produce pig iron in much higher volumes than wrought iron. Because pig iron could be melted, people began to develop processes to reduce carbon in liquid pig iron to create steel. Puddling had been used in China since the first century, and was introduced in Europe during the 1700s, where molten pig iron was stirred while exposed to the air, to remove the carbon by oxidation. In 1858, Henry Bessemer developed a process of steel-making by blowing hot air through liquid pig iron to reduce the carbon content. The Bessemer process led to the first large scale manufacture of steel.

Steel is an alloy of iron and carbon, but the term "alloy steel" usually only refers to steels that contain other elements— like vanadium, molybdenum, or cobalt—in amounts sufficient to alter the properties of the base steel. Since ancient times, when steel was used primarily for tools and weapons, the methods of producing and working the metal were often closely guarded secrets. Even long after the Age of reason, the steel industry was very competitive and manufacturers went through great lengths to keep their processes confidential, resisting any attempts to scientifically analyze the material for fear it would reveal their methods. For example, the people of Sheffield, a center of steel production in England, were known to routinely bar visitors and tourists from entering town to deter industrial espionage. Thus, almost no metallurgical information existed about steel until 1860. Because of this lack of understanding, steel was not generally considered an alloy until the decades between 1930 and 1970 (primarily due to the work of scientists like William Chandler Roberts-Austen, Adolf Martens, and Edgar Bain), so "alloy steel" became the popular term for ternary and quaternary steel-alloys.

After Benjamin Huntsman developed his crucible steel in 1740, he began experimenting with the addition of elements like manganese (in the form of a high-manganese pig-iron called "spiegeleisen"), which helped remove impurities such as phosphorus and oxygen; a process adopted by Bessemer and still used in modern steels (albeit in concentrations low enough to still be considered carbon steel). Afterward, many people began experimenting with various alloys of steel without much success. However, in 1882, Robert Hadfield, being a pioneer in steel metallurgy, took an interest and produced a steel alloy containing around 12% manganese. Called mangalloy, it exhibited extreme hardness and toughness, becoming the first commercially viable alloy-steel. Afterward, he created silicon steel, launching the search for other possible alloys of steel.

Robert Forester Mushet found that by adding tungsten to steel it could produce a very hard edge that would resist losing its hardness at high temperatures. "R. Mushet's special steel" (RMS) became the first high-speed steel. Mushet's steel was quickly replaced by tungsten carbide steel, developed by Taylor and White in 1900, in which they doubled the tungsten content and added small amounts of chromium and vanadium, producing a superior steel for use is lathes and machining tools. In 1903 the Wright brothers used a chromium-nickel steel to make the crankshaft for their airplane engine, while in 1908 Henry Ford began using vanadium steels for parts like crankshafts and valves in his Model T Ford, due to their higher strength and resistance to high temperatures. In 1912, the Krupp Ironworks in Germany developed a rust-resistant steel by adding 21% chromium and 7% nickel, producing the first stainless steel.

Nonferrous alloys contain no appreciable amounts of iron. The first alloys, bronze and brass, were used for thousands of years, along with lead alloys, pewter and others—but these were all made from metals that were fairly non-reactive and could be smelted over open flames. In the 18th century, Antoine Lavoisier helped to establish the oxygen theory of combustion, displacing the defunct phlogiston theory that had ruled since the late Middle Ages. The oxygen theory helped correctly explain the phenomenon of things like oxidation of metals (i.e., rust) and how rocky ores transform into metals when heated. Lavoisier predicted that many of the earths, salts, and alkalis—for example in alum, a salt used since antiquity—contained metallic bases that were too reactive to oxygen to smelt by the usual methods. His work eventually led to the periodic table of elements, which helped confirm the existence of these "missing metals."

Due to their high reactivity, most metals were not discovered until the 19th century. A method for extracting aluminium from bauxite was proposed by Humphry Davy in 1807, using an electric arc. Although his attempts were unsuccessful, by 1855 the first sales of pure aluminium reached the market. However, as extractive metallurgy was still in its infancy, most aluminium extraction-processes produced unintended alloys contaminated with other elements found in the ore; the most abundant of which was copper. These aluminium-copper alloys (at the time termed "aluminum bronze") preceded pure aluminium, offering greater strength and hardness over the soft, pure metal, and to a slight degree were found to be heat treatable. However, due to their softness and limited hardenability these alloys found little practical use, and were more of a novelty, until the Wright brothers used an aluminium alloy to construct the first airplane engine in 1903. During the time between 1865 and 1910, processes for extracting many other metals were discovered, such as chromium, vanadium, tungsten, iridium, cobalt, and molybdenum, and various alloys were developed.

Prior to 1910, research mainly consisted of private individuals tinkering in their own laboratories. However, as the aircraft and automotive industries began growing, research into alloys became an industrial effort in the years following 1910, as new magnesium alloys were developed for pistons and wheels in cars, and pot metal for levers and knobs, and aluminium alloys developed for airframes and aircraft skins were put into use.

In 1906, precipitation hardening alloys were discovered by Alfred Wilm. Precipitation hardening alloys, such as certain alloys of aluminium, titanium, and copper, are heat-treatable alloys that soften when quenched (cooled quickly), and then harden over time. Wilm had been searching for a way to harden aluminium alloys for use in machine-gun cartridge cases. Knowing that aluminium-copper alloys were heat-treatable to some degree, Wilm tried quenching a ternary alloy of aluminium, copper, and the addition of magnesium, but was initially disappointed with the results. However, when Wilm retested it the next day he discovered that the alloy increased in hardness when left to age at room temperature, and far exceeded his expectations. Although an explanation for the phenomenon was not provided until 1919, duralumin was one of the first "age hardening" alloys used, becoming the primary building material for the first Zeppelins, and was soon followed by many others. Because they often exhibit a combination of high strength and low weight, these alloys became widely used in many forms of industry, including the construction of modern aircraft.




</doc>
<doc id="1192" url="https://en.wikipedia.org/wiki?curid=1192" title="Artistic revolution">
Artistic revolution

Throughout history, forms of art have gone through periodic abrupt changes called artistic revolutions. Movements have come to an end to be replaced by a new movement markedly different in striking ways. See also cultural movements.

The role of fine art has been to simultaneously express values of the current culture while also offering criticism, balance, or alternatives to any such values that are proving no longer useful. So as times change, art changes. If changes were abrupt they were deemed revolutions. The best artists have predated society's changes due not to any prescience, but because sensitive perceptivity is part of their talent of seeing.

Artists who succeeded enough to portray visions that future generations could live to see, often had to navigate an often treacherous path between their own capacity to see and execute what lesser artists could not, while still appealing to powerful patrons who could finance their visions. For example, paintings glorified aristocracy in the early 17th century when leadership was needed to nationalize small political groupings, but later as leadership became oppressive, satirization increased and subjects were less concerned with leaders and more with more common plights of mankind.

No art owes quite as much to state power as French painting does. It was in the age of absolute monarchy launched by Louis XIV in the 17th century that the likes of Poussin and Le Brun put France in the forefront of European art. Versailles found its stately mirror in the powerful idea of classicism – a painting style, enduring in later artists like Ingres, whose austerity and grandeur express the authority of a world where Jove is very much in his throne.

Examples of revolutionary art in conjunction with cultural and political movements:


Here is an example of an Artistic Revolution Pieces

Not all artistic revolutions were political. Sometimes, science and technological innovations have brought about unforeseen transformations in the works of artists. The stylistic revolution known as Impressionism, by painters eager to more accurately capture the changing colors of light and shadow, is inseparable from discoveries and inventions in the mid-19th century in which the style was born.

Eugene Chevreul, a French chemist hired as director of dyes at a French tapestry works, began to investigate the optical nature of color in order to improve color in fabrics. Chevreul realized It was the eye, and not the dye, that had the greatest influence on color, and from this, he revolutionized color theory by grasping what came to be called the law of simultaneous contrast: that colors mutually influence one another when juxtaposed, each imposing its own complementary color on the other. The French painter Eugène Delacroix, who had been experimenting with what he called broken tones, embraced Chevreul's book, "The Law of Contrast of Color (1839) with its explanations of how juxtaposed colors can enhance or diminish each other, and his exploration of all the visible colors of the spectrum. Inspired by Chevreul’s 1839 treatise, Delacroix passed his enthusiasm on to the young artists who were inspired by him. It was Chevreul who led the Impressionists to grasp that they should apply separate brushstrokes of pure color to a canvas and allow the viewer’s eye to combine them optically.

They were aided greatly in this by innovations in oil paint itself. Since the Renaissance, painters had to grind pigment, add oil and thus create their own paints; these time-consuming paints also quickly dried out, making studio painting a necessity for large works, and limiting painters to mix one or two colors at a time and fill in an entire area using just that one color before it dried out. in 1841, a little-known American painter named John G. Rand invented a simple improvement without which the Impressionist movement could not have occurred: the small, flexible tin tube with removable cap in which oil paints could be stored. Oil paints kept in such tubes stayed moist and usable -- and quite portable. For the first time since the Renaissance, painters were not trapped by the time frame of how quickly oil paint dried.

Paints in tubes could be easily loaded up and carried out into the real world, to directly observe the play of color and natural light, in shadow and movement, to paint in the moment. Selling the oil paint in tubes also brought about the arrival of dazzling new pigments - chrome yellow, cadmium blue - invented by 19th century industrial chemists. The tubes freed the Impressionists to paint quickly, and across an entire canvas, rather than carefully delineated single-color sections at a time; in short, to sketch directly in oil - racing across the canvas in every color that came to hand and thus inspiring their name of "impressionists" - since such speedy, bold brushwork and dabs of separate colors made contemporary critics think their paintings were mere impressions, not finished paintings, which were to have no visible brush marks at all, seamless under layers of varnish.

Pierre-Auguste Renoir said, “Without colors in tubes, there would be no Cézanne, no Monet, no Pissarro, and no Impressionism.”

Finally, the careful, hyper-realistic techniques of French neo-classicism were seen as stiff and lifeless when compared to the remarkable new vision of the world as seen through the new invention of photography by the mid-1850s. It was not merely that the increasing ability of this new invention, particularly by the French inventor Daguerre, made the realism of the painted image redundant as he deliberately competed in the Paris diorama with large-scale historical paintings. The neo-classical subject matter, limited by Academic tradition to Greek and Roman legends, historical battles and Biblical stories, seemed oppressively cliched and limited to artists eager to explore the actual world in front of their own eyes revealed by the camera - daily life, candid groupings of everyday people doing simple things, Paris itself, rural landscapes and most particularly the play of captured light - not the imaginary lionizing of unseen past events. Early photographs influenced Impressionist style by its use of asymmetry, cropping and most obviously the blurring of motion, as inadvertently captured in the very slow speeds of early photography.

Edgar Degas, Claude Monet, Pierre-Auguste Renoir - in their framing, use of color, light and shadow, subject matter - put these innovations to work to create a new language of visual beauty and meaning.

Their initial break with realism into an exploration of light, color and the nature of paint was brought to an ultimate conclusion by the Abstract Expressionists who broke away from recognizable content of any kind into works of pure shape, color and painterliness which emerged at the end of the second world war. At first thought of as primitive, inept works - as in "my four year old could do that"—these works were misunderstood and neglected until given critical and support by the rise of art journalists and critics who championed their work in the 1940s and 50's, expressing the power of such work in aesthetic terms the artists themselves seldom used, or even understood. Jackson Pollock who pioneered splatter painting, dispensing with a paint brush altogether, soon became lionized as the angry young man in a large spread in Life Magazine.

In fact, in a deliberate, secret and successful effort to separate artistic revolutions from political ones, abstract expressionists like Pollack, Robert Motherwell, Willem de Kooning and Mark Rothko, while seemingly difficult, pathbreaking artists, were in fact secretly supported for twenty years by the C.I.A. in a Cold War policy begun in 1947 to prove that the United States could foster more artistic freedom than the Soviet bloc. "It was recognized that Abstract Expressionism was the kind of art that made Socialist Realism look even more stylized and rigid and confined than it was, " said former C.I.A. case worker Donald Jameson, who finally broke the silence on this program in 1995. Ironically, the covert C.I.A. support for these radical works was required because an attempt to use government funds for a European tour of these works during the Truman administration led to a public uproar in conservative McCarthy-era America, with Truman famously remarking, "If that's art, I'm a Hottentot." Thus the program was hidden under the guise of fabricated foundations and the support of wealthy patrons who were actually using C.I.A. funds, not their own, to sponsor traveling exhibitions of American abstract expressionists all over the world, publish books and articles praising them and to purchase and exhibit Abstract Expressionist works in major American and British museums. Thomas Braden, in charge of these cultural programs for the C.I.A.. in the early years of the Cold War, had formerly been executive secretary of the Museum of Modern Art, America's leading institution for 20th Century art and the charges of collusion between the two echoed for many years after this program was revealed, though most of the artists involved had no idea they were being used in this way and were furious when they found out.

Key dates: 15000 BCE / 400 BCE-200CE / 350 CE-450CE
Ancient - There are few remaining examples with early art often favouring drawing over colour. Work has been found recently in tombs, Egyptian frescoes, pottery and metalwork.
Classical - Relating to or from ancient Roman or Greek architecture and art. Mainly concerned with geometry and symmetry rather than individual expression.
Byzantine - A religious art characterised by large domes, rounded arches and mosaics from the eastern Roman Empire in the 4th Century.

Key dates: 400CE
Medieval - A highly religious art beginning in the 5th Century in Western Europe. It was characterised by iconographic paintings illustrating scenes from the bible.
Gothic - This style prevailed between the 12th century and the 16th century in Europe. Mainly an architectural movement, Gothic was characterised by its detailed ornamentation most noticeably the pointed archways and elaborate rib vaulting.
First developed in France, Gothic was intended as a solution to the inadequacies of Romanesque architecture. It allowed for cathedrals to be built with thinner walls and it became possible to introduce stained glass windows instead of traditional mosaic decorations. Some of the finest examples of the style include the cathedrals of Chartres, Reims and Amiens. The term was also used to describe sculpture and painting that demonstrated a greater degree of naturalism.

Key dates: 14th century
This movement began in Italy in the 14th century and the term, literally meaning rebirth, describes the revival of interest in the artistic achievements of the Classical world. Initially in a literary revival Renaissance was determined to move away from the religion-dominated Middle Ages and to turn its attention to the plight of the individual man in society. It was a time when individual expression and worldly experience became two of the main themes of Renaissance art. The movement owed a lot to the increasing sophistication of society, characterised by political stability, economic growth and cosmopolitanism. Education blossomed at this time, with libraries and academies allowing more thorough research to be conducted into the culture of the antique world. In addition, the arts benefited from the patronage of such influential groups as the Medici family of Florence, the Sforza family of Milan and Popes Julius II and Leo X. The works of Petrarch first displayed the new interest in the intellectual values of the Classical world in the early 14th century and the romance of this era as rediscovered in the Renaissance period can be seen expressed by Boccaccio. Leonardo da Vinci was the archetypal Renaissance man representing the humanistic values of the period in his art, science and writing. Michelangelo and Raphael were also vital figures in this movement, producing works regarded for centuries as embodying the classical notion of perfection. Renaissance architects included Alberti, Brunelleschi and Bramante. Many of these artists came from Florence and it remained an important centre for the Renaissance into the 16th century eventually to be overtaken by Rome and Venice. Some of the ideas of the Italian Renaissance did spread to other parts of Europe, for example to the German artist Albrecht Dürer of the 'Northern Renaissance'. But by the 16th century Mannerism had overtaken the Renaissance and it was this style that caught on in Europe. 
Representative artists:
Leonardo da Vinci, Sandro Botticelli, Filippo Brunelleschi, Raphael da Urbino, Titian, Michelangelo Buonarroti, and Donatello Bardi.

Key dates: 1520-1600
Artists of the Early Renaissance and the High Renaissance developed their characteristic styles from the observation of nature and the formulation of a pictorial science. When Mannerism matured after 1520(The year Raphael died), all the representational problems had been solved. A body of knowledge was there to be learned. Instead of nature as their teacher, Mannerist artists took art. While Renaissance artists sought nature to find their style, the Mannerists looked first for a style and found a manner. In Mannerist paintings, compositions can have no focal point, space can be ambiguous, figures can be characterized by an athletic bending and twisting with distortions, exaggerations, an elastic elongation of the limbs, bizarre posturing on one hand, graceful posturing on the other hand, and a rendering of the heads as uniformly small and oval. The composition is jammed by clashing colors, which is unlike what we've seen in the balanced, natural, and dramatic colors of the High Renaissance. Mannerist artwork seeks instability and restlessness. There is also a fondness for allegories that have lascivious undertones. 
Representative artists:
Andrea del Sarto, Jacopo da Pontormo, Correggio

Key dates: 17th century
Baroque Art emerged in Europe around 1600, as a reaction against the intricate and formulaic Mannerist style which dominated the Late Renaissance. Baroque Art is less complex, more realistic and more emotionally affecting than Mannerism.
This movement was encouraged by the Catholic Church, the most important patron of the arts at that time, as a return to tradition and spirituality.
One of the great periods of art history, Baroque Art was developed by Caravaggio, Annibale Carracci, and Gianlorenzo Bernini, among others. This was also the age of Rubens, Rembrandt, Velázquez, and Vermeer.
In the 18th century, Baroque Art was replaced by the more elegant and elaborate Rococo style.
Representative artists:
Caravaggio, Annibale Carracci, Gianlorenzo Bernini, Rubens, Rembrandt, Nicolas Poussin

Key dates: 18th century
Throughout the 18th century in France, a new wealthy and influential middle-class was beginning to rise, even though the royalty and nobility continued to be patrons of the arts. Upon the death of Louis XIV and the abandonment of Versailles, the Paris high society became the purveyors of style. This style, primarily used in interior decoration, came to be called Rococo. The term Rococo was derived from the French word "rocaille", which means pebbles and refers to the stones and shells used to decorate the interiors of caves. Therefore, shell forms became the principal motif in Rococo. The society women competed for the best and most elaborate decorations for their houses. Hence the Rococo style was highly dominated by the feminine taste and influence.
François Boucher was the 18th century painter and engraver whose works are regarded as the perfect expression of French taste in the Rococo period. Trained by his father who was a lace designer, Boucher won fame with his sensuous and light-hearted mythological paintings and landscapes. He executed important works for both the Queen of France and Mme. de Pompadour, Louis XV's mistress, who was considered the most powerful woman in France at the time. Boucher was Mme. de Pompadour's favorite artist and was commissioned by her for numerous paintings and decorations. Boucher also became the principal designer for the royal porcelain factory and the director of the Gobelins tapestry factory. The Vulcan Presenting Venus with Arms for Aeneas is a template for a tapestry made by this factory. 
Characterized by elegant and refined yet playful subject matters, Boucher's style became the epitome of the court of Louis XV. His style consisted of delicate colors and gentle forms painted within a frivolous subject matter. His works typically utilized delightful and decorative designs to illustrate graceful stories with Arcadian shepherds, goddesses and cupids playing against a pink and blue sky. These works mirrored the frolicsome, artificial and ornamented decadence of the French aristocracy of the time.
The Rococo is sometimes considered a final phase of the Baroque period.
Representative artists:
François Boucher, William Hogarth, Giovanni Battista Tiepolo, Angelica Kauffman, Giovanni Antonio Canaletto, Velázquez Vermeer

Key dates: 1750-1880
A nineteenth-century French art style and movement that originated as a reaction to the Baroque. It sought to revive the ideals of ancient Greek and Roman art. Neoclassic artists used classical forms to express their ideas about courage, sacrifice, and love of country. David and Canova are examples of neo-classicists.
Representative artists:
Jacques-Louis David, Sir Henry Raeburn, Sir Joshua Reynolds, Jean-Auguste-Dominique Ingres, Thomas Gainsborough, Antonio Canova, Arnold Bocklin

Key dates: 1800-1880
Romanticism was basically a reaction against Neoclassicism, it is a deeply felt style which is individualistic, beautiful, exotic, and emotionally wrought.
Although Romanticism and Neoclassicism were philosophically opposed, they were the dominant European styles for generations, and many artists were affected to a greater or lesser degree by both. Artists might work in both styles at different times or even mix the styles, creating an intellectually Romantic work using a Neoclassical visual style, for example.
Great artists closely associated with Romanticism include J.M.W. Turner, Caspar David Friedrich, John Constable, and William Blake.
In the United States, the leading Romantic movement was the Hudson River School of dramatic landscape painting.
Obvious successors of Romanticism include the Pre-Raphaelite movement and the Symbolists. But Impressionism, and through it almost all of 20th-century art, is also firmly rooted in the Romantic tradition. 
Representative artists:
George Stubbs, William Blake, John Martin, Francisco Goya, Sir Thomas Lawrence, John Constable, Eugène Delacroix, Sir Edwin landseer, Caspar David Friedrich, JMW Turner


</doc>
<doc id="1193" url="https://en.wikipedia.org/wiki?curid=1193" title="Agrarianism">
Agrarianism

Agrarianism is a social philosophy or political philosophy which relates to the ownership and use of land for farming, or relating to the part of a society or economy that is tied to agriculture. Agrarianism and agrarians will typically advocate on behalf of farmers and those in rural communities. While there are many schools of thought within agrarianism, historically a reoccurring feature of agrarians has been a commitment to egalitarianism, with agrarian political parties normally supporting the rights of small farmers and poor peasants against the wealthy in society.

Some scholars suggest that agrarianism values rural society as superior to urban society and the independent farmer as superior to the paid worker, and sees farming as a way of life that can shape the ideal social values. It stresses the superiority of a simpler rural life as opposed to the complexity of city life. For example, M. Thomas Inge defines agrarianism by the following basic tenets:

The philosophical roots of agrarianism include European and Chinese philosophers. The Chinese school of Agriculturalism (农家/農家) was a philosophy that advocated peasant utopian communalism and egalitarianism. In societies influenced by Confucianism, the farmer was considered an esteemed productive member of society, but merchants who made money were looked down upon. That influenced European intellectuals like François Quesnay, an avid Confucianist and advocate of China's agrarian policies, in forming the French agrarian philosophy of physiocracy. The physiocrats, along with the ideas of John Locke and the Romantic Era, formed the basis of modern European and American agrarianism.

The United States president Thomas Jefferson was an agrarian who based his ideas about the budding American democracy around the notion that farmers are “the most valuable citizens” and the truest republicans. Jefferson and his support base were committed to American republicanism, which saw as being in opposition to aristocracy, opposition to corruption, and priority on virtue, exemplified by the "yeoman farmer", "planters", and the "plain folk". While praising the rural farmfolk, the Jeffersonians felt that financiers, bankers and industrialists created "cesspools of corruption" in the cites and should thus be avoided.

The Jeffersonians sought to orientate the American economy more towards agriculture than industry. Part of their motive to do was Jefferson's fear that the over industrialisation of America would create a class of wage laborers who relied on their employers for income and sustenance. In turn, these workers would cease to be independent voters as their vote could be manipulated by said employers. In order to counter this, Jefferson introduced, as scholar Clay Jenkinson noted, "a graduated income tax that would serve as a disincentive to vast accumulations of wealth and would make funds available for some sort of benign redistribution downward" as well as tariffs on imported articles, which were mainly purchased by the wealthy. In 1811 Jefferson, writing to a friend, explained: "These revenues will be levied entirely on the rich . ... The Rich alone use imported article, and on these alone the whole taxes of the General Government are levied. The poor man ... pays not a farthing of tax to the General Government, but on his salt."

Agrarian socialism is a form of agrarianism that is anti-capitalist in nature and seeks to introduce socialist economic systems in their stead.

Notable agrarian socialists include Emiliano Zapata who was a leading figure in the Mexican Revolution. As part of the Liberation Army of the South, his group of revolutionaries fought on behalf of the Mexican peasants, whom they saw as exploited by the landowning classes. Zapata published Plan of Ayala, which called for significant land reforms and land redistribution in Mexico as part of the revolution. Zapata was killed and his forces crushed over the course of the Revolution, but his political ideas lived on in the form of Zapatismo.

Zapatismo would form the basis for neozapatismo, the ideology of the Zapatista Army of National Liberation. Known as "Ejército Zapatista de Liberación Nacional" or EZLN in Spanish, EZLN is a far-left libertarian socialist political and militant group that emerged in the state of Chiapas in southmost Mexico in 1994. EZLN and Neozapatismo, as explicit in their name, seek to revive the agrarian socialist movement of Zapata, but fuse it with new elements such as a commitment to indigenous rights and community-level decision making.

Subcommander Marcos, a leading member of the movement, argues that the peoples' collective ownership of the land was and is the basis for all subsequent developments the movement sought to create:
…When the land became property of the peasants … when the land passed into the hands of those who work it … [This was] the starting point for advances in government, health, education, housing, nutrition, women’s participation, trade, culture, communication, and information …[it was] recovering the means of production, in this case, the land, animals, and machines that were in the hands of large property owners.”

Maoism, the far-left ideology of Mao Zedong and his followers, places a heavy emphasis on the role of peasants in its goals. In contrast to other Marxist schools of thought which normally seek to acquire the support of urban workers, Maoism sees the peasantry as key. Believing that "political power grows out of the barrel of a gun", Maoism saw the Chinese Peasantry as the prime source for a Marxist vanguard because it possessed two qualities: (i) they were poor, and (ii) they were a political blank slate; in Mao's words, “A clean sheet of paper has no blotches, and so the newest and most beautiful words can be written on it”. During the Chinese Civil War and the Second Sino-Japanese War, Mao and the Chinese Communist Party made extensive use of peasants and rural bases in their military tactics, often eschewing the cities.

Following the eventual victory of the Communist Party in both wars, the countryside and how it should be run remained a focus for Mao. In 1958 Mao launched the Great Leap Forward, a social and economic campaign which, amongst other things, altered many aspects of rural Chinese life. It introduced mandatory collective farming and forced the peasantry to organize itself into communal living units which were known as people's communes. These communes, which consisted of 5,000 people on average, were expected to meet high production quotas while the peasants who lived on them adapted to this radically new way of life. The communes were run as co-operatives where wages and money were replaced by work points. Peasants who criticised this new system were persecuted as "rightists" and "counter-revolutionaries". Leaving the communes was forbidden and escaping from them was difficult or impossible, and those who attempted it were subjected to party-orchestrated "public struggle sessions," which further jeopardized their survival. These public criticism sessions were often used to intimidate the peasants into obeying local officials and they often devolved into little more than public beatings.

On the communes, experiments were conducted in order to find new methods of planting crops, efforts were made to construct new irrigation systems on a massive scale, and the communes were all encouraged to produce steel backyard furnaces as part of an effort to increase steel production. However, following the Anti-Rightist Campaign, Mao had instilled a mass distrust of intellectuals into China, and thus engineers were often not consulted with regard to the new irrigation systems and the wisdom of asking untrained peasants to produce good quality steel from scrap iron was not publicly questioned. Similarly, the experimentation with the crops did not produce results. In addition to this the Four Pests Campaign was launched, in which the peasants were called upon to destroy sparrows and other wild birds that ate crop seeds, in order to protect fields. Pest birds were shot down or scared away from landing until they dropped from exhaustion. This campaign resulted in an ecological disaster that saw an explosion of the vermin population, especially crop-eating insects, which was consequently not in danger of being killed by predators.

None of these new systems were working, but local leaders did not dare to state this, instead, they falsified reports so as not to be punished for failing to meet the quotas. In many cases they stated that they were greatly exceeding their quotas, and in turn, the Chinese state developed a completely false sense of success with regard to the commune system.

All of this culminated in the Great Chinese Famine, which began in 1959, lasted 3 years, and saw an estimated 15 to 30 million Chinese people die. A combination of bad weather and the new, failed farming techniques that were introduced by the state led to massive shortages of food. By 1962, the Great Leap Forward was declared to be at an end.

In the late 1960s and early 1970s, Mao once again radically altered life in rural China with the launching of the Down to the Countryside Movement. As a response to the Great Chinese Famine, the Chinese President Liu Shaoqi began "sending down" urban youths to rural China in order to recover its population losses and alleviate overcrowding in the cities. However, Mao turned the practice into a political crusade, declaring that the sending down would strip the youth of any bourgeois tendencies by forcing them to learn from the unprivileged rural peasants. In reality, it was the Communist Party's attempt to reign in the Red Guards, who had become uncontrollable during the course of the Cultural Revolution. 10% of the 1970 urban population of China was sent out to remote rural villages, often in Inner Mongolia. The villages, which were still poorly recovering from the effects of the Great Chinese Famine, did not have the excess resources that were needed to support the newcomers. Furthermore, the so-called "sent-down youth" had no agricultural experience and as a result, they were unaccustomed to the harsh lifestyle that existed in the countryside, and their unskilled labor in the villages provided little benefit to the agricultural sector. As a result, many of the sent-down youth died in the countryside. The relocation of the youths was originally intended to be permanent, but by the end of the Cultural Revolution, the Communist Party relented and some of those who had the capacity to return to the cities were allowed to do so.

In imitation of Mao's policies, the Khmer Rouge of Cambodia (who were heavily funded and supported by the People's Republic of China) created their own version of the Great Leap Forward which was known as "Maha Lout Ploh". With the Great Leap Forward as its model, it had similarly disastrous effects, contributing to what is now known as the Cambodian genocide. As a part of the Maha Lout Ploh, the Khmer Rouge sought to create an entirely agrarian socialist society by forcibly relocating 100,000 people to move from Cambodia's cities into newly created communes. The Khmer Rouge leader, Pol Pot sought to "purify" the country by setting it back to "Year Zero", freeing it from "corrupting influences". Besides trying to completely de-urbanize Cambodia, ethnic minorities were slaughtered along with anyone else who was suspected of being a "reactionary" or a member of the "bourgeoisie", to the point that wearing glasses was seen as grounds for execution. The killings were only brought to an end when Cambodia was invaded by the neighboring socialist nation of Vietnam, whose army toppled the Khmer Rouge. However, with Cambodia's entire society and economy in disarray, including its agricultural sector, the country still plunged into renewed famine due to vast food shortages. However, as international journalists began to report on the situation and send images of it out to the world, a massive international response was provoked, leading to one of the most concentrated relief efforts of its time.

Peasant parties first appeared across Eastern Europe between 1860 and 1910, when commercialized agriculture and world market forces disrupted traditional rural society, and the railway and growing literacy facilitated the work of roving organizers. Agrarian parties advocated land reforms to redistribute land on large estates among those who work it. They also wanted village cooperatives to keep the profit from crop sales in local hands and credit institutions to underwrite needed improvements. Many peasant parties were also nationalist parties because peasants often worked their land for the benefit of landlords of different ethnicity.

Peasant parties rarely had any power before World War I but some became influential in the interwar era, especially in Bulgaria and Czechoslovakia. For a while, in the 1920s and the 1930s, there was a Green International (International Agrarian Bureau) based on the peasant parties in Bulgaria, Czechoslovakia, Poland, and Serbia. It functioned primarily as an information center that spread the ideas of agrarianism and combating socialism on the left and landlords on the right and never launched any significant activities.

The Farmers' Voice Party won a seat in the district of Jendouba after the parliamentary election of 2014.

In Bulgaria, the Bulgarian Agrarian National Union (BZNS) was organized in 1899 to resist taxes and build cooperatives. BZNS came to power in 1919 and introduced many economic, social, and legal reforms. However, conservative forces crushed BZNS in a 1923 coup and assassinated its leader, Aleksandar Stamboliyski (1879–1923). BZNS was made into a communist puppet group until 1989, when it reorganized as a genuine party.

In Czechoslovakia, the Republican Party of Agricultural and Smallholder People often shared power in parliament as a partner in the five-party pětka coalition. The party's leader, Antonin Svehla (1873–1933), was prime minister several times. It was consistently the strongest party, forming and dominating coalitions. It moved beyond its original agrarian base to reach middle-class voters. The party was banned by the National Front after the Second World War.

In France, the Hunting, Fishing, Nature, Tradition party is a moderate conservative, agrarian party, reaching a peak of 4.23% in the 2002 French presidential election. It would later on become affiliated to France's main conservative party, Union for a Popular Movement.

In the late 19th century, the Irish National Land League aimed to abolish landlordism in Ireland and enable tenant farmers to own the land they worked on. The "Land War" of 1878–1909 led to the Irish Land Acts, ending absentee landlords and ground rent and redistributing land among peasant farmers.

Post-independence, the Farmers' Party operated in the Irish Free State from 1922, folding into the National Centre Party in 1932. It was mostly supported by wealthy farmers in the east of Ireland.

Clann na Talmhan (Family of the Land; also called the "National Agricultural Party") was founded in 1938. They focused more on the poor smallholders of the west, supporting land reclamation, afforestation, social democracy and rates reform. They formed part of the governing coalition of the Government of the 13th Dáil and Government of the 15th Dáil. Economic improvement in the 1960s saw farmers vote for other parties and Clann na Talmhan disbanded in 1965.

In Latvia, the Union of Greens and Farmers is supportive of traditional small farms and perceives them as more environmentally friendly than large-scale farming: Nature is threatened by development, while small farms are threatened by large industrial-scale farms.

In Lithuania, as of 2017, the government is led by the Lithuanian Farmers and Greens Union, under the leadership of industrial farmer Ramūnas Karbauskis.

In Poland, the Polish People's Party traces its tradition to an agrarian party in Austro-Hungarian-controlled Galician Poland. After the fall of the communist regime, PPP's biggest success came in 1993 elections, where it won 132 out of 460 parliamentary seats. Since then, PPP's support has steadily declined, until 2019, when they formed Polish Coalition with an anti- establishment, direct democracy Kukiz'15 party, and managed to get 8.5% of votes. Moreover, PPP tends to get much better results in local elections. In 2014 elections they have managed to get 23.88% of votes.

The right-wing Law and Justice party has also become supportive of agrarian policies in recent years and polls show that most of their support comes from rural areas.

In Romania, older parties from Transylvania, Moldavia, and Wallachia merged to become the National Peasants' Party in 1926. Iuliu Maniu (1873–1953) was a prime minister with an agrarian cabinet from 1928–1930 and briefly in 1932–1933, but the Great Depression made proposed reforms impossible. The communist regime dissolved the party in 1947, but it reformed in 1989 after they fell from power.

The reformed party, which also incorporated elements of Christian democracy in its ideology, governed Romania as part of the Romanian Democratic Convention between 1996–2000.

In Serbia, Nikola Pašić (1845–1926) and his People's Radical Party dominated Serbian politics after 1903. The party also monopolized power in Yugoslavia from 1918 to 1929. During the dictatorship of the 1930s, the prime minister was from that party.

In Ukraine, the Radical Party of Oleh Lyashko has promised to purify the country of oligarchs "with a pitchfork". The party advocates a number of traditional left-wing positions (a progressive tax structure, a ban on agricultural land sale and eliminating the illegal land market, a tenfold increase in budget spending on health, setting up primary health centres in every village
), and mixes them with strong nationalist sentiments.

The heyday of British agrarianism was in the 1500s, led by the Tudor royal advisors, who sought to maintain a broad pool of agricultural commoners from which to draw military men, against the interests of larger landowners who sought enclosure (meaning of common land). This was reversed by Acts of Parliament which effected the latter policy, chiefly in the 1650 to 1800 period (see enclosure). Politicians standing strongly as reactionaries to enclosure included the Levellers, anti-industrialist Luddites and, later, radicals such as William Cobbett. A high level of net self-sufficiency has a strong base in the national policy debate of successive governments, epitomised in successive centuries by Peelites, the Campaign for Rural England, and local food (anti food-miles) advocates.

Historian F.K. Crowley finds that:

The National Party of Australia (formerly called the Country Party), from the 1920s to the 1970s, promulgated its version of agrarianism, which it called "countrymindedness". The goal was to enhance the status of the graziers (operators of big sheep ranches) and small farmers and justified subsidies for them.

The New Zealand Liberal Party aggressively promoted agrarianism in its heyday (1891–1912). The landed gentry and aristocracy ruled Britain at this time. New Zealand never had an aristocracy but its wealthy landowners largely controlled politics before 1891. The Liberal Party set out to change that by a policy it called "populism." Richard Seddon had proclaimed the goal as early as 1884: "It is the rich and the poor; it is the wealthy and the landowners against the middle and labouring classes. That, Sir, shows the real political position of New Zealand." The Liberal strategy was to create a large class of small landowning farmers who supported Liberal ideals. The Liberal government also established the basis of the later welfare state such as old age pensions and developed a system for settling industrial disputes, which was accepted by both employers and trade unions. In 1893, it extended voting rights to women, making New Zealand the first country in the world to do so.

To obtain land for farmers, the Liberal government from 1891 to 1911 purchased of Maori land. The government also purchased from large estate holders for subdivision and closer settlement by small farmers. The Advances to Settlers Act (1894) provided low-interest mortgages, and the agriculture department disseminated information on the best farming methods. The Liberals proclaimed success in forging an egalitarian, anti-monopoly land policy. The policy built up support for the Liberal Party in rural North Island electorates. By 1903, the Liberals were so dominant that there was no longer an organized opposition in Parliament.

Agrarianism is similar to but not identical with the back-to-the-land movement. Agrarianism concentrates on the fundamental goods of the earth, on communities of more limited economic and political scale than in modern society, and on simple living, even when the shift involves questioning the "progressive" character of some recent social and economic developments. Thus, agrarianism is not industrial farming, with its specialization on products and industrial scale.







</doc>
<doc id="1194" url="https://en.wikipedia.org/wiki?curid=1194" title="Atomic">
Atomic

Atomic may refer to:






</doc>
<doc id="1196" url="https://en.wikipedia.org/wiki?curid=1196" title="Angle">
Angle

In plane geometry, an angle is the figure formed by two rays, called the "sides" of the angle, sharing a common endpoint, called the "vertex" of the angle.
Angles formed by two rays lie in a plane, but this plane does not have to be a Euclidean plane. Angles are also formed by the intersection of two planes in Euclidean and other spaces. These are called dihedral angles. Angles formed by the intersection of two curves in a plane are defined as the angle determined by the tangent rays at the point of intersection. Similar statements also hold in space. For example, the spherical angle formed by two great circles on a sphere is the dihedral angle between the planes determined by the great circles.

"Angle" is also used to designate the measure of an angle or of a rotation. This measure is the ratio of the length of a circular arc to its radius. In the case of a geometric angle, the arc is centered at the vertex and delimited by the sides. In the case of a rotation, the arc is centered at the center of the rotation and delimited by any other point and its image by the rotation.

The word "angle" comes from the Latin word "angulus", meaning "corner"; cognate words are the Greek "(ankylοs)", meaning "crooked, curved," and the English word "ankle". Both are connected with the Proto-Indo-European root "*ank-", meaning "to bend" or "bow".
Euclid defines a plane angle as the inclination to each other, in a plane, of two lines which meet each other, and do not lie straight with respect to each other. According to Proclus, an angle must be either a quality or a quantity, or a relationship. The first concept was used by Eudemus, who regarded an angle as a deviation from a straight line; the second by Carpus of Antioch, who regarded it as the interval or space between the intersecting lines; Euclid adopted the third concept, although his definitions of right, acute, and obtuse angles are certainly quantitative.

In mathematical expressions, it is common to use Greek letters (α, β, γ, θ, φ, . . . ) as variables denoting the size of some angle (to avoid confusion with its other meaning, the symbol is typically not used for this purpose). Lower case Roman letters ("a", "b", "c", . . . ) are also used, as are upper case Roman letters in the context of polygons. See the figures in this article for examples.

In geometric figures, angles may also be identified by the labels attached to the three points that define them. For example, the angle at vertex A enclosed by the rays AB and AC (i.e. the lines from point A to point B and point A to point C) is denoted ∠BAC (in Unicode ) or formula_1. Where there is no risk of confusion, the angle may sometimes be referred to simply by its vertex (in this case "angle A").

Potentially, an angle denoted as, say, ∠BAC, might refer to any of four angles: the clockwise angle from B to C, the anticlockwise angle from B to C, the clockwise angle from C to B, or the anticlockwise angle from C to B, where the direction in which the angle is measured determines its sign (see Positive and negative angles). However, in many geometrical situations, it is obvious from context that the positive angle less than or equal to 180 degrees is meant, in which case no ambiguity arises. Otherwise, a convention may be adopted so that ∠BAC always refers to the anticlockwise (positive) angle from B to C, and ∠CAB the anticlockwise (positive) angle from C to B.

There is some common terminology for angles, whose measure is always non-negative (see #Positive and negative angles):

The names, intervals, and measured units are shown in the table below:


When two straight lines intersect at a point, four angles are formed. Pairwise these angles are named according to their location relative to each other.


A transversal is a line that intersects a pair of (often parallel) lines, and is associated with "alternate interior angles", "corresponding angles", "interior angles", and "exterior angles".

There are three special angle pairs which involve the summation of angles:



The size of a geometric angle is usually characterized by the magnitude of the smallest rotation that maps one of the rays into the other. Angles that have the same size are said to be "equal" or "congruent" or "equal in measure".

In some contexts, such as identifying a point on a circle or describing the "orientation" of an object in two dimensions relative to a reference orientation, angles that differ by an exact multiple of a full turn are effectively equivalent. In other contexts, such as identifying a point on a spiral curve or describing the "cumulative rotation" of an object in two dimensions relative to a reference orientation, angles that differ by a non-zero multiple of a full turn are not equivalent.

In order to measure an angle θ, a circular arc centered at the vertex of the angle is drawn, e.g. with a pair of compasses. The ratio of the length s of the arc by the radius r of the circle is the measure of the angle in radians.

The measure of the angle in another angular unit is then obtained by multiplying its measure in radians by the scaling factor , where "k" is the measure of a complete turn in the chosen unit (for example 360 for degrees or 400 for gradians):

The value of θ thus defined is independent of the size of the circle: if the length of the radius is changed then the arc length changes in the same proportion, so the ratio "s"/"r" is unaltered. (Proof. The formula above can be rewritten as One turn, for which units, corresponds to an arc equal in length to the circle's circumference, which is 2"r", so . Substituting "n" for "θ" and 2"r" for "s" in the formula, results in ) 

The angle addition postulate states that if "B" is in the interior of angle "AOC", then

The measure of the angle "AOC" is the sum of the measure of angle AOB and the measure of angle "BOC". In this postulate it does not matter in which unit the angle is measured as long as each angle is measured in the same unit.

Units used to represent angles are listed below in descending magnitude order. Of these units, the "degree" and the "radian" are by far the most commonly used. Angles expressed in radians are dimensionless for the purposes of dimensional analysis.

Most units of angular measurement are defined such that one "turn" (i.e. one full circle) is equal to "n" units, for some whole number "n". The two exceptions are the radian and the diameter part.
















Although the definition of the measurement of an angle does not support the concept of a negative angle, it is frequently useful to impose a convention that allows positive and negative angular values to represent orientations and/or rotations in opposite directions relative to some reference.

In a two-dimensional Cartesian coordinate system, an angle is typically defined by its two sides, with its vertex at the origin. The "initial side" is on the positive x-axis, while the other side or "terminal side" is defined by the measure from the initial side in radians, degrees, or turns. With "positive angles" representing rotations toward the positive y-axis and "negative angles" representing rotations toward the negative "y"-axis. When Cartesian coordinates are represented by "standard position", defined by the "x"-axis rightward and the "y"-axis upward, positive rotations are anticlockwise and negative rotations are clockwise.

In many contexts, an angle of −"θ" is effectively equivalent to an angle of "one full turn minus "θ"". For example, an orientation represented as  −45° is effectively equivalent to an orientation represented as 360° − 45° or 315°. Although the final position is the same, a physical rotation (movement) of  −45° is not the same as a rotation of 315° (for example, the rotation of a person holding a broom resting on a dusty floor would leave visually different traces of swept regions on the floor).

In three-dimensional geometry, "clockwise" and "anticlockwise" have no absolute meaning, so the direction of positive and negative angles must be defined relative to some reference, which is typically a vector passing through the angle's vertex and perpendicular to the plane in which the rays of the angle lie.

In navigation, bearings or azimuth are measured relative to north. By convention, viewed from above, bearing angles are positive clockwise, so a bearing of 45° corresponds to a north-east orientation. Negative bearings are not used in navigation, so a north-west orientation corresponds to a bearing of 315°.

There are several alternatives to measuring the size of an angle by the angle of rotation.
The "grade of a slope", or "gradient" is equal to the tangent of the angle, or sometimes (rarely) the sine. A gradient is often expressed as a percentage. For very small values (less than 5%), the grade of a slope is approximately the measure of the angle in radians.

In rational geometry the "spread" between two lines is defined as the square of the sine of the angle between the lines. As the sine of an angle and the sine of its supplementary angle are the same, any angle of rotation that maps one of the lines into the other leads to the same value for the spread between the lines.

Astronomers measure angular separation of objects in degrees from their point of observation.

These measurements clearly depend on the individual subject, and the above should be treated as rough rule of thumb approximations only.

The angle between a line and a curve (mixed angle) or between two intersecting curves (curvilinear angle) is defined to be the angle between the tangents at the point of intersection. Various names (now rarely, if ever, used) have been given to particular cases:—"amphicyrtic" (Gr. , on both sides, κυρτός, convex) or "cissoidal" (Gr. κισσός, ivy), biconvex; "xystroidal" or "sistroidal" (Gr. ξυστρίς, a tool for scraping), concavo-convex; "amphicoelic" (Gr. κοίλη, a hollow) or "angulus lunularis", biconcave.

The ancient Greek mathematicians knew how to bisect an angle (divide it into two angles of equal measure) using only a compass and straightedge, but could only trisect certain angles. In 1837 Pierre Wantzel showed that for most angles this construction cannot be performed.

In the Euclidean space, the angle "θ" between two Euclidean vectors u and v is related to their dot product and their lengths by the formula

This formula supplies an easy method to find the angle between two planes (or curved surfaces) from their normal vectors and between skew lines from their vector equations.

To define angles in an abstract real inner product space, we replace the Euclidean dot product ( · ) by the inner product formula_6, i.e.

In a complex inner product space, the expression for the cosine above may give non-real values, so it is replaced with

or, more commonly, using the absolute value, with

The latter definition ignores the direction of the vectors and thus describes the angle between one-dimensional subspaces formula_10 and formula_11 spanned by the vectors formula_12 and formula_13 correspondingly.

The definition of the angle between one-dimensional subspaces formula_10 and formula_11 given by

in a Hilbert space can be extended to subspaces of any finite dimensions. Given two subspaces formula_17, formula_18 with formula_19, this leads to a definition of formula_20 angles called canonical or principal angles between subspaces.

In Riemannian geometry, the metric tensor is used to define the angle between two tangents. Where "U" and "V" are tangent vectors and "g" are the components of the metric tensor "G",

A hyperbolic angle is an argument of a hyperbolic function just as the "circular angle" is the argument of a circular function. The comparison can be visualized as the size of the openings of a hyperbolic sector and a circular sector since the areas of these sectors correspond to the angle magnitudes in each case. Unlike the circular angle, the hyperbolic angle is unbounded. When the circular and hyperbolic functions are viewed as infinite series in their angle argument, the circular ones are just alternating series forms of the hyperbolic functions. This weaving of the two types of angle and function was explained by Leonhard Euler in "Introduction to the Analysis of the Infinite".

In geography, the location of any point on the Earth can be identified using a "geographic coordinate system". This system specifies the latitude and longitude of any location in terms of angles subtended at the centre of the Earth, using the equator and (usually) the Greenwich meridian as references.

In astronomy, a given point on the celestial sphere (that is, the apparent position of an astronomical object) can be identified using any of several "astronomical coordinate systems", where the references vary according to the particular system. Astronomers measure the "angular separation" of two stars by imagining two lines through the centre of the Earth, each intersecting one of the stars. The angle between those lines can be measured, and is the angular separation between the two stars.

In both geography and astronomy, a sighting direction can be specified in terms of a vertical angle such as altitude /elevation with respect to the horizon as well as the azimuth with respect to north.

Astronomers also measure the "apparent size" of objects as an angular diameter. For example, the full moon has an angular diameter of approximately 0.5°, when viewed from Earth. One could say, "The Moon's diameter subtends an angle of half a degree." The small-angle formula can be used to convert such an angular measurement into a distance/size ratio.




</doc>
<doc id="1197" url="https://en.wikipedia.org/wiki?curid=1197" title="Asa">
Asa

Asa may refer to:





</doc>
<doc id="1198" url="https://en.wikipedia.org/wiki?curid=1198" title="Acoustics">
Acoustics

Acoustics is a branch of physics that deals with the study of mechanical waves in gases, liquids, and solids including topics such as vibration, sound, ultrasound and infrasound. A scientist who works in the field of acoustics is an acoustician while someone working in the field of acoustics technology may be called an acoustical engineer. The application of acoustics is present in almost all aspects of modern society with the most obvious being the audio and noise control industries.

Hearing is one of the most crucial means of survival in the animal world and speech is one of the most distinctive characteristics of human development and culture. Accordingly, the science of acoustics spreads across many facets of human society—music, medicine, architecture, industrial production, warfare and more. Likewise, animal species such as songbirds and frogs use sound and hearing as a key element of mating rituals or marking territories. Art, craft, science and technology have provoked one another to advance the whole, as in many other fields of knowledge. Robert Bruce Lindsay's "Wheel of Acoustics" is a well accepted overview of the various fields in acoustics. 

The word "acoustic" is derived from the Greek word ἀκουστικός ("akoustikos"), meaning "of or for hearing, ready to hear"and that from ἀκουστός ("akoustos"), "heard, audible", which in turn derives from the verb ἀκούω("akouo"), "I hear".

The Latin synonym is "sonic", after which the term sonics used to be a synonym for acoustics and later a branch of acoustics. Frequencies above and below the audible range are called "ultrasonic" and "infrasonic", respectively.

In the 6th century BC, the ancient Greek philosopher Pythagoras wanted to know why some combinations of musical sounds seemed more beautiful than others, and he found answers in terms of numerical ratios representing the harmonic overtone series on a string. He is reputed to have observed that when the lengths of vibrating strings are expressible as ratios of integers (e.g. 2 to 3, 3 to 4), the tones produced will be harmonious, and the smaller the integers the more harmonious the sounds. For example, a string of a certain length would sound particularly harmonious with a string of twice the length (other factors being equal). In modern parlance, if a string sounds the note C when plucked, a string twice as long will sound a C an octave lower. In one system of musical tuning, the tones in between are then given by 16:9 for D, 8:5 for E, 3:2 for F, 4:3 for G, 6:5 for A, and 16:15 for B, in ascending order.

Aristotle (384–322 BC) understood that sound consisted of compressions and rarefactions of air which "falls upon and strikes the air which is next to it...", a very good expression of the nature of wave motion. "On Things Heard", generally ascribed to Strato of Lampsacus, states that the pitch is related to the frequency of vibrations of the air and to the speed of sound.

In about 20 BC, the Roman architect and engineer Vitruvius wrote a treatise on the acoustic properties of theaters including discussion of interference, echoes, and reverberation—the beginnings of architectural acoustics. In Book V of his "De architectura" ("The Ten Books of Architecture") Vitruvius describes sound as a wave comparable to a water wave extended to three dimensions, which, when interrupted by obstructions, would flow back and break up following waves. He described the ascending seats in ancient theaters as designed to prevent this deterioration of sound and also recommended bronze vessels of appropriate sizes be placed in theaters to resonate with the fourth, fifth and so on, up to the double octave, in order to resonate with the more desirable, harmonious notes.

During the Islamic golden age, Abū Rayhān al-Bīrūnī (973-1048) is believed to postulated that the speed of sound was much slower than the speed of light.

The physical understanding of acoustical processes advanced rapidly during and after the Scientific Revolution. Mainly Galileo Galilei (1564–1642) but also Marin Mersenne (1588–1648), independently, discovered the complete laws of vibrating strings (completing what Pythagoras and Pythagoreans had started 2000 years earlier). Galileo wrote "Waves are produced by the vibrations of a sonorous body, which spread through the air, bringing to the tympanum of the ear a stimulus which the mind interprets as sound", a remarkable statement that points to the beginnings of physiological and psychological acoustics. Experimental measurements of the speed of sound in air were carried out successfully between 1630 and 1680 by a number of investigators, prominently Mersenne. Meanwhile, Newton (1642–1727) derived the relationship for wave velocity in solids, a cornerstone of physical acoustics (Principia, 1687).

Substantial progress in acoustics, resting on firmer mathematical and physical concepts, was made during the eighteenth century by Euler (1707–1783), Lagrange (1736–1813), and d'Alembert (1717–1783). During this era, continuum physics, or field theory, began to receive a definite mathematical structure. The wave equation emerged in a number of contexts, including the propagation of sound in air.

In the nineteenth century the major figures of mathematical acoustics were Helmholtz in Germany, who consolidated the field of physiological acoustics, and Lord Rayleigh in England, who combined the previous knowledge with his own copious contributions to the field in his monumental work "The Theory of Sound" (1877). Also in the 19th century, Wheatstone, Ohm, and Henry developed the analogy between electricity and acoustics.

The twentieth century saw a burgeoning of technological applications of the large body of scientific knowledge that was by then in place. The first such application was Sabine's groundbreaking work in architectural acoustics, and many others followed. Underwater acoustics was used for detecting submarines in the first World War. Sound recording and the telephone played important roles in a global transformation of society. Sound measurement and analysis reached new levels of accuracy and sophistication through the use of electronics and computing. The ultrasonic frequency range enabled wholly new kinds of application in medicine and industry. New kinds of transducers (generators and receivers of acoustic energy) were invented and put to use.

Acoustics is defined by ANSI/ASA S1.1-2013 as "(a) Science of sound, including its production, transmission, and effects, including biological and psychological effects. (b) Those qualities of a room that, together, determine its character with respect to auditory effects."

The study of acoustics revolves around the generation, propagation and reception of mechanical waves and vibrations.

The steps shown in the above diagram can be found in any acoustical event or process. There are many kinds of cause, both natural and volitional. There are many kinds of transduction process that convert energy from some other form into sonic energy, producing a sound wave. There is one fundamental equation that describes sound wave propagation, the acoustic wave equation, but the phenomena that emerge from it are varied and often complex. The wave carries energy throughout the propagating medium. Eventually this energy is transduced again into other forms, in ways that again may be natural and/or volitionally contrived. The final effect may be purely physical or it may reach far into the biological or volitional domains. The five basic steps are found equally well whether we are talking about an earthquake, a submarine using sonar to locate its foe, or a band playing in a rock concert.

The central stage in the acoustical process is wave propagation. This falls within the domain of physical acoustics. In fluids, sound propagates primarily as a pressure wave. In solids, mechanical waves can take many forms including longitudinal waves, transverse waves and surface waves.

Acoustics looks first at the pressure levels and frequencies in the sound wave and how the wave interacts with the environment. This interaction can be described as either a diffraction, interference or a reflection or a mix of the three. If several media are present, a refraction can also occur. Transduction processes are also of special importance to acoustics.

In fluids such as air and water, sound waves propagate as disturbances in the ambient pressure level. While this disturbance is usually small, it is still noticeable to the human ear. The smallest sound that a person can hear, known as the threshold of hearing, is nine orders of magnitude smaller than the ambient pressure. The loudness of these disturbances is related to the sound pressure level (SPL) which is measured on a logarithmic scale in decibels.

Physicists and acoustic engineers tend to discuss sound pressure levels in terms of frequencies, partly because this is how our ears interpret sound. What we experience as "higher pitched" or "lower pitched" sounds are pressure vibrations having a higher or lower number of cycles per second. In a common technique of acoustic measurement, acoustic signals are sampled in time, and then presented in more meaningful forms such as octave bands or time frequency plots. Both of these popular methods are used to analyze sound and better understand the acoustic phenomenon.

The entire spectrum can be divided into three sections: audio, ultrasonic, and infrasonic. The audio range falls between 20 Hz and 20,000 Hz. This range is important because its frequencies can be detected by the human ear. This range has a number of applications, including speech communication and music. The ultrasonic range refers to the very high frequencies: 20,000 Hz and higher. This range has shorter wavelengths which allow better resolution in imaging technologies. Medical applications such as ultrasonography and elastography rely on the ultrasonic frequency range. On the other end of the spectrum, the lowest frequencies are known as the infrasonic range. These frequencies can be used to study geological phenomena such as earthquakes.

Analytic instruments such as the spectrum analyzer facilitate visualization and measurement of acoustic signals and their properties. The spectrogram produced by such an instrument is a graphical display of the time varying pressure level and frequency profiles which give a specific acoustic signal its defining character.

A transducer is a device for converting one form of energy into another. In an electroacoustic context, this means converting sound energy into electrical energy (or vice versa). Electroacoustic transducers include loudspeakers, microphones, particle velocity sensors, hydrophones and sonar projectors. These devices convert a sound wave to or from an electric signal. The most widely used transduction principles are electromagnetism, electrostatics and piezoelectricity.

The transducers in most common loudspeakers (e.g. woofers and tweeters), are electromagnetic devices that generate waves using a suspended diaphragm driven by an electromagnetic voice coil, sending off pressure waves. Electret microphones and condenser microphones employ electrostatics—as the sound wave strikes the microphone's diaphragm, it moves and induces a voltage change. The ultrasonic systems used in medical ultrasonography employ piezoelectric transducers. These are made from special ceramics in which mechanical vibrations and electrical fields are interlinked through a property of the material itself.

An acoustician is an expert in the science of sound.

There are many types of acoustician, but they usually have a Bachelor's degree or higher qualification. Some possess a degree in acoustics, while others enter the discipline via studies in fields such as physics or engineering. Much work in acoustics requires a good grounding in Mathematics and science. Many acoustic scientists work in research and development. Some conduct basic research to advance our knowledge of the perception (e.g. hearing, psychoacoustics or neurophysiology) of speech, music and noise. Other acoustic scientists advance understanding of how sound is affected as it moves through environments, e.g. Underwater acoustics, Architectural acoustics or Structural acoustics. Other areas of work are listed under subdisciplines below. Acoustic scientists work in government, university and private industry laboratories. Many go on to work in Acoustical Engineering. Some positions, such as Faculty (academic staff) require a Doctor of Philosophy.

These subdisciplines are a slightly modified list from the PACS (Physics and Astronomy Classification Scheme) coding used by the Acoustical Society of America.

Archaeoacoustics, also known as the archaeology of sound, is one of the only ways to experience the past with senses other than our eyes. Archaeoacoustics is studied by testing the acoustic properties of prehistoric sites, including caves. Iegor Rezkinoff, a sound archaeologist, studies the acoustic properties of caves through natural sounds like humming and whistling. Archaeological theories of acoustics are focused around ritualistic purposes as well as a way of echolocation in the caves. In archaeology, acoustic sounds and rituals directly correlate as specific sounds were meant to bring ritual participants closer to a spiritual awakening. Parallels can also be drawn between cave wall paintings and the acoustic properties of the cave; they are both dynamic. Because archaeoacoustics is a fairly new archaeological subject, acoustic sound is still being tested in these prehistoric sites today.

Aeroacoustics is the study of noise generated by air movement, for instance via turbulence, and the movement of sound through the fluid air. This knowledge is applied in acoustical engineering to study how to quieten aircraft. Aeroacoustics is important for understanding how wind musical instruments work.

Acoustic signal processing is the electronic manipulation of acoustic signals. Applications include: active noise control; design for hearing aids or cochlear implants; echo cancellation; music information retrieval, and perceptual coding (e.g. MP3 or Opus).

Architectural acoustics (also known as building acoustics) involves the scientific understanding of how to achieve good sound within a building. It typically involves the study of speech intelligibility, speech privacy, music quality, and vibration reduction in the built environment.

Bioacoustics is the scientific study of the hearing and calls of animal calls, as well as how animals are affected by the acoustic and sounds of their habitat.

This subdiscipline is concerned with the recording, manipulation and reproduction of audio using electronics. This might include products such as mobile phones, large scale public address systems or virtual reality systems in research laboratories.

Environmental acoustics is concerned with noise and vibration caused by railways, road traffic, aircraft, industrial equipment and recreational activities. The main aim of these studies is to reduce levels of environmental noise and vibration. Research work now also has a focus on the positive use of sound in urban environments: soundscapes and tranquility.

Musical acoustics is the study of the physics of acoustic instruments; the audio signal processing used in electronic music; the computer analysis of music and composition, and the perception and cognitive neuroscience of music.

Many studies have been conducted to identify the relationship between acoustics and cognition, or more commonly known as psychoacoustics, in which what one hears is a combination of perception and biological aspects. The information intercepted by the passage of sound waves through the ear is understood and interpreted through the brain, emphasizing the connection between the mind and acoustics. Psychological changes have been seen as brain waves slow down or speed up as a result of varying auditory stimulus which can in turn affect the way one thinks, feels, or even behaves. This correlation can be viewed in normal, everyday situations in which listening to an upbeat or uptempo song can cause one's foot to start tapping or a slower song can leave one feeling calm and serene. In a deeper biological look at the phenomenon of psychoacoustics, it was discovered that the central nervous system is activated by basic acoustical characteristics of music. By observing how the central nervous system, which includes the brain and spine, is influenced by acoustics, the pathway in which acoustic affects the mind, and essentially the body, is evident.

Acousticians study the production, processing and perception of speech. Speech recognition and Speech synthesis are two important areas of speech processing using computers. The subject also overlaps with the disciplines of physics, physiology, psychology, and linguistics.

Ultrasonics deals with sounds at frequencies too high to be heard by humans. Specialisms include medical ultrasonics (including medical ultrasonography), sonochemistry, material characterisation and underwater acoustics (Sonar).

Underwater acoustics is the scientific study of natural and man-made sounds underwater. Applications include sonar to locate submarines, underwater communication by whales, climate change monitoring by measuring sea temperatures acoustically, sonic weapons, and marine bioacoustics.

This is the study of how mechanical systems vibrate and interact with their surroundings. Applications might include: ground vibrations from railways; vibration isolation to reduce vibration in operating theatres; studying how vibration can damage health (vibration white finger); vibration control to protect a building from earthquakes, or measuring how structure-borne sound moves through buildings.






</doc>
<doc id="1200" url="https://en.wikipedia.org/wiki?curid=1200" title="Atomic physics">
Atomic physics

Atomic physics is the field of physics that studies atoms as an isolated system of electrons and an atomic nucleus. It is primarily concerned with the arrangement of electrons around the nucleus and
the processes by which these arrangements change. This comprises ions, neutral atoms and, unless otherwise stated, it can be assumed that the term "atom" includes ions.

The term "atomic physics" can be associated with nuclear power and nuclear weapons, due to the synonymous use of "atomic" and "nuclear" in standard English. Physicists distinguish between atomic physics—which deals with the atom as a system consisting of a nucleus and electrons—and nuclear physics, which studies nuclear reactions and special properties of atomic nuclei.

As with many scientific fields, strict delineation can be highly contrived and atomic physics is often considered in the wider context of "atomic, molecular, and optical physics". Physics research groups are usually so classified.

Atomic physics primarily considers atoms in isolation. Atomic models will consist of a single nucleus that may be surrounded by one or more bound electrons. It is not concerned with the formation of molecules (although much of the physics is identical), nor does it examine atoms in a solid state as condensed matter. It is concerned with processes such as ionization and excitation by photons or collisions with atomic particles.

While modelling atoms in isolation may not seem realistic, if one considers atoms in a gas or plasma then the time-scales for atom-atom interactions are huge in comparison to the atomic processes that are generally considered. This means that the individual atoms can be treated as if each were in isolation, as the vast majority of the time they are. By this consideration atomic physics provides the underlying theory in plasma physics and atmospheric physics, even though both deal with very large numbers of atoms.

Electrons form notional shells around the nucleus. These are normally in a ground state but can be excited by the absorption of energy from light (photons), magnetic fields, or interaction with a colliding particle (typically ions or other electrons).

If the electron absorbs a quantity of energy less than the binding energy, it will be transferred to an excited state. After a certain time, the electron in an excited state will "jump" (undergo a transition) to a lower state. In a neutral atom, the system will emit a photon of the difference in energy, since energy is conserved.

If an inner electron has absorbed more than the binding energy (so that the atom ionizes), then a more outer electron may undergo a transition to fill the inner orbital. In this case, a visible photon or a characteristic x-ray is emitted, or a phenomenon known as the Auger effect may take place, where the released energy is transferred to another bound electron, causing it to go into the continuum. The Auger effect allows one to multiply ionize an atom with a single photon.

There are rather strict selection rules as to the electronic configurations that can be reached by excitation by light — however there are no such rules for excitation by collision processes.

One of the earliest steps towards atomic physics was the recognition that matter was composed
of "atoms". It forms a part of the texts written in 6th century BC to 2nd century BC such as those of Democritus or Vaisheshika Sutra written by Kanad. This theory was later developed in the modern sense of the basic unit of a chemical element by the British chemist and physicist John Dalton in the 18th century. At this stage, it wasn't clear what atoms were although they could be described and classified by their properties (in bulk). The invention of the periodic system of elements by Mendeleev was another great step forward.

The true beginning of atomic physics is marked by the discovery of spectral lines and attempts to describe the phenomenon, most notably by Joseph von Fraunhofer. The study of these lines led to the Bohr atom model and to the birth of quantum mechanics. In seeking to explain atomic spectra an entirely new mathematical model of matter was revealed. As far as atoms and their electron shells were concerned, not only did this yield a better overall description, i.e. the atomic orbital model, but it also provided a new theoretical basis for chemistry
(quantum chemistry) and spectroscopy.

Since the Second World War, both theoretical and experimental fields have advanced at a rapid pace. This can be attributed to progress in computing technology, which has allowed larger and more sophisticated models of atomic structure and associated collision processes. Similar technological advances in accelerators, detectors, magnetic field generation and lasers have greatly assisted experimental work.




</doc>
<doc id="1201" url="https://en.wikipedia.org/wiki?curid=1201" title="American Sign Language">
American Sign Language

American Sign Language (ASL) is a natural language that serves as the predominant sign language of Deaf communities in the United States and most of Anglophone Canada. Besides North America, dialects of ASL and ASL-based creoles are used in many countries around the world, including much of West Africa and parts of Southeast Asia. ASL is also widely learned as a second language, serving as a lingua franca. ASL is most closely related to French Sign Language (LSF). It has been proposed that ASL is a creole language of LSF, although ASL shows features atypical of creole languages, such as agglutinative morphology.

ASL originated in the early 19th century in the American School for the Deaf (ASD) in West Hartford, Connecticut, from a situation of language contact. Since then, ASL use has propagated widely by schools for the deaf and Deaf community organizations. Despite its wide use, no accurate count of ASL users has been taken. Reliable estimates for American ASL users range from 250,000 to 500,000 persons, including a number of children of deaf adults. ASL users face stigma due to beliefs in the superiority of oral language to sign language.

ASL signs have a number of phonemic components, such as movement of the face, the torso, and the hands. ASL is not a form of pantomime although iconicity plays a larger role in ASL than in spoken languages. English loan words are often borrowed through fingerspelling, although ASL grammar is unrelated to that of English. ASL has verbal agreement and aspectual marking and has a productive system of forming agglutinative classifiers. Many linguists believe ASL to be a subject–verb–object (SVO) language. However, there are several alternative proposals to account for ASL word order.

ASL emerged as a language in the American School for the Deaf (ASD), founded in 1817, which brought together Old French Sign Language, various village sign languages, and home sign systems; ASL was created in that situation by language contact. ASL was influenced by its forerunners but distinct from all of them.

The influence of French Sign Language (LSF) on ASL is readily apparent; for example, it has been found that about 58% of signs in modern ASL are cognate to Old French Sign Language signs. However, that is far less than the standard 80% measure used to determine whether related languages are actually dialects. That suggests that nascent ASL was highly affected by the other signing systems brought by the ASD students although the school's original director, Laurent Clerc, taught in LSF. In fact, Clerc reported that he often learned the students' signs rather than conveying LSF:
It has been proposed that ASL is a creole in which LSF is the superstrate language and the native village sign languages are substrate languages. However, more recent research has shown that modern ASL does not share many of the structural features that characterize creole languages. ASL may have begun as a creole and then undergone structural change over time, but it is also possible that it was never a creole-type language. There are modality-specific reasons that sign languages tend towards agglutination, such as the ability to simultaneously convey information via the face, head, torso, and other body parts. That might override creole characteristics such as the tendency towards isolating morphology. Additionally, Clerc and Thomas Hopkins Gallaudet may have used an artificially constructed form of manually coded language in instruction rather than true LSF.

Although the United States, the United Kingdom, and Australia share English as a common oral and written language, ASL is not mutually intelligible with either British Sign Language (BSL) or Auslan. All three languages show degrees of borrowing from English, but that alone is not sufficient for cross-language comprehension. It has been found that a relatively high percentage (37–44%) of ASL signs have similar translations in Auslan, which for oral languages would suggest that they belong to the same language family. However, that does not seem justified historically for ASL and Auslan, and it is likely that the resemblance is caused by the higher degree of iconicity in sign languages in general as well as contact with English.

American Sign Language is growing in popularity in many states. Many people in high school and colleges desire to take it as a foreign language, but until recently, it was not a creditable foreign language elective. The issue was that many did not consider it a foreign language. ASL users, however, have a very distinct culture, and they interact very differently when they talk. Their facial expressions and hand movements reflect what they are communicating. They also have their own sentence structure, which sets the language apart.

American Sign Language is now being accepted by many colleges as a foreign language credit; many states are making it mandatory to accept it.

Prior to the birth of ASL, sign language had been used by various communities in the United States. In the United States, as elsewhere in the world, hearing families with deaf children have historically employed ad-hoc home sign, which often reaches much higher levels of sophistication than gestures used by hearing people in spoken conversation. As early as 1541 at first contact by Francisco Vásquez de Coronado, there were reports that the Plains Indians had developed a sign language to communicate between tribes of different languages.

In the 19th century, a "triangle" of village sign languages developed in New England: one in Martha's Vineyard, Massachusetts; one in Henniker, New Hampshire, and one in Sandy River Valley, Maine. Martha's Vineyard Sign Language (MVSL), which was particularly important for the history of ASL, was used mainly in Chilmark, Massachusetts. Due to intermarriage in the original community of English settlers of the 1690s, and the recessive nature of genetic deafness, Chilmark had a high 4% rate of genetic deafness. MVSL was used even by hearing residents whenever a deaf person was present, and also in some situations where spoken language would be ineffective or inappropriate, such as during church sermons or between boats at sea.

ASL is thought to have originated in the American School for the Deaf (ASD), founded in Hartford, Connecticut in 1817. Originally known as "The American Asylum, At Hartford, For The Education And Instruction Of The Deaf And Dumb", the school was founded by the Yale graduate and divinity student Thomas Hopkins Gallaudet. Gallaudet, inspired by his success in demonstrating the learning abilities of a young deaf girl Alice Cogswell, traveled to Europe in order to learn deaf pedagogy from European institutions. Ultimately, Gallaudet chose to adopt the methods of the French Institut National de Jeunes Sourds de Paris, and convinced Laurent Clerc, an assistant to the school's founder Charles-Michel de l'Épée, to accompany him back to the United States. Upon his return, Gallaudet founded the ASD on April 15, 1817.

The largest group of students during the first seven decades of the school were from Martha's Vineyard, and they brought MVSL with them. There were also 44 students from around Henniker, New Hampshire, and 27 from the Sandy River valley in Maine, each of which had their own village sign language. Other students brought knowledge of their own home signs. Laurent Clerc, the first teacher at ASD, taught using French Sign Language (LSF), which itself had developed in the Parisian school for the deaf established in 1755. From that situation of language contact, a new language emerged, now known as ASL.
More schools for the deaf were founded after ASD, and knowledge of ASL spread to those schools. In addition, the rise of Deaf community organizations bolstered the continued use of ASL. Societies such as the National Association of the Deaf and the National Fraternal Society of the Deaf held national conventions that attracted signers from across the country. All of that contributed to ASL's wide use over a large geographical area, atypical of a sign language.

Up to the 1950s, the predominant method in deaf education was oralism, acquiring oral language comprehension and production. Linguists did not consider sign language to be true "language" but as something inferior. Recognition of the legitimacy of ASL was achieved by William Stokoe, a linguist who arrived at Gallaudet University in 1955 when that was still the dominant assumption. Aided by the Civil Rights Movement of the 1960s, Stokoe argued for manualism, the use of sign language in deaf education. Stokoe noted that sign language shares the important features that oral languages have as a means of communication, and even devised a transcription system for ASL. In doing so, Stokoe revolutionized both deaf education and linguistics. In the 1960s, ASL was sometimes referred to as "Ameslan", but that term is now considered obsolete.

Counting the number of ASL signers is difficult because ASL users have never been counted by the American census. The ultimate source for current estimates of the number of ASL users in the United States is a report for the National Census of the Deaf Population (NCDP) by Schein and Delk (1974). Based on a 1972 survey of the NCDP, Schein and Delk provided estimates consistent with a signing population between 250,000 and 500,000. The survey did not distinguish between ASL and other forms of signing; in fact, the name "ASL" was not yet in widespread use.

Incorrect figures are sometimes cited for the population of ASL users in the United States based on misunderstandings of known statistics. Demographics of the deaf population have been confused with those of ASL use since adults who become deaf late in life rarely use ASL in the home. That accounts for currently-cited estimations that are greater than 500,000; such mistaken estimations can reach as high as 15,000,000. A 100,000-person lower bound has been cited for ASL users; the source of that figure is unclear, but it may be an estimate of prelingual deafness, which is correlated with but not equivalent to signing.

ASL is sometimes incorrectly cited as the third- or fourth-most-spoken language in the United States. Those figures misquote Schein and Delk (1974), who actually concluded that ASL speakers constituted the third-largest population "requiring an interpreter in court." Although that would make ASL the third-most used language among monolinguals other than English, it does not imply that it is the fourth-most-spoken language in the United States since speakers of other languages may also speak English.

ASL is used throughout Anglo-America. That contrasts with Europe, where a variety of sign languages are used within the same continent. The unique situation of ASL seems to have been caused by the proliferation of ASL through schools influenced by the American School for the Deaf, wherein ASL originated, and the rise of community organizations for the Deaf.

Throughout West Africa, ASL-based sign languages are signed by educated Deaf adults. Such languages, imported by boarding schools, are often considered by associations to be the official sign languages of their countries and are named accordingly, such as Nigerian Sign Language, Ghanaian Sign Language. Such signing systems are found in Benin, Burkina Faso, Ivory Coast, Ghana, Liberia, Mauritania, Mali, Nigeria, and Togo. Due to lack of data, it is still an open question how similar those sign languages are to the variety of ASL used in America.

In addition to the aforementioned West African countries, ASL is reported to be used as a first language in Barbados, Bolivia, Cambodia, the Central African Republic, Chad, China (Hong Kong), the Democratic Republic of the Congo, Gabon, Jamaica, Kenya, Madagascar, the Philippines, Singapore, and Zimbabwe. ASL is also used as a lingua franca throughout the deaf world, widely learned as a second language.

Sign production can often vary according to location. Signers from the South tend to sign with more flow and ease. Native signers from New York have been reported as signing comparatively more quickly and sharply. Sign production of native Californian signers has also been reported as being fast as well. Research on that phenomenon often concludes that the fast-paced production for signers from the coasts could be due to the fast-paced nature of living in large metropolitan areas. That conclusion also supports how the ease with which Southern sign could be caused by the easygoing environment of the South in comparison to that of the coasts.

Sign production can also vary depending on age and native language. For example, sign production of letters may vary in older signers. Slight differences in finger spelling production can be a signal of age. Additionally, signers who learned American Sign Language as a second language vary in production. For Deaf signers who learned a different sign language before learning American Sign Language, qualities of their native language may show in their ASL production. Some examples of that varied production include finger spelling towards the body, instead of away from it, and signing certain movement from bottom to top, instead of top to bottom. Hearing people who learn American Sign Language also have noticeable differences in signing production. The most notable production difference of hearing people learning American Sign Language is their rhythm and arm posture.

Most popularly, there are variants of the signs for English words such as "birthday", "pizza", "Halloween", "early", and "soon", just a sample of the most commonly recognized signs with variant based on regional change. The sign for "school" is commonly varied between black and white signers. The variation between sign produced by black and white signers is sometimes referred to as Black American Sign Language.

The prevalence of residential Deaf schools can account for much of the regional variance of signs and sign productions across the United States. Deaf schools often serve students of the state in which the school resides. That limited access to signers from other regions, combined with the residential quality of Deaf Schools promoted specific use of certain sign variants. Native signers did not have much access to signers from other regions during the beginning years of their education. It is hypothesized that because of that seclusion, certain variants of a sign prevailed over others due to the choice of variant used by the student of the school/signers in the community.

However, American Sign Language does not appear to be vastly varied in comparison to other signed languages. That is because when Deaf education was beginning in the United States, many educators flocked to the American School for the Deaf in Hartford, Connecticut, whose central location for the first generation of educators in Deaf education to learn American Sign Language allows ASL to be more standardized than it is variant.

Varieties of ASL are found throughout the world. There is little difficulty in comprehension among the varieties of the United States and Canada.

Mutual intelligibility among those ASL varieties is high, and the variation is primarily lexical. For example, there are three different words for English "about" in Canadian ASL; the standard way, and two regional variations (Atlantic and Ontario). Variation may also be phonological, meaning that the same sign may be signed in a different way depending on the region. For example, an extremely common type of variation is between the handshapes /1/, /L/, and /5/ in signs with one handshape.

There is also a distinct variety of ASL used by the Black Deaf community. Black ASL evolved as a result of racially segregated schools in some states, which included the residential schools for the deaf. Black ASL differs from standard ASL in vocabulary, phonology, and some grammatical structure. While African American English (AAE) is generally viewed as more innovating than standard English, Black ASL is more conservative than standard ASL, preserving older forms of many signs. Black sign language speakers use more two-handed signs than in mainstream ASL, are less likely to show assimilatory lowering of signs produced on the forehead (e.g. KNOW) and use a wider signing space. Modern Black ASL borrows a number of idioms from AAE; for instance, the AAE idiom "I feel you" is calqued into Black ASL.

ASL is used internationally as a lingua franca, and a number of closely related sign languages derived from ASL are used in many different countries. Even so, there have been varying degrees of divergence from standard ASL in those imported ASL varieties. Bolivian Sign Language is reported to be a dialect of ASL, no more divergent than other acknowledged dialects. On the other hand, it is also known that some imported ASL varieties have diverged to the extent of being separate languages. For example, Malaysian Sign Language, which has ASL origins, is no longer mutually comprehensible with ASL and must be considered its own language. For some imported ASL varieties, such as those used in West Africa, it is still an open question how similar they are to American ASL.

When communicating with hearing English speakers, ASL-speakers often use what is commonly called Pidgin Signed English (PSE) or 'contact signing', a blend of English structure with ASL. Various types of PSE exist, ranging from highly English-influenced PSE (practically relexified English) to PSE which is quite close to ASL lexically and grammatically, but may alter some subtle features of ASL grammar. Fingerspelling may be used more often in PSE than it is normally used in ASL. There have been some constructed sign languages, known as Manually Coded English (MCE), which match English grammar exactly and simply replace spoken words with signs; those systems are not considered to be varieties of ASL.

Tactile ASL (TASL) is a variety of ASL used throughout the United States by and with the deaf-blind. It is particularly common among those with Usher's syndrome. It results in deafness from birth followed by loss of vision later in life; consequently, those with Usher's syndrome often grow up in the Deaf community using ASL, and later transition to TASL. TASL differs from ASL in that signs are produced by touching the palms, and there are some grammatical differences from standard ASL in order to compensate for the lack of non-manual signing.

In 2013 the White House published a response to a petition that gained over 37,000 signatures to "officially recognize American Sign Language as a community language and a language of instruction in schools". The response is titled "there shouldn't be any stigma about American Sign Language" and addressed that ASL is a vital language for the Deaf and hard of hearing. Stigmas associated with sign languages and the use of sign for educating children often lead to the absence of sign during periods in children's lives when they can access languages most effectively. Scholars such as Beth S. Benedict advocate not only for bilingualism (using ASL and English training) but also for early childhood intervention for children who are deaf. York University psychologist Ellen Bialystok has also campaigned for bilingualism, arguing that those who are bilingual acquire cognitive skills that may help to prevent dementia later in life.

Most children born to deaf parents are hearing. Known as CODAs ("Children Of Deaf Adults"), they are often more culturally Deaf than deaf children, most of whom are born to hearing parents. Unlike many deaf children, CODAs acquire ASL as well as Deaf cultural values and behaviors from birth. Such bilingual hearing children may be mistakenly labeled as being "slow learners" or as having "language difficulties" because of preferential attitudes towards spoken language.

Although there is no well-established writing system for ASL, written sign language dates back almost two centuries. The first systematic writing system for a sign language seems to be that of Roch-Ambroise Auguste Bébian, developed in 1825. However, written sign language remained marginal among the public. In the 1960s, linguist William Stokoe created Stokoe notation specifically for ASL. It is alphabetic, with a letter or diacritic for every phonemic (distinctive) hand shape, orientation, motion, and position, though it lacks any representation of facial expression, and is better suited for individual words than for extended passages of text. Stokoe used that system for his 1965 "A Dictionary of American Sign Language on Linguistic Principles".

SignWriting, proposed in 1974 by Valerie Sutton, is the first writing system to gain use among the public and the first writing system for sign languages to be included in the Unicode Standard. SignWriting consists of more than 5000 distinct iconic graphs/glyphs. Currently, it is in use in many schools for the Deaf, particularly in Brazil, and has been used in International Sign forums with speakers and researchers in more than 40 countries, including Brazil, Ethiopia, France, Germany, Italy, Portugal, Saudi Arabia, Slovenia, Tunisia, and the United States. Sutton SignWriting has both a printed and an electronically produced form so that persons can use the system anywhere that oral languages are written (personal letters, newspapers, and media, academic research). The systematic examination of the International Sign Writing Alphabet (ISWA) as an equivalent usage structure to the International Phonetic Alphabet for spoken languages has been proposed. According to some researchers, SignWriting is not a phonemic orthography and does not have a one-to-one map from phonological forms to written forms. That assertion has been disputed, and the process for each country to look at the ISWA and create a phonemic/morphemic assignment of features of each sign language was proposed by researchers Msc. Roberto Cesar Reis da Costa and Madson Barreto in a thesis forum on June 23, 2014. The SignWriting community has an open project on Wikimedia Labs to support the various Wikimedia projects on Wikimedia Incubator and elsewhere involving SignWriting. The ASL Wikipedia request was marked as eligible in 2008 and the test ASL Wikipedia has 50 articles written in ASL using SignWriting.

The most widely used transcription system among academics is HamNoSys, developed at the University of Hamburg. Based on Stokoe Notation, HamNoSys was expanded to about 200 graphs in order to allow transcription of any sign language. Phonological features are usually indicated with single symbols, though the group of features that make up a handshape is indicated collectively with a symbol.

Several additional candidates for written ASL have appeared over the years, including SignFont, ASL-phabet, and Si5s.

For English-speaking audiences, ASL is often glossed using English words. Such glosses are typically all-capitalized and are arranged in ASL order. For example, the ASL sentence DOG NOW CHASE>IX=3 CAT, meaning "the dog is chasing the cat", uses NOW to mark ASL progressive aspect and shows ASL verbal inflection for the third person (written with >IX=3). However, glossing is not used to write the language for speakers of ASL.

Each sign in ASL is composed of a number of distinctive components, generally referred to as parameters. A sign may use one hand or both. All signs can be described using the five parameters involved in signed languages, which are handshape, movement, palm orientation, location and non-manual markers. Just as phonemes of sound distinguish meaning in spoken languages, those parameters are the phonemes that distinguish meaning in signed languages like ASL. Changing any one of them may change the meaning of a sign, as illustrated by the ASL signs THINK and DISAPPOINTED:
There are also meaningful non-manual signals in ASL, which may include movement of the eyebrows, the cheeks, the nose, the head, the torso, and the eyes.

William Stokoe proposed that such components are analogous to the phonemes of spoken languages. There has also been a proposal that they are analogous to classes like place and manner of articulation. As in spoken languages, those phonological units can be split into distinctive features. For instance, the handshapes /2/ and /3/ are distinguished by the presence or absence of the feature [± closed thumb], as illustrated to the right. ASL has processes of allophony and phonotactic restrictions. There is ongoing research into whether ASL has an analog of syllables in spoken language.

ASL has a rich system of verbal inflection, which involves both grammatical aspect: how the action of verbs flows in time—and agreement marking. Aspect can be marked by changing the manner of movement of the verb; for example, continuous aspect is marked by incorporating rhythmic, circular movement, while punctual aspect is achieved by modifying the sign so that it has a stationary hand position. Verbs may agree with both the subject and the object, and are marked for number and reciprocity. Reciprocity is indicated by using two one-handed signs; for example, the sign SHOOT, made with an L-shaped handshape with inward movement of the thumb, inflects to SHOOT, articulated by having two L-shaped hands "shooting" at each other.

ASL has a productive system of classifiers, which are used to classify objects and their movement in space. For example, a rabbit running downhill would use a classifier consisting of a bent V classifier handshape with a downhill-directed path; if the rabbit is hopping, the path is executed with a bouncy manner. In general, classifiers are composed of a "classifier handshape" bound to a "movement root". The classifier handshape represents the object as a whole, incorporating such attributes as surface, depth, and shape, and is usually very iconic. The movement root consists of a path, a direction and a manner.

ASL possesses a set of 26 signs known as the American manual alphabet, which can be used to spell out words from the English language. Such signs make use of the 19 handshapes of ASL. For example, the signs for 'p' and 'k' use the same handshape but different orientations. A common misconception is that ASL consists only of fingerspelling; although such a method (Rochester Method) has been used, it is not ASL.

Fingerspelling is a form of borrowing, a linguistic process wherein words from one language are incorporated into another. In ASL, fingerspelling is used for proper nouns and for technical terms with no native ASL equivalent. There are also some other loan words which are fingerspelled, either very short English words or abbreviations of longer English words, e.g. "O-N" from English 'on', and "A-P-T" from English 'apartment'. Fingerspelling may also be used to emphasize a word that would normally be signed otherwise.

ASL is a subject–verb–object (SVO) language, but various phenomena affect that basic word order. Basic SVO sentences are signed without any pauses:

However, other word orders may also occur since ASL allows the topic of a sentence to be moved to sentence-initial position, a phenomenon known as topicalization. In object-subject-verb (OSV) sentences, the object is topicalized, marked by a forward head-tilt and a pause:
Besides, word orders can be obtained through the phenomenon of subject copy in which the subject is repeated at the end of the sentence, accompanied by head nodding for clarification or emphasis:

ASL also allows null subject sentences whose subject is implied, rather than stated explicitly. Subjects can be copied even in a null subject sentence, and the subject is then omitted from its original position, yielding a verb–object–subject (VOS) construction:

Topicalization, accompanied with a null subject and a subject copy, can produce yet another word order, object–verb–subject (OVS).

Those properties of ASL allow it a variety of word orders, leading many to question which is the true, underlying, "basic" order. There are several other proposals that attempt to account for the flexibility of word order in ASL. One proposal is that languages like ASL are best described with a topic–comment structure whose words are ordered by their importance in the sentence, rather than by their syntactic properties. Another hypothesis is that ASL exhibits free word order, in which syntax is not encoded in word order but can be encoded by other means such as head nods, eyebrow movement, and body position.

Common misconceptions are that signs are iconically self-explanatory, that they are a transparent imitation of what they mean, or even that they are pantomime. In fact, many signs bear no resemblance to their referent because they were originally arbitrary symbols, or their iconicity has been obscured over time. Even so, in ASL iconicity plays a significant role; a high percentage of signs resemble their referents in some way. That may because the medium of sign, three-dimensional space, naturally allows more iconicity than oral language.

In the era of the influential linguist Ferdinand de Saussure, it was assumed that the mapping between form and meaning in language must be completely arbitrary. Although onomatopoeia is a clear exception, since words like 'choo-choo' bear clear resemblance to the sounds that they mimic, the Saussurean approach was to treat them as marginal exceptions. ASL, with its significant inventory of iconic signs, directly challenges that theory.

Research on acquisition of pronouns in ASL has shown that children do not always take advantage of the iconic properties of signs when they interpret their meaning. It has been found that when children acquire the pronoun "you", the iconicity of the point (at the child) is often confused, being treated more like a name. That is a similar finding to research in oral languages on pronoun acquisition. It has also been found that iconicity of signs does not affect immediate memory and recall; less iconic signs are remembered just as well as highly-iconic signs.




</doc>
<doc id="1202" url="https://en.wikipedia.org/wiki?curid=1202" title="Applet">
Applet

In computing, an applet is any small application that performs one specific task that runs within the scope of a dedicated widget engine or a larger program, often as a plug-in. The term is frequently used to refer to a Java applet, a program written in the Java programming language that is designed to be placed on a web page. Applets are typical examples of transient and auxiliary applications that don't monopolize the user's attention. Applets are not full-featured application programs, and are intended to be easily accessible.

The word "applet" was first used in 1990 in PC Magazine. However, the concept of an applet, or more broadly a small interpreted program downloaded and executed by the user, dates at least to RFC 5 (1969) by Jeff Rulifson, which described the Decode-Encode Language (DEL), which was designed to allow remote use of the oN-Line System (NLS) over ARPANET, by downloading small programs to enhance the interaction. This has been specifically credited as a forerunner of Java's downloadable programs in RFC 2555.

In some cases, an applet does not run independently. These applets must run either in a container provided by a host program, through a plugin, or a variety of other applications including mobile devices that support the applet programming model.

Applets were used to provide interactive features to web applications that historically could not be provided by HTML alone. They could capture mouse input and also had controls like buttons or check boxes. In response to the user action an applet could change the provided graphic content. This made applets well suitable for demonstration, visualization, and teaching. There were online applet collections for studying various subjects, from physics to heart physiology. Applets were also used to create online game collections that allowed players to compete against live opponents in real-time.

An applet could also be a text area only, providing, for instance, a cross platform command-line interface to some remote system. If needed, an applet could leave the dedicated area and run as a separate window. However, applets had very little control over web page content outside the applet dedicated area, so they were less useful for improving the site appearance in general (while applets like news tickers or WYSIWYG editors are also known). Applets could also play media in formats that are not natively supported by the browser.

HTML pages could embed parameters that were passed to the applet. Hence the same applet could appear differently depending on the parameters that were passed.

Examples of Web-based Applets include:


A larger application distinguishes its applets through several features:


A Java applet is a Java program that is launched from HTML and run in a web browser. It can provide web applications with interactive features that cannot be provided by HTML. Since Java's bytecode is platform-independent, Java applets can be executed by browsers running under many platforms, including Windows, Unix, macOS, and Linux. When a Java technology-enabled web browser processes a page that contains an applet, the applet's code is transferred to the client's system and executed by the browser's Java Virtual Machine (JVM). An HTML page references an applet either via the deprecated <applet> tag or via its replacement, the <object> tag.

Recent developments in the coding of applications including mobile and embedded systems have led to the awareness of the security of applets.

Applets in an open platform environment should provide secure interactions between different applications. A compositional approach can be used to provide security for open platform applets. Advanced compositional verification methods have been developed for secure applet interactions.

A Java applet contains different security models: unsigned Java applet security, signed Java applet security, and self signed Java applet security.

In an applet-enabled web browser, many methods can be used to provide applet security for malicious applets. A malicious applet can infect a computer system in many ways, including denial of service, invasion of privacy, and annoyance. A typical solution for malicious applets is to make the web browser to monitor applets' activities. This will result in a web browser that will enable the manual or automatic stopping of malicious applets.



</doc>
<doc id="1203" url="https://en.wikipedia.org/wiki?curid=1203" title="Alternate history">
Alternate history

Alternate history or alternative history (in Commonwealth English), sometimes abbreviated as AH, is a genre of speculative fiction consisting of stories in which one or more historical events occur differently. These stories usually contain "what if" scenarios at crucial points in history and present outcomes other than those in the historical record. The stories are conjectural but are sometimes based on fact. Alternate history has been seen as a subgenre of literary fiction, science fiction, or historical fiction; alternate history works may use tropes from any or all of these genres. Another term occasionally used for the genre is "allohistory" (literally "other history").

Since the 1950s, this type of fiction has, to a large extent, merged with science fiction tropes involving time travel between alternate histories, psychic awareness of the existence of one universe by the people in another, or time travel that results in history splitting into two or more timelines. Cross-time, time-splitting, and alternate history themes have become so closely interwoven that it is impossible to discuss them fully apart from one another.

In Spanish, French, German, Portuguese, Italian, Catalan and Galician, the genre of alternate history is called "uchronie / ucronia / ucronía / Uchronie", which has given rise to the term "Uchronia" in English. This neologism is based on the prefix (which in Ancient Greek means "not/not any/no") and the Greek (), meaning "time". A "uchronia" means literally "(in) no time". This term apparently also inspired the name of the alternate history book list, "".

The "Collins English Dictionary" defines alternative history as "a genre of fiction in which the author speculates on how the course of history might have been altered if a particular historical event had had a different outcome." According to Steven H Silver, an American science fiction editor, alternate history requires three things: a point of divergence from the history of our world prior to the time at which the author is writing, a change that would alter history as it is known, and an examination of the ramifications of that change.

Several genres of fiction have been misidentified as alternate history. Science fiction set in what was the future but is now the past, like Arthur C. Clarke's "" (1968) or George Orwell's "Nineteen Eighty-Four" (1949), is not alternate history because the author did not make the choice to change the past at the time of writing. Secret history, which can take the form of fiction or nonfiction, documents events that may or may not have happened historically but did not have an effect on the overall outcome of history, and so is not to be confused with alternate history. 

Alternate history is related to, but distinct from, counterfactual history. This term is used by some professional historians to describe the practice of using thoroughly researched and carefully reasoned speculations on "what might have happened if..." as a tool of academic historical research, as opposed to a literary device.

The earliest example of alternate (or counterfactual) history is found in Livy's "Ab Urbe Condita Libri" (book IX, sections 17–19). Livy contemplated an alternative 4th century BC in which Alexander the Great had survived to attack Europe as he had planned; asking, "What would have been the results for Rome if she had been engaged in a war with Alexander?" Livy concluded that the Romans would likely have defeated Alexander.

Another example of counterfactual history was posited by cardinal and Doctor of the Church Peter Damian in the 11th century. In his famous work "De Divina Omnipotentia", a long letter in which he discusses God's omnipotence, he treats questions related to the limits of divine power, including the question of whether God can change the past, for example, bringing about that Rome was never founded:I see I must respond finally to what many people, on the basis of your holiness’s [own] judgment, raise as an objection on the topic of this dispute. For they say: If, as you assert, God is omnipotent in all things, can he manage this, that things that have been made were not made? He can certainly destroy all things that have been made, so that they do not exist now. But it cannot be seen how he can bring it about that things that have been made were not made. To be sure, it can come about that from now on and hereafter Rome does not exist; for it can be destroyed. But no opinion can grasp how it can come about that it was not founded long ago...One early work of fiction detailing an alternate history is Joanot Martorell's 1490 epic romance "Tirant lo Blanch", which was written when the loss of Constantinople to the Turks was still a recent and traumatic memory for Christian Europe. It tells the story of the knight Tirant the White from Brittany who travels to the embattled remnants of the Byzantine Empire. He becomes a Megaduke and commander of its armies and manages to fight off the invading Ottoman armies of . He saves the city from Islamic conquest, and even chases the Turks deeper into lands they had previously conquered.

One of the earliest works of alternate history published in large quantities for the reception of a large audience may be Louis Geoffroy's "Histoire de la Monarchie universelle: Napoléon et la conquête du monde (1812–1832)" (History of the Universal Monarchy: Napoleon and the Conquest of the World) (1836), which imagines Napoleon's First French Empire emerging victorious in the French invasion of Russia in 1811 and in an invasion of England in 1814, later unifying the world under Bonaparte's rule.

In the English language, the first known complete alternate history is Nathaniel Hawthorne's short story "P.'s Correspondence", published in 1845. It recounts the tale of a man who is considered "a madman" due to his perceptions of a different 1845, a reality in which long-dead famous people, such as the poets Robert Burns, Lord Byron, Percy Bysshe Shelley and John Keats, the actor Edmund Kean, the British politician George Canning, and even Napoleon Bonaparte, are still alive.

The first novel-length alternate history in English would seem to be Castello Holford's "Aristopia" (1895). While not as nationalistic as Louis Geoffroy's "Napoléon et la conquête du monde, 1812–1823", "Aristopia" is another attempt to portray a Utopian society. In "Aristopia", the earliest settlers in Virginia discover a reef made of solid gold and are able to build a Utopian society in North America.

In 1905 H. G. Wells published "A Modern Utopia". As explicitly noted in the book itself, Wells's main aim in writing it was to set out his social and political ideas, the plot serving mainly as a vehicle to expound them. Still, this book introduced the plot device of a person being transported from a point in our familiar world to the precise geographical equivalent point in an alternate world where history had gone differently. The protagonist undergoes various adventures in that other world, and is then finally transported back to our world - again to the precise geographical equivalent point. Since then, this had become - and remains - a staple of the alternate history genre. 

A number of alternate history stories and novels appeared in the late 19th and early 20th centuries (see, for example, Charles Petrie's "If: A Jacobite Fantasy" [1926]). In 1931, British historian Sir John Squire collected a series of essays from some of the leading historians of the period for his anthology "If It Had Happened Otherwise". In this work, scholars from major universities (as well as important non-academic authors) turned their attention to such questions as "If the Moors in Spain Had Won" and "If Louis XVI Had Had an Atom of Firmness". The essays range from serious scholarly efforts to Hendrik Willem van Loon's fanciful and satiric portrayal of an independent 20th century Dutch city state on the island of Manhattan. Among the authors included were Hilaire Belloc, André Maurois, and Winston Churchill.
One of the entries in Squire's volume was Churchill's "If Lee Had Not the Battle of Gettysburg", written from the viewpoint of a historian in a world where the Confederate States of America had won the American Civil War. The entry considers what would have happened if the North had been victorious (in other words, a character from an alternate world imagines a world more like the real one we live in, although not identical in every detail). Speculative work that narrates from the point of view of an alternate history is variously known as "recursive alternate history", a "double-blind what-if", or an "alternate-alternate history". Churchill's essay was one of the influences behind Ward Moore's alternate history novel "Bring the Jubilee", in which General Robert E. Lee won the Battle of Gettysburg, paving the way for the eventual victory of the Confederacy in the American Civil War (named the "War of Southron Independence" in this timeline). The protagonist, autodidact Hodgins Backmaker, travels back to the aforementioned battle and inadvertently changes history, resulting in the emergence of our own timeline and the consequent victory of the Union instead.

American humorist author James Thurber parodied alternate history stories about the American Civil War in his 1930 story "If Grant Had Been Drinking at Appomattox", which he accompanied with this very brief introduction: ""Scribner's" magazine is publishing a series of three articles: 'If Booth Had Missed Lincoln', 'If Lee Had Won the Battle of Gettysburg', and 'If Napoleon Had Escaped to America'. This is the fourth."

Another example of alternate history from this period (and arguably the first to explicitly posit cross-time travel from one universe to another as anything more than a visionary experience) is H.G. Wells' "Men Like Gods" (1923), in which several Englishmen are transferred via an accidental encounter with a cross-time machine into an alternate universe featuring a seemingly pacifistic and utopian Britain. When the Englishmen, led by a satiric figure based on Winston Churchill, try to seize power, the utopians simply point a ray gun at them and send them on to someone else's universe. Wells describes a multiverse of alternative worlds, complete with the paratime travel machines that would later become popular with US pulp writers. However, since his hero experiences only a single alternate world, this story is not very different from conventional alternate history.

In the 1930s, alternate history moved into a new arena. The December 1933 issue of "Astounding" published Nat Schachner's "Ancestral Voices", which was quickly followed by Murray Leinster's "Sidewise in Time". While earlier alternate histories examined reasonably straightforward divergences, Leinster attempted something completely different. In his "World gone mad", pieces of Earth traded places with their analogs from different timelines. The story follows Professor Minott and his students from a fictitious Robinson College as they wander through analogues of worlds that followed a different history.

A somewhat similar approach was taken by Robert A. Heinlein in his 1941 novelette "Elsewhen", in which a professor trains his mind to move his body across timelines. He then hypnotizes his students so they can explore more of them. Eventually each settles into the reality most suitable for him or her. Some of the worlds they visit are mundane, some very odd; others follow science fiction or fantasy conventions.

World War II produced alternate history for propaganda: both British and American authors wrote works depicting Nazi invasions of their respective countries as cautionary tales.

The period around World War II also saw the publication of the time travel novel "Lest Darkness Fall" by L. Sprague de Camp, in which an American academic travels to Italy at the time of the Byzantine invasion of the Ostrogoths. De Camp's time traveler, Martin Padway, is depicted as making permanent historical changes and implicitly forming a new time branch, thereby making the work an alternate history.

Time travel as the cause of a point of divergence (POD), which can denote either the bifurcation of a historical timeline or a simple replacement of the future that existed before the time traveling event, has continued to be a popular theme. In Ward Moore's "Bring the Jubilee", the protagonist lives in an alternate history in which the Confederacy has won the American Civil War; he travels backward through time, and brings about a Union victory in the Battle of Gettysburg.

When a story's assumptions about the nature of time travel lead to the complete replacement of the visited time's future rather than just the creation of an additional time line, the device of a "time patrol" is often used where guardians move through time to preserve the "correct" history.

A more recent example is "Making History" by Stephen Fry, in which a time machine is used to alter history so that Adolf Hitler was never born. This ironically results in a more competent leader of the Third Reich, resulting in the country's ascendancy and longevity in this altered timeline.

H.G. Wells' "cross-time" or "many universes" variant (see above) was fully developed by Murray Leinster in his 1934 short story "Sidewise in Time", in which sections of the Earth's surface begin changing places with their counterparts in alternate timelines.

Fredric Brown employed this subgenre to satirize the science fiction pulps and their adolescent readers—and fears of foreign invasion—in the classic "What Mad Universe" (1949). In Clifford D. Simak's "Ring Around the Sun" (1953), the hero ends up in an alternate earth of thick forests in which humanity never developed but a band of mutants is establishing a colony; the story line appears to frame the author's anxieties regarding McCarthyism and the Cold War.

In the late 1940s and the 1950s, however, writers such as H. Beam Piper, Sam Merwin, Jr. and Andre Norton wrote stories set in a multiverse in which all alternate histories are co-existent and travel between them occurs via a technology involving portals and/or paratime transporter machinery. These authors established the convention of a secret paratime trading empire that exploits and/or protects worlds lacking the paratime technology via a network of secret agents (Piper called them the "paratime police").

This concept provided a convenient framing for packing a smörgåsbord of historical alternatives (and even of timeline "branches") into a single novel, either via the hero chasing or being chased by the villain(s) through multiple worlds or (less artfully) via discussions between the paratime cops and their superiors (or between paratime agents and new recruits) regarding the histories of such worlds.

The paratime theme is sometimes used without the police; for example, Poul Anderson had the Old Phoenix tavern as a nexus between alternate histories. A character from a modern American alternate history "Operation Chaos" can thus appear in the English Civil War setting of "A Midsummer's Tempest". In this context, the distinction between an alternate history and a parallel universe with some points in common but no common history may not be feasible, as the writer may not provide enough information to distinguish between them.

Paratime stories published in recent decades often cite the many-worlds interpretation of quantum mechanics (first formulated by Hugh Everett III in 1957) to account for the differing worlds. Some science fiction writers interpret the splitting of worlds to depend on human decision-making and free will, while others rely on the butterfly effect from chaos theory to amplify random differences at the atomic or subatomic level into a macroscopic divergence at some specific point in history; either way, science fiction writers usually have all changes flow from a particular historical point of divergence (often abbreviated 'POD' by fans of the genre). Prior to Everett, science-fiction writers drew on higher dimensions and the speculations of P. D. Ouspensky to explain their characters' cross-time journeys.

While many justifications for alternate histories involve a multiverse, the "many world" theory would naturally involve many worlds, in fact a continually exploding array of universes. In quantum theory, new worlds would proliferate with every quantum event, and even if the writer uses human decisions, every decision that could be made differently would result in a different timeline. A writer's fictional multiverse may, in fact, preclude some decisions as humanly impossible, as when, in "Night Watch", Terry Pratchett depicts a character informing Vimes that while anything that can happen, has happened, nevertheless there is no history whatsoever in which Vimes has ever murdered his wife. When the writer explicitly maintains that "all" possible decisions are made in all possible ways, one possible conclusion is that the characters were neither brave, nor clever, nor skilled, but simply lucky enough to happen on the universe in which they did not choose the cowardly route, take the stupid action, fumble the crucial activity, etc.; few writers focus on this idea, although it has been explored in stories such as Larry Niven's story "All the Myriad Ways", where the reality of all possible universes leads to an epidemic of suicide and crime because people conclude their choices have no moral import.

In any case, even if it is true that every possible outcome occurs in some world, it can still be argued that traits such as bravery and intelligence might still affect the relative frequency of worlds in which better or worse outcomes occurred (even if the total number of worlds with each type of outcome is infinite, it is still possible to assign a different measure to different infinite sets). The physicist David Deutsch, a strong advocate of the many-worlds interpretation of quantum mechanics, has argued along these lines, saying that "By making good choices, doing the right thing, we thicken the stack of universes in which versions of us live reasonable lives. When you succeed, all the copies of you who made the same decision succeed too. What you do for the better increases the portion of the multiverse where good things happen." This view is perhaps somewhat too abstract to be explored directly in science fiction stories, but a few writers have tried, such as Greg Egan in his short story "The Infinite Assassin", where an agent is trying to contain reality-scrambling "whirlpools" that form around users of a certain drug, and the agent is constantly trying to maximize the consistency of behavior among his alternate selves, attempting to compensate for events and thoughts he experiences, he guesses are of low measure relative to those experienced by most of his other selves.

Many writers—perhaps the majority—avoid the discussion entirely. In one novel of this type, H. Beam Piper's "Lord Kalvan of Otherwhen", a Pennsylvania State Police officer, who knows how to make gunpowder, is transported from our world to an alternate universe where the recipe for gunpowder is a tightly held secret and saves a country that is about to be conquered by its neighbors. The paratime patrol members are warned against going into the timelines immediately surrounding it, where the country "will" be overrun, but the book never depicts the slaughter of the innocent thus entailed, remaining solely in the timeline where the country is saved.

The cross-time theme was further developed in the 1960s by Keith Laumer in the first three volumes of his "Imperium" sequence, which would be completed in "Zone Yellow" (1990). Piper's politically more sophisticated variant was adopted and adapted by Michael Kurland and Jack Chalker in the 1980s; Chalker's "G.O.D. Inc" trilogy (1987–89), featuring paratime detectives Sam and Brandy Horowitz, marks the first attempt at merging the paratime thriller with the police procedural. Kurland's "Perchance" (1988), the first volume of the never-completed "Chronicles of Elsewhen", presents a multiverse of secretive cross-time societies that utilize a variety of means for cross-time travel, ranging from high-tech capsules to mutant powers. Harry Turtledove has launched the Crosstime Traffic series for teenagers featuring a variant of H. Beam Piper's paratime trading empire.

The concept of a cross-time version of a world war, involving rival paratime empires, was developed in Fritz Leiber's Change War series, starting with the Hugo Award winning "The Big Time" (1958); followed by Richard C. Meredith's "Timeliner" trilogy in the 1970s, Michael McCollum's "A Greater Infinity" (1982) and John Barnes' "Timeline Wars" trilogy in the 1990s.

Such "paratime" stories may include speculation that the laws of nature can vary from one universe to the next, providing a science fictional explanation—or veneer—for what is normally fantasy. Aaron Allston's "Doc Sidhe" and "Sidhe Devil" take place between our world, the "grim world" and an alternate "fair world" where the Sidhe retreated to. Although technology is clearly present in both worlds, and the "fair world" parallels our history, about fifty years out of step, there is functional magic in the fair world. Even with such explanation, the more explicitly the alternate world resembles a normal fantasy world, the more likely the story is to be labelled fantasy, as in Poul Anderson's "House Rule" and "Loser's Night". In both science fiction and fantasy, whether a given parallel universe is an alternate history may not be clear. The writer might allude to a POD only to explain the existence and make no use of the concept, or may present the universe without explanation of its existence.

Isaac Asimov's short story "What If—" (1952) is about a couple who can explore alternate realities by means of a television-like device. This idea can also be found in Asimov's novel "The End of Eternity" (1955), in which the "Eternals" can change the realities of the world, without people being aware of it. Poul Anderson's "Time Patrol" stories feature conflicts between forces intent on changing history and the Patrol who work to preserve it. One story, Delenda Est, describes a world in which Carthage triumphed over the Roman Republic. "The Big Time", by Fritz Leiber, describes a Change War ranging across all of history.

Keith Laumer's "Worlds of the Imperium" is one of the earliest alternate history novels; it was published by "Fantastic Stories of the Imagination" in 1961, in magazine form, and reprinted by Ace Books in 1962 as one half of an Ace Double. Besides our world, Laumer describes a world ruled by an Imperial aristocracy formed by the merger of European empires, in which the American Revolution never happened, and a third world in post-war chaos ruled by the protagonist's doppelganger.

Philip K. Dick's novel, "The Man in the High Castle" (1962), is an alternate history in which Nazi Germany and Imperial Japan won World War II. This book contains an example of "alternate-alternate" history, in that one of its characters authored a book depicting a reality in which the Allies won the war, itself divergent from real-world history in several aspects. The several characters live within a divided United States, in which the Empire of Japan takes the Pacific states, governing them as a puppet, Nazi Germany takes the East Coast of the United States and parts of the Midwest, with the remnants of the old United States' government as the Neutral Zone, a buffer state between the two superpowers. The book has inspired an Amazon series of the same name.

Vladimir Nabokov's novel, "" (1969), is a story of incest that takes place within an alternate North America settled in part by Czarist Russia and that borrows from Dick's idea of "alternate-alternate" history (the world of Nabokov's hero is wracked by rumors of a "counter-earth" that apparently is ours). Some critics believe that the references to a counter-earth suggest that the world portrayed in "Ada" is a delusion in the mind of the hero (another favorite theme of Dick's novels). Strikingly, the characters in "Ada" seem to acknowledge their own world as the copy or negative version, calling it "Anti-Terra", while its mythical twin is the real "Terra". Like history, science has followed a divergent path on Anti-Terra: it boasts all the same technology as our world, but all based on water instead of electricity; e.g., when a character in "Ada" makes a long-distance call, all the toilets in the house flush at once to provide hydraulic power.

Guido Morselli described the defeat of Italy (and subsequently France) in World War I in his novel, "Past Conditional" (1975; ), wherein the static Alpine front line which divided Italy from Austria during that war collapses when the Germans and the Austrians forsake trench warfare and adopt blitzkrieg twenty years in advance.

Kingsley Amis set his novel, "The Alteration" (1976), in the 20th century, but major events in the Reformation did not take place, and Protestantism is limited to the breakaway Republic of New England. Martin Luther was reconciled to the Roman Catholic Church and later became Pope Germanian I.

Kim Stanley Robinson's novel, "The Years of Rice and Salt" (2002), starts at the point of divergence with Timur turning his army away from Europe, and the Black Death has killed 99% of Europe's population, instead of only a third. Robinson explores world history from that point in AD 1405 (807 AH) to about AD 2045 (1467 AH). Rather than following the great man theory of history, focusing on leaders, wars, and major events, Robinson writes more about social history, similar to the Annales School of history theory and Marxist historiography, focusing on the lives of ordinary people living in their time and place.

Philip Roth's novel, "The Plot Against America" (2004), looks at an America where Franklin D. Roosevelt is defeated in 1940 in his bid for a third term as President of the United States, and Charles Lindbergh is elected, leading to a US that features increasing fascism and anti-Semitism.

Michael Chabon, occasionally an author of speculative fiction, contributed to the genre with his novel "The Yiddish Policemen's Union" (2007), which explores a world in which the State of Israel was destroyed in its infancy and many of the world's Jews instead live in a small strip of Alaska set aside by the US government for Jewish settlement. The story follows a Jewish detective solving a murder case in the Yiddish-speaking semi-autonomous city state of Sitka. Stylistically, Chabon borrows heavily from the noir and detective fiction genres, while exploring social issues related to Jewish history and culture. Apart from the alternate history of the Jews and Israel, Chabon also plays with other common tropes of alternate history fiction; in the book, Germany actually loses the war even "harder" than they did in reality, getting hit with a nuclear bomb instead of just simply losing a ground war (subverting the common "what if Germany won WWII?" trope).

The late 1980s and the 1990s saw a boom in popular-fiction versions of alternate history, fueled by the emergence of the prolific alternate history author Harry Turtledove, as well as the development of the steampunk genre and two series of anthologies—the "What Might Have Been" series edited by Gregory Benford and the "Alternate ..." series edited by Mike Resnick. This period also saw alternate history works by S. M. Stirling, Kim Stanley Robinson, Harry Harrison, Howard Waldrop, and others.

In 1986, a sixteen-part epic comic book series called "Captain Confederacy" began examining a world where the Confederate States of America won the American Civil War. In the series, the Captain and others heroes are staged government propaganda events featuring the feats of these superheroes.

Since the late 1990s, Harry Turtledove has been the most prolific practitioner of alternate history and has been given the title "Master of Alternate History" by some. His books include those of Timeline 191 (a.k.a. Southern Victory, also known as TL-191), in which, while the Confederate States of America won the American Civil War, the Union and Imperial Germany defeat the Entente Powers in the two "Great War"s of the 1910s and 1940s (with a Nazi-esque Confederate government attempting to exterminate its Black population), and the Worldwar series, in which aliens invaded Earth during World War II. Other stories by Turtledove include "A Different Flesh", in which America was not colonized from Asia during the last ice age; "In the Presence of Mine Enemies", in which the Nazis won World War II; and "Ruled Britannia", in which the Spanish Armada succeeded in conquering Britain in the Elizabethan era, with William Shakespeare being given the task of writing the play that will motivate the Britons to rise up against their Spanish conquerors. He also co-authored a book with actor Richard Dreyfuss, "The Two Georges", in which the United Kingdom retained the American colonies, with George Washington and King George III making peace. He did a two-volume series in which the Japanese not only bombed Pearl Harbor but also invaded and occupied the Hawaiian Islands.

Perhaps the most incessantly explored theme in popular alternate history focuses on worlds in which the Nazis won World War Two. In some versions, the Nazis and/or Axis Powers conquer the entire world; in others, they conquer most of the world but a "Fortress America" exists under siege; while in others, there is a Nazi/Japanese Cold War comparable to the US/Soviet equivalent in 'our' timeline. "Fatherland" (1992), by Robert Harris, is set in Europe following the Nazi victory. The novel Dominion by C.J. Sansom (2012) is similar in concept but is set in England, with Churchill the leader of an anti-German Resistance and other historic persons in various fictional roles.

Several writers have posited points of departure for such a world but then have injected time splitters from the future or paratime travel, for instance James P. Hogan's "The Proteus Operation". Norman Spinrad wrote "The Iron Dream" in 1972, which is intended to be a science fiction novel written by Adolf Hitler after fleeing from Europe to North America in the 1920s.

In Jo Walton's "Small Change" series, the United Kingdom made peace with Hitler before the involvement of the United States in World War II, and fascism slowly strangled the UK. Former House Speaker Newt Gingrich and William R. Forstchen have written a novel, "1945", in which the US defeated Japan but not Germany in World War II, resulting in a Cold War with Germany rather than the Soviet Union. Gingrich and Forstchen neglected to write the promised sequel; instead, they wrote a trilogy about the American Civil War, starting with "", in which the Confederates win a victory at the Battle of Gettysburg - however, after Lincoln responds by bringing Grant and his forces to the eastern theater, the Army of Northern Virginia is soon trapped and destroyed in Maryland, and the war ends within weeks. Also from that general era, Martin Cruz Smith, in his first novel, posited an independent American Indian nation following the defeat of Custer in "The Indians Won" (1970).

Beginning with "The Probability Broach" in 1980, L. Neil Smith wrote several novels that postulated the disintegration of the US Federal Government after Albert Gallatin joins the Whiskey Rebellion in 1794 and eventually leads to the creation of a libertarian utopia.

A recent time traveling splitter variant involves entire communities being shifted elsewhere to become the unwitting creators of new time branches. These communities are transported from the present (or the near-future) to the past or to another time-line via a natural disaster, the action of technologically advanced aliens, or a human experiment gone wrong. S. M. Stirling wrote the "Island in the Sea of Time" trilogy, in which Nantucket Island and all its modern inhabitants are transported to Bronze Age times to become the world's first superpower. In Eric Flint's 1632 series, a small town in West Virginia is transported to 17th century central Europe and drastically changes the course of the Thirty Years' War, which was then underway. John Birmingham's "Axis of Time" trilogy deals with the culture shock when a United Nations naval task force from 2021 finds itself back in 1942 helping the Allies against the Empire of Japan and the Germans (and doing almost as much harm as good in spite of its advanced weapons). Similarly, Robert Charles Wilson's "Mysterium" depicts a failed US government experiment which transports a small American town into an alternative version of the US run by believers in a form of Christianity known as Gnosticism, who are engaged in a bitter war with the "Spanish" in Mexico (the chief scientist at the laboratory where the experiment occurred is described as a Gnostic, and references to Christian Gnosticism appear repeatedly in the book).
In "Time for Patriots" by retired astronomer Thomas Wm. Hamilton (4897 Tomhamilton) a town and military academy on Long Island are transported back to 1770, where they shorten the American Revolution, rewrite the Constitution, prolong Mozart's life, battle Barbary pirates, and have other adventures.

Many fantasies and science fantasies are set in a world that has a history somewhat similar to our own world, but with magic added. Some posit points of divergence, but some also feature magic altering history all along. One example of a universe that is in part historically recognizable but also obeys different physical laws is Poul Anderson's "Three Hearts and Three Lions" in which the Matter of France is history, and the fairy folk are real and powerful. A partly familiar European history for which the author provides a point of divergence is Randall Garrett's "Lord Darcy" series: a monk systemizing magic rather than science, so the use of foxglove to treat heart disease is called superstition. The other great point of divergence in this timeline occurs in 1199, when Richard the Lionheart survives the Siege of Chaluz and returns to England, making the Angevin Empire so strong it survives into the 20th century.

"Jonathan Strange & Mr Norrell" takes place in an alternative version of England where a separate Kingdom ruled by the Raven King and founded on magic existed in Northumbria for over 300 years. In Patricia Wrede's Regency fantasies, Great Britain has a Royal Society of Wizards, and in Poul Anderson's "A Midsummer Tempest" William Shakespeare is remembered as the Great Historian, with the novel itself taking place in the era of Oliver Cromwell and Charles I, with an alternate outcome for the English Civil War and an earlier Industrial Revolution.

"The Tales of Alvin Maker" series by Orson Scott Card (a parallel to the life of Joseph Smith, founder of the Latter Day Saint movement) takes place in an alternate America, beginning in the early 19th century. Prior to that time, a POD occurred: England, under the control of Oliver Cromwell, had banished "makers", or anyone else demonstrating "knacks" (an ability to perform seemingly supernatural feats) to the North American continent. Thus the early American colonists embraced as perfectly ordinary these gifts, and counted on them as a part of their daily lives. The political division of the continent is considerably altered, with two large English colonies bookending a smaller "American" nation, one aligned with England, and the other governed by exiled Cavaliers. Actual historical figures are seen in a much different light: Ben Franklin is revered as the continent's finest "maker", George Washington was executed at the hands of an English army, and "Tom" Jefferson is the first president of "Appalachia", the result of a compromise between the Continentals and the British.

On the other hand, when the "Old Ones" still manifest themselves in England in Keith Roberts's "Pavane", which takes place in a technologically backward world after a Spanish assassination of Elizabeth I allowed the Spanish Armada to conquer England, the possibility that the fairies were real but retreated from modern advances makes the POD possible: the fairies really were present all along, in a secret history. Again, in the English Renaissance fantasy "Armor of Light" by Melissa Scott and Lisa A. Barnett, the magic used in the book, by Dr. John Dee and others, actually was practiced in the Renaissance; positing a secret history of effective magic makes this an alternate history with a POD, Sir Philip Sidney's surviving the Battle of Zutphen in 1586, and shortly thereafter saving the life of Christopher Marlowe.

Many works of fantasy posit a world in which known practitioners of magic were able to make it function, and where the consequences of such reality would not, in fact, disturb history to such an extent as to make it plainly alternate history. Many ambiguous alternate/secret histories are set in Renaissance or pre-Renaissance times, and may explicitly include a "retreat" from the world, which would explain the current absence of such phenomena.

When the magical version of our world's history is set in contemporary times, the distinction becomes clear between alternate history on the one hand and contemporary fantasy, using in effect a form of secret history (as when Josepha Sherman's "Son of Darkness" has an elf living in New York City, in disguise) on the other. In works such as Robert A. Heinlein's "Magic, Incorporated" where a construction company can use magic to rig up stands at a sporting event and Poul Anderson's "Operation Chaos" and its sequel "Operation Luna", where djinns are serious weapons of war—with atomic bombs—the use of magic throughout the United States and other modern countries makes it clear that this is not secret history—although references in "Operation Chaos" to degaussing the effects of cold iron make it possible that it is the result of a POD. The sequel clarifies this as the result of a collaboration of Einstein and Planck in 1901, resulting in the theory of "rhea tics". Henry Moseley applies this theory to "degauss the effects of cold iron and release the goetic forces." This results in the suppression of ferromagnetism and the re-emergence of magic and magical creatures.

Alternate history shades off into other fantasy subgenres when the use of actual, though altered, history and geography decreases, although a culture may still be clearly the original source; Barry Hughart's "Bridge of Birds" and its sequels take place in a fantasy world, albeit one clearly based on China, and with allusions to actual Chinese history, such as the Empress Wu. Richard Garfinkle's "Celestial Matters" incorporates ancient Chinese physics and Greek Aristotelian physics, using them as if factual.

A fantasy version of the paratime police was developed by children's writer Diana Wynne Jones in her "Chrestomanci" quartet (1977–1988), with wizards taking the place of high tech secret agents. Among the novels in this series, "Witch Week" stands out for its vivid depiction of a history alternate to that of Chrestomanci's own world rather than our own (and yet with a specific POD that turned it away from the "normal" history of most worlds visited by the wizard).

Terry Pratchett's works include several references to alternate histories of Discworld. "Men At Arms" observes that in millions of universes, Edward d'Eath became an obsessive recluse rather than the instigator of the plot that he is in the novel. In "Jingo", Vimes accidentally picks up a pocket organizer that should have gone down another leg of the Trousers of Time, and so can hear the organizer reporting on the deaths that would have occurred had his decision gone otherwise. Indeed, Discworld contains an equivalent of the Time Patrol in its History Monks. "Night Watch" revolves around a repair of history after a time traveller's murder of an important figure in Vimes's past. "Thief of Time" presents them functioning as a full-scale Time Patrol, ensuring that history occurs at all.

Alternate history has long been a staple of Japanese speculative fiction with such authors as Futaro Yamada and Ryō Hanmura writing novels set in recognizable historical settings with supernatural or science fiction elements present. In 1973, Ryō Hanmura wrote "Musubi no Yama Hiroku" which recreated 400 years of Japan's history from the perspective of a secret magical family with psychic abilities. The novel has since come to be recognized as a masterpiece of Japanese speculative fiction. Twelve years later, author Hiroshi Aramata wrote the groundbreaking "Teito Monogatari" which reimagined the history of Tokyo across the 20th century in a world heavily influenced by the supernatural.

The TV show "Sliders" explores different possible alternate realities by having the protagonist "slide" into different parallel dimensions of the same planet Earth.

The two-part play "Harry Potter and the Cursed Child" contains alternate timelines set within the world of Harry Potter.

In "World of Winx," the seven fairies- Bloom, Stella, Musa, Tecna, Flora, Aisha and Roxy- live on Earth, where humans are ignorant of the existence of fairies or belief in magic; much unlike the fourth season of "Winx Club", where they had brought all magic back to Earth by releasing its terrestrial fairies.

For the same reasons that this genre is explored by role-playing games, alternate history is also an intriguing backdrop for the storylines of many video games. A famous example of an alternate history game is "". Released in 1996, the game presents a point of divergence in 1946 where Albert Einstein goes back in time to prevent World War II from ever taking place by erasing Adolf Hitler from time after he is released from Landsberg Prison in 1924. He is successful in his mission, but in the process allows Joseph Stalin and the Soviet Union to become powerful enough to launch a massive campaign to conquer Europe.

In the "Civilization" series, the player guides a civilization from prehistory to the present day, creating radically altered versions of history on a long time-scale. Several scenarios recreate a particular period which becomes the "point of divergence" in an alternate history shaped by the player's actions. Popular examples in "Sid Meier's Civilization IV" include "Desert War", set in the Mediterranean theatre of World War II and featuring scripted events tied to possible outcomes of battles; "Broken Star", set in a hypothetical Russian civil war in 2010; and "Rhye's and Fall of Civilization", an 'Earth simulator' designed to mirror a history as closely as possible but incorporating unpredictable elements to provide realistic alternate settings.

In some games such as the "Metal Gear" and "Resident Evil" series, events that were originally intended to represent the near future at the time the games were originally released later ended up becoming alternate histories in later entries in those franchises. For example, "" (1990), set in 1999, depicted a near future that ended up becoming an alternate history in "Metal Gear Solid" (1998). Likewise, "Resident Evil" (1996) and "Resident Evil 2" (1998), both set in 1998, depicted near-future events that had later become an alternative history by the time "Resident Evil 4" (2005) was released.

In the 2009 steampunk shooter, "Damnation" is set on an alternate version of planet Earth, in the early part of the 20th century after the American Civil War, which had spanned over several decades, where steam engines replace combustion engines. The game sees the protagonists fighting off a rich industrialist who wants to do away with both the Union and Confederacy in one swift movement and turn the United States of America into a country called the "American Empire" with a totalitarian dictatorship.
"Crimson Skies" is one example of an alternate history spawning multiple interpretations in multiple genres. The stories and games in "Crimson Skies" take place in an alternate 1930s United States, where the nation crumbled into many hostile states following the effects of the Great Depression, the Great War, and Prohibition. With the road and railway system destroyed, commerce took to the skies, which led to the emergence of air pirate gangs who plunder the aerial commerce.

The game "Freedom Fighters" portrays a situation similar to that of the movie "Red Dawn" and "Red Alert 2", though less comically than the latter. The point of divergence is during World War II, where the Soviet Union develops an atomic bomb first and uses it on Berlin. With the balance of power and influence tipped in Russia's favor, history diverges; brief summaries at the beginning of the game inform the player of the Communist bloc's complete takeover of Europe by 1953, a different ending to the Cuban Missile Crisis, and the spread of Soviet influence into South America and Mexico.

Similarly, the 2007 video game "World in Conflict" is set in 1989, with the Soviet Union on the verge of collapse. The point of divergence is several months before the opening of the game, when Warsaw Pact forces staged a desperate invasion of Western Europe. As the game begins, a Soviet invasion force lands in Seattle, taking advantage of the fact that most of the US military is in Europe.

The game "", released in 2008, offered in alternate history campaign for the Imperial Japanese Navy, wherein Japan destroys all three carriers in the Battle of Midway, which follows with a successful invasion of the island. Because of this, the United States lacked any sort of aerial power to fight the Japanese, and is continuously forced into the defense.

"", released in February 2008, is an alternate history first person shooter where Winston Churchill died in 1931 from being hit by a taxi cab. Because of this, Great Britain lacks the charismatic leader needed to keep the country together and Nazi Germany successfully conquers Great Britain via Operation Sea Lion in 1940. Germany later conquers the rest of Europe, North Africa and the Middle East while mass-producing their wunderwaffe. The Axis launch a surprise invasion of an isolationist United States' Eastern Seaboard in 1953, which forces the country to surrender and submit to a puppet government.
Another alternate history game involving Nazis is "" in which Hitler died during the early days of World War II and thus, a much more effective leadership rose to power. Under the command of a new Führer (who is referred to as "Chancellor", and his real name is never revealed), Operation Sealion succeeds and the Nazis successfully conquer Britain, sparking a cold war between the Allied Powers and Germany.

The "Fallout" series of computer role-playing games is set in a divergent America, where history after World War II diverges from the real world to follow a retro-futuristic timeline. For example, fusion power was invented quite soon after the end of the war, but the transistor was never developed. The result was a future that has a 1950s 'World of Tomorrow' feel to it, with extremely high technology such as artificial intelligence implemented with thermionic valves and other technologies now considered obsolete.

Many game series by Swedish developer Paradox Interactive start off at a concise point in history, allowing the player to immerse in the role of a contemporary leader and alter the course of in-game history. The most prominent game with this setting is "Crusader Kings II".

"S.T.A.L.K.E.R." games have an alternate history at the Chernobyl Exclusion Zone, where a special area called "The Zone" is formed.

"" is set in an alternate 1960 in which the Nazis won the Second World War, also thanks to their acquisition of high technology. The sequel "" continues this, although being set in the conquered United States of America.

Fans of alternate history have made use of the internet from a very early point to showcase their own works and provide useful tools for those fans searching for anything alternate history, first in mailing lists and usenet groups, later in web databases and forums. The "Usenet Alternate History List" was first posted on April 11, 1991, to the Usenet newsgroup rec.arts.sf-lovers. In May 1995, the dedicated newsgroup "soc.history.what-if" was created for showcasing and discussing alternate histories. Its prominence declined with the general migration from unmoderated usenet to moderated web forums, most prominently AlternateHistory.com, the self-described "largest gathering of alternate history fans on the internet" with over 10,000 active members.

In addition to these discussion forums, in 1997 was created as an online repository, now containing over 2,900 alternate history novels, stories, essays, and other printed materials in several different languages. Uchronia was selected as the Sci Fi Channel's "Sci Fi Site of the Week" twice.



</doc>
<doc id="1206" url="https://en.wikipedia.org/wiki?curid=1206" title="Atomic orbital">
Atomic orbital

In atomic theory and quantum mechanics, an atomic orbital is a mathematical function describing the location and wave-like behavior of an electron in an atom. This function can be used to calculate the probability of finding any electron of an atom in any specific region around the atom's nucleus. The term "atomic orbital" may also refer to the physical region or space where the electron can be calculated to be present, as predicted by the particular mathematical form of the orbital.

Each orbital in an atom is characterized by a unique set of values of the three quantum numbers , , and , which respectively correspond to the electron's energy, angular momentum, and an angular momentum vector component (the magnetic quantum number). Each such orbital can be occupied by a maximum of two electrons, each with its own spin quantum number . The simple names s orbital, p orbital, d orbital, and f orbital refer to orbitals with angular momentum quantum number and respectively. These names, together with the value of , are used to describe the electron configurations of atoms. They are derived from the description by early spectroscopists of certain series of alkali metal spectroscopic lines as sharp, principal, diffuse, and fundamental. Orbitals for > 3 continue alphabetically, omitting j (g, h, i, k, ...) because some languages do not distinguish between the letters "i" and "j".

Atomic orbitals are the basic building blocks of the atomic orbital model (alternatively known as the electron cloud or wave mechanics model), a modern framework for visualizing the submicroscopic behavior of electrons in matter. In this model the electron cloud of a multi-electron atom may be seen as being built up (in approximation) in an electron configuration that is a product of simpler hydrogen-like atomic orbitals. The repeating "periodicity" of the blocks of 2, 6, 10, and 14 elements within sections of the periodic table arises naturally from the total number of electrons that occupy a complete set of s, p, d, and f atomic orbitals, respectively, although for higher values of the quantum number , particularly when the atom in question bears a positive charge, the energies of certain sub-shells become very similar and so the order in which they are said to be populated by electrons (e.g. Cr = [Ar]4s3d and Cr = [Ar]3d) can only be rationalized somewhat arbitrarily.

With the development of quantum mechanics and experimental findings (such as the two slit diffraction of electrons), it was found that the orbiting electrons around a nucleus could not be fully described as particles, but needed to be explained by the wave-particle duality. In this sense, the electrons have the following properties:

Wave-like properties:

Particle-like properties:

Thus, electrons cannot be described simply as solid particles. An analogy might be that of a large and often oddly shaped "atmosphere" (the electron), distributed around a relatively tiny planet (the atomic nucleus). Atomic orbitals exactly describe the shape of this "atmosphere" only when a single electron is present in an atom. When more electrons are added to a single atom, the additional electrons tend to more evenly fill in a volume of space around the nucleus so that the resulting collection (sometimes termed the atom's "electron cloud") tends toward a generally spherical zone of probability describing the electron's location, because of the uncertainty principle.

Atomic orbitals may be defined more precisely in formal quantum mechanical language. They are an approximate solution to the Schrodinger equation for the electrons bound to the atom by the electric field of the atom's nucleus. Specifically, in quantum mechanics, the state of an atom, i.e., an eigenstate of the atomic Hamiltonian, is approximated by an expansion (see configuration interaction expansion and basis set) into linear combinations of anti-symmetrized products (Slater determinants) of one-electron functions. The spatial components of these one-electron functions are called atomic orbitals. (When one considers also their spin component, one speaks of atomic spin orbitals.) A state is actually a function of the coordinates of all the electrons, so that their motion is correlated, but this is often approximated by this independent-particle model of products of single electron wave functions. (The London dispersion force, for example, depends on the correlations of the motion of the electrons.)

In atomic physics, the atomic spectral lines correspond to transitions (quantum leaps) between quantum states of an atom. These states are labeled by a set of quantum numbers summarized in the term symbol and usually associated with particular electron configurations, i.e., by occupation schemes of atomic orbitals (for example, 1s 2s 2p for the ground state of neon-term symbol: S).

This notation means that the corresponding Slater determinants have a clear higher weight in the configuration interaction expansion. The atomic orbital concept is therefore a key concept for visualizing the excitation process associated with a given transition. For example, one can say for a given transition that it corresponds to the excitation of an electron from an occupied orbital to a given unoccupied orbital. Nevertheless, one has to keep in mind that electrons are fermions ruled by the Pauli exclusion principle and cannot be distinguished from each other. Moreover, it sometimes happens that the configuration interaction expansion converges very slowly and that one cannot speak about simple one-determinant wave function at all. This is the case when electron correlation is large.

Fundamentally, an atomic orbital is a one-electron wave function, even though most electrons do not exist in one-electron atoms, and so the one-electron view is an approximation. When thinking about orbitals, we are often given an orbital visualization heavily influenced by the Hartree–Fock approximation, which is one way to reduce the complexities of molecular orbital theory.

Atomic orbitals can be the hydrogen-like "orbitals" which are exact solutions to the Schrödinger equation for a hydrogen-like "atom" (i.e., an atom with one electron). Alternatively, atomic orbitals refer to functions that depend on the coordinates of one electron (i.e., orbitals) but are used as starting points for approximating wave functions that depend on the simultaneous coordinates of all the electrons in an atom or molecule. The coordinate systems chosen for atomic orbitals are usually spherical coordinates in atoms and cartesians in polyatomic molecules. The advantage of spherical coordinates (for atoms) is that an orbital wave function is a product of three factors each dependent on a single coordinate: . The angular factors of atomic orbitals generate s, p, d, etc. functions as real combinations of spherical harmonics (where and are quantum numbers). There are typically three mathematical forms for the radial functions  which can be chosen as a starting point for the calculation of the properties of atoms and molecules with many electrons:


Although hydrogen-like orbitals are still used as pedagogical tools, the advent of computers has made STOs preferable for atoms and diatomic molecules since combinations of STOs can replace the nodes in hydrogen-like atomic orbital. Gaussians are typically used in molecules with three or more atoms. Although not as accurate by themselves as STOs, combinations of many Gaussians can attain the accuracy of hydrogen-like orbitals.

The term "orbital" was coined by Robert Mulliken in 1932 as an abbreviation for "one-electron orbital wave function". However, the idea that electrons might revolve around a compact nucleus with definite angular momentum was convincingly argued at least 19 years earlier by Niels Bohr, and the Japanese physicist Hantaro Nagaoka published an orbit-based hypothesis for electronic behavior as early as 1904. Explaining the behavior of these electron "orbits" was one of the driving forces behind the development of quantum mechanics.

With J. J. Thomson's discovery of the electron in 1897, it became clear that atoms were not the smallest building blocks of nature, but were rather composite particles. The newly discovered structure within atoms tempted many to imagine how the atom's constituent parts might interact with each other. Thomson theorized that multiple electrons revolved in orbit-like rings within a positively charged jelly-like substance, and between the electron's discovery and 1909, this "plum pudding model" was the most widely accepted explanation of atomic structure.

Shortly after Thomson's discovery, Hantaro Nagaoka predicted a different model for electronic structure. Unlike the plum pudding model, the positive charge in Nagaoka's "Saturnian Model" was concentrated into a central core, pulling the electrons into circular orbits reminiscent of Saturn's rings. Few people took notice of Nagaoka's work at the time, and Nagaoka himself recognized a fundamental defect in the theory even at its conception, namely that a classical charged object cannot sustain orbital motion because it is accelerating and therefore loses energy due to electromagnetic radiation. Nevertheless, the Saturnian model turned out to have more in common with modern theory than any of its contemporaries.

In 1909, Ernest Rutherford discovered that the bulk of the atomic mass was tightly condensed into a nucleus, which was also found to be positively charged. It became clear from his analysis in 1911 that the plum pudding model could not explain atomic structure. In 1913, Rutherford's post-doctoral student, Niels Bohr, proposed a new model of the atom, wherein electrons orbited the nucleus with classical periods, but were only permitted to have discrete values of angular momentum, quantized in units "h"/2π. This constraint automatically permitted only certain values of electron energies. The Bohr model of the atom fixed the problem of energy loss from radiation from a ground state (by declaring that there was no state below this), and more importantly explained the origin of spectral lines.
After Bohr's use of Einstein's explanation of the photoelectric effect to relate energy levels in atoms with the wavelength of emitted light, the connection between the structure of electrons in atoms and the emission and absorption spectra of atoms became an increasingly useful tool in the understanding of electrons in atoms. The most prominent feature of emission and absorption spectra (known experimentally since the middle of the 19th century), was that these atomic spectra contained discrete lines. The significance of the Bohr model was that it related the lines in emission and absorption spectra to the energy differences between the orbits that electrons could take around an atom. This was, however, "not" achieved by Bohr through giving the electrons some kind of wave-like properties, since the idea that electrons could behave as matter waves was not suggested until eleven years later. Still, the Bohr model's use of quantized angular momenta and therefore quantized energy levels was a significant step towards the understanding of electrons in atoms, and also a significant step towards the development of quantum mechanics in suggesting that quantized restraints must account for all discontinuous energy levels and spectra in atoms.

With de Broglie's suggestion of the existence of electron matter waves in 1924, and for a short time before the full 1926 Schrödinger equation treatment of hydrogen-like atom, a Bohr electron "wavelength" could be seen to be a function of its momentum, and thus a Bohr orbiting electron was seen to orbit in a circle at a multiple of its half-wavelength (this physically incorrect Bohr model is still often taught to beginning students). The Bohr model for a short time could be seen as a classical model with an additional constraint provided by the 'wavelength' argument. However, this period was immediately superseded by the full three-dimensional wave mechanics of 1926. In our current understanding of physics, the Bohr model is called a semi-classical model because of its quantization of angular momentum, not primarily because of its relationship with electron wavelength, which appeared in hindsight a dozen years after the Bohr model was proposed.

The Bohr model was able to explain the emission and absorption spectra of hydrogen. The energies of electrons in the "n" = 1, 2, 3, etc. states in the Bohr model match those of current physics. However, this did not explain similarities between different atoms, as expressed by the periodic table, such as the fact that helium (two electrons), neon (10 electrons), and argon (18 electrons) exhibit similar chemical inertness. Modern quantum mechanics explains this in terms of electron shells and subshells which can each hold a number of electrons determined by the Pauli exclusion principle. Thus the "n" = 1 state can hold one or two electrons, while the "n" = 2 state can hold up to eight electrons in 2s and 2p subshells. In helium, all "n" = 1 states are fully occupied; the same is true for "n" = 1 and "n" = 2 in neon. In argon, the 3s and 3p subshells are similarly fully occupied by eight electrons; quantum mechanics also allows a 3d subshell but this is at higher energy than the 3s and 3p in argon (contrary to the situation in the hydrogen atom) and remains empty.

Immediately after Heisenberg discovered his uncertainty principle, Bohr noted that the existence of any sort of wave packet implies uncertainty in the wave frequency and wavelength, since a spread of frequencies is needed to create the packet itself. In quantum mechanics, where all particle momenta are associated with waves, it is the formation of such a wave packet which localizes the wave, and thus the particle, in space. In states where a quantum mechanical particle is bound, it must be localized as a wave packet, and the existence of the packet and its minimum size implies a spread and minimal value in particle wavelength, and thus also momentum and energy. In quantum mechanics, as a particle is localized to a smaller region in space, the associated compressed wave packet requires a larger and larger range of momenta, and thus larger kinetic energy. Thus the binding energy to contain or trap a particle in a smaller region of space increases without bound as the region of space grows smaller. Particles cannot be restricted to a geometric point in space, since this would require an infinite particle momentum.

In chemistry, Schrödinger, Pauling, Mulliken and others noted that the consequence of Heisenberg's relation was that the electron, as a wave packet, could not be considered to have an exact location in its orbital. Max Born suggested that the electron's position needed to be described by a probability distribution which was connected with finding the electron at some point in the wave-function which described its associated wave packet. The new quantum mechanics did not give exact results, but only the probabilities for the occurrence of a variety of possible such results. Heisenberg held that the path of a moving particle has no meaning if we cannot observe it, as we cannot with electrons in an atom.

In the quantum picture of Heisenberg, Schrödinger and others, the Bohr atom number "n" for each orbital became known as an "n-sphere" in a three dimensional atom and was pictured as the most probable energy of the probability cloud of the electron's wave packet which surrounded the atom.

Orbitals have been given names, which are usually given in the form:
where "X" is the energy level corresponding to the principal quantum number ; type is a lower-case letter denoting the shape or subshell of the orbital, corresponding to the angular quantum number ; and is the number of electrons in that orbital.

For example, the orbital 1s (pronounced as the individual numbers and letters: "'one' 'ess' 'two'") has two electrons and is the lowest energy level () and has an angular quantum number of , denoted as s.

There is also another, less common system still used in X-ray science known as X-ray notation, which is a continuation of the notations used before orbital theory was well understood. In this system, the principal quantum number is given a letter associated with it. For , the letters associated with those numbers are K, L, M, N, O, ... respectively.

The simplest atomic orbitals are those that are calculated for systems with a single electron, such as the hydrogen atom. An atom of any other element ionized down to a single electron is very similar to hydrogen, and the orbitals take the same form. In the Schrödinger equation for this system of one negative and one positive particle, the atomic orbitals are the eigenstates of the Hamiltonian operator for the energy. They can be obtained analytically, meaning that the resulting orbitals are products of a polynomial series, and exponential and trigonometric functions. (see hydrogen atom).

For atoms with two or more electrons, the governing equations can only be solved with the use of methods of iterative approximation. Orbitals of multi-electron atoms are "qualitatively" similar to those of hydrogen, and in the simplest models, they are taken to have the same form. For more rigorous and precise analysis, numerical approximations must be used.

A given (hydrogen-like) atomic orbital is identified by unique values of three quantum numbers: , , and . The rules restricting the values of the quantum numbers, and their energies (see below), explain the electron configuration of the atoms and the periodic table.

The stationary states (quantum states) of the hydrogen-like atoms are its atomic orbitals. However, in general, an electron's behavior is not fully described by a single orbital. Electron states are best represented by time-depending "mixtures" (linear combinations) of multiple orbitals. See Linear combination of atomic orbitals molecular orbital method.

The quantum number first appeared in the Bohr model where it determines the radius of each circular electron orbit. In modern quantum mechanics however, determines the mean distance of the electron from the nucleus; all electrons with the same value of "n" lie at the same average distance. For this reason, orbitals with the same value of "n" are said to comprise a "shell". Orbitals with the same value of "n" and also the same value of  are even more closely related, and are said to comprise a "subshell".

Because of the quantum mechanical nature of the electrons around a nucleus, atomic orbitals can be uniquely defined by a set of integers known as quantum numbers. These quantum numbers only occur in certain combinations of values, and their physical interpretation changes depending on whether real or complex versions of the atomic orbitals are employed.

In physics, the most common orbital descriptions are based on the solutions to the hydrogen atom, where orbitals are given by the product between a radial function and a pure spherical harmonic. The quantum numbers, together with the rules governing their possible values, are as follows:

The principal quantum number describes the energy of the electron and is always a positive integer. In fact, it can be any positive integer, but for reasons discussed below, large numbers are seldom encountered. Each atom has, in general, many orbitals associated with each value of "n"; these orbitals together are sometimes called "electron shells".

The azimuthal quantum number describes the orbital angular momentum of each electron and is a non-negative integer. Within a shell where is some integer , ranges across all (integer) values satisfying the relation formula_3. For instance, the  shell has only orbitals with formula_4, and the  shell has only orbitals with formula_4, and formula_6. The set of orbitals associated with a particular value of  are sometimes collectively called a "subshell".

The magnetic quantum number, formula_7, describes the magnetic moment of an electron in an arbitrary direction, and is also always an integer. Within a subshell where formula_8 is some integer formula_9, formula_7 ranges thus: formula_11.

The above results may be summarized in the following table. Each cell represents a subshell, and lists the values of formula_7 available in that subshell. Empty cells represent subshells that do not exist.

Subshells are usually identified by their formula_13- and formula_8-values. formula_13 is represented by its numerical value, but formula_8 is represented by a letter as follows: 0 is represented by 's', 1 by 'p', 2 by 'd', 3 by 'f', and 4 by 'g'. For instance, one may speak of the subshell with formula_17 and formula_4 as a '2s subshell'.

Each electron also has a spin quantum number, "s", which describes the spin of each electron (spin up or spin down). The number "s" can be + or −.

The Pauli exclusion principle states that no two electrons in an atom can have the same values of all four quantum numbers. If there are two electrons in an orbital with given values for three quantum numbers, (, , ), these two electrons must differ in their spin.

The above conventions imply a preferred axis (for example, the "z" direction in Cartesian coordinates), and they also imply a preferred direction along this preferred axis. Otherwise there would be no sense in distinguishing from . As such, the model is most useful when applied to physical systems that share these symmetries. The Stern–Gerlach experiment — where an atom is exposed to a magnetic field — provides one such example.

An atom that is embedded in a crystalline solid feels multiple preferred axes, but often no preferred direction. Instead of building atomic orbitals out of the product of radial functions and a single spherical harmonic, linear combinations of spherical harmonics are typically used, designed so that the imaginary part of the spherical harmonics cancel out. These real orbitals are the building blocks most commonly shown in orbital visualizations.

In the real hydrogen-like orbitals, for example, and have the same interpretation and significance as their complex counterparts, but is no longer a good quantum number (though its absolute value is). The orbitals are given new names based on their shape with respect to a standardized Cartesian basis. The real hydrogen-like p orbitals are given by the following

where , , and , are the complex orbitals corresponding to .

The equations for the p and p orbitals depend on the phase convention used for the spherical harmonics. The above equations suppose that the spherical harmonics are defined by formula_22. However some quantum physicists include a phase factor in these definitions, which has the effect of relating the p orbital to a "difference" of spherical harmonics and the p orbital to the corresponding "sum". (For more detail, see Spherical harmonics#Conventions).

Simple pictures showing orbital shapes are intended to describe the angular forms of regions in space where the electrons occupying the orbital are likely to be found. The diagrams cannot show the entire region where an electron can be found, since according to quantum mechanics there is a non-zero probability of finding the electron (almost) anywhere in space. Instead the diagrams are approximate representations of boundary or contour surfaces where the probability density has a constant value, chosen so that there is a certain probability (for example 90%) of finding the electron within the contour. Although as the square of an absolute value is everywhere non-negative, the sign of the wave function is often indicated in each subregion of the orbital picture.

Sometimes the function will be graphed to show its phases, rather than the which shows probability density but has no phases (which have been lost in the process of taking the absolute value, since is a complex number). orbital graphs tend to have less spherical, thinner lobes than graphs, but have the same number of lobes in the same places, and otherwise are recognizable. This article, in order to show wave function phases, shows mostly graphs.

The lobes can be viewed as standing wave interference patterns between the two counter rotating, ring resonant travelling wave "" and "" modes, with the projection of the orbital onto the xy plane having a resonant "" wavelengths around the circumference. Though rarely depicted the travelling wave solutions can be viewed as rotating banded tori, with the bands representing phase information. For each there are two standing wave solutions and . For the case where the orbital is vertical, counter rotating information is unknown, and the orbital is "z"-axis symmetric. For the case where there are no counter rotating modes. There are only radial modes and the shape is spherically symmetric. For any given , the smaller is, the more radial nodes there are. For any given , the smaller is, the fewer radial nodes there are (zero for whichever first has that orbital). Loosely speaking is energy, is analogous to eccentricity, and is orientation. In the classical case, a ring resonant travelling wave, for example in a circular transmission line, unless actively forced, will spontaneously decay into a ring resonant standing wave because reflections will build up over time at even the smallest imperfection or discontinuity.

Generally speaking, the number determines the size and energy of the orbital for a given nucleus: as increases, the size of the orbital increases. When comparing different elements, the higher nuclear charge of heavier elements causes their orbitals to contract by comparison to lighter ones, so that the overall size of the whole atom remains very roughly constant, even as the number of electrons in heavier elements (higher ) increases.

Also in general terms, determines an orbital's shape, and its orientation. However, since some orbitals are described by equations in complex numbers, the shape sometimes depends on also. Together, the whole set of orbitals for a given and fill space as symmetrically as possible, though with increasingly complex sets of lobes and nodes.

The single s-orbitals (formula_4) are shaped like spheres. For it is roughly a solid ball (it is most dense at the center and fades exponentially outwardly), but for or more, each single s-orbital is composed of spherically symmetric surfaces which are nested shells (i.e., the "wave-structure" is radial, following a sinusoidal radial component as well). See illustration of a cross-section of these nested shells, at right. The s-orbitals for all numbers are the only orbitals with an anti-node (a region of high wave function density) at the center of the nucleus. All other orbitals (p, d, f, etc.) have angular momentum, and thus avoid the nucleus (having a wave node "at" the nucleus). Recently, there has been an effort to experimentally image the 1s and 2p orbitals in a SrTiO crystal using scanning transmission electron microscopy with energy dispersive x-ray spectroscopy. Because the imaging was conducted using an electron beam, Coulombic beam-orbital interaction that is often termed as the impact parameter effect is included in the final outcome (see the figure at right).

The shapes of p, d and f-orbitals are described verbally here and shown graphically in the "Orbitals table" below. The three p-orbitals for have the form of two ellipsoids with a point of tangency at the nucleus (the two-lobed shape is sometimes referred to as a "dumbbell"—there are two lobes pointing in opposite directions from each other). The three p-orbitals in each shell are oriented at right angles to each other, as determined by their respective linear combination of values of . The overall result is a lobe pointing along each direction of the primary axes.

Four of the five d-orbitals for look similar, each with four pear-shaped lobes, each lobe tangent at right angles to two others, and the centers of all four lying in one plane. Three of these planes are the xy-, xz-, and yz-planes—the lobes are between the pairs of primary axes—and the fourth has the centres along the x and y axes themselves. The fifth and final d-orbital consists of three regions of high probability density: a torus with two pear-shaped regions placed symmetrically on its z axis. The overall total of 18 directional lobes point in every primary axis direction and between every pair.

There are seven f-orbitals, each with shapes more complex than those of the d-orbitals.

Additionally, as is the case with the s orbitals, individual p, d, f and g orbitals with values higher than the lowest possible value, exhibit an additional radial node structure which is reminiscent of harmonic waves of the same type, as compared with the lowest (or fundamental) mode of the wave. As with s orbitals, this phenomenon provides p, d, f, and g orbitals at the next higher possible value of (for example, 3p orbitals vs. the fundamental 2p), an additional node in each lobe. Still higher values of further increase the number of radial nodes, for each type of orbital.

The shapes of atomic orbitals in one-electron atom are related to 3-dimensional spherical harmonics. These shapes are not unique, and any linear combination is valid, like a transformation to cubic harmonics, in fact it is possible to generate sets where all the d's are the same shape, just like the and are the same shape.
Although individual orbitals are most often shown independent of each other, the orbitals coexist around the nucleus at the same time. Also, in 1927, Albrecht Unsöld proved that if one sums the electron density of all orbitals of a particular azimuthal quantum number of the same shell (e.g. all three 2p orbitals, or all five 3d orbitals) where each orbital is occupied by an electron or each is occupied by an electron pair, then all angular dependence disappears; that is, the resulting total density of all the atomic orbitals in that subshell (those with the same ) is spherical. This is known as Unsöld's theorem.

This table shows all orbital configurations for the real hydrogen-like wave functions up to 7s, and therefore covers the simple electronic configuration for all elements in the periodic table up to radium. "ψ" graphs are shown with − and + wave function phases shown in two different colors (arbitrarily red and blue). The orbital is the same as the orbital, but the and are formed by taking linear
combinations of the and orbitals (which is why they are listed under the label). Also, the and are not
the same shape as the , since they are pure spherical harmonics.

The shapes of atomic orbitals can be qualitatively understood by considering the analogous case of standing waves on a circular drum. To see the analogy, the mean vibrational displacement of each bit of drum membrane from the equilibrium point over many cycles (a measure of average drum membrane velocity and momentum at that point) must be considered relative to that point's distance from the center of the drum head. If this displacement is taken as being analogous to the probability of finding an electron at a given distance from the nucleus, then it will be seen that the many modes of the vibrating disk form patterns that trace the various shapes of atomic orbitals. The basic reason for this correspondence lies in the fact that the distribution of kinetic energy and momentum in a matter-wave is predictive of where the particle associated with the wave will be. That is, the probability of finding an electron at a given place is also a function of the electron's average momentum at that point, since high electron momentum at a given position tends to "localize" the electron in that position, via the properties of electron wave-packets (see the Heisenberg uncertainty principle for details of the mechanism).

This relationship means that certain key features can be observed in both drum membrane modes and atomic orbitals. For example, in all of the modes analogous to s orbitals (the top row in the animated illustration below), it can be seen that the very center of the drum membrane vibrates most strongly, corresponding to the antinode in all s orbitals in an atom. This antinode means the electron is most likely to be at the physical position of the nucleus (which it passes straight through without scattering or striking it), since it is moving (on average) most rapidly at that point, giving it maximal momentum.

A mental "planetary orbit" picture closest to the behavior of electrons in s orbitals, all of which have no angular momentum, might perhaps be that of a Keplerian orbit with the orbital eccentricity of 1 but a finite major axis, not physically possible (because particles were to collide), but can be imagined as a limit of orbits with equal major axes but increasing eccentricity.

Below, a number of drum membrane vibration modes and the respective wave functions of the hydrogen atom are shown. A correspondence can be considered where the wave functions of a vibrating drum head are for a two-coordinate system and the wave functions for a vibrating sphere are three-coordinate .

None of the other sets of modes in a drum membrane have a central antinode, and in all of them the center of the drum does not move. These correspond to a node at the nucleus for all non-s orbitals in an atom. These orbitals all have some angular momentum, and in the planetary model, they correspond to particles in orbit with eccentricity less than 1.0, so that they do not pass straight through the center of the primary body, but keep somewhat away from it.

In addition, the drum modes analogous to p and d modes in an atom show spatial irregularity along the different radial directions from the center of the drum, whereas all of the modes analogous to s modes are perfectly symmetrical in radial direction. The non radial-symmetry properties of non-s orbitals are necessary to localize a particle with angular momentum and a wave nature in an orbital where it must tend to stay away from the central attraction force, since any particle localized at the point of central attraction could have no angular momentum. For these modes, waves in the drum head tend to avoid the central point. Such features again emphasize that the shapes of atomic orbitals are a direct consequence of the wave nature of electrons.

In atoms with a single electron (hydrogen-like atoms), the energy of an orbital (and, consequently, of any electrons in the orbital) is determined mainly by formula_13. The formula_25 orbital has the lowest possible energy in the atom. Each successively higher value of formula_13 has a higher level of energy, but the difference decreases as formula_13 increases. For high formula_13, the level of energy becomes so high that the electron can easily escape from the atom. In single electron atoms, all levels with different formula_8 within a given formula_13 are degenerate in the Schrödinger approximation, and have the same energy. This approximation is broken to a slight extent in the solution to the Dirac equation (where the energy depends on and another quantum number ), and by the effect of the magnetic field of the nucleus and quantum electrodynamics effects. The latter induce tiny binding energy differences especially for s electrons that go nearer the nucleus, since these feel a very slightly different nuclear charge, even in one-electron atoms; see Lamb shift.

In atoms with multiple electrons, the energy of an electron depends not only on the intrinsic properties of its orbital, but also on its interactions with the other electrons. These interactions depend on the detail of its spatial probability distribution, and so the energy levels of orbitals depend not only on formula_13 but also on formula_8. Higher values of formula_8 are associated with higher values of energy; for instance, the 2p state is higher than the 2s state. When formula_34, the increase in energy of the orbital becomes so large as to push the energy of orbital above the energy of the s-orbital in the next higher shell; when formula_35 the energy is pushed into the shell two steps higher. The filling of the 3d orbitals does not occur until the 4s orbitals have been filled.

The increase in energy for subshells of increasing angular momentum in larger atoms is due to electron–electron interaction effects, and it is specifically related to the ability of low angular momentum electrons to penetrate more effectively toward the nucleus, where they are subject to less screening from the charge of intervening electrons. Thus, in atoms of higher atomic number, the formula_8 of electrons becomes more and more of a determining factor in their energy, and the principal quantum numbers formula_13 of electrons becomes less and less important in their energy placement.

The energy sequence of the first 35 subshells (e.g., 1s, 2p, 3d, etc.) is given in the following table. Each cell represents a subshell with formula_13 and formula_8 given by its row and column indices, respectively. The number in the cell is the subshell's position in the sequence. For a linear listing of the subshells in terms of increasing energies in multielectron atoms, see the section below.

"Note: empty cells indicate non-existent sublevels, while numbers in italics indicate sublevels that could (potentially) exist, but which do not hold electrons in any element currently known."

Several rules govern the placement of electrons in orbitals ("electron configuration"). The first dictates that no two electrons in an atom may have the same set of values of quantum numbers (this is the Pauli exclusion principle). These quantum numbers include the three that define orbitals, as well as , or spin quantum number. Thus, two electrons may occupy a single orbital, so long as they have different values of . However, "only" two electrons, because of their spin, can be associated with each orbital.

Additionally, an electron always tends to fall to the lowest possible energy state. It is possible for it to occupy any orbital so long as it does not violate the Pauli exclusion principle, but if lower-energy orbitals are available, this condition is unstable. The electron will eventually lose energy (by releasing a photon) and drop into the lower orbital. Thus, electrons fill orbitals in the order specified by the energy sequence given above.

This behavior is responsible for the structure of the periodic table. The table may be divided into several rows (called 'periods'), numbered starting with 1 at the top. The presently known elements occupy seven periods. If a certain period has number "i", it consists of elements whose outermost electrons fall in the "i"th shell. Niels Bohr was the first to propose (1923) that the periodicity in the properties of the elements might be explained by the periodic filling of the electron energy levels, resulting in the electronic structure of the atom.

The periodic table may also be divided into several numbered rectangular 'blocks'. The elements belonging to a given block have this common feature: their highest-energy electrons all belong to the same -state (but the associated with that -state depends upon the period). For instance, the leftmost two columns constitute the 's-block'. The outermost electrons of Li and Be respectively belong to the 2s subshell, and those of Na and Mg to the 3s subshell.

The following is the order for filling the "subshell" orbitals, which also gives the order of the "blocks" in the periodic table:

The "periodic" nature of the filling of orbitals, as well as emergence of the s, p, d, and f "blocks", is more obvious if this order of filling is given in matrix form, with increasing principal quantum numbers starting the new rows ("periods") in the matrix. Then, each subshell (composed of the first two quantum numbers) is repeated as many times as required for each pair of electrons it may contain. The result is a compressed periodic table, with each entry representing two successive elements:

Although this is the general order of orbital filling according to the Madelung rule, there are exceptions, and the actual electronic energies of each element are also dependent upon additional details of the atoms (see ).

The number of electrons in an electrically neutral atom increases with the atomic number. The electrons in the outermost shell, or "valence electrons", tend to be responsible for an element's chemical behavior. Elements that contain the same number of valence electrons can be grouped together and display similar chemical properties.

For elements with high atomic number , the effects of relativity become more pronounced, and especially so for s electrons, which move at relativistic velocities as they penetrate the screening electrons near the core of high- atoms. This relativistic increase in momentum for high speed electrons causes a corresponding decrease in wavelength and contraction of 6s orbitals relative to 5d orbitals (by comparison to corresponding s and d electrons in lighter elements in the same column of the periodic table); this results in 6s valence electrons becoming lowered in energy.

Examples of significant physical outcomes of this effect include the lowered melting temperature of mercury (which results from 6s electrons not being available for metal bonding) and the golden color of gold and caesium.

In the Bohr Model, an  electron has a velocity given by formula_40, where is the atomic number, formula_41 is the fine-structure constant, and is the speed of light. In non-relativistic quantum mechanics, therefore, any atom with an atomic number greater than 137 would require its 1s electrons to be traveling faster than the speed of light. Even in the Dirac equation, which accounts for relativistic effects, the wave function of the electron for atoms with formula_42 is oscillatory and unbounded. The significance of element 137, also known as untriseptium, was first pointed out by the physicist Richard Feynman. Element 137 is sometimes informally called feynmanium (symbol Fy). However, Feynman's approximation fails to predict the exact critical value of  due to the non-point-charge nature of the nucleus and very small orbital radius of inner electrons, resulting in a potential seen by inner electrons which is effectively less than . The critical  value, which makes the atom unstable with regard to high-field breakdown of the vacuum and production of electron-positron pairs, does not occur until is about 173. These conditions are not seen except transiently in collisions of very heavy nuclei such as lead or uranium in accelerators, where such electron-positron production from these effects has been claimed to be observed.

There are no nodes in relativistic orbital densities, although individual components of the wave function will have nodes.

In late period-8 elements a hybrid of 8p and 9p is expected to exist, where "3/2" and "1/2" refer to the total angular momentum quantum number. This "pp" hybrid may be responsible for the p-block of the period due to properties similar to p subshells in ordinary valence shells. Energy levels of 8p and 9p come close due to relativistic spin–orbit effects; the 9s subshell should also participate, as these elements are expected to be analogous to the respective 5p elements indium through xenon.

Bound quantum states have discrete energy levels. When applied to atomic orbitals, this means that the energy differences between states are also discrete. A transition between these states (i.e., an electron absorbing or emitting a photon) can thus only happen if the photon has an energy corresponding with the exact energy difference between said states.

Consider two states of the hydrogen atom:

State 1) , , and 

State 2) , , and 

By quantum theory, state 1 has a fixed energy of , and state 2 has a fixed energy of . Now, what would happen if an electron in state 1 were to move to state 2? For this to happen, the electron would need to gain an energy of exactly . If the electron receives energy that is less than or greater than this value, it cannot jump from state 1 to state 2. Now, suppose we irradiate the atom with a broad-spectrum of light. Photons that reach the atom that have an energy of exactly will be absorbed by the electron in state 1, and that electron will jump to state 2. However, photons that are greater or lower in energy cannot be absorbed by the electron, because the electron can only jump to one of the orbitals, it cannot jump to a state between orbitals. The result is that only photons of a specific frequency will be absorbed by the atom. This creates a line in the spectrum, known as an absorption line, which corresponds to the energy difference between states 1 and 2.

The atomic orbital model thus predicts line spectra, which are observed experimentally. This is one of the main validations of the atomic orbital model.

The atomic orbital model is nevertheless an approximation to the full quantum theory, which only recognizes many electron states. The predictions of line spectra are qualitatively useful but are not quantitatively accurate for atoms and ions other than those containing only one electron.





</doc>
<doc id="1207" url="https://en.wikipedia.org/wiki?curid=1207" title="Amino acid">
Amino acid

Amino acids are organic compounds that contain amine (–NH) and carboxyl (–COOH) functional groups, along with a side chain (R group) specific to each amino acid. The key elements of an amino acid are carbon (C), hydrogen (H), oxygen (O), and nitrogen (N), although other elements are found in the side chains of certain amino acids. About 500 naturally occurring amino acids are known (though only 20 appear in the genetic code) and can be classified in many ways. They can be classified according to the core structural functional groups' locations as alpha- (α-), beta- (β-), gamma- (γ-) or delta- (δ-) amino acids; other categories relate to polarity, pH level, and side chain group type (aliphatic, acyclic, aromatic, containing hydroxyl or sulfur, etc.). In the form of proteins, amino acid residues form the second-largest component (water is the largest) of human muscles and other tissues. Beyond their role as residues in proteins, amino acids participate in a number of processes such as neurotransmitter transport and biosynthesis.

In biochemistry, amino acids having both the amine and the carboxylic acid groups attached to the first (alpha-) carbon atom have particular importance. They are known as 2-, alpha-, or α-amino acids (generic formula HNCHRCOOH in most cases, where R is an organic substituent known as a "side chain"); often the term "amino acid" is used to refer specifically to these. They include the 22 proteinogenic ("protein-building") amino acids, which combine into peptide chains ("polypeptides") to form the building blocks of a vast array of proteins. These are all -stereoisomers ("left-handed" isomers), although a few -amino acids ("right-handed") occur in bacterial envelopes, as a neuromodulator (-serine), and in some antibiotics.

Twenty of the proteinogenic amino acids are encoded directly by triplet codons in the genetic code and are known as "standard" amino acids. The other two ("nonstandard" or "non-canonical") are selenocysteine (present in many prokaryotes as well as most eukaryotes, but not coded directly by DNA), and pyrrolysine (found only in some archaea and one bacterium). Pyrrolysine and selenocysteine are encoded via variant codons; for example, selenocysteine is encoded by stop codon and SECIS element. "N"-formylmethionine (which is often the initial amino acid of proteins in bacteria, mitochondria, and chloroplasts) is generally considered as a form of methionine rather than as a separate proteinogenic amino acid. Codon–tRNA combinations not found in nature can also be used to "expand" the genetic code and form novel proteins known as alloproteins incorporating non-proteinogenic amino acids.

Many important proteinogenic and non-proteinogenic amino acids have biological functions. For example, in the human brain, glutamate (standard glutamic acid) and gamma-aminobutyric acid ("GABA", nonstandard gamma-amino acid) are, respectively, the main excitatory and inhibitory neurotransmitters. Hydroxyproline, a major component of the connective tissue collagen, is synthesised from proline. Glycine is a biosynthetic precursor to porphyrins used in red blood cells. Carnitine is used in lipid transport.

Nine proteinogenic amino acids are called "essential" for humans because they cannot be produced from other compounds by the human body and so must be taken in as food. Others may be conditionally essential for certain ages or medical conditions. Essential amino acids may also differ between species.

Because of their biological significance, amino acids are important in nutrition and are commonly used in nutritional supplements, fertilizers, feed, and food technology. Industrial uses include the production of drugs, biodegradable plastics, and chiral catalysts.

The first few amino acids were discovered in the early 19th century. In 1806, French chemists Louis-Nicolas Vauquelin and Pierre Jean Robiquet isolated a compound in asparagus that was subsequently named asparagine, the first amino acid to be discovered. Cystine was discovered in 1810, although its monomer, cysteine, remained undiscovered until 1884. Glycine and leucine were discovered in 1820. The last of the 20 common amino acids to be discovered was threonine in 1935 by William Cumming Rose, who also determined the essential amino acids and established the minimum daily requirements of all amino acids for optimal growth.

The unity of the chemical category was recognized by Wurtz in 1865, but he gave no particular name to it. First use of the term "amino acid" in the English language dates from 1898, while the German term, "Aminosäure", was used earlier. Proteins were found to yield amino acids after enzymatic digestion or acid hydrolysis. In 1902, Emil Fischer and Franz Hofmeister independently proposed that proteins are formed from many amino acids, whereby bonds are formed between the amino group of one amino acid with the carboxyl group of another, resulting in a linear structure that Fischer termed "peptide".

In the structure shown at the top of the page, R represents a side chain specific to each amino acid. The carbon atom next to the carboxyl group (which is therefore numbered 2 in the carbon chain starting from that functional group) is called the α–carbon. Amino acids containing an amino group bonded directly to the alpha carbon are referred to as "alpha amino acids". These include amino acids such as proline which contain secondary amines, which used to be often referred to as "imino acids".

The alpha amino acids are the most common form found in nature, but only when occurring in the -isomer. The alpha carbon is a chiral carbon atom, with the exception of glycine which has two indistinguishable hydrogen atoms on the alpha carbon. Therefore, all alpha amino acids but glycine can exist in either of two enantiomers, called or amino acids ("relative configuration"), which are mirror images of each other ("see also Chirality"). While -amino acids represent all of the amino acids found in proteins during translation in the ribosome, -amino acids are found in some proteins produced by enzyme posttranslational modifications after translation and translocation to the endoplasmic reticulum, as in exotic sea-dwelling organisms such as cone snails. They are also abundant components of the peptidoglycan cell walls of bacteria, and -serine may act as a neurotransmitter in the brain. -amino acids are used in racemic crystallography to create centrosymmetric crystals, which (depending on the protein) may allow for easier and more robust protein structure determination. The and convention for amino acid configuration refers not to the optical activity of the amino acid itself but rather to the optical activity of the isomer of glyceraldehyde from which that amino acid can, in theory, be synthesized (-glyceraldehyde is dextrorotatory; -glyceraldehyde is levorotatory).
In alternative fashion, the ("S") and ("R") designators are used to indicate the "absolute configuration". Almost all of the amino acids in proteins are ("S") at the α carbon, with cysteine being ("R") and glycine non-chiral. Cysteine has its side chain in the same geometric position as the other amino acids, but the "R"/"S" terminology is reversed because of the higher atomic number of sulfur compared to the carboxyl oxygen gives the side chain a higher priority by the Cahn–Ingold–Prelog rules, whereas the atoms in other side chains give them lower priority compared to the carboxyl group.

Amino acids are designated as α- when the nitrogen atom is attached to the carbon atom adjacent to the carboxyl group: in this case the compound contains the substructure N–C–CO. Amino acids with the sub-structure N–C–C–CO are classified as β- amino acids. γ-Amino acids contain the substructure N–C–C–C–CO, and so on.

Amino acids are usually classified by the properties of their side chain into four groups. The side chain can make an amino acid a weak acid or a weak base, and a hydrophile if the side chain is polar or a hydrophobe if it is nonpolar. The chemical structures of the 22 standard amino acids, along with their chemical properties, are described more fully in the article on these proteinogenic amino acids.

The phrase "branched-chain amino acids" or BCAA refers to the amino acids having aliphatic side chains that are linear; these are leucine, isoleucine, and valine. Proline is the only proteinogenic amino acid whose side-group links to the α-amino group and, thus, is also the only proteinogenic amino acid containing a secondary amine at this position. In chemical terms, proline is, therefore, an imino acid, since it lacks a primary amino group, although it is still classed as an amino acid in the current biochemical nomenclature, and may also be called an ""N"-alkylated alpha-amino acid".

In aqueous solution amino acids exist in two forms (as illustrated at the right), the molecular form and the zwitterion form in equilibrium with each other. The two forms coexist over the pH range to , which for glycine is pH0–12. The ratio of the concentrations of the two isomers is independent of pH. The value of this ratio cannot be determined experimentally.

Because all amino acids contain amine and carboxylic acid functional groups, they are amphiprotic. At (approximately 2.2) there will be equal concentration of the species and and at (approximately 10) there will be equal concentration of the species and . It follows that the neutral molecule and the zwitterion are effectively the only species present at biological pH.

It is generally assumed that the concentration of the zwitterion is much greater than the concentration of the neutral molecule on the basis of comparisons with the known p"K" values of amines and carboxylic acids.

The variation in titration curves when the amino acids can be grouped by category. With the exception of tyrosine, using titration to distinguish among hydrophobic amino acids is problematic.

At pH values between the two p"K" values, the zwitterion predominates, but coexists in dynamic equilibrium with small amounts of net negative and net positive ions. At the exact midpoint between the two p"K" values, the trace amount of net negative and trace of net positive ions exactly balance, so that average net charge of all forms present is zero. This pH is known as the isoelectric point p"I", so p"I" = (p"K" + p"K"). The individual amino acids all have slightly different p"K" values and therefore have different isoelectric points. For amino acids with charged side chains, the p"K" of the side chain is involved. Thus for aspartate or glutamate with negative side chains, p"I" = (p"K" + p"K"), where p"K" is the side chain p"K". Cysteine also has potentially negative side chain with p"K" = 8.14, so p"I" should be calculated as for aspartate and glutamate, even though the side chain is not significantly charged at physiological pH. For histidine, lysine, and arginine with positive side chains, p"I" = (p"K" + p"K"). Amino acids have zero mobility in electrophoresis at their isoelectric point, although this behaviour is more usually exploited for peptides and proteins than single amino acids. Zwitterions have minimum solubility at their isoelectric point, and some amino acids (in particular, with nonpolar side chains) can be isolated by precipitation from water by adjusting the pH to the required isoelectric point.

Amino acids are the structural units (monomers) that make up proteins. They join together to form short polymer chains called peptides or longer chains called either polypeptides or proteins. These polymers are linear and unbranched, with each amino acid within the chain attached to two neighboring amino acids. The process of making proteins encoded by DNA/RNA genetic material is called "translation" and involves the step-by-step addition of amino acids to a growing protein chain by a ribozyme that is called a ribosome. The order in which the amino acids are added is read through the genetic code from an mRNA template, which is an RNA copy of one of the organism's genes.

Twenty-two amino acids are naturally incorporated into polypeptides and are called proteinogenic or natural amino acids. Of these, 20 are encoded by the universal genetic code. The remaining 2, selenocysteine and pyrrolysine, are incorporated into proteins by unique synthetic mechanisms. Selenocysteine is incorporated when the mRNA being translated includes a SECIS element, which causes the UGA codon to encode selenocysteine instead of a stop codon. Pyrrolysine is used by some methanogenic archaea in enzymes that they use to produce methane. It is coded for with the codon UAG, which is normally a stop codon in other organisms. This UAG codon is followed by a PYLIS downstream sequence.

Aside from the 22 proteinogenic amino acids, many "non-proteinogenic" amino acids are known. Those either are not found in proteins (for example carnitine, GABA, levothyroxine) or are not produced directly and in isolation by standard cellular machinery (for example, hydroxyproline and selenomethionine).

Non-proteinogenic amino acids that are found in proteins are formed by post-translational modification, which is modification after translation during protein synthesis. These modifications are often essential for the function or regulation of a protein. For example, the carboxylation of glutamate allows for better binding of calcium cations, and collagen contains hydroxyproline, generated by hydroxylation of proline. Another example is the formation of hypusine in the translation initiation factor EIF5A, through modification of a lysine residue. Such modifications can also determine the localization of the protein, e.g., the addition of long hydrophobic groups can cause a protein to bind to a phospholipid membrane.

Some non-proteinogenic amino acids are not found in proteins. Examples include 2-aminoisobutyric acid and the neurotransmitter gamma-aminobutyric acid. Non-proteinogenic amino acids often occur as intermediates in the metabolic pathways for standard amino acids – for example, ornithine and citrulline occur in the urea cycle, part of amino acid catabolism (see below). A rare exception to the dominance of α-amino acids in biology is the β-amino acid beta alanine (3-aminopropanoic acid), which is used in plants and microorganisms in the synthesis of pantothenic acid (vitamin B), a component of coenzyme A.

-isomers are uncommon in live organisms, gramicidin is a polypeptide made up from mixture of - and -amino acids. Other compounds containing -amino acids are tyrocidine and valinomycin. These compounds disrupt bacterial cell walls, particularly in Gram-positive bacteria. , only 837 -amino acids were found in the Swiss-Prot database out of a total of 187 million amino acids analysed.

The 20 amino acids that are encoded directly by the codons of the universal genetic code are called "standard" or "canonical" amino acids. A modified form of methionine ("N"-formylmethionine) is often incorporated in place of methionine as the initial amino acid of proteins in bacteria, mitochondria and chloroplasts. Other amino acids are called "nonstandard" or "non-canonical". Most of the nonstandard amino acids are also non-proteinogenic (i.e. they cannot be incorporated into proteins during translation), but two of them are proteinogenic, as they can be incorporated translationally into proteins by exploiting information not encoded in the universal genetic code.

The two nonstandard proteinogenic amino acids are selenocysteine (present in many non-eukaryotes as well as most eukaryotes, but not coded directly by DNA) and pyrrolysine (found only in some archaea and one bacterium). The incorporation of these nonstandard amino acids is rare. For example, 25 human proteins include selenocysteine in their primary structure, and the structurally characterized enzymes (selenoenzymes) employ selenocysteine as the catalytic moiety in their active sites. Pyrrolysine and selenocysteine are encoded via variant codons. For example, selenocysteine is encoded by stop codon and SECIS element.

When taken up into the human body from the diet, the 20 standard amino acids either are used to synthesize proteins, other biomolecules, or are oxidized to urea and carbon dioxide as a source of energy. The oxidation pathway starts with the removal of the amino group by a transaminase; the amino group is then fed into the urea cycle. The other product of transamidation is a keto acid that enters the citric acid cycle. Glucogenic amino acids can also be converted into glucose, through gluconeogenesis. Of the 20 standard amino acids, nine (His, Ile, Leu, Lys, Met, Phe, Thr, Trp and Val) are called essential amino acids because the human body cannot synthesize them from other compounds at the level needed for normal growth, so they must be obtained from food. In addition, cysteine, tyrosine, and arginine are considered semiessential amino acids, and taurine a semiessential aminosulfonic acid in children. The metabolic pathways that synthesize these monomers are not fully developed. The amounts required also depend on the age and health of the individual, so it is hard to make general statements about the dietary requirement for some amino acids. Dietary exposure to the nonstandard amino acid BMAA has been linked to human neurodegenerative diseases, including ALS.

In humans, non-protein amino acids also have important roles as metabolic intermediates, such as in the biosynthesis of the neurotransmitter gamma-aminobutyric acid (GABA). Many amino acids are used to synthesize other molecules, for example:

Some nonstandard amino acids are used as defenses against herbivores in plants. For example, canavanine is an analogue of arginine that is found in many legumes, and in particularly large amounts in "Canavalia gladiata" (sword bean). This amino acid protects the plants from predators such as insects and can cause illness in people if some types of legumes are eaten without processing. The non-protein amino acid mimosine is found in other species of legume, in particular "Leucaena leucocephala". This compound is an analogue of tyrosine and can poison animals that graze on these plants.

Amino acids are used for a variety of applications in industry, but their main use is as additives to animal feed. This is necessary, since many of the bulk components of these feeds, such as soybeans, either have low levels or lack some of the essential amino acids: lysine, methionine, threonine, and tryptophan are most important in the production of these feeds. In this industry, amino acids are also used to chelate metal cations in order to improve the absorption of minerals from supplements, which may be required to improve the health or production of these animals.

The food industry is also a major consumer of amino acids, in particular, glutamic acid, which is used as a flavor enhancer, and aspartame (aspartylphenylalanine 1-methyl ester) as a low-calorie artificial sweetener. Similar technology to that used for animal nutrition is employed in the human nutrition industry to alleviate symptoms of mineral deficiencies, such as anemia, by improving mineral absorption and reducing negative side effects from inorganic mineral supplementation.

The chelating ability of amino acids has been used in fertilizers for agriculture to facilitate the delivery of minerals to plants in order to correct mineral deficiencies, such as iron chlorosis. These fertilizers are also used to prevent deficiencies from occurring and improving the overall health of the plants. The remaining production of amino acids is used in the synthesis of drugs and cosmetics.

Similarly, some amino acids derivatives are used in pharmaceutical industry. They include 5-HTP (5-hydroxytryptophan) used for experimental treatment of depression, -DOPA (-dihydroxyphenylalanine) for Parkinson's treatment, and eflornithine drug that inhibits ornithine decarboxylase and used in the treatment of sleeping sickness.

Since 2001, 40 non-natural amino acids have been added into protein by creating a unique codon (recoding) and a corresponding transfer-RNA:aminoacyl – tRNA-synthetase pair to encode it with diverse physicochemical and biological properties in order to be used as a tool to exploring protein structure and function or to create novel or enhanced proteins.

Nullomers are codons that in theory code for an amino acid, however in nature there is a selective bias against using this codon in favor of another, for example bacteria prefer to use CGA instead of AGA to code for arginine. This creates some sequences that do not appear in the genome. This characteristic can be taken advantage of and used to create new selective cancer-fighting drugs and to prevent cross-contamination of DNA samples from crime-scene investigations.

Amino acids are important as low-cost feedstocks. These compounds are used in chiral pool synthesis as enantiomerically pure building blocks.

Amino acids have been investigated as precursors chiral catalysts, such as for asymmetric hydrogenation reactions, although no commercial applications exist.

Amino acids have been considered as components of biodegradable polymers, which have applications as environmentally friendly packaging and in medicine in drug delivery and the construction of prosthetic implants. An interesting example of such materials is polyaspartate, a water-soluble biodegradable polymer that may have applications in disposable diapers and agriculture. Due to its solubility and ability to chelate metal ions, polyaspartate is also being used as a biodegradeable antiscaling agent and a corrosion inhibitor. In addition, the aromatic amino acid tyrosine has been considered as a possible replacement for phenols such as bisphenol A in the manufacture of polycarbonates.

The commercial production of amino acids usually relies on mutant bacteria that overproduce individual amino acids using glucose as a carbon source. Some amino acids are produced by enzymatic conversions of synthetic intermediates. 2-Aminothiazoline-4-carboxylic acid is an intermediate in one industrial synthesis of -cysteine for example. Aspartic acid is produced by the addition of ammonia to fumarate using a lyase.

In plants, nitrogen is first assimilated into organic compounds in the form of glutamate, formed from alpha-ketoglutarate and ammonia in the mitochondrion. For other amino acids, plants use transaminases to move the amino group from glutamate to another alpha-keto acids. For example, aspartate aminotransferase converts glutamate and oxaloacetate to alpha-ketoglutarate and aspartate. Other organisms use transaminases for amino acid synthesis, too.

Nonstandard amino acids are usually formed through modifications to standard amino acids. For example, homocysteine is formed through the transsulfuration pathway or by the demethylation of methionine via the intermediate metabolite "S"-adenosylmethionine, while hydroxyproline is made by a post translational modification of proline.

Microorganisms and plants synthesize many uncommon amino acids. For example, some microbes make 2-aminoisobutyric acid and lanthionine, which is a sulfide-bridged derivative of alanine. Both of these amino acids are found in peptidic lantibiotics such as alamethicin. However, in plants, 1-aminocyclopropane-1-carboxylic acid is a small disubstituted cyclic amino acid that is a key intermediate in the production of the plant hormone ethylene.

Amino acids undergo the reactions expected of the constituent functional groups. The types of these reactions are determined by the groups on these side chains and are, therefore, different between the various types of amino acid.

As both the amine and carboxylic acid groups of amino acids can react to form amide bonds, one amino acid molecule can react with another and become joined through an amide linkage. This polymerization of amino acids is what creates proteins. This condensation reaction yields the newly formed peptide bond and a molecule of water. In cells, this reaction does not occur directly; instead, the amino acid is first activated by attachment to a transfer RNA molecule through an ester bond. This aminoacyl-tRNA is produced in an ATP-dependent reaction carried out by an aminoacyl tRNA synthetase. This aminoacyl-tRNA is then a substrate for the ribosome, which catalyzes the attack of the amino group of the elongating protein chain on the ester bond. As a result of this mechanism, all proteins made by ribosomes are synthesized starting at their "N"-terminus and moving toward their "C"-terminus.

However, not all peptide bonds are formed in this way. In a few cases, peptides are synthesized by specific enzymes. For example, the tripeptide glutathione is an essential part of the defenses of cells against oxidative stress. This peptide is synthesized in two steps from free amino acids. In the first step, gamma-glutamylcysteine synthetase condenses cysteine and glutamic acid through a peptide bond formed between the side chain carboxyl of the glutamate (the gamma carbon of this side chain) and the amino group of the cysteine. This dipeptide is then condensed with glycine by glutathione synthetase to form glutathione.

In chemistry, peptides are synthesized by a variety of reactions. One of the most-used in solid-phase peptide synthesis uses the aromatic oxime derivatives of amino acids as activated units. These are added in sequence onto the growing peptide chain, which is attached to a solid resin support. The ability to easily synthesize vast numbers of different peptides by varying the types and order of amino acids (using combinatorial chemistry) has made peptide synthesis particularly important in creating libraries of peptides for use in drug discovery through high-throughput screening.

The combination of functional groups allow amino acids to be effective polydentate ligands for metal–amino acid chelates.
The multiple side chains of amino acids can also undergo chemical reactions.

Amino acids must first pass out of organelles and cells into blood circulation via amino acid transporters, since the amine and carboxylic acid groups are typically ionized. Degradation of an amino acid, occurring in the liver and kidneys, often involves deamination by moving its amino group to alpha-ketoglutarate, forming glutamate. This process involves transaminases, often the same as those used in amination during synthesis. In many vertebrates, the amino group is then removed through the urea cycle and is excreted in the form of urea. However, amino acid degradation can produce uric acid or ammonia instead. For example, serine dehydratase converts serine to pyruvate and ammonia. After removal of one or more amino groups, the remainder of the molecule can sometimes be used to synthesize new amino acids, or it can be used for energy by entering glycolysis or the citric acid cycle, as detailed in image at right.

Amino acids are bidentate ligands, forming transition metal amino acid complexes. 

The ca. 20 canonical amino acids can be classified according to their properties. Important factors are charge, hydrophilicity or hydrophobicity, size, and functional groups. These properties are important for protein structure and protein–protein interactions. The water-soluble proteins tend to have their hydrophobic residues (Leu, Ile, Val, Phe, and Trp) buried in the middle of the protein, whereas hydrophilic side chains are exposed to the aqueous solvent. (Note that in biochemistry, a residue refers to a specific monomer within the polymeric chain of a polysaccharide, protein or nucleic acid.) The integral membrane proteins tend to have outer rings of exposed hydrophobic amino acids that anchor them into the lipid bilayer. In the case partway between these two extremes, some peripheral membrane proteins have a patch of hydrophobic amino acids on their surface that locks onto the membrane. In similar fashion, proteins that have to bind to positively charged molecules have surfaces rich with negatively charged amino acids like glutamate and aspartate, while proteins binding to negatively charged molecules have surfaces rich with positively charged chains like lysine and arginine. There are different hydrophobicity scales of amino acid residues.

Some amino acids have special properties such as cysteine, that can form covalent disulfide bonds to other cysteine residues, proline that forms a cycle to the polypeptide backbone, and glycine that is more flexible than other amino acids.

Many proteins undergo a range of posttranslational modifications, when additional chemical groups are attached to the amino acids in proteins. Some modifications can produce hydrophobic lipoproteins, or hydrophilic glycoproteins. These type of modification allow the reversible targeting of a protein to a membrane. For example, the addition and removal of the fatty acid palmitic acid to cysteine residues in some signaling proteins causes the proteins to attach and then detach from cell membranes.

Two additional amino acids are in some species coded for by codons that are usually interpreted as stop codons:

In addition to the specific amino acid codes, placeholders are used in cases where chemical or crystallographic analysis of a peptide or protein cannot conclusively determine the identity of a residue. They are also used to summarise conserved protein sequence motifs. The use of single letters to indicate sets of similar residues is similar to the use of abbreviation codes for degenerate bases.

Unk is sometimes used instead of Xaa, but is less standard.

In addition, many nonstandard amino acids have a specific code. For example, several peptide drugs, such as Bortezomib and MG132, are artificially synthesized and retain their protecting groups, which have specific codes. Bortezomib is Pyz–Phe–boroLeu, and MG132 is Z–Leu–Leu–Leu–al. To aid in the analysis of protein structure, photo-reactive amino acid analogs are available. These include photoleucine (pLeu) and photomethionine (pMet).


</doc>
<doc id="1208" url="https://en.wikipedia.org/wiki?curid=1208" title="Alan Turing">
Alan Turing

Alan Mathison Turing (; 23 June 1912 – 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher, and theoretical biologist. Turing was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer. Turing is widely considered to be the father of theoretical computer science and artificial intelligence. Despite these accomplishments, he was never fully recognised in his home country during his lifetime due to the prevalence of homophobia at the time and because much of his work was covered by the Official Secrets Act.

During the Second World War, Turing worked for the Government Code and Cypher School (GC&CS) at Bletchley Park, Britain's codebreaking centre that produced Ultra intelligence. For a time he led Hut 8, the section that was responsible for German naval cryptanalysis. Here, he devised a number of techniques for speeding the breaking of German ciphers, including improvements to the pre-war Polish bombe method, an electromechanical machine that could find settings for the Enigma machine.

Turing played a crucial role in cracking intercepted coded messages that enabled the Allies to defeat the Nazis in many crucial engagements, including the Battle of the Atlantic, and in so doing helped win the war. Due to the problems of counterfactual history, it is hard to estimate the precise effect Ultra intelligence had on the war, but at the upper end it has been estimated that this work shortened the war in Europe by more than two years and saved over 14 million lives.

After the war Turing worked at the National Physical Laboratory, where he designed the Automatic Computing Engine. The Automatic Computing Engine was one of the first designs for a stored-program computer. In 1948, Turing joined Max Newman's Computing Machine Laboratory, at the Victoria University of Manchester, where he helped develop the Manchester computers and became interested in mathematical biology. He wrote a paper on the chemical basis of morphogenesis and predicted oscillating chemical reactions such as the Belousov–Zhabotinsky reaction, first observed in the 1960s.

Turing was prosecuted in 1952 for homosexual acts; the Labouchere Amendment of 1885 had mandated that "gross indecency" was a criminal offence in the UK. He accepted chemical castration treatment, with DES, as an alternative to prison. Turing died in 1954, 16 days before his 42nd birthday, from cyanide poisoning. An inquest determined his death as a suicide, but it has been noted that the known evidence is also consistent with accidental poisoning.

In 2009, following an Internet campaign, British Prime Minister Gordon Brown made an official public apology on behalf of the British government for "the appalling way he was treated". Queen Elizabeth II granted Turing a posthumous pardon in 2013. The "Alan Turing law" is now an informal term for a 2017 law in the United Kingdom that retroactively pardoned men cautioned or convicted under historical legislation that outlawed homosexual acts.

Turing was born in Maida Vale, London, while his father, Julius Mathison Turing (1873–1947), was on leave from his position with the Indian Civil Service (ICS) at Chatrapur, then in the Madras Presidency and presently in Odisha state, in India. Turing's father was the son of a clergyman, the Rev. John Robert Turing, from a Scottish family of merchants that had been based in the Netherlands and included a baronet. Turing's mother, Julius's wife, was Ethel Sara Turing ( 1881–1976), daughter of Edward Waller Stoney, chief engineer of the Madras Railways. The Stoneys were a Protestant Anglo-Irish gentry family from both County Tipperary and County Longford, while Ethel herself had spent much of her childhood in County Clare.

Julius's work with the ICS brought the family to British India, where his grandfather had been a general in the Bengal Army. However, both Julius and Ethel wanted their children to be brought up in Britain, so they moved to Maida Vale, London, where Alan Turing was born on 23 June 1912, as recorded by a blue plaque on the outside of the house of his birth, later the Colonnade Hotel. Turing had an elder brother, John (the father of Sir John Dermot Turing, 12th Baronet of the Turing baronets).

Turing's father's civil service commission was still active and during Turing's childhood years Turing's parents travelled between Hastings in the United Kingdom and India, leaving their two sons to stay with a retired Army couple. At Hastings, Turing stayed at Baston Lodge, Upper Maze Hill, St Leonards-on-Sea, now marked with a blue plaque. The plaque was unveiled on 23 June 2012, the centenary of Turing's birth.

Very early in life, Turing showed signs of the genius that he was later to display prominently. His parents purchased a house in Guildford in 1927, and Turing lived there during school holidays. The location is also marked with a blue plaque.

Turing's parents enrolled him at St Michael's, a day school at 20 Charles Road, St Leonards-on-Sea, at the age of six. The headmistress recognised his talent early on, as did many of his subsequent teachers.

Between January 1922 and 1926, Turing was educated at Hazelhurst Preparatory School, an independent school in the village of Frant in Sussex (now East Sussex). In 1926, at the age of 13, he went on to Sherborne School, a boarding independent school in the market town of Sherborne in Dorset. The first day of term coincided with the 1926 General Strike, in Britain, but Turing was so determined to attend, that he rode his bicycle unaccompanied from Southampton to Sherborne, stopping overnight at an inn.

Turing's natural inclination towards mathematics and science did not earn him respect from some of the teachers at Sherborne, whose definition of education placed more emphasis on the classics. His headmaster wrote to his parents: "I hope he will not fall between two stools. If he is to stay at public school, he must aim at becoming "educated". If he is to be solely a "Scientific Specialist", he is wasting his time at a public school". Despite this, Turing continued to show remarkable ability in the studies he loved, solving advanced problems in 1927 without having studied even elementary calculus. In 1928, aged 16, Turing encountered Albert Einstein's work; not only did he grasp it, but it is possible that he managed to deduce Einstein's questioning of Newton's laws of motion from a text in which this was never made explicit.

At Sherborne, Turing formed a significant friendship with fellow pupil Christopher Collan Morcom (13 July 1911 – 13 February 1930), who has been described as Turing's "first love". Their relationship provided inspiration in Turing's future endeavours, but it was cut short by Morcom's death, in February 1930, from complications of bovine tuberculosis, contracted after drinking infected cow's milk some years previously.

The event caused Turing great sorrow. He coped with his grief by working that much harder on the topics of science and mathematics that he had shared with Morcom. In a letter to Morcom's mother, Frances Isobel Morcom (née Swan), Turing wrote:

Turing's relationship with Morcom's mother continued long after Morcom's death, with her sending gifts to Turing, and him sending letters, typically on Morcom's birthdays. A day before the third anniversary of Morcom's death (13 February 1933), he wrote to Mrs. Morcom: 

Some have speculated that Morcom's death was the cause of Turing's atheism and materialism. Apparently, at this point in his life he still believed in such concepts as a spirit, independent of the body and surviving death. In a later letter, also written to Morcom's mother, Turing wrote: 

After Sherborne, Turing studied as an undergraduate from 1931 to 1934 at King's College, Cambridge, where he was awarded first-class honours in mathematics. In 1935, at the age of 22, he was elected a Fellow of King's College on the strength of a dissertation in which he proved the central limit theorem. Unknown to the committee, the theorem had already been proven, in 1922, by Jarl Waldemar Lindeberg. A blue plaque at the college was unveiled on the centenary of his birth on 23 June 2012 and is now installed at the college's Keynes Building on King's Parade.

In 1936, Turing published his paper "On Computable Numbers, with an Application to the Entscheidungsproblem". It was published in the "Proceedings of the London Mathematical Society" journal in two parts, the first on 30 November and the second on 23 December. In this paper, Turing reformulated Kurt Gödel's 1931 results on the limits of proof and computation, replacing Gödel's universal arithmetic-based formal language with the formal and simple hypothetical devices that became known as Turing machines. The "Entscheidungsproblem" (decision problem) was originally posed by German mathematician David Hilbert in 1928. Turing proved that his "universal computing machine" would be capable of performing any conceivable mathematical computation if it were representable as an algorithm. He went on to prove that there was no solution to the "decision problem" by first showing that the halting problem for Turing machines is undecidable: it is not possible to decide algorithmically whether a Turing machine will ever halt. This paper has been called "easily the most influential math paper in history".
Although Turing's proof was published shortly after Alonzo Church's equivalent proof using his lambda calculus, Turing's approach is considerably more accessible and intuitive than Church's. It also included a notion of a 'Universal Machine' (now known as a universal Turing machine), with the idea that such a machine could perform the tasks of any other computation machine (as indeed could Church's lambda calculus). According to the Church–Turing thesis, Turing machines and the lambda calculus are capable of computing anything that is computable. John von Neumann acknowledged that the central concept of the modern computer was due to Turing's paper. To this day, Turing machines are a central object of study in theory of computation.

From September 1936 to July 1938, Turing spent most of his time studying under Church at Princeton University, in the second year as a Jane Eliza Procter Visiting Fellow. In addition to his purely mathematical work, he studied cryptology and also built three of four stages of an electro-mechanical binary multiplier. In June 1938, he obtained his PhD from the Department of Mathematics at Princeton; his dissertation, "Systems of Logic Based on Ordinals", introduced the concept of ordinal logic and the notion of relative computing, in which Turing machines are augmented with so-called oracles, allowing the study of problems that cannot be solved by Turing machines. John von Neumann wanted to hire him as his postdoctoral assistant, but he went back to the United Kingdom.

When Turing returned to Cambridge, he attended lectures given in 1939 by Ludwig Wittgenstein about the foundations of mathematics. The lectures have been reconstructed verbatim, including interjections from Turing and other students, from students' notes. Turing and Wittgenstein argued and disagreed, with Turing defending formalism and Wittgenstein propounding his view that mathematics does not discover any absolute truths, but rather invents them.

During the Second World War, Turing was a leading participant in the breaking of German ciphers at Bletchley Park. The historian and wartime codebreaker Asa Briggs has said, "You needed exceptional talent, you needed genius at Bletchley and Turing's was that genius."

From September 1938, Turing worked part-time with the Government Code and Cypher School (GC&CS), the British codebreaking organisation. He concentrated on cryptanalysis of the Enigma cipher machine used by Nazi Germany, together with Dilly Knox, a senior GC&CS codebreaker. Soon after the July 1939 meeting near Warsaw at which the Polish Cipher Bureau gave the British and French details of the wiring of Enigma machine's rotors and their method of decrypting Enigma machine's messages, Turing and Knox developed a broader solution. The Polish method relied on an insecure indicator procedure that the Germans were likely to change, which they in fact did in May 1940. Turing's approach was more general, using crib-based decryption for which he produced the functional specification of the bombe (an improvement on the Polish Bomba).

On 4 September 1939, the day after the UK declared war on Germany, Turing reported to Bletchley Park, the wartime station of GC&CS.
Specifying the bombe was the first of five major cryptanalytical advances that Turing made during the war. The others were: deducing the indicator procedure used by the German navy; developing a statistical procedure dubbed "Banburismus" for making much more efficient use of the bombes; developing a procedure dubbed "Turingery" for working out the cam settings of the wheels of the Lorenz SZ 40/42 ("Tunny") cipher machine and, towards the end of the war, the development of a portable secure voice scrambler at Hanslope Park that was codenamed "Delilah".

By using statistical techniques to optimise the trial of different possibilities in the code breaking process, Turing made an innovative contribution to the subject. He wrote two papers discussing mathematical approaches, titled "The Applications of Probability to Cryptography" and "Paper on Statistics of Repetitions", which were of such value to GC&CS and its successor GCHQ that they were not released to the UK National Archives until April 2012, shortly before the centenary of his birth. A GCHQ mathematician, "who identified himself only as Richard," said at the time that the fact that the contents had been restricted for some 70 years demonstrated their importance, and their relevance to post-war cryptanalysis: 

Turing had a reputation for eccentricity at Bletchley Park. He was known to his colleagues as "Prof" and his treatise on Enigma was known as the "Prof's Book". According to historian Ronald Lewin, Jack Good, a cryptanalyst who worked with Turing, said of his colleague:

Peter Hilton recounted his experience working with Turing in Hut 8 in his "Reminiscences of Bletchley Park" from "A Century of Mathematics in America:"

Hilton echoed similar thoughts in the Nova PBS documentary "Decoding Nazi Secrets".

While working at Bletchley, Turing, who was a talented long-distance runner, occasionally ran the to London when he was needed for meetings, and he was capable of world-class marathon standards. Turing tried out for the 1948 British Olympic team but he was hampered by an injury. His tryout time for the marathon was only 11 minutes slower than British silver medallist Thomas Richards' Olympic race time of 2 hours 35 minutes. He was Walton Athletic Club's best runner, a fact discovered when he passed the group while running alone.

In 1946, Turing was appointed an Officer of the Order of the British Empire (OBE) by King George VI for his wartime services, but his work remained secret for many years.

Within weeks of arriving at Bletchley Park, Turing had specified an electromechanical machine called the bombe, which could break Enigma more effectively than the Polish "bomba kryptologiczna", from which its name was derived. The bombe, with an enhancement suggested by mathematician Gordon Welchman, became one of the primary tools, and the major automated one, used to attack Enigma-enciphered messages.

The bombe searched for possible correct settings used for an Enigma message (i.e., rotor order, rotor settings and plugboard settings) using a suitable "crib": a fragment of probable plaintext. For each possible setting of the rotors (which had on the order of 10 states, or 10 states for the four-rotor U-boat variant), the bombe performed a chain of logical deductions based on the crib, implemented electromechanically.

The bombe detected when a contradiction had occurred and ruled out that setting, moving on to the next. Most of the possible settings would cause contradictions and be discarded, leaving only a few to be investigated in detail. A contradiction would occur when an enciphered letter would be turned back into the same plaintext letter, which was impossible with the Enigma. The first bombe was installed on 18 March 1940.

By late 1941, Turing and his fellow cryptanalysts Gordon Welchman, Hugh Alexander and Stuart Milner-Barry were frustrated. Building on the work of the Poles, they had set up a good working system for decrypting Enigma signals, but their limited staff and bombes meant they could not translate all the signals. In the summer, they had considerable success, and shipping losses had fallen to under 100,000 tons a month; however, they badly needed more resources to keep abreast of German adjustments. They had tried to get more people and fund more bombes through the proper channels, but had failed.

On 28 October they wrote directly to Winston Churchill explaining their difficulties, with Turing as the first named. They emphasised how small their need was compared with the vast expenditure of men and money by the forces and compared with the level of assistance they could offer to the forces. As Andrew Hodges, biographer of Turing, later wrote, "This letter had an electric effect." Churchill wrote a memo to General Ismay, which read: "ACTION THIS DAY. Make sure they have all they want on extreme priority and report to me that this has been done." On 18 November, the chief of the secret service reported that every possible measure was being taken. The cryptographers at Bletchley Park did not know of the Prime Minister's response, but as Milner-Barry recalled, "All that we did notice was that almost from that day the rough ways began miraculously to be made smooth." More than two hundred bombes were in operation by the end of the war.

Turing decided to tackle the particularly difficult problem of German naval Enigma "because no one else was doing anything about it and I could have it to myself". In December 1939, Turing solved the essential part of the naval indicator system, which was more complex than the indicator systems used by the other services.

That same night, he also conceived of the idea of "Banburismus", a sequential statistical technique (what Abraham Wald later called sequential analysis) to assist in breaking the naval Enigma, "though I was not sure that it would work in practice, and was not, in fact, sure until some days had actually broken." For this, he invented a measure of weight of evidence that he called the "ban". "Banburismus" could rule out certain sequences of the Enigma rotors, substantially reducing the time needed to test settings on the bombes. Later this sequential process of accumulating sufficient weight of evidence using decibans (one tenth of a ban) was used in Cryptanalysis of the Lorenz cipher

Turing travelled to the United States in November 1942 and worked with US Navy cryptanalysts on the naval Enigma and bombe construction in Washington; he also visited their Computing Machine Laboratory in Dayton, Ohio.

Turing's reaction to the American bombe design was far from enthusiastic:
During this trip, he also assisted at Bell Labs with the development of secure speech devices. He returned to Bletchley Park in March 1943. During his absence, Hugh Alexander had officially assumed the position of head of Hut 8, although Alexander had been "de facto" head for some time (Turing having little interest in the day-to-day running of the section). Turing became a general consultant for cryptanalysis at Bletchley Park.

Alexander wrote of Turing's contribution:
In July 1942, Turing devised a technique termed "Turingery" (or jokingly "Turingismus") for use against the Lorenz cipher messages produced by the Germans' new "Geheimschreiber" (secret writer) machine. This was a teleprinter rotor cipher attachment codenamed "Tunny" at Bletchley Park. Turingery was a method of "wheel-breaking", i.e., a procedure for working out the cam settings of Tunny's wheels. He also introduced the Tunny team to Tommy Flowers who, under the guidance of Max Newman, went on to build the Colossus computer, the world's first programmable digital electronic computer, which replaced a simpler prior machine (the Heath Robinson), and whose superior speed allowed the statistical decryption techniques to be applied usefully to the messages. Some have mistakenly said that Turing was a key figure in the design of the Colossus computer. Turingery and the statistical approach of Banburismus undoubtedly fed into the thinking about cryptanalysis of the Lorenz cipher, but he was not directly involved in the Colossus development.

Following his work at Bell Labs in the US, Turing pursued the idea of electronic enciphering of speech in the telephone system. In the latter part of the war, he moved to work for the Secret Service's Radio Security Service (later HMGCC) at Hanslope Park. At the park, he further developed his knowledge of electronics with the assistance of engineer Donald Bayley. Together they undertook the design and construction of a portable secure voice communications machine codenamed "Delilah". The machine was intended for different applications, but it lacked the capability for use with long-distance radio transmissions. In any case, Delilah was completed too late to be used during the war. Though the system worked fully, with Turing demonstrating it to officials by encrypting and decrypting a recording of a Winston Churchill speech, Delilah was not adopted for use. Turing also consulted with Bell Labs on the development of SIGSALY, a secure voice system that was used in the later years of the war.

Between 1945 and 1947, Turing lived in Hampton, London, while he worked on the design of the ACE (Automatic Computing Engine) at the National Physical Laboratory (NPL). He presented a paper on 19 February 1946, which was the first detailed design of a stored-program computer. Von Neumann's incomplete "First Draft of a Report on the EDVAC" had predated Turing's paper, but it was much less detailed and, according to John R. Womersley, Superintendent of the NPL Mathematics Division, it "contains a number of ideas which are Dr. Turing's own". Although ACE was a feasible design, the secrecy surrounding the wartime work at Bletchley Park led to delays in starting the project and he became disillusioned. In late 1947 he returned to Cambridge for a sabbatical year during which he produced a seminal work on "Intelligent Machinery" that was not published in his lifetime. While he was at Cambridge, the Pilot ACE was being built in his absence. It executed its first program on 10 May 1950, and a number of later computers around the world owe much to it, including the English Electric DEUCE and the American Bendix G-15. The full version of Turing's ACE was not built until after his death.

According to the memoirs of the German computer pioneer Heinz Billing from the Max Planck Institute for Physics, published by Genscher, Düsseldorf, there was a meeting between Turing and Konrad Zuse. It took place in Göttingen in 1947. The interrogation had the form of a colloquium. Participants were Womersley, Turing, Porter from England and a few German researchers like Zuse, Walther, and Billing (for more details see Herbert Bruderer, "Konrad Zuse und die Schweiz").

In 1948, Turing was appointed reader in the Mathematics Department at the Victoria University of Manchester. A year later, he became Deputy Director of the Computing Machine Laboratory, where he worked on software for one of the earliest stored-program computers—the Manchester Mark 1. Turing wrote the first version of the Programmer's Manual for this machine, and was recruited by Ferranti as a consultant in the development of their commercialised machine, the Ferranti Mark 1. He continued to be paid consultancy fees by Ferranti until his death. During this time, he continued to do more abstract work in mathematics,<ref name="doi10.1093/qjmam/1.1.287"></ref> and in "Computing Machinery and Intelligence" ("Mind", October 1950), Turing addressed the problem of artificial intelligence, and proposed an experiment that became known as the Turing test, an attempt to define a standard for a machine to be called "intelligent". The idea was that a computer could be said to "think" if a human interrogator could not tell it apart, through conversation, from a human being. In the paper, Turing suggested that rather than building a program to simulate the adult mind, it would be better to produce a simpler one to simulate a child's mind and then to subject it to a course of education. A reversed form of the Turing test is widely used on the Internet; the CAPTCHA test is intended to determine whether the user is a human or a computer.

In 1948 Turing, working with his former undergraduate colleague, D.G. Champernowne, began writing a chess program for a computer that did not yet exist. By 1950, the program was completed and dubbed the Turochamp. In 1952, he tried to implement it on a Ferranti Mark 1, but lacking enough power, the computer was unable to execute the program. Instead, Turing "ran" the program by flipping through the pages of the algorithm and carrying out its instructions on a chessboard, taking about half an hour per move. The game was recorded. According to Garry Kasparov, Turing's program "played a recognizable game of chess." The program lost to Turing's colleague Alick Glennie, although it is said that it won a game against Champernowne's wife,
Isabel.

His Turing test was a significant, characteristically provocative, and lasting contribution to the debate regarding artificial intelligence, which continues after more than half a century.

When Turing was 39 years old in 1951, he turned to mathematical biology, finally publishing his masterpiece "The Chemical Basis of Morphogenesis" in January 1952. He was interested in morphogenesis, the development of patterns and shapes in biological organisms. He suggested that a system of chemicals reacting with each other and diffusing across space, termed a reaction-diffusion system, could account for "the main phenomena of morphogenesis". He used systems of partial differential equations to model catalytic chemical reactions. For example, if a catalyst A is required for a certain chemical reaction to take place, and if the reaction produced more of the catalyst A, then we say that the reaction is autocatalytic, and there is positive feedback that can be modelled by nonlinear differential equations. Turing discovered that patterns could be created if the chemical reaction not only produced catalyst A, but also produced an inhibitor B that slowed down the production of A. If A and B then diffused through the container at different rates, then you could have some regions where A dominated and some where B did. To calculate the extent of this, Turing would have needed a powerful computer, but these were not so freely available in 1951, so he had to use linear approximations to solve the equations by hand. These calculations gave the right qualitative results, and produced, for example, a uniform mixture that oddly enough had regularly spaced fixed red spots. The Russian biochemist Boris Belousov had performed experiments with similar results, but could not get his papers published because of the contemporary prejudice that any such thing violated the second law of thermodynamics. Belousov was not aware of Turing's paper in the "Philosophical Transactions of the Royal Society".

Although published before the structure and role of DNA was understood, Turing's work on morphogenesis remains relevant today and is considered a seminal piece of work in mathematical biology. One of the early applications of Turing's paper was the work by James Murray explaining spots and stripes on the fur of cats, large and small. Further research in the area suggests that Turing's work can partially explain the growth of "feathers, hair follicles, the branching pattern of lungs, and even the left-right asymmetry that puts the heart on the left side of the chest." In 2012, Sheth, et al. found that in mice, removal of Hox genes causes an increase in the number of digits without an increase in the overall size of the limb, suggesting that Hox genes control digit formation by tuning the wavelength of a Turing-type mechanism. Later papers were not available until "Collected Works of A. M. Turing" was published in 1992.

In 1941, Turing proposed marriage to Hut 8 colleague Joan Clarke, a fellow mathematician and cryptanalyst, but their engagement was short-lived. After admitting his homosexuality to his fiancée, who was reportedly "unfazed" by the revelation, Turing decided that he could not go through with the marriage.

In January 1952, Turing was 39 when he started a relationship with Arnold Murray, a 19-year-old unemployed man. Just before Christmas, Turing was walking along Manchester's Oxford Road when he met Murray just outside the Regal Cinema and invited him to lunch. On 23 January, Turing's house was burgled. Murray told Turing that he and the burglar were acquainted, and Turing reported the crime to the police. During the investigation, he acknowledged a sexual relationship with Murray. Homosexual acts were criminal offences in the United Kingdom at that time, and both men were charged with "gross indecency" under Section 11 of the Criminal Law Amendment Act 1885. Initial committal proceedings for the trial were held on 27 February during which Turing's solicitor "reserved his defence", i.e., did not argue or provide evidence against the allegations.

Turing was later convinced by the advice of his brother and his own solicitor, and he entered a plea of guilty. The case, "Regina v. Turing and Murray," was brought to trial on 31 March 1952. Turing was convicted and given a choice between imprisonment and probation. His probation would be conditional on his agreement to undergo hormonal physical changes designed to reduce libido. He accepted the option of injections of what was then called stilboestrol (now known as diethylstilbestrol or DES), a synthetic oestrogen; this feminization of his body was continued for the course of one year. The treatment rendered Turing impotent and caused breast tissue to form, fulfilling in the literal sense Turing's prediction that "no doubt I shall emerge from it all a different man, but quite who I've not found out". Murray was given a conditional discharge.

Turing's conviction led to the removal of his security clearance and barred him from continuing with his cryptographic consultancy for the Government Communications Headquarters (GCHQ), the British signals intelligence agency that had evolved from GC&CS in 1946, though he kept his academic job. He was denied entry into the United States after his conviction in 1952, but was free to visit other European countries. Turing was never accused of espionage but, in common with all who had worked at Bletchley Park, he was prevented by the Official Secrets Act from discussing his war work.

On 8 June 1954, Turing's housekeeper found him dead at the age of 41; he had died the previous day. Cyanide poisoning was established as the cause of death. When his body was discovered, an apple lay half-eaten beside his bed, and although the apple was not tested for cyanide, it was speculated that this was the means by which Turing had consumed a fatal dose. An inquest determined that he had committed suicide. Andrew Hodges and another biographer, David Leavitt, have both speculated that Turing was re-enacting a scene from the Walt Disney film "Snow White and the Seven Dwarfs" (1937), his favourite fairy tale. Both men noted that (in Leavitt's words) he took "an especially keen pleasure in the scene where the Wicked Queen immerses her apple in the poisonous brew". Turing's remains were cremated at Woking Crematorium on 12 June 1954, and his ashes were scattered in the gardens of the crematorium, just as his father's had been.

Philosophy professor Jack Copeland has questioned various aspects of the coroner's historical verdict. He suggested an alternative explanation for the cause of Turing's death: the accidental inhalation of cyanide fumes from an apparatus used to electroplate gold onto spoons. The potassium cyanide was used to dissolve the gold. Turing had such an apparatus set up in his tiny spare room. Copeland noted that the autopsy findings were more consistent with inhalation than with ingestion of the poison. Turing also habitually ate an apple before going to bed, and it was not unusual for the apple to be discarded half-eaten. In addition, Turing had reportedly borne his legal setbacks and hormone treatment (which had been discontinued a year previously) "with good humour" and had shown no sign of despondency prior to his death. He even set down a list of tasks that he intended to complete upon returning to his office after the holiday weekend. Turing's mother believed that the ingestion was accidental, resulting from her son's careless storage of laboratory chemicals. Biographer Andrew Hodges theorised that Turing arranged the delivery of the equipment to deliberately allow his mother plausible deniability with regard to any suicide claims.
Conspiracy theorists pointed out that Turing was the cause of intense anxiety to the British authorities at the time of his death. The secret services feared that communists would entrap prominent homosexuals and use them to gather intelligence. Turing was still engaged in highly classified work when he was also a practising homosexual who holidayed in European countries near the Iron Curtain. According to the conspiracy theory, it is possible that the secret services considered him too great a security risk and assassinated one of the most brilliant minds in their employ.

It has been suggested that Turing's belief in fortune-telling may have caused his depressed mood. As a youth, Turing had been told by a fortune-teller that he would be a genius. Shortly before his death, during a day-trip to St Annes-on-Sea with the Greenbaum family, Turing again decided to consult a fortune-teller. According to the Greenbaums' daughter, Barbara:

But it was a lovely sunny day and Alan was in a cheerful mood and off we went... Then he thought it would be a good idea to go to the Pleasure Beach at Blackpool. We found a fortune-teller's tent[,] and Alan said he'd like to go in[,] so we waited around for him to come back... And this sunny, cheerful visage had shrunk into a pale, shaking, horror-stricken face. Something had happened. We don't know what the fortune-teller said[,] but he obviously was deeply unhappy. I think that was probably the last time we saw him before we heard of his suicide.

In August 2009, British programmer John Graham-Cumming started a petition urging the British government to apologise for Turing's prosecution as a homosexual. The petition received more than 30,000 signatures. The Prime Minister, Gordon Brown, acknowledged the petition, releasing a statement on 10 September 2009 apologising and describing the treatment of Turing as "appalling":
In December 2011, William Jones and his Member of Parliament, John Leech, created an e-petition requesting that the British government pardon Turing for his conviction of "gross indecency":
The petition gathered over 37,000 signatures, and was submitted to Parliament by the Manchester MP John Leech but the request was discouraged by Justice Minister Lord McNally, who said:
John Leech, the MP for Manchester Withington (2005–15), submitted several bills to Parliament and led a high-profile campaign to secure the pardon. Leech made the case in the House of Commons that Turing's contribution to the war made him a national hero and that it was "ultimately just embarrassing" that the conviction still stood. Leech continued to take the bill through Parliament and campaigned for several years until it was passed. Leech is now regularly described as the "architect" of Turing's pardon and subsequently the Alan Turing Law which went on to secure pardons for 75,000 other men and women convicted of similar crimes. At the UK premiere of a film based on Turing's life, "The Imitation Game", the producers thanked Leech for bringing the topic to public attention and securing Turing's pardon. His campaign turned to acquiring pardons for the 75,000 other men convicted of the same crime. Leech's campaign gained public support from leading scientists, including Stephen Hawking. He is often described as the "architect" of 'Turing's Law', which used Turing's pardon as a precedent to eventually successfully grant a posthumous pardon to more than 49,000 other men historically criminally convicted of 'Gross Indecencey'. 

On 26 July 2012, a bill was introduced in the House of Lords to grant a statutory pardon to Turing for offences under section 11 of the Criminal Law Amendment Act 1885, of which he was convicted on 31 March 1952. Late in the year in a letter to "The Daily Telegraph", the physicist Stephen Hawking and 10 other signatories including the Astronomer Royal Lord Rees, President of the Royal Society Sir Paul Nurse, Lady Trumpington (who worked for Turing during the war) and Lord Sharkey (the bill's sponsor) called on Prime Minister David Cameron to act on the pardon request. The government indicated it would support the bill, and it passed its third reading in the Lords in October.

At the bill's second reading in the House of Commons on 29 November 2013, Conservative MP Christopher Chope objected to the bill, delaying its passage. The bill was due to return to the House of Commons on 28 February 2014, but before the bill could be debated in the House of Commons, the government elected to proceed under the royal prerogative of mercy. On 24 December 2013, Queen Elizabeth II signed a pardon for Turing's conviction for "gross indecency", with immediate effect. Announcing the pardon, Lord Chancellor Chris Grayling said Turing deserved to be "remembered and recognised for his fantastic contribution to the war effort" and not for his later criminal conviction. The Queen officially pronounced Turing pardoned in August 2014. The Queen's action is only the fourth royal pardon granted since the conclusion of the Second World War. Pardons are normally granted only when the person is technically innocent, and a request has been made by the family or other interested party; neither condition was met in regard to Turing's conviction.

In a letter to the Prime Minister, David Cameron, human rights advocate Peter Tatchell criticised the decision to single out Turing due to his fame and achievements when thousands of others convicted under the same law have not received pardons. Tatchell also called for a new investigation into Turing's death:

In September 2016, the government announced its intention to expand this retroactive exoneration to other men convicted of similar historical indecency offences, in what was described as an "Alan Turing law". The Alan Turing law is now an informal term for the law in the United Kingdom, contained in the Policing and Crime Act 2017, which serves as an amnesty law to retroactively pardon men who were cautioned or convicted under historical legislation that outlawed homosexual acts. The law applies in England and Wales.

Turing was appointed an officer of the Order of the British Empire in 1946. He was also elected a Fellow of the Royal Society (FRS) in 1951.

Turing has been honoured in various ways in Manchester, the city where he worked towards the end of his life. In 1994, a stretch of the A6010 road (the Manchester city intermediate ring road) was named "Alan Turing Way". A bridge carrying this road was widened, and carries the name Alan Turing Bridge. A statue of Turing was unveiled in Manchester on 23 June 2001 in Sackville Park, between the University of Manchester building on Whitworth Street and Canal Street. The memorial statue depicts the "father of computer science" sitting on a bench at a central position in the park. Turing is shown holding an apple. The cast bronze bench carries in relief the text 'Alan Mathison Turing 1912–1954', and the motto 'Founder of Computer Science' as it could appear if encoded by an Enigma machine: 'IEKYF ROMSI ADXUO KVKZC GUBJ'. However, the meaning of the coded message is disputed, as the 'u' in 'computer' matches up with the 'u' in 'ADXUO'. As a letter encoded by an enigma machine cannot appear as itself, the actual message behind the code is uncertain.

A plaque at the statue's feet reads 'Father of computer science, mathematician, logician, wartime codebreaker, victim of prejudice'. There is also a Bertrand Russell quotation: "Mathematics, rightly viewed, possesses not only truth, but supreme beauty—a beauty cold and austere, like that of sculpture." The sculptor buried his own old Amstrad computer under the plinth as a tribute to "the godfather of all modern computers".

In 1999, "Time" magazine named Turing as one of the and stated, "The fact remains that everyone who taps at a keyboard, opening a spreadsheet or a word-processing program, is working on an incarnation of a Turing machine."

To mark the 100th anniversary of Turing's birth, the Turing Centenary Advisory Committee (TCAC) co-ordinated the Alan Turing Year, a year-long programme of events around the world honouring Turing's life and achievements. The TCAC, chaired by S. Barry Cooper with Turing's nephew Sir John Dermot Turing acting as Honorary President, worked with the University of Manchester faculty members and a broad spectrum of people from Cambridge University and Bletchley Park.
In May 2020 it was reported by "Gay Star News" that a high steel sculpture, to honour Turing, designed by Sir Antony Gormley, was planned to be installed in King's College, Cambridge. Historic England, however, was quoted as saying that the abstract work of 19 steel slabs "... would be at odds with the existing character of the College. This would result in harm, of a less than substantial nature, to the significance of the listed buildings and landscape, and by extension the conservation area."





 


</doc>
<doc id="1209" url="https://en.wikipedia.org/wiki?curid=1209" title="Area">
Area

Area is the quantity that expresses the extent of a two-dimensional figure or shape or planar lamina, in the plane. Surface area is its analog on the two-dimensional surface of a three-dimensional object. Area can be understood as the amount of material with a given thickness that would be necessary to fashion a model of the shape, or the amount of paint necessary to cover the surface with a single coat. It is the two-dimensional analog of the length of a curve (a one-dimensional concept) or the volume of a solid (a three-dimensional concept).

The area of a shape can be measured by comparing the shape to squares of a fixed size. In the International System of Units (SI), the standard unit of area is the square metre (written as m), which is the area of a square whose sides are one metre long. A shape with an area of three square metres would have the same area as three such squares. In mathematics, the unit square is defined to have area one, and the area of any other shape or surface is a dimensionless real number.

There are several well-known formulas for the areas of simple shapes such as triangles, rectangles, and circles. Using these formulas, the area of any polygon can be found by dividing the polygon into triangles. For shapes with curved boundary, calculus is usually required to compute the area. Indeed, the problem of determining the area of plane figures was a major motivation for the historical development of calculus.

For a solid shape such as a sphere, cone, or cylinder, the area of its boundary surface is called the surface area. Formulas for the surface areas of simple shapes were computed by the ancient Greeks, but computing the surface area of a more complicated shape usually requires multivariable calculus.

Area plays an important role in modern mathematics. In addition to its obvious importance in geometry and calculus, area is related to the definition of determinants in linear algebra, and is a basic property of surfaces in differential geometry. In analysis, the area of a subset of the plane is defined using Lebesgue measure, though not every subset is measurable. In general, area in higher mathematics is seen as a special case of volume for two-dimensional regions.

Area can be defined through the use of axioms, defining it as a function of a collection of certain plane figures to the set of real numbers. It can be proved that such a function exists.

An approach to defining what is meant by "area" is through axioms. "Area" can be defined as a function from a collection M of special kind of plane figures (termed measurable sets) to the set of real numbers, which satisfies the following properties:

It can be proved that such an area function actually exists.

Every unit of length has a corresponding unit of area, namely the area of a square with the given side length. Thus areas can be measured in square metres (m), square centimetres (cm), square millimetres (mm), square kilometres (km), square feet (ft), square yards (yd), square miles (mi), and so forth. Algebraically, these units can be thought of as the squares of the corresponding length units.

The SI unit of area is the square metre, which is considered an SI derived unit.

Calculation of the area of a square whose length and width are 1 metre would be:

1 metre × 1 metre = 1 m

and so, a rectangle with different sides (say length of 3 metres and width of 2 metres) would have an area in square units that can be calculated as:

3 metres × 2 metres = 6 m. This is equivalent to 6 million square millimetres. Other useful conversions are:

In non-metric units, the conversion between two square units is the square of the conversion between the corresponding length units.
the relationship between square feet and square inches is
where 144 = 12 = 12 × 12. Similarly:
In addition, conversion factors include:

There are several other common units for area. The are was the original unit of area in the metric system, with:
Though the are has fallen out of use, the hectare is still commonly used to measure land:
Other uncommon metric units of area include the tetrad, the hectad, and the myriad.

The acre is also commonly used to measure land areas, where
An acre is approximately 40% of a hectare.

On the atomic scale, area is measured in units of barns, such that:
The barn is commonly used in describing the cross-sectional area of interaction in nuclear physics.

In India,

In the 5th century BCE, Hippocrates of Chios was the first to show that the area of a disk (the region enclosed by a circle) is proportional to the square of its diameter, as part of his quadrature of the lune of Hippocrates, but did not identify the constant of proportionality. Eudoxus of Cnidus, also in the 5th century BCE, also found that the area of a disk is proportional to its radius squared.

Subsequently, Book I of Euclid's "Elements" dealt with equality of areas between two-dimensional figures. The mathematician Archimedes used the tools of Euclidean geometry to show that the area inside a circle is equal to that of a right triangle whose base has the length of the circle's circumference and whose height equals the circle's radius, in his book "Measurement of a Circle". (The circumference is 2"r", and the area of a triangle is half the base times the height, yielding the area "r" for the disk.) Archimedes approximated the value of π (and hence the area of a unit-radius circle) with his doubling method, in which he inscribed a regular triangle in a circle and noted its area, then doubled the number of sides to give a regular hexagon, then repeatedly doubled the number of sides as the polygon's area got closer and closer to that of the circle (and did the same with circumscribed polygons).

Swiss scientist Johann Heinrich Lambert in 1761 proved that π, the ratio of a circle's area to its squared radius, is irrational, meaning it is not equal to the quotient of any two whole numbers. In 1794 French mathematician Adrien-Marie Legendre proved that π is irrational; this also proves that π is irrational. In 1882, German mathematician Ferdinand von Lindemann proved that π is transcendental (not the solution of any polynomial equation with rational coefficients), confirming a conjecture made by both Legendre and Euler.

Heron (or Hero) of Alexandria found what is known as Heron's formula for the area of a triangle in terms of its sides, and a proof can be found in his book, "Metrica", written around 60 CE. It has been suggested that Archimedes knew the formula over two centuries earlier, and since "Metrica" is a collection of the mathematical knowledge available in the ancient world, it is possible that the formula predates the reference given in that work.

In 499 Aryabhata, a great mathematician-astronomer from the classical age of Indian mathematics and Indian astronomy, expressed the area of a triangle as one-half the base times the height in the "Aryabhatiya" (section 2.6).

A formula equivalent to Heron's was discovered by the Chinese independently of the Greeks. It was published in 1247 in "Shushu Jiuzhang" ("Mathematical Treatise in Nine Sections"), written by Qin Jiushao.

In the 7th century CE, Brahmagupta developed a formula, now known as Brahmagupta's formula, for the area of a cyclic quadrilateral (a quadrilateral inscribed in a circle) in terms of its sides. In 1842 the German mathematicians Carl Anton Bretschneider and Karl Georg Christian von Staudt independently found a formula, known as Bretschneider's formula, for the area of any quadrilateral.

The development of Cartesian coordinates by René Descartes in the 17th century allowed the development of the surveyor's formula for the area of any polygon with known vertex locations by Gauss in the 19th century.

The development of integral calculus in the late 17th century provided tools that could subsequently be used for computing more complicated areas, such as the area of an ellipse and the surface areas of various curved three-dimensional objects.

For a non-self-intersecting (simple) polygon, the Cartesian coordinates formula_1 ("i"=0, 1, ..., "n"-1) of whose "n" vertices are known, the area is given by the surveyor's formula:

where when "i"="n"-1, then "i"+1 is expressed as modulus "n" and so refers to 0.

The most basic area formula is the formula for the area of a rectangle. Given a rectangle with length and width , the formula for the area is:

That is, the area of the rectangle is the length multiplied by the width. As a special case, as in the case of a square, the area of a square with side length is given by the formula:

The formula for the area of a rectangle follows directly from the basic properties of area, and is sometimes taken as a definition or axiom. On the other hand, if geometry is developed before arithmetic, this formula can be used to define multiplication of real numbers.

Most other simple formulas for area follow from the method of dissection.
This involves cutting a shape into pieces, whose areas must sum to the area of the original shape.

For an example, any parallelogram can be subdivided into a trapezoid and a right triangle, as shown in figure to the left. If the triangle is moved to the other side of the trapezoid, then the resulting figure is a rectangle. It follows that the area of the parallelogram is the same as the area of the rectangle:

However, the same parallelogram can also be cut along a diagonal into two congruent triangles, as shown in the figure to the right. It follows that the area of each triangle is half the area of the parallelogram:
Similar arguments can be used to find area formulas for the trapezoid as well as more complicated polygons.

The formula for the area of a circle (more properly called the area enclosed by a circle or the area of a disk) is based on a similar method. Given a circle of radius , it is possible to partition the circle into sectors, as shown in the figure to the right. Each sector is approximately triangular in shape, and the sectors can be rearranged to form an approximate parallelogram. The height of this parallelogram is , and the width is half the circumference of the circle, or . Thus, the total area of the circle is :
Though the dissection used in this formula is only approximate, the error becomes smaller and smaller as the circle is partitioned into more and more sectors. The limit of the areas of the approximate parallelograms is exactly , which is the area of the circle.

This argument is actually a simple application of the ideas of calculus. In ancient times, the method of exhaustion was used in a similar way to find the area of the circle, and this method is now recognized as a precursor to integral calculus. Using modern methods, the area of a circle can be computed using a definite integral:

The formula for the area enclosed by an ellipse is related to the formula of a circle; for an ellipse with semi-major and semi-minor axes and the formula is:

Most basic formulas for surface area can be obtained by cutting surfaces and flattening them out. For example, if the side surface of a cylinder (or any prism) is cut lengthwise, the surface can be flattened out into a rectangle. Similarly, if a cut is made along the side of a cone, the side surface can be flattened out into a sector of a circle, and the resulting area computed.

The formula for the surface area of a sphere is more difficult to derive: because a sphere has nonzero Gaussian curvature, it cannot be flattened out. The formula for the surface area of a sphere was first obtained by Archimedes in his work "On the Sphere and Cylinder". The formula is:


(see Green's theorem) or the "z"-component of

To find the bounded area between two quadratic functions, we subtract one from the other to write the difference as
where "f"("x") is the quadratic upper bound and "g"("x") is the quadratic lower bound. Define the discriminant of "f"("x")-"g"("x") as
By simplifying the integral formula between the graphs of two functions (as given in the section above) and using Vieta's formula, we can obtain
The above remains valid if one of the bounding functions is linear instead of quadratic.


The general formula for the surface area of the graph of a continuously differentiable function formula_35 where formula_36 and formula_37 is a region in the xy-plane with the smooth boundary:
An even more general formula for the area of the graph of a parametric surface in the vector form formula_39 where formula_40 is a continuously differentiable vector function of formula_41 is:

The above calculations show how to find the areas of many common shapes.

The areas of irregular polygons can be calculated using the "Surveyor's formula".

The isoperimetric inequality states that, for a closed curve of length "L" (so the region it encloses has perimeter "L") and for area "A" of the region that it encloses,

and equality holds if and only if the curve is a circle. Thus a circle has the largest area of any closed figure with a given perimeter.

At the other extreme, a figure with given perimeter "L" could have an arbitrarily small area, as illustrated by a rhombus that is "tipped over" arbitrarily far so that two of its angles are arbitrarily close to 0° and the other two are arbitrarily close to 180°.

For a circle, the ratio of the area to the circumference (the term for the perimeter of a circle) equals half the radius "r". This can be seen from the area formula "πr" and the circumference formula 2"πr".

The area of a regular polygon is half its perimeter times the apothem (where the apothem is the distance from the center to the nearest point on any side).

Doubling the edge lengths of a polygon multiplies its area by four, which is two (the ratio of the new to the old side length) raised to the power of two (the dimension of the space the polygon resides in). But if the one-dimensional lengths of a fractal drawn in two dimensions are all doubled, the spatial content of the fractal scales by a power of two that is not necessarily an integer. This power is called the fractal dimension of the fractal.
There are an infinitude of lines that bisect the area of a triangle. Three of them are the medians of the triangle (which connect the sides' midpoints with the opposite vertices), and these are concurrent at the triangle's centroid; indeed, they are the only area bisectors that go through the centroid. Any line through a triangle that splits both the triangle's area and its perimeter in half goes through the triangle's incenter (the center of its incircle). There are either one, two, or three of these for any given triangle.

Any line through the midpoint of a parallelogram bisects the area.

All area bisectors of a circle or other ellipse go through the center, and any chords through the center bisect the area. In the case of a circle they are the diameters of the circle.

Given a wire contour, the surface of least area spanning ("filling") it is a minimal surface. Familiar examples include soap bubbles.

The question of the filling area of the Riemannian circle remains open.

The circle has the largest area of any two-dimensional object having the same perimeter.

A cyclic polygon (one inscribed in a circle) has the largest area of any polygon with a given number of sides of the same lengths.

A version of the isoperimetric inequality for triangles states that the triangle of greatest area among all those with a given perimeter is equilateral.

The triangle of largest area of all those inscribed in a given circle is equilateral; and the triangle of smallest area of all those circumscribed around a given circle is equilateral.

The ratio of the area of the incircle to the area of an equilateral triangle, formula_44, is larger than that of any non-equilateral triangle.

The ratio of the area to the square of the perimeter of an equilateral triangle, formula_45 is larger than that for any other triangle.



</doc>
<doc id="1210" url="https://en.wikipedia.org/wiki?curid=1210" title="Astronomical unit">
Astronomical unit

The astronomical unit (symbol: au, ua, or AU) is a unit of length, roughly the distance from Earth to the Sun and equal to about . 
The actual distance varies as Earth orbits the Sun, from a maximum (aphelion) to a minimum (perihelion) and back again once each year. The AU was originally conceived as the average of Earth's aphelion and perihelion; however, since 2012 it has been defined as exactly . 

The astronomical unit is used primarily for measuring distances within the Solar System or around other stars. It is also a fundamental component in the definition of another unit of astronomical length, the parsec.

A variety of unit symbols and abbreviations have been in use for the astronomical unit. In a 1976 resolution, the International Astronomical Union (IAU) had used the symbol "A" to denote a length equal to the astronomical unit. In the astronomical literature, the symbol AU was (and remains) common. In 2006, the International Bureau of Weights and Measures (BIPM) had recommended ua as the symbol for the unit. In the non-normative Annex C to ISO 80000-3:2006, the symbol of the astronomical unit is "ua".

In 2012, the IAU, noting "that various symbols are presently in use for the astronomical unit", recommended the use of the symbol "au", as did the American Astronomical Society (AAS) in the manuscript preparation guidelines for its principal journals. In the 2014 revision and 2019 edition of the SI Brochure, the BIPM used the unit symbol "au". ISO 80000-3:2019, which revises ISO 80000-3:2006, makes no mention of the astronomical unit.

Earth's orbit around the Sun is an ellipse. The semi-major axis of this elliptic orbit is defined to be half of the straight line segment that joins the perihelion and aphelion. The centre of the Sun lies on this straight line segment, but not at its midpoint. Because ellipses are well-understood shapes, measuring the points of its extremes defined the exact shape mathematically, and made possible calculations for the entire orbit as well as predictions based on observation. In addition, it mapped out exactly the largest straight-line distance that Earth traverses over the course of a year, defining times and places for observing the largest parallax (apparent shifts of position) in nearby stars. Knowing Earth's shift and a star's shift enabled the star's distance to be calculated. But all measurements are subject to some degree of error or uncertainty, and the uncertainties in the length of the astronomical unit only increased uncertainties in the stellar distances. Improvements in precision have always been a key to improving astronomical understanding. Throughout the twentieth century, measurements became increasingly precise and sophisticated, and ever more dependent on accurate observation of the effects described by Einstein's theory of relativity and upon the mathematical tools it used.

Improving measurements were continually checked and cross-checked by means of improved understanding of the laws of celestial mechanics, which govern the motions of objects in space. The expected positions and distances of objects at an established time are calculated (in au) from these laws, and assembled into a collection of data called an ephemeris. NASA Jet Propulsion Laboratory HORIZONS System provides one of several ephemeris computation services.

In 1976, in order to establish a yet more precise measure for the astronomical unit, the IAU formally adopted a new definition. Although directly based on the then-best available observational measurements, the definition was recast in terms of the then-best mathematical derivations from celestial mechanics and planetary ephemerides. It stated that "the astronomical unit of length is that length ("A") for which the Gaussian gravitational constant ("k") takes the value when the units of measurement are the astronomical units of length, mass and time". Equivalently, by this definition, one au is "the radius of an unperturbed circular Newtonian orbit about the sun of a particle having infinitesimal mass, moving with an angular frequency of "; or alternatively that length for which the heliocentric gravitational constant (the product "G") is equal to () au/d, when the length is used to describe the positions of objects in the Solar System.

Subsequent explorations of the Solar System by space probes made it possible to obtain precise measurements of the relative positions of the inner planets and other objects by means of radar and telemetry. As with all radar measurements, these rely on measuring the time taken for photons to be reflected from an object. Because all photons move at the speed of light in vacuum, a fundamental constant of the universe, the distance of an object from the probe is calculated as the product of the speed of light and the measured time. However, for precision the calculations require adjustment for things such as the motions of the probe and object while the photons are transiting. In addition, the measurement of the time itself must be translated to a standard scale that accounts for relativistic time dilation. Comparison of the ephemeris positions with time measurements expressed in Barycentric Dynamical Time (TDB) leads to a value for the speed of light in astronomical units per day (of ). By 2009, the IAU had updated its standard measures to reflect improvements, and calculated the speed of light at (TDB).

In 1983, the CIPM modified the International System of Units (SI, or "modern" metric system) to make the metre defined as the distance travelled in a vacuum by light in 1 /  second. This replaced the previous definition, valid between 1960 and 1983, which was that the metre equalled a certain number of wavelengths of a certain emission line of krypton-86. (The reason for the change was an improved method of measuring the speed of light.) The speed of light could then be expressed exactly as "c" = , a standard also adopted by the IERS numerical standards. From this definition and the 2009 IAU standard, the time for light to traverse an astronomical unit is found to be "τ" = , which is slightly more than 8 minutes 19 seconds. By multiplication, the best IAU 2009 estimate was "A" = "c""τ" = , based on a comparison of Jet Propulsion Laboratory and IAA–RAS ephemerides.

In 2006, the BIPM reported a value of the astronomical unit as . In the 2014 revision of the SI Brochure, the BIPM recognised the IAU's 2012 redefinition of the astronomical unit as .

This estimate was still derived from observation and measurements subject to error, and based on techniques that did not yet standardize all relativistic effects, and thus were not constant for all observers. In 2012, finding that the equalization of relativity alone would make the definition overly complex, the IAU simply used the 2009 estimate to redefine the astronomical unit as a conventional unit of length directly tied to the metre (exactly ). The new definition also recognizes as a consequence that the astronomical unit is now to play a role of reduced importance, limited in its use to that of a convenience in some applications.

This definition makes the speed of light, defined as exactly , equal to exactly  ×  ÷  or about au/d, some 60 parts per trillion less than the 2009 estimate.

With the definitions used before 2012, the astronomical unit was dependent on the heliocentric gravitational constant, that is the product of the gravitational constant, "G", and the solar mass, . Neither "G" nor can be measured to high accuracy separately, but the value of their product is known very precisely from observing the relative positions of planets (Kepler's Third Law expressed in terms of Newtonian gravitation). Only the product is required to calculate planetary positions for an ephemeris, so ephemerides are calculated in astronomical units and not in SI units.

The calculation of ephemerides also requires a consideration of the effects of general relativity. In particular, time intervals measured on Earth's surface (Terrestrial Time, TT) are not constant when compared with the motions of the planets: the terrestrial second (TT) appears to be longer during the Northern Hemisphere winter and shorter during the Northern Hemisphere summer when compared with the "planetary second" (conventionally measured in TDB). This is because the distance between Earth and the Sun is not fixed (it varies between and ) and, when Earth is closer to the Sun (perihelion), the Sun's gravitational field is stronger and Earth is moving faster along its orbital path. As the metre is defined in terms of the second and the speed of light is constant for all observers, the terrestrial metre appears to change in length compared with the "planetary metre" on a periodic basis.

The metre is defined to be a unit of proper length, but the SI definition does not specify the metric tensor to be used in determining it. Indeed, the International Committee for Weights and Measures (CIPM) notes that "its definition applies only within a spatial extent sufficiently small that the effects of the non-uniformity of the gravitational field can be ignored". As such, the metre is undefined for the purposes of measuring distances within the Solar System. The 1976 definition of the astronomical unit was incomplete because it did not specify the frame of reference in which time is to be measured, but proved practical for the calculation of ephemerides: a fuller definition that is consistent with general relativity was proposed, and "vigorous debate" ensued until August 2012 when the IAU adopted the current definition of 1 astronomical unit = metres.

The astronomical unit is typically used for stellar system scale distances, such as the size of a protostellar disk or the heliocentric distance of an asteroid, whereas other units are used for other distances in astronomy. The astronomical unit is too small to be convenient for interstellar distances, where the parsec and light-year are widely used. The parsec (parallax arcsecond) is defined in terms of the astronomical unit, being the distance of an object with a parallax of . The light-year is often used in popular works, but is not an approved non-SI unit and is rarely used by professional astronomers.

When simulating a numerical model of the Solar System, the astronomical unit provides an appropriate scale that minimizes (overflow, underflow and truncation) errors in floating point calculations.

The book "On the Sizes and Distances of the Sun and Moon", which has long been ascribed to Aristarchus, says that he calculated the distance to the Sun to be between 18 and 20 times the distance to the Moon, whereas the true ratio is about . The latter estimate was based on the angle between the half-moon and the Sun, which he estimated as (the true value being close to ). Depending on the distance that Van Helden assumes Aristarchus used for the distance to the Moon, his calculated distance to the Sun would fall between and Earth radii.

According to Eusebius of Caesarea in the "Praeparatio Evangelica" (Book XV, Chapter 53), Eratosthenes found the distance to the Sun to be "σταδιων μυριαδας τετρακοσιας και οκτωκισμυριας" (literally "of "stadia" myriads 400 and ) but with the additional note that in the Greek text the grammatical agreement is between "myriads" (not "stadia") on the one hand and both "400" and "" on the other, as in Greek, unlike English, all three (or all four if one were to include "stadia") words are inflected. This has been translated either as "stadia" (1903 translation by Edwin Hamilton Gifford), or as "stadia" (edition of , dated 1974–1991). Using the Greek stadium of 185 to 190 metres, the former translation comes to to , which is far too low, whereas the second translation comes to 148.7 to 152.8 million kilometres (accurate within 2%). Hipparchus also gave an estimate of the distance of Earth from the Sun, quoted by Pappus as equal to 490 Earth radii. According to the conjectural reconstructions of Noel Swerdlow and G. J. Toomer, this was derived from his assumption of a "least perceptible" solar parallax of .

A Chinese mathematical treatise, the "Zhoubi Suanjing" (c. 1st century BCE), shows how the distance to the Sun can be computed geometrically, using the different lengths of the noontime shadows observed at three places li apart and the assumption that Earth is flat.

In the 2nd century CE, Ptolemy estimated the mean distance of the Sun as times Earth's radius. To determine this value, Ptolemy started by measuring the Moon's parallax, finding what amounted to a horizontal lunar parallax of 1° 26', which was much too large. He then derived a maximum lunar distance of Earth radii. Because of cancelling errors in his parallax figure, his theory of the Moon's orbit, and other factors, this figure was approximately correct. He then measured the apparent sizes of the Sun and the Moon and concluded that the apparent diameter of the Sun was equal to the apparent diameter of the Moon at the Moon's greatest distance, and from records of lunar eclipses, he estimated this apparent diameter, as well as the apparent diameter of the shadow cone of Earth traversed by the Moon during a lunar eclipse. Given these data, the distance of the Sun from Earth can be trigonometrically computed to be Earth radii. This gives a ratio of solar to lunar distance of approximately 19, matching Aristarchus's figure. Although Ptolemy's procedure is theoretically workable, it is very sensitive to small changes in the data, so much so that changing a measurement by a few per cent can make the solar distance infinite.

After Greek astronomy was transmitted to the medieval Islamic world, astronomers made some changes to Ptolemy's cosmological model, but did not greatly change his estimate of the Earth–Sun distance. For example, in his introduction to Ptolemaic astronomy, al-Farghānī gave a mean solar distance of Earth radii, whereas in his "zij", al-Battānī used a mean solar distance of Earth radii. Subsequent astronomers, such as al-Bīrūnī, used similar values. Later in Europe, Copernicus and Tycho Brahe also used comparable figures ( and Earth radii), and so Ptolemy's approximate Earth–Sun distance survived through the 16th century.

Johannes Kepler was the first to realize that Ptolemy's estimate must be significantly too low (according to Kepler, at least by a factor of three) in his "Rudolphine Tables" (1627). Kepler's laws of planetary motion allowed astronomers to calculate the relative distances of the planets from the Sun, and rekindled interest in measuring the absolute value for Earth (which could then be applied to the other planets). The invention of the telescope allowed far more accurate measurements of angles than is possible with the naked eye. Flemish astronomer Godefroy Wendelin repeated Aristarchus' measurements in 1635, and found that Ptolemy's value was too low by a factor of at least eleven.

A somewhat more accurate estimate can be obtained by observing the transit of Venus. By measuring the transit in two different locations, one can accurately calculate the parallax of Venus and from the relative distance of Earth and Venus from the Sun, the solar parallax "α" (which cannot be measured directly due to the brightness of the Sun). Jeremiah Horrocks had attempted to produce an estimate based on his observation of the 1639 transit (published in 1662), giving a solar parallax of , similar to Wendelin's figure. The solar parallax is related to the Earth–Sun distance as measured in Earth radii by

The smaller the solar parallax, the greater the distance between the Sun and Earth: a solar parallax of is equivalent to an Earth–Sun distance of Earth radii.

Christiaan Huygens believed that the distance was even greater: by comparing the apparent sizes of Venus and Mars, he estimated a value of about Earth radii, equivalent to a solar parallax of . Although Huygens' estimate is remarkably close to modern values, it is often discounted by historians of astronomy because of the many unproven (and incorrect) assumptions he had to make for his method to work; the accuracy of his value seems to be based more on luck than good measurement, with his various errors cancelling each other out.
Jean Richer and Giovanni Domenico Cassini measured the parallax of Mars between Paris and Cayenne in French Guiana when Mars was at its closest to Earth in 1672. They arrived at a figure for the solar parallax of , equivalent to an Earth–Sun distance of about Earth radii. They were also the first astronomers to have access to an accurate and reliable value for the radius of Earth, which had been measured by their colleague Jean Picard in 1669 as "toises". Another colleague, Ole Rømer, discovered the finite speed of light in 1676: the speed was so great that it was usually quoted as the time required for light to travel from the Sun to the Earth, or "light time per unit distance", a convention that is still followed by astronomers today.

A better method for observing Venus transits was devised by James Gregory and published in his "Optica Promata" (1663). It was strongly advocated by Edmond Halley and was applied to the transits of Venus observed in 1761 and 1769, and then again in 1874 and 1882. Transits of Venus occur in pairs, but less than one pair every century, and observing the transits in 1761 and 1769 was an unprecedented international scientific operation including observations by James Cook and Charles Green from Tahiti. Despite the Seven Years' War, dozens of astronomers were dispatched to observing points around the world at great expense and personal danger: several of them died in the endeavour. The various results were collated by Jérôme Lalande to give a figure for the solar parallax of .
Another method involved determining the constant of aberration. Simon Newcomb gave great weight to this method when deriving his widely accepted value of for the solar parallax (close to the modern value of ), although Newcomb also used data from the transits of Venus. Newcomb also collaborated with A. A. Michelson to measure the speed of light with Earth-based equipment; combined with the constant of aberration (which is related to the light time per unit distance), this gave the first direct measurement of the Earth–Sun distance in kilometres. Newcomb's value for the solar parallax (and for the constant of aberration and the Gaussian gravitational constant) were incorporated into the first international system of astronomical constants in 1896, which remained in place for the calculation of ephemerides until 1964. The name "astronomical unit" appears first to have been used in 1903.

The discovery of the near-Earth asteroid 433 Eros and its passage near Earth in 1900–1901 allowed a considerable improvement in parallax measurement. Another international project to measure the parallax of 433 Eros was undertaken in 1930–1931.

Direct radar measurements of the distances to Venus and Mars became available in the early 1960s. Along with improved measurements of the speed of light, these showed that Newcomb's values for the solar parallax and the constant of aberration were inconsistent with one another.

The unit distance "A" (the value of the astronomical unit in metres) can be expressed in terms of other astronomical constants:
where "G" is the Newtonian gravitational constant, is the solar mass, "k" is the numerical value of Gaussian gravitational constant and "D" is the time period of one day.
The Sun is constantly losing mass by radiating away energy, so the orbits of the planets are steadily expanding outward from the Sun. This has led to calls to abandon the astronomical unit as a unit of measurement.

As the speed of light has an exact defined value in SI units and the Gaussian gravitational constant "k" is fixed in the astronomical system of units, measuring the light time per unit distance is exactly equivalent to measuring the product "G" in SI units. Hence, it is possible to construct ephemerides entirely in SI units, which is increasingly becoming the norm.

A 2004 analysis of radiometric measurements in the inner Solar System suggested that the secular increase in the unit distance was much larger than can be accounted for by solar radiation, + metres per century.

The measurements of the secular variations of the astronomical unit are not confirmed by other authors and are quite controversial.
Furthermore, since 2010, the astronomical unit has not been estimated by the planetary ephemerides.

The following table contains some distances given in astronomical units. It includes some examples with distances that are normally not given in astronomical units, because they are either too short or far too long. Distances normally change over time. Examples are listed by increasing distance.




</doc>
<doc id="1212" url="https://en.wikipedia.org/wiki?curid=1212" title="Artist">
Artist

An artist is a person engaged in an activity related to creating art, practicing the arts, or demonstrating an art. The common usage in both everyday speech and academic discourse is a practitioner in the visual arts only. The term is often used in the entertainment business, especially in a business context, for musicians and other performers (less often for actors). "Artiste" (the French for artist) is a variant used in English only in this context; this use has become rare. Use of the term to describe writers, for example, is valid, but less common, and mostly restricted to contexts like criticism.

The "Oxford English Dictionary" defines the older broad meanings of the term "artist":


The Greek word "techně", often translated as "art," implies mastery of any sort of craft. The adjectival Latin form of the word, "technicus",
became the source of the English words technique, technology, technical.

In Greek culture each of the nine Muses oversaw a different field of human creation:

No muse was identified with the visual arts of painting and sculpture. In ancient Greece sculptors and painters were held in low regard, somewhere between freemen and slaves, their work regarded as mere manual labour.

The word "art" derives from the Latin "ars" (stem "art-"), which, although literally defined means "skill method" or "technique", also conveys a connotation of beauty.

During the Middle Ages the word "artist" already existed in some countries such as Italy, but the meaning was something resembling "craftsman", while the word "artesan" was still unknown. An artist was someone able to do a work better than others, so the skilled excellency was underlined, rather than the activity field. In this period some "artisanal" products (such as textiles) were much more precious and expensive than paintings or sculptures.

The first division into major and minor arts dates back at least to the works of Leon Battista Alberti (1404–1472): "De re aedificatoria, De statua, De pictura", which focused on the importance of the intellectual skills of the artist rather than the manual skills (even if in other forms of art there was a project behind).

With the Academies in Europe (second half of 16th century) the gap between fine and applied arts was definitely set.

Many contemporary definitions of "artist" and "art" are highly contingent on culture, resisting aesthetic prescription, in much the same way that the features constituting beauty and the beautiful cannot be standardized easily without corruption into kitsch.

"Artist" is a descriptive term applied to a person who engages in an activity deemed to be an art. An artist also may be defined unofficially as "a person who expresses him- or herself through a medium". The word is also used in a qualitative sense of, a person creative in, innovative in, or adept at, an artistic practice.

Most often, the term describes those who create within a context of the fine arts or 'high culture', activities such as drawing, painting, sculpture, acting, dancing, writing, filmmaking, new media, photography, and music—people who use imagination, talent, or skill to create works that may be judged to have an aesthetic value. Art historians and critics define artists as those who produce art within a recognized or recognizable discipline. Contrasting terms for highly skilled workers in media in the applied arts or decorative arts include artisan, craftsman, and specialized terms such as potter, goldsmith or glassblower. Fine arts artists such as painters succeeded in the Renaissance in raising their status, formerly similar to these workers, to a decisively higher level.

The term may also be used loosely or metaphorically to denote highly skilled people in any non-"art" activities, as well— law, medicine, mechanics, or mathematics, for example.

Often, discussions on the subject focus on the differences among "artist" and "technician", "entertainer" and "artisan", "fine art" and "applied art", or what constitutes art and what does not. The French word "artiste" (which in French, simply means "artist") has been imported into the English language where it means a performer (frequently in Music Hall or Vaudeville). Use of the word "artiste" can also be a pejorative term.

The English word 'artiste' has thus a narrower range of meaning than the word 'artiste' in French.

In "Living with Art", Mark Getlein proposes six activities, services or functions of contemporary artists:

After looking at years of data on arts school graduates as well as policies & program outcomes regarding artists, arts, & culture, Elizabeth Lingo and Steven Tepper propose the divide between "arts for art's sake" artists and commercially successful artists is not as wide as may be perceived, and that "this bifurcation between the commercial and the noncommercial, the excellent and the base, the elite and the popular, is increasingly breaking down" (Eikhof & Haunschild, 2007). Lingo and Tepper point out:

The US Bureau of Labor Statistics classifies many visual artists as either "craft artists" or "fine artists". A craft artist makes handmade functional works of art, such as pottery or clothing. A fine artist makes paintings, illustrations (such as book illustrations or medical illustrations), sculptures, or similar artistic works primarily for their aesthetic value.

The main source of skill for both craft artists and fine artists is long-term repetition and practice. Many fine artists have studied their art form at university and some have a master's degree in fine arts. Artists may also study on their own or receive on-the-job training from an experienced artist.

The number of available jobs as an artist is increasing more slowly than other fields. About half of US artists are self-employed. Others work in a variety of industries. For example, a pottery manufacturer will employ craft artists, and book publishers will hire illustrators.

In the US, fine artists have a median income of approximately US$50,000 per year, and craft artists have a median income of approximately US$33,000 per year. This compares to US$61,000 for all art-related fields, including related jobs such as graphic designers, multimedia artists, animators, and fashion designers. Many artists work part-time as artists and hold a second job.




</doc>
