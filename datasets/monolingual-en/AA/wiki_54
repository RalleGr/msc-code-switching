<doc id="6816" url="https://en.wikipedia.org/wiki?curid=6816" title="Cavalry">
Cavalry

Cavalry (from the French word "cavalerie", itself derived from "cheval" meaning "horse") are soldiers or warriors who fight mounted on horseback. Cavalry were historically the most mobile of the combat arms, operating as light cavalry in the roles of reconnaissance, screening and harassing in many armies, or as heavy cavalry for decisive shock attacks in other armies. An individual soldier in the cavalry is known by a number of designations depending on era and tactics, such as cavalryman, horseman, trooper, cataphract, hussar, lancer or dragoon. The designation of "cavalry" was not usually given to any military forces that used other animals for mounts, such as camels or elephants. Infantry who moved on horseback, but dismounted to fight on foot, were known in the 17th and early 18th centuries as "dragoons", a class of mounted infantry which in most armies later evolved into standard cavalry while retaining their historic designation.

Cavalry had the advantage of improved mobility, and a soldier fighting from horseback also had the advantages of greater height, speed, and inertial mass over an opponent on foot. Another element of horse mounted warfare is the psychological impact a mounted soldier can inflict on an opponent.

The speed, mobility, and shock value of cavalry was greatly appreciated and exploited in armed forces in the Ancient and Middle Ages; some forces were mostly cavalry, particularly in nomadic societies of Asia, notably the Huns of Attila and the later Mongol armies. In Europe cavalry became increasingly armoured (heavy), and eventually evolving into the mounted knights of the medieval period. During the 17th century cavalry in Europe lost most of its armor, ineffective against the muskets and cannon which were coming into use, and by the mid-19th century armor had mainly fallen into disuse, although some regiments retained a small thickened cuirass that offered protection against lances and sabres and some protection against shot.

In the period between the World Wars, many cavalry units were converted into motorized infantry and mechanized infantry units, or reformed as tank troops. However, some cavalry still served during World War II, notably in the Red Army, the Mongolian People's Army, the Royal Italian Army, the Romanian Army, the Polish Land Forces, and light reconnaissance units within the Waffen SS. Most cavalry units that are horse-mounted in modern armies serve in purely ceremonial roles, or as mounted infantry in difficult terrain such as mountains or heavily forested areas. Modern usage of the term generally refers to units performing the role of reconnaissance, surveillance, and target acquisition (RSTA).

In many modern armies, the term "cavalry" is still often used to refer to units that are a combat arm of the armed forces which in the past filled the traditional horse-borne land combat light cavalry roles. These include scouting, skirmishing with enemy reconnaissance elements to deny them knowledge of the disposition of the main body of troops, forward security, offensive reconnaissance by combat, defensive screening of friendly forces during retrograde movement, retreat, restoration of command and control, deception, battle handover and passage of lines, relief in place, linkup, breakout operations, and raiding. The shock role, traditionally filled by heavy cavalry, is generally filled by units with the "armored" designation.

Before the Iron Age, the role of cavalry on the battlefield was largely performed by light chariots. The chariot originated with the Sintashta-Petrovka culture in Central Asia and spread by nomadic or semi-nomadic Indo-Iranians. The chariot was quickly adopted by settled peoples both as a military technology and an object of ceremonial status, especially by the pharaohs of the New Kingdom of Egypt from 1550 BC as well as the Assyrian army and Babylonian royalty.

The power of mobility given by mounted units was recognized early on, but was offset by the difficulty of raising large forces and by the inability of horses (then mostly small) to carry heavy armor. Nonetheless, there are indications that, from the 15th century BC onwards, horseback riding was practiced amongst the military elites of the great states of the ancient Near East, most notably those in Egypt, Assyria, the Hittite Empire, and Mycenaean Greece.

Cavalry techniques, and the rise of true cavalry, were an innovation of equestrian nomads of the Central Asian and Iranian steppe and pastoralist tribes such as the Iranic Parthians and Sarmatians.
The photograph above left shows Assyrian cavalry from reliefs of 865–860 BC. At this time, the men had no spurs, saddles, saddle cloths, or stirrups. Fighting from the back of a horse was much more difficult than mere riding. The cavalry acted in pairs; the reins of the mounted archer were controlled by his neighbour's hand. Even at this early time, cavalry used swords, shields, spears, and bows. The sculpture implies two types of cavalry, but this might be a simplification by the artist. Later images of Assyrian cavalry show saddle cloths as primitive saddles, allowing each archer to control his own horse.

As early as 490 BC a breed of large horses was bred in the Nisaean plain in Media to carry men with increasing amounts of armour (Herodotus 7,40 & 9,20), but large horses were still very exceptional at this time. By the fourth century BC the Chinese during the Warring States period (403–221 BC) began to use cavalry against rival states, and by 331 BC when Alexander the Great defeated the Persians the use of chariots in battle was obsolete in most nations; despite a few ineffective attempts to revive scythed chariots. The last recorded use of chariots as a shock force in continental Europe was during the Battle of Telamon in 225 BC.
However, chariots remained in use for ceremonial purposes such as carrying the victorious general in a Roman triumph, or for racing.

Outside of mainland Europe, the southern Britons met Julius Caesar with chariots in 55 and 54 BC, but by the time of the Roman conquest of Britain a century later chariots were obsolete, even in Britannia. The last mention of chariot use in Britain was by the Caledonians at the Mons Graupius, in 84 AD.

During the classical Greek period cavalry were usually limited to those citizens who could afford expensive war-horses. Three types of cavalry became common: light cavalry, whose riders, armed with javelins, could harass and skirmish; heavy cavalry, whose troopers, using lances, had the ability to close in on their opponents; and finally those whose equipment allowed them to fight either on horseback or foot. The role of horsemen did however remain secondary to that of the hoplites or heavy infantry who comprised the main strength of the citizen levies of the various city states.

Cavalry played a relatively minor role in ancient Greek city-states, with conflicts decided by massed armored infantry. However, Thebes produced Pelopidas, their first great cavalry commander, whose tactics and skills were absorbed by Phillip II of Macedon when Phillip was a guest-hostage in Thebes. Thessaly was widely known for producing competent cavalrymen, and later experiences in wars both with and against the Persians taught the Greeks the value of cavalry in skirmishing and pursuit. The Athenian author and soldier Xenophon in particular advocated the creation of a small but well-trained cavalry force; to that end, he wrote several manuals on horsemanship and cavalry operations.

The Macedonian Kingdom in the north, on the other hand, developed a strong cavalry force that culminated in the "hetairoi" (Companion cavalry) of Philip II of Macedon and Alexander the Great. In addition to these heavy cavalry, the Macedonian army also employed lighter horsemen called prodromoi for scouting and screening, as well as the Macedonian pike phalanx and various kinds of light infantry. There were also the "Ippiko" (or "Horserider"), Greek "heavy" cavalry, armed with kontos (or cavalry lance), and sword. These wore leather armour or mail plus a helmet. They were medium rather than heavy cavalry, meaning that they were better suited to be scouts, skirmishers, and pursuers rather than front line fighters. The effectiveness of this combination of cavalry and infantry helped to break enemy lines and was most dramatically demonstrated in Alexander's conquests of Persia, Bactria, and northwestern India.

The cavalry in the early Roman Republic remained the preserve of the wealthy landed class known as the "equites"—men who could afford the expense of maintaining a horse in addition to arms and armor heavier than those of the common legions. Horses were provided by the Republic and could be withdrawn if neglected or misused, together with the status of being a cavalryman.

As the class grew to be more of a social elite instead of a functional property-based military grouping, the Romans began to employ Italian socii for filling the ranks of their cavalry. The weakness of Roman cavalry was demonstrated by Hannibal Barca during the Second Punic War where he used his superior mounted forces to win several battles. The most notable of these was the Battle of Cannae, where he inflicted a catastrophic defeat on the Romans. At about the same time the Romans began to recruit foreign auxiliary cavalry from among Gauls, Iberians, and Numidians, the last being highly valued as mounted skirmishers and scouts (see Numidian cavalry). Julius Caesar had a high opinion of his escort of Germanic mixed cavalry, giving rise to the "Cohortes Equitatae". Early emperors maintained an ala of Batavian cavalry as their personal bodyguards until the unit was dismissed by Galba after the Batavian Rebellion.

For the most part, Roman cavalry during the early Republic functioned as an adjunct to the legionary infantry and formed only one-fifth of the standing force comprising a consular army. Except in times of major mobilisation about 1,800 horsemen were maintained, with three hundred attached to each legion. 
The relatively low ratio of horsemen to infantry does not mean that the utility of cavalry should be underestimated, as its strategic role in scouting, skirmishing, and outpost duties was crucial to the Romans' capability to conduct operations over long distances in hostile or unfamiliar territory. On some occasions Roman cavalry also proved its ability to strike a decisive tactical blow against a weakened or unprepared enemy, such as the final charge at the Battle of Aquilonia.

After defeats such as the Battle of Carrhae, the Romans learned the importance of large cavalry formations from the Parthians. 
At the same time heavy spears and shields modelled on those favoured by the horsemen of the Greek city-states were adopted to replace the lighter weaponry of early Rome. 
These improvements in tactics and equipment reflected those of a thousand years earlier when the first Iranians to reach the Iranian Plateau forced the Assyrians to undertake similar reform. Nonetheless, the Romans would continue to rely mainly on their heavy infantry supported by auxiliary cavalry.

In the army of the late Roman Empire, cavalry played an increasingly important role. The Spatha, the classical sword throughout most of the 1st millennium was adopted as the standard model for the Empire's cavalry forces.

The most widespread employment of heavy cavalry at this time was found in the forces of the Iranian empires, the Parthians and their Persian Sasanian successors. Both, but especially the former, were famed for the cataphract (fully armored cavalry armed with lances) even though the majority of their forces consisted of lighter horse archers. The West first encountered this eastern heavy cavalry during the Hellenistic period with further intensive contacts during the eight centuries of the Roman–Persian Wars. At first the Parthians' mobility greatly confounded the Romans, whose armoured close-order infantry proved unable to match the speed of the Parthians. However, later the Romans would successfully adapt such heavy armor and cavalry tactics by creating their own units of cataphracts and "clibanarii".

The decline of the Roman infrastructure made it more difficult to field large infantry forces, and during the 4th and 5th centuries cavalry began to take a more dominant role on the European battlefield, also in part made possible by the appearance of new, larger breeds of horses. The replacement of the Roman saddle by variants on the Scythian model, with pommel and cantle, was also a significant factor as was the adoption of stirrups and the concomitant increase in stability of the rider's seat. Armored cataphracts began to be deployed in eastern Europe and the Near East, following the precedents established by Persian forces, as the main striking force of the armies in contrast to the earlier roles of cavalry as scouts, raiders, and outflankers.

The late-Roman cavalry tradition of organized units in a standing army differed fundamentally from the nobility of the Germanic invaders—individual warriors who could afford to provide their own horses and equipment. While there was no direct linkage with these predecessors the early medieval knight also developed as a member of a social and martial elite, able to meet the considerable expenses required by his role from grants of land and other incomes.

Xiongnu, Tujue, Avars, Kipchaks, Khitans, Mongols, Don Cossacks and the various Turkic peoples are also examples of the horse-mounted groups that managed to gain substantial successes in military conflicts with settled agrarian and urban societies, due to their strategic and tactical mobility. As European states began to assume the character of bureaucratic nation-states supporting professional standing armies, recruitment of these mounted warriors was undertaken in order to fill the strategic roles of scouts and raiders.
The best known instance of the continued employment of mounted tribal auxiliaries were the Cossack cavalry regiments of the Russian Empire. In eastern Europe, Russia, and out onto the steppes, cavalry remained important much longer and dominated the scene of warfare until the early 17th century and even beyond, as the strategic mobility of cavalry was crucial for the semi-nomadic pastoralist lives that many steppe cultures led. Tibetans also had a tradition of cavalry warfare, in several military engagements with the Chinese Tang dynasty (618–907 AD).

Further east, the military history of China, specifically northern China, held a long tradition of intense military exchange between Han Chinese infantry forces of the settled dynastic empires and the mounted nomads or "barbarians" of the north. The naval history of China was centered more to the south, where mountains, rivers, and large lakes necessitated the employment of a large and well-kept navy.

In 307 BC, King Wuling of Zhao, the ancient Chinese ruler of the former State of Jin territory, ordered his military commanders and troops to adopt the trousers of the nomads as well as practice the nomads' form of mounted archery to hone their new cavalry skills.
The adoption of massed cavalry in China also broke the tradition of the chariot-riding Chinese aristocracy in battle, which had been in use since the ancient Shang Dynasty (c 1600–1050 BC). By this time large Chinese infantry-based armies of 100,000 to 200,000 troops were now buttressed with several hundred thousand mounted cavalry in support or as an effective striking force. The handheld pistol-and-trigger crossbow was invented in China in the fourth century BC; it was written by the Song dynasty scholars Zeng Gongliang, Ding Du, and Yang Weide in their book "Wujing Zongyao" (1044 AD) that massed missile fire by crossbowmen was the most effective defense against enemy cavalry charges.
On many occasions the Chinese studied nomadic cavalry tactics and applied the lessons in creating their own potent cavalry forces, while in others they simply recruited the tribal horsemen wholesale into their armies; and in yet other cases nomadic empires proved eager to enlist Chinese infantry and engineering, as in the case of the Mongol Empire and its sinicized part, the Yuan Dynasty (1279–1368). The Chinese recognized early on during the Han Dynasty (202 BC – 220 AD) that they were at a disadvantage in lacking the number of horses the northern nomadic peoples mustered in their armies. Emperor Wu of Han (r 141–87 BC) went to war with the Dayuan for this reason, since the Dayuan were hoarding a massive amount of tall, strong, Central Asian bred horses in the Hellenized–Greek region of Fergana (established slightly earlier by Alexander the Great). Although experiencing some defeats early on in the campaign, Emperor Wu's war from 104 BC to 102 BC succeeded in gathering the prized tribute of horses from Fergana.

Cavalry tactics in China were enhanced by the invention of the saddle-attached stirrup by at least the 4th century, as the oldest reliable depiction of a rider with paired stirrups was found in a Jin Dynasty tomb of the year 322 AD. The Chinese invention of the horse collar by the 5th century was also a great improvement from the breast harness, allowing the horse to haul greater weight without heavy burden on its skeletal structure.

The horse warfare of Korea was first started during the ancient Korean kingdom Gojoseon. Since at least the 3rd century BC, there was influence of northern nomadic peoples and Yemaek peoples on Korean warfare. By roughly the first century BC, the ancient kingdom of Buyeo also had mounted warriors. The cavalry of Goguryeo, one of the Three Kingdoms of Korea, were called "Gaemamusa" (개마무사, 鎧馬武士), and were renowned as a fearsome heavy cavalry force. King Gwanggaeto the Great often led expeditions into the Baekje, Gaya confederacy, Buyeo, Later Yan and against Japanese invaders with his cavalry.
In the 12th century, Jurchen tribes began to violate the Goryeo–Jurchen borders, and eventually invaded Goryeo Korea. After experiencing the invasion by the Jurchen, Korean general Yun Gwan realized that Goryeo lacked efficient cavalry units. He reorganized the Goryeo military into a professional army that would contain decent and well-trained cavalry units. In 1107, the Jurchen were ultimately defeated, and surrendered to Yun Gwan. To mark the victory, General Yun built nine fortresses to the northeast of the Goryeo–Jurchen borders (동북 9성, 東北 九城).

The ancient Japanese of the Kofun period also adopted cavalry and equine culture by the 5th century AD. The emergence of the samurai aristocracy led to the development of armoured horse archers, themselves to develop into charging lancer cavalry as gunpowder weapons rendered bows obsolete.

An example is Yabusame (流鏑馬?), a type of mounted archery in traditional Japanese archery. An archer on a running horse shoots three special "turnip-headed" arrows successively at three wooden targets.

This style of archery has its origins at the beginning of the Kamakura period. Minamoto no Yoritomo became alarmed at the lack of archery skills his samurai had. He organized yabusame as a form of practice.
Currently, the best places to see yabusame performed are at the Tsurugaoka Hachiman-gū in Kamakura and Shimogamo Shrine in Kyoto (during Aoi Matsuri in early May). It is also performed in Samukawa and on the beach at Zushi, as well as other locations.

Kasagake or Kasakake (笠懸, かさがけ lit. "hat shooting") is a type of Japanese mounted archery. In contrast to yabusame, the types of targets are various and the archer shoots without stopping the horse. While yabusame has been played as a part of formal ceremonies, kasagake has developed as a game or practice of martial arts, focusing on technical elements of horse archery.

In the Indian subcontinent, cavalry played a major role from the Gupta Dynasty (320–600) period onwards. India has also the oldest evidence for the introduction of toe-stirrups.

Indian literature contains numerous references to the mounted warriors of the Central Asian horse nomads, notably the Sakas, Kambojas, Yavanas, Pahlavas and Paradas. Numerous Puranic texts refer to a conflict in ancient India (16th century BC) in which the horsemen of five nations, called the "Five Hordes" ("pañca.ganan") or Kṣatriya hordes ("Kṣatriya ganah"), attacked and captured the state of Ayudhya by dethroning its Vedic King Bahu

The Mahabharata, Ramayana, numerous Puranas and some foreign sources attest that the Kamboja cavalry frequently played role in ancient wars. V. R. Ramachandra Dikshitar writes: "Both the Puranas and the epics agree that the horses of the Sindhu and Kamboja regions were of the finest breed, and that the services of the Kambojas as cavalry troopers were utilised in ancient wars". J.A.O.S. writes: "Most famous horses are said to come either from Sindhu or Kamboja; of the latter (i.e. the Kamboja), the Indian epic Mahabharata speaks among the finest horsemen".

Mahabharata (c 950 BC) speaks of the esteemed cavalry of the Kambojas, Sakas, Yavanas and Tusharas, all of whom had participated in the Kurukshetra war under the supreme command of Kamboja ruler Sudakshin Kamboj.

Mahabharata and Vishnudharmottara Purana especially styles the Kambojas, Yavansa, Gandharas etc. as "Ashva.yuddha.kushalah" (expert cavalrymen). In the Mahabharata war, the Kamboja cavalry along with that of the Sakas, Yavanas is reported to have been enlisted by the Kuru king Duryodhana of Hastinapura.

Herodotus (c 484 – c 425 BC) attests that the Gandarian mercenaries (i.e. "Gandharans/Kambojans" of Gandari Strapy of Achaemenids) from the 20th strapy of the Achaemenids were recruited in the army of emperor Xerxes I (486–465 BC), which he led against the Hellas. Similarly, the "men of the Mountain Land " from north of Kabol-River equivalent to medieval Kohistan (Pakistan), figure in the army of Darius III against Alexander at Arbela, providing a cavalry force and 15 elephants. This obviously refers to Kamboja cavalry south of Hindukush.

The Kambojas were famous for their horses, as well as cavalrymen ("asva-yuddha-Kushalah"). On account of their supreme position in horse (Ashva) culture, they were also popularly known as Ashvakas, i.e. the "horsemen" and their land was known as "Home of Horses". They are the Assakenoi and Aspasioi of the Classical writings, and the Ashvakayanas and Ashvayanas in Pāṇini's Ashtadhyayi. The Assakenoi had faced Alexander with 30,000 infantry, 20,000 cavalry and 30 war elephants. Scholars have identified the Assakenoi and Aspasioi clans of Kunar and Swat valleys as a section of the Kambojas. These hardy tribes had offered stubborn resistance to Alexander (c 326 BC) during latter's campaign of the Kabul, Kunar and Swat valleys and had even extracted the praise of the Alexander's historians. These highlanders, designated as ""parvatiya Ayudhajivinah"" in Pāṇini's Astadhyayi, were rebellious, fiercely independent and freedom-loving cavalrymen who never easily yielded to any overlord.

The Sanskrit drama "Mudra-rakashas" by "Visakha Dutta" and the Jaina work "Parishishtaparvan" refer to Chandragupta's (c 320 BC – c 298 BC) alliance with Himalayan king "Parvataka". The Himalayan alliance gave Chandragupta a formidable composite army made up of the cavalry forces of the Shakas, Yavanas, Kambojas, Kiratas, Parasikas and Bahlikas as attested by Mudra-Rakashas (Mudra-Rakshasa 2). These hordes had helped Chandragupta Maurya defeat the ruler of Magadha and placed Chandragupta on the throne, thus laying the foundations of Mauryan Dynasty in Northern India.

The cavalry of Hunas and the Kambojas is also attested in the Raghu Vamsa epic poem of Sanskrit poet Kalidasa. Raghu of Kalidasa is believed to be Chandragupta II ("Vikaramaditya") (375–413/15 AD), of the well-known Gupta Dynasty.

As late as mediaeval era, the Kamboja cavalry had also formed part of the Gurjara-Pratihara armed forces from the eighth to the 10th centuries AD. They had come to Bengal with the Pratiharas when the latter conquered part of the province.

Ancient Kambojas organised military "Sanghas" and Srenis (corporations) to manage their political and military affairs, as Arthashastra of Kautiliya as well as the Mahabharata record. They are described as "Ayuddha-jivi" or "Shastr-opajivis" (nations-in-arms), which also means that the Kamboja cavalry offered its military services to other nations as well. There are numerous references to Kambojas having been requisitioned as cavalry troopers in ancient wars by outside nations.

As the quality and availability of heavy infantry declined in Europe with the fall of the Roman Empire, heavy cavalry became more effective. Infantry that lack the cohesion and discipline of tight formations are more susceptible to being broken and scattered by shock combat—the main role of heavy cavalry, which rose to become the dominant force on the European battlefield.

As heavy cavalry increased in importance, it became the main focus of military development. The arms and armour for heavy cavalry increased, the high-backed saddle developed, and stirrups and spurs were added, increasing the advantage of heavy cavalry even more.

This shift in military importance was reflected in society as well; knights took centre stage both on and off the battlefield. These are considered the "ultimate" in heavy cavalry: well-equipped with the best weapons, state-of-the-art armour from head to foot, leading with the lance in battle in a full-gallop, close-formation "knightly charge" that might prove irresistible, winning the battle almost as soon as it begun.

But knights remained the minority of total available combat forces; the expense of arms, armour, and horses was only affordable to a select few. While mounted men-at-arms focused on a narrow combat role of shock combat, medieval armies relied on a large variety of foot troops to fulfill all the rest (skirmishing, flank guards, scouting, holding ground, etc.). Medieval chroniclers tended to pay undue attention to the knights at the expense of the common soldiers, which led early students of military history to suppose that heavy cavalry was the only force that mattered on medieval European battlefields. But well-trained and disciplined infantry could defeat knights.

Massed English longbowmen triumphed over French cavalry at Crécy, Poitiers and Agincourt, while at Gisors (1188), Bannockburn (1314), and Laupen (1339), foot-soldiers proved they could resist cavalry charges as long as they held their formation. Once the Swiss developed their pike squares for offensive as well as defensive use, infantry started to become the principal arm. This aggressive new doctrine gave the Swiss victory over a range of adversaries, and their enemies found that the only reliable way to defeat them was by the use of an even more comprehensive combined arms doctrine, as evidenced in the Battle of Marignano. The introduction of missile weapons that required less skill than the longbow, such as the crossbow and hand cannon, also helped remove the focus somewhat from cavalry elites to masses of cheap infantry equipped with easy-to-learn weapons. These missile weapons were very successfully used in the Hussite Wars, in combination with Wagenburg tactics.

This gradual rise in the dominance of infantry led to the adoption of dismounted tactics. From the earliest times knights and mounted men-at-arms had frequently dismounted to handle enemies they could not overcome on horseback, such as in the Battle of the Dyle (891) and the Battle of Bremule (1119), but after the 1350s this trend became more marked with the dismounted men-at-arms fighting as super-heavy infantry with two-handed swords and poleaxes. In any case, warfare in the Middle Ages tended to be dominated by raids and sieges rather than pitched battles, and mounted men-at-arms rarely had any choice other than dismounting when faced with the prospect of assaulting a fortified position.

The Islamic Prophet Muhammad made use of cavalry in many of his military campaigns including the Expedition of Dhu Qarad, and the expedition of Zaid ibn Haritha in al-Is which took place in September, 627 AD, fifth month of 6 AH of the Islamic calendar.

Early organized Arab mounted forces under the Rashidun caliphate comprised a light cavalry armed with lance and sword. Its main role was to attack the enemy flanks and rear. These relatively lightly armored horsemen formed the most effective element of the Muslim armies during the later stages of the Islamic conquest of the Levant. The best use of this lightly armed fast moving cavalry was revealed at the Battle of Yarmouk (636 AD) in which Khalid ibn Walid, knowing the skills of his horsemen, used them to turn the tables at every critical instance of the battle with their ability to engage, disengage, then turn back and attack again from the flank or rear. A strong cavalry regiment was formed by Khalid ibn Walid which included the veterans of the campaign of Iraq and Syria. Early Muslim historians have given it the name "Mutaharrik tulai'a"( متحرك طليعة ), or the Mobile guard. This was used as an advance guard and a strong striking force to route the opposing armies with its greater mobility that give it an upper hand when maneuvering against any Byzantine army. With this mobile striking force, the conquest of Syria was made easy.

The Battle of Talas in 751 AD was a conflict between the Arab Abbasid Caliphate and the Chinese Tang dynasty over the control of Central Asia. Chinese infantry were routed by Arab cavalry near the bank of the River Talas.

Later Mamluks were trained as cavalry soldiers. Mamluks were to follow the dictates of al-furusiyya, a code of conduct that included values like courage and generosity but also doctrine of cavalry tactics, horsemanship, archery and treatment of wounds.

The Islamic Berber states of North Africa employed elite horse mounted cavalry armed with spears and following the model of the original Arab occupiers of the region. Horse-harness and weapons were manufactured locally and the six-monthly stipends for horsemen were double those of their infantry counterparts. During the 8th century Islamic conquest of Iberia large numbers of horses and riders were shipped from North Africa, to specialise in raiding and the provision of support for the massed Berber footmen of the main armies.

Maghrebi traditions of mounted warfare eventually influenced a number of sub-Saharan African polities in the medieval era. The Esos of Ikoyi, military aristocrats of the Yoruba peoples, were a notable manifestation of this phenomenon.

Qizilbash, were a class of Safavid militant warriors in Iran during the 15th to 18th centuries, who often fought as elite cavalry.

The Mughal armies ("lashkar") were primarily a cavalry force. The elite corps were the "ahadi" who provided direct service to the Emperor and acted as guard cavalry. Supplementary cavalry or "dakhilis" were recruited, equipped and paid by the central state. This was in contrast to the "tabinan" horsemen who were the followers of individual noblemen. Their training and equipment varied widely but they made up the backbone of the Mughal cavalry. Finally there were tribal irregulars led by and loyal to tributary chiefs. These included Hindus, Afghans and Turks summoned for military service when their autonomous leaders were called on by the Imperial government.

Ironically, the rise of infantry in the early 16th century coincided with the "golden age" of heavy cavalry; a French or Spanish army at the beginning of the century could have up to half its numbers made up of various kinds of light and heavy cavalry, whereas in earlier medieval and later 17th-century armies the proportion of cavalry was seldom more than a quarter.

Knighthood largely lost its military functions and became more closely tied to social and economic prestige in an increasingly capitalistic Western society. With the rise of drilled and trained infantry, the mounted men-at-arms, now sometimes called "gendarmes" and often part of the standing army themselves, adopted the same role as in the Hellenistic age, that of delivering a decisive blow once the battle was already engaged, either by charging the enemy in the flank or attacking their commander-in-chief.

From the 1550s onwards, the use of gunpowder weapons solidified infantry's dominance of the battlefield and began to allow true mass armies to develop. This is closely related to the increase in the size of armies throughout the early modern period; heavily armored cavalrymen were expensive to raise and maintain and it took years to replace a skilled horseman or a trained horse, while arquebusiers and later musketeers could be trained and kept in the field at much lower cost, and were much easier to replace.

The Spanish tercio and later formations relegated cavalry to a supporting role. The pistol was specifically developed to try to bring cavalry back into the conflict, together with manoeuvres such as the caracole. The caracole was not particularly successful, however, and the charge (whether with sword, pistol, or lance) remained as the primary mode of employment for many types of European cavalry, although by this time it was delivered in much deeper formations and with greater discipline than before. The demi-lancers and the heavily armored sword-and-pistol reiters were among the types of cavalry whose heyday was in the 16th and 17th centuries, as for the Polish winged hussars, a heavy cavalry force that achieved great success against Swedes, Russians, and Turks.

Cavalry retained an important role in this age of regularization and standardization across European armies. First and foremost they remained the primary choice for confronting enemy cavalry. Attacking an unbroken infantry force head-on usually resulted in failure, but extended linear infantry formations were vulnerable to flank or rear attacks. Cavalry was important at Blenheim (1704), Rossbach (1757), Eylau and Friedland (1807), remaining significant throughout the Napoleonic Wars.

Even with the increasing prominence of infantry, cavalry still had an important place in armies. They often patrolled the fringes of army encampments, with standing orders to intercept and kill suspected shirkers and deserters on sight. Cavalry units also served as outpost pickets in advance of the main body. During battle they might charge and override artillery cannon, plugging the touchholes with iron spikes. They also pursued enemy infantrymen who had broken from formation, as well as snipers.

The greatest cavalry charge of modern history was at the 1807 battle of Eylau, when the entire 11,000-strong French cavalry reserve, led by Maréchal Murat, launched a huge charge on and through the Russian infantry lines. However, in 1815 at the Battle of Waterloo, repeated charges by up to 9,000 French cavalrymen failed to break the line of the British and German infantry, who had formed squares.

Massed infantry was deadly to cavalry, but offered an excellent target for artillery. Once the bombardment had disordered the infantry formation, cavalry were able to rout and pursue the scattered foot soldiers. It was not until individual firearms gained accuracy and improved rates of fire that cavalry was diminished in this role as well. Even then light cavalry remained an indispensable tool for scouting, screening the army's movements, and harassing the enemy's supply lines until military aircraft supplanted them in this role in the early stages of World War I.

By the beginning of the 19th century, European cavalry fell into four main categories:


There were cavalry variations for individual nations as well: France had the "chasseurs à cheval"; Prussia had the "Jäger zu Pferd"; Bavaria, Saxony and Austria had the "Chevaulegers"; and Russia had Cossacks. Britain, from the mid-18th century, had Light Dragoons as light cavalry and Dragoons, Dragoon Guards and Household Cavalry as heavy cavalry. Only after the end of the Napoleonic wars were the Household Cavalry equipped with cuirasses, and some other regiments were converted to lancers. In the United States Army the cavalry were almost always dragoons. The Imperial Japanese Army had its cavalry uniformed as hussars, but they fought as dragoons.

In the Crimean War, the Charge of the Light Brigade and the Thin Red Line at the Battle of Balaclava showed the vulnerability of cavalry, when deployed without effective support.

During the Franco-Prussian War, at the Battle of Mars-la-Tour in 1870, a Prussian cavalry brigade decisively smashed the centre of the French battle line, after skilfully concealing their approach. This event became known as Von Bredow's Death Ride after the brigade commander Adalbert von Bredow; it would be used in the following decades to argue that massed cavalry charges still had a place on the modern battlefield.

Cavalry found a new role in colonial campaigns (irregular warfare), where modern weapons were lacking and the slow moving infantry-artillery train or fixed fortifications were often ineffective against indigenous insurgents (unless the latter offered a fight on an equal footing, as at Tel-el-Kebir, Omdurman, etc.). Cavalry "flying columns" proved effective, or at least cost-effective, in many campaigns—although an astute native commander (like Samori in western Africa, Shamil in the Caucasus, or any of the better Boer commanders) could turn the tables and use the greater mobility of their cavalry to offset their relative lack of firepower compared with European forces.

In 1903 the British Indian Army maintained forty regiments of cavalry, numbering about 25,000 Indian sowars (cavalrymen), with British and Indian officers.

Several of these formations are still active, though they now are armoured formations, for example the Guides Cavalry of Pakistan.
The French Army maintained substantial cavalry forces in Algeria and Morocco from 1830 until the end of the Second World War. Much of the Mediterranean coastal terrain was suitable for mounted action and there was a long established culture of horsemanship amongst the Arab and Berber inhabitants. The French forces included Spahis, Chasseurs d' Afrique, Foreign Legion cavalry and mounted Goumiers. Both Spain and Italy raised cavalry regiments from amongst the indigenous horsemen of their North African territories (see regulares, Italian Spahis and savari respectively).

Imperial Germany employed mounted formations in South West Africa as part of the Schutztruppen (colonial army) garrisoning the territory.

In the early American Civil War the regular United States Army mounted rifle, dragoon, and two existing cavalry regiments were reorganized and renamed cavalry regiments, of which there were six. Over a hundred other federal and state cavalry regiments were organized, but the infantry played a much larger role in many battles due to its larger numbers, lower cost per rifle fielded, and much easier recruitment. However, cavalry saw a role as part of screening forces and in foraging and scouting. The later phases of the war saw the Federal army developing a truly effective cavalry force fighting as scouts, raiders, and, with repeating rifles, as mounted infantry. The distinguished 1st Virginia Cavalry ranks as one of the most effectual and successful cavalry units on the Confederate side. Noted cavalry commanders included Confederate general J.E.B. Stuart, Nathan Bedford Forrest, and John Singleton Mosby (a.k.a. "The Grey Ghost") and on the Union side, Philip Sheridan and George Armstrong Custer.
Post Civil War, as the volunteer armies disbanded, the regular army cavalry regiments increased in number from six to ten, among them Custer's U.S. 7th Cavalry Regiment of Little Bighorn fame, and the African-American U.S. 9th Cavalry Regiment and U.S. 10th Cavalry Regiment. The black units, along with others (both cavalry and infantry), collectively became known as the Buffalo Soldiers. According to Robert M. Utley: 

These regiments, which rarely took the field as complete organizations, served throughout the American Indian Wars through the close of the frontier in the 1890s. Volunteer cavalry regiments like the Rough Riders consisted of horsemen such as cowboys, ranchers and other outdoorsmen, that served as a cavalry in the United States Military.

At the beginning of the 20th century all armies still maintained substantial cavalry forces, although there was contention over whether their role should revert to that of mounted infantry (the historic dragoon function). Following the experience of the South African War of 1899–1902 (where mounted Boer citizen commandos fighting on foot from cover proved more effective than regular cavalry) the British Army withdrew lances for all but ceremonial purposes and placed a new emphasis on training for dismounted action. An Army Order dated 1909 however instructed that the six British lancer regiments then in existence resume use of this impressive but obsolete weapon for active service.

In 1882 the Imperial Russian Army converted all its line hussar and lancer regiments to dragoons, with an emphasis on mounted infantry training. In 1910 these regiments reverted to their historic roles, designations and uniforms.

By 1909 official regulations dictating the role of the Imperial German cavalry had been revised to indicate an increasing realization of the realities of modern warfare. The massive cavalry charge in three waves which had previously marked the end of annual maneuvers was discontinued and a new emphasis was placed in training on scouting, raiding and pursuit; rather than main battle involvement. The perceived importance of cavalry was however still evident, with thirteen new regiments of mounted rifles ("Jager zu Pferde") being raised shortly before the outbreak of war in 1914. 

In spite of significant experience in mounted warfare in Morocco during 1908–14, the French cavalry remained a highly conservative institution. The traditional tactical distinctions between heavy, medium, and light cavalry branches were retained. French cuirassiers wore breastplates and plumed helmets unchanged from the Napoleonic period, during the early months of World War I. Dragoons were similarly equipped, though they did not wear cuirasses and did carry lances.
Light cavalry were described as being "a blaze of colour". French cavalry of all branches were well mounted and were trained to change position and charge at full gallop. One weakness in training was that French cavalrymen seldom dismounted on the march and their horses suffered heavily from raw backs in August 1914.

In August 1914 all combatant armies still retained substantial numbers of cavalry and the mobile nature of the opening battles on both Eastern and Western Fronts provided a number of instances of traditional cavalry actions, though on a smaller and more scattered scale than those of previous wars. The Imperial German cavalry, while as colourful and traditional as any in peacetime appearance, had adopted a practice of falling back on infantry support when any substantial opposition was encountered. These cautious tactics aroused derision amongst their more conservative French and Russian opponents but proved appropriate to the new nature of warfare. A single attempt by the German army, on 12 August 1914, to use six regiments of massed cavalry to cut off the Belgian field army from Antwerp foundered when they were driven back in disorder by rifle fire. The two German cavalry brigades involved lost 492 men and 843 horses in repeated charges against dismounted Belgian lancers and infantry. Once the front lines stabilised on the Western Front, a combination of barbed wire, machine guns and rapid fire rifles proved deadly to horse mounted troops.

On the Eastern Front a more fluid form of warfare arose from flat open terrain favorable to mounted warfare. On the outbreak of war in 1914 the bulk of the Russian cavalry was deployed at full strength in frontier garrisons and during the period that the main armies were mobilizing scouting and raiding into East Prussia and Austrian Galicia was undertaken by mounted troops trained to fight with sabre and lance in the traditional style. On 21 August 1914 the 4th Austro-Hungarian "Kavalleriedivison" fought a major mounted engagement at Jaroslavic with the Russian 10th Cavalry Division, in what was arguably the final historic battle to involve thousands of horsemen on both sides. While this was the last massed cavalry encounter on the Eastern Front, the absence of good roads limited the use of mechanized transport and even the technologically advanced Imperial German Army continued to deploy up to twenty-four horse-mounted divisions in the East, as late as 1917.

For the remainder of the War on the Western Front cavalry had virtually no role to play. The British and French armies dismounted many of their cavalry regiments and used them in infantry and other roles: the Life Guards for example spent the last months of the War as a machine gun corps; and the Australian Light Horse served as light infantry during the Gallipoli campaign. In September 1914 cavalry comprised 9.28% of the total manpower of the British Expeditionary Force in France—by July 1918 this proportion had fallen to 1.65%. As early as the first winter of the war most French cavalry regiments had dismounted a squadron each, for service in the trenches. The French cavalry numbered 102,000 in May 1915 but had been reduced to 63,000 by October 1918.
The German Army dismounted nearly all their cavalry in the West, maintaining only one mounted division on that front by January 1917.
Italy entered the war in 1915 with thirty regiments of line cavalry, lancers and light horse. While employed effectively against their Austro-Hungarian counterparts during the initial offensives across the Isonzo River, the Italian mounted forces ceased to have a significant role as the front shifted into mountainous terrain. By 1916 all cavalry machine-gun sections and two complete cavalry divisions had been dismounted and seconded to the infantry.

Some cavalry were retained as mounted troops behind the lines in anticipation of a penetration of the opposing trenches that it seemed would never come. Tanks, introduced on the Western Front by the British in September 1916, had the capacity to achieve such breakthroughs but did not have the reliable range to exploit them. In their first major use at the Battle of Cambrai (1917), the plan was for a cavalry division to follow behind the tanks, however they were not able to cross a canal because a tank had broken the only bridge. It was not until the German Army had been forced to retreat in the Hundred Days Offensive of 1918, that cavalry were again able to operate in their intended role. There was a successful charge by the British 7th Dragoon Guards on the last day of the war.

In the wider spaces of the Eastern Front a more fluid form of warfare continued and there was still a use for mounted troops. Some wide-ranging actions were fought, again mostly in the early months of the war. However, even here the value of cavalry was overrated and the maintenance of large mounted formations at the front by the Russian Army put a major strain on the railway system, to little strategic advantage. In February 1917 the Russian regular cavalry (exclusive of Cossacks) was reduced by nearly a third from its peak number of 200,000, as two squadrons of each regiment were dismounted and incorporated into additional infantry battalions. Their Austro-Hungarian opponents, plagued by a shortage of trained infantry, had been obliged to progressively convert most horse cavalry regiments to dismounted rifle units starting in late 1914.

In the Middle East, during the Sinai and Palestine Campaign mounted forces (British, Indian, Ottoman, Australian, Arab and New Zealand) retained an important strategic role both as mounted infantry and cavalry.

In Egypt the mounted infantry formations like the New Zealand Mounted Rifles Brigade and Australian Light Horse of ANZAC Mounted Division, operating as mounted infantry, drove German and Ottoman forces back from Romani to Magdhaba and Rafa and out of the Egyptian Sinai Peninsula in 1916.

After a stalemate on the Gaza—Beersheba line between March and October 1917, Beersheba was captured by the Australian Mounted Division's 4th Light Horse Brigade. Their mounted charge succeeded after a coordinated attack by the British Infantry and Yeomanry cavalry and the Australian and New Zealand Light Horse and Mounted Rifles brigades. A series of coordinated attacks by these Egyptian Expeditionary Force infantry and mounted troops were also successful at the Battle of Mughar Ridge, during which the British infantry divisions and the Desert Mounted Corps drove two Ottoman armies back to the Jaffa—Jerusalem line. The infantry with mainly dismounted cavalry and mounted infantry fought in the Judean Hills to eventually almost encircle Jerusalem which was occupied shortly after.

During a pause in operations necessitated by the Spring Offensive in 1918 on the Western Front joint infantry and mounted infantry attacks towards Amman and Es Salt resulted in retreats back to the Jordan Valley which continued to be occupied by mounted divisions during the summer of 1918.

The Australian Mounted Division was armed with swords and in September, after the successful breaching of the Ottoman line on the Mediterranean coast by the British Empire infantry XXI Corps was followed by cavalry attacks by the 4th Cavalry Division, 5th Cavalry Division and Australian Mounted Divisions which almost encircled two Ottoman armies in the Judean Hills forcing their retreat. Meanwhile, Chaytor's Force of infantry and mounted infantry in ANZAC Mounted Division held the Jordan Valley, covering the right flank to later advance eastwards to capture Es Salt and Amman and half of a third Ottoman army. A subsequent pursuit by the 4th Cavalry Division and the Australian Mounted Division followed by the 5th Cavalry Division to Damascus. Armoured cars and 5th Cavalry Division lancers were continuing the pursuit of Ottoman units north of Aleppo when the Armistice of Mudros was signed by the Ottoman Empire.

A combination of military conservatism in almost all armies and post-war financial constraints prevented the lessons of 1914–1918 being acted on immediately. There was a general reduction in the number of cavalry regiments in the British, French, Italian and other Western armies but it was still argued with conviction (for example in the 1922 edition of the "Encyclopædia Britannica") that mounted troops had a major role to play in future warfare. The 1920s saw an interim period during which cavalry remained as a proud and conspicuous element of all major armies, though much less so than prior to 1914.

Cavalry was extensively used in the Russian Civil War and the Soviet-Polish War. The last major cavalry battle was the Battle of Komarów in 1920, between Poland and the Russian Bolsheviks. Colonial warfare in Morocco, Syria, the Middle East and the North West Frontier of India provided some opportunities for mounted action against enemies lacking advanced weaponry.

The post-war German Army (Reichsheer) was permitted a large proportion of cavalry (18 regiments or 16.4% of total manpower) under the conditions of the Treaty of Versailles.

The British Army mechanised all cavalry regiments between 1929 and 1941, redefining their role from horse to armoured vehicles to form the Royal Armoured Corps together with the Royal Tank Regiment. The U.S. Cavalry abandoned its sabres in 1934 and commenced the conversion of its horsed regiments to mechanized cavalry, starting with the First Regiment of Cavalry in January 1933.

During the 1930s the French Army experimented with integrating mounted and mechanised cavalry units into larger formations. Dragoon regiments were converted to motorised infantry (trucks and motor cycles), and cuirassiers to armoured units; while light cavalry (Chasseurs a' Cheval, Hussars and Spahis) remained as mounted sabre squadrons. The theory was that mixed forces comprising these diverse units could utilise the strengths of each according to circumstances. In practice mounted troops proved unable to keep up with fast moving mechanised units over any distance.

The thirty-nine cavalry regiments of the British Indian Army were reduced to twenty-one as the result of a series of amalgamations immediately following World War I. The new establishment remained unchanged until 1936 when three regiments were redesignated as permanent training units, each with six, still mounted, regiments linked to them. In 1938 the process of mechanization began with the conversion of a full cavalry brigade (two Indian regiments and one British) to armoured car and tank units. By the end of 1940 all of the Indian cavalry had been mechanized initially, in the majority of cases, to motorized infantry transported in 15cwt trucks. The last horsed regiment of the British Indian Army (other than the Viceregal Bodyguard and some Indian States Forces regiments) was the 19th King George's Own Lancers which had its final mounted parade at Rawalpindi on 28 October 1939. This unit still exists in the Pakistan Army as an armored regiment.

While most armies still maintained cavalry units at the outbreak of World War II in 1939, significant mounted action was largely restricted to the Polish, Balkan, and Soviet campaigns. Rather than charge their mounts into battle, cavalry units were either used as mounted infantry (using horses to move into position and then dismounting for combat) or as reconnaissance units (especially in areas not suited to tracked or wheeled vehicles).

A popular myth is that Polish cavalry armed with lances charged German tanks during the September 1939 campaign. This arose from misreporting of a single clash on 1 September near Krojanty, when two squadrons of the Polish 18th Lancers armed with sabres scattered German infantry before being caught in the open by German armoured cars.
Two examples illustrate how the myth developed. First, because motorised vehicles were in short supply, the Poles used horses to pull anti-tank weapons into position. Second, there were a few incidents when Polish cavalry was trapped by German tanks, and attempted to fight free. However, this did not mean that the Polish army chose to attack tanks with horse cavalry. Later, on the Eastern Front, the Red Army did deploy cavalry units effectively against the Germans.

A more correct term would be "mounted infantry" instead of "cavalry", as horses were primarily used as a means of transportation, for which they were very suitable in view of the very poor road conditions in pre-war Poland. Another myth describes Polish cavalry as being armed with both sabres and lances; lances were used for peacetime ceremonial purposes only and the primary weapon of the Polish cavalryman in 1939 was a rifle. Individual equipment did include a sabre, probably because of well-established tradition, and in the case of a melee combat this secondary weapon would probably be more effective than a rifle and bayonet. Moreover, the Polish cavalry brigade order of battle in 1939 included, apart from the mounted soldiers themselves, light and heavy machine guns (wheeled), the Anti-tank rifle, model 35, anti-aircraft weapons, anti tank artillery such as the Bofors 37 mm, also light and scout tanks, etc. The last cavalry vs. cavalry mutual charge in Europe took place in Poland during the Battle of Krasnobród, when Polish and German cavalry units clashed with each other.

The last classical cavalry charge of the war took place on March 1, 1945 during the Battle of Schoenfeld by the 1st "Warsaw" Independent Cavalry Brigade. Infantry and tanks had been employed to little effect against the German position, both of which floundered in the open wetlands only to be dominated by infantry and antitank fire from the German fortifications on the forward slope of Hill 157, overlooking the wetlands. The Germans had not taken cavalry into consideration when fortifying their position which, combined with the "Warsaw"s swift assault, overran the German anti-tank guns and consolidated into an attack into the village itself, now supported by infantry and tanks.

The Italian invasion of Greece in October 1940 saw mounted cavalry used effectively by the Greek defenders along the mountainous frontier with Albania. Three Greek cavalry regiments (two mounted and one partially mechanized) played an important role in the Italian defeat in this difficult terrain.

The contribution of Soviet cavalry to the development of modern military operational doctrine and its importance in defeating Nazi Germany has been eclipsed by the louder impact of tanks and airplanes. Despite the view portrayed by German propaganda, soviet cavalry contributed significantly to the defeat of the Axis armies. Their contributions involved being the most mobile troops in the early stages when trucks and other equipment were low in quality the cavalry filled this gap. This included Pavel Belov legendary Corps which earned him the nickname the "Fox", as Belov has never retreated without an order in all of 1941, while also often being the fire squad for retreating units in most dangerous situations. 

Considering their low numbers the Soviet cavalry was among the first leading units to give Germany its first real defeats in the early stages of the war. The full potential was demonstrated during the Battle of Mosocw against Guderian and the powerful central German 9th Army which was successfully driven back. The cavalry holds very important accomplishments as they were the elite of the Soviet forces throughout the whole war. They were the first to complete the encirclement in the Battle of Stalingrad, thus sealing the fate of the German 6th army. The fate of the German capital Berlin also fell to the encirclement of the cavalry units, some Cossack cavalry units made it all the way to Reichstag in April 1945. Trought the whole war, they often lead the army along with tanks performing important tasks such as the capture of bridgeheads which is considered one of the hardest jobs in battle, often doing so with inferior numbers. For instance the 8th Guards Cavalry Regiment of the 2nd Guards Cavalry Division, often fought outnumbered against the best German units such as Guderian's Panzers, other elite units and SS as well as the rare Elefant tanks, finishing the war on the Elbe River meeting with the Americans. 

By the final stages of the war only the Soviet Union was still fielding mounted units in substantial numbers, some in combined mechanized and horse units. The advantage of this approach was that in exploitation mounted infantry could keep pace with advancing tanks. Other factors favoring the retention of mounted forces included the high quality of Russian Cossacks which made about half of all cavalry; and the relative lack of roads suitable for wheeled vehicles in many parts of the Eastern Front. Another consideration was that the logistic capacity required to support very large motorized forces exceeded that necessary for mounted troops. The main usage of the Soviet cavalry involved infiltration through front lines with subsequent deep raids, which disorganized German supply lines. Another role was the pursuit of retreating enemy forces during major frontline operations and breakthroughs.

The last mounted sabre charge by Italian cavalry occurred on August 24, 1942 at Isbuscenski (Russia), when a squadron of the Savoia Cavalry Regiment charged the 812th Siberian Infantry Regiment. The remainder of the regiment, together with the Novara Lancers made a dismounted attack in an action that ended with the retreat of the Russians after heavy losses on both sides. The final Italian cavalry action occurred on October 17, 1942 in Poloj (now Croatia) by a squadron of the Alexandria Cavalry Regiment against a large group of Yugoslav partisans.

Romanian, Hungarian and Italian cavalry were dispersed or disbanded following the retreat of the Axis forces from Russia. Germany still maintained some mounted (mixed with bicycles) SS and Cossack units until the last days of the War.

Finland used mounted troops against Russian forces effectively in forested terrain during the Continuation War. The last Finnish cavalry unit was not disbanded until 1947.

The U.S. Army's last horse cavalry actions were fought during World War II: a) by the 26th Cavalry Regiment—a small mounted regiment of Philippine Scouts which fought the Japanese during the retreat down the Bataan peninsula, until it was effectively destroyed by January 1942; and b) on captured German horses by the mounted reconnaissance section of the U.S. 10th Mountain Division in a spearhead pursuit of the German Army across the Po Valley in Italy in April 1945. The last horsed U.S. Cavalry (the Second Cavalry Division) were dismounted in March 1944.

All British Army cavalry regiments had been mechanised since 1 March 1942 when the Queen's Own Yorkshire Dragoons (Yeomanry) was converted to a motorised role, following mounted service against the Vichy French in Syria the previous year. The final cavalry charge by British Empire forces occurred on 21 March 1942 when a 60 strong patrol of the Burma Frontier Force encountered Japanese infantry near Toungoo airfield in central Myanmar. The Sikh sowars of the Frontier Force cavalry, led by Captain Arthur Sandeman of The Central India Horse (21st King George V's Own Horse), charged in the old style with sabres and most were killed.

In the early stages of World War II, mounted units of the Mongolian People's Army were involved in the Battle of Khalkhin Gol against invading Japanese forces. Soviet forces under the command of Georgy Zhukov, together with Mongolian forces, defeated the Japanese Sixth army and effectively ended the Soviet–Japanese Border Wars. After the Soviet–Japanese Neutrality Pact of 1941, Mongolia remained neutral throughout most of the war, but its geographical situation meant that the country served as a buffer between Japanese forces and the Soviet Union. In addition to keeping around 10% of the population under arms, Mongolia provided half a million trained horses for use by the Soviet Army. In 1945 a partially mounted Soviet-Mongolian Cavalry Mechanized Group played a supporting role on the western flank of the Soviet invasion of Manchuria. The last active service seen by cavalry units of the Mongolian Army occurred in 1946–1948, during border clashes between Mongolia and the Republic of China.

While most modern "cavalry" units have some historic connection with formerly mounted troops this is not always the case. The modern Irish Defence Force (DF) includes a "Cavalry Corps" equipped with armoured cars and Scorpion tracked combat reconnaissance vehicles. The DF has never included horse cavalry since its establishment in 1922 (other than a small mounted escort of Blue Hussars drawn from the Artillery Corps when required for ceremonial occasions). However, the mystique of the cavalry is such that the name has been introduced for what was always a mechanised force.

Some engagements in late 20th and early 21st century guerrilla wars involved mounted troops, particularly against partisan or guerrilla fighters in areas with poor transport infrastructure. Such units were not used as cavalry but rather as mounted infantry. Examples occurred in Afghanistan, Portuguese Africa and Rhodesia. The French Army used existing mounted squadrons of Spahis to a limited extent for patrol work during the Algerian War (1954–62). The Swiss Army maintained a mounted dragoon regiment for combat purposes until 1973. The Portuguese Army used horse mounted cavalry with some success in the wars of independence in Angola and Mozambique in the 1960s and 1970s. During the 1964–79 Rhodesian Bush War the Rhodesian Army created an elite mounted infantry unit called Grey's Scouts to fight unconventional actions against the rebel forces of Robert Mugabe and Joshua Nkomo. The horse mounted infantry of the Scouts were effective and reportedly feared by their opponents in the rebel African forces. In the 1978 to present Afghan Civil War period there have been several instances of horse mounted combat.

Central and South American armies maintained mounted cavalry for longer than those of Asia, Europe, or North America. The Mexican Army included a number of horse mounted cavalry regiments as late as the mid-1990s and the Chilean Army had five such regiments in 1983 as mounted mountain troops.

The Soviet Army retained horse cavalry divisions until 1955, and even at the dissolution of the Soviet Union in 1991, there was an independent horse mounted cavalry squadron in Kyrgyzstan.

Today the Indian Army's 61st Cavalry is reported to be the largest existing horse-mounted cavalry unit still having operational potential. It was raised in 1951 from the amalgamated state cavalry squadrons of Gwalior, Jodhpur, and Mysore. While primarily utilised for ceremonial purposes, the regiment can be deployed for internal security or police roles if required. The 61st Cavalry and the President's Body Guard parade in full dress uniform in New Delhi each year in what is probably the largest assembly of traditional cavalry still to be seen in the world. Both the Indian and the Pakistani armies maintain armoured regiments with the titles of Lancers or Horse, dating back to the 19th century.

As of 2007 the Chinese People's Liberation Army employed two battalions of horse-mounted border guards in Xinjing Military District for border patrol work. The PLA mounted units last saw action during border clashes with Vietnam in the 1970s and 80s, after which most cavalry units were disbanded as part of the major military downsizing of the 1980s.
In the wake of the 2008 Sichuan earthquake, there were calls to rebuild the army horse inventory for disaster relief in difficult terrain. Subsequent Chinese media reporting confirms that the Chinese Army maintains operational horse cavalry at squadron strength in the Mongolia Autonomous Region for scouting and logistical purposes.

The Chilean Army still maintains a mixed armoured cavalry regiment, with elements of it acting as mounted mountain exploration troops, based in the city of Angol, being part of the III Mountain Division, and another independent exploration cavalry detachment in the town of Chaiten. The rugged mountain terrain calls for the use of special horses, suited for that use.

Cavalry or mounted gendarmerie units continue to be maintained for purely or primarily ceremonial purposes by the Algerian, Argentine, Bolivian, Brazilian, British, Bulgarian, Canadian, Chilean, Danish, Dutch, Finnish, French, Hungarian, Indian, Italian, Jordanian, Malaysian, Moroccan, Nepalese, Nigerian, North Korean, Omani, Pakistani, Panamanian, Paraguayan, Peruvian, Polish, Portuguese, Russian, Senegalese, Spanish, Swedish, Thai, Tunisian, Turkmenistan, United States, and Venezuelan armed forces.

A number of armoured regiments in the British Army retain the historic designations of Hussars, Dragoons, Light Dragoons, Dragoon Guards, Lancers and Yeomanry. Only the Household Cavalry (consisting of the Life Guards' mounted squadron, The Blues and Royals' mounted squadron, the State Trumpeters of The Household Cavalry and the Household Cavalry Mounted Band) are maintained for mounted (and dismounted) ceremonial duties in London.

The French Army still has regiments with the historic designations of Cuirassiers, Hussars, Chasseurs, Dragoons and Spahis. Only the cavalry of the Republican Guard and a ceremonial "fanfare" detachment of trumpeters for the cavalry/armoured branch as a whole are now mounted.

In the Canadian Army, a number of regular and reserve units have cavalry roots, including The Royal Canadian Hussars (Montreal), the Governor General's Horse Guards, Lord Strathcona's Horse, The British Columbia Dragoons, The Royal Canadian Dragoons, and the South Alberta Light Horse. Of these, only Lord Strathcona's Horse and the Governor General's Horse Guards maintain an official ceremonial horse-mounted cavalry troop or squadron.

In 2002 the Army of the Russian Federation reintroduced a ceremonial mounted squadron wearing historic uniforms.

Both the Australian and New Zealand armies follow the British practice of maintaining traditional titles (Light Horse or Mounted Rifles) for modern mechanised units. However, neither country retains a horse-mounted unit.

Several armored units of the modern United States Army retain the designation of "Armored cavalry". The United States also has "air cavalry" units equipped with helicopters. The Horse Cavalry Detachment of the U.S. Army's 1st Cavalry Division, made up of active duty soldiers, still functions as an active unit; trained to approximate the weapons, tools, equipment and techniques used by the United States Cavalry in the 1880s.

The First Troop Philadelphia City Cavalry is a volunteer unit within the Pennsylvania Army National Guard which serves as a combat force when in federal service but acts in a mounted disaster relief role when in state service. In addition, the Parsons' Mounted Cavalry is a Reserve Officer Training Corps unit which forms part of the Corps of Cadets at Texas A&M University. Valley Forge Military Academy and College also has a Mounted Company, known as D-Troop .

Some individual U.S. states maintain cavalry units as a part of their respective state defense forces. The Maryland Defense Force includes a cavalry unit, Cavalry Troop A, which serves primarily as a ceremonial unit. The unit training includes a saber qualification course based upon the 1926 U.S. Army course. Cavalry Troop A also assists other Maryland agencies as a rural search and rescue asset. In Massachusetts, The National Lancers trace their lineage to a volunteer cavalry militia unit established in 1836 and are currently organized as an official part of the Massachusetts Organized Militia. The National Lancers maintain three units, Troops A, B, and C, which serve in a ceremonial role and assist in search and rescue missions. In July 2004, the National Lancers were ordered into active state service to guard Camp Curtis Guild during the 2004 Democratic National Convention. The Governor's Horse Guard of Connecticut maintains two companies which are trained in urban crowd control.

Historically, cavalry was divided into horse archers, light cavalry, and heavy cavalry. The differences were their role in combat, the size of the mount, and how much armor was worn by the mount and rider.

Early light cavalry (like the auxiliaries of the Roman army) were typically used to scout and skirmish, to cut down retreating infantry, and for defeating enemy missile troops. Armoured cavalry such as the Byzantine cataphract were used as shock troops—they would charge the main body of the enemy and in many cases, their actions decided the outcome of the battle, hence the later term "battle cavalry".

During the Gunpowder Age, armored cavalry units still retained cuirasses and helmets for their protective value against sword and bayonet strikes, and the morale boost these provide to the wearers. By this time the main difference between light and heavy cavalry was their training; the former was regarded as a tool for harassment and reconnaissance, while the latter was considered best for close-order charges.

Since the development of armored warfare, the distinction between light and heavy armor has persisted basically along the same lines. Armored cars and light tanks have adopted the reconnaissance role while medium and heavy tanks are regarded as the decisive shock troops.

From the beginning of civilization to the 20th century, ownership of heavy cavalry horses has been a mark of wealth amongst settled peoples. A cavalry horse involves considerable expense in breeding, training, feeding, and equipment, and has very little productive use except as a mode of transport.

For this reason, and because of their often decisive military role, the cavalry has typically been associated with high social status. This was most clearly seen in the feudal system, where a lord was expected to enter combat armored and on horseback and bring with him an entourage of lightly armed peasants on foot. If landlords and peasant levies came into conflict, the poorly trained footmen would be ill-equipped to defeat armored knights.

In later national armies, service as an officer in the cavalry was generally a badge of high social status. For instance prior to 1914 most officers of British cavalry regiments came from a socially privileged background and the considerable expenses associated with their role generally required private means, even after it became possible for officers of the line infantry regiments to live on their pay. Options open to poorer cavalry officers in the various European armies included service with less fashionable (though often highly professional) frontier or colonial units. These included the British Indian cavalry, the Russian Cossacks or the French Chasseurs d' Afrique.

During the 19th and early 20th centuries most monarchies maintained a mounted cavalry element in their royal or imperial guards. These ranged from small units providing ceremonial escorts and palace guards, through to large formations intended for active service. The mounted escort of the Spanish Royal Household provided an example of the former and the twelve cavalry regiments of the Prussian Imperial Guard an example of the latter. In either case the officers of such units were likely to be drawn from the aristocracies of their respective societies.

Some sense of the noise and power of a cavalry charge can be gained from the 1970 film "Waterloo", which featured some 2,000 cavalrymen, some of them Cossacks. It included detailed displays of the horsemanship required to manage animal and weapons in large numbers at the gallop (unlike the real battle of Waterloo, where deep mud significantly slowed the horses). The Gary Cooper movie "They Came to Cordura" contains a scene of a cavalry regiment deploying from march to battle line formation. A smaller-scale cavalry charge can be seen in "" (2003); although the finished scene has substantial computer-generated imagery, raw footage and reactions of the riders are shown in the Extended Version DVD Appendices.

Other films that show cavalry actions include:







</doc>
<doc id="6818" url="https://en.wikipedia.org/wiki?curid=6818" title="Citric acid cycle">
Citric acid cycle

The citric acid cycle (CAC) – also known as the TCA cycle (tricarboxylic acid cycle) or the Krebs cycle – is a series of chemical reactions used by all aerobic organisms to release stored energy through the oxidation of acetyl-CoA derived from carbohydrates, fats, and proteins. In addition, the cycle provides precursors of certain amino acids, as well as the reducing agent NADH, that are used in numerous other reactions. Its central importance to many biochemical pathways suggests that it was one of the earliest components of metabolism and may have originated abiogenically. Even though it is branded as a 'cycle', it is not necessary for metabolites to follow only one specific route; at least three segments of the citric acid cycle have been recognized.

The name of this metabolic pathway is derived from the citric acid (a tricarboxylic acid, often called citrate, as the ionized form predominates at biological pH) that is consumed and then regenerated by this sequence of reactions to complete the cycle. The cycle consumes acetate (in the form of acetyl-CoA) and water, reduces NAD to NADH, releasing carbon dioxide. The NADH generated by the citric acid cycle is fed into the oxidative phosphorylation (electron transport) pathway. The net result of these two closely linked pathways is the oxidation of nutrients to produce usable chemical energy in the form of ATP.

In eukaryotic cells, the citric acid cycle occurs in the matrix of the mitochondrion. In prokaryotic cells, such as bacteria, which lack mitochondria, the citric acid cycle reaction sequence is performed in the cytosol with the proton gradient for ATP production being across the cell's surface (plasma membrane) rather than the inner membrane of the mitochondrion. The overall yield of energy-containing compounds from the TCA cycle is three NADH, one FADH, and one GTP.

Several of the components and reactions of the citric acid cycle were established in the 1930s by the research of Albert Szent-Györgyi, who received the Nobel Prize in Physiology or Medicine in 1937 specifically for his discoveries pertaining to fumaric acid, a key component of the cycle. He was able to make this discovery successful with the help of pigeon breast muscle. Because this tissue maintains its oxidative capacity well after breaking down in the "Latapie" mill and releasing in aqueous solutions, breast muscle of the pigeon was very well qualified for the study of oxidative reactions. The citric acid cycle itself was finally identified in 1937 by Hans Adolf Krebs and William Arthur Johnson while at the University of Sheffield, for which the former received the Nobel Prize for Physiology or Medicine in 1953, and for whom the cycle is sometimes named (Krebs cycle).

The citric acid cycle is a key metabolic pathway that connects carbohydrate, fat, and protein metabolism. The reactions of the cycle are carried out by eight enzymes that completely oxidize acetate (a two carbon molecule), in the form of acetyl-CoA, into two molecules each of carbon dioxide and water. Through catabolism of sugars, fats, and proteins, the two-carbon organic product acetyl-CoA (a form of acetate) is produced which enters the citric acid cycle. The reactions of the cycle also convert three equivalents of nicotinamide adenine dinucleotide (NAD) into three equivalents of reduced NAD (NADH), one equivalent of flavin adenine dinucleotide (FAD) into one equivalent of FADH, and one equivalent each of guanosine diphosphate (GDP) and inorganic phosphate (P) into one equivalent of guanosine triphosphate (GTP). The NADH and FADH generated by the citric acid cycle are, in turn, used by the oxidative phosphorylation pathway to generate energy-rich ATP.

One of the primary sources of acetyl-CoA is from the breakdown of sugars by glycolysis which yield pyruvate that in turn is decarboxylated by the pyruvate dehydrogenase complex generating acetyl-CoA according to the following reaction scheme:

The product of this reaction, acetyl-CoA, is the starting point for the citric acid cycle. Acetyl-CoA may also be obtained from the oxidation of fatty acids. Below is a schematic outline of the cycle:

There are ten basic steps in the citric acid cycle, as outlined below. The cycle is continuously supplied with new carbon in the form of acetyl-CoA, entering at step 0 in the table.
Two carbon atoms are oxidized to CO, the energy from these reactions is transferred to other metabolic processes through GTP (or ATP), and as electrons in NADH and QH. The NADH generated in the citric acid cycle may later be oxidized (donate its electrons) to drive ATP synthesis in a type of process called oxidative phosphorylation. FADH is covalently attached to succinate dehydrogenase, an enzyme which functions both in the CAC and the mitochondrial electron transport chain in oxidative phosphorylation. FADH, therefore, facilitates transfer of electrons to coenzyme Q, which is the final electron acceptor of the reaction catalyzed by the succinate:ubiquinone oxidoreductase complex, also acting as an intermediate in the electron transport chain.

Mitochondria in animals, including humans, possess two succinyl-CoA synthetases: one that produces GTP from GDP, and another that produces ATP from ADP. Plants have the type that produces ATP (ADP-forming succinyl-CoA synthetase). Several of the enzymes in the cycle may be loosely associated in a multienzyme protein complex within the mitochondrial matrix.

The GTP that is formed by GDP-forming succinyl-CoA synthetase may be utilized by nucleoside-diphosphate kinase to form ATP (the catalyzed reaction is GTP + ADP → GDP + ATP).

Products of the first turn of the cycle are one GTP (or ATP), three NADH, one QH and two CO.

Because two acetyl-CoA molecules are produced from each glucose molecule, two cycles are required per glucose molecule. Therefore, at the end of two cycles, the products are: two GTP, six NADH, two QH, and four CO.

The above reactions are balanced if P represents the HPO ion, ADP and GDP the ADP and GDP ions, respectively, and ATP and GTP the ATP and GTP ions, respectively.

The total number of ATP molecules obtained after complete oxidation of one glucose in glycolysis, citric acid cycle, and oxidative phosphorylation is estimated to be between 30 and 38.

The theoretical maximum yield of ATP through oxidation of one molecule of glucose in glycolysis, citric acid cycle, and oxidative phosphorylation is 38 (assuming 3 molar equivalents of ATP per equivalent NADH and 2 ATP per UQH). In eukaryotes, two equivalents of NADH and four equivalents of ATP are generated in glycolysis, which takes place in the cytoplasm. Transport of two of these equivalents of NADH into the mitochondria consumes two equivalents of ATP, thus reducing the net production of ATP to 36. Furthermore, inefficiencies in oxidative phosphorylation due to leakage of protons across the mitochondrial membrane and slippage of the ATP synthase/proton pump commonly reduces the ATP yield from NADH and UQH to less than the theoretical maximum yield. The observed yields are, therefore, closer to ~2.5 ATP per NADH and ~1.5 ATP per UQH, further reducing the total net production of ATP to approximately 30. An assessment of the total ATP yield with newly revised proton-to-ATP ratios provides an estimate of 29.85 ATP per glucose molecule.

While the citric acid cycle is in general highly conserved, there is significant variability in the enzymes found in different taxa (note that the diagrams on this page are specific to the mammalian pathway variant).

Some differences exist between eukaryotes and prokaryotes. The conversion of D-"threo"-isocitrate to 2-oxoglutarate is catalyzed in eukaryotes by the NAD-dependent EC 1.1.1.41, while prokaryotes employ the NADP-dependent EC 1.1.1.42. Similarly, the conversion of ("S")-malate to oxaloacetate is catalyzed in eukaryotes by the NAD-dependent EC 1.1.1.37, while most prokaryotes utilize a quinone-dependent enzyme, EC 1.1.5.4.

A step with significant variability is the conversion of succinyl-CoA to succinate. Most organisms utilize EC 6.2.1.5, succinate–CoA ligase (ADP-forming) (despite its name, the enzyme operates in the pathway in the direction of ATP formation). In mammals a GTP-forming enzyme, succinate–CoA ligase (GDP-forming) (EC 6.2.1.4) also operates. The level of utilization of each isoform is tissue dependent. In some acetate-producing bacteria, such as "Acetobacter aceti", an entirely different enzyme catalyzes this conversion – EC 2.8.3.18, succinyl-CoA:acetate CoA-transferase. This specialized enzyme links the TCA cycle with acetate metabolism in these organisms. Some bacteria, such as "Helicobacter pylori", employ yet another enzyme for this conversion – succinyl-CoA:acetoacetate CoA-transferase (EC 2.8.3.5).

Some variability also exists at the previous step – the conversion of 2-oxoglutarate to succinyl-CoA. While most organisms utilize the ubiquitous NAD-dependent 2-oxoglutarate dehydrogenase, some bacteria utilize a ferredoxin-dependent 2-oxoglutarate synthase (EC 1.2.7.3).
Other organisms, including obligately autotrophic and methanotrophic bacteria and archaea, bypass succinyl-CoA entirely, and convert 2-oxoglutarate to succinate via succinate semialdehyde, using EC 4.1.1.71, 2-oxoglutarate decarboxylase, and EC 1.2.1.79, succinate-semialdehyde dehydrogenase.

In cancer, there are substantial metabolic derangements that occur to ensure the proliferation of tumor cells, and consequently metabolites can accumulate which serve to facilitate tumorigenesis, dubbed oncometabolites. Among the best characterized oncometabolites is 2-hydroxyglutarate which is produced through a heterozygous gain-of-function mutation (specifically a neomorphic one) in isocitrate dehydrogenase (IDH) (which under normal circumstances catalyzes the oxidation of isocitrate to oxalosuccinate, which then spontaneously decarboxylates to alpha-ketoglutarate, as discussed above; in this case an additional reduction step occurs after the formation of alpha-ketoglutarate via NADPH to yield 2-hydroxyglutarate), and hence IDH is considered an oncogene. Under physiological conditions, 2-hydroxyglutarate is a minor product of several metabolic pathways as an error but readily converted to alpha-ketoglutarate via hydroxyglutarate dehydrogenase enzymes (L2HGDH and D2HGDH) but does not have a known physiologic role in mammalian cells; of note, in cancer, 2-hydroxyglutarate is likely a terminal metabolite as isotope labelling experiments of colorectal cancer cell lines show that its conversion back to alpha-ketoglutarate is too low to measure. In cancer, 2-hydroxyglutarate serves as a competitive inhibitor for a number of enzymes that facilitate reactions via alpha-ketoglutarate in alpha-ketoglutarate-dependent dioxygenases. This mutation results in several important changes to the metabolism of the cell. For one thing, because there is an extra NADPH-catalyzed reduction, this can contribute to depletion of cellular stores of NADPH and also reduce levels of alpha-ketoglutarate available to the cell. In particular, the depletion of NADPH is problematic because NADPH is highly compartmentalized and cannot freely diffuse between the organelles in the cell. It is produced largely via the pentose phosphate pathway in the cytoplasm. The depletion of NADPH results in increased oxidative stress within the cell as it is a required cofactor in the production of GSH, and this oxidative stress can result in DNA damage. There are also changes on the genetic and epigenetic level through the function of histone lysine demethylases (KDMs) and ten-eleven translocation (TET) enzymes; ordinarily TETs hydroxylate 5-methylcytosines to prime them for demethylation. However, in the absence of alpha-ketoglutarate this cannot be done and there is hence hypermethylation of the cell's DNA, serving to promote epithelial-mesenchymal transition (EMT) and inhibit cellular differentiation. A similar phenomenon is observed for the Jumonji C family of KDMs which require a hydroxylation to perform demethylation at the epsilon-amino methyl group. Additionally, the inability of prolyl hydroxylases to catalyze reactions results in stabilization of hypoxia-inducible factor alpha, which is necessary to promote degradation of the latter (as under conditions of low oxygen there will not be adequate substrate for hydroxylation). This results in a pseudohypoxic phenotype in the cancer cell that promotes angiogenesis, metabolic reprogramming, cell growth, and migration.

Allosteric regulation by metabolites. The regulation of the citric acid cycle is largely determined by product inhibition and substrate availability. If the cycle were permitted to run unchecked, large amounts of metabolic energy could be wasted in overproduction of reduced coenzyme such as NADH and ATP. The major eventual substrate of the cycle is ADP which gets converted to ATP. A reduced amount of ADP causes accumulation of precursor NADH which in turn can inhibit a number of enzymes. NADH, a product of all dehydrogenases in the citric acid cycle with the exception of succinate dehydrogenase, inhibits pyruvate dehydrogenase, isocitrate dehydrogenase, α-ketoglutarate dehydrogenase, and also citrate synthase. Acetyl-coA inhibits pyruvate dehydrogenase, while succinyl-CoA inhibits alpha-ketoglutarate dehydrogenase and citrate synthase. When tested in vitro with TCA enzymes, ATP inhibits citrate synthase and α-ketoglutarate dehydrogenase; however, ATP levels do not change more than 10% in vivo between rest and vigorous exercise. There is no known allosteric mechanism that can account for large changes in reaction rate from an allosteric effector whose concentration changes less than 10%.

Citrate is used for feedback inhibition, as it inhibits phosphofructokinase, an enzyme involved in glycolysis that catalyses formation of fructose 1,6-bisphosphate, a precursor of pyruvate. This prevents a constant high rate of flux when there is an accumulation of citrate and a decrease in substrate for the enzyme.

Regulation by calcium. Calcium is also used as a regulator in the citric acid cycle. Calcium levels in the mitochondrial matrix can reach up to the tens of micromolar levels during cellular activation. It activates pyruvate dehydrogenase phosphatase which in turn activates the pyruvate dehydrogenase complex. Calcium also activates isocitrate dehydrogenase and α-ketoglutarate dehydrogenase. This increases the reaction rate of many of the steps in the cycle, and therefore increases flux throughout the pathway.

Transcriptional regulation. Recent work has demonstrated an important link between intermediates of the citric acid cycle and the regulation of hypoxia-inducible factors (HIF). HIF plays a role in the regulation of oxygen homeostasis, and is a transcription factor that targets angiogenesis, vascular remodeling, glucose utilization, iron transport and apoptosis. HIF is synthesized constitutively, and hydroxylation of at least one of two critical proline residues mediates their interaction with the von Hippel Lindau E3 ubiquitin ligase complex, which targets them for rapid degradation. This reaction is catalysed by prolyl 4-hydroxylases. Fumarate and succinate have been identified as potent inhibitors of prolyl hydroxylases, thus leading to the stabilisation of HIF.

Several catabolic pathways converge on the citric acid cycle. Most of these reactions add intermediates to the citric acid cycle, and are therefore known as anaplerotic reactions, from the Greek meaning to "fill up". These increase the amount of acetyl CoA that the cycle is able to carry, increasing the mitochondrion's capability to carry out respiration if this is otherwise a limiting factor. Processes that remove intermediates from the cycle are termed "cataplerotic" reactions.

In this section and in the next, the citric acid cycle intermediates are indicated in "italics" to distinguish them from other substrates and end-products.

Pyruvate molecules produced by glycolysis are actively transported across the inner mitochondrial membrane, and into the matrix. Here they can be oxidized and combined with coenzyme A to form CO, "acetyl-CoA", and NADH, as in the normal cycle.

However, it is also possible for pyruvate to be carboxylated by pyruvate carboxylase to form "oxaloacetate". This latter reaction "fills up" the amount of "oxaloacetate" in the citric acid cycle, and is therefore an anaplerotic reaction, increasing the cycle's capacity to metabolize "acetyl-CoA" when the tissue's energy needs (e.g. in muscle) are suddenly increased by activity.

In the citric acid cycle all the intermediates (e.g. "citrate", "iso-citrate", "alpha-ketoglutarate", "succinate", "fumarate", "malate", and "oxaloacetate") are regenerated during each turn of the cycle. Adding more of any of these intermediates to the mitochondrion therefore means that that additional amount is retained within the cycle, increasing all the other intermediates as one is converted into the other. Hence the addition of any one of them to the cycle has an anaplerotic effect, and its removal has a cataplerotic effect. These anaplerotic and cataplerotic reactions will, during the course of the cycle, increase or decrease the amount of "oxaloacetate" available to combine with "acetyl-CoA" to form "citric acid". This in turn increases or decreases the rate of ATP production by the mitochondrion, and thus the availability of ATP to the cell.

"Acetyl-CoA", on the other hand, derived from pyruvate oxidation, or from the beta-oxidation of fatty acids, is the only fuel to enter the citric acid cycle. With each turn of the cycle one molecule of "acetyl-CoA" is consumed for every molecule of "oxaloacetate" present in the mitochondrial matrix, and is never regenerated. It is the oxidation of the acetate portion of "acetyl-CoA" that produces CO and water, with the energy of O thus released captured in the form of ATP. The three steps of beta-oxidation resemble the steps that occur in the production of oxaloacetate from succinate in the TCA cycle. Acyl-CoA is oxidized to trans-Enoyl-CoA while FAD is reduced to FADH, which is similar to the oxidation of succinate to fumarate. Following, trans-Enoyl-CoA is hydrated across the double bond to beta-hydroxyacyl-CoA, just like fumarate is hydrated to malate. Lastly, beta-hydroxyacyl-CoA is oxidized to beta-ketoacyl-CoA while NAD+ is reduced to NADH, which follows the same process as the oxidation of malate to oxaloacetate.

In the liver, the carboxylation of cytosolic pyruvate into intra-mitochondrial "oxaloacetate" is an early step in the gluconeogenic pathway which converts lactate and de-aminated alanine into glucose, under the influence of high levels of glucagon and/or epinephrine in the blood. Here the addition of "oxaloacetate" to the mitochondrion does not have a net anaplerotic effect, as another citric acid cycle intermediate ("malate") is immediately removed from the mitochondrion to be converted into cytosolic oxaloacetate, which is ultimately converted into glucose, in a process that is almost the reverse of glycolysis.

In protein catabolism, proteins are broken down by proteases into their constituent amino acids. Their carbon skeletons (i.e. the de-aminated amino acids) may either enter the citric acid cycle as intermediates (e.g. "alpha-ketoglutarate" derived from glutamate or glutamine), having an anaplerotic effect on the cycle, or, in the case of leucine, isoleucine, lysine, phenylalanine, tryptophan, and tyrosine, they are converted into "acetyl-CoA" which can be burned to CO and water, or used to form ketone bodies, which too can only be burned in tissues other than the liver where they are formed, or excreted via the urine or breath. These latter amino acids are therefore termed "ketogenic" amino acids, whereas those that enter the citric acid cycle as intermediates can only be cataplerotically removed by entering the gluconeogenic pathway via "malate" which is transported out of the mitochondrion to be converted into cytosolic oxaloacetate and ultimately into glucose. These are the so-called "glucogenic" amino acids. De-aminated alanine, cysteine, glycine, serine, and threonine are converted to pyruvate and can consequently either enter the citric acid cycle as "oxaloacetate" (an anaplerotic reaction) or as "acetyl-CoA" to be disposed of as CO and water.

In fat catabolism, triglycerides are hydrolyzed to break them into fatty acids and glycerol. In the liver the glycerol can be converted into glucose via dihydroxyacetone phosphate and glyceraldehyde-3-phosphate by way of gluconeogenesis. In many tissues, especially heart and skeletal muscle tissue, fatty acids are broken down through a process known as beta oxidation, which results in the production of mitochondrial "acetyl-CoA", which can be used in the citric acid cycle. Beta oxidation of fatty acids with an odd number of methylene bridges produces propionyl-CoA, which is then converted into "succinyl-CoA" and fed into the citric acid cycle as an anaplerotic intermediate.

The total energy gained from the complete breakdown of one (six-carbon) molecule of glucose by glycolysis, the formation of 2 "acetyl-CoA" molecules, their catabolism in the citric acid cycle, and oxidative phosphorylation equals about 30 ATP molecules, in eukaryotes. The number of ATP molecules derived from the beta oxidation of a 6 carbon segment of a fatty acid chain, and the subsequent oxidation of the resulting 3 molecules of "acetyl-CoA" is 40.

In this subheading, as in the previous one, the TCA intermediates are identified by "italics".

Several of the citric acid cycle intermediates are used for the synthesis of important compounds, which will have significant cataplerotic effects on the cycle.
"Acetyl-CoA" cannot be transported out of the mitochondrion. To obtain cytosolic acetyl-CoA, "citrate" is removed from the citric acid cycle and carried across the inner mitochondrial membrane into the cytosol. There it is cleaved by ATP citrate lyase into acetyl-CoA and oxaloacetate. The oxaloacetate is returned to mitochondrion as "malate" (and then converted back into "oxaloacetate" to transfer more "acetyl-CoA" out of the mitochondrion). The cytosolic acetyl-CoA is used for fatty acid synthesis and the production of cholesterol. Cholesterol can, in turn, be used to synthesize the steroid hormones, bile salts, and vitamin D.

The carbon skeletons of many non-essential amino acids are made from citric acid cycle intermediates. To turn them into amino acids the alpha keto-acids formed from the citric acid cycle intermediates have to acquire their amino groups from glutamate in a transamination reaction, in which pyridoxal phosphate is a cofactor. In this reaction the glutamate is converted into "alpha-ketoglutarate", which is a citric acid cycle intermediate. The intermediates that can provide the carbon skeletons for amino acid synthesis are "oxaloacetate" which forms aspartate and asparagine; and "alpha-ketoglutarate" which forms glutamine, proline, and arginine.

Of these amino acids, aspartate and glutamine are used, together with carbon and nitrogen atoms from other sources, to form the purines that are used as the bases in DNA and RNA, as well as in ATP, AMP, GTP, NAD, FAD and CoA.

The pyrimidines are partly assembled from aspartate (derived from "oxaloacetate"). The pyrimidines, thymine, cytosine and uracil, form the complementary bases to the purine bases in DNA and RNA, and are also components of CTP, UMP, UDP and UTP.

The majority of the carbon atoms in the porphyrins come from the citric acid cycle intermediate, "succinyl-CoA". These molecules are an important component of the hemoproteins, such as hemoglobin, myoglobin and various cytochromes.

During gluconeogenesis mitochondrial "oxaloacetate" is reduced to "malate" which is then transported out of the mitochondrion, to be oxidized back to oxaloacetate in the cytosol. Cytosolic oxaloacetate is then decarboxylated to phosphoenolpyruvate by phosphoenolpyruvate carboxykinase, which is the rate limiting step in the conversion of nearly all the gluconeogenic precursors (such as the glucogenic amino acids and lactate) into glucose by the liver and kidney.

Because the citric acid cycle is involved in both catabolic and anabolic processes, it is known as an amphibolic pathway.

Evan M.W.Duo
The metabolic role of lactate is well recognized as a fuel for tissues and tumors. In the classical Cori cycle, muscles produce lactate which is then taken up by the liver for gluconeogenesis. New studies suggest that lactate can be used as a source of carbon for the TCA cycle.

It is believed that components of the citric acid cycle were derived from anaerobic bacteria, and that the TCA cycle itself may have evolved more than once. Theoretically, several alternatives to the TCA cycle exist; however, the TCA cycle appears to be the most efficient. If several TCA alternatives had evolved independently, they all appear to have converged to the TCA cycle.




</doc>
<doc id="6821" url="https://en.wikipedia.org/wiki?curid=6821" title="Military engineering vehicle">
Military engineering vehicle

A military engineering vehicle is a vehicle built for the construction work or for the transportation of combat engineers on the battlefield. These vehicles may be modified civilian equipment (such as the armoured bulldozers that many nations field) or purpose-built military vehicles (such as the AVRE). The first appearance of such vehicles coincided with the appearance of the first tanks, these vehicles were modified Mark V tanks for bridging and mine clearance. Modern "military engineering vehicles" are expected to fulfil numerous roles, as such they undertake numerous forms, examples of roles include; Bulldozers, cranes, graders, excavators, dump trucks, Breaching vehicles, Bridging vehicles, Military ferries, amphibious crossing vehicles, and Combat Engineer Section Carriers. 

A Heavy RE tank was developed shortly after World War I by Major Giffard LeQuesne Martel RE. This vehicle was a modified Mark V tank. Two support functions for these Engineer Tanks were developed: bridging and mine clearance. The bridging component involved an assault bridge, designed by Major Charles Inglis RE, called the Canal Lock Bridge, which had sufficient length to span a canal lock. Major Martel mated the bridge with the tank and used hydraulic power generated by the tank's engine to manoeuvre the bridge into place. For mine clearance the tanks were equipped with 2 ton rollers.

Between the wars various experimental bridging tanks were used to test a series of methods for bridging obstacles and developed by the Experimental Bridging Establishment (EBE). Captain SG Galpin RE conceived a prototype Light Tank Mk V to test the Scissors Assault Bridge. This concept was realised by Captain SA Stewart RE with significant input from a Mr DM Delany, a scientific civil servant in the employ of the EBE. MB Wild & Co, Birmingham, also developed a bridge that could span gaps of 26 feet using a complex system of steel wire ropes and a travelling jib, where the front section was projected and then attached to the rear section prior to launching the bridge. This system had to be abandoned due to lack of success in getting it to work, however the idea was later used successfully on the Beaver Bridge Laying Tank.

Once World War Two had begun, the development of armoured vehicles for use by engineers in the field was accelerated under Delaney's direction. The EBE rapidly developed an assault bridge carried on a modified Covenanter tank capable of deploying a 24-ton tracked load capacity bridge (Class 24) that could span gaps of 30 feet. However, it did not see service in the British armed forces, and all vehicles were passed onto Allied forces such as Australia and Czechoslovakia.

A Class 30 design superseded the Class 24 with no real re-design, simply the substitution of the Covenanter tank with a suitably modified Valentine.
As tanks in the war got heavier, a new bridge capable of supporting them was developed. A heavily modified Churchill used a single-piece bridge mounted on a turret-less tank and was able to lay the bridge in 90 seconds; this bridge was able to carry a 60-ton tracked or 40-ton wheeled load.

Hobart's Funnies were a number of unusually modified tanks operated during the Second World War by the 79th Armoured Division of the British Army or by specialists from the Royal Engineers. They were designed in light of problems that more standard tanks experienced during the amphibious Dieppe Raid, so that the new models would be able to overcome the problems of the planned Invasion of Normandy. These tanks played a major part on the Commonwealth beaches during the landings. They were forerunners of the modern combat engineering vehicle and were named after their commander, Major General Percy Hobart.

Hobart's unusual, specialized tanks, nicknamed "funnies", included:

In U.S. Forces, Sherman tanks were also fitted with dozer blades, and anti-mine roller devices were developed, enabling engineering operations and providing similar capabilities.

Post war, the value of the combat engineering vehicles had been proven, and armoured multi-role engineering vehicles have been added to the majority of armoured forces.

Military engineering can employ a wide variety of heavy equipment in the same or similar ways to how this equipment is used outside the military. Bulldozers, cranes, graders, excavators, dump trucks, loaders, and backhoes all see extensive use by military engineers.

Military engineers may also use civilian heavy equipment which was modified for military applications. Typically, this involves adding armour for protection from battlefield hazards such as artillery, unexploded ordnance, mines, and small arms fire. Often this protection is provided by armour plates and steel jackets. Some examples of armoured civilian heavy equipment are the IDF Caterpillar D9, American D7 TPK, Canadian D6 armoured bulldozer, cranes, graders, excavators, and M35 2-1/2 ton cargo truck.

Militarized heavy equipment may also take on the form of traditional civilian equipment designed and built to unique military specifications. These vehicles typically sacrifice some depth of capability from civilian models in order to gain greater speed and independence from prime movers. Examples of this type of vehicle include high speed backhoes such as the Australian Army's High Mobility Engineering Vehicle (HMEV) from Thales or the Canadian Army's Multi-Purpose Engineer Vehicle (MPEV) from Arva.

"The main article for civilian heavy equipment is:" Heavy equipment (construction)

Typically based on the platform of a main battle tank, these vehicles go by different names depending upon the country of use or manufacture. In the US the term "combat engineer vehicle (CEV)" is used, in the UK the term "Armoured Vehicle Royal Engineers (AVRE)" is used, while in Canada and other commonwealth nations the term "armoured engineer vehicle (AEV)" is used. There is no set template for what such a vehicle will look like, yet likely features include a large dozer blade or mine ploughs, a large calibre demolition cannon, augers, winches, excavator arms and cranes or lifting booms.

These vehicles are designed to directly conduct obstacle breaching operations and to conduct other earth-moving and engineering work on the battlefield. Good examples of this type of vehicle include the UK Trojan AVRE, the Russian IMR, and the US M728 Combat Engineer Vehicle. Although the term "armoured engineer vehicle" is used specifically to describe these multi-purpose tank based engineering vehicles, that term is also used more generically in British and Commonwealth militaries to describe all heavy tank based engineering vehicles used in the support of mechanized forces. Thus, "armoured engineer vehicle" used generically would refer to AEV, AVLB, Assault Breachers, and so on.

Lighter and less multi-functional than the CEVs or AEVs described above, these vehicles are designed to conduct earth-moving work on the battlefield. These vehicles have greater high speed mobility than traditional heavy equipment and are protected against the effects of blast and fragmentation. Good examples are the American M9 ACE and the UK FV180 Combat Engineer Tractor.

These vehicles are equipped with mechanical or other means for the breaching of man made obstacles. Common types of breaching vehicles include mechanical flails, mine plough vehicles, and mine roller vehicles. In some cases, these vehicles will also mount Mine-clearing line charges. Breaching vehicles may be either converted armoured fighting vehicles or purpose built vehicles. In larger militaries, converted AFV are likely to be used as "assault breachers" while the breached obstacle is still covered by enemy observation and fire, and then purpose built breaching vehicles will create additional lanes for following forces.

Good examples of breaching vehicles include the USMC M1 Assault Breacher Vehicle, the UK Aardvark JSFU, and the Singaporean Trailblazer.

Several types of military bridging vehicles have been developed. An armoured vehicle-launched bridge (AVLB) is typically a modified tank hull converted to carry a bridge into battle in order to support crossing ditches, small waterways, or other gap obstacles.

Another type of bridging vehicle is the truck launched bridge. The Soviet TMM bridging truck could carry and launch a 10-meter bridge that could be daisy-chained with other TMM bridges to cross larger obstacles. More recent developments have seen the conversion of AVLB and truck launched bridge with launching systems that can be mounted on either tank or truck for bridges that are capable of supporting heavy main battle tanks.

Earlier examples of bridging vehicles include a type in which a converted tank hull is the bridge. On these vehicles, the hull deck comprises the main portion of the tread way while ramps extend from the front and rear of the vehicle to allow other vehicles to climb over the bridging vehicle and cross obstacles. An example of this type of armoured bridging vehicle was the Churchill Ark used in the Second World War.

Another type of CEVs are armoured fighting vehicles which are used to transport sappers (combat engineers) and can be fitted with a bulldozer's blade and other mine-breaching devices. They are often used as APCs because of their carrying ability and heavy protection. They are usually armed with machine guns and grenade launchers and usually tracked to provide enough tractive force to push blades and rakes. Some examples are the U.S. M113 APC, IDF Puma, Nagmachon, Husky, and U.S. M1132 ESV (a Stryker variant).

One of the major tasks of military engineering is crossing major rivers. Several military engineering vehicles have been developed in various nations to achieve this task. One of the more common types is the amphibious ferry such as the M3 Amphibious Rig. These vehicles are self-propelled on land, they can transform into raft type ferries when in the water, and often multiple vehicles can connect to form larger rafts or floating bridges. Other types of military ferries, such as the Soviet "Plavayushij Transportyor - Srednyj", are able to load while still on land and transport other vehicles cross country and over water.

In addition to amphibious crossing vehicles, military engineers may also employ several types of boats. Military assault boats are small boats propelled by oars or an outboard motor and used to ferry dismounted infantry across water.

Most CEVs are armoured fighting vehicles that may be based on a tank chassis and have special attachments in order to breach obstacles. Such attachments may include dozer blades, mine rollers, cranes etc. An example of an engineering vehicle of this kind is a bridgelaying tank, which replaces the turret with a segmented hydraulic bridge. The Hobart's Funnies of the Second World War were a wide variety of armoured vehicles for combat engineering tasks. They were allocated to the initial beachhead assaults by the British and Commonwealth forces in the D-Day landings

The British Churchill tank because of its good cross-country performance and capacious interior with side hatches became the most adapted with modifications, the base unit being the AVRE carrying a large demolition gun.












</doc>
<doc id="6822" url="https://en.wikipedia.org/wiki?curid=6822" title="Catalonia">
Catalonia

Catalonia (; ; ; ) is an autonomous community on the northeastern corner of Spain, designated as a "nationality" by its Statute of Autonomy.

Catalonia consists of four provinces: Barcelona, Girona, Lleida, and Tarragona. The capital and largest city is Barcelona, the second-most populated municipality in Spain and the core of the fifth-most populous urban area in the European Union. It comprises most of the territory of the former Principality of Catalonia (with the remainder Roussillon now part of France's Pyrénées-Orientales, Occitanie). It is bordered by France (Occitanie) and Andorra to the north, the Mediterranean Sea to the east, and the Spanish autonomous communities of Aragon to the west and Valencia to the south. The official languages are Catalan, Spanish, and the Aranese dialect of Occitan.

In the late 8th century, various counties were established by the Frankish kingdom across and near the eastern Pyrenees as a defensive barrier against Muslim invasions. The eastern counties were united under the rule of the Frankish vassal, the count of Barcelona. In the 10th century the County of Barcelona became progressively independent. In 1137, Barcelona and the Kingdom of Aragon were united by marriage under the Crown of Aragon. Within the Crown, the Catalan counties adopted a common polity known as Principality of Catalonia, developing its own institutional system, such as courts (parliament), Generalitat and constitutions, becoming the base for the Crown of Aragon's naval power, trade and expansionism in the Mediterranean. In the later Middle Ages, Catalan literature flourished. During the last Medieval centuries natural disasters, social turmoils and military conflicts affected the Principality. In 1469, the king of Aragon and the queen of Castile were married and ruled their realms together, retaining all of their distinct institutions and legislation.

During the Franco-Spanish War (1635–1659), Catalonia revolted (1640–1652) against a large and burdensome presence of the royal army in its territory, being briefly proclaimed a republic under French protection, until it was largely reconquered by the Spanish army. By the Treaty of the Pyrenees (1659), the Spanish Crown ceded the northern parts of Catalonia, mostly the Roussillon, to France. During the War of the Spanish Succession (1701–1714), the Crown of Aragon sided against the Bourbon Philip V of Spain; following Catalan defeat on 11 September 1714, Philip V imposed a unifying administration across Spain, enacting the Nueva Planta decrees which, like in the other realms of the Crown of Aragon, suppressed the Catalan institutions and rights. This led to the eclipse of Catalan as a language of government and literature, replaced by Spanish. Throughout the 18th century, Catalonia experienced economic growth.

In the 19th century, Catalonia was severely affected by the Napoleonic and Carlist Wars. In the second third of the century, Catalonia experienced industrialisation. As wealth from the industrial expansion grew, it saw a cultural renaissance coupled with incipient nationalism while several workers movements appeared. With the establishment of the Second Spanish Republic (1931–1939), the Generalitat was restored as a Catalan autonomous government. After the Spanish Civil War, the Francoist dictatorship enacted repressive measures, abolishing Catalan self-government and banning the official use of the Catalan language. 

After a period of autarky, from the late 1950s through to the 1970s Catalonia saw rapid economic growth, drawing many workers from across Spain, making Barcelona one of Europe's largest industrial metropolitan areas and turning Catalonia into a major tourist destination. Since the Spanish transition to democracy (1975–1982), Catalonia has regained self-government and is now one of the most economically dynamic communities of Spain. 

Since the 2010s there has been growing support for Catalan independence. On 27 October 2017, the Catalan Parliament declared unilaterally independence following a disputed referendum. The Spanish Senate voted in favour of enforcing direct rule by removing the Catalan government and calling a snap regional election for 21 December. On 2 November, the Spanish Supreme Court imprisoned seven former ministers of the Catalan government on charges of rebellion and misuse of public funds, while several others—including then-President of Catalonia, Carles Puigdemont—fled to other European countries.

The name Catalonia—"Catalunya" in Catalan, spelled "Cathalonia", or "Cathalaunia" in Medieval Latin—began to be used for the homeland of the Catalans ("Cathalanenses") in the late 11th century and was probably used before as a territorial reference to the group of counties that comprised part of the March of Gothia and March of Hispania under the control of the Count of Barcelona and his relatives. The origin of the name "Catalunya" is subject to diverse interpretations because of a lack of evidence.

One theory suggests that "Catalunya" derives from the name "Gothia" (or "Gauthia") "Launia" ("Land of the Goths"), since the origins of the Catalan counts, lords and people were found in the March of Gothia, known as "Gothia", whence "Gothland" > "Gothlandia" > "Gothalania" > "Cathalaunia" > "Catalonia" theoretically derived. During the Middle Ages, Byzantine chroniclers claimed that "Catalania" derives from the local medley of Goths with Alans, initially constituting a "Goth-Alania".

Other less plausible or recent theories suggest:


In English, "Catalonia" is pronounced . The native name, "Catalunya", is pronounced in Central Catalan, the most widely spoken variety, whose pronunciation is considered standard. The Spanish name is "Cataluña" (), and the Aranese name is "Catalonha" ().

The first known human settlements in what is now Catalonia were at the beginning of the Middle Paleolithic. The oldest known trace of human occupation is a mandible found in Banyoles, described by some sources as pre-Neanderthal some 200,000 years old; other sources suggest it to be only about one third that old. From the next prehistoric era, the Epipalaeolithic or Mesolithic, important remains survive, the greater part dated between 8000 and 5000 BC, such as those of Sant Gregori (Falset) and el Filador (Margalef de Montsant). The most important sites from these eras, all excavated in the region of Moianès, are the Balma del Gai (Epipaleolithic) and the Balma de l'Espluga (late Epipaleolithic and Early Neolithic).

The Neolithic era began in Catalonia around 5000 BC, although the population was slower to develop fixed settlements than in other places, thanks to the abundance of woods, which allowed the continuation of a fundamentally hunter-gatherer culture. An example of such settlements would be La Draga, an "early Neolithic village which dates from the end of the 6th millennium BC."

The Chalcolithic period developed in Catalonia between 2500 and 1800 BC, with the beginning of the construction of copper objects. The Bronze Age occurred between 1800 and 700 BC. There are few remnants of this era, but there were some known settlements in the low Segre zone. The Bronze Age coincided with the arrival of the Indo-Europeans through the Urnfield Culture, whose successive waves of migration began around 1200 BC, and they were responsible for the creation of the first proto-urban settlements. Around the middle of the 7th century BC, the Iron Age arrived in Catalonia.

In pre-Roman times, the area that is now called Catalonia in the north-east of Iberian Peninsula – like the rest of the Mediterranean side of the peninsula – was populated by the Iberians. The Iberians of this area – the Ilergetes, Indigetes and Lacetani (Cerretains) – also maintained relations with the peoples of the Mediterranean. Some urban agglomerations became relevant, including Ilerda (Lleida) inland, Hibera (perhaps Amposta or Tortosa) or Indika (Ullastret). Coastal trading colonies were established by the ancient Greeks, who settled around the Gulf of Roses, in Emporion (Empúries) and Roses in the 8th century BC. The Carthaginians briefly ruled the territory in the course of the Second Punic War and traded with the surrounding Iberian population.

After the Carthaginian defeat by the Roman Republic, the north-east of Iberia became the first to come under Roman rule and became part of Hispania, the westernmost part of the Roman Empire. Tarraco (modern Tarragona) was one of the most important Roman cities in Hispania and the capital of the province of Tarraconensis. Other important cities of the Roman period are Ilerda (Lleida), Dertosa (Tortosa), Gerunda (Girona) as well as the ports of Empuriæ (former Emporion) and Barcino (Barcelona). As for the rest of Hispania, Latin law was granted to all cities under the reign of Vespasian (69-79 AD), while Roman citizenship was granted to all free men of the empire by the Edict of Caracalla in 212 AD (Tarraco, the capital, was already a colony of Roman law since 45 BC). It was a rich agricultural province (olive oil, vine, wheat), and the first centuries of the Empire saw the construction of roads (the most important being the Via Augusta, parallel to Mediterranean coastline) and infrastructure like aqueducts.

Conversion to Christianity, attested in the 3rd century, was completed in urban areas in the 4th century. Although Hispania remained under Roman rule and did not fall under the rule of Vandals, Swabians and Alans in the 5th century, the main cities suffered frequent sacking and some deurbanization.

After the fall of the Western Roman Empire, the area was conquered by the Visigoths and was ruled as part of the Visigothic Kingdom for almost two and a half centuries. In 718, it came under Muslim control and became part of Al-Andalus, a province of the Umayyad Caliphate. From the conquest of Roussillon in 760, to the conquest of Barcelona in 801, the Frankish empire took control of the area between Septimania and the Llobregat river from the Muslims and created heavily militarised, self-governing counties. These counties formed part of the historiographically known as the Gothic and Hispanic marches, a buffer zone in the south of the Frankish empire in the former province of Septimania and in the northeast of the Iberian Peninsula, to act as a defensive barrier for the Frankish empire against further Muslim invasions from Al-Andalus.

These counties came under the rule of the counts of Barcelona, who were Frankish vassals nominated by the emperor of the Franks, to whom they were feudatories (801–988). The earliest known use of the name "Catalonia" for these counties dates to 1117. At the end of the 9th century, the Count of Barcelona Wilfred the Hairy made his title hereditary and founded the dynasty of the House of Barcelona, which ruled Catalonia until 1410.

In 988 Borrell II, Count of Barcelona, did not recognise the new French king Hugh Capet as his king, evidencing the loss of dependency from Frankish rule and confirming his successors (from Ramon Borrell I to Ramon Berenguer IV) as independent of the Capetian crown whom they regarded as usurpers of the Carolingian Frankish realm. At the beginning of eleventh century the Catalan counties suffered an important process of feudalisation, partially controlled by the church's sponsored Peace and Truce Assemblies and by the negotiation skills of the Count of Barcelona Ramon Berenguer I, which began the codification of feudal law in the written Usages of Barcelona, becoming the basis of the Catalan law. In 1137, Ramon Berenguer IV, Count of Barcelona decided to accept King Ramiro II of Aragon's proposal to marry Queen Petronila, establishing the dynastic union of the County of Barcelona with the Kingdom of Aragon, creating the Crown of Aragon and making the Catalan counties that were united under the county of Barcelona into a principality of the Aragonese Crown.

In 1258, by means of the Treaty of Corbeil, James I of Aragon King of Aragon and Count of Barcelona, king of Mallorca and of Valencia, renounced his family rights and dominions in Occitania and recognised the king of France as heir of the Carolingian Dynasty. The king of France, Louis IX, formally relinquished his claims of feudal lordship over all the Catalan counties, except the County of Foix, despite the opposition of the king of Aragon and count of Barcelona. This treaty confirmed, from French point of view, the independence of the Catalan counties established and exercised during the previous three centuries, but also meant the irremediable separation between the geographical areas of Catalonia and Languedoc.

As a coastal territory, Catalonia became the base of the Aragonese Crown's maritime forces, which spread the power of the Aragonese Crown in the Mediterranean, and made Barcelona into a powerful and wealthy city. In the period of 1164–1410, new territories, the Kingdom of Valencia, the Kingdom of Majorca, Sardinia, the Kingdom of Sicily, Corsica, and, briefly, the Duchies of Athens and Neopatras, were incorporated into the dynastic domains of the House of Aragon. The expansion was accompanied by a great development of the Catalan trade, creating an extensive trade network across the Mediterranean which competed with those of the maritime republics of Genoa and Venice.

At the same time, the Principality of Catalonia developed a complex institutional and political system based in the concept of a pact between the estates of the realm and the king. Laws had to be approved in the General Court of Catalonia, one of the first parliamentary bodies of Europe that banned the royal power to create legislation unilaterally (since 1283). The Courts were composed of the three Estates, were presided over by the king of Aragon, and approved the constitutions, which created a compilation of rights for the citizenship of the Principality. In order to collect general taxes, the Courts of 1359 established a permanent representative of deputies position, called the Deputation of the General (and later usually known as Generalitat), which gained political power over the next centuries.

The domains of the Aragonese Crown were severely affected by the Black Death pandemic and by later outbreaks of the plague. Between 1347 and 1497 Catalonia lost 37 percent of its population. In 1410, King Martin I died without surviving descendants. Under the Compromise of Caspe, Ferdinand from the Castilian House of Trastámara received the Crown of Aragon as Ferdinand I of Aragon. During the reign of his son, John II, social and political tensions caused the Catalan Civil War (1462–1472).

Ferdinand II of Aragon, the grandson of Ferdinand I, and Queen Isabella I of Castile were married in 1469, later taking the title the Catholic Monarchs; subsequently, this event was seen by historiographers as the dawn of a unified Spain. At this time, though united by marriage, the Crowns of Castile and Aragon maintained distinct territories, each keeping its own traditional institutions, parliaments, laws and currency. Castile commissioned expeditions to the Americas and benefited from the riches acquired in the Spanish colonisation of the Americas, but, in time, also carried the main burden of military expenses of the united Spanish kingdoms. After Isabella's death, Ferdinand II personally ruled both kingdoms.

By virtue of descent from his maternal grandparents, Ferdinand II of Aragon and Isabella I of Castile, in 1516 Charles I of Spain became the first king to rule the Crowns of Castile and Aragon simultaneously by his own right. Following the death of his paternal (House of Habsburg) grandfather, Maximilian I, Holy Roman Emperor, he was also elected Charles V, Holy Roman Emperor, in 1519.
Over the next few centuries, the Principality of Catalonia was generally on the losing side of a series of wars that led steadily to an increased centralization of power in Spain. Despite this fact, between the 16th and 18th centuries, the participation of the political community in the local and the general Catalan government grew, while the kings remained absent and its constitutional system continued to consolidate. Tensions between Catalan institutions and the Monarchy began to arise. The large and burdensome presence of the Spanish royal army in the Principality due to the Franco-Spanish War led to an uprising of peasants, provoking the Reapers' War (1640–1652), which saw Catalonia rebel (briefly as a republic led by the chairman of the Generalitat, Pau Claris) with French help against the Spanish Crown for overstepping Catalonia's rights during the Thirty Years' War. Within a brief period France took full control of Catalonia. Most of Catalonia was reconquered by the Spanish Monarchy but Catalan rights were recognised. Roussillon was lost to France by the Treaty of the Pyrenees (1659).

The most significant conflict concerning the governing monarchy was the War of the Spanish Succession, which began when the childless Charles II of Spain, the last Spanish Habsburg, died without an heir in 1700. Charles II had chosen Philip V of Spain from the French House of Bourbon. Catalonia, like other territories that formed the Crown of Aragon, rose up in support of the Austrian Habsburg pretender Charles VI, Holy Roman Emperor, in his claim for the Spanish throne as Charles III of Spain. The fight between the houses of Bourbon and Habsburg for the Spanish Crown split Spain and Europe.

The fall of Barcelona on 11 September 1714 to the Bourbon king Philip V militarily ended the Habsburg claim to the Spanish Crown, which became legal fact in the Treaty of Utrecht. Philip felt that he had been betrayed by the Catalan Courts, as it had initially sworn its loyalty to him when he had presided over it in 1701. In retaliation for the betrayal, and inspired by the French absolutist style of government, the first Bourbon king introduced the Nueva Planta decrees, that incorporated the lands of the Crown of Aragon, including the Principality of Catalonia, as provinces under the Crown of Castile in 1716, terminating their separate institutions, laws and rights, as well as their politics, within a united kingdom of Spain. From the second third of 18th century onwards Catalonia carried out a successful process of proto-industrialization, reinforced in the late quarter of the century when the Castile's trade monopoly with American colonies ended.

At the beginning of the nineteenth century Catalonia was severely affected by the Napoleonic Wars. In 1808 it was occupied by the French troops, the resistance against the occupation eventually developed into the Peninsular War. The rejection to French dominion was institutionalized with the creation of "juntas" (councils) who, remaining loyal to the Bourbons, exercised the sovereignty and representation of the territory due to the disappearance of the old institutions. Napoleon took direct control of Catalonia to establish order, creating the Government of Catalonia under the rule of Marshall Augereau, and making Catalan briefly an official language again. Between 1812 and 1814 Catalonia was annexed to France and organized as four départements. The French troops evacuated Catalan territory at the end of 1814. After the Bourbon restoration in Spain and the death of the absolutist king Ferdinand VII, Carlist Wars erupted against the new born liberal state of Isabella II. Catalonia was divided, the coast and most industrialized areas support liberalism, while many inland areas were in the hands of Carlists, as the last ones proposed to reestablish the institutional systems suppressed in the Nueva Planta decrees in all the ancient realms of the Crown of Aragon.
In the second third of the 19th century, it became an industrial center. This process was boosted by, amongst other things, national (although the policy of the Spanish government during those times changed many times between free trade and protectionism) and the conditions of proto-industrialization of the prior two centuries of the Catalan urban areas and its countryside. Along the century, textile industry flourished in urban areas and in the countryside, usually in the form of company towns. To this day it remains one of the most industrialised areas of Spain. In 1832 it was inaugurated in Barcelona the factory Bonaplata, the first of the country which worked with steam engine. During those years, Barcelona was the focus of important revolutionary uprisings, called "bullangues", causing a difficult relation between many sectors of Catalan society and the central government and, in Catalonia, a republican current began to develop; also, inevitably, many Catalans favored a more federal Spain. Meanwhile, the Catalan language saw a cultural renaissance (the "Renaixença") at popular and bourgeois level. After the fall of the First Spanish Republic and the restoration of the Bourbon dynasty (1874), Catalan nationalism grew in importance.
The Anarchists had been active throughout the early 20th century, founding the CNT trade union and achieving one of the first eight-hour workday in Europe in 1919. Growing resentment of conscription and of the military culminated in the Tragic Week in Barcelona in 1909. In the first third of the 20th century, Catalonia gained and lost varying degrees of autonomy several times. In 1914, the four Catalan provinces were authorized to create a Commonwealth (Catalan: "Mancomunitat de Catalunya"), without any legislative power or specific autonomy which carried out an ambitious program of modernization, but it was disbanded in 1925 by the dictatorship of Primo de Rivera (1923-1930). During the last steps of the Dictatorship, Barcelona celebrated the 1929 International Exposition, while Spain began to suffer an economical crisis.

After the fall of the dictator and a brief proclamation of the Catalan Republic during the events which led to the proclamation of the Second Spanish Republic (1931-1939), it received its first Statute of Autonomy from the Spanish Republic's Parliament, establishing an autonomous body, the Generalitat of Catalonia, which included a parliament, a government and a court of appeal, and the left-wing independentist leader Francesc Macià was elected its first president. The governments of the Republican Generalitat, led by the Republican Left of Catalonia (ERC) members Francesc Macià (1931-1933) and Lluís Companys (1933-1940) made efforts to implement an advanced and progressive social agenda, despite the internal difficulties. This period was marked by political unrest, the effects of the economic crisis and their social repercussions. The Statute of Autonomy was suspended in 1934, due to the Events of 6 October in Barcelona, as a response to the accession of right-wing Spanish nationalist party CEDA to the government of the Republic, considered close to fascism.
After the electoral victory of the Popular Front in February 1936, the Government of Catalonia was pardoned and the self-government restored.

The defeat of the military rebellion against the Republican government in Barcelona placed Catalonia firmly in the Republican side of the Spanish Civil War. During the war, there were two rival powers in Catalonia: the de jure power of the Generalitat and the de facto power of the armed popular militias. Violent confrontations between the workers' parties (CNT-FAI and POUM against the PSUC) culminated in the defeat of the first ones in 1937. The situation resolved itself progressively in favor of the Generalitat, but at the same time the Generalitat was partially losing its autonomous power within Republican Spain. In 1938 Franco's troops broke the Republican territory in two, isolating Catalonia from the rest of the Republic. The defeat of the Republican army in the Battle of the Ebro led in 1938 and 1939 to the occupation of Catalonia by Franco's forces.

The defeat of the Spanish Republic in the Spanish Civil War brought to power the dictatorship of Francisco Franco, whose first ten-year rule was particularly violent, autocratic, and repressive both in a political, cultural, social, and economical sense. In Catalonia, any kind of public activities associated with Catalan nationalism, republicanism, anarchism, socialism, liberalism, democracy or communism, including the publication of books on those subjects or simply discussion of them in open meetings, was banned. Franco's regime banned the use of Catalan in government-run institutions and during public events, and also the Catalan institutions of self-government were abolished. The pro-Republic of Spain president of Catalonia, Lluís Companys, was taken to Spain from his exile in the German-occupied France, and was tortured and executed in the Montjuïc Castle of Barcelona for the crime of 'military rebellion'.

During later stages of Francoist Spain, certain folkloric and religious celebrations in Catalan resumed and were tolerated. Use of Catalan in the mass media had been forbidden, but was permitted from the early 1950s in the theatre. Despite the ban during the first years and the difficulties of the next period, publishing in Catalan continued throughout his rule.

The years after the war were extremely hard. Catalonia, like many other parts of Spain, had been devastated by the war. Recovery from the war damage was slow and made more difficult by the international trade embargo and the autarkic politics of Franco's regime. By the late 1950s the region had recovered its pre-war economic levels and in the 1960s was the second fastest growing economy in the world in what became known as the Spanish miracle. During this period there was a spectacular growth of industry and tourism in Catalonia that drew large numbers of workers to the region from across Spain and made the area around Barcelona into one of Europe's largest industrial metropolitan areas.

After Franco's death in 1975, Catalonia voted for the adoption of a democratic Spanish Constitution in 1978, in which Catalonia recovered political and cultural autonomy, restoring the Generalitat (exiled since the end of the Civil War in 1939) in 1977 and adopting a new Statute of Autonomy in 1979. First election to the Parliament of Catalonia under this Statute gave the Catalan presidency to Jordi Pujol, a position he would hold until 2003. During this time, he also led Convergència i Unió (CiU), a center-right Catalan nationalist electoral coalition. Throughout the 1980s and 1990s, the institutions of Catalan autonomy continued to develop, among them an autonomous police force ("Mossos d'Esquadra", in 1983), and the broadcasting network Televisió de Catalunya and its first channel TV3, created in 1983. Today, Catalonia is one of the most economically dynamic communities of Spain. The Catalan capital and largest city, Barcelona, is a major international cultural centre and a major tourist destination. In 1992, Barcelona hosted the Summer Olympic Games.

In November 2003, elections to the Parliament of Catalonia gave the government to a left-wing catalanist coalition formed by the Socialists' Party of Catalonia (PSC-PSOE), Republican Left of Catalonia (ERC) and Initiative for Catalonia Greens (ICV), and the socialist Pasqual Maragall was appointed president. The new government redacted a new version of the Statute of Autonomy, which consolidated and extended certain aspects of self-government.

The new Statute of Autonomy of Catalonia, approved after a referendum in 2006, was contested by important sectors of the Spanish society, especially by the conservative People's Party, which sent the law to the Constitutional Court of Spain. In 2010, the Court declared non-valid some of the articles that established an autonomous Catalan system of Justice, improved aspects of the financing, a new territorial division, the status of Catalan language or the symbolical declaration of Catalonia as a nation. This decision was severely contested by large sectors of Catalan society, which increased the demands of independence.

A controversial independence referendum was held in Catalonia on 1 October 2017, using a disputed voting process. It was declared illegal and suspended by the Constitutional Court of Spain, because it breached the 1978 Constitution. Subsequent developments saw, on 27 October 2017, a symbolic declaration of independence by the Parliament of Catalonia, the enforcement of direct rule by the Spanish government through the use of Article 155 of the Constitution, the dismissal of the Executive Council and the dissolution of the Parliament, with a snap regional election called for 21 December 2017, which ended with a victory of pro-independence parties. Former President Carles Puigdemont and five former cabinet ministers fled Spain (such as Belgium, in Puigdemont's case), whereas nine other cabinet members, including vice-president Oriol Junqueras, were sentenced to prison under various charges of rebellion, sedition, and misuse of public funds. Quim Torra became the 131st President of the Government of Catalonia on 17 May 2018, after the Spanish courts blocked three other candidates.

In 2018, the Assemblea Nacional Catalana joined the Unrepresented Nations and Peoples Organization (UNPO) on behalf of Catalonia.

On 14 October 2019, the Spanish Supreme court sentenced several Catalan political leaders involved in organizing a referendum on Catalonia's independence from Spain were convicted on charges ranging from sedition to misuse of public funds, with sentences ranging from 9 to 13 years in prison. This decision sparked demonstrations around Catalonia.

The climate of Catalonia is diverse. The populated areas lying by the coast in Tarragona, Barcelona and Girona provinces feature a Hot-summer Mediterranean climate (Köppen "Csa"). The inland part (including the Lleida province and the inner part of Barcelona province) show a mostly Mediterranean climate (Köppen "Csa"). The Pyrenean peaks have a continental (Köppen "D") or even Alpine climate (Köppen "ET") at the highest summits, while the valleys have a maritime or oceanic climate sub-type (Köppen "Cfb").

In the Mediterranean area, summers are dry and hot with sea breezes, and the maximum temperature is around . Winter is cool or slightly cold depending on the location. It snows frequently in the Pyrenees, and it occasionally snows at lower altitudes, even by the coastline. Spring and autumn are typically the rainiest seasons, except for the Pyrenean valleys, where summer is typically stormy.

The inland part of Catalonia is hotter and drier in summer. Temperature may reach , some days even . Nights are cooler there than at the coast, with the temperature of around . Fog is not uncommon in valleys and plains; it can be especially persistent, with freezing drizzle episodes and subzero temperatures during winter, mainly along the Ebro and Segre valleys and in Plain of Vic.

Catalonia has a marked geographical diversity, considering the relatively small size of its territory. The geography is conditioned by the Mediterranean coast, with of coastline, and large relief units of the Pyrenees to the north. The Catalan territory is divided into three main geomorphological units:

The Catalan Pyrenees represent almost half in length of the Pyrenees, as it extends more than . Traditionally differentiated the Axial Pyrenees (the main part) and the Pre-Pyrenees (southern from the Axial) which are mountainous formations parallel to the main mountain ranges but with lower altitudes, less steep and a different geological formation. The highest mountain of Catalonia, located north of the comarca of Pallars Sobirà is the Pica d'Estats (3,143 m), followed by the Puigpedrós (2,914 m). On the Pre-Pyrenees is located the Serra del Cadí, that separates the valley of Cerdanya from the Central Depression.

Central Catalan Depression is a plain located between the Pyrenees and Pre-Coastal Mountains. The Depression lands are located between . The plains and the water that descend from the Pyrenees have made it fertile territory for agriculture and there are built numerous irrigation canals. Other important plain is the Empordà, located on the northeast.

The Catalan Mediterranean system is based on two (more or less) parallel ranges to the coast, in a Northwest direction towards the Southwest. These two mountain ranges are the Coastal and the Pre-Coastal. The Coastal Range is minor extent and it has lower altitudes, while the Pre-Coastal is larger in both length and height. The most relevant mountains of this area are Montserrat, Montseny and Ports. Within the ranges are a series of plains, the entities over which form the Coastal and the Pre-Coastal Depressions. The Coastal Depression is located on the East of the Coastal Range towards the coast. The Pre-Coastal, on the other hand, is located in the interior, between the two mountain ranges, and constitutes the basis of the plains of Vallès and Penedès.

Catalonia is a showcase of European landscapes on a small scale. Just over hosting a variety of substrates, soils, climates, directions, altitudes and distances to the sea. The area is of great ecological diversity and a remarkable wealth of landscapes, habitats and species.

The fauna of Catalonia comprises a minority of animals endemic to the region and a majority of non-native animals. Much of Catalonia enjoys a Mediterranean climate (except mountain areas), which makes many of the animals that live there adapted to Mediterranean ecosystems. Of mammals, there are plentiful wild boar, red foxes, as well as roe deer and in the Pyrenees, the Pyrenean chamois. Other large species such as the bear have been recently reintroduced.

Waters of Balearic Sea are rich in biodiversity, and even the megafaunas of ocean; various type of whales (such as fin, sperm, and pilot) and dolphins live within the area.

Most of Catalonia belongs to the Mediterranean Basin. The Catalan hydrographic network consists of two important basins, the one of the Ebro and the one that comprises the internal basins of Catalonia (respectively covering 46.84% and 51.43% of the territory), all of them flow to the Mediterranean. Furthermore, there is the Garona river basin that flows to the Atlantic Ocean, but it only covers 1.73% of the Catalan territory.

The hydrographic network can be divided in two sectors, an occidental slope or Ebro river slope and one oriental slope constituted by minor rivers that flow to the Mediterranean along the Catalan coast. The first slope provides an average of per year, while the second only provides an average of /year. The difference is due to the big contribution of the Ebro river, from which the Segre is an important tributary. Moreover, in Catalonia there is a relative wealth of groundwaters, although there is inequality between "comarques", given the complex geological structure of the territory. In the Pyrenees there are many small lakes, remnants of the ice age. The biggest are the lake of Banyoles and the recently recovered lake of Ivars.

The Catalan coast is almost rectilinear, with a length of and few landforms—the most relevant are the Cap de Creus and the Gulf of Roses to the north and the Ebro Delta to the south. The Catalan Coastal Range hugs the coastline, and it is split into two segments, one between L'Estartit and the town of Blanes (the Costa Brava), and the other at the south, at the Costes del Garraf.

The principal rivers in Catalonia are the Ter, Llobregat, and the Ebro (Catalan: ), all of which run into the Mediterranean.

The majority of Catalan population is concentrated in 30% of the territory, mainly in the coastal plains. Intensive agriculture, livestock farming and industrial activities have been accompanied by a massive tourist influx (more than 20 million annual visitors), a rate of urbanization and even of major metropolisation which has led to a strong urban sprawl: two thirds of Catalans live in the urban area of Barcelona, while the proportion of urbanized soils increased from 4.2% in 1993 to 6.2% in 2009, a growth of 48.6% in sixteen years, complemented with a dense network of transport infrastructure. This is accompanied by a certain agricultural abandonment (decrease of 15% of all areas cultivated in Catalonia between 1993 and 2009) and a global threat to natural environment. Human activities have also put some animal species at risk, or even led to their disappearance from the territory, like the gray wolf and probably the brown bear of the Pyrenees. The pressure created by this model of life means that the country's ecological footprint exceeds its administrative area.

Faced with this problems, Catalan authorities initiated several measures whose purpose is to protect natural ecosystems. Thus, in 1990, the Catalan government created the Nature Conservation Council (Catalan: ), an advisory body with the aim to study, protect and manage the natural environments and landscapes of Catalonia. In addition, the Generalitat has carried out the Plan of Spaces of Natural Interest ( or PEIN) in 1992 while eighteen Natural Spaces of Special Protection ( or ENPE) have been instituted.

There's a National Park, Aigüestortes i Estany de Sant Maurici; fourteen Natural Parks, Alt Pirineu, Aiguamolls de l'Empordà, Cadí-Moixeró, Cap de Creus, Sources of Ter and Freser, Collserola, Ebro Delta, Ports, Montgrí, Medes Islands and Baix Ter, Montseny, Montserrat, Sant Llorenç del Munt and l'Obac, Serra de Montsant and the Garrotxa Volcanic Zone; as well as three Natural Places of National Interest ( or PNIN), the Pedraforca, the Poblet Forest and the Albères.

After Franco's death in 1975 and the adoption of a democratic constitution in Spain in 1978, Catalonia recovered and extended the powers that it had gained in the Statute of Autonomy of 1932 but lost with the fall of the Second Spanish Republic at the end of the Spanish Civil War in 1939.

This autonomous community has gradually achieved more autonomy since the approval of the Spanish Constitution of 1978. The Generalitat holds exclusive jurisdiction in education, health, culture, environment, communications, transportation, commerce, public safety and local government, and only shares jurisdiction with the Spanish government in justice. In all, some analysts argue that formally the current system grants Catalonia with "more self-government than almost any other corner in Europe".

The support for Catalan nationalism ranges from a demand for further autonomy and the federalisation of Spain to the desire for independence from the rest of Spain, expressed by Catalan independentists. The first survey following the Constitutional Court ruling that cut back elements of the 2006 Statute of Autonomy, published by "La Vanguardia" on 18 July 2010, found that 46% of the voters would support independence in a referendum. In February of the same year, a poll by the Open University of Catalonia gave more or less the same results. Other polls have shown lower support for independence, ranging from 40 to 49%. Although it is established in the whole of the territory, support for independence is significantly higher in the hinterland and the northeast, away from the more populated coastal areas such as Barcelona.

Since 2011 when the question started to be regularly surveyed by the governmental Center for Public Opinion Studies (CEO), support for Catalan independence has been on the rise. According to the CEO opinion poll from July 2016, 47.7% of Catalans would vote for independence and 42.4% against it while, about the question of preferences, according to the CEO opinion poll from March 2016, a 57.2 claim to be "absolutely" or "fairly" in favour of independence. Other polls have shown lower support for independence, ranging from 40 to 49%. Other polls show more variable results, according with the Spanish CIS, as of December 2016, 47% of Catalans rejected independence and 45% supported it.

In hundreds of non-binding local referendums on independence, organised across Catalonia from 13 September 2009, a large majority voted for independence, although critics argued that the polls were mostly held in pro-independence areas. In December 2009, 94% of those voting backed independence from Spain, on a turn-out of 25%. The final local referendum was held in Barcelona, in April 2011. On 11 September 2012, a pro-independence march pulled in a crowd of between 600,000 (according to the Spanish Government), 1.5 million (according to the Guàrdia Urbana de Barcelona), and 2 million (according to its promoters); whereas poll results revealed that half the population of Catalonia supported secession from Spain.

Two major factors were Spain's Constitutional Court's 2010 decision to declare part of the 2006 Statute of Autonomy of Catalonia unconstitutional, as well as the fact that Catalonia contributes 19.49% of the central government's tax revenue, but only receives 14.03% of central government's spending.

Parties that consider themselves either Catalan nationalist or independentist have been present in all Catalan governments since 1980. The largest Catalan nationalist party, Convergence and Union, ruled Catalonia from 1980 to 2003, and returned to power in the 2010 election. Between 2003 and 2010, a leftist coalition, composed by the Catalan Socialists' Party, the pro-independence Republican Left of Catalonia and the leftist-environmentalist Initiative for Catalonia-Greens, implemented policies that widened Catalan autonomy.

In the 25 November 2012 Catalan parliamentary election, sovereigntist parties supporting a secession referendum gathered 59.01% of the votes and held 87 of the 135 seats in the Catalan Parliament. Parties supporting independence from the rest of Spain obtained 49.12% of the votes and a majority of 74 seats.

Artur Mas, then the president of Catalonia, organised early elections that took place on 27 September 2015. In these elections, Convergència and Esquerra Republicana decided to join, and they presented themselves under the coalition named "Junts pel Sí" (in Catalan, "Together for Yes"). "Junts pel Sí" won 62 seats and was the most voted party, and CUP (Candidatura d'Unitat Popular, a far-left and independentist party) won another 10, so the sum of all the independentist forces/parties was 72 seats, reaching an absolute majority, but not in number of individual votes, comprising 47,74% of the total.

The Statute of Autonomy of Catalonia is the fundamental organic law, second only to the Spanish Constitution from which the Statute originates.

In the Spanish Constitution of 1978 Catalonia, along with the Basque Country and Galicia, was defined as a "nationality". The same constitution gave Catalonia the automatic right to autonomy, which resulted in the Statute of Autonomy of Catalonia of 1979.

Both the 1979 Statute of Autonomy and the current one, approved in 2006, state that "Catalonia, as a nationality, exercises its self-government constituted as an Autonomous Community in accordance with the Constitution and with the Statute of Autonomy of Catalonia, which is its basic institutional law, always under the law in Spain".

The Preamble of the 2006 Statute of Autonomy of Catalonia states that the Parliament of Catalonia has defined Catalonia as a nation, but that "the Spanish Constitution recognizes Catalonia's national reality as a nationality". While the Statute was approved by and sanctioned by both the Catalan and Spanish parliaments, and later by referendum in Catalonia, it has been subject to a legal challenge by the surrounding autonomous communities of Aragon, Balearic Islands and Valencia, as well as by the conservative People's Party. The objections are based on various issues such as disputed cultural heritage but, especially, on the Statute's alleged breaches of the principle of "solidarity between regions" in fiscal and educational matters enshrined by the Constitution.

Spain's Constitutional Court assessed the disputed articles and on 28 June 2010, issued its judgment on the principal allegation of unconstitutionality presented by the People's Party in 2006. The judgment granted clear passage to 182 articles of the 223 that make up the fundamental text. The court approved 73 of the 114 articles that the People's Party had contested, while declaring 14 articles unconstitutional in whole or in part and imposing a restrictive interpretation on 27 others. The court accepted the specific provision that described Catalonia as a "nation", however ruled that it was a historical and cultural term with no legal weight, and that Spain remained the only nation recognised by the constitution.

The Catalan Statute of Autonomy establishes that Catalonia is organised politically through the Generalitat of Catalonia (in Catalan: ), conformed by the Parliament, the Presidency of the Generalitat, the Government or Executive Council and the other institutions created by the Parliament, among them the Ombudsman (), the Office of Auditors () or the Council for Statutory Guarantees ()

The Parliament of Catalonia (in Catalan: ) is the legislative body of the Generalitat and represents the citizens of Catalonia. It is elected every four years by universal suffrage, and it has powers to legislate in different matters such as education, health, culture, internal institutional and territorial organization, election and control of the president of the Generalitat and the Government, budget and other affairs, according with the Statute of Autonomy. The last Catalan election was held on 21 December 2017, and its current president is Roger Torrent, incumbent since January 2018.

The president of the Generalitat of Catalonia (in Catalan: ) is the highest representative of Catalonia, and is also responsible of leading the government's action. Since the restoration of the Generalitat on the return of democracy in Spain, the presidents of Catalonia have been Josep Tarradellas (1977–1980, president in exile since 1954), Jordi Pujol (1980–2003), Pasqual Maragall (2003–2006), José Montilla (2006–2010), Artur Mas (2010–2016), Carles Puigdemont (2016–2017) and, after the imposition of direct rule from Madrid, Quim Torra (2018–).

The Executive Council (in Catalan: ) or Government (), is the body responsible of the government of the Generalitat, it holds executive and regulatory power. It comprises the president of the Generalitat, the First Minister (or the Vice President) and the Ministers (). Its seat is the Palau de la Generalitat, in Barcelona.

Catalonia has its own police force, the (officially called ), whose origins date back to the 18th century. Since 1980 they have been under the command of the Generalitat, and since 1994 they have expanded in number in order to replace the national Civil Guard and National Police Corps, which report directly to the Homeland Department of Spain. The national bodies retain personnel within Catalonia to exercise functions of national scope such as overseeing ports, airports, coasts, international borders, custom offices, the identification of documents and arms control, immigration control, terrorism prevention, arms trafficking prevention, amongst others.

Most of the justice system is administered by national judicial institutions, the highest body and last judicial instance in the Catalan jurisdiction, integrating the Spanish judiciary, is the High Court of Justice of Catalonia. The criminal justice system is uniform throughout Spain, while civil law is administered separately within Catalonia. The civil laws that are subject to autonomous legislation have been codified in the Civil Code of Catalonia () since 2002.

Navarre, the Basque Country and Catalonia are the Spanish communities with the highest degree of autonomy in terms of law enforcement.

Catalonia is organised territorially into provinces, further subdivided into comarques and municipalities. The 2006 Statute of Autonomy of Catalonia establishes the administrative organisation of three local authorities: vegueries, comarques, and municipalities.

Catalonia is divided administratively into four provinces, the governing body of which is the Provincial Deputation (, ). The four provinces and their populations are:


Comarques (singular: "comarca") are entities composed by the municipalities to manage their responsibilities and services. The current regional division has its roots in a decree of the Generalitat de Catalunya of 1936, in effect until 1939, when it was suppressed by Franco. In 1987 the Government adopted the territorial division again and in 1988 three new comarques were added (Alta Ribagorça, Pla d'Urgell and Pla de l'Estany), and in 2015 was created another comarca, the Moianès. At present there are 41. Every comarca is administered by a comarcal council ().

The Val d'Aran (Aran Valley), until 2015 considered as a comarca, is officially defined today as "unique territorial entity", has a special status and its autonomous government is named .

There are at present 948 municipalities () in Catalonia. Each municipality is run by a council () elected every four years by the residents in local elections. The council consists of a number of members () depending on population, who elect the mayor ( or ). Its seat is the town hall (, or ).

The "vegueria" is a new type of division defined as a specific territorial area for the exercise of government and inter-local cooperation with legal personality. The current Statute of Autonomy states vegueries are intended to supersede provinces in Catalonia, and take over many of functions of the comarques.

The territorial plan of Catalonia () provided six general functional areas, but was amended by Law 24/2001, of 31 December, recognizing the Alt Pirineu i Aran as a new functional area differentiated of Ponent. On 14 July 2010 the Catalan Parliament approved the creation of the functional area of the Penedès.


A highly industrialized land, the nominal GDP of Catalonia in 2018 was €228 billion (second after the community of Madrid, €230 billion) and the per capita GDP was €30,426 ($32,888), behind Madrid (€35,041), the Basque Country (€33,223), and Navarre (€31,389). That year, the GDP growth was 2.3%. In recent years, and increasingly following the unilateral declaration of independence in 2017, there has been a negative net relocation rate of companies based in Catalonia moving to other autonomous communities of Spain. From the 2017 independence referendum until the end of 2018, for example, Catalonia lost 5454 companies to other parts of Spain (mainly Madrid), 2359 only in 2018, gaining 467 new ones from the rest of the country during 2018.

Catalonia's long-term credit rating is BB (Non-Investment Grade) according to Standard & Poor's, Ba2 (Non-Investment Grade) according to Moody's, and BBB- (Low Investment Grade) according to Fitch Ratings. Catalonia's rating is tied for worst with between 1 and 5 other autonomous communities of Spain, depending on the rating agency.

In the context of the financial crisis of 2007–2008, Catalonia was expected to suffer a recession amounting to almost a 2% contraction of its regional GDP in 2009. Catalonia's debt in 2012 was the highest of all Spain's autonomous communities, reaching €13,476 million, i.e. 38% of the total debt of the 17 autonomous communities, but in recent years its economy recovered a positive evolution and the GDP grew a 3.3% in 2015.

Catalonia is amongst the List of country subdivisions by GDP over 100 billion US dollars and is a member of the Four Motors for Europe organisation.

The distribution of sectors is as follows:


The main tourist destinations in Catalonia are the city of Barcelona, the beaches of the Costa Brava in Girona, the beaches of the Costa del Maresme and Costa del Garraf from Malgrat de Mar to Vilanova i la Geltrú and the Costa Daurada in Tarragona. In the High Pyrenees there are several ski resorts, near Lleida. On 1 November 2012, Catalonia started charging a tourist tax. The revenue is used to promote tourism, and to maintain and upgrade tourism-related infrastructure.
Many savings banks were based in Catalonia before the independence referendum of 2017, with 10 of the 46 Spanish savings banks having headquarters in the region at that time. This list included Europe's premier savings bank, La Caixa, who, on 7 October 2017, a week after the referendum, moved its headquarters to Palma de Mallorca, in the Balearic Islands and CaixaBank to Valencia, in the Valencian Community. The first private bank in Catalonia, Banc Sabadell, ranked fourth among all Spanish private banks, also moved its headquarters to Alicante, in the Valencian Community.

The stock market of Barcelona, which in 2016 had a volume of around €152 billion, is the second largest of Spain after Madrid, and Fira de Barcelona organizes international exhibitions and congresses to do with different sectors of the economy.

The main economic cost for the Catalan families is the purchase of a home. According to data from the Society of Appraisal on 31 December 2005 Catalonia is, after Madrid, the second most expensive region in Spain for housing: 3,397 €/m on average (see Spanish property bubble).

The unemployment rate stood at 11.5% in 2018 and was lower than the national average.

Airports in Catalonia are owned and operated by Aena (a Spanish Government entity) except two airports in Lleida which are operated by Aeroports de Catalunya (an entity belonging to the Government of Catalonia).


Since the Middle Ages, Catalonia has been well integrated into international maritime networks. The port of Barcelona (owned and operated by , a Spanish Government entity) is an industrial, commercial and tourist port of worldwide importance. With 1,950,000 TEUs in 2015, it is the first container port in Catalonia, the third in Spain after Valencia and Algeciras in Andalusia, the 9th in the Mediterranean Sea, the 14th in Europe and the 68th in the world. It is sixth largest cruise port in the world, the first in Europe and the Mediterranean with 2,364,292 passengers in 2014. The ports of Tarragona (owned and operated by Puertos del Estado) in the southwest and Palamós near Girona at northeast are much more modest. The port of Palamós and the other ports in Catalonia (26) are operated and administered by , a Catalan Government entity.

The development of these infrastructures, resulting from the topography and history of the Catalan territory, responds strongly to the administrative and political organization of this autonomous community.

There are of roads throughout Catalonia.

The principal highways are  AP-7  () and  A-7  (). They follow the coast from the French border to Valencia, Murcia and Andalusia. The main roads generally radiate from Barcelona. The  AP-2  () and  A-2  () connect inland and onward to Madrid.

Other major roads are:

Public-own roads in Catalonia are either managed by the autonomous government of Catalonia (e.g.,  C-  roads) or the Spanish government (e.g.,  AP- ,  A- ,  N-  roads).

Catalonia saw the first railway construction in the Iberian Peninsula in 1848, linking Barcelona with Mataró. Given the topography most lines radiate from Barcelona. The city has both suburban and inter-city services. The main east coast line runs through the province connecting with the SNCF (French Railways) at Portbou on the coast.

There are two publicly owned railway companies operating in Catalonia: the Catalan FGC that operates commuter and regional services, and the Spanish national RENFE that operates long-distance and high-speed rail services (AVE and Avant) and the main commuter and regional service , administered by the Catalan government since 2010.

High-speed rail (AVE) services from Madrid currently reach Lleida, Tarragona and Barcelona. The official opening between Barcelona and Madrid took place 20 February 2008. The journey between Barcelona and Madrid now takes about two-and-a-half hours. A connection to the French high-speed TGV network has been completed (called the Perpignan–Barcelona high-speed rail line) and the Spanish AVE service began commercial services on the line 9 January 2013, later offering services to Marseille on their high speed network. This was shortly followed by the commencement of commercial service by the French TGV on 17 January 2013, leading to an average travel time on the Paris-Barcelona TGV route of 7h 42m. This new line passes through Girona and Figueres with a tunnel through the Pyrenees.

As of 2017, the official population of Catalonia was 7,522,596. 1,194,947 residents did not have Spanish citizenship, accounting for about 16% of the population.

The Urban Region of Barcelona includes 5,217,864 people and covers an area of . The metropolitan area of the Urban Region includes cities such as L'Hospitalet de Llobregat, Sabadell, Terrassa, Badalona, Santa Coloma de Gramenet and Cornellà de Llobregat.

In 1900, the population of Catalonia was 1,966,382 people and in 1970 it was 5,122,567. The sizeable increase of the population was due to the demographic boom in Spain during the 60s and early 70s as well as in consequence of large-scale internal migration from the rural economically weak regions to its more prospering industrial cities. In Catalonia that wave of internal migration arrived from several regions of Spain, especially from Andalusia, Murcia and Extremadura.

Immigrants from other countries settled in Catalonia since the 1990s; a large percentage comes from Africa, Latin America and Eastern Europe, and smaller numbers from Asia and Southern Europe, often settling in urban centers such as Barcelona and industrial areas. In 2017, Catalonia had 1,194,497 foreign residents (15.9% of the total population) with non-Spanish ID cards, without including those who acquired the Spanish citizenship.

Historically, all the Catalan population was Christian, specifically Catholic, but since the 1980s there has been a trend of decline of Christianity and parallel growth of irreligion (including stances of atheism and agnosticism) and other religions. According to the most recent study sponsored by the government of Catalonia, as of 2016, 61.9% of the Catalans identify as Christians, up from 56.5% in 2014, of whom 58.0% Catholics, 3.0% Protestants and Evangelicals, 0.9% Orthodox Christians and 0.6% Jehovah's Witnesses. At the same time, 16.0% of the population identify as atheists, 11.9% as agnostics, 4.8% as Muslims, 1.3% as Buddhists, and a further 2.4% as being of other religions.

According to the linguistic census held by the Government of Catalonia in 2013, Spanish is the most spoken language in Catalonia (46.53% claim Spanish as "their own language"), followed by Catalan (37.26% claim Catalan as "their own language"). In everyday use, 11.95% of the population claim to use both languages equally, whereas 45.92% mainly use Spanish and 35.54% mainly use Catalan. There is a significant difference between the Barcelona metropolitan area (and, to a lesser extent, the Tarragona area), where Spanish is more spoken than Catalan, and the more rural and small town areas, where Catalan clearly prevails over Spanish.

Originating in the historic territory of Catalonia, Catalan has enjoyed special status since the approval of the Statute of Autonomy of 1979 which declares it to be "Catalonia's own language", a term which signifies a language given special legal status within a Spanish territory, or which is historically spoken within a given region. The other languages with official status are Spanish, which has official status throughout Spain, and Aranese Occitan, which enjoys co-official status with Catalan and Spanish in the Val d'Aran.

Since the Statute of Autonomy of 1979, Aranese (a dialect of Gascon Occitan) has also been official and subject to special protection in Val d'Aran. This small area of 7,000 inhabitants was the only place where a dialect of Occitan has received full official status. Then, on 9 August 2006, when the new Statute came into force, Occitan became official throughout Catalonia. Occitan is the mother tongue of 22.4% of the population of Val d'Aran. Catalan Sign Language is also officially recognised.

Although not considered an "official language" in the same way as Catalan, Spanish, and Aranese, Catalan Sign Language, with about 18,000 users in Catalonia, is granted official recognition and support: "The public authorities shall guarantee the use of Catalan sign language and conditions of equality for deaf people who choose to use this language, which shall be the subject of education, protection and respect."

Under Francoist Spain, Catalan was excluded from the public education system and all other official use, so that for example families were not allowed to officially register children with Catalan names. Although never completely banned, Catalan language publishing was severely restricted during the early 1940s, with only religious texts and small-run self-published texts being released. Some books were published clandestinely or circumvented the restrictions by showing publishing dates prior to 1936. This policy was changed in 1946, when restricted publishing in Catalan resumed.

Rural–urban migration originating in other parts of Spain also reduced the social use of Catalan in urban areas and increased the use of Spanish. Lately, a similar sociolinguistic phenomenon has occurred with foreign immigration. Catalan cultural activity increased in the 1960s and Catalan classes began thanks to the initiative of associations such as Òmnium Cultural.

After the end of Francoist Spain, the newly established self-governing democratic institutions in Catalonia embarked on a long-term language policy to recover the use of Catalan and has, since 1983, enforced laws which attempt to protect and extend the use of Catalan. This policy, known as the "linguistic normalisation" ( in Catalan, in Spanish) has been supported by the vast majority of Catalan political parties through the last thirty years. Some groups consider these efforts a way to discourage the use of Spanish, whereas some others, including the Catalan government and the European Union consider the policies respectful, or even as an example which "should be disseminated throughout the Union".

Today, Catalan is the main language of the Catalan autonomous government and the other public institutions that fall under its jurisdiction. Basic public education is given basically in Catalan, but also there are some hours per week of Spanish medium instruction. Businesses are required to display all information (e.g. menus, posters) at least in Catalan, under penalty of fines. There is no obligation to display this information in either Occitan or Spanish, although there is no restriction on doing so in these or other languages. The use of fines was introduced in a 1997 linguistic law that aims to increase the public use of Catalan and defend the rights of Catalan speakers. In the other hand, the constitution of Spain obligates every citizen to know Spanish.

The law ensures that both Catalan and Spanish – being official languages – can be used by the citizens without prejudice in all public and private activities. The Generalitat uses Catalan in its communications and notifications addressed to the general population, but citizens can also receive information from the Generalitat in Spanish if they so desire. Debates in the Catalan Parliament take place almost exclusively in Catalan and the Catalan public television broadcasts programs basically in Catalan.

Due to the intense immigration which Spain in general and Catalonia in particular experienced in the first decade of the 21st century, many foreign languages are spoken in various cultural communities in Catalonia, of which Rif-Berber, Moroccan Arabic, Romanian and Urdu are the most common ones.

In Catalonia, there is a high social and political consensus on the language policies favoring Catalan, also among Spanish speakers and speakers of other languages. However, some of these policies have been criticised for trying to promote Catalan by imposing fines on businesses. For example, following the passage of the law on Catalan cinema in March 2010, which established that half of the movies shown in Catalan cinemas had to be in Catalan, a general strike of 75% of the cinemas took place. The Catalan government gave in and dropped the clause that forced 50% of the movies to be dubbed or subtitled in Catalan before the law came to effect. On the other hand, organisations such as Plataforma per la Llengua reported different violations of the linguistic rights of the Catalan speakers in Catalonia and the other Catalan-speaking territories in Spain, most of them caused by the institutions of the Spanish government in these territories.

The Catalan language policy has been challenged by some political parties in the Catalan Parliament. Citizens, currently the main opposition party, has been one of the most consistent critics of the Catalan language policy within Catalonia. The Catalan branch of the People's Party has a more ambiguous position on the issue: on one hand, it demands a bilingual Catalan–Spanish education and a more balanced language policy that would defend Catalan without favoring it over Spanish, whereas on the other hand, a few local PP politicians have supported in their municipalities measures privileging Catalan over Spanish and it has defended some aspects of the official language policies, sometimes against the positions of its colleagues from other parts of Spain.

Catalonia has given to the world many important figures in the area of the art. Catalan painters internationally known are, among others, Salvador Dalí, Joan Miró and Antoni Tàpies. Closely linked with the Catalan pictorial atmosphere, Pablo Picasso lived in Barcelona during his youth, training them as an artist and creating the movement of cubism. Other important artists are Claudi Lorenzale for the medieval Romanticism that marked the artistic Renaixença, Marià Fortuny for the Romanticism and Catalan Orientalism of the nineteenth century, Ramon Casas or Santiago Rusiñol, main representatives of the pictorial current of Catalan modernism from the end of the nineteenth century to the beginning of the twentieth century, Josep Maria Sert for early 20th-century Noucentisme, or Josep Maria Subirachs for expressionist or abstract sculpture and painting of the late twentieth century.
The most important painting museums of Catalonia are the Teatre-Museu Dalí in Figueres, the National Art Museum of Catalonia (MNAC), Picasso Museum, Fundació Antoni Tàpies, Joan Miró Foundation, the Barcelona Museum of Contemporary Art (MACBA), the Centre of Contemporary Culture of Barcelona (CCCB) and the CaixaForum.

In the field of architecture were developed and adapted to Catalonia different artistic styles prevalent in Europe, leaving footprints in many churches, monasteries and cathedrals, of Romanesque (the best examples of which are located in the northern half of the territory) and Gothic styles. The Gothic developed in Barcelona and its area of influence is known as Catalan Gothic, with some particular characteristics. The church of Santa Maria del Mar is an example of this kind of style. During the Middle Ages, many fortified castles were built by feudal nobles to mark their powers.

There are some examples of Renaissance (such as the Palau de la Generalitat), Baroque and Neoclassical architectures. In the late nineteenth century Modernism (Art Nouveau) appeared as the national art. The world-renowned Catalan architects of this style are Antoni Gaudí, Lluís Domènech i Montaner and Josep Puig i Cadafalch. Thanks to the urban expansion of Barcelona during the last decades of the century and the first ones of the next, many buildings of the Eixample are modernists. In the field of architectural rationalism, which turned especially relevant in Catalonia during the Republican era (1931-1939) highlighting Josep Lluís Sert and Josep Torres i Clavé, members of the GATCPAC and, in contemporany architecture, Ricardo Bofill and Enric Miralles.

There are several UNESCO World Heritage Sites in Catalonia:


The oldest surviving literary use of the Catalan language is considered to be the religious text known as Homilies d'Organyà, written either in late 11th or early 12th century.

There are two historical moments of splendor of Catalan literature. The first begins with the historiographic chronicles of the 13th century (chronicles written between the thirteenth and fourteenth centuries narrating the deeds of the monarchs and leading figures of the Crown of Aragon) and the subsequent Golden Age of the 14th and 15th centuries. After that period, between the 16th and 19th centuries the Romantic historiography defined this era as the , considered as the "decadent" period in Catalan literature because of a general falling into disuse of the vernacular language in cultural contexts and lack of patronage among the nobility.
The second moment of splendor began in the 19th century with the cultural and political (Renaissance) represented by writers and poets such as Jacint Verdaguer, Víctor Català (pseudonym of Caterina Albert i Paradís), Narcís Oller, Joan Maragall and Àngel Guimerà. During the 20th century, avant-garde movements developed, initiated by the Generation of '14 (called Noucentisme in Catalonia), represented by Eugeni d'Ors, Joan Salvat-Papasseit, Josep Carner, Carles Riba, J.V. Foix and others. During the dictatorship of Primo de Rivera, the Civil War (Generation of '36) and the Francoist period, Catalan literature was maintained despite the repression against the Catalan language, being often produced in exile. The most outstanding authors of this period are Salvador Espriu, Josep Pla, Josep Maria de Sagarra (the latter three being considered as the main responsible of the renewal of Catalan prose), Mercè Rodoreda, Joan Oliver Sallarès or "Pere Quart", Pere Calders, Gabriel Ferrater, Manuel de Pedrolo, Agustí Bartra or Miquel Martí i Pol. In addition, several foreign writers who fought in the framework of the International Brigades then recount their experiences of fighting in their works, historical or fictional, with for example "Homage to Catalonia" of the British George Orwell in 1938 or in 1962 and "The Georgics" in 1981 by Frenchman Claude Simon.

After the transition to democracy (1975–1978) and the restoration of the Generalitat (1977), literary life and the editorial market have returned to normality and literary production in Catalan is being bolstered with a number of language policies intended to protect Catalan culture. Besides the aforementioned authors, other relevant 20th-century writers of the Francoist and democracy periods include Joan Brossa, Agustí Bartra, Manuel de Pedrolo, Pere Calders or Quim Monzó.

Ana María Matute, Jaime Gil de Biedma, Manuel Vázquez Montalbán and Juan Goytisolo are among the most prominent Catalan writers in the Spanish language since the democratic restoration in Spain.

Castells are one of the main manifestations of Catalan popular culture. The activity consists in constructing human towers by competing (teams). This practice originated in Valls, on the region of the Camp de Tarragona, during the 18th century, and later it was extended along the next two centuries to the rest of the territory. The tradition of els Castells i els Castellers was declared Masterpiece of the Oral and Intangible Heritage of Humanity by UNESCO in 2010.

In main celebrations, other elements of the Catalan popular culture are also usually present: parades with (giants), bigheads, stick-dancers and musicians, and the , where devils and monsters dance and spray showers of sparks using firecrackers. Another traditional celebration in Catalonia is , declared a Masterpiece of the Oral and Intangible Heritage of Humanity by the UNESCO on 25 November 2005.
Christmas in Catalonia lasts two days, plus Christmas Eve. On the 25th, Christmas is celebrated, followed by a similar feast on the 26, called Sant Esteve (Saint Steve's Day). This allows families to visit and dine with different sectors of the extended family, or get together with friends on the second day.

One of the most deeply-rooted and curious Christmas traditions is the popular figure of the , consisting of an (often hollow) log with a face painted on it and often two little front legs appended, usually wearing a Catalan hat and scarf. Note that the word has nothing to do with the Spanish word "tío", meaning uncle. "Tió" means log in Catalan. The log is sometimes "found in the woods" (in an event staged for children) and then adopted and taken home, where it is fed and cared for during a month or so. On Christmas Day or on Christmas Eve, a game is played where children march around the house singing a song requesting the log to poop, then they tap the log gently with a stick, as if a magic wand, to make it poop, and lo and behold, as if through magic, it poops candy, and sometimes other small gifts. Usually the larger or main gifts are brought by the Three Kings on 6 January, and the tió only brings small things.

Another custom is to make a (nativity scene) in the home or in shop windows, the latter sometimes competing in originality or shear size and detail. Churches often host exhibits of numerous dioramas by nativity scene makers, or a single nativity scene they put out, and town halls generally put out a nativity scene in the central square. In Barcelona, every year, the main nativity scene is designed by different artists, and often ends up being an interesting, post-modern or conceptual and strange creation. In the home, the nativity scene often consists of strips of cork bark to represent cliffs or mountains in the background, moss as grass in the foreground, some wood chips or other as dirt, and aluminum foil for rivers and lakes. The traditional figurines often included are the three wise men on camels or horses, which are moved every day or so to go closer to the manger, a star with a long tail in the background to lead people to the spot, the annunciation with shepherds having a meal and an angel appearing (hanging from something), a washer lady washing clothes in the pond, sheep, ducks, people carrying packages on their backs, a donkey driver with a load of twigs, and atrezzo such as a starry sky, miniature towns placed in the distance, either Oriental-styled or local-looking, a bridge over the river, trees, etc.

One of the most astonishing and sui-generis figurines traditionally placed in the nativity scene, to the great glee of children, is the , a person depicted in the act of defecating. This figurine is hidden in some corner of the nativity scene and the game is to detect it. Of course, churches forgo this figurine, and the main nativity scene of Barcelona, for instance, likewise does not feature it. The caganer is so popular it has, together with the tió, long been a major part of the Christmas markets, where they come in the guise of your favorite politicians or other famous people, as well as the traditional figures of a Catalan farmer. People often buy a figurine of a caganer in the guise of a famous person they are actually fond of, contrary to what one would imagine, though sometimes people buy a caganer in the guise of someone they dislike, although this means they have to look at them in the home...

Another (extended) Christmas tradition is the celebration of the Epiphany on 6 January, which is called "Reis", meaning Three Kings Day. This is every important in Catalonia and the Catalan-speaking areas, and families go to watch major parades on the eve of the Epiphany, where they can greet the kings and watch them pass by in pomp and circumstance, on floats and preceded and followed by pages, musicians, dancers, etc. They often give the kings letters with their gift requests, which are collected by the pages. On the next day, the children find the gifts the three kings brought for them.

In addition to traditional local Catalan culture, traditions from other parts of Spain can be found as a result of migration from other regions, for instance the celebration of the Andalusian in Catalonia.

On 28 July 2010, second only after the Canary Islands, Catalonia became another Spanish territory to forbid bullfighting. The ban, which went into effect on 1 January 2012, had originated in a popular petition supported by over 180,000 signatures.

The sardana is considered to be the most characteristic Catalan folk dance, interpreted to the rhythm of tamborí, tible and tenora (from the oboe family), trumpet, trombó (trombone), fiscorn (family of bugles) and contrabaix with three strings played by a cobla, and are danced in a circle dance. Other tunes and dances of the traditional music are the contrapàs (obsolete today), ball de bastons (the "dance of sticks"), the moixiganga, the goigs (popular songs), the galops or the jota in the southern part. The havaneres are characteristic in some marine localities of the Costa Brava, especially during the summer months when these songs are sung outdoors accompanied by a of burned rum.

Art music was first developed, up to the nineteenth century and, as in much of Europe, in a liturgical setting, particularly marked by the Escolania de Montserrat. The main Western musical trends have marked these productions, medieval monodies or polyphonies, with the work of Abbot Oliba in the eleventh century or the compilation Llibre Vermell de Montserrat ("Red Book of Montserrat") from the fourteenth century. Through the Renaissance there were authors such as Pere Albert Vila, Joan Brudieu or the two Mateu Fletxa ("The Old" and "The Young"). Baroque had composers like Joan Cererols. The Romantic music was represented by composers such as Fernando Sor, Josep Anselm Clavé (father of choir movement in Catalonia and responsible of the music folk reviving) or Felip Pedrell.

Modernisme also expressed in musical terms from the end of the 19th century onwards, mixing folkloric and post-romantic influences, through the works of Isaac Albéniz and Enric Granados. The avant-garde spirit initiated by the modernists is prolonged throughout the twentieth century, thanks to the activities of the Orfeó Català, a choral society founded in 1891, with its monumental concert hall, the Palau de la Música Catalana in Catalan, built by Lluís Domènech i Montaner from 1905 to 1908, the Barcelona Symphony Orchestra created in 1944 and composers, conductors and musicians engaged against the Francoism like Robert Gerhard, Eduard Toldrà and Pau Casals.

Performances of opera, mostly imported from Italy, began in the 18th century, but some native operas were written as well, including the ones by Domènec Terradellas, Carles Baguer, Ramon Carles, Isaac Albéniz and Enric Granados. The Barcelona main opera house, Gran Teatre del Liceu (opened in 1847), remains one of the most important in Spain, hosting one of the most prestigious music schools in Barcelona, the Conservatori Superior de Música del Liceu. Several lyrical artists trained by this institution gained international renown during the 20th century, such as Victoria de los Ángeles, Montserrat Caballé, Giacomo Aragall and Josep Carreras.

Cellist Pau Casals is admired as an outstanding player. Other popular musical styles were born in the second half of the 20th century such as Nova Cançó from the 1960s with Lluís Llach and the group Els Setze Jutges, the Catalan rumba in the 1960s with Peret, Catalan Rock from the late 1970s with La Banda Trapera del Río and Decibelios for Punk Rock, Sau, Els Pets, Sopa de Cabra or Lax'n'Busto for pop rock or Sangtraït for hard rock, electropop since the 1990s with OBK and indie pop from the 1990s.

Catalonia is the autonomous community, along with Madrid, that has the most media (TV, Magazines, Newspapers etc.). In Catalonia there is a wide variety of local and comarcal media. With the restoration of democracy, many newspapers and magazines, until then in the hands of the Franco government, were recovered in order to convert them into free and democratic media, while local radios and televisions were implemented.

Televisió de Catalunya, which broadcasts entirely in the Catalan language, is the main Catalan public TV. It has five channels: TV3, El 33, Super3, 3/24, Esport3 and TV3CAT. In 2018, TV3 became the first television channel to be the most viewed one for nine consecutive years in Catalonia. State televisions that broadcast in Catalonia in Spanish language include Televisión Española (with few emissions in Catalan), Antena 3, Cuatro, Telecinco, and La Sexta. Other smaller Catalan television channels include; 8TV (owned by Grup Godó), Barça TV and the local televisions, the greatest exponent of which is , the TV channel of Barcelona, which also broadcasts in Catalan.

The two main Catalan newspapers of general information are "El Periódico de Catalunya" and "La Vanguardia", both with editions in Catalan and Spanish. Catalan only published newspapers include "Ara" and "El Punt Avui" (from the fusion of "El Punt" and "Avui" in 2011), as well as most part of the local press. The Spanish newspapers, such as "El País", "El Mundo" or "La Razón", can be also acquired.

Catalonia has a long tradition of use of radio, the first regular radio broadcast in the country was from Ràdio Barcelona in 1924. Today, the public Catalunya Ràdio (owned by Catalan Media Corporation) and the private RAC 1 (belonging to Grup Godó) are the two main radios of Catalonia, both in Catalan.
Regarding the cinema, after the democratic transition, three styles have dominated since then. First, auteur cinema, in the continuity of the Barcelona School, emphasizes experimentation and form, while focusing on developing social and political themes. Worn first by Josep Maria Forn or Bigas Luna, then by Marc Recha, Jaime Rosales and Albert Serra, this genre has achieved some international recognition. Then, the documentary became another genre particularly representative of contemporary Catalan cinema, boosted by Joaquim Jordà i Català and José Luis Guerín. Later, horror films and thrillers have also emerged as a specialty of the Catalan film industry, thanks in particular to the vitality of the Sitges Film Festival, created in 1968. Several directors have gained worldwide renown thanks to this genre, starting with Jaume Balagueró and his series "REC" (co-directed with Valencian Paco Plaza), Juan Antonio Bayona and "El Orfanato" or Jaume Collet-Serra with "Orphan", "Unknown" and "Non-Stop".

Catalan actors have shot for Spanish and international productions, such as Sergi López.

The Museum of Cinema - Tomàs Mallol Collection (Museu del Cinema - Col.lecció Tomàs Mallol in Catalan) of Girona is home of important permanent exhibitions of cinema and pre-cinema objects. Other important institutions for the promotion of cinema are the Gaudí Awards (Premis Gaudí in Catalan, which replaced from 2009 Barcelona Film Awards themselves created in 2002), serving as equivalent for Catalonia to the Spanish Goya or French César.

 is a form of ancestral Catalan wisdom or sensibleness. It involves well-pondered perception of situations, level-headedness, awareness, integrity, and right action. Many Catalans consider seny something unique to their culture, is based on a set of ancestral local customs stemming from the scale of values and social norms of their society.

Sport has a distinct importance in Catalan life and culture since the beginning of the 20th century and consequently, has a well developed sport infrastructure. The main sports are football, basketball, handball, rink hockey, tennis and motorsport.

Despite the fact that the most popular sports are represented outside by the Spanish national teams, Catalonia can officially play as itself in some others, like korfball, futsal or rugby league. Most of Catalan Sports Federations have a long tradition and some of them participated in the foundation of international sports federations, as the Catalan Federation of Rugby, that was one of the founder members of the Fédération Internationale de Rugby Amateur (FIRA) in 1934. The majority of Catalan sport federations are part of the Sports Federation Union of Catalonia (Catalan: ), founded in 1933.

The Catalan Football Federation also periodically fields a national team against international opposition, organizing friendly matches. In the recent years they have played with Bulgaria, Argentina, Brazil, Basque Country, Colombia, Nigeria, Cape Verde and Tunisia. The biggest football clubs are FC Barcelona (also known as Barça), who have won five European Cups (UEFA Champions League), and RCD Espanyol, who have twice been runner-up of the UEFA Cup. Both play in La Liga.

The Catalan waterpolo is one of the main powers of the Iberian Peninsula. The Catalans won triumphs in waterpolo competitions at European and world level by club (the Barcelona was champion of Europe in 1981/82 and the Catalonia in 1994/95) and national team (one gold and one silver in Olympic Games and World Championships). It also has many international synchronized swimming champions.

Motorsport has a long tradition in Catalonia, which involving many people, with some world champions and several competitions organized since the beginning of the 20th century. The Circuit de Catalunya, built in 1991, is one of the main motorsport venues, holding the Catalan motorcycle Grand Prix, the Spanish F1 Grand Prix, a DTM race, and several other races.

Catalonia hosted many relevant international sport events, such as the 1992 Summer Olympics in Barcelona, and also the 1955 Mediterranean Games, the 2013 World Aquatics Championships or the 2018 Mediterranean Games. It held annually the fourth-oldest still-existing cycling stage race in the world, the Volta a Catalunya (Tour of Catalonia).

Catalonia has its own representative and distinctive national symbols such as:


Catalan gastronomy has a long culinary tradition. Various local food recipes have been described in documents dating from the fifteenth century. As with all the cuisines of the Mediterranean, Catatonian dishes make abundant use of fish, seafood, olive oil, bread and vegetables. Regional specialties include the (bread with tomato), which consists of bread (sometimes toasted), and tomato seasoned with olive oil and salt. Often the dish is accompanied with any number of sausages (cured botifarres, fuet, iberic ham, etc.), ham or cheeses. Others dishes include the , , (fish stew), and a dessert, Catalan cream.

Catalan vineyards also have several wines, such as: Priorat, Montsant, Penedès and Empordà. There is also a sparkling wine, the cava.

Catalonia is internationally recognized for its fine dining. Three of The World's 50 Best Restaurants are in Catalonia, and four restaurants have three Michelin stars, including restaurants like El Bulli or El Celler de Can Roca, both of which regularly dominate international rankings of restaurants.





</doc>
<doc id="6823" url="https://en.wikipedia.org/wiki?curid=6823" title="Constantine Kanaris">
Constantine Kanaris

Constantine Kanaris or Canaris (; 17902 September 1877) was a Greek Prime Minister, admiral and politician who in his youth was a freedom fighter in the Greek War of Independence.

He was born and grew up on the island of Psara, close to the island of Chios, in the Aegean. His exact year of birth is unknown. The official records of the Hellenic Navy indicate 1795 but modern Greek historians believe that 1790 or 1793 is more probable.

Constantine was left an orphan at a young age. Having to support himself, he chose to become a seaman like most members of his family since the beginning of the 18th century. He was hired as a boy on the brig of his uncle Dimitris Bourekas.

Constantine gained his fame during the Greek War of Independence (1821–1829). Unlike most other prominent figures of the War, he had never been initiated into the Filiki Eteria (Friendly Society), which played a significant role in the revolution against the Ottoman Empire, primarily by secret recruitment of supporters against the Empire.

By early 1821, it had gained enough support to declare a revolution. This declaration seems to have surprised Constantine, who was absent at Odessa. He returned to Psara in haste and was there when the island joined the Revolution on 10 April 1821.

The island formed its own fleet of ships and the famed seamen of Psara, already known for their successful naval combats against pirates and their well-equipped ships, proved to be effective at full naval war. Constantine soon distinguished himself as a fire ship captain.

At Chios, on the moonless night of 6–7 June 1822 forces under his command destroyed the flagship of the Turkish admiral Nasuhzade Ali Pasha in revenge for the Chios massacre. The admiral was holding a celebration (Bayram), so Kanaris and his men managed to place a fire ship next to it without being noticed. When the flagship's powder store caught fire, all men aboard were instantly killed. The Ottoman casualties comprised 2300 men, both naval officers and common sailors, as well as Nasuhzade Ali Pasha himself.

Later in the year he led another successful attacks against the Turkish fleet at Tenedos in November 1822. He was famously said to have encouraged himself by murmuring ""Konstantí, you are going to die"" every time he was approaching a Turkish warship on the fire boat he was about to detonate.

The Turkish fleet captured Psara on 21 June 1824. A part of the population, including Kanaris, managed to flee the island, but those who didn't were either sold into slavery or slaughtered.

After the destruction of his home island, Kanaris continued to lead his men into attacks against the Turks. He took part to sea fights in the Dodecanese in August 1824.

In August 1825, Kanaris led the raid on Alexandria, a daring attempt to destroy the Egyptian fleet via fire ships that might have been successful if the wind had not failed just after the Greek ships entered Alexandria harbor.

Following the end of the war and the independence of Greece, Constantine became an officer of the new Greek Navy, reaching the rank of admiral, and later became a prominent politician.

Constantine Kanaris was one of the few with the personal confidence of Ioannis Kapodistrias the first Head of State of independent Greece. Kanaris served as Minister in various governments and then as Prime Minister in the provisional government (11 March11 April 1844). He served a second term (27 October 184824 December 1849), and as Navy Minister in Mavrokordatos' 1854 cabinet.

In 1862, he was one of the few War of Independence veterans that helped in the bloodless revolution that deposed King Otto of Greece and put Prince William of Denmark on the Greek throne as King George I of Greece. Under George I, he served as a Prime Minister for a third term (17 March28 April 1864), fourth term (7 August 18649 February 1865) and fifth and last term (7 June14 September 1877).

Kanaris died on 2 September 1877 whilst still serving in office as Prime Minister. Following his death his government remained in power until 14 September 1877 without agreeing on a replacement at its head. He was buried in the First Cemetery of Athens, where most Greek prime ministers and celebrated figures are also buried. After his death he was honored as a national hero.

To honour Kanaris, three ships of the Hellenic Navy have been named after him:

In 1817, he married Despina Maniatis, from a historical family of Psara. They had seven children:

Wilhelm Canaris, a German Admiral, speculated that he might be a descendant of Constantine Kanaris. An official genealogical family history that was researched in 1938 showed however, that Canaris was of Italian descent and was not related to Constantine Kanaris.




 


</doc>
<doc id="6824" url="https://en.wikipedia.org/wiki?curid=6824" title="Carl Sagan">
Carl Sagan

Carl Edward Sagan (; November 9, 1934December 20, 1996) was an American astronomer, planetary scientist, cosmologist, astrophysicist, astrobiologist, author, and science communicator. His best known scientific contribution is research on extraterrestrial life, including experimental demonstration of the production of amino acids from basic chemicals by radiation. Sagan assembled the first physical messages sent into space: the Pioneer plaque and the Voyager Golden Record, universal messages that could potentially be understood by any extraterrestrial intelligence that might find them. Sagan argued the now-accepted hypothesis that the high surface temperatures of Venus can be attributed to and calculated using the greenhouse effect.

Initially an associate professor at Harvard and later at Cornell, from 1976 to his death, he was the David Duncan Professor of Astronomy and Space Sciences at the latter. Sagan published more than 600 scientific papers and articles and was author, co-author or editor of more than 20 books. He wrote many popular science books, such as "The Dragons of Eden", "Broca's Brain" and "Pale Blue Dot", and narrated and co-wrote the award-winning 1980 television series "". The most widely watched series in the history of American public television, "Cosmos" has been seen by at least 500 million people across 60 different countries. The book "Cosmos" was published to accompany the series. He also wrote the science fiction novel "Contact", the basis for a 1997 film of the same name. His papers, containing 595,000 items, are archived at The Library of Congress.

Sagan advocated scientific skeptical inquiry and the scientific method, pioneered exobiology and promoted the Search for Extra-Terrestrial Intelligence (SETI). He spent most of his career as a professor of astronomy at Cornell University, where he directed the Laboratory for Planetary Studies. Sagan and his works received numerous awards and honors, including the NASA Distinguished Public Service Medal, the National Academy of Sciences Public Welfare Medal, the Pulitzer Prize for General Non-Fiction for his book "The Dragons of Eden", and, regarding "Cosmos: A Personal Voyage", two Emmy Awards, the Peabody Award, and the Hugo Award. He married three times and had five children. After suffering from myelodysplasia, Sagan died of pneumonia at the age of 62, on December 20, 1996.

Carl Sagan was born in Brooklyn, New York. His father, Samuel Sagan, was an immigrant garment worker from Kamianets-Podilskyi, then in the Russian Empire, in today's Ukraine. His mother, Rachel Molly Gruber, was a housewife from New York. Carl was named in honor of Rachel's biological mother, Chaiya Clara, in Sagan's words, "the mother she never knew".

He had a sister, Carol, and the family lived in a modest apartment near the Atlantic Ocean, in Bensonhurst, a Brooklyn neighborhood. According to Sagan, they were Reform Jews, the most liberal of North American Judaism's four main groups. Carl and his sister agreed that their father was not especially religious, but that their mother "definitely believed in God, and was active in the temple; ... and served only kosher meat". During the depths of the Depression, his father worked as a theater usher.

According to biographer Keay Davidson, Sagan's "inner war" was a result of his close relationship with both of his parents, who were in many ways "opposites". Sagan traced his later analytical urges to his mother, a woman who had been extremely poor as a child in New York City during World War I and the 1920s. As a young woman, she had held her own intellectual ambitions, but they were frustrated by social restrictions: her poverty, her status as a woman and a wife, and her Jewish ethnicity. Davidson notes that she therefore "worshipped her only son, Carl. He would fulfill her unfulfilled dreams."

However, he claimed that his sense of wonder came from his father, who in his free time gave apples to the poor or helped soothe labor-management tensions within New York's garment industry. Although he was awed by Carl's intellectual abilities, he took his son's inquisitiveness in stride and saw it as part of his growing up. In his later years as a writer and scientist, Sagan would often draw on his childhood memories to illustrate scientific points, as he did in his book "Shadows of Forgotten Ancestors". Sagan describes his parents' influence on his later thinking:
Sagan recalls that one of his most defining moments was when his parents took him to the 1939 New York World's Fair when he was four years old. The exhibits became a turning point in his life. He later recalled the moving map of the "America of Tomorrow" exhibit: "It showed beautiful highways and cloverleaves and little General Motors cars all carrying people to skyscrapers, buildings with lovely spires, flying buttresses—and it looked great!" At other exhibits, he remembered how a flashlight that shone on a photoelectric cell created a crackling sound, and how the sound from a tuning fork became a wave on an oscilloscope. He also witnessed the future media technology that would replace radio: television. Sagan wrote:
He also saw one of the Fair's most publicized events, the burial of a time capsule at Flushing Meadows, which contained mementos of the 1930s to be recovered by Earth's descendants in a future millennium. "The time capsule thrilled Carl", writes Davidson. As an adult, Sagan and his colleagues would create similar time capsules—capsules that would be sent out into the galaxy; these were the Pioneer plaque and the "Voyager Golden Record" précis, all of which were spinoffs of Sagan's memories of the World's Fair.

During World War II Sagan's family worried about the fate of their European relatives. Sagan, however, was generally unaware of the details of the ongoing war. He wrote, "Sure, we had relatives who were caught up in the Holocaust. Hitler was not a popular fellow in our household... But on the other hand, I was fairly insulated from the horrors of the war." His sister, Carol, said that their mother "above all wanted to protect Carl... She had an extraordinarily difficult time dealing with World War II and the Holocaust." Sagan's book "The Demon-Haunted World" (1996) included his memories of this conflicted period, when his family dealt with the realities of the war in Europe but tried to prevent it from undermining his optimistic spirit.

Soon after entering elementary school he began to express a strong inquisitiveness about nature. Sagan recalled taking his first trips to the public library alone, at the age of five, when his mother got him a library card. He wanted to learn what stars were, since none of his friends or their parents could give him a clear answer:
At about age six or seven, he and a close friend took trips to the American Museum of Natural History across the East River in Manhattan. While there, they went to the Hayden Planetarium and walked around the museum's exhibits of space objects, such as meteorites, and displays of dinosaurs and animals in natural settings. Sagan writes about those visits:
His parents helped nurture his growing interest in science by buying him chemistry sets and reading materials. His interest in space, however, was his primary focus, especially after reading science fiction stories by writers such as H. G. Wells and Edgar Rice Burroughs, which stirred his imagination about life on other planets such as Mars. According to biographer Ray Spangenburg, these early years as Sagan tried to understand the mysteries of the planets became a "driving force in his life, a continual spark to his intellect, and a quest that would never be forgotten".

In 1947 he discovered "Astounding Science Fiction" magazine, which introduced him to more hard science fiction speculations than those in Burroughs's novels. That same year inaugurated the "flying saucer" mass hysteria with the young Carl suspecting that the "discs" might be alien spaceships.

Sagan had lived in Bensonhurst, where he went to David A. Boody Junior High School. He had his bar mitzvah in Bensonhurst when he turned 13. The following year, 1948, his family moved to the nearby town of Rahway, New Jersey, for his father's work, where Sagan then entered Rahway High School. He graduated in 1951. Rahway was an older industrial town, and the Sagans were among its few Jewish families.

Sagan was a straight-A student but was bored due to unchallenging classes and uninspiring teachers. His teachers realized this and tried to convince his parents to send him to a private school, the administrator telling them, "This kid ought to go to a school for gifted children, he has something really remarkable." However, his parents could not afford it.

Sagan was made president of the school's chemistry club, and at home he set up his own laboratory. He taught himself about molecules by making cardboard cutouts to help him visualize how molecules were formed: "I found that about as interesting as doing [chemical] experiments", he said. Sagan remained mostly interested in astronomy as a hobby, and in his junior year made it a career goal after he learned that astronomers were paid for doing what he always enjoyed: "That was a splendid day—when I began to suspect that if I tried hard I could do astronomy full-time, not just part-time."

Before the end of high school, he entered an essay contest in which he posed the question of whether human contact with advanced life forms from another planet might be as disastrous for people on Earth as it was for Native Americans when they first had contact with Europeans. The subject was considered controversial, but his rhetorical skill won over the judges, and they awarded him first prize. By graduation, his classmates had voted him "most likely to succeed" and put him in line to be valedictorian.

Sagan attended the University of Chicago, which was one of the few colleges he applied to that would, despite his excellent high-school grades, consider admitting a 16-year-old. Its chancellor, Robert Maynard Hutchins, had recently retooled the undergraduate College of the University of Chicago into an "ideal meritocracy" built on Great Books, Socratic dialogue, comprehensive examinations and early entrance to college with no age requirement. The school also employed a number of the nation's leading scientists, including Enrico Fermi and Edward Teller, along with operating the famous Yerkes Observatory.

During his time as an honors program undergraduate, Sagan worked in the laboratory of the geneticist H. J. Muller and wrote a thesis on the origins of life with physical chemist Harold Urey. Sagan joined the Ryerson Astronomical Society, received a B.A. degree in laughingly self-proclaimed "nothing" with general and special honors in 1954, and a B.S. degree in physics in 1955. He went on to earn a M.S. degree in physics in 1956, before earning a Ph.D. degree in 1960 with his thesis "Physical Studies of Planets" submitted to the Department of Astronomy and Astrophysics.

He used the summer months of his graduate studies to work with his dissertation director, planetary scientist Gerard Kuiper, as well as physicist George Gamow and chemist Melvin Calvin. The title of Sagan's dissertation reflects his shared interests with Kuiper, who throughout the 1950s had been president of the International Astronomical Union's commission on "Physical Studies of Planets and Satellites". In 1958, the two worked on the classified military Project A119, the secret Air Force plan to detonate a nuclear warhead on the Moon.

Sagan had a Top Secret clearance at the U.S. Air Force and a Secret clearance with NASA. While working on his doctoral dissertation, Sagan revealed US Government classified titles of two Project A119 papers when he applied for a University of California, Berkeley scholarship in 1959. The leak was not publicly revealed until 1999, when it was published in the journal "Nature". A follow-up letter to the journal by project leader Leonard Reiffel confirmed Sagan's security leak.

From 1960 to 1962 Sagan was a Miller Fellow at the University of California, Berkeley. Meanwhile, he published an article in 1961 in the journal "Science" on the atmosphere of Venus, while also working with NASA's Mariner 2 team, and served as a "Planetary Sciences Consultant" to the RAND Corporation.

After the publication of Sagan's "Science" article, in 1961 Harvard University astronomers Fred Whipple and Donald Menzel offered Sagan the opportunity to give a colloquium at Harvard and subsequently offered him a lecturer position at the institution. Sagan instead asked to be made an assistant professor, and eventually Whipple and Menzel were able to convince Harvard to offer Sagan the assistant professor position he requested. Sagan lectured, performed research, and advised graduate students at the institution from 1963 until 1968, as well as working at the Smithsonian Astrophysical Observatory, also located in Cambridge, Massachusetts.

In 1968, Sagan was denied tenure at Harvard. He later indicated that the decision was very much unexpected. The tenure denial has been blamed on several factors, including that he focused his interests too broadly across a number of areas (while the norm in academia is to become a renowned expert in a narrow specialty), and perhaps because of his well-publicized scientific advocacy, which some scientists perceived as borrowing the ideas of others for little more than self-promotion. An advisor from his years as an undergraduate student, Harold Urey, wrote a letter to the tenure committee recommending strongly against tenure for Sagan.

Long before the ill-fated tenure process, Cornell University astronomer Thomas Gold had courted Sagan to move to Ithaca, New York, and join the faculty at Cornell. Following the denial of tenure from Harvard, Sagan accepted Gold's offer and remained a faculty member at Cornell for nearly 30 years until his death in 1996. Unlike Harvard, the smaller and more laid-back astronomy department at Cornell welcomed Sagan's growing celebrity status. Following two years as an associate professor, Sagan became a full professor at Cornell in 1970 and directed the Laboratory for Planetary Studies there. From 1972 to 1981, he was associate director of the Center for Radiophysics and Space Research (CRSR) at Cornell. In 1976, he became the David Duncan Professor of Astronomy and Space Sciences, a position he held for the remainder of his life.

Sagan was associated with the U.S. space program from its inception. From the 1950s onward, he worked as an advisor to NASA, where one of his duties included briefing the Apollo astronauts before their flights to the Moon. Sagan contributed to many of the robotic spacecraft missions that explored the Solar System, arranging experiments on many of the expeditions. Sagan assembled the first physical message that was sent into space: a gold-plated plaque, attached to the space probe "Pioneer 10", launched in 1972. "Pioneer 11", also carrying another copy of the plaque, was launched the following year. He continued to refine his designs; the most elaborate message he helped to develop and assemble was the Voyager Golden Record, which was sent out with the Voyager space probes in 1977. Sagan often challenged the decisions to fund the Space Shuttle and the International Space Station at the expense of further robotic missions.

Former student David Morrison described Sagan as "an 'idea person' and a master of intuitive physical arguments and 'back of the envelope' calculations", and Gerard Kuiper said that "Some persons work best in specializing on a major program in the laboratory; others are best in liaison between sciences. Dr. Sagan belongs in the latter group."

Sagan's contributions were central to the discovery of the high surface temperatures of the planet Venus. In the early 1960s no one knew for certain the basic conditions of Venus' surface, and Sagan listed the possibilities in a report later depicted for popularization in a Time Life book "Planets". His own view was that Venus was dry and very hot as opposed to the balmy paradise others had imagined. He had investigated radio waves from Venus and concluded that there was a surface temperature of . As a visiting scientist to NASA's Jet Propulsion Laboratory, he contributed to the first Mariner missions to Venus, working on the design and management of the project. Mariner 2 confirmed his conclusions on the surface conditions of Venus in 1962.

Sagan was among the first to hypothesize that Saturn's moon Titan might possess oceans of liquid compounds on its surface and that Jupiter's moon Europa might possess subsurface oceans of water. This would make Europa potentially habitable. Europa's subsurface ocean of water was later indirectly confirmed by the spacecraft "Galileo". The mystery of Titan's reddish haze was also solved with Sagan's help. The reddish haze was revealed to be due to complex organic molecules constantly raining down onto Titan's surface.

Sagan further contributed insights regarding the atmospheres of Venus and Jupiter, as well as seasonal changes on Mars. He also perceived global warming as a growing, man-made danger and likened it to the natural development of Venus into a hot, life-hostile planet through a kind of runaway greenhouse effect. Sagan and his Cornell colleague Edwin Ernest Salpeter speculated about life in Jupiter's clouds, given the planet's dense atmospheric composition rich in organic molecules. He studied the observed color variations on Mars' surface and concluded that they were not seasonal or vegetational changes as most believed, but shifts in surface dust caused by windstorms.

Sagan is also known for his research on the possibilities of extraterrestrial life, including experimental demonstration of the production of amino acids from basic chemicals by radiation.

He is also the 1994 recipient of the Public Welfare Medal, the highest award of the National Academy of Sciences for "distinguished contributions in the application of science to the public welfare". He was denied membership in the Academy, reportedly because his media activities made him unpopular with many other scientists.

, Sagan is the most cited SETI scientist and one of the most cited planetary scientists.

In 1980 Sagan co-wrote and narrated the award-winning 13-part PBS television series "", which became the most widely watched series in the history of American public television. The show has been seen by at least 500 million people across 60 different countries. The book, "Cosmos", written by Sagan, was published to accompany the series.

Because of his earlier popularity as a science writer from his best-selling books, including "The Dragons of Eden", which won him a Pulitzer Prize in 1977, he was asked to write and narrate the show. It was targeted to a general audience of viewers, who Sagan felt had lost interest in science, partly due to a stifled educational system.

Each of the 13 episodes was created to focus on a particular subject or person, thereby demonstrating the synergy of the universe. They covered a wide range of scientific subjects including the origin of life and a perspective of humans' place on Earth.

The show won an Emmy, along with a Peabody Award, and transformed Sagan from an obscure astronomer into a pop-culture icon. "Time" magazine ran a cover story about Sagan soon after the show broadcast, referring to him as "creator, chief writer and host-narrator of the show". In 2000, "Cosmos" was released on a remastered set of DVDs.

Sagan was invited to frequent appearances on "The Tonight Show Starring Johnny Carson".
After "Cosmos" aired, he became associated with the catchphrase "billions and billions", although he never actually used the phrase in the "Cosmos" series. He rather used the term "billions "upon" billions". Carson, however, would sometimes use the phrase during his parodies of Sagan.

As a humorous tribute to Sagan and his association with the catchphrase "billions and billions", a "sagan" has been defined as a unit of measurement equivalent to a very large number – technically at least four billion (two billion plus two billion) – of anything.

Sagan's ability to convey his ideas allowed many people to understand the cosmos better—simultaneously emphasizing the value and worthiness of the human race, and the relative insignificance of the Earth in comparison to the Universe. He delivered the 1977 series of Royal Institution Christmas Lectures in London.

Sagan was a proponent of the search for extraterrestrial life. He urged the scientific community to listen with radio telescopes for signals from potential intelligent extraterrestrial life-forms. Sagan was so persuasive that by 1982 he was able to get a petition advocating SETI published in the journal "Science", signed by 70 scientists, including seven Nobel Prize winners. This signaled a tremendous increase in the respectability of a then-controversial field. Sagan also helped Frank Drake write the Arecibo message, a radio message beamed into space from the Arecibo radio telescope on November 16, 1974, aimed at informing potential extraterrestrials about Earth.

Sagan was chief technology officer of the professional planetary research journal "Icarus" for 12 years. He co-founded The Planetary Society and was a member of the SETI Institute Board of Trustees. Sagan served as Chairman of the Division for Planetary Science of the American Astronomical Society, as President of the Planetology Section of the American Geophysical Union, and as Chairman of the Astronomy Section of the American Association for the Advancement of Science (AAAS).
At the height of the Cold War, Sagan became involved in nuclear disarmament efforts by promoting hypotheses on the effects of nuclear war, when Paul Crutzen's "Twilight at Noon" concept suggested that a substantial nuclear exchange could trigger a nuclear twilight and upset the delicate balance of life on Earth by cooling the surface. In 1983 he was one of five authors—the "S"—in the follow-up "TTAPS" model (as the research article came to be known), which contained the first use of the term "nuclear winter", which his colleague Richard P. Turco had coined. In 1984 he co-authored the book "" and in 1990 the book "A Path Where No Man Thought: Nuclear Winter and the End of the Arms Race", which explains the nuclear-winter hypothesis and advocates nuclear disarmament. Sagan received a great deal of skepticism and disdain for the use of media to disseminate a very uncertain hypothesis. A personal correspondence with nuclear physicist Edward Teller around 1983 began amicably, with Teller expressing support for continued research to ascertain the credibility of the winter hypothesis. However, Sagan and Teller's correspondence would ultimately result in Teller writing: "A propagandist is one who uses incomplete information to produce maximum persuasion. I can compliment you on being, indeed, an excellent propagandist, remembering that a propagandist is the better the less he appears to be one". Biographers of Sagan would also comment that from a scientific viewpoint, nuclear winter was a low point for Sagan, although, politically speaking, it popularized his image amongst the public.

The adult Sagan remained a fan of science fiction, although disliking stories that were not realistic (such as ignoring the inverse-square law) or, he said, did not include "thoughtful pursuit of alternative futures". He wrote books to popularize science, such as "Cosmos", which reflected and expanded upon some of the themes of "A Personal Voyage" and became the best-selling science book ever published in English; "The Dragons of Eden: Speculations on the Evolution of Human Intelligence", which won a Pulitzer Prize; and "Broca's Brain: Reflections on the Romance of Science". Sagan also wrote the best-selling science fiction novel "Contact" in 1985, based on a film treatment he wrote with his wife, Ann Druyan, in 1979, but he did not live to see the book's 1997 motion-picture adaptation, which starred Jodie Foster and won the 1998 Hugo Award for Best Dramatic Presentation.

Sagan wrote a sequel to "Cosmos", "Pale Blue Dot: A Vision of the Human Future in Space", which was selected as a notable book of 1995 by "The New York Times". He appeared on PBS's "Charlie Rose" program in January 1995. Sagan also wrote the introduction for Stephen Hawking's bestseller "A Brief History of Time". Sagan was also known for his popularization of science, his efforts to increase scientific understanding among the general public, and his positions in favor of scientific skepticism and against pseudoscience, such as his debunking of the Betty and Barney Hill abduction. To mark the tenth anniversary of Sagan's death, David Morrison, a former student of Sagan, recalled "Sagan's immense contributions to planetary research, the public understanding of science, and the skeptical movement" in "Skeptical Inquirer".

Following Saddam Hussein's threats to light Kuwait's oil wells on fire in response to any physical challenge to Iraqi control of the oil assets, Sagan together with his "TTAPS" colleagues and Paul Crutzen, warned in January 1991 in the "Baltimore Sun" and "Wilmington Morning Star" newspapers that if the fires were left to burn over a period of several months, enough smoke from the 600 or so 1991 Kuwaiti oil fires "might get so high as to disrupt agriculture in much of South Asia ..." and that this possibility should "affect the war plans"; these claims were also the subject of a televised debate between Sagan and physicist Fred Singer on January 22, aired on the ABC News program "Nightline". In the televised debate, Sagan argued that the effects of the smoke would be similar to the effects of a nuclear winter, with Singer arguing to the contrary. After the debate, the fires burnt for many months before extinguishing efforts were complete. The results of the smoke did not produce continental-sized cooling. Sagan later conceded in "The Demon-Haunted World" that the prediction did not turn out to be correct: "it "was" pitch black at noon and temperatures dropped 4–6 °C over the Persian Gulf, but not much smoke reached stratospheric altitudes and Asia was spared".

In his later years Sagan advocated the creation of an organized search for asteroids/near-Earth objects (NEOs) that might impact the Earth but to forestall or postpone developing the technological methods that would be needed to defend against them. He argued that all of the numerous methods proposed to alter the orbit of an asteroid, including the employment of nuclear detonations, created a deflection dilemma: if the ability to deflect an asteroid away from the Earth exists, then one would also have the ability to divert a non-threatening object towards Earth, creating an immensely destructive weapon. In a 1994 paper he co-authored, he ridiculed a 3-day long "Near-Earth Object Interception Workshop" held by Los Alamos National Laboratory (LANL) in 1993 that did not, "even in passing" state that such interception and deflection technologies could have these "ancillary dangers".

Sagan remained hopeful that the natural NEO impact threat and the intrinsically double-edged essence of the methods to prevent these threats would serve as a "new and potent motivation to maturing international relations". Later acknowledging that, with sufficient international oversight, in the future a "work our way up" approach to implementing nuclear explosive deflection methods could be fielded, and when sufficient knowledge was gained, to use them to aid in mining asteroids. His interest in the use of nuclear detonations in space grew out of his work in 1958 for the Armour Research Foundation's Project A119, concerning the possibility of detonating a nuclear device on the lunar surface.

Sagan was a critic of Plato, having said of the ancient Greek philosopher: "Science and mathematics were to be removed from the hands of the merchants and the artisans. This tendency found its most effective advocate in a follower of Pythagoras named Plato" and

He (Plato) believed that ideas were far more real than the natural world. He advised the astronomers not to waste their time observing the stars and planets. It was better, he believed, just to think about them. Plato expressed hostility to observation and experiment. He taught contempt for the real world and disdain for the practical application of scientific knowledge. Plato's followers succeeded in extinguishing the light of science and experiment that had been kindled by Democritus and the other Ionians.
Sagan popularized a set of tools for skeptical thinking first coined by friend Arthur Felberbaum called the "baloney detection kit".

Speaking about his activities in popularizing science, Sagan said that there were at least two reasons for scientists to share the purposes of science and its contemporary state. Simple self-interest was one: much of the funding for science came from the public, and the public therefore had the right to know how the money was being spent. If scientists increased public admiration for science, there was a good chance of having more public supporters. The other reason was the excitement of communicating one's own excitement about science to others.

Following the success of "Cosmos", Sagan set up his own publishing firm, Cosmos Store, in order to publish science books for the general public. It was not successful.

While Sagan was widely adored by the general public, his reputation in the scientific community was more polarized. Critics sometimes characterized his work as fanciful, non-rigorous, and self-aggrandizing, and others complained in his later years that he neglected his role as a faculty member to foster his celebrity status.

One of Sagan's harshest critics, Harold Urey, felt that Sagan was getting too much publicity for a scientist and was treating some scientific theories too casually. Urey and Sagan were said to have different philosophies of science, according to Davidson. While Urey was an "old-time empiricist" who avoided theorizing about the unknown, Sagan was by contrast willing to speculate openly about such matters. Fred Whipple wanted Harvard to keep Sagan there, but learned that because Urey was a Nobel laureate, his opinion was an important factor in Harvard denying Sagan tenure.

Sagan's Harvard friend Lester Grinspoon also stated: "I know Harvard well enough to know there are people there who certainly do not like people who are outspoken." Grinspoon added:
Some, like Urey, later came to realize that Sagan's popular brand of scientific advocacy was beneficial to the science as a whole. Urey especially liked Sagan's 1977 book "The Dragons of Eden" and wrote Sagan with his opinion: "I like it very much and am amazed that someone like you has such an intimate knowledge of the various features of the problem... I congratulate you... You are a man of many talents."

Sagan was accused of borrowing some ideas of others for his own benefit and countered these claims by explaining that the misappropriation was an unfortunate side effect of his role as a science communicator and explainer, and that he attempted to give proper credit whenever possible.

Sagan believed that the Drake equation, on substitution of reasonable estimates, suggested that a large number of extraterrestrial civilizations would form, but that the lack of evidence of such civilizations highlighted by the Fermi paradox suggests technological civilizations tend to self-destruct. This stimulated his interest in identifying and publicizing ways that humanity could destroy itself, with the hope of avoiding such a cataclysm and eventually becoming a spacefaring species. Sagan's deep concern regarding the potential destruction of human civilization in a nuclear holocaust was conveyed in a memorable cinematic sequence in the final episode of "Cosmos", called "Who Speaks for Earth?" Sagan had already resigned from the Air Force Scientific Advisory Board's UFO investigating Condon Committee and voluntarily surrendered his top-secret clearance in protest over the Vietnam War. Following his marriage to his third wife (novelist Ann Druyan) in June 1981, Sagan became more politically active—particularly in opposing escalation of the nuclear arms race under President Ronald Reagan.

In March 1983, Reagan announced the Strategic Defense Initiative—a multibillion-dollar project to develop a comprehensive defense against attack by nuclear missiles, which was quickly dubbed the "Star Wars" program. Sagan spoke out against the project, arguing that it was technically impossible to develop a system with the level of perfection required, and far more expensive to build such a system than it would be for an enemy to defeat it through decoys and other means—and that its construction would seriously destabilize the "nuclear balance" between the United States and the Soviet Union, making further progress toward nuclear disarmament impossible.

When Soviet leader Mikhail Gorbachev declared a unilateral moratorium on the testing of nuclear weapons, which would begin on August 6, 1985—the 40th anniversary of the atomic bombing of Hiroshima—the Reagan administration dismissed the dramatic move as nothing more than propaganda and refused to follow suit. In response, US anti-nuclear and peace activists staged a series of protest actions at the Nevada Test Site, beginning on Easter Sunday in 1986 and continuing through 1987. Hundreds of people in the "Nevada Desert Experience" group were arrested, including Sagan, who was arrested on two separate occasions as he climbed over a chain-link fence at the test site during the underground Operation Charioteer and United States's Musketeer nuclear test series of detonations.

Sagan was also a vocal advocate of the controversial notion of testosterone poisoning, arguing in 1992 that human males could become gripped by an "unusually severe [case of] testosterone poisoning" and this could compel them to become genocidal. In his review of Moondance magazine writer Daniela Gioseffi's 1990 book "Women on War", he argues that females are the only half of humanity "untainted by testosterone poisoning". One chapter of his 1993 book "Shadows of Forgotten Ancestors" is dedicated to testosterone and its alleged poisonous effects.

Sagan was married three times. In 1957, he married biologist Lynn Margulis. The couple had two children, Jeremy and Dorion Sagan. After Carl Sagan and Margulis divorced, he married artist Linda Salzman in 1968 and they also had a child together, Nick Sagan. During these marriages, Carl Sagan focused heavily on his career, a factor which may have contributed to Sagan's first divorce. In 1981, Sagan married author Ann Druyan and they later had two children, Alexandra (known as Sasha) and Samuel Sagan. Carl Sagan and Druyan remained married until his death in 1996. He lived in an Egyptian revival house in Ithaca perched on the edge of a cliff that had formerly been the headquarters of a Cornell secret society. Daughter Sasha published a book in 2019 on her father's primary legacy: skepticism does not mean pessimism. In 2020 Sasha Sagan released "For Small Creatures Such As We: Rituals for Finding Meaning in our Unlikely World" which depicts life with her parents and her father's death when she was fourteen.

Isaac Asimov described Sagan as one of only two people he ever met whose intellect surpassed his own. The other, he claimed, was the computer scientist and artificial intelligence expert Marvin Minsky.

Sagan wrote frequently about religion and the relationship between religion and science, expressing his skepticism about the conventional conceptualization of God as a sapient being. For example: Some people think God is an outsized, light-skinned male with a long white beard, sitting on a throne somewhere up there in the sky, busily tallying the fall of every sparrow. Others—for example Baruch Spinoza and Albert Einstein—considered God to be essentially the sum total of the physical laws which describe the universe. I do not know of any compelling evidence for anthropomorphic patriarchs controlling human destiny from some hidden celestial vantage point, but it would be madness to deny the existence of physical laws.

In another description of his view on the concept of God, Sagan wrote: The idea that God is an oversized white male with a flowing beard who sits in the sky and tallies the fall of every sparrow is ludicrous. But if by God one means the set of physical laws that govern the universe, then clearly there is such a God. This God is emotionally unsatisfying ... it does not make much sense to pray to the law of gravity.

On atheism, Sagan commented in 1981: An atheist is someone who is certain that God does not exist, someone who has compelling evidence against the existence of God. I know of no such compelling evidence. Because God can be relegated to remote times and places and to ultimate causes, we would have to know a great deal more about the universe than we do now to be sure that no such God exists. To be certain of the existence of God and to be certain of the nonexistence of God seem to me to be the confident extremes in a subject so riddled with doubt and uncertainty as to inspire very little confidence indeed.

Sagan also commented on Christianity and the Jefferson Bible, stating "My long-time view about Christianity is that it represents an amalgam of two seemingly immiscible parts, the religion of Jesus and the religion of Paul. Thomas Jefferson attempted to excise the Pauline parts of the New Testament. There wasn't much left when he was done, but it was an inspiring document."

Regarding spirituality and its relationship with science, Sagan stated: 'Spirit' comes from the Latin word 'to breathe'. What we breathe is air, which is certainly matter, however thin. Despite usage to the contrary, there is no necessary implication in the word 'spiritual' that we are talking of anything other than matter (including the matter of which the brain is made), or anything
outside the realm of science. On occasion, I will feel free to use the word. Science is not only compatible with spirituality; it is a profound source of spirituality. When we recognize our place in an immensity of light-years and in the passage of ages, when we grasp the intricacy, beauty, and subtlety of life, then that soaring feeling, that sense of elation and humility combined, is surely spiritual.

An environmental appeal, "Preserving and Cherishing the Earth", signed by Sagan with other noted scientists in January 1990, stated that "The historical record makes clear that religious teaching, example, and leadership are powerfully able to influence personal conduct and commitment... Thus, there is a vital role for religion and science."

In reply to a question in 1996 about his religious beliefs, Sagan answered, "I'm agnostic." Sagan maintained that the idea of a creator God of the Universe was difficult to prove or disprove and that the only conceivable scientific discovery that could challenge it would be an infinitely old universe. Sagan's views on religion have been interpreted as a form of pantheism comparable to Einstein's belief in Spinoza's God. His son, Dorion Sagan said, "My father believed in the God of Spinoza and Einstein, God not behind nature but as nature, equivalent to it." His last wife, Ann Druyan, stated: When my husband died, because he was so famous and known for not being a believer, many people would come up to me—it still sometimes happens—and ask me if Carl changed at the end and converted to a belief in an afterlife. They also frequently ask me if I think I will see him again. Carl faced his death with unflagging courage and never sought refuge in illusions. The tragedy was that we knew we would never see each other again. I don't ever expect to be reunited with Carl.

In 2006, Ann Druyan edited Sagan's 1985 Glasgow "Gifford Lectures in Natural Theology" into a book, "", in which he elaborates on his views of divinity in the natural world.

Sagan is also widely regarded as a freethinker or skeptic; one of his most famous quotations, in "Cosmos", was, "Extraordinary claims require extraordinary evidence" (called the "Sagan standard" by some). This was based on a nearly identical statement by fellow founder of the Committee for the Scientific Investigation of Claims of the Paranormal, Marcello Truzzi, "An extraordinary claim requires extraordinary proof." This idea had been earlier aphorized in Théodore Flournoy's work "From India to the Planet Mars" (1899) from a longer quote by Pierre-Simon Laplace (1749–1827), a French mathematician and astronomer, as the Principle of Laplace: "The weight of the evidence should be proportioned to the strangeness of the facts."

Late in his life, Sagan's books elaborated on his naturalistic view of the world. In "The Demon-Haunted World", he presented tools for testing arguments and detecting fallacious or fraudulent ones, essentially advocating wide use of critical thinking and the scientific method. The compilation "Billions and Billions: Thoughts on Life and Death at the Brink of the Millennium", published in 1997 after Sagan's death, contains essays written by Sagan, such as his views on abortion, as well as an account by his widow, Ann Druyan, of his death in relation to his having been an agnostic and freethinker.

Sagan warned against humans' tendency towards anthropocentrism. He was the faculty adviser for the Cornell Students for the Ethical Treatment of Animals. In the "Cosmos" chapter "Blues For a Red Planet", Sagan wrote, "If there is life on Mars, I believe we should do nothing with Mars. Mars then belongs to the Martians, even if the Martians are only microbes."

Sagan was a user and advocate of marijuana. Under the pseudonym "Mr. X", he contributed an essay about smoking cannabis to the 1971 book "Marihuana Reconsidered". The essay explained that marijuana use had helped to inspire some of Sagan's works and enhance sensual and intellectual experiences. After Sagan's death, his friend Lester Grinspoon disclosed this information to Sagan's biographer, Keay Davidson. The publishing of the biography, "Carl Sagan: A Life", in 1999 brought media attention to this aspect of Sagan's life. Not long after his death, his widow Ann Druyan went on to preside over the board of directors of the National Organization for the Reform of Marijuana Laws (NORML), a non-profit organization dedicated to reforming cannabis laws.

In 1994, engineers at Apple Computer code-named the Power Macintosh 7100 "Carl Sagan" in the hope that Apple would make "billions and billions" with the sale of the PowerMac 7100. The name was only used internally, but Sagan was concerned that it would become a product endorsement and sent Apple a cease-and-desist letter. Apple complied, but engineers retaliated by changing the internal codename to "BHA" for "Butt-Head Astronomer". Sagan then sued Apple for libel in federal court. The court granted Apple's motion to dismiss Sagan's claims and opined in dicta that a reader aware of the context would understand Apple was "clearly attempting to retaliate in a humorous and satirical way", and that "It strains reason to conclude that Defendant was attempting to criticize Plaintiff's reputation or competency as an astronomer. One does not seriously attack the expertise of a scientist using the undefined phrase 'butt-head'." Sagan then sued for Apple's original use of his name and likeness, but again lost. Sagan appealed the ruling. In November 1995, an out-of-court settlement was reached and Apple's office of trademarks and patents released a conciliatory statement that "Apple has always had great respect for Dr. Sagan. It was never Apple's intention to cause Dr. Sagan or his family any embarrassment or concern." Apple's third and final code name for the project was "LAW", short for "Lawyers are Wimps".

Sagan briefly served as an adviser on Stanley Kubrick's film "". Sagan proposed that the film suggest, rather than depict, extraterrestrial superintelligence.

In 1947, the year that inaugurated the "flying saucer" craze, the young Sagan suspected the "discs" might be alien spaceships.

Sagan's interest in UFO reports prompted him on August 3, 1952, to write a letter to U.S. Secretary of State Dean Acheson to ask how the United States would respond if flying saucers turned out to be extraterrestrial. He later had several conversations on the subject in 1964 with Jacques Vallée. Though quite skeptical of any extraordinary answer to the UFO question, Sagan thought scientists should study the phenomenon, at least because there was widespread public interest in UFO reports.

Stuart Appelle notes that Sagan "wrote frequently on what he perceived as the logical and empirical fallacies regarding UFOs and the abduction experience. Sagan rejected an extraterrestrial explanation for the phenomenon but felt there were both empirical and pedagogical benefits for examining UFO reports and that the subject was, therefore, a legitimate topic of study."

In 1966 Sagan was a member of the Ad Hoc Committee to Review Project Blue Book, the U.S. Air Force's UFO investigation project. The committee concluded Blue Book had been lacking as a scientific study, and recommended a university-based project to give the UFO phenomenon closer scientific scrutiny. The result was the Condon Committee (1966–68), led by physicist Edward Condon, and in their final report they formally concluded that UFOs, regardless of what any of them actually were, did not behave in a manner consistent with a threat to national security.

Sociologist Ron Westrum writes that "The high point of Sagan's treatment of the UFO question was the AAAS' symposium in 1969. A wide range of educated opinions on the subject were offered by participants, including not only proponents such as James McDonald and J. Allen Hynek but also skeptics like astronomers William Hartmann and Donald Menzel. The roster of speakers was balanced, and it is to Sagan's credit that this event was presented in spite of pressure from Edward Condon." With physicist Thornton Page, Sagan edited the lectures and discussions given at the symposium; these were published in 1972 as "UFO's: A Scientific Debate". Some of Sagan's many books examine UFOs (as did one episode of "Cosmos") and he claimed a religious undercurrent to the phenomenon.

Sagan again revealed his views on interstellar travel in his 1980 "Cosmos" series. In one of his last written works, Sagan argued that the chances of extraterrestrial spacecraft visiting Earth are vanishingly small. However, Sagan did think it plausible that Cold War concerns contributed to governments misleading their citizens about UFOs, and wrote that "some UFO reports and analyses, and perhaps voluminous files, have been made inaccessible to the public which pays the bills ... It's time for the files to be declassified and made generally available." He cautioned against jumping to conclusions about suppressed UFO data and stressed that there was no strong evidence that aliens were visiting the Earth either in the past or present.

Sagan's contribution to the 1969 symposium was an attack on the belief that UFOs are piloted by extraterrestrial beings. Applying several logical assumptions (see Drake equation), Sagan calculated the possible number of advanced civilizations capable of interstellar travel to be about one million. He projected that any civilization wishing to check on all the others on a regular basis of, say, once a year would have to launch 10,000 spacecraft annually. Not only does that seem like an unreasonable number of launchings, but it would take all the material in one percent of the universe's stars to produce all the spaceships needed for all the civilizations to seek each other out.

To argue that the Earth was being chosen for regular visitations, Sagan said, one would have to assume that the planet is somehow unique, and that assumption "goes exactly against the idea that there are lots of civilizations around. Because if there are then our sort of civilization must be pretty common. And if we're not pretty common then there aren't going to be many civilizations advanced enough to send visitors".

This argument, which some called Sagan's paradox, helped to establish a new school of thought, namely the belief that extraterrestrial life exists, but it has nothing to do with UFOs. The new belief had a salutary effect on UFO studies. It helped separate researchers who wanted to distinguish UFOs from those who wanted to identify their pilots and it gave scientists opportunities to search the universe for intelligent life unencumbered by the stigma associated with UFOs.

After suffering from myelodysplasia for two years and receiving three bone marrow transplants from his sister, Sagan died from pneumonia at the age of 62, at the Fred Hutchinson Cancer Research Center in Seattle, Washington, on December 20, 1996.
His burial took place at Lake View Cemetery in Ithaca, New York.


The 1997 film "Contact", based on Sagan's only fiction novel of the same name and finished after his death, ends with the dedication "For Carl". His photo can also be seen in the film.

In 1997 the Sagan Planet Walk was opened in Ithaca, New York. It is a walking-scale model of the Solar System, extending 1.2 km from the center of The Commons in downtown Ithaca to the Sciencenter, a hands-on museum. The exhibition was created in memory of Carl Sagan, who was an Ithaca resident and Cornell Professor. Professor Sagan had been a founding member of the museum's advisory board.

The landing site of the unmanned "Mars Pathfinder" spacecraft was renamed the Carl Sagan Memorial Station on July 5, 1997. Asteroid 2709 Sagan is named in his honor, as is the Carl Sagan Institute for the search of habitable planets.

Sagan's son, Nick Sagan, wrote several episodes in the "Star Trek" franchise. In an episode of "" entitled "Terra Prime", a quick shot is shown of the relic rover "Sojourner", part of the "Mars Pathfinder" mission, placed by a historical marker at Carl Sagan Memorial Station on the Martian surface. The marker displays a quote from Sagan: "Whatever the reason you're on Mars, I'm glad you're there, and I wish I was with you." Sagan's student Steve Squyres led the team that landed the rovers "Spirit" and "Opportunity" successfully on Mars in 2004.

On November 9, 2001, on what would have been Sagan's 67th birthday, the Ames Research Center dedicated the site for the Carl Sagan Center for the Study of Life in the Cosmos. "Carl was an incredible visionary, and now his legacy can be preserved and advanced by a 21st century research and education laboratory committed to enhancing our understanding of life in the universe and furthering the cause of space exploration for all time", said NASA Administrator Daniel Goldin. Ann Druyan was at the Center as it opened its doors on October 22, 2006.

Sagan has at least three awards named in his honor:

August 2007 the Independent Investigations Group (IIG) awarded Sagan posthumously a Lifetime Achievement Award. This honor has also been awarded to Harry Houdini and James Randi.

In September 2008, a musical compositor Benn Jordan released his album "Pale Blue Dot" as a tribute to Carl Sagan's life.

Beginning in 2009, a musical project known as Symphony of Science sampled several excerpts of Sagan from his series "Cosmos" and remixed them to electronic music. To date, the videos have received over 21 million views worldwide on YouTube.

The 2014 Swedish science fiction short film "Wanderers" uses excerpts of Sagan's narration of his book "Pale Blue Dot", played over digitally-created visuals of humanity's possible future expansion into outer space.

In February 2015, the Finnish-based symphonic metal band Nightwish released the song "Sagan" as a non-album bonus track for their single "Élan". The song, written by the band's songwriter/composer/keyboardist Tuomas Holopainen, is an homage to the life and work of the late Carl Sagan.

In August 2015, it was announced that a biopic of Sagan's life was being planned by Warner Bros.

On October 21, 2019, the Carl Sagan and Ann Druyan Theater was opened at the Center for Inquiry West in Los Angeles.

Footnotes
Citations
 


</doc>
<doc id="6827" url="https://en.wikipedia.org/wiki?curid=6827" title="Cuban Missile Crisis">
Cuban Missile Crisis

The Cuban Missile Crisis, also known as the October Crisis of 1962 (), the Caribbean Crisis (), or the Missile Scare, was a 13-day (October 16–28, 1962) confrontation between the United States and the Soviet Union initiated by Soviet ballistic missile deployment in Cuba. The confrontation is often considered the closest the Cold War came to escalating into a full-scale nuclear war.

In response to the failed Bay of Pigs Invasion of 1961 and the presence of American Jupiter ballistic missiles in Italy and Turkey, Soviet leader Nikita Khrushchev agreed to Cuba's request to place nuclear missiles on the island to deter a future invasion. An agreement was reached during a secret meeting between Khrushchev and Fidel Castro in July 1962, and construction of a number of missile launch facilities started later that summer.

Meanwhile, the 1962 United States elections were under way, and the White House had denied charges for months that it was ignoring dangerous Soviet missiles from Florida. The missile preparations were confirmed when an Air Force U-2 spy plane produced clear photographic evidence of medium-range (SS-4) and intermediate-range (R-14) ballistic missile facilities. 

When this was reported to President John F. Kennedy he then convened a meeting of the nine members of the National Security Council and five other key advisers in a group that became known as the Executive Committee of the National Security Council (EXCOMM). After consultation with them, Kennedy ordered a naval blockade on October 22 to prevent further missiles from reaching Cuba. The US announced it would not permit offensive weapons to be delivered to Cuba and demanded that the weapons already in Cuba be dismantled and returned to the Soviet Union.

After several days of tense negotiations, an agreement was reached between Kennedy and Khrushchev. Publicly, the Soviets would dismantle their offensive weapons in Cuba and return them to the Soviet Union, subject to United Nations verification, in exchange for a US public declaration and agreement to avoid invading Cuba again. Secretly, the United States agreed that it would dismantle all US-built Jupiter MRBMs, which had been deployed in Turkey against the Soviet Union; there has been debate on whether or not Italy was included in the agreement as well.

When all offensive missiles and Ilyushin Il-28 light bombers had been withdrawn from Cuba, the blockade was formally ended on November 21, 1962. The negotiations between the United States and the Soviet Union pointed out the necessity of a quick, clear, and direct communication line between the two Superpowers. As a result, the Moscow–Washington hotline was established. A series of agreements later reduced US–Soviet tensions for several years until both parties began to build their nuclear arsenals even further.

With the end of World War II and the start of the Cold War, the United States had grown concerned about the expansion of communism. A Latin American country openly allying with the Soviet Union was regarded by the US as unacceptable. It would, for example, defy the Monroe Doctrine, a US policy limiting US involvement in European colonies and European affairs but holding that the Western Hemisphere was in the US sphere of influence.

The Kennedy administration had been publicly embarrassed by the failed Bay of Pigs Invasion in April 1961, which had been launched under President John F. Kennedy by CIA-trained forces of Cuban exiles. Afterward, former President Dwight Eisenhower told Kennedy that "the failure of the Bay of Pigs will embolden the Soviets to do something that they would otherwise not do." The half-hearted invasion left Soviet premier Nikita Khrushchev and his advisers with the impression that Kennedy was indecisive and, as one Soviet adviser wrote, "too young, intellectual, not prepared well for decision making in crisis situations... too intelligent and too weak". US covert operations against Cuba continued in 1961 with the unsuccessful Operation Mongoose.

In addition, Khrushchev's impression of Kennedy's weaknesses was confirmed by the President's response during the Berlin Crisis of 1961, particularly to the building of the Berlin Wall. Speaking to Soviet officials in the aftermath of the crisis, Khrushchev asserted, "I know for certain that Kennedy doesn't have a strong background, nor, generally speaking, does he have the courage to stand up to a serious challenge." He also told his son Sergei that on Cuba, Kennedy "would make a fuss, make more of a fuss, and then agree".
In January 1962, US Army General Edward Lansdale described plans to overthrow the Cuban government in a top-secret report (partially declassified 1989), addressed to Kennedy and officials involved with Operation Mongoose. CIA agents or "pathfinders" from the Special Activities Division were to be infiltrated into Cuba to carry out sabotage and organization, including radio broadcasts. In February 1962, the US launched an embargo against Cuba, and Lansdale presented a 26-page, top-secret timetable for implementation of the overthrow of the Cuban government, mandating guerrilla operations to begin in August and September. "Open revolt and overthrow of the Communist regime" would occur in the first two weeks of October.

When Kennedy ran for president in 1960, one of his key election issues was an alleged "missile gap" with the Soviets leading. Actually, the US at that time "led" the Soviets by a wide margin that would only increase. In 1961, the Soviets had only four intercontinental ballistic missiles (R-7 Semyorka). By October 1962, they may have had a few dozen, with some intelligence estimates as high as 75.

The US, on the other hand, had 170 ICBMs and was quickly building more. It also had eight - and ballistic missile submarines, with the capability to launch 16 Polaris missiles, each with a range of . Khrushchev increased the perception of a missile gap when he loudly boasted to the world that the Soviets were building missiles "like sausages" but Soviet missiles' numbers and capabilities were nowhere close to his assertions. The Soviet Union had medium-range ballistic missiles in quantity, about 700 of them, but they were very unreliable and inaccurate. The US had a considerable advantage in total number of nuclear warheads (27,000 against 3,600) and in the technology required for their accurate delivery. The US also led in missile defensive capabilities, naval and air power; but the Soviets had a 2–1 advantage in conventional ground forces, more pronounced in field guns and tanks, particularly in the European theatre.

In May 1962, Soviet Premier Nikita Khrushchev was persuaded by the idea of countering the US's growing lead in developing and deploying strategic missiles by placing Soviet intermediate-range nuclear missiles in Cuba, despite the misgivings of the Soviet Ambassador in Havana, Alexandr Ivanovich Alexeyev, who argued that Castro would not accept the deployment of the missiles. Khrushchev faced a strategic situation in which the US was perceived to have a "splendid first strike" capability that put the Soviet Union at a huge disadvantage. In 1962, the Soviets had only 20 ICBMs capable of delivering nuclear warheads to the US from inside the Soviet Union. The poor accuracy and reliability of the missiles raised serious doubts about their effectiveness. A newer, more reliable generation of ICBMs would become operational only after 1965.

Therefore, Soviet nuclear capability in 1962 placed less emphasis on ICBMs than on medium and intermediate-range ballistic missiles (MRBMs and IRBMs). The missiles could hit American allies and most of Alaska from Soviet territory but not the Contiguous United States. Graham Allison, the director of Harvard University's Belfer Center for Science and International Affairs, points out, "The Soviet Union could not right the nuclear imbalance by deploying new ICBMs on its own soil. In order to meet the threat it faced in 1962, 1963, and 1964, it had very few options. Moving existing nuclear weapons to locations from which they could reach American targets was one."

A second reason that Soviet missiles were deployed to Cuba was because Khrushchev wanted to bring West Berlin, controlled by the American, British and French within Communist East Germany, into the Soviet orbit. The East Germans and Soviets considered western control over a portion of Berlin a grave threat to East Germany. Khrushchev made West Berlin the central battlefield of the Cold War. Khrushchev believed that if the US did nothing over the missile deployments in Cuba, he could muscle the West out of Berlin using said missiles as a deterrent to western countermeasures in Berlin. If the US tried to bargain with the Soviets after it became aware of the missiles, Khrushchev could demand trading the missiles for West Berlin. Since Berlin was strategically more important than Cuba, the trade would be a win for Khrushchev, as Kennedy recognised: "The advantage is, from Khrushchev's point of view, he takes a great chance but there are quite some rewards to it."

Thirdly, from the perspective of the Soviet Union and of Cuba, it seemed that the United States wanted to increase its presence in Cuba. With actions including the attempt to expel Cuba from the Organization of American States, placing economic sanctions on the nation and conducting secret operations on containing communism and Cuba, it was assumed that America was trying to invade Cuba. As a result, to try and prevent this, the USSR would place missiles in Cuba and neutralise the threat. This would ultimately serve to secure Cuba against attack and keep the country in the Socialist Bloc.
Another major reason why Khrushchev planned to place missiles on Cuba undetected was to "level the playing field" with the evident American nuclear threat. America had the upper hand as they could launch from Turkey and destroy the USSR before they would have a chance to react. After the transmission of nuclear missiles, Khrushchev had finally established mutually assured destruction, meaning that if the U.S. decided to launch a nuclear strike against the USSR, the latter would react by launching a retaliatory nuclear strike against the U.S.

Additionally, placing nuclear missiles on Cuba was a way for the USSR to show their support for Cuba and support the Cuban people who viewed the United States as a threatening force, as the latter had become their ally after the Cuban Revolution of 1959. According to Khrushchev, the Soviet Union's motives were "aimed at allowing Cuba to live peacefully and develop as its people desire".

In early 1962, a group of Soviet military and missile construction specialists accompanied an agricultural delegation to Havana. They obtained a meeting with Cuban leader Fidel Castro. The Cuban leadership had a strong expectation that the US would invade Cuba again and enthusiastically approved the idea of installing nuclear missiles in Cuba. According to another source, Castro objected to the missiles deployment that would have made him look like a Soviet puppet, but he was persuaded that missiles in Cuba would be an irritant to the US and help the interests of the entire socialist camp. Also, the deployment would include short-range tactical weapons (with a range of 40 km, usable only against naval vessels) that would provide a "nuclear umbrella" for attacks upon the island.

By May, Khrushchev and Castro agreed to place strategic nuclear missiles secretly in Cuba. Like Castro, Khrushchev felt that a US invasion of Cuba was imminent and that to lose Cuba would do great harm to the communists, especially in Latin America. He said he wanted to confront the Americans "with more than words... the logical answer was missiles". The Soviets maintained their tight secrecy, writing their plans longhand, which were approved by Marshal of the Soviet Union Rodion Malinovsky on July 4 and Khrushchev on July 7.

From the very beginning, the Soviets' operation entailed elaborate denial and deception, known as "maskirovka". All the planning and preparation for transporting and deploying the missiles were carried out in the utmost secrecy, with only a very few told the exact nature of the mission. Even the troops detailed for the mission were given misdirection by being told that they were headed for a cold region and being outfitted with ski boots, fleece-lined parkas, and other winter equipment. The Soviet code-name was Operation Anadyr. The Anadyr River flows into the Bering Sea, and Anadyr is also the capital of Chukotsky District and a bomber base in the far eastern region. All the measures were meant to conceal the program from both internal and external audiences.

Specialists in missile construction under the guise of "machine operators", "irrigation specialists", and "agricultural specialists" arrived in July. A total of 43,000 foreign troops would ultimately be brought in. Chief Marshal of Artillery Sergei Biryuzov, Head of the Soviet Rocket Forces, led a survey team that visited Cuba. He told Khrushchev that the missiles would be concealed and camouflaged by palm trees.

The Cuban leadership was further upset when on September 20, the US Senate approved Joint Resolution 230, which expressed the US was determined "to prevent in Cuba the creation or use of an externally-supported military capability endangering the security of the United States". On the same day, the US announced a major military exercise in the Caribbean, PHIBRIGLEX-62, which Cuba denounced as a deliberate provocation and proof that the US planned to invade Cuba.

The Soviet leadership believed, based on its perception of Kennedy's lack of confidence during the Bay of Pigs Invasion, that he would avoid confrontation and accept the missiles as a "fait accompli". On September 11, the Soviet Union publicly warned that a US attack on Cuba or on Soviet ships that were carrying supplies to the island would mean war. The Soviets continued the "Maskirovka" program to conceal their actions in Cuba. They repeatedly denied that the weapons being brought into Cuba were offensive in nature. On September 7, Soviet Ambassador to the United States Anatoly Dobrynin assured United States Ambassador to the United Nations Adlai Stevenson that the Soviet Union was supplying only defensive weapons to Cuba. On September 11, the Telegraph Agency of the Soviet Union (TASS: "Telegrafnoe Agentstvo Sovetskogo Soyuza") announced that the Soviet Union had no need or intention to introduce offensive nuclear missiles into Cuba. On October 13, Dobrynin was questioned by former Undersecretary of State Chester Bowles about whether the Soviets planned to put offensive weapons in Cuba. He denied any such plans. On October 17, Soviet embassy official Georgy Bolshakov brought President Kennedy a personal message from Khrushchev reassuring him that "under no circumstances would surface-to-surface missiles be sent to Cuba."

As early as August 1962, the US suspected the Soviets of building missile facilities in Cuba. During that month, its intelligence services gathered information about sightings by ground observers of Russian-built MiG-21 fighters and Il-28 light bombers. U-2 spy planes found S-75 Dvina (NATO designation "SA-2") surface-to-air missile sites at eight different locations. CIA director John A. McCone was suspicious. Sending antiaircraft missiles into Cuba, he reasoned, "made sense only if Moscow intended to use them to shield a base for ballistic missiles aimed at the United States". On August 10, he wrote a memo to Kennedy in which he guessed that the Soviets were preparing to introduce ballistic missiles into Cuba.

With important Congressional elections scheduled for November, the crisis became enmeshed in American politics. On August 31, Senator Kenneth Keating (R-New York) warned on the Senate floor that the Soviet Union was "in all probability" constructing a missile base in Cuba. He charged the Kennedy administration with covering up a major threat to the US, thereby starting the crisis. He may have received this initial "remarkably accurate" information from his friend, former congresswoman and ambassador Clare Booth Luce, who in turn received it from Cuban exiles. A later confirming source for Keating's information possibly was the West German ambassador to Cuba, who had received information from dissidents inside Cuba that Soviet troops had arrived in Cuba in early August and were seen working "in all probability on or near a missile base" and who passed this information to Keating on a trip to Washington in early October. Air Force General Curtis LeMay presented a pre-invasion bombing plan to Kennedy in September, and spy flights and minor military harassment from US forces at Guantanamo Bay Naval Base were the subject of continual Cuban diplomatic complaints to the US government.
The first consignment of R-12 missiles arrived on the night of September 8, followed by a second on September 16. The R-12 was a medium-range ballistic missile, capable of carrying a thermonuclear warhead. It was a single-stage, road-transportable, surface-launched, storable liquid propellant fuelled missile that could deliver a megaton-class nuclear weapon. The Soviets were building nine sites—six for R-12 medium-range missiles (NATO designation "SS-4 Sandal") with an effective range of and three for R-14 intermediate-range ballistic missiles (NATO designation "SS-5 Skean") with a maximum range of .

On October 7, Cuban President Osvaldo Dorticós Torrado spoke at the UN General Assembly: "If... we are attacked, we will defend ourselves. I repeat, we have sufficient means with which to defend ourselves; we have indeed our inevitable weapons, the weapons, which we would have preferred not to acquire, and which we do not wish to employ." On October 10 in another Senate speech Sen. Keating reaffirmed his earlier warning of August 31 and stated that, "Construction has begun on at least a half dozen launching sites for intermediate range tactical missiles."

The missiles in Cuba allowed the Soviets to effectively target most of the Continental US. The planned arsenal was forty launchers. The Cuban populace readily noticed the arrival and deployment of the missiles and hundreds of reports reached Miami. US intelligence received countless reports, many of dubious quality or even laughable, most of which could be dismissed as describing defensive missiles.

Only five reports bothered the analysts. They described large trucks passing through towns at night that were carrying very long canvas-covered cylindrical objects that could not make turns through towns without backing up and manoeuvring. Defensive missiles could turn. The reports could not be satisfactorily dismissed.

The United States had been sending U-2 surveillance over Cuba since the failed Bay of Pigs Invasion. The first issue that led to a pause in reconnaissance flights took place on August 30, when a U-2 operated by the US Air Force's Strategic Air Command flew over Sakhalin Island in the Soviet Far East by mistake. The Soviets lodged a protest and the US apologised. Nine days later, a Taiwanese-operated U-2 was lost over western China to an SA-2 surface-to-air missile. US officials were worried that one of the Cuban or Soviet SAMs in Cuba might shoot down a CIA U-2, initiating another international incident. In a meeting with members of the Committee on Overhead Reconnaissance (COMOR) on September 10, Secretary of State Dean Rusk and National Security Advisor McGeorge Bundy heavily restricted further U-2 flights over Cuban airspace. The resulting lack of coverage over the island for the next five weeks became known to historians as the "Photo Gap". No significant U-2 coverage was achieved over the interior of the island. US officials attempted to use a Corona photo-reconnaissance satellite to obtain coverage over reported Soviet military deployments, but imagery acquired over western Cuba by a Corona KH-4 mission on October 1 was heavily covered by clouds and haze and failed to provide any usable intelligence. At the end of September, Navy reconnaissance aircraft photographed the Soviet ship "Kasimov", with large crates on its deck the size and shape of Il-28 jet bomber fuselages.

In September 1962, analysts from the Defense Intelligence Agency (DIA) noticed that Cuban surface-to-air missile sites were arranged in a pattern similar to those used by the Soviet Union to protect its ICBM bases, leading DIA to lobby for the resumption of U-2 flights over the island. Although in the past the flights had been conducted by the CIA, pressure from the Defense Department led to that authority being transferred to the Air Force. Following the loss of a CIA U-2 over the Soviet Union in May 1960, it was thought that if another U-2 were shot down, an Air Force aircraft arguably being used for a legitimate military purpose would be easier to explain than a CIA flight.

When the reconnaissance missions were reauthorized on October 9, poor weather kept the planes from flying. The US first obtained U-2 photographic evidence of the missiles on October 14, when a U-2 flight piloted by Major Richard Heyser took 928 pictures on a path selected by DIA analysts, capturing images of what turned out to be an SS-4 construction site at San Cristóbal, Pinar del Río Province (now in Artemisa Province), in western Cuba.

On October 15, the CIA's National Photographic Interpretation Center (NPIC) reviewed the U-2 photographs and identified objects that they interpreted as medium range ballistic missiles. This identification was made, in part, on the strength of reporting provided by Oleg Penkovsky, a double agent in the GRU working for CIA and MI6. Although he provided no direct reports of the Soviet missile deployments to Cuba, technical and doctrinal details of Soviet missile regiments that had been provided by Penkovsky in the months and years prior to the Crisis helped NPIC analysts correctly identify the missiles on U-2 imagery.

That evening, the CIA notified the Department of State and at 8:30 pm EDT, Bundy chose to wait until the next morning to tell the President. McNamara was briefed at midnight. The next morning, Bundy met with Kennedy and showed him the U-2 photographs and briefed him on the CIA's analysis of the images. At 6:30 pm EDT, Kennedy convened a meeting of the nine members of the National Security Council and five other key advisers, in a group he formally named the Executive Committee of the National Security Council (EXCOMM) after the fact on October 22 by the National Security Action Memorandum 196. Without informing the members of EXCOMM, President Kennedy tape recorded all of their proceedings, and Sheldon M. Stern, head of the Kennedy library transcribed some of them.

The US had no plan in place because its intelligence had been convinced that the Soviets would never install nuclear missiles in Cuba. EXCOMM, of which Vice President Lyndon B. Johnson was a member, quickly discussed several possible courses of action:


The Joint Chiefs of Staff unanimously agreed that a full-scale attack and invasion was the only solution. They believed that the Soviets would not attempt to stop the US from conquering Cuba. Kennedy was sceptical:

Kennedy concluded that attacking Cuba by air would signal the Soviets to presume "a clear line" to conquer Berlin. Kennedy also believed that US allies would think of the country as "trigger-happy cowboys" who lost Berlin because they could not peacefully resolve the Cuban situation.

The EXCOMM then discussed the effect on the strategic balance of power, both political and military. The Joint Chiefs of Staff believed that the missiles would seriously alter the military balance, but McNamara disagreed. An extra 40, he reasoned, would make little difference to the overall strategic balance. The US already had approximately 5,000 strategic warheads, but the Soviet Union had only 300. McNamara concluded that the Soviets having 340 would not therefore substantially alter the strategic balance. In 1990, he reiterated that "it made "no" difference... The military balance wasn't changed. I didn't believe it then, and I don't believe it now."

The EXCOMM agreed that the missiles would affect the "political" balance. Kennedy had explicitly promised the American people less than a month before the crisis that "if Cuba should possess a capacity to carry out offensive actions against the United States... the United States would act." Also, credibility among US allies and people would be damaged if the Soviet Union appeared to redress the strategic balance by placing missiles in Cuba. Kennedy explained after the crisis that "it would have politically changed the balance of power. It would have appeared to, and appearances contribute to reality."
On October 18, Kennedy met with Soviet Minister of Foreign Affairs, Andrei Gromyko, who claimed the weapons were for defensive purposes only. Not wanting to expose what he already knew and to avoid panicking the American public, Kennedy did not reveal that he was already aware of the missile buildup. By October 19, frequent U-2 spy flights showed four operational sites.

Two Operational Plans (OPLAN) were considered. OPLAN 316 envisioned a full invasion of Cuba by Army and Marine units, supported by the Navy following Air Force and naval airstrikes. Army units in the US would have had trouble fielding mechanised and logistical assets, and the US Navy could not supply enough amphibious shipping to transport even a modest armoured contingent from the Army.

OPLAN 312, primarily an Air Force and Navy carrier operation, was designed with enough flexibility to do anything from engaging individual missile sites to providing air support for OPLAN 316's ground forces.

Kennedy met with members of EXCOMM and other top advisers throughout October 21, considering two remaining options: an air strike primarily against the Cuban missile bases or a naval blockade of Cuba. A full-scale invasion was not the administration's first option. McNamara supported the naval blockade as a strong but limited military action that left the US in control. The term "blockade" was problematic. According to international law, a blockade is an act of war, but the Kennedy administration did not think that the Soviets would be provoked to attack by a mere blockade. Additionally, legal experts at the State Department and Justice Department concluded that a declaration of war could be avoided if another legal justification, based on the Rio Treaty for defence of the Western Hemisphere, was obtained from a resolution by a two-thirds vote from the members of the Organization of American States (OAS).

Admiral Anderson, Chief of Naval Operations wrote a position paper that helped Kennedy to differentiate between what they termed a "quarantine" of offensive weapons and a blockade of all materials, claiming that a classic blockade was not the original intention. Since it would take place in international waters, Kennedy obtained the approval of the OAS for military action under the hemispheric defence provisions of the Rio Treaty:

On October 19, the EXCOMM formed separate working groups to examine the air strike and blockade options, and by the afternoon most support in the EXCOMM shifted to the blockade option. Reservations about the plan continued to be voiced as late as the October 21, the paramount concern being that once the blockade was put into effect, the Soviets would rush to complete some of the missiles. Consequently, the US could find itself bombing operational missiles if the blockade failed to force Khrushchev to remove the missiles already on the island.

At 3:00 pm EDT on October 22, President Kennedy formally established the Executive Committee (EXCOMM) with National Security Action Memorandum (NSAM) 196. At 5:00 pm, he met with Congressional leaders who contentiously opposed a blockade and demanded a stronger response. In Moscow, Ambassador Foy D. Kohler briefed Khrushchev on the pending blockade and Kennedy's speech to the nation. Ambassadors around the world gave notice to non-Eastern Bloc leaders. Before the speech, US delegations met with Canadian Prime Minister John Diefenbaker, British Prime Minister Harold Macmillan, West German Chancellor Konrad Adenauer, French President Charles de Gaulle and Secretary-General of the Organization of American States, José Antonio Mora to brief them on the US intelligence and their proposed response. All were supportive of the US position, except Macmillan who advocated appeasement.

Shortly before his speech, Kennedy called former President Dwight Eisenhower. Kennedy's conversation with the former president also revealed that the two were consulting during the Cuban Missile Crisis. The two also anticipated that Khrushchev would respond to the Western world in a manner that was similar to his response during the Suez Crisis and would possibly wind up trading off Berlin.

On October 22 at 7:00 pm EDT, Kennedy delivered a nationwide televised address on all of the major networks announcing the discovery of the missiles. He noted:

Kennedy described the administration's plan:

During the speech, a directive went out to all US forces worldwide, placing them on DEFCON 3. The heavy cruiser was designated flagship for the blockade, with as "Newport News"s destroyer escort.

On October 23, at 11:24 am EDT, a cable, drafted by George Wildman Ball to the US Ambassador in Turkey and NATO, notified them that they were considering making an offer to withdraw what the US knew to be nearly-obsolete missiles from Italy and Turkey, in exchange for the Soviet withdrawal from Cuba. Turkish officials replied that they would "deeply resent" any trade involving the US missile presence in their country. Two days later, on the morning of October 25, American journalist Walter Lippmann proposed the same thing in his syndicated column. Castro reaffirmed Cuba's right to self-defense and said that all of its weapons were defensive and Cuba would not allow an inspection.

Three days after Kennedy's speech, the Chinese "People's Daily" announced that "650,000,000 Chinese men and women were standing by the Cuban people." In West Germany, newspapers supported the US response by contrasting it with the weak American actions in the region during the preceding months. They also expressed some fear that the Soviets might retaliate in Berlin. In France on October 23, the crisis made the front page of all the daily newspapers. The next day, an editorial in "Le Monde" expressed doubt about the authenticity of the CIA's photographic evidence. Two days later, after a visit by a high-ranking CIA agent, the newspaper accepted the validity of the photographs. Also in France, in the October 29 issue of "Le Figaro", Raymond Aron wrote in support of the American response. On October 24, Pope John XXIII sent a message to the Soviet embassy in Rome to be transmitted to the Kremlin in which he voiced his concern for peace. In this message he stated, "We beg all governments not to remain deaf to this cry of humanity. That they do all that is in their power to save peace."

The crisis was continuing unabated, and in the evening of October 24, the Soviet news agency TASS broadcast a telegram from Khrushchev to Kennedy in which Khrushchev warned that the United States's "outright piracy" would lead to war. That was followed at 9:24 pm by a telegram from Khrushchev to Kennedy, which was received at 10:52 pm EDT. Khrushchev stated, "if you weigh the present situation with a cool head without giving way to passion, you will understand that the Soviet Union cannot afford not to decline the despotic demands of the USA" and that the Soviet Union views the blockade as "an act of aggression" and their ships will be instructed to ignore it. After October 23, Soviet communications with the USA increasingly showed indications of having being rushed. Undoubtedly a product of pressure, it was not uncommon for Khrushchev to repeat himself and send messages lacking simple editing. With President Kennedy making his aggressive intentions of a possible air-strike followed by an invasion on Cuba known, Khrushchev rapidly sought after a diplomatic compromise. Communications between the two super-powers had entered into a unique and revolutionary period; with the newly developed threat of mutual destruction through the deployment of nuclear weapons, diplomacy now demonstrated how power and coercion could dominate negotiations.

The US requested an emergency meeting of the United Nations Security Council on October 25. US Ambassador to the United Nations Adlai Stevenson confronted Soviet Ambassador Valerian Zorin in an emergency meeting of the Security Council, challenging him to admit the existence of the missiles. Ambassador Zorin refused to answer. The next day at 10:00 pm EDT, the US raised the readiness level of SAC forces to DEFCON 2. For the only confirmed time in US history, B-52 bombers went on continuous airborne alert, and B-47 medium bombers were dispersed to various military and civilian airfields and made ready to take off, fully equipped, on 15 minutes' notice. One eighth of SAC's 1,436 bombers were on airborne alert, and some 145 intercontinental ballistic missiles stood on ready alert, some of which targeted Cuba, and Air Defense Command (ADC) redeployed 161 nuclear-armed interceptors to 16 dispersal fields within nine hours, with one third maintaining 15-minute alert status. Twenty-three nuclear-armed B-52s were sent to orbit points within striking distance of the Soviet Union so that it would believe that the US was serious. Jack J. Catton later estimated that about 80 percent of SAC's planes were ready for launch during the crisis; David A. Burchinal recalled that, by contrast:

By October 22, Tactical Air Command (TAC) had 511 fighters plus supporting tankers and reconnaissance aircraft deployed to face Cuba on one-hour alert status. TAC and the Military Air Transport Service had problems. The concentration of aircraft in Florida strained command and support echelons, which faced critical undermanning in security, armaments, and communications; the absence of initial authorization for war-reserve stocks of conventional munitions forced TAC to scrounge; and the lack of airlift assets to support a major airborne drop necessitated the call-up of 24 Reserve squadrons.

On October 25 at 1:45 am EDT, Kennedy responded to Khrushchev's telegram by stating that the US was forced into action after receiving repeated assurances that no offensive missiles were being placed in Cuba, and when the assurances proved to be false, the deployment "required the responses I have announced... I hope that your government will take necessary action to permit a restoration of the earlier situation."
At 7:15 am EDT on October 25, and attempted to intercept "Bucharest" but failed to do so. Fairly certain that the tanker did not contain any military material, the US allowed it through the blockade. Later that day, at 5:43 pm, the commander of the blockade effort ordered the destroyer to intercept and board the Lebanese freighter "Marucla". That took place the next day, and "Marucla" was cleared through the blockade after its cargo was checked.

At 5:00 pm EDT on October 25, William Clements announced that the missiles in Cuba were still actively being worked on. That report was later verified by a CIA report that suggested there had been no slowdown at all. In response, Kennedy issued Security Action Memorandum 199, authorizing the loading of nuclear weapons onto aircraft under the command of SACEUR, which had the duty of carrying out first air strikes on the Soviet Union. During the day, the Soviets responded to the blockade by turning back 14 ships that were presumably carrying offensive weapons. The first indication of this came from a report from the British GCHQ sent to the White House Situation Room containing intercepted communications from Soviet ships reporting their positions. On October 24, "Kislovodsk," a Soviet cargo ship, reported a position north-east of where it had been 24 hours earlier indicating it had "discontinued" its voyage and turned back towards the Baltic. The next day, reports showed more ships originally bound for Cuba had altered their course.

The next morning, October 26, Kennedy informed the EXCOMM that he believed only an invasion would remove the missiles from Cuba. He was persuaded to give the matter time and continue with both military and diplomatic pressure. He agreed and ordered the low-level flights over the island to be increased from two per day to once every two hours. He also ordered a crash program to institute a new civil government in Cuba if an invasion went ahead.

At this point, the crisis was ostensibly at a stalemate. The Soviets had shown no indication that they would back down and had made several comments to the contrary. The US had no reason to believe otherwise and was in the early stages of preparing for an invasion, along with a nuclear strike on the Soviet Union if it responded militarily, which was assumed. Kennedy had no intention of keeping these plans a secret; with an array of Cuban and Soviet spies forever present, Khrushchev was quickly made aware of this looming danger.

The sword of Damocles looming over the USSR in the form of an air strike followed by invasion allowed the United States to exert pressure in future talks. It was precisely this sword that played such an influential role in accelerating Khrushchev's proposal for a compromise. Throughout the closing stages of October, Soviet telegrams were typically rushed and showed signs of immense pressure. Khrushchev's tendency to use platitudinous and ambiguous language assisted the United States in exerting linguistic dominance throughout the compromise negotiations. Leading Soviet figures consistently failed to mention that only Cuban government could agree to inspections of the territory and continually made arrangements relating to Cuba without the knowledge of Fidel Castro himself. According to Dean Rusk, Khrushchev "blinked", he began to panic from the consequences of his own plan and it became clear that his nervousness led to communicative failures that allowed the US to largely dominate negotiations in late October.

At 1:00 pm EDT on October 26, John A. Scali of ABC News had lunch with Aleksandr Fomin, the cover name of Alexander Feklisov, the KGB station chief in Washington, at Fomin's request. Following the instructions of the Politburo of the CPSU, Fomin noted, "War seems about to break out." He asked Scali to use his contacts to talk to his "high-level friends" at the State Department to see if the US would be interested in a diplomatic solution. He suggested that the language of the deal would contain an assurance from the Soviet Union to remove the weapons under UN supervision and that Castro would publicly announce that he would not accept such weapons again in exchange for a public statement by the US that it would not invade Cuba. The US responded by asking the Brazilian government to pass a message to Castro that the US would be "unlikely to invade" if the missiles were removed.

On October 26 at 6:00 pm EDT, the State Department started receiving a message that appeared to be written personally by Khrushchev. It was Saturday at 2:00 am in Moscow. The long letter took several minutes to arrive, and it took translators additional time to translate and transcribe it.

Robert F. Kennedy described the letter as "very long and emotional". Khrushchev reiterated the basic outline that had been stated to Scali earlier in the day: "I propose: we, for our part, will declare that our ships bound for Cuba are not carrying any armaments. You will declare that the United States will not invade Cuba with its troops and will not support any other forces which might intend to invade Cuba. Then the necessity of the presence of our military specialists in Cuba will disappear." At 6:45 pm EDT, news of Fomin's offer to Scali was finally heard and was interpreted as a "set up" for the arrival of Khrushchev's letter. The letter was then considered official and accurate although it was later learned that Fomin was almost certainly operating of his own accord without official backing. Additional study of the letter was ordered and continued into the night.

Castro, on the other hand, was convinced that an invasion of Cuba was soon at hand, and on October 26, he sent a telegram to Khrushchev that appeared to call for a pre-emptive nuclear strike on the US in case of attack. In a 2010 interview, Castro expressed regret about his earlier stance on first use: "After I've seen what I've seen, and knowing what I know now, it wasn't worth it at all." Castro also ordered all anti-aircraft weapons in Cuba to fire on any US aircraft: the orders had been to fire only on groups of two or more. At 6:00 am EDT on October 27, the CIA delivered a memo reporting that three of the four missile sites at San Cristobal and the two sites at Sagua la Grande appeared to be fully operational. It also noted that the Cuban military continued to organise for action but was under order not to initiate action unless attacked.

At 9:00 am EDT on October 27, Radio Moscow began broadcasting a message from Khrushchev. Contrary to the letter of the night before, the message offered a new trade: the missiles on Cuba would be removed in exchange for the removal of the Jupiter missiles from Italy and Turkey. At 10:00 am EDT, the executive committee met again to discuss the situation and came to the conclusion that the change in the message was because of internal debate between Khrushchev and other party officials in the Kremlin. Kennedy realised that he would be in an "insupportable position if this becomes Khrushchev's proposal" because the missiles in Turkey were not militarily useful and were being removed anyway and "It's gonna – to any man at the United Nations or any other rational man, it will look like a very fair trade." Bundy explained why Khrushchev's public acquiescence could not be considered: "The current threat to peace is not in Turkey, it is in Cuba."

McNamara noted that another tanker, the "Grozny", was about out and should be intercepted. He also noted that they had not made the Soviets aware of the blockade line and suggested relaying that information to them via U Thant at the United Nations.
While the meeting progressed, at 11:03 am EDT a new message began to arrive from Khrushchev. The message stated, in part:

"You are disturbed over Cuba. You say that this disturbs you because it is ninety-nine miles by sea from the coast of the United States of America. But... you have placed destructive missile weapons, which you call offensive, in Italy and Turkey, literally next to us... I therefore make this proposal: We are willing to remove from Cuba the means which you regard as offensive... Your representatives will make a declaration to the effect that the United States... will remove its analogous means from Turkey... and after that, persons entrusted by the United Nations Security Council could inspect on the spot the fulfillment of the pledges made."

The executive committee continued to meet through the day.

Throughout the crisis, Turkey had repeatedly stated that it would be upset if the Jupiter missiles were removed. Italy's Prime Minister Amintore Fanfani, who was also Foreign Minister "ad interim", offered to allow withdrawal of the missiles deployed in Apulia as a bargaining chip. He gave the message to one of his most trusted friends, Ettore Bernabei, the general manager of RAI-TV, to convey to Arthur M. Schlesinger Jr. Bernabei was in New York to attend an international conference on satellite TV broadcasting. Unknown to the Soviets, the US regarded the Jupiter missiles as obsolescent and already supplanted by the Polaris nuclear ballistic submarine missiles.
On the morning of October 27, a U-2F (the third CIA U-2A, modified for air-to-air refuelling) piloted by USAF Major Rudolf Anderson, departed its forward operating location at McCoy AFB, Florida. At approximately 12:00 pm EDT, the aircraft was struck by an SA-2 surface-to-air missile launched from Cuba. The aircraft was shot down, and Anderson was killed. The stress in negotiations between the Soviets and the US intensified; it was only later believed that the decision to fire the missile was made locally by an undetermined Soviet commander, acting on his own authority. Later that day, at about 3:41 pm EDT, several US Navy RF-8A Crusader aircraft, on low-level photo-reconnaissance missions, were fired upon.

On October 28, 1962, Khrushchev told his son Sergei that the shooting down of Anderson's U-2 was by the "Cuban military at the direction of Raul Castro".

At 4:00 pm EDT, Kennedy recalled members of EXCOMM to the White House and ordered that a message should immediately be sent to U Thant asking the Soviets to suspend work on the missiles while negotiations were carried out. During the meeting, General Maxwell Taylor delivered the news that the U-2 had been shot down. Kennedy had earlier claimed he would order an attack on such sites if fired upon, but he decided to not act unless another attack was made. Forty years later, McNamara said:

Ellsberg said that Robert Kennedy (RFK) told him in 1964 that after the U-2 was shot down and the pilot killed, he (RFK) told Soviet ambassador Dobrynin, "You have drawn first blood ... . [T]he president had decided against advice ... not to respond militarily to that attack, but he [Dobrynin] should know that if another plane was shot at, ... we would take out all the SAMs and antiaircraft ... . And that would almost surely be followed by an invasion."

Emissaries sent by both Kennedy and Khrushchev agreed to meet at the Yenching Palace Chinese restaurant in the Cleveland Park neighbourhood of Washington, DC, on Saturday evening, October 27. Kennedy suggested to take Khrushchev's offer to trade away the missiles. Unknown to most members of the EXCOMM, but with the support of his brother the president, Robert Kennedy had been meeting with the Soviet Ambassador Dobrynin in Washington to discover whether the intentions were genuine. The EXCOMM was generally against the proposal because it would undermine NATO's authority, and the Turkish government had repeatedly stated it was against any such trade.

As the meeting progressed, a new plan emerged, and Kennedy was slowly persuaded. The new plan called for him to ignore the latest message and instead to return to Khrushchev's earlier one. Kennedy was initially hesitant, feeling that Khrushchev would no longer accept the deal because a new one had been offered, but Llewellyn Thompson argued that it was still possible. White House Special Counsel and Adviser Ted Sorensen and Robert Kennedy left the meeting and returned 45 minutes later, with a draft letter to that effect. The President made several changes, had it typed, and sent it.

After the EXCOMM meeting, a smaller meeting continued in the Oval Office. The group argued that the letter should be underscored with an oral message to Dobrynin that stated that if the missiles were not withdrawn, military action would be used to remove them. Rusk added one proviso that no part of the language of the deal would mention Turkey, but there would be an understanding that the missiles would be removed "voluntarily" in the immediate aftermath. The president agreed, and the message was sent.

At Rusk's request, Fomin and Scali met again. Scali asked why the two letters from Khrushchev were so different, and Fomin claimed it was because of "poor communications". Scali replied that the claim was not credible and shouted that he thought it was a "stinking double cross". He went on to claim that an invasion was only hours away, and Fomin stated that a response to the US message was expected from Khrushchev shortly and urged Scali to tell the State Department that no treachery was intended. Scali said that he did not think anyone would believe him, but he agreed to deliver the message. The two went their separate ways, and Scali immediately typed out a memo for the EXCOMM.

Within the US establishment, it was well understood that ignoring the second offer and returning to the first put Khrushchev in a terrible position. Military preparations continued, and all active duty Air Force personnel were recalled to their bases for possible action. Robert Kennedy later recalled the mood: "We had not abandoned all hope, but what hope there was now rested with Khrushchev's revising his course within the next few hours. It was a hope, not an expectation. The expectation was military confrontation by Tuesday (October 30), and possibly tomorrow (October 29) ..."

At 8:05 pm EDT, the letter drafted earlier in the day was delivered. The message read, "As I read your letter, the key elements of your proposals—which seem generally acceptable as I understand them—are as follows: 1) You would agree to remove these weapons systems from Cuba under appropriate United Nations observation and supervision; and undertake, with suitable safe-guards, to halt the further introduction of such weapon systems into Cuba. 2) We, on our part, would agree—upon the establishment of adequate arrangements through the United Nations, to ensure the carrying out and continuation of these commitments (a) to remove promptly the quarantine measures now in effect and (b) to give assurances against the invasion of Cuba." The letter was also released directly to the press to ensure it could not be "delayed". With the letter delivered, a deal was on the table. As Robert Kennedy noted, there was little expectation it would be accepted. At 9:00 pm EDT, the EXCOMM met again to review the actions for the following day. Plans were drawn up for air strikes on the missile sites as well as other economic targets, notably petroleum storage. McNamara stated that they had to "have two things ready: a government for Cuba, because we're going to need one; and secondly, plans for how to respond to the Soviet Union in Europe, because sure as hell they're going to do something there".

At 12:12 am EDT, on October 27, the US informed its NATO allies that "the situation is growing shorter... the United States may find it necessary within a very short time in its interest and that of its fellow nations in the Western Hemisphere to take whatever military action may be necessary." To add to the concern, at 6:00 am, the CIA reported that all missiles in Cuba were ready for action.

On October 27, Khrushchev also received a letter from Castro, what is now known as the Armageddon Letter (dated the day before), which was interpreted as urging the use of nuclear force in the event of an attack on Cuba: "I believe the imperialists' aggressiveness is extremely dangerous and if they actually carry out the brutal act of invading Cuba in violation of international law and morality, that would be the moment to eliminate such danger forever through an act of clear legitimate defense, however harsh and terrible the solution would be," Castro wrote.

Later that same day, what the White House later called "Black Saturday", the US Navy dropped a series of "signalling" depth charges (practice depth charges the size of hand grenades) on a Soviet submarine () at the blockade line, unaware that it was armed with a nuclear-tipped torpedo with orders that allowed it to be used if the submarine was damaged by depth charges or surface fire. As the submarine was too deep to monitor any radio traffic, the captain of the "B-59", Valentin Grigorievitch Savitsky, decided that a war might already have started and wanted to launch a nuclear torpedo. The decision to launch these required agreement from all three officers on board, but one of them, Vasily Arkhipov, objected and so the nuclear launch was narrowly averted.

On the same day a U-2 spy plane made an accidental, unauthorised ninety-minute overflight of the Soviet Union's far eastern coast. The Soviets responded by scrambling MiG fighters from Wrangel Island; in turn, the Americans launched F-102 fighters armed with nuclear air-to-air missiles over the Bering Sea.

On Saturday, October 27, after much deliberation between the Soviet Union and Kennedy's cabinet, Kennedy secretly agreed to remove all missiles set in Turkey and possibly southern Italy, the former on the border of the Soviet Union, in exchange for Khrushchev removing all missiles in Cuba. There is some dispute as to whether removing the missiles from Italy was part of the secret agreement. Khrushchev wrote in his memoirs that it was, and when the crisis had ended McNamara gave the order to dismantle the missiles in both Italy and Turkey.

At this point, Khrushchev knew things the US did not: First, that the shooting down of the U-2 by a Soviet missile violated direct orders from Moscow, and Cuban antiaircraft fire against other US reconnaissance aircraft also violated direct orders from Khrushchev to Castro. Second, the Soviets already had 162 nuclear warheads on Cuba that the US did not then believe were there. Third, the Soviets and Cubans on the island would almost certainly have responded to an invasion by using those nuclear weapons, even though Castro believed that every human in Cuba would likely die as a result. Khrushchev also knew but may not have considered the fact that he had submarines armed with nuclear weapons that the US Navy may not have known about.

Khrushchev knew he was losing control. President Kennedy had been told in early 1961 that a nuclear war would likely kill a third of humanity, with most or all of those deaths concentrated in the US, the USSR, Europe and China; Khrushchev may well have received similar reports from his military.

With this background, when Khrushchev heard Kennedy's threats relayed by Robert Kennedy to Soviet Ambassador Dobrynin, he immediately drafted his acceptance of Kennedy's latest terms from his dacha without involving the Politburo, as he had previously, and had them immediately broadcast over Radio Moscow, which he believed the US would hear. In that broadcast at 9:00 am EST, on October 28, Khrushchev stated that "the Soviet government, in addition to previously issued instructions on the cessation of further work at the building sites for the weapons, has issued a new order on the dismantling of the weapons which you describe as 'offensive' and their crating and return to the Soviet Union."
At 10:00 am, October 28, Kennedy first learned of Khrushchev's solution to the crisis with the US removing the 15 Jupiters in Turkey and the Soviets would remove the rockets from Cuba. Khrushchev had made the offer in a public statement for the world to hear. Despite almost solid opposition from his senior advisers, Kennedy quickly embraced the Soviet offer. "This is a pretty good play of his," Kennedy said, according to a tape recording that he made secretly of the Cabinet Room meeting. Kennedy had deployed the Jupiters in March of the year, causing a stream of angry outbursts from Khrushchev. "Most people will think this is a rather even trade and we ought to take advantage of it," Kennedy said. Vice President Lyndon Johnson was the first to endorse the missile swap but others continued to oppose the offer. Finally, Kennedy ended the debate. "We can't very well invade Cuba with all its toil and blood," Kennedy said, "when we could have gotten them out by making a deal on the same missiles on Turkey. If that's part of the record, then you don't have a very good war."

Kennedy immediately responded to Khrushchev's letter, issuing a statement calling it "an important and constructive contribution to peace". He continued this with a formal letter:

Kennedy's planned statement would also contain suggestions he had received from his adviser Schlesinger Jr. in a "Memorandum for the President" describing the "Post Mortem on Cuba".

Kennedy's Oval Office telephone conversation with Eisenhower soon after Khrushchev's message arrived revealed that the President was planning to use the Cuban Missile Crisis to escalate tensions with Khrushchev and in the long run, Cuba as well. The President also claimed that he thought the crisis would result in direct military confrontations in Berlin by the end of the next month. He also claimed in his conversation with Eisenhower that the Soviet leader had offered to withdraw from Cuba in exchange for the withdrawal of missiles from Turkey and that while the Kennedy Administration had agreed not to invade Cuba, they were only in process of determining Khrushchev's offer to withdraw from Turkey.

When former US President Harry Truman called President Kennedy the day of Khrushchev's offer, the President informed him that his Administration had rejected the Soviet leader's offer to withdraw missiles from Turkey and was planning on using the Soviet setback in Cuba to escalate tensions in Berlin.

The US continued the blockade; in the following days, aerial reconnaissance proved that the Soviets were making progress in removing the missile systems. The 42 missiles and their support equipment were loaded onto eight Soviet ships. On November 2, 1962, Kennedy addressed the US via radio and television broadcasts regarding the dismantlement process of the Soviet R-12 missile bases located in the Caribbean region. The ships left Cuba on November 5 to 9. The US made a final visual check as each of the ships passed the blockade line. Further diplomatic efforts were required to remove the Soviet Il-28 bombers, and they were loaded on three Soviet ships on December 5 and 6. Concurrent with the Soviet commitment on the Il-28s, the US government announced the end of the blockade from 6:45 pm EST on November 20, 1962. 

At the time when the Kennedy administration thought that the Cuban Missile Crisis was resolved, nuclear tactical rockets stayed in Cuba since they were not part of the Kennedy-Khrushchev understandings and the Americans did not know about them. The Soviets changed their minds, fearing possible future Cuban militant steps, and on November 22, 1962, Deputy Premier of the Soviet Union Anastas Mikoyan told Castro that the rockets with the nuclear warheads were being removed as well.

In his negotiations with the Soviet Ambassador Anatoly Dobrynin, Robert Kennedy informally proposed that the Jupiter missiles in Turkey would be removed "within a short time after this crisis was over". The last US missiles were disassembled by April 24, 1963, and were flown out of Turkey soon afterward.

The practical effect of the Kennedy-Khrushchev Pact was that the US would remove their rockets from Italy and Turkey and that the Soviets had no intention of resorting to nuclear war if they were out-gunned by the US. Because the withdrawal of the Jupiter missiles from NATO bases in Italy and Turkey was not made public at the time, Khrushchev appeared to have lost the conflict and become weakened. The perception was that Kennedy had won the contest between the superpowers and that Khrushchev had been humiliated. Both Kennedy and Khrushchev took every step to avoid full conflict despite pressures from their respective governments. Khrushchev held power for another two years.

By the time of the crisis in October 1962, the total amount of nuclear weapons in the stockpiles of each country numbered approximately 26,400 for the United States and 3,300 for the Soviet Union. At the peak of the crisis, the U.S. had some 3,500 nuclear weapons ready to be used on command with a combined yield of approximately 6,300 megatons. The Soviets had considerably less strategic firepower at their disposal (some 300-320 bombs and warheads), lacking submarine-based weapons in a position to threaten the U.S. mainland and having most of their intercontinental delivery systems based on bombers that would have difficulty penetrating North American air defence systems. The U.S. had approximately 4,375 nuclear weapons deployed in Europe, most of which were tactical weapons such as nuclear artillery, with around 450 of them for ballistic missiles, cruise missiles, and aircraft; the Soviets had more than 550 similar weapons in Europe.



The enormity of how close the world came to thermonuclear war impelled Khrushchev to propose a far-reaching easing of tensions with the US. In a letter to President Kennedy dated October 30, 1962, Khrushchev outlined a range of bold initiatives to forestall the possibility of a further nuclear crisis, including proposing a non-aggression treaty between the North Atlantic Treaty Organization (NATO) and the Warsaw Pact or even disbanding these military blocs, a treaty to cease all nuclear weapons testing and even the elimination of all nuclear weapons, resolution of the hot-button issue of Germany by both East and West formally accepting the existence of West Germany and East Germany, and US recognition of the government of mainland China. The letter invited counter-proposals and further exploration of these and other issues through peaceful negotiations. Khrushchev invited Norman Cousins, the editor of a major US periodical and an anti-nuclear weapons activist, to serve as liaison with President Kennedy, and Cousins met with Khrushchev for four hours in December 1962.

Kennedy's response to Khrushchev's proposals was lukewarm but Kennedy expressed to Cousins that he felt constrained in exploring these issues due to pressure from hardliners in the US national security apparatus. The US and the USSR did shortly thereafter agree on a treaty banning atmospheric testing of nuclear weapons, known as the "Partial Nuclear Test Ban Treaty".

Further after the crisis, the US and the Soviet Union created the Moscow–Washington hotline, a direct communications link between Moscow and Washington. The purpose was to have a way that the leaders of the two Cold War countries could communicate directly to solve such a crisis.

The compromise embarrassed Khrushchev and the Soviet Union because the withdrawal of US missiles from Italy and Turkey was a secret deal between Kennedy and Khrushchev. Khrushchev went to Kennedy as he thought that the crisis was getting out of hand, but the Soviets were seen as retreating from circumstances that they had started.

Khrushchev's fall from power two years later was in part because of the Soviet Politburo's embarrassment at both Khrushchev's eventual concessions to the US and this ineptitude in precipitating the crisis in the first place. According to Dobrynin, the top Soviet leadership took the Cuban outcome as "a blow to its prestige bordering on humiliation".

Cuba perceived the outcome as a betrayal by the Soviets, as decisions on how to resolve the crisis had been made exclusively by Kennedy and Khrushchev. Castro was especially upset that certain issues of interest to Cuba, such as the status of the US Naval Base in Guantánamo, were not addressed. That caused Cuban–Soviet relations to deteriorate for years to come. On the other hand, Cuba continued to be protected from invasion.

The worldwide US Forces DEFCON 3 status was returned to DEFCON 4 on November 20, 1962. General Curtis LeMay told the President that the resolution of the crisis was the "greatest defeat in our history"; his was a minority position. He had pressed for an immediate invasion of Cuba as soon as the crisis began and still favoured invading Cuba even after the Soviets had withdrawn their missiles. Twenty-five years later, LeMay still believed that "We could have gotten not only the missiles out of Cuba, we could have gotten the Communists out of Cuba at that time."

At least four contingency strikes were armed and launched from Florida against Cuban airfields and suspected missile sites in 1963 and 1964, although all were diverted to the Pinecastle Range Complex after the planes passed Andros island. Critics, including Seymour Melman, and Seymour Hersh suggested that the Cuban Missile Crisis encouraged the United States' use of military means, such as the case in the later Vietnam War.

U-2 pilot Anderson's body was returned to the US and was buried with full military honours in South Carolina. He was the first recipient of the newly created Air Force Cross, which was awarded posthumously. Although Anderson was the only combatant fatality during the crisis, 11 crew members of three reconnaissance Boeing RB-47 Stratojets of the 55th Strategic Reconnaissance Wing were also killed in crashes during the period between September 27 and November 11, 1962. Seven crew died when a Military Air Transport Service Boeing C-135B Stratolifter delivering ammunition to Guantanamo Bay Naval Base stalled and crashed on approach on October 23.

Schlesinger, a historian and adviser to Kennedy, told National Public Radio in an interview on October 16, 2002 that Castro did not want the missiles, but Khrushchev pressured Castro to accept them. Castro was not completely happy with the idea, but the Cuban National Directorate of the Revolution accepted them, both to protect Cuba against US attack and to aid the Soviet Union. Schlesinger believed that when the missiles were withdrawn, Castro was more angry with Khrushchev than with Kennedy because Khrushchev had not consulted Castro before deciding to remove them. Although Castro was infuriated by Khrushchev, he planned on striking the US with remaining missiles if an invasion of the island occurred.

In early 1992, it was confirmed that Soviet forces in Cuba had already received tactical nuclear warheads for their artillery rockets and Il-28 bombers when the crisis broke. Castro stated that he would have recommended their use if the US invaded despite Cuba being destroyed.

Arguably, the most dangerous moment in the crisis was not recognised until the Cuban Missile Crisis Havana conference, in October 2002. Attended by many of the veterans of the crisis, they all learned that on October 27, 1962, had tracked and dropped signalling depth charges (the size of hand grenades) on , a Soviet Project 641 (NATO designation ) submarine. Unknown to the US, it was armed with a 15-kiloton nuclear torpedo. Running out of air, the Soviet submarine was surrounded by American warships and desperately needed to surface. An argument broke out among three officers aboard "B-59", including submarine captain Valentin Savitsky, political officer Ivan Semonovich Maslennikov, and Deputy brigade commander Captain 2nd rank (US Navy Commander rank equivalent) Vasily Arkhipov. An exhausted Savitsky became furious and ordered that the nuclear torpedo on board be made combat ready. Accounts differ about whether Arkhipov convinced Savitsky not to make the attack or whether Savitsky himself finally concluded that the only reasonable choice left open to him was to come to the surface. During the conference, McNamara stated that nuclear war had come much closer than people had thought. Thomas Blanton, director of the National Security Archive, said, "A guy called Vasili Arkhipov saved the world."

Fifty years after the crisis, Graham T. Allison wrote:

BBC journalist Joe Matthews published the story, on October 13, 2012, behind the 100 tactical nuclear warheads mentioned by Graham Allison in the excerpt above. Khrushchev feared that Castro's hurt pride and widespread Cuban indignation over the concessions he had made to Kennedy might lead to a breakdown of the agreement between the Soviet Union and the US. To prevent that, Khrushchev decided to offer to give Cuba more than 100 tactical nuclear weapons that had been shipped to Cuba along with the long-range missiles but, crucially, had escaped the notice of US intelligence. Khrushchev determined that because the Americans had not listed the missiles on their list of demands, keeping them in Cuba would be in the Soviet Union's interests.

Anastas Mikoyan was tasked with the negotiations with Castro over the missile transfer deal that was designed to prevent a breakdown in the relations between Cuba and the Soviet Union. While in Havana, Mikoyan witnessed the mood swings and paranoia of Castro, who was convinced that Moscow had made the agreement with the US at the expense of Cuba's defence. Mikoyan, on his own initiative, decided that Castro and his military not be given control of weapons with an explosive force equal to 100 Hiroshima-sized bombs under any circumstances. He defused the seemingly intractable situation, which risked re-escalating the crisis, on November 22, 1962. During a tense, four-hour meeting, Mikoyan convinced Castro that despite Moscow's desire to help, it would be in breach of an unpublished Soviet law, which did not actually exist, to transfer the missiles permanently into Cuban hands and provide them with an independent nuclear deterrent. Castro was forced to give way and, much to the relief of Khrushchev and the rest of the Soviet government, the tactical nuclear weapons were crated and returned by sea to the Soviet Union during December 1962.

The American popular media, especially television, made frequent use of the events of the missile crisis and both fictional and documentary forms. Jim Willis includes the Crisis as one of the 100 "media moments that changed America". Sheldon Stern finds that a half century later there are still many "misconceptions, half-truths, and outright lies" that have shaped media versions of what happened in the White House during those harrowing two weeks.

Historian William Cohn argued in a 1976 article that television programs are typically the main source used by the American public to know about and interpret the past. According to Cold War historian Andrei Kozovoi, the Soviet media proved somewhat disorganised as it was unable to generate a coherent popular history. Khrushchev lost power and was airbrushed out of the story. Cuba was no longer portrayed as a heroic David against the American Goliath. One contradiction that pervaded the Soviet media campaign was between the pacifistic rhetoric of the peace movement that emphasises the horrors of nuclear war and the militancy of the need to prepare Soviets for war against American aggression.









</doc>
<doc id="6828" url="https://en.wikipedia.org/wiki?curid=6828" title="Aquilegia">
Aquilegia

Aquilegia (common names: granny's bonnet, columbine) is a genus of about 60–70 species of perennial plants that are found in meadows, woodlands, and at higher altitudes throughout the Northern Hemisphere, known for the spurred petals of their flowers.

The genus name "Aquilegia" is derived from the Latin word for eagle ("aquila"), because of the shape of the flower petals, which are said to resemble an eagle's claw. The common name "columbine" comes from the Latin for "dove", due to the resemblance of the inverted flower to five doves clustered together.

The leaves of this plant are compound and the flowers contain five sepals, five petals and five pistils. The fruit is a follicle
which holds many seeds and is formed at the end of the pistils. Underneath the flower are spurs which contain nectar, mainly consumed by long-beaked birds such as hummingbirds. Almost all "Aquilegia" species have a ring of staminodia around the base of the stigma, which may help protect against insects.

Columbines are closely related to plants in the genera "Actaea" (baneberries) and "Aconitum" (wolfsbanes/monkshoods), which like "Aquilegia" produce cardiogenic toxins.

They are used as food plants by some Lepidoptera (butterfly and moth) caterpillars. These are mainly of noctuid moths – noted for feeding on many poisonous plants without harm – such as cabbage moth ("Mamestra brassicae"), dot moth ("Melanchra persicariae") and mouse moth ("Amphipyra tragopoginis"). the engrailed ("Ectropis crepuscularia"), a geometer moth, also uses columbine as a larval food plant. The larvae of the "Papaipema leucostigma" also feed on columbine.

Plants in the genus "Aquilegia" are a major food source for "Bombus hortorum", a species of bumblebee. Specifically, they have been found to forage on species of "Aquilegia vulgaris" in Belgium and "Aquilegia chrysantha" in North America and Belgium. The bees do not show any preference in color of the flowers.

Columbine is a hardy perennial, which propagates by seed. It will grow to a height of 15 to 20 inches. It will grow in full sun; however, it prefers growing in partial shade and well drained soil, and is able to tolerate average soils and dry soil conditions. Columbine is rated at hardiness zone 3 in the United States so does not require mulching or protection in the winter.

Large numbers of hybrids are available for the garden, since the European "A. vulgaris" was hybridized with other European and North American varieties.
The British National Collection of "Aquilegia"s was held by Mrs Carrie Thomas at Killay near Swansea. Some time during or before 2014 the collection started to succumb to Aquilegia Downy Mildew "Peronospora aquilegiicola" which was at the time an emerging disease to which the plants had no resistance. By 2018 the entire collection had been lost.

The flowers of various species of columbine were consumed in moderation by Native Americans as a condiment with other fresh greens, and are reported to be very sweet, and safe if consumed in small quantities. The plant's seeds and roots, however, are highly poisonous and contain cardiogenic toxins which cause both severe gastroenteritis and heart palpitations if consumed as food. Native Americans used very small amounts of "Aquilegia" root as a treatment for ulcers. However, the medical use of this plant is better avoided due to its high toxicity; columbine poisonings may be fatal.

An acute toxicity test in mice has demonstrated that ethanol extract mixed with isocytisoside, the main flavonoid compound from the leaves and stems of "Aquilegia vulgaris", can be classified as non-toxic, since a dose of 3000 mg/kg did not cause mortality.

The Colorado blue columbine ("A. coerulea") is the official state flower of Colorado (see also Columbine, Colorado).

Columbines have been important in the study of evolution. It was found that the Sierra columbine ("A. pubescens") and crimson columbine ("A. formosa") each has adapted specifically to a pollinator. Bees and hummingbirds are the visitors to "A. formosa", while hawkmoths would only visit "A. pubescens" when given a choice. Such a "pollination syndrome", being due to flower color and orientation controlled by their genetics, ensures reproductive isolation and can be a cause of speciation.
"Aquilegia" petals show an enormous range of petal spur length diversity ranging from a centimeter to the 15 cm spurs of "Aquilegia longissima". Selection from pollinator shifts is suggested to have driven these changes in nectar spur length. 
It was shown that this spur length diversity is achieved solely through changing cell shape, not cell number or cell size. This suggests that a simple microscopic change can result in a dramatic evolutionarily relevant morphological change.

Columbine species include:




</doc>
<doc id="6829" url="https://en.wikipedia.org/wiki?curid=6829" title="Cache (computing)">
Cache (computing)

In computing, a cache ( , or in Australian English) is a hardware or software component that stores data so that future requests for that data can be served faster; the data stored in a cache might be the result of an earlier computation or a copy of data stored elsewhere. A "cache hit" occurs when the requested data can be found in a cache, while a "cache miss" occurs when it cannot. Cache hits are served by reading data from the cache, which is faster than recomputing a result or reading from a slower data store; thus, the more requests that can be served from the cache, the faster the system performs.

To be cost-effective and to enable efficient use of data, caches must be relatively small. Nevertheless, caches have proven themselves in many areas of computing, because typical computer applications access data with a high degree of locality of reference. Such access patterns exhibit temporal locality, where data is requested that has been recently requested already, and spatial locality, where data is requested that is stored physically close to data that has already been requested.

There is an inherent trade-off between size and speed (given that a larger resource implies greater physical distances) but also a tradeoff between expensive, premium technologies (such as SRAM) vs cheaper, easily mass-produced commodities (such as DRAM or hard disks).

The buffering provided by a cache benefits both latency and throughput (bandwidth):

A larger resource incurs a significant latency for access e.g. it can take hundreds of clock cycles for a modern 4 GHz processor to reach DRAM. This is mitigated by reading in large chunks, in the hope that subsequent reads will be from nearby locations. Prediction or explicit prefetching might also guess where future reads will come from and make requests ahead of time; if done correctly the latency is bypassed altogether.

The use of a cache also allows for higher throughput from the underlying resource, by assembling multiple fine grain transfers into larger, more efficient requests. In the case of DRAM circuits, this might be served by having a wider data bus. For example, consider a program accessing bytes in a 32-bit address space, but being served by a 128-bit off-chip data bus; individual uncached byte accesses would allow only 1/16th of the total bandwidth to be used, and 80% of the data movement would be memory addresses instead of data itself. Reading larger chunks reduces the fraction of bandwidth required for transmitting address information.

Hardware implements cache as a block of memory for temporary storage of data likely to be used again. Central processing units (CPUs) and hard disk drives (HDDs) frequently use a cache, as do web browsers and web servers.

A cache is made up of a pool of entries. Each entry has associated "data", which is a copy of the same data in some "backing store". Each entry also has a "tag", which specifies the identity of the data in the backing store of which the entry is a copy. Tagging allows simultaneous cache-oriented algorithms to function in multilayered fashion without differential relay interference.

When the cache client (a CPU, web browser, operating system) needs to access data presumed to exist in the backing store, it first checks the cache. If an entry can be found with a tag matching that of the desired data, the data in the entry is used instead. This situation is known as a cache hit. For example, a web browser program might check its local cache on disk to see if it has a local copy of the contents of a web page at a particular URL. In this example, the URL is the tag, and the content of the web page is the data. The percentage of accesses that result in cache hits is known as the hit rate or hit ratio of the cache.

The alternative situation, when the cache is checked and found not to contain any entry with the desired tag, is known as a cache miss. This requires a more expensive access of data from the backing store. Once the requested data is retrieved, it is typically copied into the cache, ready for the next access.

During a cache miss, some other previously existing cache entry is removed in order to make room for the newly retrieved data. The heuristic used to select the entry to replace is known as the replacement policy. One popular replacement policy, "least recently used" (LRU), replaces the oldest entry, the entry that was accessed less recently than any other entry (see cache algorithm). More efficient caching algorithms compute the use-hit frequency against the size of the stored contents, as well as the latencies and throughputs for both the cache and the backing store. This works well for larger amounts of data, longer latencies, and slower throughputs, such as that experienced with hard drives and networks, but is not efficient for use within a CPU cache.

When a system writes data to cache, it must at some point write that data to the backing store as well. The timing of this write is controlled by what is known as the "write policy". There are two basic writing approaches:


A write-back cache is more complex to implement, since it needs to track which of its locations have been written over, and mark them as "dirty" for later writing to the backing store. The data in these locations are written back to the backing store only when they are evicted from the cache, an effect referred to as a "lazy write". For this reason, a read miss in a write-back cache (which requires a block to be replaced by another) will often require two memory accesses to service: one to write the replaced data from the cache back to the store, and then one to retrieve the needed data.

Other policies may also trigger data write-back. The client may make many changes to data in the cache, and then explicitly notify the cache to write back the data.

Since no data is returned to the requester on write operations, a decision needs to be made on write misses, whether or not data would be loaded into the cache.
This is defined by these two approaches:


Both write-through and write-back policies can use either of these write-miss policies, but usually they are paired in this way:


Entities other than the cache may change the data in the backing store, in which case the copy in the cache may become out-of-date or "stale". Alternatively, when the client updates the data in the cache, copies of those data in other caches will become stale. Communication protocols between the cache managers which keep the data consistent are known as coherency protocols.

Small memories on or close to the CPU can operate faster than the much larger main memory. Most CPUs since the 1980s have used one or more caches, sometimes in cascaded levels; modern high-end embedded, desktop and server microprocessors may have as many as six types of cache (between levels and functions). Examples of caches with a specific function are the D-cache and I-cache and the translation lookaside buffer for the MMU.

Earlier graphics processing units (GPUs) often had limited read-only texture caches, and introduced morton order swizzled textures to improve 2D cache coherency. Cache misses would drastically affect performance, e.g. if mipmapping was not used. Caching was important to leverage 32-bit (and wider) transfers for texture data that was often as little as 4 bits per pixel, indexed in complex patterns by arbitrary UV coordinates and perspective transformations in inverse texture mapping.

As GPUs advanced (especially with GPGPU compute shaders) they have developed progressively larger and increasingly general caches, including instruction caches for shaders, exhibiting increasingly common functionality with CPU caches. For example, GT200 architecture GPUs did not feature an L2 cache, while the Fermi GPU has 768 KB of last-level cache, the Kepler GPU has 1536 KB of last-level cache, and the Maxwell GPU has 2048 KB of last-level cache. These caches have grown to handle synchronisation primitives between threads and atomic operations, and interface with a CPU-style MMU.

Digital signal processors have similarly generalised over the years. Earlier designs used scratchpad memory fed by DMA, but modern DSPs such as Qualcomm Hexagon often include a very similar set of caches to a CPU (e.g. Modified Harvard architecture with shared L2, split L1 I-cache and D-cache).

A memory management unit (MMU) that fetches page table entries from main memory has a specialized cache, used for recording the results of virtual address to physical address translations. This specialized cache is called a translation lookaside buffer (TLB).

Information-centric networking (ICN) is an approach to evolve the Internet infrastructure away from a host-centric paradigm, based on perpetual connectivity and the end-to-end principle, to a network architecture in which the focal point is identified information (or content or data). Due to the inherent caching capability of the nodes in an ICN, it can be viewed as a loosely connected network of caches, which has unique requirements of caching policies. However, ubiquitous content caching introduces the challenge to content protection against unauthorized access, which requires extra care and solutions.
Unlike proxy servers, in ICN the cache is a network-level solution. Therefore, it has rapidly changing cache states and higher request arrival rates; moreover, smaller cache sizes further impose a different kind of requirements on the content eviction policies. In particular, eviction policies for ICN should be fast and lightweight. Various cache replication and eviction schemes for different ICN architectures and applications have been proposed.

The Time aware Least Recently Used (TLRU) is a variant of LRU designed for the situation where the stored contents in cache have a valid life time. The algorithm is suitable in network cache applications, such as Information-centric networking (ICN), Content Delivery Networks (CDNs) and distributed networks in general. TLRU introduces a new term: TTU (Time to Use). TTU is a time stamp of a content/page which stipulates the usability time for the content based on the locality of the content and the content publisher announcement. Owing to this locality based time stamp, TTU provides more control to the local administrator to regulate in network storage.
In the TLRU algorithm, when a piece of content arrives, a cache node calculates the local TTU value based on the TTU value assigned by the content publisher. The local TTU value is calculated by using a locally defined function. Once the local TTU value is calculated the replacement of content is performed on a subset of the total content stored in cache node. The TLRU ensures that less popular and small life content should be replaced with the incoming content.

The Least Frequent Recently Used (LFRU) cache replacement scheme combines the benefits of LFU and LRU schemes. LFRU is suitable for 'in network' cache applications, such as Information-centric networking (ICN), Content Delivery Networks (CDNs) and distributed networks in general. In LFRU, the cache is divided into two partitions called privileged and unprivileged partitions. The privileged partition can be defined as a protected partition. If content is highly popular, it is pushed into the privileged partition. Replacement of the privileged partition is done as follows: LFRU evicts content from the unprivileged partition, pushes content from privileged partition to unprivileged partition, and finally inserts new content into the privileged partition. In the above procedure the LRU is used for the privileged partition and an approximated LFU (ALFU) scheme is used for the unprivileged partition, hence the abbreviation LFRU.
The basic idea is to filter out the locally popular contents with ALFU scheme and push the popular contents to one of the privileged partition.

While CPU caches are generally managed entirely by hardware, a variety of software manages other caches. The page cache in main memory, which is an example of disk cache, is managed by the operating system kernel.

While the disk buffer, which is an integrated part of the hard disk drive, is sometimes misleadingly referred to as "disk cache", its main functions are write sequencing and read prefetching. Repeated cache hits are relatively rare, due to the small size of the buffer in comparison to the drive's capacity. However, high-end disk controllers often have their own on-board cache of the hard disk drive's data blocks.

Finally, a fast local hard disk drive can also cache information held on even slower data storage devices, such as remote servers (web cache) or local tape drives or optical jukeboxes; such a scheme is the main concept of hierarchical storage management. Also, fast flash-based solid-state drives (SSDs) can be used as caches for slower rotational-media hard disk drives, working together as hybrid drives or solid-state hybrid drives (SSHDs).

Web browsers and web proxy servers employ web caches to store previous responses from web servers, such as web pages and images. Web caches reduce the amount of information that needs to be transmitted across the network, as information previously stored in the cache can often be re-used. This reduces bandwidth and processing requirements of the web server, and helps to improve responsiveness for users of the web.

Web browsers employ a built-in web cache, but some Internet service providers (ISPs) or organizations also use a caching proxy server, which is a web cache that is shared among all users of that network.

Another form of cache is P2P caching, where the files most sought for by peer-to-peer applications are stored in an ISP cache to accelerate P2P transfers. Similarly, decentralised equivalents exist, which allow communities to perform the same task for P2P traffic, for example, Corelli.

A cache can store data that is computed on demand rather than retrieved from a backing store. Memoization is an optimization technique that stores the results of resource-consuming function calls within a lookup table, allowing subsequent calls to reuse the stored results and avoid repeated computation. It is related to the dynamic programming algorithm design methodology, which can also be thought of as a means of caching.

The BIND DNS daemon caches a mapping of domain names to IP addresses, as does a resolver library.

Write-through operation is common when operating over unreliable networks (like an Ethernet LAN), because of the enormous complexity of the coherency protocol required between multiple write-back caches when communication is unreliable. For instance, web page caches and client-side network file system caches (like those in NFS or SMB) are typically read-only or write-through specifically to keep the network protocol simple and reliable.

Search engines also frequently make web pages they have indexed available from their cache. For example, Google provides a "Cached" link next to each search result. This can prove useful when web pages from a web server are temporarily or permanently inaccessible.

Another type of caching is storing computed results that will likely be needed again, or memoization. For example, ccache is a program that caches the output of the compilation, in order to speed up later compilation runs.

Database caching can substantially improve the throughput of database applications, for example in the processing of indexes, data dictionaries, and frequently used subsets of data.

A distributed cache uses networked hosts to provide scalability, reliability and performance to the application. The hosts can be co-located or spread over different geographical regions.

The semantics of a "buffer" and a "cache" are not totally different; even so, there are fundamental differences in intent between the process of caching and the process of buffering.

Fundamentally, caching realizes a performance increase for transfers of data that is being repeatedly transferred. While a caching system may realize a performance increase upon the initial (typically write) transfer of a data item, this performance increase is due to buffering occurring within the caching system.

With read caches, a data item must have been fetched from its residing location at least once in order for subsequent reads of the data item to realize a performance increase by virtue of being able to be fetched from the cache's (faster) intermediate storage rather than the data's residing location. With write caches, a performance increase of writing a data item may be realized upon the first write of the data item by virtue of the data item immediately being stored in the cache's intermediate storage, deferring the transfer of the data item to its residing storage at a later stage or else occurring as a background process. Contrary to strict buffering, a caching process must adhere to a (potentially distributed) cache coherency protocol in order to maintain consistency between the cache's intermediate storage and the location where the data resides. Buffering, on the other hand,


With typical caching implementations, a data item that is read or written for the first time is effectively being buffered; and in the case of a write, mostly realizing a performance increase for the application from where the write originated. Additionally, the portion of a caching protocol where individual writes are deferred to a batch of writes is a form of buffering. The portion of a caching protocol where individual reads are deferred to a batch of reads is also a form of buffering, although this form may negatively impact the performance of at least the initial reads (even though it may positively impact the performance of the sum of the individual reads). In practice, caching almost always involves some form of buffering, while strict buffering does not involve caching.

A buffer is a temporary memory location that is traditionally used because CPU instructions cannot directly address data stored in peripheral devices. Thus, addressable memory is used as an intermediate stage. Additionally, such a buffer may be feasible when a large block of data is assembled or disassembled (as required by a storage device), or when data may be delivered in a different order than that in which it is produced. Also, a whole buffer of data is usually transferred sequentially (for example to hard disk), so buffering itself sometimes increases transfer performance or reduces the variation or jitter of the transfer's latency as opposed to caching where the intent is to reduce the latency. These benefits are present even if the buffered data are written to the buffer once and read from the buffer once.

A cache also increases transfer performance. A part of the increase similarly comes from the possibility that multiple small transfers will combine into one large block. But the main performance-gain occurs because there is a good chance that the same data will be read from cache multiple times, or that written data will soon be read. A cache's sole purpose is to reduce accesses to the underlying slower storage. Cache is also usually an abstraction layer that is designed to be invisible from the perspective of neighboring layers.



</doc>
<doc id="6830" url="https://en.wikipedia.org/wiki?curid=6830" title="Columbus, Indiana">
Columbus, Indiana

Columbus is a city in and the county seat of Bartholomew County, Indiana, United States. The population was 44,061 at the 2010 census. The relatively small city has provided a unique place for noted Modern architecture and public art, commissioning numerous works since the mid-20th century; the annual program Exhibit Columbus celebrates this legacy. Located about south of Indianapolis, on the east fork of the White River, it is the state's 20th-largest city. It is the principal city of the Columbus, Indiana metropolitan statistical area, which encompasses all of Bartholomew County. Columbus is the birthplace of former Indiana Governor and current Vice President of the United States, Mike Pence.

"National Geographic Traveler" ranked Columbus 11th on its historic destinations list in late 2008, describing the city as "authentic, unique, and unspoiled." Columbus won the national contest "America in Bloom" in 2006, and in 2004 it was named as one of "The Ten Most Playful Towns" by "Nick Jr. Family Magazine". The July 2005 edition of "GQ" magazine, Columbus was named as one of the "62 Reasons to Love Your Country". Columbus is the headquarters of the engine company Cummins, Inc.

The land developed as Columbus was bought by General John Tipton and Luke Bonesteel in 1820. Tipton built a log cabin on Mount Tipton, a small hill overlooking White River and the surrounding flat, heavily forested and swampy valley. It held wetlands of the river. The town was first known as Tiptonia, named in honor of Tipton. The town's name was changed to Columbus on March 20, 1821. General Tipton was upset by the name change and decided to leave the newly founded town. He was later appointed as the highway commissioner for the State of Indiana and was assigned to building a highway from Indianapolis, Indiana to Louisville, Kentucky. When the road reached Columbus, Tipton constructed the first bypass road ever built; it detoured south around the west side of Columbus en route to Seymour.

Joseph McKinney was the first to plot the town of Columbus, but no date was recorded.

Local history books for years said that the land on which Columbus sits was donated by General Tipton. But in 2003, Historic Columbus Indiana acquired a deed showing that General Tipton sold the land.

A ferry was established below the confluence of the Flatrock and Driftwood rivers, which form the White River. A village of three or four log cabins developed around the ferry landing, and a store was added in 1821. Later that year, Bartholomew County was organized by an act of the State Legislature and named to honor the famous Hoosier militiaman, General Joseph Bartholomew. Columbus was incorporated on June 28, 1864.

The first railroad in Indiana was constructed to Columbus from Madison, Indiana in 1844. This eventually became the Madison branch of the Pennsylvania Railroad. The railroad fostered the growth of the community into one of the largest in Indiana, and three more railroads reached the city by 1850.

Columbus is host to the oldest theater in Indiana, The Crump Theatre, which was built in 1889 by John Crump. Today the building is included within the Columbus Historic District. Before it closed permanently in 2010, it was an all-ages venue with occasional musical performances. Columbus was host to the oldest continually operated bookstore in Indiana, Cummins Bookstore, which began operations in 1892. It closed in late 2007.

The Irwin Union Bank building was built in 1954. It was designated as a National Historic Landmark by the National Park Service in 2001 in recognition of its unique architecture. The building consists of a one-story bank structure adjacent to a three-story office annex. A portion of the office annex was built along with the banking hall in 1954. The remaining larger portion, designed by Kevin Roche John Dinkeloo and Associates, was built in 1973. Eero Saarinen designed the bank building with its glazed hall to be set off against the blank background of its three-story brick annex. Two steel and glass vestibule connectors lead from the north side of this structure to the annex. The building was designed to distance the Irwin Union Bank from traditional banking architecture, which mostly echoed imposing, neoclassical style buildings of brick or stone. Tellers were behind iron bars and removed from their customers. Saarinen worked to develop a building that would welcome customers rather than intimidate them.

Columbus has been home to many manufacturing companies, including Noblitt-Sparks Industries (which built radios under the Arvin brand in the 1930s) and Arvin Industries, now Meritor, Inc. After merging with Meritor Automotive on July 10, 2000, the headquarters of the newly created ArvinMeritor Industries was established in Troy, Michigan, the home of parent company, Rockwell International. It was announced in February 2011 that the company name would revert to Meritor, Inc. Cummins, Inc. is by far the region's largest employer, and the Infotech Park accounts for a sizable number of research jobs in Columbus proper. Just south of Columbus are the North American headquarters of Toyota Material Handling, U.S.A., Inc., the world's largest material handling (forklift) manufacturer. Other notable industries include architecture, a discipline for which Columbus is famous worldwide. The late J. Irwin Miller (then president and chairman of Cummins Engine Company) launched the Cummins Foundation, a charitable program that helps subsidize a large number of architectural projects throughout the city by up-and-coming engineers and architects.

Early in the 20th century, Columbus also was home to a number of pioneering car manufacturers, including Reeves, which produced the unusual four-axle Octoauto and the twin rear-axle Sextoauto, both around 1911.

Nearly 19,000 workers commute into the city from the surrounding townships and villages. In recent years city officials have explored ways to revitalize the city. They recognize the value of J. Irwin Miller's support of architectural excellence in the mid-20th century, when the Cummins Foundation made it a mecca of modern architecture. Economic development, widespread beautification innovations, various tax incentives, and increased law enforcement have helped Columbus overcome what some considered a slump during the 1980s and 1990s.

In addition to the Columbus Historic District and Irwin Union Bank, the city has numerous buildings listed on the National Register of Historic Places, including seven National Historic Landmarks of modernist architecture: Bartholomew County Courthouse, Columbus City Hall, First Baptist Church, First Christian Church, Haw Creek Leather Company, Mabel McDowell Elementary School, McEwen-Samuels-Marr House, McKinley School, Miller House, North Christian Church, and The Republic Newspaper Office.

Columbus is located at (39.213998, −85.911056). The Driftwood and Flatrock Rivers converge at Columbus to form the East Fork of the White River.

According to the 2010 census, Columbus has a total area of , of which (or 98.62%) is land and (or 1.38%) is water.

Columbus is served by the Columbus Municipal Airport (KBAK). It is located approximately north of Columbus. The airport handles approximately 40,500 operations per year, with roughly 87% general aviation, 4% air taxi, 8% military and <1% commercial service. The airport has two concrete runways; a 6,401 foot runway with approved ILS and GPS approaches (Runway 5-23) and a 5,001 foot crosswind runway, also with GPS approaches, (Runway 14-32).

As of the census of 2010, there were 44,061 people, 17,787 households, and 11,506 families residing in the city. The population density was . There were 19,700 housing units at an average density of . The racial makeup of the city was 86.9% White, 2.7% African American, 0.2% Native American, 5.6% Asian, 0.1% Pacific Islander, 2.5% from other races, and 2.0% from two or more races. Hispanic or Latino of any race were 5.8% of the population.

There were 17,787 households, of which 33.5% had children under the age of 18 living with them, 48.5% were married couples living together, 11.7% had a female householder with no husband present, 4.5% had a male householder with no wife present, and 35.3% were non-families. 29.7% of all households were made up of individuals, and 11.5% had someone living alone who was 65 years of age or older. The average household size was 2.43 and the average family size was 3.00.

The median age in the city was 37.1 years. 25.2% of residents were under the age of 18; 8.1% were between the ages of 18 and 24; 27.3% were from 25 to 44; 24.9% were from 45 to 64; and 14.4% were 65 years of age or older. The gender makeup of the city was 48.4% male and 51.6% female.

As of the census of 2000, there were 39,059 people, 15,985 households, and 10,566 families residing in the city. The population density was 1,505.3 people per square mile (581.1/km). There were 17,162 housing units at an average density of 661.4 per square mile (255.3/km). The racial makeup of the city was 91.32% White, 2.71% Black or African American, 0.13% Native American, 3.23% Asian, 0.05% Pacific Islander, 1.39% from other races, and 1.19% from two or more races. 2.81% of the population were Hispanic or Latino of any race.

There were 15,985 households, out of which 31.8% had children under the age of 18 living with them, 51.9% were married couples living together, 11.0% had a female householder with no husband present, and 33.9% were non-families. 29.1% of all households were composed of individuals, and 10.7% had someone living alone who was 65 years of age or older. The average household size was 2.39, and the average family size was 2.94.

In the city, the population was spread out, with 25.7% under the age of 18, 8.0% from 18 to 24 years, 29.5% from 25 to 44 years, 23.0% from 45 to 64 years, and 13.7% over the age of 65. The median age was 36 years. There were 92.8 males for every 100 females and 89.6 males for every 100 females over age 18.

The median income for a household in the city was $41,723, and the median income for a family was $52,296. Males had a median income of $40,367 versus $24,446 for females, and the per capita income was $22,055. About 6.5% of families and 8.1% of the population were below the poverty line, including 9.7% of those under age 18 and 8.8% of those age 65 or over.

Columbus is a city known for its modern architecture and public art. J. Irwin Miller, 2nd CEO and a nephew of a co-founder of Cummins Inc., the Columbus-headquartered diesel engine manufacturer, instituted a program in which the Cummins Foundation paid the architects' fees, provided the client selected a firm from a list compiled by the foundation. The plan was initiated with public schools and was so successful that the foundation decided to offer such design support to other non-profit and civic organizations. The high number of notable public buildings and public art in the Columbus area, designed by such individuals as Eero Saarinen, I.M. Pei, Robert Venturi, Cesar Pelli, and Richard Meier, led to Columbus earning the nickname "Athens on the Prairie."

Seven buildings, constructed between 1942 and 1965, are National Historic Landmarks, and approximately 60 other buildings sustain the Bartholomew County seat's reputation as a showcase of modern architecture. National Public Radio once devoted an article to the town's architecture.

In 2015, Landmark Columbus was created as a program of Heritage Fund - The Community Foundation of Bartholomew county.





In May 2016, Landmark Columbus launched Exhibit Columbus as a way to continue the ambitious traditions of the past into the future. Exhibit Columbus features annual programming that alternates between symposium and exhibition years.

Columbus High School was home to footwear pioneer Chuck Taylor, who played basketball in Columbus before setting out to promote his now famous shoes and the sport of basketball before being inducted into the Naismith Memorial Basketball Hall of Fame.

Two local high schools compete within the state in various sports. Columbus North and Columbus East both have competitive athletics and have many notable athletes that go on to compete in college and beyond. Columbus North High School houses one of the largest high school gyms in the United States. CNHS vs CEHS

Indiana Diesels of the Premier Basketball League play their home games at the gymnasium at Ceraland Park, with plans to move to a proposed downtown sports complex in the near future. Columbus also boasts a roller derby league, the Terrorz of Tiny Towns. Established in 2010, this league hosts weekly practices at Columbus Skateland. The town also has two cricket teams, both which play under the name of Columbus Indiana Cricket Club; their home ground is at Ceraland Park.

Columbus boasts over of parks and green space and over 20 miles of People Trails. These amenities, in addition to several athletic and community facilities, including Donner Aquatic Center, Lincoln Park Softball Complex, Hamilton Center Ice Arena, Clifty Park, Foundation for Youth/Columbus Gymnastics Center and The Commons, are managed and maintained by the Columbus Parks and Recreation Department.

Columbus uses the Mayor-Council form of government. The council consists of seven members. Five are elected from one of five wards the other two are elected at-large. The Mayor is elected in a citywide vote. The current mayor is Jim Lienhoop.

This is a list of notable people who were born in, or who currently live, or have lived in Columbus.

The Bartholomew Consolidated School Corporation (BCSC) is the local school district. High schools include:

Columbus has a public library, a branch of the Bartholomew County Public Library.

Secondary education includes Indiana University – Purdue University Columbus (IUPUC), an Ivy Tech campus, Purdue Polytechnic and an Indiana Wesleyan University education center.






</doc>
<doc id="6834" url="https://en.wikipedia.org/wiki?curid=6834" title="List of computer scientists">
List of computer scientists

This is a list of computer scientists, people who do work in computer science, in particular researchers and authors.

Some persons notable as programmers are included here because they work in research as well as program. A few of these people pre-date the invention of the digital computer; they are now regarded as computer scientists because their work can be seen as leading to the invention of the computer. Others are mathematicians whose work falls within what would now be called theoretical computer science, such as complexity theory and algorithmic information theory.


























</doc>
<doc id="6839" url="https://en.wikipedia.org/wiki?curid=6839" title="Reaction kinetics in uniform supersonic flow">
Reaction kinetics in uniform supersonic flow

Reaction kinetics in uniform supersonic flow (, CRESU ) is an experiment investigating chemical reactions taking place at very low temperatures.

The technique involves the expansion of a gas or mixture of gases through a de Laval nozzle from a high pressure reservoir into a vacuum chamber. As it expands, the nozzle collimates the gas into a uniform supersonic beam that is essentially collision free and has a temperature that, in the centre of mass frame, can be significantly below that of the reservoir gas. Each nozzle produces a characteristic temperature. This way, any temperature between room temperature and about 10K can be achieved.

There are relatively few CRESU apparatuses in existence for the simple reason that the gas throughput and pumping requirements are huge, which makes them expensive to run. Two of the leading centres have been the University of Rennes (France) and the University of Birmingham (UK). A more recent development has been a pulsed version of the CRESU, which requires far less gas and therefore smaller pumps.

Most species have a negligible vapour pressure at such low temperatures and this means that they quickly condense on the sides of the apparatus. Essentially, the CRESU technique provides a "wall-less flow tube," which allows the kinetics of gas phase reactions to be investigated at much lower temperatures than otherwise possible.

Chemical kinetics experiments can then be carried out in a pump-probe fashion using a laser to initiate the reaction (for example by preparing one of the reagents by photolysis of a precursor), followed by observation of that same species (for example by laser-induced fluorescence) after a known time delay. The fluorescence signal is captured by a photomultiplier a known distance downstream of the de Laval nozzle. The time delay can be varied up to the maximum corresponding to the flow time over that known distance. By studying how quickly the reagent species disappears in the presence of differing concentrations of a (usually stable) co-reagent species the reaction rate constant at the low temperature of the CRESU flow can be determined.

Reactions studied by the CRESU technique typically have no significant activation energy barrier. In the case of neutral-neutral reactions (i.e., not involving any charged species, ions), these type of barrier-free reactions usually involve free radical species such as molecular oxygen (O), the cyanide radical (CN) or the hydroxyl radical (OH). The energetic driving force for these reactions is typically an attractive long range intermolecular potential.

CRESU experiments have been used to show deviations from Arrhenius kinetics at low temperatures: as the temperature is reduced, the rate constant actually increases. They can explain why chemistry is so prevalent in the interstellar medium, where many different polyatomic species have been detected (by radio astronomy).



</doc>
<doc id="6840" url="https://en.wikipedia.org/wiki?curid=6840" title="Cygwin">
Cygwin

Cygwin ( ) is a POSIX-compatible programming and runtime environment that runs natively on Microsoft Windows. Under Cygwin, source code designed for Unix-like operating systems may be compiled and run natively with minimal modification.

The Cygwin installation directory has a similar directory layout to that found in the root file system of Unix-like systems, with familiar directories, such as /bin, /home, /etc, /usr, /var. Cygwin installs with hundreds of command-line tools and other programs commonly found on a Unix-like system. Additionally, many applications may be installed from a packaging system. The terminal emulator Mintty is the default command-line interface provided to interact with the environment.

Cygwin provides native integration of Windows-based applications. Thus it is possible to launch Windows applications from the Cygwin environment, as well as to use Cygwin tools and applications within the Windows operating context.

Cygwin consists of two parts: a dynamic-link library (DLL) as an API compatibility layer in the form of a C standard library providing a substantial part of the POSIX API functionality, and an extensive collection of software tools and applications that provide a Unix-like look and feel.

Cygwin was originally developed by Cygnus Solutions, which was later acquired by Red Hat (now part of IBM), to port the GNU/Linux toolchain to Win32, including the GNU Compiler Suite. Rather than rewrite all the tools to use Win32 runtimes, Cygwin implemented a POSIX compatible runtime as a DLL. It is free and open-source software, released under the GNU Lesser General Public License version 3. Today it is maintained by volunteers including employees of Red Hat and many others.

The Cygwin environment is provided in two versions, for 32-bit versions of Windows, and for 64-bit versions. Cygwin consists of a library that implements the POSIX system call API in terms of Windows system calls, a GNU development toolchain (including GCC and GDB) to allow software development, and running of a large number of application programs equivalent to those on Unix systems. Programmers have ported many Unix, GNU, BSD and Linux programs and packages to Cygwin, including the X Window System, K Desktop Environment 3, GNOME, Apache, and TeX. Cygwin permits installing inetd, syslogd, sshd, Apache, and other daemons as standard Windows services, allowing Microsoft Windows systems to emulate Unix and Linux servers.

Cygwin programs are installed by running Cygwin's "setup" program, which downloads the necessary program and feature package files from repositories on the Internet. As mentioned, there are two versions of this setup program, one for 32-bit versions of the Cygwin DLL, and corresponding applications, and one for 64-bit versions. Setup can install, update, and remove programs and their source code packages. A complete installation will take in excess of 90 GB of hard disk space, but usable configurations may require as little as 1 or 2 GB.

Efforts to reconcile concepts that differ between Unix and Windows systems include:

The version of gcc that comes with Cygwin has various extensions for creating Windows DLLs, specifying whether a program is a windowing or console-mode program, adding resources, etc. Support for compiling programs that do not require the POSIX compatibility layer provided by the Cygwin DLL used to be included in the default codice_13, but is provided by cross-compilers contributed by the MinGW-w64 project.

Cygwin is used heavily for porting many popular pieces of software to the Windows platform. It is used to compile Sun Java, LibreOffice, and even web server software like Lighttpd and Hiawatha.

The Cygwin API library is licensed under the GNU Lesser General Public License version 3 (or later) with an exception to allow linking to any free and open-source software whose license conforms to the Open Source Definition (less strict than the Free Software Definition).

Cygwin began in 1995 as a project of Steve Chamberlain, a Cygnus engineer who observed that Windows NT and 95 used COFF as their object file format, and that GNU already included support for x86 and COFF, and the C library newlib. He thought it would be possible to retarget GCC and produce a cross compiler generating executables that could run on Windows. This proved practical and a prototype was quickly developed.

The next step was to attempt to bootstrap the compiler on a Windows system, requiring sufficient emulation of Unix to let the GNU configure shell script run. A Bourne shell-compatible command interpreter, such as bash, was needed and in turn a fork system call emulation and standard input/output. Windows includes similar functionality, so the Cygwin library just needed to provide a POSIX-compatible application programming interface (API) and properly translate calls and manage private versions of data, such as file descriptors.

Initially, Cygwin was called gnuwin32 (not to be confused with the current GnuWin32 project). The name was changed to Cygwin32 to emphasize Cygnus' role in creating it. When Microsoft registered the trademark Win32, the 32 was dropped to simply become Cygwin.

By 1996, other engineers had joined in, because it was clear that Cygwin would be a useful way to provide Cygnus' embedded tools hosted on Windows systems (the previous strategy had been to use DJGPP). It was especially attractive because it was possible to do a three-way cross-compile, for instance to use a hefty Sun Microsystems workstation to build, say, a Windows-x-MIPS cross-compiler, which was faster than using the PC at the time. In 1999, Cygnus offered Cygwin 1.0 as a commercial product of interest in its own right although subsequent versions have not been released, instead relying on continued open source releases.

Geoffrey Noer was the project lead from 1996 to 1999. Christopher Faylor was the project lead from 1999 to mid-2014. Corinna Vinschen became co-lead since 2004 when Faylor left Red Hat and has been lead since mid-2014, when Faylor withdrew from active participation in the project.

Cygwin's base package selection is fairly small (about 100 MB), containing little more than the bash (interactive user) and dash (installation) shells and the core file and text manipulation utilities expected of a Unix command line. Additional packages are available as optional installs from within Cygwin's package manager ("setup-x86.exe" – 32bit & "setup-x86_64.exe" – 64bit). These include (among many others):

The Cygwin/X project contributes an implementation of the X Window System that allows graphical Unix programs to display their user interfaces on the Windows desktop. This can be used with both local and remote programs. Cygwin/X supports over 500 packages including major X window managers, desktop environments, and applications, for example:

In addition to the low-level Xlib/XCB libraries for developing X applications, Cygwin also ships with various higher-level and cross-platform GUI frameworks, including GTK+ and Qt.

The Cygwin Ports project provided many additional packages that were not available in the Cygwin distribution itself. Examples included GNOME and K Desktop Environment 3 as well as the MySQL database and the PHP scripting language. Most ports have been adopted by volunteer maintainers as Cygwin packages, and Cygwin Ports are no longer maintained. 


</doc>
<doc id="6845" url="https://en.wikipedia.org/wiki?curid=6845" title="Corinth">
Corinth

Corinth (; , is the successor to an ancient city, and is a former municipality in Corinthia, Peloponnese, which is located in south-central Greece. Since the 2011 local government reform, it has been part of the municipality of Corinth, of which it is the seat and a municipal unit. It is the capital of Corinthia.

It was founded as Nea Korinthos or New Corinth (Νέα Κόρινθος) in 1858 after an earthquake destroyed the existing settlement of Corinth, which had developed in and around the site of ancient Corinth.

Located about west of Athens, Corinth is surrounded by the coastal townlets of (clockwise) Lechaio, Isthmia, Kechries, and the inland townlets of Examilia and the archaeological site and village of ancient Corinth. Natural features around the city include the narrow coastal plain of Vocha, the Corinthian Gulf, the Isthmus of Corinth cut by its canal, the Saronic Gulf, the Oneia Mountains, and the monolithic rock of Acrocorinth, where the medieval acropolis was built.

Corinth derives its name from Ancient Corinth, a city-state of antiquity. The site was occupied from before 3000 BC. Historical references begin with the early 8th century BC, when Corinth began to develop as a commercial center. Between the 8th and 7th centuries, the Bacchiad family ruled Corinth. Cypselus overthrew the Bacchiad family, and between 657 and 550 BC, he and his son Periander ruled Corinth as the Tyrants. 

In about 550 BC, an oligarchical government seized power. This government allied with Sparta within the Peloponnesian League, and Corinth participated in the Persian Wars and Peloponnesian War as an ally of Sparta. After Sparta's victory in the Peloponnesian war, the two allies fell out with one another, and Corinth pursued an independent policy in the various wars of the early 4th century BC. After the Macedonian conquest of Greece, the Acrocorinth was the seat of a Macedonian garrison until 243 BC, when the city was liberated and joined the Achaean League. Nearly a century later, in 146 BC, Corinth was captured and was completely destroyed by the Roman army.

As a newly rebuilt Roman colony in 44 BC, Corinth flourished and became the administrative capital of the Roman province of Achaea.

In 1858, the old city, now known as Ancient Corinth (Αρχαία Κόρινθος, "Archaia Korinthos"), located south-west of the modern city, was totally destroyed by a magnitude 6.5 earthquake. New Corinth ("Nea Korinthos") was then built to the north-east of it, on the coast of the Gulf of Corinth. In 1928, a magnitude 6.3 earthquake devastated the new city, which was then rebuilt on the same site. In 1933, there was a great fire, and the new city was rebuilt again.

The Municipality of Corinth (Δήμος Κορινθίων) had a population of 58,192 according to the 2011 census, the second most populous municipality in the Peloponnese Region after Kalamata. The municipal unit of Corinth had 38,132 inhabitants, of which Corinth itself had 30,176 inhabitants, placing it in third place behind Kalamata and Tripoli among the cities of the Peloponnese Region.

The municipal unit of Corinth (Δημοτική ενότητα Κορινθίων) includes apart from Corinth proper the town of Archaia Korinthos (2,198 inhabitants in 2011), the town of Examilia (2,905 inhabitants), and the smaller settlements of Xylokeriza (1,316 inhabitants) and Solomos (817 inhabitants). The municipal unit has an area of 102.187 km.

Corinth is a major industrial hub at a national level. The Corinth Refinery is one of the largest oil refining industrial complexes in Europe. Ceramic tiles, copper cables, gums, gypsum, leather, marble, meat products, medical equipment, mineral water and beverages, petroleum products, and salt are produced nearby. , a period of deindustrialization commenced as a large pipework complex, a textile factory and a meat packing facility diminished their operations.

Corinth is a major road hub. The A7 toll motorway for Tripoli and Kalamata, (and Sparta via A71 toll), branches off the A8/European route E94 toll motorway from Athens at Corinth. Corinth is the main entry point to the Peloponnesian peninsula, the southernmost area of continental Greece.

KTEL Korinthias provides intercity bus service in the peninsula and to Athens via the Isthmos station southeast of the city center. Local bus service is also available.

The metre gauge railway from Athens and Pireaeus reached Corinth in 1884. This station closed to regular public transport in 2007. In 2005, two years prior, the city was connected to the Proastiakos, the Athens suburban rail network, following the completion of the new Corinth railway station. The journey from Athens to Corinth is estimated to approx. 55 minutes so it is really convenient to choose a hotel in Corinth and commute to Athens for sightseeing. Train station is 5 minutes by car from the city center and parking is available for free.

The port of Corinth, located north of the city centre and close to the northwest entrance of the Corinth Canal, at 37 56.0’ N / 22 56.0’ E, serves the local needs of industry and agriculture. It is mainly a cargo exporting facility.

It is an artificial harbour (depth approximately , protected by a concrete mole (length approximately 930 metres, width 100 metres, mole surface 93,000 m2). A new pier finished in the late 1980s doubled the capacity of the port. The reinforced mole protects anchored vessels from strong northern winds.

Within the port operates a customs office facility and a Hellenic Coast Guard post. Sea traffic is limited to trade in the export of local produce, mainly citrus fruits, grapes, marble, aggregates and some domestic imports. The port operates as a contingency facility for general cargo ships, bulk carriers and ROROs, in case of strikes at Piraeus port.

There was formerly a ferry link to Catania, Sicily and Genoa in Italy.

The Corinth Canal, carrying ship traffic between the western Mediterranean Sea and the Aegean Sea, is about east of the city, cutting through the Isthmus of Corinth that connects the Peloponnesian peninsula to the Greek mainland, thus effectively making the former an island. The builders dug the canal through the Isthmus at sea level; no locks are employed. It is in length and only wide at its base, making it impassable for most modern ships. It now has little economic importance.

The canal was mooted in classical times and an abortive effort was made to build it in the 1st century AD. Julius Caesar and Caligula both considered digging the canal but died before starting the construction. The emperor Nero was the first to attempt to construct the canal. The Roman workforce responsible for the initial digging consisted of 6,000 Jewish prisoners of war. Modern construction started in 1882, after Greece gained independence from the Ottoman Empire, but was hampered by geological and financial problems that bankrupted the original builders. It was completed in 1893, but due to the canal's narrowness, navigational problems and periodic closures to repair landslips from its steep walls, it failed to attract the level of traffic anticipated by its operators. It is now used mainly for tourist traffic.

The city's association football team is Korinthos F.C. ("Π.Α.E. Κόρινθος"), established in 1999 after the merger of Pankorinthian Football Club ("Παγκορινθιακός") and Corinth Football Club ("Κόρινθος"). During the 2006–2007 season, the team played in the Greek Fourth Division's Regional Group 7. The team went undefeated that season and it earned the top spot. This granted the team a promotion to the Gamma Ethnikí (Third Division) for the 2007–2008 season. For the 2008–2009 season, Korinthos F.C. competed in the Gamma Ethniki (Third Division) southern grouping.

Corinth is twinned with:


Due to its ancient history and the presence of St. Paul the Apostle in Corinth some locations all over the world have been named Corinth.




</doc>
<doc id="6846" url="https://en.wikipedia.org/wiki?curid=6846" title="Colossae">
Colossae

Colossae (; Greek: Κολοσσαί) was an ancient city of Phrygia in Asia Minor, and one of the most celebrated cities of southern Anatolia (modern Turkey). The Epistle to the Colossians, an early Christian text which identifies its author as Paul the Apostle, is addressed to the church in Colossae. A significant city from the 5th century BC onwards, it had dwindled in importance by the time of Paul, but was notable for the existence of its local angel cult. It was part of the Roman – and then Byzantine – province of Phrygia Pacatiana, before being destroyed in 1192/3 and its population relocating to nearby Chonae (Chonai, modern day Honaz).

Colossae was located in Phrygia, in Asia Minor. It was located 15 km southeast of Laodicea on the road through the Lycus Valley near the Lycus River at the foot of Mt. Cadmus, the highest mountain in Turkey's western Aegean Region, and between the cities Sardeis and Celaenae, and southeast of the ancient city of Hierapolis. At Colossae, Herodotus describes how, "the river Lycos falls into an opening of the earth and disappears from view, and then after an interval of about five furlongs it comes up to view again, and this river also flows into the Maiander." Despite a treacherously ambiguous cartography and history, Colossae has been clearly distinguished in modern research from nearby "Chonai" (Χῶναι), now called Honaz, with what remains of the buried ruins of Colossae ("the mound") lying 3 km to the north of Honaz.

The medieval poet Manuel Philes, incorrectly, imagined that the name "Colossae" was connected to the Colossus of Rhodes. More recently, in an interpretation which ties Colossae to an Indo-European root that happens to be shared with the word "kolossos", Jean-Pierre Vernant has connected the name to the idea of setting up a sacred space or shrine. Another proposal relates the name to the Greek "kolazo", "to punish". Others believe the name derives from the manufacture of its famous dyed wool, or "colossinus".

The first mention of the city may be in a 17th-century BC Hittite inscription, which speaks of a city called Huwalušija, which some archeologists believe refer to early Colossae. The Fifth Century geographer Herodotus first mentions Colossae by name and as a "great city in Phrygia", which accommodates the Persian King Xerxes I while en route to wage war against the Greeks - showing the city had already reached a certain level of wealth and size by this time. 
Writing in the 5th century BC, Xenophon refers to Colossae as "a populous city, wealthy and of considerable magnitude". It was famous for its wool trade. Strabo notes that the city drew great revenue from the flocks, and that the wool of Colossae gave its name to colour "colossinus".

In 396 BC, Colossae was the site of the execution of the rebellious Persian satrap Tissaphernes who was lured there and slain by an agent of the party of Cyrus the Younger.

Although during the Hellenistic period, the town was of some mercantile importance, by the 1st century it had dwindled greatly in size and significance. Paul's letter to the Colossians point to the existence of an early Christian community. The town was known for its fusion of religious influences (syncretism), which included Jewish, Gnostic, and pagan influences that in the first century AD were described as an angel-cult. This unorthodox cult venerated the archangel Michael who is said to have caused a curative spring to gush from a fissure in the Earth.

The canonical biblical text Epistle to the Colossians is addressed to the Christian community in Colossae. The epistle has traditionally been attributed to Paul the Apostle due to its autobiographical salutation & style, but some modern critical scholars now believe it to be written by another author some time after Paul's death. It is believed that one aim of the letter was to address the challenges that the Colossian community faced in its context of the syncretistic Gnostic religions that were developing in Asia Minor.

According to the Epistle to the Colossians, Epaphras seems to have been a person of some importance in the Christian community in Colossae (; ), and tradition presents him as its first bishop.
The epistle also seems to imply that Paul had never visited the city, because it only speaks of him having "heard" of the Colossians' faith (), and in the Epistle to Philemon Paul tells Philemon of his hope to visit Colossae upon being freed from prison (see ). Tradition also gives Philemon as the second bishop of the see.

The city was decimated by an earthquake in the 60s AD, and was rebuilt independent of the support of Rome.

The Apostolic Constitutions list Philemon as a Bishop of Colossae. On the other hand, the Catholic Encyclopedia considers Philemon doubtful.

The first historically documented bishop is Epiphanius, who was not personally at the Council of Chalcedon, but whose metropolitan bishop Nunechius of Laodicea, the capital of the Roman province of Phrygia Pacatiana signed the acts on his behalf.

The city's fame and renowned status continued into the Byzantine period, and in 858, it was distinguished as a Metropolitan See. The Byzantines also built the church of St. Michael in the vicinity of Colossae, one of the largest church buildings in the Middle East. Nevertheless, sources suggest that the town may have decreased in size or may even been completely abandoned due to Arab invasions in the seventh and eighth centuries, forcing the population to flee to resettle in the nearby city of Chonai (modern day Honaz).

Colossae's famous church was destroyed in 1192/3 during the Byzantine civil wars. It was a suffragan diocese of Laodicea in Phyrigia Pacatiane but was replaced in the Byzantine period by the Chonae settlement on higher ground

As of 2019, Colossae has never been excavated, as most archeological attention has been focused on nearby Laodicea and Hierapolis, though plans are reported for an Australian-led expedition to the site. The present site exhibits a biconical acropolis almost 100 feet high, and encompasses an area of almost 22 acres. On the eastern slope there sits a theater which probably seated around 5,000 people, suggesting a total population of 25,000 - 30,000 people. The theater was probably built during the Roman period, and may be near an agora that abuts the "Cardo Maximus", or the city's main north-south road. Ceramic finds around the theater confirm the city's early occupation in the third and second millennia BC. Northeast of the tell, and most likely outside the city walls, a necropolis displays Hellenistic tombs with two main styles of burial: one with an antecedent room connected to an inner chamber, and tumuli, or underground chambers accessed by stairs leading to the entrance. Outside the tell there are also remains of sections of columns that may have marked a processional way or the "cardo". Today, the remains of one column marks the location where locals believe a church once stood, possibly that of St. Michael. Near the Lycus River, there is evidence that water channels had been cut out of the rock with a complex of pipes and sluice gates to divert water for bathing and for agricultural and industrial purposes.

The holiness and healing properties associated with the waters of Colossae during the Byzantine Era continue to this day, particularly at a pool fed by the Lycus River at the Göz picnic grounds west of Colossae at the foot of Mt. Cadmus. Locals consider the water to be therapeutic.





</doc>
<doc id="6848" url="https://en.wikipedia.org/wiki?curid=6848" title="Charge of the Goddess">
Charge of the Goddess

The Charge is the promise of the Goddess (who is embodied by the high priestess) to all witches that she will teach and guide them. It has been called "perhaps the most important single theological document in the neo-Pagan movement". It is used not only in Wicca, but as part of the foundational documents of the Reclaiming (neopaganism) tradition of witchcraft co-founded by Starhawk.

Several versions of the Charge exist, though they all have the same basic premise, that of a set of instructions given by the Great Goddess to her worshippers. The best-known version is that compiled by Gerald Gardner. This version, titled "Leviter Veslis" or "Lift Up the Veil", includes material paraphrased from works by Aleister Crowley, primarily from Liber AL (The Book of the Law, particularly from Ch 1, spoken by Nuit, the Star Goddess), and from Liber LXV (The Book of the Heart Girt with a Serpent) and from Crowley's essay "The Law of Liberty", thus linking modern Wicca to the cosmology and revelations of Thelema. It has been shown that Gerald Gardner's book collection which was acquired by Ripley's Believe It or Not! included a copy of Crowley's The Blue Equinox" (1919) which includes all of the Crowley quotations transferred by Gardner to the Charge of the Goddess. 

There are also two versions written by Doreen Valiente in the mid-1950s, after her 1953 Wiccan initiation. The first was a poetic paraphrase which eliminated almost all the material derived from Leland and Crowley. The second was a prose version which is contained within the traditional Gardnerian Book of Shadows and more closely resembles Gardner's "Leviter Veslis" version of 1949.

Several different versions of a Wiccan "Charge of the God" have since been created to mirror and accompany the "Charge of the Goddess".

The opening paragraph names a collection of goddesses, some derived from Greek or Roman mythology, others from Celtic or Arthurian legends, affirming a belief that these various figures represent a single Great Mother:

This theme echoes the ancient Roman belief that the Goddess Isis was known by ten thousand names and also that the Goddess still worshipped today by Wiccans and other neopagans is known under many guises but is in fact one universal divinity.

The second paragraph is largely derived and paraphrased from the words that Aradia, the messianic daughter of Diana, speaks to her followers in Charles Godfrey Leland's 1899 book "Aradia, or the Gospel of the Witches" (London: David Nutt; various reprints). The third paragraph is largely written by Doreen Valiente, with a significant content of phrases loosely from "The Book of the Law" and "The Book of the Heart Girt with the Serpent" by Aleister Crowley.

The charge affirms that "all" acts of love and pleasure are sacred to the Goddess e.g.

"Let my worship be within the heart that rejoices,
for behold, all acts of love and pleasure are my rituals.

Therefore, let there be beauty and strength,

power and compassion, honor and humility,
mirth and reverence within you."

In book eleven, chapter 47 of Apuleius's "The Golden Ass", Isis delivers what Ceisiwr Serith calls "essentially a charge of a goddess". This is rather different from the modern version known in Wicca, though they have the same premise, that of the rules given by a great Mother Goddess to her faithful.

The Charge of the Goddess is also known under the title "Leviter Veslis". This has been identified by the historian Ronald Hutton, cited in an article by Roger Dearnsley "The Influence of Aleister Crowley on "Ye Bok of Ye Art Magical", as a piece of medieval ecclesiastical Latin used to mean "lifting the veil." However, Hutton's interpretation does not reflect the Latin grammar as it currently stands. It may represent Gardner's attempt to write "Levetur Velis", which has the literal meaning of "Let the veil be lifted." This expression would, by coincidence or design, grammatically echo the famous "fiat lux" ("Gen. 1:3") of the Latin Vulgate.

The earliest known Wiccan version is found in a document dating from the late 1940s, Gerald Gardner's ritual notebook titled "Ye Bok of Ye Art Magical" (formerly in the collection of Ripley's International, Toronto).The oldest identifiable source contained in this version is the final line, which is traceable to the 17th-century "Centrum Naturae Concentratum" of Alipili (or Ali Puli). This version also draws extensively from Charles Godfrey Leland's "Aradia, or the Gospel of the Witches" (1899) and other modern sources, particularly from the works of Aleister Crowley.

It is believed to have been compiled by Gerald Gardner or possibly another member of the New Forest coven. Gardner intended his version to be a theological statement justifying the Gardnerian sequence of initiations. Like the Charge found in Freemasonry, where the charge is a set of instructions read to a candidate standing in a temple, the Charge of the Goddess was intended to be read immediately before an initiation.

Valiente felt that the influence of Crowley on the Charge was too obvious, and she did not want "the Craft" ( a common term for Wicca) associated with Crowley. Gardner invited her to rewrite the Charge. She proceeded to do so, her first version being into verse.

The initial verse version by Doreen Valiente consisted of eight verses, the second of which was :

Valiente was unhappy with this version, saying that "people seemed to have some difficulty with this, because of the various goddess-names which they found hard to pronounce", and so she rewrote it as a prose version, much of which differs from her initial version, and is more akin to Gardner's version. This prose version has since been modified and reproduced widely by other authors.




</doc>
<doc id="6849" url="https://en.wikipedia.org/wiki?curid=6849" title="Cy Young">
Cy Young

Denton True "Cy" Young (March 29, 1867 – November 4, 1955) was an American Major League Baseball (MLB) pitcher. Born in Gilmore, Ohio, he worked on his family's farm as a youth before starting his professional baseball career. Young entered the major leagues in 1890 with the National League's Cleveland Spiders and pitched for them until 1898. He was then transferred to the St. Louis Cardinals franchise. In 1901, Young jumped to the American League and played for the Boston Red Sox franchise until 1908, helping them win the 1903 World Series. He finished his career with the Cleveland Naps and Boston Rustlers, retiring in 1911.

Young was one of the hardest-throwing pitchers in the game early in his career. After his speed diminished, he relied more on his control and remained effective into his forties. By the time Young retired, he had established numerous pitching records, some of which have stood for over a century. He holds MLB records for the most career wins, with 511, along with most career innings pitched, games started, and complete games. He led his league in wins during five seasons and pitched three no-hitters, including a perfect game.

Young was elected to the National Baseball Hall of Fame in 1937. In 1956, one year after his death, the Cy Young Award was created to honor the best pitcher in each league for each season.

Cy Young was the oldest child born to McKinzie Young, Jr. a German American and Nancy Mottmiller. He was christened Denton True Young. The couple had four more children: Jesse Carlton, Alonzo, Ella, and Anthony. When the couple married, McKinzie's father gave him the of farm land he owned. Young was born in Gilmore, a tiny farming community located in Washington Township, Tuscarawas County, Ohio. 

He was raised on one of the local farms and went by the name Dent Young in his early years. Young was also known as "Farmer Young" and "Farmboy Young". Young stopped his formal education after he completed the sixth grade so he could help out on the family's farm. In 1885, Young moved with his father to Nebraska, and in the summer of 1887, they returned to Gilmore.

Young played for many amateur baseball leagues during his youth, including a semi-professional Carrollton team in 1888. Young pitched and played second base. The first box score known containing the name Young came from that season. In that game, Young played first base and had three hits in three at-bats. After the season, Young received an offer to play for the minor league Canton team, which started Young's professional career.

Young began his professional career in 1889 with the Canton, Ohio, team of the Tri-State League, a professional minor league. During his tryout, Young impressed the scouts, recalling years later, "I almost tore the boards off the grandstand with my fast ball." Cy Young's nickname came from the fences that he had destroyed using his fastball. The fences looked like a cyclone had hit them. Reporters later shortened the name to "Cy", which became the nickname Young used for the rest of his life. During Young's one year with the Canton team, he won 15 games and lost 15.

Franchises in the National League, the major professional baseball league at the time, wanted the best players available to them. Therefore, in 1890, Young signed with the Cleveland Spiders, a team which had moved from the American Association to the National League the previous year.

On August 6, 1890, Young's major league debut, he pitched a three-hit 8–1 victory over the Chicago Colts. While Young was on the Spiders, Chief Zimmer was his catcher more often than any other player. Bill James, a baseball statistician, estimated that Zimmer caught Young in more games than any other battery in baseball history.

Early on, Young established himself as one of the harder-throwing pitchers in the game. Bill James wrote that Zimmer often put a piece of beefsteak inside his baseball glove to protect his catching hand from Young's fastball. In the absence of radar guns, however, it is impossible to say just how hard Young actually threw. Young continued to perform at a high level during the 1890 season. On the last day of the season, Young won both games of a doubleheader. In the first weeks of Young's career, Cap Anson, the player-manager of the Chicago Colts spotted Young's ability. Anson told Spiders manager Gus Schmelz, "He's too green to do your club much good, but I believe if I taught him what I know, I might make a pitcher out of him in a couple of years. He's not worth it now, but I'm willing to give you $1,000 ($ today) for him." Schmelz replied, "Cap, you can keep your thousand and we'll keep the rube."
Two years after Young's debut, the National League moved the pitcher's position back by . Since 1881, pitchers had pitched within a "box" whose front line was from home base, and since 1887 they had been compelled to toe the back line of the box when delivering the ball. The back line was away from home. In 1893, was added to the back line, yielding the modern pitching distance of . In the book "The Neyer/James Guide to Pitchers", sports journalist Rob Neyer wrote that the speed with which pitchers like Cy Young, Amos Rusie, and Jouett Meekin threw was the impetus that caused the move.

The 1892 regular season was a success for Young, who led the National League in wins (36), ERA (1.93), and shutouts (9). Just as many contemporary Minor League Baseball leagues operate today, the National League was using a split season format during the 1892 season. The Boston Beaneaters won the first-half title, and the Spiders won the second-half title, with a best-of-nine series determining the league champion. Despite the Spiders' second half run, the Beaneaters swept the series, five games to none. Young pitched three complete games in the series, but lost two decisions. He also threw a complete game shutout, but the game ended in a scoreless tie.

The Spiders faced the Baltimore Orioles in the Temple Cup, a precursor to the World Series, in 1895. Young won three games in the series and Cleveland won the Cup, four games to one. It was around this time that Young added what he called a "slow ball" to his pitching repertoire to reduce stress on his arm. The pitch today is called a changeup.

In 1896, Young lost a no-hitter with two outs in the ninth inning when Ed Delahanty of the Philadelphia Phillies hit a single. On September 18, 1897, Young pitched the first no-hitter of his career in a game against the Cincinnati Reds. Although Young did not walk a batter, the Spiders committed four errors while on defense. One of the errors had originally been ruled a hit, but the Cleveland third baseman sent a note to the press box after the eighth inning, saying he had made an error, and the ruling was changed. Young later said that, despite his teammate's gesture, he considered the game to be a one-hitter.

Prior to the 1899 season, Frank Robison, the Spiders owner, bought the St. Louis Browns, thus owning two clubs simultaneously. The Browns were renamed the "Perfectos", and restocked with Cleveland talent. Just weeks before the season opener, most of the better Spiders players were transferred to St. Louis, including three future Hall of Famers: Young, Jesse Burkett, and Bobby Wallace. The roster maneuvers failed to create a powerhouse Perfectos team, as St. Louis finished fifth in both 1899 and 1900. Meanwhile, the depleted Spiders lost 134 games, the most in MLB history, before folding. Young spent two years with St. Louis, which is where he found his favorite catcher, Lou Criger. The two men were teammates for a decade.

In 1901, the rival American League declared major league status and set about raiding National League rosters. Young left St. Louis and joined the American League's Boston Americans for a $3,500 contract ($ today). Young would remain with the Boston team until 1909. In his first year in the American League, Young was dominant. Pitching to Criger, who had also jumped to Boston, Young led the league in wins, strikeouts, and ERA, thus earning the colloquial AL Triple Crown for pitchers. Young won almost 42% of his team's games in 1901, accounting for 33 of his team's 79 wins. In February 1902, before the start of the baseball season, Young served as a pitching coach at Harvard University. The sixth-grade graduate instructing Harvard students delighted Boston newspapers. The following year, Young coached at Mercer University during the spring. The team went on to win the Georgia state championship in 1903, 1904, and 1905.

The Boston Americans played the Pittsburgh Pirates in the first modern World Series in 1903. Young, who started Game One against the visiting Pirates, thus threw the first pitch in modern World Series history. The Pirates scored four runs in that first inning, and Young lost the game. Young performed better in subsequent games, winning his next two starts. He also drove in three runs in Game Five. Young finished the series with a 2–1 record and a 1.85 ERA in four appearances, and Boston defeated Pittsburgh, five games to three games.
After one-hitting Boston on May 2, 1904, Philadelphia Athletics pitcher Rube Waddell taunted Young to face him so that he could repeat his performance against Boston's ace. Three days later, Young pitched a perfect game against Waddell and the Athletics. It was the first perfect game in American League history. Waddell was the 27th and last batter, and when he flied out, Young shouted, "How do you like that, you hayseed?"

Waddell had picked an inauspicious time to issue his challenge. Young's perfect game was the centerpiece of a pitching streak. Young set major league records for the most consecutive scoreless innings pitched and the most consecutive innings without allowing a hit; the latter record still stands at 25.1 innings, or 76 hitless batters. Even after allowing a hit, Young's scoreless streak reached a then-record 45 shutout innings. Before Young, only two pitchers had thrown perfect games. This occurred in 1880, when Lee Richmond and John Montgomery Ward pitched perfect games within five days of each other, although under somewhat different rules: the front edge of the pitcher's box was only from home base (the modern release point is about farther away); walks required eight balls; and pitchers were obliged to throw side-armed. Young's perfect game was the first under the modern rules established in 1893. One year later, on July 4, 1905, Rube Waddell beat Young and the Americans, 4–2, in a 20-inning matchup. Young pitched 13 consecutive scoreless innings before he gave up a pair of unearned runs in the final inning. Young did not walk a batter and was later quoted: "For my part, I think it was the greatest game of ball I ever took part in." In 1907, Young and Waddell faced off in a scoreless 13-inning tie.

In 1908, Young pitched the third no-hitter of his career. Three months past his 41st birthday, Cy Young was the oldest pitcher to record a no-hitter, a record which would stand 82 years until 43-year-old Nolan Ryan surpassed the feat. Only a walk kept Young from his second perfect game. After that runner was caught stealing, no other batter reached base. At this time, Young was the second-oldest player in either league. In another game one month before his no-hitter, he allowed just one single while facing 28 batters. On August 13, 1908, the league celebrated "Cy Young Day." No American League games were played on that day, and a group of All-Stars from the league's other teams gathered in Boston to play against Young and the Red Sox. When the season ended, he posted a 1.26 ERA, which gave him not only the lowest in his career, but also gave him a major league record of being the oldest pitcher with 150+ innings pitched to post a season ERA under 1.50.

Young was traded back to Cleveland, the place where he played over half his career, before the 1909 season, to the Cleveland Naps of the American League. The following season, 1910, he won his 500th career game on July 19 against Washington. He split 1911, his final year, between the Naps and the Boston Rustlers. On September 22, 1911, Young shut out the Pittsburgh Pirates, 1–0, for his last career victory. In his final start two weeks later, the last eight batters of Young's career combined to hit a triple, four singles, and three doubles. By the time of his retirement, Young's control had faltered. He had also gained weight. In two of his last three years, he was the oldest player in the league.

Young established numerous pitching records, some of which have stood for over a century. Young compiled 511 wins, which is the most in major league history and 94 ahead of Walter Johnson, second on the list. At the time of Young's retirement, Pud Galvin had the second most career wins with 364. In addition to wins, Young still holds the major league records for most career innings pitched (7,356), most career games started (815), and most complete games (749). He also retired with 316 losses, the most in MLB history. Young's career record for strikeouts was broken by Johnson in 1921. Young's 76 career shutouts are fourth all-time.
Young led his league in wins five times (1892, 1895, and 1901–1903), finishing second twice. His career high was 36 in 1892. He won at least 30 games in a season five times. He had 15 seasons with 20 or more wins, two more than the runners-up, Christy Mathewson and Warren Spahn. Young won two ERA titles during his career, in 1892 (1.93) and in 1901 (1.62), and was three times the runner-up. Young's earned run average was below 2.00 six times, but this was not uncommon during the dead-ball era. Although Young threw over 400 innings in each of his first four full seasons, he did not lead his league until 1902. He had 40 or more complete games nine times. Young also led his league in strikeouts twice (with 140 in 1896, and 158 in 1901), and in shutouts seven times. Young led his league in fewest walks per nine innings fourteen times and finished second one season. Only twice in his 22-year career did Young finish lower than 5th in the category. Although the WHIP ratio was not calculated until well after Young's death, Young was the retroactive league leader in this category seven times and was second or third another seven times. Young is tied with Roger Clemens for the most career wins by a Boston Red Sox pitcher. They each won 192 games while with the franchise. In addition, Young pitched three no-hitters, including the third perfect game in baseball history, first in baseball's "modern era".

Young also was an above average hitting pitcher in his career. He posted a .210 batting average (623-for-2960) with 325 runs, 18 home runs, 290 RBI and drew 81 bases on balls. From 1891 through 1905, he drove in 10 or more runs for 15 straight seasons, with a high of 28 RBI in 1896.

Particularly after his fastball slowed, Young relied upon his control. Young was once quoted as saying, "Some may have thought it was essential to know how to curve a ball before anything else. Experience, to my mind, teaches to the contrary. Any young player who has good control will become a successful curve pitcher long before the pitcher who is endeavoring to master both curves and control at the same time. The curve is merely an accessory to control." In addition to his exceptional control, Young was also a workhorse who avoided injury. For nineteen consecutive years, from 1891 through 1909, Young was in his league's top ten for innings pitched; in fourteen of the seasons, he was in the top five. Not until 1900, a decade into his career, did Young pitch two consecutive incomplete games. By habit, Young restricted his practice throws in spring training. "I figured the old arm had just so many throws in it", said Young, "and there wasn't any use wasting them." Young once described his approach before a game:
I never warmed up ten, fifteen minutes before a game like most pitchers do. I'd loosen up, three, four minutes. Five at the outside. And I never went to the bullpen. Oh, I'd relieve all right, plenty of times, but I went right from the bench to the box, and I'd take a few warm-up pitches and be ready. Then I had good control. I aimed to make the batter hit the ball, and I threw as few pitches as possible. That's why I was able to work every other day.

In 1910, it was reported that Young was a vegetarian. Beginning in 1912, Young lived and worked on his farm. In 1913, he served as manager of the Cleveland Green Sox of the Federal League, which was at the time an outlaw league. However, he never worked in baseball after that.

Young's wife, Roba, whom he had known since childhood, died in 1933. After she died, Young tried several jobs, and eventually moved in with friends John and Ruth Benedum and did odd jobs for them. Young took part in many baseball events after his retirement. In 1937, 26 years after he retired from baseball, Young was inducted into the Baseball Hall of Fame. He was among the first to donate mementos to the Hall.

By 1940, Young's only source of income was stock dividends of $300 per year ($ today). On November 4, 1955, Young died on the Benedums' farm at the age of 88. He was buried in Peoli, Ohio.

Young's career is seen as a bridge from baseball's earliest days to its modern era; he pitched against stars such as Cap Anson, already an established player when the National League was first formed in 1876, as well as against Eddie Collins, who played until 1930. When Young's career began, pitchers delivered the baseball underhand and fouls were not counted as strikes. The pitcher's mound was not moved back to its present position of until Young's fourth season; he did not wear a glove until his sixth season.

Young was elected to the National Baseball Hall of Fame in 1937. In 1956, about one year after Young's death, the Cy Young Award was created to honor the best pitcher in Major League Baseball for each season. The first award was given to Brooklyn's Don Newcombe. Originally, it was a single award covering all of baseball. The honor was divided into two Cy Young Awards in 1967, one for each league.

On September 23, 1993, a statue dedicated to him was unveiled by Northeastern University on the site of the Red Sox's original stadium, the Huntington Avenue Grounds. It was there that Young had pitched the first game of the 1903 World Series, as well as the first perfect game in the modern era of baseball. A home plate-shaped plaque next to the statue reads:

On October 1, 1903 the first modern World Series between the American League champion Boston Pilgrims (later known as the Red Sox) and the National League champion Pittsburgh Pirates was played on this site. General admission tickets were fifty cents. The Pilgrims, led by twenty-eight game winner Cy Young, trailed the series three games to one but then swept four consecutive victories to win the championship five games to three.
In 1999, 88 years after his final major league appearance and 44 years after his death, editors at "The Sporting News" ranked Young 14th on their list of "Baseball's 100 Greatest Players". That same year, baseball fans named him to the Major League Baseball All-Century Team.




</doc>
<doc id="6851" url="https://en.wikipedia.org/wiki?curid=6851" title="Coronation Street">
Coronation Street

Coronation Street (often referred to as Corrie) is a British soap opera created by Granada Television and shown on ITV since 9 December 1960. The programme typically centres around the residents of Coronation Street – a cobbled, terraced street in Weatherfield, a fictional town based on inner-city Salford.

Originally broadcast twice weekly, the series now airs six times a week: Monday, Wednesday and Friday 7:30–8 pm and 8:30–9 pm. The programme was conceived by scriptwriter Tony Warren and entered production at Granada Television in Manchester in 1960. Warren's initial proposal was rejected by the station's founder Sidney Bernstein, but he was persuaded by producer Harry Elton to produce the programme for 13 pilot episodes, and the show has since become a significant part of British culture.

"Coronation Street" is made by ITV Granada at MediaCityUK and shown in all ITV regions, as well as internationally. On 17 September 2010, it became the world's longest-running television soap opera and was listed in "Guinness World Records". Initially influenced by the conventions of kitchen sink realism, "Coronation Street" is noted for its depiction of a down-to-earth, working-class community, combined with light-hearted humour and strong characters. The show currently averages around seven million viewers per episode. The show premiered its 10,000th episode on 7 February 2020.

The was aired on 9 December 1960 at 7 pm, and was not initially a critical success; "Daily Mirror" columnist Ken Irwin claimed the series would only last three weeks. Granada Television had commissioned only 13 episodes, and some inside the company doubted the show would last beyond its planned production run. Despite the criticism, viewers were immediately drawn into the serial, won over by "Coronation Street"s ordinary characters. The programme also made use of Northern English language and dialect; affectionate local terms like "eh, chuck?", "nowt" (, from "nought", meaning "nothing"), and "by 'eck!" became widely heard on British television for the first time.

Early episodes told the story of student Ken Barlow (William Roache), who had won a place at university, and thus found his working-class background—as well as his parents, Frank (Frank Pemberton) and Ida (Noel Dyson)—something of an embarrassment. The character was one of the few to have experienced life outside of Coronation Street. In some ways this predicts the growth of globalisation, and the decline of similar communities. In an episode from 1961, Barlow declares: "You can't go on just thinking about your own street these days. We're living with people on the other side of the world. There's more to worry about than Elsie Tanner (Pat Phoenix) and her boyfriends." Roache is the only remaining member of the original cast, which makes him the longest-serving actor in "Coronation Street", and in British and global soap history.

At the centre of many early stories, there was Ena Sharples (Violet Carson), caretaker of the Glad Tidings Mission Hall, and her friends: timid Minnie Caldwell (Margot Bryant), and bespectacled Martha Longhurst (Lynne Carol). The trio were likened to the Greek chorus, and the three witches in William Shakespeare's "Macbeth", as they would sit in the snug bar of The Rovers Return Inn, passing judgement over family, neighbours and frequently each other. Headstrong Ena often clashed with Elsie Tanner (Pat Phoenix), whom she believed espoused a dauntlessly loose set of morals. Elsie resented Ena's interference and gossip, which most of the time had little basis in reality.

In April 1961, Jed Stone (Kenneth Cope) made his first appearance and returned the following year in 1962. He left in 1963, but returned three years later in 1966. He left again and then returned 42 years later in 2008.

In March 1961, "Coronation Street" reached No. 1 in the television ratings and remained there for the rest of the year. Earlier in 1961, a Television Audience Measurement (TAM) showed that 75% of available viewers (15 million) tuned into "Corrie", and by 1964 the programme had over 20 million regular viewers, with ratings peaking on 2 December 1964, at 21.36 million viewers.

Storylines throughout the decade included Elsie's mystery poison-pen letter, the 1962 marriage of Ken and Valerie Tatlock (Anne Reid), the death of Martha Longhurst in 1964, the birth of the Barlow twins in 1965, Elsie Tanner's wedding to Steve Tanner (Paul Maxwell) and a train crashing from the viaduct (both in 1967), Steve Tanner's murder in 1968, and a coach crash in 1969.

In spite of rising popularity with viewers, "Coronation Street" was criticised by some for its outdated portrayal of the urban working class, and its representation of a community that was a nostalgic fantasy. After the first episode in 1960, the "Daily Mirror" printed: "The programme is doomed from the outset ... For there is little reality in this new serial, which apparently, we have to suffer twice a week." By 1967, critics were suggesting that the programme no longer reflected life in 1960s Britain, but reflected how life was in the "1950s". Granada hurried to update the programme, with the hope of introducing more issue-driven stories, including Lucille Hewitt (Jennifer Moss) becoming addicted to drugs, Jerry Booth (Graham Haberfield) being in a storyline about homosexuality, Emily Nugent (Eileen Derbyshire) having an out-of-wedlock child, and introducing a black family, but all of these ideas were dropped for fear of upsetting viewers.

The show's production team was tested when many core cast members left the programme in the early 1970s. When Arthur Leslie died suddenly in 1970, his character, Rovers' landlord Jack Walker, died with him. Anne Reid quit as Valerie Barlow; her character was killed off in 1971, electrocuting herself with a faulty hairdryer. Ratings reached a low of eight million in February 1973, when Pat Phoenix quit as Elsie Tanner and Doris Speed (haughty landlady Annie Walker) took two months' leave due to bereavement. The audience of ITV's other flagship soap opera "Crossroads" increased markedly at this time, as its established cast, such as Meg Richardson (Noele Gordon), grew in popularity. These sudden departures forced the writing team to quickly develop characters who had previously stood in the background. The roles of Bet Lynch (Julie Goodyear), Deirdre Hunt (Anne Kirkbride), Rita Littlewood (Barbara Knox), Mavis Riley (Thelma Barlow) and Ivy Tyldesley (Lynne Perrie) were built up between 1972 and 1973 (with Perrie's character being renamed to the better-known "Tilsley"), and characters such as Gail Potter (Helen Worth), Blanche Hunt (Patricia Cutts/Maggie Jones), and Vera Duckworth (Liz Dawn) first appearing in 1974. These characters would remain at the centre of the programme for many years.

Comic storylines had been popular in the series in the 1960s, but had become sparse during the early 1970s. These were re-introduced by new producer Bill Podmore who joined the series in 1976. He had worked on Granada comedy productions prior to his appointment. Stan (Bernard Youens) and Hilda Ogden (Jean Alexander) were often at the centre of overtly funny storylines, with other comic characters including Eddie Yeats (Geoffrey Hughes), Fred Gee (Fred Feast), and Jack Duckworth (Bill Tarmey) all making their first appearances during the decade.

In 1976, Pat Phoenix returned to her role as Elsie Tanner and, after a spate of ill health (including a stroke in 1974 where she was written out of the show for 10 months), Violet Carson returned on a more regular basis as Ena. "Coronation Street's" stalwart cast slotted back into the programme alongside the newcomers, examining new relationships between characters of different ages and backgrounds: Eddie Yeats became the Ogdens' lodger, Gail Potter and Suzie Birchall (Cheryl Murray) moved in with Elsie, Mike Baldwin (Johnny Briggs) arrived in 1976 as the tough factory boss, and Annie Walker reigned at the Rovers with her trio of staff: Bet Lynch, Fred Gee and Betty Turpin (Betty Driver).

Storylines throughout the decade included a warehouse fire in 1975, the birth of Tracy Langton in 1977, the murder of Ernest Bishop (Stephen Hancock) in 1978, a lorry crashing into the Rovers Return in 1979, and the marriage of Gail to Brian Tilsley (Christopher Quinten) (also in 1979).

For eleven weeks, between August and October 1979, industrial action forced "Coronation Street" and the entire ITV network (apart from the Channel Islands) off the air. When ITV did return, its first evening schedule included a special "catch-up" edition of "Coronation Street". This included storylines which would have taken place during the strike, and they were explained in the form of a narrative chat between Bet Lynch and popular character Len Fairclough (Peter Adamson). For several weeks the channel had very few fresh episodes to show, and episodes of the game show "3-2-1" were screened in its place. "Coronation Street" returned to ITV screens with a regular scheduled time closer to the end of 1979.

"Coronation Street" had little competition within its prime time slot, and certain critics suggested that the programme had grown complacent, moving away from socially viable storylines and again presenting a dated view of working class life.

Between 1980 and 1989, "Coronation Street" underwent some of the biggest changes since its launch. By May 1984, William Roache (Ken Barlow) stood as the only original cast member, after the departures of Violet Carson (Ena Sharples) in 1980, Doris Speed (Annie Walker) in 1983, and both Pat Phoenix (Elsie Tanner) and Jack Howarth (Albert Tatlock) in 1984. In 1983, antihero Len Fairclough (Peter Adamson), one of the show's central male characters since 1961, was killed off, and in 1984, Stan Ogden (Bernard Youens) died. While the press predicted the end of "Corrie", H. V. Kershaw declared that "There are no stars in "Coronation Street"." Writers drew on the show's many archetypes, with established characters stepping into the roles left by the original cast. Phyllis Pearce (Jill Summers) was hailed as the new Ena Sharples in 1982, the Duckworths moved into No.9 in 1983 and slipped into the role once held by the Ogdens, while Percy Sugden (Bill Waddington) appeared in 1983 and took over the grumpy war veteran role from Albert Tatlock. The question of who would take over the Rovers Return after Annie Walker's 1983 exit was answered in 1985 when Bet Lynch (who also mirrored the vulnerability and strength of Elsie Tanner) was installed as landlady. In 1983, Shirley Armitage (Lisa Lewis) became the first major black character in her role as machinist at Baldwin's Casuals.

Ken Barlow married Deirdre Langton (Anne Kirkbride) on 27 July 1981. The episode was watched by over 15 million viewers – more ITV viewers than the wedding of Prince Charles and Lady Diana two days later. In the 1980s relationships were cemented between established characters: Alf Roberts (Bryan Mosley) married Audrey Potter (Sue Nicholls) in 1985; Kevin Webster (Michael Le Vell) married Sally Seddon (Sally Whittaker) in 1986; Bet Lynch married Alec Gilroy (Roy Barraclough) in 1987; and 1988 saw the marriages of both Ivy Tilsley and Don Brennan (Geoffrey Hinsliff), and the long-awaited union of Mavis Riley and Derek Wilton (Peter Baldwin), after over a decade of on-off romances and a failed marriage attempt in 1984.

In 1982, the arrival of Channel 4, and its edgy new soap opera "Brookside", was one of the biggest changes for "Coronation Street". Unlike "Coronation Street", which had a very nostalgic view of working-class life, "Brookside" brought together working and middle-class families in a more contemporary environment. The dialogue often included expletives and the stories were more hard-hitting, and of the current Zeitgeist. Whereas stories at this time in "Coronation Street" were largely about family affairs, "Brookside" concentrated on social affairs such as industrial action, unemployment, and the black market. The BBC also introduced a new prime time soap opera, "EastEnders" in 1985. Like "Brookside", "EastEnders" had a more gritty premise than "Coronation Street", although unlike "Brookside" it tended to steer clear of blue language and politicised stories.

While ratings for "Coronation Street" remained consistent throughout the decade, "EastEnders" regularly obtained higher viewing figures due to its omnibus episodes shown at weekends. The "Coronation Street" episode broadcast on 2 January 1985 attracted 21.40 million viewers, making it the most-watched episode in the shows history based on a single showing. Subsequent episodes would achieve higher figures when the original broadcast and omnibus edition figures were combined. With prime time competition, "Corrie" was again seen as being old fashioned, with the introduction of the 'normal' Clayton family in 1985 being a failure with viewers. Between 1988 and 1989, many aspects of the show were modernised by new producer David Liddiment. A new exterior set had been built in 1982, and in 1989 it was redeveloped to include new houses and shops. Production techniques were also changed with a new studio being built, and the inclusion of more location filming, which had moved the show from being shot on film to videotape in 1988. Due to new pressures, an introduction of the third weekly episode aired on 20 October 1989, to broadcast each Friday at 7:30 pm.

The 1980s featured some of the most prominent storylines in the programme's history, such as Deirdre Barlow's affair with Mike Baldwin (Johnny Briggs) in 1983, the first soap storyline to receive widespread media attention. The feud between Ken Barlow and Mike Baldwin would continue for many years, with Mike even marrying Ken's daughter, Susan (Wendy Jane Walker). In 1986, there was a fire at the Rovers Return. The episode that aired on 25 December 1987, attracted a combined audience (original and omnibus) of 26.65 million – a figure helped by the fact that this episode heralded the departure of immensely-popular character Hilda Ogden (Jean Alexander). Between 1986 and 1989, the story of Rita Fairclough's (Barbara Knox) psychological abuse at the hands of Alan Bradley (Mark Eden), and then his subsequent death under the wheels of a Blackpool tram, was played out. This storyline gave the show its highest combined viewing figure in its history with 26.93 million for the episode that aired on 15 (and 19) March 1989, where Alan is hiding from the police after trying to kill Rita in the previous episode. This rating is sometimes incorrectly credited to the 8 December 1989 tram death episode. Other stories included the birth of Nicky Tilsley (Warren Jackson) in 1980, Elsie Tanner's departure and Stan Ogden's funeral in 1984, the birth of Sarah-Louise Tilsley (Lynsay King) in 1987, and Brian Tilsley's murder in 1989.

New characters were introduced, such as Terry Duckworth (Nigel Pivaro), Curly Watts (Kevin Kennedy), Martin Platt (Sean Wilson), Reg Holdsworth (Ken Morley), and the McDonald family; one of whom, Simon Gregson, started on the show as Steve McDonald a week after his 15th birthday, and has been on the show ever since.

In spite of updated sets and production changes, "Coronation Street" still received criticism. In 1992, chairman of the Broadcasting Standards Council, Lord Rees-Mogg, criticised the low representation of ethnic minorities, and the programme's portrayal of the cosy familiarity of a bygone era. Some newspapers ran headlines such as ""Coronation Street" shuts out blacks" ("The Times"), and "'Put colour in t'Street" ("Daily Mirror"). Patrick Stoddart of "The Times" wrote: "The millions who watch "Coronation Street" – and who will continue to do so despite Lord Rees-Mogg – know real life when they see it ... in the most confident and accomplished soap opera television has ever seen". Black and Asian characters had appeared, but it was not until 1999 that the show featured its first regular non-white family, the Desai family.

New characters Des (Philip Middlemiss) and Steph Barnes (Amelia Bullmore) moved into one of the new houses in 1990, being dubbed by the media as Yuppies. Raquel Wolstenhulme (Sarah Lancashire) first appeared in 1991 and went on to become one of the most popular characters. The McDonald family were developed and the fiery relationships between Liz (Beverly Callard), Jim (Charles Lawson), Steve (Simon Gregson) and Andy (Nicholas Cochrane) interested viewers. Other newcomers were Maud Grimes (Elizabeth Bradley), Roy Cropper (David Neilson), Gary and Judy Mallett (Ian Mercer and Gaynor Faye), as well as Fred Elliott (John Savident) and Ashley Peacock (Steven Arnold). The amount of slapstick and physical humour in storylines increased during the 1990s, with comical characters such as Reg Holdsworth (Ken Morley) and his water bed.

In the early 1990s storylines included the death of newborn Katie McDonald in 1992, Mike Baldwin's (Johnny Briggs) wedding to Alma Sedgewick (Amanda Barrie) in 1992, Tommy Duckworth being sold by his father Terry (Nigel Pivaro) in 1993, Deirdre Barlow's (Anne Kirkbride) marriage to Moroccan Samir Rachid (Al Nedjari), and the rise of Tanya Pooley (Eva Pope) between 1993 and 1994.

In 1995, Julie Goodyear (Bet Lynch) left the show. She made brief return appearances in 2002 and 2003.

In 1997, Brian Park took over as producer, with the idea of promoting young characters as opposed to the older cast. On his first day, he cut the characters of Derek Wilton (Peter Baldwin), Don Brennan (Geoffrey Hinsliff), Percy Sugden (Bill Waddington), Bill Webster (Peter Armitage), Billy Williams (Frank Mills) and Maureen Holdsworth (Sherrie Hewson). Thelma Barlow, who played Derek's wife Mavis, was angered by the firing of her co-star and resigned. The production team lost some of its key writers when Barry Hill, Adele Rose and Julian Roach all resigned as well.

In line with Park's suggestion, younger characters were introduced: Nick Tilsley was recast, played by Adam Rickitt, single mother Zoe Tattersall (Joanne Froggatt) first appeared, and the Battersbys moved into No.5. Storylines focussed on tackling 'issues', such as drug dealers, eco-warriors, religious cults, and a transsexual woman. Park quit in 1998, after deciding that he had done what he intended to do; he maintained that his biggest achievement was the introduction of Hayley Patterson (Julie Hesmondhalgh), the first transsexual character in a British soap.

Some viewers were alienated by the new "Coronation Street", and sections of the media voiced their disapproval. Having received criticism of being too out of touch, "Corrie" now struggled to emulate the more modern "Brookside" and "EastEnders". In the "Daily Mirror", Victor Lewis-Smith wrote: "Apparently it doesn't matter that this is a first-class soap opera, superbly scripted and flawlessly performed by a seasoned repertory company."

One of "Coronation Street"'s best known storylines took place in March/April 1998, with Deirdre Rachid (Anne Kirkbride) being wrongfully imprisoned after a relationship with con-man Jon Lindsay (Owen Aaronovitch). The episode in which Deirdre was sent to prison had an audience of 19 million viewers, and 'Free the Weatherfield One' campaigns sprung up in a media frenzy. Then Prime Minister Tony Blair even passed comment on Deirdre's sentencing in Parliament. Deirdre was freed after three weeks, with Granada stating that they had always intended for her to be released, in spite of the media interest.

On 8 December 2000, the show celebrated its fortieth year by broadcasting a live, hour-long . The Prince of Wales appeared as himself in an ITV News bulletin report. Earlier in the year, 13-year-old Sarah-Louise Platt (Tina O'Brien) had become pregnant and given birth to a baby girl, Bethany, on 4 June. The episode where Gail was told of her daughter's pregnancy was watched by 15 million viewers. In September 2000, Mike Baldwin married Linda Sykes but shortly afterwards, his drunken son Mark confessed he and Linda had been having an affair behind his dad's back. The episode attracted an audience of 16.8 million and in the 2000 British Soap Awards won Best Storyline.

From 1999 to 2001, issue-led storylines were introduced such as Toyah Battersby's (Georgia Taylor) rape, Roy and Hayley Cropper (David Neilson and Julie Hesmondhalgh) abducting their foster child, Sarah Platt's Internet chat room abduction and Alma Halliwell's (Amanda Barrie) death from cervical cancer. Such storylines were unpopular with viewers and ratings dropped and in October 2001, Macnaught was abruptly moved to another Granada department and Carolyn Reynolds took over. "Corrie" continued to struggle in the ratings, with "EastEnders" introducing some of its strongest stories. In 2002, Kieran Roberts was appointed as producer and aimed to re-introduce "gentle storylines and humour", after deciding that "the Street" should not try to compete with other soaps. In 2002, Gail Platt (Helen Worth) married Richard Hillman (Brian Capron), a financial advisor who would go on to leave Duggie Ferguson (John Bowe) to die; murder both his ex-wife Patricia (Annabelle Apsion) and local neighbour Maxine Peacock (Tracy Shaw); and attempt to kill both his mother-in-law Audrey Roberts (Sue Nicholls) and her longtime friend, Emily Bishop (Eileen Derbyshire). After confessing his crimes to Gail in a two-episode handler, Hillman left the street for two weeks before returning with a suicidal impact on himself and his stepfamily; he kidnapped Gail, her children Sarah and David (Jack P. Shepherd), and granddaughter Bethany, before driving them into a canal – though the Platt family survived whilst Richard drowned. The storyline received wide press attention, and viewing figures peaked at 19.4 million, with Hillman dubbed a "serial killer" by the media. Todd Grimshaw (Bruno Langley) became "Corrie's" first regular homosexual character. In 2003 another gay male character was introduced, Sean Tully (Antony Cotton). The character of Karen McDonald (Suranne Jones) was developed, with her fiery marriage to Steve and warring with Tracy Barlow (Kate Ford). In 2004, "Coronation Street" retconned the Baldwin family when Mike's nephew Danny Baldwin (Bradley Walsh) and his wife Frankie (Debra Stephenson) moved to the area from Essex, with their two sons Jamie (Rupert Hill) and Warren (Danny Young). Until this time, Mike Baldwin had been portrayed as an only child, with his father (also called Frankie and portrayed by Sam Kydd) appearing in the programme between 1980 and 1982 confirming the fact. The bigamy of Peter Barlow (Chris Gascoyne) and his addiction to alcohol, later in the decade, Maya Sharma's (Sasha Behar) revenge on former lover Dev Alahan (Jimmi Harkishin), Charlie Stubbs's (Bill Ward) psychological abuse of Shelley Unwin (Sally Lindsay), and the deaths of Mike Baldwin (Johnny Briggs), Vera Duckworth (Liz Dawn) and Fred Elliott (John Savident). In 2007, Tracy Barlow (Kate Ford) murdered Charlie Stubbs and claiming it was self-defence; the audience during this storyline peaked at 13.3 million. At the 2007 British Soap Awards, it won Best Storyline, and Ford was voted Best Actress for her portrayal. Other storylines included Leanne Battersby (Jane Danson) becoming a prostitute and the show's first bisexual love triangle (between Michelle Connor (Kym Marsh), Sonny Dhillon (Pal Aron), and Sean Tully (Antony Cotton)). The Connor family were central to many storylines during 2007 — the accidental death of a Polish worker at Underworld due to overworking, Michelle's discovery that her brothers Paul (Sean Gallagher) and Liam (Rob James-Collier) were the cause of her husband's death, Paul's use of an escort service, his kidnapping of Leanne and his subsequent death.

In July 2007, after 34 years in the role of Vera Duckworth, Liz Dawn left the show due to ill health. After conversation between Dawn and producers Kieran Roberts and Steve Frost, the decision was made to kill Vera off. In January 2008, shortly before plans to retire to Blackpool, Vera's husband Jack (William Tarmey) found that she had died in her armchair.

Tina O'Brien revealed in the British press on 4 April 2007 that she would be leaving "Coronation Street". Sarah-Louise, who was involved in some of the decade's most controversial stories, left in December 2007 with her daughter, Bethany Platt (who had been in an ecstasy storyline earlier that year, in which she discovered her uncle David's stash of the drug he was looking after for a friend in one of her dolls, and ended up in hospital after she ate them). In 2008, Michelle learning that Ryan (Ben Thompson) was not her biological son, having been accidentally swapped at birth with Alex Neeson (Dario Coates). Carla Connor (Alison King) turned to Liam for comfort and developed feelings for him. In spite of knowing about her feelings, Liam married Maria Sutherland (Samia Longchambon). Maria and Liam's baby son was stillborn in April, and during an estrangement from Maria upon the death of their baby, Liam had a one-night stand with Carla, a story which helped pave the way for his departure. Gail Platt's (Helen Worth) son David (Jack P. Shepherd) pushed her down the stairs. Enraged that Gail refused to press charges, David vandalised the Street and was sent to a young offenders' facility for several months. In May 2008, Gail finally met Ted Page (Michael Byrne), the father she had never known and in 2009, Gail's boyfriend Joe McIntyre (Reece Dinsdale) became addicted to painkillers, which came to a head when he broke into the medical centre. In August 2008, Jed Stone (Kenneth Cope) returned after 42 years. Liam Connor and his ex-sister-in-law Carla gave into their feelings for each other and began an affair. Carla's fiancée Tony Gordon (Gray O'Brien) discovered the affair and had Liam killed in a hit-and-run in October. Carla struggled to come to terms with Liam's death, but decided she still loved Tony and married him on 3 December, in an episode attracting 10.3 million viewers. In April 2009 it was revealed that Eileen Grimshaw's (Sue Cleaver) father, Colin (Edward de Souza) – the son of Elsie Tanner's (Pat Phoenix) cousin Arnley – had slept with Eileen's old classmate, Paula Carp (Sharon Duce) while she was still at school, and that Paula's daughter Julie (Katy Cavanagh) was in fact also Colin's daughter. In May, Norris Cole (Malcolm Hebden) received a blast from the past with the reappearance of his estranged brother Ramsay Clegg (Andrew Sachs) who wanted a reconciliation. Peter Barlow's battle against alcoholism, Ken Barlow's affair with actress Martha Fraser (Stephanie Beacham) after his dog Eccles fell in the canal, Maria giving birth to Liam's son and her subsequent relationship with Liam's killer Tony, Steve McDonald's (Simon Gregson) marriage to Becky Granger (Katherine Kelly) and Kevin Webster's (Michael Le Vell) affair with Molly Dobbs (Vicky Binns). On Christmas Day 2009, Sally Webster (Sally Dynevor) told husband Kevin that she had breast cancer, just as he was about to leave her for lover Molly.

The show began broadcasting in high-definition in May 2010, and on 17 September that year, "Coronation Street" entered "Guinness World Records" as the world's longest-running television soap opera after the American soap opera "As the World Turns" concluded. William Roache was listed as the world's longest-running soap actor.
"Coronation Street" 50th anniversary week was celebrated with seven episodes, plus a special one-hour live episode, broadcast from 6–10 December. The episodes averaged 14 million viewers, a 52.1% share of the audience. The anniversary was also publicised with ITV specials and news broadcasts. In the storyline, Nick Tilsley and Leanne Battersby's bar—The Joinery—exploded during Peter Barlow's stag party. As a result, the viaduct was destroyed, sending a Metrolink tram careering onto the street, destroying D&S Alahan's Corner Shop and The Kabin. Two characters, Ashley Peacock (Steven Arnold) and Molly Dobbs (Vicky Binns), along with an unknown taxi driver, were killed as a result of the disaster. Rita Sullivan (Barbara Knox) survived, despite being trapped under the rubble of her destroyed shop. Fiz Stape (Jennie McAlpine) prematurely gave birth to a baby girl, Hope. The episode of "EastEnders" broadcast on the same day as "Coronation Street" 50th anniversary episode included a tribute, with the character Dot Branning (June Brown) saying that she never misses an episode of "Coronation Street".

In May 2011, Dennis Tanner (Philip Lowrie) returned after 43 years off screen. On 15 October 2011, Betty Driver, who had played Betty Williams since 1969, died of pneumonia, aged 91. In 2011, the major storyline of John Stape and his murder spree came to an end in October 2011 after he crashed his car whilst fleeing from Kevin Webster. He later died in hospital.

On the morning of 1 March 2016, "Coronation Street" creator Tony Warren died aged 79.

On Friday 7 February 2020, the show aired its landmark 10,000th episode.

Since 1960, "Coronation Street" has featured many characters whose popularity with viewers and critics has differed greatly. The original cast was created by Tony Warren, with the characters of Ena Sharples (Violet Carson), Elsie Tanner (Pat Phoenix) and Annie Walker (Doris Speed) as central figures. These three women remained with the show for 20 years or more, and became archetypes of British soap opera, often being emulated by other serials. Ena was the street's busybody, battle-axe and self-proclaimed moral voice. Elsie was the tart with a heart, who was constantly hurt by men in the search for true love. Annie Walker, landlady of the Rovers Return Inn, had delusions of grandeur and saw herself as better than other residents of "Coronation Street".

"Coronation Street" became known for the portrayal of strong female characters, including original cast characters like Ena, Annie and Elsie, and Hilda Ogden (Jean Alexander), who first appeared in 1964; who became household names during the 1960s. Warren's programme was largely matriarchal, which some commentators put down to the female-dominant environment in which he grew up. Consequently, the show has a long tradition of psychologically abused husbands, most famously Stan Ogden (Bernard Youens) and Jack Duckworth (Bill Tarmey), husbands of Hilda and Vera Duckworth (Liz Dawn), respectively.
Ken Barlow (William Roache) entered the storyline as a young radical, reflecting the youth of 1960s Britain, where figures like the Beatles, the Rolling Stones and the model Twiggy were to reshape the concept of youthful rebellion. Though the rest of the original Barlow family were killed off before the end of the 1970s, Ken, who for 27 years was the only character from the first episode remaining, has remained the constant link throughout the entire series. In 2011, Dennis Tanner (Philip Lowrie), another character from the first episode, returned to "Coronation Street" after a 43-year absence. Since 1984, Ken Barlow has been the show's only remaining original character. Emily Bishop (Eileen Derbyshire) had appeared in the series since late-January 1961, when the show was just weeks old, and was the show's longest-serving female character before she departed on 1 January 2016. Rita Tanner (Barbara Knox) appeared on the show for one episode in December 1964, before returning as a full-time cast member in January 1972. She is currently the second longest-serving original cast member on the show.

Stan and Hilda Ogden were introduced in 1964, with Hilda becoming one of the most famous British soap opera characters of all time. In a 1982 poll, she was voted fourth-most recognisable woman in Britain, after Queen Elizabeth The Queen Mother, Queen Elizabeth II and Diana, Princess of Wales. Hilda's best-known attributes were her pinny, hair curlers, and the "muriel" in her living room with three "flying" duck ornaments. Hilda Ogden's departure on Christmas Day 1987, remains the highest-rated episode of "Coronation Street" ever, with nearly 27,000,000 viewers. Stan Ogden had been killed off in 1984 following the death of actor Bernard Youens after a long illness which had restricted his appearances towards the end.

Bet Lynch (Julie Goodyear) first appeared in 1966, before becoming a regular in 1970, and went on to become one of the most famous "Corrie" characters. Bet stood as the central character of the show from 1985 until departing in 1995, often being dubbed as "Queen of the Street" by the media, and indeed herself. The character briefly returned in June 2002.

"Coronation Street" and its characters often rely heavily on archetypes, with the characterisation of some of its current and recent cast based loosely on past characters. Phyllis Pearce (Jill Summers), Blanche Hunt (Maggie Jones) and Sylvia Goodwin (Stephanie Cole) embodied the role of the acid-tongued busybody originally held by Ena, Sally Webster (Sally Dynevor) has grown snobbish, like Annie, and a number of the programme's female characters, such as Carla Connor (Alison King), mirror the vulnerability of Elsie and Bet. Other recurring archetypes include the war veteran such as Albert Tatlock (Jack Howarth), Percy Sugden (Bill Waddington) and Gary Windass (Mikey North), the bumbling retail manager like Leonard Swindley (Arthur Lowe), Reg Holdsworth (Ken Morley), Norris Cole (Malcolm Hebden), quick-tempered, tough tradesmen like Len Fairclough (Peter Adamson), Jim McDonald (Charles Lawson), Tommy Harris (Thomas Craig) and Owen Armstrong (Ian Puleston-Davies), and the perennial losers such as Stan and Hilda, Jack and Vera, Les Battersby (Bruce Jones), Beth Tinker (Lisa George) and Kirk Sutherland (Andrew Whyment).

Villains are also common character types such as Tracy Barlow (Kate Ford), Alan Bradley (Mark Eden), Jenny Bradley (Sally Ann Matthews), Rob Donovan (Marc Baylis), Frank Foster (Andrew Lancel), Tony Gordon (Gray O'Brien), Caz Hammond (Rhea Bailey), Richard Hillman (Brian Capron), Greg Kelly (Stephen Billington), Will Chatterton (Leon Ockenden), Nathan Curtis (Christopher Harper), Callum Logan (Sean Ward), Karl Munro (John Michie), Pat Phelan (Connor McIntyre), David Platt (Jack P. Shepherd), Maya Sharma (Sasha Behar), Kirsty Soames (Natalie Gumede) and John Stape (Graeme Hawley). The show's former archivist and scriptwriter Daran Little disagreed with the characterisation of the show as a collection of stereotypes. "Rather, remember that Elsie, Ena and others were the first of their kind ever seen on British television. If later characters are stereotypes, it's because they are from the same original mould. It is the hundreds of programmes that have followed which have copied "Coronation Street"."

Over the show's history, "Coronation Street" has highlighted a wide range of different social issues, including: rape, incest, Stockholm syndrome, murder, hit-and-run, cancer, adultery, sexual exploitation, child grooming, revenge porn, prostitution, poverty, homelessness, domestic violence, parental abuse, teenage pregnancy, late in life pregnancy, surrogacy, abortion, stillbirth, premature birth, miscarriage, adoption, fostering, male rape, alcoholism, drug addiction, psychotic episodes, gambling addiction, terminal illness, euthanasia, suicide, depression, postpartum depression, bipolar disorder, post-traumatic stress disorder, obsessive compulsive disorder, homosexuality, homosexuality in Islam, child sexual abuse, being transgender, HIV, deafness, epilepsy, osteoporosis, childhood cancer, Ehlers–Danlos syndrome, brain aneurysm, multiple sclerosis, Alzheimer's disease, organ transplant, sepsis, amputation, myotonic dystrophy, identity theft, compulsive hoarding, drink driving, coercive control, skin whitening and mitochondrial disease.

Between 9 December 1960 and 3 March 1961, "Coronation Street" was broadcast twice weekly, on Wednesday and Friday. During this period, the Friday episode was broadcast live, with the Wednesday episode being pre-recorded 15 minutes later. When the programme went fully networked on 6 March 1961, broadcast days changed to Monday and Wednesday. The last regular episode to be shown live was broadcast on 3 February 1961.

The series was transmitted in black and white for the majority of the 1960s. Preparations were made to film episode 923, to be transmitted Wednesday 29 October 1969, in colour. This instalment featured the street's residents on a coach trip to the Lake District. In the end, suitable colour film stock for the cameras could not be found and the footage was shot in black and white. The following episode, transmitted Monday 3 November, was videotaped in colour but featured black and white film inserts and title sequence. Like BBC1, the ITV network was officially broadcast in black and white at this point (though programmes were actually broadcast in colour as early as July that year for colour transmission testing and adjustment) so the episode was seen by most in black and white.

The ITV network, like BBC1, began full colour transmissions on 15 November 1969. Daran Little, for many years the official programme archivist, claims that the first episode to be transmitted in colour was episode 930 shown on 24 November 1969.

In October 1970 a technicians' dispute turned into a work-to-rule when sound staff were denied a pay rise given to camera staff the year before for working with colour recording equipment. The terms of the work-to-rule were that staff refused to work with the new equipment (though the old black and white equipment had been disposed of by then) and therefore programmes were recorded and transmitted in black and white, including "Coronation Street" The dispute was resolved in early 1971 and the last black and white episode was broadcast on 10 February 1971.

Episode 5191, originally broadcast on 7 January 2002, was the first to be broadcast in widescreen format. "Coronation Street" was the last UK-wide soap to make the switch to 16:9 ("Take the High Road" remained in until it finished in 2003).

From 22 March 2010, "Coronation Street" was produced in 1080/50i for transmission on HDTV platforms on ITV HD. The first transmission in this format was episode 7351 on 31 May 2010 with a new set of titles and re-recorded theme tune. On 26 May 2010 ITV previewed the new HD titles on the "Coronation Street" website. Due to copyright reasons only viewers residing in the UK could see them on the ITV site.

"Coronation Street's" creator, Tony Warren, wrote the first 13 episodes of the programme in 1960, and continued to write for the programme intermittently until 1976. He had retained links with "Coronation Street" up to his death in 2016, often advising on storylines.

Harry Kershaw was the script editor for "Coronation Street" when the programme began in 1960, working alongside Tony Warren. Kershaw was also a script writer for the programme and the show's producer between 1962 and 1971. He remains the only person, along with John Finch, to have held the three posts of script editor, writer and producer. Kershaw continued to write for the programme until his retirement in January 1988.

Adele Rose was the longest-serving "Coronation Street" writer, completing 455 scripts between 1961 and 1998. She also created "Byker Grove".

Bill Podmore was the show's longest serving producer. By the time he stepped down in 1988 he had completed 13 years at the production helm. Nicknamed the "godfather" by the tabloid press, he was renowned for his tough, uncompromising style and was feared by both crew and cast alike. He is probably most famous for sacking Peter Adamson, the show's Len Fairclough, in 1983.

Iain Macleod is the current series producer.

Michael Apted, best known for the "Up!" series of documentaries was a director on the programme in the early 1960s. This period of his career marked the first of his many collaborations with writer Jack Rosenthal. Rosenthal, noted for such television plays as "Bar Mitzvah Boy", began his career on the show, writing over 150 episodes between 1961 and 1969. Paul Abbott was a story editor on the programme in the 1980s and began writing episodes in 1989, but left in 1993 to produce "Cracker", for which he later wrote, before creating his own dramas such as "Touching Evil" and "Shameless". Russell T Davies was briefly a storyliner on the programme in the mid-1990s, also writing the script for the direct-to-video special "" He, too, has become a noted writer of his own high-profile television drama programmes, including "Queer as Folk" and the 2005 revival of "Doctor Who". Jimmy McGovern also wrote some episodes.

The show's theme music, a cornet piece, accompanied by a brass band plus clarinet and double bass, reminiscent of northern band music, was written by Eric Spear.

The identity of the trumpeter was not public knowledge until 1994, when jazz musician and journalist Ron Simmonds revealed that it was the Surrey musician Ronnie Hunt. He added, "an attempt was made in later years to re-record that solo, using Stan Roderick, but it sounded too good, and they reverted to the old one." In 2004, the "Manchester Evening News" published a contradictory story that a young musician from Wilmslow called David Browning played the trumpet on both the original recording of the theme in 1960 and a re-recording in 1964, for a one-off payment of £36.

A new, completely re-recorded version of the theme tune replaced the original when the series started broadcasting in HD on 31 May 2010. It accompanied a new montage-style credits sequence featuring images of Manchester and Weatherfield.

A reggae version of the theme tune was recorded by The I-Royals and released by Media Marvels and WEA in 1983.

On 31 March 2017, it was revealed on the YouTube channel of Corrie that some of the soap's cast would sing a specially-written lyric, of which will be added to the new theme song that will be played, as of the first episode of the evening of Monday, 3 April 2017, but it turned out to be an April Fools joke.

Episodes in the 1960s, 70s, and 80s, regularly attracted figures of between 18 and 21 million viewers, and during the 1990s and early 2000s, 14 to 16 million per episode would be typical. Like most terrestrial television in the UK, a decline in viewership has taken place and the show posts an average audience of just under 9 million per episode , remaining one of the highest rated programmes in the UK. Since "EastEnders" began airing in 1985 on the BBC, the two programmes have constantly battled it out for first place in the ratings.

"Coronation Street" rates as one of the most watched programmes on UK television for every day it is aired. The episode that aired on 2 January 1985, where Bet Lynch (Julie Goodyear) finds out she has got the job as manager of the Rovers Return, is the highest-rated single episode in the show's history, attracting 21.40 million viewers. 25 December 1987 episode, where Hilda Ogden (Jean Alexander) leaves the street to start a new life as a housekeeper for long-term employer Dr Lowther, attracted a combined audience of 26.65 million for its original airing and omnibus repeat on 27 December 1987. This is the second-highest combined rating in the show's history. The show attracted its highest-ever combined rating of 26.93 million for the episode that aired on 15 (and 19) March 1989, where Rita Fairclough (Barbara Knox) is in hospital and Alan Bradley (Mark Eden) is hiding from the police after trying to kill Rita in the previous episode.

The regular exterior buildings shown in "Coronation Street" include a row of terrace houses, several townhouses, and communal areas including a newsagents ("The Kabin"), a café ("Roy's Rolls"), a general grocery shop ("D&S Alahan's"), a factory ("Underworld") and "Rovers Return Inn" public house. The Rovers Return Inn is the main meeting place for the show's characters.

Between 1960 and 1968, street scenes were filmed before a set constructed in a studio, with the house fronts reduced in scale to 3/4 and constructed from wood. In 1968 Granada built an outside set not all that different from the interior version previously used, with the wooden façades from the studio simply being erected on the new site. These were replaced with brick façades, and back yards were added in the 1970s.

In 1982, a permanent full-street set was built in the Granada backlot, an area between Quay Street and Liverpool Road in Manchester. The set was constructed from reclaimed Salford brick. The set was updated in 1989 with the construction of a new factory, two shop units and three modern town houses on the south side of the street.

Between 1989 and 1999, the Granada Studios Tour allowed members of the public to visit the set. The exterior set was extended and updated in 1999. This update added to the Rosamund Street and Victoria Street façades, and added a viaduct on Rosamund Street. Most interior scenes are shot in the adjoining purpose-built studio.

In 2008, "Victoria Court", an apartment building full of luxury flats, was started on Victoria Street.

In 2014, production moved to a new site at Trafford Wharf, a former dock area about two miles to the east, part of the MediaCityUK complex. The Trafford Wharf backlot is built upon a former truck stop site next to the Imperial War Museum North. It took two years from start to finish to recreate the iconic Street. The houses were built to almost full scale after previously being three-quarter size.

On 5 April 2014, the staff began to allow booked public visits to the old Quay Street set. An advert, with a voiceover from Victoria Wood, appeared on TV to advertise the tour. The tour was discontinued in December 2015.

On 12 March 2018, the extension of the " Victoria Street" set was officially unveiled. The new set features a garden, featuring a memorial bench paying tribute to the 22 victims of the Manchester Arena bombing, including "Coronation Street" super fan Martyn Hett. The precinct includes a Greater Manchester Police station called "Weatherfield Police station". As part of a product placement deal between three companies and ITV Studios, new additions include a Tram stop station which is named "Weatherfield North" with "Transport for Greater Manchester" "Metrolink" branding, and shop front facades of Costa Coffee and the Weatherfield branded Co-op Food store interior scenes have been screened and exterior scenes at the new set first aired on 20 April 2018.
On 20 April 2018, ITV announced that they had been granted official approval of planning permission to allow booked public visits to the MediaCityUK Trafford Wharf set. Tours commenced on weekends from 26 May 2018 onwards.

For 60 years, "Coronation Street" has remained at the centre of ITV's prime time schedule. The programme is shown in the UK in six episodes, over three evenings a week on ITV. From Friday 9 December 1960 until Friday 3 March 1961, the programme was shown in two episodes broadcast Wednesday and Friday at 7 pm. Schedules were changed and from Monday 6 March 1961 until Wednesday 11 October 1989, the programme was shown in two episodes broadcast Monday and Wednesday at 7:30 pm. The third weekly episode was introduced on Friday 20 October 1989, broadcast at 7:30 pm. From 1996, an extra episode was broadcast at 7:30 pm on Sunday nights. Aside from Granada, the programme originally appeared on the following stations of the ITV network: Anglia Television, Associated-Rediffusion, Television Wales and the West, Scottish Television, Southern Television and Ulster Television. From episode 14 on Wednesday 25 January 1961, Tyne Tees Television broadcast the programme. That left ATV in the Midlands as the only ITV station not carrying the show. When they decided to broadcast the programme, national transmission was changed from Wednesday and Friday at 7 pm to Monday and Wednesday at 7:30 pm and the programme became fully networked under this new arrangement from episode 25 on Monday 6 March 1961.

As the ITV network grew over the next few years, the programme was transmitted by these new stations on these dates onward: Westward Television from episode 40 on 1 May 1961, Border Television from episode 76 on 4 September 1961, Grampian Television from episode 84 on 2 October 1961, Channel Television from episode 180 on 3 September 1962 and Teledu Cymru (north and west Wales) from episode 184 on 17 September 1962. At this point, the ITV network became complete and the programme was broadcast almost continuously across the country at 7:30 pm on Monday and Wednesday for the next twenty-seven years.

From episode 2981 on Friday 20 October 1989 at 7:30 pm, a third weekly episode was introduced and this increased to four episodes a week from episode 4096 on Sunday 24 November 1996, again at 7:30 pm. The second Monday episode was introduced in 2002 and was broadcast at 7:30 pm to usher in the return of Bet Lynch. The Monday 8:30 pm episode was used intermittently during the popular Richard Hillman story line but has become fully scheduled since episode 5568 on Monday 25 August 2003. Additional episodes have been broadcast during the weekly schedule of ITV at certain times, notably in 2004 when, between 22 and 26 November, eight episodes were shown.

Older episodes had been broadcast by satellite and cable channel Granada Plus from launch in 1996. The first episodes shown were from episode 1588 (originally transmitted on Monday 5 April 1976) onwards. Originally listed and promoted as "Classic Coronation Street", the "classic" was dropped in early 2002, at which stage the episodes were from late 1989. By the time of the channel's closure in 2004, the repeats had reached February 1994.

In addition to this, "specials" were broadcast on Saturday afternoons in the early years of the channel with several episodes based on a particular theme or character(s) were shown. The latest episode shown in these specials was from 1991. In addition, on 27 and 28 December 2003, several Christmas Day editions of the show were broadcast.

From 23 July 2009 "Coronation Street" started to be broadcast in five instalments a week, at 7:30  and 8:30 pm on Mondays and Fridays, and at 8:30 pm on Thursdays. The Thursday episode replaced the former Wednesday show. Occasional late night episodes of "Coronation Street" begin at 10 pm, due to the watershed. Repeat episodes, omnibus broadcasts and specials have been shown on ITV and ITV2. In January 2008 the omnibus returned to the main ITV channel where it was aired on Saturday mornings/afternoons depending on the schedule and times. In May 2008 it moved to Sunday mornings until August 2008 when it returned to Saturdays. In January 2009 it moved back to Sunday mornings usually broadcasting at around 9.25am until December 2010. In January 2011 the omnibus moved to Saturday mornings on ITV at 9.25am. During the Rugby World Cup, which took place in New Zealand, matches had to be broadcast on a Saturday morning, so the omnibus moved to Saturday lunchtimes/afternoons during September and October 2011. However, as of 22 October 2011 the omnibus moved back to Saturday mornings at 9.25am on ITV. From January 2012 the omnibus was no longer broadcast on ITV after four years, it stayed on ITV2 for eight years. From January 2020, the omnibus moved to ITV3.

On 30 June 2011 it was confirmed that "Coronation Street" would return to its traditional 7:30 pm timeslot on a Wednesday evening in September 2012. A sixth weekly episode aired on Wednesdays at 8:30pm from 20 September 2017. ITV also confirmed on this date that ITV3 would air afternoon timeslot sequential reruns of "Classic Coronation Street". Two classic episodes were retransmitted between Mondays to Fridays at 2:40 pm until 3:45 pm from 2 October 2017. The first episodes shown were from episode 2587 (originally transmitted on Wednesday 15 January 1986) onwards.

In March 2020, it was revealed that episodes that were currently filming for future broadcast (as episodes are filmed a few weeks in advance) during the COVID-19 pandemic would be shown differently. Instead of six episodes a week, only three episodes would be broadcast, airing as normal on a Monday, Wednesday and Friday at the normal timeslot of 7:30 pm. The actions provided will be made effective starting from Monday 30 March. Simultaneously, the announcement also mentioned that the elderly cast of the show would be "written off" due to health advice issued by Public Health England and the NHS. On 22 March, ITV released a statement confirming that filming of both "Coronation Street" and "Emmerdale" was suspended.

In June 2020 ITV announced that filming will resume on 9 June. However, due to the new health and safety measures, cast members over the age of 70 or with underlying health conditions will not come back on set, until the production can determine it is safe for them to return. The schedule of only three episodes a week will continue.

"Coronation Street" is shown in various countries worldwide. YouTube has the first episode and many others available as reruns.

The programme was first aired in Australia in 1963 on TCN-9 Sydney, GTV-9 Melbourne and NWS-9 Adelaide, and by 1966 "Coronation Street" was more popular in Australia than in the UK. The show eventually left free-to-air television in Australia in the 1970s. It briefly returned to the Nine Network in a daytime slot during 1994–1995. In 2005 STW-9 Perth began to show episodes before the 6 pm news to improve the lead in to Nine News Perth, but this did not work and the show was cancelled a few months later. In 1996 Pay-TV began and Arena began screening the series in one-hour instalments on Saturdays and Sundays at 6:30 pm EST. The series was later moved to Pay-TV channel UKTV where it is still shown. "Coronation Street" is shown Mon-Thu at 7:20 pm EST & a double episode on Fridays. Episodes on UKTV are 1 week behind UK broadcast.

In Canada, "Coronation Street" is broadcast on CBC Television. Until 2011, episodes were shown in Canada approximately 10 months after they aired in Britain; however, beginning in the fall of 2011, the CBC began showing two episodes every weekday, in order to catch up with the ITV showings, at 6:30 pm and 7 pm local time Monday-Friday, with an omnibus on Sundays at 7.30am. By May 2014, the CBC was only two weeks behind Britain, so the show was reduced to a single showing weeknights at 6:30 pm local time. The show debuted on Toronto's CBLT in July 1966. The 2002 edition of the "Guinness Book of Records" recognises the 1,144 episodes sold to the now-defunct CBC-owned Saskatoon, Saskatchewan, TV station CBKST by Granada TV on 31 May 1971 to be the largest number of TV shows ever purchased in one transaction. The show traditionally aired on weekday afternoons in Canada, with a Sunday morning omnibus. In 2004, CBC moved the weekday airings from their daytime slot to prime time. In light of austerity measures imposed on the CBC in 2012, which includes further cutbacks on non-Canadian programming, one of the foreign shows to remain on the CBC schedule is "Coronation Street", according to the CBC's director of content planning Christine Wilson, who commented: "Unofficially I can tell you "Coronation Street" is coming back. If it didn't come back, something would happen on Parliament Hill." Kirstine Stewart, the head of the CBC's English-language division, once remarked: ""Coronation Street" fans are the most loyal, except maybe for curling viewers, of all CBC viewers." In late September 2014, CBC aired extra episodes to become only one week behind the UK in airing of new episodes.

In the Republic of Ireland, "Coronation Street" aired on Virgin Media Three (formerly named Be3) for same night repeats and currently airs the Sunday omnibus from 1pm. The shows same night repeats currently air for an hour from 10:30pm on Virgin Media Two(formerly named 3e), on Monday's,Wednesday's and Friday's. The show was first aired in 1978, beginning with episodes from 1976. Ireland eventually caught up with the current UK episodes in 1983. Until 1992 it was broadcast on RTÉ2 and from 1992 to 2001 it was broadcast on RTÉ One. In 2001 Granada TV bought 45 percent of TV3, which resulted in TV3 broadcasting series from 2001 to 2014. In 2006, ITV sold its share of the channel but TV3. TV3 continued to buy the soap until the end of 2014 when it moved to UTV Ireland. Coronation Street has broadcast on each of the main Irish networks, except for the Irish language network TG4. From December 2016, "Coronation Street" returned to TV3 (now Virgin Media One). The show is consistently the channels most viewed programme every week.

In South Africa, "Coronation Street" episodes are broadcast three days after the UK air date on ITV Choice.

In New Zealand, "Coronation Street" has been shown locally since 1964, first on NZBC television until 1975, and then on TV One, which broadcasts it in a 4-episode/2-hour block on Fridays from 7:30 pm. Since September 2014, TV One has added a 2-episode/1-hour block on Saturday from 8:30 pm. Because TV One has never upgraded to showing the equivalent of five or six episodes per week, New Zealand continues to fall further and further behind with episodes, and is 23 months behind Britain (as of 28 March 2014). During the weekday nights of the week ending 11 April 2014 and previous weeks, Coronation Street was the least watched programme on TV One in the 7:30 pm slot by a considerable margin in comparison to other weeknights, The serial aired on Tuesdays and Thursdays at 7:30 pm until October 2011, when the show moved to a 5:30 pm half-hour slot every weekday. The move proved unpopular with fans, and the series was quickly moved into its present prime-time slot within weeks. Episodes 7883, 7884, 7885 and 7886 were screened on 16 May 2014. These were originally aired in the UK between 4 and 11 June 2012. On 10 May 2018 it was announced that the current 2016 episodes would be moved to 1 p.m. Monday-Friday titled 'Catch-up Episodes' and for primetime Wednesday-Friday express episodes would be airing in New Zealand a week behind The United Kingdom titled '2018 Episodes' these changes would be taking place from 11 June 2018.

In the United States, "Coronation Street" is available by broadcast or cable only in northern markets where CBC coverage from Canada overlaps the border or is available on local cable systems. It was broadcast on CBC's US cable channel, Trio until the CBC sold its stake in the channel to Universal, before it was shut down in 2006. Beginning in 2009, episodes were available in the United States through Amazon.com's on-demand service, one month behind their original UK airdates. The final series of shows available from Amazon appears to be from November 2012, as no new episodes have been uploaded. On 15 January 2013, online distributor Hulu began airing episodes of the show, posting a new episode daily, two weeks after their original airdates. For a time, Hulu's website stated: "New episodes of "Coronation Street" will be unavailable as of April 7th, 2016", with the same being said for British soap "Hollyoaks", but Hulu is once again showing new episodes of "Coronation Street" as of April 2017, two weeks behind the UK airdate. The BBC/ITV service Britbox shows new episodes on the same day as the UK airing. "Coronation Street" was also shown on USA Network for an unknown period starting in 1982.

HM Forces and their families stationed overseas can watch "Coronation Street" on ITV, carried by the British Forces Broadcasting Service, which is also available to civilians in the Falkland Islands. It used to be shown on BFBS1.

Satellite channel ITV Choice shows the programme in Asia, Middle East, Cyprus, and Malta. In the United Arab Emirates, episodes of "Coronation Street" are broadcast one month after their UK showing.

"The Street", a magazine dedicated to the show, was launched in 1989. Edited by Bill Hill, the magazine contained a summary of recent storylines, interviews, articles about classic episodes, and stories that occurred from before 1960. The format was initially A5 size, expanding to A4 from the seventh issue. The magazine folded after issue 23 in 1993 when the publisher's contract with Granada Studios Tour expired and Granada wanted to produce their own magazine.

On 25 June 2010, a video game of the show was released on Nintendo DS. The game was developed by Mindscape, and allowed players to complete tasks in the fictitious town of Weatherfield.

In 1995, to commemorate the programme's 35th anniversary, a CD titled "The Coronation Street Album" was released, featuring cover versions of modern songs and standards by contemporary cast members.

In 2010, an album featuring songs sung by cast members was released to celebrate 50 years of "Coronation Street". The album is titled "Rogues, Angels, Heroes & Fools", and was later developed into a musical.

Granada launched one spin-off in 1965, "Pardon the Expression", following the story of clothing store manager Leonard Swindley (Arthur Lowe) after he left Weatherfield. Swindley's management experience was tested when he was appointed assistant manager at a fictional department store, Dobson and Hawks. Granada produced two series of the spin-off, which ended in 1966.

In 1967, Arthur Lowe returned as Leonard Swindley in "Turn Out the Lights", a short-lived sequel to "Pardon the Expression". It ran for just one series of six episodes before it was cancelled.

From 1985 to 1988 Granada TV produced a sitcom called "The Brothers McGregor" featuring a pair of half-brothers (one black, one white) who had appeared in a single episode of "Coronation Street" as old friends of Eddie Yeats and guests at his wedding. The original actors were unavailable so the characters were recast with Paul Barber and Philip Whitchurch. The show ran for 26 episodes over four series.

In 1985, a sister series, "Albion Market" was launched. It ran for one year, with 100 episodes produced.

In 2010, several actors from the show appeared on "The Jeremy Kyle Show" as their soap characters: David Platt (Jack P. Shepherd), Nick Tilsley (Ben Price) and Tina McIntyre (Michelle Keegan). In the fictional, semi-improvised scenario, David accused Nick (his brother) and Tina (his ex-girlfriend) of sleeping together.

"Coronation Street" and rival soap opera "EastEnders" had a crossover for "Children in Need" in November 2010 called "East Street". "EastEnders" stars that visited Weatherfield include Laurie Brett as Jane Beale, Charlie G. Hawkins as Darren Miller, Kylie Babbington as Jodie Gold, Nina Wadia as Zainab Masood and John Partridge as Christian Clarke.

On 21 December 2012, "Coronation Street" produced a Text Santa special entitled "A Christmas Corrie" which featured Norris Cole in the style of Scrooge, being visited by the ghosts of dead characters. The ghosts were Mike Baldwin, Maxine Peacock, Derek Wilton and Vera Duckworth. Other special guests include Torvill and Dean, Lorraine Kelly and Sheila Reid. The episode concluded with Norris learning the error of his ways and dancing on the cobbles. The original plan for this feature was to have included Jack Duckworth, along with Vera, but actor Bill Tarmey died before filming commenced. In the end a recording of his voice was played.

"Coronation Street: Family Album" was several documentaries about various families living on the street.

"Farewell ..." was several documentaries featuring the best moments of a single character who had recently left the series—most notably, Farewell Mike (Baldwin), Farewell Vera (Duckworth), Farewell Blanche (Hunt), Farewell Jack (Duckworth), Farewell Janice (Battersby), Farewell Liz (McDonald), Farewell Becky (McDonald), and Farewell Tina (McIntyre). Most of these were broadcast on the same day as the character's final scenes in the series.

"Stars on the Street" was aired around Christmas 2009. It featured actors from the soap talking about the famous guest stars who had appeared in the series including people who were in it before they were famous.

In December 2010, ITV made a few special programmes to mark the 50th anniversary. "Coronation Street Uncovered: Live", hosted by Stephen Mulhern was shown after the episode with the tram crash was aired on ITV 2. On 7 and 9 December a countdown on the greatest Corrie moments, "Coronation Street: 50 Years, 50 Moments", the viewers voted "The Barlows at Alcoholics Anonymous" as the greatest moment. On 10 December Paul O'Grady hosted a quiz show, "Coronation Street: The Big 50" with three teams from the soap and a celebrity team answering questions about Coronation Street and other soaps. Also, "Come Dine with Me" and "Celebrity Juice" aired Coronation Street specials in the anniversary week.

The German TV series "Lindenstraße" took "Coronation Street" as the model. "Lindenstraße" started in 1985 and broadcast its final episode on 29 March 2020, after airing for nearly 35 years.

Over the years "Coronation Street" has released several straight-to-video films. Unlike other soaps which often used straight-to-video films to cover more contentious plot lines that may not be allowed by the broadcaster, "Coronation Street" has largely used these films to reset their characters in other locations.

In 1995, "Coronation Street: The Cruise" also known as "Coronation Street: The Feature Length Special" was released on VHS to celebrate the 35th anniversary of the show, featuring Rita Sullivan, Mavis Wilton, Alec Gilroy, Curly Watts and Raquel Watts. ITV heavily promoted the programme as a direct-to-video exclusive but broadcast a brief version of it on 24 March 1996. The Independent Television Commission investigated the broadcast, as viewers complained that ITV misled them.

In 1997, following the controversial cruise spin-off, "Coronation Street: Viva Las Vegas!" was released on VHS, featuring Vera Duckworth, Jack Duckworth, Fiona Middleton and Maxine Peacock on a trip to Las Vegas, which included the temporary return of Ray Langton.

In 1999, six special episodes of "Coronation Street" were produced, following the story of Steve McDonald and Vikram Desai in Brighton, which included the temporary returns of, Bet Gilroy, Reg Holdsworth and Vicky McDonald. This video was titled "Coronation Street: Open All Hours" and released on VHS.

In 2008, ITV announced filming was to get underway for a new special DVD episode, "", featuring Kirk Sutherland, Fiz Brown, Chesney Brown, which included the temporary return of Cilla Battersby-Brown. Sophie Webster, Becky Granger and Tina McIntyre also make brief appearances. 

In 2009, another DVD special, "", was released. The feature-length comedy drama followed Roy, Hayley and Becky as they travelled to Romania for the wedding of a face from their past. Eddie Windass also briefly appears. 

The BBC commissioned a one-off drama called "The Road to Coronation Street", about how the series first came into being. Jessie Wallace plays Pat Phoenix (Elsie Tanner) with Lynda Baron as Violet Carson (Ena Sharples), Celia Imrie as Doris Speed (Annie Walker) and James Roache as his own father William Roache (Ken Barlow). It was broadcast on 16 September 2010 on BBC Four.

On 1 November 2010, "Coronation Street: A Knight's Tale" was released. Reg Holdsworth and Curly Watts returned in the film. Mary tries to take Norris to an apparently haunted castle where she hoped to seduce him. Rosie gets a job there and she takes Jason with her. Brian Capron also guest starred as an assumed relative of Richard Hillman. He rises out of a lake with a comedic "wink to the audience" after Hillman drowned in 2003. Rita Sullivan also briefly appears.

A feature-length film is planned for a 2020 release in order to tie with the show's 60th anniversary.

On 21 December 2008, a web-based miniseries ran on ITV.com; called "Corrie Confidential"; the first episode featured the characters Rosie and Sophie Webster in "Underworld".

ITV.com launched a small spin-off drama series called 'Gary's Army Diaries' which revolves around Gary Windass's experiences in Afghanistan and the loss of his best friend, Quinny. Due to their popularity, the three five-minute episodes were recut into a single 30-minute episode, which was broadcast on ITV2.

William Roache and Anne Kirkbride starred as Ken and Deirdre in a series of ten three-minute internet 'webisodes'. The first episode of the series titled, "Ken and Deirdre's Bedtime Stories" was activated on Valentine's Day 2011.

In 2011, an internet based spin-off starring Helen Flanagan as Rosie Webster followed her on her quest to be a supermodel.

On 3 February 2014, another web-based miniseries ran on ITV.com; called "Streetcar Stories". It showed what Steve and Lloyd get up to during the late nights in their Streetcar cab office. The first episode shows Steve and Lloyd making a cup of tea with "The Stripper" playing in the background, referencing Morecambe and Wise's Breakfast Sketch. The second episode involves the pair having a biscuit dunking competition.

During the 'Who Attacked Ken' storyline, a mini series of police files was run on the official Coronation Street YouTube channel. They outlined the suspects' details and possible motives.

In August 2010, many "Coronation Street" characters were brought to the stage in Jonathan Harvey's comedy play "Corrie!". The play was commissioned to celebrate the 50th Anniversary of the TV series and was presented at The Lowry in Salford, England by ITV Studios and Phil McIntyre Entertainments. Featuring a cast of six actors who alternate roles of favourite characters including Ena Sharples, Hilda Ogden, Hayley and Roy, Richard Hillman, Jack and Vera, Bet Lynch, Steve, Karen and Becky, the play weaves together some of the most memorable moments from the TV show. It toured UK theatres between February 2011 and July 2011 with guest star narrators including Roy Barraclough, Ken Morley and Gaynor Faye.

The British rock band Queen produced a single "I Want to Break Free" in 1984 which reached number 3 position in UK charts and which is largely known for its music video for which all the band members dressed in women's clothes, which parodied the characters and is considered an homage to the show. The video depicts Mercury as a housewife, loosely based on Bet Lynch, who wants to "break free" from his life. Although Lynch was a blonde in the soap opera, Mercury thought he would look too silly as a blonde and chose a dark wig. May plays another, more relaxed housewife based on Hilda Ogden.

As an April Fools' Day joke in 2019, TheJournal.ie claimed that Leader of the Opposition and Labour Jeremy Corbyn had made an attempt to appear in an episode of "Coronation Street" in response to Prime Minister Theresa May's supposed appearance in a special live episode, where she was to issue a final plea for unity on Brexit. In the joke, Corbyn's plan had not come to fruition, with members of "Coronation Street"'s crew deeming his request inappropriate in light of the devastation already wreaked upon the soap opera's characters following its most recent knicker factory tragedy.

Cadbury was the first sponsor of "Coronation Street" beginning in July 1996. In the summer of 2006, Cadbury Trebor Bassetts had to recall over one million chocolate bars, due to suspected salmonella contamination, and "Coronation Street" stopped the sponsorship for several months. In 2006, Cadbury did not renew their contract, but agreed to sponsor the show until "Coronation Street" found a new sponsor.

In July 2007, an ITV press release announced that Harveys was the new sponsor of "Coronation Street" on the ITV Network. Harveys' sponsorship began on 30 September 2007. In the "Coronation Street: Romanian Holiday" film, Roy and Hayley Cropper are filmed in front of a Harveys store. In "Coronation Street: A Knights Tale", a Harveys truck can be seen driving past Mary Taylor's motorhome to further endorse the brand. On 11 April 2012, it was announced that Harveys had decided not to renew their contract and ceased sponsorship in December 2012. Compare The Market were named as the new sponsor, and in 2022 will become "Coronation Street"’s longest-lasting sponsor.

In November 2011, a Nationwide Building Society ATM in Dev Alahan's corner shop became the first use of paid-for product placement in a UK primetime show. In 2018, the shop fronts of Co-Op and Costa Coffee were added to the sets, along with characters using shopping bags with the respective logos on as props.

Hyundai are the current sponsor since January 2015 in the Republic of Ireland, aired on Virgin Media One.

"Coronation Street" is the second most award-winning British soap opera in the UK, behind rival soap "EastEnders" and just ahead of "Emmerdale".





</doc>
<doc id="6852" url="https://en.wikipedia.org/wiki?curid=6852" title="Caligula">
Caligula

Caligula (; 31 August 12 – 24 January 41), formally known as Gaius (Gaius Caesar Augustus Germanicus), was the third Roman emperor, ruling from AD 37 to 41. The son of the popular Roman general Germanicus and Augustus's granddaughter Agrippina the Elder, Caligula was born into the first ruling family of the Roman Empire, conventionally known as the Julio-Claudian dynasty. Germanicus's uncle and adoptive father, Tiberius, succeeded Augustus as emperor of Rome in AD14.

Although he was named after Gaius Julius Caesar, he acquired the nickname "Caligula" (meaning "little [soldier's] boot") from his father's soldiers during their campaign in Germania. When Germanicus died at Antioch in 19, Agrippina returned with her six children to Rome, where she became entangled in a bitter feud with Tiberius. The conflict eventually led to the destruction of her family, with Caligula as the sole male survivor. Untouched by the deadly intrigues, Caligula accepted an invitation in 31 to join the emperor on the island of Capri, where Tiberius had withdrawn five years earlier. Following the death of Tiberius, Caligula succeeded his adoptive grandfather as emperor in 37.

There are few surviving sources about the reign of Caligula, though he is described as a noble and moderate emperor during the first six months of his rule. After this, the sources focus upon his cruelty, sadism, extravagance, and sexual perversion, presenting him as an insane tyrant. While the reliability of these sources is questionable, it is known that during his brief reign, Caligula worked to increase the unconstrained personal power of the emperor, as opposed to countervailing powers within the principate. He directed much of his attention to ambitious construction projects and luxurious dwellings for himself, and initiated the construction of two aqueducts in Rome: the Aqua Claudia and the Anio Novus. During his reign, the empire annexed the client kingdom of Mauretania as a province.

In early 41, Caligula was assassinated as a result of a conspiracy by officers of the Praetorian Guard, senators, and courtiers. The conspirators' attempt to use the opportunity to restore the Roman Republic was thwarted, however. On the day of the assassination of Caligula, the Praetorians declared Caligula's uncle, Claudius, the next Roman emperor. Although the Julio-Claudian dynasty continued to rule the empire until the fall of his nephew Nero in 68, Caligula's death marked the official end of the Julii Caesares in the male line.

Gaius Julius Caesar (named in honour of his famous relative) was born in Antium (modern Anzio and Nettuno) on 31 August 12 AD, the third of six surviving children born to Germanicus and his second cousin Agrippina the Elder. Gaius had two older brothers, Nero and Drusus, as well as three younger sisters, Agrippina the Younger, Julia Drusilla and Julia Livilla. He was also a nephew of Claudius, Germanicus' younger brother and the future emperor.

Agrippina the Elder was the daughter of Marcus Vipsanius Agrippa and Julia the Elder. She was a granddaughter of Augustus and Scribonia on her mother's side. Through Agrippina, Augustus was the maternal great-grandfather of Gaius.

As a boy of just two or three, Gaius accompanied his father, Germanicus, on campaigns in the north of Germania. The soldiers were amused that Gaius was dressed in a miniature soldier's outfit, including boots and armour. He was soon given an affectionate nickname, "Caligula", meaning "little (soldier's) boot" in Latin, after the small boots (caligae) he wore. Gaius, though, reportedly grew to dislike this nickname.

Suetonius claims that Germanicus was poisoned in Syria by an agent of Tiberius, who viewed Germanicus as a political rival.

After the death of his father, Caligula lived with his mother until her relations with Tiberius deteriorated. Tiberius would not allow Agrippina to remarry for fear her husband would be a rival. Agrippina and Caligula's brother, Nero, were banished in 29 on charges of treason.

The adolescent Caligula was then sent to live with his great-grandmother (and Tiberius's mother) Livia. After her death, he was sent to live with his grandmother Antonia Minor. In 30, his brother, Drusus Caesar, was imprisoned on charges of treason and his brother Nero died in exile from either starvation or suicide. Suetonius writes that after the banishment of his mother and brothers, Caligula and his sisters were nothing more than prisoners of Tiberius under the close watch of soldiers.

In 31, Caligula was remanded to the personal care of Tiberius on Capri, where he lived for six years. To the surprise of many, Caligula was spared by Tiberius. According to historians, Caligula was an excellent natural actor and, recognizing danger, hid all his resentment towards Tiberius. An observer said of Caligula, "Never was there a better servant or a worse master!"

Caligula claimed to have planned to kill Tiberius with a dagger to avenge his mother and brother: however, having brought the weapon into Tiberius's bedroom he did not kill the Emperor but instead threw the dagger down on the floor. Supposedly Tiberius knew of this but never dared to do anything about it. Suetonius claims that Caligula was already cruel and vicious: he writes that, when Tiberius brought Caligula to Capri, his purpose was to allow Caligula to live in order that he "prove the ruin of himself and of all men, and that he was rearing a viper for the Roman people and a Phaethon for the world."

In 33, Tiberius gave Caligula an honorary quaestorship, a position he held until his rise to emperor. Meanwhile, both Caligula's mother and his brother Drusus died in prison. Caligula was briefly married to Junia Claudilla in 33, though she died in childbirth the following year. Caligula spent time befriending the Praetorian prefect, Naevius Sutorius Macro, an important ally. Macro spoke well of Caligula to Tiberius, attempting to quell any ill will or suspicion the Emperor felt towards Caligula.

In 35, Caligula was named joint heir to Tiberius's estate along with Tiberius Gemellus.

When Tiberius died on 16 March 37 AD, his estate and the titles of the principate were left to Caligula and Tiberius's own grandson, Gemellus, who were to serve as joint heirs. Although Tiberius was 77 and on his death bed, some ancient historians still conjecture that he was murdered. Tacitus writes that the Praetorian Prefect, Macro, smothered Tiberius with a pillow to hasten Caligula's accession, much to the joy of the Roman people, while Suetonius writes that Caligula may have carried out the killing, though this is not recorded by any other ancient historian. Seneca the Elder and Philo, who both wrote during Tiberius's reign, as well as Josephus, record Tiberius as dying a natural death. Backed by Macro, Caligula had Tiberius's will nullified with regard to Gemellus on grounds of insanity, but otherwise carried out Tiberius's wishes.
Caligula accepted the powers of the principate as conferred by the Senate and entered Rome on 28 March amid a crowd that hailed him as "our baby" and "our star", among other nicknames. Caligula is described as the first emperor who was admired by everyone in "all the world, from the rising to the setting sun." Caligula was loved by many for being the beloved son of the popular Germanicus, and because he was not Tiberius. Suetonius said that over 160,000 animals were sacrificed during three months of public rejoicing to usher in the new reign. Philo describes the first seven months of Caligula's reign as completely blissful.

Caligula's first acts were said to be generous in spirit, though many were political in nature. To gain support, he granted bonuses to the military, including the Praetorian Guard, city troops and the army outside Italy. He destroyed Tiberius's treason papers, declared that treason trials were a thing of the past, and recalled those who had been sent into exile. He helped those who had been harmed by the imperial tax system, banished certain sexual deviants, and put on lavish spectacles for the public, including gladiatorial games. Caligula collected and brought back the bones of his mother and of his brothers and deposited their remains in the tomb of Augustus.

In October 37, Caligula fell seriously ill, or perhaps was poisoned. He soon recovered from his illness, but many believed that the illness turned the young emperor toward the diabolical: he started to kill off or exile those who were close to him or whom he saw as a serious threat. Perhaps his illness reminded him of his mortality and of the desire of others to advance into his place. He had his cousin and adopted son Tiberius Gemellus executed – an act that outraged Caligula's and Gemellus's mutual grandmother Antonia Minor. She is said to have committed suicide, although Suetonius hints that Caligula actually poisoned her. He had his father-in-law Marcus Junius Silanus and his brother-in-law Marcus Lepidus executed as well. His uncle Claudius was spared only because Caligula preferred to keep him as a laughing stock. His favourite sister Julia Drusilla died in 38 of a fever: his other two sisters, Livilla and Agrippina the Younger, were exiled. He hated being the grandson of Agrippa and slandered Augustus by repeating a falsehood that his mother was actually conceived as the result of an incestuous relationship between Augustus and his daughter Julia the Elder.

In 38, Caligula focused his attention on political and public reform. He published the accounts of public funds, which had not been made public during the reign of Tiberius. He aided those who lost property in fires, abolished certain taxes, and gave out prizes to the public at gymnastic events. He allowed new members into the equestrian and senatorial orders.

Perhaps most significantly, he restored the practice of democratic elections. Cassius Dio said that this act "though delighting the rabble, grieved the sensible, who stopped to reflect, that if the offices should fall once more into the hands of the many ... many disasters would result".

During the same year, though, Caligula was criticized for executing people without full trials and for forcing the Praetorian prefect, Macro, to commit suicide. Macro had fallen out of favor with the emperor, probably due to an attempt to ally himself with Gemellus when it appeared that Caligula might die of fever.

According to Cassius Dio, a financial crisis emerged in 39. Suetonius places the beginning of this crisis in 38. Caligula's political payments for support, generosity and extravagance had exhausted the state's treasury. Ancient historians state that Caligula began falsely accusing, fining and even killing individuals for the purpose of seizing their estates.

Historians describe a number of Caligula's other desperate measures. To gain funds, Caligula asked the public to lend the state money. He levied taxes on lawsuits, weddings and prostitution. Caligula began auctioning the lives of the gladiators at shows. Wills that left items to Tiberius were reinterpreted to leave the items instead to Caligula. Centurions who had acquired property by plunder were forced to turn over spoils to the state.

The current and past highway commissioners were accused of incompetence and embezzlement and forced to repay money. According to Suetonius, in the first year of Caligula's reign he squandered 2.7 billion sesterces that Tiberius had amassed. His nephew Nero Caesar both envied and admired the fact that Gaius had run through the vast wealth Tiberius had left him in so short a time.

However, some historians have shown scepticism towards the large number of sesterces quoted by Suetonius and Dio. According to Wilkinson, Caligula's use of precious metals to mint coins throughout his principate indicates that the treasury most likely never fell into bankruptcy. He does point out, however, that it is difficult to ascertain whether the purported 'squandered wealth' was from the treasury alone due to the blurring of "the division between the private wealth of the emperor and his income as head of state." Furthermore, Alston points out that Caligula's successor, Claudius, was able to donate 15,000 sesterces to each member of the praetorian guard in 41, suggesting the Roman treasury was solvent.
A brief famine of unknown extent occurred, perhaps caused by this financial crisis, but Suetonius claims it resulted from Caligula's seizure of public carriages; according to Seneca, grain imports were disrupted because Caligula re-purposed grain boats for a pontoon bridge.

Despite financial difficulties, Caligula embarked on a number of construction projects during his reign. Some were for the public good, though others were for himself.

Josephus describes Caligula's improvements to the harbours at Rhegium and Sicily, allowing increased grain imports from Egypt, as his greatest contributions. These improvements may have been in response to the famine.

Caligula completed the temple of Augustus and the theatre of Pompey and began an amphitheatre beside the Saepta. He expanded the imperial palace. He began the aqueducts Aqua Claudia and Anio Novus, which Pliny the Elder considered engineering marvels. He built a large racetrack known as the "circus of Gaius and Nero" and had an Egyptian obelisk (now known as the "Vatican Obelisk") transported by sea and erected in the middle of Rome.

At Syracuse, he repaired the city walls and the temples of the gods. He had new roads built and pushed to keep roads in good condition. He had planned to rebuild the palace of Polycrates at Samos, to finish the temple of Didymaean Apollo at Ephesus and to found a city high up in the Alps. He planned to dig a canal through the Isthmus of Corinth in Greece and sent a chief centurion to survey the work.
In 39, Caligula performed a spectacular stunt by ordering a temporary floating bridge to be built using ships as pontoons, stretching for over two miles from the resort of Baiae to the neighbouring port of Puteoli. It was said that the bridge was to rival the Persian king Xerxes' pontoon bridge crossing of the Hellespont. Caligula, who could not swim, then proceeded to ride his favourite horse Incitatus across, wearing the breastplate of Alexander the Great. This act was in defiance of a prediction by Tiberius's soothsayer Thrasyllus of Mendes that Caligula had "no more chance of becoming emperor than of riding a horse across the Bay of Baiae".

Caligula had two large ships constructed for himself (which were recovered from the bottom of Lake Nemi around 1930). The ships were among the largest vessels in the ancient world. The smaller ship was designed as a temple dedicated to Diana. The larger ship was essentially an elaborate floating palace with marble floors and plumbing. The ships burned in 1944 after an attack in the Second World War; almost nothing remains of their hulls, though many archaeological treasures remain intact in the museum at Lake Nemi and in the Museo Nazionale Romano (Palazzo Massimo) at Rome.

In 39, relations between Caligula and the Roman Senate deteriorated. The subject of their disagreement is unknown. A number of factors, though, aggravated this feud. The Senate had become accustomed to ruling without an emperor between the departure of Tiberius for Capri in 26 and Caligula's accession. Additionally, Tiberius' treason trials had eliminated a number of pro-Julian senators such as Asinius Gallus.

Caligula reviewed Tiberius' records of treason trials and decided, based on their actions during these trials, that numerous senators were not trustworthy. He ordered a new set of investigations and trials. He replaced the consul and had several senators put to death. Suetonius reports that other senators were degraded by being forced to wait on him and run beside his chariot.

Soon after his break with the Senate, Caligula faced a number of additional conspiracies against him. A conspiracy involving his brother-in-law was foiled in late 39. Soon afterwards, the Governor of Germany, Gnaeus Cornelius Lentulus Gaetulicus, was executed for connections to a conspiracy.

In 40, Caligula expanded the Roman Empire into Mauretania and made a significant attempt at expanding into Britannia – even challenging Neptune in his campaign. The conquest of Britannia was later achieved during the reign of his successor, Claudius.

Mauretania was a client kingdom of Rome ruled by Ptolemy of Mauretania. Caligula invited Ptolemy to Rome and then suddenly had him executed. Mauretania was annexed by Caligula and subsequently divided into two provinces, Mauretania Tingitana and Mauretania Caesariensis, separated by the river Malua. Pliny claims that division was the work of Caligula, but Dio states that in 42 an uprising took place, which was subdued by Gaius Suetonius Paulinus and Gnaeus Hosidius Geta, and the division only took place after this. This confusion might mean that Caligula decided to divide the province, but the division was postponed because of the rebellion. The first known equestrian governor of the two provinces was Marcus Fadius Celer Flavianus, in office in 44.

Details on the Mauretanian events of 39–44 are unclear. Cassius Dio wrote an entire chapter on the annexation of Mauretania by Caligula, but it is now lost. Caligula's move seemingly had a strictly personal political motive – fear and jealousy of his cousin Ptolemy – and thus the expansion may not have been prompted by pressing military or economic needs. However, the rebellion of Tacfarinas had shown how exposed Africa Proconsularis was to its west and how the Mauretanian client kings were unable to provide protection to the province, and it is thus possible that Caligula's expansion was a prudent response to potential future threats.

There seems to have been a northern campaign to Britannia that was aborted. This campaign is derided by ancient historians with accounts of Gauls dressed up as Germanic tribesmen at his triumph and Roman troops ordered to collect seashells as "spoils of the sea". The few primary sources disagree on what precisely occurred. Modern historians have put forward numerous theories in an attempt to explain these actions. This trip to the English Channel could have merely been a training and scouting mission. The mission may have been to accept the surrender of the British chieftain Adminius. "Seashells", or "conchae" in Latin, may be a metaphor for something else such as female genitalia (perhaps the troops visited brothels) or boats (perhaps they captured several small British boats).

When several client kings came to Rome to pay their respects to him and argued about their nobility of descent, he allegedly cried out the Homeric line: "Let there be one lord, one king." In 40, Caligula began implementing very controversial policies that introduced religion into his political role. Caligula began appearing in public dressed as various gods and demigods such as Hercules, Mercury, Venus and Apollo. Reportedly, he began referring to himself as a god when meeting with politicians and he was referred to as "Jupiter" on occasion in public documents.

A sacred precinct was set apart for his worship at Miletus in the province of Asia and two temples were erected for worship of him in Rome. The Temple of Castor and Pollux on the forum was linked directly to the imperial residence on the Palatine and dedicated to Caligula. He would appear there on occasion and present himself as a god to the public. Caligula had the heads removed from various statues of gods located across Rome and replaced them with his own. It is said that he wished to be worshipped as "Neos Helios", the "New Sun". Indeed, he was represented as a sun god on Egyptian coins.

Caligula's religious policy was a departure from that of his predecessors. According to Cassius Dio, living emperors could be worshipped as divine in the east and dead emperors could be worshipped as divine in Rome. Augustus had the public worship his spirit on occasion, but Dio describes this as an extreme act that emperors generally shied away from. Caligula took things a step further and had those in Rome, including senators, worship him as a tangible, living god.

Caligula needed to quell several riots and conspiracies in the eastern territories during his reign. Aiding him in his actions was his good friend, Herod Agrippa, who became governor of the territories of Batanaea and Trachonitis after Caligula became emperor in 37.

The cause of tensions in the east was complicated, involving the spread of Greek culture, Roman Law and the rights of Jews in the empire.

Caligula did not trust the prefect of Egypt, Aulus Avilius Flaccus. Flaccus had been loyal to Tiberius, had conspired against Caligula's mother and had connections with Egyptian separatists. In 38, Caligula sent Agrippa to Alexandria unannounced to check on Flaccus. According to Philo, the visit was met with jeers from the Greek population who saw Agrippa as the king of the Jews. Flaccus tried to placate both the Greek population and Caligula by having statues of the emperor placed in Jewish synagogues. As a result, riots broke out in the city. Caligula responded by removing Flaccus from his position and executing him.

In 39, Agrippa accused Herod Antipas, the tetrarch of Galilee and Perea, of planning a rebellion against Roman rule with the help of Parthia. Herod Antipas confessed and Caligula exiled him. Agrippa was rewarded with his territories.

Riots again erupted in Alexandria in 40 between Jews and Greeks. Jews were accused of not honouring the emperor. Disputes occurred in the city of Jamnia. Jews were angered by the erection of a clay altar and destroyed it. In response, Caligula ordered the erection of a statue of himself in the Jewish Temple of Jerusalem, a demand in conflict with Jewish monotheism. In this context, Philo wrote that Caligula "regarded the Jews with most especial suspicion, as if they were the only persons who cherished wishes opposed to his".

The Governor of Syria, Publius Petronius, fearing civil war if the order were carried out, delayed implementing it for nearly a year. Agrippa finally convinced Caligula to reverse the order. However, Caligula issued a second order to have his statue erected in the Temple of Jerusalem. In Rome, another statue of himself, of colossal size, was made of gilt brass for the purpose. The Temple of Jerusalem was then transformed into a temple for Caligula, and it was called the Temple of Illustrious Gaius the New Jupiter.

Philo of Alexandria and Seneca the Younger, contemporaries of Caligula, describe him as an insane emperor who was self-absorbed, short-tempered, killed on a whim, and indulged in too much spending and sex. He is accused of sleeping with other men's wives and bragging about it, killing for mere amusement, deliberately wasting money on his bridge, causing starvation, and wanting a statue of himself in the Temple of Jerusalem for his worship. Once, at some games at which he was presiding, he was said to have ordered his guards to throw an entire section of the audience into the arena during the intermission to be eaten by the wild beasts because there were no prisoners to be used and he was bored.

While repeating the earlier stories, the later sources of Suetonius and Cassius Dio provide additional tales of insanity. They accuse Caligula of incest with his sisters, Agrippina the Younger, Drusilla, and Livilla, and say he prostituted them to other men. They state he sent troops on illogical military exercises, turned the palace into a brothel, and, most famously, planned or promised to make his horse, Incitatus, a consul,
and actually appointed him a priest.

The validity of these accounts is debatable. In Roman political culture, insanity and sexual perversity were often presented hand-in-hand with poor government.

Caligula's actions as emperor were described as being especially harsh to the Senate, to the nobility and to the equestrian order. According to Josephus, these actions led to several failed conspiracies against Caligula. Eventually, officers within the Praetorian Guard led by Cassius Chaerea succeeded in murdering the emperor. The plot is described as having been planned by three men, but many in the senate, army and equestrian order were said to have been informed of it and involved in it.

The situation had escalated when, in 40, Caligula announced to the Senate that he planned to leave Rome permanently and to move to Alexandria in Egypt, where he hoped to be worshipped as a living god. The prospect of Rome losing its emperor and thus its political power was the final straw for many. Such a move would have left both the Senate and the Praetorian Guard powerless to stop Caligula's repression and debauchery. With this in mind Chaerea convinced his fellow conspirators, who included Marcus Vinicius and Lucius Annius Vinicianus, to put their plot into action quickly.

According to Josephus, Chaerea had political motivations for the assassination. Suetonius sees the motive in Caligula calling Chaerea derogatory names. Caligula considered Chaerea effeminate because of a weak voice and for not being firm with tax collection. Caligula would mock Chaerea with names like "Priapus" and "Venus".

On 22 January 41 (Suetonius gives the date as 24 January), Cassius Chaerea and other guardsmen accosted Caligula as he addressed an acting troupe of young men beneath the palace, during a series of games and dramatics being held for the Divine Augustus. Details recorded on the events vary somewhat from source to source, but they agree that Chaerea stabbed Caligula first, followed by a number of conspirators. Suetonius records that Caligula's death resembled that of Julius Caesar. He states that both the elder Gaius Julius Caesar (Julius Caesar) and the younger Gaius Julius Caesar (Caligula) were stabbed 30 times by conspirators led by a man named Cassius (Cassius Longinus and Cassius Chaerea). By the time Caligula's loyal Germanic guard responded, the Emperor was already dead. The Germanic guard, stricken with grief and rage, responded with a rampaging attack on the assassins, conspirators, innocent senators and bystanders alike. These wounded conspirators were treated by the physician Arcyon.

The "cryptoporticus" (underground corridor) beneath the imperial palaces on the Palatine Hill where this event took place was discovered by archaeologists in 2008.

The senate attempted to use Caligula's death as an opportunity to restore the Republic. Chaerea tried to persuade the military to support the Senate. The military, though, remained loyal to the idea of imperial monarchy. The grieving Roman people assembled and demanded that Caligula's murderers be brought to justice. Uncomfortable with lingering imperial support, the assassins sought out and killed Caligula's wife, Caesonia, and killed their young daughter, Julia Drusilla, by smashing her head against a wall. They were unable to reach Caligula's uncle, Claudius. After a soldier, Gratus, found Claudius hiding behind a palace curtain, he was spirited out of the city by a sympathetic faction of the Praetorian Guard to their nearby camp.

Claudius became emperor after procuring the support of the Praetorian Guard. He ordered the execution of Chaerea and of any other known conspirators involved in the death of Caligula.
According to Suetonius, Caligula's body was placed under turf until it was burned and entombed by his sisters. He was buried within the Mausoleum of Augustus; in 410, during the Sack of Rome, the ashes in the tomb were scattered.

The facts and circumstances of Caligula's reign are mostly lost to history. Only two sources contemporary with Caligula have survived – the works of Philo and Seneca. Philo's works, "On the Embassy to Gaius" and "Flaccus", give some details on Caligula's early reign, but mostly focus on events surrounding the Jewish population in Judea and Egypt with whom he sympathizes. Seneca's various works give mostly scattered anecdotes on Caligula's personality. Seneca was almost put to death by Caligula in AD 39 likely due to his associations with conspirators.

At one time, there were detailed contemporaneous histories on Caligula, but they are now lost. Additionally, the historians who wrote them are described as biased, either overly critical or praising of Caligula. Nonetheless, these lost primary sources, along with the works of Seneca and Philo, were the basis of surviving secondary and tertiary histories on Caligula written by the next generations of historians. A few of the contemporaneous historians are known by name. Fabius Rusticus and Cluvius Rufus both wrote condemning histories on Caligula that are now lost. Fabius Rusticus was a friend of Seneca who was known for historical embellishment and misrepresentation. Cluvius Rufus was a senator involved in the assassination of Caligula.

Caligula's sister, Agrippina the Younger, wrote an autobiography that certainly included a detailed explanation of Caligula's reign, but it too is lost. Agrippina was banished by Caligula for her connection to Marcus Lepidus, who conspired against him. The inheritance of Nero, Agrippina's son and the future emperor, was seized by Caligula. Gaetulicus, a poet, produced a number of flattering writings about Caligula, but they are lost.

The bulk of what is known of Caligula comes from Suetonius and Cassius Dio. Suetonius wrote his history on Caligula 80 years after his death, while Cassius Dio wrote his history over 180 years after Caligula's death. Cassius Dio's work is invaluable because it alone gives a loose chronology of Caligula's reign.

A handful of other sources add a limited perspective on Caligula. Josephus gives a detailed description of Caligula's assassination. Tacitus provides some information on Caligula's life under Tiberius. In a now lost portion of his "Annals", Tacitus gave a detailed history of Caligula. Pliny the Elder's "Natural History" has a few brief references to Caligula.

There are few surviving sources on Caligula and none of them paints Caligula in a favourable light. The paucity of sources has resulted in significant gaps in modern knowledge of the reign of Caligula. Little is written on the first two years of Caligula's reign. Additionally, there are only limited details on later significant events, such as the annexation of Mauretania, Caligula's military actions in Britannia, and his feud with the Roman Senate. According to legend, during his military actions in Britannia Caligula grew addicted to a steady diet of European sea eels, which led to their Latin name being "Coluber caligulensis". 

All surviving sources, except Pliny the Elder, characterize Caligula as insane. However, it is not known whether they are speaking figuratively or literally. Additionally, given Caligula's unpopularity among the surviving sources, it is difficult to separate fact from fiction. Recent sources are divided in attempting to ascribe a medical reason for his behavior, citing as possibilities encephalitis, epilepsy or meningitis. The question of whether or not Caligula was insane (especially after his illness early in his reign) remains unanswered.

Philo of Alexandria, Josephus and Seneca state that Caligula was insane, but describe this madness as a personality trait that came through experience. Seneca states that Caligula became arrogant, angry and insulting once he became emperor and uses his personality flaws as examples his readers can learn from. According to Josephus, power made Caligula incredibly conceited and led him to think he was a god. Philo of Alexandria reports that Caligula became ruthless after nearly dying of an illness in the eighth month of his reign in 37. Juvenal reports he was given a magic potion that drove him insane.

Suetonius said that Caligula suffered from "falling sickness", or epilepsy, when he was young. Modern historians have theorized that Caligula lived with a daily fear of seizures. Despite swimming being a part of imperial education, Caligula could not swim. Epileptics are discouraged from swimming in open waters because unexpected fits in such difficult rescue circumstances can be fatal. Caligula reportedly talked to the full moon: Epilepsy was long associated with the moon.

Suetonius described Caligula as sickly-looking, skinny and pale: "he was tall, very pale, ill-shaped, his neck and legs very slender, his eyes and temples hollow, his brows broad and knit, his hair thin, and the crown of the head bald. The other parts of his body were much covered with hair ... He was crazy both in body and mind, being subject, when a boy, to the falling sickness. When he arrived at the age of manhood he endured fatigue tolerably well. Occasionally he was liable to faintness, during which he remained incapable of any effort". Based on scientific reconstructions of his official painted busts, Caligula had brown hair, brown eyes, and fair skin.

Some modern historians think that Caligula suffered from hyperthyroidism. This diagnosis is mainly attributed to Caligula's irritability and his "stare" as described by Pliny the Elder.

On 17 January 2011, police in Nemi, Italy, announced that they believed they had discovered the site of Caligula's burial, after arresting a thief caught smuggling a statue which they believed to be of the emperor. The claim has been met with scepticism by Cambridge historian Mary Beard.







 


</doc>
<doc id="6854" url="https://en.wikipedia.org/wiki?curid=6854" title="Church–Turing thesis">
Church–Turing thesis

In computability theory, the Church–Turing thesis (also known as computability thesis, the Turing–Church thesis, the Church–Turing conjecture, Church's thesis, Church's conjecture, and Turing's thesis) is a hypothesis about the nature of computable functions. It states that a function on the natural numbers can be calculated by an effective method if and only if it is computable by a Turing machine. The thesis is named after American mathematician Alonzo Church and the British mathematician Alan Turing. Before the precise definition of computable function, mathematicians often used the informal term effectively calculable to describe functions that are computable by paper-and-pencil methods. In the 1930s, several independent attempts were made to formalize the notion of computability:


Church and Turing proved that these three formally defined classes of computable functions coincide: a function is λ-computable if and only if it is Turing computable, and if and only if it is "general recursive". This has led mathematicians and computer scientists to believe that the concept of computability is accurately characterized by these three equivalent processes. Other formal attempts to characterize computability have subsequently strengthened this belief (see below).

On the other hand, the Church–Turing thesis states that the above three formally-defined classes of computable functions coincide with the "informal" notion of an effectively calculable function. Since, as an informal notion, the concept of effective calculability does not have a formal definition, the thesis, although it has near-universal acceptance, cannot be formally proven.

Since its inception, variations on the original thesis have arisen, including statements about what can physically be realized by a computer in our universe (physical Church-Turing thesis) and what can be efficiently computed (Church–Turing thesis (complexity theory)). These variations are not due to Church or Turing, but arise from later work in complexity theory and digital physics. The thesis also has implications for the philosophy of mind (see below).

 addresses the notion of "effective computability" as follows: "Clearly the existence of CC and RC (Church's and Rosser's proofs) presupposes a precise definition of 'effective'. 'Effective method' is here used in the rather special sense of a method each step of which is precisely predetermined and which is certain to produce the answer in a finite number of steps". Thus the adverb-adjective "effective" is used in a sense of "1a: producing a decided, decisive, or desired effect", and "capable of producing a result".

In the following, the words "effectively calculable" will mean "produced by any intuitively 'effective' means whatsoever" and "effectively computable" will mean "produced by a Turing-machine or equivalent mechanical device". Turing's "definitions" given in a footnote in his 1938 Ph.D. thesis "Systems of Logic Based on Ordinals", supervised by Church, are virtually the same:

The thesis can be stated as: "Every effectively calculable function is a computable function".
Church also stated that "No computational procedure will be considered as an algorithm unless it can be represented as a Turing Machine".
Turing stated it this way:
It was stated ... that "a function is effectively calculable if its values can be found by some purely mechanical process". We may take this literally, understanding that by a purely mechanical process one which could be carried out by a machine. The development ... leads to ... an identification of computability with effective calculability. [ is the footnote quoted above.]

One of the important problems for logicians in the 1930s was the Entscheidungsproblem of David Hilbert and Wilhelm Ackermann, which asked whether there was a mechanical procedure for separating mathematical truths from mathematical falsehoods. This quest required that the notion of "algorithm" or "effective calculability" be pinned down, at least well enough for the quest to begin. But from the very outset Alonzo Church's attempts began with a debate that continues to this day. the notion of "effective calculability" to be (i) an "axiom or axioms" in an axiomatic system, (ii) merely a "definition" that "identified" two or more propositions, (iii) an "empirical hypothesis" to be verified by observation of natural events, or (iv) just "a proposal" for the sake of argument (i.e. a "thesis").

In the course of studying the problem, Church and his student Stephen Kleene introduced the notion of λ-definable functions, and they were able to prove that several large classes of functions frequently encountered in number theory were λ-definable. The debate began when Church proposed to Gödel that one should define the "effectively computable" functions as the λ-definable functions. Gödel, however, was not convinced and called the proposal "thoroughly unsatisfactory". Rather, in correspondence with Church (c. 1934–35), Gödel proposed "axiomatizing" the notion of "effective calculability"; indeed, in a 1935 letter to Kleene, Church reported that:

But Gödel offered no further guidance. Eventually, he would suggest his recursion, modified by Herbrand's suggestion, that Gödel had detailed in his 1934 lectures in Princeton NJ (Kleene and Rosser transcribed the notes). But he did not think that the two ideas could be satisfactorily identified "except heuristically".

Next, it was necessary to identify and prove the equivalence of two notions of effective calculability. Equipped with the λ-calculus and "general" recursion, Stephen Kleene with help of Church and J. Barkley Rosser produced proofs (1933, 1935) to show that the two calculi are equivalent. Church subsequently modified his methods to include use of Herbrand–Gödel recursion and then proved (1936) that the Entscheidungsproblem is unsolvable: there is no algorithm that can determine whether a well formed formula 

Many years later in a letter to Davis (c. 1965), Gödel said that "he was, at the time of these [1934] lectures, not at all convinced that his concept of recursion comprised all possible recursions". By 1963–64 Gödel would disavow Herbrand–Gödel recursion and the λ-calculus in favor of the Turing machine as the definition of "algorithm" or "mechanical procedure" or "formal system".

A hypothesis leading to a natural law?: In late 1936 Alan Turing's paper (also proving that the Entscheidungsproblem is unsolvable) was delivered orally, but had not yet appeared in print. On the other hand, Emil Post's 1936 paper had appeared and was certified independent of Turing's work. Post strongly disagreed with Church's "identification" of effective computability with the λ-calculus and recursion, stating:

Rather, he regarded the notion of "effective calculability" as merely a "working hypothesis" that might lead by inductive reasoning to a "natural law" rather than by "a definition or an axiom". This idea was "sharply" criticized by Church.

Thus Post in his 1936 paper was also discounting Kurt Gödel's suggestion to Church in 1934–35 that the thesis might be expressed as an axiom or set of axioms.

Turing adds another definition, Rosser equates all three: Within just a short time, Turing's 1936–37 paper "On Computable Numbers, with an Application to the Entscheidungsproblem" appeared. In it he stated another notion of "effective computability" with the introduction of his a-machines (now known as the Turing machine abstract computational model). And in a proof-sketch added as an "Appendix" to his 1936–37 paper, Turing showed that the classes of functions defined by λ-calculus and Turing machines coincided. Church was quick to recognise how compelling Turing's analysis was. In his review of Turing's paper he made clear that Turing's notion made "the identification with effectiveness in the ordinary (not explicitly defined) sense evident immediately".

In a few years (1939) Turing would propose, like Church and Kleene before him, that "his" formal definition of mechanical computing agent was the correct one. Thus, by 1939, both Church (1934) and Turing (1939) had individually proposed that their "formal systems" should be "definitions" of "effective calculability"; neither framed their statements as "theses".

Rosser (1939) formally identified the three notions-as-definitions:

Kleene proposes "Church's Thesis": This left the overt expression of a "thesis" to Kleene. In his 1943 paper "Recursive Predicates and Quantifiers" Kleene proposed his "THESIS I":
() references Church 1936; () references Turing 1936–7
Kleene goes on to note that:
(24) references Post 1936 of Post and Church's "Formal definitions in the theory of ordinal numbers", "Fund. Math". vol 28 (1936) pp.11–21 (see ref. #2, ).

Kleene's Church–Turing Thesis: A few years later (1952) Kleene, who switched from presenting his work in the mathematical terminology of the lambda calculus of his phd advisor Alonzo Church to the theory of general recursive functions of his other teacher Kurt Gödel, would overtly name the Church–Turing thesis in his correction of Turing's paper "The Word Problem in Semi-Groups with Cancellation", defend, and express the two "theses" and then "identify" them (show equivalence) by use of his Theorem XXX:

An attempt to understand the notion of "effective computability" better led Robin Gandy (Turing's student and friend) in 1980 to analyze "machine" computation (as opposed to human-computation acted out by a Turing machine). Gandy's curiosity about, and analysis of, cellular automata (including Conway's game of life), parallelism, and crystalline automata, led him to propose four "principles (or constraints) ... which it is argued, any machine must satisfy". His most-important fourth, "the principle of causality" is based on the "finite velocity of propagation of effects and signals; contemporary physics rejects the possibility of instantaneous action at a distance". From these principles and some additional constraints—(1a) a lower bound on the linear dimensions of any of the parts, (1b) an upper bound on speed of propagation (the velocity of light), (2) discrete progress of the machine, and (3) deterministic behavior—he produces a theorem that "What can be calculated by a device satisfying principles I–IV is computable."

In the late 1990s Wilfried Sieg analyzed Turing's and Gandy's notions of "effective calculability" with the intent of "sharpening the informal notion, formulating its general features axiomatically, and investigating the axiomatic framework". In his 1997 and 2002 work Sieg presents a series of constraints on the behavior of a "computor"—"a human computing agent who proceeds mechanically". These constraints reduce to:

The matter remains in active discussion within the academic community.

The thesis can be viewed as nothing but an ordinary mathematical definition. Comments by Gödel on the subject suggest this view, e.g. "the correct definition of mechanical computability was established beyond any doubt by Turing". The case for viewing the thesis as nothing more than a definition is made explicitly by Robert I. Soare, where it is also argued that Turing's definition of computability is no less likely to be correct than the epsilon-delta definition of a continuous function.

Other formalisms (besides recursion, the λ-calculus, and the Turing machine) have been proposed for describing effective calculability/computability. Stephen Kleene (1952) adds to the list the functions ""reckonable" in the system S" of Kurt Gödel 1936, and Emil Post's (1943, 1946) ""canonical" [also called "normal"] "systems"". In the 1950s Hao Wang and Martin Davis greatly simplified the one-tape Turing-machine model (see Post–Turing machine). Marvin Minsky expanded the model to two or more tapes and greatly simplified the tapes into "up-down counters", which Melzak and Lambek further evolved into what is now known as the counter machine model. In the late 1960s and early 1970s researchers expanded the counter machine model into the register machine, a close cousin to the modern notion of the computer. Other models include combinatory logic and Markov algorithms. Gurevich adds the pointer machine model of Kolmogorov and Uspensky (1953, 1958): "... they just wanted to ... convince themselves that there is no way to extend the notion of computable function."

All these contributions involve proofs that the models are computationally equivalent to the Turing machine; such models are said to be Turing complete. Because all these different attempts at formalizing the concept of "effective calculability/computability" have yielded equivalent results, it is now generally assumed that the Church–Turing thesis is correct. In fact, Gödel (1936) proposed something stronger than this; he observed that there was something "absolute" about the concept of "reckonable in S":

Proofs in computability theory often invoke the Church–Turing thesis in an informal way to establish the computability of functions while avoiding the (often very long) details which would be involved in a rigorous, formal proof. To establish that a function is computable by Turing machine, it is usually considered sufficient to give an informal English description of how the function can be effectively computed, and then conclude "by the Church–Turing thesis" that the function is Turing computable (equivalently, partial recursive).

Dirk van Dalen gives the following example for the sake of illustrating this informal use of the Church–Turing thesis:

In order to make the above example completely rigorous, one would have to carefully construct a Turing machine, or λ-function, or carefully invoke recursion axioms, or at best, cleverly invoke various theorems of computability theory. But because the computability theorist believes that Turing computability correctly captures what can be computed effectively, and because an effective procedure is spelled out in English for deciding the set B, the computability theorist accepts this as proof that the set is indeed recursive.

The success of the Church–Turing thesis prompted variations of the thesis to be proposed. For example, the physical Church–Turing thesis states: "All physically computable functions are Turing-computable."

The Church–Turing thesis says nothing about the efficiency with which one model of computation can simulate another. It has been proved for instance that a (multi-tape) universal Turing machine only suffers a logarithmic slowdown factor in simulating any Turing machine.

A variation of the Church–Turing thesis addresses whether an arbitrary but "reasonable" model of computation can be efficiently simulated. This is called the feasibility thesis, also known as the (classical) complexity-theoretic Church–Turing thesis or the extended Church–Turing thesis, which is not due to Church or Turing, but rather was realized gradually in the development of complexity theory. It states: "A probabilistic Turing machine can efficiently simulate any realistic model of computation." The word 'efficiently' here means up to polynomial-time reductions. This thesis was originally called computational complexity-theoretic Church–Turing thesis by Ethan Bernstein and Umesh Vazirani (1997). The complexity-theoretic Church–Turing thesis, then, posits that all 'reasonable' models of computation yield the same class of problems that can be computed in polynomial time. Assuming the conjecture that probabilistic polynomial time (BPP) equals deterministic polynomial time (P), the word 'probabilistic' is optional in the complexity-theoretic Church–Turing thesis. A similar thesis, called the invariance thesis, was introduced by Cees F. Slot and Peter van Emde Boas. It states: Reasonable' machines can simulate each other within a polynomially bounded overhead in time and a constant-factor overhead in space." The thesis originally appeared in a paper at STOC'84, which was the first paper to show that polynomial-time overhead and constant-space overhead could be "simultaneously" achieved for a simulation of a Random Access Machine on a Turing machine.

If BQP is shown to be a strict superset of BPP, it would invalidate the complexity-theoretic Church–Turing thesis. In other words, there would be efficient quantum algorithms that perform tasks that do not have efficient probabilistic algorithms. This would not however invalidate the original Church–Turing thesis, since a quantum computer can always be simulated by a Turing machine, but it would invalidate the classical complexity-theoretic Church–Turing thesis for efficiency reasons. Consequently, the quantum complexity-theoretic Church–Turing thesis states: "A quantum Turing machine can efficiently simulate any realistic model of computation."

Eugene Eberbach and Peter Wegner claim that the Church–Turing thesis is sometimes interpreted too broadly,
stating "the broader assertion that algorithms precisely capture what can be computed is invalid". They claim that forms of computation not captured by the thesis are relevant today,
terms which they call super-Turing computation.

Philosophers have interpreted the Church–Turing thesis as having implications for the philosophy of mind. B. Jack Copeland states that it is an open empirical question whether there are actual deterministic physical processes that, in the long run, elude simulation by a Turing machine; furthermore, he states that it is an open empirical question whether any such processes are involved in the working of the human brain. There are also some important open questions which cover the relationship between the Church–Turing thesis and physics, and the possibility of hypercomputation. When applied to physics, the thesis has several possible meanings:


There are many other technical possibilities which fall outside or between these three categories, but these serve to illustrate the range of the concept.

Philosophical aspects of the thesis, regarding both physical and biological computers, are also discussed in Odifreddi's 1989 textbook on recursion theory.

One can formally define functions that are not computable. A well-known example of such a function is the Busy Beaver function. This function takes an input "n" and returns the largest number of symbols that a Turing machine with "n" states can print before halting, when run with no input. Finding an upper bound on the busy beaver function is equivalent to solving the halting problem, a problem known to be unsolvable by Turing machines. Since the busy beaver function cannot be computed by Turing machines, the Church–Turing thesis states that this function cannot be effectively computed by any method.

Several computational models allow for the computation of (Church-Turing) non-computable functions. These are known as
hypercomputers.
Mark Burgin argues that super-recursive algorithms such as inductive Turing machines disprove the Church–Turing thesis. His argument relies on a definition of algorithm broader than the ordinary one, so that non-computable functions obtained from some inductive Turing machines are called computable. This interpretation of the Church–Turing thesis differs from the interpretation commonly accepted in computability theory, discussed above. The argument that super-recursive algorithms are indeed algorithms in the sense of the Church–Turing thesis has not found broad acceptance within the computability research community.





</doc>
<doc id="6856" url="https://en.wikipedia.org/wiki?curid=6856" title="Chomsky (surname)">
Chomsky (surname)

Chomsky (, , , , "from (Vyoska) (nearby Brest, now Belarus)") is a surname of Belarusian-Ukrainian origin. Notable people with the surname include:


Elsie, William, Avram Noam, Carol, Marvin, and Aviva are all closely related. William and Elsie were husband and wife. Avram Noam, generally referred by his given name Noam, is their son. Carol and Noam were married until Carol's death in 2008; Aviva is their daughter. Marvin is Noam's cousin. Also, Judith is Noam's sister in-law.



</doc>
<doc id="6857" url="https://en.wikipedia.org/wiki?curid=6857" title="Computer multitasking">
Computer multitasking

In computing, multitasking is the concurrent execution of multiple tasks (also known as processes) over a certain period of time. New tasks can interrupt already started ones before they finish, instead of waiting for them to end. As a result, a computer executes segments of multiple tasks in an interleaved manner, while the tasks share common processing resources such as central processing units (CPUs) and main memory. Multitasking automatically interrupts the running program, saving its state (partial results, memory contents and computer register contents) and loading the saved state of another program and transferring control to it. This "context switch" may be initiated at fixed time intervals (pre-emptive multitasking), or the running program may be coded to signal to the supervisory software when it can be interrupted (cooperative multitasking).

Multitasking does not require parallel execution of multiple tasks at exactly the same time; instead, it allows more than one task to advance over a given period of time. Even on multiprocessor computers, multitasking allows many more tasks to be run than there are CPUs.

Multitasking is a common feature of computer operating systems. It allows more efficient use of the computer hardware; where a program is waiting for some external event such as a user input or an input/output transfer with a peripheral to complete, the central processor can still be used with another program. In a time-sharing system, multiple human operators use the same processor as if it was dedicated to their use, while behind the scenes the computer is serving many users by multitasking their individual programs. In multiprogramming systems, a task runs until it must wait for an external event or until the operating system's scheduler forcibly swaps the running task out of the CPU. Real-time systems such as those designed to control industrial robots, require timely processing; a single processor might be shared between calculations of machine movement, communications, and user interface.

Often multitasking operating systems include measures to change the priority of individual tasks, so that important jobs receive more processor time than those considered less significant. Depending on the operating system, a task might be as large as an entire application program, or might be made up of smaller threads that carry out portions of the overall program.

A processor intended for use with multitasking operating systems may include special hardware to securely support multiple tasks, such as memory protection, and protection rings that ensure the supervisory software cannot be damaged or subverted by user-mode program errors.

The term "multitasking" has become an international term, as the same word is used in many other languages such as German, Italian, Dutch, Danish and Norwegian.

In the early days of computing, CPU time was expensive, and peripherals were very slow. When the computer ran a program that needed access to a peripheral, the central processing unit (CPU) would have to stop executing program instructions while the peripheral processed the data. This was usually very inefficient.

The first computer using a multiprogramming system was the British "Leo III" owned by J. Lyons and Co. During batch processing, several different programs were loaded in the computer memory, and the first one began to run. When the first program reached an instruction waiting for a peripheral, the context of this program was stored away, and the second program in memory was given a chance to run. The process continued until all programs finished running.

The use of multiprogramming was enhanced by the arrival of virtual memory and virtual machine technology, which enabled individual programs to make use of memory and operating system resources as if other concurrently running programs were, for all practical purposes, non-existent and invisible to them.

Multiprogramming doesn't give any guarantee that a program will run in a timely manner. Indeed, the very first program may very well run for hours without needing access to a peripheral. As there were no users waiting at an interactive terminal, this was no problem: users handed in a deck of punched cards to an operator, and came back a few hours later for printed results. Multiprogramming greatly reduced wait times when multiple batches were being processed.

Early multitasking systems used applications that voluntarily ceded time to one another. This approach, which was eventually supported by many computer operating systems, is known today as cooperative multitasking. Although it is now rarely used in larger systems except for specific applications such as CICS or the JES2 subsystem, cooperative multitasking was once the only scheduling scheme employed by Microsoft Windows and Classic Mac OS to enable multiple applications to run simultaneously. Cooperative multitasking is still used today on RISC OS systems.

As a cooperatively multitasked system relies on each process regularly giving up time to other processes on the system, one poorly designed program can consume all of the CPU time for itself, either by performing extensive calculations or by busy waiting; both would cause the whole system to hang. In a server environment, this is a hazard that makes the entire environment unacceptably fragile.

Preemptive multitasking allows the computer system to more reliably guarantee to each process a regular "slice" of operating time. It also allows the system to deal rapidly with important external events like incoming data, which might require the immediate attention of one or another process. Operating systems were developed to take advantage of these hardware capabilities and run multiple processes preemptively. Preemptive multitasking was implemented in the PDP-6 Monitor and MULTICS in 1964, in OS/360 MFT in 1967, and in Unix in 1969, and was available in some operating systems for computers as small as DEC's PDP-8; it is a core feature of all Unix-like operating systems, such as Linux, Solaris and BSD with its derivatives, as well as modern versions of Windows.

At any specific time, processes can be grouped into two categories: those that are waiting for input or output (called "I/O bound"), and those that are fully utilizing the CPU ("CPU bound"). In primitive systems, the software would often "poll", or "busywait" while waiting for requested input (such as disk, keyboard or network input). During this time, the system was not performing useful work. With the advent of interrupts and preemptive multitasking, I/O bound processes could be "blocked", or put on hold, pending the arrival of the necessary data, allowing other processes to utilize the CPU. As the arrival of the requested data would generate an interrupt, blocked processes could be guaranteed a timely return to execution.

The earliest preemptive multitasking OS available to home users was Sinclair QDOS on the Sinclair QL, released in 1984, but very few people bought the machine. Commodore's Amiga, released the following year, was the first commercially successful home computer to use the technology, and its multimedia abilities make it a clear ancestor of contemporary multitasking personal computers. Microsoft made preemptive multitasking a core feature of their flagship operating system in the early 1990s when developing Windows NT 3.1 and then Windows 95. It was later adopted on the Apple Macintosh by Mac OS X that, as a Unix-like operating system, uses preemptive multitasking for all native applications.

A similar model is used in Windows 9x and the Windows NT family, where native 32-bit applications are multitasked preemptively. 64-bit editions of Windows, both for the x86-64 and Itanium architectures, no longer support legacy 16-bit applications, and thus provide preemptive multitasking for all supported applications.

Another reason for multitasking was in the design of real-time computing systems, where there are a number of possibly unrelated external activities needed to be controlled by a single processor system. In such systems a hierarchical interrupt system is coupled with process prioritization to ensure that key activities were given a greater share of available process time.

As multitasking greatly improved the throughput of computers, programmers started to implement applications as sets of cooperating processes (e. g., one process gathering input data, one process processing input data, one process writing out results on disk). This, however, required some tools to allow processes to efficiently exchange data.

Threads were born from the idea that the most efficient way for cooperating processes to exchange data would be to share their entire memory space. Thus, threads are effectively processes that run in the same memory context and share other resources with their parent processes, such as open files. Threads are described as "lightweight processes" because switching between threads does not involve changing the memory context.

While threads are scheduled preemptively, some operating systems provide a variant to threads, named "fibers", that are scheduled cooperatively. On operating systems that do not provide fibers, an application may implement its own fibers using repeated calls to worker functions. Fibers are even more lightweight than threads, and somewhat easier to program with, although they tend to lose some or all of the benefits of threads on machines with multiple processors.

Some systems directly support multithreading in hardware.

Essential to any multitasking system is to safely and effectively share access to system resources. Access to memory must be strictly managed to ensure that no process can inadvertently or deliberately read or write to memory locations outside the process's address space. This is done for the purpose of general system stability and data integrity, as well as data security.

In general, memory access management is a responsibility of the operating system kernel, in combination with hardware mechanisms that provide supporting functionalities, such as a memory management unit (MMU). If a process attempts to access a memory location outside its memory space, the MMU denies the request and signals the kernel to take appropriate actions; this usually results in forcibly terminating the offending process. Depending on the software and kernel design and the specific error in question, the user may receive an access violation error message such as "segmentation fault".

In a well designed and correctly implemented multitasking system, a given process can never directly access memory that belongs to another process. An exception to this rule is in the case of shared memory; for example, in the System V inter-process communication mechanism the kernel allocates memory to be mutually shared by multiple processes. Such features are often used by database management software such as PostgreSQL.

Inadequate memory protection mechanisms, either due to flaws in their design or poor implementations, allow for security vulnerabilities that may be potentially exploited by malicious software.

Use of a swap file or swap partition is a way for the operating system to provide more memory than is physically available by keeping portions of the primary memory in secondary storage. While multitasking and memory swapping are two completely unrelated techniques, they are very often used together, as swapping memory allows more tasks to be loaded at the same time. Typically, a multitasking system allows another process to run when the running process hits a point where it has to wait for some portion of memory to be reloaded from secondary storage.

Processes that are entirely independent are not much trouble to program in a multitasking environment. Most of the complexity in multitasking systems comes from the need to share computer resources between tasks and to synchronize the operation of co-operating tasks.

Various concurrent computing techniques are used to avoid potential problems caused by multiple tasks attempting to access the same resource.

Bigger systems were sometimes built with a central processor(s) and some number of I/O processors, a kind of asymmetric multiprocessing.

Over the years, multitasking systems have been refined. Modern operating systems generally include detailed mechanisms for prioritizing processes, while symmetric multiprocessing has introduced new complexities and capabilities.



</doc>
<doc id="6859" url="https://en.wikipedia.org/wiki?curid=6859" title="Chiang Kai-shek">
Chiang Kai-shek

Chiang Kai-shek (31 October 1887 – 5 April 1975), also known as Chiang Chung-cheng and romanized via Mandarin as Chiang Chieh-shih and Jiang Jieshi, was a Chinese nationalist politician, revolutionary and military leader who served as the leader of the Republic of China between 1928 and 1975, first in mainland China until 1949 and then in Taiwan until his death.

Born in Chekiang (Zhejiang) Province, Chiang was a member of the Kuomintang (KMT) and a lieutenant of Sun Yat-sen in the revolution to overthrow the Beiyang government and reunify China. With Soviet and communist (Communist Party of China: CPC) help, Chiang organized the military for Sun's Canton Nationalist Government and headed the Whampoa Military Academy. Commander in chief of the National Revolutionary Army (from which he came to be known as Generalissimo), he led the Northern Expedition from 1926 to 1928, before defeating a coalition of warlords and nominally reunifying China under a new Nationalist government. Midway through the campaign, the KMT–CPC alliance broke down and Chiang purged the communists inside the party, triggering a civil war with the CPC, which he eventually lost in 1949.

As leader of the Republic of China in the Nanjing decade, Chiang sought to strike a difficult balance between modernizing China while also devoting resources to defending the nation against the impending Japanese threat. Trying to avoid a war with Japan while hostilities with CPC continued, he was kidnapped in the Xi'an Incident and obliged to form an Anti-Japanese United Front with the CPC. Following the Marco Polo Bridge Incident in 1937, he mobilized China for the Second Sino-Japanese War. For eight years he led the war of resistance against a vastly superior enemy, mostly from the wartime capital Chongqing. As the leader of a major Allied power, Chiang met with British Prime Minister Winston Churchill and U.S. President Franklin D. Roosevelt in the Cairo Conference to discuss terms for Japanese surrender. No sooner had the Second World War ended than the Civil War with the communists, by then led by Mao Zedong, resumed. Chiang's nationalists were mostly defeated in a few decisive battles in 1948.

In 1949 Chiang's government and army retreated to Taiwan, where Chiang imposed martial law and persecuted critics during the White Terror. Presiding over a period of social reforms and economic prosperity, Chiang won five elections to six-year terms as President of the Republic of China and was Director-General of the Kuomintang until his death in 1975, three years into his fifth term as President and just one year before Mao's death.

One of the longest-serving non-royal heads of state in the 20th century, Chiang was the longest-serving non-royal ruler of China having held the post for 46 years. Like Mao, he is regarded as a controversial figure. Supporters credit him with playing a major part in unifying the nation and leading the Chinese resistance against Japan, as well as with countering Soviet-communist encroachment. Detractors and critics denounce him as a dictator at the front of an authoritarian regime who suppressed opponents.

Like many other Chinese historical figures, Chiang used several names throughout his life. The name inscribed in the genealogical records of his family is Chiang Chou-t‘ai (). This so-called "register name" (譜名) is the one under which his extended relatives knew him, and the one he used in formal occasions, such as when he got married. In deference to tradition, family members did not use the register name in conversation with people outside of the family. The concept of a "real" or original name is/was not as clear-cut in China as it is in the Western world.

In honor of tradition, Chinese families waited a number of years before officially naming their children. In the meantime, they used a "milk name" (), given to the infant shortly after his birth and known only to the close family, thus the actual name that Chiang received at birth was Chiang Jui-yüan ().

In 1903, the 16-year-old Chiang went to Ningbo to be a student, and he chose a "school name" (). This was actually the formal name of a person, used by older people to address him, and the one he would use the most in the first decades of his life (as the person grew older, younger generations would have to use one of the courtesy names instead). Colloquially, the school name is called "big name" (), whereas the "milk name" is known as the "small name" (). The school name that Chiang chose for himself was Zhiqing (, which means "purity of aspirations"). For the next fifteen years or so, Chiang was known as Jiang Zhiqing (Wade-Giles: Chiang Chi-ch‘ing). This is the name under which Sun Yat-sen knew him when Chiang joined the republicans in Kwangtung in the 1910s.

In 1912, when Jiang Zhiqing was in Japan, he started to use the name Chiang Kai-shek () as a pen name for the articles that he published in a Chinese magazine he founded: "Voice of the Army" (). "Jieshi" is the Pinyin romanization of this name, based on Mandarin, but the most recognized romanized rendering is "Kai-shek" which is in Cantonese romanization. As the republicans were based in Canton (a Cantonese speaking area, now known as Guangdong), Chiang became known by Westerners under the Cantonese romanization of his courtesy name, while the family name as known in English seems to be the Mandarin pronunciation of his Chinese family name, transliterated in Wade-Giles.

"Kai-shek"/"Jieshi" soon became Chiang's courtesy name (). Some think the name was chosen from the classic Chinese book the "I Ching"; , is the beginning of line 2 of Hexagram 16, "". Others note that the first character of his courtesy name is also the first character of the courtesy name of his brother and other male relatives on the same generation line, while the second character of his courtesy name "shi" (—meaning "stone") suggests the second character of his "register name" "tai" (—the famous Mount Tai). Courtesy names in China often bore a connection with the personal name of the person. As the courtesy name is the name used by people of the same generation to address the person, Chiang soon became known under this new name.

Sometime in 1917 or 1918, as Chiang became close to Sun Yat-sen, he changed his name from Jiang Zhiqing to Chiang Chung-cheng (). By adopting the name Chung-cheng ("central uprightness"), he was choosing a name very similar to the name of Sun Yat-sen, who was (and still is) known among Chinese as Zhongshan (—meaning "central mountain"), thus establishing a link between the two. The meaning of uprightness, rectitude, or orthodoxy, implied by his name, also positioned him as the legitimate heir of Sun Yat-sen and his ideas. It was readily accepted by members of the Chinese Nationalist Party and is the name under which Chiang Kai-shek is still commonly known in Taiwan. However, the name was often rejected by the Chinese Communists and is not as well known in mainland China. Often the name is shortened to "Chung-cheng" only ("Zhongzheng" in Pinyin). Many public places in Taiwan are named Chungcheng after Chiang. For many years passengers arriving at the Chiang Kai-shek International Airport were greeted by signs in Chinese welcoming them to the "Chung Cheng International Airport". Similarly, the monument erected to Chiang's memory in Taipei, known in English as Chiang Kai-shek Memorial Hall, was literally named "Chung Cheng Memorial Hall" in Chinese. In Singapore, Chung Cheng High School was named after him.

His name is also written in Taiwan as "The Late President Honorable Chiang" (), where the one-character-wide space in front of his name known as nuo tai shows respect. He is often called "Honorable Chiang" () (without the title or space), or his name Chiang Chung-cheng, in Taiwan.

Chiang was born at noon on October 31, 1887 on the second floor of the Yutai Salt Store in Xikou (Chikow, Ch'i-k'ou), a town in Fenghua (Fenghwa), Zhejiang (Chekiang), China, about west of central Ningbo. He was born into a family of Wu Chinese-speaking people with their ancestral home—a concept important in Chinese society—in Heqiao (), a town in Yixing, Jiangsu, about southwest of central Wuxi and from the shores of Lake Tai. He was the third child and second son of his father (also Chiang Su-an; 1842–1895; ) and the first child of his father's third wife (1863–1921; ) who were members of a prosperous family of salt merchants. Chiang lost his father when he was eight, and he wrote of his mother as the "embodiment of Confucian virtues". The young Chiang was inspired throughout his youth by the realisation that the reputation of an honored family rested upon his shoulders. He was a naughty child. At a young age he was interested in war. As he grew older, Chiang became more aware of the issues that surrounded him and in his speech to the Kuomintang in 1945 said:

In early 1906, Chiang cut off his queue, the required hairstyle of men during the Qing Dynasty, and had it sent home from school, shocking the people in his hometown.

Chiang grew up at a time in which military defeats, natural disasters, famines, revolts, unequal treaties and civil wars had left the Manchu-dominated Qing dynasty destabilized and in debt. Successive demands of the Western powers and Japan since the Opium War had left China owing millions of taels of silver. During his first visit to Japan to pursue a military career from April 1906 to later that year, he describes himself having strong nationalistic feelings with a desire among other things to, 'expel the Manchu Qing and to restore China'. In a 1969 speech, Chiang related a story about his boat trip to Japan at nineteen years old. Another passenger on the ship, a Chinese fellow student who was in the habit of spitting on the floor, was chided by a Chinese sailor who said that Japanese people did not spit on the floor, but instead would spit into a handkerchief. Chiang used the story as an example of how the common man in 1969 Taiwan had not developed the spirit of public sanitation that Japan had. Chiang decided to pursue a military career. He began his military training at the Baoding Military Academy in 1906, the same year Japan left its bimetallic currency standard, devaluing its yen. He left for Tokyo Shinbu Gakko, a preparatory school for the Imperial Japanese Army Academy intended for Chinese students, in 1907. There, he came under the influence of compatriots to support the revolutionary movement to overthrow the Manchu-dominated Qing dynasty and to set up a Han-dominated Chinese republic. He befriended Chen Qimei, and in 1908 Chen brought Chiang into the Tongmenghui, an important revolutionary brotherhood of the era. Finishing his military schooling at Tokyo Shinbu Gakko, Chiang served in the Imperial Japanese Army from 1909 to 1911.

After learning of the Wuchang Uprising, Chiang returned to China in 1911, intending to fight as an artillery officer. He served in the revolutionary forces, leading a regiment in Shanghai under his friend and mentor Chen Qimei, as one of Chen's chief lieutenants. Chen valued Chiang despite Chiang's already legendary temper, regarding such bellicosity as useful in a military leader.

Chiang's friendship with Chen Qimei signaled an association with Shanghai's criminal syndicate (the Green Gang headed by Du Yuesheng and Huang Jinrong). During Chiang's time in Shanghai, the British-administered Shanghai International Settlement police watched him and charged him with various felonies. These charges never resulted in a trial, and Chiang was never jailed.

Chiang became a founding member of the KMT after the success (February 1912) of the 1911 Revolution. After the takeover of the Republican government by Yuan Shikai and the failed Second Revolution in 1913, Chiang, like his KMT comrades, divided his time between exile in Japan and the havens of the Shanghai International Settlement. In Shanghai, Chiang cultivated ties with the city's underworld gangs, which were dominated by the notorious Green Gang and its leader Du Yuesheng. On 18 May 1916, agents of Yuan Shikai assassinated Chen Qimei. Chiang then succeeded Chen as leader of the Chinese Revolutionary Party in Shanghai. Sun Yat-sen's political career reached its lowest point during this time when most of his old Revolutionary Alliance comrades refused to join him in the exiled Chinese Revolutionary Party.

In 1917 Sun Yat-sen moved his base of operations to Canton (now known as Guangzhou), and Chiang joined him in 1918. At this time Sun remained largely sidelined - without arms or money, he was soon expelled from Kwangtung and exiled again to Shanghai. He was restored to Kwangtung with mercenary help in 1920. After his return to Kwangtung, a rift developed between Sun, who sought to militarily unify China under the KMT, and Guangdong Governor Chen Jiongming, who wanted to implement a federalist system with Guangdong as a model province. On 16 June 1922 Ye Ju, a general of Chen's whom Sun had attempted to exile, led an assault on Kwangtung's Presidential Palace. Sun had already fled to the naval yard and boarded the SS "Haiqi", but his wife narrowly evaded shelling and rifle-fire as she fled. They met on the SS "Yongfeng", where Chiang joined them as swiftly as he could return from Shanghai, where he was ritually mourning his mother's death. For about 50 days, Chiang stayed with Sun, protecting and caring for him and earning his lasting trust. They abandoned their attacks on Chen on 9 August, taking a British ship to Hong Kong and traveling to Shanghai by steamer.

Sun regained control of Kwangtung in early 1923, again with the help of mercenaries from Yunnan and of the Comintern. Undertaking a reform of the KMT, he established a revolutionary government aimed at unifying China under the KMT. That same year Sun sent Chiang to spend three months in Moscow studying the Soviet political and military system. During his trip in Russia, Chiang met Leon Trotsky and other Soviet leaders, but quickly came to the conclusion that the Russian model of government was not suitable for China. Chiang later sent his eldest son, Ching-kuo, to study in Russia. After his father's split from the First United Front in 1927, Ching-kuo was forced to stay there, as a hostage, until 1937. Chiang wrote in his diary, "It is not worth it to sacrifice the interest of the country for the sake of my son." Chiang even refused to negotiate a prisoner swap for his son in exchange for the Chinese Communist Party leader. His attitude remained consistent, and he continued to maintain, by 1937, that "I would rather have no offspring than sacrifice our nation's interests." Chiang had absolutely no intention of ceasing the war against the Communists.

Chiang Kai-shek returned to Kwangtung and in 1924 Sun appointed him Commandant of the Whampoa Military Academy. Chiang resigned from the office after one month in disagreement with Sun's extremely close cooperation with the Comintern, but returned at Sun's demand. The early years at Whampoa allowed Chiang to cultivate a cadre of young officers loyal both to the KMT and to himself.

Throughout his rise to power, Chiang also benefited from membership within the nationalist Tiandihui fraternity, to which Sun Yat-sen also belonged, and which remained a source of support during his leadership of the Kuomintang.

Sun Yat-sen died on 12 March 1925, creating a power vacuum in the Kuomintang. A contest ensued among Wang Jingwei, Liao Zhongkai, and Hu Hanmin. In August, Liao was assassinated and Hu arrested for his connections to the murderers. Wang Jingwei, who had succeeded Sun as chairman of the Kwangtung regime, seemed ascendant but was forced into exile by Chiang following the Canton Coup. The , renamed the "Zhongshan" in Sun's honour, had appeared off Changzhou—the location of the Whampoa Academy—on apparently falsified orders and amid a series of unusual phone calls trying to ascertain Chiang's location. He initially considered fleeing Kwangtung and even booked passage on a Japanese steamer, but then decided to use his military connections to declare martial law on 20 March 1926, and crack down on Communist and Soviet influence over the NRA, the military academy, and the party. The right wing of the party supported him and Stalin—anxious to maintain Soviet influence in the area—had his lieutenants agree to Chiang's demands regarding a reduced Communist presence in the KMT leadership in exchange for certain other concessions. The rapid replacement of leadership enabled Chiang to effectively end civilian oversight of the military after 15 May, though his authority was somewhat limited by the army's own regional composition and divided loyalties. On 5 June 1926, he was named commander-in-chief of the National Revolutionary Army and, on 27 July, he finally launched Sun's long-delayed Northern Expedition, aimed at conquering the northern warlords and bringing China together under the KMT.

The NRA branched into three divisions: to the west was the returned Wang Jingwei, who led a column to take Wuhan; Bai Chongxi's column went east to take Shanghai; Chiang himself led in the middle route, planning to take Nanjing before pressing ahead to capture Beijing. However, in January 1927, Wang Jingwei and his KMT leftist allies took the city of Wuhan amid much popular mobilization and fanfare. Allied with a number of Chinese Communists and advised by Soviet agent Mikhail Borodin, Wang declared the National Government as having moved to Wuhan. Having taken Nanjing in March (and briefly visited Shanghai, now under the control of his close ally Bai Chongxi), Chiang halted his campaign and prepared a violent break with Wang's leftist elements, which he believed threatened his control of the KMT.

Now with an established national government in Nanjing, and supported by conservative allies including Hu Hanmin, Chiang's expulsion of the Communists and their Soviet advisers led to the beginning of the Chinese Civil War. Wang Jingwei's National Government was weak militarily, and was soon ended by Chiang with the support of a local warlord (Li Zongren of Guangxi). Eventually, Wang and his leftist party surrendered to Chiang and joined him in Nanjing. In the Central Plains War, Beijing was taken on June 1928, from an alliance of the warlords Feng Yuxiang and Yan Xishan. In December, the Manchurian warlord Zhang Xueliang pledged allegiance to Chiang's government, completing Chiang's nominal unification of China and ending the Warlord Era.

In 1927, when he was setting up the Nationalist government in Nanjing, he was preoccupied with "the elevation of our leader Dr. Sun Yat-sen to the rank of 'Father of our Chinese Republic'. Dr. Sun worked for 40 years to lead our people in the Nationalist cause, and we cannot allow any other personality to usurp this honored position". He asked Chen Guofu to purchase a photograph that had been taken in Japan around 1895 or 1898. It showed members of the Revive China Society with Yeung Kui-wan ( or , pinyin Yáng Qúyún) as President, in the place of honor, and Sun, as secretary, on the back row, along with members of the Japanese Chapter of the Revive China Society. When told that it was not for sale, Chiang offered a million dollars to recover the photo and its negative. "The party must have this picture and the negative at any price. They must be destroyed as soon as possible. It would be embarrassing to have our Father of the Chinese Republic shown in a subordinate position". Chiang never obtained either the photo or its negative.

Chiang made great efforts to gain recognition as the official successor of Sun Yat-sen. In a pairing of great political significance, Chiang was Sun's brother-in-law: he had married Soong Mei-ling, the younger sister of Soong Ching-ling, Sun's widow, on 1 December 1927. Originally rebuffed in the early 1920s, Chiang managed to ingratiate himself to some degree with Soong Mei-ling's mother by first divorcing his wife and concubines and promising to sincerely study the precepts of Christianity. He read the copy of the Bible that May-ling had given him twice before making up his mind to become a Christian, and three years after his marriage he was baptized in the Soong's Methodist church. Although some observers felt that he adopted Christianity as a political move, studies of his recently opened diaries suggest that his faith was strong and sincere and that he felt that Christianity reinforced Confucian moral teachings.

Upon reaching Beijing, Chiang paid homage to Sun Yat-sen and had his body moved to the new capital of Nanjing to be enshrined in a mausoleum, the Sun Yat-sen Mausoleum.

In the West and in the Soviet Union, Chiang Kai-shek was known as the "Red General". Movie theaters in the Soviet Union showed newsreels and clips of Chiang. At Moscow, Sun Yat-sen University portraits of Chiang were hung on the walls; and, in the Soviet May Day Parades that year, Chiang's portrait was to be carried along with the portraits of Karl Marx, Friedrich Engels, Vladimir Lenin, Joseph Stalin, Mao Zedong, Ho Chi Minh and other Communist leaders. The United States consulate and other Westerners in Shanghai were concerned about the approach of "Red General" Chiang as his army was seizing control of large areas of the country in the Northern Expedition.

On 12 April 1927, Chiang carried out a purge of thousands of suspected Communists and dissidents in Shanghai, and began large-scale massacres across the country collectively known as the "White Terror". During April, more than people were killed in Shanghai. The killings drove most Communists from urban cities and into the rural countryside, where the KMT was less powerful. In the year after April 1927, over 300,000 people died across China in anti-Communist suppression campaigns, executed by the KMT. One of the most famous quotes from Chiang (during that time) was that he would rather mistakenly kill 1,000 innocent people rather than allow one Communist to escape. Some estimates claim the White Terror in China took millions of lives, most of them in the rural areas. No concrete number can be verified. Chiang allowed Soviet agent and advisor Mikhail Borodin and Soviet general Vasily Blücher (Galens) to "escape" to safety after the purge.

Having gained control of China, Chiang's party remained surrounded by "surrendered" warlords who remained relatively autonomous within their own regions. On 10 October 1928, Chiang was named director of the State Council, the equivalent to President of the country, in addition to his other titles. As with his predecessor Sun Yat-sen, the Western media dubbed him "Generalissimo".

According to Sun Yat-sen's plans, the Kuomintang (KMT) was to rebuild China in three steps: military rule, political tutelage, and constitutional rule. The ultimate goal of the KMT revolution was democracy, which was not considered to be feasible in China's fragmented state. Since the KMT had completed the first step of revolution through seizure of power in 1928, Chiang's rule thus began a period of what his party considered to be "political tutelage" in Sun Yat-sen's name. During this so-called Republican Era, many features of a modern, functional Chinese state emerged and developed.

From 1928 to 1937, a time period known as the Nanjing decade, some aspects of foreign imperialism, concessions and privileges in China were moderated through diplomacy. The government acted to modernize the legal and penal systems, attempted to stabilize prices, amortize debts, reform the banking and currency systems, build railroads and highways, improve public health facilities, legislate against traffic in narcotics, and augment industrial and agricultural production. Not all of these projects were successfully completed. Efforts were made towards improving education standards, and in an effort to unify Chinese society, the New Life Movement was launched to encourage Confucian moral values and personal discipline. "Guoyu" ("national language") was promoted as a standard tongue, and the establishment of communications facilities (including radio) were used to encourage a sense of Chinese nationalism in a way that was not possible when the nation lacked an effective central government.

Any successes that the Nationalists did make, however, were met with constant political and military upheavals. While much of the urban areas were now under the control of the KMT, much of the countryside remained under the influence of weakened yet undefeated warlords and Communists. Chiang often resolved issues of warlord obstinacy through military action, but such action was costly in terms of men and material. The 1930 Central Plains War alone nearly bankrupted the Nationalist government and caused almost casualties on both sides. In 1931, Hu Hanmin, Chiang's old supporter, publicly voiced a popular concern that Chiang's position as both premier and president flew in the face of the democratic ideals of the Nationalist government. Chiang had Hu put under house arrest, but he was released after national condemnation, after which he left Nanjing and supported a rival government in Canton. The split resulted in a military conflict between Hu's Kwangtung government and Chiang's Nationalist government. Chiang only won the campaign against Hu after a shift in allegiance by Zhang Xueliang, who had previously supported Hu Hanmin.
Throughout his rule, complete eradication of the Communists remained Chiang's dream. After assembling his forces in Jiangxi, Chiang led his armies against the newly established Chinese Soviet Republic. With help from foreign military advisers, Chiang's Fifth Campaign finally surrounded the Chinese Red Army in 1934. The Communists, tipped off that a Nationalist offensive was imminent, retreated in the Long March, during which Mao Zedong rose from a mere military official to the most influential leader of the Chinese Communist Party.

Chiang, as a nationalist and a Confucianist, was against the iconoclasm of the May Fourth Movement. Motivated by his sense of nationalism, he viewed some Western ideas as foreign, and he believed that the great introduction of Western ideas and literature that the May Fourth Movement promoted was not beneficial to China. He and Dr. Sun criticized the May Fourth intellectuals as corrupting the morals of China's youth.

Contrary to Communist propaganda that he was pro-capitalism, Chiang antagonized the capitalists of Shanghai, often attacking them and confiscating their capital and assets for the use of the government. Chiang confiscated the wealth of capitalists even while he denounced and fought against communists. Chiang crushed pro-communist worker and peasant organizations and rich Shanghai capitalists at the same time. Chiang continued the anti-capitalist ideology of Sun Yat-sen, directing Kuomintang media to openly attack capitalists and capitalism, while demanding government controlled industry instead.

Chiang has often been interpreted as being pro-capitalist, but this conclusion may be problematic. Shanghai capitalists did briefly support him out of fear of communism in 1927, but this support eroded in 1928 when Chiang turned his tactics of intimidation on them. The relationship between Chiang Kai-shek and Chinese capitalists remained poor throughout the period of his administration. Chiang blocked Chinese capitalists from gaining any political power or voice within his regime. Once Chiang Kai-shek was done with his White Terror on pro-communist laborers, he proceeded to turn on the capitalists. Gangster connections allowed Chiang to attack them in the International Settlement, successfully forcing capitalists to back him up with their assets for his military expeditions.

Chiang viewed Japan, the United States, the Soviet Union, France and Britain as all being imperialists with nobody else's interests in mind but their own, seeing them as hypocritical to condemn each other for imperialism which they all practiced. He manipulated America, Nazi Germany, and the Soviet Union to regain lost territories for China as he viewed all the powers as imperialists trying to curtail and suppress China's power and national resurrection.

Some sources attribute Chiang Kai-shek with responsibility for millions of deaths in scattered mass death events caused by the Nationalist Government of China. He has been deemed partially responsible for the man-made 1938 Yellow River flood, which killed hundreds of thousands of Chinese civilians in order to fend off a Japanese advance. This accusation is usually sourced from Rudolph Rummel who was referring to the Nationalist regime as whole rather than Chiang Kai-Shek in particular. Regardless, the Nationalist government of China has been accused by Rummel of mass killings; he alleged that, based on various claims, the Nationalist government of China was responsible for between 6 and 18.5 million deaths.
He attributes this death toll to a few major causes, for example:

In Nanjing, on April 1931, Chiang Kai-shek attended a national leadership conference with Zhang Xueliang and General Ma Fuxiang, in which Chiang and Zhang dauntlessly upheld that Manchuria was part of China in the face of the Japanese invasion. After the Japanese invasion of Manchuria in 1931, Chiang resigned as Chairman of the National Government. He returned shortly afterwards, adopting the slogan "first internal pacification, then external resistance". However, this policy of avoiding a frontal war against the Japanese was widely unpopular. In 1932, while Chiang was seeking first to defeat the Communists, Japan launched an advance on Shanghai and bombarded Nanjing. This disrupted Chiang's offensives against the Communists for a time, although it was the northern factions of Hu Hanmin's Kwangtung government (notably the 19th Route Army) that primarily led the offensive against the Japanese during this skirmish. Brought into the Nationalist army immediately after the battle, the 19th Route Army's career under Chiang would be cut short after it was disbanded for demonstrating socialist tendencies.

In December 1936, Chiang flew to Xi'an to coordinate a major assault on the Red Army and the Communist Republic that had retreated into Yan'an. However, Chiang's allied commander Zhang Xueliang, whose forces were used in his attack and whose homeland of Manchuria had been recently invaded by the Japanese, did not support the attack on the Communists. On 12 December, Zhang and several other Nationalist generals headed by Yang Hucheng of Shaanxi kidnapped Chiang for two weeks in what is known as the Xi'an Incident. They forced Chiang into making a "Second United Front" with the Communists against Japan. After releasing Chiang and returning to Nanjing with him, Zhang was placed under house arrest and the generals who had assisted him were executed. Chiang's commitment to the Second United Front was nominal at best, and it was all but broken up in 1941.
The Second Sino-Japanese War broke out in July 1937, and in August of that year Chiang sent of his best-trained and equipped soldiers to defend Shanghai. With over 200,000 Chinese casualties, Chiang lost the political cream of his Whampoa-trained officers. Although Chiang lost militarily, the battle dispelled Japanese claims that it could conquer China in three months and demonstrated to the Western powers that the Chinese would continue the fight. By December, the capital city of Nanjing had fallen to the Japanese resulting in the Nanking Massacre. Chiang moved the government inland, first to Wuhan and later to Chongqing.

Having lost most of China's economic and industrial centers, Chiang withdrew into the hinterlands, stretching the Japanese supply lines and bogging down Japanese soldiers in the vast Chinese interior. As part of a policy of protracted resistance, Chiang authorized the use of scorched earth tactics, resulting in many civilian deaths. During the Nationalists' retreat from Zhengzhou, the dams around the city were deliberately destroyed by the Nationalist army in order to delay the Japanese advance, killing 500,000 people in the subsequent 1938 Yellow River flood.

After heavy fighting, the Japanese occupied Wuhan in the fall of 1938 and the Nationalists retreated farther inland, to Chongqing. While en route to Chongqing, the Nationalist army intentionally started the "fire of Changsha", as a part of the scorched earth policy. The fire destroyed much of the city, killed twenty thousand civilians, and left hundreds of thousands of people homeless. Due to an organizational error (it was claimed), the fire was begun without any warning to the residents of the city. The Nationalists eventually blamed three local commanders for the fire and executed them. Newspapers across China blamed the fire on (non-KMT) arsonists, but the blaze contributed to a nationwide loss of support for the KMT.

In 1939 Muslim leaders Isa Yusuf Alptekin and Ma Fuliang were sent by Chiang to several Middle Eastern countries, including Egypt, Turkey, and Syria, to gain support for the Chinese War against Japan, and to express his support for Muslims.

The Japanese, controlling the puppet-state of Manchukuo and much of China's eastern seaboard, appointed Wang Jingwei as a Quisling-ruler of the occupied Chinese territories around Nanjing. Wang named himself President of the Executive Yuan and Chairman of the National Government (not the same 'National Government' as Chiang's), and led a surprisingly large minority of anti-Chiang/anti-Communist Chinese against his old comrades. He died in 1944, within a year of the end of World War II.

The Hui Muslim Xidaotang sect pledged allegiance to the Kuomintang after their rise to power and Hui Muslim General Bai Chongxi acquainted Chiang Kaishek with the Xidaotang jiaozhu Ma Mingren in 1941 in Chongqing.

In 1942 Generalissimo Chiang Kai-shek went on tour in northwestern China in Xinjiang, Gansu, Ningxia, Shaanxi, and Qinghai, where he met both Muslim Generals Ma Buqing and Ma Bufang. He also met the Muslim Generals Ma Hongbin and Ma Hongkui separately.

A border crisis erupted with Tibet in 1942. Under orders from Chiang, Ma Bufang repaired Yushu airport to prevent Tibetan separatists from seeking independence. Chiang also ordered Ma Bufang to put his Muslim soldiers on alert for an invasion of Tibet in 1942. Ma Bufang complied and moved several thousand troops to the border with Tibet. Chiang also threatened the Tibetans with aerial bombardment if they worked with the Japanese. Ma Bufang attacked the Tibetan Buddhist Tsang monastery in 1941. He also constantly attacked the Labrang monastery.

With the attack on Pearl Harbor and the opening of the Pacific War, China became one of the Allied Powers. During and after World War II, Chiang and his American-educated wife Soong Mei-ling, known in the United States as "Madame Chiang", held the support of the China Lobby in the United States, which saw in them the hope of a Christian and democratic China. Chiang was even named the Supreme Commander of Allied forces in the China war zone. He was appointed Knight Grand Cross of the Order of the Bath in 1942.

General Joseph Stilwell, an American military adviser to Chiang during World War II, strongly criticized Chiang and his generals for what he saw as their incompetence and corruption. In 1944, the United States Army Air Corps commenced Operation Matterhorn in order to bomb Japan's steel industry from bases to be constructed in mainland China. This was meant to fulfill President Roosevelt's promise to Chiang Kai-shek to begin bombing operations against Japan by November 1944. However, Chiang Kai-shek's subordinates refused to take airbase construction seriously until enough capital had been delivered to permit embezzlement on a massive scale. Stilwell estimated that at least half of the $100 million spent on construction of airbases was embezzled by Nationalist party officials.

Chiang played the Soviets and Americans against each other during the war. He first told the Americans that they would be welcome in talks between the Soviet Union and China, then secretly told the Soviets that the Americans were unimportant and that their opinions would not be considered. Chiang also used American support and military power in China against the ambitions of the Soviet Union to dominate the talks, stopping the Soviets from taking full advantage of the situation in China with the threat of American military action against the Soviets.

U.S. President Franklin D. Roosevelt, through General Stilwell, privately made it clear that they preferred that the French not reacquire French Indochina (modern day Vietnam, Cambodia and Laos) after the war was over. Roosevelt offered Chiang control of all of Indochina. It was said that Chiang replied: "Under no circumstances!"

After the war, 200,000 Chinese troops under General Lu Han were sent by Chiang Kai-shek to northern Indochina (north of the 16th parallel) to accept the surrender of Japanese occupying forces there, and remained in Indochina until 1946, when the French returned. The Chinese used the VNQDD, the Vietnamese branch of the Chinese Kuomintang, to increase their influence in Indochina and to put pressure on their opponents. Chiang Kai-shek threatened the French with war in response to maneuvering by the French and Ho Chi Minh's forces against each other, forcing them to come to a peace agreement. In February 1946 he also forced the French to surrender all of their concessions in China and to renounce their extraterritorial privileges in exchange for the Chinese withdrawing from northern Indochina and allowing French troops to reoccupy the region. Following France's agreement to these demands, the withdrawal of Chinese troops began in March 1946.

During the Cairo Conference in 1943, Chiang said that Roosevelt asked him whether China would like to claim the Ryukyu Islands from Japan in addition to retaking Taiwan, the Pescadores, and Manchuria. Chiang claims that he said he was in favor of an international presence on the islands. However, the U.S. became the sole protector of the Ryukyus in 1945, and reverted it to the Japanese in 1972 while securing US military presence there.

In 1945, when Japan surrendered, Chiang's Chongqing government was ill-equipped and ill-prepared to reassert its authority in formerly Japanese-occupied China, and it asked the Japanese to postpone their surrender until Kuomintang (KMT) authority could arrive to take over. American troops and weapons soon bolstered KMT forces, allowing them to reclaim cities. The countryside, however, remained largely under Communist control.

For over a year after the Japanese surrender, rumors circulated throughout China that the Japanese had entered into a secret agreement with Chiang, in which the Japanese would assist the Nationalists in fighting the Communists in exchange for the protection of Japanese persons and property there. Many top nationalist generals, including Chiang, had studied and trained in Japan before the Nationalists had returned to the mainland in the 1920s, and maintained close personal friendships with top Japanese officers. The Japanese general in charge of all forces in China, General Yasuji Okamura, had personally trained officers who later became generals in Chiang's staff. Reportedly, General Okamura, before surrendering command of all Japanese military forces in Nanjing, offered Chiang control of all 1.5 million Japanese military and civilian support staff then present in China. Reportedly, Chiang seriously considered accepting this offer, but declined only in the knowledge that the United States would certainly be outraged by the gesture. Even so, armed Japanese troops remained in China well into 1947, with some noncommissioned officers finding their way into the Nationalist officer corps. That the Japanese in China came to regard Chiang as a magnanimous figure to whom many Japanese owed their lives and livelihoods was a fact attested by both Nationalist and Communist sources.

Westad says the Communists won the Civil War because they made fewer military mistakes than Chiang Kai-Shek, and because in his search for a powerful centralized government, Chiang antagonized too many interest groups in China. Furthermore, his party was weakened in the war against Japan. Meanwhile, the Communists told different groups, such as peasants, exactly what they wanted to hear, and cloaked themselves in the cover of Chinese Nationalism.

Following the war, the United States encouraged peace talks between Chiang and Communist leader Mao Zedong in Chongqing. Due to concerns about widespread and well-documented corruption in Chiang's government throughout his rule, the U.S. government limited aid to Chiang for much of the period of 1946 to 1948, in the midst of fighting against the People's Liberation Army led by Mao Zedong. Alleged infiltration of the U.S. government by Chinese Communist agents may have also played a role in the suspension of American aid.

Chiang's right-hand man, the secret police Chief Dai Li, was both anti-American and anti-Communist. Dai ordered Kuomintang agents to spy on American officers. Earlier, Dai had been involved with the Blue Shirts Society, a fascist-inspired paramilitary group within the Kuomintang, which wanted to expel Western and Japanese imperialists, crush the Communists, and eliminate feudalism. Dai Li died in a plane crash, which was suspected to be an assassination orchestrated by Chiang.

Although Chiang had achieved status abroad as a world leader, his government deteriorated as the result of corruption and inflation. In his diary on June 1948, Chiang wrote that the KMT had failed, not because of external enemies but because of rot from within. The war had severely weakened the Nationalists, while the Communists were strengthened by their popular land-reform policies, and by a rural population that supported and trusted them. The Nationalists initially had superiority in arms and men, but their lack of popularity, infiltration by Communist agents, low morale, and disorganization soon allowed the Communists to gain the upper hand in the civil war.

A new Constitution was promulgated in 1947, and Chiang was elected by the National Assembly as the first term President of the Republic of China on 20 May 1948. This marked the beginning of what was termed the "democratic constitutional government" period by the KMT political orthodoxy, but the Communists refused to recognize the new Constitution, and its government, as legitimate. Chiang resigned as President on 21 January 1949, as KMT forces suffered terrible losses and defections to the Communists. After Chiang's resignation the vice-president of the ROC, Li Zongren, became China's acting president.

Shortly after Chiang's resignation the Communists halted their advances and attempted to negotiate the virtual surrender of the ROC. Li attempted to negotiate milder terms that would have ended the civil war, but without success. When it became clear that Li was unlikely to accept Mao's terms, the Communists issued an ultimatum in April 1949, warning that they would resume their attacks if Li did not agree within five days. Li refused.

Li's attempts to carry out his policies faced varying degrees of opposition from Chiang's supporters, and were generally unsuccessful. Chiang especially antagonized Li by taking possession of (and moving to Taiwan) US$200 million of gold and US dollars belonging to the central government that Li desperately needed to cover the government's soaring expenses. When the Communists captured the Nationalist capital of Nanjing in April 1949, Li refused to accompany the central government as it fled to Guangdong, instead expressing his dissatisfaction with Chiang by retiring to Guangxi.
The former warlord Yan Xishan, who had fled to Nanjing only one month before, quickly insinuated himself within the Li-Chiang rivalry, attempting to have Li and Chiang reconcile their differences in the effort to resist the Communists. At Chiang's request Yan visited Li in order to convince Li not to withdraw from public life. Yan broke down in tears while talking of the loss of his home province of Shanxi to the Communists, and warned Li that the Nationalist cause was doomed unless Li went to Guangdong. Li agreed to return under the condition that Chiang surrender most of the gold and US dollars in his possession that belonged to the central government, and that Chiang stop overriding Li's authority. After Yan communicated these demands and Chiang agreed to comply with them, Li departed for Guangdong.

In Guangdong, Li attempted to create a new government composed of both Chiang supporters and those opposed to Chiang. Li's first choice of premier was Chu Cheng, a veteran member of the Kuomintang who had been virtually driven into exile due to his strong opposition to Chiang. After the Legislative Yuan rejected Chu, Li was obliged to choose Yan Xishan instead. By this time Yan was well known for his adaptability and Chiang welcomed his appointment.

Conflict between Chiang and Li persisted. Although he had agreed to do so as a prerequisite of Li's return, Chiang refused to surrender more than a fraction of the wealth that he had sent to Taiwan. Without being backed by gold or foreign currency, the money issued by Li and Yan quickly declined in value until it became virtually worthless.

Although he did not hold a formal executive position in the government, Chiang continued to issue orders to the army, and many officers continued to obey Chiang rather than Li. The inability of Li to coordinate KMT military forces led him to put into effect a plan of defense that he had contemplated in 1948. Instead of attempting to defend all of southern China, Li ordered what remained of the Nationalist armies to withdraw to Guangxi and Guangdong, hoping that he could concentrate all available defenses on this smaller, and more easily defensible, area. The object of Li's strategy was to maintain a foothold on the Chinese mainland in the hope that the United States would eventually be compelled to enter the war in China on the Nationalist side.

Chiang opposed Li's plan of defense because it would have placed most of the troops still loyal to Chiang under the control of Li and Chiang's other opponents in the central government. To overcome Chiang's intransigence Li began ousting Chiang's supporters within the central government. Yan Xishan continued in his attempts to work with both sides, creating the impression among Li's supporters that he was a "stooge" of Chiang, while those who supported Chiang began to bitterly resent Yan for his willingness to work with Li. Because of the rivalry between Chiang and Li, Chiang refused to allow Nationalist troops loyal to him to aid in the defense of Kwangsi and Canton, with the result that Communist forces occupied Canton in October 1949.

After Canton fell to the Communists, Chiang relocated the government to Chongqing, while Li effectively surrendered his powers and flew to New York for treatment of his chronic duodenum illness at the Hospital of Columbia University. Li visited the President of the United States, Harry S. Truman, and denounced Chiang as a dictator and an usurper. Li vowed that he would "return to crush" Chiang once he returned to China. Li remained in exile, and did not return to Taiwan.

In the early morning of 10 December 1949, Communist troops laid siege to Chengdu, the last KMT-controlled city in mainland China, where Chiang Kai-shek and his son Chiang Ching-kuo directed the defense at the Chengtu Central Military Academy. Chiang Kai-shek, father and son, were evacuated to Taiwan on an aircraft called "May-ling" and arrived the same day. Chiang Kai-shek would never return to the mainland.

Chiang did not re-assume the presidency until 1 March 1950. On January 1952, Chiang commanded the Control Yuan, now in Taiwan, to impeach Li in the "Case of Li Zongren's Failure to carry out Duties due to Illegal Conduct" (李宗仁違法失職案). Chiang relieved Li of the position as vice-president in the National Assembly in March 1954.

Chiang moved the government to Taipei, Taiwan, where he resumed his duties as President of the Republic of China on 1 March 1950. Chiang was reelected by the National Assembly to be the President of the Republic of China (ROC) on 20 May 1954, and again in 1960, 1966, and 1972. He continued to claim sovereignty over all of China, including the territories held by his government and the People's Republic, as well as territory the latter ceded to foreign governments, such as Tuva and Outer Mongolia. In the context of the Cold War, most of the Western world recognized this position and the ROC represented China in the United Nations and other international organizations until the 1970s.
During his presidency on Taiwan, Chiang continued making preparations in order to take back mainland China. He developed the ROC army in order to prepare for an invasion of the mainland, and to defend Taiwan in case of an attack by the Communist forces. He also financed armed groups in mainland China, such as Muslim soldiers of the ROC Army left in Yunnan under Li Mi, who continued to fight. It was not until the 1980s that these troops were finally airlifted to Taiwan. He promoted the Uyghur Yulbars Khan to Governor during the Islamic insurgency on the mainland for resisting the Communists, even though the government had already evacuated to Taiwan. He planned an invasion of the mainland in 1962. In the 1950s Chiang's airplanes dropped supplies to Kuomintang Muslim insurgents in Amdo.

Despite the democratic constitution, the government under Chiang was a one-party state, consisting almost completely of mainlanders; the "Temporary Provisions Effective During the Period of Communist Rebellion" greatly enhanced executive powers, and the goal of retaking mainland China allowed the KMT to maintain a monopoly on power and the prohibition of opposition parties. The government's official line for these martial law provisions stemmed from the claim that emergency provisions were necessary, since the Communists and KMT were still in a state of war. Seeking to promote Chinese nationalism, Chiang's government actively ignored and suppressed local cultural expression, even forbidding the use of local languages in mass media broadcasts or during class sessions. As a result of Taiwan's anti-government uprising in 1947, known as the February 28 incident, the KMT-led political repression resulted in the death or disappearance of over 30,000 Taiwanese intellectuals, activists, and people suspected of opposition to the KMT.

The first decades after the Nationalists moved the seat of government to the province of Taiwan are associated with the organized effort to resist Communism known as the "White Terror", during which about 140,000 Taiwanese were imprisoned for their real or perceived opposition to the Kuomintang. Most of those prosecuted were labeled by the Kuomintang as "bandit spies" (匪諜), meaning spies for Chinese Communists, and punished as such.

Under Chiang, the government recognized limited civil liberties, economic freedoms, property rights (personal and intellectual) and other liberties. Despite these restrictions, free debate within the confines of the legislature was permitted. Under the pretext that new elections could not be held in Communist-occupied constituencies, the National Assembly, Legislative Yuan, and Control Yuan members held their posts indefinitely. The Temporary Provisions also allowed Chiang to remain as president beyond the two-term limit in the Constitution. He was reelected by the National Assembly as president four times—doing so in 1954, 1960, 1966, and 1972.
Believing that corruption and a lack of morals were key reasons that the KMT lost mainland China to the Communists, Chiang attempted to purge corruption by dismissing members of the KMT accused of graft. Some major figures in the previous mainland Chinese government, such as H. H. Kung and T. V. Soong, exiled themselves to the United States. Although politically authoritarian and, to some extent, dominated by government-owned industries, Chiang's new Taiwanese state also encouraged economic development, especially in the export sector. A popular sweeping Land Reform Act, as well as American foreign aid during the 1950s, laid the foundation for Taiwan's economic success, becoming one of the Four Asian Tigers.

Chiang personally had the power to review the rulings of all military tribunals which during the martial law period tried civilians as well. In 1950 Lin Pang-chun and two other men were arrested on charges of financial crimes and sentenced to 3-10 years in prison. Chiang reviewed the sentences of all three and ordered them executed instead. In 1954 Changhua monk Kao Chih-te and two others were sentenced to 12 years in prison for providing aid to accused communists, Chiang sentenced them to death after reviewing the case. This control over the decision of military tribunals violated the ROC constitution.

After Chiang's death, the next president, Chiang's son, Chiang Ching-kuo, and Chiang Ching-kuo's successor, Lee Teng-hui a native Taiwanese, would, in the 1980s and 1990s, increase native Taiwanese representation in the government and loosen the many authoritarian controls of the early era of ROC control in Taiwan.

In 1971, the Australian Opposition Leader Gough Whitlam, who became Prime Minister in 1972 and swiftly relocated the Australian mission from Taipei to Beijing, visited Japan. After meeting with the Japanese Prime Minister, Eisaku Sato, Whitlam observed that the reason Japan at that time was hesitant to withdraw recognition from the Nationalist government was "the presence of a treaty between the Japanese government and that of Chiang Kai-shek". Sato explained that the continued recognition of Japan towards the Nationalist government was due largely to the personal relationship that various members of the Japanese government felt towards Chiang. This relationship was rooted largely in the generous and lenient treatment of Japanese prisoners-of-war by the Nationalist government in the years immediately following the Japanese surrender in 1945, and was felt especially strongly as a bond of personal obligation by the most senior members then in power.

Although Japan recognized the People's Republic in 1972, shortly after Kakuei Tanaka succeeded Sato as Prime Minister of Japan, the memory of this relationship was strong enough to be reported by "The New York Times" (15 April 1978) as a significant factor inhibiting trade between Japan and the mainland. There is speculation that a clash between Communist forces and a Japanese warship in 1978 was caused by Chinese anger after Prime Minister Takeo Fukuda attended Chiang's funeral. Historically, Japanese attempts to normalize their relationship with the People's Republic were met with accusations of ingratitude in Taiwan.

Chiang was suspicious that covert operatives of the United States plotted a coup against him. In 1950, Chiang Ching-kuo became director of the secret police (Bureau of Investigation and Statistics), which he remained until 1965. Chiang was also suspicious of politicians who were overly friendly to the United States, and considered them his enemies. In 1953, seven days after surviving an assassination attempt, Wu Kuo-chen lost his position as governor of Taiwan Province to Chiang Ching-kuo. After fleeing to United States the same year, he became a vocal critic of Chiang's family and government.

Chiang Ching-kuo, educated in the Soviet Union, initiated Soviet-style military organization in the Republic of China Military. He reorganized and Sovietized the political officer corps, and propagated Kuomintang ideology throughout the military. Sun Li-jen, who was educated at the American Virginia Military Institute, was opposed to this.

Chiang Ching-kuo orchestrated the controversial court-martial and arrest of General Sun Li-jen in August 1955, for plotting a coup d'état with the American Central Intelligence Agency (CIA) against his father Chiang Kai-shek and the Kuomintang. The CIA allegedly wanted to help Sun take control of Taiwan and declare its independence.

In 1975, 26 years after Chiang came to Taiwan, he died in Taipei at the age of 87. He had suffered a heart attack and pneumonia in the foregoing months and died from renal failure aggravated with advanced cardiac failure on 5 April. Chiang's funeral was held on April 16.

A month of mourning was declared. Chinese music composer Hwang Yau-tai wrote the Chiang Kai-shek Memorial Song. In mainland China, however, Chiang's death was met with little apparent mourning and Communist state-run newspapers gave the brief headline "Chiang Kai-shek Has Died." Chiang's body was put in a copper coffin and temporarily interred at his favorite residence in Cihu, Daxi, Taoyuan. His funeral was attended by dignitaries from many nations, including American Vice President Nelson Rockefeller, South Korean Prime Minister Kim Jong-pil and two former Japanese prime ministers : Nobusuke Kishi and Eisaku Sato. Chiang Kai-shek Memorial Day () was established on April 5. The memorial day was disestablished in 2007.

When his son Chiang Ching-kuo died in 1988, he was entombed in a separate mausoleum in nearby Touliao (頭寮). The hope was to have both buried at their birthplace in Fenghua if and when it was possible. In 2004, Chiang Fang-liang, the widow of Chiang Ching-kuo, asked that both father and son be buried at Wuzhi Mountain Military Cemetery in Xizhi, Taipei County (now New Taipei City). Chiang's ultimate funeral ceremony became a political battle between the wishes of the state and the wishes of his family.

Chiang was succeeded as President by Vice President Yen Chia-kan and as Kuomintang party ruler by his son Chiang Ching-kuo, who retired Chiang Kai-shek's title of Director-General and instead assumed the position of Chairman. Yen's presidency was interim; Chiang Ching-kuo, who was the Premier, became President after Yen's term ended three years later.

Chiang's portrait hung over Tiananmen Square before Mao's portrait was set up in its place. People also put portraits of Chiang in their homes and in public on the streets.

After his death, the Chiang Kai-shek Memorial Song was written in 1988 to commemorate Chiang Kai-shek.

In Cihu, there are several statues of Chiang Kai-shek.
Chiang was popular among many people and dressed in plain, simple clothes, unlike contemporary Chinese warlords who dressed extravagantly.

Quotes from the Quran and Hadith were used by Muslims in the Kuomintang-controlled Muslim publication, the "Yuehua", to justify Chiang Kai-shek's rule over China.

When the Muslim General and Warlord Ma Lin was interviewed, Ma Lin was described as having "high admiration for and unwavering loyalty to Chiang Kai-shek".

In the Philippines, a school was named in his honour in 1939. Today, Chiang Kai-shek College is the largest educational institution for the Chinoy community in the country.

The Kuomintang used traditional Chinese religious ceremonies, and promulgated/practised martyrdom in Chinese culture. Kuomintang ideology subserved and promulgated the view that the souls of Party martyrs who died fighting for the Kuomintang, the revolution, and the party founder Dr. Sun Yat-sen were sent to heaven. Chiang Kai-shek believed that these martyrs witnessed events on Earth from heaven after their deaths.

When the Northern Expedition was complete, Kuomintang Generals led by Chiang Kai-shek paid tribute to Dr. Sun's soul in heaven with a sacrificial ceremony at the Xiangshan Temple in Beijing in July 1928. Among the Kuomintang Generals present were the Muslim Generals Bai Chongxi and Ma Fuxiang.

Chiang Kai-shek considered both Han Chinese and all ethnic minorities of China, the Five Races Under One Union, as descendants of the Yellow Emperor, the mythical founder of the Chinese nation, and belonging to the Chinese Nation Zhonghua Minzu and he introduced this into Kuomintang ideology, which was propagated into the educational system of the Republic of China.

Chiang's legacy has been the target of heated debates because of the different views held about him. For some, Chiang was a national hero who led the victorious Northern Expedition against the Beiyang Warlords in 1927, achieving Chinese unification, and who subsequently led China to ultimate victory against Japan in 1945. Some blamed him for not doing enough against the Japanese forces in the lead-up to, and during, the Second Sino-Japanese War, preferring to withhold his armies for the fight against the Communists, or merely waiting and hoping that the United States would get involved. Some also see him as a champion of anti-Communism, being a key figure during the formative years of the World Anti-Communist League. During the Cold War, he was also seen as the leader who led Free China and the bulwark against a possible Communist invasion. However, Chiang presided over purges, political authoritarianism, and graft during his tenure in mainland China, and ruled throughout a period of imposed martial law. His governments were accused of being corrupt even before he even took power in 1928. He also allied with known criminals like Du Yuesheng for political and financial gains. Some opponents charge that Chiang's efforts in developing Taiwan were mostly to make the island a strong base from which to one day return to mainland China, and that Chiang had little regard for the long-term prosperity and well-being of the Taiwanese people.

Today, Chiang's popularity in Taiwan is divided along political lines, enjoying greater support among Kuomintang (KMT) supporters. He is generally unpopular among Democratic Progressive Party (DPP) voters and supporters who blame him for the thousands killed during the February 28 Incident and criticise his subsequent dictatorial rule. In sharp contrast to his son, Chiang Ching-kuo, and to Sun Yat-sen, his memory is rarely invoked by current political parties, including the Kuomintang. In contrast, his image has been rehabilitated in contemporary Mainland China. Until recently portrayed as a villain who fought against the "liberation" of China by the Communists, since the 2000s, he has been portrayed by the media in a neutral or slightly positive light as a Chinese nationalist who tried to bring about national unification and resisted the Japanese invasion during World War II. This shift is largely in response to current political landscape of Taiwan, in relation to Chiang's commitment to a unified China and his stance against Taiwanese separatism during his rule of the island, along with the recent détente between the Chinese Communist Party (CPC) and Chiang's KMT. In contrast to efforts to remove his public monuments in Taiwan, his ancestral home in Fenghua, Zhejiang on the Mainland has become a commemorative museum and major tourist attraction.

In the United States and Europe, Chiang was often perceived negatively as the one who lost China to the Communists. His constant demands for Western support and funding also earned him the nickname of "General Cash-My-Check". In the West he has been criticized for his poor military skills. He had a record of issuing unrealistic orders and persistently attempting to fight unwinnable battles, leading to the loss of his best troops.

In recent years, there has been an attempt to find a more moderate interpretation of Chiang. Chiang is now increasingly perceived as a man simply overwhelmed by the events in China, having to fight simultaneously Communists, Japanese, and provincial warlords while having to reconstruct and unify the country. His sincere, albeit often unsuccessful attempts to build a more powerful nation have been noted by scholars such as Jonathan Fenby and Rana Mitter. Mitter has observed that, ironically, today's China is closer to Chiang's vision than to Mao Zedong's. He argues that the Communists, since the 1980s, have essentially created the state envisioned by Chiang in the 1930s. Mitter concludes by writing that "one can imagine Chiang Kai-shek's ghost wandering round China today nodding in approval, while Mao's ghost follows behind him, moaning at the destruction of his vision". Liang Shuming opined that Chiang Kai-shek's "greatest contribution was to make the CCP successful. If he had been a bit more trustworthy, if his character was somewhat better, the CCP would have been unable to beat him".

"Formosa Betrayed", one of the few American movies concerning the process of democratization in Taiwan, depicts Chiang Kai-shek as a brutal dictator, responsible for the execution of thousands of native Taiwanese during the days following the February 28 Incident.

In 1901 in an arranged marriage at age 14, Chiang was married to a fellow villager named Mao Fumei who was illiterate and five years his senior. While married to Mao, Chiang adopted two concubines (concubinage was still a common practice for well-to-do, non-Christian males in China): he took Yao Yecheng (, 1889–1972) as concubine in late 1912 and married Chen Jieru (陳潔如, 1906–1971) in December 1921. While he was still living in Shanghai, Chiang and Yao adopted a son, Wei-kuo. Chen adopted a daughter in 1924, named Yaoguang (瑤光), who later adopted her mother's surname. Chen's autobiography refuted the idea that she was a concubine. Chen claiming that, by the time she married Chiang, he had already divorced Yao, and that Chen was therefore his wife. Chiang and Mao had a son, Ching-kuo.

According to the memoirs of Chen Jieru, Chiang's second wife, she contracted gonorrhea from Chiang soon after their marriage. He told her that he acquired this disease after separating from his first wife and living with his concubine Yao Yecheng, as well as with many other women he consorted with. His doctor explained to her that Chiang had sex with her before completing his treatment for the disease. As a result, both Chiang and Ch'en Chieh-ju believed they had become sterile, which would explain why he had only one child, by his first wife; however, a purported miscarriage by Soong Mei-ling in August 1928 would, if it actually occurred, cast serious doubt on whether this was true.

The Xikou (Chikow) Chiangs were descended from Chiang Shih-chieh who during the 1600s (17th century) moved there from Fenghua district, whose ancestors in turn came to southeastern China's Zhejiang (Chekiang) province after moving out of Northern China in the 13th century AD. The 12th century BC Duke of Zhou's (Duke of Chou) third son was the ancestors of the Chiangs.

His great grandfather was Chiang Qi-zeng (Jiang Qizeng) 蔣祈增, his grandfather was Chiang Si-qian 蔣斯千, his uncle was Chiang Zhao-hai 蔣肇海, and his father was Chiang Zhao-cong (Jiang Zhaocong) 蔣肇聰.

Chiang personally dealt extensively with religions and power figures in China during his regime.

Chiang Kai-shek was born and raised as a Buddhist, but became a Methodist upon his marriage to his fourth wife, Soong Mei-ling. It was previously believed that this was a political move, but studies of his recently opened diaries suggest that his faith was sincere.

Chiang developed relationships with other generals. Chiang became a sworn brother of the Chinese Muslim general Ma Fuxiang and appointed him to high ranking positions. Chiang addressed Ma Fuxiang's son Ma Hongkui as Shao Yun Shixiong Ma Fuxiang attended national leadership conferences with Chiang during battles against Japan. Ma Hongkui was eventually scapegoated for the failure of the Ningxia Campaign against the Communists, so he moved to the US instead of remaining in Taiwan with Chiang.

When Chiang became President of China after the Northern Expedition, he carved out Ningxia and Qinghai out of Gansu province, and appointed Muslim generals as military governors of all three provinces: Ma Hongkui, Ma Hongbin, and Ma Qi. The three Muslim governors, known as Xibei San Ma (lit. "the three Mas of the Northwest"), controlled armies composed entirely of Muslims. Chiang called on the three and their subordinates to wage war against the Soviet peoples, Tibetans, Communists, and the Japanese. Chiang continued to appoint Muslims as governors of the three provinces, including Ma Lin and Ma Fushou. Chiang's appointments, the first time that Muslims had been appointed as governors of Gansu, increased the prestige of Muslim officials in northwestern China. The armies raised by this "Ma Clique", most notably their Muslim cavalry, were incorporated into the KMT army. Chiang appointed a Muslim general, Bai Chongxi, as the Minister of National Defence of the Republic of China, which controlled the ROC military.

Chiang also supported the Muslim General Ma Zhongying, whom he had trained at Whampoa Military Academy during the Kumul Rebellion, in a Jihad against Jin Shuren, Sheng Shicai, and the Soviet Union during the Soviet Invasion of Xinjiang. Chiang designated Ma's Muslim army as the 36th Division (National Revolutionary Army) and gave his troops Kuomintang flags and uniforms. Chiang then supported Muslim General Ma Hushan against Sheng Shicai and the Soviet Union in the Xinjiang War (1937). All Muslim generals commissioned by Chiang in the National Revolutionary Army swore allegiance to him. Several, like Ma Shaowu and Ma Hushan were loyal to Chiang and Kuomintang hardliners.

The Ili Rebellion and Pei-ta-shan Incident plagued relations with the Soviet Union during Chiang's rule and caused trouble with the Uyghurs. During the Ili Rebellion and Peitashan incident, Chiang deployed Hui troops against Uyghur mobs in Turfan, and against Soviet Russian and Mongols at Peitashan.

During Chiang's rule, attacks on foreigners by Kuomintang forces flared up in several incidents. One of these was the Battle of Kashgar (1934) where a Muslim army loyal to the Kuomintang massacred 4,500 Uyghurs, and killed several British at the British consulate in Kashgar. The British were unable to retaliate.

Hu Songshan, a Muslim Imam, backed Chiang Kai-shek's regime and gave prayers for his government. ROC flags were saluted by Muslims in Ningxia during prayer along with exhortations to nationalism during Chiang's rule. Chiang sent Muslim students abroad to study at places like Al-Azhar University and Muslim schools throughout China taught loyalty to his regime.

The Yuehua, a Chinese Muslim publication, quoted the Quran and Hadith to justify submitting to Chiang Kai-shek as the leader of China, and as justification for Jihad in the war against Japan.

The Yihewani (Ikhwan al Muslimun a.k.a. Muslim brotherhood) was the predominant Muslim sect backed by the Chiang government during Chiang's regime. Other Muslim sects, like the Xidaotang and Sufi brotherhoods like Jahriyya and Khuffiya were also supported by his regime. The Chinese Muslim Association, a pro-Kuomintang and anti-Communist organization, was set up by Muslims working in his regime. Salafism attempted to gain a foothold in China during his regime, but the Yihewani and Hanafi Sunni Gedimu denounced the Salafis as radicals, engaged in fights against them, and declared them heretics, forcing the Salafis to form a separate sect. Ma Ching-chiang, a Muslim General, served as an advisor to Chiang Kai-shek. Ma Buqing was another Muslim General who fled to Taiwan along with Chiang. His government donated money to build the Taipei Grand Mosque on Taiwan.

Chiang had uneasy relations with the Tibetans. He fought against them in the Sino-Tibetan War, and he supported the Muslim General Ma Bufang in his war against Tibetan rebels in Qinghai. Chiang ordered Ma Bufang to prepare his Islamic army to invade Tibet several times, to deter Tibetan independence, and threatened them with aerial bombardment. After the war, Chiang appointed Ma Bufang as ambassador to Saudi Arabia.

Chiang incorporated Methodist values into the New Life Movement under the influence of his wife. Dancing and Western music were discouraged. In one incident, several youths splashed acid on people wearing Western clothing, although Chiang was not directly responsible for these incidents. Despite being a Methodist, he made reference to the Buddha in his diary, and encouraged the establishment of a Buddhist political party under Master Taixu.

According to Jehovah's Witnesses some of their members travelled to Chonqqing and spoke to him personally while distributing their literature there during the Second World War.






</doc>
<doc id="6863" url="https://en.wikipedia.org/wiki?curid=6863" title="Compression ratio">
Compression ratio

In a combustion engine, the static compression ratio is calculated based on the relative volumes of the combustion chamber and the cylinder; that is, the ratio between the volume of the cylinder and combustion chamber when the piston is at the bottom of its stroke, and the volume of the combustion chamber when the piston is at the top of its stroke. The dynamic compression ratio is a more advanced calculation which also takes into account gasses entering and exiting the cylinder during the compression phase. The compression ratio is a fundamental specification for combustion engines. 

A high compression ratio is desirable because it allows an engine to extract more mechanical energy from a given mass of air–fuel mixture due to its higher thermal efficiency. This occurs because internal combustion engines are heat engines, and higher compression ratios permit the same combustion temperature to be reached with less fuel, while giving a longer expansion cycle, creating more mechanical power output and lowering the exhaust temperature. 

In petrol (gasoline) engines used in passenger cars for the past 20 years, compression ratios have typically been between 8∶1 and 12∶1. Several production engines have used higher compression ratios, including:

When forced induction (e.g. a turbocharger or supercharger) is used, the compression ratio is often lower than naturally aspirated engines. This is due to the turbocharger/supercharger already having compressed the air before it enters the cylinders. Engines using port fuel-injection typically run lower boost pressures and/or compression ratios than direct injected engines because port fuel injection causes the air/fuel mixture to be heated together, leading to detonation. Conversely, directly injected engines can run higher boost because heated air will not detonate without a fuel being present.

Higher compression ratios can make gasoline (petrol) engines subject to engine knocking (also known as "detonation", "pre-ignition" or "pinging") if lower octane-rated fuel is used. This can reduce efficiency or damage the engine if knock sensors are not present to modify the ignition timing.

Diesel engines use higher compression ratios than petrol engines, because the lack of a spark plug means that the compression ratio must increase the temperature of the air in the cylinder sufficiently to ignite the diesel using compression ignition. Compression ratios are often between 14∶1 and 23∶1 for direct injection diesel engines, and between 18∶1 and 23∶1 for indirect injection diesel engines.

The compression ratio may be higher in engines running exclusively on liquefied petroleum gas (LPG or "propane autogas") or compressed natural gas, due to the higher octane rating of these fuels.

Kerosene engines typically use a compression ratio of 6.5 or lower. The petrol-paraffin engine version of the Ferguson TE20 tractor had a compression ratio of 4.5∶1 for operation on tractor vaporising oil with an octane rating between 55 and 70.

Motorsport engines often run on high octane petrol and can therefore use higher compression ratios. For example, motorcycle racing engines can use compression ratios as high as 14.7∶1, and it is common to find motorcycles with compression ratios above 12.0∶1 designed for 86 or 87 octane fuel.

Ethanol and methanol can take significantly higher compression ratios than gasoline. Racing engines burning methanol and ethanol fuel often have a compression ratio of 14∶1 to 16∶1.

In a piston engine, the static compression ratio (formula_1) is the ratio between the volume of the cylinder and combustion chamber when the piston is at the bottom of its stroke, and the volume of the combustion chamber when the piston is at the top of its stroke. It is therefore calculated by the formula

Where:

formula_3 can be estimated by the cylinder volume formula

Where:

Because of the complex shape of formula_4 it is usually measured directly. This is often done by filling the cylinder with liquid and then measuring the volume of the used liquid.

Most engines use a fixed compression ratio, however a variable compression ratio engine is able to adjust the compression ratio while the engine is in operation. The first production engine with a variable compression ratio was introduced in 2019.

Variable compression ratio is a technology to adjust the compression ratio of an internal combustion engine while the engine is in operation. This is done to increase fuel efficiency while under varying loads. Variable compression engines allow the volume above the piston at top dead centre to be changed.

Higher loads require lower ratios to increase power, while lower loads need higher ratios to increase efficiency, i.e. to lower fuel consumption. For automotive use this needs to be done as the engine is running in response to the load and driving demands.

The 2019 Infiniti QX50 is the first commercially available car that uses a variable compression ratio engine.

Based on the assumptions that adiabatic compression is carried out (i.e. that no heat energy is supplied to the gas being compressed, and that any temperature rise is solely due to the compression) and that air is a perfect gas, the relationship between the compression ratio and overall pressure ratio is as follows:
This relationship is derived from the following equation:

However, in most real-life internal combustion engines, the ratio of specific heats changes with temperature and that significant deviations from adiabatic behavior will occur.

The "static compression ratio" discussed above — calculated solely based on the cylinder and combustion chamber volumes — does not take into account any gasses entering or exiting the cylinder during the compression phase. In most automotive engines, the intake valve closure (which seals the cylinder) takes place during the compression phase (i.e. after bottom dead centre, BDC), which can cause some of the gasses to be pushed back out through the intake valve. On the other hand, intake port tuning and scavenging can cause a greater amount of gas to be trapped in the cylinder than the static volume would suggest. The "dynamic compression ratio" accounts for these factors.

The dynamic compression ratio is higher with more conservative intake camshaft timing (i.e. soon after BDC), and lower with more radical intake camshaft timing (i.e. later after BDC). Regardless, the dynamic compression ratio is always lower than the static compression ratio.

The absolute cylinder pressure is used to calculate the dynamic compression ratio, using the following formula:

Under ideal (adiabatic) conditions, the ratio of specific heats would be 1.4, but a lower value, generally between 1.2 and 1.3 is used, since the amount of heat lost will vary among engines based on design, size and materials used. For example, if the static compression ratio is 10∶1, and the dynamic compression ratio is 7.5∶1, a useful value for cylinder pressure would be 7.5 × atmospheric pressure, or 13.7 bar (relative to atmospheric pressure).

The two corrections for dynamic compression ratio affect cylinder pressure in opposite directions, but not in equal strength. An engine with high static compression ratio and late intake valve closure will have a dynamic compression ratio similar to an engine with lower compression but earlier intake valve closure.



</doc>
<doc id="6867" url="https://en.wikipedia.org/wiki?curid=6867" title="Context-free language">
Context-free language

In formal language theory, a context-free language (CFL) is a language generated by a context-free grammar (CFG).

Context-free languages have many applications in programming languages, in particular, most arithmetic expressions are generated by context-free grammars.

Different context-free grammars can generate the same context-free language. Intrinsic properties of the language can be distinguished from extrinsic properties of a particular grammar by comparing multiple grammars that describe the language.

The set of all context-free languages is identical to the set of languages accepted by pushdown automata, which makes these languages amenable to parsing. Further, for a given CFG, there is a direct way to produce a pushdown automaton for the grammar (and thereby the corresponding language), though going the other way (producing a grammar given an automaton) is not as direct.

A model context-free language is formula_1, the language of all non-empty even-length strings, the entire first halves of which are 's, and the entire second halves of which are 's. is generated by the grammar formula_2.
This language is not regular.
It is accepted by the pushdown automaton formula_3 where formula_4 is defined as follows:

Unambiguous CFLs are a proper subset of all CFLs: there are inherently ambiguous CFLs. An example of an inherently ambiguous CFL is the union of formula_6 with formula_7. This set is context-free, since the union of two context-free languages is always context-free. But there is no way to unambiguously parse strings in the (non-context-free) subset formula_8 which is the intersection of these two languages.

The language of all properly matched parentheses is generated by the grammar formula_9.

The context-free nature of the language makes it simple to parse with a pushdown automaton.

Determining an instance of the membership problem; i.e. given a string formula_10, determine whether formula_11 where formula_12 is the language generated by a given grammar formula_13; is also known as "recognition". Context-free recognition for Chomsky normal form grammars was shown by Leslie G. Valiant to be reducible to boolean matrix multiplication, thus inheriting its complexity upper bound of "O"("n").
Conversely, Lillian Lee has shown "O"("n") boolean matrix multiplication to be reducible to "O"("n") CFG parsing, thus establishing some kind of lower bound for the latter.

Practical uses of context-free languages require also to produce a derivation tree that exhibits the structure that the grammar associates with the given string. The process of producing this tree is called "parsing". Known parsers have a time complexity that is cubic in the size of the string that is parsed.

Formally, the set of all context-free languages is identical to the set of languages accepted by pushdown automata (PDA). Parser algorithms for context-free languages include the CYK algorithm and Earley's Algorithm.

A special subclass of context-free languages are the deterministic context-free languages which are defined as the set of languages accepted by a deterministic pushdown automaton and can be parsed by a LR(k) parser.

See also parsing expression grammar as an alternative approach to grammar and parser.

The class of context-free languages is closed under the following operations. That is, if "L" and "P" are context-free languages, the following languages are context-free as well:

The context-free languages are not closed under intersection. This can be seen by taking the languages formula_22 and formula_23, which are both context-free. Their intersection is formula_24, which can be shown to be non-context-free by the pumping lemma for context-free languages. As a consequence, context-free languages cannot be closed under complementation, as for any languages "A" and "B", their intersection can be expressed by union and complement: formula_25. In particular, context-free language cannot be closed under difference, since complement can be expressed by difference: formula_26. 

However, if "L" is a context-free language and "D" is a regular language then both their intersection formula_27 and their difference formula_28 are context-free languages.

In formal language theory, questions about regular languages are usually decidable, but ones about context-free languages are often not. It is decidable whether such a language is finite, but not whether it contains every possible string, is regular, is unambiguous, or is equivalent to a language with a different grammar.

The following problems are undecidable for arbitrarily given context-free grammars A and B:

The following problems are "decidable" for arbitrary context-free languages:

According to Hopcroft, Motwani, Ullman (2003), 
many of the fundamental closure and (un)decidability properties of context-free languages were shown in the 1961 paper of Bar-Hillel, Perles, and Shamir

The set formula_8 is a context-sensitive language, but there does not exist a context-free grammar generating this language. So there exist context-sensitive languages which are not context-free. To prove that a given language is not context-free, one may employ the pumping lemma for context-free languages or a number of other methods, such as Ogden's lemma or Parikh's theorem.



</doc>
<doc id="6868" url="https://en.wikipedia.org/wiki?curid=6868" title="Caffeine">
Caffeine

Caffeine is a central nervous system (CNS) stimulant of the methylxanthine class. It is the world's most widely consumed psychoactive drug. Unlike many other psychoactive substances, it is legal and unregulated in nearly all parts of the world. There are several known mechanisms of action to explain the effects of caffeine. The most prominent is that it reversibly blocks the action of adenosine on its receptors and consequently prevents the onset of drowsiness induced by adenosine. Caffeine also stimulates certain portions of the autonomic nervous system.
Caffeine is a bitter, white crystalline purine, a methylxanthine alkaloid, and is chemically related to the adenine and guanine bases of deoxyribonucleic acid (DNA) and ribonucleic acid (RNA). It is found in the seeds, nuts, or leaves of a number of plants native to Africa, East Asia and South America, and helps to protect them against predator insects and to prevent germination of nearby seeds. The most well-known source of caffeine is the coffee bean, the seed of the "Coffea" plant. People may drink beverages containing caffeine to relieve or prevent drowsiness and to improve cognitive performance. To make these drinks, caffeine is extracted by steeping the plant product in water, a process called infusion. Caffeine-containing drinks, such as coffee, tea, and cola, are very popular; as of 2014, 85% of American adults consumed some form of caffeine daily, consuming 164 mg on average.
Caffeine can have both positive and negative health effects. It can treat and prevent the premature infant breathing disorders bronchopulmonary dysplasia of prematurity and apnea of prematurity. Caffeine citrate is on the WHO Model List of Essential Medicines. It may confer a modest protective effect against some diseases, including Parkinson's disease. Some people experience sleep disruption or anxiety if they consume caffeine, but others show little disturbance. Evidence of a risk during pregnancy is equivocal; some authorities recommend that pregnant women limit caffeine to the equivalent of two cups of coffee per day or less. Caffeine can produce a mild form of drug dependence – associated with withdrawal symptoms such as sleepiness, headache, and irritability – when an individual stops using caffeine after repeated daily intake. Tolerance to the autonomic effects of increased blood pressure and heart rate, and increased urine output, develops with chronic use (i.e., these symptoms become less pronounced or do not occur following consistent use).
Caffeine is classified by the US Food and Drug Administration as generally recognized as safe (GRAS). Toxic doses, over 10 grams per day for an adult, are much higher than the typical dose of under 500 milligrams per day. A cup of coffee contains 80–175 mg of caffeine, depending on what "bean" (seed) is used, how it is roasted (darker roasts have less caffeine), and how it is prepared (e.g., drip, percolation, or espresso). Thus it requires roughly 50–100 ordinary cups of coffee to reach the toxic dose. However, pure powdered caffeine, which is available as a dietary supplement, can be lethal in tablespoon-sized amounts.

Caffeine is used in:

Caffeine is a central nervous system stimulant that reduces fatigue and drowsiness. At normal doses, caffeine has variable effects on learning and memory, but it generally improves reaction time, wakefulness, concentration, and motor coordination. The amount of caffeine needed to produce these effects varies from person to person, depending on body size and degree of tolerance. The desired effects arise approximately one hour after consumption, and the desired effects of a moderate dose usually subside after about three or four hours.

Caffeine can delay or prevent sleep and improves task performance during sleep deprivation. Shift workers who use caffeine make fewer mistakes due to drowsiness.

A systematic review and meta-analysis from 2014 found that concurrent caffeine and -theanine use has synergistic psychoactive effects that promote alertness, attention, and task switching; these effects are most pronounced during the first hour post-dose.

Caffeine is a proven ergogenic aid in humans. Caffeine improves athletic performance in aerobic (especially endurance sports) and anaerobic conditions. Moderate doses of caffeine (around 5 mg/kg) can improve sprint performance, cycling and running time trial performance, endurance (i.e., it delays the onset of muscle fatigue and central fatigue), and cycling power output. Caffeine increases basal metabolic rate in adults.

Caffeine improves muscular strength and power, and may enhance muscular endurance. Caffeine also enhances performance on anaerobic tests. Caffeine consumption before constant load exercise is associated with reduced perceived exertion. While this effect is not present during exercise-to-exhaustion exercise, performance is significantly enhanced. This is congruent with caffeine reducing perceived exertion, because exercise-to-exhaustion should end at the same point of fatigue. Caffeine also improves power output and reduces time to completion in aerobic time trials, an effect positively (but not exclusively) associated with longer duration exercise.

For the general population of healthy adults, Health Canada advises a daily intake of no more than 400 mg. This limit was found to be safe by a 2017 systematic review on caffeine toxicology.

In healthy children, moderate caffeine intake under 400 mg produces effects that are "modest and typically innocuous". Higher doses of caffeine (>400 mg) can cause physiological, psychological and behavioral harm, particularly for children with psychiatric or cardiac conditions. There is no evidence that coffee stunts a child's growth. The American Academy of Pediatrics recommends that caffeine consumption is not appropriate for children and adolescents and should be avoided. This recommendation is based on a clinical report released by American Academy of Pediatrics in 2011 with a review of 45 publications from 1994 to 2011 and includes inputs from various stakeholders (Pediatricians, Committee on nutrition, Canadian Pediatric Society, Centers for Disease Control & Prevention, Food and Drug Administration, Sports Medicine & Fitness committee, National Federations of High School Associations). For children age 12 and under, Health Canada recommends a maximum daily caffeine intake of no more than 2.5 milligrams per kilogram of body weight. Based on average body weights of children, this translates to the following age-based intake limits:

Health Canada has not developed advice for adolescents because of insufficient data. However, they suggest that daily caffeine intake for this age group be no more than 2.5 mg/kg body weight. This is because the maximum adult caffeine dose may not be appropriate for light-weight adolescents or for younger adolescents who are still growing. The daily dose of 2.5 mg/kg body weight would not cause adverse health effects in the majority of adolescent caffeine consumers. This is a conservative suggestion since older and heavier weight adolescents may be able to consume adult doses of caffeine without suffering adverse effects.

The metabolism of caffeine is reduced in pregnancy, especially in the third trimester, and the half life of caffeine during pregnancy can be increased up to 15 hours (as compared to 2.5 to 4.5 hours in non-pregnant adults). Current evidence regarding the effects of caffeine on pregnancy and for breastfeeding are inconclusive. There is limited primary and secondary advice for, or against, caffeine use during pregnancy and its effects on the fetus or newborn.

The UK Food Standards Agency has recommended that pregnant women should limit their caffeine intake, out of prudence, to less than 200 mg of caffeine a day – the equivalent of two cups of instant coffee, or one and a half to two cups of fresh coffee. The American Congress of Obstetricians and Gynecologists (ACOG) concluded in 2010 that caffeine consumption is safe up to 200 mg per day in pregnant women. For women who breastfeed, are pregnant, or may become pregnant, Health Canada recommends a maximum daily caffeine intake of no more than 300 mg, or a little over two 8 oz (237 mL) cups of coffee. A 2017 systematic review on caffeine toxicology found evidence supporting that caffeine consumption up to 300 mg/day for pregnant women is generally not associated with adverse reproductive or developmental effect.

There are conflicting reports in the scientific literature about caffeine use during pregnancy. A 2011 review found that caffeine during pregnancy does not appear to increase the risk of congenital malformations, miscarriage or growth retardation even when consumed in moderate to high amounts. Other reviews, however, concluded that there is some evidence that higher caffeine intake by pregnant women may be associated with a higher risk of giving birth to a low birth weight baby, and may be associated with a higher risk of pregnancy loss. A systematic review, analyzing the results of observational studies, suggests that women who consume large amounts of caffeine (greater than 300 mg/day) prior to becoming pregnant may have a higher risk of experiencing pregnancy loss.

Coffee and caffeine can affect gastrointestinal motility and gastric acid secretion. Caffeine in low doses may cause weak bronchodilation for up to four hours in asthmatics. In postmenopausal women, high caffeine consumption can accelerate bone loss.

Acute ingestion of caffeine in large doses (at least 250–300 mg, equivalent to the amount found in 2–3 cups of coffee or 5–8 cups of tea) results in a short-term stimulation of urine output in individuals who have been deprived of caffeine for a period of days or weeks. This increase is due to both a diuresis (increase in water excretion) and a natriuresis (increase in saline excretion); it is mediated via proximal tubular adenosine receptor blockade. The acute increase in urinary output may increase the risk of dehydration. However, chronic users of caffeine develop a tolerance to this effect and experience no increase in urinary output.

Minor undesired symptoms from caffeine ingestion not sufficiently severe to warrant a psychiatric diagnosis are common and include mild anxiety, jitteriness, insomnia, increased sleep latency, and reduced coordination. Caffeine can have negative effects on anxiety disorders. According to a 2011 literature review, caffeine use is positively associated with anxiety and panic disorders. At high doses, typically greater than 300 mg, caffeine can both cause and worsen anxiety. For some people, discontinuing caffeine use can significantly reduce anxiety. In moderate doses, caffeine has been associated with reduced symptoms of depression and lower suicide risk.

Increased consumption of coffee and caffeine is associated with a decreased risk of depression.

Some textbooks state that caffeine is a mild euphoriant, others state that it is not a euphoriant, and one states that it is and is not a euphoriant.

Caffeine-induced anxiety disorder is a subclass of the DSM-5 diagnosis of substance/medication-induced anxiety disorder.

Whether caffeine can result in an addictive disorder depends on how addiction is defined. Compulsive caffeine consumption under any circumstances has not been observed, and caffeine is therefore not generally considered addictive. However, some diagnostic models, such as the and ICD-10, include a classification of caffeine addiction under a broader diagnostic model. Some state that certain users can become addicted and therefore unable to decrease use even though they know there are negative health effects.

Caffeine does not appear to be a reinforcing stimulus, and some degree of aversion may actually occur, with people preferring placebo over caffeine in a study on drug abuse liability published in an NIDA research monograph. Some state that research does not provide support for an underlying biochemical mechanism for caffeine addiction. Other research states it can affect the reward system.

"Caffeine addiction" was added to the ICDM-9 and ICD-10. However, its addition was contested with claims that this diagnostic model of caffeine addiction is not supported by evidence. The American Psychiatric Association's does not include the diagnosis of a "caffeine addiction" but proposes criteria for the disorder for more study.

Withdrawal can cause mild to clinically significant distress or impairment in daily functioning. The frequency at which this occurs is self-reported at 11%, but in lab tests only half of the people who report withdrawal actually experience it, casting doubt on many claims of dependence. Mild physical dependence and withdrawal symptoms may occur upon abstinence, with greater than 100 mg caffeine per day, although these symptoms last no longer than a day. Some symptoms associated with psychological dependence may also occur during withdrawal. The diagnostic criteria for caffeine withdrawal require a previous prolonged daily use of caffeine. Following 24 hours of a marked reduction in consumption, a minimum of 3 of these signs or symptoms is required to meet withdrawal criteria: difficulty concentrating, depressed mood/irritability, flu-like symptoms, headache, and fatigue. Additionally, the signs and symptoms must disrupt important areas of functioning and are not associated with effects of another condition

The ICD-11 includes caffeine dependence as a distinct diagnostic category, which closely mirrors the DSM-5’s proposed set of criteria for “caffeine-use disorder”.  Caffeine use disorder refers to dependence on caffeine characterized by failure to control caffeine consumption despite negative physiological consequences. The APA, which published the DSM-5, acknowledged that there was sufficient evidence in order to create a diagnostic model of caffeine dependence for the DSM-5, but they noted that the clinical significance of the disorder is unclear. Due to this inconclusive evidence on clinical significance, the DSM-5 classifies caffeine-use disorder as a “condition for further study”.

Tolerance to the effects of caffeine occurs for caffeine induced elevations in blood pressure and the subjective feelings of nervousness. Sensitization, the process whereby effects become more prominent with use, occurs for positive effects such as feelings of alertness and well being. Tolerance varies for daily, regular caffeine users and high caffeine users. High doses of caffeine (750 to 1200 mg/day spread throughout the day) have been shown to produce complete tolerance to some, but not all of the effects of caffeine. Doses as low as 100 mg/day, such as a 6 oz cup of coffee or two to three 12 oz servings of caffeinated soft-drink, may continue to cause sleep disruption, among other intolerances. Non-regular caffeine users have the least caffeine tolerance for sleep disruption. Some coffee drinkers develop tolerance to its undesired sleep-disrupting effects, but others apparently do not.

A protective effect of caffeine against Alzheimer's disease and dementia is possible but the evidence is inconclusive. It may protect people from liver cirrhosis. Caffeine may lessen the severity of acute mountain sickness if taken a few hours prior to attaining a high altitude. One meta analysis has found that caffeine consumption is associated with a reduced risk of type 2 diabetes. Two meta analyses have reported that caffeine consumption is associated with a linear reduction in risk for Parkinson's disease. Caffeine consumption may be associated with reduced risk of depression, although conflicting results have been reported.

Caffeine increases intraocular pressure in those with glaucoma but does not appear to affect normal individuals.

The DSM-5 also includes other caffeine-induced disorders consisting of caffeine-induced anxiety disorder, caffeine-induced sleep disorder and unspecified caffeine-related disorders. The first two disorders are classified under “Anxiety Disorder” and “Sleep-Wake Disorder” because they share similar characteristics. Other disorders that present with significant distress and impairment of daily functioning that warrant clinical attention but do not meet the criteria to be diagnosed under any specific disorders are listed under “Unspecified Caffeine-Related Disorders”.

Consumption of per day is associated with a condition known as "<dfn>caffeinism</dfn>." Caffeinism usually combines caffeine dependency with a wide range of unpleasant symptoms including nervousness, irritability, restlessness, insomnia, headaches, and palpitations after caffeine use.

Caffeine overdose can result in a state of central nervous system over-stimulation known as caffeine intoxication, a clinically significant temporary condition that develops during, or shortly after, the consumption of caffeine. This syndrome typically occurs only after ingestion of large amounts of caffeine, well over the amounts found in typical caffeinated beverages and caffeine tablets (e.g., more than 400–500 mg at a time). According to the DSM-5, caffeine intoxication may be diagnosed if five (or more) of the following symptoms develop after recent consumption of caffeine: restlessness, nervousness, excitement, insomnia, flushed face, diuresis (increased production of urine), gastrointestinal disturbance, muscle twitching, rambling flow of thought and speech, tachycardia (increased heart rate) or cardiac arrythmia, periods of inexhaustibility, and psychomotor agitation.

According to the International Classification of Diseases (ICD-11), cases of very high caffeine intake (e.g. > 5 g) may result in caffeine intoxication with symptoms including mania, depression, lapses in judgement, disorientation, disinhibition, delusions, hallucinations or psychosis, and rhabdomyolysis (breakdown of skeletal muscle tissue).

Death from caffeine ingestion appears to be rare, and most commonly caused by an intentional overdose of medications. In 2016, 3702 caffeine related exposure were reported to Poison Control Centers in the United States, of which 846 required an hospitalization and 16 with a major outcome, and several caffeine-related deaths are reported in case studies. The LD of caffeine in humans is dependent on individual sensitivity, but is estimated to be 150–200 milligrams per kilogram (2.2 lb) of body mass (75–100 cups of coffee for a adult). There are cases where doses as low as 57 milligrams per kilogram have been fatal. A number of fatalities have been caused by overdoses of readily available powdered caffeine supplements, for which the estimated lethal amount is less than a tablespoon. The lethal dose is lower in individuals whose ability to metabolize caffeine is impaired due to genetics or chronic liver disease. A death was reported in a man with liver cirrhosis who overdosed on caffeinated mints.

High caffeine consumption in energy drinks (At least 1 liter or 320 mg of caffeine) was associated with short term cardiovascular side effects including hypertension, prolonged QT interval and heart palpitations. These cardiovascular side effects were not seen with smaller amounts of caffeine consumption in energy drinks (less than 200 mg).

Since there is no antidote nor reversal agent for caffeine intoxication, treatment of mild caffeine intoxication is directed toward symptom relief; severe intoxication may require peritoneal dialysis, hemodialysis, or hemofiltration.

Caffeine is a substrate for CYP1A2, and interacts with many substances through this and other mechanisms.

According to DSST, alcohol provides a reduction in performance and caffeine has a significant improvement in performance. When alcohol and caffeine are consumed jointly, the effects produced by caffeine are affected, but the alcohol effects remain the same. For example, when additional caffeine is added, the drug effect produced by alcohol is not reduced. However, the jitteriness and alertness given by caffeine is decreased when additional alcohol is consumed. Alcohol consumption alone reduces both inhibitory and activational aspects of behavioral control. Caffeine antagonizes the activational aspect of behavioral control, but has no effect on the inhibitory behavioral control. The Dietary Guidelines for Americans recommend avoidance of concomitant consumption of alcohol and caffeine, as this may lead to increased alcohol consumption, with a higher risk of alcohol-associated injury.

Smoking tobacco increases caffeine clearance by 56%.

Birth control pills can extend the half-life of caffeine, requiring greater attention to caffeine consumption.

Caffeine sometimes increases the effectiveness of some medications, such as those for headaches. Caffeine was determined to increase the potency of some over-the-counter analgesic medications by 40%.

The pharmacological effects of adenosine may be blunted in individuals taking large quantities of methylxanthines like caffeine.

In the absence of caffeine and when a person is awake and alert, little adenosine is present in (CNS) neurons. With a continued wakeful state, over time adenosine accumulates in the neuronal synapse, in turn binding to and activating adenosine receptors found on certain CNS neurons; when activated, these receptors produce a cellular response that ultimately increases drowsiness. When caffeine is consumed, it antagonizes adenosine receptors; in other words, caffeine prevents adenosine from activating the receptor by blocking the location on the receptor where adenosine binds to it. As a result, caffeine temporarily prevents or relieves drowsiness, and thus maintains or restores alertness.

Caffeine is an antagonist of adenosine A receptors, and knockout mouse studies have specifically implicated antagonism of the A receptor as responsible for the wakefulness-promoting effects of caffeine. Antagonism of A2A receptors in the ventrolateral preoptic area (VLPO) reduces inhibitory GABA neurotransmission to the tuberomammillary nucleus, a histaminergic projection nucleus that activation-dependently promotes arousal. This disinhibition of the tuberomammillary nucleus is the downstream mechanism by which caffeine produces wakefulness-promoting effects. Caffeine is an antagonist of all four adenosine receptor subtypes (A, A, A, and A), although with varying potencies. The affinity (K) values of caffeine for the human adenosine receptors are 12 μM at A, 2.4 μM at A, 13 μM at A, and 80 μM at A.

Antagonism of adenosine receptors by caffeine also stimulates the medullary vagal, vasomotor, and respiratory centers, which increases respiratory rate, reduces heart rate, and constricts blood vessels. Adenosine receptor antagonism also promotes neurotransmitter release (e.g., monoamines and acetylcholine), which endows caffeine with its stimulant effects; adenosine acts as an inhibitory neurotransmitter that suppresses activity in the central nervous system. Heart palpitations are caused by blockade of the A receptor.

Because caffeine is both water- and lipid-soluble, it readily crosses the blood–brain barrier that separates the bloodstream from the interior of the brain. Once in the brain, the principal mode of action is as a nonselective antagonist of adenosine receptors (in other words, an agent that reduces the effects of adenosine). The caffeine molecule is structurally similar to adenosine, and is capable of binding to adenosine receptors on the surface of cells without activating them, thereby acting as a competitive antagonist.

In addition to its activity at adenosine receptors, caffeine is an inositol trisphosphate receptor 1 antagonist and a voltage-independent activator of the ryanodine receptors (RYR1, RYR2, and RYR3). It is also a competitive antagonist of the ionotropic glycine receptor.

While caffeine does not directly bind to any dopamine receptors, it influences the binding activity of dopamine at its receptors in the striatum by binding to adenosine receptors that have formed GPCR heteromers with dopamine receptors, specifically the A–D receptor heterodimer (this is a receptor complex with 1 adenosine A receptor and 1 dopamine D receptor) and the A–D receptor heterotetramer (this is a receptor complex with 2 adenosine A receptors and 2 dopamine D receptors). The A–D receptor heterotetramer has been identified as a primary pharmacological target of caffeine, primarily because it mediates some of its psychostimulant effects and its pharmacodynamic interactions with dopaminergic psychostimulants.

Caffeine also causes the release of dopamine in the dorsal striatum and nucleus accumbens core (a substructure within the ventral striatum), but not the nucleus accumbens shell, by antagonizing A receptors in the axon terminal of dopamine neurons and A–A heterodimers (a receptor complex composed of 1 adenosine A receptor and 1 adenosine A receptor) in the axon terminal of glutamate neurons. During chronic caffeine use, caffeine-induced dopamine release within the nucleus accumbens core is markedly reduced due to drug tolerance.

Caffeine, like other xanthines, also acts as a phosphodiesterase inhibitor. As a competitive nonselective phosphodiesterase inhibitor, caffeine raises intracellular cAMP, activates protein kinase A, inhibits TNF-alpha and leukotriene synthesis, and reduces inflammation and innate immunity. Caffeine also affects the cholinergic system where it is a moderate inhibitor of the enzyme acetylcholinesterase.

Caffeine from coffee or other beverages is absorbed by the small intestine within 45 minutes of ingestion and distributed throughout all bodily tissues. Peak blood concentration is reached within 1–2 hours. It is eliminated by first-order kinetics. Caffeine can also be absorbed rectally, evidenced by suppositories of ergotamine tartrate and caffeine (for the relief of migraine) and of chlorobutanol and caffeine (for the treatment of hyperemesis). However, rectal absorption is less efficient than oral: the maximum concentration (C) and total amount absorbed (AUC) are both about 30% (i.e., 1/3.5) of the oral amounts.

Caffeine's biological half-life – the time required for the body to eliminate one-half of a dose – varies widely among individuals according to factors such as pregnancy, other drugs, liver enzyme function level (needed for caffeine metabolism) and age. In healthy adults, caffeine's half-life is between 3 and 7 hours. Smoking decreases the half-life by 30–50%, while oral contraceptives can double it and pregnancy can raise it to as much as 15 hours during the third trimester. In newborns the half-life can be 80 hours or more, dropping very rapidly with age, possibly to less than the adult value by age 6 months. The antidepressant fluvoxamine (Luvox) reduces the clearance of caffeine by more than 90%, and increases its elimination half-life more than tenfold; from 4.9 hours to 56 hours.

Caffeine is metabolized in the liver by the cytochrome P450 oxidase enzyme system, in particular, by the CYP1A2 isozyme, into three dimethylxanthines, each of which has its own effects on the body:

1,3,7-Trimethyluric acid is a minor caffeine metabolite. Each of these metabolites is further metabolized and then excreted in the urine. Caffeine can accumulate in individuals with severe liver disease, increasing its half-life.

A 2011 review found that increased caffeine intake was associated with a variation in two genes that increase the rate of caffeine catabolism. Subjects who had this mutation on both chromosomes consumed 40 mg more caffeine per day than others. This is presumably due to the need for a higher intake to achieve a comparable desired effect, not that the gene led to a disposition for greater incentive of habituation.

Pure anhydrous caffeine is a bitter-tasting, white, odorless powder with a melting point of 235–238 °C. Caffeine is moderately soluble in water at room temperature (2 g/100 mL), but very soluble in boiling water (66 g/100 mL). It is also moderately soluble in ethanol (1.5 g/100 mL). It is weakly basic (pK of conjugate acid = ~0.6) requiring strong acid to protonate it. Caffeine does not contain any stereogenic centers and hence is classified as an achiral molecule.

The xanthine core of caffeine contains two fused rings, a pyrimidinedione and imidazole. The pyrimidinedione in turn contains two amide functional groups that exist predominantly in a zwitterionic resonance the location from which the nitrogen atoms are double bonded to their adjacent amide carbons atoms. Hence all six of the atoms within the pyrimidinedione ring system are sp hybridized and planar. Therefore, the fused 5,6 ring core of caffeine contains a total of ten pi electrons and hence according to Hückel's rule is aromatic.

The biosynthesis of caffeine is an example of convergent evolution among different species.

Caffeine may be synthesized in the lab starting with dimethylurea and malonic acid.

Commercial supplies of caffeine are not usually manufactured synthetically because the chemical is readily available as a byproduct of decaffeination.

Extraction of caffeine from coffee, to produce caffeine and decaffeinated coffee, can be performed using a number of solvents. Following are main methods:

"Decaffeinated" coffees do in fact contain caffeine in many cases – some commercially available decaffeinated coffee products contain considerable levels. One study found that decaffeinated coffee contained 10 mg of caffeine per cup, compared to approximately 85 mg of caffeine per cup for regular coffee.

Caffeine can be quantified in blood, plasma, or serum to monitor therapy in neonates, confirm a diagnosis of poisoning, or facilitate a medicolegal death investigation. Plasma caffeine levels are usually in the range of 2–10 mg/L in coffee drinkers, 12–36 mg/L in neonates receiving treatment for apnea, and 40–400 mg/L in victims of acute overdosage. Urinary caffeine concentration is frequently measured in competitive sports programs, for which a level in excess of 15 mg/L is usually considered to represent abuse.

Some analog substances have been created which mimic caffeine's properties with either function or structure or both. Of the latter group are the xanthines DMPX and 8-chlorotheophylline, which is an ingredient in dramamine. Members of a class of nitrogen substituted xanthines are often proposed as potential alternatives to caffeine. Many other xanthine analogues constituting the adenosine receptor antagonist class have also been elucidated.

Some other caffeine analogs:

Caffeine, as do other alkaloids such as cinchonine, quinine or strychnine, precipitates polyphenols and tannins. This property can be used in a quantitation method.

Around thirty plant species are known to contain caffeine. Common sources are the "beans" (seeds) of the two cultivated coffee plants, "Coffea arabica" and "Coffea canephora" (the quantity varies, but 1.3% is a typical value); and of the cocoa plant, "Theobroma cacao"; the leaves of the tea plant; and kola nuts. Other sources include the leaves of yaupon holly, South American holly yerba mate, and Amazonian holly guayusa; and seeds from Amazonian maple guarana berries. Temperate climates around the world have produced unrelated caffeine-containing plants.

Caffeine in plants acts as a natural pesticide: it can paralyze and kill predator insects feeding on the plant. High caffeine levels are found in coffee seedlings when they are developing foliage and lack mechanical protection. In addition, high caffeine levels are found in the surrounding soil of coffee seedlings, which inhibits seed germination of nearby coffee seedlings, thus giving seedlings with the highest caffeine levels fewer competitors for existing resources for survival. Caffeine is stored in tea leaves in two places. Firstly, in the cell vacuoles where it is complexed with polyphenols. This caffeine probably is released into the mouth parts of insects, to discourage herbivory. Secondly, around the vascular bundles, where it probably inhibits pathogenic fungi from entering and colonizing the vascular bundles. Caffeine in nectar may improve the reproductive success of the pollen producing plants by enhancing the reward memory of pollinators such as honey bees.

The differing perceptions in the effects of ingesting beverages made from various plants containing caffeine could be explained by the fact that these beverages also contain varying mixtures of other methylxanthine alkaloids, including the cardiac stimulants theophylline and theobromine, and polyphenols that can form insoluble complexes with caffeine.

Products containing caffeine include coffee, tea, soft drinks ("colas"), energy drinks, other beverages, chocolate, caffeine tablets, other oral products, and inhalation products. According to a 2020 study in the United States, coffee is the major source of caffeine intake in middle-aged adults, while soft drinks and tea are the major sources in adolescents. Energy drinks are more commonly consumed as a source of caffeine in adolescents as compared to adults.

The world's primary source of caffeine is the coffee "bean" (the seed of the coffee plant), from which coffee is brewed. Caffeine content in coffee varies widely depending on the type of coffee bean and the method of preparation used; even beans within a given bush can show variations in concentration. In general, one serving of coffee ranges from 80 to 100 milligrams, for a single shot (30 milliliters) of arabica-variety espresso, to approximately 100–125 milligrams for a cup (120 milliliters) of drip coffee. "Arabica" coffee typically contains half the caffeine of the "robusta" variety.
In general, dark-roast coffee has very slightly less caffeine than lighter roasts because the roasting process reduces caffeine content of the bean by a small amount.

Tea contains more caffeine than coffee by dry weight. A typical serving, however, contains much less, since less of the product is used as compared to an equivalent serving of coffee. Also contributing to caffeine content are growing conditions, processing techniques, and other variables. Thus, teas contain varying amounts of caffeine.

Tea contains small amounts of theobromine and slightly higher levels of theophylline than coffee. Preparation and many other factors have a significant impact on tea, and color is a very poor indicator of caffeine content. Teas like the pale Japanese green tea, "gyokuro", for example, contain far more caffeine than much darker teas like "lapsang souchong", which has very little.

Caffeine is also a common ingredient of soft drinks, such as cola, originally prepared from kola nuts. Soft drinks typically contain 0 to 55 milligrams of caffeine per 12 ounce serving. By contrast, energy drinks, such as Red Bull, can start at 80 milligrams of caffeine per serving. The caffeine in these drinks either originates from the ingredients used or is an additive derived from the product of decaffeination or from chemical synthesis. Guarana, a prime ingredient of energy drinks, contains large amounts of caffeine with small amounts of theobromine and theophylline in a naturally occurring slow-release excipient.


Chocolate derived from cocoa beans contains a small amount of caffeine. The weak stimulant effect of chocolate may be due to a combination of theobromine and theophylline, as well as caffeine. A typical 28-gram serving of a milk chocolate bar has about as much caffeine as a cup of decaffeinated coffee. By weight, dark chocolate has one to two times the amount of caffeine as coffee: 80–160 mg per 100 g. Higher percentages of cocoa such as 90% amount to 200 mg per 100 g approximately and thus, a 100-gram 85% cocoa chocolate bar contains about 195 mg caffeine.

Tablets offer several advantages over coffee, tea, and other caffeinated beverages, including convenience, known dosage, and avoidance of concomitant intake of sugar, acids, and fluids. Manufacturers of caffeine tablets claim that using caffeine of pharmaceutical quality improves mental alertness. These tablets are commonly used by students studying for their exams and by people who work or drive for long hours.

One U.S. company is marketing oral dissolvable caffeine strips. Another intake route is SpazzStick, a caffeinated lip balm. Alert Energy Caffeine Gum was introduced in the United States in 2013, but was voluntarily withdrawn after an announcement of an investigation by the FDA of the health effects of added caffeine in foods.

There are several products being marketed that offer inhalers that deliver proprietary blends of supplements, with caffeine being a key ingredient. In 2012, the FDA sent a warning letter to one of the companies marketing these inhalers, expressing concerns for the lack of safety information available about inhaled caffeine.


According to Chinese legend, the Chinese emperor Shennong, reputed to have reigned in about 3000 BCE, inadvertently discovered tea when he noted that when certain leaves fell into boiling water, a fragrant and restorative drink resulted. Shennong is also mentioned in Lu Yu's "Cha Jing", a famous early work on the subject of tea.

The earliest credible evidence of either coffee drinking or knowledge of the coffee plant appears in the middle of the fifteenth century, in the Sufi monasteries of the Yemen in southern Arabia. From Mocha, coffee spread to Egypt and North Africa, and by the 16th century, it had reached the rest of the Middle East, Persia and Turkey. From the Middle East, coffee drinking spread to Italy, then to the rest of Europe, and coffee plants were transported by the Dutch to the East Indies and to the Americas.

Kola nut use appears to have ancient origins. It is chewed in many West African cultures, in both private and social settings, to restore vitality and ease hunger pangs.

The earliest evidence of cocoa bean use comes from residue found in an ancient Mayan pot dated to 600 BCE. Also, chocolate was consumed in a bitter and spicy drink called "xocolatl", often seasoned with vanilla, chile pepper, and achiote. "Xocolatl" was believed to fight fatigue, a belief probably attributable to the theobromine and caffeine content. Chocolate was an important luxury good throughout pre-Columbian Mesoamerica, and cocoa beans were often used as currency.

"Xocolatl" was introduced to Europe by the Spaniards, and became a popular beverage by 1700. The Spaniards also introduced the cacao tree into the West Indies and the Philippines. It was used in alchemical processes, where it was known as "black bean".

The leaves and stems of the yaupon holly ("Ilex vomitoria") were used by Native Americans to brew a tea called "asi" or the "black drink". Archaeologists have found evidence of this use far into antiquity, possibly dating to Late Archaic times.

In 1819, the German chemist Friedlieb Ferdinand Runge isolated relatively pure caffeine for the first time; he called it ""Kaffebase"" (i.e., a base that exists in coffee). According to Runge, he did this at the behest of Johann Wolfgang von Goethe. In 1821, caffeine was isolated both by the French chemist Pierre Jean Robiquet and by another pair of French chemists, Pierre-Joseph Pelletier and Joseph Bienaimé Caventou, according to Swedish chemist Jöns Jacob Berzelius in his yearly journal. Furthermore, Berzelius stated that the French chemists had made their discoveries independently of any knowledge of Runge's or each other's work. However, Berzelius later acknowledged Runge's priority in the extraction of caffeine, stating: "However, at this point, it should not remain unmentioned that Runge (in his "Phytochemical Discoveries", 1820, pages 146–147) specified the same method and described caffeine under the name "Caffeebase" a year earlier than Robiquet, to whom the discovery of this substance is usually attributed, having made the first oral announcement about it at a meeting of the Pharmacy Society in Paris."

Pelletier's article on caffeine was the first to use the term in print (in the French form "Caféine" from the French word for coffee: "café"). It corroborates Berzelius's account:

Robiquet was one of the first to isolate and describe the properties of pure caffeine, whereas Pelletier was the first to perform an elemental analysis.

In 1827, M. Oudry isolated "théine" from tea, but in 1838 it was proved by Mulder and by Carl Jobst that theine was actually the same as caffeine.

In 1895, German chemist Hermann Emil Fischer (1852–1919) first synthesized caffeine from its chemical components (i.e. a "total synthesis"), and two years later, he also derived the structural formula of the compound. This was part of the work for which Fischer was awarded the Nobel Prize in 1902.

Because it was recognized that coffee contained some compound that acted as a stimulant, first coffee and later also caffeine has sometimes been subject to regulation. For example, in the 16th century Islamists in Mecca and in the Ottoman Empire made coffee illegal for some classes. Charles II of England tried to ban it in 1676, Frederick II of Prussia banned it in 1777, and coffee was banned in Sweden at various times between 1756 and 1823.

In 1911, caffeine became the focus of one of the earliest documented health scares, when the US government seized 40 barrels and 20 kegs of Coca-Cola syrup in Chattanooga, Tennessee, alleging the caffeine in its drink was "injurious to health". Although the judge ruled in favor of Coca-Cola, two bills were introduced to the U.S. House of Representatives in 1912 to amend the Pure Food and Drug Act, adding caffeine to the list of "habit-forming" and "deleterious" substances, which must be listed on a product's label.

The Food and Drug Administration (FDA) in the United States currently allows only beverages containing less than 0.02% caffeine; but caffeine powder, which is sold as a dietary supplement, is unregulated. It is a regulatory requirement that the label of most prepackaged foods must declare a list of ingredients, including food additives such as caffeine, in descending order of proportion. However, there is no regulatory provision for mandatory quantitative labeling of caffeine, (e.g., milligrams caffeine per stated serving size). There are a number of food ingredients that naturally contain caffeine. These ingredients must appear in food ingredient lists. However, as is the case for "food additive caffeine", there is no requirement to identify the quantitative amount of caffeine in composite foods containing ingredients that are natural sources of caffeine. While coffee or chocolate are broadly recognized as caffeine sources, some ingredients (e.g., guarana, yerba maté) are likely less recognized as caffeine sources. For these natural sources of caffeine, there is no regulatory provision requiring that a food label identify the presence of caffeine nor state the amount of caffeine present in the food.

Global consumption of caffeine has been estimated at 120,000 tonnes per year, making it the world's most popular psychoactive substance. This amounts to one serving of a caffeinated beverage for every person every day. The consumption of caffeine has remained stable between 1997 and 2015. Coffee, tea and soft drinks are the most important caffeine sources, with energy drinks contributing little to the total caffeine intake across all age groups.

Some Church of God (Restoration) adherents and Christian Scientists do not consume caffeine. Until recently, the Seventh-day Adventist Church asked for its members to "abstain from caffeinated drinks", but has removed this from baptismal vows (while still recommending abstention as policy). Some from these religions believe that one is not supposed to consume a non-medical, psychoactive substance, or believe that one is not supposed to consume a substance that is addictive. The Church of Jesus Christ of Latter-day Saints has said the following with regard to caffeinated beverages: " . . . the Church revelation spelling out health practices (Doctrine and Covenants 89) does not mention the use of caffeine. The Church's health guidelines prohibit alcoholic drinks, smoking or chewing of tobacco, and 'hot drinks' – taught by Church leaders to refer specifically to tea and coffee."

Gaudiya Vaishnavas generally also abstain from caffeine, because they believe it clouds the mind and over-stimulates the senses. To be initiated under a guru, one must have had no caffeine, alcohol, nicotine or other drugs, for at least a year.

Caffeinated beverages are widely consumed by Muslims today. In the 16th century, some Muslim authorities made unsuccessful attempts to ban them as forbidden "intoxicating beverages" under Islamic dietary laws.

Recently discovered bacteria "Pseudomonas putida" CBB5 can live on pure caffeine and can cleave caffeine into carbon dioxide and ammonia.

Caffeine is toxic to birds and to dogs and cats, and has a pronounced adverse effect on mollusks, various insects, and spiders. This is at least partly due to a poor ability to metabolize the compound, causing higher levels for a given dose per unit weight. Caffeine has also been found to enhance the reward memory of honey bees.

Caffeine has been used to double chromosomes in haploid wheat.





</doc>
<doc id="6874" url="https://en.wikipedia.org/wiki?curid=6874" title="Cyc">
Cyc

Cyc (pronounced ) is a long-term artificial intelligence project that aims to assemble a comprehensive ontology and knowledge base that spans the basic concepts and rules about how the world works. Hoping to capture common sense knowledge, Cyc focuses on implicit knowledge that other AI platforms may take for granted. This is contrasted with facts one might find somewhere on the internet or retrieve via a search engine or Wikipedia. Cyc enables AI applications to perform human-like reasoning and be less "brittle" when confronted with novel situations.

Douglas Lenat began the project in July 1984 at MCC, where he was Principal Scientist 1984–1994, and then, since January 1995, has been under active development by the Cycorp company, where he is the CEO.

The need for a massive symbolic artificial intelligence project of this kind was born in the early 1980s. Early AI researchers had ample experience over the previous 25 years with AI programs that would generate encouraging early results but then fail to "scale up"—move beyond the 'training set' to tackle a broader range of cases. Douglas Lenat and Alan Kay publicized this need, and they organized a meeting at Stanford in 1983 to address the problem. The back-of-the-envelope calculations by Doug, Alan, and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum, and John McCarthy) indicated that that effort would require between 1000 and 3000 person-years of effort, far beyond the standard academic project model. However, events within a year of that meeting enabled an effort of that scale to get underway.

The project began in July 1984 as the flagship project of the 400-person Microelectronics and Computer Technology Corporation (MCC), a research consortium started by two dozen large United States based corporations "to counter a then ominous Japanese effort in AI, the so-called "fifth-generation" project." The US Government reacted to the Fifth Generation threat by passing the National Cooperative Research Act of 1984, which for the first time allowed US companies to "collude" on long-term high-risk high-payoff research, and MCC and Sematech sprang up to take advantage of that ten-year opportunity. MCC's first President and CEO was Bobby Ray Inman, former NSA Director and Central Intelligence Agency deputy director.

The objective of the Cyc project was to codify, in machine-usable form, the millions of pieces of knowledge that compose human common sense. This entailed, along the way, (1) developing an adequately expressive representation language, CycL, (2) developing an ontology spanning all human concepts down to some appropriate level of detail, (3) developing a knowledge base on that ontological framework, comprising all human knowledge about those concepts down to some appropriate level of detail, and (4) developing an inference engine exponentially faster than those used in then-conventional expert systems, to be able to infer the same types and depth of conclusions that humans are capable of, given their knowledge of the world.

In slightly more detail:

CycL has a publicly released specification and dozens of HL modules were described in Lenat and Guha's textbook, but the actual Cyc inference engine code, and the full list of 1000+ HL modules, is Cycorp-proprietary.

The name "Cyc" (from "encyclopedia", pronounced , like ""syke"") is a registered trademark owned by Cycorp. Access to Cyc is through paid licenses, but "bona fide" AI research groups are given research-only no-cost licenses (cf. ResearchCyc); as of 2017, over 600 such groups worldwide have these licenses.

Typical pieces of knowledge represented in the Cyc knowledge base are "Every tree is a plant" and "Plants die eventually". When asked whether trees die, the inference engine can draw the obvious conclusion and answer the question correctly.

Most of Cyc's knowledge, outside math, is only true by default. For example, Cyc knows that "as a default" parents love their children, when you're made happy you smile, taking your first step is a big accomplishment, when someone you love has a big accomplishment that makes you happy, and only adults have children. When asked whether a picture captioned "Someone watching his daughter take her first step" contains a smiling adult person, Cyc can logically infer that the answer is "Yes", and "show its work" by presenting the step by step logical argument using those five pieces of knowledge from its knowledge base. These are formulated in the language CycL, which is based on predicate calculus and has a syntax similar to that of the Lisp programming language.

In 2008, Cyc resources were mapped to many Wikipedia articles. Cyc is presently connected to Wikidata. Future plans may connect Cyc to both DBpedia and Freebase.

Much of the current work Cyc continues to be knowledge engineering, representing facts about the world by hand, and implementing efficient inference mechanisms on that knowledge. Increasingly, however, work at Cycorp involves giving the Cyc system the ability to communicate with end users in natural language, and to assist with the ongoing knowledge formation process via machine learning and natural language understanding. Another large effort at Cycorp is building a suite of Cyc-powered ontological engineering tools to lower the bar to entry for individuals to contribute to, edit, browse, and query Cyc.

Like many companies, Cycorp has ambitions to use Cyc's natural language processing to parse the entire internet to extract structured data; unlike all others, it is able to call on the Cyc system itself to act as an inductive bias and as an adjudicator of ambiguity, metaphor, and ellipsis. There are few, if any, systematic benchmark studies of Cyc's performance.

The concept names in Cyc are CycL "terms" or "constants". Constants start with an optional "#$" and are case-sensitive. There are constants for:

Two important binary predicates are #$isa and #$genls. The first one describes that one item is an instance of some collection, the second one that one collection is a subcollection of another one. Facts about concepts are asserted using certain CycL "sentences". Predicates are written before their arguments, in parentheses:
"Bill Clinton belongs to the collection of U.S. presidents."
"All trees are plants."
"Paris is the capital of France."

Sentences can also contain variables, strings starting with "?". These sentences are called "rules". One important rule asserted about the #$isa predicate reads:
"If OBJ is an instance of the collection SUBSET and SUBSET is a subcollection of SUPERSET, then OBJ is an instance of the collection SUPERSET". Another typical example is
which means that for every instance of the collection #$ChordataPhylum (i.e. for every chordate), there exists a female animal (instance of #$FemaleAnimal), which is its mother (described by the predicate #$biologicalMother).

The knowledge base is divided into "microtheories" (Mt), collections of concepts and facts typically pertaining to one particular realm of knowledge. Unlike the knowledge base as a whole, each microtheory must be free from "monotonic" contradictions. Each microtheory is a first-class object in the Cyc ontology; it has a name that is a regular constant; microtheory constants contain the string "Mt" by convention. An example is #$MathMt, the microtheory containing mathematical knowledge. The microtheories can inherit from each other and are organized in a hierarchy:
one specialization of #$MathMt is #$GeometryGMt, the microtheory about geometry.

An inference engine is a computer program that tries to derive answers from a knowledge base.
The Cyc inference engine performs general logical deduction (including modus ponens, modus tollens, universal quantification and existential quantification). It also performs inductive reasoning, statistical machine learning and symbolic machine learning, and abductive reasoning (but of course sparingly and using the existing knowledge base as a filter and guide).

The first version of OpenCyc was released in spring 2002 and contained only 6,000 concepts and 60,000 facts. The knowledge base was released under the Apache License. Cycorp stated its intention to release OpenCyc under parallel, unrestricted licences to meet the needs of its users. The CycL and SubL interpreter (the program that allows users to browse and edit the database as well as to draw inferences) was released free of charge, but only as a binary, without source code. It was made available for Linux and Microsoft Windows. The open source Texai project released the RDF-compatible content extracted from OpenCyc. A version of OpenCyc, 4.0, was released in June 2012. OpenCyc 4.0 included much of the Cyc ontology at that time, containing hundreds of thousands of terms, along with millions of assertions relating the terms to each other; however, these are mainly taxonomic assertions, not the complex rules available in Cyc. The OpenCyc 4.0 knowledge base contained 239,000 concepts and 2,093,000 facts.

The main point of releasing OpenCyc was to help AI researchers understand what was "missing" from what they now call ontologies and knowledge graphs. It's useful and important to have properly taxonomized concepts like person, night, sleep, lying down, waking, happy, etc., but what's "missing" from the OpenCyc content about those terms, but present in the Cyc KB content, are the various rules of thumb that most of us share about those terms: that (as a default, in the ModernWesternHumanCultureMt) each person sleeps at night, sleeps lying down, can be woken up, is not happy about being woken up, "and so on." That point does not require continually-updated releases of OpenCyc, so, as of 2017, OpenCyc is no longer available.

In July 2006, Cycorp released the executable of ResearchCyc 1.0, a version of Cyc aimed at the research community, at no charge. (ResearchCyc was in beta stage of development during all of 2004; a beta version was released in February 2005.) In addition to the taxonomic information contained in OpenCyc, ResearchCyc includes significantly more semantic knowledge (i.e., additional facts and rules of thumb) involving the concepts in its knowledge base; it also includes a large lexicon, English parsing and generation tools, and Java based interfaces for knowledge editing and querying. In addition it contains a system for Ontology-based data integration. As of 2017, regular releases of ResearchCyc continued to appear, with 600 research groups utilizing licenses around the world at no cost for noncommercial research purposes. As of December 2019, ResearchCyc is no longer supported. Cycorp expects to improve and overhaul tools for external developers over the coming years.

There have been over 100 successful applications of Cyc; listed here are a few mutually dissimilar instances:-

For over a decade, Glaxo has used Cyc to semi-automatically integrate all the large (hundreds of thousands of terms) thesauri of pharmaceutical-industry terms that reflect differing usage across companies, countries, years, and sub-industries. This ontology integration task requires domain knowledge, shallow semantic knowledge, but also arbitrarily deep common sense knowledge and reasoning. Pharma vocabulary varies across countries, (sub-) industries, companies, departments, and decades of time. E.g., what’s a" gel pak"? What’s the “street name” for "ranitidine hydrochloride"? Each of these "n "controlled vocabularies is an ontology with approximately 300k terms. Glaxo researchers need to issue a query "in their current vocabulary", have it translated into a neutral “true meaning”, and then have that transformed in the opposite direction to find potential matches against documents each of which was written to comply with a particular known vocabulary. They had been using a large staff to do that manually. Cyc is used as the universal interlingua capable of representing the union of all the terms’ “true meanings”, and capable of representing the 300k transformations between each of those controlled vocabularies and Cyc, thereby converting an "n²" problem into a linear one without introducing the usual sort of “telephone game” attenuation of meaning. Furthermore, creating each of those 300k mappings for each thesaurus is done in a largely automated fashion, by Cyc.

The comprehensive Terrorism Knowledge Base was an application of Cyc in development that tried to ultimately contain all relevant knowledge about "terrorist" groups, their members, leaders, ideology, founders, sponsors, affiliations, facilities, locations, finances, capabilities, intentions, behaviors, tactics, and full descriptions of specific terrorist events. The knowledge is stored as statements in mathematical logic, suitable for computer understanding and reasoning.

The Cleveland Clinic has used Cyc to develop a natural language query interface of biomedical information, spanning decades of information on cardiothoracic surgeries. A query is parsed into a set of CycL (higher-order logic) fragments with open variables (e.g., "this question is talking about a person who developed an endocarditis infection", "this question is talking about a subset of Cleveland Clinic patients who underwent surgery there in 2009", etc.); then various constraints are applied (medical domain knowledge, common sense, discourse pragmatics, syntax) to see how those fragments could possibly fit together into one semantically meaningful formal query; significantly, in most cases, there is exactly "one and only one" such way of incorporating and integrating those fragments. Integrating the fragments involves (i) deciding which open variables in which fragments actually represent the same variable, and (ii) for all the final variables, decide what order and scope of quantification that variable should have, and what type (universal or existential). That logical (CycL) query is then converted into a SPARQL query that is passed to the CCF SemanticDB that is its data lake.

One Cyc application aims to help students doing math at a 6th grade level, helping them much more deeply understand that subject matter. It is based on the experience that we often have "thought" we understood something, but only "really" understood it after we had to explain or teach it to someone else. Unlike almost all other educational software, where the computer plays the role of the teacher, this application of Cyc, called MathCraft, has Cyc play the role of a fellow student who is always slightly more confused than you, the user, are about the subject. The user's role is to observe the Cyc avatar and give it advice, correct its errors, mentor it, get it to see what it's doing wrong, etc. As the user gives good advice, Cyc allows the avatar to make fewer mistakes of that type, hence, from the user's point of view, it seems as though the user has just successfully taught it something. This is a variation of Learning by Teaching.

The Cyc project has been described as "one of the most controversial endeavors of the artificial intelligence history". Catherine Havasi, CEO of Luminoso, says that Cyc is the predecessor project to IBM's Watson. Machine-learning scientist Pedro Domingos refers to the project as a "catastrophic failure" for several reasons, including the unending amount of data required to produce any viable results and the inability for Cyc to evolve on its own.

Robin Hanson, a professor of economics at George Mason University, gives a more balanced analysis:

A similar sentiment was expressed by Marvin Minsky: "Unfortunately, the strategies most popular among AI researchers in the 1980s have come to a dead end," said Minsky. So-called “expert systems,” which emulated human expertise within tightly defined subject areas like law and medicine, could match users’ queries to relevant diagnoses, papers and abstracts, yet they could not learn concepts that most children know by the time they are 3 years old. “For each different kind of problem,” said Minsky, “the construction of expert systems had to start all over again, because they didn’t accumulate common-sense knowledge.” Only one researcher has committed himself to the colossal task of building a comprehensive common-sense reasoning system, according to Minsky. Douglas Lenat, through his Cyc project, has directed the line-by-line entry of more than 1 million rules into a commonsense knowledge base."

Gary Marcus, a professor of psychology and neural science at New York University and the cofounder of an AI company called Geometric Intelligence, says "it represents an approach that is very different from all the deep-learning stuff that has been in the news.” This is consistent with Doug Lenat's position that "Sometimes the "veneer" of intelligence is not enough".

Stephen Wolfram writes:

Marcus writes: 
Every few years since it began publishing (1993), there is a new Wired Magazine article about Cyc, some positive and some negative (including one issue which contained one of each).

This is a list of some of the notable people who work or have worked on Cyc either while it was a project at MCC (where Cyc was first started) or Cycorp.




</doc>
<doc id="6876" url="https://en.wikipedia.org/wiki?curid=6876" title="CE">
CE

CE, Ce or ce may refer to:












</doc>
<doc id="6878" url="https://en.wikipedia.org/wiki?curid=6878" title="Carlos Valderrama">
Carlos Valderrama

Carlos Alberto Valderrama Palacio ( ; born 2 September 1961), also known as "El Pibe" ("The Kid"), is a Colombian former professional footballer who played as an attacking midfielder. A creative playmaker, he is regarded as one of the best Colombian footballers of all time, and by some as Colombia's greatest player ever. His distinctive hairstyle, as well as his precise passing and technical skills made him one of South America's most recognisable footballers in the late 1980s and early 1990s. He won the South American Footballer of the Year award in 1987 and 1993, and in 1999, he was also named one of the top 100 players of the 20th century by World Soccer. In 2004, he was included in the FIFA 100, a list of the 125 "greatest living footballers" chosen by Pelé to celebrate the 100th anniversary of FIFA.

Valderrama was a member of the Colombia national football team from 1985 until 1998. He represented Colombia in 111 full internationals and scored 11 times, making him the most capped player in the country's history. He played a major role during the golden era of Colombian football in the 1990s, representing his national side in three FIFA World Cups and five Copa América tournaments.

After spending most of his career playing club football in South America and Europe, towards the end of his career Valderrama played in Major League Soccer, joining the league in its first season. One of the most recognisable players in the league at the time of its inception, he helped popularise the league during the second half of the 1990s. To this day, he is an icon and is considered one of the most decorated players to ever play in MLS; in 2005, he was named to the MLS All-Time Best XI.

Born in Santa Marta, Colombia, Valderrama began his career at Unión Magdalena of the Colombian First Division in 1981. He also later played for Millonarios in 1984. He joined Deportivo Cali in 1985, where he played most of his Colombian football. In 1988, he moved to the French First Division side Montpellier. He struggled to adapt to the less technical and the faster, more physical, and tactical brand of football being played in Europe, losing his place in the squad. However, his passing ability later saw him become the club's main creative force, and he played a decisive role as his side won the Coupe de France in 1990. In 1991, he remained in Europe and joined Spanish side Real Valladolid for a season. He then returned to Colombia in 1992 and went on to play for Independiente Medellín, and subsequently Atlético Junior in 1993, with whom he won the Colombian championship in 1993 and 1995.

Valderrama began his Major League Soccer career with the US side Tampa Bay Mutiny in the league's inaugural 1996 season. The team won the first ever Supporters' Shield, awarded for having the league's best regular season record, while Valderrama was the league's first Most Valuable Player, finishing the season with 4 goals and 17 assists. He remained with the club for the 1997 season, and also spent a spell on loan back at Deportivo Cali in Colombia, before moving to another MLS side, Miami Fusion, in 1998, where he also remained for two seasons. He returned to Tampa Bay in 2000, spending two more seasons with the club; while a member of the Mutiny, the team would sell Carlos Valderrama wigs at Tampa Stadium. In the 2000 MLS season, Valderrama recorded the only 20+ assist season in MLS history—ending the season with 26 — a single season assist record that remains intact to this day, and which MLS itself suggested was an "unbreakable" record in a 2012 article. In 2001, Valderrama joined the Colorado Rapids, and remained with the team until 2002, when he retired; his American soccer league career spanned a total of eight years, during which he made 175 appearances. In the MLS, Valderrama scored relatively few goals (16) for a midfielder, but is the league's fourth all-time leader in assists (114) after Brad Davis (123), Steve Ralston (135) – a former teammate, and Landon Donovan (145). In 2005, he was named to the MLS All-Time Best XI.

Valderrama was a member of the Colombia national football team from 1985 until 1998; he made 111 international appearances, scoring 11 goals, making him the most capped player in the country's history. He represented and captained his national side in the 1990, 1994, and 
1998 FIFA World Cups, and also took part in the 1987, 1989, 1991, 1993, and 1995 Copa América tournaments.

Valderrama made his international debut on 27 October 1985, in a 3–0 defeat to Paraguay in a 1986 World Cup qualifying match, at the age of 24. In his first major international tournament, he helped Colombia to a third-place finish at the 1987 Copa América in Argentina, as his team's captain, where he was named the tournament's best player; during the tournament he scored the opening goal in Colombia's 2–0 over Bolivia on 1 July, their first match of the group stage.
Some of Valderrama's most impressive international performances came during the 1990 FIFA World Cup in Italy, during which he served as Colombia's captain. He helped his team to a 2–0 win against the UAE in Colombia's opening match of the group stage, scoring the second goal of the match with a strike from 20 yards. Colombia lost their second match against Yugoslavia, however, needing at least a draw against the eventual champions West Germany in their final group match in order to advance to the next round of the competition. In the decisive game, German striker Pierre Littbarski scored what appeared to be the winning goal in the 88th minute of the game; however, within the last minute of injury time, Valderrama beat several opposing players and made a crucial left-footed pass to Freddy Rincón, who subsequently equalised, sealing a place for Colombia in the second round of the tournament with a 1–1 draw. Colombia were eliminated in the round of 16, following a 2–1 extra time loss to Cameroon.

On 5 September 1993, Valderrama contributed to Colombia's historic 5–0 victory over South American rivals Argentina at the "Monumental" in Buenos Aires, which allowed them to qualify for the 1994 World Cup. Although much was expected of Valderrama at the World Cup, an injury during a pre-tournament warm-up game put his place in the squad in jeopardy; although he was able to regain match fitness in time for the tournament, Colombia disappointed and suffered a first round elimination following defeats to Romania and the hosts USA, though it has been contributed by the internal problem and threats by cartel groups at the time.

Four years later, Valderrama led his nation to qualify for the 1998 World Cup in France, scoring three goals during the qualifying stages. His impact in the final tournament at the advancing age of 37, however, was less decisive, and, despite defeating Tunisia, Colombia once again suffered a first round exit, following a 2–0 defeat against England, which was Valderrama's final international appearance.

Although Valderrama is often defined as a 'classic number 10 playmaker', due to his creativity and offensive contribution, in reality he was not a classic playmaker in the traditional sense. Although he often wore the number 10 shirt throughout his career and was deployed as an attacking midfielder at times, he played mostly in deeper positions in the centre of the pitch – often operating in a free role as a deep-lying playmaker, rather than in more advanced midfield positions behind the forwards – in order to have a greater influence on the game. A team-player, Valderrama was also known to be an extremely selfless midfielder, who preferred assisting his teammates over going for goal himself; his tactical intelligence, positioning, reading of the game, efficient movement, and versatile range of passing enabled him to find space for himself to distribute and receive the ball, which allowed him both to set the tempo of his team in midfield with short, first time exchanges, or create chances with long lobbed passes or through balls.

Valderrama's most instantly recognisable physical features were his big afro-blonde hairstyle, jewelry, and moustache, but he was best known for his grace and elegance on the ball, as well as his agility, and quick feet as a footballer. His control, dribbling ability and footwork were similar to those of smaller players, which for a player of Valderrama's size and physical build was fairly uncommon, and he frequently stood out throughout his career for his ability to use his strength, balance, composure, and flamboyant technique to shield the ball from opponents when put under pressure, and retain possession in difficult situations, often with elaborate skills, which made him an extremely popular figure with the fans. Valderrama's mix of physical strength, two-footed ability, unpredictability and flair enabled him to produce key and incisive performances against top tier teams, while his world class vision and exceptional passing and crossing ability with his right foot made him one of the best assist providers of his time; his height, physique and elevation also made him effective in the air, and he was also an accurate free kick taker and striker of the ball, despite not being a particularly prolific goalscorer.

Despite his natural talent and ability as a footballer, Valderrama earned a reputation for having a "languid" playing style, as well as lacking notable pace, being unfit, and for having a poor defensive work-rate on the pitch, in particular, after succumbing to the physical effects of ageing in his later career in the MLS. In his first season in France, he also initially struggled to adapt to the faster-paced, more physical and tactically rigorous European brand of football, which saw him play in an unfamiliar position, and gave him less space and time on the ball to dictate attacking passing moves; he was criticised at times for his lack of match fitness and his low defensive contribution, which initially limited his appearances with the club, although he later successfully became a key creative player in his team's starting line-up due to his discipline, skill, and his precise and efficient passing. Despite these claims, earlier in his career, however, Valderrama demonstrated substantial pace, stamina, and defensive competence.

Former French defender Laurent Blanc, who played with Valderrama in Montpellier, voiced one of the most accurate descriptions for Valderrama, "In the fast and furious European game he wasn't always at his ease. He was a natural exponent of 'toque', keeping the ball moving. But he was so gifted that we could give him the ball when we didn't know what else to do with it knowing he wouldn't lose it... and often he would do things that most of us only dream about."

In February 2004, Valderrama ended his 22-year career in a tribute match at the Metropolitan stadium of Barranquilla, with some of the most important football players of South America, such as Diego Maradona, Enzo Francescoli, Iván Zamorano, and José Luis Chilavert.

In 2006, a 22-foot bronze statue of Valderrama, created by Colombian artist Amilkar Ariza, was erected outside Estadio Eduardo Santos in Valderrama's birthplace of Santa Marta.

Valderrama was the only Colombian to feature in FIFA's 125 Top Living Football Players list in March 2004.

Valderrama appeared on the cover of Konami's "International Superstar Soccer Pro 98". In the Nintendo 64 version of the game, he is referred to by his nickname, "El Pibe".

Valderrama has also appeared in EA Sports' FIFA football video game series; he was named one of the Ultimate Team Legend cards in "FIFA 15".

Valderrama also appeared in the greatest Backyard Sports game in history, Backyard Soccer: MLS Edition.

Since retiring from professional football, Valderrama has become assistant manager of Atlético Junior. On 1 November 2007, Valderrama accused a referee of corruption by waving cash in the face of Oscar Julian Ruiz when the official awarded a penalty to América de Cali. Junior lost the match 4–1, which ended the club's hopes of playoff qualification. He later also served as a coach for a football academy called Clearwater Galactics in Clearwater, Florida.

Valderrama is married and has six children.

"Scores and results lists Colombia's goal tally first."

Montpellier

Atletico Junior

Tampa Bay Mutiny




</doc>
<doc id="6880" url="https://en.wikipedia.org/wiki?curid=6880" title="Caesar salad">
Caesar salad

A Caesar salad (also spelled Cesar and Cesare) is a green salad of romaine lettuce and croutons dressed with lemon juice (or lime juice), olive oil, egg, Worcestershire sauce, anchovies, garlic, Dijon mustard, Parmesan cheese, and black pepper.

In its original form, this salad was prepared and served tableside.

The salad's creation is generally attributed to restaurateur Caesar Cardini, an Italian immigrant who operated restaurants in Mexico and the United States. Cardini was living in San Diego but he was also working in Tijuana where he avoided the restrictions of Prohibition. His daughter Rosa recounted that her father invented the salad at his restaurant Caesar's (at the Hotel Caesar) when a Fourth of July rush in 1924 depleted the kitchen's supplies. Cardini made do with what he had, adding the dramatic flair of the table-side tossing "by the chef." A number of Cardini's staff have said that they invented the dish.

Julia Child said that she had eaten a Caesar salad at Cardini's restaurant when she was a child in the 1920s. In 1946, newspaper columnist Dorothy Kilgallen wrote of a Caesar containing anchovies, differing from Cardini's version:
The big food rage in Hollywood—the Caesar salad—will be introduced to New Yorkers by Gilmore's Steak House. It's an intricate concoction that takes ages to prepare and contains (zowie!) lots of garlic, raw or slightly coddled eggs, croutons, romaine, anchovies, parmeasan ["sic"] cheese, olive oil, vinegar and plenty of black pepper.According to Rosa Cardini, the original Caesar salad (unlike his brother Alex's "Aviator's salad", which was later renamed to Caesar salad) did not contain pieces of anchovy; the slight anchovy flavor comes from the Worcestershire sauce. Cardini was opposed to using anchovies in his salad.

In the 1970s, Cardini's daughter said that the original recipe included whole lettuce leaves, which were meant to be lifted by the stem and eaten with the fingers; coddled eggs; and Italian olive oil.

Although the original recipe does not contain anchovies, modern recipes typically include anchovies as a key ingredient, which frequently is emulsified in bottled versions. Bottled Caesar dressings are now produced and marketed by many companies.

The trademark brands "Cardini's", "Caesar Cardini's" and "The Original Caesar Dressing" are all claimed to date to February 1950, although they were only registered decades later, and more than a dozen varieties of bottled "Cardini's" dressing are available today, with various ingredients.

Common ingredients in many recipes:

Variations include varying the leaf, adding meat such as grilled chicken or bacon, or omitting ingredients such as anchovies and eggs.

There is inherent risk of infection by salmonella bacteria occasionally found in raw egg from cracked or improperly washed eggshells. However, some countries such as the UK have eliminated this risk through vaccination and tracking strategies. Nevertheless, later versions of the recipe call at least for briefly cooked coddled eggs or pasteurized eggs. Recipes may omit the egg and produce a "Caesar vinaigrette". Many variations of this salad exist; yogurt is sometimes substituted for the eggs to maintain a creamy texture and others call for using mayonnaise.





</doc>
<doc id="6881" url="https://en.wikipedia.org/wiki?curid=6881" title="Cecilia Beaux">
Cecilia Beaux

Cecilia Beaux (May 1, 1855 – September 17, 1942) was an American society portraitist, in the manner of John Singer Sargent. She was a near-contemporary of American artist Mary Cassatt and also received her training in Philadelphia and France. Her sympathetic renderings of the American ruling class made her one of the most successful portrait painters of her era.

Eliza Cecilia Beaux was born on May 1, 1855 in Philadelphia, Pennsylvania. She was the youngest daughter of French silk manufacturer Jean Adolphe Beaux and teacher Cecilia Kent Leavitt. Her mother was the daughter of prominent businessman John Wheeler Leavitt of New York City and his wife Cecilia Kent of Suffield, Connecticut. Cecilia Kent Leavitt died from puerperal fever 12 days after giving birth at age 33. Cecilia "Leilie" Beaux and her sister Etta were subsequently raised by their maternal grandmother and aunts, primarily in Philadelphia. Her father, unable to bear the grief of his loss, and feeling adrift in a foreign country, returned to his native France for 16 years, with only one visit back to Philadelphia. He returned when Cecilia was two, but left four years later after his business failed. As she confessed later, "We didn't love Papa very much, he was so foreign. We thought him "peculiar"." Her father did have a natural aptitude for drawing and the sisters were charmed by his whimsical sketches of animals. Later, Beaux would discover that her French heritage would serve her well during her pilgrimage and training in France. 

In Philadelphia, Beaux's aunt Emily married mining engineer William Foster Biddle, whom Beaux would later describe as "after my grandmother, the strongest and most beneficent influence in my life." For fifty years, he cared for his nieces-in-law with consistent attention and occasional financial support. Her grandmother, on the other hand, provided day-to-day supervision and kindly discipline. Whether with housework, handiwork, or academics, Grandma Leavitt offered a pragmatic framework, stressing that "everything undertaken must be completed, conquered." The Civil War years were particularly challenging, but the extended family survived despite little emotional or financial support from Beaux's father.

After the war, Beaux began to spend some time in the household of "Willie" and Emily, both proficient musicians. Beaux learned to play the piano but preferred singing. The musical atmosphere later proved an advantage for her artistic ambitions. Beaux recalled, "They understood perfectly the spirit and necessities of an artist's life." In her early teens, she had her first major exposure to art during visits with Willie to the nearby Pennsylvania Academy of the Fine Arts, one of America's foremost art schools and museums. Though fascinated by the narrative elements of some of the pictures, particularly the Biblical themes of the massive paintings of Benjamin West, at this point Beaux had no aspirations of becoming an artist.

Her childhood was a sheltered though generally happy one. As a teen she already manifested the traits, as she described, of "both a realist and a perfectionist, pursued by an uncompromising passion for carrying through." She attended the Misses Lyman School and was just an average student, though she did well in French and Natural History. However, she was unable to afford the extra fee for art lessons. At age 16, Beaux began art lessons with a relative, Catherine Ann Drinker, an accomplished artist who had her own studio and a growing clientele. Drinker became Beaux's role model, and she continued lessons with Drinker for a year. She then studied for two years with the painter Francis Adolf Van der Wielen, who offered lessons in perspective and drawing from casts during the time that the new Pennsylvania Academy of the Fine Arts was under construction. Given the bias of the Victorian age, female students were denied direct study in anatomy and could not attend drawing classes with live models (who were often prostitutes) until a decade later.

At 18, Beaux was appointed as a drawing teacher at Miss Sanford's School, taking over Drinker's post. She also gave private art lessons and produced decorative art and small portraits. Her own studies were mostly self-directed. Beaux received her first introduction to lithography doing copy work for Philadelphia printer Thomas Sinclair and she published her first work in "St. Nicholas" magazine in December 1873. Beaux demonstrated accuracy and patience as a scientific illustrator, creating drawings of fossils for Edward Drinker Cope, for a multi-volume report sponsored by the U.S. Geological Survey. However, she did not find technical illustration suitable for a career (the extreme exactitude required gave her pains in the "solar plexus"). At this stage, she did not yet consider herself an artist.

Beaux began attending the Pennsylvania Academy of the Fine Arts in 1876, then under the dynamic influence of Thomas Eakins, whose great work "The Gross Clinic" had "horrified Philadelphia Exhibition-goers as a gory spectacle" at the Centennial Exhibition of 1876. She steered clear of the controversial Eakins, though she much admired his work. His progressive teaching philosophy, focused on anatomy and live study (and allowed the female students to partake in segregated studios), eventually led to his firing as director of the Academy. She did not ally herself with Eakins' ardent student supporters, and later wrote, "A curious instinct of self-preservation kept me outside the magic circle." Instead, she attended costume and portrait painting classes for three years taught by the ailing director Christian Schussele. Beaux won the Mary Smith Prize at the Pennsylvania Academy of the Fine Arts exhibitions in 1885, 1887, 1891, and 1892.

After leaving the Academy, the 24-year-old Beaux decided to try her hand at porcelain painting and she enrolled in a course at the National Art Training School. She was well suited to the precise work but later wrote, "this was the lowest depth I ever reached in commercial art, and although it was a period when youth and romance were in their first attendance on me, I remember it with gloom and record it with shame." She studied privately with William Sartain, a friend of Eakins and a New York artist invited to Philadelphia to teach a group of art students, starting in 1881. Though Beaux admired Eakins more and thought his painting skill superior to Sartain's, she preferred the latter's gentle teaching style which promoted no particular aesthetic approach. Unlike Eakins, however, Sartain believed in phrenology and Beaux adopted a lifelong belief that physical characteristics correlated with behaviors and traits.

Beaux attended Sartain's classes for two years, then rented her own studio and shared it with a group of women artists who hired a live model and continued without an instructor. After the group disbanded, Beaux set in earnest to prove her artistic abilities. She painted a large canvas in 1884, "Les Derniers Jours d'Enfance", a portrait of her sister and nephew whose composition and style revealed a debt to James McNeill Whistler and whose subject matter was akin to Mary Cassatt's mother-and-child paintings. It was awarded a prize for the best painting by a female artist at the Academy, and further exhibited in Philadelphia and New York. Following that seminal painting, she painted over 50 portraits in the next three years with the zeal of a committed professional artist. Her invitation to serve as a juror on the hanging committee of the Academy confirmed her acceptance amongst her peers. In the mid-1880s, she was receiving commissions from notable Philadelphians and earning $500 per portrait, comparable to what Eakins commanded. When her friend Margaret Bush-Brown insisted that "Les Derniers" was good enough to be exhibited at the famed Paris Salon, Beaux relented and sent the painting abroad in the care of her friend, who managed to get the painting into the exhibition.

At 32, despite her clear success in Philadelphia, Beaux decided that she still needed to advance her skills. She left for Paris with cousin May Whitlock, forsaking several suitors and overcoming the objections of her family. There she trained at the Académie Julian, the largest art school in Paris, and at the Académie Colarossi, receiving weekly critiques from established masters like Tony Robert-Fleury and William-Adolphe Bouguereau. She wrote, "Fleury is much less benign than Bouguereau and don't temper his severities…he hinted of possibilities before me and as he rose said the nicest thing of all, 'we will do all we can to help you'…I want these men…to know me and recognize that I can do something." Though advised regularly of Beaux's progress abroad and to "not be worried about any indiscretions of ours", her Aunt Eliza repeatedly reminded her niece to avoid the temptations of Paris, "Remember you are first of all a Christian – then a woman and last of all an Artist."

When Beaux arrived in Paris, the Impressionists, a group of artists who had begun their own series of independent exhibitions from the official Salon in 1874, were beginning to lose their solidarity. Also known as the "Independents" or "Intransigents", the group which at times included Degas, Monet, Sisley, Caillebotte, Pissarro, Renoir, and Berthe Morisot, had been receiving the wrath of the critics for several years. Their art, though varying in style and technique, was the antithesis of the type of Academic art in which Beaux was trained and of which her teacher William-Adolphe Bouguereau was a leading master. In the summer of 1888, with classes in summer recess, Beaux worked in the fishing village of Concarneau with the American painters Alexander Harrison and Charles Lazar. She tried applying the plein-air painting techniques used by the Impressionists to her own landscapes and portraiture, with little success. Unlike her predecessor Mary Cassatt, who had arrived near the beginning of the Impressionist movement 15 years earlier and who had absorbed it, Beaux's artistic temperament, precise and true to observation, would not align with Impressionism and she remained a realist painter for the rest of her career, even as Cézanne, Matisse, Gauguin, and Picasso were beginning to take art into new directions. Beaux mostly admired classic artists like Titian and Rembrandt. Her European training did influence her palette, however, and she adopted more white and paler coloration in her oil painting, particularly in depicting female subjects, an approach favored by Sargent as well.

Back in America in 1889, Beaux proceeded to paint portraits in the grand manner, taking as her subjects members of her sister's family as well as the elite of Philadelphia. In making her decision to devote herself to art, she also thought it was best not to marry, and in choosing male company she selected men who would not threaten to sidetrack her career. She resumed life with her family, and they supported her fully, acknowledging her chosen path and demanding of her little in the way of household responsibilities, "I was never once asked to do an errand in town, some bit of shopping…so well did they understand." She developed a structured, professional routine, arriving promptly at her studio, and expected the same from her models.

The five years that followed were highly productive, resulting in over forty portraits. In 1890 she exhibited at the Paris Exposition, obtained in 1893 the gold medal of the Philadelphia Art Club, and also the Dodge prize at the New York National Academy of Design. She exhibited her work at the Palace of Fine Arts and The Woman's Building at the 1893 World's Columbian Exposition in Chicago, Illinois. Her portrait of "The Reverend Matthew Blackburne Grier" was particularly well-received, as was "Sita and Sarita", a portrait of her cousin Charles W. Leavitt's wife Sarah (Allibone) Leavitt in white, with a small black cat perched on her shoulder, both gazing out mysteriously. The mesmerizing effect prompted one critic to point out "the witch-like weirdness of the black kitten" and for many years, the painting solicited questions by the press. But the result was not pre-planned, as Beaux's sister later explained, "Please make no mystery about it—it was only an idea to put the black kitten on her cousin's shoulder. Nothing deeper." Beaux donated "Sita and Sarita" to the Musée du Luxembourg, but only after making a copy for herself. Another highly regarded portrait from that period is "New England Woman" (1895), a nearly all-white oil painting which was purchased by the Pennsylvania Academy of the Fine Arts.

In 1895 Beaux became the first woman to have a regular teaching position at the Pennsylvania Academy of the Fine Arts, where she instructed in portrait drawing and painting for the next twenty years. That rare type of achievement by a woman prompted one local newspaper to state, "It is a legitimate source of pride to Philadelphia that one of its most cherished institutions has made this innovation." She was a popular instructor. In 1896, Beaux returned to France to see a group of her paintings presented at the Salon. Influential French critic M. Henri Rochefort commented, "I am compelled to admit, not without some chagrin, that not one of our female artists…is strong enough to compete with the lady who has given us this year the portrait of Dr. Grier. Composition, flesh, texture, sound drawing—everything is there without affectation, and without seeking for effect."

Cecilia Beaux considered herself a "New Woman", a 19th-century women who explored educational and career opportunities that had generally been denied to women. In the late 19th century Charles Dana Gibson depicted the "New Woman" in his painting, "The Reason Dinner was Late", which is "a sympathetic portrayal of artistic aspiration on the part of young women" as she paints a visiting policeman. This "New Woman" was successful, highly trained, and often did not marry; other such women included Ellen Day Hale, Mary Cassatt, Elizabeth Nourse and Elizabeth Coffin.

Beaux was a member of Philadelphia's The Plastic Club. Other members included Elenore Abbott, Jessie Willcox Smith, Violet Oakley, Emily Sartain, and Elizabeth Shippen Green. Many of the women who founded the organization had been students of Howard Pyle. It was founded to provide a means to encourage one another professionally and create opportunities to sell their works of art.

By 1900 the demand for Beaux's work brought clients from Washington, D.C., to Boston, prompting the artist to move to New York City; it was there she spent the winters, while summering at Green Alley, the home and studio she had built in Gloucester, Massachusetts. Beaux's friendship with Richard Gilder, editor-in-chief of the literary magazine "The Century", helped promote her career and he introduced her to the elite of society. Among her portraits which followed from that association are those of Georges Clemenceau; First Lady Edith Roosevelt and her daughter; and Admiral Sir David Beatty. She also sketched President Teddy Roosevelt during her White House visits in 1902, during which "He sat for two hours, talking most of the time, reciting Kipling, and reading scraps of Browning." Her portraits "Fanny Travis Cochran", "Dorothea and Francesca", and "Ernesta and her Little Brother", are fine examples of her skill in painting children; "Ernesta with Nurse", one of a series of essays in luminous white, was a highly original composition, seemingly without precedent. She became a member of the National Academy of Design in 1902. and won the Logan Medal of the arts at the Art Institute of Chicago in 1921.

By 1906, Beaux began to live year-round at Green Alley, in a comfortable colony of "cottages" belonging to her wealthy friends and neighbors. All three aunts had died and she needed an emotional break from Philadelphia and New York. She managed to find new subjects for portraiture, working in the mornings and enjoying a leisurely life the rest of the time. She carefully regulated her energy and her activities to maintain a productive output, and considered that a key to her success. On why so few women succeeded in art as she did, she stated, "Strength is the stumbling block. They (women) are sometimes unable to stand the hard work of it day in and day out. They become tired and cannot reenergize themselves."

While Beaux stuck to her portraits of the elite, American art was advancing into urban and social subject matter, led by artists such as Robert Henri who espoused a totally different aesthetic, "Work with great speed..Have your energies alert, up and active. Do it all in one sitting if you can. In one minute if you can. There is no use delaying…Stop studying water pitchers and bananas and paint everyday life." He advised his students, among them Edward Hopper and Rockwell Kent, to live with the common man and paint the common man, in total opposition to Cecilia Beaux's artistic methods and subjects. The clash of Henri and William Merritt Chase (representing Beaux and the traditional art establishment) resulted in 1907 in the independent exhibition by the urban realists known as "The Eight" or the Ashcan School. Beaux and her art friends defended the old order, and many thought (and hoped) the new movement to be a passing fad, but it turned out to be a revolutionary turn in American art.

In 1910, her beloved Uncle Willie died. Though devastated by the loss, at fifty-five years of age, Beaux remained highly productive. In the next five years she painted almost 25 percent of her lifetime output and received a steady stream of honors. She had a major exhibition of 35 paintings at the Corcoran Gallery of Art in Washington, D.C., in 1912. Despite her continuing production and accolades, however, Beaux was working against the current of tastes and trends in art. The famed "Armory Show" of 1913 in New York City was a landmark presentation of 1,200 paintings showcasing Modernism. Beaux believed that the public, initially of mixed opinion about the "new" art, would ultimately reject it and return its favor to the Pre-Impressionists.

Beaux was crippled after breaking her hip while walking in Paris in 1924. With her health impaired, her work output dwindled for the remainder of her life. That same year Beaux was asked to produce a self-portrait for the Medici collection in the Uffizi Gallery in Florence. In 1930 she published an autobiography, "Background with Figures". Her later life was filled with honors. In 1930 she was elected a member of the National Institute of Arts and Letters; in 1933 came membership in the American Academy of Arts and Letters, which two years later organized the first major retrospective of her work. Also in 1933 Eleanor Roosevelt honored Beaux as "the American woman who had made the greatest contribution to the culture of the world". In 1942 The National Institute of Arts and Letters awarded her a gold medal for lifetime achievement.

Cecilia Beaux died at the age of 87 on September 17, 1942, in Gloucester, Massachusetts. She was buried at West Laurel Hill Cemetery in Bala Cynwyd, Pennsylvania. In her will she left a Duncan Phyfe rosewood secretaire made for her father to her cherished nephew Cecil Kent Drinker, a Harvard physician whom she had painted as a young boy. 

Beaux was included in the 2018 exhibit "Women in Paris 1850-1900" at the Clark Art Institute.

Though Beaux was an individualist, comparisons to Sargent would prove inevitable, and often favorable. Her strong technique, her perceptive reading of her subjects, and her ability to flatter without falsifying, were traits similar to his.

"The critics are very enthusiastic. (Bernard) Berenson, Mrs. Coates tells me, stood in front of the portraits – Miss Beaux's three – and wagged his head. 'Ah, yes, I see!' Some Sargents. The ordinary ones are signed John Sargent, the best are signed Cecilia Beaux, which is, of course, nonsense in more ways than one, but it is part of the generous chorus of praise." Though overshadowed by Mary Cassatt and relatively unknown to museum-goers today, Beaux's craftsmanship and extraordinary output were highly regarded in her time. While presenting the Carnegie Institute's Gold Medal to Beaux in 1899, William Merritt Chase stated "Miss Beaux is not only the greatest living woman painter, but the best that has ever lived. Miss Beaux has done away entirely with sex [gender] in art."

During her long productive life as an artist, she maintained her personal aesthetic and high standards against all distractions and countervailing forces. She constantly struggled for perfection, "A perfect technique in anything," she stated in an interview, "means that there has been no break in continuity between the conception and the act of performance." She summed up her driving work ethic, "I can say this: When I attempt anything, I have a passionate determination to overcome every obstacle…And I do my own work with a refusal to accept defeat that might almost be called painful."




</doc>
<doc id="6882" url="https://en.wikipedia.org/wiki?curid=6882" title="Chrysler">
Chrysler

Chrysler (; officially FCA US LLC, the first initialism standing for Fiat Chrysler Automobiles) is one of the "Big Three" automobile manufacturers in the United States, headquartered in Auburn Hills, Michigan. The company will be renamed Stellantis once the merger of Fiat Chrysler Automobiles and Peugeot S.A. is completed in the first quarter of 2021. The original Chrysler Corporation was founded in 1925 by Walter Chrysler from the remains of the Maxwell Motor Company. In 1998, it was acquired by Daimler-Benz, and the holding company was renamed DaimlerChrysler. After Daimler divested Chrysler in 2007, the company existed as Chrysler LLC (2007–2009) and Chrysler Group LLC (2009–2014) before merging in 2014 with Italian holding company Fiat S.p.A. and becoming a subsidiary of its successor Fiat Chrysler Automobiles. In addition to the Chrysler brand, FCA sells vehicles worldwide under the Dodge, Jeep, and Ram nameplates. Furthermore, the subsidiary includes Mopar, its automotive parts and accessories division, and SRT, its performance automobile division.

After founding the company, Walter Chrysler used the General Motors brand diversification and hierarchy strategy that he had seen working for Buick, and acquired Fargo Trucks and Dodge Brothers, and created the Plymouth and DeSoto brands in 1928. Facing postwar declines in market share, productivity, and profitability, as GM and Ford were growing, Chrysler borrowed $250 million in 1954 from Prudential Insurance to pay for expansion and updated car designs.

Chrysler expanded into Europe by taking control of French, British and Spanish auto companies in the 1960s; Chrysler Europe was sold in 1978 to PSA Peugeot Citroën for $1. The company struggled to adapt to changing markets, increased U.S. import competition, and safety and environmental regulation in the 1970s. It began an engineering partnership with Mitsubishi Motors, and began selling Mitsubishi vehicles branded as Dodge and Plymouth in North America. On the verge of bankruptcy in the late 1970s, it was saved by $1.5 billion in loan guarantees from the U.S. government. New CEO Lee Iacocca was credited with returning the company to profitability in the 1980s. In 1985, Diamond-Star Motors was created, further expanding the Chrysler-Mitsubishi relationship. In 1987, Chrysler acquired American Motors Corporation (AMC), which brought the profitable Jeep brand under the Chrysler umbrella. In 1998, Chrysler merged with German automaker Daimler-Benz to form DaimlerChrysler AG; the merger proved contentious with investors. As a result, Chrysler was sold to Cerberus Capital Management and renamed Chrysler LLC in 2007.

Like the other Big Three automobile manufacturers, Chrysler was impacted by the automotive industry crisis of 2008–2010. The company remained in business through a combination of negotiations with creditors, filing for Chapter 11 bankruptcy reorganization on April 30, 2009, and participating in a bailout from the U.S. government through the Troubled Asset Relief Program. On June 10, 2009, Chrysler emerged from the bankruptcy proceedings with the United Auto Workers pension fund, Fiat S.p.A., and the U.S. and Canadian governments as principal owners. The bankruptcy resulted in Chrysler defaulting on over $4 billion in debts. By May 24, 2011, Chrysler finished repaying its obligations to the U.S. government five years early, although the cost to the American taxpayer was $1.3 billion. Over the next few years, Fiat gradually acquired the other parties' shares while removing much of the weight of the loans (which carried a 21% interest rate) in a short period.

On January 1, 2014, Fiat S.p.A announced a deal to purchase the rest of Chrysler from the United Auto Workers retiree health trust. The deal was completed on January 21, 2014, making Chrysler Group a subsidiary of Fiat S.p.A. In May 2014, Fiat Chrysler Automobiles was established by merging Fiat S.p.A. into the company. This was completed in August 2014. Chrysler Group LLC remained a subsidiary until December 15, 2014, when it was renamed FCA US LLC, to reflect the Fiat-Chrysler merger.

The Chrysler company was founded by Walter Chrysler on June 6, 1925, when the Maxwell Motor Company (est. 1904) was re-organized into the Chrysler Corporation.

Chrysler had arrived at the ailing Maxwell-Chalmers company in the early 1920s, hired to overhaul the company's troubled operations (after a similar rescue job at the Willys-Overland car company). In late 1923 production of the Chalmers automobile was ended.
In January 1924, Walter Chrysler launched the well-received Chrysler automobile. The 6-cylinder Chrysler was designed to provide customers with an advanced, well-engineered car, was an automobile at an affordable price. Elements of this car are traceable to a prototype which had been under development at Willys during Chrysler's tenure The original 1924 Chrysler included a carburetor air filter, high compression engine, full pressure lubrication, and an oil filter, features absent from most autos at the time. Among the innovations in its early years were the first practical mass-produced four-wheel hydraulic brakes, a system nearly completely engineered by Chrysler with patents assigned to Lockheed, and rubber engine mounts to reduce vibration.

Chrysler also developed a wheel with a ridged rim, designed to keep a deflated tire from flying off the wheel. This wheel was eventually adopted by the auto industry worldwide.

The Maxwell brand was dropped after the 1925 model year, with the new, lower-priced four-cylinder Chryslers introduced for the 1926 year being badge-engineered Maxwells. The advanced engineering and testing that went into Chrysler Corporation cars helped to push the company to the second-place position in U.S. sales by 1936, which it held until 1949.

In 1928, the Chrysler Corporation began dividing its vehicle offerings by price class and function. The Plymouth brand was introduced at the low-priced end of the market (created essentially by once again reworking and rebadging Chrysler's four-cylinder model). At the same time, the DeSoto brand was introduced in the medium-price field. Also in 1928, Chrysler bought the Dodge Brothers automobile and truck company and continued the successful Dodge line of automobiles and Fargo range of trucks. By the mid-1930s, the DeSoto and Dodge divisions would trade places in the corporate hierarchy.
The Imperial name had been used since 1926 but was never a separate make, just the top-of-the-line Chrysler. However, in 1955, the company decided to spin it off as its own make/brand and division to better compete with its rivals, Lincoln and Cadillac.

On April 28, 1955, Chrysler and Philco had announced the development and production of the World's First All-Transistor car radio. The all-transistor car radio, Mopar model 914HR, was developed and produced by Chrysler and Philco, and it was a $150.00 "option" on the 1956 Imperial automobile models. Philco began manufacturing this radio in the fall of 1955 at its Sandusky Ohio plant.

On September 28, 1957, Chrysler had announced the first production electronic fuel injection (EFI), as an option on some of its new 1958 car models (Chrysler 300D, Dodge D500, DeSoto Adventurer, Plymouth Fury). The first attempt to use this system was by American Motors on the 1957 Rambler Rebel. Bendix Corporation's Electrojector used a transistor computer brain modulator box, but teething problems on pre-production cars meant very few cars were made. The EFI system in the Rambler ran fine in warm weather, but suffered hard starting in cooler temperatures and AMC decided not to use this EFI system, on its 1957 Rambler Rebel production cars that were sold to the public. Chrysler also used the Bendix "Electrojector" fuel injection system and only around 35 vehicles were built with this option, on its 1958 production built car models. Owners of EFI Chryslers were so dissatisfied that all but one were retrofitted with carburetors (while that one has been completely restored, with original EFI electronic problems resolved).

Imperial would see new body styles introduced every two to three years, all with V8 engines and automatic transmissions, as well as technologies that would filter down to Chrysler corporation's other models. Imperial was folded back into the Chrysler brand in 1971.

The Valiant was also introduced for 1960 as a distinct brand. In the U.S. market, Valiant was made a model in the Plymouth line for 1961 and the DeSoto make was discontinued in 1961. With those exceptions per applicable year and market, Chrysler's range from lowest to highest price from the 1940s through the 1970s was Valiant, Plymouth, Dodge, DeSoto, Chrysler, and Imperial.
From 1963 through 1969, Chrysler increased its existing stakes to take full control of the French Simca, British Rootes and Spanish Barreiros companies, merging them into Chrysler Europe in 1967. In the 1970s, an engineering partnership was established with Mitsubishi Motors, and Chrysler began selling Mitsubishi vehicles branded as Dodge and Plymouth in North America.

Chrysler struggled to adapt to the changing environment of the 1970s. When consumer tastes shifted to smaller cars in the early 1970s, particularly after the 1973 oil crisis, Chrysler could not meet the demand. Additional burdens came from increased US import competition, and tougher government regulation of car safety, fuel economy, and emissions. As the smallest of the Big 3 US automakers, Chrysler lacked the financial resources to meet all of these challenges. In 1978, Lee Iacocca was brought in to turn the company around, and in 1979 Iacocca sought US government help. Congress later passed the "Loan Guarantee Act" providing $1.5 billion in loan guarantees. The "Loan Guarantee Act" required that Chrysler also obtain $2 billion in concessions or aid from sources outside the federal government, which included interest rate reductions for $650 million of the savings, asset sales of $300 million, local and state tax concessions of $250 million, and wage reductions of about $590 million along with a $50 million stock offering. $180 million was to come from concessions from dealers and suppliers.

After a period of plant closures and salary cuts agreed to by both management and the auto unions, the loans were repaid with interest in 1983. In November 1983, the Dodge Caravan/Plymouth Voyager was introduced, establishing the minivan as a major category, and initiating Chrysler's return to stability.

In 1985, Diamond-Star Motors was created, further expanding the Chrysler-Mitsubishi relationship. In 1987, Chrysler acquired American Motors Corporation (AMC), which brought the profitable Jeep brand under the Chrysler umbrella.

In 1985, Chrysler entered an agreement with AMC to produce Chrysler M platform rear-drive, as well as Dodge Omnis front wheel drive cars, in AMC's Kenosha, Wisconsin plant. In 1987, Chrysler acquired the 47% ownership of AMC that was held by Renault. The remaining outstanding shares of AMC were bought on the NYSE by August 5, 1987, making the deal valued somewhere between US$1.7 billion and US$2 billion, depending on how costs were counted. Chrysler CEO Lee Iacocca wanted the Jeep brand, particularly the Jeep Grand Cherokee (ZJ) that was under development, the new world-class manufacturing plant in Bramalea, Ontario, and AMC's engineering and management talent that became critical for Chrysler's future success. Chrysler established the Jeep/Eagle division as a "specialty" arm to market products distinctly different from the K-car-based products with the Eagle cars targeting import buyers. Former AMC dealers sold Jeep vehicles and various new Eagle models, as well as Chrysler products, strengthening the automaker's retail distribution system.

Eurostar, a joint venture between Chrysler and Steyr-Daimler-Puch, began producing the Chrysler Voyager in Austria for European markets in 1992.

In 1998, Chrysler and its subsidiaries entered into a partnership dubbed a "merger of equals" with German-based Daimler-Benz AG, creating the combined entity DaimlerChrysler AG. To the surprise of many stockholders, Daimler acquired Chrysler in a stock swap before Chrysler CEO Bob Eaton retired. It is widely accepted that the merger was needed because of Eaton's lack of planning for Chrysler in the 1990s, to become their own global automotive company. Under DaimlerChrysler, the company was named DaimlerChrysler Motors Company LLC, with its U.S. operations generally called "DCX". The Eagle brand was retired soon after Chrysler's merger with Daimler-Benz in 1998 Jeep became a stand-alone division, and efforts were made to merge the Chrysler and Jeep brands as one sales unit. In 2001, the Plymouth brand was also discontinued.

Eurostar also built the Chrysler PT Cruiser in 2001 and 2002. The Austrian venture was sold to Magna International in 2002 and became Magna Steyr. The Voyager continued in production until 2007, whereas the Chrysler 300C, Jeep Grand Cherokee and Jeep Commander were also built at the plant from 2005 to 2010.

On May 14, 2007, DaimlerChrysler announced the sale of 80.1% of Chrysler Group to American private equity firm Cerberus Capital Management, L.P., thereafter known as Chrysler LLC, although Daimler (renamed as Daimler AG) continued to hold a 19.9% stake.

The economic collapse of 2007 to 2009 pushed the fragile company to the brink. On April 30, 2009, the automaker filed for Chapter 11 bankruptcy protection to be able to operate as a going concern, while renegotiating its debt structure and other obligations, which resulted in the corporation defaulting on over $4 billion in secured debts. The U.S. government described the company's action as a "prepackaged surgical bankruptcy".

On June 10, 2009, substantially all of Chrysler's assets were sold to "New Chrysler", organized as Chrysler Group LLC. The federal government provided support for the deal with US$8 billion in financing at near 21%. Under CEO Sergio Marchionne, "World Class Manufacturing" or WCM, a system of thorough manufacturing quality, was introduced and several products re-launched with quality and luxury. The 2010 Jeep Grand Cherokee very soon became the most awarded SUV ever. The Ram, Jeep, Dodge, SRT and Chrysler divisions were separated to focus on their own identity and brand, and 11 major model refreshes occurred in 21 months. The PT Cruiser, Nitro, Liberty and Caliber models (created during DCX) were discontinued. On May 24, 2011, Chrysler repaid its $7.6 billion loans to the United States and Canadian governments. The US Treasury, through the Troubled Asset Relief Program (TARP), invested $12.5 billion in Chrysler and recovered $11.2 billion when the company shares were sold in May 2011, resulting in a $1.3 billion loss. On July 21, 2011, Fiat bought the Chrysler shares held by the US Treasury. The purchase made Chrysler foreign-owned again, this time as the luxury division. The Chrysler 300 was badged Lancia Thema in some European markets (with additional engine options), giving Lancia a much needed replacement for its flagship.

On January 21, 2014, Fiat bought the remaining shares of Chrysler owned by the VEBA worth $3.65 billion. Several days later, the intended reorganization of Fiat and Chrysler under a new holding company, Fiat Chrysler Automobiles, together with a new FCA logo were announced. The most challenging launch for this new company came immediately in January 2014 with a completely redesigned Chrysler 200. The vehicle's creation is from the completely integrated company, FCA, executing from a global compact-wide platform.

On December 16, 2014, Chrysler Group LLC announced a name change to FCA US LLC.

On January 12, 2017, FCA shares traded at the New York Stock Exchange lost value after the EPA accused FCA US of using emissions cheating software to evade diesel-emissions tests, however the company countered the accusations, and the chairman and CEO Sergio Marchionne sternly rejected them. The following day, shares rose as investors played down the effect of the accusations. Analysts gave estimates of potential fines from several hundred million dollars to $4 billion, although the likelihood of a hefty fine was low. Senior United States Senator Bill Nelson urged the FTC to look into possible deceptive marketing of the company's diesel-powered SUVs. Shares dropped 2.2% after the announcement.

On July 21, 2018, Sergio Marchionne stepped down as chairman and CEO for health reasons, and was replaced by John Elkann and Michael Manley, respectively.

As a result of ending domestic production of more fuel-efficient passenger automobiles such as the Dodge Dart and Chrysler 200 sedans, FCA US elected to pay $77 million in fines for violating the anti-backsliding provision of fuel economy standards set under the Energy Independence and Security Act of 2007 for its model year 2016 fleet. It was again fined for the 2017 model year for not meeting the minimum domestic passenger car standard. FCA described the $79 million civil penalty as "not expected to have a material impact on its business."

As part of a January 2019 settlement, Fiat Chrysler will recall and repair approximately 100,000 automobiles equipped with a 3.0-liter V6 EcoDiesel engine having a prohibited defeat device, pay $311 million in total civil penalties to US regulators and CARB, pay $72.5 million for state civil penalties, implement corporate governance reforms, and pay $33.5 million to mitigate excess pollution. The company will also pay affected consumers up to $280 million and offer extended warranties on such vehicles worth $105 million. The total value of the settlement is worth about $800 million, though FCA did not admit liability, and it did not resolve an ongoing criminal investigation.

, management positions of FCA US include:



Chrysler is the smallest of the "Big Three" U.S. automakers (FCA US, Ford Motor Company, and General Motors). In 2019, Chrysler sold just over 2.2 million vehicles.

Chrysler is the world's 11th largest vehicle manufacturer as ranked by OICA in 2012. Total Chrysler vehicle production was about 2.37 million that year.

In 2007, Chrysler began to offer vehicle lifetime powertrain warranty for the first registered owner or retail lessee. The deal covered owner or lessee in U.S., Puerto Rico and the Virgin Islands, for 2009 model year vehicles, and 2006, 2007 and 2008 model year vehicles purchased on or after July 26, 2007. Covered vehicles excluded SRT models, Diesel vehicles, Sprinter models, Ram Chassis Cab, Hybrid System components (including transmission), and certain fleet vehicles. The warranty is non-transferable. After Chrysler's restructuring, the warranty program was replaced by five-year/100,000 mile transferable warranty for 2010 or later vehicles.

In 2008, as a response to customer feedback citing the prospect of rising gas prices as a top concern, Chrysler launched the "Let's Refuel America" incentive campaign, which guaranteed new-car buyers a gasoline price of $2.99 for three years. With the U.S. purchase of eligible Chrysler, Jeep, and Dodge vehicles, customers could enroll in the program and receive a gas card that immediately lowers their gas price to $2.99 a gallon, and keeps it there for the three years.

Chrysler plans for Lancia to codevelop products, with some vehicles being shared. Olivier Francois, Lancia's CEO, was appointed to the Chrysler division in October 2009. Francois plans to reestablish the Chrysler brand as an upscale brand.

In October 2009, Dodge's car and truck lines were separated, with the name "Dodge" being used for cars, minivans and crossovers and "Ram" for light- and medium-duty trucks and other commercial-use vehicles.<ref name="autoblog.com/2009"></ref>
In 2011, Chrysler unveiled their "Imported From Detroit" campaign with ads featuring Detroit rapper Eminem, one of which aired during the Super Bowl. The campaign highlighted the rejuvenation of the entire product lineup, which included the new, redesigned and repackaged 2011 200 sedan and 200 convertible, the Chrysler 300 sedan and the Chrysler Town & Country minivan. As part of the campaign, Chrysler sold a line of clothing items featuring the Monument to Joe Louis, with proceeds being funneled to Detroit-area charities, including the Boys and Girls Clubs of Southeast Michigan, Habitat for Humanity Detroit and the Marshall Mathers Foundation. Following the Eminem ad, there was also an ad for Detroit Lions defensive tackle Ndamukong Suh driving a Chrysler 300 to Portland, Oregon, to visit his mother, an ad featuring Detroit-born fashion designer John Varvatos cruising through a shadowy Gotham while Kevin Yon's familiar baritone traces the designer's genesis.

In March 2011, Chrysler Group LLC filed a lawsuit against Moda Group LLC (owner of Pure Detroit clothing retailer) for copying and selling merchandise with the "Imported from Detroit" slogan. Chrysler claimed it had notified defendant of its pending trademark application February 14, but the defendant argued Chrysler had not secured a trademark for the "Imported From Detroit" phrase. On June 18, 2011, U.S. District Judge Arthur Tarnow ruled that Chrysler's request did not show that it would suffer irreparable harm or that it had a strong likelihood of winning its case. Therefore, Pure Detroit's owner, Detroit retailer Moda Group LLC, can continue selling its "Imported from Detroit" products. Tarnow also noted that Chrysler does not have a trademark on "Imported from Detroit" and rejected the automaker's argument that trademark law is not applicable to the case. In March 2012, Chrysler Group LLC and Pure Detroit agreed to a March 27 mediation to try to settle the lawsuit over the clothing company's use of "Imported from Detroit" slogan. Pure Detroit stated that Chrysler has made false claims about the origins of three vehicles - Chrysler 200, Chrysler 300 and Chrysler Town & Country - none of which are built in Detroit. Pure Detroit also said that Chrysler's Imported From Detroit merchandise is not being made in Detroit. In 2012 Chrysler and Pure Detroit came to an undisclosed settlement.

Chrysler's Jefferson North Assembly, which makes the Jeep Grand Cherokee and Dodge Durango, is the only car manufacturing plant of any company remaining entirely in Detroit (General Motors operates a plant which is partly in Detroit and partly in Hamtramck).

In 2011, Eminem settled a lawsuit against Audi alleging the defendant had ripped off the Chrysler 300 Super Bowl commercial in the Audi A6 Avant ad.

Again in 2012, Chrysler advertised during the Super Bowl. Its two-minute February 5, 2012 Super Bowl XLVI advertisement was titled "Half Time in America". The ad drew criticism from several leading U.S. conservatives, who suggested that its messaging implied that President Barack Obama deserved a second term and, as such, was political payback for Obama's support for the federal bailout of the company. Asked about the criticism in a "60 Minutes" interview with Steve Kroft, Sergio Marchionne responded "just to rectify the record I paid back the loans at 19.7% Interest. I don't think I committed to do to a commercial on top of that" and characterized the Republican reaction as "unnecessary and out of place".


In 2014, Chrysler started using a new slogan, "America's Import" in ads introducing their all-new 2015 Chrysler 200, targeting foreign automakers from Germany to Japan with such ads (German performance and Japanese quality), and at the ending of selected ads, the advertisement will say, "We Built This", indicating being built in America, instead of overseas.




First introduced as MyGig, Chrysler Uconnect is a system that brings interactive ability to the in-car radio and telemetric-like controls to car settings. As of mid-2015, it is installed in hundreds of thousands of Fiat Chrysler vehicles. It connects to the Internet via the mobile network of AT&T, providing the car with its own IP address. Internet connectivity using any Chrysler, Dodge, Jeep or Ram vehicle, via a Wi-Fi "hot-spot", is also available via Uconnect Web. According to Chrysler LLC, the hotspot range extends approximately from the vehicle in all directions, and combines both Wi-Fi and Sprint's 3G cellular connectivity. Uconnect is available on several current and was available on several discontinued Chrysler models including the current Dodge Dart, Chrysler 300, Aspen, Sebring, Town and Country, Dodge Avenger, Caliber, Grand Caravan, Challenger, Charger, Journey, Nitro, and Ram.

In July 2015, IT security researchers announced a severe security flaw assumed to affect every Chrysler vehicle with Uconnect produced from late 2013 to early 2015. It allows hackers to gain access to the car over the Internet, and in the case of a Jeep Cherokee was demonstrated to enable an attacker to take control not just of the radio, A/C, and windshield wipers, but also of the car's steering, brakes and transmission. Chrysler published a patch that car owners can download and install via a USB stick, or have a car dealer install for them.


The Chrysler brand has mostly been Chrysler's premium brand competing with brands such as Cadillac, Packard, Cord and Lincoln. After the corporation decided to spin Imperial off as a separate brand in 1955 to better compete with Cadillac and Lincoln, Chrysler became the corporation's number two brand, but still offered luxury and near-luxury products. After the Imperial brand was dropped in 1983, Chrysler once again became the top brand.

The first Chrysler cars were introduced on January 5, 1924, at the New York Automobile Show — one year before Chrysler Corporation itself was created. These cars, launched by Maxwell Motors, had a new high-compression six-cylinder, a seven-bearing crankshaft, carburetor air cleaner, replaceable oil filter and four-wheel hydraulic brakes. Features like this had never been offered in a medium-priced car before, and the 32,000 first-year record sales proved to popularity of this model.

In 1926, Chrysler Introduces the Chrysler 70 named for its ability to hit 70 MPH. This car came with innovative rubber engine and spring mounts.
In 1927, Chrysler had 4 models the Chrysler 50, 60, 70, and Imperial 80. Chrysler was fourth place in sales with 192,082 units delivered.
In 1928 Chrysler invested $23 million to expand its plants.

In 1930, Chrysler began wiring the Chrysler Model 70 and 77 for radios. Chrysler also became the first car to offer the downdraft carburetor on its models. With the new carburetor Chrysler also received a new cam-driven fuel pump. For the 1931 model Chrysler received new radiator grilles, a new inline 8 engine, and automatic spark control. The 1932 Chryslers introduced the Floating Power rubber engine mounts which eliminated further vibrations from the chassis. A vacuum controlled automatic clutch, Oilite bearings and the first universal joints with roller bearings were also added. In 1933 Chrysler models received a host of new improvements including a new three-speed manual transmission that used helical gears- for silent use. Chrysler engines received new alloy valve seats for better reliability, along with new spring shackles which improved lubrication. In 1934 the Chrysler 6 introduced an independent front coil spring suspension and received vent windows that rolled down with the side glass. Chrysler also introduced its revolutionary Chrysler Airflow, which included a welded Unibody, a wind tunnel designed aerodynamic body for a better power to power ratio, and better handling. In 1935 Chrysler introduced the Plymouth based Chrysler Airstream Six which gave customers an economical modern alternative to the radically styled Airflows. The Airflow received an updated front hood and grille for 1935. For 1936, the Chrysler Airflow received an enlarged luggage compartment, a new roof, and a new adjustable front seat. The Airstream Six and Eight of the previous year was renamed the Chrysler Six and Deluxe Eight. The Automatic overdrive was optional to both cars. For 1937 the Airflow cars were mostly discontinued besides the C-17 Airflow, which received a final facelift. Only 4600 C-17 Airflows were built for 1937. The Chrysler Six and Chrysler Eight were respectively renamed the Royal and Imperial, and gained isolated rubber body mounts to remove road vibrations. In 1938 the Chrysler Royal received the new 95 HP Gold Seal Inline 6. For 1939 Chrysler unveiled "Superfinish" a process in which all major chassis components subject to wear were finished to a mirror-like surface. Other features new to Chrysler were push button door locks and rotary type door latches.

For 1940 Chrysler introduces sealed beam headlights on its cars which in turn improves night visibility by 50%. Mid year in 1940 Chrysler introduces the Highlander as a special edition featuring popular features and Scottish plaid interior. the performance oriented model the Saratoga was also added to the Newyorker range. In 1941 Chrysler introduces the fluid-drive semiautomatic transmission. 1942 Chryslers were redesigned with a wrap-a-round chrome grille and concealed running boards for this abbreviated model year, civilian production stopped by February of 1942. For 1946 Chrysler redesigned the 1942 cars and reintroduced the Town & Country. For 1949 Chrysler came out with the first all new redesign in almost a decade. For 1949 Chrysler moved the ignition to key only instead of having a key and push button, they also reintroduced the nine passenger station wagon bodystyle to the line.

For 1950 Chrysler updated the overly conservative 1949 models by lowering cars slightly, updating the grille to appear mor simple, replacing the chrome fin tail lamps with flush units and the removal of the third brake light from the trunk lid. Also in 1950 chrysler introduced disc brakes on the Imperial, the new Chrysler Newport hardtop, Power windows and the padded safety dash.Chrysler introduced their first overhead-valve, high-compression V8 engine in 1951, Displacing 331 cubic inches, it was rated at 180 bhp, 20 more hoursepower than the new-for-1949 Cadillac V8. It was unique as the only American V8 engine designed with hemispherical combustion chambers. After successfully winning Mexican Road Races, the engine was upgraded to 250 bhp by 1955. Although Chrysler didn't have the capital to build a small sporty car (such as the Chevrolet Corvette and the Ford Thunderbird), they decided to build a unique sporting car based on the New Yorker hardtop coupe, that featured a 300-bhp "Hemi" V8. To add to the car's uniqueness, the car was given a grille from the Imperial, and side trim from the less-adorned Windsor. A PowerFlite 2-speed automatic transmission was the only available gearbox. It was marketed as the Chrysler 300, emphasizing the engine's horsepower.

A 1955 restyle by newly-hired Virgil Exner saw a dramatic rise in Chrysler sales, which rose even more in 1957, when the entire line was dramatically restyled a second time with a sloping front end and high-flying tailfins at the rear. Although well-received at first, it soon became apparent that quality control was compromised to get the new cars to market on an accelerated schedule. Sales therefore plummeted in 1958 and 1959 despite improvements in quality. Throughout the mid- and late-1950s, Chryslers were available in top-line New Yorker, mid-line Saratoga, and base Windsor series. Exner's designs for the Chrysler brand in the early 1960s were overblown versions of the late 1950s, which were unhelpful in sales. Exner left his post by 1962, leaving Elwood Engel, a recent transfer from Ford Motor Co, in charge of Chrysler styling.

Although early 1960s Chrysler cars reflected Virgil Exner's exaggerated styling, ELwood Engel's influence was evident as early as 1963, when a restyled, trimmer, boxier Chrysler was introduced. The Desoto lines along with the Windsor and Saratoga series were replaced with the Newport, while New Yorker continued as the top-of-the-line. The Chrysler 300, officially part of the New York line, continued in production through 1965, adding a different letter of the alphabet for each year of production, starting with the 300-B of 1956, through the 300-L of 1965. 1962 saw a "non-letter" 300 which was lower in price but was equipped with downgraded standard equipment. The '65 Chryslers were again dramatically restyled, with a thoroughly modern unit body and larger engines up to 440 cubic inches. They were trim and boxy, with glass-covered headlamps and a swept-back roofline for 2-door hardtop models. Although Chryslers though the 1960s were well-built, quality cars with man innovative features (such as unit bodies and front torsion bar suspension), sales slumped as American buyers bought record numbers of cars from Ford and GM.

The Cordoba was introduced by Chrysler for the 1975 model year as an upscale personal luxury car, competing with the Oldsmobile Cutlass, Buick Regal, and Mercury Cougar. The Cordoba was originally intended to be a Plymouth—the names Mirada, Premier, Sebring, and Grand Era were associated with the project; all except Grand Era would be used on later Chrysler, Dodge, and Eagle vehicles, though only the Dodge Mirada would be related to the Cordoba. However, losses from the newly introduced full-size C-body models due to the 1973 oil crisis encouraged Chrysler executives to seek higher profits by marketing the model under the more upscale Chrysler brand.

The car was a success, with over 150,000 examples sold in 1975, a sales year that was otherwise dismal for the company. For the 1976 model year, sales increased slightly to 165,000. The mildly revised 1977 version also sold well, with just under 140,000 cars. The success of using the Chrysler nameplate strategy is contrasted to sales of its similar and somewhat cheaper corporate cousin, the Dodge Charger SE. Interiors were more luxurious than the Dodge Charger SE and much more than the top-line standard intermediates (Plymouth Fury, Dodge Coronet) with a velour cloth notchback bench seat and folding armrest standard. Optionally available were bucket seats upholstered in Corinthian leather with a center armrest and cushion, or at extra cost, a center console with floor shifter and storage compartment.

In 1977, Chrysler brought out a new mid-size line of cars called LeBaron (a name previously used for an Imperial model) which included a coupe, sedan, and station wagon.

For 1982, the LeBaron moved to the front-wheel drive Chrysler K platform, where it was the upscale brand's lowest priced offering. It was initially available in just sedan and coupe versions. In early 1982, it was released in a convertible version, bringing to the market the first factory-built open-topped domestic vehicle since the 1976 Cadillac Eldorado. A station wagon version called the Town and Country was added as well. A special Town and Country convertible was also made from 1983 to 1986 in limited quantities (1,105 total), which like the wagon featured simulated wood paneling that made it resemble the original 1940s Town and Country. This model was part of the well-equipped Mark Cross option package for the latter years.

In 1982 the R-body line was discontinued and the New Yorker nameplate transferred to the smaller M-body line. Up to this point, the Chrysler M-body entry had been sold as LeBaron, but that name was moved to a new K-car based FWD line (refer to the Chrysler LeBaron article for information on the 1977-81 M-bodies). Following the nameplate swap, the M-body line was consolidated and simplified. 360 V8 engines were gone, as were coupes and station wagons (the K-car LeBaron's coupe and wagon replaced them). The Fifth Avenue option was still available as a $1,244 option package. It was adapted from the earlier LeBaron's package, with a distinctive vinyl roof, electro-luminescent opera lamps, and a rear fascia adapted from the Dodge Diplomat. Interiors featured button-tufted, pillow-soft seats covered in either "Kimberley velvet" or "Corinthian leather", choices that would continue unchanged throughout the car's run. In addition, the carpet was thicker than that offered in the base New Yorker, Diplomat and Gran Fury/Caravelle Salon, and the interior had more chrome trim.

1983 was the last year for Chrysler's Cordoba coupe. Also in 1983, Chrysler introduced a new front-wheel drive New Yorker model based on a stretched K-Car platform. Additionally, a less expensive, less equipped version of the new New Yorker was sold as the Chrysler E-Class in 1983 and 1984. More upscale stretched K-Car models were also sold as Chrysler Executive sedans and limousines.

For 1984, the New Yorker Fifth Avenue was now simply called Fifth Avenue, setting the name that would continue for six successful years. All Fifth Avenues from 1984 to 1989 were powered by a 5.2 L (318 in³) V8 engine, with either a two barrel carburetor making (in all states except California) or a four barrel rated at (in California), mated to Chrysler's well-known Torqueflite three speed automatic transmission. Fifth Avenue production was moved from Windsor, Ontario to St. Louis, Missouri. Beginning in late 1986 through the 1989 model year, they were manufactured at the American Motors plant in Kenosha, Wisconsin (purchased by Chrysler in 1987). The Fifth Avenue also far outsold its Dodge Diplomat and Plymouth Gran Fury siblings, with a much greater proportion of sales going to private customers, despite its higher price tag. Production peaked at 118,000 cars for 1986 and the Fifth Avenue stood out in a by-now K-car dominated lineup as Chrysler's lone concession to traditional RWD American sedans.

Chrysler introduced a new mid-size five door hatchback model for 1985 under the LeBaron GTS nameplate. It was sold alongside the mid-size LeBaron sedan, coupe, convertible, and station wagon. The LeBaron coupe and convertible were redesigned for 1987. Unlike previous LeBarons, this new coupe and convertible had unique styling instead of being just two-door versions of the sedan. The new design featured hidden headlamps (through 1992) and full width taillights.

The New Yorker was redesigned for the 1988 model year and now included a standard V6 engine. This generation New Yorker also saw the return of hidden headlamps which had not been available on the New Yorker since the 1981 R-body version. In 1989, Chrysler brought out the TC by Maserati luxury roadster as a more affordable alternative to Cadillac's Allante. It was a joint venture model between Chrysler and Maserati.

Chrysler re-introduced the Town & Country nameplate in calendar year 1989 as a luxury rebadged variant of the Dodge Grand Caravan/Plymouth Grand Voyager minivan for the 1990 model year and continued to sell this incarnation of the Chrysler Town & Country until the end of the 2016 model year when Chrysler reintroduced the Pacifica nameplate for their minivan in calendar year 2016 for the 2017 model year run. 1990 saw the previous relationship between New Yorker and Fifth Avenue return, as the Fifth Avenue became a model of the New Yorker. There was some substantive difference, however, as the New Yorker Fifth Avenue used a slightly longer chassis than the standard car. The new New Yorker Fifth Avenue's larger interior volume classified it as a full-size model this time; despite having smaller exterior dimensions than the first generation. For 1990, Chrysler's new 3.3-liter V6 engine was the standard and only choice, teamed with the company's A-604 four-speed electronic automatic transaxle. Beginning in 1991, a larger 3.8-liter V-6 became optional. It delivered the same 147 horsepower as the 3.3, but had more torque.

The New Yorker Fifth Avenue's famous seats, long noted for their button-tufted appearance and sofa-like comfort, continued to be offered with the customer's choice of velour or leather, with the former "Corinthian leather" replaced by that of the Mark Cross company. Leather-equipped cars bore the Mark Cross logo on the seats and, externally, on an emblem attached to the brushed aluminum band ahead of the rear door opera windows. In this form, the New Yorker Fifth Avenue resembled the newly revived Chrysler Imperial, although some much-needed distinction was provided between the cars when the New Yorker Fifth Avenue (along with its New Yorker Salon linemate) received restyled, rounded-off front and rear ends for the 1992 model year, while the Imperial continued in its original crisply-lined form.

The early 1990s saw a revival of the Imperial as a high-end sedan in Chrysler's lineup. Unlike the 1955–1983 Imperial, this car was a model of Chrysler, not its own marque. Based on the Y platform, it represented the top full-size model in Chrysler's lineup; below it was the similar New Yorker Fifth Avenue, and below that was the shorter wheelbase New Yorker. The reintroduction of the Imperial was two years after the Lincoln Continental was changed to a front-wheel drive sedan with a V6 engine. Other domestic competitors in this segment included the Cadillac Sedan de Ville/Fleetwood, Oldsmobile 98 and Buick Electra/Park Avenue. Though closely related, the Imperial differed from the New Yorker Fifth Avenue in many ways. The Imperial's nose was more wedge-shaped, while the New Yorker Fifth Avenue's had a sharper, more angular profile (the New Yorker Fifth Avenue was later restyled with a more rounded front end). The rears of the two cars also differed. Like the front, the New Yorker Fifth Avenue's rear came to stiffer angles while the Imperial's rear-end came to more rounded edges. Also found on the Imperial were full-width taillights which were similar to those of the Chrysler TC, as well as the early 1980s Imperial coupe, while the New Yorker Fifth Avenue came with smaller vertical taillights.

Initially, the 1990 Imperial was powered by the 3.3 L "EGA" V6 engine, which was rated at of torque. For 1991, the 3.3 L V6 was replaced by the larger 3.8 L "EGH" V6. Although horsepower only increased to , with the new larger 3.8 L V6 torque increased to at 2750 rpm. A four-speed automatic transmission was standard with both engines.

Also new for 1990 was a redesigned LeBaron sedan which offered a standard V6 engine. Later models would also be available with 4 cylinder engines.

The Town & Country minivan was restyled for 1991 in conjunction with the restyling of the Dodge and Plymouth minivan models. 1991 would also be the last year for the TC by Maserati, leaving the LeBaron as the brand's sole coupe and convertible options.

The first generation of the Chrysler Concorde debuted at the 1992 North American International Auto Show in Detroit as a 1993 model. It debuted as a single, well-equipped model with a base price of US$18,341. Out of all the LH sedans, the first generation Concorde was most closely related to the Eagle Vision. The Concorde was given a more traditional image than the Vision. The two shared nearly all sheetmetal in common with the main differences limited to their grilles, rear fascias, body side moldings, and wheel choices. The Concorde featured a modern take on Chrysler's signature waterfall grille. It was split into six sections divided by body colored strips with the Chrysler Pentastar logo on the center strip. The Concorde's rear fascia was highlighted by a full-width and full-height lightbar between the taillights, giving the appearance that the taillights stretched across the entire trunk. In keeping with its upscale position, Concorde's body side moldings incorporated bright chrome (later golden colored) work not found on its Dodge or Eagle siblings. On Concordes with gray lower body paint color, the gray came all the way up to the chrome beltline; on Visions the gray lower body paint area was smaller and much more subtle. Wheel styles, which included available aluminum wheels with a Spiralcast design, were also unique to the Chrysler LH sedans (Concorde, LHS, New Yorker); Dodge and Eagle had their own different wheel styles.

Introduced in May 1993 for the 1994 model year, the Chrysler LHS was the top of the line model for the division, as well as the most expensive of the Chrysler LH platform cars. All the LH-series models shared a wheelbase and were developed using Chrysler's new computer drafting system. The car was differentiated from the division's New Yorker sedan by its bucket leather seats (the New Yorker had a bench seat) and standard features such as alloy wheels that were options on the New Yorker. Further differences between the Chrysler LHS and its New Yorker counterpart were a floor console and shifter, five-passenger seating, lack of chrome trim, an upgraded interior and a sportier image. The New Yorker was dropped after the 1996 model year in favor of a six-passenger option on the LHS. The LHS received a minor face change in 1995 when the corporate wide pentastar emblem was replaced with the revived Chrysler brand emblem. Standard features of the LHS included a 3.5 L EGE 24-valve V6 engine, body-colored grille, side mirrors and trim, traction control, aluminum wheels, integrated fog lights, 8-way power adjustable front seats, premium sound systems with amplifiers, and automatic temperature control. Unlike the New Yorker, leather seats were standard.

The final generation of the New Yorker continued with front-wheel drive on an elongated version of the new Chrysler LH platform and was released in May 1993 along with the nearly identical Chrysler LHS as an early 1994 model, eight months after the original LH cars: the Chrysler Concorde, Dodge Intrepid, and Eagle Vision, were introduced. The New Yorker came standard with the 3.5 L "EGE" which produced . Chrysler gave the New Yorker a more "traditional American" luxury image, and the LHS a more European performance image (as was done with the Eagle Vision). Little separated New Yorker from LHS in appearance, with New Yorker's chrome hood trim, body-color cladding, standard chrome wheel covers and 15" wheels, column shifter and front bench seat, being the only noticeable differences. An option provided for 16" wheels and a firmer suspension type ("touring suspension"). This option eliminated the technical differences between New Yorker and LHS. LHS came with almost all of New Yorker's optional features as standard equipment and featured the firmer tuned suspension, to go with its more European image.

During the 1994 model run, various changes were made to the New Yorker. On the outside, New Yorker was switched to new accent-color body cladding, whereas LHS received body-color cladding. This change aligned New Yorker with the Chrysler Concorde which also had accent-color cladding. Instead of standard 15" and optional 16" wheels, for the sake of enhanced stability 16" wheels became standard and the 15" wheels were dropped. Likewise, the touring suspension option available on early 1994 New Yorker models was discontinued, leaving only "ride-tuned" suspension.

In 1995, the Chrysler Sebring was introduced as a coupe, replacing the LeBaron coupe, and the new JA platform Chrysler Cirrus replaced the outgoing LeBaron sedan. A year later, a convertible version of the Sebring went on the market and replaced the LeBaron convertible. In 1999, Chrysler introduced the new LH platform 300M sedan alongside a redesigned LHS. The 300M was originally designed to be the next generation Eagle Vision but since the Eagle brand had been discontinued in 1998, it instead became a Chrysler sedan.

In 2000, the Voyager and Grand Voyager minivans were repositioned as Chrysler models due to the phasing out of the Plymouth brand. In 2001, a sedan was added to the Sebring model line and served as a replacement for the discontinued Cirrus. That same year, the Chrysler brand added a retro-styled PT Cruiser as well as the Prowler roadster which had previously been a Plymouth model. By 2004, all Chrysler brand minivans were now sold under the Town & Country nameplate.

The 2000s also saw the Chrysler brand move into the fast growing crossover/SUV segment with the introduction of the Chrysler Pacifica crossover in 2004, and the Chrysler Aspen SUV in 2007. The Pacifica would be discontinued in 2008 (the nameplate would return on a new minivan model in 2017) and the Aspen would be discontinued in 2009.

Between 2004 and 2008, Chrysler offered a two-seat coupe and convertible model called Crossfire. This was in addition to Chrysler's five-seat Sebring coupe (through 2005) and four-seat convertible being sold at the time.

In 2005, Chrysler introduced the LX platform Chrysler 300 sedan which replaced both the 300M and Concorde. It was the brand's first rear-wheel drive sedan since the discontinuation of the Chrysler Fifth Avenue in 1989. It was also the first time a Chrysler sedan was available with a V8 engine since 1989.

Following FCA's acquisition of Chrysler, FCA set a long-term goal of reviving the Chrysler brand as a full luxury brand to compete again with Cadillac and other luxury brands. The company stated in October 2009 that future plans for Chrysler brand vehicles include closer cooperation and shared development between Chrysler and Lancia, an upscale Italian automaker within the Fiat Group. In 2011, the brand's winged emblem was modified, eliminating the historic blue ribbon center which dated from the 1930s, replacing it with a blue-backed "Chrysler" nameplate. Also that year, the Chrysler 300 was restyled and the Sebring was rebranded as the Chrysler 200. In May 2014, FCA announced it would make the brand a mainstream brand with premium features. A redesigned Chrysler 200 was introduced for 2015 as a sedan only, but would be discontinued in 2017 as FCA shifted focus more towards SUVs and minivans. For 2017, the Chrysler Pacifica nameplate returned on a new minivan, replacing the long-running Town & Country.

On June 27, 2019, FCA announced that the low-end "L" and "LX" models would be separated from the Pacifica line and sold under the Voyager nameplate starting with the 2020 model year. Additionally, a fleet-only Voyager "LXi" version would be added.

The brand's current lineup consists of the Chrysler 300, Chrysler Pacifica and Chrysler Voyager.

In 2010, Fiat Auto was planning to sell seven of its vehicles in the U.S. by 2014, while Fiat-controlled Chrysler Group was to supply nine models to sell under Fiat brands in the European market, according to a five-year plan rolled out on April 21, 2010 in Turin, Italy, by Fiat and Chrysler CEO Sergio Marchionne. At least five of the Fiat Auto models were expected to be marketed in the U.S. under its Alfa Romeo brand. Showing the level of integration envisioned, a product introduction timeline envisaged Chrysler-built compact and full-size SUVs going on sale in 2012 and 2014, respectively, in both European and North American markets.

Chrysler's quality and customer satisfaction ratings have been below average according to Consumer Reports and JD Powers since the late 1990s. Consumer Reports has consistently reported Chrysler brands at the bottom of their reliability ratings in the past decade as well as their Automotive Brand Report Card. JDP has found similar results over the same time period in both Initial Quality Studies and Customer Service Indexes as has the American Customer Satisfaction Index survey. Chrysler has had a few quality successes during this period. Strategic Vision named Chrysler an overall winner in 2015 noting strong customer appeal and that with the rise in quality of all cars the difference between high and low "problem-counting" ratings are relatively small.

Chrysler produced an experimental electric vehicle in 1979, the company developed Chrysler ETV-1 electric prototype in cooperation with U.S. Department of Energy.

In 1992, Chrysler developed the Dodge EPIC concept minivan. In 1993, Chrysler began to sell a limited-production electric minivan called the TEVan; however only 56 were produced. In 1997, a second generation, called the EPIC, was released. It was discontinued after 1999.

Chrysler once owned the Global Electric Motorcars company, building low-speed neighborhood electric vehicles, but sold GEM to Polaris Industries in 2011.

In September 2007, Chrysler established ENVI, an in-house organization focused on electric-drive vehicles and related technologies which was disbanded by late 2009. In August 2009, Chrysler took US$70 million in grants from the U.S. Department of Energy to develop a test fleet of 220 hybrid pickup trucks and minivans.

The first hybrid models, the Chrysler Aspen hybrid and the Dodge Durango hybrid, were discontinued a few months after production in 2008, sharing their GM-designed hybrid technology with GM, Daimler and BMW.

Chrysler is on the Advisory Council of the PHEV Research Center, and undertook a government sponsored demonstration project with Ram and minivan vehicles.

In 2012, FCA CEO Sergio Marchionne said that Chrysler and Fiat both plan to focus primarily on alternative fuels, such as CNG and Diesel, instead of hybrid and electric drivetrains for their consumer products.

Fiat Chrysler bought 8.2 million megagrams of U.S. greenhouse gas emission credits from competitors including Toyota, Honda, Tesla and Nissan. It had the worst fleet average fuel economy among major manufacturers selling in the US from model years 2012–2018.

The dedicated tank building division of Chrysler, this division was founded as the Chrysler Tank division in 1940, originally with the intention of providing another production line for the M2 Medium Tank, so that the U.S. Army could more rapidly build up its inventory of the type. Its first plant was the Detroit Arsenal Tank Plant. When the M2A1 was unexpectedly declared obsolete in August of the same year, plans were altered (though not without considerable difficulty) to produce the M3 Grant instead, primarily for the British as part of the United States under the counter support for Great Britain against Nazi Germany (the U.S. not yet being formally in the war), with the balance of the revised order going to the U.S. Army as the "Lee". After December 1941 and the United States' entry into the war against the Axis powers, the Tank division rapidly expanded, with new facilities such as the Tank Arsenal Proving Ground at (then) Utica, Michigan. It also quickly widened the range of products it was developing and producing, including the M4 Sherman tank and the Chrysler A57 multibank tank engine.

During World War II, essentially all of Chrysler's facilities were devoted to building military vehicles (the Jeep brand came later, after Chrysler acquired American Motors Corporation). They were also designing V12 and V16 hemi-engines producing for airplanes, but they did not make it into production as jets were developed and were seen as the future for air travel. During the 1950s Cold War period, Chrysler made air raid sirens powered by its Hemi V-8 engines.

When the Radiation Laboratory at MIT was established in 1941 to develop microwave radars, one of the first projects resulted in the SCR-584, the most widely recognized radar system of the war era. This system included a parabolic antenna six feet in diameter that was mechanically aimed in a helical pattern (round and round as well as up and down).

One of Chrysler's most significant contributions to the war effort was not in the field of vehicles but in the radar field. For the final production design of this antenna and its highly complex drive mechanism, the Army's Signal Corps Laboratories turned to Chrysler's Central Engineering Office. There, the parabola was changed from aluminum to steel, allowing production forming using standard automotive presses. To keep weight down, 6,000 equally spaced holes were drilled in the face (this had no effect on the radiation pattern). The drive mechanism was completely redesigned, using technology derived from Chrysler's research in automotive gears and differentials. The changes resulted in improved performance, reduced weight, and easier maintenance. A large portion of the Dodge plant was used in building 1,500 of the SCR-584 antennas as well as the vans used in the systems.


In April 1950, the U.S. Army established the Ordnance Guided Missile Center (OGMC) at Redstone Arsenal, adjacent to Huntsville, Alabama. To form OGMC, over 1,000 civilian and military personnel were transferred from Fort Bliss, Texas. Included was a group of German scientists and engineers led by Wernher von Braun; this group had been brought to America under Project Paperclip. OGMC designed the Army's first short-range ballistic missile, the PGM-11 Redstone, based on the WWII German V-2 missile. Chrysler established the Missile Division to serve as the Redstone prime contractor, setting up an engineering operation in Huntsville and for production obtaining use from the U.S. Navy of a large plant in Sterling Heights, Michigan. The Redstone was in active service from 1958 to 1964; it was also the first missile to test-launch a live nuclear weapon, first detonated in a 1958 test in the South Pacific.

Working together, the Missile Division and von Braun's team greatly increased the capability of the Redstone, resulting in the PGM-19 Jupiter, a medium-range ballistic missile. In May 1959, a Jupiter missile launched two small monkeys into space in a nose cone; this was America's first successful flight and recovery of live space payloads. Responsibility for deploying Jupiter missiles was transferred from the Army to the Air Force; armed with nuclear warheads, they were first deployed in Italy and Turkey during the early 1960s.

In July 1959, NASA chose the Redstone missile as the basis for the Mercury-Redstone Launch Vehicle to be used for suborbital test flights of the Project Mercury spacecraft. Three unmanned MRLV launch attempts were made between November 1960 and March 1961, two of which were successful. The MRLV successfully launched the chimpanzee Ham, and astronauts Alan Shepard and Gus Grissom on three suborbital flights in January, May and July 1961, respectively.

America's more ambitious manned space travel plans included the design of the Saturn series of heavy-lift launch vehicles by a team headed by Wernher von Braun. Chrysler's Huntsville operation, then designated the Space Division, became Marshall Space Flight Center's prime contractor for the first stage of the Saturn I and Saturn IB versions. The design was based on a cluster of Redstone and Jupiter fuel tanks, and Chrysler built it for the Apollo program in the Michoud Assembly Facility in East New Orleans, one of the largest manufacturing plants in the world. Between October 1961 and July 1975, NASA used ten Saturn Is and nine Saturn IBs for suborbital and orbital flights, all of which were successful; Chrysler missiles and boosters never suffered a launch failure. The division was also a subcontractor which modified one of the mobile launcher platforms for use with the Saturn IB rockets using Saturn V infrastructure.





</doc>
<doc id="6883" url="https://en.wikipedia.org/wiki?curid=6883" title="City of London">
City of London

The City of London is a city, ceremonial county and local government district that contains the historic centre and the primary central business district (CBD) of London. It constituted most of London from its settlement by the Romans in the 1st century AD to the Middle Ages, but the modern city named London has since grown far beyond the formal City of London borders. The City is now only a tiny part of the metropolis of London, though it remains a notable part of central London. Administratively, it forms one of the 33 local authority districts of London; however, the City of London is not a London borough, a status reserved for the other 32 districts (including London's only other city, the City of Westminster). It is also a separate ceremonial county, being an enclave surrounded by Greater London, and is the smallest county in the United Kingdom.

The City of London is widely referred to simply as the City (differentiated from the phrase "the city of London" by capitalising "City") and is also colloquially known as the Square Mile, as it is in area. Both of these terms are also often used as metonyms for the United Kingdom's trading and financial services industries, which continue a notable history of being largely based in the City. The name "London" is now ordinarily used for a far wider area than just the City. "London" most often denotes the sprawling London metropolis, or the 32 London boroughs, in addition to the City of London itself. This wider usage of "London" is documented as far back as 1888, when the County of London was created.

The local authority for the City, namely the City of London Corporation, is unique in the UK and has some unusual responsibilities for a local council, such as being the police authority. It is also unusual in having responsibilities and ownerships beyond its boundaries. The Corporation is headed by the Lord Mayor of the City of London (an office separate from, and much older than, the Mayor of London). The Lord Mayor, as of November 2019, is William Russell. The City is made up of 25 wards, with administration at the historic Guildhall. Other historic sites include, St Paul's Cathedral, Royal Exchange, Mansion House, Old Bailey, and Smithfield Market. Although not within the City, the adjacent Tower of London is part of its old defensive perimeter. Bridges under the jurisdiction of the City include London Bridge and Blackfriars Bridge. 

The City is a major business and financial centre. Throughout the 19th century, the City was the world's primary business centre, and it continues to be a major meeting point for businesses. London came top in the Worldwide Centres of Commerce Index, published in 2008. The insurance industry is focused around the eastern side of the City, around Lloyd's building. A secondary financial district exists outside the City, at Canary Wharf, to the east.

The City has a resident population of 9,401 (ONS estimate, mid-2016) but over 500,000 are employed there, and some estimates put the number of workers in the city to be over 1 million. About three-quarters of the jobs in the City of London are in the financial, professional, and associated business services sectors. The legal profession forms a major component of the northern and western sides of the City, especially in the Temple and Chancery Lane areas where the Inns of Court are located, of which two—Inner Temple and Middle Temple—fall within the City of London boundary.

The Roman legions established a settlement known as "Londinium" on the current site of the City of London around AD 43. Its bridge over the River Thames turned the city into a road nexus and major port, serving as a major commercial centre in Roman Britain until its abandonment during the 5th century. Archaeologist Leslie Wallace notes that, because extensive archaeological excavation has not revealed any signs of a significant pre-Roman presence, "arguments for a purely Roman foundation of London are now common and uncontroversial."

At its height, the Roman city had a population of approximately 45,000–60,000 inhabitants. Londinium was an ethnically diverse city, with inhabitants from across the Roman Empire, including natives of Britannia, continental Europe, the Middle East, and North Africa. The Romans built the London Wall some time between AD 190 and 225. The boundaries of the Roman city were similar to those of the City of London today, though the City extends further west than Londonium's Ludgate, and the Thames was undredged and thus wider than it is today, with Londonium's shoreline slightly north of the City's present shoreline. The Romans built a bridge across the river, as early as AD 50, near to today's London Bridge.

By the time the London Wall was constructed, the City's fortunes were in decline, and it faced problems of plague and fire. The Roman Empire entered a long period of instability and decline, including the Carausian Revolt in Britain. In the 3rd and 4th centuries, the city was under attack from Picts, Scots, and Saxon raiders. The decline continued, both for Londinium and the Empire, and in AD 410 the Romans withdrew entirely from Britain. Many of the Roman public buildings in Londinium by this time had fallen into decay and disuse, and gradually after the formal withdrawal the city became almost (if not, at times, entirely) uninhabited. The centre of trade and population moved away from the walled Londinium to Lundenwic ("London market"), a settlement to the west, roughly in the modern-day Strand/Aldwych/Covent Garden area.

During the Anglo-Saxon Heptarchy, the London area came in turn under the Kingdoms of Essex, Mercia, and later Wessex, though from the mid 8th century it was frequently under the control or threat of the Vikings.
Bede records that in AD 604 St Augustine consecrated Mellitus as the first bishop to the Anglo-Saxon kingdom of the East Saxons and their king, Sæberht. Sæberht's uncle and overlord, Æthelberht, king of Kent, built a church dedicated to St Paul in London, as the seat of the new bishop. It is assumed, although unproven, that this first Anglo-Saxon cathedral stood on the same site as the later medieval and the present cathedrals.

Alfred the Great, King of Wessex (and arguably the first king of the "English") occupied and began the resettlement of the old Roman walled area, in 886, and appointed his son-in-law Earl Æthelred of Mercia over it as part of their reconquest of the Viking occupied parts of England. The refortified Anglo-Saxon settlement was known as Lundenburh ("London Fort", a borough). The historian Asser said that "Alfred, king of the Anglo-Saxons, restored the city of London splendidly ... and made it habitable once more." Alfred's "restoration" entailed reoccupying and refurbishing the nearly deserted Roman walled city, building quays along the Thames, and laying a new city street plan.

Alfred's taking of London and the rebuilding of the old Roman city was a turning point in history, not only as the permanent establishment of the City of London, but also as part of a unifying moment in early England, with Wessex becoming the dominant English kingdom and the repelling (to some degree) of the Viking occupation and raids. While London, and indeed England, were afterwards subjected to further periods of Viking and Danish raids and occupation, the establishment of the City of London and the Kingdom of England prevailed.

In the 10th century, Athelstan permitted eight mints to be established, compared with six in his capital, Winchester, indicating the wealth of the city. London Bridge, which had fallen into ruin following the Roman evacuation and abandonment of Londinium, was rebuilt by the Saxons, but was periodically destroyed by Viking raids and storms.

As the focus of trade and population was moved back to within the old Roman walls, the older Saxon settlement of Lundenwic was largely abandoned and gained the name of "Ealdwic" (the "old settlement"). The name survives today as Aldwych (the "old market-place"), a name of a street and an area of the City of Westminster between Westminster and the City of London.

Following the Battle of Hastings, William the Conqueror marched on London, reaching as far as Southwark, but failed to get across London Bridge or to defeat the Londoners. He eventually crossed the River Thames at Wallingford, pillaging the land as he went. Rather than continuing the war, Edgar the Ætheling, Edwin of Mercia and Morcar of Northumbria surrendered at Berkhamsted. William granted the citizens of London a charter in 1075; the City was one of a few examples of the English retaining some authority. The City was not covered by the Domesday Book.

William built three castles around the City, to keep Londoners subdued:


About 1130, Henry I granted a sheriff to the people of London, along with control of the county of Middlesex: this meant that the two entities were regarded as one administratively (not that the county was a dependency of the City) until the Local Government Act 1888. By 1141 the whole body of the citizenry was considered to constitute a single community. This 'commune' was the origin of the City of London Corporation and the citizens gained the right to appoint, with the king's consent, a mayor in 1189—and to directly elect the mayor from 1215.

From medieval times, the City has been composed of 25 ancient wards, each headed by an alderman, who chairs Wardmotes, which still take place at least annually. A Folkmoot, for the whole of the City held at the outdoor cross of St Paul's Cathedral, was formerly also held. Many of the medieval offices and traditions continue to the present day, demonstrating the unique nature of the City and its Corporation.

In 1381, the Peasants' Revolt affected London. The rebels took the City and the Tower of London, but the rebellion ended after its leader, Wat Tyler, was killed during a confrontation that included Lord Mayor William Walworth.

The City was burnt severely on a number of occasions, the worst being in 1123 and in the Great Fire of London in 1666. Both of these fires were referred to as "the" Great Fire. After the fire of 1666, a number of plans were drawn up to remodel the City and its street pattern into a renaissance-style city with planned urban blocks, squares and boulevards. These plans were almost entirely not taken up, and the medieval street pattern re-emerged almost intact.

In the 1630s the Crown sought to have the Corporation of the City of London extend its jurisdiction to surrounding areas. In what is sometimes called the "great refusal", the Corporation said no to the King, which in part accounts for its unique government structure to the present. 

By the late 16th century, London increasingly became a major centre for banking, international trade and commerce. The Royal Exchange was founded in 1565 by Sir Thomas Gresham as a centre of commerce for London's merchants, and gained Royal patronage in 1571. Although no longer used for its original purpose, its location at the corner of Cornhill and Threadneedle Street continues to be the geographical centre of the City's core of banking and financial services, with the Bank of England moving to its present site in 1734, opposite the Royal Exchange on Threadneedle Street. Immediately to the south of Cornhill, Lombard Street was the location from 1691 of Lloyd's Coffee House, which became the world-leading insurance market. London's insurance sector continues to be based in the area, particularly in Lime Street.

In 1708, Christopher Wren's masterpiece, St Paul's Cathedral, was completed on his birthday. The first service had been held on 2 December 1697, more than 10 years earlier. It replaced the original St Paul's, which had been completely destroyed in the Great Fire of London, and is considered to be one of the finest cathedrals in Britain and a fine example of Baroque architecture.

The 18th century was a period of rapid growth for London, reflecting an increasing national population, the early stirrings of the Industrial Revolution, and London's role at the centre of the evolving British Empire. The urban area expanded beyond the borders of the City of London, most notably during this period towards the West End and Westminster.

Expansion continued and became more rapid by the beginning of the 19th century, with London growing in all directions. To the East the Port of London grew rapidly during the century, with the construction of many docks, needed as the Thames at the City could not cope with the volume of trade. The arrival of the railways and the Tube meant that London could expand over a much greater area. By the mid-19th century, with London still rapidly expanding in population and area, the City had already become only a small part of the wider metropolis.

An attempt was made in 1894 with the Royal Commission on the Amalgamation of the City and County of London to end the distinction between the City and the surrounding County of London, but a change of government at Westminster meant the option was not taken up. The City as a distinct polity survived despite its position within the London conurbation and numerous local government reforms. Supporting this status, the City was a special parliamentary borough that elected four members to the unreformed House of Commons, who were retained after the Reform Act 1832; reduced to two under the Redistribution of Seats Act 1885; and ceased to be a separate constituency under the Representation of the People Act 1948. Since then the City is a minority (in terms of population and area) of the Cities of London and Westminster.
The City's population fell rapidly in the 19th century and through most of the 20th century, as people moved outwards in all directions to London's vast suburbs, and many residential buildings were demolished to make way for office blocks. Like many areas of London and other British cities, the City fell victim to large scale and highly destructive aerial bombing during World War II, especially in the Blitz. Whilst St Paul's Cathedral survived the onslaught, large swathes of the area did not and the particularly heavy raids of late December 1940 led to a firestorm called the Second Great Fire of London.

There was a major rebuilding programme in the decades following the war, in some parts (such as at the Barbican) dramatically altering the urban landscape. But the destruction of the older historic fabric allowed the construction of modern and larger-scale developments, whereas in those parts not so badly affected by bomb damage the City retains its older character of smaller buildings. The street pattern, which is still largely medieval, was altered slightly in places, although there is a more recent trend of reversing some of the post-war modernist changes made, such as at Paternoster Square.

The City suffered terrorist attacks including the 1993 Bishopsgate bombing (IRA) and the 7 July 2005 London bombings (Islamist). In response to the 1993 bombing, a system of road barriers, checkpoints and surveillance cameras referred to as the "ring of steel" has been maintained to control entry points to the City.

The 1970s saw the construction of tall office buildings including the 600-foot (183 m), 47-storey Natwest Tower, the first skyscraper in the UK. Office space development has intensified especially in the central, northern and eastern parts, with skyscrapers including 30 St. Mary Axe ("the Gherkin"'), Leadenhall Building ("the Cheesegrater"), 20 Fenchurch Street ("the Walkie-Talkie"), the Broadgate Tower and the Heron Tower, the tallest in the City. Another skyscraper, 22 Bishopsgate, is under construction.

The main residential section of the City today is the Barbican Estate, constructed between 1965 and 1976. The Museum of London is based there, as are a number of other services provided by the Corporation.

The City has a unique political status, a legacy of its uninterrupted integrity as a corporate city since the Anglo-Saxon period and its singular relationship with the Crown. Historically its system of government was not unusual, but it was not reformed by the Municipal Reform Act 1835 and little changed by later reforms, so that it is the only local government in the UK where elections are not run on the basis of one vote for every adult citizen.

It is administered by the City of London Corporation, headed by the Lord Mayor of London (not to be confused with the separate Mayor of London, an office created only in the year 2000), which is responsible for a number of functions and has interests in land beyond the City's boundaries. Unlike other English local authorities, the Corporation has two council bodies: the (now largely ceremonial) Court of Aldermen and the Court of Common Council. The Court of Aldermen represents the wards, with each ward (irrespective of size) returning one Alderman. The chief executive of the Corporation holds the ancient office of Town Clerk of London.

The City is a ceremonial county which has a Commission of Lieutenancy headed by the Lord Mayor instead of a Lord-Lieutenant and has two Sheriffs instead of a High Sheriff (see list of Sheriffs of London), quasi-judicial offices appointed by the Livery Companies, an ancient political system based on the representation and protection of trades (Guilds). Senior members of the Livery Companies are known as Liverymen and form the Common Hall, which chooses the Lord Mayor, the Sheriffs and certain other officers.

The City is made up of 25 wards. They are survivors of the medieval government system that allowed a very local area to exist as a self-governing unit within the wider city. They can be described as electoral/political divisions; ceremonial, geographic and administrative entities; sub-divisions of the City. Each ward has an Alderman, who until the mid-1960s held office for life but since put themselves up for re-election at least every 6 years. Wards continue to have a Beadle, an ancient position which is now largely ceremonial whose main remaining function is the running of an annual Wardmote of electors, representatives and officials. At the Wardmote the ward's Alderman appoints at least one Deputy for the year ahead. Each ward also has a Ward Club, which is similar to a residents' association.

The wards are ancient and their number has changed three times since time immemorial

Following boundary changes in 1994, and later reform of the business vote in the City, there was a major boundary and electoral representation revision of the wards in 2003, and they were reviewed again in 2010 for change in 2013, though not to such a dramatic extent. The review was conducted by senior officers of the Corporation and senior judges of the Old Bailey; the wards are reviewed by this process to avoid malapportionment. The procedure of review is unique in the United Kingdom as it is not conducted by the Electoral Commission or a local government boundary commission every 8 to 12 years, which is the case for all other wards in Great Britain. Particular churches, livery company halls and other historic buildings and structures are associated with a ward, such as St Paul's Cathedral with Castle Baynard, and London Bridge with Bridge; boundary changes in 2003 removed some of these historic connections.

Each ward elects an Alderman to the Court of Aldermen, and Commoners (the City equivalent of a Councillor) to the Court of Common Council of the Corporation. Only electors who are Freemen of the City of London are eligible to stand. The number of Commoners a ward sends to the Common Council varies from two to ten, depending on the number of electors in each ward. Since the 2003 review it has been agreed that the four more residential wards: Portsoken, Queenhithe, Aldersgate and Cripplegate together elect 20 of the 100 Commoners, whereas the business-dominated remainder elect the remaining 80 Commoners. 2003 and 2013 boundary changes have increased the residential emphasis of the mentioned four wards.

Census data provides eight nominal rather than 25 real wards, all of varying size and population. Being subject to renaming and definition at any time, these census 'wards' are notable in that four of the eight wards accounted for 67% of the 'square mile' and held 86% of the population, and these were in fact similar to and named after four City of London wards:

The City has a unique electoral system. Most of its voters are representatives of businesses and other bodies that occupy premises in the City. Its ancient wards have very unequal numbers of voters. In elections, both the businesses based in the City and the residents of the City vote.

The City of London Corporation was not reformed by the Municipal Corporations Act 1835, because it had a more extensive electoral franchise than any other borough or city; in fact, it widened this further with its own equivalent legislation allowing one to become a freeman without being a liveryman. In 1801, the City had a population of about 130,000, but increasing development of the City as a central business district led to this falling to below 5,000 after the Second World War. It has risen slightly to around 9,000 since, largely due to the development of the Barbican Estate. In 2009, the business vote was about 24,000, greatly exceeding residential voters. As the City of London Corporation has not been affected by other municipal legislation over the period of time since then, its electoral practice has become increasingly anomalous. Uniquely for city or borough elections, its elections remain independent-dominated.

The business or "non-residential vote" was abolished in other UK local council elections by the Representation of the People Act 1969, but was preserved in the City of London. The principal reason given by successive UK governments for retaining this mechanism for giving businesses representation, is that the City is "primarily a place for doing business". About 330,000 non-residents constitute the day-time population and use most of its services, far outnumbering residents, who number around 7,000 (2011). By contrast, opponents of the retention of the business vote argue that it is a cause of institutional inertia.

The City of London (Ward Elections) Act 2002, a private Act of Parliament, reformed the voting system and greatly increased the business franchise, allowing many more businesses to be represented. Under the new system, the number of non-resident voters has doubled from 16,000 to 32,000. Previously disenfranchised firms (and other organisations) are entitled to nominate voters, in addition to those already represented, and all such bodies are now required to choose their voters in a representative fashion. Bodies employing fewer than ten people may appoint one voter; those employing ten to 50 people one voter for every five employees; those employing more than 50 people ten voters and one additional voter for each 50 employees beyond the first 50. The Act also removed other anomalies which had been unchanged since the 1850s.

Inner Temple and Middle Temple (which neighbour each other) are two of the few remaining liberties, an old name for a geographic division. They are independent extra-parochial areas, historically not governed by the City of London Corporation (and are today regarded as local authorities for most purposes) and equally outside the ecclesiastical jurisdiction of the Bishop of London. They are within the boundaries and liberties of the City, but can be thought of as independent enclaves. They are both part of Farringdon Without.

Within the City, the Corporation owns and runs both Smithfield Market and Leadenhall Market. It owns land beyond its boundaries, including open spaces (parks, forests and commons) in and around Greater London, including most of Epping Forest and Hampstead Heath. The Corporation owns Old Spitalfields Market and Billingsgate Fish Market, in the neighbouring London Borough of Tower Hamlets. It owns and helps fund the Old Bailey, the Central Criminal Court for England and Wales, as a gift to the nation, having begun as the City and Middlesex Sessions. The Honourable The Irish Society, a body closely linked with the Corporation, also owns many public spaces in Northern Ireland.

The City has its own independent police force, the City of London Police—the Common Council (the main body of the Corporation) is the police authority. The Corporation also run the Hampstead Heath Constabulary, Epping Forest Keepers and the City of London market constabularies (whose members are no longer attested as constables but retain the historic title). The majority of Greater London is policed by the Metropolitan Police Service, based at New Scotland Yard.

The City has one hospital, St Bartholomew's Hospital, also known as 'Barts'. Founded in 1123, it is located at Smithfield, and is undergoing a long-awaited regeneration after doubts as to its continuing use during the 1990s.

The City is the third largest UK patron of the arts. It oversees the Barbican Centre and subsidises several important performing arts companies.

The London Port Health Authority, which is the responsibility of the Corporation, is responsible for all port health functions on the tidal part of the Thames, including various seaports and London City Airport. The Corporation oversees the running of the Bridge House Trust, which maintains London Bridge, Blackfriars Bridge, Southwark Bridge, Tower Bridge and the Millennium Bridge. The City's flag flies over Tower Bridge, although neither footing is in the City.

The size of the City was constrained by a defensive perimeter wall, known as London Wall, which was built by the Romans in the late 2nd century to protect their strategic port city. However the boundaries of the City of London no longer coincide with the old city wall, as the City expanded its jurisdiction slightly over time. During the medieval era, the City's jurisdiction expanded westwards, crossing the historic western border of the original settlement—the River Fleet—along Fleet Street to Temple Bar. The City also took in the other "City bars" which were situated just beyond the old walled area, such as at Holborn, Aldersgate, West Smithfield, Bishopsgate and Aldgate. These were the important entrances to the City and their control was vital in maintaining the City's special privileges over certain trades.
Most of the wall has disappeared, but several sections remain visible. A section near the Museum of London was revealed after the devastation of an air raid on 29 December 1940 at the height of the Blitz. Other visible sections are at St Alphage, and there are two sections near the Tower of London. The River Fleet was canalised after the Great Fire of 1666 and then in stages was bricked up and has been since the 18th century one of London's "lost rivers or streams", today underground as a storm drain.

The boundary of the City was unchanged until minor boundary changes on 1 April 1994, when it expanded slightly to the west, north and east, taking small parcels of land from the London Boroughs of Westminster, Camden, Islington, Hackney and Tower Hamlets. The main purpose of these changes was to tidy up the boundary where it had been rendered obsolete by changes in the urban landscape. In this process the City also lost small parcels of land, though there was an overall net gain (the City grew from 1.05 to 1.12 square miles). Most notably, the changes placed the (then recently developed) Broadgate estate entirely in the City.

Southwark, to the south of the City on the other side of the Thames, was within the City between 1550 and 1899 as the Ward of Bridge Without, a situation connected with the Guildable Manor. The City's administrative responsibility there had in practice disappeared by the mid-Victorian period as various aspects of metropolitan government were extended into the neighbouring areas. Today it is part of the London Borough of Southwark. The Tower of London has always been outside the City and comes under the London Borough of Tower Hamlets.

The Corporation of the City of London has a full achievement of armorial bearings consisting of a shield on which the arms are displayed, a crest displayed on a helm above the shield, supporters on either side and a motto displayed on a scroll beneath the arms.

The coat of arms is "anciently recorded" at the College of Arms. The arms consist of a silver shield bearing a red cross with a red upright sword in the first quarter. They combine the emblems of the patron saints of England and London: the Cross of St George with the symbol of the martyrdom of Saint Paul. The sword is often erroneously supposed to commemorate the killing of Peasants' Revolt leader Wat Tyler by Lord Mayor of London William Walworth. However the arms were in use some months before Tyler's death, and the tradition that Walworth's dagger is depicted may date from the late 17th century.

The Latin motto of the City is ""Domine dirige nos"", which translates as "Lord, direct us". It is thought to have been adopted in the 17th century, as the earliest record of it is in 1633.

A banner of the arms (the design on the shield) is flown as a flag.

The City is England's smallest ceremonial county by area and population, and the fourth most densely populated. Of the 326 English districts, it is the second smallest by population, after the Isles of Scilly, and the smallest by area. It is also the smallest English city by population (and in Britain, only two cities in Wales are smaller), and the smallest in the UK by area.

The elevation of the City ranges from sea level at the Thames to at the junction of High Holborn and Chancery Lane. Two small but notable hills are within the historic core, Ludgate Hill to the west and Cornhill to the east. Between them ran the Walbrook, one of the many "lost" rivers or streams of London (another is the Fleet).

Official boundary map, with wards.

Beginning in the west, where the City borders Westminster, the boundary crosses the Victoria Embankment from the Thames, passes to the west of Middle Temple, then turns for a short distance along Strand and then north up Chancery Lane, where it borders Camden. It turns east along Holborn to Holborn Circus, and then goes north east to Charterhouse Street. As it crosses Farringdon Road it becomes the boundary with Islington. It continues to Aldersgate, goes north, and turns east into some back streets soon after Aldersgate becomes Goswell Road, since 1994 embracing all of the Corporation's Golden Lane Estate. Here, at Baltic Street West, is the most northerly extent. The boundary includes all of the Barbican Estate and continues east along Ropemaker Street and its continuation on the other side of Moorgate, becomes South Place. It goes north, reaching the border with Hackney, then east, north, east on back streets, with Worship Street forming a northern boundary, so as to include the Broadgate estate. The boundary then turns south at Norton Folgate and becomes the border with Tower Hamlets. It continues south into Bishopsgate, and takes some backstreets to Middlesex Street (Petticoat Lane) where it continues south-east then south. It then turns south-west, crossing the Minories so as to exclude the Tower of London, and then reaches the river. It then runs up the centre of the Thames, with the exception that Blackfriars Bridge falls within the City; the City controls London Bridge (as part of Bridge ward) but only half of the river underneath it, a feature which is unique in British local administration.

The boundaries are marked by black bollards bearing the City's emblem, and by dragon boundary marks at major entrances, such as Holborn. A more substantial monument marks the boundary at Temple Bar on Fleet Street.

In some places the financial district extends slightly beyond the boundaries, notably to the north and east, into the London Boroughs of Tower Hamlets, Hackney and Islington, and informally these locations are seen as part of the "Square Mile". Since the 1990s the eastern fringe, extending into Hackney and Tower Hamlets, has increasingly been a focus for large office developments due to the availability of large sites compared to within the City.

The City has no sizeable parks within its boundary, but does have a network of a large number of gardens and small open spaces, many of them maintained by the Corporation. These range from formal gardens such as the one in Finsbury Circus, containing a bowling green and bandstand, to churchyards such as St Olave Hart Street, to water features and artwork in courtyards and pedestrianised lanes.

Gardens include:

There are a number of private gardens and open spaces, often within courtyards of the larger commercial developments. Two of the largest are those of the Inner Temple and Middle Temple Inns of Court, in the far southwest.

The Thames and its riverside walks are increasingly being valued as open space and in recent years efforts have been made to increase the ability for pedestrians to access and walk along the river.

The nearest weather station has historically been the London Weather Centre at Kingsway/ Holborn, although observations ceased in 2010. Now St. James Park provides the nearest official readings.

The City has an oceanic climate (Köppen "Cfb") modified by the Urban Heat Island in the centre of London. This generally causes higher night-time minima than outlying areas. For example, the August mean minimum of compares to a figure of for Greenwich and Heathrow whereas is at Wisley in the middle of several square miles of Metropolitan Green Belt. All figures refer to the observation period 1971–2000.

Accordingly, the weather station holds the record for the UK's warmest overnight minimum temperature, , recorded on 4 August 1990. The maximum is , set on 10 August 2003. The absolute minimum for the weather station is a mere , compared to readings around towards the edges of London. Unusually, this temperature was during a windy and snowy cold spell (mid-January 1987), rather than a cold clear night—cold air drainage is arrested due to the vast urban area surrounding the city.

The station holds the record for the highest British mean monthly temperature, (mean maximum , mean minimum during July 2006). However, in terms of daytime maximum temperatures, Cambridge NIAB and Botanical Gardens with a mean maximum of , and Heathrow with all exceeded this.

The City is a police area and has its own police force, the City of London Police, separate from the Metropolitan Police Service covering the majority of Greater London. The City Police have three police stations, at Snow Hill, Wood Street and Bishopsgate, and an administrative headquarters at Guildhall Yard East. The force comprises 735 police officers including 273 detectives. It is the smallest territorial police force in England and Wales, in both geographic area and the number of police officers.

Where the majority of British police forces have silver-coloured badges, those of the City of London Police are black and gold featuring the City crest. The force has rare red and white chequered cap bands and unique red and white striped duty arm bands on the sleeves of the tunics of constables and sergeants (red and white being the colours of the City), which in most other British police forces are black and white. City police sergeants and constables wear crested custodian helmets whilst on foot patrol. These helmets do not feature either St Edward's Crown or the Brunswick Star, which are used on most other police helmets in England and Wales.

The City's position as the United Kingdom's financial centre and a critical part of the country's economy, contributing about 2.5% of the UK's gross national product, has resulted in it becoming a target for political violence. The Provisional IRA exploded several bombs in the early 1990s, including the 1993 Bishopsgate bombing.

The area is also spoken of as a possible target for al-Qaeda. For instance, when in May 2004 the BBC's "Panorama" programme examined the preparedness of Britain's emergency services for a terrorist attack on the scale of the September 11, 2001 attacks, they simulated a chemical explosion on Bishopsgate in the east of the City. The "Ring of Steel" was established in the wake of the IRA bombings to guard against terrorist threats.

The City has fire risks in many historic buildings, including St Paul's Cathedral, Old Bailey, Mansion House, Smithfield Market, the Guildhall, and also in numerous high-rise buildings. There is one London Fire Brigade station in the City, at Dowgate, with one pumping appliance. The City relies upon stations in the surrounding London boroughs to support it at some incidents. The first fire engine is in attendance in roughly five minutes on average, the second when required in a little over five and a half minutes. There were 1,814 incidents attended in the City in 2006/2007—the lowest in Greater London. No-one died in an event arising from a fire in the four years prior to 2007.

There is power station located in Charterhouse Street that also provides heat to some of the surrounding buildings

The Office for National Statistics recorded the population in 2011 as 7,375; slightly higher than in the last census, 2001, and estimates the population as at mid-2016 to be 9,401. At the 2001 census the ethnic composition was 84.6% White, 6.8% South Asian, 2.6% Black, 2.3% Mixed, 2.0% Chinese and 1.7% were listed as "other". To the right is a table showing the change in population since 1801, based on decadal censuses. The first half of the 19th century shows a population of between 120,000–140,000, decreasing dramatically from 1851 to 1991, with a small increase between 1991 and 2001. The only notable boundary change since the first census in 1801 occurred in 1994.

The City's full-time working residents have much higher gross weekly pay than in London and Great Britain (England, Wales and Scotland): £773.30 compared to £598.60 and £491.00 respectively. There is a large inequality of income between genders (£1,085.90 in men compared to £653.50 in women), though this can be explained by job type and length of employment respectively. The 2001 Census showed the City as a unique district amongst 376 districts surveyed in England and Wales. The City had the highest proportional population increase, one-person households, people with qualifications at degree level or higher and the highest indications of overcrowding. It recorded the lowest proportion of households with cars or vans, people who travel to work by car, married couple households and the lowest average household size: just 1.58 people. It also ranked highest within the Greater London area for the percentage of people with no religion and people who are employed.

The City vies with New York City's Downtown Manhattan as the financial capital of the world; many banking and insurance institutions have their headquarters there. The London Stock Exchange (shares and bonds), Lloyd's of London (insurance) and the Bank of England are all based in the City. Over 500 banks have offices in the City, and the City is an established leader in trading in Eurobonds, foreign exchange, energy futures and global insurance. The Alternative Investment Market, a market for trades in equities of smaller firms, is a recent development. In 2009, the City of London accounted for 2.4% of UK GDP.

London is the world's greatest foreign exchange market, with much of the trade conducted in the City of London. Of the $3.98 trillion daily global turnover, as measured in 2009, trading in London accounted for around $1.85 trillion, or 46.7% of the total. The pound sterling, the currency of the United Kingdom, is globally the fourth most traded currency and the third most held reserve currency.

Since 1991 Canary Wharf, a few miles east of the City in Tower Hamlets, has become another centre for London's financial services industry which houses many banks and other institutions formerly located in the Square Mile. Although growth has continued in both locations, and there have been relocations in both directions, the Corporation has come to realise that its planning policies may have been causing financial firms to choose Canary Wharf as a location.

Many major global companies have their headquarters in the City, including Aviva, BT Group, Lloyds Banking Group, Old Mutual, Prudential, Schroders, Standard Chartered, and Unilever.

A number of the world's largest law firms are headquartered in the City, including four of the "Magic Circle" law firms (Allen & Overy, Freshfields Bruckhaus Deringer, Linklaters and Slaughter & May), as well as other firms such as DLA Piper, Eversheds Sutherland, Herbert Smith Freehills and Hogan Lovells.

Whilst the financial sector, and related businesses and institutions, continue to dominate, the economy is not limited to that sector. The legal profession has a strong presence, especially in the west and north (i.e., towards the Inns of Court). Retail businesses were once important, but have gradually moved to the West End of London, though it is now Corporation policy to encourage retailing in some locations, for example at Cheapside near St Paul's. The City has a number of visitor attractions, mainly based on its historic heritage as well as the Barbican Centre and adjacent Museum of London, though tourism is not at present a major contributor to the City's economy or character. The City has many pubs, bars and restaurants, and the "night-time" economy does feature in the Bishopsgate area, towards Shoreditch. The meat market at Smithfield, wholly within the City, continues to be one of London's main markets (the only one remaining in central London) and the country's largest meat market. In the east is Leadenhall Market, a fresh food market that is also a visitor attraction.

The trend for purely office development is beginning to reverse as the Corporation encourages residential use, albeit with development occurring when it arises on windfall sites. The City has a target of 90 additional dwellings per year. Some of the extra accommodation is in small pre-World War II listed buildings, which are not suitable for occupation by the large companies which now provide much of the City's employment. Recent residential developments include "the Heron", a high-rise residential building on the Milton Court site adjacent to the Barbican, and the Heron Plaza development on Bishopsgate is also expected to include residential parts.

Since the 1990s, the City has diversified away from near exclusive office use in other ways. For example, several hotels and the first department store opened in the 2000s. A shopping centre was more recently opened at One New Change, Cheapside (near St Paul's Cathedral) in October 2010, which is open seven days a week. However, large sections remain quiet at weekends, especially in the eastern section, and it is quite common to find shops, pubs and cafes closed on these days.

Fire bombing and post-World War II redevelopment have meant that the City, despite its history, has fewer intact historic structures than one might expect. Nonetheless, there remain many dozens of (mostly Victorian and Edwardian) fine buildings, typically in historicist and neoclassical style. They include the Monument to the Great Fire of London ("the Monument"), St Paul's Cathedral, the Guildhall, the Royal Exchange, Dr. Johnson's House, Mansion House and a , many designed by Sir Christopher Wren, who also designed St Paul's. 2 King's Bench Walk and Prince Henry's Room are notable historic survivors of heavy bombing of the Temple area, which has largely been rebuilt to its historic form. Another example of a bomb-damaged place having been restored is Staple Inn on Holborn. A few small sections of the Roman London Wall exist, for example near the Tower of London and in the Barbican area. Among the twentieth-century listed buildings are Bracken House, the first post World War II buildings in the country to be given statutory protection, and the whole of the Barbican and Golden Lane Estate.

The Tower of London is not in the City, but is a notable visitor attraction which brings tourists to the southeast of the City. Other landmark buildings with historical significance include the Bank of England, the Old Bailey, the Custom House, Smithfield Market, Leadenhall Market and St Bartholomew's Hospital. Noteworthy contemporary buildings include a number of modern high-rise buildings (see section below) as well as the Lloyd's building.


A growing number of tall buildings and skyscrapers are principally used by the financial sector. Almost all are situated in the eastern side around Bishopsgate, Leadenhall Street and Fenchurch Street, in the financial core of the City. In the north there is a smaller cluster comprising the Barbican Estate's three tall residential towers and the commercial CityPoint tower. In 2007, the tall Drapers' Gardens building was demolished and replaced by a shorter tower.

The City's buildings of more than in height are:

The timeline of the tallest building in the City is as follows:

The City is well served by the London Underground ("tube") and National Rail networks.

Seven London Underground lines serve the City:


Aldgate East ( ), Barbican ( ), Chancery Lane (), and Tower Hill ( ) tube stations are all situated within metres of the City of London boundary.

The Docklands Light Railway (DLR ) has two terminii in the City: Bank and Tower Gateway. The DLR links the City directly to the East End. Destinations include Canary Wharf business district and London City Airport ().

The Elizabeth line (Crossrail) will run east-west underneath the City of London once it opens. The line will serve two stations in the City - Farringdon and Liverpool Street - which will additionally serve the Barbican and Moorgate areas. Elizabeth line services will link the City directly to destinations such as Canary Wharf, Heathrow Airport (), and the M4 Corridor high-technology hub (serving Slough and Reading).

The City is served by a frequent Thameslink rail service which runs north-south through London. Thameslink services call at Farringdon, City Thameslink, and London Blackfriars. This provides the City with a direct link to key destinations across London, including Elephant & Castle, London Bridge, and St Pancras International (for the Eurostar to mainland Europe). There are also regular, direct trains from these stations to major destinations across East Anglia and the South East, including Bedford, Brighton, Cambridge, Gatwick Airport (), Luton Airport (), and Peterborough.

There are several "London Terminals" in the City:


All stations in the City are in London fare zone 1.

The national A1, A10 A3, A4, and A40 road routes begin in the City. The City is in the London congestion charge zone, with the small exception on the eastern boundary of the sections of the A1210/A1211 that are part of the Inner Ring Road. The following bridges, listed west to east (downstream), cross the River Thames: Blackfriars Bridge, Blackfriars Railway Bridge, Millennium Bridge (footbridge), Southwark Bridge, Cannon Street Railway Bridge and London Bridge; Tower Bridge is not in the City. The City, like most of central London, is well served by buses, including night buses. Two bus stations are in the City, at Aldgate on the eastern boundary with Tower Hamlets, and at Liverpool Street by the railway station.

Cycling infrastructure in the City is maintained by the City of London Corporation and Transport for London (TfL).


The Sandander Cycles and Beryl bike sharing systems operate in the City of London.

One London River Services pier is on the Thames in the City, Blackfriars Millennium Pier, though the Tower Millennium Pier lies adjacent to the boundary near the Tower of London. One of the Port of London's 25 safeguarded wharves, Walbrook Wharf, is adjacent to Cannon Street station, and is used by the Corporation to transfer waste via the river. Swan Lane Pier, just upstream of London Bridge, is proposed to be replaced and upgraded for regular passenger services, planned to take place in 2012–2015. Before then, Tower Pier is to be extended.

There is a public riverside walk along the river bank, opened in stages over recent years. The only section not running along the river is a short stretch at Queenhithe. The walk along Walbrook Wharf is closed to pedestrians when waste is being transferred onto barges.

According to a survey conducted in March 2011, the methods by which employed residents 16–74 get to work varied widely: 48.4% go on foot; 19.5% via light rail, (i.e. the Underground, DLR, etc.); 9.2% work mainly from home; 5.8% take the train; 5.6% travel by bus, minibus, or coach; and 5.3% go by bicycle; with just 3.4% commuting by car or van, as driver or passenger.

The City is home to a number of higher education institutions including: the Guildhall School of Music and Drama, the Cass Business School, The London Institute of Banking & Finance and parts of three of the universities in London: the Maughan Library of King's College London on Chancery Lane, the business school of London Metropolitan University, and a campus of the University of Chicago Booth School of Business. The College of Law has its London campus in Moorgate. Part of Barts and The London School of Medicine and Dentistry is on the Barts hospital site at West Smithfield.
The City has only one directly maintained primary school, Sir John Cass's Foundation Primary School at Aldgate (ages 4 to 11). It is a Voluntary-Aided (VA) Church of England school, maintained by the Education Service of the City of London.

City residents send their children to schools in neighbouring Local Education Authorities, such as Islington, Tower Hamlets, Westminster and Southwark.

The City controls three independent schools, City of London School (a boys' school) and City of London School for Girls in the City, and the City of London Freemen's School (co-educational day and boarding) in Ashtead, Surrey. The City of London School for Girls and City of London Freemen's School have their own preparatory departments for entrance at age seven. It is the principal sponsor of The City Academy, Hackney, City of London Academy Islington, and City of London Academy, Southwark.

Libraries operated by the Corporation include three lending libraries; Barbican Library, Shoe Lane Library and Artizan Street Library and Community Centre. Membership is open to all – with one official proof of address required to join.

Guildhall Library, and City Business Library are also public reference libraries, specialising in the history of London and business reference resources.

Author and journalist Nicholas Shaxson argued that, in return for the financial institutions based in the City raising loans and finance for the British government, the City "has extracted privileges and freedoms from rules and laws to which the rest of Britain must submit". He further claims that the assistance provided to the institutions based within it, many of which help their rich clients with offshore tax arrangements, mean that the City is "a tax haven in its own right".

The documentary "" asserts the tax haven status that the City provides.



</doc>
<doc id="6884" url="https://en.wikipedia.org/wiki?curid=6884" title="Clitoris">
Clitoris

The clitoris ( or ) is a female sex organ present in mammals, ostriches and a limited number of other animals. In humans, the visible portion – the glans – is at the front junction of the labia minora (inner lips), above the opening of the urethra. Unlike the penis, the male homologue (equivalent) to the clitoris, it usually does not contain the distal portion (or opening) of the urethra and is therefore not used for urination. The clitoris also usually lacks a reproductive function. While few animals urinate through the clitoris or use it reproductively, the spotted hyena, which has an especially large clitoris, urinates, mates, and gives birth via the organ. Some other mammals, such as lemurs and spider monkeys, also have a large clitoris.

The clitoris is the human female's most sensitive erogenous zone and generally the primary anatomical source of human female sexual pleasure. In humans and other mammals, it develops from an outgrowth in the embryo called the genital tubercle. Initially undifferentiated, the tubercle develops into either a penis or a clitoris during the development of the reproductive system depending on exposure to androgens (which are primarily male hormones). The clitoris is a complex structure, and its size and sensitivity can vary. The glans (head) of the human clitoris is roughly the size and shape of a pea, and is estimated to have about 8,000 sensory nerve endings.

Sexological, medical, and psychological debate have focused on the clitoris, and it has been subject to social constructionist analyses and studies. Such discussions range from anatomical accuracy, gender inequality, female genital mutilation, and orgasmic factors and their physiological explanation for the G-spot. Although, in humans, the only known purpose of the clitoris is to provide sexual pleasure, whether the clitoris is vestigial, an adaptation, or serves a reproductive function has been debated. Social perceptions of the clitoris include the significance of its role in female sexual pleasure, assumptions about its true size and depth, and varying beliefs regarding genital modification such as clitoris enlargement, clitoris piercing and clitoridectomy. Genital modification may be for aesthetic, medical or cultural reasons.

Knowledge of the clitoris is significantly impacted by cultural perceptions of the organ. Studies suggest that knowledge of its existence and anatomy is scant in comparison with that of other sexual organs, and that more education about it could help alleviate social stigmas associated with the female body and female sexual pleasure; for example, that the clitoris and vulva in general are visually unappealing, that female masturbation is taboo, or that men should be expected to master and control women's orgasms.
The "Oxford English Dictionary" states that the word "clitoris" likely has its origin in the Ancient Greek , , perhaps derived from the verb , , "to shut". "Clitoris" is also Greek for the word "key", "indicating that the ancient anatomists considered it the key" to female sexuality. In addition to "key," the "Online Etymology Dictionary" suggests other Greek candidates for the word's etymology include a noun meaning "latch" or "hook"; a verb meaning "to touch or titillate lasciviously", "to tickle" (one German synonym for the clitoris is "der Kitzler", "the tickler"), although this verb is more likely derived from "clitoris"; and a word meaning "side of a hill", from the same root as "climax". The "Oxford English Dictionary" also states that the shortened form "clit", the first occurrence of which was noted in the United States, has been used in print since 1958: until then, the common abbreviation was "clitty".

The plural forms are "clitorises" in English and "clitorides" in Latin. The Latin genitive is "clitoridis", as in "glans clitoridis". In medical and sexological literature, the clitoris is sometimes referred to as "the female penis" or pseudo-penis, and the term "clitoris" is commonly used to refer to the glans alone; partially because of this, there have been various terms for the organ that have historically confused its anatomy.

In mammals, sexual differentiation is determined by the sperm that carries either an X or a Y (male) chromosome. The Y chromosome contains a sex-determining gene (SRY) that encodes a transcription factor for the protein TDF (testis determining factor) and triggers the creation of testosterone and Anti-Müllerian hormone for the embryo's development into a male. This differentiation begins about eight or nine weeks after conception. Some sources state that it continues until the twelfth week, while others state that it is clearly evident by the thirteenth week and that the sex organs are fully developed by the sixteenth week.

The clitoris develops from a phallic outgrowth in the embryo called the genital tubercle. Initially undifferentiated, the tubercle develops into either a clitoris or penis during the development of the reproductive system depending on exposure to androgens (which are primarily male hormones). The clitoris forms from the same tissues that become the glans and shaft of the penis, and this shared embryonic origin makes these two organs homologous (different versions of the same structure).

If exposed to testosterone, the genital tubercle elongates to form the penis. By fusion of the urogenital folds – elongated spindle-shaped structures that contribute to the formation of the urethral groove on the belly aspect of the genital tubercle – the urogenital sinus closes completely and forms the spongy urethra, and the labioscrotal swellings unite to form the scrotum. In the absence of testosterone, the genital tubercle allows for formation of the clitoris; the initially rapid growth of the phallus gradually slows and the clitoris is formed. The urogenital sinus persists as the vestibule of the vagina, the two urogenital folds form the labia minora, and the labioscrotal swellings enlarge to form the labia majora, completing the female genitalia. A rare condition that can develop from higher than average androgen exposure is clitoromegaly.

The clitoris contains external and internal components. It consists of the glans, the body (which is composed of two erectile structures known as the corpora cavernosa), and two crura ("legs"). It has a hood formed by the labia minora (inner lips). It also has vestibular or clitoral bulbs. The frenulum of clitoris is a frenulum on the under-surface of the glans and is created by the two medial parts of the labia minora. The clitoral body may be referred to as the shaft (or internal shaft), while the length of the clitoris between the glans and the body may also be referred to as the shaft. The shaft supports the glans, and its shape can be seen and felt through the clitoral hood.

Research indicates that clitoral tissue extends into the vagina's anterior wall. Şenaylı et al. said that the histological evaluation of the clitoris, "especially of the corpora cavernosa, is incomplete because for many years the clitoris was considered a rudimentary and nonfunctional organ." They added that Baskin and colleagues examined the clitoris's masculinization after dissection and, using imaging software after Masson chrome staining, put the serial dissected specimens together; this revealed that the nerves of the clitoris surround the whole clitoral body (corpus).

The clitoris, vestibular bulbs, labia minora, and urethra involve two histologically distinct types of vascular tissue (tissue related to blood vessels), the first of which is trabeculated, erectile tissue innervated by the cavernous nerves. The trabeculated tissue has a spongy appearance; along with blood, it fills the large, dilated vascular spaces of the clitoris and the bulbs. Beneath the epithelium of the vascular areas is smooth muscle. As indicated by Yang et al.'s research, it may also be that the urethral lumen (the inner open space or cavity of the urethra), which is surrounded by spongy tissue, has tissue that "is grossly distinct from the vascular tissue of the clitoris and bulbs, and on macroscopic observation, is paler than the dark tissue" of the clitoris and bulbs. The second type of vascular tissue is non-erectile, which may consist of blood vessels that are dispersed within a fibrous matrix and have only a minimal amount of smooth muscle.

Highly innervated, the glans exists at the tip of the clitoral body as a fibro-vascular cap, and is usually the size and shape of a pea, although it is sometimes much larger or smaller. The clitoral glans, or the entire clitoris, is estimated to have about 8,000 sensory nerve endings. Research conflicts on whether or not the glans is composed of erectile or non-erectile tissue. Although the clitoral body becomes engorged with blood upon sexual arousal, erecting the clitoral glans, some sources describe the clitoral glans and labia minora as composed of non-erectile tissue; this is especially the case for the glans. They state that the clitoral glans and labia minora have blood vessels that are dispersed within a fibrous matrix and have only a minimal amount of smooth muscle, or that the clitoral glans is "a midline, densely neural, non-erectile structure".

Other descriptions of the glans assert that it is composed of erectile tissue and that erectile tissue is present within the labia minora. The glans may be noted as having glandular vascular spaces that are not as prominent as those in the clitoral body, with the spaces being separated more by smooth muscle than in the body and crura. Adipose tissue is absent in the labia minora, but the organ may be described as being made up of dense connective tissue, erectile tissue and elastic fibers.
The clitoral body forms a wishbone-shaped structure containing the corpora cavernosa – a pair of sponge-like regions of erectile tissue which contain most of the blood in the clitoris during clitoral erection. The two corpora forming the clitoral body are surrounded by thick fibro-elastic tunica albuginea, literally meaning "white covering", connective tissue. These corpora are separated incompletely from each other in the midline by a fibrous pectiniform septum – a comblike band of connective tissue extending between the corpora cavernosa.

The clitoral body extends up to several centimeters before reversing direction and branching, resulting in an inverted "V" shape that extends as a pair of crura ("legs"). The crura are the proximal portions of the arms of the wishbone. Ending at the glans of the clitoris, the tip of the body bends anteriorly away from the pubis. Each crus (singular form of crura) is attached to the corresponding ischial ramus – extensions of the copora beneath the descending pubic rami. Concealed behind the labia minora, the crura end with attachment at or just below the middle of the pubic arch. Associated are the urethral sponge, perineal sponge, a network of nerves and blood vessels, the suspensory ligament of the clitoris, muscles and the pelvic floor.

There is no identified correlation between the size of the clitoral glans, or clitoris as a whole, and a woman's age, height, weight, use of hormonal contraception, or being post-menopausal, although women who have given birth may have significantly larger clitoral measurements. Centimeter (cm) and millimeter (mm) measurements of the clitoris show variations in its size. The clitoral glans has been cited as typically varying from 2 mm to 1 cm and usually being estimated at 4 to 5 mm in both the transverse and longitudinal planes.

A 1992 study concluded that the total clitoral length, including glans and body, is , where 16 mm is the mean and 4.3 mm is the standard deviation. Concerning other studies, researchers from the Elizabeth Garrett Anderson and Obstetric Hospital in London measured the labia and other genital structures of 50 women from the age of 18 to 50, with a mean age of 35.6., from 2003 to 2004, and the results given for the clitoral glans were 3–10 mm for the range and 5.5 [1.7] mm for the mean. Other research indicates that the clitoral body can measure in length, while the clitoral body and crura together can be or more in length.

The clitoral hood projects at the front of the labia commissure, where the edges of the labia majora (outer lips) meet at the base of the pubic mound; it is partially formed by fusion of the upper part of the external folds of the labia minora (inner lips) and covers the glans and external shaft. There is considerable variation in how much of the glans protrudes from the hood and how much is covered by it, ranging from completely covered to fully exposed, and tissue of the labia minora also encircles the base of the glans.

The vestibular bulbs are more closely related to the clitoris than the vestibule because of the similarity of the trabecular and erectile tissue within the clitoris and bulbs, and the absence of trabecular tissue in other genital organs, with the erectile tissue's trabecular nature allowing engorgement and expansion during sexual arousal. The vestibular bulbs are typically described as lying close to the crura on either side of the vaginal opening; internally, they are beneath the labia majora. When engorged with blood, they cuff the vaginal opening and cause the vulva to expand outward. Although a number of texts state that they surround the vaginal opening, Ginger et al. state that this does not appear to be the case and tunica albuginea does not envelop the erectile tissue of the bulbs. In Yang et al.'s assessment of the bulbs' anatomy, they conclude that the bulbs "arch over the distal urethra, outlining what might be appropriately called the 'bulbar urethra' in women."

The clitoris and penis are generally the same anatomical structure, although the distal portion (or opening) of the urethra is absent in the clitoris of humans and most other animals. The idea that males have clitorises was suggested in 1987 by researcher Josephine Lowndes Sevely, who theorized that the male corpora cavernosa (a pair of sponge-like regions of erectile tissue which contain most of the blood in the penis during penile erection) are the true counterpart of the clitoris. She argued that "the male clitoris" is directly beneath the rim of the glans penis, where the frenulum of prepuce of the penis (a fold of the prepuce) is located, and proposed that this area be called the "Lownde's crown." Her theory and proposal, though acknowledged in anatomical literature, did not materialize in anatomy books. Modern anatomical texts show that the clitoris displays a hood that is the equivalent of the penis's foreskin, which covers the glans. It also has a shaft that is attached to the glans. The male corpora cavernosa are homologous to the corpus cavernosum clitoridis (the female cavernosa), the bulb of penis is homologous to the vestibular bulbs beneath the labia minora, the scrotum is homologous to the labia majora, and the penile urethra and part of the skin of the penis is homologous to the labia minora.

Upon anatomical study, the penis can be described as a clitoris that has been mostly pulled out of the body and grafted on top of a significantly smaller piece of spongiosum containing the urethra. With regard to nerve endings, the human clitoris's estimated 8,000 or more (for its glans or clitoral body as a whole) is commonly cited as being twice as many as the nerve endings found in the human penis (for its glans or body as a whole), and as more than any other part of the human body. These reports sometimes conflict with other sources on clitoral anatomy or those concerning the nerve endings in the human penis. For example, while some sources estimate that the human penis has 4,000 nerve endings, other sources state that the glans or the entire penile structure have the same amount of nerve endings as the clitoral glans, or discuss whether the uncircumcised penis has thousands more than the circumcised penis or is generally more sensitive.

Some sources state that in contrast to the glans penis, the clitoral glans lacks smooth muscle within its fibrovascular cap and is thus differentiated from the erectile tissues of the clitoris and bulbs; additionally, bulb size varies and may be dependent on age and estrogenization. While the bulbs are considered the equivalent of the male spongiosum, they do not completely encircle the urethra.

The thin corpus spongiosum of the penis runs along the underside of the penile shaft, enveloping the urethra, and expands at the end to form the glans. It partially contributes to erection, which are primarily caused by the two corpora cavernosa that comprise the bulk of the shaft; like the female cavernosa, the male cavernosa soak up blood and become erect when sexually excited. The male corpora cavernosa taper off internally on reaching the spongiosum head. With regard to the Y-shape of the cavernosa – crown, body, and legs – the body accounts for much more of the structure in men, and the legs are stubbier; typically, the cavernosa are longer and thicker in males than in females.

The clitoris has an abundance of nerve endings, and is the human female's most sensitive erogenous zone and generally the primary anatomical source of human female sexual pleasure. When sexually stimulated, it may incite female sexual arousal. Sexual stimulation, including arousal, may result from mental stimulation, foreplay with a sexual partner, or masturbation, and may lead to orgasm. The most effective sexual stimulation of the organ is usually manually or orally (cunnilingus), which is often referred to as direct clitoral stimulation; in cases involving sexual penetration, these activities may also be referred to as additional or assisted clitoral stimulation.

Direct clitoral stimulation involves physical stimulation to the external anatomy of the clitoris – glans, hood and the external shaft. Stimulation of the labia minora (inner lips), due to its external connection with the glans and hood, may have the same effect as direct clitoral stimulation. Though these areas may also receive indirect physical stimulation during sexual activity, such as when in friction with the labia majora (outer lips), indirect clitoral stimulation is more commonly attributed to penile-vaginal penetration. Penile-anal penetration may also indirectly stimulate the clitoris by the shared sensory nerves (especially the pudendal nerve, which gives off the inferior anal nerves and divides into two terminal branches: the perineal nerve and the dorsal nerve of the clitoris).

Due to the glans's high sensitivity, direct stimulation to it is not always pleasurable; instead, direct stimulation to the hood or the areas near the glans are often more pleasurable, with the majority of women preferring to use the hood to stimulate the glans, or to have the glans rolled between the lips of the labia, for indirect touch. It is also common for women to enjoy the shaft of the clitoris being softly caressed in concert with occasional circling of the clitoral glans. This might be with or without manual penetration of the vagina, while other women enjoy having the entire area of the vulva caressed. As opposed to use of dry fingers, stimulation from fingers that have been well-lubricated, either by vaginal lubrication or a personal lubricant, is usually more pleasurable for the external anatomy of the clitoris.

As the clitoris's external location does not allow for direct stimulation by sexual penetration, any external clitoral stimulation while in the missionary position usually results from the pubic bone area, the movement of the groins when in contact. As such, some couples may engage in the woman-on-top position or the coital alignment technique, a sex position combining the "riding high" variation of the missionary position with pressure-counterpressure movements performed by each partner in rhythm with sexual penetration, to maximize clitoral stimulation. Lesbian couples may engage in tribadism for ample clitoral stimulation or for mutual clitoral stimulation during whole-body contact. Pressing the penis in a gliding or circular motion against the clitoris (intercrural sex), or stimulating it by movement against another body part, may also be practiced. A vibrator (such as a clitoral vibrator), dildo or other sex toy may be used. Other women stimulate the clitoris by use of a pillow or other inanimate object, by a jet of water from the faucet of a bathtub or shower, or by closing their legs and rocking.

During sexual arousal, the clitoris and the whole of the genitalia engorge and change color as the erectile tissues fill with blood (vasocongestion), and the individual experiences vaginal contractions. The ischiocavernosus and bulbocavernosus muscles, which insert into the corpora cavernosa, contract and compress the dorsal vein of the clitoris (the only vein that drains the blood from the spaces in the corpora cavernosa) and the arterial blood continues a steady flow and, having no way to drain out, fills the venous spaces until they become turgid and engorged with blood. This is what leads to clitoral erection.

The clitoral glans doubles in diameter upon arousal, and, upon further stimulation, becomes less visible as it is covered by the swelling of tissues of the clitoral hood. The swelling protects the glans from direct contact, as direct contact at this stage can be more irritating than pleasurable. Vasocongestion eventually triggers a muscular reflex, which expels the blood that was trapped in surrounding tissues, and leads to an orgasm. A short time after stimulation has stopped, especially if orgasm has been achieved, the glans becomes visible again and returns to its normal state, with a few seconds (usually 5–10) to return to its normal position and 5–10 minutes to return to its original size. If orgasm is not achieved, the clitoris may remain engorged for a few hours, which women often find uncomfortable. Additionally, the clitoris is very sensitive after orgasm, making further stimulation initially painful for some women.

General statistics indicate that 70–80 percent of women require direct clitoral stimulation (consistent manual, oral or other concentrated friction against the external parts of the clitoris) to reach orgasm. Indirect clitoral stimulation (for example, via vaginal penetration) may also be sufficient for female orgasm. The area near the entrance of the vagina (the lower third) contains nearly 90 percent of the vaginal nerve endings, and there are areas in the anterior vaginal wall and between the top junction of the labia minora and the urethra that are especially sensitive, but intense sexual pleasure, including orgasm, solely from vaginal stimulation is occasional or otherwise absent because the vagina has significantly fewer nerve endings than the clitoris.

Prominent debate over the quantity of vaginal nerve endings began with Alfred Kinsey. Although Sigmund Freud's theory that clitoral orgasms are a prepubertal or adolescent phenomenon and that vaginal (or G-spot) orgasms are something that only physically mature females experience had been criticized before, Kinsey was the first researcher to harshly criticize the theory. Through his observations of female masturbation and interviews with thousands of women, Kinsey found that most of the women he observed and surveyed could not have vaginal orgasms, a finding that was also supported by his knowledge of sex organ anatomy. Scholar Janice M. Irvine stated that he "criticized Freud and other theorists for projecting male constructs of sexuality onto women" and "viewed the clitoris as the main center of sexual response". He considered the vagina to be "relatively unimportant" for sexual satisfaction, relaying that "few women inserted fingers or objects into their vaginas when they masturbated". Believing that vaginal orgasms are "a physiological impossibility" because the vagina has insufficient nerve endings for sexual pleasure or climax, he "concluded that satisfaction from penile penetration [is] mainly psychological or perhaps the result of referred sensation".

Masters and Johnson's research, as well as Shere Hite's, generally supported Kinsey's findings about the female orgasm. Masters and Johnson were the first researchers to determine that the clitoral structures surround and extend along and within the labia. They observed that both clitoral and vaginal orgasms have the same stages of physical response, and found that the majority of their subjects could only achieve clitoral orgasms, while a minority achieved vaginal orgasms. On that basis, they argued that clitoral stimulation is the source of both kinds of orgasms, reasoning that the clitoris is stimulated during penetration by friction against its hood. The research came at the time of the second-wave feminist movement, which inspired feminists to reject the distinction made between clitoral and vaginal orgasms. Feminist Anne Koedt argued that because men "have orgasms essentially by friction with the vagina" and not the clitoral area, this is why women's biology had not been properly analyzed. "Today, with extensive knowledge of anatomy, with [C. Lombard Kelly], Kinsey, and Masters and Johnson, to mention just a few sources, there is no ignorance on the subject [of the female orgasm]," she stated in her 1970 article "The Myth of the Vaginal Orgasm." She added, "There are, however, social reasons why this knowledge has not been popularized. We are living in a male society which has not sought change in women's role."

Supporting an anatomical relationship between the clitoris and vagina is a study published in 2005, which investigated the size of the clitoris; Australian urologist Helen O'Connell, described as having initiated discourse among mainstream medical professionals to refocus on and redefine the clitoris, noted a direct relationship between the legs or roots of the clitoris and the erectile tissue of the clitoral bulbs and corpora, and the distal urethra and vagina while using magnetic resonance imaging (MRI) technology. While some studies, using ultrasound, have found physiological evidence of the G-spot in women who report having orgasms during vaginal intercourse, O'Connell argues that this interconnected relationship is the physiological explanation for the conjectured G-Spot and experience of vaginal orgasms, taking into account the stimulation of the internal parts of the clitoris during vaginal penetration. "The vaginal wall is, in fact, the clitoris," she said. "If you lift the skin off the vagina on the side walls, you get the bulbs of the clitoris – triangular, crescental masses of erectile tissue." O'Connell et al., having performed dissections on the female genitals of cadavers and used photography to map the structure of nerves in the clitoris, made the assertion in 1998 that there is more erectile tissue associated with the clitoris than is generally described in anatomical textbooks, and were thus already aware that the clitoris is more than just its glans. They concluded that some females have more extensive clitoral tissues and nerves than others, especially having observed this in young cadavers compared to elderly ones, and therefore whereas the majority of females can only achieve orgasm by direct stimulation of the external parts of the clitoris, the stimulation of the more generalized tissues of the clitoris via vaginal intercourse may be sufficient for others.

French researchers Odile Buisson and Pierre Foldès reported similar findings to that of O'Connell's. In 2008, they published the first complete 3D sonography of the stimulated clitoris, and republished it in 2009 with new research, demonstrating the ways in which erectile tissue of the clitoris engorges and surrounds the vagina. On the basis of their findings, they argued that women may be able to achieve vaginal orgasm via stimulation of the G-spot, because the highly innervated clitoris is pulled closely to the anterior wall of the vagina when the woman is sexually aroused and during vaginal penetration. They assert that since the front wall of the vagina is inextricably linked with the internal parts of the clitoris, stimulating the vagina without activating the clitoris may be next to impossible. In their 2009 published study, the "coronal planes during perineal contraction and finger penetration demonstrated a close relationship between the root of the clitoris and the anterior vaginal wall". Buisson and Foldès suggested "that the special sensitivity of the lower anterior vaginal wall could be explained by pressure and movement of clitoris's root during a vaginal penetration and subsequent perineal contraction".

Researcher Vincenzo Puppo, who, while agreeing that the clitoris is the center of female sexual pleasure and believing that there is no anatomical evidence of the vaginal orgasm, disagrees with O'Connell and other researchers' terminological and anatomical descriptions of the clitoris (such as referring to the vestibular bulbs as the "clitoral bulbs") and states that "the inner clitoris" does not exist because the penis cannot come in contact with the congregation of multiple nerves/veins situated until the angle of the clitoris, detailed by Kobelt, or with the roots of the clitoris, which do not have sensory receptors or erogenous sensitivity, during vaginal intercourse. Puppo's belief contrasts the general belief among researchers that vaginal orgasms are the result of clitoral stimulation; they reaffirm that clitoral tissue extends, or is at least stimulated by its bulbs, even in the area most commonly reported to be the G-spot.

The G-spot being analogous to the base of the male penis has additionally been theorized, with sentiment from researcher Amichai Kilchevsky that because female fetal development is the "default" state in the absence of substantial exposure to male hormones and therefore the penis is essentially a clitoris enlarged by such hormones, there is no evolutionary reason why females would have an entity in addition to the clitoris that can produce orgasms. The general difficulty of achieving orgasms vaginally, which is a predicament that is likely due to nature easing the process of child bearing by drastically reducing the number of vaginal nerve endings, challenge arguments that vaginal orgasms help encourage sexual intercourse in order to facilitate reproduction. Supporting a distinct G-spot, however, is a study by Rutgers University, published in 2011, which was the first to map the female genitals onto the sensory portion of the brain; the scans indicated that the brain registered distinct feelings between stimulating the clitoris, the cervix and the vaginal wall – where the G-spot is reported to be – when several women stimulated themselves in a functional magnetic resonance (fMRI) machine. Barry Komisaruk, head of the research findings, stated that he feels that "the bulk of the evidence shows that the G-spot is not a particular thing" and that it is "a region, it's a convergence of many different structures".

Whether the clitoris is vestigial, an adaptation, or serves a reproductive function has also been debated. Geoffrey Miller stated that Helen Fisher, Meredith Small and Sarah Blaffer Hrdy "have viewed the clitoral orgasm as a legitimate adaptation in its own right, with major implications for female sexual behavior and sexual evolution". Like Lynn Margulis and Natalie Angier, Miller believes, "The human clitoris shows no apparent signs of having evolved directly through male mate choice. It is not especially large, brightly colored, specifically shaped or selectively displayed during courtship." He contrasts this with other female species such as spider monkeys and spotted hyenas that have clitorises as long as their male counterparts. He said the human clitoris "could have evolved to be much more conspicuous if males had preferred sexual partners with larger brighter clitorises" and that "its inconspicuous design combined with its exquisite sensitivity suggests that the clitoris is important not as an object of male mate choice, but as a mechanism of female choice."

While Miller stated that male scientists such as Stephen Jay Gould and Donald Symons "have viewed the female clitoral orgasm as an evolutionary side-effect of the male capacity for penile orgasm" and that they "suggested that clitoral orgasm cannot be an adaptation because it is too hard to achieve", Gould acknowledged that "most female orgasms emanate from a clitoral, rather than vaginal (or some other), site" and that his nonadaptive belief "has been widely misunderstood as a denial of either the adaptive value of female orgasm in general, or even as a claim that female orgasms lack significance in some broader sense". He said that although he accepts that "clitoral orgasm plays a pleasurable and central role in female sexuality and its joys," "[a]ll these favorable attributes, however, emerge just as clearly and just as easily, whether the clitoral site of orgasm arose as a spandrel or an adaptation". He added that the "male biologists who fretted over [the adaptionist questions] simply assumed that a deeply vaginal site, nearer the region of fertilization, would offer greater selective benefit" due to their Darwinian, "summum bonum" beliefs about enhanced reproductive success.

Similar to Gould's beliefs about adaptionist views and that "females grow nipples as adaptations for suckling, and males grow smaller unused nipples as a spandrel based upon the value of single development channels", Elisabeth Lloyd suggested that there is little evidence to support an adaptionist account of female orgasm. Meredith L. Chivers stated that "Lloyd views female orgasm as an ontogenetic leftover; women have orgasms because the urogenital neurophysiology for orgasm is so strongly selected for in males that this developmental blueprint gets expressed in females without affecting fitness" and this is similar to "males hav[ing] nipples that serve no fitness-related function."

At the 2002 conference for Canadian Society of Women in Philosophy, Nancy Tuana argued that the clitoris is unnecessary in reproduction; she stated that it has been ignored because of "a fear of pleasure. It is pleasure separated from reproduction. That's the fear." She reasoned that this fear causes ignorance, which veils female sexuality. O'Connell stated, "It boils down to rivalry between the sexes: the idea that one sex is sexual and the other reproductive. The truth is that both are sexual and both are reproductive." She reiterated that the vestibular bulbs appear to be part of the clitoris and that the distal urethra and vagina are intimately related structures, although they are not erectile in character, forming a tissue cluster with the clitoris that appears to be the location of female sexual function and orgasm.

Modifications to the clitoris can be intentional or unintentional. They include female genital mutilation (FGM), sex reassignment surgery (for trans men as part transitioning, which may also include clitoris enlargement), intersex surgery, and genital piercings. Use of anabolic steroids by bodybuilders and other athletes can result in significant enlargement of the clitoris in concert with other masculinizing effects on their bodies. Abnormal enlargement of the clitoris may also be referred to as "clitoromegaly", but clitoromegaly is more commonly seen as a congenital anomaly of the genitalia.

Those taking hormones or other medications as part of a transgender transition usually experience dramatic clitoral growth; individual desires and the difficulties of phalloplasty (construction of a penis) often result in the retention of the original genitalia with the enlarged clitoris as a penis analogue (metoidioplasty). However, the clitoris cannot reach the size of the penis through hormones. A surgery to add function to the clitoris, such as metoidioplasty, is an alternative to phalloplasty that permits retention of sexual sensation in the clitoris.

In clitoridectomy, the clitoris may be removed as part of a radical vulvectomy to treat cancer such as vulvar intraepithelial neoplasia; however, modern treatments favor more conservative approaches, as invasive surgery can have psychosexual consequences. Clitoridectomy more often involves parts of the clitoris being partially or completely removed during FGM, which may be additionally known as female circumcision or female genital cutting (FGC). Removing the glans of the clitoris does not mean that the whole structure is lost, since the clitoris reaches deep into the genitals.

In reduction clitoroplasty, a common intersex surgery, the glans is preserved and parts of the erectile bodies are excised. Problems with this technique include loss of sensation, sexual function, and sloughing of the glans. One way to preserve the clitoris with its innervations and function is to imbricate and bury the clitoral glans; however, Şenaylı et al. state that "pain during stimulus because of trapped tissue under the scarring is nearly routine. In another method, 50 percent of the ventral clitoris is removed through the level base of the clitoral shaft, and it is reported that good sensation and clitoral function are observed in follow up"; additionally, it has "been reported that the complications are from the same as those in the older procedures for this method".

With regard to females who have the condition congenital adrenal hyperplasia, the largest group requiring surgical genital correction, researcher Atilla Şenaylı stated, "The main expectations for the operations are to create a normal female anatomy, with minimal complications and improvement of life quality." Şenaylı added that "[c]osmesis, structural integrity, and coital capacity of the vagina, and absence of pain during sexual activity are the parameters to be judged by the surgeon." (Cosmesis usually refers to the surgical correction of a disfiguring defect.) He stated that although "expectations can be standardized within these few parameters, operative techniques have not yet become homogeneous. Investigators have preferred different operations for different ages of patients".

Gender assessment and surgical treatment are the two main steps in intersex operations. "The first treatments for clitoromegaly were simply resection of the clitoris. Later, it was understood that the clitoris glans and sensory input are important to facilitate orgasm," stated Atilla. The clitoral glans's epithelium "has high cutaneous sensitivity, which is important in sexual responses" and it is because of this that "recession clitoroplasty was later devised as an alternative, but reduction clitoroplasty is the method currently performed."

What is often referred to as "clit piercing" is the more common (and significantly less complicated) clitoral hood piercing. Since clitoral piercing is difficult and very painful, piercing of the clitoral hood is more common than piercing the clitoral shaft, owing to the small percentage of people who are anatomically suited for it. Clitoral hood piercings are usually channeled in the form of vertical piercings, and, to a lesser extent, horizontal piercings. The triangle piercing is a very deep horizontal hood piercing, and is done behind the clitoris as opposed to in front of it. For styles such as the Isabella, which pass through the clitoral shaft but are placed deep at the base, they provide unique stimulation and still require the proper genital build; the Isabella starts between the clitoral glans and the urethra, exiting at the top of the clitoral hood; this piercing is highly risky with regard to damage that may occur because of intersecting nerves.

Persistent genital arousal disorder (PGAD) results in a spontaneous, persistent, and uncontrollable genital arousal in women, unrelated to any feelings of sexual desire. Clitoral priapism, also known as clitorism, is a rare, potentially painful medical condition and is sometimes described as an aspect of PGAD. With PGAD, arousal lasts for an unusually extended period of time (ranging from hours to days); it can also be associated with morphometric and vascular modifications of the clitoris.

Drugs may cause or affect clitoral priapism. The drug trazodone is known to cause male priapism as a side effect, but there is only one documented report that it may have caused clitoral priapism, in which case discontinuing the medication may be a remedy. Additionally, nefazodone is documented to have caused clitoral engorgement, as distinct from clitoral priapism, in one case, and clitoral priapism can sometimes start as a result of, or only after, the discontinuation of antipsychotics or selective serotonin reuptake inhibitors (SSRIs).

Because PGAD is relatively rare and, as its own concept apart from clitoral priapism, has only been researched since 2001, there is little research into what may cure or remedy the disorder. In some recorded cases, PGAD was caused by, or caused, a pelvic arterial-venous malformation with arterial branches to the clitoris; surgical treatment was effective in these cases.

With regard to historical and modern perceptions of the clitoris, the clitoris and the penis were considered equivalent by scholars for more than 2,500 years in all respects except their arrangement. Due to it being frequently omitted from, or misrepresented, in historical and contemporary anatomical texts, it was also subject to a continual cycle of male scholars claiming to have discovered it. The ancient Greeks, ancient Romans, and Greek and Roman generations up to and throughout the Renaissance, were aware that male and female sex organs are anatomically similar, but prominent anatomists such as Galen (129 – c. 200 AD) and Vesalius (1514–1564) regarded the vagina as the structural equivalent of the penis, except for being inverted; Vesalius argued against the existence of the clitoris in normal women, and his anatomical model described how the penis corresponds with the vagina, without a role for the clitoris.

Ancient Greek and Roman sexuality additionally designated penetration as "male-defined" sexuality. The term "tribas", or "tribade", was used to refer to a woman or intersex individual who actively penetrated another person (male or female) through use of the clitoris or a dildo. As any sexual act was believed to require that one of the partners be "phallic" and that therefore sexual activity between women was impossible without this feature, mythology popularly associated lesbians with either having enlarged clitorises or as incapable of enjoying sexual activity without the substitution of a phallus.
In 1545, Charles Estienne was the first writer to identify the clitoris in a work based on dissection, but he concluded that it had a urinary function. Following this study, Realdo Colombo (also known as Matteo Renaldo Colombo), a lecturer in surgery at the University of Padua, Italy, published a book called "De re anatomica" in 1559, in which he describes the "seat of woman's delight". In his role as researcher, Colombo concluded, "Since no one has discerned these projections and their workings, if it is permissible to give names to things discovered by me, it should be called the love or sweetness of Venus.", in reference to the mythological Venus, goddess of erotic love. Colombo's claim was disputed by his successor at Padua, Gabriele Falloppio (discoverer of the fallopian tube), who claimed that he was the first to discover the clitoris. In 1561, Falloppio stated, "Modern anatomists have entirely neglected it ... and do not say a word about it ... and if others have spoken of it, know that they have taken it from me or my students." This caused an upset in the European medical community, and, having read Colombo's and Falloppio's detailed descriptions of the clitoris, Vesalius stated, "It is unreasonable to blame others for incompetence on the basis of some sport of nature you have observed in some women and you can hardly ascribe this new and useless part, as if it were an organ, to healthy women." He concluded, "I think that such a structure appears in hermaphrodites who otherwise have well formed genitals, as Paul of Aegina describes, but I have never once seen in any woman a penis (which Avicenna called albaratha and the Greeks called an enlarged nympha and classed as an illness) or even the rudiments of a tiny phallus."

The average anatomist had difficulty challenging Galen's or Vesalius's research; Galen was the most famous physician of the Greek era and his works were considered the standard of medical understanding up to and throughout the Renaissance (i.e. for almost two thousand years), and various terms being used to describe the clitoris seemed to have further confused the issue of its structure. In addition to Avicenna's naming it the "albaratha" or "virga" ("rod") and Colombo's calling it sweetness of Venus, Hippocrates used the term "columella" ("little pillar'"), and Albucasis, an Arabic medical authority, named it "tentigo" ("tension"). The names indicated that each description of the structures was about the body and glans of the clitoris, but usually the glans. It was additionally known to the Romans, who named it (vulgar slang) "landica". However, Albertus Magnus, one of the most prolific writers of the Middle Ages, felt that it was important to highlight "homologies between male and female structures and function" by adding "a psychology of sexual arousal" that Aristotle had not used to detail the clitoris. While in Constantine's treatise "Liber de coitu", the clitoris is referred to a few times, Magnus gave an equal amount of attention to male and female organs.

Like Avicenna, Magnus also used the word "virga" for the clitoris, but employed it for the male and female genitals; despite his efforts to give equal ground to the clitoris, the cycle of suppression and rediscovery of the organ continued, and a 16th-century justification for clitoridectomy appears to have been confused by hermaphroditism and the imprecision created by the word "nymphae" substituted for the word "clitoris". Nymphotomia was a medical operation to excise an unusually large clitoris, but what was considered "unusually large" was often a matter of perception. The procedure was routinely performed on Egyptian women, due to physicians such as Jacques Daléchamps who believed that this version of the clitoris was "an unusual feature that occurred in almost all Egyptian women [and] some of ours, so that when they find themselves in the company of other women, or their clothes rub them while they walk or their husbands wish to approach them, it erects like a male penis and indeed they use it to play with other women, as their husbands would do ... Thus the parts are cut".

Caspar Bartholin, a 17th-century Danish anatomist, dismissed Colombo's and Falloppio's claims that they discovered the clitoris, arguing that the clitoris had been widely known to medical science since the second century. Although 17th-century midwives recommended to men and women that women should aspire to achieve orgasms to help them get pregnant for general health and well-being and to keep their relationships healthy, debate about the importance of the clitoris persisted, notably in the work of Regnier de Graaf in the 17th century and Georg Ludwig Kobelt in the 19th.

Like Falloppio and Bartholin, De Graaf criticized Colombo's claim of having discovered the clitoris; his work appears to have provided the first comprehensive account of clitoral anatomy. "We are extremely surprised that some anatomists make no more mention of this part than if it did not exist at all in the universe of nature," he stated. "In every cadaver we have so far dissected we have found it quite perceptible to sight and touch." De Graaf stressed the need to distinguish "nympha" from "clitoris", choosing to "always give [the clitoris] the name clitoris" to avoid confusion; this resulted in frequent use of the correct name for the organ among anatomists, but considering that "nympha" was also varied in its use and eventually became the term specific to the labia minora, more confusion ensued. Debate about whether orgasm was even necessary for women began in the Victorian era, and Freud's 1905 theory about the immaturity of clitoral orgasms (see above) negatively affected women's sexuality throughout most of the 20th century.

Toward the end of World War I, a maverick British MP named Noel Pemberton Billing published an article entitled "The Cult of the Clitoris", furthering his conspiracy theories and attacking the actress Maud Allan and Margot Asquith, wife of the prime minister. The accusations led to a sensational libel trial, which Billing eventually won; Philip Hoare reports that Billing argued that "as a medical term, 'clitoris' would only be known to the 'initiated', and was incapable of corrupting moral minds". Jodie Medd argues in regard to "The Cult of the Clitoris" that "the female nonreproductive but desiring body [...] simultaneously demands and refuses interpretative attention, inciting scandal through its very resistance to representation."

From the 18th – 20th century, especially during the 20th, details of the clitoris from various genital diagrams presented in earlier centuries were omitted from later texts. The full extent of the clitoris was alluded to by Masters and Johnson in 1966, but in such a muddled fashion that the significance of their description became obscured; in 1981, the Federation of Feminist Women's Health Clinics (FFWHC) continued this process with anatomically precise illustrations identifying 18 structures of the clitoris. Despite the FFWHC's illustrations, Josephine Lowndes Sevely, in 1987, described the vagina as more of the counterpart of the penis.

Concerning other beliefs about the clitoris, Hite (1976 and 1981) found that, during sexual intimacy with a partner, clitoral stimulation was more often described by women as foreplay than as a primary method of sexual activity, including orgasm. Further, although the FFWHC's work significantly propelled feminist reformation of anatomical texts, it did not have a general impact. Helen O'Connell's late 1990s research motivated the medical community to start changing the way the clitoris is anatomically defined. O'Connell describes typical textbook descriptions of the clitoris as lacking detail and including inaccuracies, such as older and modern anatomical descriptions of the female human urethral and genital anatomy having been based on dissections performed on elderly cadavers whose erectile (clitoral) tissue had shrunk. She instead credits the work of Georg Ludwig Kobelt as the most comprehensive and accurate description of clitoral anatomy. MRI measurements, which provide a live and multi-planar method of examination, now complement the FFWHC's, as well as O'Connell's, research efforts concerning the clitoris, showing that the volume of clitoral erectile tissue is ten times that which is shown in doctors' offices and in anatomy text books.

In Bruce Bagemihl's survey of "The Zoological Record" (1978–1997) – which contains over a million documents from over 6,000 scientific journals – 539 articles focusing on the penis were found, while 7 were found focusing on the clitoris. In 2000, researchers Shirley Ogletree and Harvey Ginsberg concluded that there is a general neglect of the word "clitoris" in common vernacular. They looked at the terms used to describe genitalia in the PsycINFO database from 1887 to 2000 and found that "penis" was used in 1,482 sources, "vagina" in 409, while "clitoris" was only mentioned in 83. They additionally analyzed 57 books listed in a computer database for sex instruction. In the majority of the books, "penis" was the most commonly discussed body part – mentioned more than "clitoris", "vagina", and "uterus" put together. They last investigated terminology used by college students, ranging from Euro-American (76%/76%), Hispanic (18%/14%), and African American (4%/7%), regarding the students' beliefs about sexuality and knowledge on the subject. The students were overwhelmingly educated to believe that the vagina is the female counterpart of the penis. The authors found that the students' belief that the inner portion of the vagina is the most sexually sensitive part of the female body correlated with negative attitudes toward masturbation and strong support for sexual myths.

A 2005 study reported that, among a sample of undergraduate students, the most frequently cited sources for knowledge about the clitoris were school and friends, and that this was associated with the least amount of tested knowledge. Knowledge of the clitoris by self-exploration was the least cited, but "respondents correctly answered, on average, three of the five clitoral knowledge measures". The authors stated that "[k]nowledge correlated significantly with the frequency of women's orgasm in masturbation but not partnered sex" and that their "results are discussed in light of gender inequality and a social construction of sexuality, endorsed by both men and women, that privileges men's sexual pleasure over women's, such that orgasm for women is pleasing, but ultimately incidental." They concluded that part of the solution to remedying "this problem" requires that males and females are taught more about the clitoris than is currently practiced.

In May 2013, humanitarian group Clitoraid launched the first annual International Clitoris Awareness Week, from May 6 to May 12. Clitoraid spokesperson Nadine Gary stated that the group's mission is to raise public awareness about the clitoris because it has "been ignored, vilified, made taboo, and considered sinful and shameful for centuries".

In 2016, Odile Fillod created a 3D printable, open source, full-size model of the clitoris, for use in a set of anti-sexist videos she had been commissioned to produce. Fillod was interviewed by Stephanie Theobald, whose article in "The Guardian" stated that the 3D model would be used for sex education in French schools, from primary to secondary level, from September 2016 onwards; this was not the case, but the story went viral across the world.

In a 2019 study, a questionnaire was administered to a sample of educational sciences postgraduate students to trace the level of their knowledge concerning the organs of the female and male reproductive system. The authors reported that about two-thirds of the students failed to name external female genitals, such as the clitoris and labia, even after detailed pictures were provided to them.

In 2012, New York artist Sophia Wallace started work on a multimedia project to challenge misconceptions about the clitoris. Based on O'Connell's 1998 research, Wallace's work emphasizes the sheer scope and size of the human clitoris. She says that ignorance of this still seems to be pervasive in modern society. "It is a curious dilemma to observe the paradox that on the one hand the female body is the primary metaphor for sexuality, its use saturates advertising, art and the mainstream erotic imaginary," she said. "Yet, the clitoris, the true female sexual organ, is virtually invisible." The project is called "Cliteracy" and it includes a "clit rodeo", which is an interactive, climb-on model of a giant golden clitoris, including its inner parts, produced with the help of sculptor Kenneth Thomas. "It's been a showstopper wherever it's been shown. People are hungry to be able to talk about this," Wallace said. "I love seeing men standing up for the clit [...] Cliteracy is about not having one's body controlled or legislated [...] Not having access to the pleasure that is your birthright is a deeply political act."

In 2016, another project started in New York, street art that has since spread to almost 100 cities: Clitorosity, a "community-driven effort to celebrate the full structure of the clitoris", combining chalk drawings and words to spark interaction and conversation with passers-by, which the team documents on social media.

Other projects listed by the BBC include Clito Clito, body-positive jewellery made in Berlin; "Clitorissima", a documentary intended to normalize mother-daughter conversations about the clitoris; and a ClitArt festival in London, encompassing spoken word performances as well as visual art. French art collective Les Infemmes (a pun on "infamous" and "women") published a fanzine whose title can be translated as "The Clit Cheatsheet".

Significant controversy surrounds female genital mutilation (FGM), with the World Health Organization (WHO) being one of many health organizations that have campaigned against the procedures on behalf of human rights, stating that "FGM has no health benefits" and that it is "a violation of the human rights of girls and women" and "reflects deep-rooted inequality between the sexes". The practice has existed at one point or another in almost all human civilizations, most commonly to exert control over the sexual behavior, including masturbation, of girls and women, but also to change the clitoris's appearance. Custom and tradition are the most frequently cited reasons for FGM, with some cultures believing that not performing it has the possibility of disrupting the cohesiveness of their social and political systems, such as FGM also being a part of a girl's initiation into adulthood. Often, a girl is not considered an adult in a FGM-practicing society unless she has undergone FGM, and the "removal of the clitoris and labia – viewed by some as the "male parts" of a woman's body – is thought to enhance the girl's femininity, often synonymous with docility and obedience".

Female genital mutilation is carried out in several societies, especially in Africa, with 85 percent of genital mutilations performed in Africa consisting of clitoridectomy or excision, and to a lesser extent in other parts of the Middle East and Southeast Asia, on girls from a few days old to mid-adolescent, often to reduce sexual desire in an effort to preserve vaginal virginity. The practice of FGM has spread globally, as immigrants from Asia, Africa, and the Middle East bring the custom with them. In the United States, it is sometimes practiced on girls born with a clitoris that is larger than usual. Comfort Momoh, who specializes in the topic of FGM, states that FGM might have been "practiced in ancient Egypt as a sign of distinction among the aristocracy"; there are reports that traces of infibulation are on Egyptian mummies. FGM is still routinely practiced in Egypt. Greenberg et al. report that "one study found that 97% of married women in Egypt had had some form of genital mutilation performed." Amnesty International estimated in 1997 that more than two million FGM procedures are performed every year.

Although the clitoris exists in all mammal species, few detailed studies of the anatomy of the clitoris in non-humans exist. The clitoris is especially developed in fossas, apes, lemurs, moles, and, like the penis in many non-human placental mammals, often contains a small bone. In females, this bone is known as the os clitoridis. The clitoris exists in turtles, ostriches, crocodiles, and in species of birds in which the male counterpart has a penis. Some intersex female bears mate and give birth through the tip of the clitoris; these species are grizzly bears, brown bears, American black bears and polar bears. Although the bears have been described as having "a birth canal that runs through the clitoris rather than forming a separate vagina" (a feature that is estimated to make up 10 to 20 percent of the bears' population), scientists state that female spotted hyenas are the only non-hermaphroditic female mammals devoid of an external vaginal opening, and whose sexual anatomy is distinct from usual intersex cases.

In spider monkeys, the clitoris is especially developed and has an interior passage, or urethra, that makes it almost identical to the penis, and it retains and distributes urine droplets as the female spider monkey moves around. Scholar Alan F. Dixson stated that this urine "is voided at the bases of the clitoris, flows down the shallow groove on its perineal surface, and is held by the skin folds on each side of the groove". Because spider monkeys of South America have pendulous and erectile clitorises long enough to be mistaken for a penis, researchers and observers of the species look for a scrotum to determine the animal's sex; a similar approach is to identify scent-marking glands that may also be present on the clitoris.

The clitoris erects in squirrel monkeys during dominance displays, which indirectly influences the squirrel monkeys' reproductive success.

The clitoris of bonobos is larger and more externalized than in most mammals; Natalie Angier said that a young adolescent "female bonobo is maybe half the weight of a human teenager, but her clitoris is three times bigger than the human equivalent, and visible enough to waggle unmistakably as she walks". Female bonobos often engage in the practice of genital-genital (GG) rubbing, which is the non-human form of tribadism that human females engage in. Ethologist Jonathan Balcombe stated that female bonobos rub their clitorises together rapidly for ten to twenty seconds, and this behavior, "which may be repeated in rapid succession, is usually accompanied by grinding, shrieking, and clitoral engorgement"; he added that, on average, they engage in this practice "about once every two hours", and as bonobos sometimes mate face-to-face, "evolutionary biologist Marlene Zuk has suggested that the position of the clitoris in bonobos and some other primates has evolved to maximize stimulation during sexual intercourse".

Many strepsirrhine species exhibit elongated clitorises that are either fully or partially tunneled by the urethra, including mouse lemurs, dwarf lemurs, all "Eulemur" species, lorises and galagos.  Some of these species also exhibit a membrane seal across the vagina that closes the vaginal opening during the non-mating seasons, most notably mouse and dwarf lemurs. The clitoral morphology of the ring-tailed lemur is the most well-studied. They are described as having "elongated, pendulous clitorises that are [fully] tunneled by a urethra". The urethra is surrounded by erectile tissue, which allows for significant swelling during breeding seasons, but this erectile tissue differs from the typical male corpus spongiosum. Non-pregnant adult ring-tailed females do not show higher testosterone levels than males, but they do exhibit higher A and estrogen levels during seasonal aggression. During pregnancy, estrogen, A, and testosterone levels are raised, but female fetuses are still "protected" from excess testosterone. These "masculinized" genitalia are often found alongside other traits, such as female-dominated social groups, reduced sexual dimorphism that makes females the same size as males, and even ratios of sexes in adult populations. This phenomenon that has been dubbed the "lemur syndrome". A 2014 study of "Eulemur" masculinization proposed that behavioral and morphological masculinization in female lemuriformes is an ancestral trait that likely emerged after their split from lorisiformes.

While female spotted hyenas are sometimes referred to as hermaphrodites or as intersex, and scientists of ancient and later historical times believed that they were hermaphrodites, modern scientists do not refer to them as such. That designation is typically reserved for those who simultaneously exhibit features of both sexes; the genetic makeup of female spotted hyenas "are clearly distinct" from male spotted hyenas.

Female spotted hyenas have a clitoris 90 percent as long and the same diameter as a male penis (171 millimeters long and 22 millimeters in diameter), and this pseudo-penis's formation seems largely androgen-independent because it appears in the female fetus before differentiation of the fetal ovary and adrenal gland. The spotted hyenas have a highly erectile clitoris, complete with a false scrotum; author John C. Wingfield stated that "the resemblance to male genitalia is so close that sex can be determined with confidence only by palpation of the scrotum". The pseudo-penis can also be distinguished from the males' genitalia by its greater thickness and more rounded glans. The female possesses no external vagina, as the labia are fused to form a pseudo-scrotum. In the females, this scrotum consists of soft adipose tissue. Like male spotted hyenas with regard to their penises, the female spotted hyenas have small penile spines on the head of their clitorises, which scholar Catherine Blackledge said makes "the clitoris tip feel like soft sandpaper". She added that the clitoris "extends away from the body in a sleek and slender arc, measuring, on average, over 17 cm from root to tip. Just like a penis, [it] is fully erectile, raising its head in hyena greeting ceremonies, social displays, games of rough and tumble or when sniffing out peers".

Due to their higher levels of androgen exposure during fetal development, the female hyenas are significantly more muscular and aggressive than their male counterparts; social-wise, they are of higher rank than the males, being dominant or dominant and alpha, and the females who have been exposed to higher levels of androgen than average become higher-ranking than their female peers. Subordinate females lick the clitorises of higher-ranked females as a sign of submission and obedience, but females also lick each other's clitorises as a greeting or to strengthen social bonds; in contrast, while all males lick the clitorises of dominant females, the females will not lick the penises of males because males are considered to be of lowest rank.

The urethra and vagina of the female spotted hyena exit through the clitoris, allowing the females to urinate, copulate and give birth through this organ. This trait makes mating more laborious for the male than in other mammals, and also makes attempts to sexually coerce (physically force sexual activity on) females futile. Joan Roughgarden, an ecologist and evolutionary biologist, said that because the hyena's clitoris is higher on the belly than the vagina in most mammals, the male hyena "must slide his rear under the female when mating so that his penis lines up with [her clitoris]". In an action similar to pushing up a shirtsleeve, the "female retracts the [pseudo-penis] on itself, and creates an opening into which the male inserts his own penis". The male must practice this act, which can take a couple of months to successfully perform. Female spotted hyenas exposed to larger doses of androgen have significantly damaged ovaries, making it difficult to conceive. After giving birth, the pseudo-penis is stretched and loses much of its original aspects; it becomes a slack-walled and reduced prepuce with an enlarged orifice with split lips. Approximately 15% of the females die during their first time giving birth, and over 60% of their species' firstborn young die.

A 2006 Baskin et al. study concluded, "The basic anatomical structures of the corporeal bodies in both sexes of humans and spotted hyenas were similar. As in humans, the dorsal nerve distribution was unique in being devoid of nerves at the 12 o'clock position in the penis and clitoris of the spotted hyena" and that "[d]orsal nerves of the penis/clitoris in humans and male spotted hyenas tracked along both sides of the corporeal body to the corpus spongiosum at the 5 and 7 o'clock positions. The dorsal nerves penetrated the corporeal body and distally the glans in the hyena" and, in female hyenas, "the dorsal nerves fanned out laterally on the clitoral body. Glans morphology was different in appearance in both sexes, being wide and blunt in the female and tapered in the male".

Many species of Talpid moles exhibit peniform clitorises that are tunneled by the urethra and are found to have erectile tissue, most notably species from the "Talpa" genus found in Europe. Unique to this clade are the presence of ovotestes, wherein the female ovary also is mostly made up of sterile testicular tissue that secretes testosterone with only a small portion of the gonad containing ovarian tissue. Genetic studies have revealed that females have an XX genotype and do not have any translocated Y-linked genes. Detailed developmental studies of "Talpa occidentalis" have revealed that the female gonads develop in a "testis-like pattern". DMRT1, a gene that regulates development of Sertoli cells, was found to be expressed in female germ cells before meiosis, however no Sertoli cells were present in the fully-developed ovotestes. Additionally, the female germ cells only enter meiosis postnatally, a phenomenon that has not been found in any other eutherian mammal.  Phylogenetic analyses have suggested that, like in lemuroids, this trait must have evolved in a common ancestor of the clade, and has been "turned off and on" in different Talpid lineages.

Female European moles are highly territorial and will not allow males in to their territory outside of breeding season, the probable cause of this behavior being the high levels of testosterone secreted by the female ovotestes. During the non-breeding season, their vaginal opening is covered by skin, akin to the condition seen in mouse and dwarf lemurs.

Researchers studying the peripheral and central afferent pathways from the feline clitoris concluded that "afferent neurons projecting to the clitoris of the cat were identified by WGA-HRP tracing in the S1 and S2 dorsal root ganglia. An average of 433 cells were identified on each side of the animal. 85 percent and 15 percent of the labeled cells were located in the S1 and S2 dorsal root ganglia, respectively. The average cross sectional area of clitoral afferent neuron profiles was 1.479±627 μm2." They also stated that light "constant pressure on the clitoris produced an initial burst of single unit firing (maximum frequencies 170–255 Hz) followed by rapid adaptation and a sustained firing (maximum 40 Hz), which was maintained during the stimulation" and that further examination of tonic firing "indicate that the clitoris is innervated by mechano-sensitive myelinated afferent fibers in the pudental nerve which project centrally to the region of the dorsal commissure in the L7-S1 spinal cord".

The external phenotype and reproductive behavior of 21 freemartin sheep and two male pseudohermaphrodite sheep were recorded with the aim of identifying any characteristics that could predict a failure to breed. The vagina's length and the size and shape of the vulva and clitoris were among the aspects analyzed. While the study reported that "a number of physical and behavioural abnormalities were detected," it also concluded that "the only consistent finding in all 23 animals was a short vagina which varied in length from 3.1 to 7.0 cm, compared with 10 to 14 cm in normal animals."

In a study concerning the clitoral structure of mice, the mouse perineal urethra was documented as being surrounded by erectile tissue forming the bulbs of the clitoris. The researchers stated, "In the mouse, as in human females, tissue organization in the corpora cavernosa of the clitoris is essentially similar to that of the penis except for the absence of a subalbugineal layer interposed between the tunica albuginea and the erectile tissue."






</doc>
<doc id="6886" url="https://en.wikipedia.org/wiki?curid=6886" title="Chicago">
Chicago

Chicago (, ), officially the City of Chicago, is the most populous city in the U.S. state of Illinois, and the third-most-populous city in the United States. With an estimated population of 2,693,976 in 2019, it is also the most populous city in the Midwestern United States. Chicago is the county seat of Cook County, the second-most-populous county in the US, with a small portion of the northwest side of the city extending into DuPage County near O'Hare Airport. Chicago is the principal city of the Chicago metropolitan area, often referred to as Chicagoland. At nearly 10 million people, the metropolitan area is the third most populous in the United States.

Located on the shores of freshwater Lake Michigan, Chicago was incorporated as a city in 1837 near a portage between the Great Lakes and the Mississippi River watershed and grew rapidly in the mid-19th century. After the Great Chicago Fire of 1871, which destroyed several square miles and left more than 100,000 homeless, the city made a concerted effort to rebuild. The construction boom accelerated population growth throughout the following decades, and by 1900, less than 30 years after the great fire, Chicago was the fifth-largest city in the world. Chicago made noted contributions to urban planning and zoning standards, including new construction styles (including the Chicago School of architecture), the development of the City Beautiful Movement, and the steel-framed skyscraper.

Chicago is an international hub for finance, culture, commerce, industry, education, technology, telecommunications, and transportation. It is the site of the creation of the first standardized futures contracts, issued by the Chicago Board of Trade, which today is part of the largest and most diverse derivatives market in the world, generating 20% of all volume in commodities and financial futures alone. Depending on the particular year, the city's O'Hare International Airport is routinely ranked as the world's fifth or sixth busiest airport according to tracked data by the Airports Council International. The region also has the largest number of federal highways and is the nation's railroad hub. The Chicago area has one of the highest gross domestic products (GDP) in the world, generating $689 billion in 2018. In addition, the city has one of the world's most diversified and balanced economies, with no single industry employing more than 14% of the workforce. Chicago is home to several "Fortune" 500 companies, including Allstate, Boeing, Caterpillar, Exelon, Kraft Heinz, McDonald's, Mondelez International, Sears, United Airlines Holdings, US Foods, and Walgreens.

Chicago's 58 million domestic and international visitors in 2018 made it the second most visited city in the nation, as compared with New York City's 65 million visitors in 2018. The city was ranked first in the 2018 "Time Out" City Life Index, a global quality of life survey of 15,000 people in 32 cities. Landmarks in the city include Millennium Park, Navy Pier, the Magnificent Mile, the Art Institute of Chicago, Museum Campus, the Willis (Sears) Tower, Grant Park, the Museum of Science and Industry, and Lincoln Park Zoo. Chicago's culture includes the visual arts, literature, film, theatre, comedy (especially improvisational comedy), food, and music, particularly jazz, blues, soul, hip-hop, gospel, and electronic dance music including house music. Of the area's many colleges and universities, the University of Chicago, Northwestern University, and the University of Illinois at Chicago are classified as "highest research" doctoral universities. Chicago has professional sports teams in each of the major professional leagues, including two Major League Baseball teams.

The name "Chicago" is derived from a French rendering of the indigenous Miami-Illinois word "shikaakwa" for a wild relative of the onion; it is known to botanists as "Allium tricoccum" and known more commonly as "ramps". The first known reference to the site of the current city of Chicago as ""Checagou"" was by Robert de LaSalle around 1679 in a memoir. Henri Joutel, in his journal of 1688, noted that the eponymous wild "garlic" grew abundantly in the area. According to his diary of late September 1687:
The city has had several nicknames throughout its history, such as the Windy City, Chi-Town, Second City, and City of the Big Shoulders.

In the mid-18th century, the area was inhabited by the Potawatomi, a Native American tribe who had succeeded the Miami and Sauk and Fox peoples in this region.

The first known non-indigenous permanent settler in Chicago was explorer Jean Baptiste Point du Sable. Du Sable was of African and French descent and arrived in the 1780s. He is commonly known as the "Founder of Chicago".

In 1795, following the victory of the new United States in the Northwest Indian War, an area that was to be part of Chicago was turned over to the US for a military post by native tribes in accordance with the Treaty of Greenville. In 1803, the United States Army built Fort Dearborn. This was destroyed in 1812 in the Battle of Fort Dearborn by the British and their native allies. It was later rebuilt.

After the War of 1812, the Ottawa, Ojibwe, and Potawatomi tribes ceded additional land to the United States in the 1816 Treaty of St. Louis. The Potawatomi were forcibly removed from their land after the Treaty of Chicago in 1833 and sent west of the Mississippi River during Indian Removal.

On August 12, 1833, the Town of Chicago was organized with a population of about 200. Within seven years it grew to more than 6,000 people. On June 15, 1835, the first public land sales began with Edmund Dick Taylor as Receiver of Public Monies. The City of Chicago was incorporated on Saturday, March 4, 1837, and for several decades was the world's fastest-growing city.

As the site of the Chicago Portage, the city became an important transportation hub between the eastern and western United States. Chicago's first railway, Galena and Chicago Union Railroad, and the Illinois and Michigan Canal opened in 1848. The canal allowed steamboats and sailing ships on the Great Lakes to connect to the Mississippi River.

A flourishing economy brought residents from rural communities and immigrants from abroad. Manufacturing and retail and finance sectors became dominant, influencing the American economy. The Chicago Board of Trade (established 1848) listed the first-ever standardized "exchange-traded" forward contracts, which were called futures contracts.
In the 1850s, Chicago gained national political prominence as the home of Senator Stephen Douglas, the champion of the Kansas–Nebraska Act and the "popular sovereignty" approach to the issue of the spread of slavery. These issues also helped propel another Illinoisan, Abraham Lincoln, to the national stage. Lincoln was nominated in Chicago for US president at the 1860 Republican National Convention, which was held in Chicago in a temporary building called the Wigwam. He defeated Douglas in the general election, and this set the stage for the American Civil War.

To accommodate rapid population growth and demand for better sanitation, the city improved its infrastructure. In February 1856, Chicago's Common Council approved Chesbrough's plan to build the United States' first comprehensive sewerage system. The project raised much of central Chicago to a new grade. While elevating Chicago, and at first improving the city's health, the untreated sewage and industrial waste now flowed into the Chicago River, and subsequently into Lake Michigan, polluting the city's primary freshwater source.

The city responded by tunneling out into Lake Michigan to newly built water cribs. In 1900, the problem of sewage contamination was largely resolved when the city completed a major engineering feat. It reversed the flow of the Chicago River so that the water flowed away from Lake Michigan rather than into it. This project began with the construction and improvement of the Illinois and Michigan Canal, and was completed with the Chicago Sanitary and Ship Canal that connects to the Illinois River, which flows into the Mississippi River.

In 1871, the Great Chicago Fire destroyed an area about long and wide, a large section of the city at the time. Much of the city, including railroads and stockyards, survived intact, and from the ruins of the previous wooden structures arose more modern constructions of steel and stone. These set a precedent for worldwide construction. During its rebuilding period, Chicago constructed the world's first skyscraper in 1885, using steel-skeleton construction.

The city has grown significantly in size and population by incorporating many neighboring townships between 1851 and 1920, with the largest annexation happening in 1889, with five townships joining the city, including the Hyde Park Township, which now comprises most of the South Side of Chicago and the far southeast of Chicago, and the Jefferson Township, which now makes up most of Chicago's Northwest Side. The desire to join the city was driven by municipal services that the city could provide its residents.
Chicago's flourishing economy attracted huge numbers of new immigrants from Europe and migrants from the Eastern United States. Of the total population in 1900, more than 77% were either foreign-born or born in the United States of foreign parentage. Germans, Irish, Poles, Swedes and Czechs made up nearly two-thirds of the foreign-born population (by 1900, whites were 98.1% of the city's population).

Labor conflicts followed the industrial boom and the rapid expansion of the labor pool, including the Haymarket affair on May 4, 1886, and in 1894 the Pullman Strike. Anarchist and socialist groups played prominent roles in creating very large and highly organized labor actions. Concern for social problems among Chicago's immigrant poor led Jane Addams and Ellen Gates Starr to found Hull House in 1889. Programs that were developed there became a model for the new field of social work.

During the 1870s and 1880s, Chicago attained national stature as the leader in the movement to improve public health. City, and later, state laws that upgraded standards for the medical profession and fought urban epidemics of cholera, smallpox, and yellow fever were both passed and enforced. These laws became templates for public health reform in other cities and states.

The city established many large, well-landscaped municipal parks, which also included public sanitation facilities. The chief advocate for improving public health in Chicago was Dr. John H. Rauch, M.D. Rauch established a plan for Chicago's park system in 1866. He created Lincoln Park by closing a cemetery filled with shallow graves, and in 1867, in response to an outbreak of cholera he helped establish a new Chicago Board of Health. Ten years later, he became the secretary and then the president of the first Illinois State Board of Health, which carried out most of its activities in Chicago.

In the 1800s, Chicago became the nation's railroad hub, and by 1910 over 20 railroads operated passenger service out of six different downtown terminals. In 1883, Chicago's railway managers needed a general time convention, so they developed the standardized system of North American time zones. This system for telling time spread throughout the continent.

In 1893, Chicago hosted the World's Columbian Exposition on former marshland at the present location of Jackson Park. The Exposition drew 27.5 million visitors, and is considered the most influential world's fair in history. The University of Chicago, formerly at another location, moved to the same South Side location in 1892. The term "midway" for a fair or carnival referred originally to the Midway Plaisance, a strip of park land that still runs through the University of Chicago campus and connects the Washington and Jackson Parks.

During World War I and the 1920s there was a major expansion in industry. The availability of jobs attracted African Americans from the Southern United States. Between 1910 and 1930, the African American population of Chicago increased dramatically, from 44,103 to 233,903. This Great Migration had an immense cultural impact, called the Chicago Black Renaissance, part of the New Negro Movement, in art, literature, and music. Continuing racial tensions and violence, such as the Chicago Race Riot of 1919, also occurred.

The ratification of the 18th amendment to the Constitution in 1919 made the production and sale (including exportation) of alcoholic beverages illegal in the United States. This ushered in the beginning of what is known as the Gangster Era, a time that roughly spans from 1919 until 1933 when Prohibition was repealed. The 1920s saw gangsters, including Al Capone, Dion O'Banion, Bugs Moran and Tony Accardo battle law enforcement and each other on the streets of Chicago during the Prohibition era. Chicago was the location of the infamous St. Valentine's Day Massacre in 1929, when Al Capone sent men to gun down members of a rival gang, North Side, led by Bugs Moran.

Chicago was the first American city to have a homosexual-rights organization. The organization, formed in 1924, was called the Society for Human Rights. It produced the first American publication for homosexuals, "Friendship and Freedom". Police and political pressure caused the organization to disband.

The Great Depression brought unprecedented suffering to Chicago, in no small part due to the city's heavy reliance on heavy industry. Notably, industrial areas on the south side and neighborhoods lining both branches of the Chicago River were devastated; by 1933 over 50% of industrial jobs in the city had been lost, and unemployment rates amongst blacks and Mexicans in the city were over 40%. The Republican political machine in Chicago was utterly destroyed by the economic crisis, and every mayor since 1931 has been a Democrat. From 1928 to 1933, the city witnessed a tax revolt, and the city was unable to meet payroll or provide relief efforts. Unemployed workers, relief recipients, and unpaid schoolteachers held huge demonstrations during the early years of the Great Depression. The fiscal crisis was resolved by 1933, and at the same time, federal relief funding began to flow into Chicago and enabled the city to complete construction of Lake Shore Drive, landscape numerous parks, construct 30 new schools, and build a thoroughly modernized State Street Subway. Chicago was also a hotbed of labor activism, with Unemployed Councils contributing heavily in the early depression to create solidarity for the poor and demand relief, these organizations were created by socialist and communist groups. By 1935 the Workers Alliance of America begun organizing the poor, workers, the unemployed. In the spring of 1937 Republic Steel Works witnessed the Memorial Day massacre of 1937 in the neighborhood of East Side.

In 1933, Chicago Mayor Anton Cermak was fatally wounded in Miami, Florida, during a failed assassination attempt on President-elect Franklin D. Roosevelt. In 1933 and 1934, the city celebrated its centennial by hosting the Century of Progress International Exposition World's Fair. The theme of the fair was technological innovation over the century since Chicago's founding.

When general prosperity returned in 1940, Chicago had an entrenched Democratic machine, a fully solvent city government, and a population that had enthusiastically shared mass culture and mass movements. Over one-third of the workers in Chicago's manufacturing sector were unionized. During World War II, the city of Chicago alone produced more steel than the United Kingdom every year from 1939 - 1945, and more than Nazi Germany from 1943 - 1945. The city's diversified industrial base made it second only to Detroit in the value—$24 billion—of war goods produced. Over 1,400 companies produced everything from field rations to parachutes to torpedoes, while new aircraft plants employed 100,000 in the construction of engines, aluminum sheeting, bombsights, and other components. The Great Migration, which had been on pause due to the Depression, resumed at an even faster pace in the second wave, as hundreds of thousands of blacks from the South arrived in the city to work in the steel mills, railroads, and shipping yards.

On December 2, 1942, physicist Enrico Fermi conducted the world's first controlled nuclear reaction at the University of Chicago as part of the top-secret Manhattan Project. This led to the creation of the atomic bomb by the United States, which it used in World War II in 1945.

Mayor Richard J. Daley, a Democrat, was elected in 1955, in the era of machine politics. In 1956, the city conducted its last major expansion when it annexed the land under O'Hare airport, including a small portion of DuPage County.

By the 1960s, white residents in several neighborhoods left the city for the suburban areas – in many American cities, a process known as white flight – as Blacks continued to move beyond the Black Belt. While home loan discriminatory redlining against blacks continued, the real estate industry practiced what became known as blockbusting, completely changing the racial composition of whole neighborhoods. Structural changes in industry, such as globalization and job outsourcing, caused heavy job losses for lower-skilled workers. At its peak during the 1960s, some 250,000 workers were employed in the steel industry in Chicago, but the steel crisis of the 1970s and 1980s reduced this number to just 28,000 in 2015. In 1966, Martin Luther King Jr. and Albert Raby led the Chicago Freedom Movement, which culminated in agreements between Mayor Richard J. Daley and the movement leaders.

Two years later, the city hosted the tumultuous 1968 Democratic National Convention, which featured physical confrontations both inside and outside the convention hall, with anti-war protesters, journalists and bystanders being beaten by police. Major construction projects, including the Sears Tower (now known as the Willis Tower, which in 1974 became the world's tallest building), University of Illinois at Chicago, McCormick Place, and O'Hare International Airport, were undertaken during Richard J. Daley's tenure. In 1979, Jane Byrne, the city's first female mayor, was elected. She was notable for temporarily moving into the crime-ridden Cabrini-Green housing project and for leading Chicago's school system out of a financial crisis.

In 1983, Harold Washington became the first black mayor of Chicago. Washington's first term in office directed attention to poor and previously neglected minority neighborhoods. He was re‑elected in 1987 but died of a heart attack soon after. Washington was succeeded by 6th ward Alderman Eugene Sawyer, who was elected by the Chicago City Council and served until a special election.

Richard M. Daley, son of Richard J. Daley, was elected in 1989. His accomplishments included improvements to parks and creating incentives for sustainable development, as well as closing Meigs Field in the middle of the night and destroying the runways. After successfully running for re-election five times, and becoming Chicago's longest-serving mayor, Richard M. Daley declined to run for a seventh term.

In 1992, a construction accident near the Kinzie Street Bridge produced a breach connecting the Chicago River to a tunnel below, which was part of an abandoned freight tunnel system extending throughout the downtown Loop district. The tunnels filled with of water, affecting buildings throughout the district and forcing a shutdown of electrical power. The area was shut down for three days and some buildings did not reopen for weeks; losses were estimated at $1.95 billion.

On February 23, 2011, former Illinois Congressman and White House Chief of Staff Rahm Emanuel won the mayoral election. Emanuel was sworn in as mayor on May 16, 2011, and won re-election in 2015. Lori Lightfoot, the city's first African American woman mayor and its first openly LGBTQ Mayor, was elected to succeed Emanuel as mayor in 2019. All three city-wide elective offices were held by women for the first time in Chicago history: in addition to Lightfoot, the City Clerk was Anna Valencia and City Treasurer, Melissa Conyears-Ervin.

Chicago is located in northeastern Illinois on the southwestern shores of freshwater Lake Michigan. It is the principal city in the Chicago metropolitan area, situated in both the Midwestern United States and the Great Lakes region. The city rests on a continental divide at the site of the Chicago Portage, connecting the Mississippi River and the Great Lakes watersheds. In addition to it lying beside Lake Michigan, two rivers—the Chicago River in downtown and the Calumet River in the industrial far South Side—flow either entirely or partially through the city.

Chicago's history and economy are closely tied to its proximity to Lake Michigan. While the Chicago River historically handled much of the region's waterborne cargo, today's huge lake freighters use the city's Lake Calumet Harbor on the South Side. The lake also provides another positive effect: moderating Chicago's climate, making waterfront neighborhoods slightly warmer in winter and cooler in summer.
When Chicago was founded in 1837, most of the early building was around the mouth of the Chicago River, as can be seen on a map of the city's original 58 blocks. The overall grade of the city's central, built-up areas is relatively consistent with the natural flatness of its overall natural geography, generally exhibiting only slight differentiation otherwise. The average land elevation is above sea level. While measurements vary somewhat, the lowest points are along the lake shore at , while the highest point, at , is the morainal ridge of Blue Island in the city's far south side.

While the Chicago Loop is the central business district, Chicago is also a city of neighborhoods. Lake Shore Drive runs adjacent to a large portion of Chicago's waterfront. Some of the parks along the waterfront include Lincoln Park, Grant Park, Burnham Park, and Jackson Park. There are 24 public beaches across of the waterfront. Landfill extends into portions of the lake providing space for Navy Pier, Northerly Island, the Museum Campus, and large portions of the McCormick Place Convention Center. Most of the city's high-rise commercial and residential buildings are close to the waterfront.

An informal name for the entire Chicago metropolitan area is "Chicagoland", which generally means the city and all its suburbs. The "Chicago Tribune", which coined the term, includes the city of Chicago, the rest of Cook County, and eight nearby Illinois counties: Lake, McHenry, DuPage, Kane, Kendall, Grundy, Will and Kankakee, and three counties in Indiana: Lake, Porter and LaPorte. The Illinois Department of Tourism defines Chicagoland as Cook County without the city of Chicago, and only Lake, DuPage, Kane, and Will counties. The Chicagoland Chamber of Commerce defines it as all of Cook and DuPage, Kane, Lake, McHenry, and Will counties.

Major sections of the city include the central business district, called The Loop, and the North, South, and West Sides. The three sides of the city are represented on the Flag of Chicago by three horizontal white stripes. The North Side is the most-densely-populated residential section of the city, and many high-rises are located on this side of the city along the lakefront. The South Side is the largest section of the city, encompassing roughly 60% of the city's land area. The South Side contains most of the facilities of the Port of Chicago.

In the late-1920s, sociologists at the University of Chicago subdivided the city into 77 distinct community areas, which can further be subdivided into over 200 informally defined neighborhoods.

Chicago's streets were laid out in a street grid that grew from the city's original townsite plot, which was bounded by Lake Michigan on the east, North Avenue on the north, Wood Street on the west, and 22nd Street on the south. Streets following the Public Land Survey System section lines later became arterial streets in outlying sections. As new additions to the city were platted, city ordinance required them to be laid out with eight streets to the mile in one direction and sixteen in the other direction (about one street per 200 meters in one direction and one street per 100 meters in the other direction). The grid's regularity provided an efficient means of developing new real estate property. A scattering of diagonal streets, many of them originally Native American trails, also cross the city (Elston, Milwaukee, Ogden, Lincoln, etc.). Many additional diagonal streets were recommended in the Plan of Chicago, but only the extension of Ogden Avenue was ever constructed.

In 2016, Chicago was ranked the sixth-most walkable large city in the United States. Many of the city's residential streets have a wide patch of grass and/or trees between the street and the sidewalk itself. This helps to keep pedestrians on the sidewalk further away from the street traffic. Chicago's Western Avenue is the longest continuous urban street in the world. Other notable streets include Michigan Avenue, State Street, Oak, Rush, Clark Street, and Belmont Avenue. The City Beautiful movement inspired Chicago's boulevards and parkways.

The destruction caused by the Great Chicago Fire led to the largest building boom in the history of the nation. In 1885, the first steel-framed high-rise building, the Home Insurance Building, rose in the city as Chicago ushered in the skyscraper era, which would then be followed by many other cities around the world. Today, Chicago's skyline is among the world's tallest and densest.

Some of the United States' tallest towers are located in Chicago; Willis Tower (formerly Sears Tower) is the second tallest building in the Western Hemisphere after One World Trade Center, and Trump International Hotel and Tower is the third tallest in the country. The Loop's historic buildings include the Chicago Board of Trade Building, the Fine Arts Building, 35 East Wacker, and the Chicago Building, 860-880 Lake Shore Drive Apartments by Mies van der Rohe. Many other architects have left their impression on the Chicago skyline such as Daniel Burnham, Louis Sullivan, Charles B. Atwood, John Root, and Helmut Jahn.

The Merchandise Mart, once first on the list of largest buildings in the world, currently listed as 44th-largest (), had its own zip code until 2008, and stands near the junction of the North and South branches of the Chicago River. Presently, the four tallest buildings in the city are Willis Tower (formerly the Sears Tower, also a building with its own zip code), Trump International Hotel and Tower, the Aon Center (previously the Standard Oil Building), and the John Hancock Center. Industrial districts, such as some areas on the South Side, the areas along the Chicago Sanitary and Ship Canal, and the Northwest Indiana area are clustered.

Chicago gave its name to the Chicago School and was home to the Prairie School, two movements in architecture. Multiple kinds and scales of houses, townhouses, condominiums, and apartment buildings can be found throughout Chicago. Large swaths of the city's residential areas away from the lake are characterized by brick bungalows built from the early 20th century through the end of World War II. Chicago is also a prominent center of the Polish Cathedral style of church architecture. The Chicago suburb of Oak Park was home to famous architect Frank Lloyd Wright, who had designed The Robie House located near the University of Chicago.

A popular tourist activity is to take an architecture boat tour along the Chicago River.

Chicago is famous for its outdoor public art with donors establishing funding for such art as far back as Benjamin Ferguson's 1905 trust. A number of Chicago's public art works are by modern figurative artists. Among these are Chagall's Four Seasons; the Chicago Picasso; Miro's Chicago; Calder's Flamingo; Oldenburg's Batcolumn; Moore's Large Interior Form, 1953-54, Man Enters the Cosmos and Nuclear Energy; Dubuffet's Monument with Standing Beast, Abakanowicz's Agora; and, Anish Kapoor's Cloud Gate which has become an icon of the city. Some events which shaped the city's history have also been memorialized by art works, including the Great Northern Migration (Saar) and the centennial of statehood for Illinois. Finally, two fountains near the Loop also function as monumental works of art: Plensa's Crown Fountain as well as Burnham and Bennett's Buckingham Fountain.

More representational and portrait statuary includes a number of works by Lorado Taft (Fountain of Time, The Crusader, Eternal Silence, and the Heald Square Monument completed by Crunelle), French's Statue of the Republic, Edward Kemys's Lions, Saint-Gaudens's (a.k.a. Standing Lincoln) and (a.k.a. Seated Lincoln), Brioschi's Christopher Columbus, Meštrović's The Bowman and The Spearman, Dallin's Signal of Peace, Fairbanks's The Chicago Lincoln, Boyle's The Alarm, Polasek's memorial to Masaryk, memorials along "Solidarity Promenade" to Kościuszko, Havliček and Copernicus by Chodzinski, Strachovský, and Thorvaldsen, a memorial to General Logan by Saint-Gaudens, and Kearney's Moose (W-02-03). A number of statues also honor recent local heroes such as Michael Jordan (by Amrany and Rotblatt-Amrany), Stan Mikita, and Bobby Hull outside of the United Center; Harry Caray (by Amrany and Cella) outside Wrigley field, Jack Brickhouse (by McKenna) next to the WGN studios, and Irv Kupcinet at the Wabash Avenue Bridge.

There are preliminary plans to erect a 1:1‑scale replica of Wacław Szymanowski's "Art Nouveau" statue of Frédéric Chopin found in Warsaw's Royal Baths along Chicago's lakefront in addition to a different sculpture commemorating the artist in Chopin Park for the 200th anniversary of Frédéric Chopin's birth.

The city lies within the typical hot-summer humid continental climate (Köppen: "Dfa"), and experiences four distinct seasons. Summers are hot and humid, with frequent heat waves. The July daily average temperature is , with afternoon temperatures peaking at . In a normal summer, temperatures reach at least on as many as 23 days, with lakefront locations staying cooler when winds blow off the lake. Winters are cold and snowy, although the city typically sees less snow and rain in winter than that experienced in the eastern Great Lakes region; blizzards do occur, as in 2011. There are many sunny but cold days in winter. The normal winter high from December through March is about , with January and February being the coldest months; a polar vortex in January 2019 nearly broke the city's cold record of , which was set on January 20, 1985. Spring and autumn are mild, short seasons, typically with low humidity. Dew point temperatures in the summer range from an average of in June to in July, but can reach nearly , such as during the July 2019 heat wave. The city lies within USDA plant hardiness zone 6a, transitioning to 5b in the suburbs.

According to the National Weather Service, Chicago's highest official temperature reading of was recorded on July 24, 1934, although Midway Airport reached one day prior and recorded a heat index of during the 1995 heatwave. The lowest official temperature of was recorded on January 20, 1985, at O'Hare Airport. Most of the city's rainfall is brought by thunderstorms, averaging 38 a year. The region is also prone to severe thunderstorms during the spring and summer which can produce large hail, damaging winds, and occasionally tornadoes. Like other major cities, Chicago experiences an urban heat island, making the city and its suburbs milder than surrounding rural areas, especially at night and in winter. The proximity to Lake Michigan tends to keep the Chicago lakefront somewhat cooler in summer and less brutally cold in winter than inland parts of the city and suburbs away from the lake. Northeast winds from wintertime cyclones departing south of the region sometimes bring the city lake-effect snow.

As in the rest of the state of Illinois, Chicago forms part of the Central Time Zone. The border with the Eastern Time Zone is located a short distance to the east, used in Michigan and certain parts of Indiana.

During its first hundred years, Chicago was one of the fastest-growing cities in the world. When founded in 1833, fewer than 200 people had settled on what was then the American frontier. By the time of its first census, seven years later, the population had reached over 4,000. In the forty years from 1850 to 1890, the city's population grew from slightly under 30,000 to over 1 million. At the end of the 19th century, Chicago was the fifth-largest city in the world, and the largest of the cities that did not exist at the dawn of the century. Within sixty years of the Great Chicago Fire of 1871, the population went from about 300,000 to over 3 million, and reached its highest ever recorded population of 3.6 million for the 1950 census.

From the last two decades of the 19th century, Chicago was the destination of waves of immigrants from Ireland, Southern, Central and Eastern Europe, including Italians, Jews, Poles, Greeks, Lithuanians, Bulgarians, Albanians, Romanians, Turkish, Croatians, Serbs, Bosnians, Montenegrins and Czechs. To these ethnic groups, the basis of the city's industrial working class, were added an additional influx of African Americans from the American South—with Chicago's black population doubling between 1910 and 1920 and doubling again between 1920 and 1930.

In the 1920s and 1930s, the great majority of African Americans moving to Chicago settled in a so‑called "Black Belt" on the city's South Side. A large number of blacks also settled on the West Side. By 1930, two-thirds of Chicago's black population lived in sections of the city which were 90% black in racial composition. Chicago's South Side emerged as United States second-largest urban black concentration, following New York's Harlem. Today, Chicago's South Side and the adjoining south suburbs constitute the largest black majority region in the entire United States.

Chicago's population declined in the latter half of the 20th century, from over 3.6 million in 1950 down to under 2.7 million by 2010. By the time of the official census count in 1990, it was overtaken by Los Angeles as the United States' second largest city.

The city has seen a rise in population for the 2000 census and is expected to have an increase for the 2020 census.

Per U.S. Census estimates , Chicago's largest racial or ethnic group is non-Hispanic White at 32.8% of the population, Blacks at 30.1% and the Hispanic population at 29.0% of the population

As of the 2010 census, there were 2,695,598 people with 1,045,560 households living in Chicago. More than half the population of the state of Illinois lives in the Chicago metropolitan area. Chicago is one of the United States' most densely populated major cities, and the largest city in the Great Lakes Megalopolis. The racial composition of the city was:
Chicago has a Hispanic or Latino population of 28.9%. (Its members may belong to any race; 21.4% Mexican, 3.8% Puerto Rican, 0.7% Guatemalan, 0.6% Ecuadorian, 0.3% Cuban, 0.3% Colombian, 0.2% Honduran, 0.2% Salvadoran, 0.2% Peruvian).

Chicago has the third-largest LGBT population in the United States. In 2015, roughly 4% of the population identified as LGBT. Since the 2013 legalization of same-sex marriage in Illinois, over 10,000 same-sex couples have wed in Cook County, a majority in Chicago.

Chicago became a "de jure" sanctuary city in 2012 when Mayor Rahm Emanuel and the City Council passed the Welcoming City Ordinance.

According to the U.S. Census Bureau's American Community Survey data estimates for 2008–2012, the median income for a household in the city was $47,408, and the median income for a family was $54,188. Male full-time workers had a median income of $47,074 versus $42,063 for females. About 18.3% of families and 22.1% of the population lived below the poverty line. In 2018, Chicago ranked 7th globally for the highest number of ultra-high-net-worth residents with roughly 3,300 residents worth more than $30 million.

According to the 2008–2012 American Community Survey, the ancestral groups having 10,000 or more persons in Chicago were:
Persons identifying themselves as "Other groups" were classified at 1.72 million, and unclassified or not reported were approximately 153,000.

Seventy-one percent identify as Christians (almost half of whom—35%—identify as Catholic), 7% identity with other faiths, and 22% have no religious affiliation. Chicago has many Jews, Muslims, Buddhists, Hindus, and others. Chicago is the headquarters of several religious denominations, including the Evangelical Covenant Church and the Evangelical Lutheran Church in America. It is the seat of several dioceses. The Fourth Presbyterian Church is one of the largest Presbyterian congregations in the United States based on memberships.

The first two Parliament of the World's Religions in 1893 and 1993 were held in Chicago. Many international religious leaders have visited Chicago, including Mother Teresa, the Dalai Lama and Pope John Paul II in 1979.

Chicago has the third-largest gross metropolitan product in the United States—about $670.5 billion according to September 2017 estimates. The city has also been rated as having the most balanced economy in the United States, due to its high level of diversification. In 2007, Chicago was named the fourth-most important business center in the world in the MasterCard Worldwide Centers of Commerce Index. Additionally, the Chicago metropolitan area recorded the greatest number of new or expanded corporate facilities in the United States for calendar year 2014. The Chicago metropolitan area has the third-largest science and engineering work force of any metropolitan area in the nation. In 2009 Chicago placed ninth on the UBS list of the world's richest cities. Chicago was the base of commercial operations for industrialists John Crerar, John Whitfield Bunn, Richard Teller Crane, Marshall Field, John Farwell, Julius Rosenwald and many other commercial visionaries who laid the foundation for Midwestern and global industry.
Chicago is a major world financial center, with the second-largest central business district in the United States. The city is the seat of the Federal Reserve Bank of Chicago, the Bank's Seventh District. The city has major financial and futures exchanges, including the Chicago Stock Exchange, the Chicago Board Options Exchange (CBOE), and the Chicago Mercantile Exchange (the "Merc"), which is owned, along with the Chicago Board of Trade (CBOT) by Chicago's CME Group. In 2017, Chicago exchanges traded 4.7 billion derivatives with a face value of over one quadrillion dollars. Chase Bank has its commercial and retail banking headquarters in Chicago's Chase Tower. Academically, Chicago has been influential through the Chicago school of economics, which fielded some 12 Nobel Prize winners.

The city and its surrounding metropolitan area contain the third-largest labor pool in the United States with about 4.63 million workers. Illinois is home to 66 "Fortune" 1000 companies, including those in Chicago. The city of Chicago also hosts 12 "Fortune" Global 500 companies and 17 "Financial Times" 500 companies. The city claims three Dow 30 companies: aerospace giant Boeing, which moved its headquarters from Seattle to the Chicago Loop in 2001, McDonald's and Walgreens Boots Alliance. For six consecutive years since 2013, Chicago was ranked the nation's top metropolitan area for corporate relocations.

Manufacturing, printing, publishing and food processing also play major roles in the city's economy. Several medical products and services companies are headquartered in the Chicago area, including Baxter International, Boeing, Abbott Laboratories, and the Healthcare division of General Electric. In addition to Boeing, which located its headquarters in Chicago in 2001, and United Airlines in 2011, GE Transportation moved its offices to the city in 2013 and GE Healthcare moved its HQ to the city in 2016, as did ThyssenKrupp North America, and agriculture giant Archer Daniels Midland. Moreover, the construction of the Illinois and Michigan Canal, which helped move goods from the Great Lakes south on the Mississippi River, and of the railroads in the 19th century made the city a major transportation center in the United States. In the 1840s, Chicago became a major grain port, and in the 1850s and 1860s Chicago's pork and beef industry expanded. As the major meat companies grew in Chicago many, such as Armour and Company, created global enterprises. Although the meatpacking industry currently plays a lesser role in the city's economy, Chicago continues to be a major transportation and distribution center. Lured by a combination of large business customers, federal research dollars, and a large hiring pool fed by the area's universities, Chicago is also the site of a growing number of web startup companies like CareerBuilder, Orbitz, Basecamp, Groupon, Feedburner, Grubhub and NowSecure.

Prominent food companies based in Chicago include the world headquarters of Conagra, Ferrara Candy Company, Kraft Heinz, McDonald's, Mondelez International, Quaker Oats, and US Foods.

Chicago has been a hub of the retail sector since its early development, with Montgomery Ward, Sears, and Marshall Field's. Today the Chicago metropolitan area is the headquarters of several retailers, including Walgreens, Sears, Ace Hardware, Claire's, ULTA Beauty and Crate & Barrel.

Late in the 19th century, Chicago was part of the bicycle craze, with the Western Wheel Company, which introduced stamping to the production process and significantly reduced costs, while early in the 20th century, the city was part of the automobile revolution, hosting the Brass Era car builder Bugmobile, which was founded there in 1907. Chicago was also the site of the Schwinn Bicycle Company.

Chicago is a major world convention destination. The city's main convention center is McCormick Place. With its four interconnected buildings, it is the largest convention center in the nation and third-largest in the world. Chicago also ranks third in the U.S. (behind Las Vegas and Orlando) in number of conventions hosted annually.

Chicago's minimum wage for non-tipped employees is one of the highest in the nation at $14 per hour and will reach $15 by 2021.

The city's waterfront location and nightlife has attracted residents and tourists alike. Over a third of the city population is concentrated in the lakefront neighborhoods from Rogers Park in the north to South Shore in the south. The city has many upscale dining establishments as well as many ethnic restaurant districts. These districts include the Mexican American neighborhoods, such as Pilsen along 18th street, and "La Villita" along 26th Street; the Puerto Rican enclave of Paseo Boricua in the Humboldt Park neighborhood; Greektown, along South Halsted Street, immediately west of downtown; Little Italy, along Taylor Street; Chinatown in Armour Square; Polish Patches in West Town; Little Seoul in Albany Park around Lawrence Avenue; Little Vietnam near Broadway in Uptown; and the Desi area, along Devon Avenue in West Ridge.

Downtown is the center of Chicago's financial, cultural, governmental and commercial institutions and the site of Grant Park and many of the city's skyscrapers. Many of the city's financial institutions, such as the CBOT and the Federal Reserve Bank of Chicago, are located within a section of downtown called "The Loop", which is an eight-block by five-block area of city streets that is encircled by elevated rail tracks. The term "The Loop" is largely used by locals to refer to the entire downtown area as well. The central area includes the Near North Side, the Near South Side, and the Near West Side, as well as the Loop. These areas contribute famous skyscrapers, abundant restaurants, shopping, museums, a stadium for the Chicago Bears, convention facilities, parkland, and beaches.

Lincoln Park contains the Lincoln Park Zoo and the Lincoln Park Conservatory. The River North Gallery District features the nation's largest concentration of contemporary art galleries outside of New York City.

Lakeview is home to Boystown, the city's large LGBT nightlife center. The Chicago Pride Parade, held the last Sunday in June, is one of the world's largest with over a million people in attendance.
North Halsted Street is the main thoroughfare of Boystown.

The South Side neighborhood of Hyde Park is the home of former US President Barack Obama. It also contains the University of Chicago, ranked one of the world's top ten universities, and the Museum of Science and Industry. The long Burnham Park stretches along the waterfront of the South Side. Two of the city's largest parks are also located on this side of the city: Jackson Park, bordering the waterfront, hosted the World's Columbian Exposition in 1893, and is the site of the aforementioned museum; and slightly west sits Washington Park. The two parks themselves are connected by a wide strip of parkland called the Midway Plaisance, running adjacent to the University of Chicago. The South Side hosts one of the city's largest parades, the annual African American Bud Billiken Parade and Picnic, which travels through Bronzeville to Washington Park. Ford Motor Company has an automobile assembly plant on the South Side in Hegewisch, and most of the facilities of the Port of Chicago are also on the South Side.

The West Side holds the Garfield Park Conservatory, one of the largest collections of tropical plants in any U.S. city. Prominent Latino cultural attractions found here include Humboldt Park's Institute of Puerto Rican Arts and Culture and the annual Puerto Rican People's Parade, as well as the National Museum of Mexican Art and St. Adalbert's Church in Pilsen. The Near West Side holds the University of Illinois at Chicago and was once home to Oprah Winfrey's Harpo Studios, the site of which has been rebuilt as the global headquarters of McDonald's.

The city's distinctive accent, made famous by its use in classic films like "The Blues Brothers" and television programs like the "Saturday Night Live" skit "Bill Swerski's Superfans", is an advanced form of Inland Northern American English. This dialect can also be found in other cities bordering the Great Lakes such as Cleveland, Milwaukee, Detroit, and Rochester, New York, and most prominently features a rearrangement of certain vowel sounds, such as the short 'a' sound as in "cat", which can sound more like "kyet" to outsiders. The accent remains well associated with the city.

Renowned Chicago theater companies include the Goodman Theatre in the Loop; the Steppenwolf Theatre Company and Victory Gardens Theater in Lincoln Park; and the Chicago Shakespeare Theater at Navy Pier. Broadway In Chicago offers Broadway-style entertainment at five theaters: the Nederlander Theatre, CIBC Theatre, Cadillac Palace Theatre, Auditorium Building of Roosevelt University, and Broadway Playhouse at Water Tower Place. Polish language productions for Chicago's large Polish speaking population can be seen at the historic Gateway Theatre in Jefferson Park. Since 1968, the Joseph Jefferson Awards are given annually to acknowledge excellence in theater in the Chicago area. Chicago's theater community spawned modern improvisational theater, and includes the prominent groups The Second City and I.O. (formerly ImprovOlympic).

The Chicago Symphony Orchestra (CSO) performs at Symphony Center, and is recognized as one of the best orchestras in the world. Also performing regularly at Symphony Center is the Chicago Sinfonietta, a more diverse and multicultural counterpart to the CSO. In the summer, many outdoor concerts are given in Grant Park and Millennium Park. Ravinia Festival, located north of Chicago, is the summer home of the CSO, and is a favorite destination for many Chicagoans. The Civic Opera House is home to the Lyric Opera of Chicago. The Lithuanian Opera Company of Chicago was founded by Lithuanian Chicagoans in 1956, and presents operas in Lithuanian.

The Joffrey Ballet and Chicago Festival Ballet perform in various venues, including the Harris Theater in Millennium Park. Chicago has several other contemporary and jazz dance troupes, such as the Hubbard Street Dance Chicago and Chicago Dance Crash.

Other live-music genre which are part of the city's cultural heritage include Chicago blues, Chicago soul, jazz, and gospel. The city is the birthplace of house music (a popular form of electronic dance music) and industrial music, and is the site of an influential hip hop scene. In the 1980s and 90s, the city was the global center for house and industrial music, two forms of music created in Chicago, as well as being popular for alternative rock, punk, and new wave. The city has been a center for rave culture, since the 1980s. A flourishing independent rock music culture brought forth Chicago indie. Annual festivals feature various acts, such as Lollapalooza and the Pitchfork Music Festival. A 2007 report on the Chicago music industry by the University of Chicago Cultural Policy Center ranked Chicago third among metropolitan U.S. areas in "size of music industry" and fourth among all U.S. cities in "number of concerts and performances".

Chicago has a distinctive fine art tradition. For much of the twentieth century, it nurtured a strong style of figurative surrealism, as in the works of Ivan Albright and Ed Paschke. In 1968 and 1969, members of the Chicago Imagists, such as Roger Brown, Leon Golub, Robert Lostutter, Jim Nutt, and Barbara Rossi produced bizarre representational paintings. Henry Darger is one of the most celebrated figures of outsider art.

Chicago contains a number of large, outdoor works by well-known artists. These include the Chicago Picasso, "Miró's Chicago", "Flamingo" and "Flying Dragon" by Alexander Calder, "Agora" by Magdalena Abakanowicz, "Monument with Standing Beast" by Jean Dubuffet, "Batcolumn" by Claes Oldenburg, "Cloud Gate" by Anish Kapoor, "Crown Fountain" by Jaume Plensa, and the "Four Seasons" mosaic by Marc Chagall.

Chicago also has a nationally televised Thanksgiving parade that occurs annually. The McDonald's Thanksgiving Parade is seen across the nation on WGN-TV and WGN America, featuring a variety of diverse acts from the community, marching bands from across the country, and is the only parade in the city to feature inflatable balloons every year.

, Chicago attracted 50.17 million domestic leisure travelers, 11.09 million domestic business travelers and 1.308 million overseas visitors. These visitors contributed more than billion to Chicago's economy. Upscale shopping along the Magnificent Mile and State Street, thousands of restaurants, as well as Chicago's eminent architecture, continue to draw tourists. The city is the United States' third-largest convention destination. A 2017 study by Walk Score ranked Chicago the sixth-most walkable of fifty largest cities in the United States. Most conventions are held at McCormick Place, just south of Soldier Field. The historic Chicago Cultural Center (1897), originally serving as the Chicago Public Library, now houses the city's Visitor Information Center, galleries and exhibit halls. The ceiling of its Preston Bradley Hall includes a Tiffany glass dome. Grant Park holds Millennium Park, Buckingham Fountain (1927), and the Art Institute of Chicago. The park also hosts the annual Taste of Chicago festival. In Millennium Park, the reflective "Cloud Gate" public sculpture by artist Anish Kapoor is the centerpiece of the AT&T Plaza in Millennium Park. Also, an outdoor restaurant transforms into an ice rink in the winter season. Two tall glass sculptures make up the Crown Fountain. The fountain's two towers display visual effects from LED images of Chicagoans' faces, along with water spouting from their lips. Frank Gehry's detailed, stainless steel band shell, the Jay Pritzker Pavilion, hosts the classical Grant Park Music Festival concert series. Behind the pavilion's stage is the Harris Theater for Music and Dance, an indoor venue for mid-sized performing arts companies, including the Chicago Opera Theater and Music of the Baroque.

Navy Pier, located just east of Streeterville, is long and houses retail stores, restaurants, museums, exhibition halls and auditoriums. In the summer of 2016, Navy Pier constructed a DW60 Ferris wheel. Dutch Wheels, a world renowned company that manufactures ferris wheels, was selected to design the new wheel. It features 42 navy blue gondolas that can hold up to eight adults and two kids. It also has entertainment systems inside the gondolas as well as a climate controlled environment. The DW60 stands at approximately , which is 46 ft taller than the previous wheel. The new DW60 is the first in the United States and is the sixth tallest in the U.S. Chicago was the first city in the world to ever erect a ferris wheel.

On June 4, 1998, the city officially opened the Museum Campus, a lakefront park, surrounding three of the city's main museums, each of which is of national importance: the Adler Planetarium & Astronomy Museum, the Field Museum of Natural History, and the Shedd Aquarium. The Museum Campus joins the southern section of Grant Park, which includes the renowned Art Institute of Chicago. Buckingham Fountain anchors the downtown park along the lakefront. The University of Chicago Oriental Institute has an extensive collection of ancient Egyptian and Near Eastern archaeological artifacts. Other museums and galleries in Chicago include the Chicago History Museum, the Driehaus Museum, the DuSable Museum of African American History, the Museum of Contemporary Art, the Peggy Notebaert Nature Museum, the Polish Museum of America, the Museum of Broadcast Communications, the Pritzker Military Library, the Chicago Architecture Foundation, and the Museum of Science and Industry.

With an estimated completion date of 2020, the Barack Obama Presidential Center will be housed at the University of Chicago in Hyde Park and include both the Obama presidential library and offices of the Obama Foundation.

The Willis Tower (formerly named Sears Tower) is a popular destination for tourists. The Willis Tower has an observation deck open to tourists year round with high up views overlooking Chicago and Lake Michigan. The observation deck includes an enclosed glass balcony that extends 10 feet out on the side of the building. Tourists are able to look straight down.

In 2013, Chicago was chosen as one of the "Top Ten Cities in the United States" to visit for its restaurants, skyscrapers, museums, and waterfront, by the readers of "Condé Nast Traveler".

Chicago lays claim to a large number of regional specialties that reflect the city's ethnic and working-class roots. Included among these are its nationally renowned deep-dish pizza; this style is said to have originated at Pizzeria Uno. The Chicago-style thin crust is also popular in the city. Certain Chicago pizza favorites include Lou Malnati's and Giordano's.

The Chicago-style hot dog, typically an all-beef hot dog, is loaded with an array of toppings that often includes pickle relish, yellow mustard, pickled sport peppers, tomato wedges, dill pickle spear and topped off with celery salt on a poppy seed bun. Enthusiasts of the Chicago-style hot dog frown upon the use of ketchup as a garnish, but may prefer to add giardiniera.

A distinctly Chicago sandwich, the Italian beef sandwich is thinly sliced beef simmered in au jus and served on an Italian roll with sweet peppers or spicy giardiniera. A popular modification is the Combo—an Italian beef sandwich with the addition of an Italian sausage. The Maxwell Street Polish is a grilled or deep-fried kielbasa—on a hot dog roll, topped with grilled onions, yellow mustard, and hot sport peppers.

Chicken Vesuvio is roasted bone-in chicken cooked in oil and garlic next to garlicky oven-roasted potato wedges and a sprinkling of green peas. The Puerto Rican-influenced jibarito is a sandwich made with flattened, fried green plantains instead of bread. The mother-in-law is a tamale topped with chili and served on a hot dog bun. The tradition of serving the Greek dish saganaki while aflame has its origins in Chicago's Greek community. The appetizer, which consists of a square of fried cheese, is doused with Metaxa and flambéed table-side.

One of the world's most decorated restaurants and a recipient of three Michelin stars, Alinea is located in Chicago. Well-known chefs who have had restaurants in Chicago include: Charlie Trotter, Rick Tramonto, Grant Achatz, and Rick Bayless. In 2003, "Robb Report" named Chicago the country's "most exceptional dining destination".

Chicago literature finds its roots in the city's tradition of lucid, direct journalism, lending to a strong tradition of social realism. In the "Encyclopedia of Chicago", Northwestern University Professor Bill Savage describes Chicago fiction as prose which tries to ""capture the essence of the city, its spaces and its people"". The challenge for early writers was that Chicago was a frontier outpost that transformed into a global metropolis in the span of two generations. Narrative fiction of that time, much of it in the style of "high-flown romance" and "genteel realism", needed a new approach to describe the urban social, political, and economic conditions of Chicago. Nonetheless, Chicagoans worked hard to create a literary tradition that would stand the test of time, and create a "city of feeling" out of concrete, steel, vast lake, and open prairie. Much notable Chicago fiction focuses on the city itself, with social criticism keeping exultation in check.

At least three short periods in the history of Chicago have had a lasting influence on American literature. These include from the time of the Great Chicago Fire to about 1900, what became known as the Chicago Literary Renaissance in the 1910s and early 1920s, and the period of the Great Depression through the 1940s.

What would become the influential "Poetry" magazine was founded in 1912 by Harriet Monroe, who was working as an art critic for the "Chicago Tribune". The magazine discovered such poets as Gwendolyn Brooks, James Merrill, and John Ashbery. T. S. Eliot's first professionally published poem, "The Love Song of J. Alfred Prufrock", was first published by "Poetry". Contributors have included Ezra Pound, William Butler Yeats, William Carlos Williams, Langston Hughes, and Carl Sandburg, among others. The magazine was instrumental in launching the Imagist and Objectivist poetic movements. From the 1950s through 1970s, American poetry continued to evolve in Chicago. In the 1980s, a modern form of poetry performance began in Chicago, the Poetry Slam.

"Sporting News" named Chicago the "Best Sports City" in the United States in 1993, 2006, and 2010. Along with Boston, Chicago is the only city to continuously host major professional sports since 1871, having only taken 1872 and 1873 off due to the Great Chicago Fire. Additionally, Chicago is one of the eight cities in the United States to have won championships in the four major professional leagues and, along with Los Angeles, New York, Philadelphia and Washington, is one of five cities to have won soccer championships as well. All of its major franchises have won championships within recent years – the Bears (1985), the Bulls (1991, 1992, 1993, 1996, 1997, and 1998), the White Sox (2005), the Cubs (2016), the Blackhawks (2010, 2013, 2015), and the Fire (1998). Chicago has the third most franchises in the four major North American sports leagues with five, behind the New York and Los Angeles Metropolitan Areas, and have six top-level professional sports clubs when including Chicago Fire FC of Major League Soccer (MLS).

The city has two Major League Baseball (MLB) teams: the Chicago Cubs of the National League play in Wrigley Field on the North Side; and the Chicago White Sox of the American League play in Guaranteed Rate Field on the South Side. Chicago is the only city that has had more than one MLB franchise every year since the AL began in 1901 (New York hosted only one between 1958 and early 1962). The two teams have faced each other in a World Series only once: in 1906, when the White Sox, known as the "Hitless Wonders," defeated the Cubs, 4–2.

The Cubs are the oldest Major League Baseball team to have never changed their city; they have played in Chicago since 1871, and continuously so since 1874 due to the Great Chicago Fire. They have played more games and have more wins than any other team in Major League baseball since 1876. They have won three World Series titles, including the 2016 World Series, but had the dubious honor of having the two longest droughts in American professional sports: They had not won their sport's title since 1908, and had not participated in a World Series since 1945, both records, until they beat the Cleveland Indians in the 2016 World Series.

The White Sox have played on the South Side continuously since 1901, with all three of their home fields throughout the years being within blocks of one another. They have won three World Series titles (1906, 1917, 2005) and six American League pennants, including the first in 1901. The Sox are fifth in the American League in all-time wins, and sixth in pennants.

The Chicago Bears, one of the last two remaining charter members of the National Football League (NFL), have won nine NFL Championships, including the 1985 Super Bowl XX. The other remaining charter franchise, the Chicago Cardinals, also started out in the city, but is now known as the Arizona Cardinals. The Bears have won more games in the history of the NFL than any other team, and only the Green Bay Packers, their longtime rivals, have won more championships. The Bears play their home games at Soldier Field. Soldier Field re-opened in 2003 after an extensive renovation.

The Chicago Bulls of the National Basketball Association (NBA) is one of the most recognized basketball teams in the world. During the 1990s, with Michael Jordan leading them, the Bulls won six NBA championships in eight seasons. They also boast the youngest player to win the NBA Most Valuable Player Award, Derrick Rose, who won it for the 2010–11 season.

The Chicago Blackhawks of the National Hockey League (NHL) began play in 1926, and are one of the "Original Six" teams of the NHL. The Blackhawks have won six Stanley Cups, including in 2010, 2013, and 2015. Both the Bulls and the Blackhawks play at the United Center.

Chicago Fire FC is a member of Major League Soccer (MLS) and plays at Soldier Field. After playing its first eight seasons at Soldier Field, the team moved to suburban Bridgeview to play at SeatGeek Stadium. In 2019, the team announced a move back to Soldier Field. The Fire have won one league title and four U.S. Open Cups, since their founding in 1997. In 1994, the United States hosted a successful FIFA World Cup with games played at Soldier Field.

The Chicago Sky is a professional basketball team playing in the Women's National Basketball Association (WNBA). They play home games at the Wintrust Arena. The team was founded before the 2006 WNBA season began.

The Chicago Marathon has been held each year since 1977 except for 1987, when a half marathon was run in its place. The Chicago Marathon is one of six World Marathon Majors.

Five area colleges play in Division I conferences: two from major conferences—the DePaul Blue Demons (Big East Conference) and the Northwestern Wildcats (Big Ten Conference)—and three from other D1 conferences—the Chicago State Cougars (Western Athletic Conference); the Loyola Ramblers (Missouri Valley Conference); and the UIC Flames (Horizon League).

Chicago has also entered into eSports with the creation of the Chicago Huntsmen, a professional Call of Duty team that participates within the CDL. At the Call of Duty League's Launch Week games in Minneapolis, Minnesota, the Chicago Huntsmen went on to beat both the Dallas Empire and Optic Gaming Los Angeles.

When Chicago was incorporated in 1837, it chose the motto "Urbs in Horto", a Latin phrase which means "City in a Garden". Today, the Chicago Park District consists of more than 570 parks with over of municipal parkland. There are 31 sand beaches, a plethora of museums, two world-class conservatories, and 50 nature areas. Lincoln Park, the largest of the city's parks, covers and has over 20 million visitors each year, making it third in the number of visitors after Central Park in New York City, and the National Mall and Memorial Parks in Washington, D.C.

There is a historic boulevard system, a network of wide, tree-lined boulevards which connect a number of Chicago parks. The boulevards and the parks were authorized by the Illinois legislature in 1869. A number of Chicago neighborhoods emerged along these roadways in the 19th century. The building of the boulevard system continued intermittently until 1942. It includes nineteen boulevards, eight parks, and six squares, along twenty-six miles of interconnected streets. Part of the system in the Logan Square Boulevards Historic District was listed in the National Register of Historic Places in 1985.

With berths for more than 6,000 boats, the Chicago Park District operates the nation's largest municipal harbor system. In addition to ongoing beautification and renewal projects for the existing parks, a number of new parks have been added in recent years, such as the Ping Tom Memorial Park in Chinatown, DuSable Park on the Near North Side, and most notably, Millennium Park, which is in the northwestern corner of one of Chicago's oldest parks, Grant Park in the Chicago Loop.

The wealth of greenspace afforded by Chicago's parks is further augmented by the Cook County Forest Preserves, a network of open spaces containing forest, prairie, wetland, streams, and lakes that are set aside as natural areas which lie along the city's outskirts, including both the Chicago Botanic Garden in Glencoe and the Brookfield Zoo in Brookfield. Washington Park is also one of the city's biggest parks; covering nearly . The park is listed on the National Register of Historic Places listings in South Side Chicago.

The government of the City of Chicago is divided into executive and legislative branches. The Mayor of Chicago is the chief executive, elected by general election for a term of four years, with no term limits. The current mayor is Lori Lightfoot. The mayor appoints commissioners and other officials who oversee the various departments. As well as the mayor, Chicago's clerk and treasurer are also elected citywide. The City Council is the legislative branch and is made up of 50 aldermen, one elected from each ward in the city. The council takes official action through the passage of ordinances and resolutions and approves the city budget.

The Chicago Police Department provides law enforcement and the Chicago Fire Department provides fire suppression and emergency medical services for the city and its residents. Civil and criminal law cases are heard in the Cook County Circuit Court of the State of Illinois court system, or in the Northern District of Illinois, in the federal system. In the state court, the public prosecutor is the Illinois State's Attorney; in the Federal court it is the United States Attorney.

During much of the last half of the 19th century, Chicago's politics were dominated by a growing Democratic Party organization. During the 1880s and 1890s, Chicago had a powerful radical tradition with large and highly organized socialist, anarchist and labor organizations. For much of the 20th century, Chicago has been among the largest and most reliable Democratic strongholds in the United States; with Chicago's Democratic vote the state of Illinois has been "solid blue" in presidential elections since 1992. Even before then, it was not unheard of for Republican presidential candidates to win handily in downstate Illinois, only to lose statewide due to large Democratic margins in Chicago. The citizens of Chicago have not elected a Republican mayor since 1927, when William Thompson was voted into office. The strength of the party in the city is partly a consequence of Illinois state politics, where the Republicans have come to represent rural and farm concerns while the Democrats support urban issues such as Chicago's public school funding.

Chicago contains less than 25% of the state's population, but it is split between eight of Illinois' 19 districts in the United States House of Representatives. All eight of the city's representatives are Democrats; only two Republicans have represented a significant portion of the city since 1973, for one term each: Robert P. Hanrahan from 1973 to 1975, and Michael Patrick Flanagan from 1995 to 1997.

Machine politics persisted in Chicago after the decline of similar machines in other large U.S. cities. During much of that time, the city administration found opposition mainly from a liberal "independent" faction of the Democratic Party. The independents finally gained control of city government in 1983 with the election of Harold Washington (in office 1983–1987). From 1989 until May 16, 2011, Chicago was under the leadership of its longest-serving mayor, Richard M. Daley, the son of Richard J. Daley. Because of the dominance of the Democratic Party in Chicago, the Democratic primary vote held in the spring is generally more significant than the general elections in November for U.S. House and Illinois State seats. The aldermanic, mayoral, and other city offices are filled through nonpartisan elections with runoffs as needed.

Formerly a state legislator representing Chicago and later a US Senator, the city is home of former United States President Barack Obama and First Lady Michelle Obama. The Obamas' residence is located near the University of Chicago in Kenwood on the city's south side.

Chicago had a murder rate of 18.5 per 100,000 residents in 2012, ranking 16th among US cities with 100,000 people or more. This was higher than in New York City and Los Angeles, the two largest cities in the United States, which have lower murder rates and lower total homicides. However, it was less than in many smaller American cities, including New Orleans, Newark, and Detroit, which had 53 murders per 100,000 residents in 2012. The 2015 year-end crime statistics showed there were 468 murders in Chicago in 2015 compared with 416 the year before, a 12.5% increase, as well as 2,900 shootings—13% more than the year prior, and up 29% since 2013. Chicago had more homicides than any other city in 2015 in total but not on per capita basis, according to the Chicago Tribune. In its annual crime statistics for 2016, the Chicago Police Department reported that the city experienced a dramatic rise in gun violence, with 4,331 shooting victims. The department also reported 762 murders in Chicago for the year 2016, a total that marked a 62.79% increase in homicides from 2015. In June 2017, the Chicago Police Department and the Federal ATF announced a new task force, similar to past task forces, to address the flow of illegal guns and repeat offenses with guns.

According to reports in 2013, "most of Chicago's violent crime comes from gangs trying to maintain control of drug-selling territories", and is specifically related to the activities of the Sinaloa Cartel, which is active in several American cities. By 2006, the cartel sought to control most illicit drug sales. Violent crime rates vary significantly by area of the city, with more economically developed areas having low rates, but other sections have much higher rates of crime. In 2013, the violent crime rate was 910 per 100,000 people; the murder rate was 10.4 – while high crime districts saw 38.9, low crime districts saw 2.5 murders per 100,000.

The number of murders in Chicago peaked at 970 in 1974, when the city's population was over 3 million people (a murder rate of about 29 per 100,000), and it reached 943 murders in 1992, (a murder rate of 34 per 100,000). However, Chicago, like other major U.S. cities, experienced a significant reduction in violent crime rates through the 1990s, falling to 448 homicides in 2004, its lowest total since 1965 and only 15.65 murders per 100,000. Chicago's homicide tally remained low during 2005 (449), 2006 (452), and 2007 (435) but rose to 510 in 2008, breaking 500 for the first time since 2003. In 2009, the murder count fell to 458 (10% down). and in 2010 Chicago's murder rate fell to 435 (16.14 per 100,000), a 5% decrease from 2009 and lowest levels since 1965. In 2011, Chicago's murders fell another 1.2% to 431 (a rate of 15.94 per 100,000). but shot up to 506 in 2012.

In 2012, Chicago ranked 21st in the United States in numbers of homicides per person, and in the first half of 2013 there was a significant drop per-person, in all categories of violent crime, including homicide (down 26%). Chicago ended 2013 with 415 murders, the lowest number of murders since 1965, and overall crime rates dropped by 16 percent. In 2013, the city's murder rate was only slightly higher than the national average as a whole.) According to the FBI, St. Louis, New Orleans, Detroit, and Baltimore
had the highest murder rate along with several other cities.
Jens Ludwig, director of the University of Chicago Crime Lab, estimated that shootings cost the city of Chicago $2.5 billion in 2012.

In September 2016, an Illinois state appellate court found that cities do not have an obligation under the Illinois Constitution to pay certain benefits if those benefits had included an expiration date under whichever negotiated agreement they were covered. The Illinois Constitution prohibits governments from doing anything that could cause retirement benefits for government workers to be "diminished or impaired." In this particular case, the fact that the workers' agreements had expiration dates let the city of Chicago set an expiration date of 2013 for contribution to health benefits for workers who retired after 1989.

Chicago Public Schools (CPS) is the governing body of the school district that contains over 600 public elementary and high schools citywide, including several selective-admission magnet schools. There are eleven selective enrollment high schools in the Chicago Public Schools, designed to meet the needs of Chicago's most academically advanced students. These schools offer a rigorous curriculum with mainly honors and Advanced Placement (AP) courses. Walter Payton College Prep High School is ranked number one in the city of Chicago and the state of Illinois. Northside College Preparatory High School is ranked second, Jones College Prep is third, and the oldest magnet school in the city, Whitney M. Young Magnet High School, which was opened in 1975, is ranked fourth. The magnet school with the largest enrollment is Lane Technical College Prep High School. Lane is one of the oldest schools in Chicago and in 2012 was designated a National Blue Ribbon School by the U.S. Department of Education.

Chicago high school rankings are determined by the average test scores on state achievement tests. The district, with an enrollment exceeding 400,545 students (2013–2014 20th Day Enrollment), is the third-largest in the U.S. On September 10, 2012, teachers for the Chicago Teachers Union went on strike for the first time since 1987 over pay, resources and other issues. According to data compiled in 2014, Chicago's "choice system", where students who test or apply and may attend one of a number of public high schools (there are about 130), sorts students of different achievement levels into different schools (high performing, middle performing, and low performing schools).

Chicago has a network of Lutheran schools, and several private schools are run by other denominations and faiths, such as the Ida Crown Jewish Academy in West Ridge. Several private schools are completely secular, such as the Latin School of Chicago in the Near North Side neighborhood, the University of Chicago Laboratory Schools in Hyde Park, the British School of Chicago and the Francis W. Parker School in Lincoln Park, the Lycée Français de Chicago in Uptown, the Feltre School in River North and the Morgan Park Academy. There are also the private Chicago Academy for the Arts, a high school focused on six different categories of the arts and the public Chicago High School for the Arts, a high school focused on five categories (visual arts, theatre, musical theatre, dance, and music) of the arts.

The Roman Catholic Archdiocese of Chicago operates Catholic schools, that include Jesuit preparatory schools and others including St. Rita of Cascia High School, De La Salle Institute, Josephinum Academy, DePaul College Prep, Cristo Rey Jesuit High School, Brother Rice High School, St. Ignatius College Preparatory School, Mount Carmel High School, Queen of Peace High School, Mother McAuley Liberal Arts High School, Marist High School, St. Patrick High School and Resurrection High School.

The Chicago Public Library system operates 79 public libraries, including the central library, two regional libraries, and numerous branches distributed throughout the city.

Since the 1850s, Chicago has been a world center of higher education and research with several universities. These institutions consistently rank among the top "National Universities" in the United States, as determined by "U.S. News & World Report". Highly regarded universities in Chicago are: the University of Chicago; Illinois Institute of Technology; Loyola University Chicago; DePaul University; Columbia College Chicago and University of Illinois at Chicago. Other notable schools include: Chicago State University; the School of the Art Institute of Chicago, the Illinois Institute of Art – Chicago; East–West University; National Louis University; North Park University; Northeastern Illinois University; Robert Morris University Illinois; Roosevelt University; Saint Xavier University; Rush University; and Shimer College.

William Rainey Harper, the first president of the University of Chicago, was instrumental in the creation of the junior college concept, establishing nearby Joliet Junior College as the first in the nation in 1901. His legacy continues with the multiple community colleges in the Chicago proper, including the seven City Colleges of Chicago: Richard J. Daley College, Kennedy–King College, Malcolm X College, Olive–Harvey College, Truman College, Harold Washington College and Wilbur Wright College, in addition to the privately held MacCormac College.

Chicago also has a high concentration of post-baccalaureate institutions, graduate schools, seminaries, and theological schools, such as the Adler School of Professional Psychology, The Chicago School of Professional Psychology, the Erikson Institute, The Institute for Clinical Social Work, the Lutheran School of Theology at Chicago, the Catholic Theological Union, the Moody Bible Institute, the John Marshall Law School and the University of Chicago Divinity School.

The Chicago metropolitan area is the third-largest media market in North America, after New York City and Los Angeles and a major media hub. Each of the big four U.S. television networks, CBS, ABC, NBC and Fox, directly owns and operates a high-definition television station in Chicago (WBBM 2, WLS 7, WMAQ 5 and WFLD 32, respectively). Former CW affiliate WGN-TV 9, which is owned by the Tribune Media, is carried with some programming differences, as "WGN America" on cable and satellite TV nationwide and in parts of the Caribbean.

Chicago has also been the home of several prominent talk shows, including "The Oprah Winfrey Show", "Steve Harvey Show", "The Rosie Show", "The Jerry Springer Show", "The Phil Donahue Show", "The Jenny Jones Show", and more. The city also has one PBS member station (its second: WYCC 20, removed its affiliation with PBS in 2017): WTTW 11, producer of shows such as "Sneak Previews", "The Frugal Gourmet", "Lamb Chop's Play-Along" and "The McLaughlin Group".

, "Windy City Live" is Chicago's only daytime talk show, which is hosted by Val Warner and Ryan Chiaverini at ABC7 Studios with a live weekday audience. Since 1999, "Judge Mathis" also films his syndicated arbitration-based reality court show at the NBC Tower. Beginning in January 2019, "Newsy" began producing 12 of its 14 hours of live news programming per day from its new facility in Chicago.

Two major daily newspapers are published in Chicago: the "Chicago Tribune" and the "Chicago Sun-Times", with the Tribune having the larger circulation. There are also several regional and special-interest newspapers and magazines, such as "Chicago", the "Dziennik Związkowy" ("Polish Daily News"), "Draugas" (the Lithuanian daily newspaper), the "Chicago Reader", the "SouthtownStar", the "Chicago Defender", the "Daily Herald", "Newcity", "StreetWise" and the "Windy City Times". The entertainment and cultural magazine "Time Out Chicago" and "GRAB" magazine are also published in the city, as well as local music magazine "Chicago Innerview". In addition, Chicago is the home of satirical national news outlet, "The Onion", as well as its sister pop-culture publication, "The A.V. Club".

Since the 1980s, many motion pictures have been filmed and/or set in the city such as "The Untouchables", "The Blues Brothers", "The Matrix", "Brewster's Millions", "Ferris Bueller's Day Off", "Sixteen Candles", "Home Alone", "The Fugitive", "I, Robot", "Mean Girls", "Wanted", "Batman Begins", "The Dark Knight",
"Dhoom 3", "", "", "", "Divergent", "", "Sinister 2", "Suicide Squad".

Chicago has also been the setting of a number of television shows, including the situation comedies "Perfect Strangers" and its spinoff "Family Matters", "Married... with Children", "Punky Brewster", "Kenan & Kel", "Still Standing", "The League", "The Bob Newhart Show", and "Shake It Up". The city served as the venue for the medical dramas "ER" and "Chicago Hope", as well as the fantasy drama series "Early Edition" and the 2005–2009 drama "Prison Break". Discovery Channel films two shows in Chicago: "Cook County Jail" and the Chicago version of "Cash Cab". Other notable shows include CBS's "The Good Wife" and "Mike and Molly".

Chicago is currently the setting for Showtime's "Shameless", and NBC's "Chicago Fire", "Chicago P.D." and "Chicago Med". All three Chicago franchise shows are filmed locally throughout Chicago.

Chicago has five 50,000 watt AM radio stations: the CBS Radio-owned WBBM and WSCR; the Tribune Broadcasting-owned WGN; the Cumulus Media-owned WLS; and the ESPN Radio-owned WMVP. Chicago is also home to a number of national radio shows, including "Beyond the Beltway" with Bruce DuMont on Sunday evenings.

Chicago Public Radio produces nationally aired programs such as PRI's "This American Life" and NPR's "Wait Wait...Don't Tell Me!".

In 2005, indie rock artist Sufjan Stevens created a concept album about Illinois titled "Illinois"; many of its songs were about Chicago and its history.

The city was particularly important for the development of the harsh and electronic based music genre known as industrial. Many themes are transgressive and derived from the works of authors such as William S. Burroughs. While the genre was pioneered by Throbbing Gristle in the late 70s, the genre was largely started in the United Kingdom, with the Chicago-based record label Wax Trax! later establishing itself as America's home for the genre. The label first found success with Ministry, with the release of the cold life single, which entered the US Dance charts in 1982. The record label later signed many prominent industrial acts, with the most notable being: My Life with the Thrill Kill Kult, KMFDM, Front Line Assembly and Front 242. Richard Giraldi of the "Chicago Sun-Times" remarked on the significance of the label and wrote, "As important as Chess Records was to blues and soul music, Chicago's Wax Trax imprint was just as significant to the punk rock, new wave and industrial genres."

Chicago is also featured in a few video games, including "Watch Dogs" and "Midtown Madness", a real-life, car-driving simulation game. Chicago is home to NetherRealm Studios, the developers of the Mortal Kombat series.

Chicago is a major transportation hub in the United States. It is an important component in global distribution, as it is the third-largest inter-modal port in the world after Hong Kong and Singapore.

The city of Chicago has a higher than average percentage of households without a car. In 2015, 26.5 percent of Chicago households were without a car, and increased slightly to 27.5 percent in 2016. The national average was 8.7 percent in 2016. Chicago averaged 1.12 cars per household in 2016, compared to a national average of 1.8.

Seven mainline and four auxiliary interstate highways (55, 57, 65 (only in Indiana), 80 (also in Indiana), 88, 90 (also in Indiana), 94 (also in Indiana), 190, 290, 294, and 355) run through Chicago and its suburbs. Segments that link to the city center are named after influential politicians, with three of them named after former U.S. Presidents (Eisenhower, Kennedy, and Reagan) and one named after two-time Democratic candidate Adlai Stevenson.

The Kennedy and Dan Ryan Expressways are the busiest state maintained routes in the entire state of Illinois.

The Regional Transportation Authority (RTA) coordinates the operation of the three service boards: CTA, Metra, and Pace.

Greyhound Lines provides inter-city bus service to and from the city, and Chicago is also the hub for the Midwest network of Megabus (North America).

Amtrak long distance and commuter rail services originate from Union Station. Chicago is one of the largest hubs of passenger rail service in the nation. The services terminate in San Francisco, Washington, D.C., New York City, Indianapolis, New Orleans, Portland, Seattle, Milwaukee, Quincy, St. Louis, Carbondale, Boston, Grand Rapids, Port Huron, Pontiac, Los Angeles, and San Antonio. An attempt was made in the early 20th century to link Chicago with New York City via the Chicago – New York Electric Air Line Railroad. Parts of this were built, but it was never completed.

In July 2013, the bicycle-sharing system Divvy was launched with 750 bikes and 75 docking stations It is operated by Lyft for the Chicago Department of Transportation. As of July 2019, Divvy operated 5800 bicycles at 608 stations, covering almost all of the city, excluding Pullman, Rosedale, Beverly, Belmont Cragin and Edison Park.

In May 2019, The City of Chicago announced its Chicago's Electric Shared Scooter Pilot Program, scheduled to run from June 15 to October 15. The program started on June 15 with 10 different scooter companies, including scooter sharing market leaders Bird, Jump, Lime and Lyft. Each company was allowed to bring 250 electric scooters, although both Bird and Lime claimed that they experienced a higher demand for their scooters. The program ended on October 15, with nearly 800,000 rides taken.

Chicago is the largest hub in the railroad industry. Six of the seven Class I railroads meet in Chicago, with the exception being the Kansas City Southern Railway. , severe freight train congestion caused trains to take as long to get through the Chicago region as it took to get there from the West Coast of the country (about 2 days). According to U.S. Department of Transportation, the volume of imported and exported goods transported via rail to, from, or through Chicago is forecast to increase nearly 150 percent between 2010 and 2040. CREATE, the Chicago Region Environmental and Transportation Efficiency Program, comprises about 70 programs, including crossovers, overpasses and underpasses, that intend to significantly improve the speed of freight movements in the Chicago area.

Chicago is served by O'Hare International Airport, the world's busiest airport measured by airline operations, on the far Northwest Side, and Midway International Airport on the Southwest Side. In 2005, O'Hare was the world's busiest airport by aircraft movements and the second-busiest by total passenger traffic. Both O'Hare and Midway are owned and operated by the City of Chicago. Gary/Chicago International Airport and Chicago Rockford International Airport, located in Gary, Indiana and Rockford, Illinois, respectively, can serve as alternative Chicago area airports, however they do not offer as many commercial flights as O'Hare and Midway. In recent years the state of Illinois has been leaning towards building an entirely new airport in the Illinois suburbs of Chicago. The City of Chicago is the world headquarters for United Airlines, the world's third-largest airline.

The Port of Chicago consists of several major port facilities within the city of Chicago operated by the Illinois International Port District (formerly known as the Chicago Regional Port District). The central element of the Port District, Calumet Harbor, is maintained by the U.S. Army Corps of Engineers.

Electricity for most of northern Illinois is provided by Commonwealth Edison, also known as ComEd. Their service territory borders Iroquois County to the south, the Wisconsin border to the north, the Iowa border to the west and the Indiana border to the east. In northern Illinois, ComEd (a division of Exelon) operates the greatest number of nuclear generating plants in any US state. Because of this, ComEd reports indicate that Chicago receives about 75% of its electricity from nuclear power. Recently, the city began installing wind turbines on government buildings to promote renewable energy.

Natural gas is provided by Peoples Gas, a subsidiary of Integrys Energy Group, which is headquartered in Chicago.

Domestic and industrial waste was once incinerated but it is now landfilled, mainly in the Calumet area. From 1995 to 2008, the city had a blue bag program to divert recyclable refuse from landfills. Because of low participation in the blue bag programs, the city began a pilot program for blue bin recycling like other cities. This proved successful and blue bins were rolled out across the city.

The Illinois Medical District is on the Near West Side. It includes Rush University Medical Center, ranked as the second best hospital in the Chicago metropolitan area by "U.S. News & World Report" for 2014–16, the University of Illinois Medical Center at Chicago, Jesse Brown VA Hospital, and John H. Stroger Jr. Hospital of Cook County, one of the busiest trauma centers in the nation.

Two of the country's premier academic medical centers reside in Chicago, including Northwestern Memorial Hospital and the University of Chicago Medical Center. The Chicago campus of Northwestern University includes the Feinberg School of Medicine; Northwestern Memorial Hospital, which is ranked as the best hospital in the Chicago metropolitan area by "U.S. News & World Report" for 2017–18; the Shirley Ryan AbilityLab (formerly named the Rehabilitation Institute of Chicago), which is ranked the best U.S. rehabilitation hospital by "U.S. News & World Report"; the new Prentice Women's Hospital; and Ann & Robert H. Lurie Children's Hospital of Chicago.

The University of Illinois College of Medicine at UIC is the second largest medical school in the United States (2,600 students including those at campuses in Peoria, Rockford and Urbana–Champaign).

In addition, the Chicago Medical School and Loyola University Chicago's Stritch School of Medicine are located in the suburbs of North Chicago and Maywood, respectively. The Midwestern University Chicago College of Osteopathic Medicine is in Downers Grove.

The American Medical Association, Accreditation Council for Graduate Medical Education, Accreditation Council for Continuing Medical Education, American Osteopathic Association, American Dental Association, Academy of General Dentistry, Academy of Nutrition and Dietetics, American Association of Nurse Anesthetists, American College of Surgeons, American Society for Clinical Pathology, American College of Healthcare Executives, the American Hospital Association and Blue Cross and Blue Shield Association are all based in Chicago.

Chicago has 28 sister cities around the world. Like Chicago, many of them are or were the second-most populous city or second-most influential city of their country, or they are the main city of a country that has had large numbers of immigrants settle in Chicago. These relationships have sought to promote economic, cultural, educational, and other ties.

To celebrate the sister cities, Chicago hosts a yearly festival in Daley Plaza, which features cultural acts and food tastings from the other cities. In addition, the Chicago Sister Cities program hosts a number of delegation and formal exchanges. In some cases, these exchanges have led to further informal collaborations, such as the academic relationship between the Buehler Center on Aging, Health & Society at the Feinberg School of Medicine of Northwestern University and the Institute of Gerontology of Ukraine (originally of the Soviet Union), that was originally established as part of the Chicago-Kiev sister cities program.

Sister cities




</doc>
<doc id="6887" url="https://en.wikipedia.org/wiki?curid=6887" title="Cyrix 6x86">
Cyrix 6x86

The Cyrix 6x86 (codename M1) is a sixth-generation, 32-bit x86 microprocessor designed by Cyrix and manufactured by IBM and SGS-Thomson. It was originally released in 1996.

The 6x86 is superscalar and superpipelined and performs register renaming, speculative execution, out-of-order execution, and data dependency removal. However, it continued to use native x86 execution and ordinary microcode only, like Centaur's Winchip, unlike competitors Intel and AMD which introduced the method of "dynamic" translation to micro-operations with Pentium Pro and K5. The 6x86 is socket-compatible with the Intel P54C Pentium, and was offered in six performance levels: PR 90+, PR 120+, PR 133+, PR 150+, PR 166+ and PR 200+. These performance levels do not map to the clock speed of the chip itself (for example, a PR 133+ ran at 110 MHz, a PR 166+ ran at 133 MHz, etc.).

With regard to internal caches, it has a 16-KB primary cache and a fully associative 256-byte instruction line cache is included alongside the primary cache, which functions as the primary instruction cache.

The 6x86 and 6x86L weren't completely compatible with the Intel P5 Pentium instruction set and is not multi-processor capable. For this reason, the chip identified itself as a 80486 and disabled the CPUID instruction by default. CPUID support could be enabled by first enabling extended CCR registers then setting bit 7 in CCR4. The lack of full P5 Pentium compatibility caused problems with some applications because programmers had begun to use P5 Pentium-specific instructions. Some companies released patches for their products to make them function on the 6x86. 

Compatibility with the Pentium was improved in the 6x86MX, by adding a Time Stamp Counter to support the P5 Pentium's RDTSC instruction. Support for the Pentium Pro's CMOVcc instructions were also added.

Similarly to AMD with their K5 and early K6 processors, Cyrix used a PR rating (Performance Rating) to relate their performance to the Intel P5 Pentium (pre-P55C), as the 6x86's higher per-clock performance relative to a P5 Pentium could be quantified against a higher-clocked Pentium part. For example, a 133 MHz 6x86 will match or outperform a P5 Pentium at 166 MHz, and as a result Cyrix could market the 133 MHz chip as being a P5 Pentium 166's equal. However, the PR rating was not an entirely truthful representation of the 6x86's performance.

While the 6x86's integer performance was significantly higher than P5 Pentium's, its floating point performance was more mediocre—between 2 and 4 times the performance of the 486 FPU per clock cycle (depending on the operation and precision). The FPU in the 6x86 was largely the same circuitry that was developed for Cyrix's earlier high performance 8087/80287/80387-compatible coprocessors, which was very fast for its time—the Cyrix FPU was much faster than the 80387, and even the 80486 FPU. However, it was still considerably slower than the new and completely redesigned P5 Pentium and P6 Pentium Pro-Pentium III FPUs.

During the 6x86's development, the majority of applications (office software as well as games) performed almost entirely integer operations. The designers foresaw that future applications would most likely maintain this instruction focus. So, to optimize the chip's performance for what they believed to be the most likely application of the CPU, the integer execution resources received most of the transistor budget. This would later prove to be a strategic mistake, as the popularity of the P5 Pentium caused many software developers to hand-optimize code in assembly language, to take advantage of the P5 Pentium's tightly pipelined and lower latency FPU. For example, the highly anticipated first person shooter "Quake" used highly optimized assembly code designed almost entirely around the P5 Pentium's FPU. As a result, the P5 Pentium significantly outperformed other CPUs in the game. 

Therefore, despite being very fast clock by clock, the 6x86 and MII were forced to compete at the low-end of the market as AMD K6 and Intel P6 Pentium II were always ahead on clock speed. The 6x86's and MII's old generation "486 class" floating point unit combined with an integer section that was at best on-par with the newer P6 and K6 chips meant that Cyrix could no longer compete in performance.

The "6x86" (codename M1) was released by Cyrix in 1996. The first generation of 6x86 had heat problems. This was primarily caused by their higher heat output than other x86 CPUs of the day and, as such, computer builders sometimes did not equip them with adequate cooling. The CPUs topped out at around 25 W heat output (like the AMD K6), whereas the P5 Pentium produced around 15 W of waste heat at its peak. However, both numbers would be a fraction of the heat generated by many high performance processors, some years later.

The 6x86L (codename M1L) was later released by Cyrix to address heat issues; the "L" standing for "low-power". Improved manufacturing technologies permitted usage of a lower Vcore. Just like the Pentium MMX, the 6x86L required a split powerplane voltage regulator with separate voltages for I/O and CPU core. 

Another release of the 6x86, the 6x86MX, added MMX compatibility along with the EMMI instruction set, improved compatibility with the Pentium and Pentium Pro by adding a Time Stamp Counter and CMOVcc instructions respectively, and quadrupled the primary cache size to 64 KB. The 256-byte instruction line cache can be turned into a scratchpad cache to provide support for multimedia operations. Later revisions of this chip were renamed MII, to better compete with the Pentium II processor. Unfortunately, 6x86MX / MII was late to market, and couldn't scale well in clock speed with the manufacturing processes used at the time.





</doc>
<doc id="6888" url="https://en.wikipedia.org/wiki?curid=6888" title="Colon classification">
Colon classification

Colon classification (CC) is a system of library classification developed by S. R. Ranganathan. It was the first ever faceted (or analytico-synthetic) classification. The first edition was published in 1933. Since then, six more editions have been published. It is especially used in libraries in India.

Its name "colon classification" comes from the use of colons to separate facets in class numbers. However, many other classification schemes, some of which are completely unrelated, also use colons and other punctuation in various functions.

In CC, facets describe "personality" (the most specific subject), matter, energy, space, and time (PMEST). These facets are generally associated with every item in a library, and so form a reasonably universal sorting system.

As an example, the subject "research in the cure of tuberculosis of lungs by x-ray conducted in India in 1950" would be categorized as:

This is summarized in a specific call number:

The colon classification uses 42 main classes that are combined with other letters, numbers and marks in a manner resembling the Library of Congress Classification to sort a publication.

CC uses five primary categories, or facets, to further specify the sorting of a publication. Collectively, they are called "PMEST":

The following are the main classes of CC, with some subclasses, the main method used to sort the subclass using the PMEST scheme and examples showing application of PMEST.

A common example of the colon classification is:






</doc>
