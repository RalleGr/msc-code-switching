<doc id="14604" url="https://en.wikipedia.org/wiki?curid=14604" title="Foreign relations of India">
Foreign relations of India

The Ministry of External Affairs (India) (MEA), also known as the Foreign Ministry, is the government agency responsible for the conduct of foreign relations of India. With the world's third largest military expenditure, largest armed force, fifth largest economy by nominal rates and third largest economy in terms of purchasing power parity, India is a regional power, a nuclear power, a nascent global power and a potential superpower. India has a growing international influence and a prominent voice in global affairs.

India faces serious economic and social issues as a result of centuries of economic exploitation by colonial powers. However, since gaining independence from Britain in 1947, India has become a newly industrialised country, has a history of collaboration with several countries, is a component of the BRICS and a major part of developing world. India was one of the founding members of several international organisations—the United Nations, the Asian Development Bank, New Development BRICS Bank, and G-20—and the founder of the Non-Aligned Movement.

India has also played an important and influential role in other international organisations like East Asia Summit, World Trade Organization, International Monetary Fund (IMF), G8+5 and IBSA Dialogue Forum. India is also a member of the Asian Infrastructure Investment Bank and the Shanghai Cooperation Organisation.

Regionally, India is a part of SAARC and BIMSTEC. India has taken part in several UN peacekeeping missions, and , is the fifth-largest troop contributor. India is currently seeking a permanent seat in the UN Security Council, along with the other G4 nations.

India wields enormous influence in global affairs and can be classified as an emerging superpower.

India's relations with the world have evolved since the British Raj (1857–1947), when the British Empire monopolised external and defence relations. When India gained independence in 1947, few Indians had experience in making or conducting foreign policy. However, the country's oldest political party, the Indian National Congress, had established a small foreign department in 1925 to make overseas contacts and to publicise its independence struggle. From the late 1920s on, Jawaharlal Nehru, who had a long-standing interest in world affairs among independence leaders, formulated the Congress stance on international issues. As Prime Minister from 1947, Nehru articulated India's approach to the world.

India's international influence varied over the years after independence. Indian prestige and moral authority were high in the 1950s and facilitated the acquisition of developmental assistance from both East and West. Although the prestige stemmed from India's nonaligned stance, the nation was unable to prevent Cold War politics from becoming intertwined with interstate relations in South Asia. On the intensely debated Kashmir issue with Pakistan, India lost credibility by rejecting United Nations calls for a plebiscite in the disputed area.

In the 1960s and 1970s India's international position among developed and developing countries faded in the course of wars with China and Pakistan, disputes with other countries in South Asia, and India's attempt to match Pakistan's support from the United States and China by signing the Indo-Soviet Treaty of Friendship and Cooperation in August 1971. Although India obtained substantial Soviet military and economic aid, which helped to strengthen the nation, India's influence was undercut regionally and internationally by the perception that its friendship with the Soviet Union prevented a more forthright condemnation of the Soviet presence in Afghanistan. In the late 1980s, India improved relations with the United States, other developed countries, and China while continuing close ties with the Soviet Union. Relations with its South Asian neighbours, especially Pakistan, Sri Lanka, and Nepal, occupied much of the energies of the Ministry of External Affairs.

Even before independence, the British-controlled Government of India maintained semi-autonomous diplomatic relations. It had colonies (such as the Aden Settlement), who sent and received full missions. India was a founder member of both the League of Nations and the United Nations. After India gained independence from the United Kingdom in 1947, it soon joined the Commonwealth of Nations and strongly supported independence movements in other colonies, like the Indonesian National Revolution. The partition and various territorial disputes, particularly that over Kashmir, would strain its relations with Pakistan for years to come. During the Cold War, India adopted a foreign policy of not aligning itself with any major power bloc. However, India developed close ties with the Soviet Union and received extensive military support from it.

The end of the Cold War significantly affected India's foreign policy, as it did for much of the world. The country now seeks to strengthen its diplomatic and economic ties with the United States, the European Union trading bloc, Japan, Israel, Mexico, and Brazil. India has also forged close ties with the member states of the Association of Southeast Asian Nations, the African Union, the Arab League and Iran.

Though India continues to have a military relationship with Russia, Israel has emerged as India's second largest military partner while India has built a strong strategic partnership with the United States. The foreign policy of Narendra Modi indicated a shift towards focusing on the Asian region and, more broadly, trade deals.

India's foreign policy has always regarded the concept of neighbourhood as one of widening concentric circles, around a central axis of historical and cultural commonalities.

As many as 44 million people of Indian origin live and work abroad and constitute an important link with the mother country. An important role of India's foreign policy has been to ensure their welfare and wellbeing within the framework of the laws of the country where they live.

Jawaharlal Nehru, India's first Prime Minister, promoted a strong personal role for the Prime Minister but a weak institutional structure. Nehru served concurrently as Prime Minister and Minister of External Affairs; he made all major foreign policy decisions himself after consulting with his advisers and then entrusted the conduct of international affairs to senior members of the Indian Foreign Service. He was the main founding fathers of the Panchsheel or the Five Principles of Peaceful Co-existence.

His successors continued to exercise considerable control over India's international dealings, although they generally appointed separate ministers of external affairs.

India's second prime minister, Lal Bahadur Shastri (1964–66), expanded the Prime Minister Office (sometimes called the Prime Minister's Secretariat) and enlarged its powers. By the 1970s, the Office of the Prime Minister had become the de facto coordinator and supraministry of the Indian government. The enhanced role of the office strengthened the prime minister's control over foreign policy making at the expense of the Ministry of External Affairs. Advisers in the office provided channels of information and policy recommendations in addition to those offered by the Ministry of External Affairs. A subordinate part of the office—the Research and Analysis Wing (RAW)—functioned in ways that significantly expanded the information available to the prime minister and his advisers. The RAW gathered intelligence, provided intelligence analysis to the Office of the Prime Minister, and conducted covert operations abroad.

The prime minister's control and reliance on personal advisers in the Office of the Prime Minister was particularly strong under the tenures of Indira Gandhi (1966–77 and 1980–84) and her son, Rajiv (1984–89), who succeeded her, and weaker during the periods of coalition governments. Observers find it difficult to determine whether the locus of decision-making authority on any particular issue lies with the Ministry of External Affairs, the Council of Ministers, the Office of the Prime Minister, or the prime minister himself.

The Prime Minister is however free to appoint advisers and special committees to examine various foreign policy options and areas of interest. In a recent instance, Manmohan Singh appointed K. Subrahmanyam in 2005 to head a special government task force to study 'Global Strategic Developments' over the next decade. The Task Force submitted its conclusions to the Prime Minister in 2006. The report has not yet been released in the public domain.

The Ministry of External Affairs is the Indian government's agency responsible for the foreign relations of India. The Minister of External Affairs holds cabinet rank as a member of the Council of Ministers.

Subrahmanyam Jaishankar is current Minister of External Affairs. The Ministry has a Minister of State V Muraleedharan. The Indian Foreign Secretary is the head of Indian Foreign Service (IFS) and therefore, serves as the head of all Indian (ambassadors) and high commissioners. Harsh Vardhan Shringla is the current Foreign Secretary of India.

In the post Cold War era, a significant aspect of India's foreign policy is the Look East Policy. During the cold war, India's relations with its South East Asian neighbours was not very strong. After the end of the cold war, the government of India particularly realised the importance of redressing this imbalance in India's foreign policy. Consequently, the Narsimha Rao government in the early nineties of the last century unveiled the look east policy. Initially it focused on renewing political and economic contacts with the countries of East and South-East Asia.

At present, under the Look East Policy, the Government of India is giving special emphasis on the economic development of backward north eastern region of India taking advantage of huge market of ASEAN as well as of the energy resources available in some of the member countries of ASEAN like Burma.
Look-east policy was launched in 1991 just after the end of the cold war, following the dissolution of the Soviet Union. After the start of liberalisation, it was a very strategic policy decision taken by the government in the foreign policy. To quote Prime Minister Manmohan Singh "it was also a strategic shift in India's vision of the world and India's place in the evolving global economy".

The policy was given an initial thrust with the then Prime Minister Narasimha Rao visiting China, Japan, South Korea, Vietnam and Singapore and India becoming an important dialogue partner with ASEAN in 1992. Since the beginning of this century, India has given a big push to this policy by becoming a summit level partner of ASEAN (2002) and getting involved in some regional initiatives such as the BIMSTEC and the Ganga–Mekong Cooperation and now becoming a member of the East Asia Summit (EAS) in December 2005.

Since the dissolution of the Soviet Union, India has forged a closer partnership with Western powers.
In the 1990s, India's economic problems and the demise of the bipolar world political system forced India to reassess its foreign policy and adjust its foreign relations. Previous policies proved inadequate to cope with the serious domestic and international problems facing India. The end of the Cold War gutted the core meaning of nonalignment and left Indian foreign policy without significant direction. The hard, pragmatic considerations of the early 1990s were still viewed within the nonaligned framework of the past, but the disintegration of the Soviet Union removed much of India's international leverage, for which relations with Russia and the other post-Soviet states could not compensate. After the dissolution of the Soviet Union, India improved its relations with the United States, Canada, France, Japan and Germany. In 1992, India established formal diplomatic relations with Israel and this relationship grew during the tenures of the Bharatiya Janata Party (BJP) government and the subsequent UPA (United Progressive Alliance) governments.

In the mid-1990s, India attracted the world attention towards the Pakistan-backed terrorism in Kashmir. The Kargil War resulted in a major diplomatic victory for India. The United States and European Union recognised the fact that Pakistani military had illegally infiltrated into Indian territory and pressured Pakistan to withdraw from Kargil. Several anti-India militant groups based in Pakistan were labelled as terrorist groups by the United States and European Union.
In 1998, India tested nuclear weapons for the second time (see Pokhran-II) which resulted in several US, Japanese and European sanctions on India. India's then-defence minister, George Fernandes, said that India's nuclear programme was necessary as it provided a deterrence to potential Chinese nuclear threat. Most of the sanctions imposed on India were removed by 2001.

After September 11 attacks in 2001, Indian intelligence agencies provided the US with significant information on Al-Qaeda and related groups' activities in Pakistan and Afghanistan. India's extensive contribution to the War on Terror, coupled with a surge in its economy, has helped India's diplomatic relations with several countries. Over the past three years, India has held numerous joint military exercises with US and European nations that have resulted in a strengthened US-India and EU-India bilateral relationship. India's bilateral trade with Europe and United States had more than doubled in the five years since 2003.

India has been pushing for reforms in the UN and WTO with mixed results. India's candidature for a permanent seat at the UN Security Council is currently backed by several countries including France, Russia, the United Kingdom, Germany, Japan, Brazil, Australia and UAE. In 2004, the United States signed a nuclear co-operation agreement with India even though the latter is not a part of the Nuclear Non-Proliferation Treaty. The US argued that India's strong nuclear non-proliferation record made it an exception, however this has not persuaded other Nuclear Suppliers Group members to sign similar deals with India. During a state visit to India in November 2010, US president Barack Obama announced US support for India's bid for permanent membership to UN Security Council as well as India's entry to Nuclear Suppliers Group, Wassenaar Arrangement, Australia Group and Missile Technology Control Regime. As of January 2018, India has become member of Wassenaar Arrangement, Australia Group and Missile Technology Control Regime.

India's growing economy, strategic location, mix of friendly and diplomatic foreign policy and large and vibrant diaspora has won it more allies than enemies. India has friendly relations with several countries in the developing world. Though India is not a part of any major military alliance, it has close strategic and military relationship with most of the fellow major powers.

Countries considered India's closest include the Russian Federation, Israel, Afghanistan, France, Bhutan, Bangladesh, and the United States. Russia is the largest supplier of military equipment to India, followed by Israel and France. According to some analysts, Israel is set to overtake Russia as India's largest military and strategic partner. The two countries also collaborate extensively in the sphere of counter-terrorism and space technology. India also enjoys strong military relations with several other countries, including the United Kingdom, the United States, Japan, Singapore, Brazil, South Africa and Italy. In addition, India operates an airbase in Tajikistan, signed a landmark defence accord with Qatar in 2008, and has leased out Assumption Island from Seychelles to build a naval base in 2015.

India has also forged relationships with developing countries, especially South Africa, Brazil, and Mexico. These countries often represent the interests of the developing countries through economic forums such as the G8+5, IBSA and WTO. India was seen as one of the standard bearers of the developing world and claimed to speak for a collection of more than 30 other developing nations at the Doha Development Round. Indian Look East policy has helped it develop greater economic and strategic partnership with Southeast Asian countries, South Korea, Japan, and Taiwan. India also enjoys friendly relations with the Persian Gulf countries and most members of the African Union.

The Foundation for National Security Research in New Delhi published "India's Strategic Partners: A Comparative Assessment" and ranked India's top strategic partners with a score out of 90 points : Russia comes out on top with 62, followed by the United States (58), France (51), UK (41), Germany (37), and Japan (34).

India has signed strategic partnership agreements with more than two dozen countries/supranational entities listed here in the chronological order of the pacts:

Currently, India is taking steps towards establishing strategic partnerships with Canada and Argentina. Although India has not signed any formal strategic partnership agreements with Bhutan and Qatar, its foreign ministry often describes relations with these countries as 'strategic'.

Certain aspects of India's relations within the subcontinent are conducted through the South Asian Association for Regional Cooperation (SAARC). Other than India, its members are Afghanistan, Bangladesh, Bhutan, Maldives, Nepal, Pakistan and Sri Lanka. Established in 1985, SAARC encourages co-operation in agriculture, rural development, science and technology, culture, health, population control, narcotics control and anti-terrorism.

SAARC has intentionally stressed these "core issues" and avoided more divisive political issues, although political dialogue is often conducted on the margins of SAARC meetings. In 1993, India and its SAARC partners signed an agreement to gradually lower tariffs within the region. Forward movement in SAARC has come to a standstill because of the tension between India and Pakistan, and the SAARC Summit originally scheduled for, but not held in, November 1999 has not been rescheduled. The Fourteenth SAARC Summit was held during 3–4 April 2007 in New Delhi.

Recent SAARC summit that was scheduled to be held in Islamabad was postponed recently due to terrorist acts particularly Uri attack.

Bilateral relations between India and Afghanistan have been traditionally strong and friendly. While India was the only South Asian country to recognise the Soviet-backed Democratic Republic of Afghanistan in the 1980s, its relations were diminished during the Afghan civil wars and the rule of the Islamist Taliban in the 1990s. India aided the overthrow of the Taliban and became the largest regional provider of humanitarian and reconstruction aid.

The new democratically elected Afghan government strengthened its ties with India in wake of persisting tensions and problems with Pakistan, which is continuing to shelter and support the Taliban. India pursues a policy of close co-operation to bolster its standing as a regional power and contain its rival Pakistan, which it maintains is supporting Islamic militants in Kashmir and other parts of India. India is the largest regional investor in Afghanistan, having committed more than US$2.2 billion for reconstruction purposes.

India was the second country to recognise Bangladesh as a separate and independent state, doing so on 6 December 1971. India fought alongside the Bangladeshis to liberate Bangladesh from West Pakistan in 1971.
Bangladesh's relationship with India has been difficult in terms of irrigation and land border disputes post 1976. However, India has enjoyed favourable relationship with Bangladesh during governments formed by the Awami League in 1972 and 1996. The recent solutions of land and maritime disputes have taken out irritants in ties.

At the outset India's relations with Bangladesh could not have been stronger because of India's unalloyed support for independence and opposition against Pakistan in 1971. During the independence war, many refugees fled to India. When the struggle of resistance matured in November 1971, India also intervened militarily and may have helped bring international attention to the issue through Indira Gandhi's visit to Washington, D.C. Afterwards India furnished relief and reconstruction aid. India extended recognition to Bangladesh prior to the end of the war in 1971 (the second country to do so after Bhutan) and subsequently lobbied others to follow suit. India also withdrew its military from the land of Bangladesh when Sheikh Mujibur Rahman requested Indira Gandhi to do so during the latter's visit to Dhaka in 1972.

Indo-Bangladesh relations have been somewhat less friendly since the fall of Mujib government in August 1975. over the years over issues such as South Talpatti Island, the Tin Bigha Corridor and access to Nepal, the Farakka Barrage and water sharing, border conflicts near Tripura and the construction of a fence along most of the border which India explains as security provision against migrants, insurgents and terrorists. Many Bangladeshis feel India likes to play "big brother" to smaller neighbours, including Bangladesh. Bilateral relations warmed in 1996, due to a softer Indian foreign policy and the new Awami League Government. A 30-year water-sharing agreement for the Ganges River was signed in December 1996, after an earlier bilateral water-sharing agreement for the Ganges River lapsed in 1988. Both nations also have cooperated on the issue of flood warning and preparedness. The Bangladesh Government and tribal insurgents signed a peace accord in December 1997, which allowed for the return of tribal refugees who had fled into India, beginning in 1986, to escape violence caused by an insurgency in their homeland in the Chittagong Hill Tracts. The Bangladesh Army maintains a very strong presence in the area to this day. The army is increasingly concerned about a growing problem of cultivation of illegal drugs.

There are also small pieces of land along the border region that Bangladesh is diplomatically trying to reclaim. Padua, part of Sylhet Division before 1971, has been under Indian control since the war in 1971. This small strip of land was re-occupied by the BDR in 2001, but later given back to India after Bangladesh government decided to solve the problem through diplomatic negotiations. The Indian New Moore island no longer exists, but Bangladesh repeatedly claims it to be part of the Satkhira district of Bangladesh.

In recent years India has increasingly complained that Bangladesh does not secure its border properly. It fears an increasing flow of poor Bangladeshis and it accuses Bangladesh of harbouring Indian separatist groups like ULFA and alleged terrorist groups. The Bangladesh government has refused to accept these allegations. India estimates that over 20 million Bangladeshis are living illegally in India. One Bangladeshi official responded that "there is not a single Bangladeshi migrant in India". Since 2002, India has been constructing an India – Bangladesh Fence along much of the 2500 mile border. The failure to resolve migration disputes bears a human cost for illegal migrants, such as imprisonment and health risks (namely HIV/AIDS).

India's prime minister Narendra Modi and his Bangladeshi counterpart Sheikh Hasina have completed a landmark deal redrawing their messy shared border and there by solving disputes between India and Bangladesh. Bangladesh has also given India transit route to travel through Bangladesh to its North East states. India and Bangladesh also have free trade agreement on 7 June 2015.

Both countries solved its border dispute on 6 June 2015.

To connect Kolkata with Tripura via Bangladesh through railway, the Union Government on 10 February 2016 sanctioned about 580 crore rupees. The project that is expected to be completed by 2017 will pass through Bangladesh.

The Agartala-Akhaura rail-link between Indian Railway and Bangladesh Railway will reduce the current 1700 km road distance between Kolkata to Agartala via Siliguri to just 350-kilometer by railway.

The project ranks high on Prime Minister's 'Act East’ Policy, and is expected to increase connectivity and boost trade between India and Bangladesh.

Historically, there have been close ties with India. Both countries signed a friendship treaty in 1949, where India would assist Bhutan in foreign relations. On 8 February 2007, the Indo-Bhutan Friendship Treaty was substantially revised under the Bhutanese King, Jigme Khesar Namgyel Wangchuck. Whereas in the Treaty of 1949 Article 2 read as "The Government of India undertakes to exercise no interference in the internal administration of Bhutan. On its part the Government of Bhutan agrees to be guided by the advice of the Government of India in regard to its external relations."

In the revised treaty it now reads as, "In keeping with the abiding ties of close friendship and cooperation between Bhutan and India, the Government of the Kingdom of Bhutan and the Government of the Republic of India shall cooperate closely with each other on issues relating to their national interests. Neither government shall allow the use of its territory for activities harmful to the national security and interest of the other". The revised treaty also includes in it the preamble "Reaffirming their respect for each other's independence, sovereignty and territorial integrity", an element that was absent in the earlier version. The Indo-Bhutan Friendship Treaty of 2007 strengthens Bhutan's status as an independent and sovereign nation.

India continues to be the largest trade and development partner of Bhutan. Planned development efforts in Bhutan began in the early 1960s. The First Five Year Plan (FYP) of Bhutan was launched in 1961. Since then, India has been extending financial assistance to Bhutan's FYPs. The 10th FYP ended in June 2013. India's overall assistance to the 10th FYP was a little over Rs. 5000 crores, excluding grants for hydropower projects. India has committed Rs. 4500 crores for Bhutan's 11th FYP along with Rs. 500 crores as an Economic Stimulus Package.

The hydropower sector is one of the main pillars of bilateral co-operation, exemplifying mutually beneficial synergy by providing clean energy to India and exports revenue to Bhutan (power contributes 14% to the Bhutanese GDP, comprising about 35% of Bhutan's total exports). Three hydroelectric projects (HEPs) totalling 1416 MW, (336 MW Chukha HEP, the 60 MW Kurichu HEP, and the 1020 MW Tala HEP), are already exporting electricity to India. In 2008 the two governments identified ten more projects for development with a total generation capacity of 10,000 MW. Of these, three projects totalling 2940 MW (1200 MW Punatsangchu-I, 1020 MW Punatsangchu-II and 720 MW Mangdechu HEPs) are under construction and are scheduled to be commissioned in the last quarter of 2017–2018. Out of the remaining 7 HEPs, 4 projects totalling 2120 MW (600 MW Kholongchhu, 180 MW Bunakha, 570 MW Wangchu and 770 MW Chamkarchu) will be constructed under Joint Venture model, for which a Framework Inter-Governmental Agreement was signed between both governments in 2014. Of these 4 JV-model projects, pre-construction activities for Kholongchhu HEP have commenced. Tata Power is also building a hydro-electric dam in Bhutan.

India established diplomatic relations after Burma's independence from Great Britain in 1948. For many years, Indo-Burmese relations were strong due to cultural links, flourishing commerce, common interests in regional affairs and the presence of a significant Indian community in Burma. India provided considerable support when Burma struggled with regional insurgencies. However, the overthrow of the democratic government by the Military of Burma led to strains in ties. Along with much of the world, India condemned the suppression of democracy and Burma ordered the expulsion of the Burmese Indian community, increasing its own isolation from the world. Only China maintained close links with Burma while India supported the pro-democracy movement.

However, due to geo-political concerns, India revived its relations and recognised the military junta ruling Burma in 1993, overcoming strains over drug trafficking, the suppression of democracy and the rule of the military junta in Burma. Burma is situated to the south of the states of Mizoram, Manipur, Nagaland and Arunachal Pradesh in Northeast India. and the proximity of the People's Republic of China gives strategic importance to Indo-Burmese relations. The Indo-Burmese border stretches over 1,600 kilometres and some insurgents in North-east India seek refuge in Burma. Consequently, India has been keen on increasing military co-operation with Burma in its counter-insurgency activities. In 2001, the Indian Army completed the construction of a major road along its border with Burma. India has also been building major roads, highways, ports and pipelines within Burma in an attempt to increase its strategic influence in the region and also to counter China's growing strides in the Indochina peninsula. Indian companies have also sought active participation in oil and natural gas exploration in Burma. In February 2007, India announced a plan to develop the Sittwe port, which would enable ocean access from Indian Northeastern states like Mizoram, via the Kaladan River.

India is a major customer of Burmese oil and gas. In 2007, Indian exports to Burma totalled US$185 million, while its imports from Burma were valued at around US$810 million, consisting mostly of oil and gas. India has granted US$100 million credit to fund highway infrastructure projects in Burma, while US$57 million has been offered to upgrade Burmese railways. A further US$27 million in grants has been pledged for road and rail projects. India is one of the few countries that has provided military assistance to the Burmese junta. However, there has been increasing pressure on India to cut some of its military supplies to Burma. Relations between the two remain close which was evident in the aftermath of Cyclone Nargis, when India was one of the few countries whose relief and rescue aid proposals were accepted by Burma's ruling junta.

Both India and the PRC maintain embassies in Rangoon and consulate-generals in Mandalay.

Despite lingering suspicions remaining from the 1962 Sino-Indian War, the 1967 Nathu La and Cho La incidents, and continuing boundary disputes over Aksai Chin and Arunachal Pradesh, Sino-Indian relations have improved gradually since 1988. Both countries have sought to reduce tensions along the frontier, expand trade and cultural ties, and normalise relations.

A series of high-level visits between the two nations have helped improve relations. In December 1996, PRC President Jiang Zemin visited India during a tour of South Asia. While in New Delhi, he signed with the Indian Prime Minister a series of confidence-building measures for the disputed borders. Sino-Indian relations suffered a brief setback in May 1998 when the Indian Defence minister justified the country's nuclear tests by citing potential threats from the PRC. However, in June 1999, during the Kargil crisis, then-External Affairs Minister Jaswant Singh visited Beijing and stated that India did not consider China a threat. By 2001, relations between India and the PRC were on the mend, and the two sides handled the move from Tibet to India of the 17th Karmapa in January 2000 with delicacy and tact. In 2003, India formally recognised Tibet as a part of China, and China recognised Sikkim as a formal part of India in 2004.

Since 2004, the economic rise of both China and India has also helped forge closer relations between the two. Sino-Indian trade reached US$65.47 billion in 2013–14, making China the single largest trading partner of India. The increasing economic reliance between India and China has also bought the two nations closer politically, with both India and China eager to resolve their boundary dispute. They have also collaborated on several issues ranging from WTO's Doha round in 2008 to regional free trade agreement. Similar to Indo-US nuclear deal, India and China have also agreed to co-operate in the field of civilian nuclear energy. However, China's economic interests have clashed with those of India. Both the countries are the largest Asian investors in Africa and have competed for control over its large natural resources.

India enjoys a considerable influence over Maldives' foreign policy and provides extensive security co-operation especially after the Operation Cactus in 1988 during which India repelled Tamil mercenaries who invaded the country.

As a founder member in 1985 of the South Asian Association for Regional Cooperation, SAARC, which brings together Afghanistan, Bangladesh, Bhutan, India, Maldives, Nepal, Pakistan and Sri Lanka, the country plays a very active role in SAARC. The Maldives has taken the lead in calling for a South Asian Free Trade Agreement, the formulation of a Social Charter, the initiation of informal political consultations in SAARC forums, the lobbying for greater action on environmental issues, the proposal of numerous human rights measures such as the regional convention on child rights and for setting up a SAARC Human Rights Resource Centre. The Maldives is also an advocate of greater international profile for SAARC such as through formulating common positions at the UN.

India is starting the process to bring the island country into India's security grid. The move comes after the moderate Islamic nation approached New Delhi earlier this year over fears that one of its island resorts could be taken over by terrorists given its lack of military assets and surveillance capabilities.
India also signed an agreement with the Maldives in 2011 which is centred around the following:

Relations between India and Nepal are close yet fraught with difficulties stemming from border disputes, geography, economics, the problems inherent in big power-small power relations, and common ethnic and linguistic identities that overlap the two countries' borders. In 1950 New Delhi and Kathmandu initiated their intertwined relationship with the Treaty of Peace and Friendship and accompanying secret letters that defined security relations between the two countries, and an agreement governing both bilateral trade and trade transiting Indian soil. The 1950 treaty and letters stated that "neither government shall tolerate any threat to the security of the other by a foreign aggressor" and obligated both sides "to inform each other of any serious friction or misunderstanding with any neighboring state likely to cause any breach in the friendly relations subsisting between the two governments", and also granted the Indian and Nepali citizens right to get involved in any economic activity such as work and business related activity in each other's territory. These accords cemented a "special relationship" between India and Nepal that granted Nepalese in India the same economic and educational opportunities as Indian citizens.

Relations between India and Nepal reached its lowest during 1989 when India imposed a 13-month-long economic blockade of Nepal. Indian PM Narendra Modi visited Nepal in 2014, the first by an Indian PM in nearly 17 years.

In 2015, a blockade of the India-Nepal border has effected relations. The blockade is led by ethnic communities angered by Nepal's recently promulgated new constitution. However, the Nepalese government accuses India of deliberately worsening the embargo, but India denies this.

Despite historical, cultural and ethnic links between them, relations between India and Pakistan have been plagued by years of mistrust and suspicion ever since the partition of India in 1947. The principal source of contention between India and its western neighbour has been the Kashmir conflict. After an invasion by Pashtun tribesmen and Pakistani paramilitary forces, the Hindu Maharaja of the Dogra Kingdom of Jammu and Kashmir, Hari Singh, and its Muslim Prime Minister, Sheikh Abdullah, signed an Instrument of Accession with New Delhi. The First Kashmir War started after the Indian Army entered Srinagar, the capital of the state, to secure the area from the invading forces. The war ended in December 1948 with the Line of Control dividing the erstwhile princely state into territories administered by Pakistan (northern and western areas) and India (southern, central and northeastern areas). Pakistan contested the legality of the Instrument of Accession since the Dogra Kingdom has signed a standstill agreement with it. The Indo-Pakistani War of 1965 started following the failure of Pakistan's Operation Gibraltar, which was designed to infiltrate forces into Jammu and Kashmir to precipitate an insurgency against rule by India. The five-week war caused thousands of casualties on both sides. It ended in a United Nations (UN) mandated ceasefire and the subsequent issuance of the Tashkent Declaration.
India and Pakistan went to war again in 1971, this time the conflict being over East Pakistan. The large-scale atrocities committed there by the Pakistan army led to millions of Bengali refugees pouring over into India. India, along with the Mukti Bahini, defeated Pakistan and the Pakistani forces surrendered on the eastern front. The war resulted in the creation of Bangladesh.

In 1998, India carried out the Pokhran-II nuclear tests which was followed by Pakistan's Chagai-I tests. Following the Lahore Declaration in February 1999, relations briefly improved. A few months later, however, Pakistani paramilitary forces and Pakistan Army, infiltrated in large numbers into the Kargil district of Indian Kashmir. This initiated the Kargil War after India moved in thousands of troops to successfully flush out the infiltrators. Although the conflict did not result in a full-scale war between India and Pakistan, relations between the two reached all-time low which worsened even further following the involvement of Pakistan-based terrorists in the hijacking of the Indian Airlines Flight 814 in December 1999. Attempts to normalise relations, such as the Agra summit held in July 2001, failed. An attack on the Indian Parliament in December 2001, which was blamed on Pakistan, which had condemned the attack caused a military standoff between the two countries which lasted for nearly a year raising fears of a nuclear warfare. However, a peace process, initiated in 2003, led to improved relations in the following years.

Since the initiation of the peace process, several confidence-building-measures (CBMs) between India and Pakistan have taken shape. The Samjhauta Express and Delhi–Lahore Bus service are two of these successful measures which have played a crucial role in expanding people-to-people contact between the two countries. The initiation of Srinagar–Muzaffarabad Bus service in 2005 and opening of a historic trade route across the Line of Control in 2008 further reflects increasing eagerness between the two sides to improve relations. Although bilateral trade between India and Pakistan was a modest US$1.7 billion in March 2007, it is expected to cross US$10 billion by 2010. After the 2005 Kashmir earthquake, India sent aid to affected areas in Pakistani Kashmir and Punjab as well as Indian Kashmir.

The 2008 Mumbai attacks seriously undermined the relations between the two countries. India alleged Pakistan of harbouring militants on their soil, while Pakistan vehemently denies such claims.

A new chapter started in India Pakistan relation when a new NDA government took charge in Delhi after victory in 2014 election and invited SAARC members' leaders in oath taking ceremony. Subsequently visit of Indian Prime Minister on 25 December informally to wish Pakistani Prime minister Nawaj Sharif on his Birth Day and participate in his daughter's wedding. It was hoped that the relation between the neighbor will improve but attack on Indian army camp by Pakistani infiltrators on 18 September 2016 and subsequent surgical strike by India aggravated the already strained relation between the nations.

A SAARC summit scheduled in Islamabad was called off because of after boycott by India and other SAARC member's subsequently.

The relation took a further nosedive after another attack on CRPF on February 2019 by a terrorist associated with the Pakistan based Terror Organisation, Jaish-e-Mohammed, when the terrorist rammed his vehicle packed with explosive against a bus carrying CRPF jawans in Pulwama, Kashmir, killing 40. India blamed Pakistan which was denied by the Pakistani establishment.

Bilateral relations between Sri Lanka and India have been generally friendly, but were affected by the Sri Lankan Civil War and by the failure of Indian intervention during the civil war as well as India's support for Tamil Tiger militants. India is Sri Lanka's only neighbour, separated by the Palk Strait; both nations occupy a strategic position in South Asia and have sought to build a common security umbrella in the Indian Ocean.

India-Sri Lanka relations have undergone a qualitative and quantitative transformation in the recent past. Political relations are close, trade and investments have increased dramatically, infrastructural linkages are constantly being augmented, defence collaboration has increased and there is a general, broad-based improvement across all sectors of bilateral co-operation. India was the first country to respond to Sri Lanka's request for assistance after the tsunami in December 2004. In July 2006, India evacuated 430 Sri Lankan nationals from Lebanon, first to Cyprus by Indian Navy ships and then to Delhi and Colombo by special Air India flights.

There exists a broad consensus within the Sri Lankan polity on the primacy of India in Sri Lanka's external relations matrix. Both the major political parties in Sri Lanka, the Sri Lanka Freedom Party and the United Nationalist Party have contributed to the rapid development of bilateral relations in the last ten years. Sri Lanka has supported India's candidature to the permanent membership of the UN Security Council.

India & Australia are both Commonwealth members. Sporting and cultural ties are significant. Australian cricketers often undertake large commercial ventures in India, enhanced with the IPL, and, to a lesser degree, the ICL. Bollywood productions enjoy a large market in Australia. In 2007, PM John Howard visited Mumbai and its entertainment industry, in efforts to increase Tourism in India to Australia.

There are ongoing strategic attempts to form an "Asian NATO" with India, Japan, the US and Australia through the Quadrilateral Security Dialogue. During the first decade of the 21st century, the deepening of strategic relations between the two nations was prevented by a range of policy disagreements, such as India's refusal to sign the NPT and Australia's consequent refusal to provide India with uranium. Australia's parliament later allowed for the sale of uranium to India, following changes in government. Closer strategic cooperation between India, Japan, the United States and Australia also began during the second half of the 2010s, which some analysts attributed to a desire to balance Chinese initiatives in the Indo-Pacific region.

Brunei has a high commission in New Delhi, and India has a high commission in Bandar Seri Begawan. Both countries are full members of the Commonwealth of Nations.

Fiji's relationship with the Republic of India is often seen by observers against the backdrop of the sometimes tense relations between its indigenous people and the 44 percent of the population who are of Indian descent. India has used its influence in international forums such as the Commonwealth of Nations and United Nations on behalf of ethnic Indians in Fiji, lobbying for sanctions against Fiji in the wake of the 1987 coups and the 2000 coup, both of which removed governments, one dominated and one led, by Indo-Fijians.

The ties between Indonesia and India date back to the times of the Ramayana, "Yawadvipa" (Java) is mentioned in India's earliest epic, the Ramayana. Sugriva, the chief of Rama's army dispatched his men to Yawadvipa, the island of Java, in search of Sita. Indonesians had absorbed many aspects of Indian culture since almost two millennia ago. The most obvious trace is the large adoption of Sanskrit into Indonesian language. Several of Indonesian toponymy has Indian parallel or origin, such as Madura with Mathura, Serayu and Sarayu rivers, Kalingga from Kalinga Kingdom, and Ngayogyakarta from Ayodhya. Indianised Hindu–Buddhist kingdoms, such as Kalingga, Srivijaya, Medang i Bhumi Mataram, Sunda, Kadiri, Singhasari and Majapahit were the predominant governments in Indonesia, and lasted from 200 to the 1500s, with the last remaining being in Bali. The example of profound Hindu-Buddhist influences in Indonesian history are the 9th century Prambanan and Borobudur temples.

In 1950, the first President of Indonesia – Sukarno called upon the peoples of Indonesia and India to "intensify the cordial relations" that had existed between the two countries "for more than 1000 years" before they had been "disrupted" by colonial powers. In the spring of 1966, the foreign ministers of both countries began speaking again of an era of friendly relations. India had supported Indonesian independence and Nehru had raised the Indonesian question in the United Nations Security Council.

India has an embassy in Jakarta and Indonesia operates an embassy in Delhi. India regards Indonesia as a key member of ASEAN. Today, both countries maintain cooperative and friendly relations. India and Indonesia is one of the few (and also one of the largest) democracies in Asian region which can be projected as a real democracy. Both nations had agreed to establish a strategic partnership. As fellow Asian democracies that share common values, it is natural for both countries to nurture and foster strategic alliance. Indonesia and India are member states of the G-20, the E7, the Non-Aligned Movement, and the United Nations.

India-Japan relations have always been strong. India has culturally influenced Japan through Buddhism. During World War II, the Imperial Japanese Army helped Netaji Subhash Chandra Bose's Indian National Army. Relations have remained warm since India's independence, despite Japan imposing sanctions on India after the 1998 Pokhran-II nuclear tests (the sanctions were removed in 2001). Japanese companies, like Sony, Toyota, and Honda, have manufacturing facilities in India, and with the growth of the Indian economy, India is a big market for Japanese firms. The most prominent Japanese company to have a big investment in India is automobiles giant Suzuki which is in partnership with Indian automobiles company Maruti Suzuki, the largest car manufacturer in India. Honda was also a partner in "Hero Honda", one of the largest motor cycle sellers in the world (the companies split in 2011).
According to Prime Minister Shinzō Abe's "arc of freedom" theory, it is in Japan's interests to develop closer ties with India, world's most populous democracy, while its relations with China remain chilly. To this end, Japan has funded many infrastructure projects in India, most notably in New Delhi's metro subway system.
In December 2006, Prime Minister Manmohan Singh's visit to Japan culminated in the signing of the "Joint Statement Towards Japan-India Strategic and Global Partnership". Indian applicants were welcomed in 2006 to the JET Programme, starting with just one slot available in 2006 and 41 in 2007. Also, in 2007, the Japan Self-Defense Forces took part in a naval exercise in the Indian Ocean, known as Malabar 2007, which also involved the naval forces of India, Australia, Singapore and the United States.

In October 2008, Japan signed an agreement with India under which it would grant the latter a low-interest loan worth US$4.5 billion to construct a high-speed rail line between Delhi and Mumbai. This is the single largest overseas project being financed by Japan and reflects growing economic partnership between the two. India and Japan signed a security co-operation agreement in which both will hold military exercises, police the Indian Ocean and conduct military-to-military exchanges on fighting terrorism, making India one of only three countries, the other two being the United States and Australia, with which Japan has such a security pact. There are 25,000 Indians in Japan as of 2008.

In recent years, India has endeavoured to build relations, with this small Southeast Asian nation. They have strong military relations, and India shall be building an Airforce Academy in Laos.

India has a high commission in Kuala Lumpur, and Malaysia has a high commission in New Delhi. Both countries are full members of the Commonwealth of Nations and the Asian Union. India and Malaysia are also connected by various cultural and historical ties that date back to antiquity. The two countries are on friendly terms with each other and Malaysia harbours a small population of Indian immigrants. Mahathir bin Mohamad the fourth and longest serving Prime Minister of Malaysia is of Indian origin. His father Mohamad Iskandar, is a Malayalee Muslim who migrated from Kerala and his mother Wan Tampawan, is a Malay.

India and Nauru relations have been established since the island nation's independence in 1968. Leaders of both countries have been meeting on the sidelines of some of the international forums of which both the nations are part of such as the United Nations and the Non-Aligned Movement. India is one of the largest donors to the island by improving the education ministry and creating transportation and computer connections for the MPs and the Speaker of the Parliament of Nauru. There were numerous visits by the President of Nauru to the republic for further strengthen in ties and co-operation.

Bilateral relations were established between India and New Zealand in 1952. India has a High Commission in Wellington with an Honorary Consulate in Auckland, while New Zealand has a High Commission in New Delhi along with a Consulate in Mumbai, trade offices in New Delhi and Mumbai and an Honorary Consulate in Chennai.

India–New Zealand relations were cordial but not extensive after Indian independence. More recently, New Zealand has shown interest in extending ties with India due to India's impressive GDP growth.

India and North Korea have growing trade and diplomatic relations. India maintains a fully functioning embassy in Pyongyang, and North Korea has an embassy in New Delhi. India has said that it wants the "reunification" of Korea.

India and Papua New Guinea established relations in 1975, following PNG's independence from Australia. Since 1975, relations have grown between the two nations. India maintains a High Commission in Port Moresby while Papua New Guinea maintains a High Commission in New Delhi In the 2010 Fiscal Year, Trade between the two nations grew to US$239 Million. PNG has sent numerous military officers and students to be trained and educated in India's academies and universities respectively. In recent years, India and PNG have signed an Economic Partnership Agreement, allowing India to further invest into PNG's infrastructure, telecommunications and educational institutions.

Through the Srivijaya and Majapahit empires, Hindu influence has been visible in Philippine history from the 10th to 14th centuries. During the 18th century, there was robust trade between Manila and the Coromandel Coast of Bengal, involving Philippine exports of tobacco, silk, cotton, indigo, sugar cane and coffee.

Formal diplomatic relations between Philippines and India were established on 16 November 1949. The first Philippine envoy to India was the late Foreign Secretary Narciso Ramos. Seven years after India's independence in 1947, the Philippines and India signed a Treaty of Friendship on 11 July 1952 in Manila to strengthen the friendly relations existing between the two countries. Soon after, the Philippine Legation in New Delhi was established and then elevated to an embassy. However, due to foreign policy differences as a result of the bipolar alliance structure of the Cold War, the development of bilateral relations was stunted. It was only in 1976 that relations started to normalise when Aditya Birla, one of India's successful industrialists, met with then President Ferdinand E. Marcos to explore possibilities of setting up joint ventures in the Philippines.

Today, like India, the Philippines is the leading voice-operated business process outsourcing (BPO) source in terms of revenue (US$5.7) and number of people (500,000) employed in the sector. In partnership with the Philippines, India has 20 IT/BPO companies in the Philippines. Philippines-India bilateral trade stood at US$986.60 million in 2009. In 2004 it was US$600 million. Both countries aim to reach US$1 billion by 2010. There are 60,000 Indians living in the Philippines. The Philippines and India signed in October 2007 the Framework for Bilateral Cooperation which created the PH-India JCBC. It has working groups in trade, agriculture, tourism, health, renewable energy and a regular policy consultation mechanism and security dialogue.

Both countries established diplomatic relations in June 1970.

India and Singapore share long-standing cultural, commercial and strategic relations, with Singapore being a part of the "Greater India" cultural and commercial region. More than 300,000 people of Indian Tamil "தமிழ்" origin live in Singapore. Following its independence in 1965, Singapore was concerned with China-backed communist threats as well as domination from Malaysia and Indonesia and sought a close strategic relationship with India, which it saw as a counterbalance to Chinese influence and a partner in achieving regional security. Singapore had always been an important strategic trading post, giving India trade access to Maritime Southeast Asia and the Far East. Although the rival positions of both nations over the Vietnam War and the Cold War caused consternation between India and Singapore, their relationship expanded significantly in the 1990s; Singapore was one of the first to respond to Indian Look East policy of expanding its economic, cultural and strategic ties in Southeast Asia to strengthen its standing as a regional power. Singapore, and especially, the Singaporean Foreign Minister, George Yeo, have taken an interest, in re-establishing the ancient Indian university, Nalanda University.

Singapore is the 8th largest source of investment in India and the largest amongst ASEAN member nations. It is also India's 9th biggest trading partner as of 2005–06. Its cumulative investment in India totals US$3 billion as of 2006 and is expected to rise to US 5 billion by 2010 and US 10 billion by 2015. India's economic liberalisation and its "Look East" policy have led to a major expansion in bilateral trade, which grew from USD 2.2 billion in 2001 to US 9–10 billion in 2006 – a 400% growth in span of five years – and to USD 50 billion by 2010. Singapore accounts for 38% of India's trade with ASEAN member nations and 3.4% of its total foreign trade. India's main exports to
Singapore in 2005 included petroleum, gemstones, jewellery, machinery and its imports from Singapore included electronic goods, organic chemicals and metals. More than half of Singapore's exports to India are basically "re-exports" – items
that had been imported from India.

The cordial relationship between the two countries extends back to 48AD, when Queen Suro, or Princess Heo, travelled from the kingdom of Ayodhya to Korea. According to the Samguk Yusa, the princess had a dream about a heavenly king who was awaiting heaven's anointed ride. After Princess Heo had the dream, she asked her parents, the king and queen, for permission to set out and seek the man, which the king and queen urged with the belief that god orchestrated the whole fate. Upon approval, she set out on a boat, carrying gold, silver, a tea plant, and a stone which calmed the waters. Archeologists discovered a stone with two fish kissing each other, a symbol of the Gaya kingdom that is unique to the Mishra royal family in Ayodhya, India. This royal link provides further evidence that there was an active commercial engagements between India and Korea since the queen's arrival to Korea. Current descendants live in the city of Kimhae as well as abroad in America's state of New Jersey and Kentucky. Many of them became prominent and well-known around the world like President Kim Dae Jung, Prime Minister Jong Pil Kim.

The relations between the countries have been relatively limited, although much progress arose during the three decades. Since the formal establishment of the diplomatic ties between two countries in 1973, several trade agreements have been reached. Trade between the two nations has increased exponentially, exemplified by the $530 million during the fiscal year of 1992–1993, and the $10 billion during 2006–2007. During the 1997 Asian financial crisis, South Korean businesses sought to increase access to the global markets, and began trade investments with India. The last two presidential visits from South Korea to India were in 1996 and 2006, and the embassy works between the two countries are seen as needing improvements. Recently, there have been acknowledgements in the Korean public and political spheres that expanding relations with India should be a major economical and political priority for South Korea. Much of the economic investments of South Korea have been drained into China; however, South Korea is currently the fifth largest source of investment in India. To The Times of India, President Roh Moo-hyun voiced his opinion that co-operation between India's software and Korea's IT industries would bring very efficient and successful outcomes. The two countries agreed to shift their focus to the revision of the visa policies between the two countries, expansion of trade, and establishment of free trade agreement to encourage further investment between the two countries. Korean companies such as LG, Hyundai and Samsung have established manufacturing and service facilities in India, and several Korean construction companies won grants for a portion of the many infrastructural building plans in India, such as the "National Highway Development Project". Tata Motor's purchase of Daewoo Commercial Vehicles at the cost of $102 million highlights the India's investments in Korea, which consist mostly of subcontracting.

India's Indian Look East policy, saw India grow relations with ASEAN countries including Thailand, and Thailand's Look West policy, also saw it grow its relations with India. Both countries are members of BIMSTEC. Indian Prime Ministers Rajiv Gandhi, P.V. Narasimha Rao, Atal Bihari Vajpayee, and Manmohan Singh, have visited Thailand, which were reciprocated by contemporary Thai Prime Ministers Chatichai Choonhavan, Thaksin Sinawatra, and Surayud Chulanont. In 2003, a Free Trade Agreement was signed between the two countries. India, is the 13th largest investor in Thailand. The spheres of trade are in chemicals, pharmaceuticals, textiles, nylon, tyre cord, real estate, rayon fibres, paper grade pulps, steel wires, and rods. However, IT services, and manufacturing, are the main spheres. Through Buddhism, India, has culturally influenced Thailand. The Indian epics, Mahabharata, and Ramayana, are popular and are widely taught in schools as part of the curriculum in Thailand. The example can also be seen in temples around Thailand, where the story of Ramayana and renowned Indian folk stories are depicted on the temple wall. Thailand, has become a big tourist destination for Indians.

India supported Vietnam's independence from France, opposed US involvement in the Vietnam War and supported unification of Vietnam. India established official diplomatic relations in 1972 and maintained friendly relations, especially in the wake of Vietnam's hostile relations with the People's Republic of China, which had become India's strategic rival.

India granted the "Most favoured nation" status to Vietnam in 1975 and both nations signed a bilateral trade agreement in 1978 and the Bilateral Investment Promotion and Protection Agreement (BIPPA) on 8 March 1997. In 2007, a fresh joint declaration was issued during the state visit of the Prime Minister of Vietnam Nguyen Tan Dung. Bilateral trade has increased rapidly since the liberalisation of the economies of both Vietnam and India. India is the 13th-largest exporter to Vietnam, with exports have grown steadily from US$11.5 million in 1985–86 to USD 395.68 million by 2003. Vietnam's exports to India rose to USD 180 million, including agricultural products, handicrafts, textiles, electronics and other goods. Between 2001 and 2006, the volume of bilateral trade expanded at 20–30% per annum to reach $1 billion by 2006. Continuing the rapid pace of growth, bilateral trade is expected to rise to $2 billion by 2008, two years ahead of the official target. India and Vietnam have also expanded co-operation in information technology, education and collaboration of the respective national space programmes. Direct air links and lax visa regulations have been established to bolster tourism.

India and Vietnam are members of the Mekong–Ganga Cooperation, created to develop to enhance close ties between India and nations of Southeast Asia. Vietnam has supported India's bid to become a permanent member of the United Nations Security Council and join the Indo-Pacific Economic Cooperation (APEC). In the 2003 joint declaration, India and Vietnam envisaged creating an "Arc of Advantage and Prosperity" in Southeast Asia; to this end, Vietnam has backed a more important relationship and role between India and the Association of Southeast Asian Nations (ASEAN) and its negotiation of an Indo–ASEAN free trade agreement. India and Vietnam have also built strategic partnerships, including extensive co-operation on developing nuclear power, enhancing regional security and fighting terrorism, transnational crime and drug trafficking.

India's interaction with ASEAN during the Cold War was very limited. India declined to get associated with ASEAN in the 1960s when full membership was offered even before the grouping was formed.

It is only with the formulation of the Look East policy in the last decade (1992), India had started giving this region due importance in the foreign policy. India became a sectoral dialogue partner with ASEAN in 1992, a full dialogue partner in 1995, a member of the ASEAN Regional Forum (ARF) in 1996, and a summit-level partner (on par with China, Japan and Korea) in 2002.

The first India–ASEAN Business Summit was held at New Delhi in October 2002. The then Prime Minister A. B. Vajpayee addressed this meet and since then this business summit has become an annual feature before the India–ASEAN Summits, as a forum for networking and exchange of business experiences between policy makers and business leaders from ASEAN and India.

Four India-ASEAN Summits, first in 2002 at Phnom Penh (Cambodia), second in 2003 at Bali, Indonesia, third in 2004 at Vientiane, Laos, and the fourth in 2005 at Kuala Lumpur, Malaysia, have taken place.

The following agreements have been entered into with ASEAN:

The following proposals were announced by the Prime Minister at the 4th ASEAN-India Summit:

The ASEAN region has an abundance of natural resources and significant technological skills. These provide a natural base for the integration between ASEAN and India in both trade and investment. The present level of bilateral trade with ASEAN of nearly US$18 billion is reportedly increasing by about 25% per year. India hopes to reach the level of US$30 billion by 2007. India is also improving its relations with the help of other policy decisions like offers of lines of credit, better connectivity through air (open skies policy), rail and road links.

India's commonalities with developing nations in Latin America, especially Brazil and Mexico have continued to grow. India and Brazil continue to work together on the reform of Security Council through the G4 nations while have also increased strategic and economic co-operation through the IBSA Dialogue Forum. The process of finalising Preferential Trade Agreement (PTA) with MERCOSUR (Brazil, Argentina, Uruguay, and Paraguay) is on the itinerary and negotiations are being held with Chile. Brazilian President Luiz Inácio Lula da Silva was the guest of honour at the 2004 Republic Day celebrations in New Delhi.
Both countries have established diplomatic relations and have an Extradition Arrangement.

Formal relations between both the countries were first established in 1949. India has an embassy in Buenos Aires and Argentina has an embassy in New Delhi. The current Indian Ambassador to Argentina (concurrently accredited to Uruguay and Paraguay) is R Viswanathan.
According to the Ministry of External Affairs of the Government of India, "Under the 1968 Visa agreement, (Argentine)fees for transit and tourist visas have been abolished. Under the new visa agreement signed during Argentine Presidential visit in October 2009, it has been agreed that five-year multi-entry business visas would be given free of cost. The Embassy of India in Buenos Aires gives Cafe Con Visa (coffee with visa) to Argentine visitors. The applicants are invited for coffee and visa is given immediately. This has been praised by the Argentine media, public and the Foreign Minister himself."

India and Barbados established diplomatic relations on 30 November 1966 (the date of Barbados' national independence). On that date, the government of India gifted Barbados the throne in Barbados' national House of Assembly. India is represented in Barbados through its embassy in Suriname and an Indian consulate in Holetown, St. James. In 2011–12 the Indian-based firm Era's Lucknow Medical College and Hospital, established the American University of Barbados (AUB), as the island's first Medical School for international students. In 2015 the governments of Barbados and India signed a joint Open Skies Agreement. Today around 3,000 persons from India call Barbados home. Two-thirds are from the India's Surat district of Gujarat known as Suratis. Most of the Suratis are involved in trading. The rest are mainly of Sindhis ancestry.

India has an Honorary Consulate in Belize City and Belize has an Honorary Consulate in New Delhi. Bilateral trade stood at US$45.3 Million in 2014 and has steadily increased since. Belize and India have engaged in dialogue in Central American Integration System (SICA) discussing anti-terrorism, climate change and food security. India signed a Tax Information Exchange Agreement in 2013 with Belize. India also provides Belize US$30 Million as part of its foreign aid commitment to SICA countries. Citizens of Belize are eligible for scholarships in Indian universities under Indian Technical and Economic Cooperation Programme and the Indian Council for Cultural Relations.

The two nations share a close cultural link due to Belize's large East Indian Population, estimated at 4% of the total population.

Relations between Brazil and India has been extended to diverse areas as science and technology, pharmaceuticals and space as both are member nations of BRICS. The two-way trade in 2007 nearly tripled to US$3.12 billion from US$1.2 billion in 2004. India attaches tremendous importance to its relationship with this Latin American giant and hopes to see the areas of co-operation expand in the coming years.

Both countries want the participation of developing countries in the UNSC permanent membership since the underlying philosophy for both of them are: UNSC should be more democratic, legitimate and representative – the G4 is a novel grouping for this realisation.
Brazil and India are deeply committed to IBSA (South-South co-operation) initiatives and attach utmost importance to this trilateral co-operation between the three large, multi-ethnic, multi-racial and multi-religious developing countries, which are bound by the common principle of pluralism and democracy.

Indo-Canadian relations, are the longstanding bilateral relations between India and Canada, which are built upon a "mutual commitment to democracy", "pluralism", and "people-to-people links", according to the government of Canada. In 2004, bilateral trade between India and Canada was at about C$2.45 billion. However, the botched handling of the Air India investigation and the case in general suffered a setback to Indo-Canadian relations. India's Smiling Buddha nuclear test led to connections between the two countries being frozen, with allegations that India broke the terms of the Colombo Plan. Although Jean Chrétien and Roméo LeBlanc both visited India in the late 1990s, relations were again halted after the Pokhran-II tests.

Canada-India relations have been on an upward trajectory since 2005. Governments at all levels, private-sector organisations, academic institutes in two countries, and people-to-people contacts—especially diaspora networks—have contributed through individual and concerted efforts to significant improvements in the bilateral relationship.
The two governments have agreed on important policy frameworks to advance the bilateral relationship. In particular, the Nuclear Cooperation Agreement (signed in June 2010) and the current successful negotiations of the Comprehensive Economic Partnership Agreement (CEPA) constitute a watershed in Canada-India relations.
The two governments have attempted to make up for lost time and are eager to complete CEPA negotiations by 2013 and ensure its ratification by 2014. After conclusion of CEPA, Canada and India must define the areas for their partnership which will depend on their ability to convert common interests into common action and respond effectively for steady co-operation. For example, during "pull-aside" meetings between Prime Minister Manmohan Singh and Stephen Harper at the G-20 summit in Mexico in June 2012, and an earlier meeting in Toronto between External Affairs Minister S. M. Krishna and John Baird, the leaders discussed developing a more comprehensive partnership going beyond food security and including the possibility of tie-ups in the energy sector, mainly hydrocarbon.

Both countries established diplomatic ties on 19 January 1959. Since then the relationship between the two countries has been gradually increasing with more frequent diplomatic visits to promote political, commercial cultural and academic exchanges. Colombia is currently the commercial point of entry into Latin America for Indian companies.

Relations between India and Cuba are relatively warm. Both nations are part of the Non-Aligned Movement. Cuba has repeatedly called for a more "democratic" representation of the United Nations Security Council and supports India's candidacy as a permanent member on a reformed Security Council. Fidel Castro said that "The maturity of India…, its unconditional adherence to the principles which lay at the foundation of the Non-Aligned Movement give us the assurances that under the wise leadership of Indira Gandhi (the former Prime Minister of India), the non-aligned countries will continue advancing in their inalienable role as a bastion for peace, national independence and development..."

India has an embassy in Havana, the capital of Cuba which opened in January 1960. This had particular significance as it symbolised Indian solidarity with the Cuban revolution. India had been one of the first countries in the world to have recognised the new Cuban government after the Cuban Revolution.

Cuba has an embassy in New Delhi, the Indian capital.

Relations between India and Jamaica are generally cordial and close. There are many cultural and political connections inherited from British colonisation, such as membership in the Commonwealth of Nations, parliamentary democracy, the English language and cricket.

Both nations are members of the Non-Aligned Movement, the United Nations and the Commonwealth, and Jamaica supports India's candidacy for permanent membership on a reformed UN Security Council.

During the British era, Indians voluntarily went to jobs in Jamaica and the West Indies. This has created a considerable population of people of Indian origin in Jamaica.
India has a High Commission in Kingston, whilst Jamaica has a consulate in New Delhi and plans to upgrade it to a High Commission soon.

Mexico is a very important and major economic partner of India. Nobel Prize laureate and ambassador to India Octavio Paz wrote is book "In Light of India" which is an analysis of Indian history and culture. Both nations are regional powers and members of the G-20 major economies.

Bilateral relations between India and Nicaragua have been limited to SICA dialogue and visits by Nicaraguan Ministers to India. India maintains an honorary consul general in Nicaragua, concurrently accredited to the Indian embassy in Panama City and Nicaragua used to maintain an embassy in India but was reduced to honorary consulate general in New Delhi. the current Foreign minister Samuel Santos López visited India in 2008 for the SICA-India Foreign ministers' meeting and in 2013 for high-level talks with the then External Affairs minister Salman Khurshid which also expanded bilateral trade with the two countries reaching a total of US$60.12 million during 2012–13.

Bilateral relations between Panama and India have been growing steadily, reflecting the crucial role the Panama Canal plays in global trade and commerce. Moreover, with over 15,000 Indians living in Panama, diplomatic ties have considerably increased over the past decade.

The opening of the expanded Canal in 2016 is expected to provide new prospects for maritime connectivity. In seeking to rapidly strengthen trade relations such the flow of trade triples between the two countries, India is keen to leverage these transit trade facilities in Panama to access the wider market of Latin America. Along with pursuing a free trade agreement, India wants to promote investment in various sectors of Panama's economy, including the banking and maritime industry and the multimodal centre of the Colón Free Trade Zone.

The bilateral relations between the Republic of India and the Paraguay have been traditionally strong due to strong commercial, cultural and strategic co-operation. India is represented in Paraguay through its embassy in Buenos Aires in Argentina. India also has an Honorary Consul-General in Asuncion. Paraguay opened its embassy in India in 2005.

Bilateral relations between the Republic of India and the Republic of Trinidad and Tobago have considerably expanded in recent years with both nations building strategic and commercial ties. Both nations formally established diplomatic relations in 1962.

Both nations were colonised by the British Empire; India supported independence of Trinidad and Tobago from colonial rule and established its diplomatic mission in 1962 – the year that Trinidad and Tobago officially gained independence from British rule. They possess diverse natural and economic resources and are the largest economies in their respective regions. Both are members of the Commonwealth of Nations, the United Nations, G-77 and the Non-Aligned Movement (NAM).

The Republic of India operates a High Commission in Port of Spain, whilst the Republic of Trinidad and Tobago operates a High Commission in New Delhi.

Historically, United States gave very strong support to the Indian independence movement in defiance of the British Empire. Relations between India and the United States were lukewarm following Indian independence, as India took a leading position in the Non-Aligned Movement, and received support from the Soviet Union. The US provided support to India in 1962 during its war with China. For most of the Cold War, the USA tended to have warmer relations with Pakistan, primarily as a way to contain Soviet-friendly India and to use Pakistan to back the Afghan Mujahideen against the Soviet occupation of Afghanistan. An Indo-Soviet Treaty of Friendship and Cooperation, signed in 1971, also positioned India against the USA.

After the Sino-Indian War and the Indo-Pakistani War of 1965, India made considerable changes to its foreign policy. It developed a close relationship with the Soviet Union and started receiving massive military equipment and financial assistance from the USSR. This had an adverse effect on the Indo-US relationship. The United States saw Pakistan as a counterweight to pro-Soviet India and started giving the former military assistance. This created an atmosphere of suspicion between India and the US. The Indo-US relationship suffered a considerable setback when the Soviets took over Afghanistan and India overtly supported the Soviet Union.

Relations between India and the United States came to an all-time low during the early 1970s. Despite reports of atrocities in East Pakistan, and being told, most notably in the "Blood telegram", of genocidal activities being perpetrated by Pakistani forces, US. Secretary of State Henry Kissinger and US President Richard Nixon did nothing to discourage then Pakistani President Yahya Khan and the Pakistan Army. Kissinger was particularly concerned about Soviet expansion into South Asia as a result of a treaty of friendship that had recently been signed between India and the Soviet Union, and sought to demonstrate to the People's Republic of China the value of a tacit alliance with the United States. During the Indo-Pakistani War of 1971, Indian Armed Forces, along with the Mukti Bahini, succeeded in liberating East Pakistan which soon declared independence. Nixon feared that an Indian invasion of West Pakistan would mean total Soviet domination of the region, and that it would seriously undermine the global position of the United States and the regional position of America's new tacit ally, China. To demonstrate to China the "bona fides" of the United States as an ally, and in direct violation of the Congress-imposed sanctions on Pakistan, Nixon sent military supplies to Pakistan, routing them through Jordan and Iran, while also encouraging China to increase its arms supplies to Pakistan.

When Pakistan's defeat in the eastern sector seemed certain, Nixon sent the to the Bay of Bengal, a move deemed by the Indians as a nuclear threat. The "Enterprise" arrived on station on 11 December 1971. On 6 and 13 December, the Soviet Navy dispatched two groups of ships, armed with nuclear missiles, from Vladivostok; they trailed US Task Force 74 into the Indian Ocean from 18 December 1971 until 7 January 1972. The Soviets also sent nuclear submarines to ward off the threat posed by USS "Enterprise" in the Indian Ocean.

Though American efforts had no effect in turning the tide of the war, the incident involving USS "Enterprise" is viewed as the trigger for India's subsequent interest in developing nuclear weapons. American policy towards the end of the war was dictated primarily by a need to restrict the escalation of war on the western sector to prevent the 'dismemberment' of West Pakistan. Years after the war, many American writers criticised the White House policies during the war as being badly flawed and ill-serving the interests of the United States. India carried out nuclear tests a few years later resulting in sanctions being imposed by United States, further drifting the two countries apart. In recent years, Kissinger came under fire for comments made during the Indo-Pakistan War in which he described Indians as "bastards." Kissinger has since expressed his regret over the comments.

Since the end of the Cold War, India-USA relations have improved dramatically. This has largely been fostered by the fact that the United States and India are both democracies and have a large and growing trade relationship. During the Gulf War, the economy of India went through an extremely difficult phase. The Government of India adopted liberalised economic systems. After the break-up of the Soviet Union, India improved diplomatic relations with the members of the NATO particularly Canada, France and Germany. In 1992, India established formal diplomatic relations with Israel.

In 1998, India tested nuclear weapons which resulted in several US, Japanese and European sanctions on India. India's then defence minister, George Fernandes, said that India's nuclear programme was necessary as it provided a deterrence to some potential nuclear threat. Most of the sanctions imposed on India were removed by 2001. India has categorically stated that it will never use weapons first but will defend if attacked.

The economic sanctions imposed by the United States in response to India's nuclear tests in May 1998 appeared, at least initially, to seriously damage Indo-American relations. President Bill Clinton imposed wide-ranging sanctions pursuant to the 1994 Nuclear Proliferation Prevention Act. US sanctions on Indian entities involved in the nuclear industry and opposition to international financial institution loans for non-humanitarian assistance projects in India. The United States encouraged India to sign the Comprehensive Nuclear-Test-Ban Treaty (CTBT) immediately and without condition. The United States also called for restraint in missile and nuclear testing and deployment by both India and Pakistan. The non-proliferation dialogue initiated after the 1998 nuclear tests has bridged many of the gaps in understanding between the countries.

Diplomatic relations between India and Venezuela were established on 1 October 1959. India maintains an embassy in Caracas, while Venezuela maintains an embassy in New Delhi.

There have been several visits by heads of state and government, and other high-level officials between the countries. President Hugo Chávez visited New Delhi on 4–7 March 2005. Chávez met with Indian President APJ Abdul Kalam and Prime Minister Manmohan Singh. The two countries signed six agreements including one to establish a Joint Commission to promote bilateral relations and another on cooperation in the hydrocarbon sector. Foreign Minister Nicolás Maduro visited India to attend the First Meeting of the India-CELAC Troika Foreign Ministers meeting in New Delhi on 7 August 2012.

The Election Commission of India (ECI) and the National Electoral Council (CNE) of Venezuela signed an MoU during a visit by Indian Election Commissioner V S Sampath to Caracas in 2012. Minister of State for Corporate Affairs visited Venezuela to attend the state funeral of President Chavez in March 2013. The President and Prime Minister of India expressed condolences on the death of Chávez. The Rajya Sabha, the upper house of Parliament, observed a minute's silence to mark his death. Ambassador Smita Purushottam represented India at the swearing-in ceremony of Chávez's successor Nicolás Maduro on 19 April 2013.

Citizens of Venezuela are eligible for scholarships under the Indian Technical and Economic Cooperation Programme and the Indian Council for Cultural Relations.

The first contacts between both civilisations date back from 2,500 years ago, during the 5th century BC. In modern times, India recognised Armenia on 26 December 1991.India has an embassy in Yerevan.Since 1999, Armenia has an embassy in New Delhi and 2 honorary consulates Mumbai, and Chennai.
Armenia recognises Jammu and Kashmir to be part of India and not of Pakistan.Armenia supports India's bid for permanent seat in the UNSC.

Austria–India relations refers to the bilateral ties between Austria and India. Indo-Austrian relations were established in May 1949 by the first Prime Minister of India Jawaharlal Nehru and the Chancellor of Austria Leopold Figl. Historically, Indo-Austrian ties have been particularly strong and India intervened in June 1953 in Austria's favour whilst negotiations were going on with Soviet Union about the Austrian State Treaty. There is a fully functioning Indian embassy in Vienna, Austria's capital, which is concurrently accredited to the United Nations offices in the city. Austria is represented in India by its embassy and Trade commission in New Delhi, India's capital, as well as honorary consulates in Mumbai, Kolkata, Chennai and Goa.

Czech-Indian relations were established in 1921 by a consulate in Bombay. The Czech Republic has an embassy in New Delhi. Consulates of Czech Republic in India are in Chennai, Mumbai and Kolkata. India has an embassy in Prague.

Denmark has an embassy in New Delhi, and India has an embassy in Copenhagen.

Tranquebar, a town in the southern Indian state of Tamil Nadu, was a Danish colony in India from 1620 to 1845. It is spelled "Trankebar" or "Tranquebar" in Danish, which comes from the native Tamil, Tarangambadi, meaning "place of the singing waves". It was sold, along with the other Danish settlements in mainland India, most notably Serampore (now in West Bengal), to Great Britain in 1845. The Nicobar Islands were also colonised by Denmark, until sold to the British in 1868, who made them part of their colony of British India.

After Independence in 1947, Indian prime minister Jawaharlal Nehru's visit to Denmark in 1957 laid the foundation for a friendly relationship between India and Denmark that has endured ever since. The bilateral relations between India and Denmark are cordial and friendly, based on synergies in political, economic, academic and research fields. There have been periodic high level visits between the two countries.

Anders Fogh Rasmussen, former Prime Minister of Denmark, accompanied by a large business delegation, paid a state visit to India from 4 to 8 February 2008. He visited Infosys, Biocon and IIM Bangalore in Bangalore and Agra. He launched an 'India Action Plan', which called for strengthening of the political dialogue, strengthening of co-operation in trade and investments, research in science and technology, energy, climate and environment, culture, education, student exchanges and attracting skilled manpower and IT experts to Denmark for short periods. The two countries signed an Agreement for establishment of a Bilateral Joint Commission for Cooperation.

In July 2012, the Government of India decided to scale down its diplomatic ties with Denmark after that country's refusal to appeal in their Supreme Court against a decision of its lower court rejecting the extradition of Purulia arms drop case prime accused Kim Davy a.k.a. Niels Holck. Agitated over Denmark's refusal to act on India's repeated requests to appeal in their apex court to facilitate Davy's extradition to India, government issued a circular directing all senior officials not to meet or entertain any Danish diplomat posted in India.

India's first recognition of Estonia came on 22 September 1921 when the former had just acquired membership in the League of Nations. India re-recognised Estonia on 9 September 1991 and diplomatic relations were established on 2 December of the same year in Helsinki. Neither country has a resident ambassador. Estonia is represented in India by two honorary consulates (in Mumbai and New Delhi). India is represented in Estonia through its embassy in Helsinki (Finland) and through an honorary consulate in Tallinn.

France and India established diplomatic relationships soon after India's independence from the United Kingdom in 1947. France's Indian possessions were returned to India after a treaty of cession was signed by the two countries in May 1956. On 16 August 1962, India and France exchanged the instruments of ratification under which France ceded to India full sovereignty over the territories it held. Pondicherry and the other enclaves of Karaikal, Mahe and Yanam came to be administered as the Union Territory of Puducherry from 1 July 1963.

France, Russia and Israel were the only countries that did not condemn India's decision to go nuclear in 1998. In 2003, France became the largest supplier of nuclear fuel and technology to India and remains a large military and economic trade partner. India's candidacy for permanent membership in the UN Security Council has found very strong support from former French President Nicolas Sarkozy. The Indian Government's decisions to purchase French s worth US$3 billion and 43 Airbus aircraft for Air India worth US$2.5 billion have further cemented the strategic, military and economic co-operation between India and France.

France's decision to ban schoolchildren from wearing of head-dresses and veils had the unintended consequence of affecting Sikh children who have been refused entry in public schools. The Indian Government, citing historic traditions of the Sikh community, has requested French authorities to review the situation so as to not to exclude Sikh children from education.

President Nicolas Sarkozy and François Hollande visited India in January 2008 and 2016 respectively as the Chief Guest of the annual Republic Day parade in New Delhi. France was the first country to sign a nuclear energy co-operation agreement with India; this was done during Prime Minister Singh's visit, following the waiver by the Nuclear Suppliers Group. During the Bastille Day celebrations on 14 July 2009, a detachment of 400 Indian troops marched alongside the French troops and the then Indian Prime Minister Manmohan Singh was the guest of honour.

During the Cold War India maintained diplomatic relations with both West Germany and East Germany. Since the fall of the Berlin Wall, and the reunification of Germany, relations have further improved.

Germany is India's largest trade partner in Europe. Between 2004 and 2013, Indo-German trade grew in volume but dropped in importance. According to Indian Ministry of Commerce MX data: Total trade between India and Germany was $5.5billion (3.8% share of Indian trade and ranked 6) in 2004 and $21.6billion (2.6% share of Indian trade and ranked 9) in 2013. Indian exports to Germany were $2.54billion (3.99% ranked 6) in 2004 and $7.3billion (2.41% ranked 10) in 2013. Indian imports from Germany were $2.92billion (3.73% ranked 6) in 2004 and $14.33billion (2.92% ranked 10) in 2013.

Indo-German ties are transactional. The strategic relationship between Germany and India suffers from sustained anti-Asian sentiment, institutionalized discrimination against minority groups, and xenophobic incidents against Indians in Germany. The 2007 Mügeln mob attack on Indians and the 2015 Leipzig University internship controversy has clouded the predominantly commercial-oriented relationship between the two countries. Stiff competition between foreign manufactured goods within the Indian market has seen machine-tools, automotive parts and medical supplies from German "Mittelstand" ceding ground to high-technology imports manufactured by companies located in ASEAN & BRICS countries. The Volkswagen emissions scandal drew the spotlight to corrupt behaviour in German boardrooms and brought back memories of the HDW bribery scandal surrounding the procurement of s by the Indian Navy. The India-Germany strategic relationship is limited by the insignificance of German geopolitical influence in Asian affairs. Germany has no strategic footprint in Asia. Germany like India is working towards gaining permanent seats in the United Nations Security Council.

In modern time, diplomatic relations between Greece and India were established in May 1950. The new Greek Embassy building in New Delhi was inaugurated on 6 February 2001.

Iceland and India established diplomatic relations in 1972. The Embassy of Iceland in London was accredited to India and the Embassy of India in Oslo, Norway, was accredited to Iceland. However, it was only after 2003 that the two countries began close diplomatic and economic relationships. In 2003, President of Iceland Ólafur Ragnar Grímsson visited India on a diplomatic mission. This was the first visit by an Icelandic President to India. During the visit, Iceland pledged support to New Delhi's candidature for a permanent seat in the United Nation Security Council thus becoming the first Nordic country to do so. This was followed by an official visit of President of India A. P. J. Abdul Kalam to Iceland in May 2005. Following this a new embassy of Iceland was opened in New Delhi on 26 February 2006. Soon, an Indian Navy team visited Iceland on friendly mission. Gunnar Pálsson is the ambassador of Iceland to India. The Embassy's area of accreditation, apart from India includes Bangladesh, Indonesia, the Seychelles, Singapore, Sri Lanka, Malaysia, Maldives, Mauritius and Nepal. India appointed S. Swaminathan as the first resident ambassador to Iceland in March 2008.

Indo-Irish relations picked up steam during the freedom struggles of the respective countries against a common imperial empire in the United Kingdom. Political relations between the two states have largely been based on socio-cultural ties, although political and economic ties have also helped build relations. Indo-Irish relations were greatly strengthened by such luminaries as Pandit Nehru, Éamon de Valera, Rabindranath Tagore, W. B. Yeats, James Joyce, and, above all, Annie Besant. Politically, relations have not been cold or warm. Mutual benefit has led to economic ties that are fruitful for both states. Visits by government leaders have kept relations cordial at regular intervals.

India maintains an embassy in Rome, and a consulate-general in Milan. Italy has an embassy in New Delhi, and consulate-generals in Mumbai and Calcutta.

Indo-Italian relations have historically been cordial. In recent times, their state has mirrored the political fortunes of Sonia Maino-Gandhi, the Italian-born leader of the Indian National Congress and "de facto" leader of the UPA government of Manmohan Singh.

Since 2012 the relationship has been affected by the ongoing Enrica Lexie case: two Indian fishermen were killed on the Indian fishing vessel "St. Antony" as a result of gunshot wounds following a confrontation with the Italian oil tanker "Enrica Lexie" in international waters, off the Kerala coast.

After a period of tensions, in 2017 Italian Prime Minister Paolo Gentiloni visited India and met his Indian counterpart Narendra Modi; they held extensive talks in order to strengthen the political cooperation and to boost the bilateral trade.

There are around 150,000 people of Indian Origins living in Italy. Around 1,000 Italian citizens reside in India, mostly working on behalf of Italian industrial groups.

Relations were established in 1947, following India's independence. Luxembourg operates an Embassy in New Delhi whilst India operates a Consulate General in Luxembourg City. Bilateral Trade stood at US$37 Million in 2014 and trade continues to grow every year. Diplomats from both countries have visited the other several time. In 2019, Luxembourg plans to host the annual Asian Infrastructure Investment Bank and open an economic mission in India.

Both countries established diplomatic relations in March 1993.

India–Netherlands relations refer to foreign relations between India and the Netherlands. India maintains an embassy in The Hague, Netherlands and the Netherlands maintains an embassy in New Delhi and a consulate general in Mumbai. Both countries established diplomatic relations in 1947.

Both countries established diplomatic relations in 1996.

In 2012, Trond Giske met with Minister of Finance Pranab Mukherjee, to save Telenor's investments to put forth Norway's "strong wish" that there must not be a waiting period between the confiscation of telecom licences and the re-sale of those. The leader of Telenor attended the meeting.

Diplomatic ties with Spain started in 1956. The first Spanish embassy was established in Delhi in 1958. India and Spain have had cordial relationship with each other especially after the establishment of democracy in Spain in 1978. Spain has been a main tourist spot for Indians over the years. Many presidents including Prathibha Patil visited Spain.
The royal family of Spain have always liked the humble nature of the Indian government and they have thus paid several visits to India.
There was no direct flight from India to Spain but it all changed in 1986 when Iberain travels started to fly directly from Mumbai to Madrid. However, it was stopped in 22 months. In 2006 this issue of direct flight was reconsidered so as to improve the ties between India and Spain. "Zindagi Na Milegi Dobara" was shot completely in Spain in 2011. The tourism ministry of Spain are using this movie to promote tourism to Spain in India.


India is one of Switzerland's most important partners in Asia. Bilateral and political contacts are constantly developing, and trade and scientific co-operation between the two countries are flourishing. Switzerland was the first country in the World to sign a Friendship treaty with India in 1947.

Diplomatic relations between India and Ukraine were established in January 1992. The Indian Embassy in Kiev was opened in May 1992 and Ukraine opened its mission in New Delhi in February 1993. The Consulate General of India in Odessa functioned from 1962 till its closure in March 1999.

India has a high commission in London and two consulates-general in Birmingham and Edinburgh. The United Kingdom has a high commission in New Delhi and five deputy high commissions in Mumbai, Chennai, Bangalore, Hyderabad and Kolkata. Since 1947, India's relations with the United Kingdom have been through bilateral, as well as through the Commonwealth of Nations framework. Although the Sterling Area no longer exists and the Commonwealth is much more an informal forum, India and the UK still have many enduring links. This is in part due to the significant number of people of Indian origin living in the UK. The large South Asian population in the UK results in steady travel and communication between the two countries. The British Raj allowed for both cultures to imbibe tremendously from the other. The English language and cricket are perhaps the two most evident British exports, whilst in the UK food from the Indian subcontinent are very popular. The United Kingdom's favourite food is often reported to be Indian cuisine, although no official study reports this.

Economically the relationship between Britain and India is also strong. India is the second largest investor in Britain after the US. Britain is also one of the largest investors in India.

Formal bilateral relations between India and the Vatican City have existed since 12 June 1948. An Apostolic Delegation existed in India from 1881. The Holy See has a nunciature in New Delhi whilst India has accredited its embassy in Bern, Switzerland to the Holy See as well. India's Ambassador in Bern has traditionally been accredited to the Holy See.

The connections between the Catholic Church and India can be traced back to the apostle St. Thomas, who, according to tradition, came to India in 52 CE in the 9th century, the patriarch of the Nestorians in Persia sent bishops to India. There is a record of an Indian bishop visiting Rome in the early part of the 12th century.

The diplomatic mission was established as the Apostolic Delegation to the East Indies in 1881, and included Ceylon, and was extended to Malaca in 1889, and then to Burma in 1920, and eventually included Goa in 1923. It was raised to an Internunciature by Pope Pius XII on 12 June 1948 and to a full Apostolic Nunciature by Pope Paul VI on 22 August 1967.

There have been three Papal visits to India. The first Pope to visit India was Pope Paul VI, who visited Mumbai in 1964 to attend the Eucharistic Congress. Pope John Paul II visited India in February 1986 and November 1999. Several Indian dignitaries have, from time to time, called on the Pope in the Vatican. These include Prime Minister Indira Gandhi in 1981 and Prime Minister I. K. Gujral in September 1987. Atal Bihari Vajpayee, Prime Minister, called on the Pope in June
2000 during his official visit to Italy. Vice-President Bhairon Singh Shekhawat represented the country at the funeral of Pope John Paul II.

India was one of the first countries to develop relations with the European Union. The Joint Political Statement of 1993 and the 1994 Co-operation Agreement were the foundational agreements for the bilateral partnership. In 2004, India and European Union became "Strategic Partners". A Joint Action Plan was agreed upon in 2005 and updated in 2008. India-EU Joint Statements was published in 2009 and 2012 following the India-European Union Summits.

India and the European Commission initiated negotiations on a "Broad-based Trade and Investment Agreement" (BTIA) in 2007. Seven rounds of negotiations have been completed without reaching a Free Trade Agreement.

According to the Government of India, trade between India and the EU was $57.25 billion between April and October 2014 and stood at $101.5 billion for the fiscal period of 2014–2015.

The European Union is India's second largest trading bloc, accounting for around 20% of Indian trade (Gulf Cooperation Council is the largest trading bloc with almost $160 billion in total trade). India was the European Union's 8th largest trading partner in 2010. EU-India trade grew from €28.6 billion in 2003 to €72.7 billion in 2013.

France, Germany and UK collectively represent the major part of EU-India trade. Annual trade in commercial services tripled from €5.2billion in 2002 to €17.9 billion in 2010. 
Denmark, Sweden, Finland and the Netherlands are the other more prominent European Union countries who trade with India.

India and the Arab states of the Persian Gulf enjoy strong cultural and economic ties. This is reflected in the fact that more than 50% of the oil consumed by India comes from the Persian Gulf countries and Indian nationals form the largest expatriate community in the Arabian peninsula. The annual remittance by Indian expatriates in the region amounted to US$20 billion in 2007. India is one of the largest trading partners of the CCASG with non-oil trade between India and Dubai alone amounting to US$19 billion in 2007. The Persian Gulf countries have also played an important role in addressing India's energy security concerns, with Saudi Arabia and Kuwait regularly increasing their oil supply to India to meet the country's rising energy demand. In 2005, Kuwait increased its oil exports to India by 10% increasing the net oil trade between the two to US$4.5 billion. In 2008, Qatar decided to invest US$5 billion in India's energy sector.

India has maritime security arrangement in place with Oman and Qatar. In 2008, a landmark defence pact was signed, under which India committed its military assets to protect "Qatar from external threats".
There has been progress in a proposed deep-sea gas pipeline from Qatar, via Oman, to India.

India is a close ally of Bahrain, the Kingdom along with its GCC partners are (according to Indian officials) among the most prominent backers of India's bid for a permanent seat on the UN Security Council, and Bahraini officials have urged India to play a greater role in international affairs. For instance, over concerns about Iran's nuclear programme Bahrain's Crown Prince appealed to India to play an active role in resolving the crisis.

Ties between India and Bahrain go back generations, with many of Bahrain's most prominent figures having close connections: poet and constitutionalist Ebrahim Al-Arrayedh grew up in Bombay, while 17th century Bahraini theologians Sheikh Salih Al-Karzakani and Sheikh Ja'far bin Kamal al-Din were influential figures in the Kingdom of Golkonda and the development of Shia thought in the sub-continent.

Bahraini politicians have sought to enhance these long standing ties, with Parliamentary Speaker Khalifa Al Dhahrani in 2007 leading a delegation of parliamentarians and business leaders to meet the then Indian President Pratibha Patil, the then opposition leader L K Advani, and take part in training and media interviews. Politically, it is easier for Bahrain's politicians to seek training and advice from India than it is from the United States or other western alternative.

Adding further strength to the ties, Sheikh Hamad Bin Isa Al-Khalifa visited India during which MOUs and bilateral deals worth $450 million were approved. India expressed its support for Bahrain's bid for a non-permanent seat in the UNSC in 2026–27.

Modern Egypt-India relations go back to the contacts between Saad Zaghloul and Mohandas Gandhi on the common goals of their respective movements of independence. In 1955, Egypt under Gamal Abdul Nasser and India under Jawaharlal Nehru became the founders of the Non-Aligned Movement. During the 1956 War, Nehru stood supporting Egypt to the point of threatening to withdraw his country from the Commonwealth of Nations. In 1967, following the Arab–Israeli conflict, India supported Egypt and the Arabs. In 1977, New Delhi described the visit of President Anwar al-Sadat to Jerusalem as a "brave" move and considered the peace treaty between Egypt and Israel a primary step on the path of a just settlement of the Middle East problem. Major Egyptian exports to India include raw cotton, raw and manufactured fertilisers, oil and oil products, organic and non-organic chemicals, leather and iron products. Major imports into Egypt from India are cotton yarn, sesame, coffee, herbs, tobacco, lentils, pharmaceutical products and transport equipment. The Egyptian Ministry of Petroleum is also currently negotiating the establishment of a natural gas-operated fertiliser plant with another Indian company. In 2004 the Gas Authority of India Limited, bought 15% of Egypt Nat Gas distribution and marketing company. In 2008 Egyptian investment in India was worth some 750 million dollars, according to the Egyptian ambassador.
After Arab Spring of 2011, with ousting of Hosni Mubarak, Egypt has asked for help of India in conducting nationwide elections.

Independent India and Iran established diplomatic links on 15 March 1950.
After the Iranian Revolution of 1979, Iran withdrew from CENTO and dissociated itself from US-friendly countries, including Pakistan, which automatically meant improved relationship with the Republic of India.

Currently, the two countries have friendly relations in many areas. There are significant trade ties, particularly in crude oil imports into India and diesel exports to Iran. Iran frequently objected to Pakistan's attempts to draft anti-India resolutions at international organisations such as the OIC. India welcomed Iran's inclusion as an observer state in the SAARC regional organisation. Lucknow continues to be a major centre of Shiite culture and Persian study in the subcontinent.

In the 1990s, India and Iran both supported the Northern Alliance in Afghanistan against the Taliban regime. They continue to collaborate in supporting the broad-based anti-Taliban government led by Hamid Karzai and backed by the United States.

However, one complex issue in Indo-Iran relations is the issue of Iran's nuclear programme. In this intricate issue, India tries to make a delicate balance. According to Rejaul Laskar, an Indian expert on international relations, "India's position on Iran's nuclear programme has been consistent, principled and balanced, and makes an endeavour to reconcile Iran's quest for energy security with the international community's concerns on proliferation. So, while India acknowledges and supports Iran's ambitions to achieve energy security and in particular, its quest for peaceful use of nuclear energy, it is also India's principled position that Iran must meet all its obligations under the international law, particularly its obligations under the nuclear Non Proliferation Treaty (NPT) and other such treaties to which it is a signatory"

Following an attack on an Israeli diplomat in India in February 2012, the Delhi Police contended that the Iranian Revolutionary Guard Corps had some involvement in the attack. This was subsequently confirmed in July 2012, after a report by the Delhi Police found evidence that members of Iranian Revolutionary Guard Corps had been involved in the 13 February bomb attack in the capital.

Iraq was one of the few countries in the Middle East with which India established diplomatic relations at the embassy level immediately after its independence in 1947. Both nations signed the "Treaty of Perpetual Peace and Friendship" in 1952 and an agreement of co-operation on cultural affairs in 1954. India was amongst the first to recognise the Ba'ath Party-led government, and Iraq remained neutral during the Indo-Pakistani War of 1965. However, Iraq sided alongside other Persian Gulf states in supporting Pakistan against India during the Indo-Pakistani War of 1971, which saw the creation of Bangladesh. The eight-year-long Iran–Iraq War caused a steep decline in trade and commerce between the two nations.

During the 1991 Persian Gulf War, India remained neutral but permitted refuelling for US aircraft. It opposed UN sanctions on Iraq, but the period of war and Iraq's isolation further diminished India's commercial and diplomatic ties. From 1999 onwards, Iraq and India began to work towards a stronger relationship. Iraq had supported India's right to conduct nuclear tests following its tests of five nuclear weapons on 11 and 13 May 1998. In 2000, the then-Vice-President of Iraq Taha Yassin Ramadan visited India, and on 6 August 2002 President Saddam Hussein conveyed Iraq's "unwavering support" to India over the Kashmir conflict with Pakistan. India and Iraq established joint ministerial committees and trade delegations to promote extensive bilateral co-operation. Although initially disrupted during the 2003 invasion of Iraq, diplomatic and commercial ties between India and the new democratic government of Iraq have since been normalised.

The establishment of Israel at the end of World War II was a complex issue. Based on its own experience during partition, when 14 million people were displaced and an estimated 200,000 to 500,000 people were killed in Punjab Province, India had recommended a single state, as did Iran and Yugoslavia (later to undergo its own genocidal partition). The state could allocate Arab- and Jewish-majority provinces with a goal of preventing partition of historic Palestine and prevent widespread conflict. But, the final UN resolution recommended partition of Mandatory Palestine into Arab and Jewish states based on religious and ethnic majorities. India opposed this in the final vote as it did not agree with the concept of partition on the basis of religion.

Due to the security threat from a US-backed Pakistan and its nuclear programme in the 1980s, Israel and India started a clandestine relationship that involved co-operation between their respective intelligence agencies. Israel shared India's concerns about the growing danger posed by Pakistan and nuclear proliferation to Iran and other Arab states. After the end of the Cold War, formal relations with Israel started improving significantly.

Since the establishment of full diplomatic relations with Israel in 1992, India has improved its relation with the Jewish state. India is regarded as Israel's strongest ally in Asia, and Israel is India's second-largest arms supplier. Since India achieved its independence in 1947, it has supported Palestinian self-determination. India recognised Palestine's statehood following Palestine's declaration on 18 November 1988 and Indo-Palestinian relations were first established in 1974. This has not adversely affected India's improved relations with Israel.

India has entertained the Israeli Prime Minister in a visit in 2003, and Israel has entertained Indian dignitaries such as Finance Minister Jaswant Singh in diplomatic visits. India and Israel collaborate in scientific and technological endeavours. Israel's Minister for Science and Technology has expressed interest in collaborating with the Indian Space Research Organisation (ISRO) towards using satellites to better manage land and other resources. Israel has also expressed interest in participating in ISRO's Chandrayaan Mission involving an unmanned mission to the moon. On 21 January 2008, India successfully launched an Israeli spy satellite into orbit from Sriharikota space station in southern India.

Israel and India share intelligence on terrorist groups. They have developed close defence and security ties since establishing diplomatic relations in 1992. India has bought more than $5 billion worth of Israeli equipment since 2002. In addition, Israel is training Indian military units and in 2008 was discussing an arrangement to give Indian commandos instruction in counter-terrorist tactics and urban warfare. In December 2008, Israel and India signed a memorandum to set up an Indo-Israel Legal Colloquium to facilitate discussions and exchange programmes between judges and jurists of the two countries.

Following the Israeli invasion of Lebanon in 2006, India stated that the Israeli use of force was "disproportionate and excessive."

India and Lebanon enjoy cordial and friendly relations based on many complementarities
such as political system based on parliamentary democracy, non-alignment, human rights,
commitment to a just world order, regional and global peace, liberal market economy and a vibrant
entrepreneurial spirit. India has a peacekeeping force as part of the United Nations Interim Force in Lebanon (UNIFIL). One infantry battalion is deployed in Lebanon and about 900 personnel are stationed in the Eastern part of Southern Lebanon. The force also provided non-patrol aid to citizens.
India and Lebanon have very good relations since the 1950s.

India–Oman relations are foreign relations between India and the Sultanate of Oman. India has an embassy in Muscat, Oman. The Indian consulate was opened in Muscat in February 1955 and five years later it was upgraded to a consulate general and later developed into a full-fledged embassy in 1971. The first Ambassador of India arrived in Muscat in 1973. Oman established its embassy in New Delhi in 1972 and a consulate general in Mumbai in 1976.

$5.6 bn Oman-India energy pipeline plans progressing: Fox Petroleum Group envisions a roughly five-year timeframe for the execution of the pipeline project.

Ajay Kumar, the chairman and managing director of Fox Petroleum, based in New Delhi, which is an associate company of Fox Petroleum FZC in the UAE, said that Mr Modi had "fired the best weapon of economic development and growth". "He has given a red carpet for global players to invest in India," Mr Kumar added. "It will boost all sectors of industry – especially for small-scale manufacturing units and heavy industries too."

After India achieved its independence in 1947, the country has moved to support Palestinian self-determination following the partition of British India. In the light of a religious partition between India and Pakistan, the impetus to boost ties with Muslim states around the world was a further tie to India's support for the Palestinian cause. Though it started to waver in the late 1980s and 1990s as the recognition of Israel led to diplomatic exchanges, the ultimate support for the Palestinian cause was still an underlying concern.
Beyond the recognition for Palestinian self-determination ties have been largely dependent upon socio-cultural bonds, while economic relations were neither cold nor warm.

India recognised Palestine's statehood following its own declaration on 18 November 1988; although relations were first established in 1974.

PNA President Abbas paid a State visit to India in September 2012, during which India pledged $10 million as aid. Indian officials said it was the third such donation, adding that New Delhi was committed to helping other development projects. India also pledged support to Palestine's bid for full and equal membership of the UN.

Bilateral relations between India and the Saudi Arabia have strengthened considerably owing to co-operation in regional affairs and trade. Saudi Arabia is the one of largest suppliers of oil to India, who is one of the top seven trading partners and the 5th biggest investor in Saudi Arabia.

India was one of the first nations to establish ties with the Third Saudi State. During the 1930s, India heavily funded Nejd through financial subsidies.

India's strategic relations with Saudi Arabia have been affected by the latter's close ties with Pakistan. Saudi Arabia supported Pakistan's stance on the Kashmir conflict and during the Indo-Pakistani War of 1971 at the expense of its relations with India. The Soviet Union's close relations with India also served as a source of consternation. During the Persian Gulf War (1990–91), India officially maintained neutrality. Saudi Arabia's close military and strategic ties with Pakistan have also been a source of continuing strain.

Since the 1990s, both nations have taken steps to improve ties. Saudi Arabia has supported granting observer status to India in the Organisation of Islamic Cooperation (OIC) and has expanded its co-operation with India to fight terrorism. In January 2006, King Abdullah of Saudi Arabia made a special visit to India, becoming the first Saudi monarch in 51 years to do so. The Saudi king and former Prime Minister of India Manmohan Singh signed an agreement forging a strategic energy partnership that was termed the "Delhi Declaration". The pact provides for a "reliable, stable and increased volume of crude oil supplies to India through long-term contracts." Both nations also agreed on joint ventures and the development of oil and natural gas in public and private sectors. An Indo-Saudi joint declaration in the Indian capital New Delhi described the king's visit as "heralding a new era in India-Saudi Arabia relations."

Bilateral relations between the India and Syria are historic where the two have ancient civilizational ties. Both countries were on the silk Road through which civilizational exchanges took place for centuries.

The Syriac Christianity, originating in ancient Syria, spread further to the East and created the first Christian communities in ancient India.

Due to controversial issues such as Turkey's close relationship with Pakistan, relations between the two countries have often been blistered at certain times, but better at others. India and Turkey's relationship alters from unsureness to collaboration when the two nations work together to combat terrorism in Central and South Asia, and the Middle East. India and Turkey are also connected by history, seeing as they have known each other since the days of the Ottoman Empire, and seeing as India was one of the countries to send aid to Turkey following its war of independence. The Indian real estate firm GMR, has invested in and is working towards the modernisation of Istanbul's Sabiha Gökçen International Airport.

India–United Arab Emirates relations refers to the bilateral relations that exist between the Republic of India and the United Arab Emirates.After the creation of the Federation in 1971, India-UAE relations flourished. Today UAE and India share political, economical and cultural links. There are over a million Indians in the United Arab Emirates, being by far the largest migrant group in the country.[1] A large Indian expatriate community resides and engages in the UAE in economically productive activities and has played a significant role in the evolution of the UAE. In 2008-09, India emerged as the largest trade partner of the UAE with bilateral trade between the two countries exceeding US$44.5 billion. [9] UAEand India are each other's main trading parthers. The trade totals over $75 billion (AED275.25 billion).

The dissolution of the Soviet Union and the emergence of the Commonwealth of Independent States (CIS) had major repercussions for Indian foreign policy. Substantial trade with the former Soviet Union plummeted after the Soviet collapse and has yet to recover. Longstanding military supply relationships were similarly disrupted due to questions over financing, although Russia continues to be India's largest supplier of military systems and spare parts.

The relationship with USSR was tested (and proven) during the 1971 war with Pakistan, which led to the subsequent liberation of Bangladesh. Soon after the victory of the Indian Armed Forces, one of the foreign delegates to visit India was Admiral S.G. Gorshkov, Chief of the Soviet Navy. During his visit to Mumbai (Bombay) he came on board INS "Vikrant". During a conversation with Vice Admiral Swaraj Prakash, Gorshkov asked the Vice Admiral, "Were you worried about a battle against the American carrier?" He answered himself: "Well, you had no reason to be worried, as I had a Soviet nuclear submarine trailing the American task force all the way into the Indian Ocean."

India's ties with the Russian Federation are time-tested and based on continuity, trust and mutual understanding. There is national consensus in both the countries on the need to preserve and strengthen India-Russia relations and further consolidate the strategic partnership between the two countries. A Declaration on Strategic Partnership was signed between present Russian President Vladimir Putin and former Indian Prime Minister Atal Bihari Vajpayee in October 2000.

Russia and India have decided not to renew the 1971 Indo-Soviet Peace and Friendship Treaty and have sought to follow what both describe as a more pragmatic, less ideological relationship. Russian President Yeltsin's visit to India in January 1993 helped cement this new relationship. Ties have grown stronger with President Vladimir Putin's 2004 visit. The pace of high-level visits has since increased, as has discussion of major defence purchases. Russia, is working for the development of the Kudankulam Nuclear Power Plant, that will be capable of producing 1000 MW of electricity. Gazprom, is working for the development of oil and natural gas, in the Bay of Bengal. India and Russia, have collaborated extensively, on space technology. Other areas of collaboration include software, ayurveda, etc. India and Russia, have set a determination in increasing trade to $10 billion. Cooperation between clothing manufacturers of the two countries continues to strengthen. India and Russia signed an agreement on joint efforts to increase investment and trade volumes in the textile industry in both countries. In signing the document included representatives of the Russian Union of Entrepreneurs of Textile and Light Industry Council and apparel exports of India (AEPC). A co-operation agreement provides, inter alia, exchange of technology and know-how in textile production. For this purpose, a special Commission on Affairs textile (Textile Communication Committee). Counter-terrorism techniques are also in place between Russia and India. In 2007 President Vladimir Putin was guest of honour at Republic Day celebration on 26 January 2007. 2008, has been declared by both countries as the Russia-India Friendship Year. Bollywood films are quite popular in Russia. The Indian public sector oil company ONGC bought Imperial Energy Corporation in 2008. In December 2008, during President Medvedev's visit, to New Delhi, India and Russia, signed a nuclear energy co-operation agreement. In March 2010, Russian Prime Minister Vladimir Putin signed an additional 19 pacts with India which included civilian nuclear energy, space and military co-operation and the final sale of Admiral Gorshkov (Aircraft Carrier) along with MiG-29K fighter jets.

During the 2014 Crimean crisis India refused to support American sanctions against Russia and one of India's national security advisers Shivshankar Menon was reported to have said "There are legitimate Russian and other interests involved and we hope they are discussed and resolved."

From 7 August 2014 India and Russia will hold a joint counter-terrorism exercise near Moscow boundary with China and Mongolia. It will involve the use of tanks and armoured vehicles.

India and Russia have so far conducted three rounds of INDRA exercises. The first exercise was carried out in 2005 in Rajasthan, followed by Prshkov in Russia. The third exercise was conducted at Chaubattia in Kumaon hills in October 2010.

India is working towards developing strong relations with this resource rich Central Asian country. The Indian oil company, Oil and Natural Gas Corporation, has got oil exploration and petroleum development grants in Kazakhstan. The two countries are collaborating in petrochemicals, information technology, and space technology. Kazakhstan has offered India five blocks for oil and gas exploration. India and Kazakhstan, are to set up joint projects in construction, minerals and metallurgy. India also signed four other pacts, including an extradition treaty, in the presence of President Prathibha Patil and her Kazakh counterpart Nursultan Nazarbayev. Kazakhstan will provide uranium and related products under the MoU between Nuclear Power Corp. of India and KazatomProm. These MoU also opens possibilities of joint exploration of uranium in Kazakhstan, which has the world's second largest reserves, and India building atomic power plants in the Central Asian country.

The relations between India and Mongolia are still at a nascent stage and Indo-Mongolian co-operation is limited to diplomatic visits, provision of soft loans and financial aid and the collaborations in the IT sector.

India established diplomatic relations in December 1955. India was the first country outside the Soviet bloc to establish diplomatic relations with Mongolia. Since then, there have been treaties of mutual friendship and co-operation between the two countries in 1973, 1994, 2001 and 2004.

Diplomatic relations were established India and Tajikistan following Tajikistan's independence from the 1991 dissolution of the Soviet Union, which had been friendly with India. Tajikistan occupies a strategically important position in Central Asia, bordering Afghanistan, the People's Republic of China and separated by a small strip of Afghan territory from Pakistan. India's role in fighting the Taliban and Al-Qaeda and its strategic rivalry with both China and Pakistan have made its ties with Tajikistan important to its strategic and security policies. Despite their common efforts, bilateral trade has been comparatively low, valued at USD 12.09 million in 2005; India's exports to Tajikistan were valued at USD 6.2 million and its imports at USD 5.89 million. India's military presence and activities have been significant, beginning with India's extensive support to the anti-Taliban Afghan Northern Alliance (ANA). India began renovating the Farkhor Air Base and stationed aircraft of the Indian Air Force there. The Farkhor Air Base became fully operational in 2006, and 12 MiG-29 bombers and trainer aircraft are planned to be stationed there.

India has an embassy in Tashkent. Uzbekistan has an embassy in New Delhi. Uzbekistan has had a great impact on Indian culture mostly due to the Mughal Empire which was founded by Babur of Ferghana (in present-day Uzbekistan) who created his empire southward first in Afghanistan and then in India.

As of year 2011, India's total trade with Africa is over US$46 billion and total investment is over US$11 billion with US$5.7 billion line of credit for executing various projects in Africa.

India has had good relationships with most sub-Saharan African nations for most of its history. In the Prime Minister's visit to Mauritius in 1997, the two countries secured a deal to a new Credit Agreement of INR 105 million (US$3 million) to finance import by Mauritius of capital goods, consultancy services and consumer durable from India. The government of India secured a rice and medicine agreement with the people of Seychelles. India continued to build upon its historically close relations with Ethiopia, Kenya, Uganda and Tanzania. Visits from political ministers from Ethiopia provided opportunities for strengthening bilateral co-operation between the two countries in the fields of education and technical training, water resources management and development of small industries. This has allowed India to gain benefits from nations that are generally forgotten by other Western Nations. The South African President, Thabo Mbeki has called for a strategic relationship between India and South Africa to avoid imposition by Western Nations. India continued to build upon its close and friendly relations with Angola, Botswana, Lesotho, Malawi, Mozambique, Namibia, Swaziland, Zambia and Zimbabwe. The Minister of Foreign Affairs arranged for the sending of Special Envoys to each of these countries during 1996–97 as a reaffirmation of India's assurance to strengthening co-operation with these countries in a spirit of South-South partnership. These relations have created a position of strength with African nations that other nations may not possess.



India and Ethiopia have warm bilateral ties based on mutual co-operation and support. India has been a partner in Ethiopia's developmental efforts, training Ethiopian personnel under its ITEC programmer, providing it with several lines of credit and launching the Pan-African e-Network Project there in 2007. The Second India–Africa Forum Summit was held in Addis Ababa in 2011. India is also Ethiopia's second largest source of foreign direct investments.

Gabon maintains an embassy in New Delhi. The Embassy of India in Kinshasa, Democratic Republic of Congo is jointly accredited to Gabon.

Relations between Ghana and India are generally close and cordial mixed with economic and cultural connections. Trade between India and Ghana amounted to US$818 million in 2010–11 and is expected to be worth US$1 billion by 2013. Ghana imports automobiles and buses from India and companies like Tata Motors and Ashok Leyland have a significant presence in the country. Ghanaian exports to India consist of gold, cocoa and timber while Indian exports to Ghana comprise pharmaceuticals, agricultural machinery, electrical equipment, plastics, steel and cement.

The Government of India has extended $228 million in lines of credit to Ghana which has been used for projects in sectors like agro-processing, fish processing, waste management, rural electrification and the expansion of Ghana's railways. India has also offered to set up an India-Africa Institute of Information Technology (IAIIT) and a Food Processing Business Incubation Centre in Ghana under the India–Africa Forum Summit.

India is among the largest foreign investors in Ghana's economy. At the end of 2011, Indian investments in Ghana amounted to $550 million covering some 548 projects. Indian investments are primarily in the agriculture and manufacturing sectors of Ghana while Ghanaian companies manufacture drugs in collaboration with Indian companies. The IT sector in Ghana too has a significant Indian presence in it. India and Ghana also have a Bilateral Investment Protection Agreement between them. India's Rashtriya Chemicals and Fertilisers is in the process of setting up a fertiliser plant in Ghana at Nyankrom in the Shama District of the Western Region of Ghana. The project entails an investment of US$1.3 billion and the plant would have an annual production capacity of 1.1 million tonnes, the bulk of which would be exported to India. There are also plans to develop a sugar processing plant entailing an investment of US$36 million. Bank of Baroda, Bharti Airtel, Tata Motors and Tech Mahindra are amongst the major Indian companies in Ghana.

There are about seven to eight thousand Indians and Persons of Indian Origin living in Ghana today with some of them having been there for over 70 years. Ghana is home to a growing indigenous Hindu population that today numbers 3000 families. Hinduism first came to Ghana only in the late 1940s with the Sindhi traders who migrated here following India's Partition. It has been growing in Ghana and neighbouring Togo since the mid-1970s when an African Hindu monastery was established in Accra.

The bilateral relations between India and Ivory Coast have expanded considerably in recent years as India seeks to develop an extensive commercial and strategic partnership in the West African region. The Indian diplomatic mission in Abidjan was opened in 1979. Ivory Coast opened its resident mission in New Delhi in September 2004. Both nations are currently fostering efforts to increase trade, investments and economic co-operation.

As littoral states of the Indian Ocean, trade links and commercial ties between India and Kenya go back several centuries. Kenya has a large minority of Indians and Persons of Indian Origin living there who are descendants of labourers who were brought in by the British to construct the Uganda Railway and Gujarati merchants. 
India and Kenya have growing trade and commercial ties. Bilateral trade amounted to $2.4 billion in 2010–2011 but with Kenyan imports from India accounting for $2.3 billion, the balance of trade was heavily in India's favour. India is Kenya's sixth largest trading partner and the largest exporter to Kenya. Indian exports to Kenya include pharmaceuticals, steel, machinery and automobiles while Kenyan exports to India are largely primary commodities such as soda ash, vegetables and tea. Indian companies have a significant presence in Kenya with Indian corporates like the Tata Group, Essar Group, Reliance Industries and Bharti Airtel operating there.

India operates a High Commission in Pretoria which serves Lesotho and Lesotho operates a residential mission in India. Lesotho and India have strong ties. Lesotho has backed India's bid for a Permanent UN seat and has also recognized Jammu and Kashmir as a part of India. India exported US$11 Million to Lesotho in the 2010-2011 year while only importing US$1 Million in goods from Lesotho. Since 2001, an India Army Training Team has trained several soldiers in the LDF.

The bilateral relations between the Republic of India and the Republic of Liberia have expanded on growing bilateral trade and strategic co-operation.
India is represented in Liberia through its embassy in Abidjan (Ivory Coast) and an active honorary consulate in Monrovia since 1984. Liberia was represented in India through its resident mission in New Delhi which subsequently closed due to budgetary constraints.

India is represented in Mauritania by its embassy in Bamako, Mali. India also has an honorary consulate in Nouakchott.

The relations between India and Mauritius existed since 1730, diplomatic relations were established in 1948, before Mauritius became an independent state. The relationship is very cordial due to cultural affinities and long historical ties that exist between the two nations. More than 68% of the Mauritian population are of Indian origin, most commonly known as Indo-Mauritian. Economic and commercial corporation has been increasing over the years. India has become Mauritius' largest source of imports since 2007 and Mauritius imported US$816 million worth of goods in the April 2010 – March 2011 financial year. Mauritius has remained the largest source of FDI for India for more than a decade with FDI equity inflows totalling US$55.2 billion in the period April 2000 to April 2011. India and Mauritius co-operate in combating piracy which has emerged as a major threat in the Indian Ocean region and support India's stand against terrorism.

The relationship between Mauritius and India date back in the early 1730s, when artisans were brought from Puducherry and Tamil Nadu. Diplomatic relations between India and Mauritius were established in 1948. Mauritius maintained contacts with India through successive Dutch, French and British occupation. From the 1820s, Indian workers started coming into Mauritius to work on sugar plantations. From 1834 when slavery was abolished by the British Parliament, large numbers of Indian workers began to be brought into Mauritius as indentured labourers. On 2 November 1834 the ship named 'Atlas' docked in Mauritius carrying the first batch of Indian indentured labourers.

Morocco has an embassy in New Delhi. It also has an Honorary Consul based in Mumbai. India operates an embassy in Rabat. Both nations are part of the Non-Aligned Movement.

In the United Nations, India supported the decolonisation of Morocco and the Moroccan freedom movement. India recognised Morocco on 20 June 1956 and established relations in 1957. The Ministry of External Affairs of the Government of India states that "India and Morocco have enjoyed cordial and friendly relations and over the years bilateral relations have witnessed significant depth and growth."

The Indian Council for Cultural Relations promotes Indian culture in Morocco. Morocco seeks to increase its trade ties with India and is seeking Indian investment in various sectors The bilateral relations between India and Morocco strengthened after the Moroccan Ambassador to India spent nearly a week in Srinagar, the capital city of Jammu and Kashmir. This showed Moroccan solidarity with India in regard to Kashmir.

India has a high commissioner in Maputo and Mozambique has a high commissioner in New Delhi.

Relations between India and Namibia are warm and cordial.

India was one of SWAPO's earliest supporters during the Namibian liberation movement. The first SWAPO embassy was established in India in 1986. India's observer mission was converted to a full High Commissioner on Namibia's independence day of 21 March 1990. India has helped train the Namibian Air Force since its creation in 1995. The two countries work closely in mutual multilateral organisations such as the United Nations, Non-Aligned Movement and the Commonwealth of Nations. Namibia supports expansion of the United Nations Security Council to include a permanent seat for India.

In 2008–09, trade between the two countries stood at approximately US$80 million. Namibia's main imports from India were drugs and pharmaceuticals, chemicals, agricultural machinery, automobile and automobile parts, glass and glassware, plastic and linoleum products. India primarily imported nonferrous metals, ores and metal scarps. Indian products are also exported to neighbouring South Africa and re-imported to Namibia as South African imports. Namibian diamonds are often exported to European diamond markets before being again imported to India. In 2009, the first direct sale of Namibian diamonds to India took place. In 2008, two Indian companies won a US$105 million contract from NamPower to lay a high-voltage direct current bi-polar line from Katima Mulilo to Otjiwarongo. Namibia is a beneficiary of the Indian Technical and Economic Cooperation (ITEC) programme for telecommunications professionals from developing countries.

India has a high commissioner in Windhoek and Namibia has a high commissioner in New Delhi. Namibia's high commissioner is also accredited for Bangladesh, the Maldives and Sri Lanka.

India has close relations with this oil rich West African country. Twenty percent of India's crude oil needs are met, by Nigeria. of oil, is the amount of oil, that India receives from Nigeria. Trade, between these two countries stands at $875 million in 2005–2006. Indian companies have also invested in manufacturing, pharmaceuticals, iron ore, steel, information technology, and communications, amongst other things. Both India and Nigeria, are members of the Commonwealth of Nations, G-77, and the Non-Aligned Movement. Former Nigerian President, Olusegun Obasanjo was the guest of honour, at the Republic Day parade, in 1999, and the Indian Prime Minister Manmohan Singh, visited Nigeria in 2007, and addressed the Nigerian Parliament.

Indo-Rwandan relations are the foreign relations between the Republic of India and the Republic of Rwanda. India is represented in Rwanda through its honorary consulate in Kigali. Rwanda has been operating its Embassy in New Delhi since 1998 and appointed its first resident Ambassador in 2001.

India–Seychelles relations are bilateral relations between the Republic of India and the Republic of Seychelles. India has a High Commission in Victoria while Seychelles maintains a High Commission in New Delhi.

India and South Africa, have always had strong relations even though India revoked diplomatic relations in protest to the apartheid regime in the mid 20th century. The history of British rule connects both lands. There is a large group of Indian South Africans. Mahatma Gandhi, spent many years in South Africa, during which time, he fought for the rights of the ethnic Indians. Nelson Mandela was inspired by Gandhi. After India's independence, India strongly condemned apartheid, and refused diplomatic relations while apartheid was conducted as state policy in South Africa.

The two countries, now have close economic, political, and sports relations. Trade between the two countries grew from $3 million in 1992–1993 to $4 billion in 2005–2006, and aim to reach trade of $12 billion by 2010. One third of India's imports from South Africa is gold bar. Diamonds, that are mined from South Africa, are polished in India. Nelson Mandela was awarded the Gandhi Peace Prize. The two countries are also members of the IBSA Dialogue Forum, with Brazil. India hopes to get large amounts of uranium, from resource rich South Africa, for India's growing civilian nuclear energy sector.

India recognised South Sudan on 10 July 2011, a day after South Sudan became an independent state. At the moment relations are primarily economic. Pramit Pal Chaudhuri wrote in the "Hindustan Times" that South Sudan "has other attractions. As the Indian Foreign Ministry's own literature notes, South Sudan [is] 'reported to has ("sic") some of the largest oil reserves in Africa outside Nigeria and Angola.'" An article in ""The Telegraph"" read that South Sudan is "one of the poorest [countries] in the world, [but] is oil rich. Foreign ministry officials said New Delhi has [a] keen interest in increasing its investments in the oil fields in South Sudan, which now owns over two-thirds of the erstwhile united Sudan's oil fields."

In return for the oil resources that can be provided by South Sudan, India said it was willing to assist in developing infrastructure, training officials in health, education and rural development. "We have compiled a definite road map using ("sic") which India can help South Sudan."

Indo-Sudanese relations have always been characterised as longstanding, close, and friendly, even since the early development stages of their countries. At the time of Indian independence, Sudan had contributed 70,000 pounds, which was used to build part of the National Defence Academy in Pune. The main building of NDA is called Sudan Block. The two nations established diplomatic relations shortly after India became known as one of the first Asian countries to recognise the newly independent African country. India and Sudan also share geographic and historical similarities, as well as economic interests. Both countries are former British colonies, and remotely border Saudi Arabia by means of a body of water. India and Sudan continue to have cordial relations, despite issues such as India's close relationship with Israel, India's solidarity with Egypt over border issues with Sudan, and Sudan's intimate bonds with Pakistan and Bangladesh. India had also contributed some troops as United Nations peacekeeping force in Darfur.

Togo opened its embassy in New Delhi in October 2010. The High Commission of India in Accra, Ghana is concurrently accredited to Togo. Togolese President Gnassingbé Eyadéma made an official state visit to India in September 1994. During the visit, the two countries agreed to establish Joint Commission.

India and Uganda established diplomatic relations in 1965 and each maintain a High Commissioner in the other's capital. The Indian High Commission in Kampala has concurrent accreditation to Burundi and Rwanda. Uganda hosts a large Indian community and India–Uganda relations cover a broad range of sectors including political, economic, commercial, cultural and scientific co-operation.

Relations between India and Uganda began with the arrival of over 30,000 Indians in Uganda in the 19th century who were brought there to construct the Mombasa–Kampala railway line. Ugandan independence activists were inspired in their struggle for Ugandan independence by the success of the Indian independence movement and were also supported in their struggle by the Prime Minister of India Jawaharlal Nehru.
Indo-Ugandan relations have been good since Uganda's independence except during the regime of Idi Amin. Amin in 1972 expelled over 55,000 people of Indian origin and 5,000 Indians who had largely formed the commercial and economic backbone of the country accusing them of exploiting native Ugandans. Since the mid-1980s when President Yoweri Museveni came to power, relations have steadily improved. Today some 20,000 Indians and PIOs live or work in Uganda. Ethnic tensions between Indians and Ugandans have been a recurring issue in bilateral relations given the role of Indians in the Ugandan economy.

India participates in the following international organisations:

India became independent within the British Commonwealth in August 1947 as the Dominion of India after the partition of India into India and the Dominion of Pakistan. King George VI, the last Emperor of India became the King of India with the Governor-General of India as his viceregal representative.

India became the very first Commonwealth republic on 26 January 1950, as a result of the London Declaration.

India played an important role in the multilateral movements of colonies and newly independent countries that developed into the Non-Aligned Movement.

Nonalignment had its origins in India's colonial experience and the nonviolent Indian independence movement led by the Congress, which left India determined to be the master of its fate in an international system dominated politically by Cold War alliances and economically by Western capitalism and Soviet communism. The principles of nonalignment, as articulated by Nehru and his successors, were preservation of India's freedom of action internationally through refusal to align India with any bloc or alliance, particularly those led by the United States or the Soviet Union; nonviolence and international co-operation as a means of settling international disputes.
Nonalignment was a consistent feature of Indian foreign policy by the late 1940s and enjoyed strong, almost unquestioning support among the Indian elite.

The term "Non-Alignment" was coined by V K Menon in his speech at UN in 1953 which was later used by Indian Prime Minister, Jawaharlal Nehru during his speech in 1954 in Colombo, Sri Lanka. In this speech, Nehru described the five pillars to be used as a guide for China–India relations, which were first put forth by PRC Premier Zhou Enlai. Called Panchsheel (five restraints), these principles would later serve as the basis of the Non-Aligned Movement. The five principles were:

Jawaharlal Nehru's concept of nonalignment brought India considerable international prestige among newly independent states that shared India's concerns about the military confrontation between the superpowers and the influence of the former colonial powers. New Delhi used nonalignment to establish a significant role for itself as a leader of the newly independent world in such multilateral organisations as the United Nations (UN) and the Nonaligned Movement. The signing of the Treaty of Peace, Friendship, and Cooperation between India and the Soviet Union in 1971 and India's involvement in the internal affairs of its smaller neighbours in the 1970s and 1980s tarnished New Delhi's image as a nonaligned nation and led some observers to note that in practice, nonalignment applied only to India's relations with countries outside South Asia.

India was among the original members of the United Nations that signed the Declaration by United Nations at Washington on 1 January 1942 and also participated in the United Nations Conference on International Organization at San Francisco from 25 April to 26 June 1945. As a founding member of the United Nations, India strongly supports the purposes and principles of the UN and has made significant contributions to implementing the goals of the Charter, and the evolution of the UN's specialised programmes and agencies. India is a charter member of the United Nations and participates in all of its specialised agencies and organisations. India has contributed troops to United Nations peacekeeping efforts in Korea, Egypt and the Congo in its earlier years and in Somalia, Angola, Haiti, Liberia, Lebanon and Rwanda in recent years, and more recently in the South Sudan conflict. India has been a member of the UN Security Council for six terms (a total of 12 years), and was a member for the term 2011–12. India is a member of the G4 group of nations who back each other in seeking a permanent seat on the security council and advocate in favour of the reformation of the UNSC. India is also part of the Group of 77.

Described by the WTO's former chief, Pascal Lamy, as one of the organisation's "big brothers", India was instrumental in bringing down the Doha Development Round of talks in 2008. It has played an important role of representing as many as 100 developing nations during WTO summits.

India's territorial disputes with neighbouring Pakistan and People's Republic of China have played a crucial role in its foreign policy. India is also involved in minor territorial disputes with neighbouring Bangladesh, Nepal and Maldives. India currently maintains two manned stations in Antarctica but has made some unofficial territorial claims, which are yet to be clarified.

India is involved in the following international disputes:

Kalapani village of India is claimed by Nepal and Susta village in Nawalparasi district of Nepal is claimed by India.

The dispute between India and Nepal involves about of area in Kalapani, where China, India, and Nepal meet. Indian forces occupied the area in 1962 after China and India fought their border war. Three villages are located in the disputed zone: Kuti [Kuthi, 30°19'N, 80°46'E], Gunji, and Knabe. India and Nepal disagree about how to interpret the 1816 Sugauli treaty between the British East India Company and Nepal, which delimited the boundary along the Maha Kali River (Sarda River in India). The dispute intensified in 1997 as the Nepali parliament considered a treaty on hydro-electric development of the river. India and Nepal differ as to which stream constitutes the source of the river. Nepal regards the Limpiyadhura as the source; India claims the Lipu Lekh. Nepal has reportedly tabled an 1856 map from the British India Office to support its position. The countries have held several meetings about the dispute and discussed jointly surveying to resolve the issue. Although the Indo-Nepali dispute appears to be minor, it was aggravated in 1962 by tensions between China and India. Because the disputed area lies near the Sino-Indian frontier, it gains strategic value.



Two regions are claimed by both India and China. Aksai Chin is in the disputed territory of Jammu and Kashmir, at the junction of India, Tibet and Xinjiang, India claims the 38,000-square-kilometre territory, currently administered by China after Sino-Indian War. India also considers the cessation of Shaksam Valley to China by Pakistan as illegal and a part of its territory.
Arunachal Pradesh is a state of India in the country's northeast, bordering on Bhutan, Burma and China's Tibet, though it is under Indian administration since 1914, China claims the 90,000-square-kilometre area as South Tibet. Also the boundary between the North Indian states of Himachal Pradesh and Uttarakhand with China's Tibet is not properly demarcated with some portions under de facto administration of India.





</doc>
<doc id="14605" url="https://en.wikipedia.org/wiki?curid=14605" title="Indian religions">
Indian religions

Indian religions, sometimes also termed Dharmic religions or Indic religions, are the religions that originated in the Indian subcontinent; namely Hinduism, Jainism, Buddhism, and Sikhism. These religions are also all classified as Eastern religions. Although Indian religions are connected through the history of India, they constitute a wide range of religious communities, and are not confined to the Indian subcontinent.

Evidence attesting to prehistoric religion in the Indian subcontinent derives from scattered Mesolithic rock paintings. The Harappan people of the Indus Valley Civilisation, which lasted from 3300 to 1300 BCE (mature period 2600–1900 BCE), had an early urbanized culture which predates the Vedic religion.

The documented history of Indian religions begins with the historical Vedic religion, the religious practices of the early Indo-Iranians, which were collected and later redacted into the "Vedas". The period of the composition, redaction and commentary of these texts is known as the Vedic period, which lasted from roughly 1750 to 500 BCE. The philosophical portions of the Vedas were summarized in Upanishads, which are commonly referred to as "Vedānta", variously interpreted to mean either the "last chapters, parts of the Veda" or "the object, the highest purpose of the Veda". The early Upanishads all predate the Common Era, five of the eleven principal Upanishads were composed in all likelihood before 6th century BCE, and contain the earliest mentions of "Yoga" and Moksha.

The Shramanic Period between 800 and 200 BCE marks a "turning point between the Vedic Hinduism and Puranic Hinduism". The Shramana movement, an ancient Indian religious movement parallel to but separate from Vedic tradition, often defied many of the Vedic and Upanishadic concepts of soul (Atman) and the ultimate reality (Brahman). In 6th century BCE, the Shramnic movement matured into Jainism and Buddhism and was responsible for the schism of Indian religions into two main philosophical branches of astika, which venerates Veda (e.g., six orthodox schools of Hinduism) and nastika (e.g., Buddhism, Jainism, Charvaka, etc.). However, both branches shared the related concepts of Yoga, "saṃsāra" (the cycle of birth and death) and "moksha" (liberation from that cycle).

The Puranic Period (200 BCE – 500 CE) and Early Medieval period (500–1100 CE) gave rise to new configurations of Hinduism, especially bhakti and Shaivism, Shaktism, Vaishnavism, Smarta, and smaller groups like the conservative Shrauta.

The early Islamic period (1100–1500 CE) also gave rise to new movements. Sikhism was founded in the 15th century on the teachings of Guru Nanak and the nine successive Sikh Gurus in Northern India. The vast majority of its adherents originate in the Punjab region.

With the colonial dominance of the British a reinterpretation and synthesis of Hinduism arose, which aided the Indian independence movement.

James Mill (1773–1836), in his The History of British India (1817), distinguished three phases in the history of India, namely Hindu, Muslim and British civilisations. This periodisation has been criticised, for the misconceptions it has given rise to. Another periodisation is the division into "ancient, classical, medieval and modern periods", although this periodization has also received criticism.

Romila Thapar notes that the division of Hindu-Muslim-British periods of Indian history gives too much weight to "ruling dynasties and foreign invasions," neglecting the social-economic history which often showed a strong continuity. The division in Ancient-Medieval-Modern overlooks the fact that the Muslim-conquests took place between the eight and the fourteenth century, while the south was never completely conquered. According to Thapar, a periodisation could also be based on "significant social and economic changes," which are not strictly related to a change of ruling powers.

Smart and Michaels seem to follow Mill's periodisation, while Flood and Muesse follow the "ancient, classical, mediaeval and modern periods" periodisation. An elaborate periodisation may be as follows:

Evidence attesting to prehistoric religion in the Indian subcontinent derives from scattered Mesolithic rock paintings such as at Bhimbetka, depicting dances and rituals. Neolithic agriculturalists inhabiting the Indus River Valley buried their dead in a manner suggestive of spiritual practices that incorporated notions of an afterlife and belief in magic. Other South Asian Stone Age sites, such as the Bhimbetka rock shelters in central Madhya Pradesh and the Kupgal petroglyphs of eastern Karnataka, contain rock art portraying religious rites and evidence of possible ritualised music.

The religion and belief system of the Indus valley people have received considerable attention, especially from the view of identifying precursors to deities and religious practices of Indian religions that later developed in the area. However, due to the sparsity of evidence, which is open to varying interpretations, and the fact that the Indus script remains undeciphered, the conclusions are partly speculative and largely based on a retrospective view from a much later Hindu perspective. An early and influential work in the area that set the trend for Hindu interpretations of archaeological evidence from the Harrapan sites was that of John Marshall, who in 1931 identified the following as prominent features of the Indus religion: a Great Male God and a Mother Goddess; deification or veneration of animals and plants; symbolic representation of the phallus (linga) and vulva (yoni); and, use of baths and water in religious practice. Marshall's interpretations have been much debated, and sometimes disputed over the following decades.
One Indus valley seal shows a seated, possibly ithyphallic and tricephalic, figure with a horned headdress, surrounded by animals. Marshall identified the figure as an early form of the Hindu god Shiva (or Rudra), who is associated with asceticism, yoga, and linga; regarded as a lord of animals; and often depicted as having three eyes. The seal has hence come to be known as the Pashupati Seal, after "Pashupati" (lord of all animals), an epithet of Shiva. While Marshall's work has earned some support, many critics and even supporters have raised several objections. Doris Srinivasan has argued that the figure does not have three faces, or yogic posture, and that in Vedic literature Rudra was not a protector of wild animals. Herbert Sullivan and Alf Hiltebeitel also rejected Marshall's conclusions, with the former claiming that the figure was female, while the latter associated the figure with "Mahisha", the Buffalo God and the surrounding animals with vahanas (vehicles) of deities for the four cardinal directions. Writing in 2002, Gregory L. Possehl concluded that while it would be appropriate to recognise the figure as a deity, its association with the water buffalo, and its posture as one of ritual discipline, regarding it as a proto-Shiva would be going too far. Despite the criticisms of Marshall's association of the seal with a proto-Shiva icon, it has been interpreted as the Tirthankara Rishabha by Jains and Dr. Vilas Sangave or an early Buddha by Buddhists. Historians like Heinrich Zimmer, Thomas McEvilley are of the opinion that there exists some link between first Jain Tirthankara Rishabha and Indus Valley civilisation.

Marshall hypothesized the existence of a cult of Mother Goddess worship based upon excavation of several female figurines, and thought that this was a precursor of the Hindu sect of Shaktism. However the function of the female figurines in the life of Indus Valley people remains unclear, and Possehl does not regard the evidence for Marshall's hypothesis to be "terribly robust". Some of the baetyls interpreted by Marshall to be sacred phallic representations are now thought to have been used as pestles or game counters instead, while the ring stones that were thought to symbolise "yoni" were determined to be architectural features used to stand pillars, although the possibility of their religious symbolism cannot be eliminated. Many Indus Valley seals show animals, with some depicting them being carried in processions, while others show chimeric creations. One seal from Mohen-jodaro shows a half-human, half-buffalo monster attacking a tiger, which may be a reference to the Sumerian myth of such a monster created by goddess Aruru to fight Gilgamesh.

In contrast to contemporary Egyptian and Mesopotamian civilisations, Indus valley lacks any monumental palaces, even though excavated cities indicate that the society possessed the requisite engineering knowledge. This may suggest that religious ceremonies, if any, may have been largely confined to individual homes, small temples, or the open air. Several sites have been proposed by Marshall and later scholars as possibly devoted to religious purpose, but at present only the Great Bath at Mohenjo-daro is widely thought to have been so used, as a place for ritual purification. The funerary practices of the Harappan civilisation is marked by its diversity with evidence of supine burial; fractional burial in which the body is reduced to skeletal remains by exposure to the elements before final interment; and even cremation. 

The early Dravidian religion constituted of non-Vedic form of Hinduism in that they were either historically or are at present Āgamic. The Agamas are non-vedic in origin and have been dated either as post-vedic texts. or as pre-vedic oral compositions. The "Agamas" are a collection of Tamil and later Sanskrit scriptures chiefly constituting the methods of temple construction and creation of "murti", worship means of deities, philosophical doctrines, meditative practices, attainment of sixfold desires and four kinds of yoga. The worship of tutelary deity, sacred flora and fauna in Hinduism is also recognized as a survival of the pre-Vedic Dravidian religion.
Ancient Tamil grammatical works Tolkappiyam, the ten anthologies Pattuppāṭṭu, the eight anthologies Eṭṭuttokai also sheds light on early religion of ancient Dravidians. "Seyon" was glorified as "the red god seated on the blue peacock, who is ever young and resplendent," as "the favored god of the Tamils." Sivan was also seen as the supreme God. Early iconography of Seyyon and Sivan and their association with native flora and fauna goes back to Indus Valley Civilization. The Sangam landscape was classified into five categories, "thinais", based on the mood, the season and the land. Tolkappiyam, mentions that each of these "thinai" had an associated deity such Seyyon in "Kurinji"-the hills, Thirumaal in "Mullai"-the forests, and Kotravai in "Marutham"-the plains, and Wanji-ko in the "Neithal"-the coasts and the seas. Other gods mentioned were Mayyon and Vaali who were all assimilated into Hinduism over time. Dravidian linguistic influence on early Vedic religion is evident, many of these features are already present in the oldest known Indo-Aryan language, the language of the "Rigveda" (c. 1500 BCE), which also includes over a dozen words borrowed from Dravidian. This represents an early religious and cultural fusion or synthesis between ancient Dravidians and Indo-Aryans, which became more evident over time with sacred iconography, traditions, philosophy, flora and fauna that went on to influence Hinduism, Buddhism, Charvaka, Sramana and Jainism.
Throughout Tamilakam, a king was considered to be divine by nature and possessed religious significance. The king was 'the representative of God on earth’ and lived in a “koyil”, which means the “residence of a god”. The Modern Tamil word for temple is koil. Titual worship was also given to kings. Modern words for god like “kō” (“king”), “iṟai” (“emperor”) and “āṇḍavar” ( “conqueror”) now primarily refer to gods. These elements were incorporated later into Hinduism like the legendary marriage of Shiva to Queen Mīnātchi who ruled Madurai or Wanji-ko, a god who later merged into Indra. Tolkappiyar refers to the Three Crowned Kings as the “Three Glorified by Heaven”. In the Dravidian-speaking South, the concept of divine kingship led to the assumption of major roles by state and temple.

The cult of the mother goddess is treated as an indication of a society which venerated femininity. This mother goddess was conceived as a virgin, one who has given birth to all and one, typically associated with Shaktism. The temples of the Sangam days, mainly of Madurai, seem to have had priestesses to the deity, which also appear predominantly a goddess. In the Sangam literature, there is an elaborate description of the rites performed by the Kurava priestess in the shrine Palamutircholai. Among the early Dravidians the practice of erecting memorial stones “Natukal" or "Hero Stone had appeared, and it continued for quite a long time after the Sangam age, down to about 16th century. It was customary for people who sought victory in war to worship these hero stones to bless them with victory.

The documented history of Indian religions begins with the historical Vedic religion, the religious practices of the early Indo-Aryans, which were collected and later redacted into the "Samhitas" (usually known as the Vedas), four canonical collections of hymns or mantras composed in archaic Sanskrit. These texts are the central "shruti" (revealed) texts of Hinduism. The period of the composition, redaction and commentary of these texts is known as the Vedic period, which lasted from roughly 1750 to 500 BCE.

The Vedic Period is most significant for the composition of the four Vedas, Brahmanas and the older Upanishads (both presented as discussions on the rituals, mantras and concepts found in the four Vedas), which today are some of the most important canonical texts of Hinduism, and are the codification of much of what developed into the core beliefs of Hinduism.

Some modern Hindu scholars use the "Vedic religion" synonymously with "Hinduism." According to Sundararajan, Hinduism is also known as the Vedic religion. Other authors state that the Vedas contain "the fundamental truths about Hindu Dharma" which is called "the modern version of the ancient Vedic Dharma" The Arya Samajis recognize the Vedic religion as true Hinduism. Nevertheless, according to Jamison and Witzel,

The rishis, the composers of the hymns of the Rigveda, were considered inspired poets and seers.

The mode of worship was the performance of Yajna, sacrifices which involved sacrifice and sublimation of the havana sámagri (herbal preparations) in the fire, accompanied by the singing of Samans and 'mumbling' of Yajus, the sacrificial mantras. The sublime meaning of the word yajna is derived from the Sanskrit verb yaj, which has a three-fold meaning of worship of deities (devapujana), unity (saògatikaraña) and charity (dána). An essential element was the sacrificial fire – the divine Agni – into which oblations were poured, as everything offered into the fire was believed to reach God.

Central concepts in the Vedas are Satya and Rta. "Satya" is derived from Sat, the present participle of the verbal root "as", "to be, to exist, to live". "Sat" means "that which really exists [...] the really existent truth; the Good", and "Sat-ya" means "is-ness". "Rta", "that which is properly joined; order, rule; truth", is the principle of natural order which regulates and coordinates the operation of the universe and everything within it. "Satya (truth as being) and rita (truth as law) are the primary principles of Reality and its manifestation is the background of the canons of dharma, or a life of righteousness." "Satya is the principle of integration rooted in the Absolute, rita is its application and function as the rule and order operating in the universe." Conformity with Ṛta would enable progress whereas its violation would lead to punishment. Panikkar remarks:
The term rta is inherited from the Proto-Indo-Iranian religion, the religion of the Indo-Iranian peoples prior to the earliest Vedic (Indo-Aryan) and Zoroastrian (Iranian) scriptures. "Asha" is the Avestan language term (corresponding to Vedic language ṛta) for a concept of cardinal importance to Zoroastrian theology and doctrine. The term "dharma" was already used in Brahmanical thought, where it was conceived as an aspect of Rta.

Major philosophers of this era were Rishis Narayana, Kanva, Rishaba, Vamadeva, and Angiras.

During the Middle Vedic period Rgveda X, the mantras of the Yajurveda and the older Brahmana texts were composed. The Brahmans became powerful intermediairies.

Historical roots of Jainism in India is traced back to 9th-century BC with the rise of Parshvanatha and his non-violent philosophy.

The Vedic religion evolved into Hinduism and Vedanta, a religious path considering itself the 'essence' of the Vedas, interpreting the Vedic pantheon as a unitary view of the universe with 'God' (Brahman) seen as immanent and transcendent in the forms of Ishvara and Brahman. This post-Vedic systems of thought, along with the Upanishads and later texts like epics (namely Gita of Mahabharat), is a major component of modern Hinduism. The ritualistic traditions of Vedic religion are preserved in the conservative Śrauta tradition.

Since Vedic times, "people from many strata of society throughout the subcontinent tended to adapt their religious and social life to Brahmanic norms", a process sometimes called Sanskritization. It is reflected in the tendency to identify local deities with the gods of the Sanskrit texts.

During the time of the shramanic reform movements "many elements of the Vedic religion were lost". According to Michaels, "it is justified to see a turning point between the Vedic religion and Hindu religions".

The late Vedic period (9th to 6th centuries BCE) marks the beginning of the Upanisadic or Vedantic period. This period heralded the beginning of much of what became classical Hinduism, with the composition of the Upanishads, later the Sanskrit epics, still later followed by the Puranas.

Upanishads form the speculative-philosophical basis of classical Hinduism and are known as Vedanta (conclusion of the Vedas). The older Upanishads launched attacks of increasing intensity on the ritual. Anyone who worships a divinity other than the Self is called a domestic animal of the gods in the Brihadaranyaka Upanishad. The Mundaka launches the most scathing attack on the ritual by comparing those who value sacrifice with an unsafe boat that is endlessly overtaken by old age and death.

Scholars believe that Parsva, the 23rd Jain "tirthankara" lived during this period in the 9th century BCE.

Jainism and Buddhism belong to the sramana tradition. These religions rose into prominence in 700–500 BCE in the Magadha kingdom., reflecting "the cosmology and anthropology of a much older, pre-Aryan upper class of northeastern India", and were responsible for the related concepts of "saṃsāra" (the cycle of birth and death) and "moksha" (liberation from that cycle).

The shramana movements challenged the orthodoxy of the rituals. The shramanas were wandering ascetics distinct from Vedism. Mahavira, proponent of Jainism, and Buddha (c. 563-483), founder of Buddhism were the most prominent icons of this movement.

Shramana gave rise to the concept of the cycle of birth and death, the concept of samsara, and the concept of liberation. The influence of Upanishads on Buddhism has been a subject of debate among scholars. While Radhakrishnan, Oldenberg and Neumann were convinced of Upanishadic influence on the Buddhist canon, Eliot and Thomas highlighted the points where Buddhism was opposed to Upanishads. Buddhism may have been influenced by some Upanishadic ideas, it however discarded their orthodox tendencies. In Buddhist texts Buddha is presented as rejecting avenues of salvation as "pernicious views".

Jainism was established by a lineage of 24 enlightened beings culminating with Parsva (9th century BCE) and Mahavira (6th century BCE).

The 24th Tirthankara of Jainism, Mahavira, stressed five vows, including "ahimsa" (non-violence), "satya" (truthfulness), "asteya" (non-stealing) and "aparigraha" (non-attachment). Jain orthodoxy believes the teachings of the Tirthankaras predates all known time and scholars believe Parshva, accorded status as the 23rd Tirthankara, was a historical figure. The Vedas are believed to have documented a few Tirthankaras and an ascetic order similar to the shramana movement.

Buddhism was historically founded by Siddhartha Gautama, a Kshatriya prince-turned-ascetic, and was spread beyond India through missionaries. It later experienced a decline in India, but survived in Nepal and Sri Lanka, and remains more widespread in Southeast and East Asia.

Gautama Buddha, who was called an "awakened one" (Buddha), was born into the Shakya clan living at Kapilavastu and Lumbini in what is now southern Nepal. The Buddha was born at Lumbini, as emperor Ashoka's Lumbini pillar records, just before the kingdom of Magadha (which traditionally is said to have lasted from c. 546–324 BCE) rose to power. The Shakyas claimed Angirasa and Gautama Maharishi lineage, via descent from the royal lineage of Ayodhya.

Buddhism emphasises enlightenment (nibbana, nirvana) and liberation from the rounds of rebirth. This objective is pursued through two schools, Theravada, the Way of the Elders (practised in Sri Lanka, Burma, Thailand, SE Asia, etc.) and Mahayana, the Greater Way (practised in Tibet, China, Japan etc.). There may be some differences in the practice between the two schools in reaching the objective.
In the Theravada practice this is pursued in seven stages of purification (visuddhi); viz. physical purification by taking precepts (sila visiddhi), mental purification by insight meditation (citta visuddhi), followed by purification of views and concepts (ditthi visuddhi), purification by overcoming of doubts (kinkha vitarana vishuddhi), purification by acquiring knowledge and wisdom of the right path (maggarmagga-nanadasana visuddhi), attaining knowledge and wisdom through the course of practice (patipada-nanadasana visuddhi), and purification by attaining knowledge and insight wisdom (nanadasana visuddhi).

Both Jainism and Buddhism spread throughout India during the period of the Magadha empire.

Buddhism in India spread during the reign of Ashoka of the Maurya Empire, who patronised Buddhist teachings and unified the Indian subcontinent in the 3rd century BCE. He sent missionaries abroad, allowing Buddhism to spread across Asia. Jainism began its golden period during the reign of Emperor Kharavela of Kalinga in the 2nd century BCE.

Flood and Muesse take the period between 200 BCE and 500 BCE as a separate period, in which the epics and the first puranas were being written. Michaels takes a greater timespan, namely the period between 200 BCE and 1100 CE, which saw the rise of so-called "Classical Hinduism", with its "golden age" during the Gupta Empire.
According to Alf Hiltebeitel, a period of consolidation in the development of Hinduism took place between the time of the late Vedic Upanishad (c. 500 BCE) and the period of the rise of the Guptas (c. 320–467 CE), which he calls the "Hindus synthesis", "Brahmanic synthesis", or "orthodox synthesis". It develops in interaction with other religions and peoples:
The end of the Vedantic period around the 2nd century CE spawned a number of branches that furthered Vedantic philosophy, and which ended up being seminaries in their own right. Prominent amongst these developers were Yoga, Dvaita, Advaita and the medieval Bhakti movement.

The "smriti" texts of the period between 200 BCE-100 CE proclaim the authority of the Vedas, and "nonrejection of the Vedas comes to be one of the most important touchstones for defining Hinduism over and against the heterodoxies, which rejected the Vedas." Of the six Hindu darsanas, the Mimamsa and the Vedanta "are rooted primarily in the Vedic "sruti" tradition and are sometimes called "smarta" schools in the sense that they develop "smarta" orthodox current of thoughts that are based, like "smriti", directly on "sruti"." According to Hiltebeitel, "the consolidation of Hinduism takes place under the sign of "bhakti"." It is the "Bhagavadgita" that seals this achievement. The result is a universal achievement that may be called "smarta". It views Shiva and Vishnu as "complementary in their functions but ontologically identical".

In earlier writings, Sanskrit 'Vedānta' simply referred to the Upanishads, the most speculative and philosophical of the Vedic texts. However, in the medieval period of Hinduism, the word Vedānta came to mean the school of philosophy that interpreted the Upanishads. Traditional Vedānta considers scriptural evidence, or shabda pramāna, as the most authentic means of knowledge, while perception, or pratyaksa, and logical inference, or anumana, are considered to be subordinate (but valid).

The systematisation of Vedantic ideas into one coherent treatise was undertaken by Badarāyana in the Brahma Sutras which was composed around 200 BCE. The cryptic aphorisms of the Brahma Sutras are open to a variety of interpretations. This resulted in the formation of numerous Vedanta schools, each interpreting the texts in its own way and producing its own sub-commentaries.

After 200 CE several schools of thought were formally codified in Indian philosophy, including Samkhya, Yoga, Nyaya, Vaisheshika, Mimāṃsā and Advaita Vedanta. Hinduism, otherwise a highly polytheistic, pantheistic or monotheistic religion, also tolerated atheistic schools. The thoroughly materialistic and anti-religious philosophical Cārvāka school that originated around the 6th century BCE is the most explicitly atheistic school of Indian philosophy. Cārvāka is classified as a "nāstika" ("heterodox") system; it is not included among the six schools of Hinduism generally regarded as orthodox. It is noteworthy as evidence of a materialistic movement within Hinduism. Our understanding of Cārvāka philosophy is fragmentary, based largely on criticism of the ideas by other schools, and it is no longer a living tradition. Other Indian philosophies generally regarded as atheistic include Samkhya and Mimāṃsā.

Two of Hinduism's most revered "epics", the Mahabharata and Ramayana were compositions of this period. Devotion to particular deities was reflected from the composition of texts composed to their worship. For example, the "Ganapati Purana" was written for devotion to Ganapati (or Ganesh). Popular deities of this era were Shiva, Vishnu, Durga, Surya, Skanda, and Ganesh (including the forms/incarnations of these deities).

In the latter Vedantic period, several texts were also composed as summaries/attachments to the Upanishads. These texts collectively called as Puranas allowed for a divine and mythical interpretation of the world, not unlike the ancient Hellenic or Roman religions. Legends and epics with a multitude of gods and goddesses with human-like characteristics were composed.

The Gupta period marked a watershed of Indian culture: the Guptas performed Vedic sacrifices to legitimize their rule, but they also patronized Buddhism, which continued to provide an alternative to Brahmanical orthodoxy. Buddhism continued to have a significant presence in some regions of India until the 12th century.

There were several Buddhistic kings who worshiped Vishnu, such as the Gupta Empire, Pala Empire, Malla Empire, Somavanshi, and Satavahana. Buddhism survived followed by Hindus.

Tantrism originated in the early centuries CE and developed into a fully articulated tradition by the end of the Gupta period. According to Michaels this was the "Golden Age of Hinduism" (c. 320–650 CE), which flourished during the Gupta Empire (320 to 550 CE) until the fall of the Harsha Empire (606 to 647 CE). During this period, power was centralised, along with a growth of far distance trade, standardizarion of legal procedures, and general spread of literacy. Mahayana Buddhism flourished, but the orthodox Brahmana culture began to be rejuvenated by the patronage of the Gupta Dynasty. The position of the Brahmans was reinforced, and the first Hindu temples emerged during the late Gupta age.

After the end of the Gupta Empire and the collapse of the Harsha Empire, power became decentralised in India. Several larger kingdoms emerged, with "countless vasal states". The kingdoms were ruled via a feudal system. Smaller kingdoms were dependent on the protection of the larger kingdoms. "The great king was remote, was exalted and deified", as reflected in the Tantric Mandala, which could also depict the king as the centre of the mandala.

The disintegration of central power also lead to regionalisation of religiosity, and religious rivalry. Local cults and languages were enhanced, and the influence of "Brahmanic ritualistic Hinduism" was diminished. Rural and devotional movements arose, along with Shaivism, Vaisnavism, Bhakti and Tantra, though "sectarian groupings were only at the beginning of their development". Religious movements had to compete for recognition by the local lords. Buddhism lost its position, and began to disappear in India.

In the same period Vedanta changed, incorporating Buddhist thought and its emphasis on consciousness and the working of the mind. Buddhism, which was supported by the ancient Indian urban civilisation lost influence to the traditional religions, which were rooted in the countryside. In Bengal, Buddhism was even prosecuted. But at the same time, Buddhism was incorporated into Hinduism, when Gaudapada used Buddhist philosophy to reinterpret the Upanishads. This also marked a shift from Atman and Brahman as a "living substance" to "maya-vada", where Atman and Brahman are seen as "pure knowledge-consciousness". According to Scheepers, it is this "maya-vada" view which has come to dominate Indian thought.

Between 400 and 1000 CE Hinduism expanded as the decline of Buddhism in India continued. Buddhism subsequently became effectively extinct in India but survived in Nepal and Sri Lanka.

The Bhakti movement began with the emphasis on the worship of God, regardless of one's status – whether priestly or laypeople, men or women, higher social status or lower social status. The movements were mainly centered on the forms of Vishnu (Rama and Krishna) and Shiva. There were however popular devotees of this era of Durga. The best-known devotees are the Nayanars from southern India. The most popular Shaiva teacher of the south was Basava, while of the north it was Gorakhnath. Female saints include figures like Akkamadevi, Lalleshvari and Molla.

The "alwar" or "azhwars" (, "āzvārkaḷ" , those immersed in god) were Tamil poet-saints of south India who lived between the 6th and 9th centuries CE and espoused "emotional devotion" or bhakti to Visnu-Krishna in their songs of longing, ecstasy and service. The most popular Vaishnava teacher of the south was Ramanuja, while of the north it was Ramananda.

Several important icons were women. For example, within the Mahanubhava sect, the women outnumbered the men, and administration was many times composed mainly of women. Mirabai is the most popular female saint in India.

Sri Vallabha Acharya (1479–1531) is a very important figure from this era. He founded the Shuddha Advaita ("Pure Non-dualism") school of Vedanta thought.

According to "The Centre for Cultural Resources and Training",

In the 12th and 13th centuries, Turks and Afghans invaded parts of northern India and established the Delhi Sultanate in the former Rajput holdings. The subsequent Slave dynasty of Delhi managed to conquer large areas of northern India, approximately equal in extent to the ancient Gupta Empire, while the Khalji dynasty conquered most of central India but were ultimately unsuccessful in conquering and uniting the subcontinent. The Sultanate ushered in a period of Indian cultural renaissance. The resulting "Indo-Muslim" fusion of cultures left lasting syncretic monuments in architecture, music, literature, religion, and clothing.

During the 14th to 17th centuries, a great "Bhakti" movement swept through central and northern India, initiated by a loosely associated group of teachers or "Sants". Ramananda, Ravidas, Srimanta Sankardeva, Chaitanya Mahaprabhu, Vallabha Acharya, Sur, Meera, Kabir, Tulsidas, Namdev, Dnyaneshwar, Tukaram and other mystics spearheaded the Bhakti movement in the North while Annamacharya, Bhadrachala Ramadas, Tyagaraja among others propagated Bhakti in the South. They taught that people could cast aside the heavy burdens of ritual and caste, and the subtle complexities of philosophy, and simply express their overwhelming love for God. This period was also characterized by a spate of devotional literature in vernacular prose and poetry in the ethnic languages of the various Indian states or provinces.

Lingayatism is a distinct Shaivite tradition in India, established in the 12th century by the philosopher and social reformer Basavanna.
The adherents of this tradition are known as Lingayats. The term is derived from Lingavantha in Kannada, meaning 'one who wears "Ishtalinga" on their body' ("Ishtalinga" is the representation of the God). In Lingayat theology, "Ishtalinga" is an oval-shaped emblem symbolising Parasiva, the absolute reality. Contemporary Lingayatism follows a progressive reform–based theology propounded, which has great influence in South India, especially in the state of Karnataka.

According to Nicholson, already between the 12th and 16th century,
The tendency of "a blurring of philosophical distinctions" has also been noted by Burley. Lorenzen locates the origins of a distinct Hindu identity in the interaction between Muslims and Hindus, and a process of "mutual self-definition with a contrasting Muslim other", which started well before 1800. Both the Indian and the European thinkers who developed the term "Hinduism" in the 19th century were influenced by these philosophers.

Sikhism originated in 15th-century Punjab, Delhi Sultanate (present-day India and Pakistan) with the teachings of Nanak and nine successive gurus. The principal belief in Sikhism is faith in "Vāhigurū"— represented by the sacred symbol of "ēk ōaṅkār" [meaning one god]. Sikhism's traditions and teachings are distinctly associated with the history, society and culture of the Punjab. Adherents of Sikhism are known as Sikhs ("students" or "disciples") and number over 27 million across the world.

According to Gavin Flood, the modern period in India begins with the first contacts with western nations around 1500. The period of Mughal rule in India saw the rise of new forms of religiosity.

In the 19th century, under influence of the colonial forces, a synthetic vision of Hinduism was formulated by Raja Ram Mohan Roy, Swami Vivekananda, Sri Aurobindo, Sarvepalli Radhakrishnan and Mahatma Gandhi. These thinkers have tended to take an inclusive view of India's religious history, emphasising the similarities between the various Indian religions.

The modern era has given rise to dozens of Hindu saints with international influence. For example, Brahma Baba established the Brahma Kumaris, one of the largest new Hindu religious movements which teaches the discipline of Raja Yoga to millions. Representing traditional Gaudiya Vaishnavism, Prabhupada founded the Hare Krishna movement, another organisation with a global reach. In late 18th-century India, Swaminarayan founded the Swaminarayan Sampraday. Anandamurti, founder of the Ananda Marga, has also influenced many worldwide. Through the international influence of all of these new Hindu denominations, many Hindu practices such as yoga, meditation, mantra, divination, and vegetarianism have been adopted by new converts.

Jainism continues to be an influential religion and Jain communities live in Indian states Gujarat, Rajasthan, Madhya Pradesh, Maharashtra, Karnataka and Tamil Nadu. Jains authored several classical books in different Indian languages for a considerable period of time.

The Dalit Buddhist movement also referred to as Navayana is a 19th- and 20th-century Buddhist revival movement in India. It received its most substantial impetus from B. R. Ambedkar's call for the conversion of Dalits to Buddhism in 1956 and the opportunity to escape the caste-based society that considered them to be the lowest in the hierarchy.

According to Tilak, the religions of India can be interpreted "differentially" or "integrally", that is by either highlighting the differences or the similarities. According to Sherma and Sarma, western Indologists have tended to emphasise the differences, while Indian Indologists have tended to emphasise the similarities.

Hinduism, Buddhism, Jainism, and Sikhism share certain key concepts, which are interpreted differently by different groups and individuals. Until the 19th century, adherents of those various religions did not tend to label themselves as in opposition to each other, but "perceived themselves as belonging to the same extended cultural family."

The spectrum of these religions are called Dharmic religions because of their overlap over the core concept of Dharma. It has various meanings depending on the context. For example it could mean duty, righteousness, spiritual teachings, conduct etc.

Hinduism, Buddhism, Jainism, and Sikhism share the concept of moksha, liberation from the cycle of rebirth. They differ however on the exact nature of this liberation.

Common traits can also be observed in ritual. The head-anointing ritual of "abhiseka" is of importance in three of these distinct traditions, excluding Sikhism (in Buddhism it is found within Vajrayana). Other noteworthy rituals are the cremation of the dead, the wearing of vermilion on the head by married women, and various marital rituals. In literature, many classical narratives and purana have Hindu, Buddhist or Jain versions. All four traditions have notions of "karma", "dharma", "samsara", "moksha" and various "forms of Yoga".

Rama is a heroic figure in all of these religions. In Hinduism he is the God-incarnate in the form of a princely king; in Buddhism, he is a Bodhisattva-incarnate; in Jainism, he is the perfect human being. Among the Buddhist Ramayanas are: "Vessantarajataka", Reamker, Ramakien, Phra Lak Phra Lam, Hikayat Seri Rama etc. There also exists the "Khamti Ramayana" among the Khamti tribe of Asom wherein Rama is an Avatar of a Bodhisattva who incarnates to punish the demon king Ravana (B.Datta 1993). The "Tai Ramayana" is another book retelling the divine story in Asom.

Critics point out that there exist vast differences between and even within the various Indian religions. All major religions are composed of innumerable sects and subsects.

Indian mythology also reflects the competition between the various Indian religions. A popular story tells how Vajrapani kills Mahesvara, a manifestation of Shiva depicted as an evil being. The story occurs in several scriptures, most notably the "Sarvatathagatatattvasamgraha" and the "Vajrapany-abhiseka-mahatantra". According to Kalupahana, the story "echoes" the story of the conversion of Ambattha. It is to be understood in the context of the competition between Buddhist institutions and Shaivism.

"Āstika" and "nāstika" are variously defined terms sometimes used to categorise Indian religions. The traditional definition, followed by Adi Shankara, classifies religions and persons as "āstika" and "nāstika" according to whether they accept the authority of the main Hindu texts, the Vedas, as supreme revealed scriptures, or not. By this definition, Nyaya, Vaisheshika, Samkhya, Yoga, Purva Mimamsa and Vedanta are classified as "āstika" schools, while Charvaka is classified as a "nāstika" school. Buddhism and Jainism are also thus classified as "nāstika" religions since they do not accept the authority of the Vedas.

Another set of definitions—notably distinct from the usage of Hindu philosophy—loosely characterise "āstika" as "theist" and "nāstika" as "atheist". By these definitions, "Sāṃkhya" can be considered a "nāstika" philosophy, though it is traditionally classed among the Vedic "āstika" schools. From this point of view, Buddhism and Jainism remain "nāstika" religions.

Buddhists and Jains have disagreed that they are nastika and have redefined the phrases āstika and nāstika in their own view. Jains assign the term nastika to one who is ignorant of the meaning of the religious texts, or those who deny the existence of the soul was well known to the Jainas.

Frawley and Malhotra use the term "Dharmic traditions" to highlight the similarities between the various Indian religions. According to Frawley, "all religions in India have been called the Dharma", and can be
According to Paul Hacker, as described by Halbfass, the term "dharma"
The emphasis on the similarities and integral unity of the dharmic faiths has been criticised for neglecting the vast differences between and even within the various Indian religions and traditions. According to Richard E. King it is typical of the "inclusivist appropriation of other traditions" of Neo-Vedanta:
The "Council of Dharmic Faiths" (UK) regards Zoroastrianism, whilst not originating in the Indian subcontinent, also as a Dharmic religion.

The inclusion of Buddhists, Jains and Sikhs within Hinduism is part of the Indian legal system. The 1955 Hindu Marriage Act "[defines] as Hindus all Buddhists, Jains, Sikhs and anyone who is not a Christian, Muslim, Parsee (Zoroastrian) or Jew". And the Indian Constitution says that "reference to Hindus shall be construed as including a reference to persons professing the Sikh, Jaina or Buddhist religion".

In a judicial reminder, the Indian Supreme Court observed Sikhism and Jainism to be sub-sects or "special" faiths within the larger Hindu fold, and that Jainism is a denomination within the Hindu fold. Although the government of British India counted Jains in India as a major religious community right from the first Census conducted in 1873, after independence in 1947 Sikhs and Jains were not treated as national minorities. In 2005 the Supreme Court of India declined to issue a writ of Mandamus granting Jains the status of a religious minority throughout India. The Court however left it to the respective states to decide on the minority status of Jain religion.

However, some individual states have over the past few decades differed on whether Jains, Buddhists and Sikhs are religious minorities or not, by either pronouncing judgments or passing legislation. One example is the judgment passed by the Supreme Court in 2006, in a case pertaining to the state of Uttar Pradesh, which declared Jainism to be indisputably distinct from Hinduism, but mentioned that, "The question as to whether the Jains are part of the Hindu religion is open to debate. However, the Supreme Court also noted various court cases that have held Jainism to be a distinct religion.

Another example is the Gujarat Freedom of Religion Bill, that is an amendment to a legislation that sought to define Jains and Buddhists as denominations within Hinduism. Ultimately on 31 July 2007, finding it not in conformity with the concept of freedom of religion as embodied in Article 25 (1) of the Constitution, Governor Naval Kishore Sharma returned the Gujarat Freedom of Religion (Amendment) Bill, 2006 citing the widespread protests by the Jains as well as Supreme Court's extrajudicial observation that Jainism is a "special religion formed on the basis of quintessence of Hindu religion by the Supreme Court".








</doc>
<doc id="14606" url="https://en.wikipedia.org/wiki?curid=14606" title="Infusion (disambiguation)">
Infusion (disambiguation)

Infusion refers to the process of extracting chemical compounds or flavors from plant material in a solvent by allowing the material to remain suspended in the solvent over time.

Infusion may also refer to:




</doc>
<doc id="14607" url="https://en.wikipedia.org/wiki?curid=14607" title="Idaho">
Idaho

Idaho () is a state in the Pacific Northwest region of the United States. It borders the state of Montana to the east and northeast, Wyoming to the east, Nevada and Utah to the south, and Washington and Oregon to the west. To the north, it shares a small portion of the Canadian border with the province of British Columbia. With a population of approximately 1.7 million and an area of , Idaho is the 14th largest, the 12th least populous and the 7th least densely populated of the 50 U.S. states. The state's capital and largest city is Boise.

For thousands of years Idaho has been inhabited by Native American peoples. In the early 19th century, Idaho was considered part of the Oregon Country, an area disputed between the United States and the British Empire. It officially became U.S. territory with the signing of the Oregon Treaty of 1846, but a separate Idaho Territory was not organized until 1863, instead being included for periods in Oregon Territory and Washington Territory. Idaho was eventually admitted to the Union on July 3, 1890, becoming the 43rd state.

Forming part of the Pacific Northwest (and the associated Cascadia bioregion), Idaho is divided into several distinct geographic and climatic regions. The state's north, the relatively isolated Idaho Panhandle, is closely linked with Eastern Washington with which it shares the Pacific Time Zone—the rest of the state uses the Mountain Time Zone. The state's south includes the Snake River Plain (which has most of the population and agricultural land). The state's southeast incorporates part of the Great Basin. Idaho is quite mountainous, and contains several stretches of the Rocky Mountains. The United States Forest Service holds about 38% of Idaho's land, the highest proportion of any state.

Industries significant for the state economy include manufacturing, agriculture, mining, forestry, and tourism. A number of science and technology firms are either headquartered in Idaho or have factories there, and the state also contains the Idaho National Laboratory, which is the country's largest Department of Energy facility. Idaho's agricultural sector supplies many products, but the state is best known for its potato crop, which comprises around one-third of the nationwide yield. The official state nickname is the "Gem State", which references Idaho's natural beauty.

The name's origin remains a mystery. In the early 1860s, when the U.S. Congress was considering organizing a new territory in the Rocky Mountains, the name "Idaho" was suggested by George M. Willing, a politician posing as an unrecognized delegate from the unofficial Jefferson Territory. Willing claimed that the name was derived from a Shoshone term meaning "the sun comes from the mountains" or "gem of the mountains", but it was revealed later that there was no such term and Willing claimed that he had been inspired to coin the name when he met a little girl named "Ida". Since the name appeared to be fabricated, the U.S. Congress ultimately decided to name the area Colorado Territory instead when it was created in February 1861, but by the time this decision was made, the town of Idaho Springs, Colorado had already been named after Willing's proposal.

The same year Congress created Colorado Territory, a county called Idaho County was created in eastern Washington Territory. The county was named after a steamship named Idaho, which was launched on the Columbia River in 1860. It is unclear whether the steamship was named before or after Willing's claim was revealed. Regardless, part of Washington Territory, including Idaho County, was used to create Idaho Territory in 1863. Eventually, the name was given to the Idaho Territory, which would later become the U.S. state.

Despite this lack of evidence for the origin of the name, many textbooks well into the 20th century repeated as fact Willing's account the name "Idaho" derived from the Shoshone term "ee-da-how". A 1956 Idaho history textbook says:
"Idaho" is a Shoshoni Indian exclamation. The word consists of three parts. The first is "Ee", which in English conveys the idea of "coming down". The second is "dah" which is the Shoshoni stem or root for both "sun" and "mountain". The third syllable, "how", denotes the exclamation and stands for the same thing in Shoshoni that the exclamation mark (!) does in English. The Shoshoni word is "Ee-dah-how", and the Indian thought thus conveyed when translated into English means, "Behold! the sun coming down the mountain.

An alternative etymology attributes the name to the Plains Apache word "ídaahę́" (enemy) that was used in reference to the Comanche.

Idaho borders six U.S. states and one Canadian province. The states of Washington and Oregon are to the west, Nevada and Utah are to the south, and Montana and Wyoming are to the east. Idaho also shares a short border with the Canadian province of British Columbia to the north.

The landscape is rugged with some of the largest unspoiled natural areas in the United States. For example, at 2.3 million acres (930,000 ha), the Frank Church-River of No Return Wilderness Area is the largest contiguous area of protected wilderness in the continental United States. Idaho is a Rocky Mountain state with abundant natural resources and scenic areas. The state has snow-capped mountain ranges, rapids, vast lakes and steep canyons. The waters of the Snake River run through Hells Canyon, the deepest gorge in the United States. Shoshone Falls falls down cliffs from a height greater than Niagara Falls.

By far, the most important river in Idaho is the Snake River, a major tributary of the Columbia River. The Snake River flows out from Yellowstone in northwestern Wyoming through the Snake River Plain in southern Idaho before turning north, leaving the state at Lewiston before joining the Columbia in Kennewick. Other major rivers are the Clark Fork/Pend Oreille River, the Spokane River, and major tributaries of the Snake river, including the Clearwater River, the Salmon River, the Boise River, and the Payette River. The Salmon River empties into the Snake in Hells Canyon and forms the southern boundary of Nez Perce County on its north shore, of which Lewiston is the county seat. The Port of Lewiston, at the confluence of the Clearwater and the Snake Rivers is the farthest inland seaport on the West Coast at 465 river miles from the Pacific at Astoria, Oregon.

The vast majority of Idaho's population lives in the Snake River Plain, a valley running from across the entirety of southern Idaho from east to west. The valley contains the major cities of Boise, Meridian, Nampa, Caldwell, Twin Falls, Idaho Falls, and Pocatello. The plain served as an easy pass through the Rocky Mountains for westward-bound settlers on the Oregon Trail, and many settlers chose to settle the area rather than risking the treacherous route through the Blue Mountains and the Cascade Range to the west. The western region of the plain is known as the Treasure Valley, bound between the Owyhee Mountains to the southwest and the Boise Mountains to the northeast. The central region of the Snake River Plain is known as the Magic Valley.

Idaho's highest point is Borah Peak, , in the Lost River Range north of Mackay. Idaho's lowest point, , is in Lewiston, where the Clearwater River joins the Snake River and continues into Washington. The Sawtooth Range is often considered Idaho's most famous mountain range. Other mountain ranges in Idaho include the Bitterroot Range, the White Cloud Mountains, the Lost River Range, the Clearwater Mountains, and the Salmon River Mountains.

Idaho has two time zones, with the dividing line approximately midway between Canada and Nevada. Southern Idaho, including the Boise metropolitan area, Idaho Falls, Pocatello, and Twin Falls, are in the Mountain Time Zone. A legislative error ( §264) theoretically placed this region in the Central Time Zone, but this was corrected with a 2007 amendment. Areas north of the Salmon River, including Coeur d'Alene, Moscow, Lewiston, and Sandpoint, are in the Pacific Time Zone, which contains less than a quarter of the state's population and land area.

Idaho's climate varies widely. Although the state's western border is about from the Pacific Ocean, the maritime influence is still felt in Idaho, especially in the winter when cloud cover, humidity, and precipitation are at their maximum extent. This influence has a moderating effect in the winter where temperatures are not as low as would otherwise be expected for a northern state with predominantly high elevations. The maritime influence is least prominent in the state's eastern part where the precipitation patterns are often reversed, with wetter summers and drier winters, and seasonal temperature differences are more extreme, showing a more semi-arid continental climate.

Idaho can be hot, although extended periods over are rare, except for the lowest point in elevation, Lewiston, which correspondingly sees little snow. Hot summer days are tempered by the low relative humidity and cooler evenings during summer months since, for most of the state, the highest diurnal difference in temperature is often in the summer. Winters can be cold, although extended periods of bitter cold weather below zero are unusual. Idaho's all-time highest temperature of was recorded at Orofino on July 28, 1934; the all-time lowest temperature of was recorded at Island Park Dam on January 18, 1943.

Humans may have been present in the Idaho area as long as 14,500 years ago. Excavations at Wilson Butte Cave near Twin Falls in 1959 revealed evidence of human activity, including arrowheads, that rank among the oldest dated artifacts in North America. American Indian peoples predominant in the area included the Nez Percé in the north and the Northern and Western Shoshone in the south.

A Late Upper Paleolithic site was identified at Cooper's Ferry in western Idaho near the town of Cottonwood by archaeologists in 2019. Based on evidence found at the site, first people lived in this area 15,300 to 16,600 years ago, predating the Beringia land bridge by about a thousand years. The discoverers, anthropology professor Loren Davis and colleagues, emphasized that they possess similarities with tools and artifacts discovered in Japan that date from 16,000 to 13,000 years ago. The discovery also showed that the first people might not have come to North America by land, as previously theorized. On the contrary, they probably came through the water, using a Pacific coastal road.

An early presence of French-Canadian trappers is visible in names and toponyms: Nez Percé, Cœur d'Alène, Boisé, Payette, some preexisting the Lewis and Clark and Astorian expeditions which themselves included significant numbers of French and Métis guides recruited for their familiarity with the terrain.

Idaho, as part of the Oregon Country, was claimed by both the United States and Great Britain until the United States gained undisputed jurisdiction in 1846. From 1843 to 1849, present-day Idaho was under the de facto jurisdiction of the Provisional Government of Oregon. When Oregon became a state, what is now Idaho was in what remained of the original Oregon Territory not part of the new state, and designated as the Washington Territory.

Between then and the creation of the Idaho Territory on March 4, 1863, at Lewiston, parts of the present-day state were included in the Oregon, Washington, and Dakota Territories. The new territory included present-day Idaho, Montana, and most of Wyoming. The Lewis and Clark expedition crossed Idaho in 1805 on the way to the Pacific and in 1806 on the return, largely following the Clearwater River both directions. The first non-indigenous settlement was Kullyspell House, established on the shore of Lake Pend Oreille for fur trading in 1809 by David Thompson of the North West Company. In 1812 Donald Mackenzie, working for the Pacific Fur Company at the time, established a post on the lower Clearwater River near present-day Lewiston. This post, known as "MacKenzie's Post" or "Clearwater", operated until the Pacific Fur Company was bought out by the North West Company in 1813, after which it was abandoned. The first attempts at organized communities, within the present borders of Idaho, were established in 1860. The first permanent, substantial incorporated community was Lewiston in 1861.
After some tribulation as a territory, including the chaotic transfer of the territorial capital from Lewiston to Boise, disenfranchisement of Mormon polygamists upheld by the U.S. Supreme Court in 1877, and a federal attempt to split the territory between Washington Territory which gained statehood in 1889, a year before Idaho, and the state of Nevada which had been a state since 1864, Idaho achieved statehood in 1890.

Idaho was one of the hardest hit of the Pacific Northwest states during the Great Depression. Prices plummeted for Idaho's major crops: in 1932 a bushel of potatoes brought only ten cents compared to $1.51 in 1919, while Idaho farmers saw their annual income of $686 in 1929 drop to $250 by 1932.

In recent years, Idaho has expanded its commercial base as a tourism and agricultural state to include science and technology industries. Science and technology have become the largest single economic center (over 25% of the state's total revenue) within the state and are greater than agriculture, forestry and mining combined.

The United States Census Bureau estimates Idaho's population was 1,787,065 on July 1, 2018, a 14% increase since 2010.

Idaho had an estimated population of 1,754,208 in 2018, which was an increase of 37,265, from the prior year and an increase of 186,626, or 11.91%, since 2010. This includes a natural increase since the last census of 58,884 (111,131 births minus 52,247 deaths) and an increase due to net migration of 75,795 people into the state. There are large numbers of Americans of English and German ancestry in Idaho. Immigration from outside the United States resulted in a net increase of 14,522 people, and migration within the country produced a net increase of 61,273 people.

This made Idaho the tenth fastest-growing state after District of Columbia (+16.74%), Utah (+14.37%), Texas (+14.14%), Florida (+13.29%), Colorado (+13.25%), North Dakota (+13.01%), Nevada (+12.36%), Arizona (+12.20%) and Washington. From 2017 to 2018, Idaho grew the second-fastest, surpassed only by Nevada.

Nampa, about west of downtown Boise, became the state's second largest city in the late 1990s, passing Pocatello and Idaho Falls. Nampa's population was under 29,000 in 1990 and grew to over 81,000 by 2010. Located between Nampa and Boise, Meridian also experienced high growth, from fewer than 10,000 residents in 1990 to more than 75,000 in 2010 and is now Idaho's third largest city. Growth of 5% or more over the same period has also been observed in Caldwell, Coeur d'Alene, Post Falls, and Twin Falls.

From 1990 to 2010, Idaho's population increased by over 560,000 (55%). The Boise metropolitan area (officially known as the Boise City-Nampa, ID Metropolitan Statistical Area) is Idaho's largest metropolitan area. Other metropolitan areas in order of size are Coeur d'Alene, Idaho Falls, Pocatello and Lewiston.

The table below shows the racial composition of Idaho's population as of 2016.

According to the 2017 American Community Survey, 12.2% of Idaho's population were of Hispanic or Latino origin (of any race): Mexican (10.6%), Puerto Rican (0.2%), Cuban (0.1%), and other Hispanic or Latino origin (1.3%). The five largest ancestry groups were: German (17.5%), English (16.4%), Irish (9.3%), American (8.1%), and Scottish (3.2%).

"Note: Births in table don't add up, because Hispanics are counted both by their ethnicity and by their race, giving a higher overall number."


According to the Pew Research Center on Religion & Public Life, the self-identified religious affiliations of Idahoans over the age of 18 in 2008 and 2014 were:
According to the Association of Religion Data Archives, the largest denominations by number of members in 2010 were The Church of Jesus Christ of Latter-day Saints with 409,265; the Catholic Church with 123,400; the non-denominational Evangelical Protestant with 62,637; and the Assemblies of God with 22,183.

English is the state's predominant language. Minority languages include Spanish and various Native American languages.


Gross state product for 2015 was $64.9 billion, and the per capita income based on 2015 GDP and 2015 population estimates was $39,100.

Idaho is an important agricultural state, producing nearly one-third of the potatoes grown in the United States. All three varieties of wheat, dark northern spring, hard red, and soft white are grown in the state. Nez Perce County is considered a premier soft white growing locale.

Important industries in Idaho are food processing, lumber and wood products, machinery, chemical products, paper products, electronics manufacturing, silver and other mining, and tourism. The world's largest factory for barrel cheese, the raw product for processed cheese is in Gooding, Idaho. It has a capacity of 120,000 metric tons per year of barrel cheese and belongs to the Glanbia group. The Idaho National Laboratory (INL) is the largest Department of Energy facility in the country by area. INL is an important part of the eastern Idaho economy. Idaho also is home to three facilities of Anheuser-Busch which provide a large part of the malt for breweries across the nation.

A variety of industries are important. Outdoor recreation is a common example ranging from numerous snowmobile and downhill and cross-country ski areas in winter to the evolution of Lewiston as a retirement community based on mild winters, dry, year-round climate and one of the lowest median wind velocities anywhere, combined with the rivers for a wide variety of activities. Other examples would be ATK Corporation, which operates three ammunition and ammunition components plants in Lewiston. Two are sporting and one is defense contract. The Lewis-Clark valley has an additional independent ammunition components manufacturer and the Chipmunk rifle factory until it was purchased in 2007 by Keystone Sporting Arms and production was moved to Milton, Pennsylvania. Four of the world's six welded aluminum jet boat (for running river rapids) manufacturers are in the Lewiston-Clarkston, WA valley. Wine grapes were grown between Kendrick and Juliaetta in the Idaho Panhandle by the French Rothschilds until Prohibition. In keeping with this, while there are no large wineries or breweries in Idaho, there are numerous and growing numbers of award-winning boutique wineries and microbreweries in the northern part of the state.

Today, Idaho's largest industry is the science and technology sector. It accounts for over 25% of the state's revenue and over 70% of the state's exports. Idaho's industrial economy is growing, with high-tech products leading the way. Since the late 1970s, Boise has emerged as a center for semiconductor manufacturing. Boise is the home of Micron Technology, the only U.S. manufacturer of dynamic random-access memory (DRAM) chips. Micron at one time manufactured desktop computers, but with very limited success. Hewlett-Packard has operated a large plant in Boise since the 1970s, which is devoted primarily to LaserJet printers production. Boise-based Clearwater Analytics is another rapidly growing investment accounting and reporting software firm, reporting on over $1 trillion in assets. ON Semiconductor, whose worldwide headquarters is in Pocatello, is a widely recognized innovator of modern integrated mixed-signal semiconductor products, mixed-signal foundry services, and structured digital products. Coldwater Creek, a women's clothing retailer, is headquartered in Sandpoint. Sun Microsystems (now a part of Oracle Corporation) has two offices in Boise and a parts depot in Pocatello. Sun brings $4 million in annual salaries and over $300 million of revenue to the state each year.

A number of Fortune 500 companies started in or trace their roots to Idaho, including Safeway in American Falls, Albertsons in Boise, JR Simplot across southern Idaho, and Potlatch Corp. in Lewiston. Zimmerly Air Transport in Lewiston-Clarkston was one of the five companies in the merger centered around Varney Air Lines of Pasco, Washington, which became United Airlines and subsequently Varney Air Group which became Continental Airlines.

In 2014, Idaho emerged as the second most small business friendly state, ranking behind Utah, based on a study drawing upon data from more than 12,000 small business owners.

Idaho has a state gambling lottery which contributed $333.5 million in payments to all Idaho public schools and Idaho higher education from 1990 to 2006.

Tax is collected by the Idaho State Tax Commission.

The state personal income tax ranges from 1.6% to 7.8% in eight income brackets. Idahoans may apply for state tax credits for taxes paid to other states, as well as for donations to Idaho state educational entities and some nonprofit youth and rehabilitation facilities.

The state sales tax is 6% with a very limited, selective local option up to 6.5%. Sales tax applies to the sale, rental or lease of tangible personal property and some services. Food is taxed, but prescription drugs are not. Hotel, motel, and campground accommodations are taxed at a higher rate (7% to 11%). Some jurisdictions impose local option sales tax.

The sales tax was introduced at 3% in 1965, easily approved by voters, where it remained at 3% until 1983.

As of 2017, the primary energy source in Idaho was hydropower, and the energy companies had a total retail sales of 23,793,790 megawatthours (MWh). As of 2017, Idaho had a regulated electricity market, with the Idaho Public Utilities Commission regulating the three major utilities of Avista Utilities, Idaho Power, and Rocky Mountain Power.

Idaho's energy landscape is favorable to the development of renewable energy systems. The state is rich in renewable energy resources but has limited fossil fuel resources. The Snake River Plain and smaller river basins provide Idaho with some of the nation's best hydroelectric power resources and its geologically active mountain areas have significant geothermal power and wind power potential. These realities have shaped much of the state's energy landscape.

Idaho imports most of the energy it consumes. Imports account for more than 80% of energy consumption, including all of Idaho's natural gas and petroleum supplies and more than half of its electricity. Of the electricity consumed in Idaho in 2005, 48% came from hydroelectricity, 42% was generated by burning coal and 9% was generated by burning natural gas. The remainder came from other renewable sources such as wind.

The state's numerous river basins allow hydroelectric power plants to provide 556,000 MWh, which amounts to about three-fourths of Idaho's electricity generated in the state. Washington State provides most of the natural gas used in Idaho through one of the two major pipeline systems supplying the state. Although the state relies on out-of-state sources for its entire natural gas supply, it uses natural gas-fired plants to generate 127,000 MWh, or about ten percent of its output. Coal-fired generation and the state's small array of wind turbines supplies the remainder of the state's electricity output. The state produces 739,000 MWh but still needs to import half of its electricity from out-of-state to meet demand.

While Idaho's total energy consumption is low compared with other states and represents just 0.5% of United States consumption, the state also has the nation's 11th smallest population, 1.5 million, so its per capita energy consumption of is just above the national average of . As the 13th‑largest state in terms of land area of , distance creates the additional problem of "line loss". When the length of an electrical transmission line is doubled, the resistance to an electric current passing through it is also doubled.

In addition, Idaho also has the 6th fastest growing population in the United States with the population expected to increase by 31% from 2008 to 2030. This projected increase in population will contribute to a 42% increase in demand by 2030, further straining Idaho's finite hydroelectric resources.

Idaho has an upper-boundary estimate of development potential to generate 44,320 GWh/year from 18,076 MW of wind power, and 7,467,000 GWh/year from solar power using 2,061,000 MW of photovoltaics (PV), including 3,224 MW of rooftop photovoltaics, and 1,267,000 MW of concentrated solar power.

The Idaho Transportation Department is the government agency responsible for Idaho's transportation infrastructure, including operations and maintenance as well as planning for future needs. The agency is also responsible for overseeing the disbursement of federal, state, and grant funding for the transportation programs of the state.

Idaho is among the few states in the nation without a major freeway linking its two largest metropolitan areas, Boise in the south and Coeur d'Alene in the north. US-95 links the two ends of the state, but like many other highways in Idaho, it is badly in need of repair and upgrade. In 2007, the Idaho Transportation Department stated the state's highway infrastructure faces a $200 million per year shortfall in maintenance and upgrades. I-84 is the main highway linking the southeast and southwest portions of the state, along with I-86 and I-15.
Major federal aid highways in Idaho:

Major airports include the Boise International Airport which serves the southwest region of Idaho and the Spokane International Airport (in Spokane, Washington) which serves northern Idaho. Other airports with scheduled service are the Pullman-Moscow Regional Airport serving the Palouse; the Lewiston-Nez Perce County Airport, serving the Lewis-Clark Valley and north central and west central Idaho; The Magic Valley Regional Airport in Twin Falls; the Idaho Falls Regional Airport; and the Pocatello Regional Airport.

Idaho is served by three transcontinental railroads. The Burlington Northern Santa Fe (BNSF) connects the Idaho Panhandle with Seattle, Portland, and Spokane to the west, and Minneapolis and Chicago to the east. The BNSF travels through Kootenai, Bonner, and Boundary counties. The Union Pacific Railroad crosses North Idaho entering from Canada through Boundary and Bonner, and proceeding to Spokane. Canadian Pacific Railway uses Union Pacific Railroad tracks in North Idaho carrying products from Alberta to Spokane and Portland, Oregon. Amtrak's Empire Builder crosses northern Idaho, with its only stop being in Sandpoint. Montana Rail Link also operates between Billings, Montana and Sandpoint, Idaho

The Union Pacific Railroad also crosses southern Idaho traveling between Portland, Oregon, Green River, Wyoming, and Ogden, Utah and serves Boise, Nampa, Twin Falls, and Pocatello.

The Port of Lewiston is the farthest inland Pacific port on the west coast. A series of dams and locks on the Snake River and Columbia River facilitate barge travel from Lewiston to Portland, where goods are loaded on ocean-going vessels.

The constitution of Idaho is roughly modeled on the national constitution with several additions. The constitution defines the form and functions of the state government, and may be amended through plebiscite. Notably, the state constitution presently requires the state government to maintain a balanced budget. As result, Idaho has limited debt (construction bonds, etc.).

All of Idaho's state laws are contained in the Idaho Code and Statutes. The code is amended through the legislature with the approval of the governor. Idaho still operates under its original (1889) state constitution.

The constitution of Idaho provides for three branches of government: the executive, legislative and judicial branches. Idaho has a bicameral legislature, elected from 35 legislative districts, each represented by one senator and two representatives.

Since 1946, statewide elected constitutional officers have been elected to four-year terms. They include: Governor, Lieutenant Governor, Secretary of State, Idaho state controller (Auditor before 1994), Treasurer, Attorney General, and Superintendent of Public Instruction.

Last contested in 1966, Inspector of Mines was an originally elected constitutional office. Afterward it was an appointed position and ultimately done away with entirely in 1974.

Idaho's government has an alcohol monopoly.

The governor of Idaho serves a four-year term, and is elected during what is nationally referred to as midterm elections. As such, the governor is not elected in the same election year as the president of the United States. The current governor is Republican Brad Little, who was elected in 2018.

Idaho's legislature is part-time. However, the session may be extended if necessary, and often is. Because of this, Idaho's legislators are considered "citizen legislators", meaning their position as a legislator is not their main occupation.

Terms for both the Senate and House of Representatives are two years. Legislative elections occur every even numbered year.

The Idaho Legislature has been continuously controlled by the Republican Party since the late 1950s, although Democratic legislators are routinely elected from Boise, Pocatello, Blaine County and the northern Panhandle.

The highest court in Idaho is the Idaho Supreme Court. There is also an intermediate appellate court, the Idaho Court of Appeals, which hears cases assigned to it from the Supreme Court. The state's District Courts serve seven judicial districts.

Idaho is divided into political jurisdictions designated as "counties". Since 1919 there are 44 counties in the state, ranging in size from .

Three counties were first designated as such by the Washington Territorial Legislature in 1861; they were subsequently redesignated as Idaho counties in 1864. The 1861 Nez Percé county has since been broken up into Nez Percé, Lewis, Boundary, Benewah, Latah, Kootenai, and Clearwater counties.

Idaho license plates begin with a county designation based on the first letter of the county's name. Where a letter is at the beginning of more than one name, a number accompanies precedingly in alphabetical order. This reflects an anomalous coincidental situation wherein 10 counties begin with B, seven with C and four with L, which is 21 of the 44 counties.

After the Civil War, many Midwestern and Southern Democrats moved to the Idaho Territory. As a result, the early territorial legislatures were solidly Democrat-controlled. In contrast, most of the territorial governors were appointed by Republican presidents and were Republicans. This led to sometimes-bitter clashes between the two parties, including a range war with the Democrats backing the sheepherders and the Republicans the cattlemen, which ended in the "Diamondfield" Jack Davis murder trial. In the 1880s, Republicans became more prominent in local politics.

In 1864, Clinton DeWitt Smith removed the territorial seal and the state constitution from a locked safe, and took them to Boise. This effectively moved the capital from where they were stored (Lewiston, Idaho) to the current capital Boise.

Since statehood, the Republican Party has usually been the dominant party in Idaho. At one time, Idaho had two Democratic parties, one being the mainstream and the other called the Anti-Mormon Democrats, lasting into the early 20th century. In the 1890s and early 1900s, the Populist Party enjoyed prominence while the Democratic Party maintained a brief dominance in the 1930s during the Great Depression. Since World WarII most statewide-elected officials have been Republicans, though the Democrats did hold the majority in the House (by one seat) in 1958 and the governorship from 1971 to 1995.

Idaho Congressional delegations have also been generally Republican since statehood. Several Idaho Democrats have had electoral success in the House over the years, but the Senate delegation has been a Republican stronghold for decades. Several Idaho Republicans, including current Senator Mike Crapo, have won reelection to the Senate, but only Frank Church has won reelection as a Democrat. Church was the last Idaho Democrat to win a U.S. Senate race, in 1974. Walt Minnick's 2008 win in the First Congressional District was the state's first Democratic Congressional victory in 16 years.

In modern times, Idaho has been a reliably Republican state in presidential politics. It has not supported a Democrat for president since 1964. Even in that election, Lyndon Johnson defeated Barry Goldwater in the state by fewer than two percentage points, compared to a landslide nationally. In 2004, Republican George W. Bush carried Idaho by a margin of 38 percentage points and with 68.4% of the vote, winning in 43 of 44 counties. Only Blaine County, which contains the Sun Valley ski resort, supported John Kerry, who owns a home in the area. In 2008 Barack Obama's 36.1 percent showing was the best for a Democratic presidential candidate in Idaho since 1976. However, Republican margins were narrower in 1992 and 1976.

In the 2006 elections, Republicans, led by gubernatorial candidate CL "Butch" Otter, won all the state's constitutional offices and retained both of the state's seats in the United States House of Representatives. However, Democrats picked up several seats in the Idaho Legislature, notably in the Boise area.

Republicans lost one of the House seats in 2008 to Minnick, but Republican Jim Risch retained Larry Craig's Senate seat for the GOP by a comfortable margin. Minnick lost his seat in the 2010 election to Republican State Rep. Raul Labrador.




As of January 2020, the State of Idaho contains 105 school districts and 62 charter schools. The school districts range in enrollment from two to 39,507 students.

Idaho school districts are governed by elected school boards, which are elected in November of odd-numbered years, except for the Boise School District, whose elections are held in September.

The Idaho State Board of Education oversees three comprehensive universities. The University of Idaho in Moscow was the first university in the state (founded in 1889). It opened its doors in 1892 and is the land-grant institution and primary research university of the state. Idaho State University in Pocatello opened in 1901 as the Academy of Idaho, attained four-year status in 1947 and university status in 1963. Boise State University is the most recent school to attain university status in Idaho. The school opened in 1932 as Boise Junior College and became Boise State University in 1974. Lewis-Clark State College in Lewiston is the only public, non-university four-year college in Idaho. It opened as a normal school in 1893.

Idaho has four regional community colleges: North Idaho College in Coeur d'Alene; College of Southern Idaho in Twin Falls; College of Western Idaho in Nampa, which opened in 2009, College of Eastern Idaho in Idaho Falls, which transitioned from a technical college in 2017.

Private institutions in Idaho are Boise Bible College, affiliated with congregations of the Christian churches and churches of Christ; Brigham Young University-Idaho in Rexburg, which is affiliated with The Church of Jesus Christ of Latter-day Saints and a sister college to Brigham Young University; The College of Idaho in Caldwell, which still maintains a loose affiliation with the Presbyterian Church; Northwest Nazarene University in Nampa; and New Saint Andrews College in Moscow, of reformed Christian theological background. McCall College is a non-affiliated two-year private college in McCall, which was founded in 2011 and later opened in 2013.

Central Idaho is home to one of North America's oldest ski resorts, Sun Valley, where the world's first chairlift was installed in 1936. Other noted outdoor sites include Hells Canyon, the Salmon River, and its embarkation point of Riggins.

The Boise Open professional golf tournament has been played at Hillcrest Country Club since 1990 as part of the Web.com Tour.

High school sports are overseen by the Idaho High School Activities Association (IHSAA).

In 2016, Meridian's Michael Slagowski ran 800 meters in 1:48.70. That is one of the 35 fastest 800-meter times ever run by a high school boy in the United States. Weeks later, he would become only the ninth high school boy to complete a mile in under four minutes, running 3:59.53.

Judy Garland performed the elaborate song-and-dance routine "Born in a Trunk in the Princess Theater in Pocatello, Idaho" in the 1954 version of the film "A Star is Born".

The 1985 film "Pale Rider" was primarily filmed in the Boulder Mountains and the Sawtooth National Recreation Area in central Idaho, just north of Sun Valley.

The 1988 film "Moving", starring Richard Pryor, has the main character take a promotion in Idaho.

River Phoenix and Keanu Reeves starred in the 1991 movie "My Own Private Idaho", portions of which take place in Idaho.

The 2004 cult film "Napoleon Dynamite" takes place in Preston, Idaho; the film's director, Jared Hess, attended Preston High School.




</doc>
<doc id="14611" url="https://en.wikipedia.org/wiki?curid=14611" title="Italian">
Italian

Italian may refer to:




</doc>
<doc id="14612" url="https://en.wikipedia.org/wiki?curid=14612" title="Interrogatories">
Interrogatories

In law, interrogatories (also known as requests for further information) are a formal set of written questions propounded by one litigant and required to be answered by an adversary in order to clarify matters of fact and help to determine in advance what facts will be presented at any trial in the case.

Interrogatories are used to gain information from the other party relevant to the issues in a lawsuit. The law and issues will differ depending upon the facts of a case and the laws of the jurisdiction in which a lawsuit is filed. For some types of cases there are standard sets of interrogatories available that cover the essential facts, and may be modified for the case in which they are used.

When a lawsuit is filed, the pleadings filed by the parties are intended to let the other parties know what each side intends to prove at trial, and what legal case they have to answer. However, in most cases, the parties will require additional information to fully understand each other's legal and factual claims. The discovery process, including the use of interrogatories, can help the parties obtain that information from each other.

For an example of how interrogatories may be used, in a motor vehicle accident lawsuit an injured plaintiff typically asserts that the defendant driver committed the tort of negligence in causing the accident. To prove negligence, the law requires the injured plaintiff to show that the driver owed them a duty of care and breached it, causing the injury. Assuming that the defendant did not dispute driving a vehicle that was involved in the accident that injured the plaintiff, the case would come down to whether the driver drove in accordance with the standard of a reasonable driver, and whether the injured person's injuries are a foreseeable consequence of the driving.

The parties may use interrogatories to seek information, including concessions as to how the accident occurred, from each other. The injured plaintiff might serve interrogatories on the defendant driver seeking information that would support the plaintiff's theory of the case. If the plaintiff is alleging that the defendant was speeding, the plaintiff might ask the defendant to state the speed of the defendant's vehicle at the time of the accident. If the plaintiff alleges that the defendant failed to control the car properly or failed to pay proper attention to the road and other vehicles, the plaintiff could ask interrogatory questions that would help prove those allegations or require disclosure of the basis of any denial of negligence by the defendant. The driver may have a defense to those allegations, perhaps if the accident occurred at low speed, and was unavoidable (maybe due to some third party intervention). The injured person may, however, argue that the driver was still responsible (perhaps the driver should have used the horn of the vehicle to alert the third party), or there may be other allegations.

The defense may similarly use interrogatories to help build legal and factual defenses to the plaintiff's case. Continuing with the example of a car accident, the defendant may seek information or concessions from the plaintiff that would suggest that a different driver was partially or wholly responsible for the accident, or that under the facts the accident was unavoidable despite the proper exercise of care.

In England and Wales, this procedure is governed by Part 18 of the Civil Procedure Rules. It is known as a "Request for Further Information".

In the "Request for Further Information" procedure, use of standard pre-printed forms is not common, and any such request would almost certainly be looked upon critically by the courts, as use of standard forms rather than requests tailored specifically to the case is likely to offend against the 'Overriding Objective' in that it is unlikely to be proportionate to the case, and instead result in the parties or their lawyers having to spend time, money and resources in answering the questions. The way the rules work, this could easily result in the party making the request having to pay both their own costs and the costs of the opponent - even if they win the case at the end.

In England and Wales, firstly the person wanting to know the information requests it in writing, either in letter form or, more usually, on a blank document with the questions on one side of the page and space for the answers on the other side. A deadline is set for the opponent to answer the request. If they fail to answer, the person requesting can make an Application on Notice to the court and ask the procedural judge to make an order compelling the opponent to answer the questions. Whether the judge will make an order is discretionary and will be determined in accordance with the overriding objective, and in the context of the questions asked.

In particular, the procedure is not intended to be used to ask questions that would ordinarily be dealt with at trial.

In the United States, use of interrogatories is governed by the law where the case has been filed. All federal courts operate under the Federal Rules of Civil Procedure, which places various limitations on the use of this device, permitting individual jurisdictions to limit interrogatories to twenty-five questions per party. Interrogatories are typically "verified", meaning that the response will include an affidavit and will therefore be under oath. The affidavit may distinguish interrogatories from requests for admission, which are not normally answered under oath.

California, on the other hand, operates under the Civil Discovery Act of 1986 (a revision of an older 1957 act), which is codified in the California Code of Civil Procedure. The Discovery Act allows up to thirty-five specially prepared interrogatories per party, but this limit may be exceeded simply by executing and serving a declaration of necessity with the interrogatories. However, because the declaration of necessity must be executed under penalty of perjury, it can expose an attorney to "personal" sanctions for propounding an excessive number of harassing and burdensome interrogatories.

In nearly all U.S. jurisdictions, interrogatories are called just that and are supposed to be custom-written, although many questions can be reused from one case to the next. In the U.S. states of California, New Jersey, and Florida, the courts have promulgated standard "form" interrogatories. In California these come on an official court form promulgated by the Judicial Council of California and a party may ask another party to answer any of them by checking the appropriate boxes. The advantage of the California form interrogatories is that they do not count against the limit of 35 (except when used in limited civil cases); the disadvantage is that they are written in a very generic fashion, so about half of the questions are useful only in the simplest cases. In turn, California calls custom-written interrogatories "specially prepared interrogatories."

Because interrogatories are so heavily used in American discovery, there are two major compilations of generic interrogatories covering almost every conceivable type of legal case: "Bender's Forms of Discovery: Interrogatories" (published by LexisNexis) and "Pattern Discovery" (published by West).



</doc>
<doc id="14613" url="https://en.wikipedia.org/wiki?curid=14613" title="List of infectious diseases">
List of infectious diseases

This is a list of infectious diseases arranged by name, along with the infectious agents that cause them.




</doc>
<doc id="14617" url="https://en.wikipedia.org/wiki?curid=14617" title="Intel">
Intel

Intel Corporation is an American multinational corporation and technology company headquartered in Santa Clara, California, in Silicon Valley. It is the world's largest and highest valued semiconductor chip manufacturer based on revenue, and is the inventor of the x86 series of microprocessors, the processors found in most personal computers (PCs). Intel ranked No. 46 in the 2018 "Fortune" 500 list of the largest United States corporations by total revenue. Intel is incorporated in Delaware.

Intel supplies microprocessors for computer system manufacturers such as Apple, Lenovo, HP, and Dell. Intel also manufactures motherboard chipsets, network interface controllers and integrated circuits, flash memory, graphics chips, embedded processors and other devices related to communications and computing.

Intel Corporation was founded on July 18, 1968 by semiconductor pioneers Robert Noyce and Gordon Moore (of Moore's law), and is associated with the executive leadership and vision of Andrew Grove. The company's name was conceived as portmanteau of the words "int"egrated and "el"ectronics, with co-founder Noyce having been a key inventor of the integrated circuit (the microchip). The fact that "intel" is the term for intelligence information also made the name appropriate. Intel was an early developer of SRAM and DRAM memory chips, which represented the majority of its business until 1981. Although Intel created the world's first commercial microprocessor chip in 1971, it was not until the success of the personal computer (PC) that this became its primary business.

During the 1990s, Intel invested heavily in new microprocessor designs fostering the rapid growth of the computer industry. During this period, Intel became the dominant supplier of microprocessors for PCs and was known for aggressive and anti-competitive tactics in defense of its market position, particularly against Advanced Micro Devices (AMD), as well as a struggle with Microsoft for control over the direction of the PC industry.

The Open Source Technology Center at Intel hosts PowerTOP and LatencyTOP, and supports other open-source projects such as Wayland, Mesa3D, Intel Array Building Blocks, Threading Building Blocks (TBB), and Xen.

In 2017, Dell accounted for about 16% of Intel's total revenues, Lenovo accounted for 13% of total revenues, and HP Inc. accounted for 11% of total revenues.

According to IDC, while Intel enjoyed the biggest market share in both the overall worldwide PC microprocessor market (73.3%) and the mobile PC microprocessor (80.4%) in the second quarter of 2011, the numbers decreased by 1.5% and 1.9% compared to the first quarter of 2011.

Intel's market share decreased significantly in the enthusiast market as of 2019, and they have faced delays for their 10 nm products. According to Intel CEO Bob Swan, the delay was caused by the company's overly aggressive strategy for moving to its next node.

In the 1980s Intel was among the top ten sellers of semiconductors (10th in 1987) in the world. In 1992, Intel became the biggest chip maker by revenue and has held the position ever since. Other top semiconductor companies include TSMC, Advanced Micro Devices, Samsung, Texas Instruments, Toshiba and STMicroelectronics.

Competitors in PC chipsets include Advanced Micro Devices, VIA Technologies, Silicon Integrated Systems, and Nvidia. Intel's competitors in networking include NXP Semiconductors, Infineon, Broadcom Limited, Marvell Technology Group and Applied Micro Circuits Corporation, and competitors in flash memory include Spansion, Samsung, Qimonda, Toshiba, STMicroelectronics, and SK Hynix.

The only major competitor in the x86 processor market is Advanced Micro Devices (AMD), with which Intel has had full cross-licensing agreements since 1976: each partner can use the other's patented technological innovations without charge after a certain time. However, the cross-licensing agreement is canceled in the event of an AMD bankruptcy or takeover.

Some smaller competitors such as VIA Technologies produce low-power x86 processors for small factor computers and portable equipment. However, the advent of such mobile computing devices, in particular, smartphones, has in recent years led to a decline in PC sales. Since over 95% of the world's smartphones currently use processors designed by ARM Holdings, ARM has become a major competitor for Intel's processor market. ARM is also planning to make inroads into the PC and server market.

Intel has been involved in several disputes regarding violation of antitrust laws, which are noted below.

Intel was founded in Mountain View, California, in 1968 by Gordon E. Moore (known for "Moore's law"), a chemist, and Robert Noyce, a physicist and co-inventor of the integrated circuit. Arthur Rock (investor and venture capitalist) helped them find investors, while Max Palevsky was on the board from an early stage. Moore and Noyce had left Fairchild Semiconductor to found Intel. Rock was not an employee, but he was an investor and was chairman of the board. The total initial investment in Intel was $2.5 million in convertible debentures (equivalent to $ million in ) and $10,000 from Rock. Just 2 years later, Intel became a public company via an initial public offering (IPO), raising $6.8 million ($23.50 per share). Intel's third employee was Andy Grove, a chemical engineer, who later ran the company through much of the 1980s and the high-growth 1990s.

In deciding on a name, Moore and Noyce quickly rejected "Moore Noyce", near homophone for "more noise" – an ill-suited name for an electronics company, since noise in electronics is usually undesirable and typically associated with bad interference. Instead, they founded the company as N M Electronics on July 18, 1968, but by the end of the month had changed the name to Intel which stood for Integrated Electronics. Since "Intel" was already trademarked by the hotel chain Intelco, they had to buy the rights for the name.

At its founding, Intel was distinguished by its ability to make logic circuits using semiconductor devices. The founders' goal was the semiconductor memory market, widely predicted to replace magnetic-core memory. Its first product, a quick entry into the small, high-speed memory market in 1969, was the 3101 Schottky TTL bipolar 64-bit static random-access memory (SRAM), which was nearly twice as fast as earlier Schottky diode implementations by Fairchild and the Electrotechnical Laboratory in Tsukuba, Japan. In the same year, Intel also produced the 3301 Schottky bipolar 1024-bit read-only memory (ROM) and the first commercial metal–oxide–semiconductor field-effect transistor (MOSFET) silicon gate SRAM chip, the 256-bit 1101. While the 1101 was a significant advance, its complex static cell structure made it too slow and costly for mainframe memories. The three-transistor cell implemented in the first commercially available dynamic random-access memory (DRAM), the 1103 released in 1970, solved these issues. The 1103 was the bestselling semiconductor memory chip in the world by 1972, as it replaced core memory in many applications. Intel's business grew during the 1970s as it expanded and improved its manufacturing processes and produced a wider range of products, still dominated by various memory devices.

Intel created the first commercially available microprocessor (Intel 4004) in 1971. The microprocessor represented a notable advance in the technology of integrated circuitry, as it miniaturized the central processing unit of a computer, which then made it possible for small machines to perform calculations that in the past only very large machines could do. Considerable technological innovation was needed before the microprocessor could actually become the basis of what was first known as a "mini computer" and then known as a "personal computer". Intel also created one of the first microcomputers in 1973. Intel opened its first international manufacturing facility in 1972, in Malaysia, which would host multiple Intel operations, before opening assembly facilities and semiconductor plants in Singapore and Jerusalem in the early 1980s, and manufacturing and development centres in China, India and Costa Rica in the 1990s. By the early 1980s, its business was dominated by dynamic random-access memory (DRAM) chips. However, increased competition from Japanese semiconductor manufacturers had, by 1983, dramatically reduced the profitability of this market. The growing success of the IBM personal computer, based on an Intel microprocessor, was among factors that convinced Gordon Moore (CEO since 1975) to shift the company's focus to microprocessors and to change fundamental aspects of that business model. Moore's decision to sole-source Intel's 386 chip played into the company's continuing success.

By the end of the 1980s, buoyed by its fortuitous position as microprocessor supplier to IBM and IBM's competitors within the rapidly growing personal computer market, Intel embarked on a 10-year period of unprecedented growth as the primary (and most profitable) hardware supplier to the PC industry, part of the winning 'Wintel' combination. Moore handed over to Andy Grove in 1987. By launching its Intel Inside marketing campaign in 1991, Intel was able to associate brand loyalty with consumer selection, so that by the end of the 1990s, its line of Pentium processors had become a household name.

After 2000, growth in demand for high-end microprocessors slowed. Competitors, notably AMD (Intel's largest competitor in its primary x86 architecture market), garnered significant market share, initially in low-end and mid-range processors but ultimately across the product range, and Intel's dominant position in its core market was greatly reduced, mostly due to controversial NetBurst microarchitecture. In the early 2000s then-CEO, Craig Barrett attempted to diversify the company's business beyond semiconductors, but few of these activities were ultimately successful.

Intel had also for a number of years been embroiled in litigation. US law did not initially recognize intellectual property rights related to microprocessor topology (circuit layouts), until the Semiconductor Chip Protection Act of 1984, a law sought by Intel and the Semiconductor Industry Association (SIA). During the late 1980s and 1990s (after this law was passed), Intel also sued companies that tried to develop competitor chips to the 80386 CPU. The lawsuits were noted to significantly burden the competition with legal bills, even if Intel lost the suits. Antitrust allegations had been simmering since the early 1990s and had been the cause of one lawsuit against Intel in 1991. In 2004 and 2005, AMD brought further claims against Intel related to unfair competition.

In 2005, CEO Paul Otellini reorganized the company to refocus its core processor and chipset business on platforms (enterprise, digital home, digital health, and mobility).

In 2006, Intel unveiled its Core microarchitecture to widespread critical acclaim; the product range was perceived as an exceptional leap in processor performance that at a stroke regained much of its leadership of the field. In 2008, Intel had another "tick" when it introduced the Penryn microarchitecture, which was 45 nm. Later that year, Intel released a processor with the Nehalem architecture. Nehalem had positive reviews.

On June 27, 2006, the sale of Intel's XScale assets was announced. Intel agreed to sell the XScale processor business to Marvell Technology Group for an estimated $600 million and the assumption of unspecified liabilities. The move was intended to permit Intel to focus its resources on its core x86 and server businesses, and the acquisition completed on November 9, 2006.

In 2010, Intel purchased McAfee, a manufacturer of computer security technology, for $7.68 billion. As a condition for regulatory approval of the transaction, Intel agreed to provide rival security firms with all necessary information that would allow their products to use Intel's chips and personal computers. After the acquisition, Intel had about 90,000 employees, including about 12,000 software engineers. In September 2016, Intel sold a majority stake in its computer-security unit to TPG Capital, reversing the five-year-old McAfee acquisition.

In August 2010, Intel and Infineon Technologies announced that Intel would acquire Infineon's Wireless Solutions business. Intel planned to use Infineon's technology in laptops, smart phones, netbooks, tablets and embedded computers in consumer products, eventually integrating its wireless modem into Intel's silicon chips.

In March 2011, Intel bought most of the assets of Cairo-based SySDSoft.

In July 2011, Intel announced that it had agreed to acquire Fulcrum Microsystems Inc., a company specializing in network switches. The company used to be included on the EE Times list of 60 Emerging Startups.

In October 2011, Intel reached a deal to acquire Telmap, an Israeli-based navigation software company. The purchase price was not disclosed, but Israeli media reported values around $300 million to $350 million.

In July 2012, Intel agreed to buy 10% of the shares of ASML Holding NV for $2.1 billion and another $1 billion for 5% of the shares that need shareholder approval to fund relevant research and development efforts, as part of a EUR3.3 billion ($4.1 billion) deal to accelerate the development of 450-millimeter wafer technology and extreme ultra-violet lithography by as much as two years.

In July 2013, Intel confirmed the acquisition of Omek Interactive, an Israeli company that makes technology for gesture-based interfaces, without disclosing the monetary value of the deal. An official statement from Intel read: "The acquisition of Omek Interactive will help increase Intel's capabilities in the delivery of more immersive perceptual computing experiences." One report estimated the value of the acquisition between US$30 million and $50 million.

The acquisition of a Spanish natural language recognition startup, Indisys was announced in September 2013. The terms of the deal were not disclosed but an email from an Intel representative stated: "Intel has acquired Indisys, a privately held company based in Seville, Spain. The majority of Indisys employees joined Intel. We signed the agreement to acquire the company on May 31 and the deal has been completed." Indysis explains that its artificial intelligence (AI) technology "is a human image, which converses fluently and with common sense in multiple languages and also works in different platforms."

In December 2014, Intel bought PasswordBox.

In January 2015, Intel purchased a 30% stake in Vuzix, a smart glasses manufacturer. The deal was worth $24.8 million.

In February 2015, Intel announced its agreement to purchase German network chipmaker Lantiq, to aid in its expansion of its range of chips in devices with Internet connection capability.

In June 2015, Intel announced its agreement to purchase FPGA design company Altera for $16.7 billion, in its largest acquisition to date. The acquisition completed in December 2015.

In October 2015, Intel bought cognitive computing company Saffron Technology for an undisclosed price.

In August 2016, Intel purchased deep-learning startup Nervana Systems for $350 million.

In December 2016, Intel acquired computer vision startup Movidius for an undisclosed price.

In March 2017, Intel announced that they had agreed to purchase Mobileye, an Israeli developer of "autonomous driving" systems for US$15.3 billion.

In June 2017, Intel Corporation announced an investment of over Rs.1100 crore ($170 million) for its upcoming Research and Development (R&D) centre in Bangalore.

In January 2019, Intel announced an investment of over $11 billion on a new Israeli chip plant, as told by the Israeli Finance Minister.

In 2008, Intel spun off key assets of a solar startup business effort to form an independent company, SpectraWatt Inc. In 2011, SpectraWatt filed for bankruptcy.

In February 2011, Intel began to build a new microprocessor manufacturing facility in Chandler, Arizona, completed in 2013 at a cost of $5 billion. The building was never used. The company produces three-quarters of its products in the United States, although three-quarters of its revenue come from overseas.

In April 2011, Intel began a pilot project with ZTE Corporation to produce smartphones using the Intel Atom processor for China's domestic market.

In December 2011, Intel announced that it reorganized several of its business units into a new mobile and communications group that would be responsible for the company's smartphone, tablet, and wireless efforts.

Finding itself with excess fab capacity after the failure of the Ultrabook to gain market traction and with PC sales declining, in 2013 Intel reached a foundry agreement to produce chips for Altera using 14-nm process. General Manager of Intel's custom foundry division Sunit Rikhi indicated that Intel would pursue further such deals in the future. This was after poor sales of Windows 8 hardware caused a major retrenchment for most of the major semiconductor manufacturers, except for Qualcomm, which continued to see healthy purchases from its largest customer, Apple.

As of July 2013, five companies were using Intel's fabs via the "Intel Custom Foundry" division: Achronix, Tabula, Netronome, Microsemi, and Panasonic most are field-programmable gate array (FPGA) makers, but Netronome designs network processors. Only Achronix began shipping chips made by Intel using the 22-nm Tri-Gate process. Several other customers also exist but were not announced at the time.

The Alliance for Affordable Internet (A4AI) was launched in October 2013 and Intel is part of the coalition of public and private organisations that also includes Facebook, Google, and Microsoft. Led by Sir Tim Berners-Lee, the A4AI seeks to make Internet access more affordable so that access is broadened in the developing world, where only 31% of people are online. Google will help to decrease Internet access prices so that they fall below the UN Broadband Commission's worldwide target of 5% of monthly income.

In October 2018, Arm Holdings partnered with Intel in order to share code for embedded systems through the Yocto Project.

On July 25, 2019, Apple and Intel announced an agreement for Apple to acquire the smartphone modem business of Intel Mobile Communications for US$1 billion.

Intel's first products were shift register memory and random-access memory integrated circuits, and Intel grew to be a leader in the fiercely competitive DRAM, SRAM, and ROM markets throughout the 1970s. Concurrently, Intel engineers Marcian Hoff, Federico Faggin, Stanley Mazor and Masatoshi Shima invented Intel's first microprocessor. Originally developed for the Japanese company Busicom to replace a number of ASICs in a calculator already produced by Busicom, the Intel 4004 was introduced to the mass market on November 15, 1971, though the microprocessor did not become the core of Intel's business until the mid-1980s. (Note: Intel is usually given credit with Texas Instruments for the almost-simultaneous invention of the microprocessor)

In 1983, at the dawn of the personal computer era, Intel's profits came under increased pressure from Japanese memory-chip manufacturers, and then-president Andy Grove focused the company on microprocessors. Grove described this transition in the book "Only the Paranoid Survive". A key element of his plan was the notion, then considered radical, of becoming the single source for successors to the popular 8086 microprocessor.

Until then, the manufacture of complex integrated circuits was not reliable enough for customers to depend on a single supplier, but Grove began producing processors in three geographically distinct factories, and ceased licensing the chip designs to competitors such as Zilog and AMD. When the PC industry boomed in the late 1980s and 1990s, Intel was one of the primary beneficiaries.

Despite the ultimate importance of the microprocessor, the 4004 and its successors the 8008 and the 8080 were never major revenue contributors at Intel. As the next processor, the 8086 (and its variant the 8088) was completed in 1978, Intel embarked on a major marketing and sales campaign for that chip nicknamed "Operation Crush", and intended to win as many customers for the processor as possible. One design win was the newly created IBM PC division, though the importance of this was not fully realized at the time.

IBM introduced its personal computer in 1981, and it was rapidly successful. In 1982, Intel created the 80286 microprocessor, which, two years later, was used in the IBM PC/AT. Compaq, the first IBM PC "clone" manufacturer, produced a desktop system based on the faster 80286 processor in 1985 and in 1986 quickly followed with the first 80386-based system, beating IBM and establishing a competitive market for PC-compatible systems and setting up Intel as a key component supplier.

In 1975, the company had started a project to develop a highly advanced 32-bit microprocessor, finally released in 1981 as the Intel iAPX 432. The project was too ambitious and the processor was never able to meet its performance objectives, and it failed in the marketplace. Intel extended the x86 architecture to 32 bits instead.

During this period Andrew Grove dramatically redirected the company, closing much of its DRAM business and directing resources to the microprocessor business. Of perhaps greater importance was his decision to "single-source" the 386 microprocessor. Prior to this, microprocessor manufacturing was in its infancy, and manufacturing problems frequently reduced or stopped production, interrupting supplies to customers. To mitigate this risk, these customers typically insisted that multiple manufacturers produce chips they could use to ensure a consistent supply. The 8080 and 8086-series microprocessors were produced by several companies, notably AMD, with which Intel had a technology-sharing contract. Grove made the decision not to license the 386 design to other manufacturers, instead, producing it in three geographically distinct factories: Santa Clara, California; Hillsboro, Oregon; and Chandler, a suburb of Phoenix, Arizona. He convinced customers that this would ensure consistent delivery. In doing this, Intel breached its contract with AMD, which sued and was paid millions of dollars in damages but could not manufacture new Intel CPU designs any longer. (Instead, AMD started to develop and manufacture its own competing x86 designs.) As the success of Compaq's Deskpro 386 established the 386 as the dominant CPU choice, Intel achieved a position of near-exclusive dominance as its supplier. Profits from this funded rapid development of both higher-performance chip designs and higher-performance manufacturing capabilities, propelling Intel to a position of unquestioned leadership by the early 1990s.

Intel introduced the 486 microprocessor in 1989, and in 1990 established a second design team, designing the processors code-named "P5" and "P6" in parallel and committing to a major new processor every two years, versus the four or more years such designs had previously taken. Engineers Vinod Dham and Rajeev Chandrasekhar (Member of Parliament, India) were key figures on the core team that invented the 486 chip and later, Intel's signature Pentium chip. The P5 project was earlier known as "Operation Bicycle," referring to the cycles of the processor through two parallel execution pipelines. The P5 was introduced in 1993 as the Intel Pentium, substituting a registered trademark name for the former part number (numbers, such as 486, cannot be legally registered as trademarks in the United States). The P6 followed in 1995 as the Pentium Pro and improved into the Pentium II in 1997. New architectures were developed alternately in Santa Clara, California and Hillsboro, Oregon.

The Santa Clara design team embarked in 1993 on a successor to the x86 architecture, codenamed "P7". The first attempt was dropped a year later but quickly revived in a cooperative program with Hewlett-Packard engineers, though Intel soon took over primary design responsibility. The resulting implementation of the IA-64 64-bit architecture was the Itanium, finally introduced in June 2001. The Itanium's performance running legacy x86 code did not meet expectations, and it failed to compete effectively with x86-64, which was AMD's 64-bit extension of the 32-bit x86 architecture (Intel uses the name Intel 64, previously EM64T). In 2017, Intel announced that the would be the last Itanium chips produced.

The Hillsboro team designed the Willamette processors (initially code-named P68), which were marketed as the Pentium 4.

In June 1994, Intel engineers discovered a flaw in the floating-point math subsection of the P5 Pentium microprocessor. Under certain data-dependent conditions, the low-order bits of the result of a floating-point division would be incorrect. The error could compound in subsequent calculations. Intel corrected the error in a future chip revision, and under public pressure it issued a total recall and replaced the defective Pentium CPUs (which were limited to some 60, 66, 75, 90, and 100 MHz models) on customer request.

The bug was discovered independently in October 1994 by Thomas Nicely, Professor of Mathematics at Lynchburg College. He contacted Intel but received no response. On October 30, he posted a message about his finding on the Internet. Word of the bug spread quickly and reached the industry press. The bug was easy to replicate; a user could enter specific numbers into the calculator on the operating system. Consequently, many users did not accept Intel's statements that the error was minor and "not even an erratum." During Thanksgiving, in 1994, "The New York Times" ran a piece by journalist John Markoff spotlighting the error. Intel changed its position and offered to replace every chip, quickly putting in place a large end-user support organization. This resulted in a $475 million charge against Intel's 1994 revenue. Dr. Nicely later learned that Intel had discovered the FDIV bug in its own testing a few months before him (but had decided not to inform customers).

The "Pentium flaw" incident, Intel's response to it, and the surrounding media coverage propelled Intel from being a technology supplier generally unknown to most computer users to a household name. Dovetailing with an uptick in the "Intel Inside" campaign, the episode is considered to have been a positive event for Intel, changing some of its business practices to be more end-user focused and generating substantial public awareness, while avoiding a lasting negative impression.

During this period, Intel undertook two major supporting advertising campaigns. The first campaign, the 1991 "Intel Inside" marketing and branding campaign, is widely known and has become synonymous with Intel itself. The idea of "ingredient branding" was new at the time, with only NutraSweet and a few others making attempts to do so. This campaign established Intel, which had been a component supplier little-known outside the PC industry, as a household name.

The second campaign, Intel's Systems Group, which began in the early 1990s, showcased manufacturing of PC motherboards, the main board component of a personal computer, and the one into which the processor (CPU) and memory (RAM) chips are plugged. The Systems Group campaign was lesser known than the Intel Inside campaign.

Shortly after, Intel began manufacturing fully configured "white box" systems for the dozens of PC clone companies that rapidly sprang up. At its peak in the mid-1990s, Intel manufactured over 15% of all PCs, making it the third-largest supplier at the time.

During the 1990s, Intel Architecture Labs (IAL) was responsible for many of the hardware innovations for the PC, including the PCI Bus, the PCI Express (PCIe) bus, and Universal Serial Bus (USB). IAL's software efforts met with a more mixed fate; its video and graphics software was important in the development of software digital video, but later its efforts were largely overshadowed by competition from Microsoft. The competition between Intel and Microsoft was revealed in testimony by then IAL Vice-President Steven McGeady at the Microsoft antitrust trial ("United States v. Microsoft Corp.").

In early January 2018, it was reported that all Intel processors made since 1995 (besides Intel Itanium and pre-2013 Intel Atom) have been subject to two security flaws dubbed Meltdown and Spectre.
The impact on performance resulting from software patches is "workload-dependent". Several procedures to help protect home computers and related devices from the Spectre and Meltdown security vulnerabilities have been published. Spectre patches have been reported to significantly slow down performance, especially on older computers; on the newer 8th generation Core platforms, benchmark performance drops of 2–14 percent have been measured. Meltdown patches may also produce performance loss. It is believed that "hundreds of millions" of systems could be affected by these flaws.

On March 15, 2018, Intel reported that it will redesign its CPU processors (performance losses to be determined) to protect against the Spectre security vulnerability, and expects to release the newly redesigned processors later in 2018.

On May 3, 2018, eight additional Spectre-class flaws were reported. Intel reported that they are preparing new patches to mitigate these flaws.

On August 14, 2018, Intel disclosed three additional chip flaws referred to as L1 Terminal Fault (L1TF). They reported that previously released microcode updates, along with new, pre-release microcode updates can be used to mitigate these flaws.

On January 18, 2019, Intel disclosed three new vulnerabilities affecting all Intel CPUs, named "Fallout", "RIDL", and "ZombieLoad", allowing a program to read information recently written, read data in the line-fill buffers and load ports, and leak information from other processes and virtual machines. Recent Coffeelake-series CPUs are even more vulnerable, due to hardware mitigations for Spectre.

On March 5, 2020, computer security experts reported another Intel chip security flaw, besides the Meltdown and Spectre flaws, with the systematic name (or, "Intel CSME Bug"). This newly found flaw is not fixable with a firmware update, and affects nearly "all Intel chips released in the past five years".

Intel has decided to discontinue with their recent Intel Remote Keyboard Android app after encountering several security bugs. This app was launched in early 2015 to help users control Intel single-board computers and Intel NUC. The company has asked Remote Keyboard Users to delete the app at their first convenience.

In 2008, Intel began shipping mainstream solid-state drives (SSDs) with up to 160 GB storage capacities. As with their CPUs, Intel develops SSD chips using ever-smaller nanometer processes. These SSDs make use of industry standards such as NAND flash, mSATA, PCIe, and NVMe. In 2017, Intel introduced SSDs based on 3D XPoint technology under the Optane brand name.

The Intel Scientific Computers division was founded in 1984 by Justin Rattner, to design and produce parallel computers based on Intel microprocessors connected in hypercube internetwork topology. In 1992, the name was changed to the Intel Supercomputing Systems Division, and development of the iWarp architecture was also subsumed. The division designed several supercomputer systems, including the Intel iPSC/1, iPSC/2, iPSC/860, Paragon and ASCI Red. In November 2014, Intel revealed that it is going to use light beams to speed up supercomputers.

In 2007, Intel formed the Moblin project to create an open source Linux operating system for x86-based mobile devices. Following the success of Google's Android platform which ran exclusively on ARM processors, Intel announced on February 15, 2010, that it would partner with Nokia and merge Moblin with Nokia's ARM-based Maemo project to create MeeGo. MeeGo was supported by the Linux Foundation.

In February 2011, Nokia left the project after partnering with Microsoft, leaving Intel in sole charge of MeeGo. An Intel spokeswoman said it was "disappointed" by Nokia's decision but that Intel was committed to MeeGo. In September 2011 Intel stopped working on MeeGo and partnered with Samsung to create Tizen, a new project hosted by the Linux Foundation. Intel has since been co-developing the Tizen operating system which runs on several Samsung devices.

Two factors combined to end this dominance: the slowing of PC demand growth beginning in 2000 and the rise of the low-cost PC. By the end of the 1990s, microprocessor performance had outstripped software demand for that CPU power. Aside from high-end server systems and software, whose demand dropped with the end of the "dot-com bubble", consumer systems ran effectively on increasingly low-cost systems after 2000. Intel's strategy of producing ever-more-powerful processors and obsoleting their predecessors stumbled, leaving an opportunity for rapid gains by competitors, notably AMD. This, in turn, lowered the profitability of the processor line and ended an era of unprecedented dominance of the PC hardware by Intel.

Intel's dominance in the x86 microprocessor market led to numerous charges of antitrust violations over the years, including FTC investigations in both the late 1980s and in 1999, and civil actions such as the 1997 suit by Digital Equipment Corporation (DEC) and a patent suit by Intergraph. Intel's market dominance (at one time it controlled over 85% of the market for 32-bit x86 microprocessors) combined with Intel's own hardball legal tactics (such as its infamous 338 patent suit versus PC manufacturers) made it an attractive target for litigation, but few of the lawsuits ever amounted to anything.

A case of industrial espionage arose in 1995 that involved both Intel and AMD. Bill Gaede, an Argentine formerly employed both at AMD and at Intel's Arizona plant, was arrested for attempting in 1993 to sell the i486 and P5 Pentium designs to AMD and to certain foreign powers. Gaede videotaped data from his computer screen at Intel and mailed it to AMD, which immediately alerted Intel and authorities, resulting in Gaede's arrest. Gaede was convicted and sentenced to 33 months in prison in June 1996.

On June 6, 2005, Steve Jobs, then CEO of Apple, announced that Apple would be transitioning from its long favored PowerPC architecture to the Intel x86 architecture because the future PowerPC road map was unable to satisfy Apple's needs. The first Macintosh computers containing Intel CPUs were announced on January 10, 2006, and Apple had its entire line of consumer Macs running on Intel processors by early August 2006. The Apple Xserve server was updated to Intel Xeon processors from November 2006 and was offered in a configuration similar to Apple's Mac Pro.

On June 22, 2020, during the virtual WWDC, Apple announced that they would be switching some of their Mac line to their own ARM-based designs.

In July 2007, the company released a print advertisement for its Intel Core 2 Duo processor featuring six black runners appearing to bow down to a Caucasian male inside of an office setting (due to the posture taken by runners on starting blocks). According to Nancy Bhagat, Vice President of Intel Corporate Marketing, viewers found the ad to be "insensitive and insulting", and several Intel executives made public apologies.

The Classmate PC is the company's first low-cost netbook computer. In 2014, the company released an updated version of the Classmate PC.

In June 2011, Intel introduced the first Pentium mobile processor based on the Sandy Bridge core. The B940, clocked at 2 GHz, is faster than existing or upcoming mobile Celerons, although it is almost identical to dual-core Celeron CPUs in all other aspects. According to IHS iSuppli's report on September 28, 2011, Sandy Bridge chips have helped Intel increase its market share in global processor market to 81.8%, while AMD's market share dropped to 10.4%.

Intel planned to introduce Medfield – a processor for tablets and smartphones – to the market in 2012, as an effort to compete with ARM. As a 32-nanometer processor, Medfield is designed to be energy-efficient, which is one of the core features in ARM's chips.

At the Intel Developers Forum (IDF) 2011 in San Francisco, Intel's partnership with Google was announced. By January 2012, Google's Android 2.3 will use Intel's Atom microprocessor.

In July 2011, Intel announced that its server chips, the Xeon series, will use new sensors that can improve data center cooling efficiency.

In 2011, Intel announced the Ivy Bridge processor family at the Intel Developer Forum. Ivy Bridge supports both DDR3 memory and DDR3L chips.

As part of its efforts in the Positive Energy Buildings Consortium, Intel has been developing an application, called Personal Office Energy Monitor (POEM), to help office buildings to be more energy-efficient. With this application, employees can get the power consumption info for their office machines, so that they can figure out a better way to save energy in their working environment.

Intel has introduced some simulation games, starting in 2009 with web-based "". In it, the player manages a company's IT department. The goal is to apply technology and skill to enable the company to grow from a small business into a global enterprise. The game has since been discontinued and succeeded in 2012 by the web-based multiplayer game "", which is no longer available.

In 2011, Intel announced that it is working on a car security system that connects to smartphones via an application. The application works by streaming video to a cloud service if a car armed with the system is broken into.

Intel also developed High-Bandwidth Digital Content Protection (HDCP) to prevent access of digital audio and video content as it travels across connections.

In 2013, Intel's Kirk Skaugen said that Intel's exclusive focus on Microsoft platforms was a thing of the past and that they would now support all "tier-one operating systems" such as Linux, Android, iOS, and Chrome.

In 2014, Intel cut thousands of employees in response to "evolving market trends", and offered to subsidize manufacturers for the extra costs involved in using Intel chips in their tablets.

In June 2013, Intel unveiled its fourth generation of Intel Core processors (Haswell) in an event named Computex in Taipei.

On January 6, 2014, Intel announced that it was "teaming with the Council of Fashion Designers of America, Barneys New York and Opening Ceremony around the wearable tech field."

Intel developed a reference design for wearable smart earbuds that provide biometric and fitness information. The Intel smart earbuds provide full stereo audio, and monitor heart rate, while the applications on the user's phone keep track of run distance and calories burned.

CNBC reported that Intel eliminated the division that worked on health wearables in 2017.

On November 19, 2015, Intel, alongside ARM Holdings, Dell, Cisco Systems, Microsoft, and Princeton University, founded the OpenFog Consortium, to promote interests and development in fog computing. Intel's Chief Strategist for the IoT Strategy and Technology Office, Jeff Faders, became the consortium's first president.

In 2009, Intel announced that it planned to undertake an effort to remove conflict resources—materials sourced from mines whose profits are used to fund armed militant groups, particularly within the Democratic Republic of the Congo—from its supply chain. Intel sought conflict-free sources of the precious metals common to electronics from within the country, using a system of first- and third-party audits, as well as input from the Enough Project and other organizations. During a keynote address at Consumer Electronics Show 2014, Intel CEO at the time, Brian Krzanich, announced that the company's microprocessors would henceforth be conflict free. In 2016, Intel stated that it had expected its entire supply chain to be conflict-free by the end of the year.

Intel is one of the biggest stakeholders in the self-driving car industry, having joined the race in mid 2017 after joining forces with Mobileye. The company is also one of the first in the sector to research consumer acceptance, after an AAA report quoted a 78% nonacceptance rate of the technology in the US.

Safety levels of the technology, the thought of abandoning control to a machine, and psychological comfort of passengers in such situations were the major discussion topics initially. The commuters also stated that they did not want to see everything the car was doing. This was primarily a referral to the auto-steering wheel with no one sitting in the driving seat. Intel also learned that voice control regulator is vital, and the interface between the humans and machine eases the discomfort condition, and brings some sense of control back. It is important to mention that Intel included only 10 people in this study, which makes the study less credible. In a video posted on YouTube, Intel accepted this fact and called for further testing.

Robert Noyce was Intel's CEO at its founding in 1968, followed by co-founder Gordon Moore in 1975. Andy Grove became the company's president in 1979 and added the CEO title in 1987 when Moore became chairman. In 1998, Grove succeeded Moore as Chairman, and Craig Barrett, already company president, took over. On May 18, 2005, Barrett handed the reins of the company over to Paul Otellini, who had been the company president and COO and who was responsible for Intel's design win in the original IBM PC. The board of directors elected Otellini as President and CEO, and Barrett replaced Grove as Chairman of the Board. Grove stepped down as chairman but is retained as a special adviser. In May 2009, Barrett stepped down as chairman of the Board and was succeeded by Jane Shaw. In May 2012, Intel vice chairman Andy Bryant, who had held the posts of CFO (1994) and Chief Administrative Officer (2007) at Intel, succeeded Shaw as executive chairman.

In November 2012, president and CEO Paul Otellini announced that he would step down in May 2013 at the age of 62, three years before the company's mandatory retirement age. During a six-month transition period, Intel's board of directors commenced a search process for the next CEO, in which it considered both internal managers and external candidates such as Sanjay Jha and Patrick Gelsinger. Financial results revealed that, under Otellini, Intel's revenue increased by 55.8 percent (US$34.2 to 53.3 billion), while its net income increased by 46.7% (US$7.5 billion to 11 billion).

On May 2, 2013, Executive Vice President and COO Brian Krzanich was elected as Intel's sixth CEO, a selection that became effective on May 16, 2013, at the company's annual meeting. Reportedly, the board concluded that an insider could proceed with the role and exert an impact more quickly, without the need to learn Intel's processes, and Krzanich was selected on such a basis. Intel's software head Renée James was selected as president of the company, a role that is second to the CEO position.

As of May 2013, Intel's board of directors consists of Andy Bryant, John Donahoe, Frank Yeary, Ambassador Charlene Barshefsky, Susan Decker, Reed Hundt, Paul Otellini, James Plummer, David Pottruck, and David Yoffie and Creative director will.i.am. The board was described by former "Financial Times" journalist Tom Foremski as "an exemplary example of corporate governance of the highest order" and received a rating of ten from GovernanceMetrics International, a form of recognition that has only been awarded to twenty-one other corporate boards worldwide.

On June 21, 2018, Intel announced the resignation of Brian Krzanich as CEO, with the exposure of a relationship he had with an employee. Bob Swan was named interim CEO, as the Board began a search for a permanent CEO.

On January 31, 2019, Swan transitioned from his role as CFO and interim CEO and was named by the Board as the 7th CEO to lead the company.

As of 17 May 2020:

As of 2017 Intel shares are mainly held by institutional investors (The Vanguard Group, BlackRock, Capital Group Companies, State Street Corporation and others)

The firm promotes very heavily from within, most notably in its executive suite. The company has resisted the trend toward outsider CEOs. Paul Otellini was a 30-year veteran of the company when he assumed the role of CEO. All of his top lieutenants have risen through the ranks after many years with the firm. In many cases, Intel's top executives have spent their entire working careers with Intel.

Intel has a mandatory retirement policy for its CEOs when they reach age 65. Andy Grove retired at 62, while both Robert Noyce and Gordon Moore retired at 58. Grove retired as Chairman and as a member of the board of directors in 2005 at age 68.

Intel's headquarters are located in Santa Clara, California, and the company has operations around the world. Its largest workforce concentration anywhere is in Washington County, Oregon (in the Portland metropolitan area's "Silicon Forest"), with 18,600 employees at several facilities. Outside the United States, the company has facilities in China, Costa Rica, Malaysia, Israel, Ireland, India, Russia, Argentina and Vietnam, in 63 countries and regions internationally. In the U.S. Intel employs significant numbers of people in California, Colorado, Massachusetts, Arizona, New Mexico, Oregon, Texas, Washington and Utah. In Oregon, Intel is the state's largest private employer. The company is the largest industrial employer in New Mexico while in Arizona the company has over 10,000 employees.

Intel invests heavily in research in China and about 100 researchers or 10% of the total number of researchers from Intel are located in Beijing.

In 2011, the Israeli government offered Intel $290 million to expand in the country. As a condition, Intel would employ 1,500 more workers in Kiryat Gat and between 600–1000 workers in the north.

In January 2014, it was reported that Intel would cut about 5,000 jobs from its work force of 107,000. The announcement was made a day after it reported earnings that missed analyst targets.

In March 2014, it was reported that Intel would embark upon a $6 billion plan to expand its activities in Israel. The plan calls for continued investment in existing and new Intel plants until 2030. , Intel employs 10,000 workers at four development centers and two production plants in Israel.

Intel has a Diversity Initiative, including employee diversity groups as well as supplier diversity programs. Like many companies with employee diversity groups, they include groups based on race and nationality as well as sexual identity and religion. In 1994, Intel sanctioned one of the earliest corporate Gay, Lesbian, Bisexual, and Transgender employee groups, and supports a Muslim employees group, a Jewish employees group, and a Bible-based Christian group.

Intel has received a 100% rating on numerous Corporate Equality Indices released by the Human Rights Campaign including the first one released in 2002. In addition, the company is frequently named one of the 100 Best Companies for Working Mothers by "Working Mother" magazine.

In January 2015, Intel announced the investment of $300 million over the next five years to enhance gender and racial diversity in their own company as well as the technology industry as a whole.

In February 2016, Intel released its Global Diversity & Inclusion 2015 Annual Report. The male-female mix of US employees was reported as 75.2% men and 24.8% women. For US employees in technical roles, the mix was reported as 79.8% male and 20.1% female. NPR reports that Intel is facing a retention problem (particularly for African Americans), not just a pipeline problem.

In 2011, ECONorthwest conducted an economic impact analysis of Intel's economic contribution to the state of Oregon. The report found that in 2009 "the total economic impacts attributed to Intel's operations, capital spending, contributions and taxes amounted to almost $14.6 billion in activity, including $4.3 billion in personal income and 59,990 jobs". Through multiplier effects, every 10 Intel jobs supported, on average, was found to create 31 jobs in other sectors of the economy.

In Rio Rancho, New Mexico, Intel is the leading employer. In 1997, a community partnership between Sandoval County and Intel Corporation funded and built Rio Rancho High School.

In 2011, Intel Capital announced a new fund to support startups working on technologies in line with the company's concept for next generation notebooks. The company is setting aside a $300 million fund to be spent over the next three to four years in areas related to ultrabooks. Intel announced the ultrabook concept at Computex in 2011. The ultrabook is defined as a thin (less than 0.8 inches [~2 cm] thick) notebook that utilizes Intel processors and also incorporates tablet features such as a touch screen and long battery life.

At the Intel Developers Forum in 2011, four Taiwan ODMs showed prototype ultrabooks that used Intel's Ivy Bridge chips. Intel plans to improve power consumption of its chips for ultrabooks, like new Ivy Bridge processors in 2013, which will only have 10W default thermal design power.

Intel's goal for Ultrabook's price is below $1000; however, according to two presidents from Acer and Compaq, this goal will not be achieved if Intel does not lower the price of its chips.

Intel has become one of the world's most recognizable computer brands following its long-running "Intel Inside" campaign. The idea for "Intel Inside" came out of a meeting between Intel and one of the major computer resellers, MicroAge.

In the late 1980s, Intel's market share was being seriously eroded by upstart competitors such as Advanced Micro Devices (now AMD), Zilog, and others who had started to sell their less expensive microprocessors to computer manufacturers. This was because, by using cheaper processors, manufacturers could make cheaper computers and gain more market share in an increasingly price-sensitive market. In 1989, Intel's Dennis Carter visited MicroAge's headquarters in Tempe, Arizona, to meet with MicroAge's VP of Marketing, Ron Mion. MicroAge had become one of the largest distributors of Compaq, IBM, HP, and others and thus was a primary although indirect driver of demand for microprocessors. Intel wanted MicroAge to petition its computer suppliers to favor Intel chips. However, Mion felt that the marketplace should decide which processors they wanted. Intel's counterargument was that it would be too difficult to educate PC buyers on why Intel microprocessors were worth paying more for ... and they were right. But Mion felt that the public didn't really need to fully understand why Intel chips were better, they just needed to feel they were better. So Mion proposed a market test. Intel would pay for a MicroAge billboard somewhere saying, "If you're buying a personal computer, make sure it has Intel inside." In turn, MicroAge would put "Intel Inside" stickers on the Intel-based computers in their stores in that area. To make the test easier to monitor, Mion decided to do the test in Boulder, Colorado, where it had a single store. Virtually overnight, the sales of personal computers in that store dramatically shifted to Intel-based PCs. Intel very quickly adopted "Intel Inside" as its primary branding and rolled it out worldwide.

As is often the case with computer lore, other tidbits have been combined to explain how things evolved. "Intel Inside" has not escaped that tendency and there are other "explanations" that had been floating around.

Intel's branding campaign started with "The Computer Inside" tagline in 1990 in the US and Europe. The Japan chapter of Intel proposed an "Intel in it" tagline and kicked off the Japanese campaign by hosting EKI-KON (meaning "Station Concert" in Japanese) at the Tokyo railway station dome on Christmas Day, December 25, 1990. Several months later, "The Computer Inside" incorporated the Japan idea to become "Intel Inside" which eventually elevated to the worldwide branding campaign in 1991, by Intel marketing manager Dennis Carter. A case study, "Inside Intel Inside", was put together by Harvard Business School. The five-note jingle was introduced in 1994 and by its tenth anniversary was being heard in 130 countries around the world. The initial branding agency for the "Intel Inside" campaign was DahlinSmithWhite Advertising of Salt Lake City. The Intel "swirl" logo was the work of DahlinSmithWhite art director Steve Grigg under the direction of Intel president and CEO Andy Grove.

The "Intel Inside" advertising campaign sought public brand loyalty and awareness of Intel processors in consumer computers. Intel paid some of the advertiser's costs for an ad that used the "Intel Inside" logo and xylo-marimba jingle.

In 2008, Intel planned to shift the emphasis of its Intel Inside campaign from traditional media such as television and print to newer media such as the Internet. Intel required that a minimum of 35% of the money it provided to the companies in its co-op program be used for online marketing. The Intel 2010 annual financial report indicated that $1.8 billion (6% of the gross margin and nearly 16% of the total net income) was allocated to all advertising with Intel Inside being part of that.

The famous D♭  D♭  G♭  D♭  A♭ xylophone/xylomarimba jingle, sonic logo, tag, audio mnemonic was produced by Musikvergnuegen and written by Walter Werzowa, once a member of the Austrian 1980s sampling band Edelweiss. The sonic Intel logo was remade in 1999 to coincide with the launch of the Pentium III, and a second time in 2004 to coincide with the new logo change (although it overlapped with the 1999 version and was not mainstreamed until the launch of the Core processors in 2006), with the melody unchanged. Advertisements for products featuring Intel processors with prominent MMX branding featured a version of the jingle with an embellishment (shining sound) after the final note.

In 2006, Intel expanded its promotion of open specification platforms beyond Centrino, to include the Viiv media center PC and the business desktop Intel vPro.

In mid-January 2006, Intel announced that they were dropping the long running "Pentium" name from their processors. The Pentium name was first used to refer to the P5 core Intel processors and was done to comply with court rulings that prevent the trademarking of a string of numbers, so competitors could not just call their processor the same name, as had been done with the prior 386 and 486 processors (both of which had copies manufactured by IBM and AMD). They phased out the Pentium names from mobile processors first, when the new Yonah chips, branded Core Solo and Core Duo, were released. The desktop processors changed when the Core 2 line of processors were released. By 2009, Intel was using a good-better-best strategy with Celeron being good, Pentium better, and the Intel Core family representing the best the company has to offer.

According to spokesman Bill Calder, Intel has maintained only the Celeron brand, the Atom brand for netbooks and the vPro lineup for businesses. Since late 2009, Intel's mainstream processors have been called Celeron, Pentium, Core i3, Core i5, Core i7, and Core i9 in order of performance from lowest to highest. The first generation core products carry a 3 digit name, such as i5 750, and the second generation products carry a 4 digit name, such as the i5 2500. In both cases, a K at the end of it shows that it is an unlocked processor, enabling additional overclocking abilities (for instance, 2500K). vPro products will carry the Intel Core i7 vPro processor or the Intel Core i5 vPro processor name. In October 2011, Intel started to sell its Core i7-2700K "Sandy Bridge" chip to customers worldwide.

Since 2010, "Centrino" is only being applied to Intel's WiMAX and Wi-Fi technologies.

Neo Sans Intel is a customized version of Neo Sans based on the Neo Sans and Neo Tech, designed by Sebastian Lester in 2004.

Intel Clear is a global font announced in 2014 designed for to be used across all communications. The font family was designed by Red Peek Branding and Dalton Maag Initially available in Latin, Greek and Cyrillic scripts, it replaced Neo Sans Intel as the company's corporate typeface. Intel Clear Hebrew, Intel Clear Arabic were added by Daltan Maag Ltd.

It is a book produced by Red Peak Branding as part of new brand identity campaign, celebrating Intel's achievements while setting the new standard for what Intel looks, feels and sounds like.

Intel has a significant participation in the open source communities since 1999. For example, in 2006 Intel released MIT-licensed X.org drivers for their integrated graphic cards of the i965 family of chipsets. Intel released FreeBSD drivers for some networking cards, available under a BSD-compatible license, which were also ported to OpenBSD. Binary firmware files for non-wireless Ethernet devices were also released under a BSD licence allowing free redistribution. Intel ran the Moblin project until April 23, 2009, when they handed the project over to the Linux Foundation. Intel also runs the "LessWatts.org" campaigns.

However, after the release of the wireless products called Intel Pro/Wireless 2100, 2200BG/2225BG/2915ABG and 3945ABG in 2005, Intel was criticized for not granting free redistribution rights for the firmware that must be included in the operating system for the wireless devices to operate. As a result of this, Intel became a target of campaigns to allow free operating systems to include binary firmware on terms acceptable to the open source community. Linspire-Linux creator Michael Robertson outlined the difficult position that Intel was in releasing to open source, as Intel did not want to upset their large customer Microsoft. Theo de Raadt of OpenBSD also claimed that Intel is being "an Open Source fraud" after an Intel employee presented a distorted view of the situation at an open-source conference. In spite of the significant negative attention Intel received as a result of the wireless dealings, the binary firmware still has not gained a license compatible with free software principles.

The Firmware Support Package (FSP) is a proprietary firmware library developed by Intel for platform initialization and can be integrated into other firmware.

Due to declining PC sales, in 2016 Intel cut 12,000 jobs.

In October 2006, a Transmeta lawsuit was filed against Intel for patent infringement on computer architecture and power efficiency technologies. The lawsuit was settled in October 2007, with Intel agreeing to pay US$150 million initially and US$20 million per year for the next five years. Both companies agreed to drop lawsuits against each other, while Intel was granted a perpetual non-exclusive license to use current and future patented Transmeta technologies in its chips for 10 years.

In September 2005, Intel filed a response to an AMD lawsuit, disputing AMD's claims, and claiming that Intel's business practices are fair and lawful. In a rebuttal, Intel deconstructed AMD's offensive strategy and argued that AMD struggled largely as a result of its own bad business decisions, including underinvestment in essential manufacturing capacity and excessive reliance on contracting out chip foundries. Legal analysts predicted the lawsuit would drag on for a number of years, since Intel's initial response indicated its unwillingness to settle with AMD. In 2008, a court date was finally set, but in 2009, Intel settled with a $1.25 billion payout to AMD (see below).

On November 4, 2009, New York's attorney general filed an antitrust lawsuit against Intel Corp, claiming the company used "illegal threats and collusion" to dominate the market for computer microprocessors.

On November 12, 2009, AMD agreed to drop the antitrust lawsuit against Intel in exchange for $1.25 billion. A joint press release published by the two chip makers stated "While the relationship between the two companies has been difficult in the past, this agreement ends the legal disputes and enables the companies to focus all of our efforts on product innovation and development."

An antitrust lawsuit and a class-action suit relating to cold calling employees of other companies has been settled.

In 2005, the local Fair Trade Commission found that Intel violated the Japanese Antimonopoly Act. The commission ordered Intel to eliminate discounts that had discriminated against AMD. To avoid a trial, Intel agreed to comply with the order.

In July 2007, the European Commission accused Intel of anti-competitive practices, mostly against AMD. The allegations, going back to 2003, include giving preferential prices to computer makers buying most or all of their chips from Intel, paying computer makers to delay or cancel the launch of products using AMD chips, and providing chips at below standard cost to governments and educational institutions. Intel responded that the allegations were unfounded and instead qualified its market behavior as consumer-friendly. General counsel Bruce Sewell responded that the Commission had misunderstood some factual assumptions regarding pricing and manufacturing costs.

In February 2008, Intel announced that its office in Munich had been raided by European Union regulators. Intel reported that it was cooperating with investigators. Intel faced a fine of up to 10% of its annual revenue if found guilty of stifling competition. AMD subsequently launched a website promoting these allegations. In June 2008, the EU filed new charges against Intel. In May 2009, the EU found that Intel had engaged in anti-competitive practices and subsequently fined Intel €1.06 billion (US$1.44 billion), a record amount. Intel was found to have paid companies, including Acer, Dell, HP, Lenovo and NEC, to exclusively use Intel chips in their products, and therefore harmed other, less successful companies including AMD. The European Commission said that Intel had deliberately acted to keep competitors out of the computer chip market and in doing so had made a "serious and sustained violation of the EU's antitrust rules". In addition to the fine, Intel was ordered by the Commission to immediately cease all illegal practices. Intel has said that they will appeal against the Commission's verdict. In June 2014, the General Court, which sits below the European Court of Justice, rejected the appeal.

In September 2007, South Korean regulators accused Intel of breaking antitrust law. The investigation began in February 2006, when officials raided Intel's South Korean offices. The company risked a penalty of up to 3% of its annual sales if found guilty. In June 2008, the Fair Trade Commission ordered Intel to pay a fine of US $25.5 million for taking advantage of its dominant position to offer incentives to major Korean PC manufacturers on the condition of not buying products from AMD.

New York started an investigation of Intel in January 2008 on whether the company violated antitrust laws in pricing and sales of its microprocessors. In June 2008, the Federal Trade Commission also began an antitrust investigation of the case. In December 2009, the FTC announced it would initiate an administrative proceeding against Intel in September 2010.

In November 2009, following a two-year investigation, New York Attorney General Andrew Cuomo sued Intel, accusing them of bribery and coercion, claiming that Intel bribed computer makers to buy more of their chips than those of their rivals and threatened to withdraw these payments if the computer makers were perceived as working too closely with its competitors. Intel has denied these claims.

On July 22, 2010, Dell agreed to a settlement with the U.S. Securities and Exchange Commission (SEC) to pay $100M in penalties resulting from charges that Dell did not accurately disclose accounting information to investors. In particular, the SEC charged that from 2002 to 2006, Dell had an agreement with Intel to receive rebates in exchange for not using chips manufactured by AMD. These substantial rebates were not disclosed to investors, but were used to help meet investor expectations regarding the company's financial performance; "These exclusivity payments grew from 10 percent of Dell's operating income in FY 2003 to 38 percent in FY 2006, and peaked at 76 percent in the first quarter of FY 2007." Dell eventually did adopt AMD as a secondary supplier in 2006, and Intel subsequently stopped their rebates, causing Dell's financial performance to fall.

Intel has been accused by some residents of Rio Rancho, New Mexico of allowing VOCs to be released in excess of their pollution permit. One resident claimed that a release of 1.4 tons of carbon tetrachloride was measured from one acid scrubber during the fourth quarter of 2003 but an emission factor allowed Intel to report no carbon tetrachloride emissions for all of 2003.

Another resident alleges that Intel was responsible for the release of other VOCs from their Rio Rancho site and that a necropsy of lung tissue from two deceased dogs in the area indicated trace amounts of toluene, hexane, ethylbenzene, and xylene isomers, all of which are solvents used in industrial settings but also commonly found in gasoline, retail paint thinners and retail solvents. During a sub-committee meeting of the New Mexico Environment Improvement Board, a resident claimed that Intel's own reports documented more than of VOCs were released in June and July 2006.

Intel's environmental performance is published annually in their corporate responsibility report.

In its 2012 rankings on the progress of consumer electronics companies relating to conflict minerals, the Enough Project rated Intel the best of 24 companies, calling it a "Pioneer of progress". In 2014, chief executive Brian Krzanich urged the rest of the industry to follow Intel's lead by also shunning conflict minerals.

Intel has faced complaints of age discrimination in firing and layoffs. Intel was sued in 1993 by nine former employees, over allegations that they were laid off because they were over the age of 40.

A group called FACE Intel (Former and Current Employees of Intel) claims that Intel weeds out older employees. FACE Intel claims that more than 90 percent of people who have been laid off or fired from Intel are over the age of 40. "Upside" magazine requested data from Intel breaking out its hiring and firing by age, but the company declined to provide any. Intel has denied that age plays any role in Intel's employment practices. FACE Intel was founded by Ken Hamidi, who was fired from Intel in 1995 at the age of 47. Hamidi was blocked in a 1999 court decision from using Intel's email system to distribute criticism of the company to employees, which overturned in 2003 in Intel Corp. v. Hamidi.

In August 2016, Indian officials of the Bruhat Bengaluru Mahanagara Palike (BBMP) parked garbage trucks on Intel's campus and threatened to dump them for evading payment of property taxes between 2007 and 2008, to the tune of 340 million Indian rupees (US$4.9 million). Intel had reportedly been paying taxes as a non-air-conditioned office, when the campus in fact had central air conditioning. Other factors, such as land acquisition and construction improvements, added to the tax burden. Previously, Intel had appealed the demand in the Karnataka high court in July, during which the court ordered Intel to pay BBMP half the owed amount (170 million rupees, or US$2.4 million) plus arrears by August 28 of that year.


</doc>
<doc id="14618" url="https://en.wikipedia.org/wiki?curid=14618" title="İsmet İnönü">
İsmet İnönü

Mustafa İsmet İnönü (; 24 September 1884 – 25 December 1973) was a Turkish general and statesman, who served as the second President of Turkey from 11 November 1938 to 22 May 1950, when his Republican People's Party was defeated in Turkey's second free elections. He also served as the first Chief of the General Staff from 1922 to 1924, and as the first Prime Minister after the declaration of the Republic, serving three terms: from 1923 to 1924, 1925 to 1937, and 1961 to 1965. As President, he was granted the official title of "Millî Şef" (National Chief). 

When the 1934 Surname Law was adopted, Mustafa Kemal gave him a surname taken from İnönü, where he commanded the forces of Army of Grand National Assembly as the Minister of the Chief of the General Staff () during the Greco-Turkish War of 1919–1922. Afterwards these battles became to be known as the First Battle of İnönü and Second Battle of İnönü.

İsmet İnönü was born in Smyrna (now known in English as İzmir), Aidin Vilayet to Hacı Reşit () and Cevriye () (later Cevriye Temelli), and was of Kurdish descent on his father's side and of Turkish descent through his mother. Hacı Reşit was retired from the First Examinant Department of Legal Affairs Bureau of the War Ministry ("Harbiye Nezareti Muhakemat Dairesi Birinci Mümeyyizliği"), who was born in Malatya and a member of Kürümoğulları family of Bitlis. Cevriye was a daughter of "Müderris" (professor) Hasan Efendi who belonged to the ulema and was a member of a Turkish family of Razgrad. Due to his father's assignments, the family moved from one city to another. Thus, Ismet completed his primary education in Sivas and graduated Sivas Military Junior High School ("Sivas Askerî Rüştiyesi") in 1894. And then he studied at Sivas School for Civil Servants ("Sivas Mülkiye İdadisi") for a year. During the First World War, on 13 April 1916, Ismet married Mevhibe, who was a daughter of an Ashraf ("Eşraf") of Ziştovi (present day Svishtov) Zühtü Efendi. They had three children: Ömer, Erdal and Özden (married to Metin Toker).

Ismet graduated from the Imperial School of Military Engineering ("Mühendishane-i Berrî-i Hümâyûn") in 1903 as gunnery officer, and received his first military assignment in the Ottoman Army. He joined the Committee of Union and Progress. He won his first military victories by suppressing two major revolts against the struggling Ottoman Empire, first in Rumelia and later in Yemen, whose leader was Yahya Muhammad Hamid ed-Din. He served as a military officer during the Balkan Wars on the Ottoman-Bulgarian front. During World War I, he served with the Ottoman military rank of Miralay (arbitrarily the equivalent of Colonel or Senior Colonel (Brigadier)) and worked under Mustafa Kemal Pasha during his assignments at the Caucasus and Palestine fronts.

After losing the Battle of Megiddo against General Edmund Allenby during the last days of World War I, he went to Istanbul and was assigned Undersecretary of the Ministry of War and then General Secretary of the Documentation in the Military Council.

After the military occupation of Constantinople on 16 March 1920, he decided to pass to Anatolia to join the Turkish National Movement. He and his chief of staff Major Saffet (Arıkan) wore soldier uniform and left Maltepe in the evening of 19 March 1920 and arrived at Ankara on 9 April 1920.

He was appointed the commander of the Western Front of the Army of the Grand National Assembly (GNA), a position in which he remained during the Turkish War of Independence. He was promoted to the rank of Mirliva (arbitrarily the equivalent of Brigadier General or Major General; the most junior General rank with the title Pasha in the Ottoman and pre-1934 Turkish Army) after winning the First Battle of İnönü which took place between 9 and 11 January 1921. He also won the subsequent Second Battle of İnönü which was fought between 26 and 31 March 1921. During the Turkish War of Independence, he was also a member of the GNA in Ankara.

İnönü was replaced by Mustafa Fevzi Pasha, who was also the Prime Minister and Minister of Defense at the time, as the Chief of Staff of the Army of the GNA after the Turkish forces lost major battles against the advancing Greek Army in July 1921, as a result of which the cities Afyonkarahisar, Kütahya and Eskişehir were temporarily lost. He participated as a staff officer (with the rank Brigadier General) to the later battles, until the final Turkish victory in September 1922 in which he was the commander of the front.

After the War of Independence was won, İsmet Pasha was appointed as the chief negotiator of the Turkish delegation, both for the Armistice of Mudanya and for the Treaty of Lausanne.

The Lausanne conference convened in late 1922 to settle the terms of a new treaty that would take the place of the Treaty of Sèvres. Inönü became famous for his stubborn resolve in determining Ankara's position as the legitimate, sovereign government of Turkey. After delivering his position, Inönü turned off his hearing aid during the speeches of British foreign secretary Lord Curzon. When Curzon had finished, Inönü reiterated his position as if Curzon had never said a word.

İnönü later served as the Prime Minister of Turkey for several terms, maintaining the system that Mustafa Kemal had put in place. He acted after every major crisis (such as the Sheikh Said rebellion or the attempted assassination in İzmir against Mustafa Kemal) to restore peace in the country. In October 1923 he suggested to make Ankara the capital of Turkey, which successively was approved by the parliament. He shortly stepped down as prime minister between He replaced prime minister Fethi Okyar at a time the seriousness of the situation around the Sheikh Said Rebellion was realized by the Turkish Government in spring 1925. While dealing with the Sheikh Said revolt he proclaimed a Turkish nationalist policy and encouraged the turkification of the non-Turkish population. In September 1925, following the suppression of the Sheikh Said rebellion, he presided over the Reform Council for the East () which prepared the Report for Reform in the East (), which recommended to impede an establishment of a Kurdish elite, to forbid non-Turkish languages and the creation of regional administrative units called Inspectorates-General, which were to be governed with martial law. Following this report, three Inspectorates-Generals were established in the Kurdish areas comprising several provinces. 

He tried to manage the economy with heavy-handed government intervention, especially after the 1929 economic crisis, by implementing an economic plan inspired by the "Five Year Plan" of the Soviet Union. In doing so, he took much private property under government control. Due to his efforts, to this day, more than 70% of land in Turkey is still owned by the state.

Desiring a more liberal economic system, Atatürk dissolved the government of İnönü and appointed Celâl Bayar, the founder of the first Turkish commercial bank Türkiye İş Bankası, as Prime Minister.

After the death of Atatürk on 10 November 1938, İnönü was viewed as the most appropriate candidate to succeed him, and was elected the second President of the Republic of Turkey. He enjoyed the official title of "Millî Şef", i.e. "National Chief". 

World War II broke out in the first year of his presidency, and both the Allies and the Axis pressured İnönü to bring Turkey into the war on their side. The Germans sent Franz von Papen to Ankara in April 1939 while the British sent Hughe Knatchbull-Hugessen and the French René Massigli. On 23 April 1939, Turkish Foreign Minister Şükrü Saracoğlu told Knatchbull-Hugessen of his nation's fears of Italian claims of the Mediterranean as "Mare Nostrum" and German control of the Balkans, and suggested an Anglo-Soviet-Turkish alliance as the best way of countering the Axis. In May 1939, during the visit of Maxime Weygand to Turkey, İnönü told the French Ambassador René Massigli that he believed that the best way of stopping Germany was an alliance of Turkey, the Soviet Union, France and Britain; that if such an alliance came into being, the Turks would allow Soviet ground and air forces onto their soil; and that he wanted a major programme of French military aid to modernize the Turkish armed forces. 

The signing of the Molotov–Ribbentrop Pact on 23 August 1939 drew Turkey away from the Allies; the Turks always believed that it was essential to have the Soviet Union as an ally to counter Germany, and thus the signing of the German-Soviet pact undercut completely the assumptions behind Turkish security policy. With the signing of the Molotov-Ribbentrop pact, İnönü chose to be neutral in World War II as taking on Germany and the Soviet Union at the same time would be too much for Turkey, through he signed a treaty of alliance with Britain and France on 19 October 1939. It was only with France's defeat in June 1940 that İnönü abandoned the pro-Allied neutrality that he had followed since the beginning of the war. A major embarrassment for the Turks occurred in July 1940 when the Germans captured and published documents from the Quai d'Orsay in Paris showing the Turks were aware of Operation Pike—as the Anglo-French plan in the winter of 1939–40 to bomb the oil fields in the Soviet Union from Turkey was codenamed—which was intended by Berlin to worsen relations between Ankara and Moscow. In turn, worsening relations between the Soviet Union and Turkey were intended to drive Turkey into the arms of the "Reich". After the publication of the French documents relating to Operation Pike, İnönü had to sign an economic treaty with Germany that placed Turkey within the German economic sphere of influence, but İnönü would go no further towards the Axis.

In the first half of 1941, Germany which was intent upon invading the Soviet Union went out of its way to improve relations with Turkey as the "Reich" hoped for a benevolent Turkish neutrality when the German-Soviet war began. At the same time, the British had great hopes in the spring of 1941 when they dispatched an expeditionary force to Greece that İnönü could be persuaded to enter the war on the Allied side as the British leadership had high hopes of creating a Balkan front that would tie down German forces, and which thus led a major British diplomatic offensive with the Foreign Secretary Sir Anthony Eden visiting Ankara several times to meet with İnönü. İnönü always told Eden that the Turks would not join the British forces in Greece, and the Turks would only enter the war if Germany attacked Turkey. For his part, Papen offered İnönü parts of Greece if Turkey were to enter the war on the Axis side, an offer İnönü declined. In May 1941 when the Germans dispatched an expeditionary force to Iraq to fight against the British, İnönü refused Papen's request that the German forces be allowed transit rights to Iraq.

British Prime Minister Winston Churchill travelled to Ankara on 30 January 1943 for a conference with President İnönu, to urge Turkey's entry into the war on the allied side. Churchill met secretly with İnönü in January 1943, inside a railroad car at the Yenice Station near Adana. However, by December 4–6, 1943, İnönü felt confident enough about the outcome of the war, that he met openly with Franklin D. Roosevelt and Winston Churchill at the Second Cairo Conference. Until 1941, both Roosevelt and Churchill had thought that Turkey's continuing neutrality would serve the interests of the Allies by blocking the Axis from reaching the strategic oil reserves of the Middle East. But the early victories of the Axis up to the end of 1942 caused Roosevelt and Churchill to re-evaluate a possible Turkish participation in the war on the side of the Allies. Turkey had maintained a decently-sized Army and Air Force throughout the war, and Churchill wanted the Turks to open a new front in the Balkans. Roosevelt, on the other hand, still believed that a Turkish attack would be too risky, and an eventual Turkish failure would have disastrous effects for the Allies.

İnönü knew very well the hardships which his country had suffered during decades of incessant war between 1908 and 1922 and was determined to keep Turkey out of another war as long as he could. The young Turkish Republic was still re-building, recovering from the losses due to earlier wars, and lacked any modern weapons and the infrastructure to enter a war to be fought along and possibly within its borders. İnönü based his neutrality policy during the Second World War on the premise that Western Allies and the Soviet Union would sooner or later have a falling out after the war. Thus, İnönu wanted assurances on financial and military aid for Turkey, as well as a guarantee that the United States and the United Kingdom would stand beside Turkey in the event of a Soviet invasion of the Turkish Straits after the war. In August 1944 İnönü broke off diplomatic relations with Germany and on 5 January 1945, İnönü severed diplomatic relations with Japan. Shortly afterwards, İnönü allowed Allied shipping to use the Turkish straits to send supplies to the Soviet Union and on 25 February 1945 he declared war on Germany and Japan.

The post-war tensions and arguments surrounding the Turkish Straits would come to be known as the Turkish Straits crisis. The fear of Soviet invasion and Joseph Stalin's unconcealed desire for Soviet military bases in the Turkish Straits eventually caused Turkey to give up its principle of neutrality in foreign relations and join NATO in February 1952.

Under international pressure to transform the country to a democratic state, İnönü presided over the infamous 1946 elections, where voting was carried out under the gaze of onlookers who could determine which voters had voted for which parties, and where secrecy prevailed as to the subsequent counting of votes. Free and fair national elections had to wait till 1950, and on that occasion İnönü's government was defeated.

In the 1950 campaign, the leading figures of the opposition Democrat Party used the following slogan: ""Geldi İsmet, kesildi kısmet"" ("Ismet arrived, [our] fortune left" ). İnönü presided over the peaceful transfer of power to the Democratic Party of Celâl Bayar and Adnan Menderes. For ten years he served as the leader of the opposition before returning to power as Prime Minister after the 1961 election, held after the military coup-d'etat in 1960.

Even though the pro-Menderes opposition was forbidden to contest the 1961 election (most of its leaders who were still alive were in prison), İnönü's forces still did not gain enough seats in the legislature to win a majority. Therefore, they had to form coalition governments until 1965. İnönü lost both the 1965 and 1969 general elections to a much younger man, Süleyman Demirel, but he remained leader of the party till 1972, whereupon he was defeated by leadership rival Bülent Ecevit. In 1964 İnönü renounced the 1930 Greek-Turkish Treaty of friendship and took actions against the Greek minority. Following the Turkish Government also strictly enforced a long‐overlooked law barring Greek nationals from 30 professions and occupations, for example Greeks could not be doctors, nurses, architects, shoemakers, tailors, plumbers, cabaret singers, ironsmiths, cooks, tourist guides, etc. and 50,000 more Greeks were deported.

In a meeting in Bursa for the 1969 general elections, a young man yelled at him; "You let us go without food!" by implying not joining World War II. İnönü replied him by saying "Yes, I let you go without food, but I did not let you become fatherless" by implying death of millions of people from the both sides of World War II.

He died on 25 December 1973 of a heart attack, at the age of 89, and was interred opposite to Atatürk's mausoleum at Anıtkabir in Ankara.

A highly educated man, İnönü was able to speak fluently Arabic, English, French and German in addition to his native Turkish. İnönü University and Malatya İnönü Stadium in Malatya are named after him, as is the İnönü Stadium in Istanbul, home of the Beşiktaş football club. 



 


</doc>
<doc id="14624" url="https://en.wikipedia.org/wiki?curid=14624" title="Inorganic chemistry">
Inorganic chemistry

Inorganic chemistry deals with synthesis and behavior of inorganic and organometallic compounds. This field covers all chemical compounds except the myriad of organic compounds (carbon-based compounds, usually containing C-H bonds), which are the subjects of organic chemistry. The distinction between the two disciplines is far from absolute, as there is much overlap in the subdiscipline of organometallic chemistry. It has applications in every aspect of the chemical industry, including catalysis, materials science, pigments, surfactants, coatings, medications, fuels, and agriculture.

Many inorganic compounds are ionic compounds, consisting of cations and anions joined by ionic bonding. Examples of salts (which are ionic compounds) are magnesium chloride MgCl, which consists of magnesium cations Mg and chloride anions Cl; or sodium oxide NaO, which consists of sodium cations Na and oxide anions O. In any salt, the proportions of the ions are such that the electric charges cancel out, so that the bulk compound is electrically neutral. The ions are described by their oxidation state and their ease of formation can be inferred from the ionization potential (for cations) or from the electron affinity (anions) of the parent elements.

Important classes of inorganic compounds are the oxides, the carbonates, the sulfates, and the halides. Many inorganic compounds are characterized by high melting points. Inorganic salts typically are poor conductors in the solid state. Other important features include their high melting point and ease of crystallization. Where some salts (e.g., NaCl) are very soluble in water, others (e.g., FeS) are not.

The simplest inorganic reaction is double displacement when in mixing of two salts the ions are swapped without a change in oxidation state. In redox reactions one reactant, the "oxidant", lowers its oxidation state and another reactant, the "reductant", has its oxidation state increased. The net result is an exchange of electrons. Electron exchange can occur indirectly as well, e.g., in batteries, a key concept in electrochemistry.

When one reactant contains hydrogen atoms, a reaction can take place by exchanging protons in acid-base chemistry. In a more general definition, any chemical species capable of binding to electron pairs is called a Lewis acid; conversely any molecule that tends to donate an electron pair is referred to as a Lewis base. As a refinement of acid-base interactions, the HSAB theory takes into account polarizability and size of ions.

Inorganic compounds are found in nature as minerals. Soil may contain iron sulfide as pyrite or calcium sulfate as gypsum. Inorganic compounds are also found multitasking as biomolecules: as electrolytes (sodium chloride), in energy storage (ATP) or in construction (the polyphosphate backbone in DNA).

The first important man-made inorganic compound was ammonium nitrate for soil fertilization through the Haber process. Inorganic compounds are synthesized for use as catalysts such as vanadium(V) oxide and titanium(III) chloride, or as reagents in organic chemistry such as lithium aluminium hydride.

Subdivisions of inorganic chemistry are organometallic chemistry, cluster chemistry and bioinorganic chemistry. These fields are active areas of research in inorganic chemistry, aimed toward new catalysts, superconductors, and therapies.

Inorganic chemistry is a highly practical area of science. Traditionally, the scale of a nation's economy could be evaluated by their productivity of sulfuric acid. The top 20 inorganic chemicals manufactured in Canada, China, Europe, India, Japan, and the US (2005 data):
Aluminium sulfate, Ammonia, Ammonium nitrate, Ammonium sulfate, Carbon black, Chlorine, hydrochloric acid, hydrogen, hydrogen peroxide, nitric acid, nitrogen, oxygen, phosphoric acid, sodium carbonate, sodium chlorate, sodium hydroxide, sodium silicate, sodium sulfate, sulfuric acid, and titanium dioxide.

The manufacturing of fertilizers is another practical application of industrial inorganic chemistry.

Descriptive inorganic chemistry focuses on the classification of compounds based on their properties. Partly the classification focuses on the position in the periodic table of the heaviest element (the element with the highest atomic weight) in the compound, partly by grouping compounds by their structural similarities.

Classifications of inorganic chemistry:

Classical coordination compounds feature metals bound to "lone pairs" of electrons residing on the main group atoms of ligands such as HO, NH, Cl, and CN. In modern coordination compounds almost all organic and inorganic compounds can be used as ligands. The "metal" usually is a metal from the groups 3-13, as well as the "trans"-lanthanides and "trans"-actinides, but from a certain perspective, all chemical compounds can be described as coordination complexes.

The stereochemistry of coordination complexes can be quite rich, as hinted at by Werner's separation of two enantiomers of [Co((OH)Co(NH))], an early demonstration that chirality is not inherent to organic compounds. A topical theme within this specialization is supramolecular coordination chemistry. 

These species feature elements from groups I, II, III, IV, V,VI, VII, 0 (excluding hydrogen) of the periodic table. Due to their often similar reactivity, the elements in group 3 (Sc, Y, and La) and group 12 (Zn, Cd, and Hg) are also generally included, and the lanthanides and actinides are sometimes included as well.

Main group compounds have been known since the beginnings of chemistry, e.g., elemental sulfur and the distillable white phosphorus. Experiments on oxygen, O, by Lavoisier and Priestley not only identified an important diatomic gas, but opened the way for describing compounds and reactions according to stoichiometric ratios. The discovery of a practical synthesis of ammonia using iron catalysts by Carl Bosch and Fritz Haber in the early 1900s deeply impacted mankind, demonstrating the significance of inorganic chemical synthesis.
Typical main group compounds are SiO, SnCl, and NO. Many main group compounds can also be classed as “organometallic”, as they contain organic groups, e.g., B(CH)). Main group compounds also occur in nature, e.g., phosphate in DNA, and therefore may be classed as bioinorganic. Conversely, organic compounds lacking (many) hydrogen ligands can be classed as “inorganic”, such as the fullerenes, buckytubes and binary carbon oxides.

Compounds containing metals from group 4 to 11 are considered transition metal compounds. Compounds with a metal from group 3 or 12 are sometimes also incorporated into this group, but also often classified as main group compounds.

Transition metal compounds show a rich coordination chemistry, varying from tetrahedral for titanium (e.g., TiCl) to square planar for some nickel complexes to octahedral for coordination complexes of cobalt. A range of transition metals can be found in biologically important compounds, such as iron in hemoglobin.

 
Usually, organometallic compounds are considered to contain the M-C-H group. The metal (M) in these species can either be a main group element or a transition metal. Operationally, the definition of an organometallic compound is more relaxed to include also highly lipophilic complexes such as metal carbonyls and even metal alkoxides.

Organometallic compounds are mainly considered a special category because organic ligands are often sensitive to hydrolysis or oxidation, necessitating that organometallic chemistry employs more specialized preparative methods than was traditional in Werner-type complexes. Synthetic methodology, especially the ability to manipulate complexes in solvents of low coordinating power, enabled the exploration of very weakly coordinating ligands such as hydrocarbons, H, and N. Because the ligands are petrochemicals in some sense, the area of organometallic chemistry has greatly benefited from its relevance to industry.

Clusters can be found in all classes of chemical compounds. According to the commonly accepted definition, a cluster consists minimally of a triangular set of atoms that are directly bonded to each other. But metal-metal bonded dimetallic complexes are highly relevant to the area. Clusters occur in "pure" inorganic systems, organometallic chemistry, main group chemistry, and bioinorganic chemistry. The distinction between very large clusters and bulk solids is increasingly blurred. This interface is the chemical basis of nanoscience or nanotechnology and specifically arise from the study of quantum size effects in cadmium selenide clusters. Thus, large clusters can be described as an array of bound atoms intermediate in character between a molecule and a solid.

By definition, these compounds occur in nature, but the subfield includes anthropogenic species, such as pollutants (e.g., methylmercury) and drugs (e.g., Cisplatin). The field, which incorporates many aspects of biochemistry, includes many kinds of compounds, e.g., the phosphates in DNA, and also metal complexes containing ligands that range from biological macromolecules, commonly peptides, to ill-defined species such as humic acid, and to water (e.g., coordinated to gadolinium complexes employed for MRI). Traditionally bioinorganic chemistry focuses on electron- and energy-transfer in proteins relevant to respiration. Medicinal inorganic chemistry includes the study of both non-essential and essential elements with applications to diagnosis and therapies.

This important area focuses on structure, bonding, and the physical properties of materials. In practice, solid state inorganic chemistry uses techniques such as crystallography to gain an understanding of the properties that result from collective interactions between the subunits of the solid. Included in solid state chemistry are metals and their alloys or intermetallic derivatives. Related fields are condensed matter physics, mineralogy, and materials science.

An alternative perspective on the area of inorganic chemistry begins with the Bohr model of the atom and, using the tools and models of theoretical chemistry and computational chemistry, expands into bonding in simple and then more complicated molecules. Precise quantum mechanical descriptions for multielectron species, the province of inorganic chemistry, is difficult. This challenge has spawned many semi-quantitative or semi-empirical approaches including molecular orbital theory and ligand field theory, In parallel with these theoretical descriptions, approximate methodologies are employed, including density functional theory.

Exceptions to theories, qualitative and quantitative, are extremely important in the development of the field. For example, Cu(OAc)(HO) is almost diamagnetic below room temperature whereas Crystal Field Theory predicts that the molecule would have two unpaired electrons. The disagreement between qualitative theory (paramagnetic) and observation (diamagnetic) led to the development of models for "magnetic coupling." These improved models led to the development of new magnetic materials and new technologies.

Inorganic chemistry has greatly benefited from qualitative theories. Such theories are easier to learn as they require little background in quantum theory. Within main group compounds, VSEPR theory powerfully predicts, or at least rationalizes, the structures of main group compounds, such as an explanation for why NH is pyramidal whereas ClF is T-shaped. For the transition metals, crystal field theory allows one to understand the magnetism of many simple complexes, such as why [Fe(CN)] has only one unpaired electron, whereas [Fe(HO)] has five. A particularly powerful qualitative approach to assessing the structure and reactivity begins with classifying molecules according to electron counting, focusing on the numbers of valence electrons, usually at the central atom in a molecule.

A central construct in inorganic chemistry is the theory of molecular symmetry. Mathematical group theory provides the language to describe the shapes of molecules according to their point group symmetry. Group theory also enables factoring and simplification of theoretical calculations.

Spectroscopic features are analyzed and described with respect to the symmetry properties of the, "inter alia", vibrational or electronic states. Knowledge of the symmetry properties of the ground and excited states allows one to predict the numbers and intensities of absorptions in vibrational and electronic spectra. A classic application of group theory is the prediction of the number of C-O vibrations in substituted metal carbonyl complexes. The most common applications of symmetry to spectroscopy involve vibrational and electronic spectra.

Group Theory highlights commonalities and differences in the bonding of otherwise disparate species. For example, the metal-based orbitals transform identically for WF and W(CO), but the energies and populations of these orbitals differ significantly. A similar relationship exists CO and molecular beryllium difluoride.

An alternative quantitative approach to inorganic chemistry focuses on energies of reactions. This approach is highly traditional and empirical, but it is also useful. Broad concepts that are couched in thermodynamic terms include redox potential, acidity, phase changes. A classic concept in inorganic thermodynamics is the Born-Haber cycle, which is used for assessing the energies of elementary processes such as electron affinity, some of which cannot be observed directly.

An important aspect of inorganic chemistry focuses on reaction pathways, i.e. reaction mechanisms.

The mechanisms of main group compounds of groups 13-18 are usually discussed in the context of organic chemistry (organic compounds are main group compounds, after all). Elements heavier than C, N, O, and F often form compounds with more electrons than predicted by the octet rule, as explained in the article on hypervalent molecules. The mechanisms of their reactions differ from organic compounds for this reason. Elements lighter than carbon (B, Be, Li) as well as Al and Mg often form electron-deficient structures that are electronically akin to carbocations. Such electron-deficient species tend to react via associative pathways. The chemistry of the lanthanides mirrors many aspects of chemistry seen for aluminium.

Transition metal and main group compounds often react differently. The important role of d-orbitals in bonding strongly influences the pathways and rates of ligand substitution and dissociation. These themes are covered in articles on coordination chemistry and ligand. Both associative and dissociative pathways are observed.

An overarching aspect of mechanistic transition metal chemistry is the kinetic lability of the complex illustrated by the exchange of free and bound water in the prototypical complexes [M(HO)]:
The rates of water exchange varies by 20 orders of magnitude across the periodic table, with lanthanide complexes at one extreme and Ir(III) species being the slowest.

Redox reactions are prevalent for the transition elements. Two classes of redox reaction are considered: atom-transfer reactions, such as oxidative addition/reductive elimination, and electron-transfer. A fundamental redox reaction is "self-exchange", which involves the degenerate reaction between an oxidant and a reductant. For example, permanganate and its one-electron reduced relative manganate exchange one electron:

Coordinated ligands display reactivity distinct from the free ligands. For example, the acidity of the ammonia ligands in [Co(NH)] is elevated relative to NH itself. Alkenes bound to metal cations are reactive toward nucleophiles whereas alkenes normally are not. The large and industrially important area of catalysis hinges on the ability of metals to modify the reactivity of organic ligands. Homogeneous catalysis occurs in solution and heterogeneous catalysis occurs when gaseous or dissolved substrates interact with surfaces of solids. Traditionally homogeneous catalysis is considered part of organometallic chemistry and heterogeneous catalysis is discussed in the context of surface science, a subfield of solid state chemistry. But the basic inorganic chemical principles are the same. Transition metals, almost uniquely, react with small molecules such as CO, H, O, and CH. The industrial significance of these feedstocks drives the active area of catalysis. Ligands can also undergo ligand transfer reactions such as transmetalation.

Because of the diverse range of elements and the correspondingly diverse properties of the resulting derivatives, inorganic chemistry is closely associated with many methods of analysis. Older methods tended to examine bulk properties such as the electrical conductivity of solutions, melting points, solubility, and acidity. With the advent of quantum theory and the corresponding expansion of electronic apparatus, new tools have been introduced to probe the electronic properties of inorganic molecules and solids. Often these measurements provide insights relevant to theoretical models. For example, measurements on the photoelectron spectrum of methane demonstrated that describing the bonding by the two-center, two-electron bonds predicted between the carbon and hydrogen using Valence Bond Theory is not appropriate for describing ionisation processes in a simple way. Such insights led to the popularization of molecular orbital theory as fully delocalised orbitals are a more appropriate simple description of electron removal and electron excitation.

Commonly encountered techniques are:

Although some inorganic species can be obtained in pure form from nature, most are synthesized in chemical plants and in the laboratory.

Inorganic synthetic methods can be classified roughly according to the volatility or solubility of the component reactants. Soluble inorganic compounds are prepared using methods of organic synthesis. For metal-containing compounds that are reactive toward air, Schlenk line and glove box techniques are followed. Volatile compounds and gases are manipulated in “vacuum manifolds” consisting of glass piping interconnected through valves, the entirety of which can be evacuated to 0.001 mm Hg or less. Compounds are condensed using liquid nitrogen (b.p. 78K) or other cryogens. Solids are typically prepared using tube furnaces, the reactants and products being sealed in containers, often made of fused silica (amorphous SiO) but sometimes more specialized materials such as welded Ta tubes or Pt “boats”. Products and reactants are transported between temperature zones to drive reactions.



</doc>
<doc id="14625" url="https://en.wikipedia.org/wiki?curid=14625" title="Insert (filmmaking)">
Insert (filmmaking)

In film, an insert is a shot of part of a scene as filmed from a different angle and/or focal length from the master shot. Inserts cover action already covered in the master shot, but emphasize a different aspect of that action due to the different framing. An insert differs from a cutaway as cutaways cover action "not" covered in the master shot.

There are more exact terms to use when the new, inserted shot is another view of actors: close-up, head shot, knee shot, two shot. So the term "insert" is often confined to views of objects—and body parts, other than the head. Often inserts of this sort are done separately from the main action, by a second-unit director using stand-ins.

Inserts and cutaways can both be vexatious for directors, as care must be taken to preserve continuity by keeping the objects in the same relative position as in the main take, and having the lighting be the same.

The 1975 movie "Inserts" directed by John Byrum about a pornographic film production, which starred Richard Dreyfuss and was originally released with an X rating, took its name from the double meaning that "insert" both refers to this film technique (often used in pornographic filmmaking) and to sexual intercourse.



</doc>
<doc id="14626" url="https://en.wikipedia.org/wiki?curid=14626" title="Ingmar Bergman">
Ingmar Bergman

Ernst Ingmar Bergman (14 July 1918 – 30 July 2007) was a Swedish director, writer, and producer who worked in film, television, theatre, and radio. Considered to be among the most accomplished and influential filmmakers of all time, Bergman's films include "Smiles of a Summer Night" (1955), "The Seventh Seal" (1957), "Wild Strawberries" (1957), "Persona" (1966), "Cries and Whispers" (1972), "Scenes from a Marriage" (1973), and "Fanny and Alexander" (1982); the last two exist in extended television versions.

Bergman directed over sixty films and documentaries for cinematic release and for television screenings, most of which he also wrote. He also directed over 170 plays. He eventually forged a creative partnership with his cinematographers Gunnar Fischer and Sven Nykvist. Among his company of actors were Harriet and Bibi Andersson, Liv Ullmann, Gunnar Björnstrand, Erland Josephson, Ingrid Thulin, and Max von Sydow. Most of his films were set in Sweden, and many films from "Through a Glass Darkly" (1961) onward were filmed on the island of Fårö.

Philip French referred to Bergman as "one of the greatest artists of the 20th century ... he found in literature and the performing arts a way of both recreating and questioning the human condition." Director Martin Scorsese commented: "If you were alive in the 50s and the 60s and of a certain age, a teenager on your way to becoming an adult, and you wanted to make movies, I don't see how you couldn't be influenced by Bergman ...It's impossible to overestimate the effect that those films had on people."

Ernst Ingmar Bergman was born on 14 July 1918 in Uppsala, Sweden, the son of Erik Bergman, a Lutheran minister and later chaplain to the King of Sweden, and Karin ("née" Åkerblom), a nurse who also had Walloon ancestors. He grew up with his older brother Dag and sister Margareta surrounded by religious imagery and discussion. His father was a conservative parish minister with strict ideas of parenting. Ingmar was locked up in dark closets for infractions such as wetting himself. "While father preached away in the pulpit and the congregation prayed, sang, or listened", Ingmar wrote in his autobiography "Laterna Magica",

I devoted my interest to the church's mysterious world of low arches, thick walls, the smell of eternity, the coloured sunlight quivering above the strangest vegetation of medieval paintings and carved figures on ceilings and walls. There was everything that one's imagination could desire—angels, saints, dragons, prophets, devils, humans ...

Although raised in a devout Lutheran household, Bergman later stated that he lost his faith when aged eight, and only came to terms with this fact while making "Winter Light" in 1962. His interest in theatre and film began early: "At the age of nine, he traded a set of tin soldiers for a magic lantern, a possession that altered the course of his life. Within a year, he had created, by playing with this toy, a private world in which he felt completely at home, he recalled. He fashioned his own scenery, marionettes, and lighting effects and gave puppet productions of Strindberg plays in which he spoke all the parts."

Bergman attended Palmgren's School as a teenager. His school years were unhappy, and he remembered them unfavourably in later years. In a 1944 letter concerning the film "Torment" (sometimes known as "Frenzy"), which sparked debate on the condition of Swedish high schools (and which Bergman had written), the school's principal Henning Håkanson wrote, among other things, that Bergman had been a "problem child". Bergman wrote in a response that he had strongly disliked the emphasis on homework and testing in his formal schooling.

In 1934, aged 16, he was sent to Germany to spend the summer holidays with family friends. He attended a Nazi rally in Weimar at which he saw Adolf Hitler. He later wrote in "Laterna Magica" ("The Magic Lantern") about the visit to Germany, describing how the German family had put a portrait of Hitler on the wall by his bed, and that "for many years, I was on Hitler's side, delighted by his success and saddened by his defeats". Bergman commented that "Hitler was unbelievably charismatic. He electrified the crowd. ... The Nazism I had seen seemed fun and youthful". Bergman did two five-month stretches in Sweden of mandatory military service.

Bergman enrolled at Stockholm University College (later renamed Stockholm University) in 1937, to study art and literature. He spent most of his time involved in student theatre and became a "genuine movie addict". At the same time, a romantic involvement led to a physical confrontation with his father which resulted in a break in their relationship which lasted for many years. Although he did not graduate from the university, he wrote a number of plays and an opera, and became an assistant director at a local theatre. In 1942, he was given the opportunity to direct one of his own scripts, "Caspar's Death". The play was seen by members of Svensk Filmindustri, which then offered Bergman a position working on scripts. He married Else Fisher in 1943.

Bergman's film career began in 1941 with his work rewriting scripts, but his first major accomplishment was in 1944 when he wrote the screenplay for "Torment" (a.k.a. "Frenzy") ("Hets"), a film directed by Alf Sjöberg. Along with writing the screenplay, he was also appointed assistant director of the film. In his second autobiographical book, "Images: My Life in Film", Bergman describes the filming of the exteriors as his actual film directorial debut. The film sparked debate on Swedish formal education. When Henning Håkanson (the principal of the high school Bergman had attended) wrote a letter following the film's release, Bergman, according to scholar Frank Gado, disparaged in a response what he viewed as Håkanson's implication that students "who did not fit some arbitrary prescription of worthiness deserved the system's cruel neglect". Bergman also stated in the letter that he "hated school as a principle, as a system and as an institution. And as such I have definitely not wanted to criticize my own school, but all schools." The international success of this film led to Bergman's first opportunity to direct a year later. During the next ten years he wrote and directed more than a dozen films, including "Prison" ("Fängelse") in 1949, as well as "Sawdust and Tinsel" ("Gycklarnas afton") and "Summer with Monika" ("Sommaren med Monika"), both released in 1953.

Bergman first achieved worldwide success with "Smiles of a Summer Night" ("Sommarnattens leende", 1955), which won for "Best poetic humour" and was nominated for the Palme d'Or at Cannes the following year. This was followed by "The Seventh Seal" ("Det sjunde inseglet") and "Wild Strawberries" ("Smultronstället"), released in Sweden ten months apart in 1957. "The Seventh Seal" won a special jury prize and was nominated for the Palme d'Or at Cannes, and "Wild Strawberries" won numerous awards for Bergman and its star, Victor Sjöström. Bergman continued to be productive for the next two decades. From the early 1960s, he spent much of his life on the island of Fårö, where he made several films.

In the early 1960s he directed three films that explored the theme of faith and doubt in God, "Through a Glass Darkly" ("Såsom i en Spegel", 1961), "Winter Light" ("Nattvardsgästerna", 1962), and "The Silence" ("Tystnaden", 1963). Critics created the notion that the common themes in these three films made them a trilogy or cinematic triptych. Bergman initially responded that he did not plan these three films as a trilogy and that he could not see any common motifs in them, but he later seemed to adopt the notion, with some equivocation. His parody of the films of Federico Fellini, "All These Women" ("För att inte tala om alla dessa kvinnor") was released in 1964.

Largely a two-hander with Bibi Andersson and Liv Ullmann, "Persona" (1966) is a film that Bergman himself considered one of his most important works. While the highly experimental film won few awards, it has been considered his masterpiece. Other films of the period include "The Virgin Spring" ("Jungfrukällan", 1960), "Hour of the Wolf" ("Vargtimmen", 1968), "Shame" ("Skammen", 1968) and "The Passion of Anna" ("En Passion", 1969). With his cinematographer Sven Nykvist, Bergman made use of a crimson color scheme for "Cries and Whispers" (1972), which received a nomination for the Academy Award for Best Picture. He also produced extensively for Swedish television at this time. Two works of note were "Scenes from a Marriage" ("Scener ur ett äktenskap", 1973) and "The Magic Flute" ("Trollflöjten", 1975).

On 30 January 1976, while rehearsing August Strindberg's "The Dance of Death" at the Royal Dramatic Theatre in Stockholm, he was arrested by two plainclothes police officers and charged with income tax evasion. The impact of the event on Bergman was devastating. He suffered a nervous breakdown as a result of the humiliation, and was hospitalised in a state of deep depression.

The investigation was focused on an alleged 1970 transaction of 500,000 Swedish kronor (SEK) between Bergman's Swedish company "Cinematograf" and its Swiss subsidiary "Persona", an entity that was mainly used for the paying of salaries to foreign actors. Bergman dissolved "Persona" in 1974 after having been notified by the Swedish Central Bank and subsequently reported the income. On 23 March 1976, the special prosecutor Anders Nordenadler dropped the charges against Bergman, saying that the alleged crime had no legal basis, saying it would be like bringing "charges against a person who has stolen his own car, thinking it was someone else's". Director General Gösta Ekman, chief of the Swedish Internal Revenue Service, defended the failed investigation, saying that the investigation was dealing with important legal material and that Bergman was treated just like any other suspect. He expressed regret that Bergman had left the country, hoping that Bergman was a "stronger" person now when the investigation had shown that he had not done any wrong.

Although the charges were dropped, Bergman became disconsolate, fearing he would never again return to directing. Despite pleas by the Swedish prime minister Olof Palme, high public figures, and leaders of the film industry, he vowed never to work in Sweden again. He closed down his studio on the island of Fårö, suspended two announced film projects, and went into self-imposed exile in Munich, Germany. Harry Schein, director of the Swedish Film Institute, estimated the immediate damage as ten million SEK (kronor) and hundreds of jobs lost.

Bergman then briefly considered the possibility of working in America; his next film, "The Serpent's Egg" (1977) was a German-U.S. production and his second English-language film (the first being "The Touch", 1971). This was followed by a British-Norwegian co-production, "Autumn Sonata" ("Höstsonaten", 1978) starring Ingrid Bergman (no relation), and "From the Life of the Marionettes" ("Aus dem Leben der Marionetten", 1980) which was a British-German co-production.

He temporarily returned to his homeland to direct "Fanny and Alexander" ("Fanny och Alexander", 1982). Bergman stated that the film would be his last, and that afterwards he would focus on directing theatre. After that he wrote several film scripts and directed a number of television specials. As with previous work for television, some of these productions were later theatrically released. The last such work was "Saraband" (2003), a sequel to "Scenes from a Marriage" and directed by Bergman when he was 84 years old.

Although he continued to operate from Munich, by mid-1978 Bergman had overcome some of his bitterness toward the Swedish government. In July of that year he visited Sweden, celebrating his sixtieth birthday on the island of Fårö, and partly resumed his work as a director at Royal Dramatic Theatre. To honour his return, the Swedish Film Institute launched a new Ingmar Bergman Prize to be awarded annually for excellence in filmmaking. Still, he remained in Munich until 1984. In one of the last major interviews with Bergman, conducted in 2005 on the island of Fårö, Bergman said that despite being active during the exile, he had effectively lost eight years of his professional life.

Bergman retired from filmmaking in December 2003. He had hip surgery in October 2006 and was making a difficult recovery. He died in his sleep at age 89; his body was found at his home on the island of Fårö, on 30 July 2007, sixteen days after his 89th birthday. (It was the same day another renowned existentialist film director, Michelangelo Antonioni, died.) The interment was private, at the Fårö Church on 18 August 2007. A place in the Fårö churchyard was prepared for him under heavy secrecy. Although he was buried on the island of Fårö, his name and date of birth were inscribed under his wife's name on a tomb at Roslagsbro churchyard, Norrtälje Municipality, several years before his death.

Selected work:
Bergman developed a personal "repertory company" of Swedish actors whom he repeatedly cast in his films, including Max von Sydow, Bibi Andersson, Harriet Andersson, Erland Josephson, Ingrid Thulin, Gunnel Lindblom, and Gunnar Björnstrand, each of whom appeared in at least five Bergman features. Norwegian actress Liv Ullmann, who appeared in nine of Bergman's films and one televisual film ("Saraband"), was the last to join this group (in the film "Persona"), and ultimately became the most closely associated with Bergman, both artistically and personally. They had a daughter together, Linn Ullmann (born 1966).

In Bergman's working arrangement with Sven Nykvist, his best-known cinematographer, the two men developed sufficient rapport to allow Bergman not to worry about the composition of a shot until the day before it was filmed. On the morning of the shoot, he would briefly speak to Nykvist about the mood and composition he hoped for, and then leave Nykvist to work, lacking interruption or comment until post-production discussion of the next day's work.

By Bergman's own account, he never had a problem with funding. He cited two reasons for this: one, that he did not live in the United States, which he viewed as obsessed with box-office earnings; and two, that his films tended to be low-budget affairs. ("Cries and Whispers", for instance, was finished for about $450,000, while "Scenes from a Marriage", a six-episode television feature, cost only $200,000.)

Bergman usually wrote his films' screenplays, thinking about them for months or years before starting the actual process of writing, which he viewed as somewhat tedious. His earlier films are carefully constructed and are either based on his plays or written in collaboration with other authors. Bergman stated that in his later works, when on occasion his actors would want to do things differently from his own intention, he would let them, noting that the results were often "disastrous" when he did not do so. As his career progressed, Bergman increasingly let his actors improvise their dialogue. In his later films, he wrote just the ideas informing the scene and allowed his actors to determine the exact dialogue. When viewing daily rushes, Bergman stressed the importance of being critical but unemotive, claiming that he asked himself not if the work was great or terrible, but rather if it was sufficient or needed to be reshot.

Bergman's films usually deal with existential questions of mortality, loneliness, and religious faith. In addition to these cerebral topics, however, sexual desire features in the foreground of most of his films, whether the central event is medieval plague ("The Seventh Seal"), upper-class family activity in early twentieth century Uppsala ("Fanny and Alexander"), or contemporary alienation ("The Silence"). His female characters are usually more in touch with their sexuality than their male equivalents, and unafraid to proclaim it, sometimes with breathtaking overtness (as in "Cries and Whispers") as would define the work of "the conjurer," as Bergman called himself in a 1960 "TIME" cover story. In an interview with "Playboy" in 1964, he said: "The manifestation of sex is very important, and particularly to me, for above all, I don't want to make merely intellectual films. I want audiences to feel, to sense my films. This to me is much more important than their understanding them." Film, Bergman said, was his demanding mistress. While he was a social democrat as an adult, Bergman stated that "as an artist I'm not politically involved ... I don't make propaganda for either one attitude or the other."

When asked in the series of interviews later titled "Ingmar Bergman – 3 dokumentärer om film, teater, Fårö och livet" conducted by Marie Nyreröd for Swedish TV and released in 2004, Bergman said that of his works, he held "Winter Light", "Persona", and "Cries and Whispers" in the highest regard. There he also states that he managed to push the envelope of film making in the films "Persona" and "Cries and Whispers". Bergman stated on numerous occasions (for example in the interview book "Bergman on Bergman") that "The Silence" meant the end of the era in which religious questions were a major concern of his films. Bergman said that he would get depressed by his own films: "jittery and ready to cry... and miserable." In the same interview he also stated: "If there is one thing I miss about working with films, it is working with Sven" (Nykvist), the third cinematographer with whom he had collaborated.

Although Bergman was universally famous for his contribution to cinema, he was also an active and productive stage director all his life. During his studies at what was then Stockholm University College, he became active in its student theatre, where he made a name for himself early on. His first work after graduation was as a trainee-director at a Stockholm theatre. At twenty-six years, he became the youngest theatrical manager in Europe at the Helsingborg City Theatre. He stayed at Helsingborg for three years and then became the director at Gothenburg city theatre from 1946 to 1949.

He became director of the Malmö City Theatre in 1953, and remained for seven years. Many of his star actors were people with whom he began working on stage. He was the director of the Royal Dramatic Theatre in Stockholm from 1960 to 1966, and manager from 1963 to 1966, where he began a long-time collaboration with choreographer Donya Feuer.

After Bergman left Sweden because of the tax evasion incident, he became director of the "Residenz Theatre" of Munich, Germany (1977–84). He remained active in theatre throughout the 1990s and made his final production on stage with Henrik Ibsen's "The Wild Duck" at the Royal Dramatic Theatre in 2002.

Bergman was married five times:

The first four marriages ended in divorce, while the last ended when his wife Ingrid died of stomach cancer in 1995, aged 65. Aside from his marriages, Bergman had romantic relationships with actresses Harriet Andersson (1952–55), Bibi Andersson (1955–59), and Liv Ullmann (1965–70). He was the father of writer Linn Ullmann with Ullmann. In all, Bergman had nine children, one of whom predeceased him. Bergman eventually married all the mothers of his children, with the exception of Liv Ullmann. His daughter with his last wife, Ingrid von Rosen, was born twelve years before their marriage.

Although Bergman described himself as one who had lost his faith in an afterlife, Max Von Sydow stated in an interview that he had had many discussions with him about religion, and indicated that Bergman's belief in the afterlife was restored.

In 1958, he won the Best Director award for "Brink of Life" at the Cannes Film Festival, and won the Golden Bear for "Wild Strawberries" at the Berlin International Film Festival"." In 1971, Bergman received the Irving G. Thalberg Memorial Award at the Academy Awards ceremony. Three of his films ("Through a Glass Darkly", "The Virgin Spring", and "Fanny and Alexander") won the Academy Award for Best Foreign Language Film. In 1997, he was awarded the Palme des Palmes (Palm of the Palms) at the 50th anniversary of the Cannes Film Festival. He won many other awards and has been nominated for numerous other awards.

Academy Awards

Bergman's work was a point of reference and inspiration for director Woody Allen. His films are mentioned and praised in "Annie Hall" and others of his films. Allen also admired Bergman's longtime director of photography Sven Nykvist and invited him to be his DP on "Crimes and Misdemeanors".

After Bergman died, a large archive of notes was donated to the Swedish Film Institute. Among the notes are several unpublished and unfinished scripts both for stage and films, and many more ideas for works in different stages of development. A never-performed play has the title "Kärlek utan älskare" ("Love without lovers"), and has the note "Complete disaster!" written on the envelope; the play is about a director who disappears and an editor who tries to complete a work he has left unfinished. Other canceled projects include the script for a pornographic film which Bergman abandoned since he did not think it was alive enough, a play about a cannibal, some loose scenes set inside a womb, a film about the life of Jesus, a film about "The Merry Widow", and a play with the title "Från sperm till spöke" ("From sperm to spook"). The Swedish director Marcus Lindeen went through the material, and inspired by "Kärlek utan älskare" he took samples from many of the works and turned them into a play, titled "Arkivet för orealiserbara drömmar och visioner" ("The archive for unrealisable dreams and visions"). Lindeen's play premiered on 28 May 2012 at the Stockholm City Theatre.

Terrence Rafferty of "The New York Times" wrote that throughout the 1960s, when Bergman "was considered pretty much the last word in cinematic profundity, his every tic was scrupulously pored over, analyzed, elaborated in ingenious arguments about identity, the nature of film, the fate of the artist in the modern world and so on."

Writer and director Richard Ayoade counts Bergman as one of his inspirations. In 2017, the British Film Institute (BFI) hosted an Ingmar Bergman season and Ayoade said in a "Guardian" interview that he saw everything in it, "which was one of the best two months ever." The BFI's programme included a discussion with Ayoade on Bergman's 1966 film, "Persona", before a screening.






</doc>
<doc id="14627" url="https://en.wikipedia.org/wiki?curid=14627" title="Isaac Newton">
Isaac Newton

Sir Isaac Newton (25 December 1642 – 20 March 1726/27) was an English mathematician, physicist, astronomer, theologian, and author (described in his own day as a "natural philosopher") who is widely recognised as one of the most influential scientists of all time and as a key figure in the scientific revolution. His book "Philosophiæ Naturalis Principia Mathematica" ("Mathematical Principles of Natural Philosophy"), first published in 1687, laid the foundations of classical mechanics. Newton also made seminal contributions to optics, and shares credit with Gottfried Wilhelm Leibniz for developing the infinitesimal calculus.

In "Principia", Newton formulated the laws of motion and universal gravitation that formed the dominant scientific viewpoint until it was superseded by the theory of relativity. Newton used his mathematical description of gravity to prove Kepler's laws of planetary motion, account for tides, the trajectories of comets, the precession of the equinoxes and other phenomena, eradicating doubt about the Solar System's heliocentricity. He demonstrated that the motion of objects on Earth and celestial bodies could be accounted for by the same principles. Newton's inference that the Earth is an oblate spheroid was later confirmed by the geodetic measurements of Maupertuis, La Condamine, and others, convincing most European scientists of the superiority of Newtonian mechanics over earlier systems.

Newton built the first practical reflecting telescope and developed a sophisticated theory of colour based on the observation that a prism separates white light into the colours of the visible spectrum. His work on light was collected in his highly influential book "Opticks", published in 1704. He also formulated an empirical law of cooling, made the first theoretical calculation of the speed of sound, and introduced the notion of a Newtonian fluid. In addition to his work on calculus, as a mathematician Newton contributed to the study of power series, generalised the binomial theorem to non-integer exponents, developed a method for approximating the roots of a function, and classified most of the cubic plane curves.

Newton was a fellow of Trinity College and the second Lucasian Professor of Mathematics at the University of Cambridge. He was a devout but unorthodox Christian who privately rejected the doctrine of the Trinity. Unusually for a member of the Cambridge faculty of the day, he refused to take holy orders in the Church of England. Beyond his work on the mathematical sciences, Newton dedicated much of his time to the study of alchemy and biblical chronology, but most of his work in those areas remained unpublished until long after his death. Politically and personally tied to the Whig party, Newton served two brief terms as Member of Parliament for the University of Cambridge, in 1689–90 and 1701–02. He was knighted by Queen Anne in 1705 and spent the last three decades of his life in London, serving as Warden (1696–1700) and Master (1700–1727) of the Royal Mint, as well as president of the Royal Society (1703–1727).

Isaac Newton was born (according to the Julian calendar, in use in England at the time) on Christmas Day, 25 December 1642 (NS 4 January 1643) "an hour or two after midnight", at Woolsthorpe Manor in Woolsthorpe-by-Colsterworth, a hamlet in the county of Lincolnshire. His father, also named Isaac Newton, had died three months before. Born prematurely, Newton was a small child; his mother Hannah Ayscough reportedly said that he could have fit inside a quart mug. When Newton was three, his mother remarried and went to live with her new husband, the Reverend Barnabas Smith, leaving her son in the care of his maternal grandmother, Margery Ayscough (née Blythe). Newton disliked his stepfather and maintained some enmity towards his mother for marrying him, as revealed by this entry in a list of sins committed up to the age of 19: "Threatening my father and mother Smith to burn them and the house over them." Newton's mother had three children (Mary, Benjamin and Hannah) from her second marriage. 

From the age of about twelve until he was seventeen, Newton was educated at The King's School, Grantham, which taught Latin and Greek and probably imparted a significant foundation of mathematics. He was removed from school and returned to Woolsthorpe-by-Colsterworth by October 1659. His mother, widowed for the second time, attempted to make him a farmer, an occupation he hated. Henry Stokes, master at The King's School, persuaded his mother to send him back to school. Motivated partly by a desire for revenge against a schoolyard bully, he became the top-ranked student, distinguishing himself mainly by building sundials and models of windmills.

In June 1661, he was admitted to Trinity College, Cambridge, on the recommendation of his uncle Rev William Ayscough, who had studied there. He started as a subsizar—paying his way by performing valet's duties—until he was awarded a scholarship in 1664, guaranteeing him four more years until he could get his MA. At that time, the college's teachings were based on those of Aristotle, whom Newton supplemented with modern philosophers such as Descartes, and astronomers such as Galileo and Thomas Street, through whom he learned of Kepler's work. He set down in his notebook a series of ""Quaestiones"" about mechanical philosophy as he found it. In 1665, he discovered the generalised binomial theorem and began to develop a mathematical theory that later became calculus. Soon after Newton had obtained his BA degree in August 1665, the university temporarily closed as a precaution against the Great Plague. Although he had been undistinguished as a Cambridge student, Newton's private studies at his home in Woolsthorpe over the subsequent two years saw the development of his theories on calculus, optics, and the law of gravitation.

In April 1667, he returned to Cambridge and in October was elected as a fellow of Trinity. Fellows were required to become ordained priests, although this was not enforced in the restoration years and an assertion of conformity to the Church of England was sufficient. However, by 1675 the issue could not be avoided and by then his unconventional views stood in the way. Nevertheless, Newton managed to avoid it by means of special permission from Charles II.

His studies had impressed the Lucasian professor Isaac Barrow, who was more anxious to develop his own religious and administrative potential (he became master of Trinity two years later); in 1669 Newton succeeded him, only one year after receiving his MA. He was elected a Fellow of the Royal Society (FRS) in 1672.

Newton's work has been said "to distinctly advance every branch of mathematics then studied." His work on the subject usually referred to as fluxions or calculus, seen in a manuscript of October 1666, is now published among Newton's mathematical papers. The author of the manuscript "De analysi per aequationes numero terminorum infinitas", sent by Isaac Barrow to John Collins in June 1669, was identified by Barrow in a letter sent to Collins in August of that year as "[...] of an extraordinary genius and proficiency in these things."

Newton later became involved in a dispute with Leibniz over priority in the development of calculus (the Leibniz–Newton calculus controversy). Most modern historians believe that Newton and Leibniz developed calculus independently, although with very different mathematical notations. Occasionally it has been suggested that Newton published almost nothing about it until 1693, and did not give a full account until 1704, while Leibniz began publishing a full account of his methods in 1684. Leibniz's notation and "differential Method", nowadays recognised as much more convenient notations, were adopted by continental European mathematicians, and after 1820 or so, also by British mathematicians.

Such a suggestion fails to account for the calculus in Book 1 of Newton's "Principia" itself and in its forerunner manuscripts, such as "De motu corporum in gyrum" of 1684; this content has been pointed out by critics of both Newton's time and modern times.

His work extensively uses calculus in geometric form based on limiting values of the ratios of vanishingly small quantities: in the "Principia" itself, Newton gave demonstration of this under the name of "the method of first and last ratios" and explained why he put his expositions in this form, remarking also that "hereby the same thing is performed as by the method of indivisibles."

Because of this, the "Principia" has been called "a book dense with the theory and application of the infinitesimal calculus" in modern times and in Newton's time "nearly all of it is of this calculus." His use of methods involving "one or more orders of the infinitesimally small" is present in his "De motu corporum in gyrum" of 1684 and in his papers on motion "during the two decades preceding 1684".

Newton had been reluctant to publish his calculus because he feared controversy and criticism. He was close to the Swiss mathematician Nicolas Fatio de Duillier. In 1691, Duillier started to write a new version of Newton's "Principia", and corresponded with Leibniz. In 1693, the relationship between Duillier and Newton deteriorated and the book was never completed.

Starting in 1699, other members of the Royal Society accused Leibniz of plagiarism. The dispute then broke out in full force in 1711 when the Royal Society proclaimed in a study that it was Newton who was the true discoverer and labelled Leibniz a fraud; it was later found that Newton wrote the study's concluding remarks on Leibniz. Thus began the bitter controversy which marred the lives of both Newton and Leibniz until the latter's death in 1716.

Newton is generally credited with the generalised binomial theorem, valid for any exponent. He discovered Newton's identities, Newton's method, classified cubic plane curves (polynomials of degree three in two variables), made substantial contributions to the theory of finite differences, and was the first to use fractional indices and to employ coordinate geometry to derive solutions to Diophantine equations. He approximated partial sums of the harmonic series by logarithms (a precursor to Euler's summation formula) and was the first to use power series with confidence and to revert power series. Newton's work on infinite series was inspired by Simon Stevin's decimals.

When Newton received his MA and became a Fellow of the "College of the Holy and Undivided Trinity" in 1667, he made the commitment that "I will either set Theology as the object of my studies and will take holy orders when the time prescribed by these statutes [7 years] arrives, or I will resign from the college." Up until this point he had not thought much about religion and had twice signed his agreement to the thirty-nine articles, the basis of Church of England doctrine.

He was appointed Lucasian Professor of Mathematics in 1669, on Barrow's recommendation. During that time, any Fellow of a college at Cambridge or Oxford was required to take holy orders and become an ordained Anglican priest. However, the terms of the Lucasian professorship required that the holder be active in the church – presumably, so as to have more time for science. Newton argued that this should exempt him from the ordination requirement, and Charles II, whose permission was needed, accepted this argument. Thus a conflict between Newton's religious views and Anglican orthodoxy was averted.

In 1666, Newton observed that the spectrum of colours exiting a prism in the position of minimum deviation is oblong, even when the light ray entering the prism is circular, which is to say, the prism refracts different colours by different angles. This led him to conclude that colour is a property intrinsic to light – a point which had, until then, been a matter of debate. 

From 1670 to 1672, Newton lectured on optics. During this period he investigated the refraction of light, demonstrating that the multicoloured spectrum produced by a prism could be recomposed into white light by a lens and a second prism. Modern scholarship has revealed that Newton's analysis and resynthesis of white light owes a debt to corpuscular alchemy.

He showed that coloured light does not change its properties by separating out a coloured beam and shining it on various objects, and that regardless of whether reflected, scattered, or transmitted, the light remains the same colour. Thus, he observed that colour is the result of objects interacting with already-coloured light rather than objects generating the colour themselves. This is known as Newton's theory of colour.

From this work, he concluded that the lens of any refracting telescope would suffer from the dispersion of light into colours (chromatic aberration). As a proof of the concept, he constructed a telescope using reflective mirrors instead of lenses as the objective to bypass that problem. Building the design, the first known functional reflecting telescope, today known as a Newtonian telescope, involved solving the problem of a suitable mirror material and shaping technique. Newton ground his own mirrors out of a custom composition of highly reflective speculum metal, using Newton's rings to judge the quality of the optics for his telescopes. In late 1668, he was able to produce this first reflecting telescope. It was about eight inches long and it gave a clearer and larger image. In 1671, the Royal Society asked for a demonstration of his reflecting telescope. Their interest encouraged him to publish his notes, "Of Colours", which he later expanded into the work "Opticks". When Robert Hooke criticised some of Newton's ideas, Newton was so offended that he withdrew from public debate. Newton and Hooke had brief exchanges in 1679–80, when Hooke, appointed to manage the Royal Society's correspondence, opened up a correspondence intended to elicit contributions from Newton to Royal Society transactions, which had the effect of stimulating Newton to work out a proof that the elliptical form of planetary orbits would result from a centripetal force inversely proportional to the square of the radius vector. But the two men remained generally on poor terms until Hooke's death.

Newton argued that light is composed of particles or corpuscles, which were refracted by accelerating into a denser medium. He verged on soundlike waves to explain the repeated pattern of reflection and transmission by thin films (Opticks Bk.II, Props. 12), but still retained his theory of 'fits' that disposed corpuscles to be reflected or transmitted (Props.13). However, later physicists favoured a purely wavelike explanation of light to account for the interference patterns and the general phenomenon of diffraction. Today's quantum mechanics, photons, and the idea of wave–particle duality bear only a minor resemblance to Newton's understanding of light.

In his "Hypothesis of Light" of 1675, Newton posited the existence of the ether to transmit forces between particles. The contact with the Cambridge Platonist philosopher Henry More revived his interest in alchemy. He replaced the ether with occult forces based on Hermetic ideas of attraction and repulsion between particles. John Maynard Keynes, who acquired many of Newton's writings on alchemy, stated that "Newton was not the first of the age of reason: He was the last of the magicians." Newton's interest in alchemy cannot be isolated from his contributions to science. This was at a time when there was no clear distinction between alchemy and science. Had he not relied on the occult idea of action at a distance, across a vacuum, he might not have developed his theory of gravity.

In 1704, Newton published "Opticks", in which he expounded his corpuscular theory of light. He considered light to be made up of extremely subtle corpuscles, that ordinary matter was made of grosser corpuscles and speculated that through a kind of alchemical transmutation "Are not gross Bodies and Light convertible into one another, ... and may not Bodies receive much of their Activity from the Particles of Light which enter their Composition?" Newton also constructed a primitive form of a frictional electrostatic generator, using a glass globe.

In his book "Opticks", Newton was the first to show a diagram using a prism as a beam expander, and also the use of multiple-prism arrays. Some 278 years after Newton's discussion, multiple-prism beam expanders became central to the development of narrow-linewidth tunable lasers. Also, the use of these prismatic beam expanders led to the multiple-prism dispersion theory.

Subsequent to Newton, much has been amended. Young and Fresnel combined Newton's particle theory with Huygens' wave theory to show that colour is the visible manifestation of light's wavelength. Science also slowly came to realise the difference between perception of colour and mathematisable optics. The German poet and scientist, Goethe, could not shake the Newtonian foundation but "one hole Goethe did find in Newton's armour, ... Newton had committed himself to the doctrine that refraction without colour was impossible. He, therefore, thought that the object-glasses of telescopes must forever remain imperfect, achromatism and refraction being incompatible. This inference was proved by Dollond to be wrong."

In 1679, Newton returned to his work on celestial mechanics by considering gravitation and its effect on the orbits of planets with reference to Kepler's laws of planetary motion. This followed stimulation by a brief exchange of letters in 1679–80 with Hooke, who had been appointed to manage the Royal Society's correspondence, and who opened a correspondence intended to elicit contributions from Newton to Royal Society transactions. Newton's reawakening interest in astronomical matters received further stimulus by the appearance of a comet in the winter of 1680–1681, on which he corresponded with John Flamsteed. After the exchanges with Hooke, Newton worked out proof that the elliptical form of planetary orbits would result from a centripetal force inversely proportional to the square of the radius vector. Newton communicated his results to Edmond Halley and to the Royal Society in "De motu corporum in gyrum", a tract written on about nine sheets which was copied into the Royal Society's Register Book in December 1684. This tract contained the nucleus that Newton developed and expanded to form the "Principia".

The "Principia" was published on 5 July 1687 with encouragement and financial help from Edmond Halley. In this work, Newton stated the three universal laws of motion. Together, these laws describe the relationship between any object, the forces acting upon it and the resulting motion, laying the foundation for classical mechanics. They contributed to many advances during the Industrial Revolution which soon followed and were not improved upon for more than 200 years. Many of these advancements continue to be the underpinnings of non-relativistic technologies in the modern world. He used the Latin word "gravitas" (weight) for the effect that would become known as gravity, and defined the law of universal gravitation.

In the same work, Newton presented a calculus-like method of geometrical analysis using 'first and last ratios', gave the first analytical determination (based on Boyle's law) of the speed of sound in air, inferred the oblateness of Earth's spheroidal figure, accounted for the precession of the equinoxes as a result of the Moon's gravitational attraction on the Earth's oblateness, initiated the gravitational study of the irregularities in the motion of the Moon, provided a theory for the determination of the orbits of comets, and much more.

Newton made clear his heliocentric view of the Solar System—developed in a somewhat modern way because already in the mid-1680s he recognised the "deviation of the Sun" from the centre of gravity of the Solar System. For Newton, it was not precisely the centre of the Sun or any other body that could be considered at rest, but rather "the common centre of gravity of the Earth, the Sun and all the Planets is to be esteem'd the Centre of the World", and this centre of gravity "either is at rest or moves uniformly forward in a right line" (Newton adopted the "at rest" alternative in view of common consent that the centre, wherever it was, was at rest).

Newton's postulate of an invisible force able to act over vast distances led to him being criticised for introducing "occult agencies" into science. Later, in the second edition of the "Principia" (1713), Newton firmly rejected such criticisms in a concluding General Scholium, writing that it was enough that the phenomena implied a gravitational attraction, as they did; but they did not so far indicate its cause, and it was both unnecessary and improper to frame hypotheses of things that were not implied by the phenomena. (Here Newton used what became his famous expression ""hypotheses non-fingo"").

With the "Principia", Newton became internationally recognised. He acquired a circle of admirers, including the Swiss-born mathematician Nicolas Fatio de Duillier.

Newton found 72 of the 78 "species" of cubic curves and categorised them into four types. In 1717, and probably with Newton's help, James Stirling proved that every cubic was one of these four types. Newton also claimed that the four types could be obtained by plane projection from one of them, and this was proved in 1731, four years after his death.

In the 1690s, Newton wrote a number of religious tracts dealing with the literal and symbolic interpretation of the Bible. A manuscript Newton sent to John Locke in which he disputed the fidelity of —the Johannine Comma—and its fidelity to the original manuscripts of the New Testament, remained unpublished until 1785.

Newton was also a member of the Parliament of England for Cambridge University in 1689 and 1701, but according to some accounts his only comments were to complain about a cold draught in the chamber and request that the window be closed. He was, however, noted by Cambridge diarist Abraham de la Pryme to have rebuked students who were frightening locals by claiming that a house was haunted.

Newton moved to London to take up the post of warden of the Royal Mint in 1696, a position that he had obtained through the patronage of Charles Montagu, 1st Earl of Halifax, then Chancellor of the Exchequer. He took charge of England's great recoining, trod on the toes of Lord Lucas, Governor of the Tower, and secured the job of deputy comptroller of the temporary Chester branch for Edmond Halley. Newton became perhaps the best-known Master of the Mint upon the death of Thomas Neale in 1699, a position Newton held for the last 30 years of his life. These appointments were intended as sinecures, but Newton took them seriously. He retired from his Cambridge duties in 1701, and exercised his authority to reform the currency and punish clippers and counterfeiters.

As Warden, and afterwards as Master, of the Royal Mint, Newton estimated that 20 percent of the coins taken in during the Great Recoinage of 1696 were counterfeit. Counterfeiting was high treason, punishable by the felon being hanged, drawn and quartered. Despite this, convicting even the most flagrant criminals could be extremely difficult, however, Newton proved equal to the task.

Disguised as a habitué of bars and taverns, he gathered much of that evidence himself. For all the barriers placed to prosecution, and separating the branches of government, English law still had ancient and formidable customs of authority. Newton had himself made a justice of the peace in all the home counties. A draft letter regarding the matter is included in Newton's personal first edition of "Philosophiæ Naturalis Principia Mathematica", which he must have been amending at the time. Then he conducted more than 100 cross-examinations of witnesses, informers, and suspects between June 1698 and Christmas 1699. Newton successfully prosecuted 28 coiners.

Newton was made President of the Royal Society in 1703 and an associate of the French Académie des Sciences. In his position at the Royal Society, Newton made an enemy of John Flamsteed, the Astronomer Royal, by prematurely publishing Flamsteed's "Historia Coelestis Britannica", which Newton had used in his studies.

In April 1705, Queen Anne knighted Newton during a royal visit to Trinity College, Cambridge. The knighthood is likely to have been motivated by political considerations connected with the parliamentary election in May 1705, rather than any recognition of Newton's scientific work or services as Master of the Mint. Newton was the second scientist to be knighted, after Sir Francis Bacon.

As a result of a report written by Newton on 21 September 1717 to the Lords Commissioners of His Majesty's Treasury, the bimetallic relationship between gold coins and silver coins was changed by Royal proclamation on 22 December 1717, forbidding the exchange of gold guineas for more than 21 silver shillings. This inadvertently resulted in a silver shortage as silver coins were used to pay for imports, while exports were paid for in gold, effectively moving Britain from the silver standard to its first gold standard. It is a matter of debate as to whether he intended to do this or not. It has been argued that Newton conceived of his work at the Mint as a continuation of his alchemical work.

Newton was invested in the South Sea Company and lost some £20,000 (US$3 million in 2003) when it collapsed in around 1720.

Toward the end of his life, Newton took up residence at Cranbury Park, near Winchester with his niece and her husband, until his death in 1727. His half-niece, Catherine Barton Conduitt, served as his hostess in social affairs at his house on Jermyn Street in London; he was her "very loving Uncle", according to his letter to her when she was recovering from smallpox.

Newton died in his sleep in London on 20 March 1727 (OS 20 March 1726; NS 31 March 1727). His body was buried in Westminster Abbey. Voltaire may have been present at his funeral. A bachelor, he had divested much of his estate to relatives during his last years, and died intestate. His papers went to John Conduitt and Catherine Barton. After his death, Newton's hair was examined and found to contain mercury, probably resulting from his alchemical pursuits. Mercury poisoning could explain Newton's eccentricity in late life.

Although it was claimed that he was once engaged, Newton never married. The French writer and philosopher Voltaire, who was in London at the time of Newton's funeral, said that he "was never sensible to any passion, was not subject to the common frailties of mankind, nor had any commerce with women—a circumstance which was assured me by the physician and surgeon who attended him in his last moments". The widespread belief that he died a virgin has been commented on by writers such as mathematician Charles Hutton, economist John Maynard Keynes, and physicist Carl Sagan.

Newton had a close friendship with the Swiss mathematician Nicolas Fatio de Duillier, whom he met in London around 1689—some of their correspondence has survived. Their relationship came to an abrupt and unexplained end in 1693, and at the same time Newton suffered a nervous breakdown which included sending wild accusatory letters to his friends Samuel Pepys and John Locke—his note to the latter included the charge that Locke "endeavoured to embroil me with woemen".

The mathematician Joseph-Louis Lagrange said that Newton was the greatest genius who ever lived, and once added that Newton was also "the most fortunate, for we cannot find more than once a system of the world to establish." English poet Alexander Pope wrote the famous epitaph:

Nature and nature's laws lay hid in night;<br>
God said "Let Newton be" and all was light.

Newton was relatively modest about his achievements, writing in a letter to Robert Hooke in February 1676:
If I have seen further it is by standing on the shoulders of giants.

Two writers think that the above quotation, written at a time when Newton and Hooke were in dispute over optical discoveries, was an oblique attack on Hooke (said to have been short and hunchbacked), rather than—or in addition to—a statement of modesty. On the other hand, the widely known proverb about standing on the shoulders of giants, published among others by seventeenth-century poet George Herbert (a former orator of the University of Cambridge and fellow of Trinity College) in his "Jacula Prudentum" (1651), had as its main point that "a dwarf on a giant's shoulders sees farther of the two", and so its effect as an analogy would place Newton himself rather than Hooke as the 'dwarf'.

In a later memoir, Newton wrote:
I do not know what I may appear to the world, but to myself I seem to have been only like a boy playing on the sea-shore, and diverting myself in now and then finding a smoother pebble or a prettier shell than ordinary, whilst the great ocean of truth lay all undiscovered before me.

In 1816, a tooth said to have belonged to Newton was sold for £730 ($3,633) in London to an aristocrat who had it set in a ring. The "Guinness World Records 2002" classified it as the most valuable tooth, which would value approximately £25,000 ($35,700) in late 2001. Who bought it and who currently has it has not been disclosed.

Albert Einstein kept a picture of Newton on his study wall alongside ones of Michael Faraday and James Clerk Maxwell. In a 2005 survey of members of Britain's Royal Society (formerly headed by Newton) asking who had the greater effect on the history of science, Newton or Einstein, the members deemed Newton to have made the greater overall contribution. In 1999, an opinion poll of 100 of the day's leading physicists voted Einstein the "greatest physicist ever," with Newton the runner-up, while a parallel survey of rank-and-file physicists by the site PhysicsWeb gave the top spot to Newton.

Newton's monument (1731) can be seen in Westminster Abbey, at the north of the entrance to the choir against the choir screen, near his tomb. It was executed by the sculptor Michael Rysbrack (1694–1770) in white and grey marble with design by the architect William Kent. The monument features a figure of Newton reclining on top of a sarcophagus, his right elbow resting on several of his great books and his left hand pointing to a scroll with a mathematical design. Above him is a pyramid and a celestial globe showing the signs of the Zodiac and the path of the comet of 1680. A relief panel depicts putti using instruments such as a telescope and prism. The Latin inscription on the base translates as:Here is buried Isaac Newton, Knight, who by a strength of mind almost divine, and mathematical principles peculiarly his own, explored the course and figures of the planets, the paths of comets, the tides of the sea, the dissimilarities in rays of light, and, what no other scholar has previously imagined, the properties of the colours thus produced. Diligent, sagacious and faithful, in his expositions of nature, antiquity and the holy Scriptures, he vindicated by his philosophy the majesty of God mighty and good, and expressed the simplicity of the Gospel in his manners. Mortals rejoice that there has existed such and so great an ornament of the human race! He was born on 25 December 1642, and died on 20 March 1726/7.—Translation from G.L. Smyth, "The Monuments and Genii of St. Paul's Cathedral, and of Westminster Abbey" (1826), ii, 703–704.

From 1978 until 1988, an image of Newton designed by Harry Ecclestone appeared on Series D £1 banknotes issued by the Bank of England (the last £1 notes to be issued by the Bank of England). Newton was shown on the reverse of the notes holding a book and accompanied by a telescope, a prism and a map of the Solar System.

A statue of Isaac Newton, looking at an apple at his feet, can be seen at the Oxford University Museum of Natural History. A large bronze statue, "Newton, after William Blake", by Eduardo Paolozzi, dated 1995 and inspired by Blake's etching, dominates the piazza of the British Library in London.

Although born into an Anglican family, by his thirties Newton held a Christian faith that, had it been made public, would not have been considered orthodox by mainstream Christianity, with one historian labelling him a heretic.

By 1672, he had started to record his theological researches in notebooks which he showed to no one and which have only recently been examined. They demonstrate an extensive knowledge of early Church writings and show that in the conflict between Athanasius and Arius which defined the Creed, he took the side of Arius, the loser, who rejected the conventional view of the Trinity. Newton "recognized Christ as a divine mediator between God and man, who was subordinate to the Father who created him." He was especially interested in prophecy, but for him, "the great apostasy was trinitarianism."

Newton tried unsuccessfully to obtain one of the two fellowships that exempted the holder from the ordination requirement. At the last moment in 1675 he received a dispensation from the government that excused him and all future holders of the Lucasian chair.

In Newton's eyes, worshipping Christ as God was idolatry, to him the fundamental sin. In 1999, historian Stephen D. Snobelen wrote, "Isaac Newton was a heretic. But ... he never made a public declaration of his private faith—which the orthodox would have deemed extremely radical. He hid his faith so well that scholars are still unraveling his personal beliefs." Snobelen concludes that Newton was at least a Socinian sympathiser (he owned and had thoroughly read at least eight Socinian books), possibly an Arian and almost certainly an anti-trinitarian.

In a minority position, T.C. Pfizenmaier offers a more nuanced view, arguing that Newton held closer to the Semi-Arian view of the Trinity that Jesus Christ was of a "similar substance" (homoiousios) from the Father rather than the orthodox view that Jesus Christ is of the "same substance" of the Father (homoousios) as endorsed by modern Eastern Orthodox, Roman Catholics and Protestants. However, this type of view 'has lost support of late with the availability of Newton's theological papers', and now most scholars identify Newton as an Antitrinitarian monotheist.

Although the laws of motion and universal gravitation became Newton's best-known discoveries, he warned against using them to view the Universe as a mere machine, as if akin to a great clock. He said, "So then gravity may put the planets into motion, but without the Divine Power it could never put them into such a circulating motion, as they have about the sun".

Along with his scientific fame, Newton's studies of the Bible and of the early Church Fathers were also noteworthy. Newton wrote works on textual criticism, most notably "An Historical Account of Two Notable Corruptions of Scripture" and "Observations upon the Prophecies of Daniel, and the Apocalypse of St. John". He placed the crucifixion of Jesus Christ at 3 April, AD 33, which agrees with one traditionally accepted date.

He believed in a rationally immanent world, but he rejected the hylozoism implicit in Leibniz and Baruch Spinoza. The ordered and dynamically informed Universe could be understood, and must be understood, by an active reason. In his correspondence, Newton claimed that in writing the "Principia" "I had an eye upon such Principles as might work with considering men for the belief of a Deity". He saw evidence of design in the system of the world: "Such a wonderful uniformity in the planetary system must be allowed the effect of choice". But Newton insisted that divine intervention would eventually be required to reform the system, due to the slow growth of instabilities. For this, Leibniz lampooned him: "God Almighty wants to wind up his watch from time to time: otherwise it would cease to move. He had not, it seems, sufficient foresight to make it a perpetual motion."

Newton's position was vigorously defended by his follower Samuel Clarke in a famous correspondence. A century later, Pierre-Simon Laplace's work "Celestial Mechanics" had a natural explanation for why the planet orbits do not require periodic divine intervention. The contrast between Laplace's mechanistic worldview and Newton's one is the most strident considering the famous answer which the French scientist gave Napoleon, who had criticised him for the absence of the Creator in the "Mécanique céleste": "Sire, j'ai pu me passer de cette hypothese" ("I do not need such a hypothesis").

Scholars long debated whether Newton disputed the doctrine of the Trinity. His first biographer, Sir David Brewster, who compiled his manuscripts, interpreted Newton as questioning the veracity of some passages used to support the Trinity, but never denying the doctrine of the Trinity as such. In the twentieth century, encrypted manuscripts written by Newton and bought by John Maynard Keynes (among others) were deciphered and it became known that Newton did indeed reject Trinitarianism.

Newton and Robert Boyle's approach to the mechanical philosophy was promoted by rationalist pamphleteers as a viable alternative to the pantheists and enthusiasts, and was accepted hesitantly by orthodox preachers as well as dissident preachers like the latitudinarians. The clarity and simplicity of science was seen as a way to combat the emotional and metaphysical superlatives of both superstitious enthusiasm and the threat of atheism, and at the same time, the second wave of English deists used Newton's discoveries to demonstrate the possibility of a "Natural Religion".

The attacks made against pre-Enlightenment "magical thinking", and the mystical elements of Christianity, were given their foundation with Boyle's mechanical conception of the universe. Newton gave Boyle's ideas their completion through mathematical proofs and, perhaps more importantly, was very successful in popularising them.

In a manuscript he wrote in 1704 (never intended to be published), he mentions the date of 2060, but it is not given as a date for the end of days. It has been falsely reported as a prediction. The passage is clear when the date is read in context. He was against date setting for the end of days, concerned that this would put Christianity into disrepute.

"So then the time times & half a time are 42 months or 1260 days or three years & an half, recconing twelve months to a year & 30 days to a month as was done in the Calender of the primitive year. And the days of short lived Beasts being put for the years of [long-]lived kingdoms the period of 1260 days, if dated from the complete conquest of the three kings A.C. 800, will end 2060. It may end later, but I see no reason for its ending sooner."

"This I mention not to assert when the time of the end shall be, but to put a stop to the rash conjectures of fanciful men who are frequently predicting the time of the end, and by doing so bring the sacred prophesies into discredit as often as their predictions fail. Christ comes as a thief in the night, and it is not for us to know the times and seasons which God hath put into his own breast."

In the character of Morton Opperly in "Poor Superman" (1951), speculative fiction author Fritz Leiber says of Newton, "Everyone knows Newton as the great scientist. Few remember that he spent half his life muddling with alchemy, looking for the philosopher's stone. That was the pebble by the seashore he really wanted to find."

Of an estimated ten million words of writing in Newton's papers, about one million deal with alchemy. Many of Newton's writings on alchemy are copies of other manuscripts, with his own annotations. Alchemical texts mix artisanal knowledge with philosophical speculation, often hidden behind layers of wordplay, allegory, and imagery to protect craft secrets. Some of the content contained in Newton's papers could have been considered heretical by the church.

In 1888, after spending sixteen years cataloguing Newton's papers, Cambridge University kept a small number and returned the rest to the Earl of Portsmouth. In 1936, a descendant offered the papers for sale at Sotheby's. The collection was broken up and sold for a total of about £9,000. John Maynard Keynes was one of about three dozen bidders who obtained part of the collection at auction. Keynes went on to reassemble an estimated half of Newton's collection of papers on alchemy before donating his collection to Cambridge University in 1946.

All of Newton's known writings on alchemy are currently being put online in a project undertaken by Indiana University: "The Chymistry of Isaac Newton" and summarised in a book.

Charles Coulston Gillispie disputes that Newton ever practised alchemy, saying that "his chemistry was in the spirit of Boyle's corpuscular philosophy."

In June 2020, two unpublished pages of Newton's notes on Jan Baptist van Helmont's book on plague, "De Peste", were being auctioned online by Bonham's. Newton's analysis of this book, which he made in Cambridge while protecting himself from London's 1665-1666 infection, is the most substantial written statement he is known to have made about the plague, according to Bonham's. As far as the therapy is concerned, Newton writes that "the best is a toad suspended by the legs in a chimney for three days, which at last vomited up earth with various insects in it, on to a dish of yellow wax, and shortly after died. Combining powdered toad with the excretions and serum made into lozenges and worn about the affected area drove away the contagion and drew out the poison".

Enlightenment philosophers chose a short history of scientific predecessors—Galileo, Boyle, and Newton principally—as the guides and guarantors of their applications of the singular concept of nature and natural law to every physical and social field of the day. In this respect, the lessons of history and the social structures built upon it could be discarded.

It was Newton's conception of the universe based upon natural and rationally understandable laws that became one of the seeds for Enlightenment ideology. Locke and Voltaire applied concepts of natural law to political systems advocating intrinsic rights; the physiocrats and Adam Smith applied natural conceptions of psychology and self-interest to economic systems; and sociologists criticised the current social order for trying to fit history into natural models of progress. Monboddo and Samuel Clarke resisted elements of Newton's work, but eventually rationalised it to conform with their strong religious views of nature.

Newton himself often told the story that he was inspired to formulate his theory of gravitation by watching the fall of an apple from a tree. The story is believed to have passed into popular knowledge after being related by Catherine Barton, Newton's niece, to Voltaire. Voltaire then wrote in his "Essay on Epic Poetry" (1727), "Sir Isaac Newton walking in his gardens, had the first thought of his system of gravitation, upon seeing an apple falling from a tree."

Although it has been said that the apple story is a myth and that he did not arrive at his theory of gravity at any single moment, acquaintances of Newton (such as William Stukeley, whose manuscript account of 1752 has been made available by the Royal Society) do in fact confirm the incident, though not the apocryphal version that the apple actually hit Newton's head. Stukeley recorded in his "Memoirs of Sir Isaac Newton's Life" a conversation with Newton in Kensington on 15 April 1726:

John Conduitt, Newton's assistant at the Royal Mint and husband of Newton's niece, also described the event when he wrote about Newton's life:

It is known from his notebooks that Newton was grappling in the late 1660s with the idea that terrestrial gravity extends, in an inverse-square proportion, to the Moon; however, it took him two decades to develop the full-fledged theory. The question was not whether gravity existed, but whether it extended so far from Earth that it could also be the force holding the Moon to its orbit. Newton showed that if the force decreased as the inverse square of the distance, one could indeed calculate the Moon's orbital period, and get good agreement. He guessed the same force was responsible for other orbital motions, and hence named it "universal gravitation".

Various trees are claimed to be "the" apple tree which Newton describes. The King's School, Grantham claims that the tree was purchased by the school, uprooted and transported to the headmaster's garden some years later. The staff of the (now) National Trust-owned Woolsthorpe Manor dispute this, and claim that a tree present in their gardens is the one described by Newton. A descendant of the original tree can be seen growing outside the main gate of Trinity College, Cambridge, below the room Newton lived in when he studied there. The National Fruit Collection at Brogdale in Kent can supply grafts from their tree, which appears identical to Flower of Kent, a coarse-fleshed cooking variety.











</doc>
<doc id="14629" url="https://en.wikipedia.org/wiki?curid=14629" title="Inventor">
Inventor

An inventor is a person who creates or discovers a new method, form, device or other useful means that becomes known as an invention. The word "inventor" comes from the Latin verb "invenire", "invent-", to find. The system of patents was established to encourage inventors by granting limited-term, limited monopoly on inventions determined to be sufficiently novel, non-obvious, and useful. Although inventing is closely associated with science and engineering, inventors are not necessarily engineers nor scientists.


</doc>
<doc id="14631" url="https://en.wikipedia.org/wiki?curid=14631" title="Immanuel Kant">
Immanuel Kant

Immanuel Kant (, ; ; 22 April 1724 – 12 February 1804) was a German philosopher and one of the central Enlightenment thinkers. Kant's comprehensive and systematic works in epistemology, metaphysics, ethics, and aesthetics have made him one of the most influential figures in the history of Western philosophy. 

In his doctrine of transcendental idealism, Kant argued that space and time are mere "forms of intuition" which structure all experience, and therefore that while "things-in-themselves" exist and contribute to experience, they are nonetheless distinct from the objects of experience. From this it follows that the objects of experience are mere "appearances", and that the nature of things as they are in themselves is consequently unknowable to us. In an attempt to counter the skepticism he found in the writings of philosopher David Hume, he wrote the "Critique of Pure Reason" (1781/1787), one of his most well-known works. In it, he developed his theory of experience to answer the question of whether synthetic "a priori" knowledge is possible, which would in turn make it possible to determine the limits of metaphysical inquiry. Kant drew a parallel to the Copernican revolution in his proposal that the objects of the senses must conform to our spatial and temporal forms of intuition, and that we can consequently have "a priori" cognition of the objects of the senses.

Kant believed that reason is also the source of morality, and that aesthetics arise from a faculty of disinterested judgment. Kant's views continue to have a major influence on contemporary philosophy, especially the fields of epistemology, ethics, political theory, and post-modern aesthetics. He attempted to explain the relationship between reason and human experience and to move beyond what he believed to be the failures of traditional philosophy and metaphysics. He wanted to put an end to what he saw as an era of futile and speculative theories of human experience, while resisting the skepticism of thinkers such as Hume. He regarded himself as showing the way past the impasse between rationalists and empiricists, and is widely held to have synthesized both traditions in his thought.

Kant was an exponent of the idea that perpetual peace could be secured through universal democracy and international cooperation, and that perhaps this could be the culminating stage of world history. The nature of Kant's religious ideas continues to be the subject of philosophical dispute, with viewpoints ranging from the impression that he was an initial advocate of atheism who at some point developed an ontological argument for God, to more critical treatments epitomized by Schopenhauer, who criticized the imperative form of Kantian ethics as "theological morals" and the "Mosaic Decalogue in disguise", and Nietzsche, who claimed that Kant had "theologian blood" and was merely a sophisticated apologist for traditional Christian faith. Beyond his religious views, Kant has also been criticized for the racism presented in some of his lesser-known works, such as "Anthropology from a Pragmatic Point of View" and "On the Different Races of Man". Robert Bernasconi has suggested that Kant "supplied the first scientific definition of race."

Kant published other important works on ethics, religion, law, aesthetics, astronomy, and history. These include the "Universal Natural History" (1755), the "Critique of Practical Reason" (1788), the "Metaphysics of Morals" (1797), the "Critique of Judgment" (1790), which looks at aesthetics and teleology, and "Religion within the Bounds of Bare Reason" (1793).

Kant's mother, Anna Regina Reuter (1697–1737), was born in Königsberg (since 1946 the city of Kaliningrad, Kaliningrad Oblast, Russia) to a father from Nuremberg. Her surname is sometimes erroneously given as Porter. Kant's father, Johann Georg Kant (1682–1746), was a German harness maker from Memel, at the time Prussia's most northeastern city (now Klaipėda, Lithuania). Kant believed that his paternal grandfather Hans Kant was of Scottish origin. While scholars of Kant's life long accepted the claim, there is no evidence that Kant's paternal line was Scottish and it is more likely that the Kants got their name from the village of Kantwaggen (today part of Priekulė) and were of Curonian origin. Kant was the fourth of nine children (four of whom reached adulthood).

Kant was born on 22 April 1724 into a Prussian German family of Lutheran Protestant faith in Königsberg, East Prussia. Baptized Emanuel, he later changed his name to Immanuel after learning Hebrew. He was brought up in a Pietist household that stressed religious devotion, humility, and a literal interpretation of the Bible. His education was strict, punitive and disciplinary, and focused on Latin and religious instruction over mathematics and science. Kant maintained Christian ideals for some time, but struggled to reconcile the faith with his belief in science. In his "Groundwork of the Metaphysic of Morals", he reveals a belief in immortality as the necessary condition of humanity's approach to the highest morality possible. However, as Kant was skeptical about some of the arguments used prior to him in defence of theism and maintained that human understanding is limited and can never attain knowledge about God or the soul, various commentators have labelled him a philosophical agnostic.

Common myths about Kant's personal mannerisms are listed, explained, and refuted in Goldthwait's introduction to his translation of "Observations on the Feeling of the Beautiful and Sublime". It is often held that Kant lived a very strict and disciplined life, leading to an oft-repeated story that neighbors would set their clocks by his daily walks. He never married, but seemed to have a rewarding social life — he was a popular teacher and a modestly successful author even before starting on his major philosophical works. He had a circle of friends with whom he frequently met, among them Joseph Green, an English merchant in Königsberg.

A common myth is that Kant never traveled more than from Königsberg his whole life. In fact, between 1750 and 1754 he worked as a tutor ("Hauslehrer") in Judtschen (now Veselovka, Russia, approximately 20 km) and in Groß-Arnsdorf (now Jarnołtowo near Morąg (German: Mohrungen), Poland, approximately 145 km).

Kant showed a great aptitude for study at an early age. He first attended the Collegium Fridericianum from which he graduated at the end of the summer of 1740. In 1740, aged 16, he enrolled at the University of Königsberg, where he spent his whole career. He studied the philosophy of Gottfried Leibniz and Christian Wolff under Martin Knutzen (Associate Professor of Logic and Metaphysics from 1734 until his death in 1751), a rationalist who was also familiar with developments in British philosophy and science and introduced Kant to the new mathematical physics of Isaac Newton. Knutzen dissuaded Kant from the theory of pre-established harmony, which he regarded as "the pillow for the lazy mind". He also dissuaded Kant from idealism, the idea that reality is purely mental, which most philosophers in the 18th century regarded in a negative light. The theory of transcendental idealism that Kant later included in the "Critique of Pure Reason" was developed partially in opposition to traditional idealism.

His father's stroke and subsequent death in 1746 interrupted his studies. Kant left Königsberg shortly after August 1748—he would return there in August 1754. He became a private tutor in the towns surrounding Königsberg, but continued his scholarly research. In 1749, he published his first philosophical work, "Thoughts on the True Estimation of Living Forces" (written in 1745–47).

Kant is best known for his work in the philosophy of ethics and metaphysics, but he made significant contributions to other disciplines. In 1754, while contemplating on a prize question by the Berlin Academy about the problem of Earth's rotation, he argued that the Moon's gravity would slow down Earth's spin and he also put forth the argument that gravity would eventually cause the Moon's tidal locking to coincide with the Earth's rotation. The next year, he expanded this reasoning to the formation and evolution of the Solar System in his "Universal Natural History and Theory of the Heavens". In 1755, Kant received a license to lecture in the University of Königsberg and began lecturing on a variety of topics including mathematics, physics, logic and metaphysics. In his 1756 essay on the theory of winds, Kant laid out an original insight into the coriolis force. In 1757, Kant began lecturing on geography being one of the first people to explicitly teach geography as its own subject. Geography was one of Kant's most popular lecturing topics and in 1802 a compilation by Friedrich Theodor Rink of Kant's lecturing notes, "Physical Geography", was released. After Kant became a professor in 1770, he expanded the topics of his lectures to include lectures on natural law, ethics and anthropology along with other topics.
In the "Universal Natural History", Kant laid out the Nebular hypothesis, in which he deduced that the Solar System had formed from a large cloud of gas, a nebula. Kant also correctly deduced (though through usually false premises and fallacious reasoning, according to Bertrand Russell) that the Milky Way was a large disk of stars, which he theorized formed from a much larger spinning gas cloud. He further suggested that other distant "nebulae" might be other galaxies. These postulations opened new horizons for astronomy, for the first time extending it beyond the Solar System to galactic and intergalactic realms. According to Thomas Huxley (1867), Kant also made contributions to geology in his "Universal Natural History".

From then on, Kant turned increasingly to philosophical issues, although he continued to write on the sciences throughout his life. In the early 1760s, Kant produced a series of important works in philosophy. "The False Subtlety of the Four Syllogistic Figures", a work in logic, was published in 1762. Two more works appeared the following year: "Attempt to Introduce the Concept of Negative Magnitudes into Philosophy" and "The Only Possible Argument in Support of a Demonstration of the Existence of God". By 1764, Kant had become a notable popular author, and wrote "Observations on the Feeling of the Beautiful and Sublime"; he was second to Moses Mendelssohn in a Berlin Academy prize competition with his "Inquiry Concerning the Distinctness of the Principles of Natural Theology and Morality" (often referred to as "The Prize Essay"). In 1766 Kant wrote "Dreams of a Spirit-Seer" which dealt with the writings of Emanuel Swedenborg. The exact influence of Swedenborg on Kant, as well as the extent of Kant's belief in mysticism according to "Dreams of a Spirit-Seer", remain controversial. On 31 March 1770, aged 45, Kant was finally appointed Full Professor of Logic and Metaphysics ("Professor Ordinarius der Logic und Metaphysic") at the University of Königsberg. In defense of this appointment, Kant wrote his inaugural dissertation ("Inaugural-Dissertation") "De Mundi Sensibilis atque Intelligibilis Forma et Principiis" ("On the Form and Principles of the Sensible and the Intelligible World)". This work saw the emergence of several central themes of his mature work, including the distinction between the faculties of intellectual thought and sensible receptivity. To miss this distinction would mean to commit the error of subreption, and, as he says in the last chapter of the dissertation, only in avoiding this error does metaphysics flourish.

The issue that vexed Kant was central to what 20th-century scholars called "the philosophy of mind". The flowering of the natural sciences had led to an understanding of how data reaches the brain. Sunlight falling on an object is reflected from its surface in a way that maps the surface features (color, texture, etc.). The reflected light reaches the human eye, passes through the cornea, is focused by the lens onto the retina where it forms an image similar to that formed by light passing through a pinhole into a camera obscura. The retinal cells send impulses through the optic nerve and then they form a mapping in the brain of the visual features of the object. The interior mapping is not the exterior object, and our belief that there is a meaningful relationship between the object and the mapping in the brain depends on a chain of reasoning that is not fully grounded. But the uncertainty aroused by these considerations, by optical illusions, misperceptions, delusions, etc., are not the end of the problems.

Kant saw that the mind could not function as an empty container that simply receives data from outside. Something must be giving order to the incoming data. Images of external objects must be kept in the same sequence in which they were received. This ordering occurs through the mind's intuition of time. The same considerations apply to the mind's function of constituting space for ordering mappings of visual and tactile signals arriving via the already described chains of physical causation.

It is often claimed that Kant was a late developer, that he only became an important philosopher in his mid-50s after rejecting his earlier views. While it is true that Kant wrote his greatest works relatively late in life, there is a tendency to underestimate the value of his earlier works. Recent Kant scholarship has devoted more attention to these "pre-critical" writings and has recognized a degree of continuity with his mature work.

At age 46, Kant was an established scholar and an increasingly influential philosopher, and much was expected of him. In correspondence with his ex-student and friend Markus Herz, Kant admitted that, in the inaugural dissertation, he had failed to account for the relation between our sensible and intellectual faculties. He needed to explain how we combine what is known as sensory knowledge with the other type of knowledgei.e. reasoned knowledgethese two being related but having very different processes.
Kant also credited David Hume with awakening him from a "dogmatic slumber" in which he had unquestioningly accepted the tenets of both religion and natural philosophy. Hume in his 1739 "Treatise on Human Nature" had argued that we only know the mind through a subjectiveessentially illusoryseries of perceptions. Ideas such as causality, morality, and objects are not evident in experience, so their reality may be questioned. Kant felt that reason could remove this skepticism, and he set himself to solving these problems. Although fond of company and conversation with others, Kant isolated himself, and resisted friends' attempts to bring him out of his isolation. When Kant emerged from his silence in 1781, the result was the "Critique of Pure Reason". Kant countered Hume's empiricism by claiming that some knowledge exists inherently in the mind, independent of experience. He drew a parallel to the Copernican revolution in his proposal that worldly objects can be intuited "a priori" ('beforehand'), and that intuition is consequently distinct from objective reality. He acquiesced to Hume somewhat by defining causality as a "regular, constant sequence of events in time, and nothing more."

Although now uniformly recognized as one of the greatest works in the history of philosophy, this "Critique" was largely ignored upon its initial publication. The book was long, over 800 pages in the original German edition, and written in a convoluted style. It received few reviews, and these granted it no significance. Kant's former student, Johann Gottfried Herder criticized it for placing reason as an entity worthy of criticism instead of considering the process of reasoning within the context of language and one's entire personality. Similar to Christian Garve and Johann Georg Heinrich Feder, he rejected Kant's position that space and time possessed a form that could be analyzed. Additionally, Garve and Feder also faulted Kant's Critique for not explaining differences in perception of sensations. Its density made it, as Herder said in a letter to Johann Georg Hamann, a "tough nut to crack", obscured by "all this heavy gossamer". Its reception stood in stark contrast to the praise Kant had received for earlier works, such as his "Prize Essay" and shorter works that preceded the first Critique. These well-received and readable tracts include one on the earthquake in Lisbon that was so popular that it was sold by the page. Prior to the change in course documented in the first Critique, his books had sold well. Kant was disappointed with the first Critique's reception. Recognizing the need to clarify the original treatise, Kant wrote the "Prolegomena to any Future Metaphysics" in 1783 as a summary of its main views. Shortly thereafter, Kant's friend Johann Friedrich Schultz (1739–1805) (professor of mathematics) published "Erläuterungen über des Herrn Professor Kant Critik der reinen Vernunft" (Königsberg, 1784), which was a brief but very accurate commentary on Kant's "Critique of Pure Reason".

Kant's reputation gradually rose through the latter portion of the 1780s, sparked by a series of important works: the 1784 essay, "Answer to the Question: What is Enlightenment?"; 1785's "Groundwork of the Metaphysics of Morals" (his first work on moral philosophy); and, from 1786, "Metaphysical Foundations of Natural Science." But Kant's fame ultimately arrived from an unexpected source. In 1786, Karl Leonhard Reinhold published a series of public letters on Kantian philosophy. In these letters, Reinhold framed Kant's philosophy as a response to the central intellectual controversy of the era: the Pantheism Dispute. Friedrich Jacobi had accused the recently deceased Gotthold Ephraim Lessing (a distinguished dramatist and philosophical essayist) of Spinozism. Such a charge, tantamount to atheism, was vigorously denied by Lessing's friend Moses Mendelssohn, leading to a bitter public dispute among partisans. The controversy gradually escalated into a debate about the values of the Enlightenment and the value of reason.

Reinhold maintained in his letters that Kant's "Critique of Pure Reason" could settle this dispute by defending the authority and bounds of reason. Reinhold's letters were widely read and made Kant the most famous philosopher of his era.

Kant published a second edition of the "Critique of Pure Reason" in 1787, heavily revising the first parts of the book. Most of his subsequent work focused on other areas of philosophy. He continued to develop his moral philosophy, notably in 1788's "Critique of Practical Reason" (known as the second "Critique") and 1797's "Metaphysics of Morals". The 1790 "Critique of Judgment" (the third "Critique") applied the Kantian system to aesthetics and teleology. It was in this critique where Kant wrote one of his most popular statements: "it is absurd to hope that another Newton will arise in the future who will make comprehensible to us the production of a blade of grass according to natural laws".

In 1792, Kant's attempt to publish the Second of the four Pieces of "Religion within the Bounds of Bare Reason", in the journal "Berlinische Monatsschrift", met with opposition from the King's censorship commission, which had been established that same year in the context of the French Revolution. Kant then arranged to have all four pieces published as a book, routing it through the philosophy department at the University of Jena to avoid the need for theological censorship. This insubordination earned him a now famous reprimand from the King. When he nevertheless published a second edition in 1794, the censor was so irate that he arranged for a royal order that required Kant never to publish or even speak publicly about religion. Kant then published his response to the King's reprimand and explained himself, in the preface of "The Conflict of the Faculties".
He also wrote a number of semi-popular essays on history, religion, politics and other topics. These works were well received by Kant's contemporaries and confirmed his preeminent status in 18th-century philosophy. There were several journals devoted solely to defending and criticizing Kantian philosophy. Despite his success, philosophical trends were moving in another direction. Many of Kant's most important disciples and followers (including Reinhold, Beck and Fichte) transformed the Kantian position into increasingly radical forms of idealism. The progressive stages of revision of Kant's teachings marked the emergence of German Idealism. Kant opposed these developments and publicly denounced Fichte in an open letter in 1799. It was one of his final acts expounding a stance on philosophical questions. In 1800, a student of Kant named Gottlob Benjamin Jäsche (1762–1842) published a manual of logic for teachers called "Logik", which he had prepared at Kant's request. Jäsche prepared the "Logik" using a copy of a textbook in logic by Georg Friedrich Meier entitled "Auszug aus der Vernunftlehre", in which Kant had written copious notes and annotations. The "Logik" has been considered of fundamental importance to Kant's philosophy, and the understanding of it. The great 19th-century logician Charles Sanders Peirce remarked, in an incomplete review of Thomas Kingsmill Abbott's English translation of the introduction to "Logik", that "Kant's whole philosophy turns upon his logic." Also, Robert Schirokauer Hartman and Wolfgang Schwarz, wrote in the translators' introduction to their English translation of the "Logik", "Its importance lies not only in its significance for the "Critique of Pure Reason", the second part of which is a restatement of fundamental tenets of the "Logic", but in its position within the whole of Kant's work."

Kant's health, long poor, worsened and he died at Königsberg on 12 February 1804, uttering ""Es ist gut" (It is good)" before expiring. His unfinished final work was published as "Opus Postumum". Kant always cut a curious figure in his lifetime for his modest, rigorously scheduled habits, which have been referred to as clocklike. However, Heinrich Heine noted the magnitude of "his destructive, world-crushing thoughts" and considered him a sort of philosophical "executioner", comparing him to Robespierre with the observation that both men "represented in the highest the type of provincial bourgeois. Nature had destined them to weigh coffee and sugar, but Fate determined that they should weigh other things and placed on the scales of the one a king, on the scales of the other a god."

When his body was transferred to a new burial spot, his skull was measured during the exhumation and found to be larger than the average German male's with a "high and broad" forehead. His forehead has been an object of interest ever since it became well-known through his portraits: "In Döbler's portrait and in Kiefer's faithful if expressionistic reproduction of it — as well as in many of the other late eighteenth- and early nineteenth-century portraits of Kant — the forehead is remarkably large and decidedly retreating. Was Kant's forehead shaped this way in these images because he was a philosopher, or, to follow the implications of Lavater's system, was he a philosopher because of the intellectual acuity manifested by his forehead? Kant and Johann Kaspar Lavater were correspondents on theological matters, and Lavater refers to Kant in his work "Physiognomic Fragments, for the Education of Human Knowledge and Love of People" (Leipzig & Winterthur, 1775–1778).
Kant's mausoleum adjoins the northeast corner of Königsberg Cathedral in Kaliningrad, Russia. The mausoleum was constructed by the architect Friedrich Lahrs and was finished in 1924 in time for the bicentenary of Kant's birth. Originally, Kant was buried inside the cathedral, but in 1880 his remains were moved to a neo-Gothic chapel adjoining the northeast corner of the cathedral. Over the years, the chapel became dilapidated and was demolished to make way for the mausoleum, which was built on the same location.

The tomb and its mausoleum are among the few artifacts of German times preserved by the Soviets after they conquered and annexed the city. Today, many newlyweds bring flowers to the mausoleum. Artifacts previously owned by Kant, known as "Kantiana", were included in the Königsberg City Museum. However, the museum was destroyed during World War II. A replica of the statue of Kant that stood in German times in front of the main University of Königsberg building was donated by a German entity in the early 1990s and placed in the same grounds.

After the expulsion of Königsberg's German population at the end of World War II, the University of Königsberg where Kant taught was replaced by the Russian-language Kaliningrad State University, which appropriated the campus and surviving buildings. In 2005, the university was renamed Immanuel Kant State University of Russia. The name change was announced at a ceremony attended by President Vladimir Putin of Russia and Chancellor Gerhard Schröder of Germany, and the university formed a Kant Society, dedicated to the study of Kantianism.

In late November 2018, his tomb and statue were vandalized with paint by unknown assailants, who also scattered leaflets glorifying Rus' and denouncing Kant as a "traitor". The incident is apparently connected with a recent vote to rename Khrabrovo Airport, where Kant was in the lead for a while, prompting Russian nationalist resentment.

In Kant's essay "Answering the Question: What is Enlightenment?", he defined the Enlightenment as an age shaped by the Latin motto "Sapere aude" ("Dare to be wise"). Kant maintained that one ought to think autonomously, free of the dictates of external authority. His work reconciled many of the differences between the rationalist and empiricist traditions of the 18th century. He had a decisive impact on the Romantic and German Idealist philosophies of the 19th century. His work has also been a starting point for many 20th century philosophers.

Kant asserted that, because of the limitations of argumentation in the absence of irrefutable evidence, no one could really know whether there is a God and an afterlife or not. For the sake of morality and as a ground for reason, Kant asserted, people are justified in believing in God, even though they could never know God's presence empirically.

The sense of an enlightened approach and the critical method required that "If one cannot prove that a thing "is," he may try to prove that it is "not." If he fails to do either (as often occurs), he may still ask whether it is in his "interest" to "accept" one or the other of the alternatives hypothetically, from the theoretical or the practical point of view. Hence the question no longer is as to whether perpetual peace is a real thing or not a real thing, or as to whether we may not be deceiving ourselves when we adopt the former alternative, but we must "act" on the supposition of its being real." The presupposition of God, soul, and freedom was then a practical concern, for
Kant drew a parallel between the Copernican revolution and the epistemology of his new transcendental philosophy, involving two interconnected foundations of his "critical philosophy": 

These teachings placed the active, rational human subject at the center of the cognitive and moral worlds. Kant argued that the rational order of the world as known by science was not just the accidental accumulation of sense perceptions.

Conceptual unification and integration is carried out by the mind through concepts or the "categories of the understanding" operating on the perceptual manifold within space and time. The latter are not concepts, but are forms of sensibility that are "a priori" necessary conditions for any possible experience. Thus the objective order of nature and the causal necessity that operates within it depend on the mind's processes, the product of the rule-based activity that Kant called, "synthesis." There is much discussion among Kant scholars about the correct interpretation of this train of thought.

The 'two-world' interpretation regards Kant's position as a statement of epistemological limitation, that we are not able to transcend the bounds of our own mind, meaning that we cannot access the "thing-in-itself". However, Kant also speaks of the thing in itself or "transcendental object" as a product of the (human) understanding as it attempts to conceive of objects in abstraction from the conditions of sensibility. Following this line of thought, some interpreters have argued that the thing in itself does not represent a separate ontological domain but simply a way of considering objects by means of the understanding alonethis is known as the two-aspect view.

The notion of the "thing in itself" was much discussed by philosophers after Kant. It was argued that because the "thing in itself" was unknowable, its existence must not be assumed. Rather than arbitrarily switching to an account that was ungrounded in anything supposed to be the "real," as did the German Idealists, another group arose to ask how our (presumably reliable) accounts of a coherent and rule-abiding universe were actually grounded. This new kind of philosophy became known as Phenomenology, and its founder was Edmund Husserl.

With regard to morality, Kant argued that the source of the good lies not in anything outside the human subject, either in nature or given by God, but rather is only the good will itself. A good will is one that acts from duty in accordance with the universal moral law that the autonomous human being freely gives itself. This law obliges one to treat humanityunderstood as rational agency, and represented through oneself as well as othersas an end in itself rather than (merely) as means to other ends the individual might hold. This necessitates practical self-reflection in which we universalize our reasons.

These ideas have largely framed or influenced all subsequent philosophical discussion and analysis. The specifics of Kant's account generated immediate and lasting controversy. Nevertheless, his thesesthat the mind itself necessarily makes a constitutive contribution to its knowledge, that this contribution is transcendental rather than psychological, that philosophy involves self-critical activity, that morality is rooted in human freedom, and that to act autonomously is to act according to rational moral principleshave all had a lasting effect on subsequent philosophy.

Kant defines his theory of perception in his influential 1781 work the "Critique of Pure Reason", which has often been cited as the most significant volume of metaphysics and epistemology in modern philosophy. Kant maintains that our understanding of the external world had its foundations not merely in experience, but in both experience and "a priori" concepts, thus offering a "non-empiricist critique of rationalist philosophy", which is what has been referred to as his Copernican revolution.

Firstly, Kant distinguishes between analytic and synthetic propositions:


An analytic proposition is true by nature of the meaning of the words in the sentence — we require no further knowledge than a grasp of the language to understand this proposition. On the other hand, a synthetic statement is one that tells us something about the world. The truth or falsehood of synthetic statements derives from something outside their linguistic content. In this instance, weight is not a necessary predicate of the body; until we are told the heaviness of the body we do not know that it has weight. In this case, experience of the body is required before its heaviness becomes clear. Before Kant's first Critique, empiricists (cf. Hume) and rationalists (cf. Leibniz) assumed that all synthetic statements required experience to be known.

Kant contests this assumption by claiming that elementary mathematics, like arithmetic, is synthetic "a priori", in that its statements provide new knowledge not derived from experience. This becomes part of his over-all argument for transcendental idealism. That is, he argues that the possibility of experience depends on certain necessary conditions — which he calls "a priori" forms — and that these conditions structure and hold true of the world of experience. His main claims in the "Transcendental Aesthetic" are that mathematic judgments are synthetic "a priori" and that space and time are not derived from experience but rather are its preconditions.

Once we have grasped the functions of basic arithmetic, we do not need empirical experience to know that 100 + 100 = 200, and so it appears that arithmetic is analytic. However, that it is analytic can be disproved by considering the calculation 5 + 7 = 12: there is nothing in the numbers 5 and 7 by which the number 12 can be inferred. Thus "5 + 7" and "the cube root of 1,728" or "12" are not analytic because their reference is the same but their sense is not — the statement "5 + 7 = 12" tells us something new about the world. It is self-evident, and undeniably "a priori", but at the same time it is synthetic. Thus Kant argued that a proposition can be synthetic and "a priori".

Kant asserts that experience is based on the perception of external objects and "a priori" knowledge. The external world, he writes, provides those things that we sense. But our mind processes this information and gives it order, allowing us to comprehend it. Our mind supplies the conditions of space and time to experience objects. According to the "transcendental unity of apperception", the concepts of the mind (Understanding) and perceptions or intuitions that garner information from phenomena (Sensibility) are synthesized by comprehension. Without concepts, perceptions are nondescript; without perceptions, concepts are meaningless. Thus the famous statement: "Thoughts without content are empty, intuitions [perceptions] without concepts are blind."

Kant also claims that an external environment is necessary for the establishment of the self. Although Kant would want to argue that there is no empirical way of observing the self, we can see the logical necessity of the self when we observe that we can have different perceptions of the external environment over time. By uniting these general representations into one global representation, we can see how a transcendental self emerges. "I am therefore conscious of the identical self in regard to the manifold of the representations that are given to me in an intuition because I call them all together my representations, which constitute one."

Kant deemed it obvious that we have some objective knowledge of the world, such as, say, Newtonian physics. But this knowledge relies on synthetic, "a priori" laws of nature, like causality and substance. How is this possible? Kant's solution was that the subject must supply laws that make experience of objects possible, and that these laws are synthetic, "a priori" laws of nature that apply to all objects before we experience them. To deduce all these laws, Kant examined experience in general, dissecting in it what is supplied by the mind from what is supplied by the given intuitions. This is commonly called a transcendental deduction.

To begin with, Kant's distinction between the "a posteriori" being contingent and particular knowledge, and the "a priori" being universal and necessary knowledge, must be kept in mind. If we merely connect two intuitions together in a perceiving subject, the knowledge is always subjective because it is derived "a posteriori," when what is desired is for the knowledge to be objective, that is, for the two intuitions to refer to the object and hold good of it for anyone at any time, not just the perceiving subject in its current condition. What else is equivalent to objective knowledge besides the "a priori" (universal and necessary knowledge)? Before knowledge can be objective, it must be incorporated under an "a priori" category of "understanding".

For example, if a subject says, "The sun shines on the stone; the stone grows warm," all he perceives are phenomena. His judgment is contingent and holds no necessity. But if he says, "The sunshine causes the stone to warm," he subsumes the perception under the category of causality, which is not found in the perception, and necessarily synthesizes the concept sunshine with the concept heat, producing a necessarily universally true judgment.

To explain the categories in more detail, they are the preconditions of the construction of objects in the mind. Indeed, to even think of the sun and stone presupposes the category of subsistence, that is, substance. For the categories synthesize the random data of the sensory manifold into intelligible objects. This means that the categories are also the most abstract things one can say of any object whatsoever, and hence one can have an "a priori" cognition of the totality of all objects of experience if one can list all of them. To do so, Kant formulates another transcendental deduction.

Judgments are, for Kant, the preconditions of any thought. Man thinks via judgments, so all possible judgments must be listed and the perceptions connected within them put aside, so as to make it possible to examine the moments when "the understanding" is engaged in constructing judgments. For the categories are equivalent to these moments, in that they are concepts of intuitions in general, so far as they are determined by these moments universally and necessarily. Thus by listing all the moments, one can deduce from them all of the categories.

One may now ask: How many possible judgments are there? Kant believed that all the possible propositions within Aristotle's syllogistic logic are equivalent to all possible judgments, and that all the logical operators within the propositions are equivalent to the moments of the understanding within judgments. Thus he listed Aristotle's system in four groups of three: quantity (universal, particular, singular), quality (affirmative, negative, infinite), relation (categorical, hypothetical, disjunctive) and modality (problematic, assertoric, apodeictic). The parallelism with Kant's categories is obvious: quantity (unity, plurality, totality), quality (reality, negation, limitation), relation (substance, cause, community) and modality (possibility, existence, necessity).

The fundamental building blocks of experience, i.e. objective knowledge, are now in place. First there is the sensibility, which supplies the mind with intuitions, and then there is the understanding, which produces judgments of these intuitions and can subsume them under categories. These categories lift the intuitions up out of the subject's current state of consciousness and place them within consciousness in general, producing universally necessary knowledge. For the categories are innate in any rational being, so any intuition thought within a category in one mind is necessarily subsumed and understood identically in any mind. In other words, we filter what we see and hear.

Kant ran into a problem with his theory that the mind plays a part in producing objective knowledge. Intuitions and categories are entirely disparate, so how can they interact? Kant's solution is the (transcendental) schema: a priori principles by which the transcendental imagination connects concepts with intuitions through time. All the principles are temporally bound, for if a concept is purely a priori, as the categories are, then they must apply for all times. Hence there are principles such as "substance is that which endures through time", and "the cause must always be prior to the effect".. In the context of transcendental schema the concept of transcendental reflection is of a great importance.

Kant developed his moral philosophy in three works: "Groundwork of the Metaphysic of Morals" (1785), "Critique of Practical Reason" (1788), and "Metaphysics of Morals" (1797).

In "Groundwork", Kant' tries to convert our everyday, obvious, rational knowledge of morality into philosophical knowledge. The latter two works used "practical reason", which is based only on things about which reason can tell us, and not deriving any principles from experience, to reach conclusions which can be applied to the world of experience (in the second part of "The Metaphysics of Morals").

Kant is known for his theory that there is a single moral obligation, which he called the "Categorical Imperative", and is derived from the concept of duty. Kant defines the demands of moral law as "categorical imperatives". Categorical imperatives are principles that are intrinsically valid; they are good in and of themselves; they must be obeyed in all situations and circumstances, if our behavior is to observe the moral law. The Categorical Imperative provides a test against which moral statements can be assessed. Kant also stated that the moral means and ends can be applied to the categorical imperative, that rational beings can pursue certain "ends" using the appropriate "means". Ends based on physical needs or wants create hypothetical imperatives. The categorical imperative can only be based on something that is an "end in itself", that is, an end that is not a means to some other need, desire, or purpose. Kant believed that the moral law is a principle of reason itself, and is not based on contingent facts about the world, such as what would make us happy, but to act on the moral law which has no other motive than "worthiness to be happy". Accordingly, he believed that moral obligation applies only to rational agents.

Unlike a hypothetical imperative, a categorical imperative is an unconditional obligation; it has the force of an obligation regardless of our will or desires In "Groundwork of the Metaphysic of Morals" (1785) Kant enumerated three formulations of the categorical imperative that he believed to be roughly equivalent. In the same book, Kant stated:

According to Kant, one cannot make exceptions for oneself. The philosophical maxim on which one acts should always be considered to be a universal law without exception. One cannot allow oneself to do a particular action unless one thinks it appropriate that the reason for the action should become a universal law. For example, one should not steal, however dire the circumstancesbecause, by permitting oneself to steal, one makes stealing a universally acceptable act. This is the first formulation of the categorical imperative, often known as the universalizability principle.

Kant believed that, if an action is not done with the motive of duty, then it is without moral value. He thought that every action should have pure intention behind it; otherwise, it is meaningless. The final result is not the most important aspect of an action; rather, how the person feels while carrying out the action is the time when value is attached to the result.

In "Groundwork of the Metaphysic of Morals", Kant also posited the "counter-utilitarian idea that there is a difference between preferences and values, and that considerations of individual rights temper calculations of aggregate utility", a concept that is an axiom in economics:

Everything has either a "price" or a "dignity". Whatever has a price can be replaced by something else as its equivalent; on the other hand, whatever is above all price, and therefore admits of no equivalent, has a dignity. But that which constitutes the condition under which alone something can be an end in itself does not have mere relative worth, i.e., price, but an intrinsic worth, i.e., a dignity. (p. 53, italics in original).

A phrase quoted by Kant, which is used to summarize the counter-utilitarian nature of his moral philosophy, is "Fiat justitia, pereat mundus", ("Let justice be done, though the world perish"), which he translates loosely as "Let justice reign even if all the rascals in the world should perish from it". This appears in his 1795 "" (""""), Appendix 1.

The first formulation (Formula of Universal Law) of the moral imperative "requires that the maxims be chosen as though they should hold as universal laws of nature". This formulation in principle has as its supreme law the creed "Always act according to that maxim whose universality as a law you can at the same time will" and is the "only condition under which a will can never come into conflict with itself [...]"

One interpretation of the first formulation is called the "universalizability test". An agent's maxim, according to Kant, is his "subjective principle of human actions": that is, what the agent believes is his reason to act. The universalisability test has five steps:


The second formulation (or Formula of the End in Itself) holds that "the rational being, as by its nature an end and thus as an end in itself, must serve in every maxim as the condition restricting all merely relative and arbitrary ends". The principle dictates that you "[a]ct with reference to every rational being (whether yourself or another) so that it is an end in itself in your maxim", meaning that the rational being is "the basis of all maxims of action" and "must be treated never as a mere means but as the supreme limiting condition in the use of all means, i.e., as an end at the same time".

The third formulation (i.e. Formula of Autonomy) is a synthesis of the first two and is the basis for the "complete determination of all maxims". It states "that all maxims which stem from autonomous legislation ought to harmonize with a possible realm of ends as with a realm of nature".

In principle, "So act as if your maxims should serve at the same time as the universal law (of all rational beings)", meaning that we should so act that we may think of ourselves as "a member in the universal realm of ends", legislating universal laws through our maxims (that is, a universal code of conduct), in a "possible realm of ends". No one may elevate themselves above the universal law, therefore it is one's duty to follow the maxim(s).

Commentators, starting in the 20th century, have tended to see Kant as having a strained relationship with religion, though this was not the prevalent view in the 19th century. Karl Leonhard Reinhold, whose letters first made Kant famous, wrote "I believe that I may infer without reservation that the interest of religion, and of Christianity in particular, accords completely with the result of the Critique of Reason.". Johann Schultz, who wrote one of the first Kant commentaries, wrote "And does not this system itself cohere most splendidly with the Christian religion? Do not the divinity and beneficence of the latter become all the more evident?" This view continued throughout the 19th century, as noted by Friedrich Nietzsche, who said "Kant's success is merely a theologian's success." The reason for these views was Kant's moral theology, and the widespread belief that his philosophy was the great antithesis to Spinozism, which had been convulsing the European academy for much of the 18th century. Spinozism was widely seen as the cause of the Pantheism controversy, and as a form of sophisticated pantheism or even atheism. As Kant's philosophy disregarded the possibility of arguing for God through pure reason alone, for the same reasons it also disregarded the possibility of arguing against God through pure reason alone. This, coupled with his moral philosophy (his argument that the existence of morality is a rational reason why God and an afterlife do and must exist), was the reason he was seen by many, at least through the end of the 19th century, as a great defender of religion in general and Christianity in particular.

Kant articulates his strongest criticisms of the organization and practices of religious organizations to those that encourage what he sees as a religion of counterfeit service to God. Among the major targets of his criticism are external ritual, superstition and a hierarchical church order. He sees these as efforts to make oneself pleasing to God in ways other than conscientious adherence to the principle of moral rightness in choosing and acting upon one's maxims. Kant's criticisms on these matters, along with his rejection of certain theoretical proofs grounded in pure reason (particularly the ontological argument) for the existence of God and his philosophical commentary on some Christian doctrines, have resulted in interpretations that see Kant as hostile to religion in general and Christianity in particular (e.g., Walsh 1967). Nevertheless, other interpreters consider that Kant was trying to mark off defensible from indefensible Christian belief. Kant sees in Jesus Christ the affirmation of a "pure moral disposition of the heart" that "can make man well-pleasing to God". Regarding Kant's conception of religion, some critics have argued that he was sympathetic to deism. Other critics have argued that Kant's moral conception moves from deism to theism (as moral theism), for example Allen W. Wood and Merold Westphal. As for Kant's book "Religion within the Bounds of Bare Reason", it was emphasized that Kant reduced religiosity to rationality, religion to morality and Christianity to ethics.

In the "Critique of Pure Reason", Kant distinguishes between the transcendental idea of freedom, which as a psychological concept is "mainly empirical" and refers to "whether a faculty of beginning a series of successive things or states from itself is to be assumed" and the practical concept of freedom as the independence of our will from the "coercion" or "necessitation through sensuous impulses". Kant finds it a source of difficulty that the practical idea of freedom is founded on the transcendental idea of freedom, but for the sake of practical interests uses the practical meaning, taking "no account of... its transcendental meaning," which he feels was properly "disposed of" in the Third Antinomy, and as an element in the question of the freedom of the will is for philosophy "a real stumbling block" that has embarrassed speculative reason.

Kant calls practical "everything that is possible through freedom", and the pure practical laws that are never given through sensuous conditions but are held analogously with the universal law of causality are moral laws. Reason can give us only the "pragmatic laws of free action through the senses", but pure practical laws given by reason "a priori" dictate "what is to be done". (The same distinction of transcendental and practical meaning can be applied to the idea of God, with the "proviso" that the practical concept of freedom can be experienced.)

In the "Critique of Practical Reason", at the end of the second Main Part of the "Analytics", Kant introduces the categories of freedom, in analogy with the categories of understanding their practical counterparts. Kant's categories of freedom apparently function primarily as conditions for the possibility for actions (i) to be free, (ii) to be understood as free and (iii) to be morally evaluated. For Kant, although actions as theoretical objects are constituted by means of the theoretical categories, actions as practical objects (objects of practical use of reason, and which can be good or bad) are constituted by means of the categories of freedom. Only in this way can actions, as phenomena, be a consequence of freedom, and be understood and evaluated as such.

Kant discusses the subjective nature of aesthetic qualities and experiences in "Observations on the Feeling of the Beautiful and Sublime" (1764). Kant's contribution to aesthetic theory is developed in the "Critique of Judgment" (1790) where he investigates the possibility and logical status of "judgments of taste." In the "Critique of Aesthetic Judgment," the first major division of the "Critique of Judgment", Kant used the term "aesthetic" in a manner that, according to Kant scholar W.H. Walsh, differs from its modern sense. In the "Critique of Pure Reason", to note essential differences between judgments of taste, moral judgments, and scientific judgments, Kant abandoned the term "aesthetic" as "designating the critique of taste," noting that judgments of taste could never be "directed" by "laws "a priori"." After A. G. Baumgarten, who wrote "Aesthetica" (1750–58), Kant was one of the first philosophers to develop and integrate aesthetic theory into a unified and comprehensive philosophical system, utilizing ideas that played an integral role throughout his philosophy.

In the chapter "Analytic of the Beautiful" in the "Critique of Judgment", Kant states that beauty is not a property of an artwork or natural phenomenon, but is instead consciousness of the pleasure that attends the 'free play' of the imagination and the understanding. Even though it appears that we are using reason to decide what is beautiful, the judgment is not a cognitive judgment, "and is consequently not logical, but aesthetical" (§ 1). A pure judgement of taste is subjective since it refers to the emotional response of the subject and is based upon nothing but esteem for an object itself: it is a disinterested pleasure, and we feel that pure judgements of taste (i.e. judgements of beauty), lay claim to universal validity (§§ 20–22). It is important to note that this universal validity is not derived from a determinate concept of beauty but from "common sense" (§40). Kant also believed that a judgement of taste shares characteristics engaged in a moral judgement: both are disinterested, and we hold them to be universal. In the chapter "Analytic of the Sublime" Kant identifies the sublime as an aesthetic quality that, like beauty, is subjective, but unlike beauty refers to an indeterminate relationship between the faculties of the imagination and of reason, and shares the character of moral judgments in the use of reason. The feeling of the sublime, divided into two distinct modes (the mathematical and the dynamical sublime), describes two subjective moments that concern the relationship of the faculty of the imagination to reason. Some commentators argue that Kant's critical philosophy contains a third kind of the sublime, the moral sublime, which is the aesthetic response to the moral law or a representation, and a development of the "noble" sublime in Kant's theory of 1764. The mathematical sublime results from the failure of the imagination to comprehend natural objects that appear boundless and formless, or appear "absolutely great" (§§ 23–25). This imaginative failure is then recuperated through the pleasure taken in reason's assertion of the concept of infinity. In this move the faculty of reason proves itself superior to our fallible sensible self (§§ 25–26). In the dynamical sublime there is the sense of annihilation of the sensible self as the imagination tries to comprehend a vast might. This power of nature threatens us but through the resistance of reason to such sensible annihilation, the subject feels a pleasure and a sense of the human moral vocation. This appreciation of moral feeling through exposure to the sublime helps to develop moral character.

Kant developed a distinction between an object of art as a material value subject to the conventions of society and the transcendental condition of the judgment of taste as a "refined" value in his "Idea of A Universal History" (1784). In the Fourth and Fifth Theses of that work he identified all art as the "fruits of unsociableness" due to men's "antagonism in society" and, in the Seventh Thesis, asserted that while such material property is indicative of a civilized state, only the ideal of morality and the universalization of refined value through the improvement of the mind "belongs to culture".

In "Perpetual Peace: A Philosophical Sketch", Kant listed several conditions that he thought necessary for ending wars and creating a lasting peace. They included a world of constitutional republics. His classical republican theory was extended in the "Science of Right", the first part of the "Metaphysics of Morals" (1797). Kant believed that universal history leads to the ultimate world of republican states at peace, but his theory was not pragmatic. The process was described in "Perpetual Peace" as natural rather than rational:
Kant's political thought can be summarized as republican government and international organization. "In more characteristically Kantian terms, it is doctrine of the state based upon the law ("Rechtsstaat") and of eternal peace. Indeed, in each of these formulations, both terms express the same idea: that of legal constitution or of 'peace through law'. Kant's political philosophy, being essentially a legal doctrine, rejects by definition the opposition between moral education and the play of passions as alternate foundations for social life. The state is defined as the union of men under law. The state is constituted by laws which are necessary a priori because they flow from the very concept of law. "A regime can be judged by no other criteria nor be assigned any other functions, than those proper to the lawful order as such." 

He opposed "democracy," which at his time meant direct democracy, believing that majority rule posed a threat to individual liberty. He stated, "...democracy is, properly speaking, necessarily a despotism, because it establishes an executive power in which 'all' decide for or even against one who does not agree; that is, 'all,' who are not quite all, decide, and this is a contradiction of the general will with itself and with freedom." As with most writers at the time, he distinguished three forms of government i.e. democracy, aristocracy, and monarchy with mixed government as the most ideal form of it.

Kant lectured on anthropology, the study of human nature, for twenty-three and a half years. His "Anthropology from a Pragmatic Point of View" was published in 1798. (This was the subject of Michel Foucault's secondary dissertation for his State doctorate, "Introduction to Kant's Anthropology".) Kant's Lectures on Anthropology were published for the first time in 1997 in German. "Introduction to Kant's Anthropology" was translated into English and published by the Cambridge Texts in the History of Philosophy series in 2006.

Kant was among the first people of his time to introduce anthropology as an intellectual area of study, long before the field gained popularity, and his texts are considered to have advanced the field. His point of view was to influence the works of later philosophers such as Martin Heidegger and Paul Ricoeur.

Kant was also the first to suggest using a dimensionality approach to human diversity. He analyzed the nature of the Hippocrates-Galen four temperaments and plotted them in two dimensions: (1) "activation", or energetic aspect of behaviour, and (2) "orientation on emotionality". Cholerics were described as emotional and energetic; Phlegmatics as balanced and weak; Sanguines as balanced and energetic, and Melancholics as emotional and weak. These two dimensions reappeared in all subsequent models of temperament and personality traits.

Kant viewed anthropology in two broad categories: (1) the physiological approach, which he referred to as "what nature makes of the human being"; and (2) the pragmatic approach, which explored the things that a human "can and should make of himself."

Kant was one of the most notable Enlightenment thinkers to promote racism, and was one of the central figures in the birth of modern "scientific" racism. Where previous figures such as Carl Linnaeus and Johann Friedrich Blumenbach had supposed only "empirical" observation for racism, Kant produced a full-blown theory of race. Using the Four Temperaments of ancient Greece, he proposed a hierarchy of four racial categories: white Europeans, yellow Asians, black Africans, and red Amerindians.

Kant wrote that "[Whites] contain all the impulses of nature in affects and passions, all talents, all dispositions to culture and civilization and can as readily obey as govern. They are the only ones who always advance to perfection.” He describes South Asians as "educated to the highest degree but only in the arts and not in the sciences". He goes on that Hindustanis can never reach the level of abstract concepts and that a "great hindustani man" is one who has "gone far in the art of deception and has much money". He stated that the Hindus always stay the way they are and can never advance. About black Africans, Kant wrote that "they can be educated but only as servants, that is they allow themselves to be trained". He quotes David Hume as challenging anyone to "cite a [single] example in which a Negro has shown talents" and asserts that, among the "hundreds of thousands" of blacks transported during the Atlantic slave trade, even among the freed "still not a single one was ever found who presented anything great in art or science or any other praiseworthy quality". To Kant, "the Negro can be disciplined and cultivated, but is never genuinely civilized. He falls of his own accord into savagery." Native Americans, Kant opined, "cannot be educated". He calls them unmotivated, lacking affect, passion and love, describing them as too weak for labor, unfit for any culture, and too phlegmatic for diligence. He said the Native Americans are "far below the Negro, who undoubtedly holds the lowest of all remaining levels by which we designate the different races". Kant stated that "Americans and Blacks cannot govern themselves. They thus serve only for slaves."

Kant was an opponent of miscegenation, believing that whites would be "degraded" and the "fusing of races" is undesireable, for "not every race adopts the morals and customs of the Europeans". He stated that "instead of assimilation, which was intended by the melting together of the various races, Nature has here made a law of just the opposite". He believed that in the future all races would be extinguished, except that of the whites.

Charles W. Mills wrote that Kant has been "sanitized for public consumption", his racist works conveniently ignored. Robert Bernasconi stated that Kant "supplied the first scientific definition of race". Emmanuel Chukwudi Eze is credited with bringing Kant's contributions to racism to light in the 1990s among Western philosophers, who often gloss over this part of his life and works. He wrote about Kant's ideas of race:

Kant's influence on Western thought has been profound. Over and above his influence on specific thinkers, Kant changed the framework within which philosophical inquiry has been carried out. He accomplished a paradigm shift; very little philosophy is now carried out in the style of pre-Kantian philosophy. This shift consists in several closely related innovations that have become foundational in philosophy itself and in the social sciences and humanities generally:

Kant's ideas have been incorporated into a variety of schools of thought. These include German Idealism, Marxism, positivism, phenomenology, existentialism, critical theory, linguistic philosophy, structuralism, post-structuralism, and deconstructionism.

During his own life, much critical attention was paid to his thought. He influenced Reinhold, Fichte, Schelling, Hegel, and Novalis during the 1780s and 1790s. The school of thinking known as German Idealism developed from his writings. The German Idealists Fichte and Schelling, for example, tried to bring traditional "metaphysically" laden notions like "the Absolute", "God", and "Being" into the scope of Kant's critical thought. In so doing, the German Idealists tried to reverse Kant's view that we cannot know what we cannot observe.

Hegel was one of Kant's first major critics. In response to what he saw as Kant's abstract and formal account, Hegel brought about an ethic focused on the "ethical life" of the community. But Hegel's notion of "ethical life" is meant to subsume, rather than replace, Kantian ethics. And Hegel can be seen as trying to defend Kant's idea of freedom as going beyond finite "desires", by means of reason. Thus, in contrast to later critics like Nietzsche or Russell, Hegel shares some of Kant's most basic concerns.

Kant's thinking on religion was used in Britain to challenge the decline in religious faith in the nineteenth century. British Catholic writers, notably G.K. Chesterton and Hilaire Belloc, followed this approach. Ronald Englefield debated this movement, and Kant's use of language. Criticisms of Kant were common in the realist views of the new positivism at that time.

Arthur Schopenhauer was strongly influenced by Kant's transcendental idealism. He, like G.E. Schulze, Jacobi, and Fichte before him, was critical of Kant's theory of the thing in itself. Things in themselves, they argued, are neither the cause of what we observe nor are they completely beyond our access. Ever since the first "Critique of Pure Reason" philosophers have been critical of Kant's theory of the thing in itself. Many have argued, if such a thing exists beyond experience then one cannot posit that it affects us causally, since that would entail stretching the category 'causality' beyond the realm of experience. For Schopenhauer things in themselves do not exist outside the non-rational will. The world, as Schopenhauer would have it, is the striving and largely unconscious will. Michael Kelly, in the preface to his 1910 book "Kant's Ethics and Schopenhauer's Criticism", stated: "Of Kant it may be said that what is good and true in his philosophy would have been buried with him, were it not for Schopenhauer..."

With the success and wide influence of Hegel's writings, Kant's influence began to wane, though there was in Germany a movement that hailed a return to Kant in the 1860s, beginning with the publication of "Kant und die Epigonen" in 1865 by Otto Liebmann. His motto was "Back to Kant", and a re-examination of his ideas began (see Neo-Kantianism). During the turn of the 20th century there was an important revival of Kant's theoretical philosophy, known as the Marburg School, represented in the work of Hermann Cohen, Paul Natorp, Ernst Cassirer, and anti-Neo-Kantian Nicolai Hartmann.

Kant's notion of "Critique" has been quite influential. The Early German Romantics, especially Friedrich Schlegel in his "Athenaeum Fragments", used Kant's self-reflexive conception of criticism in their Romantic theory of poetry. Also in Aesthetics, Clement Greenberg, in his classic essay "Modernist Painting", uses Kantian criticism, what Greenberg refers to as "immanent criticism", to justify the aims of Abstract painting, a movement Greenberg saw as aware of the key limitiaton—flatness—that makes up the medium of painting. French philosopher Michel Foucault was also greatly influenced by Kant's notion of "Critique" and wrote several pieces on Kant for a re-thinking of the Enlightenment as a form of "critical thought". He went so far as to classify his own philosophy as a "critical history of modernity, rooted in Kant".

Kant believed that mathematical truths were forms of synthetic "a priori" knowledge, which means they are necessary and universal, yet known through intuition. Kant's often brief remarks about mathematics influenced the mathematical school known as intuitionism, a movement in philosophy of mathematics opposed to Hilbert's formalism, and Frege and Bertrand Russell's logicism.

With his "", Kant is considered to have foreshadowed many of the ideas that have come to form the democratic peace theory, one of the main controversies in political science.

Prominent recent Kantians include the British philosophers P.F. Strawson, Onora O'Neill, and Quassim Cassam and the American philosophers Wilfrid Sellars and Christine Korsgaard. Due to the influence of Strawson and Sellars, among others, there has been a renewed interest in Kant's view of the mind. Central to many debates in philosophy of psychology and cognitive science is Kant's conception of the unity of consciousness.

Jürgen Habermas and John Rawls are two significant political and moral philosophers whose work is strongly influenced by Kant's moral philosophy. They argued against relativism, supporting the Kantian view that universality is essential to any viable moral philosophy. Jean-Francois Lyotard, however, emphasized the indeterminacy in the nature of thought and language and has engaged in debates with Habermas based on the effects this indeterminacy has on philosophical and political debates.

Mou Zongsan's study of Kant has been cited as a highly crucial part in the development of Mou’s personal philosophy, namely New Confucianism. Widely regarded as the most influential Kant scholar in China, Mou's rigorous critique of Kant’s philosophy—having translated all three of Kant’s critiques—served as an ardent attempt to reconcile Chinese and Western philosophy whilst increasing pressure to westernize in China.

Kant's influence also has extended to the social, behavioral, and physical sciences, as in the sociology of Max Weber, the psychology of Jean Piaget and Carl Gustav Jung, and the linguistics of Noam Chomsky. Kant's work on mathematics and synthetic "a priori" knowledge is also cited by theoretical physicist Albert Einstein as an early influence on his intellectual development, which he later criticised heavily and rejected. Because of the thoroughness of the Kantian paradigm shift, his influence extends to thinkers who neither specifically refer to his work nor use his terminology.


Wilhelm Dilthey inaugurated the Academy edition (the "Akademie-Ausgabe" abbreviated as "AA" or "Ak") of Kant's writings ("Gesammelte Schriften", Königlich-Preußische Akademie der Wissenschaften, Berlin, 1902–38) in 1895, and served as its first editor. The volumes are grouped into four sections:


In Germany, one important contemporary interpreter of Kant and the movement of German Idealism he began is Dieter Henrich, who has some work available in English. P.F. Strawson's "The Bounds of Sense" (1966) played a significant role in determining the contemporary reception of Kant in England and America. More recent interpreters of note in the English-speaking world include Lewis White Beck, Jonathan Bennett, Henry Allison, Paul Guyer, Christine Korsgaard, Stephen Palmquist, Robert B. Pippin, Roger Scruton, Rudolf Makkreel, and Béatrice Longuenesse.
General introductions to his thought

Biography and historical context

Collections of essays

Theoretical philosophy

Practical philosophy

Aesthetics

Philosophy of religion

Perpetual peace and international relations

Other works

Contemporary philosophy with a Kantian influence



</doc>
<doc id="14643" url="https://en.wikipedia.org/wiki?curid=14643" title="History of Indonesia">
History of Indonesia

The history of Indonesia has been shaped by its geographic position, its natural resources, a series of human migrations and contacts, wars and conquests, as well as by trade, economics and politics. Indonesia is an archipelagic country of 17,000 to 18,000 islands (8,844 named and 922 permanently inhabited) stretching along the equator in South East Asia. The country's strategic sea-lane position fostered inter-island and international trade; trade has since fundamentally shaped Indonesian history. The area of Indonesia is populated by peoples of various migrations, creating a diversity of cultures, ethnicities, and languages. The archipelago's landforms and climate significantly influenced agriculture and trade, and the formation of states. The boundaries of the state of Indonesia represent the 20th century borders of the Dutch East Indies.

Fossilised remains of "Homo erectus" and his tools, popularly known as the "Java Man", suggest the Indonesian archipelago was inhabited by at least 1.5 million years ago. Austronesian people, who form the majority of the modern population, are thought to have originally been from Taiwan and arrived in Indonesia around 2000 BCE. From the 7th century CE, the powerful Srivijaya naval kingdom flourished bringing Hindu and Buddhist influences with it. The agricultural Buddhist Sailendra and Hindu Mataram dynasties subsequently thrived and declined in inland Java. The last significant non-Muslim kingdom, the Hindu Majapahit kingdom, flourished from the late 13th century, and its influence stretched over much of Indonesia. The earliest evidence of Islamised populations in Indonesia dates to the 13th century in northern Sumatra; other Indonesian areas gradually adopted Islam which became the dominant religion in Java and Sumatra by the end of the 16th century. For the most part, Islam overlaid and mixed with existing cultural and religious influences.

Europeans such as the Portuguese arrived in Indonesia from the 16th century seeking to monopolise the sources of valuable nutmeg, cloves, and cubeb pepper in Maluku. In 1602 the Dutch established the Dutch East India Company (VOC) and became the dominant European power by 1610. Following bankruptcy, the VOC was formally dissolved in 1800, and the government of the Netherlands established the Dutch East Indies under government control. By the early 20th century, Dutch dominance extended to the current boundaries. The Japanese invasion and subsequent occupation in 1942–45 during WWII ended Dutch rule, and encouraged the previously suppressed Indonesian independence movement. Two days after the surrender of Japan in August 1945, nationalist leader, Sukarno, declared independence and became president. The Netherlands tried to reestablish its rule, but a bitter armed and diplomatic struggle ended in December 1949, when in the face of international pressure, the Dutch formally recognised Indonesian independence.

An attempted coup in 1965 led to a violent army-led anti-communist purge in which over half a million people were killed. General Suharto politically outmanoeuvred President Sukarno, and became president in March 1968. His New Order administration garnered the favour of the West, whose investment in Indonesia was a major factor in the subsequent three decades of substantial economic growth. In the late 1990s, however, Indonesia was the country hardest hit by the East Asian Financial Crisis, which led to popular protests and Suharto's resignation on 21 May 1998. The "Reformasi" era following Suharto's resignation, has led to a strengthening of democratic processes, including a regional autonomy program, the secession of East Timor, and the first direct presidential election in 2004. Political and economic instability, social unrest, corruption, natural disasters, and terrorism have slowed progress. Although relations among different religious and ethnic groups are largely harmonious, acute sectarian discontent and violence remain problems in some areas.

In 2007, an analysis of cut marks on two bovid bones found in Sangiran, showed them to have been made 1.5 to 1.6 million years ago by clamshell tools. This is the oldest evidence for the presence of early humans in Indonesia. Fossilised remains of "Homo erectus" in Indonesia, popularly known as the "Java Man" were first discovered by the Dutch anatomist Eugène Dubois at Trinil in 1891, and are at least 700,000 years old. Other "H. erectus" fossils of a similar age were found at Sangiran in the 1930s by the anthropologist Gustav Heinrich Ralph von Koenigswald, who in the same time period also uncovered fossils at Ngandong alongside more advanced tools, re-dated in 2011 to between 550,000 and 143,000 years old. In 1977 another "H. erectus" skull was discovered at Sambungmacan. The earliest evidence of artistic activity ever found, in the form of diagonal etchings made with the use of a shark's tooth, was detected in 2014 on a 500,000-year-old fossil of a clam found in Java in the 1890s, associated with "H. erectus".

In 2003, on the island of Flores, fossils of a new small hominid dated between 74,000 and 13,000 years old were discovered, much to the surprise of the scientific community. This newly discovered hominid was named the "Flores Man", or "Homo florensis". This 3 foot tall hominid is thought to be a species descended from "Homo erectus" that reduced in size over thousands of years, through a well-known process called island dwarfism. Flores Man seems to have shared the island with modern "Homo sapiens" until only 12,000 years ago, when they became extinct. In 2010, stone tools were discovered on Flores, dating from 1 million years ago. These are the earliest remains implying human seafaring technology.

The Indonesian archipelago was formed during the thaw after the Last Glacial Maximum. Early humans travelled by sea and spread from mainland Asia eastward to New Guinea and Australia. "Homo sapiens" reached the region by around 45,000 years ago. In 2011, evidence was uncovered in neighbouring East Timor, showing that 42,000 years ago, these early settlers had high-level maritime skills, and by implication the technology needed to make ocean crossings to reach Australia and other islands, as they were catching and consuming large numbers of big deep sea fish such as tuna.

Austronesian people form the majority of the modern population. They may have arrived in Indonesia around 2000 BCE and are thought to have originated in Taiwan. Dong Son culture spread to Indonesia bringing with it techniques of wet-field rice cultivation, ritual buffalo sacrifice, bronze casting, megalithic practises, and ikat weaving methods. Some of these practices remain in areas including the Batak areas of Sumatra, Toraja in Sulawesi, and several islands in Nusa Tenggara. Early Indonesians were animists who honoured the spirits of the dead believing their souls or life force could still help the living.

Ideal agricultural conditions, and the mastering of wet-field rice cultivation as early as the 8th century BCE, allowed villages, towns, and small kingdoms to flourish by the 1st century CE. These kingdoms (little more than collections of villages subservient to petty chieftains) evolved with their own ethnic and tribal religions. Java's hot and even temperature, abundant rain and volcanic soil, was perfect for wet rice cultivation. Such agriculture required a well-organized society, in contrast to the society based on dry-field rice, which is a much simpler form of cultivation that does not require an elaborate social structure to support it.

Buni culture clay pottery flourished in coastal northern West Java and Banten around 400 BCE to 100 CE. The Buni culture was probably the predecessor of the Tarumanagara kingdom, one of the earliest Hindu kingdoms in Indonesia, producing numerous inscriptions and marking the beginning of the historical period in Java.

In 11 December 2019, a team of researchers led by Dr. Maxime Aubert announced the discovery of the oldest hunting scenes  in prehistoric art  in the world which is more than 44,000 years old from the limestone cave of Leang Bulu’ Sipong 4. Archaeologists determined the age of the depiction of hunting a pig and buffalo thanks to the calcite ‘popcorn’, different isotope levels of radioactive uranium and thorium.

Indonesia like much of Southeast Asia was influenced by Indian culture. From the 2nd century, through the Indian dynasties like the Pallava, Gupta, Pala and Chola in the succeeding centuries up to the 12th century, Indian culture spread across all of Southeast Asia.

References to the Dvipantara or Yawadvipa, a Hindu kingdom in Java and Sumatra appear in Sanskrit writings from 200 BCE. In India's earliest epic, the Ramayana, Sugriva, the chief of Rama's army dispatched his men to Yawadvipa, the island of Java, in search of Sita. According to the ancient Tamil text Manimekalai Java had a kingdom with a capital called Nagapuram. The earliest archaeological relic discovered in Indonesia is from the Ujung Kulon National Park, West Java, where an early Hindu statue of Ganesha estimated from the 1st century CE was found on the summit of Mount Raksa in Panaitan island. There is also archaeological evidence of Sunda Kingdom in West Java dating from the 2nd-century, and Jiwa Temple in Batujaya, Karawang, West Java was probably built around this time. South Indian culture was spread to Southeast Asia by the south Indian Pallava dynasty in the 4th and 5th century. and by the 5th century, stone inscriptions written in Pallava scripts were found in Java and Borneo.

A number of Hindu and Buddhist states flourished and then declined across Indonesia. Three rough plinths dating from the beginning of the 4th century are found in Kutai, East Kalimantan, near Mahakam River. The plinths bear an inscription in the Pallava script of India reading "A gift to the Brahmin priests".

One such early kingdom was Tarumanagara, which flourished between 358 and 669 CE. Located in West Java close to modern-day Jakarta, its 5th-century King, Purnawarman, established the earliest known inscriptions in Java, the Ciaruteun inscription located near Bogor. And other inscriptions called the Pasar Awi inscription and the Muncul inscription. On this monument, King Purnawarman inscribed his name and made an imprint of his footprints, as well as his elephant's footprints. The accompanying inscription reads, "Here are the footprints of King Purnavarman, the heroic conqueror of the world". This inscription is written in Pallava script and in Sanskrit and is still clear after 1500 years. Purnawarman apparently built a canal that changed the course of the Cakung River, and drained a coastal area for agriculture and settlement purpose. In his stone inscriptions, Purnawarman associated himself with Vishnu, and Brahmins ritually secured the hydraulic project.

Around the same period, in the 6th to 7th century, the Kalingga Kingdom was established in Central Java northern coast, mentioned in Chinese account. The name of this kingdom was derived from ancient Indian kingdom of Kalinga, which suggest the ancient link between India and Indonesia.

The political history of Indonesian archipelago during the 7th to 11th centuries was dominated by Srivijaya based in Sumatra and Sailendra that dominated southeast Asia based in Java and constructed Borobudur, the largest Buddhist monument in the world. The history prior of the 14th and 15th centuries is not well known due to the scarcity of evidence. By the 15th century, two major states dominated this period; Majapahit in East Java, the greatest of the pre-Islamic Indonesian states, and Malacca on the west coast of the Malay Peninsula, arguably one of the greatest of the Muslim trading empires, this marked the rise of Muslim states in Indonesian archipelago.

Medang Empire, sometimes referred to as Mataram, was an Indianized kingdom based in Central Java around modern-day Yogyakarta between the 8th and 10th centuries. The kingdom was ruled by the Sailendra dynasty, and later by the Sanjaya dynasty. The centre of the kingdom was moved from central Java to East Java by Mpu Sindok. An eruption of the volcano Mount Merapi in 929, and political pressure from Sailendrans based in the Srivijaya Empire may have caused the move.

The first king of Mataram, Sri Sanjaya, left inscriptions in stone. The monumental Hindu temple of Prambanan in the vicinity of Yogyakarta was built by Pikatan. Dharmawangsa ordered the translation of the Mahabharata into Old Javanese in 996.

In the period 750 CE - 850 CE, the kingdom saw the blossoming of classical Javanese art and architecture. A rapid increase in temple construction occurred across the landscape of its heartland in Mataram (Kedu and Kewu Plain). The most notable temples constructed in Medang Mataram are Kalasan, Sewu, Borobudur and Prambanan. The Empire had become the dominant power (mandala) not only in Java but also Srivijayan Empire, Bali, southern Thailand, Indianized kingdoms of Philippines, and Khmer in Cambodia.

Later in its history, the dynasty divided into two dynasties based on their own religion, the Buddhist and Shivaist dynasties. Civil war was unavoidable and the outcome was Medang Empire divided into two powerful kingdom based on region and religion. The Shivaist dynasty of Medang kingdom in Java led by Rakai Pikatan and the Buddhist dynasty of Srivijaya kingdom in Sumatra led by Balaputradewa. The hostility between them didn't end until in 1006 when the Sailendran based in Srivijaya kingdom incited rebellion by Wurawari, vassal of Medang kingdom and sacked Shivaist dynasty's capital in Watugaluh, Java. Srivijaya kingdom rose into undisputed hegemonic Empire in the era as the result. Yet the Shivaist dynasty survived and successfully reclaimed the east Java in 1019 then descended to Kahuripan kingdom led by Airlangga son of Udayana of Bali.

Srivijaya was an ethnic Malay kingdom on Sumatra which influenced much of the Maritime Southeast Asia. From the 7th century, the powerful Srivijaya naval kingdom flourished as a result of trade and the influences of Hinduism and Buddhism that were imported with it.

Srivijaya was centred in the coastal trading centre of present-day Palembang. Srivijaya was not a "state" in the modern sense with defined boundaries and a centralised government to which the citizens own allegiance. Rather Srivijaya was a confederacy form of society centred on a royal heartland. It was a thalassocracy and did not extend its influence far beyond the coastal areas of the islands of Southeast Asia. Trade was the driving force of Srivijaya just as it is for most societies throughout history. The Srivijayan navy controlled the trade that made its way through the Strait of Malacca.

By the 7th century, the harbours of various vassal states of Srivijaya lined both coasts of the Straits of Melaka. Around this time, Srivijaya had established suzerainty over large areas of Sumatra, western Java, and much of the Malay Peninsula. Dominating the Malacca and Sunda straits, the empire controlled both the Spice Route traffic and local trade. It remained a formidable sea power until the 13th century. This spread the ethnic Malay culture throughout Sumatra, the Malay Peninsula, and western Borneo. A stronghold of Vajrayana Buddhism, Srivijaya attracted pilgrims and scholars from other parts of Asia.

The relation between Srivijaya and the Chola Empire of south India was friendly during the reign of Raja Raja Chola I but during the reign of Rajendra Chola I the Chola Empire attacked Srivijaya cities. A series of Chola raids in the 11th century weakened the Srivijayan hegemony and enabled the formation of regional kingdoms based, like Kediri, on intensive agriculture rather than coastal and long distance trade. Srivijayan influence waned by the 11th century. The island was in frequent conflict with the Javanese kingdoms, first Singhasari and then Majapahit. Islam eventually made its way to the Aceh region of Sumatra, spreading its influence through contacts with Arabs and Indian traders. By the late 13th century, the kingdom of Pasai in northern Sumatra converted to Islam. The last inscription dates to 1374, where a crown prince, Ananggavarman, is mentioned. Srivijaya ceased to exist by 1414, when Parameswara, the kingdom's last prince, fled to Temasik, then to Malacca. Later his son converted to Islam and founded the Sultanate of Malacca on the Malay peninsula.

Despite a lack of historical evidence, it is known that Majapahit was the most dominant of Indonesia's pre-Islamic states. The Hindu Majapahit kingdom was founded in eastern Java in the late 13th century, and under Gajah Mada it experienced what is often referred to as a "Golden Age" in Indonesian history, when its influence extended to much of southern Malay Peninsula, Borneo, Sumatra, and Bali from about 1293 to around 1500.

The founder of the Majapahit Empire, Kertarajasa, was the son-in-law of the ruler of the Singhasari kingdom, also based in Java. After Singhasari drove Srivijaya out of Java in 1290, the rising power of Singhasari came to the attention of Kublai Khan in China and he sent emissaries demanding tribute. Kertanagara, ruler of the Singhasari kingdom, refused to pay tribute and the Khan sent a punitive expedition which arrived off the coast of Java in 1293. By that time, a rebel from Kediri, Jayakatwang, had killed Kertanagara. The Majapahit founder allied himself with the Mongols against Jayakatwang and, once the Singhasari kingdom was destroyed, turned and forced his Mongol allies to withdraw in confusion.

Gajah Mada, an ambitious Majapahit prime minister and regent from 1331 to 1364, extended the empire's rule to the surrounding islands. A few years after Gajah Mada's death, the Majapahit navy captured Palembang, putting an end to the Srivijayan kingdom. Although the Majapahit rulers extended their power over other islands and destroyed neighbouring kingdoms, their focus seems to have been on controlling and gaining a larger share of the commercial trade that passed through the archipelago. About the time Majapahit was founded, Muslim traders and proselytisers began entering the area. After its peak in the 14th century, Majapahit power began to decline and was unable to control the rising power of the Sultanate of Malacca. Dates for the end of the Majapahit Empire range from 1478 to 1520. A large number of courtiers, artisans, priests, and members of the royal family moved east to the island of Bali at the end of Majapahit power.

The earliest accounts of the Indonesian archipelago date from the Abbasid Caliphate, according to those early accounts the Indonesian archipelago were famous among early Muslim sailors mainly due to its abundance of precious spice trade commodities such as nutmeg, cloves, galangal and many other spices.

Although Muslim traders first travelled through South East Asia early in the Islamic era, the spread of Islam among the inhabitants of the Indonesian archipelago dates to the 13th century in northern Sumatra. Although it is known that the spread of Islam began in the west of the archipelago, the fragmentary evidence does not suggest a rolling wave of conversion through adjacent areas; rather, it suggests the process was complicated and slow. The spread of Islam was driven by increasing trade links outside of the archipelago; in general, traders and the royalty of major kingdoms were the first to adopt the new religion.

Other Indonesian areas gradually adopted Islam, making it the dominant religion in Java and Sumatra by the end of the 16th century. For the most part, Islam overlaid and mixed with existing cultural and religious influences, which shaped the predominant form of Islam in Indonesia, particularly in Java. Only Bali retained a Hindu majority. In the eastern archipelago, both Christian and Islamic missionaries were active in the 16th and 17th centuries, and, currently, there are large communities of both religions on these islands.

The Sultanate of Mataram was the third Sultanate in Java, after the Sultanate of Demak Bintoro and the Sultanate of Pajang.

According to Javanese records, Kyai Gedhe Pamanahan became the ruler of the Mataram area in the 1570s with the support of the kingdom of Pajang to the east, near the current site of Surakarta (Solo). Pamanahan was often referred to as Kyai Gedhe Mataram after his ascension.

Pamanahan's son, Panembahan Senapati Ingalaga, replaced his father on the throne around 1584. Under Senapati the kingdom grew substantially through regular military campaigns against Mataram's neighbours. Shortly after his accession, for example, he conquered his father's patrons in Pajang.

The reign of Panembahan Seda ing Krapyak ("c." 1601–1613), the son of Senapati, was dominated by further warfare, especially against powerful Surabaya, already a major centre in East Java. The first contact between Mataram and the Dutch East India Company (VOC) occurred under Krapyak. Dutch activities at the time were limited to trading from limited coastal settlements, so their interactions with the inland Mataram kingdom were limited, although they did form an alliance against Surabaya in 1613. Krapyak died that year.

Krapyak was succeeded by his son, who is known simply as Sultan Agung ("Great Sultan") in Javanese records. Agung was responsible for the great expansion and lasting historical legacy of Mataram due to the extensive military conquests of his long reign from 1613 to 1646.

After years of war Agung finally conquered Surabaya. The city was surrounded by land and sea and starved into submission. With Surabaya brought into the empire, the Mataram kingdom encompassed all of central and eastern Java, and Madura; only in the west did Banten and the Dutch settlement in Batavia remain outside Agung's control. He tried repeatedly in the 1620s and 1630s to drive the Dutch from Batavia, but his armies had met their match, and he was forced to share control over Java.

In 1645 he began building Imogiri, his burial place, about fifteen kilometres south of Yogyakarta. Imogiri remains the resting place of most of the royalty of Yogyakarta and Surakarta to this day. Agung died in the spring of 1646, with his image of royal invincibility shattered by his losses to the Dutch, but he did leave behind an empire that covered most of Java and its neighbouring islands.

Upon taking the throne, Agung's son Susuhunan Amangkurat I tried to bring long-term stability to Mataram's realm, murdering local leaders that were insufficiently deferential to him, and closing ports so he alone had control over trade with the Dutch.

By the mid-1670s dissatisfaction with the king fanned into open revolt. Raden Trunajaya, a prince from Madura, lead a revolt fortified by itinerant mercenaries from Makassar that captured the king's court at Mataram in mid-1677. The king escaped to the north coast with his eldest son, the future king Amangkurat II, leaving his younger son Pangeran Puger in Mataram. Apparently more interested in profit and revenge than in running a struggling empire, the rebel Trunajaya looted the court and withdrew to his stronghold in East Java leaving Puger in control of a weak court.

Amangkurat I died just after his expulsion, making Amangkurat II king in 1677. He too was nearly helpless, though, having fled without an army or treasury to build one. In an attempt to regain his kingdom, he made substantial concessions to the Dutch, who then went to war to reinstate him. For the Dutch, a stable Mataram empire that was deeply indebted to them would help ensure continued trade on favourable terms. They were willing to lend their military might to keep the kingdom together. Dutch forces first captured Trunajaya, then forced Puger to recognise the sovereignty of his elder brother Amangkurat II. The kingdom collapsed after a two-year war, in which power plays crippled the Sunan.

In 1524–25, Sunan Gunung Jati from Cirebon, together with the armies of Demak Sultanate, seized the port of Banten from the Sunda kingdom, and established The Sultanate of Banten. This was accompanied by Muslim preachers and the adoption of Islam amongst the local population. At its peak in the first half of the 17th century, the Sultanate lasted from 1526 to 1813 AD. The Sultanate left many archaeological remains and historical records.

Beginning in the 16th century, successive waves of Europeans—the Portuguese, Spanish, Dutch and British—sought to dominate the spice trade at its sources in India and the 'Spice Islands' (Maluku) of Indonesia. This meant finding a way to Asia to cut out Muslim merchants who, with their Venetian outlet in the Mediterranean, monopolised spice imports to Europe. Astronomically priced at the time, spices were highly coveted not only to preserve and make poorly preserved meat palatable, but also as medicines and magic potions.

The arrival of Europeans in South East Asia is often regarded as the watershed moment in its history. Other scholars consider this view untenable, arguing that European influence during the times of the early arrivals of the 16th and 17th centuries was limited in both area and depth. This is in part due to Europe not being the most advanced or dynamic area of the world in the early 15th century. Rather, the major expansionist force of this time was Islam; in 1453, for example, the Ottoman Turks conquered Constantinople, while Islam continued to spread through Indonesia and the Philippines. European influence, particularly that of the Dutch, would not have its greatest impact on Indonesia until the 18th and 19th centuries.

New found Portuguese expertise in navigation, shipbuilding and weaponry allowed them to make daring expeditions of exploration and expansion. Starting with the first exploratory expeditions sent from newly conquered Malacca in 1512, the Portuguese were the first Europeans to arrive in Indonesia, and sought to dominate the sources of valuable spices and to extend the Catholic Church's missionary efforts. The Portuguese turned east to Maluku and through both military conquest and alliance with local rulers, they established trading posts, forts, and missions on the islands of Ternate, Ambon, and Solor among others. The height of Portuguese missionary activities, however, came in the latter half of the 16th century. Ultimately, the Portuguese presence in Indonesia was reduced to Solor, Flores and Timor in modern-day Nusa Tenggara, following defeat at the hands of indigenous Ternateans and the Dutch in Maluku, and a general failure to maintain control of trade in the region. In comparison with the original Portuguese ambition to dominate Asian trade, their influence on Indonesian culture was small: the romantic "keroncong" guitar ballads; a number of Indonesian words which reflect Portuguese's role as the "lingua franca" of the archipelago alongside Malay; and many family names in eastern Indonesia such as da Costa, Dias, de Fretes, Gonsalves, etc. The most significant impacts of the Portuguese arrival were the disruption and disorganisation of the trade network mostly as a result of their conquest of Malacca, and the first significant plantings of Christianity in Indonesia. There have continued to be Christian communities in eastern Indonesia through to the present, which has contributed to a sense of shared interest with Europeans, particularly among the Ambonese.

In 1602, the Dutch parliament awarded the VOC a monopoly on trade and colonial activities in the region at a time before the company controlled any territory in Java. In 1619, the VOC conquered the West Javan city of Jayakarta, where they founded the city of Batavia (present-day Jakarta). The VOC became deeply involved in the internal politics of Java in this period, and fought in a number of wars involving the leaders of Mataram and Banten.

The Dutch followed the Portuguese aspirations, courage, brutality, and strategies but brought better organisation, weapons, ships, and superior financial backing. Although they failed to gain complete control of the Indonesian spice trade, they had much more success than the previous Portuguese efforts. They exploited the factionalisation of the small kingdoms in Java that had replaced Majapahit, establishing a permanent foothold in Java, from which grew a land-based colonial empire which became one of the richest colonial possessions on earth.

By the mid-17th century, Batavia, the headquarter of VOC in Asia, had become an important trade centre in the region. It had repelled attacks from the Javanese Mataram kingdom. In 1641 the Dutch captured Malacca from the Portuguese, thus weakened Portuguese position in Asia. The Dutch defeated the Sulawesi city of Makassar in 1667 thus bringing its trade under VOC control. Sumatran ports were also brought under VOC control and the last of the Portuguese were expelled in 1660. In return for monopoly control over the pepper trade and the expulsion of the British, the Dutch helped the son of the ruler of Banten overthrow his father in 1680. By the 18th century, the VOC has established themselves firmly in Indonesian archipelago, controlling inter-island trade as part of their Asian business which includes India, Ceylon, Formosa, and Japan. VOC has established their important bases in some ports in Java, Maluku, and parts of Sulawesi, Sumatra, and Malay Peninsula.

After the fall of the Netherlands to the First French Empire and the dissolution of the Dutch East India Company in 1800, there were profound changes in the European colonial administration of the East Indies. The Company's assets in East Indies were nationalised as the Dutch colony, the Dutch East Indies. Meanwhile, Europe was devastated by the Napoleonic Wars. In the Netherlands, Napoleon Bonaparte in 1806 oversaw the dissolution of the Batavian Republic, which was replaced by the Kingdom of Holland, a French puppet kingdom ruled by Napoleon's third brother Louis Bonaparte (Lodewijk Napoleon). The East Indies were treated as a proxy French colony, administrated through a Dutch intermediary.

In 1806, King Lodewijk of the Netherlands sent one of his generals, Herman Willem Daendels, to serve as governor-general of the East Indies, based in Java. Daendels was sent to strengthen Javanese defences against a predicted British invasion. Since 1685, the British had had a presence in Bencoolen on the western coast of Sumatra, as well as several posts north of the Malaccan straits. Daendels was responsible for the construction of the Great Post Road () across northern Java from Anjer to Panaroecan. The thousand-kilometre road was meant as to ease logistics across Java and was completed in only one year, during which thousands of Javanese forced labourers died.

In 1811, Java fell to a British East India Company force under Baron Minto, the governor-general of India. Lord Minto appointed Sir Thomas Stamford Raffles as lieutenant governor of Java. Raffles carried further the administrative centralisation previously initiated by Daendels. Raffles launched some military expeditions against local princes to subjugate them into British rule; such as the assault on Yogyakarta kraton on 21 June 1812, and the military expedition against Sultan Mahmud Badaruddin II of Palembang, and seized the nearby Bangka Island. During his administration, numbers of ancient monuments in Java were rediscovered, excavated and systematically catalogued for the first time, the most important one is the rediscovery of Borobudur Buddhist temple in Central Java. Raffles was an enthusiast of the island's history, as he wrote the book History of Java published later in 1817. In 1815, the island of Java was returned to control of the Netherlands following the end of Napoleonic Wars, under the terms of the Anglo-Dutch Treaty of 1814.

After the VOC was dissolved in 1800 following bankruptcy, and after a short British rule under Thomas Stamford Raffles, the Dutch state took over the VOC possessions in 1816. A Javanese uprising was crushed in the Java War of 1825–1830. After 1830 a system of forced cultivations and indentured labour was introduced on Java, the Cultivation System (in Dutch: "cultuurstelsel"). This system brought the Dutch and their Indonesian allies enormous wealth. The cultivation system tied peasants to their land, forcing them to work in government-owned plantations for 60 days of the year. The system was abolished in a more liberal period after 1870. In 1901 the Dutch adopted what they called the Ethical Policy, which included somewhat increased investment in indigenous education, and modest political reforms.

The Dutch colonials formed a privileged upper social class of soldiers, administrators, managers, teachers, and pioneers. They lived together with the "natives", but at the top of a rigid social and racial caste system. The Dutch East Indies had two legal classes of citizens; European and indigenous. A third class, Foreign Easterners, was added in 1920.

Upgrading the infrastructure of ports and roads was a high priority for the Dutch, with the goal of modernising the economy, pumping wages into local areas, facilitating commerce, and speeding up military movements. By 1950 Dutch engineers had built and upgraded a road network with 12,000 km of asphalted surface, 41,000 km of metalled road area and 16,000 km of gravel surfaces. In addition the Dutch built of railways, bridges, irrigation systems covering 1.4 million hectares (5,400 sq mi) of rice fields, several harbours, and 140 public drinking water systems. These Dutch constructed public works became the economic base of the colonial state; after independence, they became the basis of the Indonesian infrastructure.

For most of the colonial period, Dutch control over its territories in the Indonesian archipelago was tenuous. In some cases, Dutch police and military actions in parts of Indonesia were quite cruel. Recent discussions, for example, of Dutch cruelty in Aceh have encouraged renewed research on these aspects of Dutch rule. It was only in the early 20th century, three centuries after the first Dutch trading post, that the full extent of the colonial territory was established and direct colonial rule exerted across what would become the boundaries of the modern Indonesian state. Portuguese Timor, now East Timor, remained under Portuguese rule until 1975 when it was invaded by Indonesia. The Indonesian government declared the territory an Indonesian province but relinquished it in 1999.

In October 1908, the first nationalist movement was formed, Budi Utomo. On 10 September 1912, the first nationalist mass movement was formed: Sarekat Islam. By December 1912, Sarekat Islam had 93,000 members. The Dutch responded after the First World War with repressive measures. The nationalist leaders came from a small group of young professionals and students, some of whom had been educated in the Netherlands. In the post–World War I era, the Indonesian communists who were associated with the Third International started to usurp the nationalist movement. The repression of the nationalist movement led to many arrests, including Indonesia's first president, Sukarno (1901–70), who was imprisoned for political activities on 29 December 1929. Also arrested was Mohammad Hatta, first Vice-President of Indonesia. Additionally, Sutan Sjahrir, who later became the first Prime Minister of Indonesia, was arrested on this date.

In 1914 the exiled Dutch socialist Henk Sneevliet founded the Indies Social Democratic Association. Initially a small forum of Dutch socialists, it would later evolve into the Communist Party of Indonesia (PKI) in 1924. In the post–World War I era, the Dutch strongly repressed all attempts at change. This repression led to a growth of the PKI. By December 1924, the PKI had a membership of 1,140. One year later in 1925, the PKI had grown to 3,000 members. From 1926 to 1927, there was a PKI-led revolt against Dutch colonialism and the harsh repression of strikes of urban workers. However, the strikes and the revolt was put down by the Dutch with some 13,000 nationalists and communists leaders were arrested. Some 4,500 were given prison sentences.

Sukarno was released from prison in December 1931 but was re-arrested on 1 August 1933.

The Japanese invasion and subsequent occupation during World War II ended Dutch rule and encouraged the previously suppressed Indonesian independence movement. In May 1940, early in World War II, the Netherlands was occupied by Nazi Germany. The Dutch East Indies declared a state of siege and in July redirected exports for Japan to the US and Britain. Negotiations with the Japanese aimed at securing supplies of aviation fuel collapsed in June 1941, and the Japanese started their conquest of Southeast Asia in December of that year. That same month, factions from Sumatra sought Japanese assistance for a revolt against the Dutch wartime government. The last Dutch forces were defeated by Japan in March 1942.
In July 1942, Sukarno accepted Japan's offer to rally the public in support of the Japanese war effort. Sukarno and Mohammad Hatta were decorated by the Emperor of Japan in 1943. However, experience of the Japanese occupation of Dutch East Indies varied considerably, depending upon where one lived and one's social position. Many who lived in areas considered important to the war effort experienced torture, sex slavery, arbitrary arrest and execution, and other war crimes. Thousands taken away from Indonesia as war labourers (romusha) suffered or died as a result of ill-treatment and starvation. People of Dutch and mixed Dutch-Indonesian descent were particular targets of the Japanese occupation.

In March 1945, the Japanese established the Investigating Committee for Preparatory Work for Independence (BPUPK) as the initial stage of the establishment of independence for the area under the control of the Japanese 16th Army. At its first meeting in May, Soepomo spoke of national integration and against personal individualism, while Muhammad Yamin suggested that the new nation should claim British Borneo, British Malaya, Portuguese Timor, and all the pre-war territories of the Dutch East Indies. The committee drafted the 1945 Constitution, which remains in force, though now much amended. On 9 August 1945 Sukarno, Hatta, and Radjiman Wediodiningrat were flown to meet Marshal Hisaichi Terauchi in Vietnam. They were told that Japan intended to announce Indonesian independence on 24 August. After the Japanese surrender, however, Sukarno unilaterally proclaimed Indonesian independence on 17 August. A later UN report stated that four million people died in Indonesia as a result of the Japanese occupation.

Under pressure from radical and politicised "pemuda" ('youth') groups, Sukarno and Hatta proclaimed Indonesian independence on 17 August 1945, two days after the Japanese Emperor's surrender in the Pacific. The following day, the Central Indonesian National Committee (KNIP) declared Sukarno President and Hatta Vice-President. Word of the proclamation spread by shortwave and fliers while the Indonesian war-time military (PETA), youths, and others rallied in support of the new republic, often moving to take over government offices from the Japanese. In December 1946 the United Nations acknowledged that Netherlands had advised the United Nations that the "Netherlands Indies" was a non-self-governing territory (colony) for which the Netherlands had a legal duty to make yearly reports and to assist towards "a full measure of self-government" as required by the ‘’Charter of the United Nations article 73‘’.

The Dutch, initially backed by the British, tried to re-establish their rule, and a bitter armed and diplomatic struggle ended in December 1949, when in the face of international pressure, the Dutch formally recognised Indonesian independence. Dutch efforts to re-establish complete control met resistance. At the end of World War II, a power vacuum arose, and the nationalists often succeeded in seizing the arms of the demoralised Japanese. A period of unrest with city guerrilla warfare called the Bersiap period ensued. Groups of Indonesian nationalists armed with improvised weapons (like bamboo spears) and firearms attacked returning Allied troops. 3,500 Europeans were killed and 20,000 were missing, meaning there were more European deaths in Indonesia after the war than during the war. After returning to Java, Dutch forces quickly re-occupied the colonial capital of Batavia (now Jakarta), so the city of Yogyakarta in central Java became the capital of the nationalist forces. Negotiations with the nationalists led to two major truce agreements, but disputes about their implementation, and much mutual provocation, led each time to renewed conflict. Within four years the Dutch had recaptured almost the whole of Indonesia, but guerrilla resistance persisted, led on Java by commander Nasution. On 27 December 1949, after four years of sporadic warfare and fierce criticism of the Dutch by the UN, the Netherlands officially recognised Indonesian sovereignty under the federal structure of the United States of Indonesia (RUSI). On 17 August 1950, exactly five years after the proclamation of independence, the last of the federal states were dissolved and Sukarno proclaimed a single unitary Republic of Indonesia.

With the unifying struggle to secure Indonesia's independence over, divisions in Indonesian society began to appear. These included regional differences in customs, religion, the impact of Christianity and Marxism, and fears of Javanese political domination. Following colonial rule, Japanese occupation, and war against the Dutch, the new country suffered from severe poverty, a ruinous economy, low educational and skills levels, and authoritarian traditions. Challenges to the authority of the Republic included the militant "Darul Islam" who waged a guerrilla struggle against the Republic from 1948 to 1962; the declaration of an independent Republic of South Maluku by Ambonese formerly of the Royal Dutch Indies Army; and rebellions in Sumatra and Sulawesi between 1955 and 1961.

In contrast to the 1945 Constitution, the 1950 constitution mandated a parliamentary system of government, an executive responsible to parliament, and stipulated at length constitutional guarantees for human rights, drawing heavily on the 1948 United Nations Universal Declaration of Human Rights. A proliferation of political parties dealing for shares of cabinet seats resulted in a rapid turnover of coalition governments including 17 cabinets between 1945 and 1958. The long-postponed parliamentary elections were held in 1955; although the Indonesian National Party (PNI)—considered Sukarno's party—topped the poll, and the Communist Party of Indonesia (PKI) received strong support, no party garnered more than a quarter of the votes, which resulted in short-lived coalitions.

By 1956, Sukarno was openly criticising parliamentary democracy, stating that it was "based upon inherent conflict" which ran counter to Indonesian notions of harmony as being the natural state of human relationships. Instead, he sought a system based on the traditional village system of discussion and consensus, under the guidance of village elders. He proposed a threefold blend of "nasionalisme" ('nationalism'), "agama" ('religion'), and "komunisme" ('communism') into a co-operative 'Nas-A-Kom' government. This was intended to appease the three main factions in Indonesian politics — the army, Islamic groups, and the communists. With the support of the military, he proclaimed in February 1957 a system of 'Guided Democracy', and proposed a cabinet representing all the political parties of importance (including the PKI). The US tried and failed to secretly overthrow the President, even though Secretary of State Dulles declared before Congress that "we are not interested in the internal affairs of this country."

Sukarno abrogated the 1950 Constitution on 9 July 1959 by a decree dissolving the Constitutional Assembly and restoring the 1945 Constitution. The elected parliament was replaced by one appointed by, and subject to the will of, the President. Another non-elected body, the Supreme Advisory Council, was the main policy development body, while the National Front was set up in September 1960 and presided over by the president to "mobilise the revolutionary forces of the people". Western-style parliamentary democracy was thus finished in Indonesia until the 1999 elections of the "Reformasi" era.

Charismatic Sukarno spoke as a romantic revolutionary, and under his increasingly authoritarian rule, Indonesia moved on a course of stormy nationalism. Sukarno was popularly referred to as "bung" ("older brother"), and he painted himself as a man of the people carrying the aspirations of Indonesia and one who dared take on the West. He instigated a number of large, ideologically driven infrastructure projects and monuments celebrating Indonesia's identity, which were criticised as substitutes for real development in a deteriorating economy.

Western New Guinea had been part of the Dutch East Indies, and Indonesian nationalists had thus claimed it on this basis. Indonesia was able to instigate a diplomatic and military confrontation with the Dutch over the territory following an Indonesian-Soviet arms agreement in 1960. It was, however, United States pressure on the Netherlands that led to an Indonesian takeover in 1963. Also in 1963, Indonesia commenced "Konfrontasi" with the new state of Malaysia. The northern states of Borneo, formerly British Sarawak and Sabah, had wavered in joining Malaysia, whilst Indonesia saw itself as the rightful ruler of Austronesian peoples and supported an unsuccessful revolution attempt in Brunei. Reviving the glories of the Indonesian National Revolution, Sukarno rallied against notions of British imperialism and mounted military offensives along the Indonesia-Malaysia border in Borneo. As the PKI rallied in Jakarta streets in support, the West became increasingly alarmed at Indonesian foreign policy and the United States withdrew its aid to Indonesia.

In social policy, Sukarno's time in office witnessed substantial reforms in health and education, together with the passage of various pro-labour measures. However, Indonesia's economic position deteriorated under Sukarno; by the mid-1960s, the cash-strapped government had to scrap critical public sector subsidies, inflation was at 1,000%, export revenues were shrinking, infrastructure crumbling, and factories were operating at minimal capacity with negligible investment. Severe poverty and hunger were widespread.

Described as the great "dalang" ("puppet master"), Sukarno's position depended on balancing the opposing and increasingly hostile forces of the army and the PKI. Sukarno's anti-imperialist ideology saw Indonesia increasingly dependent on Soviet and then communist China. By 1965, the PKI was the largest communist party in the world outside the Soviet Union or China. Penetrating all levels of government, the party increasingly gained influence at the expense of the army.

On 30 September 1965, six of the most senior generals within the military and other officers were executed in an attempted coup. The insurgents, known later as the 30 September Movement, backed a rival faction of the army and took up positions in the capital, later seizing control of the national radio station. They claimed they were acting against a plot organised by the generals to overthrow Sukarno. Within a few hours, Major General Suharto, commander of the Army Strategic Reserve (Kostrad), mobilised counteraction, and by the evening of 1 October, it was clear that the coup, which had little co-ordination and was largely limited to Jakarta, had failed. Complicated and partisan theories continue to this day over the identity of the attempted coup's organisers and their aims. According to the Indonesian army, the PKI were behind the coup and used disgruntled army officers to carry it out, and this became the official account of Suharto's subsequent New Order administration. Most historians agree that the coup and the surrounding events were not led by a single mastermind controlling all events, and that the full truth will never likely be known.

The PKI was blamed for the coup, and anti-communists, initially following the army's lead, went on a violent anti-communist purge across much of the country. The PKI was effectively destroyed, and the most widely accepted estimates are that between 500,000 and 1 million were killed. The violence was especially brutal in Java and Bali. The PKI was outlawed and possibly more than 1 million of its leaders and affiliates were imprisoned.

Throughout the 1965–66 period, President Sukarno attempted to restore his political position and shift the country back to its pre-October 1965 position but his Guided Democracy balancing act was destroyed with the PKI's demise. Although he remained president, the weakened Sukarno was forced to transfer key political and military powers to General Suharto, who by that time had become head of the armed forces. In March 1967, the Provisional People's Consultative Assembly (MPRS) named General Suharto acting president. Suharto was formally appointed president in March 1968. Sukarno lived under virtual house arrest until his death in 1970.

In the aftermath of Suharto's rise, hundreds of thousands of people were killed or imprisoned by the military and religious groups in a backlash against alleged communist supporters, with direct support from the United States. Suharto's administration is commonly called the "New Order" era. Suharto invited major foreign investment, which produced substantial, if uneven, economic growth. However, Suharto enriched himself and his family through business dealings and widespread corruption.

At the time of independence, the Dutch retained control over the western half of New Guinea (also known as West Irian), and permitted steps towards self-government and a declaration of independence on 1 December 1961. After negotiations with the Dutch on the incorporation of the territory into Indonesia failed, an Indonesian paratroop invasion 18 December preceded armed clashes between Indonesian and Dutch troops in 1961 and 1962. In 1962 the United States pressured the Netherlands into secret talks with Indonesia which in August 1962 produced the New York Agreement, and Indonesia assumed administrative responsibility for West Irian on 1 May 1963.

Rejecting UN supervision, the Indonesian government under Suharto decided to settle the question of West Irian, the former Dutch New Guinea, in their favour. Rather than a referendum of all residents of West Irian as had been agreed under Sukarno, an 'Act of Free Choice' was conducted in 1969 in which 1,025 Papuan representatives of local councils were selected by the Indonesians. They were warned to vote in favour of Indonesian integration with the group unanimously voting for integration with Indonesia. A subsequent UN General Assembly resolution confirmed the transfer of sovereignty to Indonesia.

West Irian was renamed Irian Jaya ('glorious Irian') in 1973. Opposition to Indonesian administration of Irian Jaya (later known as Papua) gave rise to guerrilla activity in the years following Jakarta's assumption of control.

In 1975, the Carnation Revolution in Portugal caused authorities there to announce plans for decolonisation of Portuguese Timor, the eastern half of the island of Timor whose western half was a part of the Indonesian province of East Nusa Tenggara. In the East Timorese elections held in 1975, Fretilin, a left-leaning party, and UDT, aligned with the local elite, emerged as the largest parties, having previously formed an alliance to campaign for independence from Portugal. Apodeti, a party advocating integration with Indonesia, enjoyed little popular support.

Indonesia alleged that Fretilin was communist, and feared that an independent East Timor would influence separatism in the archipelago. Indonesian military intelligence influenced the break-up of the alliance between Fretilin and UDT, which led to a coup by the UDT on 11 August 1975 and the start of a month-long civil war. During this time, the Portuguese government effectively abandoned the territory and did not resume the decolonisation process. On 28 November, Fretilin unilaterally declared independence, and proclaimed the 'Democratic Republic of East Timor'. Nine days later, on 7 December, Indonesia invaded East Timor, eventually annexing the tiny country of (then) 680,000 people. Indonesia was supported materially and diplomatically by the United States, Australia, and the United Kingdom, who regarded Indonesia as an anti-communist ally.

Following the 1998 resignation of Suharto, the people of East Timor voted overwhelmingly for independence in a UN-sponsored referendum held on 30 August 1999. About 99% of the eligible population participated; more than three quarters chose independence despite months of attacks by the Indonesian military and its militia. After the result was announced, elements of the Indonesian military and its militia retaliated by killing approximately 2,000 East Timorese, displacing two-thirds of the population, raping hundreds of women and girls, and destroying much of the country's infrastructure. In October 1999, the Indonesian parliament (MPR) revoked the decree that annexed East Timor, and the United Nations Transitional Administration in East Timor (UNTAET) assumed responsibility for governing East Timor until it officially became an independent state in May 2002.

The Transmigration program ("Transmigrasi") was a National Government initiative to move landless people from densely populated areas of Indonesia (such as Java and Bali) to less populous areas of the country including Papua, Kalimantan, Sumatra, and Sulawesi. The stated purpose of this program was to reduce the considerable poverty and overpopulation on Java, to provide opportunities for hard-working poor people, and to provide a workforce to better utilise the resources of the outer islands. The program, however, has been controversial, with critics accusing the Indonesian Government of trying to use these migrants to reduce the proportion of native populations in destination areas to weaken separatist movements. The program has often been cited as a major and ongoing factor in controversies and even conflict and violence between settlers and indigenous populations.

In 1996 Suharto undertook efforts to pre-empt a challenge to the New Order government. The Indonesian Democratic Party (PDI), a legal party that had traditionally propped up the regime, had changed direction and began to assert its independence. Suharto fostered a split over the leadership of PDI, backing a co-opted faction loyal to deputy speaker of the People's Representative Council Suryadi against a faction loyal to Megawati Sukarnoputri, the daughter of Sukarno and the PDI's chairperson.

After the Suryadi faction announced a party congress to sack Megawati would be held in Medan on 20–22 June, Megawati proclaimed that her supporters would hold demonstrations in protest. The Suryadi faction went through with its sacking of Megawati, and the demonstrations manifested themselves throughout Indonesia. This led to several confrontations on the streets between protesters and security forces, and recriminations over the violence. The protests culminated in the military allowing Megawati's supporters to take over PDI headquarters in Jakarta, with a pledge of no further demonstrations.

Suharto allowed the occupation of PDI headquarters to go on for almost a month, as attentions were also on Jakarta due to a set of high-profile ASEAN meetings scheduled to take place there. Capitalizing on this, Megawati supporters organised "democracy forums" with several speakers at the site. On 26 July, officers of the military, Suryadi, and Suharto openly aired their disgust with the forums.

On 27 July, police, soldiers, and persons claiming to be Suryadi supporters stormed the headquarters. Several Megawati supporters were killed, and over two hundred people were arrested and tried under the Anti-Subversion and Hate-Spreading laws. The day would become known as "Black Saturday" and mark the beginning of a renewed crackdown by the New Order government against supporters of democracy, now called the "Reformasi" or Reform movement.

In 1997 and 1998, Indonesia was the country hardest hit by the 1997 Asian financial crisis, which had dire consequences for the Indonesian economy and society, as well as Suharto's presidency. At the same time, the country suffered a severe drought and some of the largest forest fires in history burned in Kalimantan and Sumatra. The rupiah, the Indonesian currency, took a sharp dive in value. Suharto came under scrutiny from international lending institutions, chiefly the World Bank, International Monetary Fund (IMF) and the United States, over longtime embezzlement of funds and some protectionist policies. In December, Suharto's government signed a letter of intent to the IMF, pledging to enact austerity measures, including cuts to public services and removal of subsidies, in return for aid from the IMF and other donors. Prices for goods such as kerosene and rice, as well as fees for public services including education, rose dramatically. The effects were exacerbated by widespread corruption. The austerity measures approved by Suharto had started to erode domestic confidence with the New Order and led to popular protests.

Suharto stood for re-election by parliament for the seventh time in March 1998, justifying it on the grounds of the necessity of his leadership during the crisis. The parliament approved a new term. This sparked protests and riots throughout the country, now termed the Indonesian 1998 Revolution. Dissent within the ranks of his own Golkar party and the military finally weakened Suharto, and on 21 May he stood down from power. He was replaced by his deputy, Vice President B.J. Habibie.

President Habibie quickly assembled a cabinet. One of its main tasks was to re-establish International Monetary Fund and donor community support for an economic stabilisation program. He moved quickly to release political prisoners and lift some controls on freedom of speech and association. Elections for the national, provincial, and sub-provincial parliaments were held on 7 June 1999. In the elections for the national parliament, the Indonesian Democratic Party of Struggle (PDI-P, led by Sukarno's daughter Megawati Sukarnoputri) won 34% of the vote; Golkar (Suharto's party, formerly the only legal party of government) 22%; United Development Party (PPP, led by Hamzah Haz) 12%; and National Awakening Party (PKB, led by Abdurrahman Wahid) 10%.

The May 1998 riots of Indonesia also known as the 1998 tragedy or simply the 1998 event, were incidents of mass violence, demonstrations, and civil unrest of a racial nature that occurred throughout Indonesia

In October 1999, the People's Consultative Assembly (MPR), which consists of the 500-member Parliament plus 200 appointed members, elected Abdurrahman Wahid, commonly referred to as "Gus Dur", as President, and Megawati Sukarnoputri as Vice-President, both for five-year terms. Wahid named his first Cabinet in early November 1999 and a reshuffled, second Cabinet in August 2000. President Wahid's government continued to pursue democratisation and to encourage renewed economic growth under challenging conditions. In addition to continuing economic malaise, his government faced regional, interethnic, and interreligious conflict, particularly in Aceh, the Maluku Islands, and Irian Jaya. In West Timor, the problems of displaced East Timorese and violence by pro-Indonesian East Timorese militias caused considerable humanitarian and social problems. An increasingly assertive Parliament frequently challenged President Wahid's policies and prerogatives, contributing to a lively and sometimes rancorous national political debate.
During the People's Consultative Assembly's first annual session in August 2000, President Wahid gave an account of his government's performance. On 29 January 2001, thousands of student protesters stormed parliament grounds and demanded that President Abdurrahman Wahid resign due to alleged involvement in corruption scandals. Under pressure from the Assembly to improve management and co-ordination within the government, he issued a presidential decree giving Vice-President Megawati control over the day-to-day administration of government. Soon after, Megawati Sukarnoputri assumed the presidency on 23 July. Susilo Bambang Yudhoyono won Indonesia's first direct presidential election in 2004, and was reelected in 2009.

Joko Widodo, the PDI-P candidate, was elected president in 2014. Having previously served as the Governor of Jakarta, he is the first Indonesian president without a high-ranking political or military background. However, his opponent Prabowo Subianto disputed the outcome and withdrew from the race before the count was completed. Jokowi was reelected in 2019, again defeating Prabowo Subianto.

As a multi-ethnic and multi-culture democratic country with a majority of moderate Muslim population, Indonesia faces the challenges to deal with terrorism that is linked to global militant Islamic movement. The Jemaah Islamiyah (JI), a militant Islamic organisation that aspired for the establishment of a Daulah Islamiyah that encompassed whole Southeast Asia including Indonesia, is responsible for a series of terrorist attacks in Indonesia. This terrorist organisation that is linked to Al-Qaeda, was responsible for the Bali bombings in 2002 and 2005, as well as Jakarta bombings in 2003, 2004, and 2009. The Indonesian government, people and authorities has ever since tried to crack down the terrorist cells in Indonesia.

On 14 January 2016, Indonesia encountered a terrorist attack in Jakarta. Suicide bombers and gunmen initiated the attack, which resulted in the death of seven people; an Indonesian, a Canadian and the rest were the attackers themselves. Twenty people were wounded from the attack. The assault was claimed as an act by the Islamic state.

On 26 December 2004, a massive earthquake and tsunami devastated parts of northern Sumatra, particularly Aceh. Partly as a result of the need for co-operation and peace during the recovery from the tsunami in Aceh, peace talks between the Indonesian government and the Free Aceh Movement (GAM) were restarted. Accords signed in Helsinki created a framework for military de-escalation in which the government has reduced its military presence, as members of GAM's armed wing decommission their weapons and apply for amnesty. The agreement also allows for Acehnese nationalist forces to form their own party, and other autonomy measures.

Since 1997 Indonesia has been struggling to contain forest fires, especially on the islands of Sumatra and Kalimantan. Haze occurs annually during the dry season and is largely caused by illegal agricultural fires due to slash-and-burn practices in Indonesia, especially in the provinces of South Sumatra and Riau on Indonesia's Sumatra island, and Kalimantan on Indonesian Borneo. The haze that occurred in 1997 was one of the most severe; dense hazes occurred again in 2005, 2006, 2009, 2013, and the worst was in 2015, killing dozens of Indonesians as a result of respiratory illnesses and road accidents due to poor visibility. Another 10 people were killed due to smog from forest and land fires.

In September 2014, Indonesia ratified the ASEAN Agreement on Transboundary Haze Pollution, becoming the last ASEAN country to do so.





</doc>
<doc id="14644" url="https://en.wikipedia.org/wiki?curid=14644" title="Geography of Indonesia">
Geography of Indonesia

Indonesia is an archipelagic country located in Southeast Asia, lying between the Indian Ocean and the Pacific Ocean. It is located in a strategic location astride or along major sea lanes connecting East Asia, South Asia and Oceania. Indonesia is the largest archipelago in the world. Indonesia's various regional cultures have been shaped—although not specifically determined—by centuries of complex interactions with its physical environment.

Indonesia is an archipelagic country extending about from east to west and from north to south. According to a geospatial survey conducted between 2007 and 2010 by National Coordinating Agency for Survey and Mapping (Bakosurtanal), Indonesia has 13,466 islands. While earlier survey conducted in 2002 by National Institute of Aeronautics and Space (LAPAN) stated Indonesia has 18,307 islands. According to the CIA World Factbook, there are 17,508 islands. The discrepancy between the surveys is likely caused by the earlier different survey method including tidal islands, sandy cays and rocky reefs that surface during low tide and submerge during high tide. There are 8,844 named islands according to estimates made by the government of Indonesia, with 922 of those are permanently inhabited. It comprises five main islands: Sumatra, Java, Borneo (known as "Kalimantan" in Indonesia), Sulawesi, and New Guinea; two major island groups (Nusa Tenggara and the Maluku Islands) and sixty smaller island groups. Four of the islands are shared with other countries: Borneo is shared with Malaysia and Brunei; Sebatik, located off the northeastern coast of Kalimantan, shared with Malaysia; Timor is shared with East Timor; and New Guinea is shared with Papua New Guinea.

Indonesia has total land area of , Including of inland seas (straits, bays, and other bodies of water). This makes it the largest island country in the world. The additional surrounding sea areas bring Indonesia's generally recognised territory (land and sea) to about 5 million km. The government claims an exclusive economic zone of . This brings the total area to about 7.9 million km.

Indonesia is a transcontinental country, where its territory consisted of islands geologically considered as part of either Asia or Australia. During the Pleistocene, the Greater Sunda Islands were connected to the Asian mainland while New Guinea was connected to Australia. Karimata Strait, Java Sea and Arafura Sea were formed as the sea level rose at the end of the Pleistocene.

The main islands of Sumatra, Java, Madura, and Kalimantan lie on the Sunda Plate and geographers have conventionally grouped them, (along with Sulawesi), as the Greater Sunda Islands. At Indonesia's eastern extremity is western New Guinea, which lies on the Australian Plate. Sea depths in the Sunda and Sahul shelves average or less. Between these two shelves lie Sulawesi, Nusa Tenggara (also known as the Lesser Sunda Islands), and the Maluku Islands (or the Moluccas), which form a second island group with deep, surrounding seas down to in depth. The term "Outer Islands" is used inconsistently by various writers but it is usually taken to mean those islands other than Java and Madura.

Sulawesi is an island lies on three separate plates, the Banda Sea Plate, Molucca Sea Plate, and Sunda Plate. Seismic and volcanic activities are high on its northeastern part, evidenced by the formation of volcanoes in North Sulawesi and island arcs such as the Sangihe and Talaud Islands, southwest of the Philippine Trench.

Nusa Tenggara or Lesser Sunda Islands consists of two strings of islands stretching eastward from Bali toward southern Maluku. The inner arc of Nusa Tenggara is a continuation of the Alpide belt chain of mountains and volcanoes extending from Sumatra through Java, Bali, and Flores, and trailing off in the volcanic Banda Islands, which along with the Kai Islands and the Tanimbar Islands and other small islands in the Banda Sea are typical examples of the Wallacea mixture of Asian and Australasian plant and animal life. The outer arc of Nusa Tenggara is a geological extension of the chain of islands west of Sumatra that includes Nias, Mentawai, and Enggano. This chain resurfaces in Nusa Tenggara in the ruggedly mountainous islands of Sumba and Timor.

The Maluku Islands (or Moluccas) are geologically among the most complex of the Indonesian islands, consisted of four different tectonic plates. They are located in the northeast sector of the archipelago, bounded by the Philippine Sea to the north, Papua to the east, and Nusa Tenggara to the southwest. The largest of these islands include Halmahera, Seram and Buru, all of which rise steeply out of very deep seas and have unique Wallacea vegetation. This abrupt relief pattern from sea to high mountains means that there are very few level coastal plains. To the south lies the Banda Sea. The convergence between the Banda Sea Plate and Australian Plate created a chain of volcanic islands called the Banda Arc. The sea also contains the Weber Deep, one of the deepest point in Indonesia.

Geomorphologists believe that the island of New Guinea is part of the Australian continent, both lies on Sahul Shelf and once joined via a land bridge during the Last glacial period. The tectonic movement of the Australian Plate created towering, snowcapped mountain peaks lining the island's central east-west spine and hot, humid alluvial plains along the coasts. The New Guinea Highlands range some east to west along the island, forming a mountainous spine between the northern and southern portion of the island. Due to its tectonic movement, New Guinea experienced many earthquakes and tsunamis, especially in its northern and western part.

Most of the larger islands are mountainous, with peaks ranging between meters above sea level in Sumatra, Java, Bali, Lombok, Sulawesi, and Seram. The country's tallest mountains are located in the Jayawijaya Mountains and the Sudirman Range in Papua. The highest peak, Puncak Jaya (, is located in the Sudirman Mountains. A string of volcanoes stretches from Sumatra to Nusa Tenggara, and then loops around through to the Banda Islands of Maluku to northeastern Sulawesi. Of the 400 volcanoes, approximately 150 are active. Two of the most violent volcanic eruptions in modern times occurred in Indonesia; in 1815 Mount Tambora in Sumbawa erupted killing 92,000 and in 1883, Krakatau, erupted killing 36,000. While volcanic ashes resulted from eruption has positive effects for the fertility of the surrounding soils, it also makes agricultural conditions unpredictable in some areas.Indonesia has relatively high tectonic and volcanic activities. It lies on the convergence between the Eurasian, Indo-Australian, Pacific, and Philippine Sea Plate. The Sunda megathrust is a 5,500 km long fault located off southern coasts of Sumatra, Java and Lesser Sunda Islands, where the Pacific Plate is thrusting northeastward towards the subducting Sunda Plate. Tectonic movement in this fault is responsible for the creation of the Sunda Trench, and mountain ranges across Sumatra, Java, and the Lesser Sunda Islands. Many great earthquakes occurred in the vicinity of the fault, such as the 2004 Indian Ocean earthquake. Mount Merapi, located in the Java portion of the megathrust, is the most active volcano in Indonesia and is designated as one of world's Decade Volcanoes due to the hazard it poses to the surrounding populated areas.

The northern part of Sulawesi and Maluku Islands lie on the convergence of Sunda Plate and Molucca Sea Plate, making it an active tectonic region with volcanic chains such as the Sangihe and Talaud Islands. Northern Maluku and western New Guinea is located on the convergence of Bird's Head, Philippine Sea and Caroline Plate. It is also a seismically active region, with the 7.6 M 2009 Papua earthquakes being the most recent great earthquake to date in the region.

Borneo is the third largest island in the world and the native vegetation was mostly Borneo lowland rain forests although much of this has been cleared with wildlife retreating to the Borneo montane rain forests inland. The islands of North Maluku are the original Spice Islands, a distinct rainforest ecoregion. A number of islands off the coast of New Guinea have their own distinctive biogeographic features, including the limestone islands of Biak, in the entrance to the large Cenderawasih Bay at the northwest end of the island.

Indonesia is divided into three time zones: 

Lying along the equator, Indonesia's climate tends to be relatively even year-round. Indonesia has two seasons—a wet season and a dry season—with no extremes of summer or winter. For most of Indonesia, the dry season falls between May and October while the wet season between November and April.

Some regions, such as Kalimantan and Sumatra, experience only slight differences in rainfall and temperature between the seasons, whereas others, such as Nusa Tenggara, experience far more pronounced differences with droughts in the dry season, and floods in the wet. Rainfall in Indonesia is plentiful, particularly in west Sumatra, northwest Kalimantan, west Java, and western New Guinea.

Parts of Sulawesi and some islands closer to Australia, such as Sumba and Timor, are drier, however, these are exceptions. The almost uniformly warm waters that make up 81% of Indonesia's area ensure that temperatures on land remain fairly constant. The coastal plains averaging , the inland and mountain areas averaging , and the higher mountain regions, . The area's relative humidity ranges between 70 and 90%.

Winds are moderate and generally predictable, with monsoons usually blowing in from the south and east in June through October and from the northwest in November through March. Typhoons and large scale storms pose little hazard to mariners in Indonesia waters; the major danger comes from swift currents in channels, such as the Lombok and Sape straits.

Indonesia's climate is almost entirely tropical, dominated by the tropical rainforest climate found in every major island of Indonesia, followed by the tropical monsoon climate that predominantly lies along Java's coastal north, Sulawesi's coastal south and east, and Bali, and finally the tropical savanna climate, found in isolated locations of Central Java, lowland East Java, coastal southern Papua and smaller islands to the east of Lombok.

However, cooler climate types do exist in mountainous regions of Indonesia 1,300–1,500 metres above sea level. The oceanic climate (Köppen "Cfb") prevail in highland areas with fairly uniform precipitation year-round, adjacent to rainforest climates, while the subtropical highland climate (Köppen "Cwb") exist in highland areas with a more pronounced dry season, adjacent to tropical monsoon and savanna climates.

Above 3000 metres is where cold, subpolar climates dominate and where frost and occasional snow become more commonplace. The subpolar oceanic climate (Köppen "Cfc"), existing between 3,000 and 3,500 metres, can be found on the mountain slopes of Indonesia's highest peaks, and serves as a transition between oceanic climates and tundra climates. Tundra climates (Köppen "ET"), are found anywhere above 3500 metres on the highest peaks of Indonesia, including the permanently snow-capped peaks in Papua. In this climate regime, average monthly temperatures are all below 10 °C, and monthly precipitation is uniform.

Indonesia's high population and rapid industrialisation present serious environmental issues, which are often given a lower priority due to high poverty levels and weak, under-resourced governance. Issues include large-scale deforestation (much of it illegal) and related wildfires causing heavy smog over parts of western Indonesia, Malaysia and Singapore; over-exploitation of marine resources; and environmental problems associated with rapid urbanisation and economic development, including air pollution, traffic congestion, garbage management, and reliable water and waste water services.

Deforestation and the destruction of peatlands make Indonesia the world's third largest emitter of greenhouse gases. Habitat destruction threatens the survival of indigenous and endemic species, including 140 species of mammals identified by the World Conservation Union (IUCN) as threatened, and 15 identified as critically endangered, including the Sumatran Orangutan.

In 1970, 15% of Indonesians lived in cities compared to over 30% today, and this increases pressure on the urban environment. Industrial pollution is increasing, particularly in Java, and the increasing affluence of the growing middle class drives a rapid increase in the number of motor vehicles and associated emissions. Garbage and waste water services are being placed under increasing pressure. Reliance on septic systems or effluent disposal in open canals and river systems remains the norm, and is a major polluter of water resources. Very few Indonesians have access to safe drinking water and must boil water before use.

The geographical resources of the Indonesian archipelago have been exploited in ways that fall into consistent social and historical patterns. One cultural pattern consists of the formerly Indianized, rice-growing peasants in the valleys and plains of Sumatra, Java, and Bali, another cultural complex is composed of the largely Islamic coastal commercial sector, a third, more marginal sector consists of the upland forest farming communities which exist by means of subsistence swidden agriculture. To some degree, these patterns can be linked to the geographical resources themselves, with abundant shoreline, generally calm seas, and steady winds favouring the use of sailing vessels, and fertile valleys and plains—at least in the Greater Sunda Islands—permitting irrigated rice farming. The heavily forested, mountainous interior hinders overland communication by road or river, but fosters slash-and-burn agriculture.

Area:
<br>"total land area:" 1,904,569 km ("land:" 1,811,569 km,
"inland water:" 93,000 km) (35,907 mi)

Area - comparative:


Land boundaries:

Coastline: 

Maritime claims: measured from claimed archipelagic baselines
<br>"territorial sea:" 
<br>"exclusive economic zone:" with 

Elevation extremes:
<br>"lowest point:" Sea level at 0 m (sea surface level); southern portion of the Philippine Trench, east of Miangas at <br>"highest point:" Puncak Jaya (also known as "Carstensz Pyramid") 4,884 m

Land use:
<br>"arable land:" 12.97%
<br>"permanent crops:" 12.14%
<br>"other:" 74.88% (2013)

Irrigated land: 67,220 km (2005) (25,953 mi)

Total renewable water resources: 2,019 km (2011) (484 mi)

Freshwater withdrawal (domestic/industrial/agricultural):
<br>"total:" 113.3 km/yr (11%/19%/71%)
<br>"per capita:" 517.3 m/yr (2005)

Natural resources: coal, petroleum, natural gas, tin, nickel, timber, bauxite, copper, fertile soils, gold, silver




</doc>
<doc id="14645" url="https://en.wikipedia.org/wiki?curid=14645" title="Demographics of Indonesia">
Demographics of Indonesia

The population of Indonesia was 237.64 million according to the 2010 national census, and it was estimated to have reached 255.18 million at the official Inter-census Survey in 2015. Fifty-eight per cent live on the island of Java, the world's most populous island.

Despite a fairly effective family planning program that has been in place since 1967, Indonesia's population growth was 1.49% for the decade ending in 2010. At that rate, Indonesia's population is projected to surpass the present population of the United States. Some say family planning should be revitalised based on the 1967 program to avoid Indonesia becoming the world's third most populous country, but this aim has been criticised by religious groups who believe that family planning goes against religious teachings.

Indonesia has a relatively young population compared to Western nations, though it is ageing as the country's birth rate has slowed and its life expectancy has increased. The median age was 30.2 years in 2017.
Indonesia includes numerous ethnic, cultural and linguistic groups, some of which are related to each other. Since independence, Indonesian (a form of Malay and the official national language) is the language of most written communication, education, government, and business. Many local ethnic languages are the first language of most Indonesians and are still important.

Source: Population Census 2010, except for final column, taken from Inter-Census Survey 2015.

Note: North Kalimantan province was created in 2012 (by separation from East Kalimantan province); the 2010 total figures given are those for the provinces as they were following that splitting (Urban % and Total Fertility Rate columns unadjusted).

Total Fertility Rate (TFR) (Wanted Fertility Rate) and Crude Birth Rate (CBR):

Total fertility rate (TFR) and population over age 60 by region as of 2010:

Source: "UN World Population Prospects"

There are over 300 ethnic groups in Indonesia; 95% of those are of Native Indonesian ancestry. Javanese is the largest group with 100 million people (42%), followed by Sundanese, who number nearly 40 million (15%).

Indonesia is the world's most populous Muslim-majority nation; almost 87.18% of Indonesians declared themselves Muslim in the 2010 census. 9.87% of the population adhered to Christianity (of which more than 70% were Protestant), 1.69% were Hindu, 0.72% Buddhist, and 0.56 of other faiths. Most Indonesian Hindus are Balinese and most Buddhists in modern-day Indonesia are Chinese.

Indonesian is the official language, but there are many different languages native to Indonesia. According to Ethnologue, there are currently 737 living languages spoken in Indonesia, the most widely spoken being Javanese.

Some Chinese varieties, most prominently Min Nan, are also spoken. The public use of Chinese, especially Chinese characters, was officially discouraged between 1966 and 1998.

"definition:" age 15 and over can read and write
"total population:" 92.81%
"male:" 95.5%
"female:" 90.4% (2011 est.)

Education is free in state schools; it is compulsory for children through to grade 12. Although about 92% of eligible children are enrolled in primary school, a much smaller percentage attends full-time. About 44% of secondary school-age children attend junior high school, and some others of this age group attend vocational schools.

The following demographic statistics are from the CIA World Factbook, unless otherwise indicated.

Age structure

Median age

Birth rate

Death rate

Population growth rate

Urbanization

Sex ratio

Infant mortality rate

Life expectancy at birth

HIV/AIDS

Obesity - adult prevalence rate

Children under the age of 5 years underweight

Nationality

Religions

Languages

School life expectancy (primary to tertiary education)

Education expenditures




</doc>
<doc id="14646" url="https://en.wikipedia.org/wiki?curid=14646" title="Politics of Indonesia">
Politics of Indonesia

The politics of Indonesia take place in the framework of a presidential representative democratic republic whereby the President of Indonesia is both head of state and head of government and of a multi-party system. Executive power is exercised by the government. Legislative power is vested in both the government and the two People's Representative Councils. The judiciary is independent of the executive and the legislature.

The 1945 constitution provided for a limited separation of executive, legislative and judicial power. The governmental system has been described as "presidential with parliamentary characteristics". Following the Indonesian riots of May 1998 and the resignation of President Suharto, several political reforms were set in motion via amendments to the Constitution of Indonesia, which resulted in changes to all branches of government.

An era of Liberal Democracy () in Indonesia began on 17 August 1950 following the dissolution of the federal United States of Indonesia less than a year after its formation, and ended with the imposition of martial law and President Sukarno's 1959 Decree regarding the introduction of Guided Democracy () on 5 July. It saw a number of important events, including the 1955 Bandung Conference, Indonesia's first general and Constitutional Assembly elections, and an extended period of political instability, with no cabinet lasting as long as two years.

From 1957, Guided Democracy was the political system in place until the New Order began in 1966. It was the brainchild of President Sukarno, and was an attempt to bring about political stability. He believed that Western-style democracy was inappropriate for Indonesia's situation. Instead, he sought a system based on the traditional village system of discussion and consensus, which occurred under the guidance of village elders.

The transition to the "New Order" in the mid-1960s, ousted Sukarno after 22 years in the position. One of the most tumultuous periods in the country's modern history, it was the commencement of Suharto's three-decade presidency. Described as the great "dhalang" ("puppet master"), Sukarno drew power from balancing the opposing and increasingly antagonistic forces of the army and the Communist Party of Indonesia (PKI).

By 1965, the PKI extensively penetrated all levels of government and gained influence at the expense of the army. On 30 September 1965, six of the military's most senior officers were killed in an action (generally labelled an "attempted coup") by the so-called 30 September Movement, a group from within the armed forces. Within a few hours, Major General Suharto mobilised forces under his command and took control of Jakarta. Anti-communists, initially following the army's lead, went on a violent purge of communists throughout the country, killing an estimated half million people and destroying the PKI, which was officially blamed for the crisis.

The politically weakened Sukarno was forced to transfer key political and military powers to General Suharto, who had become head of the armed forces. In March 1967, the Provisional People's Consultative Assembly (MPRS) named General Suharto acting president. He was formally appointed president one year later. Sukarno lived under virtual house arrest until his death in 1970. In contrast to the stormy nationalism, revolutionary rhetoric, and economic failure that characterised the early 1960s under the left-leaning Sukarno, Suharto's pro-Western "New Order" stabilised the economy but continued with the official state philosophy of "Pancasila".

The New Order () is the term coined by President Suharto to characterise his regime as he came to power in 1966. He used this term to contrast his rule with that of his predecessor, Sukarno (dubbed the "Old Order," or "Orde Lama"). The term "New Order" in more recent times has become synonymous with the Suharto years (1966–1998).

Immediately following the attempted coup in 1965, the political situation was uncertain, but the New Order found much popular support from groups wanting a separation from Indonesia's problems since its independence. The 'generation of 66' ("Angkatan 66") epitomised talk of a new group of young leaders and new intellectual thought. Following communal and political conflicts, and economic collapse and social breakdown of the late 1950s through to the mid-1960s, the New Order was committed to achieving and maintaining political order, economic development, and the removal of mass participation in the political process. The features of the New Order established from the late 1960s were thus a strong political role for the military, the bureaucratisation and corporatisation of political and societal organisations, and selective but effective repression of opponents. Strident anti-communism remained a hallmark of the regime for its subsequent 32 years.

Within a few years, however, many of its original allies had become indifferent or averse to the New Order, which comprised a military faction supported by a narrow civilian group. Among much of the pro-democracy movement which forced Suharto to resign in 1998 and then gained power, the term "New Order" has come to be used pejoratively. It is frequently employed to describe figures who were either tied to the New Order, or who upheld the practises of his authoritarian regime, such as corruption, collusion and nepotism (widely known by the acronym KKN: "korupsi", "kolusi", "nepotisme").

The Post-Suharto era began with the fall of Suharto in 1998 during which Indonesia has been in a period of transition, an era known as "Reformasi" (English: "Reform"). This period has seen a more open and liberal political-social environment.

A process of constitutional reform lasted from 1999 to 2002, with four amendments producing major changes. Among these are term limits of up to 2 five-year terms for the President and Vice-President, and measures to institute checks and balances. The highest state institution is the People's Consultative Assembly (, MPR), whose functions previously included electing the president and vice-president (since 2004 the president has been elected directly by the people), establishing broad guidelines of state policy, and amending the constitution. The 695-member MPR includes all 550 members of the People's Representative Council (, DPR) plus 130 members of Regional Representative Council (, DPD) elected by the 26 provincial parliaments and 65 appointed members from societal groups.

The DPR, which is the premier legislative institution, originally included 462 members elected through a mixed proportional/district representational system and thirty-eight appointed members of the Indonesian Armed Forces (TNI) and police (POLRI). TNI/POLRI representation in the DPR and MPR ended in 2004. Societal group representation in the MPR was eliminated in 2004 through further constitutional change. Having served as rubberstamp bodies in the past, the DPR and MPR have gained considerable power and are increasingly assertive in oversight of the executive branch. Under constitutional changes in 2004, the MPR became a bicameral legislature, with the creation of the DPD, in which each province is represented by four members, although its legislative powers are more limited than those of the DPR. Through his/her appointed cabinet, the president retains the authority to conduct the administration of the government.

A general election in June 1999 produced the first freely elected national, provincial and regional parliaments in over 40 years. In October 1999, the MPR elected a compromise candidate, Abdurrahman Wahid, as the country's fourth president, and Megawati Sukarnoputri—a daughter of Sukarno—as the vice-president. Megawati's PDI-P party had won the largest share of the vote (34%) in the general election, while Golkar, the dominant party during the New Order, came in second (22%). Several other, mostly Islamic parties won shares large enough to be seated in the DPR. Further democratic elections took place in 2004, 2009 and 2014.

The executive branch of Indonesia is headed by a president, who is head of government and head of state. The president is elected by general election and can serve up to two five-year terms if reelected. The executive branch also includes a vice-president and a cabinet. All bills need joint approval between the executive and the legislature to become law, meaning the president has veto power over all legislation. The president also has the power to issue presidential decrees that have policy effects, and they are also in charge of Indonesia's international relationships, although they require legislative approval for treaties. Prior to 2004, the president was chosen by the MPR, but the president is currently selected through national election. The last election was held in April 2019, and incumbent Joko Widodo emerged as the winner.

The MPR is the legislative branch of Indonesia's political system. The MPR is composed of two houses: the DPR, which is commonly called the People's Representative Council, and the DPD, which is called the Regional Representative Council. The 575 DPR parliamentarians are elected through multi-member electoral districts, whereas 4 DPD parliamentarians are elected in each of Indonesia's 34 provinces. The DPR holds most of the legislative power because it has the sole power to pass laws. The DPD acts as a supplementary body to the DPR; it can propose bills, offer its opinion and participate in discussions, but it has no legal power. The MPR itself has power outside of those given to the individual houses. It can amend the constitution, inaugurate the president and conduct impeachment procudures. When the MPR acts in this function, it does so by simply combining the members of the two houses.

The General Elections Commission (, "KPU") is the body that is responsible for running both parliamentary and presidential elections. Article 22E(5) of the Constitution rules that the KPU is national, permanent, and independent. Prior to the 2004 elections, the KPU was made up of members who were also members of political parties. However, members of KPU must now be non-partisan.

Both The Supreme Court of Indonesia () and The Constitutional Court ("Mahkamah Konstitusi") are the highest level of the judicial branch. The Constitutional Court ("Mahkamah Konstitusi") listens to disputes concerning legality of law, general elections, dissolution of political parties, and the scope of authority of state institution. It has 9 judges and its judges are appointed by the DPR, the President and the Supreme Court. The Supreme Court of Indonesia hears final cessation appeals and conducts case reviews. It has 51 judges divided into 8 chambers. Its judges are nominated by the Judicial Commission of Indonesia and appointed by the President. Most civil disputes appear before the State Court ("Pengadilan Negeri"); appeals are heard before the High Court ("Pengadilan Tinggi"). Other courts include the Commercial Court, which handles bankruptcy and insolvency; the State Administrative Court ("Pengadilan Tata Usaha Negara") to hear administrative law cases against the government; and the Religious Court ("Pengadilan Agama") to deal with codified Islamic Law ("sharia") cases. Additionally, the Judicial Commission ("Komisi Yudisial") monitors the performance of judges.

During the regime of president Suharto, Indonesia built strong relations with the United States and had difficult relations with the People's Republic of China owing to Indonesia's anti-communist policies and domestic tensions with the Chinese community. It received international denunciation for its annexation of East Timor in 1978. Indonesia is a founding member of the Association of South East Asian Nations, and thereby a member of both ASEAN+3 and the East Asia Summit.

Since the 1980s, Indonesia has worked to develop close political and economic ties between Southeast Asian countries, and is also influential in the Organisation of Islamic Cooperation. Indonesia was heavily criticised between 1975 and 1999 for allegedly suppressing human rights in East Timor, and for supporting violence against the East Timorese following the latter's secession and independence in 1999. Since 2001, the government of Indonesia has co-operated with the US in cracking down on Islamic fundamentalism and terrorist groups.





</doc>
<doc id="14647" url="https://en.wikipedia.org/wiki?curid=14647" title="Economy of Indonesia">
Economy of Indonesia

The economy of Indonesia is the largest in Southeast Asia and is one of the emerging market economies of the world. As an upper-middle income country and member of the G20 Indonesia is classified as a newly industrialised country. It is the 16th largest economy in the world by nominal GDP and the 7th largest in terms of GDP (PPP). Estimated at US$40 billion in 2019, Indonesia’s Internet economy is expected to cross the US$130 billion mark by 2025. Indonesia depends on domestic market and government budget spending and its ownership of state-owned enterprises (the central government owns 141 enterprises). The administration of prices of a range of basic goods (including rice and electricity) also plays a significant role in Indonesia's market economy. However, since the 1990s, the majority of the economy has been controlled by individual Indonesians and foreign companies.

In the aftermath of the 1997 Asian financial crisis, the government took custody of a significant portion of private sector assets through the acquisition of nonperforming bank loans and corporate assets through the debt restructuring process and the companies in custody were sold for privatisation several years later. Since 1999 the economy has recovered, and growth has accelerated to over 4–6% in recent years.

In 2012, Indonesia replaced India as the second-fastest-growing G-20 economy, behind China. Since then, the annual growth rate has slowed and has fluctuated around 5%.

In the years immediately following the proclamation of Indonesian independence, both the Japanese occupation and conflict between Dutch and Republican forces had crippled the country's production, with exports of commodities such as rubber and oil being reduced to 12 and 5% of their pre-WW2 levels, respectively. The first Republican government-controlled bank, the Indonesian State Bank ("Bank Negara Indonesia", BNI) was founded on 5 July 1946. It initially acted as the manufacturer and distributor of ORI ("Oeang Republik Indonesia"/Money of the Republic of Indonesia), a currency issued by the Republican Government which was the predecessor of Rupiah. Despite this, currency issued during the Japanese occupation and by Dutch authorities was still in circulation, and the simplicity of the ORI made its counterfeiting relatively easy, worsening matters. Between 1949 and 1960, Indonesia experienced several economic disruptions. The country's independence recognised by the Netherlands, the dissolution of the United States of Indonesia in 1950, the subsequent liberal democracy period, the nationalisation of "De Javasche Bank" into the modern Bank Indonesia, and the takeover of Dutch corporate assets following the West New Guinea dispute,
which all resulted in the devaluation of Dutch banknotes into half their value.

During the guided democracy era in the 1960s, the economy deteriorated drastically as a result of political instability. The government was inexperienced in implementing macro-economic policies, which resulted in severe poverty and hunger. By the time of Sukarno's downfall in the mid-1960s, the economy was in chaos with 1,000% annual inflation, shrinking export revenues, crumbling infrastructure, factories operating at minimal capacity, and negligible investment. Nevertheless, Indonesia's post-1960 economic improvement was considered remarkable when taking consideration of how few indigenous Indonesians in the 1950s had received a formal education under Dutch colonial policies.

Following President Sukarno's downfall, the New Order administration brought a degree of discipline to economic policy that quickly brought inflation down, stabilised the currency, rescheduled foreign debt, and attracted foreign aid and investment. (See Inter-Governmental Group on Indonesia and Berkeley Mafia). Indonesia was until recently Southeast Asia's only member of OPEC, and the 1970s oil price rise provided an export revenue windfall that contributed to sustained high economic growth rates, averaging over 7% from 1968 to 1981.

With high levels of regulation and dependence on declining oil prices, growth slowed to an average of 4.5% per annum between 1981 and 1988. A range of economic reforms was introduced in the late 1980s, including a managed devaluation of the rupiah to improve export competitiveness, and de-regulation of the financial sector. Foreign investment flowed into Indonesia, particularly into the rapidly developing export-oriented manufacturing sector, and from 1989 to 1997, the Indonesian economy grew by an average of over 7%. GDP per capita grew 545% from 1970 to 1980 as a result of the sudden increase in oil export revenues from 1973 to 1979. High levels of economic growth masked several structural weaknesses in the economy. It came at a high cost in terms of weak and corrupt governmental institutions, severe public indebtedness through mismanagement of the financial sector, the rapid depletion of natural resources, and culture of favours and corruption in the business elite.

Corruption particularly gained momentum in the 1990s, reaching to the highest levels of the political hierarchy as Suharto became the most corrupt leader according to Transparency International. As a result, the legal system was weak, and there was no effective way to enforce contracts, collect debts, or sue for bankruptcy. Banking practices were very unsophisticated, with collateral-based lending the norm and widespread violation of prudential regulations, including limits on connected lending. Non-tariff barriers, rent-seeking by state-owned enterprises, domestic subsidies, barriers to domestic trade and export restrictions all created economic distortions.

The 1997 Asian financial crisis that began to affect Indonesia became an economic and political crisis. The initial response was to float the rupiah, raise key domestic interest rates, and tighten fiscal policy. In October 1997, Indonesia and the International Monetary Fund (IMF) reached agreement on an economic reform program aimed at macroeconomic stabilisation and elimination of some of the country's most damaging economic policies, such as the National Car Program and the clove monopoly, both involving family members of Suharto. The rupiah remained weak, however, and Suharto was forced to resign in May 1998 after massive riots erupted. In August 1998, Indonesia and the IMF agreed on an Extended Fund Facility (EFF) under President B. J. Habibie that included significant structural reform targets. President Abdurrahman Wahid took office in October 1999, and Indonesia and the IMF signed another EFF in January 2000. The new program also has a range of economic, structural reform, and governance targets.

The effects of the crisis were severe. By November 1997, rapid currency depreciation had seen public debt reach US$60 billion, imposing severe strains on the government's budget. In 1998, real GDP contracted by 13.1%, and the economy reached its low point in mid-1999 with 0.8% real GDP growth. Inflation reached 72% in 1998 but slowed to 2% in 1999. The rupiah, which had been in the Rp 2,600/USD1 range at the start of August 1997 fell to 11,000/USD1 by January 1998, with spot rates around 15,000 for brief periods during the first half of 1998. It returned to the 8,000/USD1 range at the end of 1998 and has generally traded in the Rp 8,000–10,000/USD1 range ever since, with fluctuations that are relatively predictable and gradual. However, the rupiah began devaluing past 11,000 in 2013, and as of November 2016 is around 13,000 USD.

Since an inflation target was introduced in 2000, the GDP deflator and the CPI have grown at an average annual pace of 10¾% and 9%, respectively, similar to the pace recorded in the two decades prior to the 1997 crisis, but well below the pace in the 1960s and 1970s. Inflation has also generally trended lower through the 2000s, with some of the fluctuations in inflation reflecting government policy initiatives such as the changes in fiscal subsidies in 2005 and 2008, which caused large temporary spikes in CPI growth.

In late 2004, Indonesia faced a 'mini-crisis' due to international oil prices rises and imports. The currency exchange rate reached Rp 12,000/USD1 before stabilising. Under President Susilo Bambang Yudhoyono (SBY), the government was forced to cut its massive fuel subsidies, which were planned to cost $14 billion in October 2005. This led to a more than doubling in the price of consumer fuels, resulting in double-digit inflation. The situation had stabilised but the economy continued to struggle with inflation at 17% in late 2005. Economic outlook became more positive as the 2000s progressed. Growth accelerated to 5.1% in 2004 and reached 5.6% in 2005. Real per capita income has reached fiscal levels in 1996-1997. Growth was driven primarily by domestic consumption, which accounts for roughly three-fourths of Indonesia's gross domestic product (GDP). The Jakarta Stock Exchange was the best performing market in Asia in 2004, up by 42%. Problems that continue to put a drag on growth include low foreign investment levels, bureaucratic red tape, and widespread corruption which costs Rp. 51.4 trillion (US$5.6 billion) or approximately 1.4% of GDP annually. However, there is a robust economic optimism due to the conclusion of the peaceful 2004 elections.

As of February 2007, the unemployment rate was 9.75%. Despite a slowing global economy, Indonesia's economic growth accelerated to a ten-year high of 6.3% in 2007. This growth rate was sufficient to reduce poverty from 17.8% to 16.6% based on the government's poverty line and reversed the recent trend towards jobless growth, with unemployment falling to 8.46% in February 2008. Unlike many of its more export-dependent neighbours, Indonesia has managed to skirt the recession helped by strong domestic demand (which makes up about two-thirds of the economy) and a government fiscal stimulus package of about 1.4% of GDP. After India and China, Indonesia was the third-fastest growing economy in the G20. With the $512 billion economy expanded 4.4% in the first quarter from a year earlier and last month, the IMF revised its 2009 Indonesia forecast to 3–4% from 2.5%. Indonesia enjoyed stronger fundamentals with the authorities implemented wide-ranging economic and financial reforms, including a rapid reduction in public and external debt, strengthening of corporate and banking sector balance sheets and reducing bank vulnerabilities through higher capitalisation and better supervision.

In 2012, Indonesia's real GDP growth reached 6%, then it steadily decreased below 5% until 2015. After Joko Widodo succeeded SBY, the government took measures to ease regulations for foreign direct investments to stimulate the economy. Indonesia managed to increase their GDP growth slightly above 5% in 2016–2017. However, the government is currently still facing problems such as currency weakening, decreasing exports and stagnating consumer spending. The current unemployment rate for 2019 is at 5.3%.

Source: Indonesian Statistics Bureau (Biro Pusat Statistik), annual production data.

Agriculture is a key sector which contributed to 14.43% of GDP. Currently, there are around 30% of the land area used for agriculture and employed about 49 million people (41% of the total workforce). Primary agriculture commodities include rice, cassava (tapioca), peanuts, natural rubber, cocoa, coffee, palm oil, copra; poultry, beef, pork, and eggs. Palm oil production is vital to the economy as Indonesia is the world's biggest producer and consumer of the commodity, providing about half of the world's supply. Plantations in the country stretch across 6 million hectares as of 2007, with a replanting plan set for an additional 4.7 million to boost productivity in 2017. There are a number of negative social and environmental impacts of palm oil production in southeast Asia.

Indonesia was the only Asian member of the Organization of Petroleum Exporting Countries (OPEC) until 2008 and is currently a net oil importer. In 1999, crude and condensate output averaged per day, and in 1998, the oil and gas sector including refining, contributed approximately 9% to GDP. As of 2005, crude oil and condensate output were per day. It indicates a substantial decline from the 1990s, due primarily to ageing oil fields and a lack of investment in oil production equipment. This decline in production has been accompanied by a substantial increase in domestic consumption, about 5.4% per year, leading to an estimated US$1.2 billion cost for importing oil in 2005. The state owns all petroleum and mineral rights. Foreign firms participate through production-sharing and work contracts. Oil and gas contractors are required to finance all exploration, production, and development costs in their contract areas and are entitled to recover operating, exploration, and development costs out of the oil and gas produced. Indonesia had previously subsidised fuel prices to keep prices low, costing US$7 billion in 2004. SBY has mandated a significant reduction of government subsidy of fuel prices in several stages. The government has stated that cuts in subsidies are aimed at reducing the budget deficit to 1% of GDP in 2005, down from around 1.6% last year. At the same time, the government has offered one-time subsidies for qualified citizens, to alleviate hardships.

Indonesia is the world's largest tin market. Although mineral production traditionally centred on bauxite, silver, and tin, it is expanding its copper, nickel, gold, and coal output for export markets. In mid-1993, the "Department of Mines and Energy" reopened the coal sector to foreign investment, resulting in a joint venture between Indonesian coal producer and BP and Rio Tinto Group. Total coal production reached 74 million metric tons in 1999, including exports of 55 million tons, and in 2011, production was 353 million. As of 2014, Indonesia is the third-largest producer with a total output of 458 Mt and export of 382 Mt. At this rate, the reserves will be used up in 61 years until 2075. Not all of the productions can be exported due to Domestic Market Obligation (DMO) regulation, which should fulfil the domestic market. In 2012, the DMO was 24.72%. Starting from 2014, no low-grade coal exports are allowed, so the upgraded brown coal process that cranks up the calorie value of coal from 4,500 to 6,100 kcal/kg will be built in South Kalimantan and South Sumatra. Indonesia is also the world's largest producer of nickel.

Two US firms operate three copper/gold mines in Indonesia, with a Canadian and British firm holding significant other investments in nickel and gold, respectively. India's fortune groups like Vedanta Resources and Tata Group also have substantial mining operations in Indonesia. In 1998, the value of Indonesian gold and copper production was $1 billion and $843 million respectively. Receipts from gold, copper, and coal comprised 84% of the $3 billion earned in 1998 by the mineral mining sector. With the addition of Alumina project that produces 5% of the world's alumina production, Indonesia would be the world's second-largest Alumina producer. The project will not make the ores to become Aluminium, as there are 100 types of Alumina derivatives that can be developed further by other companies in Indonesia.

Joko Widodo's administration continued the resource nationalism policy of SBY, nationalising some assets controlled by multinational companies such as Freeport McMoRan, Total SA and Chevron. In 2018, in a move aimed to cut imports, oil companies operating in Indonesia were ordered to sell their crude oil to state-owned Pertamina.

In 2010, Indonesia sold 7.6 million motorcycles, which were mainly produced in the country with almost 100% local components. Honda led the market with a 50.95% market share, followed by Yamaha with 41.37%. In 2011, the retail car sales total was 888,335 units, a 19.26% increase from last year. Toyota dominated the domestic car market (35.34%), followed by Daihatsu and Mitsubishi with 15.44% and 14.56%, respectively. Since 2011, some local carmakers have introduced some Indonesian national cars which can be categorised as Low-Cost Green Car (LCGC). In 2012, sales increased significantly by 24%, making it the first time that there were more than one million units in automobile sales.

In August 2014, Indonesia exported 126,935 Completely Build Up (CBU) vehicle units and 71,000 Completely Knock Down (CKD) vehicle units, while total production reached 878,000 vehicle units, comprising 22.5% of total output. Automotive export is more than double of its import. By 2020, it is predicted that the automotive exports will be the third after CPO and shoe export. In August 2015, Indonesia exported 123,790 motorcycles. In the same year, Yamaha Motor Company, which exported 82,641, announced to make Indonesia as a base of exporting of its products.

In 2017, the country produced almost 1.2 million motor vehicles, ranking it as the 18th largest producer in the world. Nowadays, Indonesian automotive companies can produce cars with a high ratio of local content (80%–90%).

In 2018, the country produced 1.34 million units car with include export 346,000 units car mainly to the Philippines and Vietnam.
There are 50 million small businesses in Indonesia, with online usage growth of 48% in 2010. Google announced that it would open a local office in Indonesia before 2012. According to Deloitte in 2011, Internet-related activities have generated 1.6% of the GDP. It is bigger than electronic and electrical equipment exports and liquefied natural gas at 1.51% and 1.45% respectively.

Up to the end of June 2011, the fixed state assets were Rp 1,265 trillion ($128 billion). The value of state stocks was Rp 50 trillion ($5 billion) while other state assets were Rp 24 trillion ($2.4 billion).

In 2015, financial services covered Rp 7,2 trillion. Fifty domestic and foreign conglomerations held around 70.5%. Fourteen of it were vertical conglomerations, 28 were horizontal, and eight are mixed. Thirty-five entities are mainly in the bank industries, 13 were in non-bank industries and one each in special financial industries and capital market industries.

The Indonesian Textile Association has reported that in 2013, the textile sector is likely to attract investment of around $175 million. In 2012, the investment in this sector was $247 million, of which only $51 million was for new textile machinery. Exports from the textile sector in 2012 were $13.7 billion.

In 2011, Indonesia released 55,010 working visas for foreigners, an increase of 10% compared to 2010, while the number of foreign residents in Indonesia, excluding tourists and foreign emissaries was 111,752, rose by 6% compared to last year. Those who received visas for six months to one year were mostly Chinese, Japanese, South Koreans, Indians, Americans and Australians. A few of them were entrepreneurs who made new businesses. Malaysia is the most common destination of Indonesian migrant workers (including illegal workers). In 2010, according to a World Bank report, Indonesia was among the world's top ten remittance-receiving countries with a value totalling $7 billion. In May 2011, six million Indonesian citizens were working overseas, 2.2 million of whom reside in Malaysia and another 1.5 million in Saudi Arabia.

Indonesia and Japan signed the Indonesia–Japan Economic Partnership Agreement (IJEPA), which had come into effect on 1 July 2008. The agreement was Indonesia's first bilateral free-trade agreement to ease the cross-border flow of goods and people as well as investment between both countries. Trade with China has increased since the 1990s, and in 2014, China became Indonesia's second-largest export destination after Japan. With China's economic rise, Indonesia has been intensifying its trade relationship with China to counterbalance its ties with the West. By 2020, China had become Indonesia's largest export destination.

At the beginning of the post-Suharto era, US exports to Indonesia in 1999 totalled $2 billion, down significantly from $4.5 billion in 1997. The main exports were construction equipment, machinery, aviation parts, chemicals, and agricultural products. US imports from Indonesia in 1999 totalled $9.5 billion and consisted primarily of clothing, machinery and transportation equipment, petroleum, natural rubber, and footwear. Financial assistance to Indonesia is coordinated through the Consultative Group on Indonesia (CGI) formed in 1989. It includes 19 donor countries and 13 international organisations that meet annually to coordinate donor assistance. In 2019, as Indonesia's share of global trade exceeded 0.5 percent, the United States Trade Representatives decided not to classify Indonesia as a "developing country." Despite a revocation of this status, the Indonesian government has assured that this would not change the current Generalized System of Preferences facilities that Indonesia had enjoyed from the United States.

This is a chart of trend of Indonesia's GDP at market prices by the IMF with figures in millions of rupiah.
For purchasing power parity comparisons, the exchange rate for 1 US dollar is set at 3,094.57 rupiah.

Average net wage in Indonesia is varied by sector. In February 2017 the electricity, gas, and water sector is the sector with the highest average net wage, while the agriculture sector is the lowest.

Since the late 1980s, Indonesia has made significant changes to its regulatory framework to encourage economic growth. This growth was financed mostly from private investment, both foreign and domestic. US investors dominated the oil and gas sector and undertook some of Indonesia's largest mining projects. In addition, the presence of US banks, manufacturers, and service providers expanded, especially after the industrial and financial sector reforms of the 1980s. Other major foreign investors included India, Japan, the UK, Singapore, the Netherlands, Qatar, Hong Kong, Taiwan and South Korea.

The 1997 crisis made continued private financing imperative but problematic. New foreign investment approvals fell by almost two-thirds between 1997 and 1999. The crisis further highlighted areas where additional reform was needed. Frequently cited areas for improving the investment climate were the establishment of a functioning legal and judicial system, adherence to competitive processes, and adoption of internationally acceptable accounting and disclosure standards. Despite improvements of laws in recent years, Indonesia's intellectual property rights regime remains weak, and lack of effective enforcement is a significant concern. Under Suharto, Indonesia had moved towards the private provision of public infrastructure, including electric power, toll roads, and telecommunications. The 1997 crisis brought to light a severe weakness in the process of dispute resolution, however, particularly in the area of private infrastructure projects. Although Indonesia continued to have the advantages of a large labour force, abundant natural resources and modern infrastructure, private investment in new projects largely ceased during the crisis.

As of 28 June 2010, the Indonesia Stock Exchange had 341 listed companies with a combined market capitalisation of $269.9 billion. As of November 2010, two-thirds of the market capitalisation was in the form of foreign funds, and only around 1% of the population have stock investments. Efforts are further being made to improve the business and investment environment. Within the World Bank's Doing Business Survey, Indonesia rose to 122 out of 178 countries in 2010, from 129 in the previous year. Despite these efforts, the rank is still below regional peers, and an unfavourable investment climate persists. For example, potential foreign investors and their executive staff cannot maintain their own bank accounts in Indonesia, unless they are tax-paying local residents (paying tax in Indonesia for their worldwide income).

From 1990 to 2010, Indonesian companies have been involved in 3,757 mergers and acquisitions as either acquirer or target with a total known value of $137 billion. In 2010, 609 transactions were announced, which is a new record. Numbers had increased by 19% compared to 2009. The value of deals in 2010 was US$17 billion, which is the second-highest number ever. In 2012, Indonesia realised total investments of $32.5 billion, surpassing its annual target $25 billion, as reported by Investment Coordinating Board (BKPM) on 22 January. The primary investments were in the mining, transport and chemicals sectors. In 2011, the Indonesian government announced a new "Masterplan" (known as the "MP3EI", or "Masterplan Percepatan dan Perluasan Pembangunan Ekonomi Indonesia", the "Masterplan to Accelerate and Expand Economic Development in Indonesia"). The aim was to encourage increased investment, particularly in infrastructure projects across Indonesia.

Indonesia regained its investment grade rating from Fitch Rating in late 2011, and from Moody's Rating in early 2012, after losing it in the 1997 crisis, during which Indonesia spent more than Rp. 450 trillion ($50 billion) to bail out lenders from banks. Fitch raised Indonesia's long-term and local currency debt rating to BBB- from BB+ with both ratings is stable. Fitch also predicted that the economy would grow at least 6% on average per year through 2013, despite a less conducive global economic climate. Moody's raised Indonesia's foreign and local currency bond ratings to Baa3 from Ba1 with a stable outlook. On May 2017, S&P Global raised Indonesia's investment grade from BB+ to BBB- with a stable outlook, due to the economy experiencing a rebound in exports and strong consumer spending during early 2017.

In 2015, total public spending was Rp 1,806 trillion (US$130.88 billion, 15.7% of GDP). Government revenues, including those from state-owned enterprises (BUMN), totalled Rp 1,508 trillion (US$109.28 billion, 13.1% of GDP) resulting in a deficit of 2.6%. Since the 1997 crisis that caused an increase in debt and public subsidies and a decrease in development spending, Indonesia's public finances have undergone a major transformation. As a result of a series macroeconomic policies, including a low budget deficit, Indonesia is considered to have moved into a situation of financial resources sufficiency to address development needs. Decentralisation, enacted during the Habibie administration, has changed the manner of government spending, which has resulted in around 40% of public funds being transferred to regional governments by 2006.

In 2005, rising international oil prices led to the government's decision of slashing fuel subsidies. It led to an extra US$10 billion for government spending on development, and by 2006, there were an additional 5 billion due to steady growth, and declining debt service payments. It was the country's first "fiscal space" since the revenue windfall during the 1970s oil boom. Due to decentralisation and fiscal space, Indonesia has the potential to improve the quality of its public services. Such potential also enables the country to focus on further reforms, such as the provision of targeted infrastructure. Careful management of allocated funds has been described as Indonesia's main issue in public expenditure.

In 2018, President Joko Widodo substantially increased the amount of debt by taking foreign loans. Indonesia has increased the debt by Rp 1,815 trillion compared to his predecessor, SBY. He has insisted that the loan is used for productive long-term projects such as building roads, bridges, and airports. Finance Minister Sri Mulyani also stated that despite an increase of foreign loans and debt, the government has also increased the budget for infrastructure development, healthcare, education, and budget given to regencies and villages. The government is insisting that foreign debt is still under control, and complying with relevant laws that limit debt to be under 60% of GDP.

Based on the regional administration implementation performance evaluation of 2009, by an order the best performance were:

Based on JBIC Fiscal Year 2010 survey (22nd Annual Survey Report) found that in 2009, Indonesia has the highest satisfaction level in net sales and profits for Japanese companies.

According to Asia Wealth Report, Indonesia has the highest growth rate of high-net-worth individuals (HNWI) predicted among the 10 most Asian economies. The Wealth Report 2015 by Knight Frank reported that in 2014 there were 24 individuals with a net worth above US$1 billion. 18 of them lived in Jakarta and the others spread among other large cities in Indonesia. 192 persons can be categorised as centamillionaires with over US$100 million of wealth and 650 persons as high-net-worth individuals with wealth exceeding US$30 million.

As of 2011, labour militancy was increasing with a major strike at the Grasberg mine and numerous strikes elsewhere. A common issue was the attempts by foreign-owned enterprises to evade Indonesia's strict labour laws by calling their employees' contract workers. "The New York Times" expressed concern that Indonesia's cheap labour advantage might be lost. However, a large pool of the unemployed who will accept substandard wages and conditions remains available. One factor in the increase of militancy is increased awareness via the internet of prevailing wages in other countries, and the generous profits foreign companies are making in Indonesia.

On 1 September 2015, thousands of workers in Indonesia staged demonstrations across the country in pursuit of higher wages and improved labour laws. Approximately 35,000 people rallied in several parts of the country. They demanded a 22% to 25% increase in the minimum wage by 2016 and lower prices on essential goods, including fuel. The unions also want the government to ensure job security and provide the fundamental rights of the workers.

Economic disparity and the flow of natural resource profits to Jakarta has led to discontent and even contributed to separatist movements in areas such as Aceh and Papua. Geographically, the poorest fifth regions account for just 8% of consumption, while the wealthiest fifth account for 45%. While there are new laws on decentralisation that may address the problem of uneven growth and satisfaction partially, there are many hindrances in putting this new policy into practice. At a 2011 Makassar Indonesian Chamber of Commerce and Industry (Kadin) meeting, Disadvantaged Regions Minister said there are 184 regencies classified as disadvantaged areas with around 120 in eastern Indonesia. 1% of Indonesia's population has 49.3% of the country's $1.8 trillion wealth, down from 53.5%. However, it is in the fourth rank after Russia (74.5%), India (58.4%) and Thailand (58%).

Inflation has long been a problem in Indonesia. Because of political turmoil, the country had once suffered hyperinflation, with 1,000% annual inflation between 1964 and 1967, and this had been enough to create severe poverty and hunger. Even though the economy recovered very quickly during the first decade of the New Order administration (1970–1981), never once was the inflation less than 10% annually. The inflation slowed during the mid-1980s; however, the economy was also languid due to the decrease in oil price that reduced its export revenue dramatically. The economy was again experiencing rapid growth between 1989–1997 due to the improving export-oriented manufacturing sector. Still, the inflation rate was higher than economic growth, and this caused a widening gap among several Indonesians. The inflation peaked in 1998 during the 1997 crisis, with over 58%, causing poverty to raise to the levels in the 1960s. During the economic recovery and growth in recent years, the government has been trying to lower the inflation rate. However, it seems that inflation has been affected by global fluctuation and domestic market competition. As of 2010, the inflation rate was approximately 7%, when its economic growth was 6%. To date, inflation is affecting Indonesian lower middle class, especially those who are not able to afford food after price hikes. At the end of 2017, Indonesia's inflation rate was 3.61%, above the government-set forecast of 3.0–3.5%.



</doc>
<doc id="14648" url="https://en.wikipedia.org/wiki?curid=14648" title="Communications in Indonesia">
Communications in Indonesia

Communications in Indonesia has a complex history due to the need to reach an extended archipelago of over 17,500 islands. The once important non-electronic communication methods of the past have given away to a considerable telecommunications infrastructure in contemporary Indonesia.

Indonesia has long been using traditional forms of slayed communications between various islands and villages. It was not until the sixteenth century when the Dutch colonised Indonesia, constructing a more elaborate communication system, both within Indonesia and to other countries. The first connection to Australia was an undersea telegraph cable that was completed on 18 November 1871, connecting Java to Darwin, and eventually to the Australian Overland Telegraph Line across Australia.

After gaining Independence, Indonesia started to develop its own communication systems, generally following the rest of the world. The construction of communication towers and launch of the Palapa series of communication satellites was done during the New Order period.

A number of lines connect Indonesia to international communication routes. For example, the SEA-ME-WE 3 optical submarine telecommunications cable lands at both Medan and Jakarta connecting Europe with South eastern Asia (several countries up to Japan) and Australia (Perth). 

Domestically, Indonesia has good coverage for media across most major islands, although smaller and less populated Islands do not always receive attention from media companies, and rely on satellite communication.

Indonesia has a long list of print media, in the form of newspapers and magazines. Some, such as Kompas and Koran Tempo are circulated daily and are relatively simple to obtain. Others are island- or city-specific, and are usually not distributed to other regions.





By June 2011, all sub-districts in Indonesia will be connected to the Internet.

The media in Indonesia is regulated by the Ministry of Communications and Informatics.

LIRNEasia's Telecommunications Regulatory Environment (TRE) index, which summarises stakeholders’ perception on certain TRE dimensions, provides insight into how conducive the environment is for further development and progress. The most recent survey was conducted in July 2008 in eight Asian countries, including Bangladesh, India, Indonesia, Sri Lanka, Maldives, Pakistan, Thailand, and the Philippines. The tool measured seven dimensions: i) market entry; ii) access to scarce resources; iii) interconnection; iv) tariff regulation; v) anti-competitive practices; and vi) universal services; vii) quality of service, for the fixed, mobile and broadband sectors.

Below-average scores received in all sectors and across dimensions reflect general dissatisfaction of the TRE in Indonesia. However, this does not mean that respondents have ignored recent developments. The relatively healthy growth in mobile sector is reflected in the higher TRE scores received by the sector for most dimensions, when compared to the fixed sector. On average, the mobile sector scores best, with fixed and broadband following.



</doc>
<doc id="14649" url="https://en.wikipedia.org/wiki?curid=14649" title="Transport in Indonesia">
Transport in Indonesia

Indonesia's transport system has been shaped over time by the economic resource base of an archipelago with thousands of islands, and the distribution of its more than 200 million people highly concentrated on a single island, Java.

All transport modes play a role in the country’s transport system and are generally complementary rather than competitive.
Road transport is predominant, with a total system length of est. in 2008.
The railway system has four unconnected networks in Java and Sumatra primarily dedicated to transport bulk commodities and long-distance passenger traffic.

Sea transport is extremely important for economic integration and for domestic and foreign trade. It is well developed, with each of the major islands having at least one significant port city.
The role of inland waterways is relatively minor and is limited to certain areas of Eastern Sumatra and Kalimantan.
The function of air transport is significant, particularly where land or water transport is deficient or non-existent. It is based on an extensive domestic airline network where all major cities can be reached by passenger plane.

Because Indonesia encompasses a sprawling archipelago, maritime shipping provides essential links between different parts of the country. Boats in common use include large container ships, a variety of ferries, passenger ships, sailing ships, and smaller motorised vessels. Traditional wooden vessel pinisi still widely used as the inter-island freight service within Indonesian archipelago. Main pinisi traditional harbours are Sunda Kelapa in Jakarta and Paotere harbour in Makassar.

Frequent ferry services cross the straits between nearby islands, especially in the chain of islands stretching from Sumatra through Java to the Lesser Sunda Islands. On the busy crossings between Sumatra, Java, and Bali, multiple car ferries run frequently twenty-four hours per day. There are also international ferry services between across the Straits of Malacca between Sumatra and Malaysia, and between Singapore and nearby Indonesian islands, such as Batam.
A network of passenger ships makes longer connections to more remote islands, especially in the eastern part of the archipelago. The national shipping line, Pelni, provides passenger service to ports throughout the country on a two to four week schedule. These ships generally provide the least expensive way to cover long distances between islands. Still smaller privately run boats provide service between islands.

On some islands, major rivers provide a key transportation link in the absence of good roads. On Kalimantan, longboats running on the rivers are the only way to reach many inland areas.

Indonesia has 21,579 km of navigable waterways (), of which about one half are on Kalimantan, and a quarter each on Sumatra and Papua. Waterways are highly needed because the rivers on these islands are not wide enough to hold medium-sized ships. In addition to this, roads and railways are not good options since Kalimantan and Papua are not like Java, which is a highly developed island. With the current length of waterways, Indonesia ranked seventh on the countries with longest waterways.

Major ports and harbours include Bitung, Cilacap, Cirebon, Jakarta, Kupang, Palembang, Semarang, Surabaya, and Makassar. Ports are managed by the various Indonesia Port Corporations, of which there are four, numbered I through IV. Each has jurisdiction over various regions of the country, with I in the west and IV in the east. Port of Tanjung Priok in Jakarta is the Indonesia's busiest port, handling over 5.20 million TEUs. A two-phase "New Tanjung Priok" extension project is currently underway, which will triple the existing annual capacity when fully operational in 2023. In 2015, ground breaking of the strategic North Sumatra's Kuala Tanjung Port has been completed. It is expected to accommodate 500,000 TEUs per year, overtaking Johor's Tanjung Pelepas Port and could even compete with the port of Singapore.

A wide variety of vehicles are used for transportation on Indonesia's roads. Bus services are available in most areas connected to the road network. Between major cities, especially on Sumatra, Java, and Bali, services are frequent and direct; many services are available with no stops until the final destination. In more remote areas, and between smaller towns, most services are provided with minibuses or minivans ("angkut"). Buses and vans are also the primary form of transportation within cities. Often, these are operated as share taxis, running semi-fixed routes.
Many cities and towns have some form of transportation for hire available as well such as taxis. There are usually also bus services of various kinds such as the Kopaja buses and the more sophisticated Transjakarta bus rapid transit system in Jakarta, the longest bus rapid transit (BRT) system in the world that boasts some in 13 corridors and 10 cross-corridor routes and carrying 430,000 passengers daily in 2016. Other cities such as Yogyakarta, Palembang, Bandung, Denpasar, Pekanbaru, Semarang, Makassar, and Padang also have BRT systems in place without segregated lanes. Many cities also have motorised autorickshaws ("bajaj") of various kinds. Cycle rickshaws, called "becak" in Indonesia, are a regular sight on city roads and provide inexpensive transportation. They have been blamed for causing traffic congestion and, consequently, banned from most parts of Jakarta in 1972. Horse-drawn carts are found in some cities and towns.
Due to the increasing purchasing power of Indonesians, private cars are becoming more common especially in major cities. However the growth of the number of cars increasingly outpaces the construction of new roads, resulting in frequently crippling traffic jams in large parts in major cities especially in Jakarta, which often also happen on highways. Jakarta also has one of the worst traffic jams in the world.

Indonesia has about of paved highways and of unpaved highways ( estimate). The AH2 highway is one of Indonesia's main highways. The other one is AH25 in Sumatra. Indonesia has some highways, some of them are National Routes (25, currently only in Java and (partially) Sumatera), and some of them are expressways known locally as (lit. toll roads). The first expressway in Indonesia is the Jagorawi Toll Road, opened in 1978. Over of expressways opened during the first term of President Joko Widodo, surpassing previous administrations. Since 2018, all expressways do not accept any cash tolls; all tolls must be paid with certain contactless bank cards.

Indonesia has also been gradually introducing an Intelligent Transportation System (ITS) since 2012. ITS Indonesia was formed on 26 April 2011.

National routes of Indonesia pass through the hearts of most main 
cities, and are designed to connect between city centres. They act as main inter-city route outside the tollways. A national route has to be passable by logistic trucks, while simultaneously handling the common traffic. National routes in Java are numbered, while those outside Java aren't. In some cities, even in crowded districts, national routes often form bypasses or ring roads (Indonesian: "jalan lingkar") around the city to prevent inter-city traffic entering the city center.

Ministry of Public Works And Public Housing is responsible to these networks, except DKI Jakarta part from Jakarta Inner Ring Road to Jakarta Outer Ring Road. A national route can be revised if it serves unable to handle the traffic. It would usually be handled by the province/regional central government.

The overwhelming majority of highways in Indonesia is tolled, the high cost of building and maintaining a national highway system means that Indonesia has to outsource the construction and maintenance to private and state-owned companies. Indonesia has an extensive system of highways consisting of:



The toll road between Tanjung Benoa to Airport and from Airport to Serangan, all in direct line (not curve) is 12.7 kilometres and is equipped also with motorcycle lanes. The toll road is formally opened on 23 September 2013, about a week before APEC Summit in Bali is opened.


"Planned:"

The majority of Indonesia's railways is located on Java, used for both passenger and freight transport. The railway is operated by Kereta Api Indonesia. The inter-city rail network on Java is complemented by local commuter rail services in the Jakarta metropolitan area and in Surabaya. In Jakarta, the commuter rail service (Kereta Commuter Indonesia) carries 885,000 passengers a day. In addition, the Jakarta MRT began operations in March 2019, and the light rail transit system is currently under construction in Jakarta. There are four separate railway networks on Sumatra: one in Aceh, one in North Sumatra (Aceh connection proposed to be finished in 2020s), another in West Sumatra, and the final one in South Sumatra and Lampung. South Sulawesi has railway network in Barru Regency as the impact of Trans-Sulawesi Railway construction, although the network has not been used yet. There are no railways in other parts of Indonesia, although new networks are being developed on Kalimantan and Sulawesi. The government's plan to build a high-speed rail (HSR) was announced in 2015, the first in Indonesia and Southeast Asia. It is expected to connect the capital Jakarta with Bandung, covering a distance of around . Plans were also mentioned for its possible extension to Surabaya, the country's second largest city.

As of 2013, Indonesia has pipelines for condensate , condensate/gas , gas , liquid petroleum gas , oil , oil/gas/water , refined products , and water .

Air transport in Indonesia serves as a critical means of connecting the thousands of islands throughout the archipelago. Indonesia is the largest archipelagic country in the world, extending from east to west and from north to south, comprising 13,466 islands, with 922 of those permanently inhabited. With an estimated population of over 255 million people — making it the world's fourth-most-populous country — and also due to the growth of the middle-class, the boom of low-cost carriers in the recent decade, and overall economic growth, many domestic travellers shifted from land and sea transport to faster and more comfortable air travel. Indonesia is widely regarded as an emerging market for air travel in the region. Between 2009 and 2014, the number of Indonesian air passengers increased from 27,421,235 to 94,504,086, an increase of over threefold.

However, safety issues continue to be a persistent problem in Indonesian aviation. Several accidents have given Indonesia's air transport system the reputation of the least safe in the world. Indonesian aviation faces numerous challenges, including poorly maintained, outdated, and often overwhelmed infrastructure, the factor of human error, bad weather, haze problems caused by plantation fires, and volcanic ash spewed by numerous volcanoes that disrupts air transportation.

The Indonesian Air Force has 34,930 personnel equipped with 224 aircraft, among them 110 combat aircraft. The Indonesian Air Force possesses and operates numerous military air bases and military airstrips across the archipelago.

The International Air Transport Association (IATA) has predicted that Indonesia will become the world's sixth largest air travel market by 2034. Around 270 million passengers are predicted to fly from and within Indonesia by 2034.

As of 2013, there are 673 airports in Indonesia, 186 of those have paved runways, and 487 have unpaved runways. As of 2013, there are 76 heliports in Indonesia. Jakarta's Soekarno–Hatta International Airport serves as the country's main air transportation hub as well as the nation's busiest. Since 2010, it has become the busiest airport in Southeast Asia, surpassing Suvarnabhumi and Changi airports. In 2017, it became the 17th busiest airport in the world with 62.1 million passengers. Today the airport is running over capacity. After an expansion with a third terminal was completed in 2016, the total capacity of the three terminals increased to 43 million passengers a year. The first and second terminals will be revitalised in order to accommodate 67 million passengers a year.

In Indonesia, there are 22 commercial scheduled airlines that carry more than 30 passengers, and 32 commercial scheduled airlines that transport 30 or less passengers, as well as chartered airlines. Some notable Indonesian airlines, among others, include Garuda Indonesia, the government-owned flag carrier of Indonesia, Lion Air, currently the largest private low-cost carrier airline in Indonesia, Sriwijaya Air, currently the largest medium service regional carrier in Indonesia, also the country's third largest carrier, and Indonesia AirAsia, the Indonesian branch of Malaysian-based AirAsia.

"Mudik", or "Pulang Kampung", is an Indonesian term for the activity where migrants or migrant workers return to their hometown or village during or before major holidays, especially Lebaran (Eid al-Fitr). Although the mudik homecoming travel before Lebaran takes place in most Indonesian urban centers, the highlight is on the nation's largest urban agglomeration; Greater Jakarta, as millions of Jakartans exit the city by various means of transportation, overwhelming train stations and airports and also clogging highways, especially the Trans-Java toll road and Java's Northern Coast Road. In 2017 it was estimated that the people that took annual "mudik" travel reached 33 million people. 
The demand for train and airplane tickets usually spikes a month or two prior to Lebaran, prompting an unusually higher cost for tickets for highly sought days of departure. Some airlines might add extra flights or operate larger airplanes to deal with the surge in demand. Indonesian train operator Kereta Api Indonesia usually offers additional train trips or introduces longer trains with more cars in order to meet the demand. The private operators of intercity and interprovince buses usually charge higher ticket costs during this period. The impact is indeed tremendous as millions of buses, cars and motorcycles jam the roads and highways, causing kilometres of traffic jams each year.



</doc>
<doc id="14650" url="https://en.wikipedia.org/wiki?curid=14650" title="Indonesian National Armed Forces">
Indonesian National Armed Forces

The Indonesian National Armed Forces (, literally ""Indonesian National Military""; abbreviated as TNI) are the military forces of the Republic of Indonesia. It consists of the Army (TNI-AD), Navy (TNI-AL), and Air Force (TNI-AU). The President of Indonesia is the commander-in-chief of the Armed Forces. In 2016, it comprises approximately 395,500 military personnel including the Indonesian Marine Corps (), which is a branch of the Navy.

Initially formed with the name of the People's Security Army (TKR), then later changed to the Republic of Indonesia Army (TRI) before changing again its name to the Indonesian National Armed Forces (TNI) to the present. The Indonesian Armed Forces was formed during the Indonesian National Revolution, when it undertook a guerrilla war along with informal militia. As a result of this, and the need to maintain internal security, the Armed forces including the Army, Navy, and Air Force has been organised along territorial lines, aimed at defeating internal enemies of the state and potential external invaders.

Under the 1945 Constitution, all citizens are legally entitled and obliged to defend the nation. Conscription is provided for by law, yet the Forces have been able to maintain mandated strength levels without resorting to a draft. Most enlisted personnel are recruited in their own home regions and generally train and serve most of their time in units nearby.

The Indonesian armed forces (military) personnel does not include members of law enforcement and paramilitary personnel such as the Indonesian National Police (Polri) consisting of approximately 590,000+ personnel, Mobile Brigade Corps (Brimob) of around 42,000+ armed personnel, the Civil Service Police Unit (Municipal police) or "Satpol PP", Indonesian College Students' Regiment or (Menwa) which is a collegiate military service consisting 26,000 trained personnel, and civil defence personnel (Linmas or Public Protection Service Corps, which replaced the old Hansip in 2014).

Before the formation of the Indonesian Republic, the military authority in the Dutch East Indies was held by the Royal Dutch East Indies Army (KNIL) and naval forces of the Royal Netherlands Navy (KM). Although both the KNIL and KM were not directly responsible for the formation of the future Indonesian armed forces, and mainly took the role of foe during Indonesian National Revolution in 1945 to 1949, the KNIL had also provided military training and infrastructure for some of the future TNI officers and other ranks. There were military training centres, military schools and academies in the Dutch East Indies. Next to Dutch volunteers and European mercenaries, the KNIL also recruited indigenous, especially Ambonese, Kai Islanders, Timorese, and Minahasan people. In 1940, with the Netherlands under German occupation and the Japanese pressing for access to Dutch East Indies oil supplies, the Dutch had opened up the KNIL to large intakes of previously excluded Javanese. Some of the indigenous soldiers that had enjoyed Dutch KNIL military academy education would later become important TNI officers, like for example: Soeharto and Nasution.

Indonesian nationalism and militarism started to gain momentum and support in World War II during the Japanese occupation of Indonesia. To gain support from the Indonesian people in their war against the Western Allied force, Japan started to encourage and back Indonesian nationalistic movements by providing Indonesian youth with military training and weapons. On 3 October 1943, the Japanese military formed the Indonesian volunteer army called PETA ( – Defenders of the Homeland). The Japanese intended PETA to assist their forces oppose a possible invasion by the Allies. The Japanese military training for Indonesian youth originally was meant to rally the local's support for the Japanese Empire, but later it became the significant resource for the Republic of Indonesia during the Indonesian National Revolution in 1945 to 1949. Many of these men who served in PETA, both officers and NCOs alike like Soedirman, formed majority of the personnel that would compose the future armed forces.

At first, Indonesian Armed Forces started out as the BKR ( – People's Security Agency), which was formed in the 3rd PPKI meeting, on 29 August 1945; this was an organisation of militias in a united nationwide force to ensure the security remained intact across the newly declared independent Indonesia; it was created more as a civil defence force than an armed forces. The decision to create a "security agency" and not an army, was taken to lessen the probability of the allied forces viewing it as an armed revolution and invading in full force. During their capitulation, one of the terms of surrender to Japan was to return the Asian domains they had conquered to the previous nation of the Allies, certainly not to liberate them independently.

When confrontations became sharp and hostile between Indonesia and the Allied forces, on 5 October 1945 the TKR ("Tentara Keamanan Rakyat" – People's Security Armed Forces) was formed on the basis of existing BKR units; this was a move taken to formalise, unite, and organise the splintered pockets of independent troopers ("laskar") across Indonesia, ensuing a more professional military approach, to contend with the Netherlands and the Allied force invaders.

The Indonesian armed forces have seen significant action since their establishment in 1945. Their first conflict was the 1945–1949 Indonesian National Revolution, in which the 1945 Battle of Surabaya was especially important as the baptism of fire of the young armed forces.

In January 1946, TKR renamed as the "Tentara Keselamatan Rakyat" (People's Safety Military Forces), then succeeded by TRI ("Tentara Republik Indonesia" – Republic of Indonesia Armed Forces), in a further step to professionalise the armed forces and increase its ability to engage systematically.

In June 1947, the TRI, per a government decision, was renamed the TNI ("Tentara Nasional Indonesia" – Indonesian National Armed Forces) which is a merger between the TRI and the independent paramilitary organizations ("laskar") across Indonesia, becoming by 1950 the APRIS or "National Military Forces of the Republic of the United States of Indonesia" ("Angkatan Perang Republik Indonesia Serikat"), by mid year the APRI or "Military Forces of the Republic of Indonesia" ("Angkatan Perang Republik Indonesia"), absolving also native personnel from within both the former KNIL and KM within the expanded republic.

On 21 June 1962, the name ""Tentara Nasional Indonesia"" (TNI) was changed to ""Angkatan Bersenjata Republik Indonesia"" (Republic of Indonesia Armed Forces, ABRI). The POLRI (Indonesian National Police) was integrated under the Armed Forces and changed its name to ""Angkatan Kepolisian"" (Police Force), and its commander maintained the concurrent status of Minister of Defence and Security, reporting to the President, who is commander in chief. The commanding generals (later chiefs of staff) and the Chief of the National Police then all held ministerial status as members of the cabinet of the republic, while a number of higher-ranking officers were appointed to other cabinet posts. On 1 July 1969, the Police Force's name was reverted to ""POLRI"".

After the fall of Suharto in 1998, the democratic and civil movement grew against the acute military role and involvements in Indonesian politics. As the result, the post-Soeharto Indonesian military has undergone certain reforms, such as the revocation of the Dwifungsi doctrine and the terminations of military controlled business. The reforms also involved law enforcement in common civil society, which questioned the position of Indonesian police under the military corps umbrella. These reforms led to the separation of the police force from the military. In April 1999, the Indonesian National Police officially regained its independence and now is a separate entity from the armed forces proper. The official name of the Indonesian military also changed from ""Angkatan Bersenjata Republik Indonesia"" (ABRI) back to ""Tentara Nasional Indonesia"" (TNI).

In the Beginning of 2010, the Indonesian government seeks to strengthen the TNI to achieve minimum standards of minimum strength (Minimum Essential Force). The MEF is divided into three strategic plan stages, 2010–2014, 2015–2019, and 2020–2024. Initially the government budgeted Rp156 trillion for the provision of TNI's main weapon system equipment (alutsista) in the MEF period 2010–2014.


The Indonesian military philosophy over-riding defence of the archipelago is summarily civilian-military defence, called "Total People's Defence"- consisting of a three-stage war: a short initial period in which invader would defeat a conventional Indonesian military, a long period of territorial guerrilla war followed by a final stage of expulsion- with military acting as a rallying point for defence from grass-roots village level upwards. The doctrine relies on a close bond between villager and soldier to encourage the support of the entire population and enable the military to manage all war-related resources.

The civilian population would provide logistical support, intelligence, and upkeep with some trained to join the guerrilla struggle. The armed forces regularly engage in large-scale community and rural development. The "Armed Forces Enters the Village" (AMD/TMMD) program, begun in 1983 is held three times annually to organise and assist construction and development of civilian village projects.

The current developments in Indonesia's defence policies are framed within the concept of achieving "Minimum Essential Force" or MEF by 2024. This concept of MEF was first articulated in Presidential Decree No. 7/2008 on General Policy Guidelines on State Defence Policy which came into effect on 26 January 2008. MEF is defined as a capability based defence and force level that can guarantee the attainment of immediate strategic defence interests, where the procurement priority is given to the improvement of minimum defence strength and/or the replacement of outdated main weapon systems/equipments. To achieve this aim, MEF had been restructured into a series of 3 strategic programmes with timeframes from 2010 to 2014, 2015 to 2019 and 2020 to 2024 as well as spending of up the 1.5 – 2% of the GDP.

The identity of the Indonesian National Armed forces is (Article 2 of the TNI Law) is the TNI must aim to become the:


The Indonesian armed forces have long been organised around territorial commands. Following independence, seven were established by 1958. No central reserve formation was formed until 1961 (when the 1st Army Corps of the Army General Reserve, "CADUAD", the precursor of today's Kostrad was established). It was only after the attempted coup d'état of 1 October 1965 and General Suharto's rise to the presidency that it became possible to integrate the armed forces and begin to develop a joint operations structure.

Following a decision in 1985, major reorganization separate the Ministry of Defense and Security ("MoDS") from the "ABRI" (Indonesian Armed Forces name during Soeharto's presidential era) headquarters and staff. MoDS was made responsible for planning, acquisition, and management tasks but had no command or control of troop units. The "ABRI" commander in chief retained command and control of all armed forces and continued by tradition to be the senior military officer in the country, while continuing to be a part of the cabinet.

The administrative structure of Ministry of Defense and Security consisted of a minister, deputy minister, secretary general, inspector general, three directorates-general and a number of functional centers and institutes. The minister, deputy minister, inspector general, and three directors general were retired senior military officers; the secretary general (who acted as deputy minister) and most functional center chiefs were, as is the case today, active-duty military officers, while employees and staff were personnel of the armed forces and of the civil service.

The 1985 reorganisation also made significant changes in the armed forces chain of command. The four multi-service Regional Defense Commands ("Kowilhans") and the National Strategic Command ("Kostranas") were eliminated from the defense structure, establishing the Military Regional Command ("Kodam"), or area command, as the key organisation for strategic, tactical, and territorial operations for all services. The chain of command flowed directly from the "ABRI" commander in chief to the ten "Kodam" commanders, and then to subordinate army territorial commands. The former territorial commands of the air force and navy were eliminated from the structure altogether, with each of those services represented on the "Kodam" staff by a senior liaison officer. The navy and air force territorial commands were replaced by operational commands. The air force formed two Operational Commands ("Ko-Ops") while the navy had its two Fleet Commands, the Western and Eastern Armadas. The air force's National Air Defense Command ("Kohanudnas") remained under the "ABRI" commander in chief. It had an essentially defensive function that included responsibility for the early warning system.

After Suharto's presidential era collapsed in 1998, the Indonesian National Police was separated from the Armed Forces making the Indonesian Armed Forces under the direct auspices command of the Ministry of Defense and the Police Force under the direct auspices of the President of Indonesia. Before 1998, the Armed Forces of Indonesia (the then name "ABRI") was composed of four service branches: Indonesian Army, Indonesian Navy, Indonesian Air Force, and the Indonesian National Police. Then after 1998 (After reformation from Soeharto), the Armed Forces' name, in 1999, was changed to TNI ("Tentara Nasional Indonesia") literally meaning: "The National Military of Indonesia" and the independent Indonesian Police Force changed its name to POLRI ("Kepolisian Negara Republik Indonesia") literally meaning: "The National Police Force of Indonesia". Now specifically, although the Armed Forces of Indonesia and the National Police of Indonesia has been separated, they still cooperate and conduct special duties and tasks together for the sake of the national security and integrity of Indonesia.

On 13 May 2018, Commander Hadi Tjahjanto reorganized the armed forces once more by inaugurating 4 new military units: Kostrad 3rd Infantry Division, 3rd Fleet Command, 3rd Air Force Operational Command and Marine Force III. The new military units are intended to reduce response time against any threats and problems in Eastern Indonesia. He also officially renamed the Western and Eastern Fleet Commands to 1st and 2nd Fleet Commands.

The Indonesian National Armed Forces is structured into the following in accordance with article 9 of Presidential decree No. 66/ 2019. Indonesian National Armed Forces organization consist of the following:

Commander of the Indonesian National Armed Forces (Panglima TNI) and serve as the elements of leadership in the Indonesia National Armed Forces, both position are held by the four-star General/Admiral/Air Marshall appointed by and reporting directly to the President of Indonesia, who is overall commander-in-chief of the armed forces. As of Nov 2019, position of deputy commander is still vacant.






Indonesian Military Special Forces

In the immediate aftermath of 2018 Surabaya bombings, President Widodo has agreed to revive the TNI Joint Special Operations Command ("Koopsusgab") to assist the National Police in antiterrorism operations under certain conditions. This joint force is composed of special forces of the National Armed Forces as mentioned above, and is under the direct control of the Commander of the National Armed Forces. In July 2019, President Widodo officially formed the Armed Forces Special Operations Command ("Koopsus TNI") which comprised 400 personnel each from Sat-81 Gultor of Kopassus, Denjaka, and Den Bravo of Paskhas to conduct special operations to protect national interests within or outside Indonesian territory.

Military spending in the national budget was widely estimated 3% of GDP in 2005, but is supplemented by revenue from many military-run businesses and foundations. The defence budget for 2017 was $8.17bn.

Beeson and Bellamy wrote in 2002 that: '..By some estimates 60–65% of the military's actual operating expenses come from 'off-budget sources' rather than the government (Cochrane 2002). This is a euphemism for a host of legal and illegal practices that include legitimate involvement in state-owned and private businesses, as well as a range of activities in the 'black economy.' An estimated 30% of government funding of the military 'is lost through corruption in the process of buying military equipment and supplies.'(International Crisis Group 2001: 13)'

In addition, the territorial commands (KODAM) are responsible for 'the bulk of their operational fund-raising.'

The Indonesian armed forces are voluntary. The active military strength is 395,500 with available manpower fit for military service of males aged between 16 and 49 is 75,000,000, with a further 4,500,000 new suitable for service annually.

In the Indonesian Army, Navy (including Marine Corps), Air Force, and the Police Force, the rank consists of officer known as in Indonesian: ""Perwira"", NCO: ""Bintara"" and enlisted: ""Tamtama"". The rank titles of the Marine Corps are the same as those of the Army, but it still uses the Navy's style insignia (for lower-ranking enlisted men, blue are replacing the red colour).

The Armed Forces Pledge is a pledge of loyalty and fidelity of the military personnel to the government and people of Indonesia and to the principles of nationhood.





</doc>
<doc id="14651" url="https://en.wikipedia.org/wiki?curid=14651" title="Foreign relations of Indonesia">
Foreign relations of Indonesia

Since independence, Indonesian foreign relations have adhered to a "free and active" foreign policy, seeking to play a role in regional affairs commensurate with its size and location but avoiding involvement in conflicts among major powers. Indonesian foreign policy under the "New Order" government of President Suharto moved away from the stridently anti-Western, anti-American posturing that characterised the latter part of the Sukarno era. Following Suharto's ouster in 1998, Indonesia's government has preserved the broad outlines of Suharto's independent, moderate foreign policy. Preoccupation with domestic problems has not prevented successive presidents from travelling abroad.

Indonesia's relations with the international community were strained as a result of its invasion of neighbouring East Timor in December 1975, the subsequent annexation and occupation, the independence referendum in 1999 and the resulting violence afterwards. As one of the founding members of Association of Southeast Asian Nations (ASEAN), established in 1967, and also as the largest country in Southeast Asia, Indonesia has put ASEAN as the cornerstone of its foreign policy and outlook. After the transformation from Suharto's regime to a relatively open and democratic country in the 21st century, Indonesia today exercises its influence to promote co-operation, development, democracy, security, peace and stability in the region through its leadership in ASEAN.

Indonesia managed to play a role as a peacemaker in the Cambodia-Thailand conflict over the Preah Vihear temple. Indonesia and other ASEAN member countries collectively have also played a role in encouraging the government of Myanmar to open up its political system and introduce other reforms more quickly.

Given its geographic and demographic size, rising capabilities and diplomatic initiatives, scholars have classified Indonesia as one of Asia-Pacific's middle powers.

A cornerstone of Indonesia's contemporary foreign policy is its participation in the Association of Southeast Asian Nations (ASEAN), of which it was a founding member in 1967 with Thailand, Malaysia, Singapore, and the Philippines. Since then, Brunei, Vietnam, Laos, Burma, and Cambodia also have joined ASEAN. While organised to promote shared economic, social, and cultural goals, ASEAN acquired a security dimension after Vietnam's invasion of Cambodia in 1979; this aspect of ASEAN expanded with the establishment of the ASEAN Regional Forum in 1994, which comprises 22 countries, including the US.

Indonesian national capital Jakarta is also the seat of ASEAN Secretariat, located at Jalan Sisingamangaraja No.70A, Kebayoran Baru, South Jakarta. Other than serving their diplomatic missions for Indonesia, numbers of foreign embassies and diplomatic mission in Jakarta are also accredited to ASEAN. ASEAN Headquarter has led to the prominence of Jakarta as a diplomatic hub in Southeast Asia.

In the late 1990s to early 2000s, Indonesia's continued domestic troubles have distracted it from ASEAN matters and consequently lessened its influence within the organisation. However, after the political and economic transformation, from the turmoil of 1998 "Reformasi" to the relatively open and democratic civil society with rapid economic growth in the 2010s, Indonesia returned to the region's diplomatic stage by assuming its leadership role in ASEAN in 2011. Indonesia is viewed to have weight, international legitimacy and global appeal to draw support and attention from around the world to ASEAN. Indonesia believes that ASEAN can contribute positively to the international community, by promoting economic development and co-operation, improving security, peace, the stability of ASEAN, and making the Southeast Asia region far from conflicts.

Indonesia's bilateral relations with three neighbouring ASEAN members — Malaysia, Singapore, and Vietnam — are not without challenges. If not appropriately managed, it would result in mutual mistrust and suspicion, thus hindering bilateral and regional co-operation. In the era of rising Indonesia, which might assert its leadership role within ASEAN, the problem could become more significant. Nevertheless, the rise of Indonesia should be regarded in the sense of optimism. First, although Indonesia is likely to become assertive, the general tone of its foreign policy is mainly liberal and accommodating. The consolidation of the Indonesian democratic government played a key role and influence in ASEAN. The second, institutional web of ASEAN will sustain engagements and regular meetings between regional elites, thus deepening their mutual understanding and personal connections.

Indonesia also was one of the founders of NAM and has taken moderate positions in its councils. As NAM Chairman in 1992–95, it led NAM positions away from the rhetoric of North-South confrontation, advocating the broadening of North-South co-operation instead in the area of development. Indonesia continues to be a prominent, and generally helpful, leader of the Non-Aligned Movement.

Indonesia has the world's largest Muslim population and is a member of OIC. It carefully considers the interests of Islamic solidarity in its foreign policy decisions but generally has been an influence for moderation in the OIC.

Indonesia has been a strong supporter of the Asia-Pacific Economic Cooperation (APEC) forum. Mainly through the efforts of President Suharto at the 1994 meeting in Indonesia, APEC members agreed to implement free trade in the region by 2010 for industrialised economies and 2020 for developing economies. As the largest economy in Southeast Asia, Indonesia also belongs to other economic groupings such as G20 and Developing 8 Countries (D-8).

In 2008, Indonesia was admitted as a member of the G20, as the only ASEAN member state in the group. Through its membership in the global economic powerhouse that accounted of 85% of the global economy, Indonesia is keen to position itself as a mouthpiece for ASEAN countries, and as a representative of the developing world within the G-20.

After 1966, Indonesia welcomed and maintained close relations with the donor community, particularly the United States, western Europe, Australia, and Japan, through the Inter-Governmental Group on Indonesia (IGGI) and its successor, the Consultative Group on Indonesia (CGI), which have provided substantial foreign economic assistance. Problems in Timor and Indonesia's reluctance to implement economic reform, have complicated Indonesia's relationship with donors.

Indonesia has numerous outlying and remote islands, which some are inhabited by many pirate groups that regularly attack ships in the Strait of Malacca in the north, and illegal fishing crews known for penetrating Australian and Filipino waters. While Indonesian waters itself is the target of many illegal fishing activities by numerous foreign vessels.

Indonesia has some present and historic territorial disputes with neighboring nations, such as:




</doc>
<doc id="14652" url="https://en.wikipedia.org/wiki?curid=14652" title="List of islands of Indonesia">
List of islands of Indonesia

The islands of Indonesia, also known as the Indonesian Archipelago, may refer either to the islands comprising the country of Indonesia or to the geographical groups which include its islands. According to the Indonesian Coordinating Ministry for Maritime and Investments Affairs, of 17,508 officially listed islands within the territory of the Republic of Indonesia, 16,671 island names have been verified by the United Nations Group of Experts on Geographical Names (UNGEGN) as of 2018. This makes Indonesia the world's largest island country.

The exact number of islands comprising Indonesia varies among definitions and sources. According to a geospatial survey conducted between 2007 and 2010 by Badan Koordinasi Survei dan Pemetaan Nasional (Bakorsurtanal), the National Coordinating Agency for Survey and Mapping, Indonesia has 13,466 islands. However, according to earlier survey in 2002 by National Institute of Aeronautics and Space (LAPAN), the Indonesian archipelago has 18,307 islands, and according to the CIA "World Factbook", there are 17,508 islands. The discrepancy of the numbers of Indonesian islands was because that the earlier surveys include "tidal islands"; sandy cays and rocky reefs that appear during low tide and are submerged during high tide. According to estimates made by the government of Indonesia 8,844 islands have been named, with 922 of those permanently inhabited.


The following islands are listed by province:






"199 islands"

"479 islands"





"about 3,200 islands"















"Islands near the Indonesian half of New Guinea island."

"610 islands, 35 inhabited"




</doc>
<doc id="14653" url="https://en.wikipedia.org/wiki?curid=14653" title="Iran">
Iran

Iran ( ), also called Persia, and officially the Islamic Republic of Iran ( ), is a country in Western Asia. It is bordered to the northwest by Armenia and Azerbaijan, to the north by the Caspian Sea, to the northeast by Turkmenistan, to the east by Afghanistan and Pakistan, to the south by the Persian Gulf and the Gulf of Oman, and to the west by Turkey and Iraq. Its central location in Eurasia and proximity to the Strait of Hormuz give it significant geostrategic importance. Tehran is the capital and largest city, as well as the leading economic and cultural hub; it is also the most populous city in Western Asia, with more than 8.8 million residents, and up to 15 million including the metropolitan area. With 83 million inhabitants, Iran is the world's 17th most populous country. Spanning , it is the second largest country in the Middle East and the 17th largest in the world.

Iran is home to one of the world's oldest civilizations, beginning with the formation of the Elamite kingdoms in the fourth millennium BC. It was first unified by the Iranian Medes in the seventh century BC, and reached its territorial height in the sixth century BC, when Cyrus the Great founded the Achaemenid Empire, which stretched from Eastern Europe to the Indus Valley, making it one of the largest empires in history. The empire fell to Alexander the Great in the fourth century BC and was divided into several Hellenistic states. An Iranian rebellion established the Parthian Empire in the third century BC, which was succeeded in the third century AD by the Sasanian Empire, a major world power for the next four centuries.

Arab Muslims conquered the empire in the seventh century AD, and the subsequent Islamization of Iran led to the decline of the once dominant Zoroastrian religion. Iran subsequently became a major center of Islamic culture and learning, with its art, literature, philosophy, and architecture spreading across the Muslim world and beyond during the Islamic Golden Age. Over the next two centuries, a series of native Muslim dynasties emerged before the Seljuq Turks and the Ilkhanate Mongols conquered the region. In the 15th century, the native Safavids reestablished a unified Iranian state and national identity, with the country's conversion to Shia Islam marking a turning point in Iranian and Muslim history.

Under the reign of Nader Shah in the 18th century, Iran once again became a major world power, though by the 19th century a series of conflicts with the Russian Empire led to significant territorial losses. However, Iran would remain one of the few non-European states to avoid colonization by Europe. The early 20th century saw the Persian Constitutional Revolution, which created the country's first constitutional monarchy and legislature, and a gradual move towards greater democracy. Efforts to nationalize its fossil fuel supply from Western companies led to an Anglo-American coup in 1953, which resulted in greater autocratic rule under Mohammad Reza Pahlavi and growing Western political influence. He went on to launch a far-reaching series of reforms in 1963, which included industrial growth, infrastructure expansion, land reforms, and increased women's rights. However, widespread dissatisfaction with the monarchy culminated in the Iranian Revolution, which established the current Islamic Republic in 1979. Iran was invaded by Iraq in 1980, leading to a bloody and protracted war that lasted for almost eight years, and ended in a stalemate with devastating losses for both sides.

Iran's political system combines elements of a presidential democracy and an Islamic theocracy, with the ultimate authority vested in an autocratic "Supreme Leader". The Iranian government is widely considered to be authoritarian, and has attracted widespread criticism for its significant constraints and abuses against human rights and civil liberties, including the violent suppression of mass protests, unfair elections, and unequal rights for women and children. It has also been alleged by international observors to sponsor and spread antisemitism both domestically and internationally.

Iran is a founding member of the UN, ECO, OIC, and OPEC. It is a major regional and middle power, and its large reserves of fossil fuels — including the world's largest natural gas supply and the third largest proven oil reserves — exert considerable influence in international energy security and the world economy. The country's rich cultural legacy is reflected in part by its 22 UNESCO World Heritage Sites, the third largest number in Asia and 10th largest in the world. Historically a multi-ethnic country, Iran remains a pluralistic society comprising numerous ethnic, linguistic, and religious groups, the largest being Persians, Azeris, Kurds, Mazandaranis and Lurs.

The term "Iran" derives directly from Middle Persian , first attested in a third-century inscription at Rustam Relief, with the accompanying Parthian inscription using the term , in reference to the Iranians. The Middle Iranian "ērān" and "aryān" are oblique plural forms of gentilic nouns "ēr-" (Middle Persian) and "ary-" (Parthian), both deriving from Proto-Iranian "*arya-" (meaning "Aryan", i.e. "of the Iranians"), recognized as a derivative of Proto-Indo-European ', meaning "one who assembles (skilfully)". In the Iranian languages, the gentilic is attested as a self-identifier, included in ancient inscriptions and the literature of the Avesta, and remains also in other Iranian ethnic names "Alan" ( ) and "Iron" (). According to the Iranian mythology, the country's name comes from name of Iraj, a legendary prince and shah who was killed by his brothers.

Historically, Iran has been referred to as "Persia" by the West, due mainly to the writings of Greek historians who referred to all of Iran as (; from Old Persian ), meaning "land of the Persians", while Persis itself was one of the provinces of ancient Iran that is today defined as Fars. As the most extensive interaction the ancient Greeks had with any outsider was with the Persians, the term persisted, even long after the Greco-Persian Wars (499–449 BC).

In 1935, Reza Shah requested the international community to refer to the country by its native name, "Iran", effective 22 March that year. Opposition to the name change led to the reversal of the decision in 1959, and Professor Ehsan Yarshater, editor of "Encyclopædia Iranica", propagated a move to use "Persia" and "Iran" interchangeably. Today, both "Iran" and "Persia" are used in cultural contexts, while "Iran" remains irreplaceable in official state contexts.

Historical and cultural usage of the word "Iran" is not restricted to the modern state proper. "Greater Iran" ("Irānzamīn" or "Irān e Bozorg") refers to territories of the Iranian cultural and linguistic zones. In addition to modern Iran, it includes portions of the Caucasus, Anatolia, Mesopotamia, Afghanistan, and Central Asia.

The Persian pronunciation of "Iran" is . Common Commonwealth English pronunciations of "Iran" are listed in the "Oxford English Dictionary" as and , while American English dictionaries such as Merriam-Webster's provide pronunciations which map to , or likewise in "Random House Webster's Unabridged Dictionary" as . The "Cambridge Dictionary" lists as the British pronunciation and as the American pronunciation. Similarly, Glasgow-based "Collins English Dictionary" provides both English English and American English pronunciations. The pronunciation guide from Voice of America also provides .

The American English pronunciation may be heard in U.S. media. Max Fisher in "The Washington Post" prescribed for "Iran", while proscribing . "The American Heritage Dictionary of the English Language", in the dictionary's 2014 Usage Ballot, addressed the topic of the pronunciations of Iran and Iraq. According to this survey, the pronunciations and were deemed almost equally acceptable, while was preferred by most panelists participating in the ballot. With regard to the pronunciation, more than 70% of the panelists deemed it unacceptable. Among the reasons given by those panelists were that has "hawkish connotations" and sounds "angrier", "xenophobic", "ignorant", and "not... cosmopolitan". The pronunciation remains standard and acceptable, reflected in the entry for "Iran" in the American Heritage Dictionary itself, as well as in each of the other major dictionaries of American English.

The earliest attested archaeological artifacts in Iran, like those excavated at Kashafrud and Ganj Par in northern Iran, confirm a human presence in Iran since the Lower Paleolithic. Iran's Neanderthal artifacts from the Middle Paleolithic have been found mainly in the Zagros region, at sites such as Warwasi and Yafteh. From the 10th to the seventh millennium BC, early agricultural communities began to flourish in and around the Zagros region in western Iran, including Chogha Golan, Chogha Bonut, and Chogha Mish.

The occupation of grouped hamlets in the area of Susa, as determined by radiocarbon dating, ranges from 4395-3955 to 3680-3490 BC. There are dozens of prehistoric sites across the Iranian Plateau, pointing to the existence of ancient cultures and urban settlements in the fourth millennium BC. During the Bronze Age, the territory of present-day Iran was home to several civilizations, including Elam, Jiroft, and Zayanderud. Elam, the most prominent of these civilizations, developed in the southwest alongside those in Mesopotamia, and continued its existence until the emergence of the Iranian empires. The advent of writing in Elam was paralleled to Sumer, and the Elamite cuneiform was developed since the third millennium BC.

From the 34th to the 20th century BC, northwestern Iran was part of the Kura-Araxes culture, which stretched into the neighboring Caucasus and Anatolia. Since the earliest second millennium BC, Assyrians settled in swaths of western Iran and incorporated the region into their territories.

By the second millennium BC, the ancient Iranian peoples arrived in what is now Iran from the Eurasian Steppe, rivaling the native settlers of the region. As the Iranians dispersed into the wider area of Greater Iran and beyond, the boundaries of modern-day Iran were dominated by Median, Persian, and Parthian tribes.

From the late 10th to the late seventh century BC, the Iranian peoples, together with the "pre-Iranian" kingdoms, fell under the domination of the Assyrian Empire, based in northern Mesopotamia. Under king Cyaxares, the Medes and Persians entered into an alliance with Babylonian ruler Nabopolassar, as well as the fellow Iranian Scythians and Cimmerians, and together they attacked the Assyrian Empire. The civil war ravaged the Assyrian Empire between 616 and 605 BC, thus freeing their respective peoples from three centuries of Assyrian rule. The unification of the Median tribes under king Deioces in 728 BC led to the foundation of the Median Empire which, by 612 BC, controlled almost the entire territory of present-day Iran and eastern Anatolia. This marked the end of the Kingdom of Urartu as well, which was subsequently conquered and dissolved.
In 550 BC, Cyrus the Great, the son of Mandane and Cambyses I, took over the Median Empire, and founded the Achaemenid Empire by unifying other city-states. The conquest of Media was a result of what is called the "Persian Revolt". The brouhaha was initially triggered by the actions of the Median ruler Astyages, and was quickly spread to other provinces, as they allied with the Persians. Later conquests under Cyrus and his successors expanded the empire to include Lydia, Babylon, Egypt, parts of the Balkans and Eastern Europe proper, as well as the lands to the west of the Indus and Oxus rivers.

539 BC was the year in which Persian forces defeated the Babylonian army at Opis, and marked the end of around four centuries of Mesopotamian domination of the region by conquering the Neo-Babylonian Empire. Cyrus entered Babylon and presented himself as a traditional Mesopotamian monarch. Subsequent Achaemenid art and iconography reflect the influence of the new political reality in Mesopotamia.
At its greatest extent, the Achaemenid Empire included territories of modern-day Iran, Republic of Azerbaijan (Arran and Shirvan), Armenia, Georgia, Turkey (Anatolia), much of the Black Sea coastal regions, northeastern Greece and southern Bulgaria (Thrace), northern Greece and North Macedonia (Paeonia and Macedon), Iraq, Syria, Lebanon, Jordan, Israel and the Palestinian territories, all significant population centers of ancient Egypt as far west as Libya, Kuwait, northern Saudi Arabia, parts of the United Arab Emirates and Oman, Pakistan, Afghanistan, and much of Central Asia, making it the first world government and the largest empire the world had yet seen.

It is estimated that in 480 BC, 50 million people lived in the Achaemenid Empire. The empire at its peak ruled over 44% of the world's population, the highest such figure for any empire in history.
The Achaemenid Empire is noted for the release of the Jewish exiles in Babylon, building infrastructures such as the Royal Road and the Chapar (postal service), and the use of an official language, Imperial Aramaic, throughout its territories. The empire had a centralized, bureaucratic administration under the emperor, a large professional army, and civil services, inspiring similar developments in later empires.

Eventual conflict on the western borders began with the Ionian Revolt, which erupted into the Greco-Persian Wars and continued through the first half of the fifth century BC, and ended with the withdrawal of the Achaemenids from all of the territories in the Balkans and Eastern Europe proper.

In 334 BC, Alexander the Great invaded the Achaemenid Empire, defeating the last Achaemenid emperor, Darius III, at the Battle of Issus. Following the premature death of Alexander, Iran came under the control of the Hellenistic Seleucid Empire. In the middle of the second century BC, the Parthian Empire rose to become the main power in Iran, and the century-long geopolitical arch-rivalry between the Romans and the Parthians began, culminating in the Roman–Parthian Wars. The Parthian Empire continued as a feudal monarchy for nearly five centuries, until 224 CE, when it was succeeded by the Sasanian Empire. Together with their neighboring arch-rival, the Roman-Byzantines, they made up the world's two most dominant powers at the time, for over four centuries.
The Sasanians established an empire within the frontiers achieved by the Achaemenids, with their capital at Ctesiphon. Late antiquity is considered one of Iran's most influential periods, as under the Sasanians their influence reached the culture of ancient Rome (and through that as far as Western Europe), Africa, China, and India, and played a prominent role in the formation of the medieval art of both Europe and Asia.
Most of the era of the Sasanian Empire was overshadowed by the Roman–Persian Wars, which raged on the western borders at Anatolia, the Western Caucasus, Mesopotamia, and the Levant, for over 700 years. These wars ultimately exhausted both the Romans and the Sasanians and led to the defeat of both by the Muslim invasion.

Throughout the Achaemenid, Parthian, and Sasanian eras, several offshoots of the Iranian dynasties established eponymous branches in Anatolia and the Caucasus, including the Pontic Kingdom, the Mihranids, and the Arsacid dynasties of Armenia, Iberia (Georgia), and Caucasian Albania (present-day Republic of Azerbaijan and southern Dagestan).

The prolonged Byzantine–Sasanian wars, most importantly the climactic war of 602–628, as well as the social conflict within the Sasanian Empire, opened the way for an Arab invasion of Iran in the seventh century. The empire was initially defeated by the Rashidun Caliphate, which was succeeded by the Umayyad Caliphate, followed by the Abbasid Caliphate. A prolonged and gradual process of state-imposed Islamization followed, which targeted Iran's then Zoroastrian majority and included religious persecution, demolition of libraries and fire temples, a special tax penalty ("jizya"), and language shift.

In 750, the Abbasids overthrew the Umayyads, notably by the support from the "mawali" (converted Iranians). The mawali formed the majority of the rebel army, which was led by converted Iranian general Abu Muslim. The arrival of the Abbasid Caliphs saw a relative revival of Iranian culture and influence, as the role of the old Arab aristocracy was partially replaced by a Muslim Iranian bureaucracy.

After two centuries of Arab rule, semi-independent and independent Iranian kingdoms—including the Tahirids, Saffarids, Samanids, and Buyids—began to appear on the fringes of the declining Abbasid Caliphate. By the Samanid era in the ninth and 10th centuries, the efforts of Iranians to regain their independence had been well solidified.
The blossoming literature, philosophy, mathematics, medicine, astronomy and art of Iran became major elements in the formation of a new age for the Iranian civilization, during a period known as the "Islamic Golden Age". The Islamic Golden Age reached its peak by the 10th and 11th centuries, during which Iran was the main theater of scientific activities. After the 10th century, Persian, alongside Arabic, was used for scientific, medical, philosophical, arithmetical, historical, and musical works, and renowned Iranian writers—such as Tusi, Avicenna, Qotb-od-Din Shirazi, and Biruni—had major contributions in scientific writing. Among Iran's famous medieval scientists, Al-Khwarizmi (whose name was Latinized as "Algoritmi") gave a significant role in the development of the Arabic numerals and algebra through his 9th-century work "On the Calculation with Hindu Numerals" that is globally adopted as the modern numerical system.

The cultural revival that began in the Abbasid period led to a resurfacing of the Iranian national identity; thus, the attempts of Arabization never succeeded in Iran. The Shu'ubiyya movement became a catalyst for Iranians to regain independence in their relations with the Arab invaders. The most notable effect of this movement was the continuation of the Persian language attested to the works of the epic poet Ferdowsi, now considered the most prominent figure in Iranian literature.
The 10th century saw a mass migration of Turkic tribes from Central Asia into the Iranian Plateau. Turkic tribesmen were first used in the Abbasid army as mamluks (slave-warriors), replacing Iranian and Arab elements within the army. As a result, the Mamluks gained a significant political power. In 999, large portions of Iran came briefly under the rule of the Ghaznavids, whose rulers were of mamluk Turkic origin, and longer subsequently under the Seljuk and Khwarezmian empires. These dynasties had been Persianized, and had adopted Persian models of administration and rulership. The Seljuks subsequently gave rise to the Sultanate of Rum in Anatolia, while taking their thoroughly Persianized identity with them. The result of the adoption and patronage of Iranian culture by Turkish rulers was the development of a distinct Turko-Persian tradition.

From 1219 to 1221, under the Khwarazmian Empire, Iran suffered a devastating invasion by the Mongol army of Genghis Khan. According to Steven R. Ward, "Mongol violence and depredations killed up to three-fourths of the population of the Iranian Plateau, possibly 10 to 15 million people. Some historians have estimated that Iran's population did not again reach its pre-Mongol levels until the mid-20th century."

Following the fracture of the Mongol Empire in 1256, Hulagu Khan, grandson of Genghis Khan, established the Ilkhanate in Iran. In 1370, yet another conqueror, Timur, followed the example of Hulagu, establishing the Timurid Empire which lasted for another 156 years. In 1387, Timur ordered the complete massacre of Isfahan, reportedly killing 70,000 citizens. The Ilkhans and the Timurids soon came to adopt the ways and customs of the Iranians, surrounding themselves with a culture that was distinctively Iranian.

By the 1500s, Ismail I of Ardabil established the Safavid Empire, with his capital at Tabriz. Beginning with Azerbaijan, he subsequently extended his authority over all of the Iranian territories, and established an intermittent Iranian hegemony over the vast relative regions, reasserting the Iranian identity within large parts of Greater Iran. Iran was predominantly Sunni, but Ismail instigated a forced conversion to the Shia branch of Islam, spreading throughout the Safavid territories in the Caucasus, Iran, Anatolia, and Mesopotamia. As a result, modern-day Iran is the only official Shia nation of the world, with it holding an absolute majority in Iran and the Republic of Azerbaijan, having there the first and the second highest number of Shia inhabitants by population percentage in the world. Meanwhile, the centuries-long geopolitical and ideological rivalry between Safavid Iran and the neighboring Ottoman Empire led to numerous Ottoman–Iranian wars.
The Safavid era peaked in the reign of Abbas I (1587–1629), surpassing their Turkish archrivals in strength, and making Iran a leading science and art hub in western Eurasia. The Safavid era saw the start of mass integration from Caucasian populations into new layers of the society of Iran, as well as mass resettlement of them within the heartlands of Iran, playing a pivotal role in the history of Iran for centuries onwards. Following a gradual decline in the late 1600s and the early 1700s, which was caused by internal conflicts, the continuous wars with the Ottomans, and the foreign interference (most notably the Russian interference), the Safavid rule was ended by the Pashtun rebels who besieged Isfahan and defeated Sultan Husayn in 1722.

In 1729, Nader Shah, a chieftain and military genius from Khorasan, successfully drove out and conquered the Pashtun invaders. He subsequently took back the annexed Caucasian territories which were divided among the Ottoman and Russian authorities by the ongoing chaos in Iran. During the reign of Nader Shah, Iran reached its greatest extent since the Sasanian Empire, reestablishing the Iranian hegemony all over the Caucasus, as well as other major parts of the west and central Asia, and briefly possessing what was arguably the most powerful empire at the time.
Nader Shah invaded India and sacked far off Delhi by the late 1730s. His territorial expansion, as well as his military successes, went into a decline following the final campaigns in the Northern Caucasus against then revolting Lezgins. The assassination of Nader Shah sparked a brief period of civil war and turmoil, after which Karim Khan of the Zand dynasty came to power in 1750, bringing a period of relative peace and prosperity.

Compared to its preceding dynasties, the geopolitical reach of the Zand dynasty was limited. Many of the Iranian territories in the Caucasus gained "de facto" autonomy, and were locally ruled through various Caucasian khanates. However, despite the self-ruling, they all remained subjects and vassals to the Zand king. Another civil war ensued after the death of Karim Khan in 1779, out of which Agha Mohammad Khan emerged, founding the Qajar dynasty in 1794.

In 1795, following the disobedience of the Georgian subjects and their alliance with the Russians, the Qajars captured Tbilisi by the Battle of Krtsanisi, and drove the Russians out of the entire Caucasus, reestablishing the Iranian suzerainty over the region.

The Russo-Iranian wars of 1804–1813 and 1826–1828 resulted in large irrevocable territorial losses for Iran in the Caucasus, comprising all of Transcaucasia and Dagestan, which made part of the very concept of Iran for centuries, and thus substantial gains for the neighboring Russian Empire.

As a result of the 19th-century Russo-Iranian wars, the Russians took over the Caucasus, and Iran irrevocably lost control over its integral territories in the region (comprising modern-day Dagestan, Georgia, Armenia, and Republic of Azerbaijan), which got confirmed per the treaties of Gulistan and Turkmenchay. The area to the north of Aras River, among which the contemporary Republic of Azerbaijan, eastern Georgia, Dagestan, and Armenia are located, were Iranian territory until they were occupied by Russia in the course of the 19th century.

As Iran shrank, many Transcaucasian and North Caucasian Muslims moved towards Iran, especially until the aftermath of the Circassian Genocide, and the decades afterwards, while Iran's Armenians were encouraged to settle in the newly incorporated Russian territories, causing significant demographic shifts.

Around 1.5 million people—20 to 25% of the population of Iran—died as a result of the Great Famine of 1870–1871.
Between 1872 and 1905, a series of protests took place in response to the sale of concessions to foreigners by Qajar monarchs Naser-ed-Din and Mozaffar-ed-Din, and led to the Constitutional Revolution in 1905. The first Iranian constitution and the first national parliament of Iran were founded in 1906, through the ongoing revolution. The Constitution included the official recognition of Iran's three religious minorities, namely Christians, Jews, and Zoroastrians, which has remained a basis in the legislation of Iran since then. The struggle related to the constitutional movement was followed by the Triumph of Tehran in 1909, when Mohammad Ali Shah was defeated and forced to abdicate. On the pretext of restoring order, the Russians occupied northern Iran in 1911 and maintained a military presence in the region for years to come. But this did not put an end to the civil uprisings and was soon followed by Mirza Kuchik Khan's Jungle Movement against both the Qajar monarchy and foreign invaders.
Despite Iran's neutrality during World War I, the Ottoman, Russian and British empires occupied the territory of western Iran and fought the Persian Campaign before fully withdrawing their forces in 1921. At least 2 million Persian civilians died either directly in the fighting, the Ottoman perpetrated anti-Christian genocides or the war induced famine of 1917-1919. A large number of Iranian Assyrian and Iranian Armenian Christians, as well as those Muslims who tried to protect them, were victims of mass murders committed by the invading Ottoman troops, notably in and around Khoy, Maku, Salmas, and Urmia.

Apart from the rule of Agha Mohammad Khan, the Qajar rule is characterized as a century of misrule. The inability of Qajar Iran's government to maintain the country's sovereignty during and immediately after World War I led to the British directed 1921 Persian coup d'état and Reza Shah's establishment of the Pahlavi dynasty. Reza Shah, became the new Prime Minister of Iran and was declared the new monarch in 1925.

In the midst of World War II, in June 1941, Nazi Germany broke the Molotov–Ribbentrop Pact and invaded the Soviet Union, Iran's northern neighbor. The Soviets quickly allied themselves with the Allied countries and in July and August, 1941 the British demanded that the Iranian government expel all Germans from Iran. Reza Shah refused to expel the Germans and on 25 August 1941, the British and Soviets launched a surprise invasion and Reza Shah's government quickly surrendered. The invasion's strategic purpose was to secure a supply line to the USSR (later named the Persian Corridor), secure the oil fields and Abadan Refinery (of the UK-owned Anglo-Iranian Oil Company), prevent a German advance via Turkey or the USSR on Baku's oil fields, and limit German influence in Iran. Following the invasion, on 16 September 1941 Reza Shah abdicated and was replaced by Mohammad Reza Pahlavi, his 21 year old son.
During the rest of World War II, Iran became a major conduit for British and American aid to the Soviet Union and an avenue through which over 120,000 Polish refugees and Polish Armed Forces fled the Axis advance. At the 1943 Tehran Conference, the Allied "Big Three"—Joseph Stalin, Franklin D. Roosevelt, and Winston Churchill—issued the Tehran Declaration to guarantee the post-war independence and boundaries of Iran. However, at the end of the war, Soviet troops remained in Iran and established two puppet states in north-western Iran, namely the People's Government of Azerbaijan and the Republic of Mahabad. This led to the Iran crisis of 1946, one of the first confrontations of the Cold War, which ended after oil concessions were promised to the USSR and Soviet forces withdrew from Iran proper in May 1946. The two puppet states were soon overthrown and the oil concessions were later revoked.

In 1951, Mohammad Mosaddegh was appointed as the Prime Minister. He became enormously popular in Iran after he nationalized Iran's petroleum industry and oil reserves. He was deposed in the 1953 Iranian coup d'état, an Anglo-American covert operation that marked the first time the United States had participated in the overthrow of a foreign government during the Cold War.

After the coup, the Shah became increasingly autocratic and sultanistic, and Iran entered a phase of decades-long controversial close relations with the United States and some other foreign governments. While the Shah increasingly modernized Iran and claimed to retain it as a fully secular state, arbitrary arrests and torture by his secret police, the SAVAK, were used to crush all forms of political opposition.

Ruhollah Khomeini, a radical Muslim cleric, became an active critic of the Shah's far-reaching series of reforms known as the "White Revolution". Khomeini publicly denounced the government, and was arrested and imprisoned for 18 months. After his release in 1964, he refused to apologize, and was eventually sent into exile.

Due to the 1973 spike in oil prices, the economy of Iran was flooded with foreign currency, which caused inflation. By 1974, the economy of Iran was experiencing double digit inflation, and despite the many large projects to modernize the country, corruption was rampant and caused large amounts of waste. By 1975 and 1976, an economic recession led to increased unemployment, especially among millions of youths who had migrated to the cities of Iran looking for construction jobs during the boom years of the early 1970s. By the late 1970s, many of these people opposed the Shah's regime and began to organize and join the protests against it.

The 1979 Revolution, later known as the "Islamic Revolution", began in January 1978 with the first major demonstrations against the Shah. After a year of strikes and demonstrations paralyzing the country and its economy, Mohammad Reza Pahlavi fled to the United States, and Ruhollah Khomeini returned from exile to Tehran in February 1979, forming a new government. After holding a referendum, Iran officially became an Islamic republic in April 1979. A second referendum in December 1979 approved a theocratic constitution.

The immediate nationwide uprisings against the new government began with the 1979 Kurdish rebellion and the Khuzestan uprisings, along with the uprisings in Sistan and Baluchestan and other areas. Over the next several years, these uprisings were subdued in a violent manner by the new Islamic government. The new government began purging itself of the non-Islamist political opposition, as well as of those Islamists who were not considered radical enough. Although both nationalists and Marxists had initially joined with Islamists to overthrow the Shah, tens of thousands were executed by the new regime afterwards. Many former ministers and officials in the Shah's government, including former prime minister Amir-Abbas Hoveyda, were executed following Khomeini's order to purge the new government of any remaining officials still loyal to the exiled Shah.

On 4 November 1979, a group of Muslim students seized the United States Embassy and took the embassy with 52 personnel and citizens hostage, after the United States refused to extradite Mohammad Reza Pahlavi to Iran, where his execution was all but assured. Attempts by the Jimmy Carter administration to negotiate for the release of the hostages, and a failed rescue attempt, helped force Carter out of office and brought Ronald Reagan to power. On Jimmy Carter's final day in office, the last hostages were finally set free as a result of the Algiers Accords. Mohammad Reza Pahlavi left the United States for Egypt, where he died of complications from cancer only months later, on 27 July 1980.

The Cultural Revolution began in 1980, with an initial closure of universities for three years, in order to perform an inspection and clean up in the cultural policy of the education and training system.
On 22 September 1980, the Iraqi army , launching the Iran–Iraq War. Although the forces of Saddam Hussein made several early advances, by mid 1982, the Iranian forces successfully managed to into Iraq. In July 1982, with Iraq thrown on the defensive, the regime of Iran took the decision to invade Iraq and conducted countless offensives in a bid to conquer Iraqi territory and capture cities, such as Basra. The war continued until 1988 when the Iraqi army defeated the Iranian forces inside Iraq and pushed the remaining Iranian troops back across the border. Subsequently, Khomeini accepted a truce mediated by the United Nations. The total Iranian casualties in the war were estimated to be 123,220–160,000 KIA, 60,711 MIA, and 11,000–16,000 civilians killed.
Following the Iran–Iraq War, in 1989, Akbar Hashemi Rafsanjani and his administration concentrated on a pragmatic pro-business policy of rebuilding and strengthening the economy without making any dramatic break with the ideology of the revolution. In 1997, Rafsanjani was succeeded by moderate reformist Mohammad Khatami, whose government attempted, unsuccessfully, to make the country more free and democratic.

The 2005 presidential election brought conservative populist candidate, Mahmoud Ahmadinejad, to power. By the time of the 2009 Iranian presidential election, the Interior Ministry announced incumbent President Ahmadinejad had won 62.63% of the vote, while Mir-Hossein Mousavi had come in second place with 33.75%. The election results were widely disputed, and resulted in widespread protests, both within Iran and in major cities outside the country, and the creation of the Iranian Green Movement.

Hassan Rouhani was elected as the president on 15 June 2013, defeating Mohammad Bagher Ghalibaf and four other candidates. The electoral victory of Rouhani relatively improved the relations of Iran with other countries.
The 2017–18 Iranian protests swept across the country against the government and its longtime Supreme Leader in response to the economic and political situation. The scale of protests throughout the country and the number of people participating were significant, and it was formally confirmed that thousands of protesters were arrested. The 2019–20 Iranian protests started on 15 November in Ahvaz, spreading across the country within hours, after the government announced increases in the fuel price of up to 300%. A week-long total Internet shutdown throughout the country marked one of the most severe Internet blackouts in any country, and according to international observers, tens of thousands were arrested and hundreds were killed within a few days.

On 3 January 2020, the revolutionary guard's general, Qasem Soleimani, was assassinated by the United States in Iraq, which considerably heightened the existing tensions between the two countries. Three days after, Iran's Islamic Revolutionary Guard Corps launched a retaliatory attack on US forces in Iraq and shot down Ukraine International Airlines Flight 752, killing 176 civilians and leading to nation-wide protests. An international investigation led to the government admitting to the shootdown of the plane by a surface-to-air missile after three days of denial, calling it a "human error".

Iran has an area of . It lies between latitudes 24° and 40° N, and longitudes 44° and 64° E. It is bordered to the northwest by Armenia (), the Azeri exclave of Nakhchivan (), and the Republic of Azerbaijan (); to the north by the Caspian Sea; to the northeast by Turkmenistan (); to the east by Afghanistan () and Pakistan (); to the south by the Persian Gulf and the Gulf of Oman; and to the west by Iraq () and Turkey ().

Iran consists of the Iranian Plateau, with the exception of the coasts of the Caspian Sea and Khuzestan. It is one of the world's most mountainous countries, its landscape dominated by rugged mountain ranges that separate various basins or plateaux from one another. The populous western part is the most mountainous, with ranges such as the Caucasus, Zagros, and Alborz, the last containing Mount Damavand, Iran's highest point at , which is also the highest mountain in Asia west of the Hindu Kush.

The northern part of Iran is covered by the lush lowland Caspian Hyrcanian mixed forests, located near the southern shores of the Caspian Sea. The eastern part consists mostly of desert basins, such as the Kavir Desert, which is the country's largest desert, and the Lut Desert, as well as some salt lakes.

The only large plains are found along the coast of the Caspian Sea and at the northern end of the Persian Gulf, where the country borders the mouth of the Arvand river. Smaller, discontinuous plains are found along the remaining coast of the Persian Gulf, the Strait of Hormuz, and the Gulf of Oman.

Having 11 climates out of the world's 13, Iran's climate is diverse, ranging from arid and semi-arid, to subtropical along the Caspian coast and the northern forests. On the northern edge of the country (the Caspian coastal plain), temperatures rarely fall below freezing and the area remains humid for the rest of the year. Summer temperatures rarely exceed . Annual precipitation is in the eastern part of the plain and more than in the western part. Gary Lewis, the United Nations Resident Coordinator for Iran, has said that "Water scarcity poses the most severe human security challenge in Iran today".

To the west, settlements in the Zagros basin experience lower temperatures, severe winters with below zero average daily temperatures and heavy snowfall. The eastern and central basins are arid, with less than of rain, and have occasional deserts. Average summer temperatures rarely exceed . The coastal plains of the Persian Gulf and Gulf of Oman in southern Iran have mild winters, and very humid and hot summers. The annual precipitation ranges from .

The wildlife of Iran is composed of several animal species, including bears, the Eurasian lynx, foxes, gazelles, gray wolves, jackals, panthers, and wild pigs. Other domestic animals of Iran include Asian water buffaloes, camels, cattle, donkeys, goats, horses, and the sheep. Eagles, falcons, partridges, pheasants, and storks are also native to the wildlife of Iran.

One of the most famous members of the Iranian wildlife is the critically endangered Asiatic cheetah, also known as the "Iranian cheetah", whose numbers were greatly reduced after the 1979 Revolution. The Persian leopard, which is the world's largest leopard subspecies living primarily in northern Iran, is also listed as an endangered species. Iran lost all its Asiatic lions and the now extinct Caspian tigers by the earlier part of the 20th century.

At least 74 species of the Iranian wildlife are on the red list of the International Union for Conservation of Nature, a sign of serious threats against the country's biodiversity. The Iranian Parliament has been showing disregard for wildlife by passing laws and regulations such as the act that lets the Ministry of Industries and Mines exploit mines without the involvement of the Department of Environment, and by approving large national development projects without demanding comprehensive study of their impact on wildlife habitats.

Iran is divided into five regions with thirty-one provinces ("ostān"), each governed by an appointed governor ("ostāndār"). The provinces are divided into counties ("šahrestān"), and subdivided into districts ("baxš") and sub-districts ("dehestān").

The country has one of the highest urban growth rates in the world. From 1950 to 2002, the urban proportion of the population increased from 27% to 60%. The United Nations predicts that by 2030, 80% of the population will be urban. Most internal migrants have settled around the cities of Tehran, Isfahan, Ahvaz, and Qom. The listed populations are from the 2006/07 (1385 AP) census.
Tehran, with a population of around 8.8 million (2016 census), is the capital and largest city of Iran. It is an economical and cultural center, and is the hub of the country's communication and transport network.

The country's second most populous city, Mashhad, has a population of around 3.3 million (2016 census), and is capital of the province of Razavi Khorasan. Being the site of the Imam Reza Shrine, it is a holy city in Shia Islam. About 15 to 20 million pilgrims visit the shrine every year.

Isfahan has a population of around 2.2 million (2016 census), and is Iran's third most populous city. It is the capital of the province of Isfahan, and was also the third capital of the Safavid Empire. It is home to a wide variety of historical sites, including the famous Shah Square, Siosepol, and the churches at the Armenian district of New Julfa. It is also home to the world's seventh largest shopping mall, Isfahan City Center.

The fourth most populous city of Iran, Karaj, has a population of around 1.9 million (2016 census). It is the capital of the province of Alborz, and is situated 20 km west of Tehran, at the foot of the Alborz mountain range. It is a major industrial city in Iran, with large factories producing sugar, textiles, wire, and alcohol.

With a population of around 1.7 million (2016 census), Tabriz is the fifth most populous city of Iran, and had been the second most populous until the late 1960s. It was the first capital of the Safavid Empire, and is now the capital of the province of East Azerbaijan. It is also considered the country's second major industrial city (after Tehran).

Shiraz, with a population of around 1.8 million (2016 census), is Iran's sixth most populous city. It is the capital of the province of Fars, and was also the capital of Iran under the reign of the Zand dynasty. It is located near the ruins of Persepolis and Pasargadae, two of the four capitals of the Achaemenid Empire.

The political system of the Islamic Republic is based on the 1979 Constitution. According to international reports, Iran's human rights record is exceptionally poor. The regime in Iran is undemocratic, has frequently persecuted and arrested critics of the government and its Supreme Leader, and severely restricts the participation of candidates in popular elections as well as other forms of political activity. Women's rights in Iran are described as seriously inadequate, and children's rights have been severely violated, with more child offenders being executed in Iran than in any other country in the world. Sexual activity between members of the same sex is illegal and is punishable by up to death. Since the 2000s, Iran's controversial nuclear program has raised concerns, which is part of the basis of the international sanctions against the country. The Joint Comprehensive Plan of Action, an agreement reached between Iran and the P5+1, was created on 14 July 2015, aimed to loosen the nuclear sanctions in exchange for Iran's restriction in producing enriched uranium.

Over the past decade, numbers of anti-government protests have broken out throughout Iran (such as the 2019–20 Iranian protests), demanding reforms or the end to the Islamic Republic. However, the IRGC and police often suppressed mass protests by violent means, which resulted in thousands of protesters killed.

The Leader of the Revolution ("Supreme Leader") is responsible for delineation and supervision of the policies of the Islamic Republic of Iran. The Iranian president has limited power compared to the Supreme Leader Khamenei. The current longtime Supreme Leader, Ali Khamenei, has been issuing decrees and making the final decisions on the economy, environment, foreign policy, education, national plannings, and everything else in the country. Khamenei also outlines elections guidelines and urges for the transparency, and has fired and reinstated presidential cabinet appointments. Key ministers are selected with the Supreme Leader Ali Khamenei's agreement and he has the ultimate say on Iran's foreign policy. The president-elect is required to gain the Leader Khamenei's official approval before being sworn in before the Parliament (Majlis). Through this process, known as Tanfiz (validation), the Leader agrees to the outcome of the presidential election. The Supreme Leader is directly involved in ministerial appointments for Defense, Intelligence and Foreign Affairs, as well as other top ministries after submission of candidates from the president. Iran's regional policy is directly controlled by the office of the Supreme Leader with the Ministry of Foreign Affairs' task limited to protocol and ceremonial occasions. All of Iran's ambassadors to Arab countries, for example, are chosen by the Quds Corps, which directly reports to the Supreme Leader. The budget bill for every year, as well as withdrawing money from the National Development Fund of Iran, require Supreme Leader Ali Khamenei's approval and permission. The Supreme Leader Khamenei can and did order laws to be amended. Setad, estimated at $95 billion in 2013 by the Reuters, accounts of which are secret even to the Iranian parliament, is controlled only by the Supreme Leader.
The Supreme Leader is the commander-in-chief of the armed forces, controls the military intelligence and security operations, and has sole power to declare war or peace. The heads of the judiciary, the state radio and television networks, the commanders of the police and military forces, and six of the twelve members of the Guardian Council are directly appointed by the Supreme Leader.

The Assembly of Experts is responsible for electing the Supreme Leader, and has the power to dismiss him on the basis of qualifications and popular esteem. To date, the Assembly of Experts has not challenged any of the Supreme Leader's decisions, nor has it attempted to dismiss him. The previous head of the judicial system, Sadeq Larijani, appointed by the Supreme Leader, said that it is illegal for the Assembly of Experts to supervise the Supreme Leader. Due to Khamenei's very longtime unchallenged rule, many believe the Assembly of Experts has become a ceremonial body without any real power. There have been instances when the current Supreme Leader publicly criticized members of the Assembly of Experts, resulting in their arrest and dismissal. For example, Khamenei publicly called then-member of the Assembly of Experts Ahmad Azari Qomi a traitor, resulting in Qomi's arrest and eventual dismissal from the Assembly of Experts. Another instance is when Khamenei indirectly called Akbar Hashemi Rafsanjani a traitor for a statement he made, causing Rafsanjani to retract it.

Presidential candidates and parliamentary candidates must be approved by the Guardian Council (all members of which are directly or indirectly appointed by the Leader) or the Leader before running, in order to ensure their allegiance to the Supreme Leader. The Leader very rarely does the vetting himself directly, but has the power to do so, in which case additional approval of the Guardian Council would not be needed. The Leader can also revert the decisions of the Guardian Council. The Guardian Council can, and has dismissed some elected members of the Iranian parliament in the past. For example, Minoo Khaleghi was disqualified by Guardian Council even after winning election, as she had been photographed in a meeting without wearing headscarf.

After the Supreme Leader, the Constitution defines the President of Iran as the highest state authority. The President is elected by universal suffrage for a term of four years, however, the president is still required to gain the Leader's official approval before being sworn in before the Parliament (Majlis). The Leader also has the power to dismiss the elected president anytime. The President can only be re-elected for one term.
The President is responsible for the implementation of the constitution, and for the exercise of executive powers in implementing the decrees and general policies as outlined by the Supreme Leader, except for matters directly related to the Supreme Leader, who has the final say in all matters. Unlike the executive in other countries, the President of Iran does not have full control over anything, as these are ultimately under the control of the Supreme Leader. Chapter IX of the Constitution of the Islamic Republic of Iran sets forth the qualifications for presidential candidates. The procedures for presidential election and all other elections in Iran are outlined by the Supreme Leader. The President functions as the executive of affairs such as signing treaties and other international agreements, and administering national planning, budget, and state employment affairs, all as approved by the Supreme Leader.

The President appoints the ministers, subject to the approval of the Parliament, as well as the approval of the Supreme Leader, who can dismiss or reinstate any of the ministers at any time, regardless of the decisions made by the President or the Parliament. The President supervises the Council of Ministers, coordinates government decisions, and selects government policies to be placed before the legislature. The current Supreme Leader, Ali Khamenei, has fired as well as reinstated Council of Ministers members. Eight Vice Presidents serve under the President, as well as a cabinet of twenty-two ministers, who must all be approved by the legislature.

The legislature of Iran, known as the "Islamic Consultative Assembly", is a unicameral body comprising 290 members elected for four-year terms. It drafts legislation, ratifies international treaties, and approves the national budget. All parliamentary candidates and all legislation from the assembly must be approved by the Guardian Council.

The Guardian Council comprises twelve jurists, including six appointed by the Supreme Leader. Others are elected by the Parliament, from among the jurists nominated by the Head of the Judiciary. The Council interprets the constitution and may veto the Parliament. If a law is deemed incompatible with the constitution or Sharia (Islamic law), it is referred back to the Parliament for revision. The Expediency Council has the authority to mediate disputes between the Parliament and the Guardian Council, and serves as an advisory body to the Supreme Leader, making it one of the most powerful governing bodies in the country. Local city councils are elected by public vote to four-year terms in all cities and villages of Iran.

The Supreme Leader appoints the head of the country's judiciary, who in turn appoints the head of the Supreme Court and the chief public prosecutor. There are several types of courts, including public courts that deal with civil and criminal cases, and revolutionary courts which deal with certain categories of offenses, such as crimes against national security. The decisions of the revolutionary courts are final and cannot be appealed.

The Special Clerical Court handles crimes allegedly committed by clerics, although it has also taken on cases involving laypeople. The Special Clerical Court functions independently of the regular judicial framework, and is accountable only to the Supreme Leader. The Court's rulings are final and cannot be appealed. The Assembly of Experts, which meets for one week annually, comprises 86 "virtuous and learned" clerics elected by adult suffrage for eight-year terms.

The officially stated goal of the government of Iran is to establish a new world order based on world peace, global collective security, and justice. Since the time of the 1979 Revolution, Iran's foreign relations have often been portrayed as being based on two strategic principles; eliminating outside influences in the region, and pursuing extensive diplomatic contacts with developing and non-aligned countries.

Since 2005, Iran's nuclear program has become the subject of contention with the international community, mainly the United States. Many countries have expressed concern that Iran's nuclear program could divert civilian nuclear technology into a weapons program. This has led the United Nations Security Council to impose sanctions against Iran which had further isolated Iran politically and economically from the rest of the global community. In 2009, the U.S. Director of National Intelligence said that Iran, if choosing to, would not be able to develop a nuclear weapon until 2013.
, the government of Iran maintains diplomatic relations with 99 members of the United Nations, but not with the United States, and not with Israel—a state which Iran's government has derecognized since the 1979 Revolution. Among Muslim nations, Iran has an adversarial relationship with Saudi Arabia due to different political and Islamic ideologies. While Iran is a Shia Islamic Republic, Saudi Arabia is a conservative Sunni monarchy. Regarding the Israeli–Palestinian conflict, the government of Iran has recognized Jerusalem as the capital of the State of Palestine, after Trump recognized Jerusalem as the capital of Israel.

On 14 July 2015, Tehran and the P5+1 came to a historic agreement ("Joint Comprehensive Plan of Action") to end economic sanctions after demonstrating a peaceful nuclear research project that would meet the International Atomic Energy Agency standards.
Iran is a member of dozens of international organizations, including the G-15, G-24, G-77, IAEA, IBRD, IDA, IDB, IFC, ILO, IMF, IMO, Interpol, OIC, OPEC, WHO, and the United Nations, and currently has observer status at the World Trade Organization.

In September 2018, the Iranian ambassador to the United Nations asked the UN to condemn Israeli threats against Tehran and also bring Israel's nuclear program under the International Atomic Energy Agency's supervision.

In April 2019 the U.S. threatened to sanction countries continuing to buy oil from Iran after an initial six-month waiver announced in November expired. According to the BBC, U.S. sanctions against Iran "have led to a sharp downturn in Iran's economy, pushing the value of its currency to record lows, quadrupling its annual inflation rate, driving away foreign investors, and triggering protests."

On 1 September 2019, the Iranian authorities took a step to enhance its relations with Qatar, and decided to grant Qatari passport holders tourist visas upon arrival at Iranian airports. Besides, Qatari nationals were also permitted to obtain a single or multiple-entry visa from Iran's embassy in Doha.

The Islamic Republic of Iran has two types of armed forces: the regular forces of the Army, the Air Force, and the Navy, and the Revolutionary Guards, totaling about 545,000 active troops. Iran also has around 350,000 Reserve Force, totaling around 900,000 trained troops.

The government of Iran has a paramilitary, volunteer militia force within the Islamic Revolutionary Guard Corps, called the "Basij", which includes about 90,000 full-time, active-duty uniformed members. Up to 11 million men and women are members of the Basij who could potentially be called up for service. GlobalSecurity.org estimates Iran could mobilize "up to one million men", which would be among the largest troop mobilizations in the world. In 2007, Iran's military spending represented 2.6% of the GDP or $102 per capita, the lowest figure of the Persian Gulf nations. Iran's military doctrine is based on deterrence. In 2014, the country spent $15 billion on arms, while the states of the Gulf Cooperation Council spent eight times more. The United States under President Donald Trump officially labeled the Revolutionary Guard as a foreign terrorist organization. It is the first time that an element of a foreign state was designated as a terrorist organization.

The government of Iran supports the military activities of its allies in Syria, Iraq, and Lebanon (Hezbollah) with military and financial aid. Iran and Syria are close strategic allies, and Iran has provided significant support for the Syrian Government in the Syrian Civil War. According to some estimates, Iran controlled over 80,000 pro-Assad Shi'ite fighters in Syria.

Since the 1979 Revolution, to overcome foreign embargoes, the government of Iran has developed its own military industry, produced its own tanks, armored personnel carriers, missiles, submarines, military vessels, missile destroyer, radar systems, helicopters, and fighter planes. In recent years, official announcements have highlighted the development of weapons such as the Hoot, Kowsar, Zelzal, Fateh-110, Shahab-3, Sejjil, and a variety of unmanned aerial vehicles (UAVs). Iran has the largest and most diverse ballistic missile arsenal in the Middle East. The Fajr-3, a liquid fuel missile with an undisclosed range which was developed and produced domestically, is currently the most advanced ballistic missile of the country.

In June 1925, Reza Shah introduced conscription law at National Consultative Majlis. At that time every male person who had reached 21 years old must serve for military for two years. The conscription exempted women from military service after 1979 revolution. Iranian constitution obliges all men of 18 years old and higher to serve in military or police bases. They cannot leave the country or be employed without completion of the service period. The period varies from 18 to 24 months. Inappropriate situation of Iranian soldiers has caused violent incidents in recent years. Most of Iranian soldiers suffer from depression. In addition, some researches have reported high rate of suicide among Iranian conscripts.

Iran's economy is a mixture of central planning, state ownership of oil and other large enterprises, village agriculture, and small-scale private trading and service ventures. In 2017, GDP was $427.7 billion ($1.631 trillion at PPP), or $20,000 at PPP per capita. Iran is ranked as an upper-middle income economy by the World Bank. In the early 21st century, the service sector contributed the largest percentage of the GDP, followed by industry (mining and manufacturing) and agriculture.

The Central Bank of the Islamic Republic of Iran is responsible for developing and maintaining the Iranian rial, which serves as the country's currency. The government does not recognize trade unions other than the Islamic labour councils, which are subject to the approval of employers and the security services. The minimum wage in June 2013 was 487 million rials a month ($134). Unemployment has remained above 10% since 1997, and the unemployment rate for women is almost double that of the men.
In 2006, about 45% of the government's budget came from oil and natural gas revenues, and 31% came from taxes and fees. , Iran had earned $70 billion in foreign-exchange reserves, mostly (80%) from crude oil exports. Iranian budget deficits have been a chronic problem, mostly due to large-scale state subsidies, that include foodstuffs and especially gasoline, totaling more than $84 billion in 2008 for the energy sector alone. In 2010, the economic reform plan was approved by parliament to cut subsidies gradually and replace them with targeted social assistance. The objective is to move towards free market prices in a five-year period and increase productivity and social justice.

The administration continues to follow the market reform plans of the previous one, and indicates that it will diversify Iran's oil-reliant economy. Iran has also developed a biotechnology, nanotechnology, and pharmaceutical industry. However, nationalized industries such as the bonyads have often been managed badly, making them ineffective and uncompetitive with years. Currently, the government is trying to privatize these industries, and, despite successes, there are still several problems to be overcome, such as the lagging corruption in the public sector and lack of competitiveness.

Iran has leading manufacturing industries in the fields of automobile manufacture, transportation, construction materials, home appliances, food and agricultural goods, armaments, pharmaceuticals, information technology, and petrochemicals in the Middle East. According to the 2012 data from the Food and Agriculture Organization, Iran has been among the world's top five producers of apricots, cherries, sour cherries, cucumbers and gherkins, dates, eggplants, figs, pistachios, quinces, walnuts, and watermelons.

Economic sanctions against Iran, such as the embargo against Iranian crude oil, have affected the economy. Sanctions have led to a steep fall in the value of the rial, and , one US dollar is worth 36,000 rial, compared with 16,000 in early 2012. In 2018, after the withdrawal of the US from the JCPOA, the price of dollar hit an all-time high at just over 190,000 rials, which halted the market from trades and stores from selling goods, particularly in the consumer electronics sector until the prices were stable. In 2015, Iran and the P5+1 reached a deal on the nuclear program that removed the main sanctions pertaining to Iran's nuclear program by 2016.

Although tourism declined significantly during the war with Iraq, it has been subsequently recovered. About 1,659,000 foreign tourists visited Iran in 2004, and 2.3 million in 2009, mostly from Asian countries, including the republics of Central Asia, while about 10% came from the European Union and North America. Since the removal of some sanctions against Iran in 2015, tourism has re-surged in the country. Over five million tourists visited Iran in the fiscal year of 2014–2015, four percent more than the previous year.

Alongside the capital, the most popular tourist destinations are Isfahan, Mashhad, and Shiraz. In the early 2000s, the industry faced serious limitations in infrastructure, communications, industry standards, and personnel training. The majority of the 300,000 travel visas granted in 2003 were obtained by Asian Muslims, who presumably intended to visit pilgrimage sites in Mashhad and Qom. Several organized tours from Germany, France, and other European countries come to Iran annually to visit archaeological sites and monuments. In 2003, Iran ranked 68th in tourism revenues worldwide. According to the UNESCO and the deputy head of research for Iran's Tourism Organization, Iran is rated fourth among the top 10 destinations in the Middle East. Domestic tourism in Iran is one of the largest in the world. Weak advertising, unstable regional conditions, a poor public image in some parts of the world, and absence of efficient planning schemes in the tourism sector have all hindered the growth of tourism.

Iran has the world's second largest proved gas reserves after Russia, with 33.6 trillion cubic metres, and the third largest natural gas production after Indonesia and Russia. It also ranks fourth in oil reserves with an estimated 153,600,000,000 barrels. It is OPEC's second largest oil exporter, and is an energy superpower.
In 2005, Iran spent US$4 billion on fuel imports, because of contraband and inefficient domestic use. Oil industry output averaged in 2005, compared with the peak of six million barrels per day reached in 1974. In the early 2000s, industry infrastructure was increasingly inefficient because of technological lags. Few exploratory wells were drilled in 2005.

In 2004, a large share of Iran's natural gas reserves were untapped. The addition of new hydroelectric stations and the streamlining of conventional coal and oil-fired stations increased installed capacity to 33,000 megawatts. Of that amount, about 75% was based on natural gas, 18% on oil, and 7% on hydroelectric power. In 2004, Iran opened its first wind-powered and geothermal plants, and the first solar thermal plant was to come online in 2009. Iran is the world's third country to have developed GTL technology.

Demographic trends and intensified industrialization have caused electric power demand to grow by 8% per year. The government's goal of 53,000 megawatts of installed capacity by 2010 is to be reached by bringing on line new gas-fired plants, and adding hydropower and nuclear power generation capacity. Iran's first nuclear power plant at Bushire went online in 2011. It is the second nuclear power plant ever built in the Middle East after the Metsamor Nuclear Power Plant in Armenia.

In 2020 Fatih Birol the head of the International Energy Agency said that fossil fuel subsidies should be redirected, for example to the health system.

Education in Iran is highly centralized. K–12 is supervised by the Ministry of Education, and higher education is under the supervision of the Ministry of Science and Technology. The adult literacy rated 93.0% in September 2015, while it had rated 85.0% in 2008, up from 36.5% in 1976.

According to the data provided by UNESCO, Iran's literacy rate among people aged 15 years and older was 85.54% as of 2016, with men (90.35%) being significantly more educated than women (80.79%), with the number of illiterate people of the same age amounting to around 8,700,000 of the country's 85 million population. According to this report, Iranian government's expenditure on education amounts to around 4% of the GDP.

The requirement to enter into higher education is to have a high school diploma and pass the Iranian University Entrance Exam (officially known as "konkur" (کنکور)), which is the equivalent of the SAT and ACT exams of the United States. Many students do a 1–2-year course of pre-university ("piš-dānešgāh"), which is the equivalent of the GCE A-levels and the International Baccalaureate. The completion of the pre-university course earns students the Pre-University Certificate.
Iran's higher education is sanctioned by different levels of diplomas, including an associate degree ("kārdāni"; also known as "fowq e diplom") delivered in two years, a bachelor's degree ("kāršenāsi"; also known as "lisāns") delivered in four years, and a master's degree ("kāršenāsi e aršad") delivered in two years, after which another exam allows the candidate to pursue a doctoral program (PhD; known as "doktorā").

According to the Webometrics Ranking of World Universities (), Iran's top five universities include Tehran University of Medical Sciences (478th worldwide), the University of Tehran (514th worldwide), Sharif University of Technology (605th worldwide), Amirkabir University of Technology (726th worldwide), and the Tarbiat Modares University (789th worldwide).

Iran has increased its publication output nearly tenfold from 1996 through 2004, and has been ranked first in terms of output growth rate, followed by China. According to a study by SCImago in 2012, Iran would rank fourth in the world in terms of research output by 2018, if the current trend persists.
In 2009, a SUSE Linux-based HPC system made by the Aerospace Research Institute of Iran (ARI) was launched with 32 cores, and now runs 96 cores. Its performance was pegged at 192 GFLOPS. The Iranian humanoid robot Sorena 2, which was designed by engineers at the University of Tehran, was unveiled in 2010. The Institute of Electrical and Electronics Engineers (IEEE) has placed the name of Surena among the five prominent robots of the world after analyzing its performance.

In the biomedical sciences, Iran's Institute of Biochemistry and Biophysics has a UNESCO chair in biology. In late 2006, Iranian scientists successfully cloned a sheep by somatic cell nuclear transfer, at the Royan Research Center in Tehran.

According to a study by David Morrison and Ali Khadem Hosseini (Harvard-MIT and Cambridge), stem cell research in Iran is amongst the top 10 in the world. Iran ranks 15th in the world in nanotechnologies.
Iran placed its domestically built satellite Omid into orbit on the 30th anniversary of the 1979 Revolution, on 2February 2009, through its first expendable launch vehicle Safir, becoming the ninth country in the world capable of both producing a satellite and sending it into space from a domestically made launcher.

The Iranian nuclear program was launched in the 1950s. Iran is the seventh country to produce uranium hexafluoride, and controls the entire nuclear fuel cycle.

Iranian scientists outside Iran have also made some major contributions to science. In 1960, Ali Javan co-invented the first gas laser, and fuzzy set theory was introduced by Lotfi A. Zadeh. Iranian cardiologist Tofigh Mussivand invented and developed the first artificial cardiac pump, the precursor of the artificial heart. Furthering research and treatment of diabetes, the HbA1c was discovered by Samuel Rahbar. Iranian physics is especially strong in string theory, with many papers being published in Iran. Iranian American string theorist Kamran Vafa proposed the Vafa–Witten theorem together with Edward Witten. In August 2014, Iranian mathematician Maryam Mirzakhani became the first woman, as well as the first Iranian, to receive the Fields Medal, the highest prize in mathematics.

Iran is a diverse country, consisting of numerous ethnic and linguistic groups that are unified through a shared Iranian nationality.

Iran's population grew rapidly during the latter half of the 20th century, increasing from about 19 million in 1956 to more than 84 million by July 2020. However, Iran's fertility rate has dropped significantly in recent years, coming down from a fertility rate of 6.5 per woman to less than 2 just two decades later, leading to a population growth rate of about 1.39% as of 2018. Due to its young population, studies project that the growth will continue to slow until it stabilizes around 105 million by 2050.

Iran hosts one of the largest refugee populations in the world, with almost one million refugees, mostly from Afghanistan and Iraq. Since 2006, Iranian officials have been working with the UNHCR and Afghan officials for their repatriation. According to estimates, about five million Iranian citizens have emigrated to other countries, mostly since the 1979 Revolution.

According to the Iranian Constitution, the government is required to provide every citizen of the country with access to social security, covering retirement, unemployment, old age, disability, accidents, calamities, health and medical treatment and care services. This is covered by tax revenues and income derived from public contributions.

The majority of the population speak Persian, which is also the official language of the country. Others include speakers of a number of other Iranian languages within the greater Indo-European family, and languages belonging to some other ethnicities living in Iran.

In northern Iran, mostly confined to Gilan and Mazenderan, the Gilaki and Mazenderani languages are widely spoken, both having affinities to the neighboring Caucasian languages. In parts of Gilan, the Talysh language is also widely spoken, which stretches up to the neighboring Republic of Azerbaijan. Varieties of Kurdish are widely spoken in the province of Kurdistan and nearby areas. In Khuzestan, several distinct varieties of Persian are spoken. Luri and Lari are also spoken in southern Iran.

Azerbaijani, which is by far the most spoken language in the country after Persian, as well as a number of other Turkic languages and dialects, is spoken in various regions of Iran, especially in the region of Azerbaijan.

Notable minority languages in Iran include Armenian, Georgian, Neo-Aramaic, and Arabic. Khuzi Arabic is spoken by the Arabs in Khuzestan, as well as the wider group of Iranian Arabs. Circassian was also once widely spoken by the large Circassian minority, but, due to assimilation over the many years, no sizable number of Circassians speak the language anymore.

Percentages of spoken language continue to be a point of debate, as many opt that they are politically motivated; most notably regarding the largest and second largest ethnicities in Iran, the Persians and Azerbaijanis. Percentages given by the CIA's World Factbook include 53% Persian, 16% Azerbaijani, 10% Kurdish, 7% Mazenderani and Gilaki, 7% Luri, 2% Turkmen, 2% Balochi, 2% Arabic, and 2% the remainder Armenian, Georgian, Neo-Aramaic, and Circassian.

As with the spoken languages, the ethnic group composition also remains a point of debate, mainly regarding the largest and second largest ethnic groups, the Persians and Azerbaijanis, due to the lack of Iranian state censuses based on ethnicity. The CIA's World Factbook has estimated that around 79% of the population of Iran are a diverse Indo-European ethno-linguistic group that comprise speakers of various Iranian languages, with Persians (including Mazenderanis and Gilaks) constituting 61% of the population, Kurds 10%, Lurs 6%, and Balochs 2%. Peoples of other ethno-linguistic groups make up the remaining 21%, with Azerbaijanis constituting 16%, Arabs 2%, Turkmens and other Turkic tribes 2%, and others (such as Armenians, Talysh, Georgians, Circassians, Assyrians) 1%.

The Library of Congress issued slightly different estimates: 65% Persians (including Mazenderanis, Gilaks, and the Talysh), 16% Azerbaijanis, 7% Kurds, 6% Lurs, 2% Baloch, 1% Turkic tribal groups (incl. Qashqai and Turkmens), and non-Iranian, non-Turkic groups (incl. Armenians, Georgians, Assyrians, Circassians, and Arabs) less than 3%. It determined that Persian is the first language of at least 65% of the country's population, and is the second language for most of the remaining 35%.

Other nongovernmental estimates regarding the groups other than Persians and Azerbaijanis are roughly congruent with the World Factbook and the Library of Congress. However, many estimates regarding the number of these two groups differ significantly from the mentioned census; some place the number of ethnic Azerbaijanis in Iran between 21.6–30% of the total population, with the majority holding it on 25%. In any case, the largest population of Azerbaijanis in the world live in Iran.

Historically, early Iranian religions such as the Proto-Iranic religion and the subsequent Zoroastrianism and Manichaeism were the dominant religions in Iran, particularly during the Median, Achaemenid, Parthian, and Sasanian eras. This changed after the fall of the Sasanian Empire by the centuries-long Islamization that followed the Muslim Conquest of Iran. Iran was predominantly Sunni until the conversion of the country (as well as the people of what is today the neighboring Republic of Azerbaijan) to Shia Islam by the order of the Safavid dynasty in the 16th century.

Today, Twelver Shia Islam is the official state religion, to which about 90% to 95% of the population adhere. About 4% to 8% of the population are Sunni Muslims, mainly Kurds and Baloches. The remaining 2% are non-Muslim religious minorities, including Christians, Jews, Bahais, Mandeans, Yezidis, Yarsanis, and Zoroastrians.

There are about 3,000,000 adherents of Yarsanism, a Kurdish indigenous religion related to Zoroastrianism: making it the largest (unrecognized) minority religion in Iran. Its followers are mainly Gorani Kurds and certain groups of Lurs. They are based in Kurdistan Province, Kermanshah Province and Lorestan mainly.

Judaism has a long history in Iran, dating back to the Achaemenid conquest of Babylonia. Although many left in the wake of the establishment of the State of Israel and the 1979 Revolution, about 8,756 to 25,000 Jewish people live in Iran. Iran has the largest Jewish population in the Middle East outside of Israel.
Around 250,000 to 370,000 Christians reside in Iran, and Christianity is the country's largest recognized minority religion. Most are of Armenian background, as well as a sizable minority of Assyrians.

Christianity, Judaism, Zoroastrianism, and the Sunni branch of Islam are officially recognized by the government, and have reserved seats in the Iranian Parliament. But the Bahá'í Faith, which is said to be the largest non-Muslim religious minority in Iran is not officially recognized, and has been persecuted during its existence in Iran since the 19th century, while according to statistics center of Iran, Bahais constitute only about 0.37% of Iran, namely about 25.000 to 40.000 people, and it is also said that there does seem to be a kind of exaggeration in declaration of their population by the order of Bahais heads. Since the 1979 Revolution, the persecution of Bahais has increased with executions and denial of civil rights, especially the denial of access to higher education and employment.

The earliest attested cultures in Iran date back to the Lower Paleolithic. Owing to its geopolitical position, Iran has influenced cultures as far as Greece and Italy to the west, Russia to the north, the Arabian Peninsula to the south, and south and east Asia to the east.

The art of Iran encompasses many disciplines, including architecture, stonemasonry, metalworking, weaving, pottery, painting, and calligraphy. Iranian works of art show a great variety in style, in different regions and periods. The art of the Medes remains obscure, but has been theoretically attributed to the Scythian style. The Achaemenids borrowed heavily from the art of their neighboring civilizations, but produced a synthesis of a unique style, with an eclectic architecture remaining at sites such as Persepolis and Pasargadae. Greek iconography was imported by the Seleucids, followed by the recombination of Hellenistic and earlier Near Eastern elements in the art of the Parthians, with remains such as the Temple of Anahita and the Statue of the Parthian Nobleman. By the time of the Sasanians, Iranian art came across a general renaissance. Although of unclear development, Sasanian art was highly influential, and spread into far regions. Taq-e-Bostan, Taq-e-Kasra, Naqsh-e-Rostam, and the Shapur-Khwast Castle are among the surviving monuments from the Sasanian period.

During the Middle Ages, Sasanian art played a prominent role in the formation of both European and Asian medieval art, which carried forward to the Islamic world, and much of what later became known as Islamic learning—including medicine, architecture, philosophy, philology, and literature—were of Sasanian basis.

The Safavid era is known as the "Golden Age" of Iranian art, and Safavid works of art show a far more unitary development than in any other period, as part of a political evolution that reunified Iran as a cultural entity. Safavid art exerted noticeable influences upon the neighboring Ottomans, the Mughals, and the Deccans, and was also influential through its fashion and garden architecture on 11th–17th-century Europe.
Iran's contemporary art traces its origins back to the time of Kamal-ol-Molk, a prominent realist painter at the court of the Qajar dynasty who affected the norms of painting and adopted a naturalistic style that would compete with photographic works. A new Iranian school of fine art was established by Kamal-ol-Molk in 1928, and was followed by the so-called "coffeehouse" style of painting.

Iran's avant-garde modernists emerged by the arrival of new western influences during World War II. The vibrant contemporary art scene originates in the late 1940s, and Tehran's first modern art gallery, Apadana, was opened in September 1949 by painters Mahmud Javadipur, Hosein Kazemi, and Hushang Ajudani. The new movements received official encouragement by mid-1950s, which led to the emergence of artists such as Marcos Grigorian, signaling a commitment to the creation of a form of modern art grounded in Iran.

The history of architecture in Iran goes back to the seventh millennium BC. Iranians were among the first to use mathematics, geometry and astronomy in architecture. Iranian architecture displays great variety, both structural and aesthetic, developing gradually and coherently out of earlier traditions and experience. The guiding motif of Iranian architecture is its cosmic symbolism, "by which man is brought into communication and participation with the powers of heaven".

Iran ranks seventh among UNESCO's list of countries with the most archaeological ruins and attractions from antiquity.

Traditionally, the guiding formative motif of Iranian architecture has been its cosmic symbolism "by which man is brought into communication and participation with the powers of heaven". This theme has not only given unity and continuity to the architecture of Persia, but has been a primary source of its emotional character as well.

According to Persian historian and archaeologist Arthur Pope, the supreme Iranian art, in the proper meaning of the word, has always been its architecture. The supremacy of architecture applies to both pre- and post-Islamic periods.

Iran's carpet-weaving has its origins in the Bronze Age, and is one of the most distinguished manifestations of Iranian art. Iran is the world's largest producer and exporter of handmade carpets, producing three-quarters of the world's total output and having a share of 30% of world's export markets.

Iran's oldest literary tradition is that of Avestan, the Old Iranian sacred language of the Avesta, which consists of the legendary and religious texts of Zoroastrianism and the ancient Iranian religion, with its earliest records dating back to the pre-Achaemenid times.

Of the various modern languages used in Iran, Persian, various dialects of which are spoken throughout the Iranian Plateau, has the most influential literature. Persian has been dubbed as a worthy language to serve as a conduit for poetry, and is considered one of the four main bodies of world literature. In spite of originating from the region of Persis (better known as "Persia") in southwestern Iran, the Persian language was used and developed further through Persianate societies in Asia Minor, Central Asia, and South Asia, leaving massive influences on Ottoman and Mughal literatures, among others.

Iran has a number of famous medieval poets, most notably Rumi, Ferdowsi, Hafez, Saadi Shirazi, Omar Khayyam, and Nezami Ganjavi. Iranian literature also inspired writers such as Johann Wolfgang von Goethe, Henry David Thoreau, and Ralph Waldo Emerson.

Iranian philosophy originates from Indo-European roots, with Zoroaster's reforms having major influences.

According to "The Oxford Dictionary of Philosophy", the chronology of the subject and science of philosophy starts with the Indo-Iranians, dating this event to 1500 BC. The Oxford dictionary also states, "Zarathushtra's philosophy entered to influence Western tradition through Judaism, and therefore on Middle Platonism."

While there are ancient relations between the Indian Vedas and the Iranian Avesta, the two main families of the Indo-Iranian philosophical traditions were characterized by fundamental differences, especially in their implications for the human being's position in society and their view of man's role in the universe.

The Cyrus Cylinder, which is known as "the first charter of human rights", is often seen as a reflection of the questions and thoughts expressed by Zoroaster, and developed in Zoroastrian schools of the Achaemenid era. The earliest tenets of Zoroastrian schools are part of the extant scriptures of the Zoroastrian religion in Avestan. Among them are treatises such as the Zatspram, Shkand-gumanik Vizar, and Denkard, as well as older passages of the Avesta and the Gathas.

Iranian mythology consists of ancient Iranian folklore and stories, all involving extraordinary beings, reflecting attitudes towards the confrontation of good and evil, actions of the gods, and the exploits of heroes and fabulous creatures.

Myths play a crucial part in Iranian culture, and understanding of them is increased when they are considered within the context of actual events in Iranian history. The geography of Greater Iran, a vast area covering present-day Iran, the Caucasus, Anatolia, Mesopotamia and Central Asia, with its high mountain ranges, plays the main role in much of Iranian mythology.

Tenth-century Persian poet Ferdowsi's long epic poem "Šāhnāme" ("Book of Kings"), which is for the most part based on "Xwadāynāmag", a Middle Persian compilation of the history of Iranian kings and heroes from mythical times down to the reign of Chosroes II, is considered the national epic of Iran. It draws heavily on the stories and characters of the Zoroastrian tradition, from the texts of the Avesta, the Denkard, and the Bundahishn.

Iran is the apparent birthplace of the earliest complex instruments, dating back to the third millennium BC. The use of both vertical and horizontal angular harps have been documented at the sites Madaktu and Kul-e Farah, with the largest collection of Elamite instruments documented at Kul-e Farah. Multiple depictions of horizontal harps were also sculpted in Assyrian palaces, dating back between 865 and 650 BC.

Xenophon's "Cyropaedia" mentions a great number of singing women at the court of the Achaemenid Empire. Athenaeus of Naucratis, in his "Deipnosophistae", points out to the capture of Achaemenid singing girls at the court of the last Achaemenid king Darius III (336–330 BC) by Macedonian general Parmenion. Under the Parthian Empire, the "gōsān" (Parthian for "minstrel") had a prominent role in the society. According to Plutarch's "Life of Crassus" (32.3), they praised their national heroes and ridiculed their Roman rivals. Likewise, Strabo's "Geographica" reports that the Parthian youth were taught songs about "the deeds both of the gods and of the noblest men".

The history of Sasanian music is better documented than the earlier periods, and is especially more evident in Avestan texts. By the time of Chosroes II, the Sasanian royal court hosted a number of prominent musicians, namely Azad, Bamshad, Barbad, Nagisa, Ramtin, and Sarkash.

Iranian traditional musical instruments include string instruments such as chang (harp), qanun, santur, rud (oud, barbat), tar, dotar, setar, tanbur, and kamanche, wind instruments such as sorna (zurna, karna) and ney, and percussion instruments such as tompak, kus, daf (dayere), and naqare.

Iran's first symphony orchestra, the Tehran Symphony Orchestra, was founded by Qolam-Hoseyn Minbashian in 1933. It was reformed by Parviz Mahmoud in 1946, and is currently Iran's oldest and largest symphony orchestra. Later, by the late 1940s, Ruhollah Khaleqi founded the country's first national music society, and established the School of National Music in 1949.

Iranian pop music has its origins in the Qajar era. It was significantly developed since the 1950s, using indigenous instruments and forms accompanied by electric guitar and other imported characteristics. The emergence of genres such as rock in the 1960s and hip hop in the 2000s also resulted in major movements and influences in Iranian music.

The earliest recorded representations of dancing figures within Iran were found in prehistoric sites such as Tepe Sialk and Tepe Mūsīān. The oldest Iranian initiation of theater and the phenomena of acting can be traced in the ancient epic ceremonial theaters such as "Sug-e Siāvuš" ("mourning of Siāvaš"), as well as dances and theater narrations of Iranian mythological tales reported by Herodotus and Xenophon.

Iran's traditional theatrical genres include Baqqāl-bāzi ("grocer play", a form of slapstick comedy), Ruhowzi (or "Taxt-howzi", comedy performed over a courtyard pool covered with boards), Siāh-bāzi (in which the central comedian appears in blackface), Sāye-bāzi (shadow play), Xeyme-šab-bāzi (marionette), and Arusak-bāzi (puppetry), and Ta'zie (religious tragedy plays).

Before the 1979 Revolution, the Iranian national stage had become a famous performing scene for known international artists and troupes, with the Roudaki Hall of Tehran constructed to function as the national stage for opera and ballet. Opened on 26 October 1967, the hall is home to the Tehran Symphony Orchestra, the Tehran Opera Orchestra, and the Iranian National Ballet Company, and was officially renamed "Vahdat Hall" after the 1979 Revolution.

Loris Tjeknavorian's "Rostam and Sohrab", based on the tragedy of "Rostam and Sohrab" from Ferdowsi's epic poem "Šāhnāme", is an example of opera with Persian libretto. Tjeknavorian, a celebrated Iranian Armenian composer and conductor, composed it in 25 years, and it was finally performed for the first time at Tehran's Roudaki Hall, with Darya Dadvar in the role of Tahmina.

A third-millennium BC earthen goblet discovered at the Burnt City, a Bronze Age urban settlement in southeastern Iran, depicts what could possibly be the world's oldest example of animation. The artifact, associated with Jiroft, bears five sequential images depicting a wild goat jumping up to eat the leaves of a tree. The earliest attested Iranian examples of visual representations, however, are traced back to the bas-reliefs of Persepolis, the ritual center of the Achaemenid Empire. The figures at Persepolis remain bound by the rules of grammar and syntax of visual language. The Iranian visual arts reached a pinnacle by the Sasanian era, and several works from this period have been found to articulate movements and actions in a highly sophisticated manner. It is even possible to see a progenitor of the cinematic close-up shot in one of these works of art, which shows a wounded wild pig escaping from the hunting ground.

By the early 20th century, the five-year-old industry of cinema came to Iran. The first Iranian filmmaker was probably Mirza Ebrahim (Akkas Bashi), the court photographer of Mozaffar-ed-Din Shah of the Qajar dynasty. Mirza Ebrahim obtained a camera and filmed the Qajar ruler's visit to Europe. Later in 1904, Mirza Ebrahim (Sahhaf Bashi), a businessman, opened the first public movie theater in Tehran. After him, several others like Russi Khan, Ardeshir Khan, and Ali Vakili tried to establish new movie theaters in Tehran. Until the early 1930s, there were around 15 cinema theaters in Tehran and 11 in other provinces. The first Iranian feature film, "Abi and Rabi", was a silent comedy directed by Ovanes Ohanian in 1930. The first sounded one, "Lor Girl", was produced by Ardeshir Irani and Abd-ol-Hosein Sepanta in 1932.

Iran's animation industry began by the 1950s, and was followed by the establishment of the influential Institute for the Intellectual Development of Children and Young Adults in January 1965. The 1960s was a significant decade for Iranian cinema, with 25 commercial films produced annually on average throughout the early 60s, increasing to 65 by the end of the decade. The majority of the production focused on melodrama and thrillers. With the screening of the films "Qeysar" and "The Cow", directed by Masoud Kimiai and Dariush Mehrjui respectively in 1969, alternative films set out to establish their status in the film industry and Bahram Beyzai's "Downpour" and Nasser Taghvai's "Tranquility in the Presence of Others" followed soon. Attempts to organize a film festival, which had begun in 1954 within the framework of the Golrizan Festival, resulted in the festival of Sepas in 1969. The endeavors also resulted in the formation of the Tehran's World Film Festival in 1973.

After the Revolution of 1979, and following the Cultural Revolution, a new age emerged in Iranian cinema, starting with "Long Live!" by Khosrow Sinai and followed by many other directors, such as Abbas Kiarostami and Jafar Panahi. Kiarostami, an acclaimed Iranian director, planted Iran firmly on the map of world cinema when he won the Palme d'Or for "Taste of Cherry" in 1997. The continuous presence of Iranian films in prestigious international festivals, such as the Cannes Film Festival, the Venice Film Festival, and the Berlin International Film Festival, attracted world attention to Iranian masterpieces. In 2006, six Iranian films, of six different styles, represented Iranian cinema at the Berlin International Film Festival. Critics considered this a remarkable event in the history of Iranian cinema.

Asghar Farhadi, a well-known Iranian director, has received a Golden Globe Award and two Academy Awards, representing Iran for Best Foreign Language Film in 2012 and 2017. In 2012, he was named as one of the 100 Most Influential People in the world by the American news magazine "Time".

Iran's official New Year begins with Nowruz, an ancient Iranian tradition celebrated annually on the vernal equinox. It is enjoyed by people adhering to different religions, but is considered a holiday for the Zoroastrians. It was registered on the UNESCO's list of Masterpieces of the Oral and Intangible Heritage of Humanity in 2009, described as the "Persian New Year", shared with a number of other countries in which it has historically been celebrated.

On the eve of the last Wednesday of the preceding year, as a prelude to Nowruz, the ancient festival of Čāršanbe Suri celebrates Ātar ("fire") by performing rituals such as jumping over bonfires and lighting off firecrackers and fireworks. The Nowruz celebrations last by the end of the 13th day of the Iranian year (Farvardin 13, usually coincided with 1or 2April), celebrating the festival of Sizdebedar, during which the people traditionally go outdoors to picnic.

Yaldā, another nationally celebrated ancient tradition, commemorates the ancient goddess Mithra and marks the longest night of the year on the eve of the winter solstice (; usually falling on 20 or 21 December), during which families gather together to recite poetry and eat fruits—particularly the red fruits watermelon and pomegranate, as well as mixed nuts. In some regions of the provinces of Mazanderan and Markazi, there is also the midsummer festival of Tirgān, which is observed on Tir 13 (2 or 3July) as a celebration of water.

Alongside the ancient Iranian celebrations, Islamic annual events such as Ramezān, Eid e Fetr, and Ruz e Āšurā are marked by the country's large Muslim population, Christian traditions such as Noel, Čelle ye Ruze, and Eid e Pāk are observed by the Christian communities, Jewish traditions such as Purim, Hanukā, and Eid e Fatir (Pesah) are observed by the Jewish communities, and Zoroastrian traditions such as Sade and Mehrgān are observed by the Zoroastrians.

Iran's official calendar is the Solar Hejri calendar, beginning at the vernal equinox in the Northern Hemisphere, which was first enacted by the Iranian Parliament on 31 March 1925. Each of the 12 months of the Solar Hejri calendar correspond with a zodiac sign, and the length of each year is absolutely solar. The months are named after the ancient Iranian months, namely Farvardin (), Ordibehešt (), Xordād (), Tir (), Amordād (), Šahrivar (), Mehr (), Ābān (), Āzar (), Dey (), Bahman (), and Esfand ().

Alternatively, the Lunar Hejri calendar is used to indicate Islamic events, and the Gregorian calendar remarks the international events.

Legal public holidays based on the Iranian solar calendar include the cultural celebrations of Nowruz (Farvardin 1–4; 21–24 March) and Sizdebedar (Farvardin 13; 2April), and the political events of Islamic Republic Day (Farvardin 12; 1April), the death of Ruhollah Khomeini (Khordad 14; 4June), the Khordad 15 event (Khordad 15; 5June), the anniversary of the 1979 Revolution (Bahman 22; 10 February), and Oil Nationalization Day (Esfand 29; 19 March).

Lunar Islamic public holidays include Tasua (Muharram 9; 30 September), Ashura (Muharram 10; 1October), Arba'een (Safar 20; 10 November), the death of Muhammad (Safar 28; 17 November), the death of Ali al-Ridha (Safar 29 or 30; 18 November), the birthday of Muhammad (Rabi-al-Awwal 17; 6December), the death of Fatimah (Jumada-al-Thani 3; 2March), the birthday of Ali (Rajab 13; 10 April), Muhammad's first revelation (Rajab 27; 24 April), the birthday of Muhammad al-Mahdi (Sha'ban 15; 12 May), the death of Ali (Ramadan 21; 16 June), Eid al-Fitr (Shawwal 1–2; 26–27 June), the death of Ja'far al-Sadiq (Shawwal 25; 20 July), Eid al-Qurban (Zulhijja 10; 1September), and Eid al-Qadir (Zulhijja 18; 9September).

Due to its variety of ethnic groups and the influences from the neighboring cultures, the cuisine of Iran is diverse. Herbs are frequently used, along with fruits such as plums, pomegranate, quince, prunes, apricots, and raisins. To achieve a balanced taste, characteristic flavorings such as saffron, dried lime, cinnamon, and parsley are mixed delicately and used in some special dishes. Onion and garlic are commonly used in the preparation of the accompanying course, but are also served separately during meals, either in raw or pickled form.

Iranian cuisine includes a wide range of main dishes, including various types of kebab, pilaf, stew (khoresh), soup and āsh, and omelette. Lunch and dinner meals are commonly accompanied by side dishes such as plain yogurt or mast-o-khiar, sabzi, salad Shirazi, and torshi, and might follow dishes such as borani, Mirza Qasemi, or kashk e bademjan as the appetizer.

In Iranian culture, tea () is widely consumed. Iran is the world's seventh major tea producer, and a cup of tea is typically the first thing offered to a guest. One of Iran's most popular desserts is the falude, consisting of vermicelli in a rose water syrup, which has its roots in the fourth century BC. There is also the popular saffron ice cream, known as "bastani sonnati" ("traditional ice cream"), which is sometimes accompanied with carrot juice. Iran is also famous for its caviar.

With two-thirds of the population under the age of 25, many sports are played in Iran.

Iran is most likely the birthplace of polo, locally known as "čowgān", with its earliest records attributed to the ancient Medes. Freestyle wrestling is traditionally considered the national sport of Iran, and the national wrestlers have been world champions on many occasions. Iran's traditional wrestling, called "košti e pahlevāni" ("heroic wrestling"), is registered on UNESCO's Intangible Cultural Heritage list.

Being a mountainous country, Iran is a venue for skiing, snowboarding, hiking, rock climbing, and mountain climbing. It is home to several ski resorts, the most famous being Tochal, Dizin, and Shemshak, all within one to three hours traveling from the capital city Tehran. The resort of Tochal, located in the Alborz mountain rage, is the world's fifth-highest ski resort ( at its highest station).

Iran's National Olympic Committee was founded in 1947. Wrestlers and weightlifters have achieved the country's highest records at the Olympics. In September 1974, Iran became the first country in West Asia to host the Asian Games. The Azadi Sport Complex, which is the largest sport complex in Iran, was originally built for this occasion.
Football has been regarded as the most popular sport in Iran, with the men's national team having won the Asian Cup on three occasions. The men's national team has maintained its position as Asia's best team, ranking 1st in Asia and 33rd in the world according to the FIFA World Rankings ().

Volleyball is the second most popular sport in Iran. Having won the 2011 and 2013 Asian Men's Volleyball Championships, the men's national team is currently the strongest team in Asia, and ranks eighth in the FIVB World Rankings ().

Basketball is also popular, with the men's national team having won three Asian Championships since 2007.

In 2016, Iran made global headlines for international female champions boycotting tournaments in Iran in chess (U.S. Woman Grandmaster Nazí Paikidze) and in shooting (Indian world champion Heena Sidhu), as they refused to enter a country where they would be forced to wear a hijab.

Iran is one of the countries with the worst freedom of the press situation, ranking 164th out of 180 countries on the Press Freedom Index (as of 2018). The Ministry of Culture and Islamic Guidance is Iran's main government department responsible for the cultural policy, including activities regarding communications and information.

Iran's first newspapers were published during the reign of Naser al-Din Shah of the Qajar dynasty in the mid-19th century. Most of the newspapers published in Iran are in Persian, the country's official language. The country's most widely circulated periodicals are based in Tehran, among which are "Etemad", "Ettela'at", "Kayhan", "Hamshahri", "Resalat", and "Shargh". "Tehran Times", "Iran Daily", and "Financial Tribune" are among English-language newspapers based in Iran.

Television was introduced in Iran in 1958. Although the 1974 Asian Games were broadcast in color, full color programming began in 1978. Since the 1979 Revolution, Iran's largest media corporation is the Islamic Republic of Iran Broadcasting (IRIB). Despite the restrictions on non-domestic television, about 65% of the residents of the capital city and about 30 to 40% of the residents outside the capital city access worldwide television channels through satellite dishes, although observers state that the figures are likely to be higher.

Iran received access to the Internet in 1993. According to Internet World Stats, , around 69.1% of the population of Iran are Internet users. Iran ranks 17th among countries by number of Internet users. According to the statistics provided by the web information company of Alexa, Google Search is Iran's most widely used search engine and Instagram is the most popular online social networking service. Direct access to many worldwide mainstream websites has been blocked in Iran, including Facebook, which has been blocked since 2009 due to the organization of anti-governmental protests on the website. However, , Facebook has around 40 million subscribers based in Iran (48.8% of the population) who use virtual private networks and proxy servers to access the website. Some of the officials themselves have verified accounts on the social networking websites that are blocked by the authorities, including Facebook and Twitter. About 90% of Iran's e-commerce takes place on the Iranian online store of Digikala, which has around 750,000 visitors per day and more than 2.3 million subscribers and is the most visited online store in the Middle East.

Fashion in Iran is divided into several historical periods. The exact date of the emergence of weaving in Iran is not yet known, but it is likely to coincide with the emergence of civilization. Clothing in Iran is mentioned in Persian mythology. Ferdowsi and many historians have considered Keyumars to be the inventor of the use of animals' skin and hair as clothing. Some historians have also mentioned Hushang as the first inventor of the use of living skins as clothing. Ferdowsi considers Tahmuras to be a kind of textile initiator in Iran. There are historical discoveries in northern Iran from about 6,000 BC that refer to wool weaving at the time. Other discoveries in central Iran dating back to 4200 BC have shown that the animals' skin has not been the only clothing worn on the Iranian plateau since those years. The clothing of ancient Iran took an advanced form, and the fabric and color of clothing became very important at that time. Depending on the social status, eminence, climate of the region and the season, Persian clothing during the Achaemenian period took various forms. The philosophy used in this clothing, in addition to being functional, also had an aesthetic role.

Beauty pageant festivals inside Iran were not held after the 1979 revolution, and the last selection ceremony of the "beauty queen of Iran" was held in 1978 in this country. Since then, a high number of Iranian girls participated in the Beauty pageant and Miss Universe outside of Iran. Sahar Biniaz (Miss Universe Canada 2012) and Shermineh Shahrivar (Miss Germany and Miss Europe) are examples of Iranian models outside Iran.





</doc>
<doc id="14664" url="https://en.wikipedia.org/wiki?curid=14664" title="History of Iraq">
History of Iraq

Iraq is the name of the state that currently partially encompasses the territory of the civilization of ancient Mesopotamia. This civilization came into being between the Tigris and Euphrates rivers. These rivers flow into the Persian Gulf, through the State of Iraq. The Hashemite Kingdom of Iraq, also known as Mandatory Iraq in its early phase, was established by the Anglo-Iraqi treaty of 1922 resulting from the 1920 Iraqi revolt against British rule. It is centered in Lower Mesopotamia (corresponding to historical Babylonia, later also known as "ʿIrāq-i ʿArab") but also includes part of Upper Mesopotamia and of the Syrian Desert and the Arabian Desert. The history of this area has witnessed some of the world's earliest writing, literature, sciences, mathematics, laws and philosophies; hence its common epithet, the Cradle of Civilization.

As part of the larger Fertile Crescent, Mesopotamia saw the earliest emergence of civilization in the Neolithic (the Ubaid period) Age and formed a significant part of the Ancient Near East throughout the Bronze Age and the Iron Age (Sumerian, Akkadian, Babylonian and Assyrian). After the fall of the Neo-Babylonian Empire, Mesopotamia fell under Persian and then Greek rule. By the 3rd century, when it was once again under Persian (Sassanid) control, the earlier population was increasingly displaced by Arabs, and the Arabic name "al-ʿIrāq" dates to about this time. The Sassanid Empire was destroyed by the Islamic conquests and displaced by the Rashidun Caliphate in the 7th century. Baghdad became the center of the "Islamic Golden Age" under the Abbasid Caliphate during the 9th century. Baghdad's rapid growth stagnated in the 10th century due to the Buwayhid and Seljuq invasions, but it remained of central importance until the Mongol invasion of 1258. After this, Iraq became a province of the Turco-Mongol Ilkhanate and declined in importance. After the disintegration of the Ilkhanate, Iraq was ruled by the Jalairids and Kara Koyunlu until its eventual absorption into the Ottoman Empire in the 16th century, intermittently falling under Iranian Safavid and Mamluk control.

Ottoman rule ended with World War I, and the British Empire administered Iraq as Mandatory Iraq until the establishment of the Kingdom of Iraq in 1933. A republic formed in 1958 following a coup d'état. Saddam Hussein governed from 1968 to 2003, into which period fall the Iran–Iraq War and the Gulf War. Saddam Hussein was deposed following the 2003 US-led invasion of the country. Over the following years, Iraq came to the brink of civil war, and the situation deteriorated in 2011. By 2015, Iraq was effectively divided, the central and southern part being controlled by the government, the northwest by the Kurdistan Regional Government and the western part by the Islamic State of Iraq and the Levant. ISIS was expelled from Iraq in 2017, but continued fighting in an insurgency.

During 1957–1961 Shanidar Cave was excavated by Ralph Solecki and his team from Columbia University, and nine skeletons of Neanderthal man of varying ages and states of preservation and completeness (labelled Shanidar I–IX) were discovered dating from 60,000–80,000 years BP. A tenth individual was recently discovered by M. Zeder during examination of a faunal assemblage from the site at the Smithsonian Institution. The remains seemed to Zeder to suggest that Neanderthals had funeral ceremonies, burying their dead with flowers (although the flowers are now thought to be a modern contaminant), and that they took care of injured and elderly individuals.

Mesopotamia is the site of the earliest developments of the Neolithic Revolution from around 10,000 BC. It has been identified as having "inspired some of the most important developments in human history including the invention of the wheel, the planting of the first cereal crops and the development of cursive script, Mathematics, Astronomy and Agriculture."

Sumer emerged as the civilization of Lower Mesopotamia out of the prehistoric Ubaid period (mid-6th millennium BC) in the Early Bronze Age (Uruk period)
Classical Sumer ends with the rise of the Akkadian Empire in the 24th century BC. Following the Gutian period, there is a brief Sumerian renaissance in the 21st century, cut short in the 20th century BC by Amorite invasion. The Amorite dynasty of Isin persisted until c. 1600 BC, when southern Mesopotamia was united under Kassite Babylonian rule.

The north of Mesopotamia had become the Akkadian-speaking state of Assyria by the late 25th century BC. Along with the rest of Mesopotamia it was ruled by Akkadian kings from the late 24th to mid 22nd centuries BC, after which it once again became independent.

Babylonia was a state in Lower Mesopotamia with Babylon as its capital. It was founded as an independent state by an Amorite king named Sumuabum in 1894 BC. During the 3rd millennium BCE, there developed a very intimate cultural symbiosis between the Sumerians and the Akkadians, which included widespread bilingualism.

Akkadian gradually replaced Sumerian as the spoken language of Mesopotamia somewhere around the turn of the 3rd and the 2nd millennium BC, but Sumerian continued to be used as a written or ceremonial language in Mesopotamia well into the period of classical antiquity.

Babylonia emerged from the Amorite dynasties (c. 1900 BC) when Hammurabi (c. 1792–1750 BC), unified the territories of the former kingdoms of Sumer and Akkad.
During the early centuries of what is called the "Amorite period", the most powerful city-states were Isin and Larsa, although Shamshi-Adad I came close to uniting the more northern regions around Assur and Mari. One of these Amorite dynasties was established in the city-state of Babylon, which would ultimately take over the others and form the first Babylonian empire, during what is also called the Old Babylonian Period.

Assyria was an Akkadian (East Semitic) kingdom in Upper Mesopotamia, that came to rule regional empires a number of times through history. It was named for its original capital, the ancient city of Assur (Akkadian "").

Of the early history of the kingdom of Assyria, little is positively known. In the Assyrian King List, the earliest king recorded was Tudiya. He was a contemporary of Ibrium of Ebla who appears to have lived in the late 25th or early 24th century BC, according to the king list. The foundation of the first true urbanised Assyrian monarchy was traditionally ascribed to Ushpia a contemporary of Ishbi-Erra of Isin and Naplanum of Larsa. c. 2030 BC.

Assyria had a period of empire from the 19th to 18th centuries BC. From the 14th to 11th centuries BC Assyria once more became a major power with the rise of the Middle Assyrian Empire.

The Neo-Assyrian Empire (911–609 BC) was the dominant political force in the Ancient Near East during the Iron Age, eclipsing Babylonia, Egypt, Urartu and Elam.
During this period, Aramaic was also made an official language of the empire, alongside the Akkadian language.

The Neo-Babylonian Empire (626–539 BC)
marks the final period of the history of the Ancient Near East preceding Persian conquest.
A year after the death of the last strong Assyrian ruler, Assurbanipal, in 627 BC, the Assyrian empire spiralled into a series of brutal civil wars. Babylonia rebelled under Nabopolassar, a member of the Chaldean tribe which had migrated from the Levant to south eastern Babylonia in the early 9th century BC. In alliance with the Medes, Persians, Scythians and Cimmerians, they sacked the city of Nineveh in 612 BC, and the seat of empire was transferred to Babylonia for the first time since the death of Hammurabi in the mid 18th century BC. This period witnessed a general improvement in economic life and agricultural production, and a great flourishing of architectural projects, the arts and science.
The Neo-Babylonian period ended with the reign of Nabonidus in 539 BC. To the east, the Persians had been growing in strength, and eventually Cyrus the Great established his dominion over Babylon.

Mesopotamia was conquered by the Achaemenid Persians under Cyrus the Great in 539 BC, and remained under Persian rule for two centuries.

The Persian Empire fell to Alexander of Macedon in 331 BC and came under Greek rule as part of the Seleucid Empire. Babylon declined after the founding of Seleucia on the Tigris, the new Seleucid Empire capital. 
The Seleucid Empire at the height of its power stretched from the Aegean in the west to India in the east. It was a major center of Hellenistic culture that maintained the preeminence of Greek customs where a Greek political elite dominated, mostly in the urban areas. The Greek population of the cities who formed the dominant elite were reinforced by immigration from Greece.
Much of the eastern part of the empire was conquered by the Parthians under Mithridates I of Parthia in the mid-2nd century BC.

At the beginning of the 2nd century AD, the Romans, led by emperor Trajan, invaded Parthia and conquered Mesopotamia, making it an imperial province. It was returned to the Parthians shortly after by Trajan's successor, Hadrian.

Christianity reached Mesopotamia in the 1st century AD, and Roman Syria in particular became the center of Eastern Rite Christianity and the Syriac literary tradition. Mandeism is also believed to have either originated there around this time or entered as Mandaeans sought refuge from Palestine.
Sumerian-Akkadian religious tradition disappeared during this period, as did the last remnants of cuneiform literacy, although temples were still being dedicated to the Assyrian national god Ashur in his home city as late as the 4th century.

In the 3rd century AD, the Parthians were in turn succeeded by the Sassanid dynasty, which ruled Mesopotamia until the 7th-century Islamic invasion. The Sassanids conquered the independent states of Adiabene, Osroene, Hatra and finally Assur during the 3rd century. In the mid-6th century the Persian Empire under the Sassanid dynasty was divided by Khosrow I into four quarters, of which the western one, called "Khvārvarān", included most of modern Iraq, and subdivided to provinces of "Mishān", Asuristān (Assyria), Adiabene and Lower Media. The term Iraq is widely used in the medieval Arabic sources for the area in the center and south of the modern republic as a geographic rather than a political term, implying no greater precision of boundaries than the term "Mesopotamia" or, indeed, many of the names of modern states before the 20th century.

There was a substantial influx of Arabs in the Sassanid period. 
Upper Mesopotamia came to be known as "Al-Jazirah" in Arabic (meaning "The Island" in reference to the "island" between the Tigris and Euphrates rivers), and Lower Mesopotamia came to be known as "ʿIrāq-i ʿArab", meaning "the escarpment of the Arabs" (viz. to the south and east of "the island".

Until 602, the desert frontier of the Persian Empire had been guarded by the Arab Lakhmid kings of Al-Hirah. In that year, Shahanshah Khosrow II Aparviz (Persian خسرو پرويز) abolished the Lakhmid kingdom and laid the frontier open to nomad incursions. Farther north, the western quarter was bounded by the Byzantine Empire. The frontier more or less followed the modern Syria-Iraq border and continued northward, passing between Nisibis (modern Nusaybin) as the Sassanian frontier fortress and Dara and Amida (modern Diyarbakır) held by the Byzantines.

The first organized conflict between local Arab tribes and Persian forces seems to have been in 634, when the Arabs were defeated at the Battle of the Bridge. There was a force of some 5,000 Muslims under Abū `Ubayd ath-Thaqafī, which was routed by the Persians. This was followed by Khalid ibn al-Walid's successful campaign which saw all of Iraq come under Arab rule within a year, with the exception of the Persian Empire's capital, Ctesiphon. Around 636, a larger Arab Muslim force under Sa`d ibn Abī Waqqās defeated the main Persian army at the Battle of al-Qādisiyyah and moved on to capture the Persian capital of Ctesiphon. By the end of 638, the Muslims had conquered all of the Western Sassanid provinces (including modern Iraq), and the last Sassanid Emperor, Yazdegerd III, had fled to central and then northern Persia, where he was killed in 651.

The Islamic expansions constituted the largest of the Semitic expansions in history. These new arrivals did not disperse and settle throughout the country; instead they established two new garrison cities, at al-Kūfah, near ancient Babylon, and at Basrah in the south, while the north remained largely Assyrian and Christian in character.

The city of Baghdad was built in the 8th century and became the capital of the Abbasid Caliphate. Baghdad soon became the primary cultural center of the Muslim world during the centuries of the incipient "Islamic Golden Age" of the 8th to 9th centuries.

In the 9th century, the Abbasid Caliphate entered a period of decline.
During the late 9th to early 11th centuries, a period known as the "Iranian Intermezzo", parts of (the modern territory of) Iraq were governed by a number of minor Iranian emirates, including the Tahirids, Saffarids, Samanids, Buyids and Sallarids. Tughril, the founder of the Seljuk Empire, captured Baghdad in 1055. 
In spite of having lost all governance, the Abbasid caliphs nevertheless maintained a highly ritualized court in Baghdad and remained influential in religious matters, maintaining the orthodoxy of their Sunni sect in opposition to the Ismaili and Shia sects of Islam.

In the later 11th century, Iraq fell under the rule of the Khwarazmian dynasty. Both Turkic secular rule and Abassid caliphate came to an end with the Mongol invasions of the 13th century.
The Mongols under Genghis Khan had conquered Khwarezmia by 1221, but Iraq proper gained a respite due to the death of Genghis Khan in 1227 and the subsequent power struggles.
Möngke Khan from 1251 began a renewed expansion of the Mongol Empire, and when caliph al-Mustasim refused to submit to the Mongols, Baghdad was besieged and captured by Hulagu Khan in 1258. With the destruction of the Abbasid Caliphate, Hulagu had an open route to Syria and moved against the other Muslim powers in the region.

Iraq now became a province on the southwestern fringes of the Ilkhanate and Baghdad would never regain its former importance.

The Jalayirids were a Mongol Jalayir dynasty which ruled over Iraq and western Persia after the breakup of the Ilkhanate in the 1330s. The Jalayirid sultanate lasted about fifty years, until disrupted by Tamerlane's conquests and the revolts of the "Black Sheep Turks" or Qara Qoyunlu Turkmen. After Tamerlane's death in 1405, there was a brief attempt to re-establish the sultanate in southern Iraq and Khuzistan. The Jalayirids were finally eliminated by Kara Koyunlu in 1432.

During the late 14th and early 15th centuries, the Black Sheep Turkmen ruled the area now known as Iraq. In 1466, the White Sheep Turkmen defeated the Black Sheep and took control. Later, the White Sheep were defeated by the Safavids, who took control over Mesopotamia for some time. In the 16th century, most of the territory of present-day Iraq came under the control of Ottoman Empire as the pashalik of Baghdad. Throughout most of the period of Ottoman rule (1533–1918) the territory of present-day Iraq was a battle zone between the rival regional empires and tribal alliances.
Iraq was divided into three vilayets:

The Safavid dynasty of Iran briefly asserted their hegemony over Iraq in the periods of 1508–1533 and 1622–1638. During the years 1747–1831 Iraq was ruled by the Mamluk officers of Georgian origin who succeeded in obtaining autonomy from the Ottoman Empire, suppressed tribal revolts, curbed the power of the Janissaries, restored order and introduced a program of modernization of economy and military. In 1831, the Ottomans managed to overthrow the Mamluk regime and again imposed their direct control over Iraq.

Ottoman rule over Iraq lasted until World War I, when the Ottomans sided with Germany and the Central Powers. In the Mesopotamian campaign against the Central Powers, British forces invaded the country and suffered a defeat at the hands of the Turkish army during the Siege of Kut (1915–16). However the British finally won in the Mesopotamian Campaign with the capture of Baghdad in March 1917. During the war the British employed the help of a number of Assyrian, Armenian and Arab tribes against the Ottomans, who in turn employed the Kurds as allies. After the war the Ottoman Empire was divided up, and the British Mandate of Mesopotamia was established by League of Nations mandate. Britain imposed a Hāshimite monarchy on Iraq and defined the territorial limits of Iraq without taking into account the politics of the different ethnic and religious groups in the country, in particular those of the Kurds and the Christian Assyrians to the north. During the British occupation, the Kurds fought for independence, and the British employed Assyrian Levies to help quell these insurrections. Iraq also became an oligarchy government at this time.

Although the monarch Faisal I of Iraq was legitimized and proclaimed King by a plebiscite in 1921, independence was achieved in 1932, when the British Mandate officially ended.

Establishment of Arab Sunni domination in Iraq was followed by Assyrian, Yazidi and Shi'a unrests, which were all brutally suppressed. In 1936, the first military coup took place in the Kingdom of Iraq, as Bakr Sidqi succeeded in replacing the acting Prime Minister with his associate. Multiple coups followed in a period of political instability, peaking in 1941.

During World War II, Iraqi regime of Regent 'Abd al-Ilah was overthrown in 1941 by the Golden Square officers, headed by Rashid Ali. The short lived pro-Nazi government of Iraq was defeated in May 1941 by the allied forces (with local Assyrian and Kurdish help) in Anglo-Iraqi War. Iraq was later used as a base for allied attacks on Vichy-French held Mandate of Syria and support for the Anglo-Soviet invasion of Iran.

In 1945, Iraq joined the United Nations and became a founding member of the Arab League. At the same time, the Kurdish leader Mustafa Barzani led a rebellion against the central government in Baghdad. After the failure of the uprising, Barzani and his followers fled to the Soviet Union.

In 1948, massive violent protests known as the Al-Wathbah uprising broke out across Baghdad with partial communist support, having demands against the government's treaty with Britain. Protests continued into spring and were interrupted in May when martial law was enforced as Iraq entered the failed 1948 Arab–Israeli War along with other Arab League members.

In February 1958, King Hussein of Jordan and `Abd al-Ilāh proposed a union of Hāshimite monarchies to counter the recently formed Egyptian-Syrian union. The prime minister Nuri as-Said wanted Kuwait to be part of the proposed Arab-Hāshimite Union. Shaykh `Abd-Allāh as-Salīm, the ruler of Kuwait, was invited to Baghdad to discuss Kuwait's future. This policy brought the government of Iraq into direct conflict with Britain, which did not want to grant independence to Kuwait. At that point, the monarchy found itself completely isolated. Nuri as-Said was able to contain the rising discontent only by resorting to even greater political oppression.

Inspired by Gamal Abdel Nasser of Egypt, officers from the Nineteenth Brigade, 3rd Division known as "The Four Colonials", under the leadership of Brigadier Abd al-Karīm Qāsim (known as ""az-Za`īm"", 'the leader') and Colonel Abdul Salam Arif overthrew the Hashemite monarchy on July 14, 1958. The new government proclaimed Iraq to be a republic and rejected the idea of a union with Jordan. Iraq's activity in the Baghdad Pact ceased.

In 1961, Kuwait gained independence from Britain and Iraq claimed sovereignty over Kuwait. A period of considerable instability followed. The same year, Mustafa Barzani, who had been invited to return to Iraq by Qasim three years earlier, began engaging Iraqi government forces and establishing Kurdish control in the north in what was the beginning of the First Kurdish Iraqi War.

Qāsim was assassinated in February 1963, when the Ba'ath Party took power under the leadership of General Ahmed Hassan al-Bakr (prime minister) and Colonel Abdul Salam Arif (president). In June 1963, Syria, which by then had also fallen under Ba'athist rule, took part in the Iraqi military campaign against the Kurds by providing aircraft, armoured vehicles and a force of 6,000 soldiers. Several months later, `Abd as-Salam Muhammad `Arif led a successful coup against the Ba'ath government. Arif declared a ceasefire in February 1964 which provoked a split among Kurdish urban radicals on one hand and Peshmerga (Freedom fighters) forces led by Barzani on the other.

On April 13, 1966, President Abdul Salam Arif died in a helicopter crash and was succeeded by his brother, General Abdul Rahman Arif. Following this unexpected death, the Iraqi government launched a last-ditch effort to defeat the Kurds. This campaign failed in May 1966, when Barzani forces thoroughly defeated the Iraqi Army at the Battle of Mount Handrin, near Rawanduz. Following the Six-Day War of 1967, the Ba'ath Party felt strong enough to retake power in 1968. Ahmed Hassan al-Bakr became president and chairman of the Revolutionary Command Council (RCC). The Ba'ath government started a campaign to end the Kurdish insurrection, which stalled in 1969. This can be partly attributed to the internal power struggle in Baghdad and also tensions with Iran. Moreover, the Soviet Union pressured the Iraqis to come to terms with Barzani. The war ended with more than 100,000 mortal casualties, with little achievements to both Kurdish rebels and the Iraqi government.

In the aftermath of the First Kurdish Iraqi War, a peace plan was announced in March 1970 and provided for broader Kurdish autonomy. The plan also gave Kurds representation in government bodies, to be implemented in four years. Despite this, the Iraqi government embarked on an Arabization program in the oil rich regions of Kirkuk and Khanaqin in the same period. In the following years, Baghdad government overcame its internal divisions and concluded a treaty of friendship with the Soviet Union in April 1972 and ended its isolation within the Arab world. On the other hand, Kurds remained dependent on the Iranian military support and could do little to strengthen their forces. By 1974 the situation in the north escalated again into the Second Kurdish Iraqi War, to last until 1975.

In July 1979, President Ahmed Hassan al-Bakr was forced to resign by Saddam Hussein, who assumed the offices of both President and Chairman of the Revolutionary Command Council.

Iraq's Territorial Claims to Neighboring Countries
Iraq's territorial claims to neighboring countries were largely due to the plans and promises of the Entente countries in 1919–1920, when the Ottoman Empire was divided, to create a more extensive Arab state in Iraq and Jazeera, which would also include significant territories of eastern Syria, southeastern Turkey, all of Kuwait and Iran’s border areas, which are shown on this English map of 1920.

Territorial disputes with Iran led to an inconclusive and costly eight-year war, the "Iran–Iraq War" (1980–1988, termed "Qādisiyyat-Saddām" – 'Saddam's Qādisiyyah'), which devastated the economy. Iraq falsely declared victory in 1988 but actually only achieved a weary return to the "status quo ante bellum", meaning both sides retained their original borders.

The war began when Iraq invaded Iran, launching a simultaneous invasion by air and land into Iranian territory on 22 September 1980, following a long history of border disputes, and fears of Shia insurgency among Iraq's long-suppressed Shia majority influenced by the Iranian Revolution. Iraq was also aiming to replace Iran as the dominant Persian Gulf state. The United States supported Saddam Hussein in the war against Iran. Although Iraq hoped to take advantage of the revolutionary chaos in Iran and attacked without formal warning, they made only limited progress into Iran and within several months were repelled by the Iranians who regained virtually all lost territory by June 1982. For the next six years, Iran was on the offensive. Despite calls for a ceasefire by the United Nations Security Council, hostilities continued until 20 August 1988. The war finally ended with a United Nations-brokered ceasefire in the form of United Nations Security Council Resolution 598, which was accepted by both sides. It took several weeks for the Iranian armed forces to evacuate Iraqi territory to honor pre-war international borders between the two nations (see 1975 Algiers Agreement). The last prisoners of war were exchanged in 2003.

The war came at a great cost in lives and economic damage—half a million Iraqi and Iranian soldiers, as well as civilians, are believed to have died in the war with many more injured—but it brought neither reparations nor change in borders. The conflict is often compared to World War I, in that the tactics used closely mirrored those of that conflict, including large scale trench warfare, manned machine-gun posts, bayonet charges, use of barbed wire across trenches, human wave attacks across no-man's land, and extensive use of chemical weapons such as mustard gas by the Iraqi government against Iranian troops and civilians as well as Iraqi Kurds. At the time, the UN Security Council issued statements that "chemical weapons had been used in the war." However, in these UN statements, it was never made clear that it was only Iraq that was using chemical weapons, so it has been said that "the international community remained silent as Iraq used weapons of mass destruction against Iranian as well as Iraqi Kurds" and it is believed.

A long-standing territorial dispute was the ostensible reason for Iraq's invasion of Kuwait in 1990. In November 1990, the UN Security Council adopted Resolution 678, permitting member states to use all necessary means, authorizing military action against the Iraqi forces occupying Kuwait and demanded a complete withdrawal by January 15, 1991. When Saddam Hussein failed to comply with this demand, the Persian Gulf War (Operation "Desert Storm") ensued on January 17, 1991. Probably as many as 30,000 Iraqi soldiers and a few thousand civilians were killed.

In March 1991 revolts in the Shia-dominated southern Iraq started involving demoralized Iraqi Army troops and the anti-government Shia parties. Another wave of insurgency broke out shortly afterwards in the Kurdish populated northern Iraq (see 1991 uprisings in Iraq). Although they presented a serious threat to the Iraqi Ba'ath Party regime, Saddam Hussein managed to suppress the rebellions with massive and indiscriminate force and maintained power. They were ruthlessly crushed by the loyalist forces spearheaded by the Iraqi Republican Guard and the population was successfully terrorized. During the few weeks of unrest tens of thousands of people were killed. Many more died during the following months, while nearly two million Iraqis fled for their lives. In the aftermath, the government intensified the forced relocating of Marsh Arabs and the draining of the Iraqi marshlands, while the Coalition established the Iraqi no-fly zones.

On 6 August 1990, after the Iraqi invasion of Kuwait, the U.N. Security Council adopted Resolution 661 which imposed economic sanctions on Iraq, providing for a full trade embargo, excluding medical supplies, food and other items of humanitarian necessity, these to be determined by the Security Council sanctions committee. After the end of the Gulf War and after the Iraqi withdrawal from Kuwait, the sanctions were linked to removal of weapons of mass destruction by Resolution 687. From 1991 until 2003 Iraq underwent hyperinflation, increased poverty and malnutrition. To varying degrees, the effects of government policy, the aftermath of Gulf War and the sanctions regime have been blamed for these conditions.

The effects of the sanctions on the civilian population of Iraq have been disputed. Whereas it was widely believed that the sanctions caused a major rise in child mortality, recent research has shown that commonly cited data were fabricated by the Iraqi government and that "there was no major rise in child mortality in Iraq after 1990 and during the period of the sanctions." An oil for food program was established in 1996 to ease the effects of sanctions.

Iraqi cooperation with UN weapons inspection teams was questioned on several occasions during the 1990s. UNSCOM chief weapons inspector Richard Butler withdrew his team from Iraq in November 1998 because of Iraq's lack of cooperation. The team returned in December. Butler prepared a report for the UN Security Council afterwards in which he expressed dissatisfaction with the level of compliance . The same month, US President Bill Clinton authorized air strikes on government targets and military facilities. Air strikes against military facilities and alleged WMD sites continued into 2002.

After the terrorist attacks on New York and Washington in the United States in 2001 were linked to the group formed by the multi-millionaire Saudi Osama bin Laden, American foreign policy began to call for the removal of the Ba'ath government in Iraq. Neoconservative think-tanks in Washington had for years been urging regime change in Baghdad. On August 14, 1998, President Clinton signed Public Law 105–235, which declared that ‘‘the Government of Iraq is in material and unacceptable breach of its international obligations.’’ It urged the President ‘‘to take appropriate action, in accordance with the Constitution and relevant laws of the United States, to bring Iraq into compliance with its international obligations.’’ Several months later, Congress enacted the Iraq Liberation Act of 1998 on October 31, 1998. This law stated that it "should be the policy of the United States to support efforts to remove the regime headed by Saddam Hussein from power in Iraq and to promote the emergence of a democratic government to replace that regime." It was passed 360 - 38 by the United States House of Representatives and 99–0 by the United States Senate in 1998.

The US urged the United Nations to take military action against Iraq. American president George W. Bush stated that Saddām had repeatedly violated 16 UN Security Council resolutions. The Iraqi government rejected Bush's assertions. A team of U.N. inspectors, led by Swedish diplomat Hans Blix was admitted, into the country; their final report stated that Iraqis capability in producing "weapons of mass destruction" was not significantly different from 1992 when the country dismantled the bulk of their remaining arsenals under terms of the ceasefire agreement with U.N. forces, but did not completely rule out the possibility that Saddam still had weapons of mass destruction. The United States and the United Kingdom charged that Iraq was hiding WMD and opposed the team's requests for more time to further investigate the matter. Resolution 1441 was passed unanimously by the UN Security Council on November 8, 2002, offering Iraq "a final opportunity to comply with its disarmament obligations" that had been set out in several previous UN resolutions, threatening "serious consequences" if the obligations were not fulfilled. The UN Security Council did not issue a resolution authorizing the use of force against Iraq.

In March 2003, the United States and the United Kingdom, with military aid from other nations, invaded Iraq.

In 2003, after the American and British invasion, Iraq was occupied by Coalition forces. On May 23, 2003, the UN Security Council unanimously approved a resolution lifting all economic sanctions against Iraq. As the country struggled to rebuild after three wars and a decade of sanctions, it was plagued by violence between a growing Iraqi insurgency and occupation forces. Saddam Hussein, who vanished in April, was captured on December 13, 2003.

Jay Garner was appointed Interim Civil Administrator with three deputies, including Tim Cross. Garner was replaced in May 2003 by Paul Bremer, who was himself replaced by John Negroponte on April 19, 2004. Negroponte was the last US interim administrator and left Iraq in 2005. A parliamentary election was held in January 2005, followed by the drafting and ratification of a constitution and a further parliamentary election in December 2005.

Terrorism emerged as a threat to Iraq's people not long after the invasion of 2003. Al Qaeda now had a presence in the country, in the form of several terrorist groups formerly led by Abu Musab Al Zarqawi. Al-Zarqawi was a Jordanian militant Islamist who ran a militant training camp in Afghanistan. He became known after going to Iraq and being responsible for a series of bombings, beheadings and attacks during the Iraq war. Al-zarqawi was killed on June 7, 2006. Many foreign fighters and former Ba'ath Party officials also joined the insurgency, which was mainly aimed at attacking American forces and Iraqis who worked with them. The most dangerous insurgent area was the Sunni Triangle, a mostly Sunni-Muslim area just north of Baghdad.

Reported acts of violence conducted by an uneasy tapestry of insurgents steadily increased by the end of 2006. Sunni jihadist forces including Al Qaeda in Iraq continued to target Shia civilians, notably in the 23 February 2006 attack on the Al Askari Mosque in Samarra, one of Shi'ite Islam's holiest sites. Analysis of the attack suggested that the Mujahideen Shura Council and Al-Qaeda in Iraq were responsible, and that the motivation was to provoke further violence by outraging the Shia population. In mid-October 2006, a statement was released stating that the Mujahideen Shura Council had been disbanded and was replaced by the "Islamic State of Iraq". It was formed to resist efforts by the U.S. and Iraqi authorities to win over Sunni supporters of the insurgency. Shia militias, some of whom were associated with elements in the Iraq government, reacted with reprisal acts against the Sunni minority. A cycle of violence thus ensued whereby Sunni insurgent attacks were followed reprisals by Shiite militias, often in the form of Shi'ite death squads that sought out and killed Sunnis. Following a surge in U.S. troops in 2007 and 2008, violence in Iraq began to decrease. The U.S. ended their main military presence in 2011, however, resulting in renewed escalation into civil war.

The departure of US troops from Iraq in 2011 triggered a renewed insurgency and by a spillover of the Syrian civil war into Iraq. By 2013, the insurgency escalated into a state renewed civil war, the central government of Iraq being opposed by various factions, primarily radical Sunni forces.

The Islamic State of Iraq and the Levant invaded Iraq in 2013–14 and seized the majority of Al Anbar Governorate, including the cities of Fallujah, Al Qaim, Abu Ghraib and (in May 2015) Ramadi, leaving them in control of 90% of Anbar. Tikrit, Mosul and most of the Nineveh province, along with parts of Salahuddin, Kirkuk and Diyala provinces, were seized by insurgent forces in the June 2014 offensive. ISIL also captured Sinjar and a number of other towns in the August 2014 offensive, but were halted by the Sinjar offensive launched in December 2014 by Kurdish Peshmerga and YPG forces. The civil war ended with a government victory in December 2017.

On 30 April 2016, thousands of protesters entered the Green Zone in Baghdad and occupied the Iraqi parliament building. This happened after the Iraqi parliament did not approve new government ministers. The protesters included supporters of Shia cleric Muqtada Al Sadr. Although Iraqi security forces were present, they did not attempt to stop the protesters from entering the parliament building.

By 2018, violence in Iraq was at its lowest level in ten years.

Protests over deteriorating economic conditions and state corruption started in July 2018 in Baghdad and other major Iraqi cities, mainly in the central and southern provinces. The latest nationwide protests, erupting in October 2019, had a death toll of at least 93 people, including police.




</doc>
<doc id="14665" url="https://en.wikipedia.org/wiki?curid=14665" title="Geography of Iraq">
Geography of Iraq

The geography of Iraq is diverse and falls into five main regions: the desert (west of the Euphrates), Upper Mesopotamia (between the upper Tigris and Euphrates rivers), the northern highlands of Iraq, Lower Mesopotamia, and the alluvial plain extending from around Tikrit to the Persian Gulf.

The mountains in the northeast are an extension of the alpine system that runs eastward from the Balkans through southern Turkey, northern Iraq, Iran, and Afghanistan, eventually reaching the Himalayas. The desert is in the southwest and central provinces along the borders with Saudi Arabia and Jordan and geographically belongs with the Arabian Peninsula.

Most geographers, including those of the Iraqi government, discuss the country's geography in terms of four main zones or regions: the desert in the west and southwest; the rolling upland between the upper Tigris and Euphrates rivers (in Arabic the "Dijla" and "Furat", respectively); the highlands in the north and northeast; and the alluvial plain through which the Tigris and Euphrates flow.
Iraq's official statistical reports give the total land area as , whereas a United States Department of State publication gives the area as .

The uplands region, between the Tigris north of Samarra and the Euphrates north of Hit, is known as Al Jazira (the island) and is part of a larger area that extends westward into Syria between the two rivers and into Turkey. Water in the area flows in deeply cut valleys, and irrigation is much more difficult than it is in the lower plain. The southwest areas of this zone are classified as desert or semi-desert. The northern parts, which include such places like the Nineveh Plains, Duhok and Zakho, mainly consist of Mediterranean vegetation. The vegetation cyclically dries out and appear brown in the virtually arid summer and flourish in the wet winter.

An Alluvial plain begins north of Baghdad and extends to the Persian Gulf. Here the Tigris and Euphrates rivers lie above the level of the plain in many places, and the whole area is a river delta interlaced by the channels of the two rivers and by irrigation canals. Intermittent lakes, fed by the rivers in flood, also characterize southeastern Iraq. A fairly large area () just above the confluence of the two rivers at Al Qurnah and extending east of the Tigris beyond the Iranian border is marshland, known as Hawr al Hammar, the result of centuries of flooding and inadequate drainage. Much of it is permanent marsh, but some parts dry out in early winter, and other parts become marshland only in years of great flood.

Because the waters of the Tigris and Euphrates above their confluence are heavily silt- laden, irrigation and fairly frequent flooding deposit large quantities of silty loam in much of the delta area. Windborne silt contributes to the total deposit of sediments. It has been estimated that the delta plains are built up at the rate of nearly twenty centimeters in a century. In some areas, major floods lead to the deposit in temporary lakes of as much as thirty centimeters of mud.

The Tigris and Euphrates also carry large quantities of salts. These, too, are spread on the land by sometimes excessive irrigation and flooding. A high water table and poor surface and subsurface drainage tend to concentrate the salts near the surface of the soil. In general, the salinity of the soil increases from Baghdad south to the Persian Gulf and severely limits productivity in the region south of Al Amarah. The salinity is reflected in the large lake in central Iraq, southwest of Baghdad, known as Bahr al Milh (Sea of Salt). There are two other major lakes in the country to the north of Bahr al Milh: Buhayrat ath Tharthar and Buhayrat al Habbaniyah.

Between Upper and Lower Mesopotamia is the urban area surrounding Baghdad. These "Baghdad Belts" can be described as the provinces adjacent to the Iraqi capital and can be divided into four quadrants: northeast, southeast, southwest, and northwest. Beginning in the north, the belts include the province of Saladin, clockwise to Baghdad province, Diyala in the northeast, Babil and Wasit in the southeast and around to Al Anbar in the west.

The northeastern highlands begin just south of a line drawn from Mosul to Kirkuk and extend to the borders with Turkey and Iran. High ground, separated by broad, undulating steppes, gives way to mountains ranging from near the Iranian and Turkish borders. Except for a few valleys, the mountain area proper is suitable only for grazing in the foothills and steppes; adequate soil and rainfall, however, make cultivation possible. Here, too, are the great oil fields near Mosul and Kirkuk. The northeast is the homeland of most Iraqi Kurds.

The desert zone, an area lying west and southwest of the Euphrates River, is a part of the Syrian Desert and Arabian Desert, which covers sections of Syria, Jordan, and Saudi Arabia and most of the Arabian Peninsula.
The region, sparsely inhabited by pastoral bedouins, consists of a wide stony plain interspersed with rare sandy stretches. A widely ramified pattern of wadis–watercourses that are dry most of the year–runs from the border to the Euphrates. Some wadis are over long and carry brief but torrential floods during the winter rains.

Western and southern Iraq is a vast desert region covering some 64,900 square miles (168,000 square km), almost two-fifths of the country.
The western desert, an extension of the Syrian Desert, rises to elevations above 1,600 feet (490 metres).
The southern desert is known as Al-Hajarah in the western part and as Al-Dibdibah in the east. Both deserts are part of the Arabian Desert.
Al Hajarah has a complex topography of rocky desert, wadis, ridges, and depressions.
Al-Dibdibah is a more sandy region with a covering of scrub vegetation. Elevation in the southern desert averages between 1,000 and 2,700 feet (300 to 800 metres).
A height of 3,119 feet (951 metres) is reached at Mount 'Unayzah at the intersection of the borders of Jordan, Iraq and Saudi Arabia.
The deep Wadi Al-Batin runs 45 miles (75 km) in a northeast-southwest direction through Al-Dibdibah. It has been recognized since 1913 as the boundary between western Kuwait and Iraq.

The Euphrates originates in Turkey, is augmented by the Balikh and Khabur rivers in Syria, and enters Iraq in the northwest. Here it is fed only by the wadis of the western desert during the winter rains. It then winds through a gorge, which varies from two to 16 kilometers in width, until it flows out on the plain at Ar Ramadi. Beyond there the Euphrates continues to the Hindiya Barrage, which was constructed in 1914 to divert the river into the Hindiyah Channel; the present day Shatt al Hillah had been the main channel of the Euphrates before 1914. Below Al Kifl, the river follows two channels to As-Samawah, where it reappears as a single channel to join the Tigris at Al Qurnah.
The Tigris also rises in Turkey but is significantly augmented by several rivers in Iraq, the most important of which are the Khabur, the Great Zab, the Little Zab, and the Adhaim, all of which join the Tigris above Baghdad, and the Diyala, which joins it about thirty-six kilometers below the city. At the Kut Barrage much of the water is diverted into the Shatt al-Hayy, which was once the main channel of the Tigris. Water from the Tigris thus enters the Euphrates through the Shatt al-Hayy well above the confluence of the two main channels at Al Qurnah.

Both the Tigris and the Euphrates break into a number of channels in the marshland area, and the flow of the rivers is substantially reduced by the time they come together at Al Qurnah. Moreover. the swamps act as silt traps, and the Shatt al Arab is relatively silt free as it flows south. Below Basra, however, the Karun River enters the Shatt al Arab from Iran, carrying large quantities of silt that present a continuous dredging problem in maintaining a channel for ocean-going vessels to reach the port at Basra. This problem has been superseded by a greater obstacle to river traffic, however, namely the presence of several sunken hulls that have been rusting in the Shatt al Arab since early in the Iran-Iraq war.

The waters of the Tigris and Euphrates are essential to the life of the country, but they sometimes threaten it. The rivers are at their lowest level in September and October and at flood in March, April, and May when they may carry forty times as much water as at low mark. Moreover, one season's flood may be ten or more times as great as that in another year. In 1954, for example, Baghdad was seriously threatened, and dikes protecting it were nearly topped by the flooding Tigris. Since Syria built a dam on the Euphrates, the flow of water has been considerably diminished and flooding was no longer a problem in the mid-1980s. In 1988 Turkey was also constructing a dam on the Euphrates that would further restrict the water flow.

Until the mid-twentieth century, most efforts to control the waters were primarily concerned with irrigation. Some attention was given to problems of flood control and drainage before the revolution of July 14, 1958, but development plans in the 1960s and 1970s were increasingly devoted to these matters, as well as to irrigation projects on the upper reaches of the Tigris and Euphrates and the tributaries of the Tigris in the northeast. During the war, government officials stressed to foreign visitors that, with the conclusion of a peace settlement, problems of irrigation and flooding would receive top priority from the government.

Iraqi coastal waters boast a living coral reef, covering an area of 28 km in the Persian Gulf, at the mouth of the Shatt al-Arab river (). The coral reef was discovered by joint Iraqi–German expeditions of scientific scuba divers carried out in September 2012 and in May 2013. Prior to its discovery, it was believed that Iraq lacks coral reefs as the local turbid waters prevented the detection of the potential presence of local coral reefs. Iraqi corals were found to be adapted to one of the most extreme coral-bearing environments in the world, as the seawater temperature in this area ranges between 14 and 34 °C. The reef harbors several living stone corals, octocorals, ophiuroids and bivalves. There are also silica-containing demo-sponges.

In the rural areas of the alluvial plain and in the lower Diyala region, settlement almost invariably clusters near the rivers, streams, and irrigation canals. The bases of the relationship between watercourse and settlement have been summarized by Robert McCormick Adams, director of the Oriental Institute of the University of Chicago. He notes that the levees laid down by streams and canals provide advantages for both settlement and agriculture. Surface water drains more easily on the levees' back-slope, and the coarse soils of the levees are easier to cultivate and permit better subsurface drainage. The height of the levees gives some protection against floods and the frost that often affect low-lying areas and may kill and/or damage winter crops. Above all, those living or cultivating on the crest of a levee have easy access to water for irrigation and household use in a dry, hot country.

Although there are some isolated homesteads, most rural communities are nucleated settlements rather than dispersed farmsteads; that is, the farmer leaves his village to cultivate the fields outside it. The pattern holds for farming communities in the Kurdish highlands of the northeast as well as for those in the alluvial plain. The size of the settlement varies, generally with the volume of water available for household use and with the amount of land accessible to village dwellers. Sometimes, particularly in the lower Tigris and Euphrates valleys, soil salinity restricts the area of arable land and limits the size of the community dependent on it, and it also usually results in large unsettled and uncultivated stretches between the villages.

Fragmentary information suggests that most farmers in the alluvial plain tend to live in villages of over 100 persons. For example, in the mid-1970s a substantial number of the residents of Baqubah, the administrative center and major city of Diyala Governorate, were employed in agriculture.

The Marsh Arabs of the south usually live in small clusters of two or three houses kept above water by rushes that are constantly being replenished. Such clusters often are close together, but access from one to another is possible only by small boat. Here and there a few natural islands permit slightly larger clusters. Some of these people are primarily water buffalo herders and lead a semi-nomadic life. In the winter, when the waters are at a low point, they build fairly large temporary villages. In the summer they move their herds out of the marshes to the river banks.

The war has had its effect on the lives of these denizens of the marshes. With much of the fighting concentrated in their areas, they have either migrated to settled communities away from the marshes or have been forced by government decree to relocate within the marshes. Also, in early 1988, the marshes had become the refuge of deserters from the Iraqi army who attempted to maintain life in the fastness of the overgrown, desolate areas while hiding out from the authorities. These deserters in many instances have formed into large gangs that raid the marsh communities; this also has induced many of the marsh dwellers to abandon their villages.

The war has also affected settlement patterns in the northern Kurdish areas. There, the struggle for a Kurdish state by guerrillas was rejected by the government as it steadily escalated violence against the local communities. Starting in 1984, the government launched a scorched-earth campaign to drive a wedge between the villagers and the guerrillas in the remote areas of two provinces of Kurdistan in which Kurdish guerrillas were active. In the process whole villages were torched and subsequently bulldozed, which resulted in the Kurds flocking into the regional centers of Irbil and As Sulaymaniyah. Also as a "military precaution", the government has cleared a broad strip of territory in the Kurdish region along the Iranian border of all its inhabitants, hoping in this way to interdict the movement of Kurdish guerrillas back and forth between Iran and Iraq. The majority of Kurdish villages, however, remained intact in early 1988.

In the arid areas of Iraq to the west and south, cities and large towns are almost invariably situated on watercourses, usually on the major rivers or their larger tributaries. In the south this dependence has had its disadvantages. Until the recent development of flood control, Baghdad and other cities were subject to the threat of inundation. Moreover, the dikes needed for protection have effectively prevented the expansion of the urban areas in some directions. The growth of Baghdad, for example, was restricted by dikes on its eastern edge. The diversion of water to the Milhat ath Tharthar and the construction of a canal transferring water from the Tigris north of Baghdad to the Diyala River have permitted the irrigation of land outside the limits of the dikes and the expansion of settlement.

The climate of Iraq is mainly a hot desert climate or a hot semi-arid climate to the northernmost part. Averages high temperatures are generally above 40 °C (104 °F) at low elevations during summer months (June, July and August) while averages low temperatures can drop to below 0 °C (32 °F) during the coldest month of the year during winter The all-time record high temperature in Iraq of 52 °C (126 °F) was recorded near An Nasiriyah on 2 August 2011. Most of the rainfall occurs from December through April and averages between annually. The mountainous region of northern Iraq receives appreciably more precipitation than the central or southern desert region, where they tend to have a Mediterranean climate.

Roughly 90% of the annual rainfall occurs between November and April, most of it in the winter months from December through March. The remaining six months, particularly the hottest ones of June, July, and August, are extremely dry.

Except in the north and northeast, mean annual rainfall ranges between . Data available from stations in the foothills and steppes south and southwest of the mountains suggest mean annual rainfall between for that area. Rainfall in the mountains is more abundant and may reach a year in some places, but the terrain precludes extensive cultivation. Cultivation on nonirrigated land is limited essentially to the mountain valleys, foothills, and steppes, which have or more of rainfall annually. Even in this zone, however, only one crop a year can be grown, and shortages of rain have often led to crop failures.

Mean minimum temperatures in the winter range from near freezing (just before dawn) in the northern and northeastern foothills and the western desert to and in the alluvial plains of southern Iraq. They rise to a mean maximum of about in the western desert and the northeast, and in the south. In the summer mean minimum temperatures range from about and rise to maxima between roughly . Temperatures sometimes fall below freezing and have fallen as low as at Ar Rutbah in the western desert. A such summer heat, even in a hot desert, is high and this can be easily explained by the very low elevations of deserts regions which experience these exceptionally searing high temperatures. In fact, the elevations of cities such as Baghdad or Basra are near the sea level (0 m) because deserts are located predominantly along the Persian Gulf. That's why some Gulf's countries like Iraq, Iran and Kuwait experience extreme heat during summer, even more extreme than the normal level. The searing summer heat only exists in low elevations in these countries while mountains and higher elevations know much more moderated summer temperatures.

The summer months are marked by two kinds of wind phenomena. The southern and southeasterly "sharqi", a dry, dusty wind with occasional gusts of , occurs from April to early June and again from late September through November. It may last for a day at the beginning and end of the season but for several days at other times. This wind is often accompanied by violent duststorms that may rise to heights of several thousand meters and close airports for brief periods. From mid-June to mid-September the prevailing wind, called the shamal, is from the north and northwest. It is a steady wind, absent only occasionally during this period. The very dry air brought by this shamal permits intensive sun heating of the land surface, but the breeze has some cooling effect.

The combination of rain shortage and extreme heat makes much of Iraq a desert. Because of very high rates of evaporation, soil and plants rapidly lose the little moisture obtained from the rain, and vegetation could not survive without extensive irrigation. Some areas, however, although arid, do have natural vegetation in contrast to the desert. For example, in the Zagros Mountains in northeastern Iraq there is permanent vegetation, such as oak trees, and date palms are found in the south.

In 1922 British officials concluded the Treaty of Mohammara with Abd al Aziz ibn Abd ar Rahman Al Saud, who in 1932 formed the Kingdom of Saudi Arabia. The treaty provided the basic agreement for the boundary between the eventually independent nations. Also in 1922 the two parties agreed to the creation of the diamond-shaped Neutral Zone of approximately adjacent to the western tip of Kuwait in which neither Iraq nor Saudi Arabia would build dwellings or installations. Bedouins from either country could utilize the limited water and seasonal grazing resources of the zone. In April 1975, an agreement signed in Baghdad fixed the borders of the countries.

Through Algerian mediation, Iran and Iraq agreed in March 1975 to normalize their relations, and three months later they signed a treaty known as the Algiers Accord. The document defined the common border all along the Khawr Abd Allah (Shatt) River estuary as the thalweg. To compensate Iraq for the loss of what formerly had been regarded as its territory, pockets of territory along the mountain border in the central sector of its common boundary with Iran were assigned to it. Nonetheless, in September 1980 Iraq went to war with Iran, citing among other complaints the fact that Iran had not turned over to it the land specified in the Algiers Accord. This problem has subsequently proved to be a stumbling block to a negotiated settlement of the ongoing conflict.

In 1988 the boundary with Kuwait was another outstanding problem. It was fixed in a 1913 treaty between the Ottoman Empire and British officials acting on behalf of Kuwait's ruling family, which in 1899 had ceded control over foreign affairs to Britain. The boundary was accepted by Iraq when it became independent in 1932, but in the 1960s and again in the mid-1970s, the Iraqi government advanced a claim to parts of Kuwait. Kuwait made several representations to the Iraqis during the war to fix the border once and for all but Baghdad repeatedly demurred, claiming that the issue is a potentially divisive one that could inflame nationalist sentiment inside Iraq. Hence in 1988 it was likely that a solution would have to wait until the war ended.

Area:<br>
"total:" <br>
"land:" <br>
"water:" 

Land boundaries:<br>
"total:" <br>
"border countries:" Iran , Saudi Arabia , Syria , Turkey , Kuwait , Jordan 

Coastline: 

Maritime claims:<br>
"territorial sea:" 
"continental shelf:" not specified

Terrain:<br> mostly broad plains; reedy marshes along Iranian border in south with large flooded areas; mountains along borders with Iran and Turkey

Elevation extremes:<br>
"lowest point:" Persian Gulf 0 m<br>
"highest point:" Cheekah Dar 

Natural resources: petroleum, natural gas, phosphates, sulfur

Land use:<br>
"arable land:" 7.89%<br>
"permanent crops:" 0.53%<br>
"other:" 91.58% (2012)

Irrigated land: (2003)

Total renewable water resources: (2011)

Freshwater withdrawal (domestic/industrial/agricultural):<br>
"total:" 66 km/yr (7%/15%/79%)<br>
"per capita:" 2,616 m/yr (2000)

While its proven oil reserves of ranks Iraq second in the world behind Saudi Arabia, the United States Department of Energy estimates that up to 90 percent of the country remains unexplored. Unexplored regions of Iraq could yield an additional . Iraq's oil production costs are among the lowest in the world. However, only about 2,000 oil wells have been drilled in Iraq, compared to about 1 million wells in Texas alone.

Natural hazards: dust storms, sandstorms, floods

Environment - current issues: government water control projects have drained most of the inhabited marsh areas east of An Kshatriya by drying up or diverting the feeder streams and rivers; a once sizable population of Shi'a Muslims, who have inhabited these areas for thousands of years, has been displaced; furthermore, the destruction of the natural habitat poses serious threats to the area's wildlife populations; inadequate supplies of potable water; development of Tigris-Euphrates Rivers system contingent upon agreements with upstream riparian Turkey; air and water pollution; soil degradation (desalination) and erosion; and desertification.

Environment - international agreements:<br>
"party to:" Biodiversity, Law of the Sea, Ozone Layer Protection<br>
"signed, but not ratified:" Environmental Modification




</doc>
<doc id="14666" url="https://en.wikipedia.org/wiki?curid=14666" title="Demographics of Iraq">
Demographics of Iraq

The Iraqi people (, , Syriac: ܥܡܐ ܥܝܪܩܝܐ, ) are people identified with the country of Iraq.

Iraqi Arabs are the largest Semitic people in Iraq, while Kurds are the largest non-Semitic ethnic group and largest ethnic minority. Iraqi Turkmen are the third largest ethnic group in the country. Studies indicate that the different ethno-religious groups of Iraq and Mesopotamia share significant similarities in genetics and that Iraqi Arabs, who make up the majority of Iraqis, are genetically related to other Arab populations in the Arabs of the Arabian peninsula.

The population was estimated to be 40,194,216 in 2018 (residing in Iraq) and over 10 million living in the diaspora, with most of the population being Shia Arabs (15 million), Sunni Arabs (9 million), followed by Kurds (4.7 million), Assyrians and Armenians (0.5 million), Turkmen (3 million), Afro-Iraqis (1 million), Yazidis (500,000) and Shabaks (250,000). Other minorities include Mandeans (3,000), Roma (50,000) and Circassians (2,000). The most spoken languages are Mesopotamian Arabic, Kurdish, Syriac and Iraqi Turkmen dialects. The percentages of different ethno-religious groups residing in Iraq vary from source to source due to the last Iraqi census having taken place over 30 years ago. A new census of Iraq is planned to take place in 2020.

Iraq is the region known outside the Islamic world as Mesopotamia. The population estimate in 1920 was 3 million. The ruins of Ur, Babylon and other ancient cities are situated in Iraq, as is the legendary location of the Garden of Eden. Almost 75% of Iraq's population lives in the flat, alluvial plain stretching southeast from Tikrit to the Persian Gulf. The Tigris and the Euphrates carry about 70 million cubic meters of silt annually from this plain down to the delta. The water from these two great rivers, and the fertility of the soil in the alluvial plain and the delta, allowed early agriculture to sustain a stable population as far back as the 7th millennium BC.

40,194,216 (2018 estimate), ( estimate), up from 31,234,000 (April 2009 IMF estimate)

Births and deaths
Average life expectancy at age 0 of the total population.

Structure of the population (1 July 2013) (Estimates) :

Iraq's dominant ethnic group are the Mesopotamian Arabs, who account for more than three-quarters of the population.

According to the CIA World Factbook, citing a 1987 Iraqi government estimate, the population of Iraq is formed of 70% Arabs followed by 25% Kurds. In addition, the estimate claims that other minorities form 5% of the country's population, including the Turkmen/Turcoman, Yazidis, Shabaks, Kaka'i, Bedouins, Roma, Chaldeans, Assyrians, Circassians, Sabaean-Mandaean, and Persians. However, the International Crisis Group points out that figures from the 1987 census, as well as the 1967, 1977, and 1997 censuses, "are all considered highly problematic, due to suspicions of regime manipulation" because Iraqi citizens were only allowed to indicate belonging to either the Arab or Kurdish ethnic groups; consequently, this skewed the number of other ethnic minorities, such as Iraq's third largest ethnic group – the Turkmens/Turkomans.

A report published by the European Parliamentary Research Service suggests that in 2015 there was 20 million Arabs (15 million Shia and 9 million Sunni); 8 million Sunni Kurds (plus 500,000 Shia Feylis and 200,000 Kaka'i); 0.5 million Iraqi Turkmen/Turkoman; 1 million Black Iraqis; 500,000 Christians (including Chaldeans, Syriacs, Assyrians, Armenians and Arab Christians); 500,000 Yazidis; 250,000 Shabaks; 50,000 Roma; 3,000 Sabean-Mandaeans; 2,000 Circassians; 1,000 Baha’i; and a few dozen Jews.

Arabic and Kurdish are the two official languages of Iraq. Arabic is taught across all schools in Iraq, however in the north the Kurdish language is the most spoken. Eastern Aramaic languages, such as Syriac and Mandaic are spoken, as well as the Iraqi Turkoman language, and various other indigenous languages.

Kurdish, including several dialects, is the second largest language and has regional language status in the north of the country. Aramaic, in antiquity spoken throughout the whole country, is now only spoken by the Assyrian Chaldean minority. The Iraqi Turkmen/Turkoman dialect of Turkish is spoken in pockets of northern Iraq (particularly in the so-called Turkmeneli region) and numerous languages of the Caucasus are also spoken by minorities, notably the Chechen community.

98% of Iraqis follow Islam: 51% Shia and 42% Sunni. 5% of these describe themselves as "Just a Muslim". According to the CIA World Factbook, Shias make up 58% of population, while Sunnis make up 37%. Christianity accounts for 1–2%, and the rest practice Yazidism, Mandaeism, and other religions.

While there has been voluntary relocation of many Christian families to northern Iraq, recent reporting indicates that the overall Christian population may have dropped by as much as 50 percent since the fall of Saddam Hussein in 2003, with many fleeing to Syria, Jordan, and Lebanon (2010 estimate). The percentage of Christians has fallen from 6% in 1991 or 1.5 million to about one third of this. Estimates say there are 500,000 Christians in Iraq.

Nearly all Iraqi Kurds are Sunni Muslims. A survey in Iraq concluded that "98% of Kurds in Iraq identified themselves as Sunnis and only 2% identified as Shias". The religious differences between Sunni Arabs and Sunni Kurds are small. While 98 percent of Shia Arabs believe that visiting the shrines of saints is acceptable, 71 percent of Sunni Arabs did and 59 percent of Sunni Kurds support this practice. About 94 percent of the population in Iraqi Kurdistan is Muslim.

The following demographic statistics are from the CIA World Factbook, unless otherwise indicated.

According to Pew, which surveyed nearly 1,500 scientifically random-sampled Iraqis regarding their religious affiliations, and also their religious beliefs and practices, at "The few available survey measures of religious identity in Iraq suggest that about half the country is Shia. Surveys by ABC News found between 47% and 51% of the country identifying as Shia between 2007 and 2009, and a Pew Research survey conducted in Iraq in late 2011 found that 51% of Iraqi Muslims said they were Shia (compared with 42% saying they were Sunni)." The following figures aren't linked to sources, and therefore may be entirely untrustworthy though the editors at Wikipedia have allowed them to be published here:




</doc>
<doc id="14667" url="https://en.wikipedia.org/wiki?curid=14667" title="Politics of Iraq">
Politics of Iraq

The politics of Iraq take place in a framework of a federal parliamentary representative democratic republic. It is a multi-party system whereby the executive power is exercised by the Prime Minister of the Council of Ministers as the head of government, as well as the President of Iraq, and legislative power is vested in the Council of Representatives and the Federation Council.

The current Prime Minister of Iraq is Mustafa Al-Kadhimi, who holds most of the executive authority and appointed the Council of Ministers, which acts as a cabinet and/or government.

The federal government of Iraq is defined under the current constitution as an Islamic, democratic, federal parliamentary republic. The federal government is composed of the executive, legislative, and judicial branches, as well as numerous independent commissions.

The legislative branch is composed of the Council of Representatives and a Federation Council. The executive branch is composed of the president, the prime minister, and the Council of Ministers. The federal judiciary is composed of the Higher Judicial Council, the Supreme Court, the Court of Cassation, the Public Prosecution Department, the Judiciary Oversight Commission, and other federal courts that are regulated by law. One such court is the Central Criminal Court.

The Independent High Commission for Human Rights, the Independent High Electoral Commission, and the Commission on Integrity are independent commissions subject to monitoring by the Council of Representatives. The Central Bank of Iraq, the Board of Supreme Audit, the Communications and Media Commission, and the Endowment Commission are financially and administratively independent institutions. The Foundation of Martyrs is attached to the Council of Ministers. The Federal Public Service Council regulates the affairs of the federal public service, including appointment and promotion.

The basic subdivisions of the country are the regions and the governorates. Both regions and governorates are given broad autonomy with regions given additional powers such as control of internal security forces for the region such as police, security forces, and guards. The last local elections for the governorates were held in the 2009 Iraqi governorate elections on 31 January 2009.

The constitution requires that the Council of Representatives enact a law which provides the procedures for forming a new region 6 months from the start of its first session. A law was passed 11 October 2006 by a unanimous vote with only 138 of 275 representatives present, with the remaining representatives boycotting the vote. Legislators from the Iraqi Accord Front, Sadrist Movement and Islamic Virtue Party all opposed the bill.

Under the law, a region can be created out of one or more existing governorates or two or more existing regions, and a governorate can also join an existing region to create a new region. A new region can be proposed by one third or more of the council members in each affected governorate plus 500 voters or by one tenth or more voters in each affected governorate. A referendum must then be held within three months, which requires a simple majority in favour to pass. In the event of competing proposals, the multiple proposals are put to a ballot and the proposal with the most supporters is put to the referendum. In the event of an affirmative referendum a Transitional Legislative Assembly is elected for one year, which has the task of writing a constitution for the Region, which is then put to a referendum requiring a simple majority to pass. The President, Prime Minister and Ministers of the region are elected by simple majority, in contrast to the Iraqi Council of Representatives which requires two thirds support.

Iraq is divided into 18 governorates, which are further divided into districts:




Elections for the National Assembly of Iraq were held on January 30, 2005 in Iraq. The 275-member National Assembly was a parliament created under the Transitional Law during the Occupation of Iraq. The newly elected transitional Assembly was given a mandate to write the new and permanent Constitution of Iraq and exercised legislative functions until the new Constitution came into effect, and resulted in the formation of the Iraqi Transitional Government.

The United Iraqi Alliance, tacitly backed by Shia Grand Ayatollah Ali al-Sistani, led with some 48% of the vote. The Democratic Patriotic Alliance of Kurdistan was in second place with some 26% of the vote. Prime Minister Ayad Allawi's party, the Iraqi List, came third with some 14%. In total, twelve parties received enough votes to win a seat in the assembly.

Low Arab Sunni turnout threatened the legitimacy of the election, which was as low as 2% in Anbar province. More than 100 armed attacks on polling places took place, killing at least 44 people (including nine suicide bombers) across Iraq, including at least 20 in Baghdad.

Following the ratification of the Constitution of Iraq on 15 October 2005, a general election was held on 15 December to elect the permanent 275-member Iraqi Council of Representatives.

The elections took place under a list system, whereby voters chose from a list of parties and coalitions. 230 seats were apportioned among Iraq's 18 governorates based on the number of registered voters in each as of the January 2005 elections, including 59 seats for Baghdad Governorate. The seats within each governorate were allocated to lists through a system of Proportional Representation. An additional 45 "compensatory" seats were allocated to those parties whose percentage of the national vote total (including out of country votes) exceeds the percentage of the 275 total seats that they have been allocated. Women were required to occupy 25% of the 275 seats. The change in the voting system gave more weight to Arab Sunni voters, who make up most of the voters in several provinces. It was expected that these provinces would thus return mostly Sunni Arab representatives, after most Sunnis boycotted the last election.

Turnout was high (79.6%). The White House was encouraged by the relatively low levels of violence during polling, with one insurgent group making good on a promised election day moratorium on attacks, even going so far as to guard the voters from attack. President Bush frequently pointed to the election as a sign of progress in rebuilding Iraq. However, post-election violence threatened to plunge the nation into civil war, before the situation began to calm in 2007. The election results themselves produced a shaky coalition government headed by Nouri al-Maliki.

A parliamentary election was held in Iraq on 7 March 2010. The election decided the 325 members of the Council of Representatives of Iraq who will elect the Iraqi Prime Minister and President. The election resulted in a partial victory for the Iraqi National Movement, led by former Interim Prime Minister Ayad Allawi, which won a total of 91 seats, making it the largest alliance in the Council. The State of Law Coalition, led by incumbent Prime Minister Nouri Al-Maliki, was the second largest grouping with 89 seats.

The election was rife with controversy. Prior to the election, the Supreme Court in Iraq ruled that the existing electoral law/rule was unconstitutional, and a new elections law made changes in the electoral system. On 15 January 2010, the Independent High Electoral Commission (IHEC) banned 499 candidates from the election due to alleged links with the Ba'ath Party. Before the start of the campaign on 12 February 2010, IHEC confirmed that most of the appeals by banned candidates had been rejected and 456 of the initially banned candidates would not be allowed to run for the election. There were numerous allegations of fraud, and a recount of the votes in Baghdad was ordered on 19 April 2010. On May 14, IHEC announced that after 11,298 ballot boxes had been recounted, there was no sign of fraud or violations.

The new parliament opened on 14 June 2010. After months of fraught negotiations, an agreement was reached on the formation of a new government on November 11. Talabani would continue as president, Al-Maliki would stay on as prime minister and Allawi would head a new security council.

Parliamentary elections were held in Iraq on 30 April 2014. The elections decided the 328 members of the Council of Representatives who will in turn elect the Iraqi President and Prime Minister.

According to Transparency International, Iraq's is the most corrupt government in the Middle East, and is described as a "hybrid regime" (between a "flawed democracy" and an "authoritarian regime"). The 2011 report "Costs of War" from Brown University's Watson Institute for International Studies concluded that U.S. military presence in Iraq has not been able to prevent this corruption, noting that as early as 2006, "there were clear signs that post-Saddam Iraq was not going to be the linchpin for a new democratic Middle East."





</doc>
<doc id="14668" url="https://en.wikipedia.org/wiki?curid=14668" title="Economy of Iraq">
Economy of Iraq

The economy of Iraq is dominated by the oil sector, which has provided about 99.7% of foreign exchange earnings in modern times. Iraq's hitherto agrarian economy underwent rapid development following the 14 July Revolution overthrowing the Hashemite Iraqi monarchy, becoming the third-largest economy in the Middle East by 1980. This occurred in part because of the Iraqi government's successful industrialization and infrastructure development initiatives in the 1970's, which included irrigation projects, railway and highway construction, and rural electricfication. 

In the 1980s, financial problems caused by massive expenditures in the Iran-Iraq War and damage to oil export facilities by Iran led the Ba'athist government to implement austerity measures, borrow heavily, and later reschedule foreign debt payments; Iraq suffered economic losses of at least $80 billion from the war. After the end of hostilities, in 1988, oil exports gradually increased with the construction of new pipelines and restoration of damaged facilities, but again underwent a sharp decline after the Persian Gulf War, dropping to one-fourth of its 1980 gross domestic product and continuing to decline under postwar international sanctions until receiving aid from the U.N. Oil-for-Food Programme in 1997.

Despite the efforts of the Coalition Provisional Authority to modernize Iraq's economy after the 2003 U.S.-led invasion through privatization and reducing its foreign debt, its economy continued to decline due to continued violence, economic mismanagement, and oil shortages caused by outdated technology. Since mid-2009, oil export earnings have returned to levels seen before and government revenues have rebounded, along with global oil prices. In 2011 Baghdad probably will increase oil exports above the current level of per day as a result of new contracts with international oil companies, but is likely to fall short of the per day it is forecasting in its budget. Iraq's recent contracts with major oil companies have the potential to greatly expand oil revenues, but Iraq will need to upgrade its oil processing, pipeline, and export infrastructure to enable these deals to reach their potential.

An improved security environment and an initial wave of foreign investment are helping to spur economic activity, particularly in the energy, construction, and retail sectors. Broader economic improvement, long-term fiscal health, and sustained increases in the standard of living still depend on the government passing major policy reforms and on continued development of Iraq's massive oil reserves. Although foreign investors viewed Iraq with increasing interest in 2010, most are still hampered by difficulties in acquiring land for projects and by other regulatory impediments.

Inflation has decreased consistently since 2006 as the security situation has improved. However, Iraqi leaders remain hard pressed to translate macroeconomic gains into improved lives for ordinary Iraqis. Unemployment remains a problem throughout the country.

Nominal GDP grew by 213% in the 1960s, 1325% in the 1970s, 2% in the 1980s, −47% in the 1990s, and 317% in 2000s.

Real GDP per capita (measured in 1990 $) increased significantly during the 1950s, 60s and 70s, which can be explained by both higher oil production levels as well as oil prices, which famously peaked in the 1970s due to the OPEC's oil embargo, causing the 1973 oil crisis. In following two decades however, GDP per capita in Iraq dropped substantially because of multiple wars, namely the 1980-88 war with Iran, the 1990-1991 Gulf War.

Prior to the outbreak of the war with Iran in September 1980, Iraq's economic prospects were bright. Oil production had reached a level of 560,000 m³ (3.5 million barrels) per day in 1979, and oil revenues were 21 billion dollars in 1979 and 27 billion in 1980 due to record oil prices. At the outbreak of the war, Iraq had amassed an estimated 35 billion in foreign exchange reserves.

The Iran–Iraq War and the 1980s oil glut depleted Iraq's foreign exchange reserves, devastated its economy, and left the country saddled with a foreign debt of more than $40 billion. After the initial destruction of the war, oil exports gradually increased with the construction of new pipelines and the restoration of damaged facilities.

Iraq's seizure of Kuwait in August 1990, subsequent international economic sanctions on Iraq, and damage from military action by an international coalition beginning in January 1991, drastically reduced economic activity. The regime exacerbated shortages by supporting large military and internal security forces and by allocating resources to key supporters of the Ba'ath Party. The implementation of the UN's Oil for Food program in December 1996 helped improve economic conditions. For the first six six-month phases of the program, Iraq was allowed to export increasing amounts of oil in exchange for food, medicine, and other humanitarian goods. In December 1999, the UN Security Council authorized Iraq to export as much oil as required to meet humanitarian needs. Per capita food imports increased substantially, while medical supplies and health care services steadily improved, though per capita economic production and living standards were still well below their prewar level.

Iraq changed its oil reserve currency from the U.S. dollar to the euro in 2000. However, 28% of Iraq's export revenues under the program were deducted to meet UN Compensation Fund and UN administrative expenses. The drop in GDP in 2001 was largely the result of the global economic slowdown and lower oil prices.

The removal of sanctions on 24 May 2003 and rising oil prices in the mid-to-late 2000s led to a doubling in oil production from a low of 1.3 mbpd during the turbulence of 2003 to a high of 2.6 mbpd in 2011. Furthermore, reduced inflation and violence since 2007 have translated to real increases in living standards for Iraqis.

One of the key economic challenges was Iraq's immense foreign debt, estimated at $125 billion. Although some of this debt was derived from normal export contracts that Iraq had failed to pay for, some was a result of military and financial support during Iraq's war with Iran.

The Jubilee Iraq campaign argued that much of these debts were odious (illegitimate). However, as the concept of odious debt is not accepted , trying to deal with the debt on those terms would have embroiled Iraq in legal disputes for years. Iraq decided to deal with its debt more pragmatically and approached the Paris Club of official creditors.

In a December 2006 "Newsweek International" article, a study by Global Insight in London was reported to show "that Civil war or not, Iraq has an economy, and—mother of all surprises—it's doing remarkably well. Real estate is booming. Construction, retail and wholesale trade sectors are healthy, too, according to [the report]. The U.S. Chamber of Commerce reports 34,000 registered companies in Iraq, up from 8,000 three years ago. Sales of secondhand cars, televisions and mobile phones have all risen sharply. Estimates vary, but one from Global Insight puts GDP growth at 17 percent last year and projects 13 percent for 2006. The World Bank has it lower: at 4 percent this year. But, given all the attention paid to deteriorating security, the startling fact is that Iraq is growing at all."

Traditionally, most of Iraq's manufacturing activity has been closely connected to the oil industry. The major industries in that category have been petroleum refining and the manufacture of chemicals and fertilizers. Before 2003, diversification was hindered by limitations on privatization and the effects of the international sanctions of the 1990s. Since 2003, security problems have blocked efforts to establish new enterprises. The construction industry is an exception; in 2000 cement was the only major industrial product not based on hydrocarbons. The construction industry has profited from the need to rebuild after Iraq's several wars. In the 1990s, the industry benefited from government funding of extensive infrastructure and housing projects and elaborate palace complexes.

Agriculture contributes just 3.3% to the gross national product and employs a fifth of the labor.

Historically, 50 to 60 percent of Iraq's arable land has been under cultivation. Because of ethnic politics, valuable farmland in Kurdish territory has not contributed to the national economy, and inconsistent agricultural policies under Saddam Hussein discouraged domestic market production. Despite its abundant land and water resources, Iraq is a net food importer. Under the UN Oil for Food program, Iraq imported large quantities of grains, meat, poultry, and dairy products. The government abolished its farm collectivization program in 1981, allowing a greater role for private enterprise in agriculture.

Iraqi agriculture suffered substantial physical disruption from the Gulf War, and economic disruption from sanctions imposed by the United Nations (August 1990). Sanctions curtailed imports by cutting off Iraq's petroleum exports, and embargoing those agricultural production inputs deemed to have potential military applications. The Iraqi government responded by monopolizing grain and oilseed marketing, imposing production quotas, and instituting a Public Distribution System for basic foodstuffs. By mid-1991 the government supplied a "basket" of foodstuffs that provided about one-third of the caloric daily requirement, and cost consumers about five percent of its market value. With subsidies for agricultural inputs diminished, the prices that the government paid to farmers failed to cover their costs. The implicit tax on agricultural production was estimated to reach 20 to 35 percent by the mid-1990s. In October 1991 the Baghdad regime had withdrawn personnel from the northern region controlled by two Kurdish parties. Kurdistan Region was described as "... a market economy essentially left alone by a very weak governing structure, but heavily influenced by substantial international humanitarian aid flows."

Under an "Oil for Food Program" negotiated with the United Nations, in December 1996 Iraq started exporting petroleum, and used the proceeds to start importing foodstuffs three months later. Grain imports averaged $828 million in the years 1997-2001, an increase of over 180 percent from the previous five-year period. Due to foreign competition, Iraqi production declined (29 percent for wheat, 31 percent for barley, and 52 percent for maize). Because the government had generally neglected the production of forage crops, fruits, vegetables, and livestock other than poultry, those sectors had remained more traditional and market-based, and less buffeted by international affairs. Nevertheless, severe drought, an outbreak of screwworm, and an epizootic of foot-and-mouth disease devastated production during this period. As the Oil for Food Program expanded to cover more agricultural inputs and machinery, the productivity of Iraqi agriculture stabilized around 2002.

Following the invasion led by the United States in March 2003, with incomes of many Iraqis devastated, the market for foodstuffs shrunk. Seeking to re-orient Iraq's economy toward private ownership and international competitiveness, the United States saw the dismantling of the Public Distribution System as essential for a market-driven agriculture. Because of the great reliance of most Iraqis on government-subsidized food, this goal was never realized. Increased productivity became the focus of much of the US-funded agricultural reconstruction program. Many of these projects were undertaken by the Agricultural Reconstruction and Development Iraq (ARDI) program run by Development Alternatives, Inc. (DAI) of Bethesda, Maryland, under a contract with USAID signed on 15 October 2003. While ARDI participated in limited ways, the restoration of Iraq's irrigation systems was mostly funded under USAID's contract with Bechtel International.

ARDI conducted demonstration trials of improved practices and varieties of many crops: winter cereals (wheat and barley), summer cereals (rice, maize, and sorghum), potatoes, and tomatoes. Feed supplements and veterinary treatments were demonstrated to increase ovulation, conception, and birth weights of livestock. Surveys were conducted of poultry growers and apple farmers. Nurseries were established for date palms and grapes. College buildings and farm tractors were rebuilt. ARDI had projects promoting trade associations and producers' co-ops, but also supported extension as an appropriate governmental function. The contract eventually cost over $100 million and lasted through December 2006. Under its Community Action Program, USAID also funded an analysis of markets for sheep and wool. It awarded a contract to the University of Hawaii to revitalize higher education in agriculture. It awarded a contract for $120 million to the Louis Berger Group to promote Iraq's private sector, including agriculture.

Starting in 2006, agricultural reconstruction was also conducted by Provincial Reconstruction Teams within the occupying military forces. Intended to promote goodwill and sap the insurgency, "PRTs" allowed military commanders to identify local needs and, with few bureaucratic hurdles, to dispense up to $500,000. Civilians from many agencies within the U.S. Department of Agriculture, as well as USAID, served tours on PRTs. Some participants criticized the absence of a national agricultural strategy, or clear direction on the design of projects. Others complained that projects emphasized "American-style, 21st-century agricultural technologies and methodologies..." that were inappropriate for Iraq.

Agricultural production has not rebounded noticeably from the reconstruction program. According to the Food and Agriculture Organization (FAO), between 2002 and 2013, production of wheat increased 11 percent and milled rice 8 percent, but barley had decreased 13 percent and maize 40 percent. Scaled in "international dollars" (2004-2006 base equaling 100) Iraq's per capita food production was 135 in 2002, 96 in 2007, and 94 in 2012. The agricultural sector shed workers. In those same years, production per worker was 117, 106, and 130, respectively.

The international Oil-for-Food program (1997–2003) further reduced farm production by supplying artificially priced foreign foodstuffs. The military action of 2003 did little damage to Iraqi agriculture; because of favorable weather conditions, in that year grain production was 22 percent higher than in 2002. Although growth continued in 2004, experts predicted that Iraq will be an importer of agricultural products for the foreseeable future. Long-term plans call for investment in agricultural machinery and materials and more prolific crop varieties—improvements that did not reach Iraq's farmers under the Hussein regime. In 2004 the main agricultural crops were wheat, barley, corn, rice, vegetables, dates, and cotton, and the main livestock outputs were cattle and sheep.

The Agricultural Cooperative Bank, capitalized at nearly 1 G$ - by 1984, targets its low-interest, low-collateral loans to private farmers for mechanization, poultry projects, and orchard development. Large modern cattle, dairy, and poultry farms are under construction. Obstacles to agricultural development include labour shortages, inadequate management and maintenance, salinization, urban migration, and dislocations resulting from previous land reform and collectivization programs.

In 2011, an agricultural adviser to the Iraqi government, Layth Mahdi, summarized the forced United States agricultural reconstruction:Prior to 2003, Iraq had imported about 30 percent of its food needs annually. The decline in agricultural production after this period, created the need for importing 90 percent of the food at a cost estimated at more than $12 billion annually. Due to the sudden shift in the agricultural policy from subsidized assistance to an immediate shift to a free market policy, the outcomes led to a decline in production. The observed outcome resulted in many farmers abandoning the land and agriculture. The impact on natural resources results in an exploited and degraded environment leaving the land destitute and the people impoverished, unemployed [and] experiencing a sense of losing their human dignity.Importation of foreign workers and increased entry of women into traditionally male labour roles have helped compensate for agricultural and industrial labour shortages exacerbated by the war. A disastrous attempt to drain the southern marshes and introduce irrigated farming to this region merely destroyed a natural food producing area, while concentration of salts and minerals in the soil due to the draining left the land unsuitable for agriculture.

In the Mada'in Qada region east of Baghdad, hundreds of small farmers united to form the Green Mada'in Association for Agricultural Development, an agricultural cooperative that provides its members with drip irrigation and greenhouses as well as access to credit.

Throughout the twentieth century, human exploration, shifting agriculture, forest fires, and uncontrolled grazing denuded large areas of Iraq's natural forests, which in 2005 were almost exclusively confined to the northeastern highlands. Most of the trees found in that region are not suitable for lumbering. In 2002 a total of 112,000 cubic meters of wood were harvested, nearly half of which was used as fuel.

Despite its many rivers, Iraq's fishing industry has remained relatively small and based largely on marine species in the Persian Gulf. In 2001 the catch was 22,800 tons.

Aside from hydrocarbons, Iraq's mining industry has been confined to extraction of relatively small amounts of phosphates (at Akashat), salt, and sulfur (near Mosul). Since a productive period in the 1970s, the mining industry has been hampered by the Iran–Iraq War (1980–88), the sanctions of the 1990s, and the economic collapse of 2003.

Iraq is one of the most oil-rich countries in the world. The country holding the fifth largest proven crude oil reserves, totaling 147.22 billion barrels at the end of 2017. Most of this oil—4 million barrels per day out of 4.3 million barrels produced daily—is exported, making Iraq the third-largest exporter of oil. Despite its ongoing civil war, Iraq was able to increase oil production during 2015 and 2016, with production dipping by 3.5 percent in 2017 due to conflict with the Kurdistan Regional Government and OPEC production limits. By world standards, production costs for Iraqi oil are relatively low. However, four wars—the 1980–1988 Iraq-Iran War, 1991 Gulf War, the 2003-2011 War in Iraq, and the civil war—and the 1991–2003 UN sanctions have left the industry's infrastructure in poor condition, and the de facto independence of oil-rich Kurdistan Region have limited production.

In the 1970s, Iraq produced over 3.5 million barrels of oil per day. Production began to fall during the Iran-Iraq War, before plummeting 85 percent after the 1991 invasion of Kuwait. UN sanctions prevented the export of oil until 1996, and then allowed exports only in exchange for humanitarian aid in the Oil-for-Food Programme.

The 2003 lifting of sanctions enabled production—and exports—to restart. Production has since recovered to pre-Gulf War levels, and most of Iraq's oil infrastructure has been repaired, in spite of persistent sabotage by the Islamic State (ISIL) and others. In 2004 Iraq had eight oil refineries, the largest of which were at Baiji, Basra, and Daura.

Despite its oil wealth, sabotage and technical problems at refineries have forced Iraq to import petroleum, other refined oil products, and electricity from neighboring countries, especially Iran. In 2004, for example, Iraq spent $60 million per month for imported gasoline. Sabotage
In late 2004 and early 2005, regular sabotage of plants and pipelines reduced export and domestic distribution of oil, particularly to Baghdad. Nationwide fuel shortages and power outages resulted. Persistent ISIL sabotage of pipelines, power plants and power lines, and theft of oil and electricity have also contributed to the July 2018 protests in southern Iraq.

In 2004 plans called for increased domestic utilization of natural gas to replace oil and for use in the petrochemical industry. However, because most of Iraq's gas output is associated with oil, output growth depends on developments in the oil industry.

Half of Iraq's power plants were destroyed in the Persian Gulf War of 1991, and full recovery never occurred. In mid-2004, Iraq had an estimated 5,000 megawatts of power-generating capacity, compared with 7,500 megawatts of demand. At that time, the transmission system included 17,700 kilometers of line. In 2004 plans called for construction of two new power plants and restoration of existing plants and transmission lines to ease the blackouts and economic hardship caused by this shortfall, but sabotage and looting kept capacity below 6,000 megawatts. The ongoing civil war, sabotage of transmission lines, and government corruption caused the electricity shortage to worsen: by 2010 demand outstripped supply by 6000 megawatts.

Oil continues to dominate Iraq's economy. , oil is responsible for over 65 percent of GDP, 90 percent of government revenue. Petroleum constitutes 94% of Iraq's exports with a value of $59.73 billion in 2017. The central government hopes to diversify the economy away from oil, and has had some success: non-oil GDP growth, which was below the regional average from 2014-2016, pushed above the average in 2017. Despite this, the percent of government spending going to non-oil investment has continued to decline since 2013 and now stands at only 34 percent.

Between June 2009 and February 2010 the Iraqi Oil Ministry tendered for the award of Service Contracts to develop Iraq's existing oil fields. The results of the tender, which were broadcast live on Iraqi television, are as follows for all major fields awarded but excluding the Kurdistan Region where Production Sharing Contracts have been awarded that are currently being disputed by the Baghdad government. All contracts are awaiting final ratification of the awards by the Iraqi government. Company shares are subject to change as a result of commercial negotiations between parties.

"Notes:"
" 1. Field shares are as a % of the total. The Iraq state retains a 25% share in all fields for which Service Contracts have been awarded."
" 2. Production Increase Share is the millions bbls per day that will attract the Service Fee for the company."
" 3. Gross revenue at plateau is the total payment each company will receive upon reaching their declared target plateau production rate (in between 5 and 8 years depending on field), before deduction of any operating costs but in addition to recovery of all development costs as billions of US$ per annum. The total gross revenue for all companies, after recovery of capital costs, is at plateau production of an additional 9.4 mb/d, 4.34 bn US per annum at a $70 bbl oil price. The 2010 Iraq govt budget is $60 billion. $300 billion is approximately $10,000 per annum for each Iraqi citizen."

In summary the shares by region in the increased production are:

Iraq's financial services have been the subject of post-Hussein reforms. The 17 private banks established during the 1990s were limited to domestic transactions and attracted few private depositors. Those banks and two main state banks were badly damaged by the international embargo of the 1990s. To further privatize and expand the system, in 2003 the Coalition Provisional Authority removed restrictions on international bank transactions and freed the Central Bank of Iraq (CBI) from government control. In its first year of independent operation, the CBI received credit for limiting Iraq's inflation. In 2004 three foreign banks received licenses to do business in Iraq.

Because of the danger posed by Iraq's ongoing insurgency, the security industry has been a uniquely prosperous part of the services sector. Often run by former US military personnel, in 2005 at least 26 companies offered personal and institutional protection, surveillance, and other forms of security.

In the early post-Hussein period, a freewheeling retail trade in all types of commodities straddled the line between legitimate and illegitimate commerce, taking advantage of the lack of income tax and import controls.

The Iraq tourism industry, which in peaceful times has profited from Iraq's many places of cultural interest (earning US$14 million in 2001), has been dormant since 2003. Despite conditions, in 2005 the Iraqi Tourism Board maintained a staff of 2,500 and 14 regional offices. Between 2009 and 2010, 165 tourists from 16 different countries entered Iraq to visit historic sites; as of January 2011, a U.S. State Department grant provided $2 million to help preserve Babylon, supporting the re-opening of one of the site's two museums.

During 2003-8, mobile phone subscriptions had expanded over hundred-fold to 10 million nationwide, according to the Brookings Institution.

In 2002 Iraq's labor force was estimated at 6.8 million people.

In 1996 some 66.4 percent of the labor force worked in services, 17.5 percent in industry, and 16.1 percent in agriculture. 2004 estimates of Iraq's unemployment ranged from 30 percent to 60 percent.

The CPA has referred to a 25% unemployment rate, the Iraqi Ministry of Planning mentioned a 30% unemployment rate, whereas the Iraqi Ministry of Social Affairs claims it to be 48%. Other sources are claiming a 20% unemployment rate and a probably 60% under-employment rate. The actual figure is problematic because of high participation in black-market activities and poor security conditions in many populous areas. In central Iraq, security concerns discouraged the hiring of new workers and the resumption of regular work schedules. At the same time, the return of Iraqis from other countries increased the number of job seekers. In late 2004, most legitimate jobs were in the government, the army, the oil industry, and security-related enterprises. Under Saddam Hussein Hussein, many of the highest-paid workers were employed by the greatly overstaffed government, whose overthrow disrupted the input of these people to the economy. In 2004 the U.S. Agency for International Development committed US$1 billion for a worker-training program. In early 2004, the minimum wage was US$72 per month.

Iraq is a founding member of OPEC. Petroleum constitutes 99,7% of Iraq's exports with a value of $43,8 billion in 2016.

From the 1990s until 2003, the international trade embargo restricted Iraq's export activity almost exclusively to oil. In 2003 oil accounted for about US$7.4 billion of Iraq's total US$7.6 billion of export value, and statistics for earlier years showed similar proportions. After the end of the trade embargo in 2003 expanded the range of exports, oil continued to occupy the dominant position: in 2004 Iraq's export income doubled (to US$16.5 billion), but oil accounted for all but US$340 million (2 percent) of the total. In late 2004, sabotage significantly reduced oil output, and experts forecast that output, hence exports, would be below capacity in 2005 as well. In 2004 the chief export markets were the United States (which accounted for nearly half), Italy, France, Jordan, Canada, and the Netherlands. In 2004 the value of Iraq's imports was US$21.7 billion, incurring a trade deficit of about US$5.2 billion. In 2003 the main sources of Iraq's imports were Turkey, Jordan, Vietnam, the United States, Germany, and Britain. Because of Iraq's inactive manufacturing sector, the range of imports was quite large, including food, fuels, medicines, and manufactured goods. By 2010, exports rose to US$50.8 billion and imports rose to US$45.2 billion. Chief 2009 export partners were: U.S., India, Italy, South Korea, Taiwan, China, Netherlands, and Japan. Chief 2009 import partners were: Turkey, Syria, U.S., China, Jordan, Italy, and Germany.



</doc>
<doc id="14670" url="https://en.wikipedia.org/wiki?curid=14670" title="Transport in Iraq">
Transport in Iraq

Transport in Iraq consists of railways, highways, waterways, pipelines, ports and harbors, marines and airports.

"total:"
2,272 km
<br>"standard gauge:"
2,272 km 

For more than two decades there have been plans for building a metro system in Baghdad. It is possible that part of the tunnels have been built, but that they are now used for military, shelter, hiding, and escaping purposes. U.N. inspectors have heard of the tunnels for years, but have not found their entrances. map In November, 2008, an overground service dubbed the Baghdad Metro began service. Local government in Baghdad is arranging feasibility studies for the construction of two new underground lines

A 37 km monorail is planned in Najaf, which would link three Shi'ite holy sites.

The first Iraqi Republic Railways train to Basra since the overthrow of Saddam Hussein's regime arrived on 26 April 2003. British troops hope to use the 68 km long railway to transport much-needed aid supplies from the port town of Umm Qasr to Basra.

In June 2011, it was announced that planning had begun for a new high-speed rail line between Baghdad and Basra, with a memorandum of understanding with Alstom having been signed.


All adjacent countries generally use , but may vary in couplings. Neighbours with electrified railways – Turkey and Iran – both use the world standard 25 kVAC


An overland trans-desert bus service between Beirut, Haifa, Damascus and Baghdad was established by the "Nairn Transport Company" of Damascus in 1923. 

"total:"
44,900 km 
<br>"paved:"
37,851 km,
<br>"unpaved:"
7,049 km (2002)

5,729 km (Euphrates River (2,815 km), Tigris River 1,899 km, Third River (565 km)); Shatt al Arab is usually navigable by maritime traffic for about 130 km. The channel has been dredged to 3 m and is in use. The Tigris and Euphrates Rivers have navigable sections for shallow-draft watercraft; the Shatt al Basrah canal was navigable by shallow-draft craft before closing in 1991 because of the Gulf War.

crude oil 5,432 km; natural gas 2,455 km; refined products 1,637 km; liquid petroleum gas 913 km


"total:"
32 ships (with a volume of or over) totaling /
<br>"ships by type:"
cargo ship 14, passenger ship 1, passenger/cargo 1, petroleum tanker 13, refrigerated cargo 1, roll-on/roll-off ship 2 (1999 est.)

Iraq has about 104 airports as of 2012. Major airports include:

20 (2012)



</doc>
<doc id="14672" url="https://en.wikipedia.org/wiki?curid=14672" title="Foreign relations of Iraq">
Foreign relations of Iraq

Since 1980, the foreign relations of Iraq were influenced by a number of controversial decisions by the Saddam Hussein administration. Hussein had good relations with the Soviet Union and a number of western countries such as France and Germany, who provided him with advanced weapons systems. He also developed a tenuous relation with the United States, who supported him during the Iran–Iraq War. However, the Invasion of Kuwait that triggered the Gulf War brutally changed Iraq's relations with the Arab World and the West. Egypt, Saudi Arabia, Syria and others were among the countries that supported Kuwait in the UN coalition. After the Hussein administration was toppled by the 2003 invasion of Iraq, the governments that succeeded it have now tried to establish relations with various nations.

In September 2005, a joint political declaration between the European Union and Iraq was signed which forms the basis of regular political dialogue. A Trade and Cooperation Agreement between the EU and Iraq is in the process of being negotiated and will probably be concluded during 2008.

July 2005 saw the introduction of EUJUST LEX, the European Union's rule of law operation intended to train Iraqi police and legal officials in human rights along with other issues. Over 1,400 Iraqis have already taken part in training courses.

Iraq belongs to the following international organizations: Arab Fund for Economic and Social Development, Arab League, Arab Monetary Fund, Council of Arab Economic Unity, Customs Cooperation Council, Economic and Social Commission for Western Asia, G-77, International Atomic Energy Agency, International Monetary Fund, International Maritime Organization, Interpol, International Organization for Standardization, International Telecommunication Union, Non-Aligned Movement, Organization of Petroleum Exporting Countries, Organization of Arab Petroleum Exporting Countries, Organisation of Islamic Cooperation, United Nations, Universal Postal Union, World Health Organization and World Bank.

Iraq's relations with other countries and with international organizations are supervised by the Ministry of Foreign Affairs. In 1988 the minister of foreign affairs was Tariq Aziz, who was an influential leader of the Ba'ath Party and had served in that post since 1983. Aziz, Saddam Hussein, and the other members of the Revolutionary Command Council (RCC) formulated Iraq's foreign policy, and the Ministry of Foreign Affairs bureaucracy implemented RCC directives. The Baath maintained control over the Ministry of Foreign Affairs and over all Iraqi diplomatic missions abroad.

Since the overthrow of Saddam Hussein in 2003, Hoshyar Zebari was first appointed Minister of Foreign Affairs in the Iraqi Governing Council in Baghdad on 3 September 2003. On 28 June 2004, he was reappointed as Minister of Foreign Affairs by the Iraqi Interim Government, under Prime Minister Ayad Allawi. On 3 May 2005 he was sworn in as Minister of Foreign Affairs by the Iraqi Transitional Government, under Prime Minister Ibrahim al-Jaafari. On 20 May 2006, he was delegated in for the fourth consecutive time as Foreign Minister in the government of Nouri Al-Maliki.

Iran and Iraq restored diplomatic relations in 1990 but are still trying to work out written agreements settling outstanding disputes from their eight-year war concerning border demarcation, prisoners-of-war, and freedom of navigation and sovereignty over the Shatt al-Arab waterway; in November 1994, Iraq formally accepted the United Nations-demarcated border with Kuwait which had been spelled out in Security Council Resolutions 687 (1991), 773 (1992), and 883 (1993); this formally ends earlier claims to Kuwait and to Bubiyan and Warbah islands although the government continues periodic rhetorical challenges; dispute over water development plans by Turkey for the Tigris and Euphrates rivers.




</doc>
<doc id="14676" url="https://en.wikipedia.org/wiki?curid=14676" title="Demographics of the Republic of Ireland">
Demographics of the Republic of Ireland

The Republic of Ireland had a population of 4,761,865 at the 2016 census.

The island of Ireland, throughout most of its history, had a small population, comparable to that of other regions of similar area in Europe. In the 18th and early 19th centuries, Ireland experienced a major population boom as a result of the Agricultural and Industrial Revolutions. In the 50-year period 1790-1840, the population of the island doubled from 4 million to 8 million. At its peak, Ireland's population density was similar to that of England and continental Europe.

This changed dramatically with the Great Famine of the mid-19th century, which led to mass starvation and consequent mass emigration. In the area covering the present day Republic of Ireland, the population reached about 6.5 million in the mid 1840s. Ten years later it was down to 5 million. The population continued a slow decline well into the 20th century, with the Republic recording a low of 2.8 million in the 1961 census.

During the 1960s, the population started to grow once more, although slowly as emigration was still common. In the 1990s the country entered a period of rapid economic growth as a result of the Celtic Tiger Irish economic boom. The Republic started to receive Immigration from that had never previously happened. Many former Irish emigrants returned home, and the Republic of Ireland became an attractive destination for immigrants, from other member states EU such as Central Europe, but also from outside the EU such as Africa, Asia and elsewhere. With the 2008 onset of the Irish economic and banking crisis, the state's economy suffered, and the Republic of Ireland has once again been experiencing net emigration of its citizens, but immigration remains high.

In November 2013, Eurostat reported that the republic had the largest net emigration rate of any member state, at 7.6 emigrants per 1,000 population. However, it has the youngest population of any European Union member state and its population size is predicted to grow for many decades, in contrast with the declining population predicted for most European countries. A report published in 2008 predicted that the population would reach 6.7 million by 2060. The Republic has also been experiencing a baby boom, with increasing birth rates and overall fertility rates. Despite this, the total fertility rate is still below replacement depending on when the measurement is taken. The Irish fertility rate is still the highest of any European country. This increase is significantly fuelled by non-Irish immigration – in 2009, a quarter of all children born in the Republic were born to mothers who had immigrated from other countries.

Gaelic culture and language forms an important part of the Irish national identity.

The Irish Travellers are an indigenous minority ethnic group, formally recognised by the Irish State since 1 March 2017.

In 2008, Ireland had the highest birth rate (18.1 per 1,000), lowest death rate (6.1 per 1,000) and highest net-migration rate (14.1 per 1,000) in the entire European Union – and the largest population growth rate (4.4%) in the 27-member bloc as a result.

Ireland contains several immigrant communities, especially in Dublin. The most common foreign nationalities include Polish, British, Lithuanian and Latvian

There is only genetic evidence for pre-Celtic migration into Ireland. The Irish people may therefore be described as strongly influenced by Celtic language and traditions.

The total fertility rate is the number of children born per woman. It is based on fairly good data for the entire period. Sources: Our World In Data and Gapminder Foundation.


Of the 59,796 births in 2019, there were 46,036 babies (77.0%) born to mothers of Irish nationality compared to 47,110 (77.2%) in 2018. There were 10.4% of births to mothers of EU 16 to EU 28 nationality, 2.1% of mothers were of UK nationality, and 2.0% were of EU 15 nationality (excluding Ireland and the UK). Mothers of nationalities other than Ireland, UK and the EU accounted for 8.4% of total births registered. There were 29 mothers where the nationality was not stated.

Source: "UN World Population Prospects"

Demographic statistics according to the World Population Review in 2019.


The following demographic statistics are from the Republic of Ireland's Central Statistics Office (CSO), Eurostat and the CIA World Factbook.


Irish 82.2%, Irish travelers 0.7%, other white 9.5%, Asian 2.1%, black 1.4%, other 1.5%, unspecified 2.6% (2016 est.)












Irish, with Norse (Scandinavian), Norman, English, French, Scottish, and Welsh, Ulster-Scots and various immigrant populations – the largest immigrant groups, with over 10,000 people, are the British, Croats, Poles, Americans, Lithuanians, Latvians, Germans, Nigerians, Indians, Pakistanis and Chinese.

Ethnic backgrounds: Irish: 82.2%, Irish Traveller: 0.7%, Other White: 9.5% (total White: 92.4%), Asian: 2.1%, Black: 1.3%, Other: 1.5%, Not Stated: 2.6% (2016)

The Republic of Ireland is a predominantly Christian country. The majority are Roman Catholic. The number of people who declare themselves Catholic has been declining in recent years. Irreligion has almost doubled since 2011 with 9.8% declaring 'No Religion' in 2016, overtaking Protestantism as the second largest group in the state. The various Protestant and other Christian faiths represent 5.6. Immigration has brought other faiths, Islam at 1.3%, other religions 2.4% and 2.6% gave no answer.

English is the most commonly used language, with 84% of the population calling it their mother tongue. Irish is the first official language of the state, with 11% calling it their mother tongue. Irish is the main language of the Gaeltacht regions, where 96,628 people live. The main sign language used is Irish Sign Language.




Groups:



</doc>
<doc id="14677" url="https://en.wikipedia.org/wiki?curid=14677" title="Politics of the Republic of Ireland">
Politics of the Republic of Ireland

Ireland is a parliamentary, representative democratic republic and a member state of the European Union. While the head of state is the popularly elected President of Ireland, it is a largely ceremonial position, with real political power being vested in the Taoiseach, who is nominated by the Dáil and is the head of the government.

Executive power is exercised by the government, which consists of no more than 15 cabinet ministers, inclusive of the Taoiseach and Tánaiste (the deputy leader of government). Legislative power is vested in the Oireachtas, the bicameral national parliament, which consists of Dáil Éireann, Seanad Éireann and the President of Ireland. The judiciary is independent of the executive and the legislature. The head of the judiciary is the Chief Justice, who presides over the Supreme Court.

Ireland has a multi-party system. Fianna Fáil and Fine Gael, historically opposed and competing entities, which both occupy the traditional centre ground and trace their roots to the opposing sides of the Irish Civil War. All governments since 1932 have been led by one or the other party, with Fianna Fáil having had sufficient support at many elections to govern alone. Fluctuations in seat levels allowed changes in governments through different coalitions. From 1932 to 2011, the parties were stable in their support, with Fianna Fáil the largest at each election, Fine Gael the second largest, and on all but two occasions, the Labour Party the third party. The last three elections, however, have each had more volatile results. At the 2011 election, the largest parties in order were Fine Gael, Labour and Fianna Fáil; at the 2016 election, the largest parties in order were Fine Gael, Fianna Fáil and Sinn Féin; and at the 2020 election, the largest parties were Fianna Fáil first in seats (second in votes), Sinn Féin second in seats (first in votes), and then Fine Gael.

The state operates under the Constitution of Ireland () which was adopted in 1937 by means of a plebiscite. The constitution falls within the liberal democratic tradition. It defines the organs of government and guarantees certain fundamental rights. The Constitution can only be amended by means of a referendum. Important constitutional referendums have concerned issues such as abortion, the status of the Catholic Church, divorce, European Union and same-sex marriage.

The head of state is the President of Ireland. In keeping with the state's parliamentary system of government, the President exercises a mainly ceremonial role but does possess certain specific powers. The presidency is open to all Irish citizens who are at least 35. They are directly elected by secret ballot under the alternative vote. A candidate may be nominated for election as president by no fewer than 20 members of the Oireachtas or by four or more of Ireland's 31 County and City Councils. A retiring President may nominate themselves as a candidate for re-election. If only one valid candidate is nominated for election, for example if there is consensus among the political parties to nominate a single candidate, it is unnecessary to proceed to a ballot and that candidate is deemed elected. The President is elected to a seven-year term of office and no person may serve more than two terms.

In carrying out certain of their constitutional functions, the President is aided by the Council of State. There is no Vice-President in Ireland. If for any reason the President is unable to carry out their functions, or if the Office of President is vacant, the duties of the President are carried out by the Presidential Commission.

The President may not veto bills passed by the Oireachtas but may, after consultation with the Council of State, refer them to the Supreme Court of Ireland for a ruling on whether they comply with the constitution. The President may refuse a request of the Taoiseach for a dissolution of Dáil Éireann, although no request for a dissolution had been refused.

Article 15 of the Constitution of Ireland established the Oireachtas as the national parliament of Ireland. The Oireachtas consists of the President of Ireland and two elected houses: Dáil Éireann (the House of Representatives) and Seanad Éireann (the Senate). As the Oireachtas also consists of the President, the title of the two law-making houses is the Houses of the Oireachtas. The Dáil is by far the dominant house of the legislature.

Members of the Dáil are directly elected at least once in every five years under the single transferable vote form of proportional representation from multi-seat constituencies. Membership of the house is open to all Irish citizens who are at least 21 and permanently resident in the State. The electorate consists of all Irish and British citizens resident in Ireland over the age of 18. Members of the Dáil are known as Teachta Dála or TDs. Currently there are 160 TDs, of which one, the Ceann Comhairle (Chairman), is automatically returned at an election. The Taoiseach, Tánaiste and the Minister for Finance must be members of the Dáil. The Dáil is the only House which can introduce and amend money bills (i.e. financial and tax legislation). Since the early 1980s, no single party has had a majority in Dáil Éireann, so that coalition governments have been the norm.

The Seanad is a largely advisory body. It consists of sixty members called Senators. An election for the Seanad must take place no later than 90 days after a general election for the members of the Dáil. Eleven Senators are nominated by the Taoiseach while a further six are elected by certain national universities. The remaining 43 are elected from special vocational panels of candidates, the electorate for which consists of the 60 members of the outgoing Senate, the 160 TDs of the incoming Dáil and the 883 elected members of 5 city and 29 county councils. The Seanad has the power to delay legislative proposals and is allowed 90 days to consider and amend bills sent to it by the Dáil (excluding money bills). The Senate is only allowed 21 days to consider money bills sent to it by the Dáil. The Senate cannot amend money bills but can make recommendations to the Dáil on such bills. No more than two members of a government may be members of the Seanad, and only twice since 1937 have members of the Seanad been appointed to government.

Executive authority is exercised by a cabinet known simply as "the Government". Article 28 of the Constitution states that the Government may consist of no less than seven and no more than fifteen members, namely the Taoiseach (prime minister), the Tánaiste (deputy prime minister) and up to thirteen other ministers. The Minister for Finance is the only other position named in the Constitution. The Taoiseach is appointed by the President, after being nominated by Dáil Éireann. The remaining ministers are nominated by the Taoiseach and appointed by the President following their approval by the Dáil. The Government must enjoy the confidence of Dáil Éireann and, in the event that they cease to enjoy the support of the lower house, the Taoiseach must either resign or request the President to dissolve the Dáil, in which case a general election follows.

Ireland is a common law jurisdiction. The judiciary consists of the Supreme Court, the Court of Appeal and the High Court established by the Constiution and other lower courts established by statute law. Judges are appointed by the President after being nominated by the Government and can be removed from office only for misbehaviour or incapacity, and then only by resolution of both houses of the Oireachtas. The final court of appeal is the Supreme Court, which consists of the Chief Justice, nine ordinary judges and, the Presidents of the Court of Appeal and the High Court. The Supreme Court rarely sits as a full bench and normally hears cases in chambers of three, five or seven judges.

The courts established by the constitution have the power of judicial review and may declare to be invalid both laws and acts of the state which are repugnant to the constitution.

The Government, through the civil and public services and state-sponsored bodies, is a significant employer in the state; these three sectors are often called the "public sector". Management of these various bodies vary, for instance in the civil service there will be clearly defined routes and patterns whilst among public services a sponsoring minister or the Minister for Finance may appoint a board or commission. Commercial activities, where the state involves itself, are typically through the state-sponsored bodies which are usually organised in a similar fashion to private companies.

A 2005 report on public sector employment, showed that in June 2005 the numbers employed in the public sector stood at 350,100; of these by sector they were 38,700 (civil service), 254,100 (public service) and 57,300 (state-sponsored). The total workforce of the state was 1,857,400 that year, thus the public sector represents approximately 20% of the total workforce.

The civil service of Ireland consists of two broad components, the "Civil Service of the Government" and the "Civil Service of the State". Whilst these two components are largely theoretical, they do have some fundamental operational differences. The civil service is expected to maintain the political impartiality in its work, and some sections of it are entirely independent of Government decision making.

The public service is a relatively broad term and is not clearly defined and sometimes is taken to include the civil service. The public service proper consists of Government agencies and bodies which provide services on behalf of the Government but are not the core civil service. For instance local authorities, Education and Training Boards and Garda Síochána are considered to be public services.

Article 28A of the constitution of Ireland provides a constitutional basis for local government. The Oireachtas is empowered to establish the number, size and powers of local authorities by law. Under Article 28A, members of local authorities must be directly elected by voters at least once every five years.

Local government in Ireland is governed by a series of Local Government Acts, beginning with the Local Government (Ireland) Act 1898. The most significant of these is the Local Government Act 2001, which established a two-tier structure of local government. The Local Government Reform Act 2014 abolished the bottom tier, the town councils, leaving 31 local authorities. There are 26 County Councils (County Dublin been divided into three council areas), 3 City Councils (Dublin, Cork and Galway), and 2 City and County Councils (Limerick and Waterford).

A number of political parties are represented in the Dáil and coalition governments are common. The Irish electoral system has been historically characterised as a two and a half party system, with two large catch-all parties, this being the centre-right Fine Gael and the centrist Fianna Fáil, dominating, and the “half-party,” being Labour. This changed after the 2011 general election, following the large drop in support for Fianna Fáil and the rise in support for other parties. Ireland's political landscape changed dramatically after the 2020 general election, when Sinn Féin made gains to become the joint-largest party in the Dáil, making Ireland a three party system.

Fianna Fáil, a traditionally Irish republican party founded in 1927 by Éamon de Valera, is the joint-largest party in the Dáil and considered centrist in Irish politics. It first formed a government on the basis of a populist programme of land redistribution and national preference in trade and republican populism remains a key part of its appeal. It has formed government seven times since Ireland gained independence: 1932–1948, 1951–1954, 1957–1973, 1977–1981, 1982, 1987–1994, and 1997–2011. Fianna Fáil was the largest party in the Dáil from 1932 to 2011. It lost a huge amount of support in the 2011 general election, going from 71 to 20 seats, its lowest ever. Its loss in support was mainly due to its handling of the 2008 economic recession. It has since regained some support, but is yet to recover to its pre-2011 levels.

The other joint-largest party is Sinn Féin, established in its current form in 1970. The original Sinn Féin played a huge role in the Irish War of Independence and the First Dáil. Fine Gael and Fianna Fáil trace their origins to that party. The current-day party has been historically linked to the Provisional IRA. The party is a Republican party which takes a more left wing stance on economics and social policy than the Labour Party. Sinn Féin received the highest percentage vote in the 2020 general election.

The third-largest party in the Dáil is Fine Gael, which has its origins in the pro-treaty movement of Michael Collins in the Irish Civil War. Traditionally the party of law and order, it is associated with strong belief in pro-enterprise and reward. Despite expressions of Social Democracy by previous leader Garrett Fitzgerald, today, it remains a Christian democratic, economically liberal party along European lines, with a strongly pro-European outlook. Fine Gael was formed out of a merger of Cumann na nGaedheal, the National Centre Party and the Blueshirts. In recent years it has generally been associated with a liberal outlook. It has formed government in the periods 1922–1932 (Cumann na nGaedheal), 1948–1951, 1954–1957, 1973–1977, 1981–1982, 1982–1987, 1994–1997, and 2011 to present. Fine Gael made massive gains at the 2011 general election, winning 78 seats, its highest ever.

The fourth-largest party in the Dáil is the Green Party, which made significant gains at the 2020 general election.

The joint-fifth largest party in the Dáil is the centre-left Labour Party which was founded by James Connolly and Jim Larkin in 1912. Labour have formal links with the trade union movement and have governed in seven coalition governments – six led by Fine Gael and one by Fianna Fáil. This role as a junior coalition partner has led to Labour being classed as the half party of Ireland's two and a half party system. Labour won a record number of seats, 37, at the 2011 general election, becoming the second-largest party for the first time. It went into coalition with Fine Gael, who also won a record number of seats. Labour was Ireland's third party or “half-party” up until the 2016 general election, when it suffered the worst general election defeat in its history, gaining just 7 seats. A lot of this was due to its being in government with Fine Gael, who introduced austerity measures to deal with the economic crisis.

The other fifth-largest Dáil party is the Social Democrats. The Social Democrats are a relatively new party and made gains at the 2020 general election.

The Solidarity–People Before Profit electoral alliance, consisting of the Solidarity and People Before Profit currently occupy the 6th largest grouping within Dáil Éireann. Formed in 2015, the group represents a left-wing, socialist viewpoint.

Other parties and political alliances represented in the Dáil after the 2020 general election are Independents 4 Change and Aontú.

The Independent Alliance, a loose alliance of independents formed in 2015, returned 6 TDs after the 2016 general election. 5 of the 6 helped elect Enda Kenny as Taoiseach again after the election, and have since entered government in various forms. Independent Alliance is defunct as of 2020.

Ireland's foreign relations are substantially influenced by its membership of the European Union, although bilateral relations with the United States and United Kingdom are also important to the country. It is one of the group of smaller nations in the EU, and has traditionally followed a non-aligned foreign policy.

Ireland tends towards independence in foreign policy, thus it is not a member of NATO and has a longstanding policy of military neutrality.

This policy has helped the Irish Defence Forces to be successful in their contributions to UN peace-keeping missions since 1960 (in the Congo Crisis ONUC) and subsequently in Cyprus (UNFICYP), Lebanon (UNIFIL), Iran/Iraq Border (UNIIMOG), Bosnia and Herzegovina (SFOR & EUFOR Althea), Ethiopia and Eritrea (UNMEE), Liberia (UNMIL), East Timor (INTERFET), Darfur and Chad (EUFOR Tchad/RCA). Irish Defence Forces do not deploy in Missions

The Republic of Ireland is member of the Australia Group, BIS, British-Irish Council, CE, Celtic League, EBRD, ECE, EIB, EMU, ESA, EU, FAO, IAEA, IBRD, ICAO, ICC, ICC, ITUC, ICRM, IDA, IEA, IFAD, IFC, IFRCS, ILO, IMF, International Maritime Organization, Intelsat, Interpol, IOC, IOM (observer), ISO, ITU, MINURSO, NAM (guest), NEA, NSG, OECD, OPCW, OSCE, PFP, UN, UNCTAD, UNESCO, UNFICYP, UNHCR, UNIDO, UNIFIL, UNIKOM, UNITAR, UNMIBH, UNMIK, UNMOP, UNTAET, UNTSO, UPU, WCO, WEU (observer), WHO, WIPO, WMO, WTrO, and the Zangger Committee.

Northern Ireland has been a major factor in Irish politics since the island of Ireland was divided between Northern Ireland and what is now the Republic in 1920. The creation of Northern Ireland led to conflict between northern nationalists (mostly Roman Catholic) who seek unification with the Republic and Unionists (mostly Protestant) who opposed British plans for Irish Home Rule and wished for Northern Ireland to remain within the United Kingdom. After the formation of Northern Ireland in 1921 following its opt out from the newly formed Irish Free State, many Roman Catholics and Republicans were discriminated against. The abolition of Proportional Representation and the gerrymandering of constituency boundaries led to Unionists being over-represented at Stormont and at Westminster. Even James Craig who was prime minister of Northern Ireland boasted of his Protestant Parliament for a Protestant People. In the 1960s NICRA was set up to end discrimination between Catholics and Protestants. There was a massive backlash to this from sections of the Unionist community. This conflict exploded into violence in the late sixties with the beginning of the Troubles, involving groups such as the Provisional IRA, loyalist paramilitaries, the police and the British army, the latter originally drafted in to protect Catholic communities from loyalist violence. These clashes were to result in the suspension of the Stormont Parliament and unsuccessful efforts by the British Government to encourage a power-sharing Executive in Northern Ireland which were only realised following the Good Friday Agreement in 1998. The Troubles caused thousands of deaths in Northern Ireland but also spilled over into bombings and acts of violence in England and the Republic.

Since its foundation it has been the stated long-term policy of governments of what is now the Republic to bring an end to the conflict in Northern Ireland and to bring about a united Ireland. Northern Ireland has also, in the past, often been a source of tension between the Irish Government and the government of the United Kingdom. To find a solution to the Troubles the Irish Government became a partner in the Good Friday Agreement in 1998.

While Sinn Féin have long organised in both Northern Ireland and the Republic, Fianna Fáil have recently opened a "cumann" (branch) in Derry and begun recruiting members at Queen's University, Belfast although both are extremely small.

Under the Good Friday Agreement and Article 3 of the Constitution a North-South Ministerial Council and six North-South Implementation Bodies co-ordinate activities and exercise a limited governmental role within certain policy areas across the whole island of Ireland. The Implementation Bodies have limited executive authority in six policy areas. Meetings of the Council take the form of meetings between ministers from both the Republic's Government and the Northern Ireland Executive. The council was suspended from 2002 to 2007. However, with the resumption of devolved government in Northern Ireland in May 2007, the council has now re-assumed its duties.





</doc>
<doc id="14679" url="https://en.wikipedia.org/wiki?curid=14679" title="Telecommunications in the Republic of Ireland">
Telecommunications in the Republic of Ireland

Telecommunications in Ireland operate in a regulated competitive market that provides customers with a wide array of advanced digital services. This article explores Ireland's telecommunications infrastructure including: fixed and mobile networks, voice, data and Internet services, cable television, developments in next generation networks and broadcast networks for radio and television.

Telecommunications, including radio frequency spectrum licensing and the postal sector, are regulated by the Commission for Communications Regulation (ComReg). ComReg was established on 1 December 2002. The Broadcasting Authority of Ireland (BAI) () is the regulator of both public and commercial broadcasting sector in Ireland. It was established on 1 October 2009, replacing the Broadcasting Commission of Ireland (BCI) ().

The Minister for Communications, Climate Action and Environment has overall responsibility for national policy and regulation of both telecommunications and broadcasting.

The telecommunications market in Ireland was opened to competition in 1998.

Eir’s dominance has reduced and by Q3 2019 operators other than eir accounted for 61% of the Irish fixed voice market retail revenue and 54.7% market share by fixed-line retail and wholesale revenue and 80.9% of the mobile market (excluding mobile broadband and machine-to-machine subscriptions) or 84.4% of total subscriptions. Other operators accounted for 68.6% of retail fixed broadband subscriptions (comprising cable, FTTH, FTTC/VDSL and ADSL) and 57.3% of retail FTTP subscriptions 

Eir remains the largest telecommunications company in Ireland, offering fixed, mobile, and broadband services. As Bord Telecom Éireann, the company was state owned until 1999, when it was floated on the Irish and New York Stock Exchanges.

Ireland's telecommunications network is a modern digital system connected by an extensive national fibre optic network with multiple high capacity fibre optic links to the UK, Continental Europe, North America and with dedicated capacity on routes to Asia and other parts of the globe.
There is an open and competitive telecommunications market regulated by ComReg. However, the fixed-line market is still dominated by the incumbent operator Eir.

Several companies operate national fibre optic networks including Eir, BT Ireland, ESB Group and Virgin Media Ireland. Eir's fibre network is the most extensive covering most parts of the country with 12,000 km of fibre routes (>40,000 km of fibres)
Eir's Next Generation Network upgrade rolled out Dense Wavelength Division Multiplexing (DWDM) which is capable of delivering up to 320 Gbit/s along a single fibre route.
This upgrade also sees Eir's core infrastructure moving to an all-IP network. It has major aggregation nodes at 140 locations around Ireland and onward fibre connections to another 470 central office sites.

Ireland also has major connections to multiple international fibre optic networks.

94 Irish towns and cities also have access to publicly owned, carrier-neutral metropolitan fibre networks managed by e|net.

These networks can be used by any licensed Irish telecommunications operator to provide commercial or residential end users with products.

For residential and small business providers, most major urban areas have access to Virgin Media Ireland's HFC network which provides speeds of up to 1 Gbit/s using EuroDOCSIS 3.1 cable modem technology.

Eir is also in the process of rolling out FTTH which provides speeds of up to 1000Mbit/s down and 100Mbit/s up. They also provide an extensive vectored VDSL2 based FTTC access network, using the legacy cooper network. This offers speeds of up to 100Mbit/s.

Retail services using this next generation access infrastructure are provided by approximately 15 operators.

Siro a joint venture between ESB Group and Vodafone Ireland provides another open access fibre to home network, used by multiple ISPs to deliver service. Fibre is run alongside ESB Networks 230V/400V LV electricity distribution system, sharing underground ducts and poles, with fibre typically entering premises next to the electricity meter. This, similar to Eir's FTTH network, delivers speeds of up to 1 Gbit/s and is capable of delivery of 10 Gbit/s in the future.

Ireland has three mobile networks that own and operate their own network infrastructure and a number of MVNO operators that operate mobile phone services using one of these infrastructure providers' radio networks. The three infrastructure owning networks are:
Meteor and Eir Mobile were the first to launch 4G LTE services in Ireland on 26 September 2013, followed by Vodafone on 14 October 2013, and Three on 27 January 2014. O2 was due to launch its 4G services later in 2014, but plans were put on hold when its acquisition by Three was approved in May, and from the time of the merger in 2015, previous O2 customers gained 4G coverage through Three's network, albeit with initial service problems.

In 2016, 41.9% of Ireland's mobile subscriptions were using 4G technology. 3G remained the dominant technology with 44.6% share, however, it is likely to be overtaken by 4G in 2017.


As mobile phone services become more price competitive, more Irish customers are opting to drop landline services. This is reflected by a sharp fall in the number of fixed line channels in use and an equivalent increase in mobile subscriptions. Details are tracked on ComReg's ComStat website

There are three mobile telecommunications providers: Three Ireland, eirMobile and Vodafone Ireland.

There are also some MNVOs (Mobile Network Virtual Operator), such as: 48 Months, Lycamobile, Postmobile, Tesco Mobile, Virgin Mobile.

The original network was taken over by the Irish Department of Posts and Telegraphs (P&T) from the British Post Office in 1921 and used a mixture of manual and step-by-step automatic exchanges. Development of the network was relatively stagnant with slow rollout of automatic switching using step-by-step exchanges until after WWII.
From 1957 onwards, P&T began to roll out more modern crossbar switches primarily using equipment supplied by Ericsson built at their Athlone facility. ITT Pentaconta crossbar switches, built by CGCT (Compagnie générale de constructions téléphoniques) were also used in some areas. This saw significant improvements to many services, but the network was still quite underdeveloped in rural areas.
Digital switching was introduced in 1980 using Ericsson AXE and Alcatel E10 switches both of which were manufactured at facilities in Ireland. This saw a total transformation of the telephone network with modern automatic and digital services reaching even the most rural parts of Ireland by the mid-1980s.
The fixed-line network is now made up of multiple operators using a diverse range of digital technologies including VoIP.

Ireland's first mobile telephone network, Eircell, went live in 1986 using the analogue TACS system.
2G GSM services from Eircell launched on 1 July 1993. Digifone followed in 1997, then Meteor in 2001 (having been licensed in 1998) and 3 Ireland launched its UMTS 3G-only service in 2005.

3G services launched in 2004 (Vodafone Ireland) and other networks quickly followed suit, and 4G launched in 2013 (Meteor) and is now available on most networks. Meteor was bought out by Eir in 2005 and eventually rebranded as Eir in 2017.


Broadband Internet access is available in Ireland via DSL, cable, wireless, and satellite. By the end of 2011 Eircom announced that 75% of its working lines would be connected to Next Generation Broadband (NGB) enabled exchanges.

Currently available services (Q3 2014)

A typical monthly broadband Internet subscription cost $26.02 in 2011, 14% less than the average of $30.16 for the 34 Organisation for Economic Co-operation and Development (OECD) countries surveyed.

In August 2012 Pat Rabbitte, the Minister for Communications, Energy and Natural Resources, outlined a national broadband plan with goals of:

Founded in 1996, the Internet Neutral Exchange (INEX) is an industry-owned association that provides IP peering and traffic exchange for its members in Ireland. The INEX switching centres are located in five secure data centres in Dublin and one in Cork: TeleCity Group in Kilcarbery Park, Dublin 22 & TeleCity Group in Citywest Business Campus, Dublin 24 and Interxion DUB1, and Interxion DUB2 in Park West, and Vodafone Clonshaugh as well as at CIX, Hollyhill, Cork T23 R68N. The switches are connected by dedicated resilient fibre links. In June 2015 it listed 74 full and 21 associate members.

Established in 1998, the Internet Service Providers Association of Ireland (ISPAI) listed 24 Internet access and hosting providers as members in 2012.

Television in Ireland is broadcast using DVB-T using the common platform specifications defined by NorDig which apply in the Nordic countries and Ireland. Video is encoded using the MPEG4 system.
The analogue PAL-I broadcasting system is no longer on air.

Cable systems operate using the DVB-C standard and Satellite is broadcast using DVB-S/S2.
Some areas still carry a range of cable channels in analogue PAL-I format. Although, this is normally just a legacy service provided by default. It is not possible to subscribe to analogue cable as a new customer.

Radio is broadcast primarily using FM 88-108 MHz.
Digital DAB Radio is also available in some areas.
RTÉ Radio 1 is also broadcast on Longwave 252 kHz (AM)
Mediumwave services have been discontinued.

2RN operates a national FM network and DAB services. However, most independent FM stations own their own broadcasting infrastructure.

Raidió Teilifís Éireann ("Radio [and] Television of Ireland"; abbreviated as RTÉ) is a statutory semi-state company and the public service broadcaster that dominates the radio and TV sectors in Ireland. The first commercial radio stations began broadcasting in 1989. Prior to 1989 hundreds of pirate radio stations were a mainstay of radio listener-ship, particularly in Dublin, and a handful of pirate stations continue to operate illegally today. In 1998 TV3 became the first privately owned commercial TV station and it remains the main free-to-air service after RTÉ. Competition also comes from British public and private terrestrial TV. Satellite and cable TV are widely available. There are also non-commercial community and special interest radio stations.

RTÉ both produces programmes and broadcasts them on television, radio and the Internet in English and Irish. The radio service began on 1 January 1926, while regular television broadcasts began on 31 December 1961, making RTÉ one of the oldest continuously operating public service broadcasters in the world. Some RTÉ services are only funded by advertising, while other RTÉ services are only funded by the television licence fee.

Saorview ( ) is Ireland's national free-to-air digital terrestrial television (DTT) service operated by 2RN. Trial service began on 29 October 2010 with full service to the public from May 2011. Analogue television transmissions ended on 24 October 2012.

SAORSAT is Ireland's national free-to-air digital satellite television service, also operated by 2RN. SAORSAT delivers Irish television services to the 1% to 2% of homes that are not covered by the SAORVIEW Digital Terrestrial Television service.

A television licence is required for any address at which there is a television set or device that is not exempt. The annual licence fee is €160. The licence is free to senior citizens (to anyone over the age of 70, some over 66), some social welfare recipients, and individuals who are blind.




</doc>
<doc id="14680" url="https://en.wikipedia.org/wiki?curid=14680" title="Transport in Ireland">
Transport in Ireland

Most of the transport system in Ireland is in public hands, either side of the Irish border. The Irish road network has evolved separately in the two jurisdictions into which Ireland is divided, while the Irish rail network was mostly created prior to the partition of Ireland.

In the Republic of Ireland, the Minister for Transport, acting through the Department of Transport, is responsible for the state's road network, rail network, public transport, airports and several other areas. Although some sections of road have been built using private or public-private funds, and are operated as toll roads, they are owned by the Government of Ireland. The rail network is also state-owned and operated, while the government currently still owns the main airports. Public transport is mainly in the hands of a statutory corporation, Córas Iompair Éireann (CIÉ), and its subsidiaries, Bus Átha Cliath (Dublin Bus), Bus Éireann (Irish Bus), and Iarnród Éireann (Irish Rail).

On 1 November 2005, the Irish government published the Transport 21 plan which includes €18bn for improved roads and €16bn for improved rail, including the Western Railway Corridor and the Dublin Metro.

The Republic of Ireland's transport sector is responsible for 21% of the state's greenhouse gas emissions.

In Northern Ireland, the road network and railways are in state ownership. The Department for Infrastructure is responsible for these and other areas (such as water services). Two of the three main airports in Northern Ireland are privately operated and owned. The exception is City of Derry Airport, which is owned and funded by Derry City Council. A statutory corporation, the Northern Ireland Transport Holding Company (which trades as Translink) operates public transport services through its three subsidiaries – NI Railways Company Limited, Ulsterbus Limited, and Citybus Limited (now branded as Metro).


Ireland's railways are in State ownership, with Iarnród Éireann (Irish Rail) operating services in the Republic and NI Railways operating services in Northern Ireland. The two companies co-operate in providing the joint Enterprise service between Dublin and Belfast. InterCity services are provided between Dublin and the major towns and cities of the Republic, and in Ulster along the Belfast–Derry railway line. Suburban railway networks operate in Dublin, Dublin Suburban Rail, and Belfast, Belfast Suburban Rail, with limited local services being offered in, or planned for, Cork, Limerick, and Galway.

The rail network in Ireland was developed by various private companies during the 19th century, with some receiving government funding. The network reached its greatest extent by 1920. A broad gauge of 1600mm (5 ft 3in) was agreed as the standard for the island, although there were also hundreds of kilometres of 914mm (3 ft) narrow gauge railways.

Many lines in the west were decommissioned in the 1930s under Éamon de Valera, with a further large cull in services by both CIÉ and the Ulster Transport Authority (UTA) during the 1960s, leaving few working lines in the northern third of the island. There is a campaign to bring some closed lines back into service, in particular the Limerick-Sligo line (the Western Railway Corridor), to facilitate economic regeneration in the west, which has lagged behind the rest of the country. There is also a move to restore service on the Dublin to Navan line, and smaller campaigns to re-establish the rail links between Sligo and Enniskillen/Omagh/Derry and Mullingar and Athlone/Galway. Under the Irish government's Transport 21 plan, the Cork to Midleton rail link was reopened in 2009. The re-opening of the Navan-Clonsilla rail link and the Western Rail Corridor are amongst future projects as part of the same plan.

Public transport services in Northern Ireland are sparse in comparison with those of the rest of Ireland or Great Britain. A large railway network was severely curtailed in the 1950s and 1960s. Current services includes suburban routes to Larne, Newry and Bangor, as well as services to Derry. There is also a branch from Coleraine to Portrush.

Since 1984 an electrified train service run by Iarnród Éireann has linked Dublin with its coastal suburbs. Running initially between Bray and Howth, the Dublin Area Rapid Transit (DART) system was extended from Bray to Greystones in 2000 and further extended from Howth Junction to Malahide. In 2004 a light rail system, Luas, was opened in Dublin serving the central and western suburbs, run by Veolia under franchise from the Railway Procurement Agency. The construction of the Luas system caused much disruption in Dublin. Plans to construct a Dublin Metro service including underground lines were mooted in 2001, but stalled in the financial crisis at the end of that decade.

Ireland has one of the largest dedicated freight railways in Europe, operated by Bord na Móna totalling nearly .


Ireland's roads link Dublin with all the major cities (Belfast, Cork, Limerick, Derry, Galway, and Waterford). Driving is on the left. Signposts in the Republic of Ireland are shown in kilometres and speed limits in kilometres per hour. Distance and speed limit signs in Northern Ireland use imperial units in common with the rest of the United Kingdom.

Historically, land owners developed most roads and later turnpike trusts collected tolls so that as early as 1800 Ireland had a road network. In 2005 the Irish Government launched Transport 21, a plan envisaging the investment of €34 billion in transport infrastructure from 2006 until 2015. Several road projects were progressed but the economic crisis that began in 2008–09 has prevented its full implementation.

Between 2011 and 2015, diesel cars constituted 70% of new cars. In 2015, 27 new cars per 1,000 inhabitants were registered in Ireland, the same as the EU average.

Ireland's first mail coach services were contracted with the government by John Anderson with William Bourne in 1791 who also paid to improve the condition of the roads. The system of mail coaches, carriages and "bians" was further developed by Charles Bianconi, based in Clonmel, from 1815 as a fore-runner of the modern Irish public transportation system.

State-owned Bus Éireann (Irish Bus) currently provides most bus services in the Republic of Ireland, outside Dublin, including an express coach network connecting most cities in Ireland, along with local bus services in the provincial cities. Bus Átha Cliath (Dublin Bus), a sister company of Bus Éireann, provides most of the bus services in Dublin, with some other operators providing a number of routes. These include Aircoach, a subsidiary of FirstGroup which provides services to Dublin Airport from Dublin city centre, South Dublin City, Greystones and Bray. They also operate two intercity express non-stop services service between Dublin Airport, Dublin City Centre, and Cork and also a non-stop route between Belfast City Centre, Dublin Airport and Dublin City. Other operators such as Irish Citylink and GoBus.ie compete on the Dublin-Galway route. Matthews Coaches run a direct service from Bettystown, Laytown and Julianstown to Dublin whilst Dublin Coach operate services to Portlaoise and Limerick. JJ Kavanagh and Sons also operates regular services on the Portlaoise/Limerick route as well as offering services to Waterford, Carlow, Kilkenny, Clonmel and a selection of regional towns and villages in the south.

Some private rural operators exist, such as Halpenny's in Blackrock, County Louth, which was the first private bus operator to run a public service in Ireland, Bus Feda (Feda O'Donnell Coaches), which operates twice daily routes from Ranafast, County Donegal to Galway and back.

In Northern Ireland Ulsterbus provides the bus network, with its sister company Metro providing services in Belfast. Both are part of state-owned Translink. Tiger Coaches operates a very late night bus service on Friday and Saturday nights between Belfast and Lisburn.

Private hire companies offer groups travelling throughout Ireland with options ranging from cars to 56 passenger coaches. Private Coach Hire Companies can be found at CTTC.ie.

Cross-border services (e.g. Dublin city centre to Belfast) are run primarily by a partnership of Ulsterbus and Bus Éireann with some services run across the border exclusively by one of the two companies (e.g. Derry–Sligo run by Bus Éireann). Aircoach, a private operator, does however operate a competing Dublin to Belfast Express service via Dublin Airport.


Natural gas transmission network (2003). There is a much more extensive distribution network.

Ireland has major ports in Dublin, Belfast, Cork, Rosslare, Derry and Waterford. Smaller ports exist in Arklow, Ballina, Drogheda, Dundalk, Dún Laoghaire, Foynes, Galway, Larne, Limerick, New Ross, Sligo, Warrenpoint and Wicklow.

Ports in the Republic of Ireland handled 2.8 million travellers crossing the sea between Ireland and Great Britain in 2014, a decrease of 1 million passengers movements since 2003. This has been steadily dropping for a number of years (20% since 1999), probably as a result of low cost airlines. Ferry connections between Britain and Ireland via the Irish Sea include the routes from Fishguard and Pembroke to Rosslare, Stranraer to Belfast and Larne, and Cairnryan to Larne; the Swansea to Cork route has closed. There is also a connection between Liverpool and Belfast via the Isle of Man. The world's largest car ferry, "Ulysses", is operated by Irish Ferries on the Dublin–Holyhead route.

In addition, there are ferries from Rosslare and Dublin to Cherbourg and Roscoff in France.

The vast majority of heavy goods trade is done by sea. Northern Irish ports handle 10 megatonnes (Mt) of goods trade with Britain annually, while ports in the south handle 7.6 Mt, representing 50% and 40% respectively of total trade by weight.


Ireland has five main international airports: Dublin Airport, Belfast International Airport (Aldergrove), Cork Airport, Shannon Airport and Ireland West Airport (Knock). Dublin Airport is the busiest of these carrying almost 28 million passengers per year; a second terminal (T2) was opened in November 2010. All provide services to Great Britain and continental Europe, while Cork, Dublin and Shannon also offer transatlantic services. 
The London to Dublin air route is the ninth busiest international air route in the world, and also the busiest international air route in Europe, with 14,500 flights between the two in 2017. In 2015, 4.5 million people took the route, at that time, the world's second-busiest. Aer Lingus is the flag carrier of Ireland, although Ryanair is the country's largest airline. Ryanair is Europe's largest low-cost carrier, the second largest in terms of passenger numbers, and the world's largest in terms of international passenger numbers. For several decades until 2007 Shannon was a mandatory stopover for transatlantic routes to the United States. In recent years it has opened a pre-screening service allowing passengers to pass through US immigration services before departing from Ireland.

There are also several smaller regional airports: George Best Belfast City Airport, City of Derry Airport, Galway Airport, Kerry Airport (Farranfore), Sligo Airport (Strandhill), Waterford Airport and Donegal Airport (Carrickfinn). Scheduled services from these regional points are in the main limited to flights travelling to other parts of Ireland and to Great Britain. Airlines based in Ireland include Aer Lingus (the former national airline of the Republic of Ireland), Ryanair, Aer Arann and CityJet. Services to the Aran Islands are operated from Aerfort na Minna (Connemara Regional Airport).
Ireland's national airline, Aer Lingus, provides services from Belfast City, Cork, Dublin and Shannon to Europe, North Africa and North America. Dublin and Cork airports are run by a State body, DAA (Dublin Airport Authority). Other Irish airlines are Ryanair, one of the largest in the world, Stobart Air, CityJet, ASL Airlines Ireland and the Aer Lingus subsidiary Aer Lingus Regional. A number of other operators specialise in general aviation.

For 2018 the passenger numbers were as follows:




</doc>
<doc id="14682" url="https://en.wikipedia.org/wiki?curid=14682" title="Foreign relations of Ireland">
Foreign relations of Ireland

The foreign relations of Ireland are substantially influenced by its membership of the European Union, although bilateral relations with the United States and United Kingdom are also important to the state. It is one of the group of smaller nations in the EU, and has traditionally followed a non-aligned foreign policy. Ireland has historically tended towards independence in foreign military policy, thus it is not a member of the North Atlantic Treaty Organisation and has a longstanding policy of military neutrality. According to the Irish Defence Forces, the neutrality policy has helped them to be successful in their contributions to United Nations peace-keeping missions since 1960 (in the Congo Crisis) and subsequently in Cyprus, Lebanon and Bosnia and Herzegovina.

Ireland's official relationship with the People's Republic of China began on 22 June 1979. Following his visit to China in 1999, former Taoiseach Bertie Ahern authorised the establishment of an Asia Strategy. The aim of this Strategy was to ensure that the Irish Government and Irish enterprise work coherently to enhance the important relationships between Ireland and Asia. In recent years due to the rapid expansion of the Chinese economy, China is becoming a key trade partner of Ireland, with over $6bn worth of bilateral trade between the two countries in 2010. In July 2013, the Irish Tánaiste and Minister for Foreign Affairs and Trade were invited to China by the Chinese foreign minister Wang Yi on a trade mission to boost both investment and political ties between the two countries.

Ireland has raised its concerns in the area of human rights with China on a number of occasions. On 12 May 2007, during a visit to Beijing, former Taoiseach Brian Cowen (then Minister for Finance) discussed human rights issues with Chinese Foreign Minister Li Zhaoxing. Former Tánaiste Mary Coughlan also raised human rights issues and concerns with visiting Chinese Vice-Premier Zeng Peiyan. Ireland also participates in the EU-China Human Rights Dialogue.

Concerning the Taiwan issue, Ireland follows a One-China policy. In 2007, the former Irish Minister for Foreign Affairs, Dermot Ahern summarised the Irish position as follows:

The former Minister's emphasis on the One China policy and to the Taiwan issue being best settled through dialogue "between the parties concerned" was consistent with Beijing's wish that the Taiwan issue be regarded as a domestic one between Chinese on both sides of the Taiwan Straits.

In July 2019, the UN ambassadors from 22 nations, including Ireland, signed a joint letter to the UNHRC condemning China's mistreatment of the Uyghurs as well as its mistreatment of other minority groups, urging the Chinese government to close the Xinjiang re-education camps.

Since at least the 1600s Ireland has had political connections with the United Kingdom, with the whole island becoming a part of the United Kingdom of Great Britain and Ireland from 1801 to 1922. From the time of Ireland declaring itself independent from the United Kingdom in 1937, the two countries have been involved in a dispute over the status of Northern Ireland. Articles 2 and 3 of the Constitution of Ireland formerly claimed Northern Ireland as a part of the ""national territory"", though in practice the Irish government did recognise the UK's jurisdiction over the region.
From the onset of the Troubles in 1969, the two governments sought to bring the violence to an end. The Sunningdale Agreement of 1973 and the Anglo-Irish Agreement of 1985 were important steps in this process. In 1998, both states signed the Good Friday Agreement and now co-operate closely to find a solution to the region's problems. Articles 2 and 3 of the Constitution of Ireland were amended as part of this agreement, the territorial claim being replaced with a statement of aspiration to unite the people of the island of Ireland. As part of the Good Friday Agreement, the states also ended their dispute over their respective names: "Ireland" and the "United Kingdom of Great Britain and Northern Ireland". Each agreed to accept and use the others' correct name.

When the Troubles were raging in Northern Ireland, the Irish Government sought, with mixed success, to prevent the import of weapons and ammunition through its territory by illegal paramilitary organisations for use in their conflict with the security forces in Northern Ireland. In 1973 three ships of the Irish Naval Service intercepted a ship carrying weapons from Libya which were probably destined for Irish Republican paramilitaries. Law enforcement acts such as these additionally improved relations with the government of the United Kingdom. However, the independent judiciary blocked a number of attempts to extradite suspects between 1970 and 1998 on the basis that their crime might have been 'political' and thus contrary to international law at the time.

Ireland is one of the parties to the Rockall continental shelf dispute that also involves Denmark, Iceland, and the United Kingdom. Ireland and the United Kingdom have signed a boundary agreement in the Rockall area. However, neither have concluded similar agreements with Iceland or Denmark (on behalf of the Faroe Islands) and the matter remains under negotiation. Iceland now claims a substantial area of the continental shelf to the west of Ireland, to a point 49°48'N 19°00'W, which is further south than Ireland.

The controversial Sellafield nuclear fuel reprocessing plant in north-western England has also been a contentious issue between the two governments. The Irish government has sought the closure of the plant, taking a case against the UK government under the United Nations Convention on the Law of the Sea. However, the European Court of Justice found that the case should have been dealt with under EU law. In 2006, however, both countries came to a friendly agreement which enabled both the Radiological Protection Institute of Ireland and the Garda Síochána (Irish Police Force) access to the site to conduct investigations.

The United States recognised the Irish Free State on 28 June 1924 with diplomatic relations being established on 7 October 1924. In 1927, the United States opened an American Legation in Dublin. Due to the ancestral ties between the two countries, Ireland and the US have a strong relationship, both politically and economically, with the US being Ireland's biggest trading partner since 2000. Ireland also receives more foreign direct investment from the US than many larger nations, with investments in Ireland equal to France and Germany combined and, in 2012, more than all of developing Asia put together.

The use of Shannon Airport as a stop-over point for US forces en route to Iraq has caused domestic controversy in Ireland. Opponents of this policy brought an unsuccessful High Court case against the government in 2003, arguing that this use of Irish airspace violated Irish neutrality. Restrictions such as carrying no arms, ammunition, or explosives, and that the flights in question did not form part of military exercises or operations were put in place to defend Irish neutrality, however allegations have been made against the Central Intelligence Agency that the airport has been used between 30 and 50 times for illegal extraordinary rendition flights to the U.S without the knowledge of the Irish Government, despite diplomatic assurances by the US that Irish airspace would not be used for transport of detainees.

In July 2006, the former Irish Minister for Foreign Affairs, Dermot Ahern voiced concern over the 2006 Lebanon War. A shipment of bombs being sent to Israel by the United States was banned using Irish airspace or airfields.

In 1995 a decision was made by the U.S. government to appoint a Special Envoy to Northern Ireland to help with the Northern Ireland peace process. During the 2008 presidential campaign in the United States, however, Democratic Party candidate Barack Obama was reported as having questioned the necessity to keep a US Special Envoy for Northern Ireland. His remarks caused uproar within the Republican Party, with Senator John McCain questioning his leadership abilities and his commitment to the ongoing peace process in Northern Ireland.

, Daniel Mulhall is the Irish ambassador to the United States while the position of U.S. ambassador to Ireland is held by Edward F. Crawford.

Ireland is consistently the most pro-European of EU member states, with 77% of the population approving of EU membership according to a Eurobarometer poll in 2006. Ireland was a founding member of the euro single currency. In May 2004, Ireland was one of only three countries to open its borders to workers from the 10 new member states. EU issues important to Ireland include the Common Agricultural Policy, corporation tax harmonisation and the EU Constitution. The Irish electorate declined to ratify the Treaty of Lisbon in 2008. A second referendum in October 2009 passed the bill, allowing the treaty to be ratified before it was ratified legal guarantees on issues such as the right of Ireland to remain militarily neutral (and not engage in any kind of "European army"), the right of the state to maintain its low levels of corporation tax and that the treaty would not change the Eighth Amendment of the Constitution of Ireland making abortion illegal (since deleted). Ireland has held the Presidency of the Council of the European Union on seven occasions (in 1975, 1979, 1984, 1990, 1996, 2004 and 2013).

As of 2008 Ireland maintains diplomatic relations with 173 states (including the Republic of Kosovo), and the European Union.

Ireland has not yet established diplomatic relations with:


The United Nations was founded in 1945, but Ireland's membership was blocked by the Soviet Union until 1955, "partly because of Dublin's neutrality" during the Second World War. Since 2017, the Irish ambassador to the UN Office at Geneva has been Michael Gaffey. Ireland has been elected to the UN Security Council as a non-permanent member on three occasions — in 1962, in 1981–1982, in 2001–2002 and most recently in 2021-2022.

Ireland is a member state of the International Criminal Court, having signed the Rome Statute in 1998 and ratified it in 2002.

Irish Aid, the Government of Ireland's programme of assistance to developing countries financed the redesign of the UNV Online Volunteering service website in 2008 and supported its operations from 2007 to 2010, which led to a significant growth in the number of online volunteers and the tasks they completed.

In 2017, Ireland signed the UN treaty on the Prohibition of Nuclear Weapons.

Ireland has a long history of participation in UN peacekeeping efforts starting in 1958, just three years after joining the UN. , 90 members of the Irish Defence Forces had been killed on peacekeeping missions.

"List of major peacekeeping operations:"

As well as these missions, Irish personnel have served as observers in Central America, Russia, Cambodia, Afghanistan, Namibia, Western Sahara, Kuwait and South Africa.

Ireland was a member state of the British Commonwealth from 1922 until 1949, initially as a Dominion called the Irish Free State from 1922 until 1937, when Ireland adopted a new constitution and changed the name of the state to "Ireland". Although the king was removed from the Constitution in 1936, a republic was only formally declared from 18 April 1949. Under the rules for membership at the time, a republic could not be a member state of the Commonwealth. This was changed a week later with the adoption of the London Declaration.

Since 1998, some people in Ireland have advocated joining the Commonwealth of Nations, most notably Éamon Ó Cuív, Frank Feighan, and Mary Kenny.

Ireland is a member of or otherwise participates in the following international organisations:

Ireland's aid program was founded in 1974, and in 2017 its budget amounted to €651 million. The government had previously set a target of reaching the Millennium Development Goal of 0.7% of Gross National Product in aid by 2012, which was not met as aid was reduced as a result of the Irish financial crisis. Irish development aid is concentrated on eight priority countries: Lesotho, Mozambique, Tanzania, Ethiopia, Zambia, Uganda, Vietnam and East Timor. In 2006, Malawi was announced as the ninth priority country, with a tenth country to follow.

There have been no serious civil, human or social rights abuses/problems in the State, according to Amnesty International and the U.S. State Department. The country consistently comes among the top nations in terms of freedom and rights ratings.




</doc>
<doc id="14687" url="https://en.wikipedia.org/wiki?curid=14687" title="Geography of Israel">
Geography of Israel

The geography of Israel is very diverse, with desert conditions in the south, and snow-capped mountains in the north. Israel is located at the eastern end of the Mediterranean Sea in Western Asia. It is bounded to the north by Lebanon, the northeast by Syria, the east by Jordan and the West Bank, and to the southwest by Egypt. To the west of Israel is the Mediterranean Sea, which makes up the majority of Israel's coastline, and the Gaza Strip. Israel has a small coastline on the Red Sea in the south.

Israel's area is approximately , which includes of inland water. Israel stretches from north to south, and its width ranges from to, at its narrowest point, . It has an Exclusive Economic Zone of .

The Israeli-occupied territories include the West Bank, , East Jerusalem, and the Golan Heights, . Geographical features in these territories will be noted as such. Of these areas, Israel has annexed East Jerusalem and the Golan Heights, an act not recognized by the international community.

Southern Israel is dominated by the Negev desert, covering some , more than half of the country's total land area. The north of the Negev contains the Judean Desert, which, at its border with Jordan, contains the Dead Sea which, at is the lowest point on Earth. The inland area of central Israel is dominated by the Judean Hills of the West Bank, whilst the central and northern coastline consists of the flat and fertile Israeli coastal plain. Inland, the northern region contains the Mount Carmel mountain range, which is followed inland by the fertile Jezreel Valley, and then the hilly Galilee region. The Sea of Galilee is located beyond this region and is bordered to the east by the Golan Heights, a plateau bordered to the north by the Israeli-occupied part of the Mount Hermon massif, which includes the highest point under Israel's control, a peak of . The highest point in territory internationally recognized as Israeli is Mount Meron at .

Israel lies to the north of the equator around 31°30' north latitude and 34°45' east longitude. It measures from north to south and, at its widest point , from east to west. At its narrowest point, however, this is reduced to just . It has a land frontier of and a coastline of . It is ranked 153 on the List of countries and outlying territories by total area.

Prior to the establishment of the British Mandate for Palestine, there was no clear-cut definition of the geographical and territorial limits of the area known as "Palestine." On the eve of World War I it was described by Encyclopædia Britannica as a "nebulous geographical concept." The Sykes-Picot Treaty in 1916 divided the region that later became Palestine into four political units. Under the British Mandate for Palestine, the first geo-political framework was created that distinguished the area from the larger countries that surrounded it. The boundary demarcation at this time did not introduce geographical changes near the frontiers and both sides of the border were controlled by the British administration.

Modern Israel is bounded to the north by Lebanon, the northeast by Syria, the east by Jordan and the West Bank, and to the southwest by Egypt. To the west of Israel is the Mediterranean Sea, which makes up the majority of Israel's 273 km (170 mi) coastline and the Gaza Strip. Israel has a small coastline on the Red Sea in the south. The southernmost settlement in Israel is the city of Eilat whilst the northernmost is the town of Metula. The territorial waters of Israel extend into the sea to a distance of twelve nautical miles measured from the appropriate baseline.

The statistics provided by the Israel Central Bureau of Statistics include the annexed East Jerusalem and Golan Heights, but exclude the West Bank and Gaza Strip. The population of Israel includes Israeli settlers in the West Bank. The route of the Israeli West Bank barrier incorporates some parts of the West Bank.

Israel is divided into four physiographic regions: the Mediterranean coastal plain, the Central Hills, the Jordan Rift Valley and the Negev Desert.

The Israeli Coastal Plain stretches from the Lebanese border in the north to Gaza in the south, interrupted only by Cape Carmel at Haifa Bay. It is about wide at Gaza and narrows toward the north to about at the Lebanese border. The region is fertile and humid (historically malarial) and is known for its citrus orchards and viticulture. The plain is traversed by several short streams. From north to south these are: Kishon, Hadera, Alexander, Poleg, and Yarkon. All of these streams were badly polluted, but in the last ten years much work has been done to clean them up. Today the Kishon, Alexander and Yarkon again flow year round, and also have parks along their banks.

Geographically, the region is divided into five sub-regions. The northernmost section lays between the Lebanese border, the Western Galilee to the east, and the sea. It stretches from Rosh HaNikra in the north and down to Haifa, Israel's third-largest city. It is a fertile region, and off the coast there are many small islands. Along the Mount Carmel range is Hof HaCarmel, or the Carmel Coastal Plain. It stretches from the point where Mount Carmel almost touches the sea, at Haifa, and down to Nahal Taninim, a stream that marks the southern limit of the Carmel range. The Sharon Plain is the next section, running from Nahal Taninim (south of Zikhron Ya'akov) to Tel Aviv's Yarkon River. This area is Israel's most densely populated. South of this, running to Nahal Shikma, is the Central Coastal Plain, also known as the Western Negev. The last segment is the Southern Coastal Plain, which extends south around the Gaza Strip. It is divided into two – in the north, the Besor region, a savanna-type area with a relatively large number of communities, and south of it the Agur-Halutza region, which is very sparsely populated.

Inland (east) of the coastal plain lies the central highland region. In the north of this region lie the mountains and hills of Upper Galilee and Lower Galilee, which are generally to in height, although they reach a maximum height of at Mount Meron. South of the Galilee, in the West Bank, are the Samarian Hills with numerous small, fertile valleys rarely reaching the height of . South of Jerusalem, also mainly within the West Bank, are the Judean Hills, including Mount Hebron. The central highlands average in height and reach their highest elevation at Har Meron, at , in Galilee near Safed. Several valleys cut across the highlands roughly from east to west; the largest is the Jezreel Valley (also known as the Plain of Esdraelon), which stretches from Haifa southeast to the valley of the Jordan River, and is across at its widest point.

East of the central highlands lies the Jordan Rift Valley, which is a small part of the -long Syrian-East African Rift. In Israel the Rift Valley is dominated by the Jordan River, the Sea of Galilee (an important freshwater source also known as Lake Tiberias and Lake Kinneret), and the Dead Sea. The Jordan, Israel's largest river (), originates in the Dan, Baniyas, and Hasbani rivers near Mount Hermon in the Anti-Lebanon Mountains and flows south through the drained Hula Basin into the freshwater Lake Tiberias. Lake Tiberias is in size and, depending on the season and rainfall, is at about below sea level. With a water capacity estimated at , it serves as the principal reservoir of the National Water Carrier (also known as the Kinneret-Negev Conduit). The Jordan River continues its course from the southern end of Lake Tiberias (forming the boundary between the West Bank and Jordan) to its terminus in the highly saline Dead Sea. The Dead Sea is in size and, at below sea level, is the lowest surface point on the earth. South of the Dead Sea, the Rift Valley continues in the Arabah (Hebrew "Arava", Arabic "Wadi 'Arabah"), which has no permanent water flow, for to the Gulf of Eilat.

The Negev Desert comprises approximately , more than half of Israel's total land area. Geographically it is an extension of the Sinai Desert, forming a rough triangle with its base in the north near Beersheba, the Dead Sea, and the southern Judean Mountains, and it has its apex in the southern tip of the country at Eilat. Topographically, it parallels the other regions of the country, with lowlands in the west, hills in the central portion, and the Arava valley as its eastern border.

Unique to the Negev region are the craterlike makhteshim cirques; Makhtesh Ramon, Makhtesh Gadol and Makhtesh Katan. The Negev is also sub-divided into five different ecological regions: northern, western and central Negev, the high plateau and the Arabah Valley. The northern Negev receives of rain annually and has fairly fertile soils. The western Negev receives of rain per year, with light and partially sandy soils. The central Negev has an annual precipitation of and is characterized by impervious soil, allowing minimum penetration of water with greater soil erosion and water runoff. This can result in rare flash floods during heavy rains as water runs across the surface of the impervious desert soil. The high plateau area of Ramat HaNegev stands between and above sea level with extreme temperatures in summer and winter. The area gets of rain each year, with inferior and partially salty soils. The Arabah Valley along the Jordanian border stretches from Eilat in the south to the tip of the Dead Sea in the north and is very arid with barely of rain annually.

Israel is divided east-west by a mountain range running north to south along the coast. Jerusalem sits on the top of this ridge, east of which lies the Dead Sea graben which is a pull-apart basin on the Dead Sea Transform fault.

The numerous limestone and sandstone layers of the Israeli mountains serve as aquifers through which water flows from the west flank to the east. Several springs have formed along the Dead Sea, each an oasis, most notably the oases at Ein Gedi and Ein Bokek (Neve Zohar) where settlements have developed. Israel also has a number of areas of karst topography. Caves in the region have been used for thousands of years as shelter, storage rooms, barns and as places of public gatherings.

The far northern coastline of the country has some chalk landscapes best seen at Rosh HaNikra, a chalk cliff into which a series of grottoes have been eroded.

The Jordan Rift Valley is the result of tectonic movements within the Dead Sea Transform (DSF) fault system. The DSF forms the transform boundary between the African Plate to the west and the Arabian Plate to the east. The Golan Heights and all of Jordan are part of the Arabian Plate, while the Galilee, West Bank, Coastal Plain, and Negev along with the Sinai Peninsula are on the African Plate. This tectonic disposition leads to a relatively high seismic activity in the region.

The entire Jordan Valley segment is thought to have ruptured repeatedly, for instance during the last two major earthquakes along this structure in 749 and 1033. The deficit in slip that has built up since the 1033 event is sufficient to cause an earthquake of ~7.4.

The most catastrophic earthquakes occurred in 31 BCE, 363, 749, and 1033 CE, that is every ca. 400 years on average. Destructive earthquakes leading to serious loss of life strike about every 80 years. While stringent construction regulations are currently in place and recently built structures are earthquake-safe, as of 2007 the majority of the buildings in Israel were older than these regulations and many public buildings as well as 50,000 residential buildings did not meet the new standards and were "expected to collapse" if exposed to a strong quake. Given the fragile political situation of the Middle East region and the presence there of major holy sites, a quake reaching magnitude 7 on the Richter scale could have dire consequences for world peace.

Israel's longest and most famous river is the long River Jordan, which rises on the southern slopes of Mount Hermon in the Anti-Lebanon mountains. The river flows south through the freshwater Sea of Galilee, and from there forms the boundary with the Kingdom of Jordan for much of its route, eventually emptying into the Dead Sea. The northern tributaries to the Jordan are the Dan, Banias, and Hasbani. Only the Dan is within undisputed Israel; the Hasbani flows from Lebanon and the Banias from territory captured from Syria in the Six-Day War.
The Sea of Galilee (also called the Kinneret) is Israel's largest and most important freshwater lake, located in the northeast of the country. The pear-shaped lake is long from north to south, with a maximum width of in the north, covering . The Kinneret lies below sea level and reaches depths of . In a previous geological epoch the lake was part of a large inland sea which extended from the Hula marshes in northern Israel to south of the Dead Sea. The bed of the lake forms part of the Jordan Rift Valley.

South of the Kinneret lies the saltwater Dead Sea which forms the border between Israel and Jordan and is below sea level, making it the lowest water surface on Earth. The Dead Sea is long with a maximum width of and also makes up part of the Rift Valley. A peninsula juts out into the lake from the eastern shore, south of which the lake is shallow, less than deep. To the north is the lake's greatest depth.

There are no navigable, artificial waterways in Israel, although the National Water Carrier, a conduit for drinking water, might be classified as such. The idea of a channel connecting the Mediterranean and Dead Seas or the Red and Dead Seas has been discussed.

The following are selected elevations of notable locations, from highest to lowest:

Israel has a Mediterranean climate with long, hot, rainless summers and relatively short, cool, rainy winters (Köppen climate classification "Csa"). The climate is as such due to Israel's location between the subtropical aridity of the Sahara and the Arabian deserts, and the subtropical humidity of the Levant and Eastern Mediterranean. The climate conditions are highly variable within the state and modified locally by altitude, latitude, and the proximity to the Mediterranean.

On average, January is the coldest month with average temperatures ranging from , and July and August are the hottest months at , on average across the country. Summers are very humid along the Mediterranean coast but dry in the central highlands, the Rift Valley, and the Negev Desert. In Eilat, a desert city, summer daytime-temperatures are often the highest in the state, at times reaching . More than 70% of the average rainfall in Israel falls between November and March; June through September are usually rainless. Rainfall is unevenly distributed, significantly lower in the south of the country. In the extreme south, rainfall averages near annually; in the north, average annual rainfall exceeds . Rainfall varies from season to season and from year to year, particularly in the Negev Desert. Precipitation is often concentrated in violent storms, causing erosion and flash floods. In winter, precipitation often takes the form of snow at the higher elevations of the central highlands, including Jerusalem. Mount Hermon has seasonal snow which covers all three of its peaks in winter and spring. In rare occasions, snow gets to the northern mountain peaks and only in extremely rare occasions even to the coast. The areas of the country most cultivated are those receiving more than of rainfall annually, making approximately one-third of the country cultivable.

Thunderstorms and hail are common throughout the rainy season and waterspouts occasionally hit the Mediterranean coast, capable of causing only minor damage. However, supercell thunderstorms and a true F2 tornado hit the Western Galilee in April 2006, causing significant damage and 75 injuries.

Heat waves are frequent. 2010 was the hottest year in the history of Israel with absolute record high in several places in August. The heat became stronger from August when temperatures were considerably above the average. October and November were also dry, and November was almost rainless when it was supposed to be rainy.

Unlike much of the Middle East which is rich in lucrative crude oil, Israel has limited natural resources. These include copper, phosphates, bromide, potash, clay, sand, sulfur, asphalt, and manganese. Small amounts of natural gas and crude oil are present, often too little to merit commercial extraction. In 2009, significant reserves of natural gas were discovered at the Tamar 1 offshore drilling site, 90 kilometers west of Haifa. It is the largest natural gas reserve ever discovered in Israel.

Israel has a large number of environmental concerns ranging from natural hazards to man-made issues both resulting from ancient times to modern development. Natural hazards facing the country include sandstorms which sometimes occur during spring in the desert south, droughts which are usually concentrated in summer months, flash floods which create great danger in the deserts due to their lack of notice, and regular earthquakes, most of which are small, although there is a constant risk due to Israel's location along the Jordan Rift Valley. Current environmental concerns include the lack of arable land and natural fresh water resources. Whilst measures have been taken to irrigate and grow in the desert, the amount of water needed here poses issues. Desertification is also a risk possible on the desert fringe, whilst air pollution from industrial and vehicle emissions and groundwater pollution from industrial and domestic waste are also issues facing the country. Furthermore, the effects of the use of chemical fertilizers, and pesticides are issues facing the country.
Israel has signed many international environmental agreements and is party to:

Signed but not ratified:

Israel's rural space includes several unique kinds of settlements, notably the moshav and the kibbutz. Originally these were collective and cooperative settlements respectively. Over time, the degree of cooperation in these settlements has decreased and in several of them the cooperative structure has been dismantled altogether. All rural settlements and many small towns (some of which are dubbed "rurban settlements") are incorporated in regional councils. Land use in Israel is 17% arable land, 4% permanent crops, and 79% other uses. As of 2003 were irrigated.

There are 242 Israeli settlements and civilian land use sites in the West Bank, 42 in the Golan Heights, and 29 in East Jerusalem.

Israel currently has no offshore islands within its territorial waters. However, the Israeli government plans to build artificial islands off the coast to house an airport, a seaport, a desalination plant, a power plant, and a military testing base, as an answer to Israel's lack of space.

As of 2013, the population of Israel is 8 million, 6,015,000 of them Jewish.

For statistical purposes, the country has three metropolitan areas; Gush Dan-Tel Aviv (population 3,150,000), Haifa (population 996,000), and Beersheba (population 531,600). Some argue that Jerusalem, Israel's largest city with a population of 763,600, and Nazareth, should also be classified as metropolitan areas. In total, Israel has 74 cities, 14 of which have populations of over 100,000. Other forms of local government in Israel are local councils of which there are 144 governing small municipalities generally over 2,000 in population, and regional councils of which there are 53, governing a group of small communities over a relatively large geographical area.

Israel's population is diverse demographically; 76% Jewish, 20% Arab, and 4% unaffiliated. In terms of religion, 76% are Jewish, 16% Muslim, 2% Christian, 2% Druze, and 4% are unclassified by choice. 8% of Israeli Jews are haredi; 9% are "religious", 12% "religious-traditionalists", 27% are "non-religious traditionalists", and 43% are "secular". Other small, but notable groups in Israel, include Circassians of whom there are approximately 3,000 living mostly in two northern villages, 2,500 Lebanese, and 5,000 Armenians predominantly in Jerusalem.

Israel is ranked 34th in the world in terms of population density with, as noted, a climate of long, hot, rainless summers and relatively short, cool, rainy winters. The Population Matters 2011 overshoot index ranked Israel as the third most dependent region in the World after Singapore and Kuwait.




</doc>
<doc id="14688" url="https://en.wikipedia.org/wiki?curid=14688" title="Demographics of Israel">
Demographics of Israel

The State of Israel has a population of approximately 9,199,700 inhabitants as of May 2020. Some 74.24% are Jews of all backgrounds (about 6,829,000 individuals), 20.95% are Arab of any religion other than Jewish (about 1,890,000 individuals), while the remaining 4.81% (about 434,000 individuals) are defined as "others", including persons of Jewish ancestry deemed non-Jewish by religious law and persons of non-Jewish ancestry who are family members of Jewish immigrants (neither of which are registered at the Ministry of Interior as Jews), Christian non-Arabs, Muslim non-Arabs and all other residents who have neither an ethnic nor religious classification.

Israel's annual population growth rate stood at 2.0% in 2015, more than three times faster than the OECD average of around 0.6%. With an average of three children per woman, Israel also has the highest fertility rate in the OECD by a considerable margin and much higher than the OECD average of 1.7.
The demographics of Israel are monitored by the Israel Central Bureau of Statistics.

The territory of Israel can be defined in a number of ways as a result of a complex and unresolved political situation (see table below). For example, whilst the Israel Central Bureau of Statistics defines the area of Israel to include the annexed East Jerusalem and Golan Heights, and to exclude the militarily controlled regions of the West Bank, the CBS defines the population of Israel to also include Israeli settlers living in the Area C of West Bank and the Muslim residents of East Jerusalem and Area C, who have Israeli residency or citizenship.

Within Israel's system of local government, an urban municipality can be granted a city council by the Israeli Interior Ministry when its population exceeds 20,000. The term "city" does not generally refer to local councils or urban agglomerations, even though a defined city often contains only a small portion of an urban area or metropolitan area's population.

The most prominent ethnic and religious groups, who live in Israel at present and who are Israeli citizens or nationals, are as follows:

According to Israel's Central Bureau of Statistics, in 2008, of Israel's 7.3 million people, 75.6 percent were Jews of any background. Among them, 70.3 percent were Sabras (born in Israel), mostly second- or third-generation Israelis, and the rest are olim (Jewish immigrants to Israel)—20.5 percent from Europe and the Americas, and 9.2 percent from Asia and Africa, including the Arab countries. About 44.9% percent of Israel's Jewish population identify as either Mizrahi or Sephardi, 44.2% identify as Ashkenazi, about 3% as Beta Israel and 7.9% as mixed or other. 

The paternal lineage of the Jewish population of Israel as of 2015 is as follows:

Arab citizens of Israel are those Arab residents of Mandatory Palestine, who remained within Israel's borders following the 1948 Arab–Israeli War, and the establishment of the state of Israel. It is including those born within the state borders subsequent to this time, as well as those who had left during the establishment of the state (or their descendants), who have since re-entered by means accepted as lawful residence by the Israeli state (primarily family reunifications).

In 2019, the official number of Arab residents in Israel was 1,890,000 people, representing 21% of Israel's population. This figure includes 209,000 Arabs (14% of the Israeli Arab population) in East Jerusalem, also counted in the Palestinian statistics, although 98 percent of East Jerusalem Palestinians have either Israeli residency or Israeli citizenship.

Most Arab citizens of Israel are Muslim, particularly of the Sunni branch of Islam. A small minority are Ahmadiyya sect and there are also some Alawites (affiliated with Shia Islam) in the northernmost village of Ghajar with Israeli citizenship. As of 2019, Arab citizens of Israel comprised 21 percent of the country's total population. About 82 percent of the Arab population in Israel are Sunni Muslims, a very small minority are Shia Muslims, another 9 percent are Druze, and around 9 percent are Christian (mostly Eastern Orthodox and Catholic denominations).

The Arab Muslim citizens of Israel include also the Bedouins, who are divided into two main groups: the Bedouin in the north of Israel, who live in villages and towns for the most part, and the Bedouin in the Negev, who include half-nomadic and inhabitants of towns and Unrecognized villages. According to the Israeli Ministry of Foreign Affairs, as of 1999, 110,000 Bedouins live in the Negev, 50,000 in the Galilee and 10,000 in the central region of Israel. The vast majority of Arab Bedouins of Israel practice Sunni Islam.

The Ahmadiyya community was first established in the region in the 1920s, in what was then Mandatory Palestine. There is a large community in Kababir, a neighbourhood on Mount Carmel in Haifa. It is unknown how many Israeli Ahmadis there are, although it is estimated there are about 2,200 Ahmadis in Kababir alone.

As of December 2013, about 161,000 Israeli citizens practiced Christianity, together comprising about 2% of the total population. The largest group consists of Melkites (about 60% of Israel's Christians), followed by the Greek Orthodox (about 30%), with the remaining ca. 10% spread between the Roman Catholic (Latin), Maronite, Anglican, Lutheran, Armenian, Syriac, Ethiopian, Coptic and other denominations.

The Arab citizens of Israel include also the Druze, who numbered at an estimated 143,000 in April 2019. All of the Druze living in what was then British Mandate Palestine became Israeli citizens after the declaration of the State of Israel. Though a few individuals identify themselves as "Palestinian Druze", the vast majority of Druze do not consider themselves to be 'Palestinian', and consider their Israeli identity stronger than their Arab identity. Druze serve prominently in the Israel Defense Forces, and are represented in mainstream Israeli politics and business as well, unlike Muslim Arabs who are not required to and generally choose not to serve in the Israeli army.

In 2014, Israel decided to recognize the Aramaic community within its borders as a national minority, allowing some of the Christians in Israel to be registered as "Aramean" instead of "Arab". As of October 2014, some 600 Israelis requested to be registered as Arameans, with several thousand eligible for the status – mostly members of the Maronite community.

The Maronite Christian community in Israel of around 7,000 resides mostly in the Galilee, with a presence in Haifa, Nazareth and Jerusalem. It is largely composed of families that lived in Upper Galilee in villages such as Jish long before the establishment of Israel in 1948. In the year 2000, the community was joined by a group of Lebanese SLA militia members and their families, who fled Lebanon after 2000 withdrawal of IDF from South Lebanon.

There are around 1,000 Assyrians living in Israel, mostly in Jerusalem and Nazareth. Assyrians are an Aramaic speaking, Eastern Rite Christian minority who are descended from the ancient Mesopotamians. The old Syriac Orthodox monastery of Saint Mark lies in Jerusalem. Other than followers of the Syriac Orthodox Church, there are also followers of the Assyrian Church of the East and the Chaldean Catholic Church living in Israel.

Some 1,000 Israeli citizens belong to the Coptic community, originating in Egypt.

The Samaritans are an ethnoreligious group of the Levant. Ancestrally, they claim descent from a group of Israelite inhabitants who have connections to ancient Samaria from the beginning of the Babylonian Exile up to the beginning of the Common Era. 2007 population estimates show that 712 Samaritans live half in Holon, Israel and half at Mount Gerizim in the West Bank. The Holon community holds Israeli citizenship, while the Gerizim community resides at an Israeli controlled enclave, holding dual Israeli-Palestinian citizenship.

About 4,000 Armenians reside in Israel mostly in Jerusalem (including in the Armenian Quarter), but also in Tel Aviv, Haifa and Jaffa. Armenians have a Patriarchate in Jerusalem and churches in Jerusalem, Haifa and Jaffa. Although Armenians of Old Jerusalem have Israeli identity cards, they are officially holders of Jordanian passports.

In Israel, there are also a few thousand Circassians, living mostly in Kfar Kama (2,000) and Reyhaniye (1,000). These two villages were a part of a greater group of Circassian villages around the Golan Heights. The Circassians in Israel enjoy, like Druzes, a "status aparte". Male Circassians (at their leader's request) are mandated for military service, while females are not.

Ethnic Russians, Ukrainians, and Belorussians, immigrants from the former Soviet Union, who were eligible to emigrate due to having, or being married to somebody who has, at least one Jewish grandparent and thus qualified for Israeli citizenship under the revised Law of Return. A number of these immigrants also belong to various ethnic groups from the Former Soviet Union such as Armenians, Georgians, Azeris, Uzbeks, Moldovans, Tatars, among others. Some of them, having a Jewish father or grandfather, identify as Jews, but being non-Jewish by Orthodox Halakha (religious law), they are not recognized formally as Jews by the state. Most of them are in the mainstream of Israel culture and are called "expanded Jewish population". In addition, a certain number of former Soviet citizens, primarily women of Russian and Ukrainian ethnicity, emigrated to Israel, after marrying Muslim or Christian Arab citizens of Israel, who went to study in the former Soviet Union in the 1970s and 1980s. 1,557,698 people from the current Russia and Ukraine live in Israel.

Although most people of Finnish origin in Israel are Finnish Jews who immigrated to Israel, and their descendants, a small number of Finnish Christians moved to Israel in the 1940s before independence and gained citizenship following independence. For the most part, many of the original Finnish settlers intermarried with the other communities in the country, and therefore remain very small in number. A Moshav shitufi near Jerusalem named Yad HaShmona, meaning the "Memorial for the Eight", was established in 1971 by a group of Finnish Christian-Israelis, although today, most members are Israeli, and are predominantly Hebrew speakers, and the moshav has become a center of Messianic Jews.

The Bahá'í population in Israel is almost entirely made up of volunteers serving at the Bahá'í World Centre. Bahá'u'lláh (1817–1892), the Faith's founder, was banished to Akka and died nearby where his shrine is located. During his lifetime he instructed his followers not to teach and convert those living in the area, and the Bahá'ís descending from those original immigrants were later asked to leave and teach elsewhere. For nearly a century there has been a policy by Shoghi Effendi and later the Universal House of Justice to not accept converts from Israel. The 650 or so foreign national Bahá'ís living in Israel are almost all on temporary duty serving at the shrines and administrative offices. A fluctuating segment of Baha'is consists of pilgrims.

The number of Vietnamese people in Israel and their descendants is estimated at 150 to 200. Most of them came to Israel in between 1976–1979, after prime minister Menachem Begin authorized their admission to Israel and granted them political asylum. The Vietnamese people living in Israel are Israeli citizens who also serve in the Israel Defense Forces. Today, the majority of the community lives in the Gush Dan area in the center of Tel Aviv, but also a few dozen Vietnamese-Israelis or Israelis of Vietnamese origin live in Haifa, Jerusalem, and Ofakim.

The African Hebrew Israelite Nation of Jerusalem is a religious sect of blacks Americans, founded in 1960 by Ben Carter a metal worker in Chicago. The members of this sect believe they are descended from the tribes of Judah driven from the Holy Land by the Romans during the First Jewish War (70 AD), and who reportedly emigrated to West Africa before being taken as slaves to the United States. With a population of over 5,000, most members live in their own community in Dimona, Israel, with additional families in Arad, Mitzpe Ramon, and the Tiberias area. The group believes that the ancient Israelites are the ancestors of black Americans and that the actual Jews are "impostors". All scholarship does consider them to be of subsaharan African origin as the genetic studies on black American have shown too and not from levantine one. Their ancestors were black Americans who after being expelled from Liberia have illegally immigrated to Israel in the late 1960s by using tourist visas, requesting that Israel provide them legal citizenship status. Israel granted their requests. The African Hebrew Israelites, like the Haredim and most Israeli Arabs, are not required to serve in the military; however, some do so.

Some naturalized foreign workers and their children born in Israel, predominantly from the Philippines, Nepal, Nigeria, Senegal, Romania, China, Cyprus, Thailand, and South America (mainly Colombia).

The number and status of African migrants in Israel is disputed and controversial, but it is estimated that at least 70,000 refugees mainly from Eritrea, Sudan, South Sudan, Ethiopia, and the Ivory Coast reside and work in Israel. A count in late 2011 published in Ynet pointed out the number only in Tel Aviv is 40,000, which represents 10 percent of the city's population. The vast majority live in the southern parts of the city. There is a significant population in the southern Israeli cities of Eilat, Arad, and Beersheba.

There are around 300,000 foreign workers, residing in Israel under temporary work visas, including Palestinians. Most of those foreign workers engage in agriculture and construction. The main groups of those foreign workers include the Chinese, Thai, Filipinos, Nigerians, Romanians, and Latin Americans.

Approximately 100–200 refugees from Bosnia, Kosovo, Iraqi Kurdistan, and North Korea were absorbed in Israel as refugees. Most of them were also given Israeli resident status, and currently reside in Israel. As of 2006, some 200 ethnic Kurdish refugees from Turkey resided in Israel as illegal immigrants, fleeing the Kurdish–Turkish conflict.

Due to its immigrant nature, Israel is one of the most multicultural and multilingual societies in the world. Hebrew is the official language of the country, and Arabic is given special status, while English and Russian are the two most widely spoken non-official languages. A certain degree of English is spoken widely, and is the language of choice for many Israeli businesses. Hebrew and English language are mandatory subjects in the Israeli school system, and most schools offer either Arabic, French, Spanish, German, Italian, or Russian.

According to a 2010 Israel Central Bureau of Statistics study of Israelis aged over 18, 8% of Israeli Jews define themselves as "Haredim" (or ultra-Orthodox); an additional 12% are "religious" (non-Haredi Orthodox, also known as: dati leumi/national-religious or religious Zionist); 13% consider themselves "religious-traditionalists" (mostly adhering to Jewish Halakha); 25% are "non-religious traditionalists" (only partly respecting the Jewish Halakha), and 43% are "secular".

While the ultra-Orthodox, or Haredim, represented only 5% of Israel's population in 1990, they are expected to represent more than one-fifth of Israel's Jewish population by 2028. By 2020, they were 12% of the population.

Education between ages 5 and 15 is compulsory. It is not free, but it is subsidized by the government, individual organizations (such as the Beit Yaakov System), or a combination. Parents are expected to participate in courses as well. The school system is organized into kindergartens, 6-year primary schools, and either 6-year secondary schools or 3-year junior secondary schools + 3-year senior secondary schools (depending on region), after which a comprehensive examination is offered for university admissions.

As Israel's continued existence as a Jewish state relies upon maintenance of a Jewish demographic majority, Israeli demographers, politicians, and bureaucrats have treated Jewish population growth promotion as a central question in their research and policymaking. Non-Jewish population growth and immigration is regarded as a threat to the Jewish demographic majority, and to Israel's security , as detailed in the Koenig Memorandum.

Israel is the eighteenth-most-densely-crowded country in the world. In an academic article, Jewish National Fund Board member Daniel Orenstein, argues that, as elsewhere, overpopulation is a stressor on the environment in Israel; he shows that environmentalists have conspicuously failed to consider the impact of population on the environment, and argues that overpopulation in Israel has not been appropriately addressed for ideological reasons.

The Citizenship and Entry into Israel Law (Temporary Order) 5763 was first passed on 31 July 2003, and has since been extended until 31 July 2008. The law places age restrictions for the automatic granting of Israeli citizenship and residency permits to spouses of Israeli citizens, such that spouses who are inhabitants of the West Bank and Gaza Strip are ineligible. On 8 May 2005, the Israeli ministerial committee for issues of legislation once again amended the Citizenship and Entry into Israel Law, to restrict citizenship and residence in Israel only to Palestinian men over the age of 35, and Palestinian women over the age of 25. Those in favor of the law say the law not only limits the possibility of the entrance of terrorists into Israel, but, as Ze'ev Boim asserts, allows Israel "to maintain the state's democratic nature, but also its Jewish nature" (i. e., its Jewish demographic majority). Critics, including the United Nations Committee on the Elimination of Racial Discrimination, say the law disproportionately affects Arab citizens of Israel, since Arabs in Israel are far more likely to have spouses from the West Bank and Gaza Strip than other Israeli citizens.

In the constitutional challenges to the Citizenship and Entry to Israel Law, the state, represented by the Attorney General, insisted that security was the only objective behind the law. The state also added that even if the law was intended to achieve demographic objectives, it is still in conformity with Israel's Jewish and democratic definition, and thus constitutional. In a 2012 ruling by the Supreme Court on the issue, some of the judges on the panel discussed demography, and were inclined to accept that demography is a legitimate consideration in devising family reunification policies that violate the right to family life.

During the 1970s about 163,000 people of Jewish descent immigrated to Israel from the USSR.

Later Ariel Sharon, in his capacity as Minister of Housing & Construction and member of the Ministerial Committee for Immigration & Absorption, launched an unprecedented large-scale construction effort to accommodate the new Russian population in Israel so as to facilitate their smooth integration and encourage further Jewish immigration as an ongoing means of increasing the Jewish population of Israel. Between 1989 and 2006, about 979,000 Jews emigrated from the former Soviet Union to Israel.

"Note:" includes over 200,000 Israelis and 250,000 Arabs in East Jerusalem, about 421,400 Jewish settlers on the West Bank (Judea and Samaria), and about 42,000 in the Golan Heights (July 2007 estimate). Does not include Arab populations in the West Bank and Gaza Strip. Does not include 222,000 foreigners living in the country.

Total:

Jews:

Arab:


The Jewish median age in Jerusalem district and the West Bank are 24.9 and 19.7, respectively, and both account for 16% of the Jewish population, but 24% of 0–4-year olds. The lowest median age in Israel, and one of the lowest in the world, is found in two of the West Bank's biggest Jewish cities: Modi'in Illit (11), Beitar Illit (11) followed by Bedouin towns in the Negev (15.2).


During the 1990s, the Jewish population growth rate was about 3% per year, as a result of massive immigration to Israel, primarily from the republics of the former Soviet Union. There is also a very high population growth rate among certain Jewish groups, especially adherents of Orthodox Judaism. The growth rate of the Arab population in Israel is 2.2%, while the growth rate of the Jewish population in Israel is 1.8%. The growth rate of the Arab population has slowed from 3.8% in 1999 to 2.2% in 2013, and for the Jewish population, the growth rate declined from 2.7% to its lowest rate of 1.4% in 2005. Due to a rise in fertility of the Jewish population since 1995 and immigration, the growth rate has since risen to 1.8%.

IV/2016-III/2017


Births, in absolute numbers, by mother's religion
Current natural population growth:


Between the mid-1980s and 2000, the fertility rate in the Muslim sector was stable at 4.6–4.7 children per woman; after 2001, a gradual decline became evident, reaching 3.51 children per woman in 2011. By point of comparison, in 2011, there was a rising fertility rate of 2.98 children among the Jewish population.

(p) = preliminar results

Births

Deaths

Natural increase


There were a total of 38,666 deaths in 2006. (39,026 in 2005 & 37,688 in 2000). Of this 33,568 were Jews (34,031 in 2005 & 33,421 in 2000). 3,078 were Muslims (2,968 in 2005 & 2,683 in 2000). 360 were Druze (363 in 2005 & 305 in 2000). 712 were Christian (686 in 2005 & 666 in 2000).


There were a total of 28,629 immigrants who made Aliyah to Israel in 2019 (jan-oct):

12,722 from Russia; 5,247 from Ukraine; 2,470 from the United States; 276 from Canada; 143 from Australia;  1,996 from France;  469 from the UK; 350 from Brazil; 321 from South Africa; 93 from Venezuela; 127 from Mexico; 143 from Turkey; 57 from Iran; 14 from Thailand and 5 from Japan.

For many years definitive data on Israeli emigration was unavailable. In "The Israeli Diaspora" sociologist Stephen J. Gold maintains that calculation of Jewish emigration has been a contentious issue, explaining, "Since Zionism, the philosophy that underlies the existence of the Jewish state, calls for return home of the world's Jews, the opposite movement—Israelis leaving the Jewish state to reside elsewhere—clearly presents an ideological and demographic problem."

In the past several decades, emigration (yerida) has seen a considerable increase. From 1990 to 2005, 230,000 Israelis left the country; a large proportion of these departures included people who initially immigrated to Israel and then reversed their course (48% of all post-1990 departures and even 60% of 2003 and 2004 departures were former immigrants to Israel). 8% of Jewish immigrants in the post-1990 period left Israel, while 15% of non-Jewish immigrants did. In 2005 alone, 21,500 Israelis left the country and had not yet returned at the end of 2006; among them 73% were Jews, 5% Arabs, and 22% "Others" (mostly non-Jewish immigrants, with Jewish ancestry, from USSR). At the same time, 10,500 Israelis came back to Israel after over one year abroad; 84% were Jews, 9% Others, and 7% Arabs.

According to the Israel Central Bureau of Statistics, as of 2005, 650,000 Israelis had left the country for over one year and not returned. Of them, 530,000 are still alive today. This number does not include the children born overseas. It should also be noted that Israeli law grants citizenship only to the first generation of children born to Israeli emigrants.

Geographic deployment:





The total fertility rate (TFR) of a population is the average number of children that an average woman would have, in her lifetime. 

Jewish total fertility rate increased by 10.2% during 1998–2009, and was recorded at 2.90 during 2009. During the same time period, Arab TFR decreased by 20.5%. Muslim TFR was measured at 3.73 for 2009. During 2000, the Arab TFR in Jerusalem (4.43) was higher than that of the Jews residing there (3.79). But as of 2009, Jewish TFR in Jerusalem was measured higher than the Arab TFR (2010: 4.26 vs 3.85, 2009: 4.16 vs 3.87). TFR for Arab residents in the West Bank was measured at 2.91 in 2013, while that for the Jewish residents was reported at 5.10 children per woman.

The ethnic group with highest recorded TFR is the Bedouin of Negev. Their TFR was reported at 10.06 in 1998, and 5.73 in 2009. TFR is also very high among Haredi Jews. For Ashkenazi Haredim, the TFR rose from 6.91 in 1980 to 8.51 in 1996. The figure for 2008 is estimated to be even higher. TFR for Sephardi/Mizrahi Haredim rose from 4.57 in 1980 to 6.57 in 1996.







Age 15 and over can read and write (2011 estimate):

In June 2013, the Central Bureau of Statistics released a demographic report, projecting that Israel's population would grow to 11.4 million by 2035, with the Jewish population numbering 8.3 million, or 73% of the population, and the Arab population at 2.6 million, or 23%. This includes some 2.3 million Muslims (20% of the population), 185,000 Druze, and 152,000 Christians. The report predicts that the Israeli population growth rate will decline to 1.4% annually, with growth in the Muslim population remaining higher than the Jewish population until 2035, at which point the Jewish population will begin growing the fastest.

In 2017, the Central Bureau of Statistics projected that Israel's population would rise to about 18 million by 2059, including 14.4 million Jews and 3.6 million Arabs. Of the Jewish population, about 5.25 million would be ultra-Orthodox Jews. Overall, the forecast projected that 49% of the population would be either ultra-Orthodox Jews (29%) and Arabs (20%). It also projected a population of 20 million in 2065.

Other forecasts project that Israel could have a population as high as 23 million, or even 36 million, by 2050.




</doc>
<doc id="14690" url="https://en.wikipedia.org/wiki?curid=14690" title="Economy of Israel">
Economy of Israel

The economy of Israel is a highly advanced free-market, primarily knowledge-based economy. Israel ranks 22 on the latest report of the UN's Human Development Index, which places it in the category of "Very Highly Developed", allowing the country to enjoy a higher standard of living than many Western countries. The prosperity of Israel's advanced economy allows the country to have a sophisticated welfare state, a modern infrastructure, and a high-technology sector competitively on par with Silicon Valley. Israel has the second-largest number of startup companies in the world after the United States, and the third-largest number of NASDAQ-listed companies after the U.S. and China. Intel, Microsoft, and Apple built their first overseas research and development facilities in Israel, and other high-tech multi-national corporations, such as IBM, Google, HP, Cisco Systems, Facebook and Motorola have opened R&D centres in the country.

The country's major economic sectors are high-technology and industrial manufacturing; the Israeli diamond industry is one of the world's centers for diamond cutting and polishing, amounting to 23.2% of all exports. Relatively poor in natural resources, Israel depends on imports of petroleum, raw materials, wheat, motor vehicles, uncut diamonds and production inputs, though the country's nearly total reliance on energy imports may change in the future with recent discoveries of natural gas reserves off its coast on the one hand and the leading role of the Israeli solar energy industry on the other.

Israel's quality university education and the establishment of a highly motivated and educated populace is largely responsible for ushering in the country's high technology boom and rapid economic development. With its strong educational infrastructure and high quality incubation system for new cutting edge ideas to create value driven goods and services has allowed the country to create a high concentration of high-tech companies across the country financially backed by a strong venture capital industry. Its central high technology hub "Silicon Wadi" is considered second in importance only to its Californian counterpart. Numerous Israeli companies have been acquired by global corporations for their reliable and quality corporate personnel.

With such an impressive track record for creating profit driven technologies, Israel has become the first choice for many of world's leading entrepreneurs, investors, and industry giants. The economic dynamism of Israel has attracted attention from international business leaders such as Microsoft founder Bill Gates, investor Warren Buffett, real estate developer and U.S. President Donald Trump and telecommunications giant Carlos Slim. Each entrepreneur has praised Israel's economy and invested heavily across numerous Israeli industries beyond their traditional business activities and investments back in their home nations. In 2007, American investor Warren Buffett's holding company Berkshire Hathaway bought an Israeli company, Iscar, its first acquisition outside the United States, for $4 billion. The country was also the destination for Berkshire Hathaway's first investment outside the United States when it acquired ISCAR Metalworking.

In September 2010, Israel was invited to join the OECD. Israel has also signed free trade agreements with the European Union, the United States, the European Free Trade Association, Turkey, Mexico, Canada, Ukraine, Jordan, Egypt, and on 18 December 2007, became the first non-Latin-American country to sign a free trade agreement with the Mercosur trade bloc. Israel is also a major tourist destination, with 3.6 million foreign tourists visiting it in 2017.

The British Mandate of Palestine that came into effect in 1920 aimed at restricting land purchases by Jewish immigrants. For this reason the Jewish population was initially more urban and had a higher share in industrial occupations. This particular development resulted economically in one of the few growth miracles of the region whereby the structure of firms was determined mainly by private entrepreneurs rather than by the government.
The first survey of the Dead Sea in 1911, by the Russian Jewish engineer Moshe Novomeysky, led to the establishment of Palestine Potash Ltd. in 1930, later renamed the Dead Sea Works. In 1923, Pinhas Rutenberg was granted an exclusive concession for the production and distribution of electric power. He founded the Palestine Electric Company, later the Israel Electric Corporation. Between 1920 and 1924, some of the countries largest factories were established, including the Shemen Oil Company, the Societe des Grand Moulins, the Palestine Silicate Company and the Palestine Salt Company. 

In 1937, there were 86 spinning and weaving factories in the country, employing a workforce of 1,500. Capital and technical expertise were supplied by Jewish professionals from Europe. The Ata textile plant in Kiryat Ata, which went on to become an icon of the Israeli textile industry, was established in 1934.In 1939, the cornerstone was laid for one of the kibbutz industry's first factories: the Naaman brick factory, which supplied the growing need for construction materials.

Industry underwent rapid development during World War II, when supplies from Europe were cut off while local manufacturers were commissioned for army needs. By 1943, the number of factories had grown to 250, with a workforce of 5,630, and output increased tenfold.

From 1924, trade fairs were held in Tel Aviv. The Levant Fair was inaugurated in 1932.

After statehood, Israel faced a deep economic crisis. As well as having to recover from the devastating effects of the 1948 Arab–Israeli War, it also had to absorb hundreds of thousands of Jewish refugees from Europe and almost a million from the Arab world. Israel was financially overwhelmed and faced a deep economic crisis, which led to a policy of austerity from 1949 to 1959. Unemployment was high, and foreign currency reserves were scarce.

In 1952, Israel and West Germany signed an agreement stipulating that West Germany was to pay Israel for the persecution of Jews during the Holocaust, and compensate for Jewish property stolen by the Nazis. Over the next 14 years, West Germany paid Israel 3 billion marks (equivalent to US$111.5bn in modern currency). The reparations became a decisive part of Israel's income, comprising as high as 87.5% of Israel's income in 1956. In 1950, the Israeli government launched Israel Bonds for American and Canadian Jews to buy. In 1951, the final results of the bonds program exceeded $52 million. Additionally, many American Jews made private donations to Israel, which in 1956 were thought to amount to $100 million a year. In 1957, bond sales amounted to 35% of Israel's special development budget. Later in the century Israel became significantly reliant on economic aid from the United States, a country which also became Israel's most important source of political support internationally.

The proceeds from these sources was invested in industrial and agricultural development projects, which allowed Israel to become economically self-sufficient. Among the projects made possible by the aid was the Hadera power plant, the Dead Sea Works, the National Water Carrier, port development in Haifa, Ashdod, and Eilat, desalination plants, and national infrastructure projects.

After statehood, priority was given to establishing industries in areas slated for development, among them Lachish, Ashkelon, the Negev and Galilee. The expansion of Israel's textile industry was a consequence of the development of cotton growing as a profitable agricultural branch. By the late 1960s, textiles were one of the largest industrial branches in Israel, second only to the foodstuff industry. Textiles constituted about 12% of industrial exports, becoming the second-largest export branch after polished diamonds. In the 1990s, cheap East Asian labor decreased the profitability of the sector. Much of the work was subcontracted to 400 Israeli Arab sewing shops. As these closed down, Israeli firms, among them Delta, Polgat, Argeman and Kitan, began doing their sewing work in Jordan and Egypt, usually under the QIZ arrangement. In the early 2000s, Israeli companies had 30 plants in Jordan. Israeli exports reached $370 million a year, supplying such retailers and designers as Marks & Spencer, The Gap, Victoria's Secret, Walmart, Sears, Ralph Lauren, Calvin Klein, and Donna Karan.

In its first two decades of existence, Israel's strong commitment to development led to economic growth rates that exceeded 10% annually. Between 1950 and 1963, the expenditure among wage-earner's families rose 97% in real terms. Between 1955 and 1966, per capita consumption rose by 221%. The years after the 1973 Yom Kippur War were a lost decade economically, as growth stalled, inflation soared and government expenditures rose significantly. Also worthy of mention is the 1983 Bank stock crisis. By 1984, the economic situation became almost catastrophic with inflation reaching an annual rate close to 450% and projected to reach over 1000% by the end of the following year. However, the successful economic stabilization plan implemented in 1985 and the subsequent introduction of market-oriented structural reforms reinvigorated the economy and paved the way for its rapid growth in the 1990s and became a model for other countries facing similar economic crises.
Two developments have helped to transform Israel's economy since the beginning of the 1990s. The first is waves of Jewish immigration, predominantly from the countries of the former USSR, that has brought over one million new citizens to Israel. These new Soviet Jewish immigrants, many of them highly educated, had a wellspring of scientific and technical expertise to help spur Israel's burgeoning technology sector, now constitute some 15% of Israel's population. The second development benefiting the Israeli economy is the peace process begun at the Madrid conference of October 1991, which led to the signing of accords and later to a peace treaty between Israel and Jordan (1994).

In the early 2000s, the Israel economy went into a downturn due to the crashing of the global dot-com bubble which bankrupted many startups established during the height of the bubble. The Second Intifada, which cost Israel billions of dollars in security costs, and a decline in investment and tourism, sent unemployment in Israel to the double digits, growth in one quarter of 2000 was 10%. In 2002 the Israeli economy declined in one quarter about 4%. Afterwards Israel managed to create a remarkable recovery by opening up new markets to Israeli exporters farther afield, such as in the rapidly growing countries of East Asia. As well as a rebound in the tech sector with the gradual bottoming out of the dotcom crash and global increase in internet usage worldwide which created a demand for software, and a demand post-9/11 in Security and defense products. Both of which Israel was ready to provide due to early investment in those fields, allowed for a gradual easing of the unemployment situation within the country.

In the past few years there has been an unprecedented inflow of foreign investment in Israel, as companies that formerly shunned the Israeli market now see its potential contribution to their global strategies. In 2006, foreign investment in Israel totaled $13 billion, according to the Manufacturers Association of Israel. The "Financial Times" said that 'bombs drop, yet Israel's economy grows'. Moreover, while Israel's total gross external debt is US$95 billion, or approximately 41.6% of GDP, since 2001 it has become a net lender nation in terms of net external debt (the total value of assets vs. liabilities in debt instruments owed abroad), which stood at a significant surplus of US$60 billion. The country also maintains a current account surplus in an amount equivalent to about 3% of its gross domestic product in 2010.
The Israeli economy withstood the late-2000s recession, registering positive GDP growth in 2009 and ending the decade with an unemployment rate lower than that of many western countries. There are several reasons behind this economic resilience, for example, the fact, as stated above, that the country is a net lender rather than a borrower nation and the government and the Bank of Israel's generally conservative macro-economic policies. Two policies in particular can be cited, one is the refusal of the government to succumb to pressure by the banks to appropriate large sums of public money to aid them early in the crisis, thus limiting their risky behavior. The second is the implementation of the recommendations of the Bach'ar commission in the early to mid-2000s which recommended decoupling the banks' depository- and Investment banking activities, contrary to the then-opposite trend, particularly in the United States, of easing such restrictions which had the effect of encouraging more risk-taking in the financial systems of those countries.

In May 2007, Israel was invited to open accession discussions with the OECD. In May 2010, the OECD voted unanimously to invite Israel to join, despite Palestinian objections. It became a full member on 7 September 2010. The OECD praised Israel's scientific and technological progress and described it as having "produced outstanding outcomes on a world scale."

Despite economic prosperity, the Israeli economy faces many challenges, some are short term and some are long term challenges. On the short term its inability to duplicate its success in the telecommunication industry into other growing industries hampers its economic outlooks. Its inability to foster large multinational companies in the last decade also calls into question its ability to employ large numbers of people in advanced industries. On the long term, Israel is facing challenges of high dependency of the growing number of Ultra-Orthodox Jews who have a low level of official labor force participation amongst men, and this situation could lead to a materially lower employment-to-population ratio and a higher dependency ratio in the future. The governor of the Bank of Israel, Stanley Fischer, stated that the growing poverty amongst the Ultra-Orthodox is hurting the Israeli economy. According to the data published by Ian Fursman, 60% of the poor households in Israel are of the Haredi Jews and the Israeli Arabs. Both groups together represent 25–28% of the Israeli population. Organizations such as The Kemach Foundation, Gvahim, Jerusalem Village and The Jerusalem Business Networking Forum are addressing these challenges with job placement services and networking events.

The following table shows the main economic indicators in 1980–2018. Inflation under 2% is in green.
In 2017, 2.3% of the country's GDP is derived from agriculture. Of a total labor force of 2.7 million, 2.6% are employed in agricultural production while 6.3% in services for agriculture. While Israel imports substantial quantities of grain (approximately 80% of local consumption), it is largely self-sufficient in other agricultural products and food stuffs. For centuries, farmers of the region have grown varieties of citrus fruits, such as grapefruit, oranges and lemons. Citrus fruits are still Israel's major agricultural export. In addition, Israel is one of the world's leading greenhouse-food-exporting countries. The country exports more than $1.3 billion worth of agricultural products every year, including farm produce as well as $1.2 billion worth of agricultural inputs and technology.

Israel has over 100 active venture capital funds operating throughout the country with US$10 billion under management. In 2004, international foreign funds from various nations around the world committed over 50 percent of the total dollars invested exemplifying the country's strong and sound reputation as an internationally sought after foreign investment by many countries. Israel's venture capital sector has rapidly developed from the early 1990s, and has about 70 active venture capital funds (VC), of which 14 international VCs have Israeli offices. Israel's thriving venture capital and business-incubator industry played an important role in financing the country's flourishing high-tech sector. In 2008, venture capital investment in Israel, rose 19 percent to $1.9 billion.

"Between 1991 and 2000, Israel's annual venture-capital outlays, nearly all private, rose nearly 60-fold, from $58 million to $3.3 billion; companies launched by Israeli venture funds rose from 100 to 800; and Israel's information-technology revenues rose from $1.6 billion to $12.5 billion. By 1999, Israel ranked second only to the United States in invested private-equity capital as a share of GDP. Israel led the world in the share of its growth attributable to high-tech ventures: 70 percent."

Israel's thriving venture capital industry has played an important role in funding the country's booming high-technology sector. The country is now teeming with hundreds of prosperous Israeli private equity and venture capital firms looking to invest in the next potential million or billion dollar business startup. Many of Israel's venture capital firms have billions of dollars under management that are seeking to invest in domestic Israeli companies in order to create value by marking a strong presence across the country. The financial crisis of 2007–08 also affected the availability of venture capital locally. In 2009, there were 63 mergers and acquisitions in the Israeli market worth a total of $2.54 billion; 7% below 2008 levels ($2.74 billion), when 82 Israeli companies were merged or acquired, and 33% lower than 2007 proceeds ($3.79 billion) when 87 Israeli companies were merged or acquired. Numerous Israeli high tech companies have been acquired by global corporations for its reliable corporate management and quality personnel. In addition to venture capital funds, many of the world's leading investment banks, pension funds, and insurance companies have a strong presence in Israel committing their funds to financially back Israeli high-tech firms and benefit from its prosperous high tech sector. These institutional investors include Goldman Sachs, Bear Stearns, Deutsche Bank, JP Morgan, Credit Swiss First Boston, Merrill Lynch, CalPERS, Ontario Teachers Pension Plan, and AIG.

Israel also has a small but fast growing hedge fund industry. Within five years between 2007 and 2012, the number of active hedge funds have doubled to 60 while the total asset values that the funds control have quadrupled in the same period . Israel based hedge funds have registered an increase of 162% since 2006 and currently manage a total of $2 billion (₪8 billion) as well as employing about 300 people. The ever-growing hedge fund industry in Israel is also attracting a myriad of investors from around the world, particularly from the United States.

Science and technology in Israel is one of the country's most highly developed and industrialized sectors. The modern Israeli ecosystem of high technology is highly optimized making up a significant bulk of Israeli economy. The percentage of Israelis engaged in scientific and technological inquiry, and the amount spent on research and development (R&D) in relation to gross domestic product (GDP), is among the highest in the world. Israel ranks fourth in the world in scientific activity, as measured by the number of scientific publications per million citizens. Israel's percentage of the total number of scientific articles published worldwide is almost 10 times higher than its percentage of the world's population. Despite its small population relative to other industrialized nations around the world, Israel has the highest number of scientists and technicians per capita in the world with 140 scientists and technicians per 10,000 employees. In comparison, the same is 85 per 10,000 in the United States and 83 per 10,000 in Japan.

Israeli scientists, engineers, and technicians have contributed to the modern advancement of the natural sciences, agricultural sciences, computer sciences, electronics, genetics, medicine, optics, solar energy and various fields of engineering. Israel is home to major corporate players in the high-tech industry and has one of the world's technologically most literate populations. In 1998, Tel Aviv was named by "Newsweek" as one of the ten technologically most influential cities in the world. In 2012, the city was also named one of the best places for high-tech startup companies, placed second behind its California counterpart.
In 2013, Tel Aviv repeated the feat where the American newspaper, Boston Globe ranked Tel Aviv as the second best city for business start-ups, after Silicon Valley Israel has the largest number of startup companies globally, second only to the United States and remains one of the largest centers in the world for technology start-up enterprises. 200 start-ups are created annually and more than 2500 start-up companies are operating throughout the country.

As a result of the country's highly renowned and creative start-up culture, Israel is often referred to as the Start-up Nation (adapted from the book Start-Up Nation, by Dan Senor and Saul Singer) and the "Silicon Valley of the Middle East". There are even numerous programs that send people to Israel to explore the "Start-Up Nation" economy (such as TAVtech Ventures and TAMID Group). This success has been attributed by some to the IDF and its development of talent which then fuels the high-tech industry upon discharge, but entrepreneur Inbal Arieli suggests in her work that characteristics inherent to Israeli culture and the way Israeli children are raised also plays a significant role.

In recent years, the industry has faced some challenges, and the further growth of the industry depends on overcoming them. Now high technology sector is rapidly growing and demand for tech talent increasing as well. There are not enough specialists in the market and in particular, 15% of positions in the high technology sector of Israel remain unfilled. However, the largest number of unfilled positions (31%) are in software engineering specialties: DevOps, back-end, data science, machine learning and artificial intelligence. Therefore, salaries of specialists in the Israeli market also increased significantly. To solve this problem, IT companies look for filling the gaps abroad. Consequently, they employ about 25% of their entire workforce overseas. Most companies choose to hire employees from Ukraine (45%) and USA (with 16%) are the second most popular offshoring destination country. Thus, to keep the industry growing, Israel should overcome this force labour shortage. Actually, Israel's Council for Higher Education has already launched a five-years program to increase the number of graduates from computer science and engineering programs by 40%.

Historically, Israel relied on external imports for meeting most of its energy needs, spending an amount equivalent to over 5% of its GDP per year in 2009 on imports of energy products. The transportation sector relies mainly on gasoline and diesel fuel, while the majority of electricity production is generated using imported coal. As of 2013, Israel was importing about 100 mln barrels of oil per year. The country possesses negligible reserves of crude oil but does have domestic natural gas resources which were discovered in more significant quantities starting in 2009, after many decades of previously unsuccessful exploration.

Until the early 2000s, natural gas use in Israel was minimal. In the late 1990s, the government of Israel decided to encourage the usage of natural gas because of environmental, cost, and resource diversification reasons. At the time however, there were no domestic sources of natural gas and the expectation was that gas would be supplied from overseas in the form of LNG and by a future pipeline from Egypt (which eventually became the Arish–Ashkelon pipeline). Plans were made for the Israel Electric Corporation to construct several natural gas-driven power plants, for erecting a national gas distribution grid, and for an LNG import terminal.

In 2000, a modest discovery was made when a 33-billion-cubic-metre (BCM), or 1,200-billion-cubic-foot, natural-gas field was located offshore Ashkelon, with commercial production starting in 2004. however, this field is nearly depleted—earlier than expected due to increased pumping to partially compensate for the loss of imported Egyptian gas in the wake of unrest associated with the fall of the Mubarak regime in 2011. In 2009, a significant gas find named Tamar, with proven reserves of 223 BCM or (307 BCM total proven + probable) was located in deep water approximately west of Haifa, as well as a smaller 15 BCM () field situated nearer the coastline. Furthermore, results of 3D seismic surveys and test drilling conducted since 2010 have confirmed that an estimated 621 BCM () natural-gas deposit named Leviathan exists in a large underwater geological formation nearby the large gas field already discovered in 2009.

The Tamar field began commercial production on 30 March 2013 after four years of development. The supply of gas from Tamar was expected to aid the Israeli economy, which had suffered losses of more than ₪20 billion between 2011 and 2013 resulting from the disruption of gas supplies from neighboring Egypt (and which are not expected to resume due to Egypt's decision to indefinitely suspend its gas supply agreement to Israel). As a result, Israel, as well as its other neighbor Jordan, which also suffered from disruption of gas deliveries from Egypt, had to resort to importing significantly more expensive and polluting liquid heavy fuels as substitute sources of energy. The ensuing energy crisis in Israel was lifted once the Tamar field came online in 2013, while Jordan committed to a US$10 billion, 15-year gas supply deal totaling 45 BCM from the Israeli Leviathan field which is scheduled to come online in late 2019. The agreement is estimated to save Jordan US$600 million per year in energy costs. In 2018, the owners of the Tamar and Leviathan fields announced that they are negotiating an agreement with a consortium of Egyptian firms for the supply of up to 64 BCM of gas over 10 years valued at up to US$15 billion. In early 2012 the Israeli cabinet announced plans to set up a sovereign wealth fund (called "the Israeli Citizens' Fund").

Since the founding of the state through the mid-2010s decade, the state-owned utility, Israel Electric Corporation (IEC) had an effective monopoly on power generation in the country. In 2010 the company sold 52,037 GWh of electricity. Until the mid-2010s the country also faced a persistently low operating reserve, which is mostly the result of Israel being an "electricity island". Most countries have the capability of relying on power drawn from producers in adjacent countries in the event of a power shortage. Israel's grid however, is unconnected to those of neighboring countries. This is mostly due to political reasons but also to the considerably less-developed nature of the power systems of Jordan and Egypt, whose systems constantly struggle to meet domestic demand and whose per-capita electric generation is less than one fifth that of Israel's. Nevertheless, while operating reserves in Israel were low, the country possessed sufficient generation and transmission capacity to meet domestic electricity needs and unlike in the countries surrounding it, rolling blackouts have historically been quite rare, even at periods of extreme demand.

Facing increasing demand for electricity and concerned about the low reserve situation, the government of Israel began taking steps to increase the supply of electricity and operating reserve, as well to reduce the monopoly position of the IEC and increase competition in the electricity market starting in second half of the 2000s decade. It instructed the IEC to construct several new power stations and encouraged private investment in the generation sector. By 2015, the IEC's share of total nationwide installed electric generation capacity had fallen to about 75%, with the company then possessing an installed generation capacity of about 13.6 gigawatts (GW). Since 2010, Independent Power Producers have constructed three new gas-fired combined cycle power stations with a total generation capacity of about 2.2 GW, while various industrial concerns constructed on-premises cogeneration facilities with a total electricity output of about 1 GW, and which are licensed by the electric authority to sell surplus electricity to the national grid at competitive rates. Also under construction is a 300 MW pumped storage facility, with two more in planning, plus several solar-powered plants.

In addition to the above steps, Israel and Cyprus are considering implementing the proposed EuroAsia Interconnector project. This consists of laying a 2000MW HVDC undersea power cable between them and between Cyprus and Greece, thus connecting Israel to the greater European power grid. If carried out, this will allow to further increase the country's operating reserve as well as sell surplus electricity abroad.

In 2016, total nationwide electricity production was 67.2 GWh, of which 55.2% was generated using natural gas and 43.8% using coal — the first time the share of electricity production using natural gas exceeded that generated using coal.

Solar power in Israel and the Israeli solar energy industry has a history that dates to the founding of the country. In the 1950s, Levi Yissar developed a solar water heater to help assuage an energy shortage in the new country. By 1967 around one in twenty households heated their water with the sun and 50,000 solar heaters had been sold. With the 1970s oil crisis, Harry Zvi Tabor, the father of Israel's solar industry, developed the prototype solar water heater that is now used in over 90% of Israeli homes. Israeli engineers are on the cutting edge of solar energy technology, and its solar companies work on projects around the world.

Israel has a large industrial capacity with a well-developed chemical industry with many of its products aimed at the export market. Most of the chemical plants are located in Ramat Hovav, the Haifa Bay area and near the Dead Sea. Israel Chemicals is one of largest fertilizer and chemical companies in Israel and its subsidiary, the Dead Sea Works in Sdom is the world's fourth largest producer and supplier of potash products. The company also produces other products such as magnesium chloride, industrial salts, de-icers, bath salts, table salt, and raw materials for the cosmetic industry. One of the country's largest employers is Israel Aerospace Industries which produces mainly aviation, space, and defense products. In 2017 the company had an order backlog of 11.4 billion US dollars. Another large employer is Teva Pharmaceutical Industries, one of the world's largest pharmaceutical companies, employing 40,000 people as of 2011. It specializes in generic and proprietary pharmaceuticals and active pharmaceutical ingredients. It is the largest generic drug manufacturer in the world and one of the 15 largest pharmaceutical companies worldwide. Industrial production of metals, electrical equipment, construction materials, consumer goods, and textiles, as well as food processing also form a significant part of the manufacturing sector.

Israel is one of the world's three major centers for polished diamonds, alongside Belgium and India. Israel's net polished diamond exports slid 22.8 percent in 2012 as polished diamond exports fell to $5.56 billion from $7.2 billion in 2011. Net exports of rough diamonds dropped 20.1 percent to $2.8 billion and net exports of polished diamonds slipped 24.9 percent to $4.3 billion, while net rough diamond imports dropped 12.9 percent to $3.8 billion. Net exports and imports have dropped due to the ongoing Global financial crisis, particularly within the Eurozone and the United States. The United States is the largest market accounting for 36% of overall export market for polished diamonds while Hong Kong remains at second with 28 percent and Belgium at 8 percent coming in third. , cut diamonds were Israel's largest export product, comprising 23.2% of all exports.

Israel is one of the world's major exporters of military equipment, accounting for 10% of the world total in 2007. Three Israeli companies were listed on the 2010 Stockholm International Peace Research Institute index of the world's top 100 arms-producing and military service companies: Elbit Systems, Israel Aerospace Industries and RAFAEL. The Defense industry in Israel is a strategically important sector and a large employer within the country. It is also a major player in the global arms market and is the 11th largest arms exporter in the world as of 2012. Total arms transfer agreements topped 12.9 billion between 2004 and 2011. There are over 150 active defense companies based in the country with combined revenues of more than US$3.5 billion annually. Israeli defense equipment exports have reached 7 billion U.S. dollars in 2012, making it a 20 percent increase from the amount of defense-related exports in 2011. Much of the exports are sold to the United States and Europe. Other major regions that purchase Israeli defense equipment include Southeast Asia and Latin America. India is also major country for Israeli arms exports and has remained Israel's largest arms market in the world. Israel is considered to be the leading UAV exporter in the world. According to the Stockholm International Peace Research Institute, Israeli defense companies were behind 41% of all drones exported in 2001–2011.

Tourism is one of Israel's major sources of income in the country, attracting 3.6 million foreign tourists in 2017, yielding a 25 percent growth since 2016 and contributed ₪20 billion to the Israeli economy making it an all-time record. The most popular paid site is Masada.

In 2016, Israeli goods exports totaled US$55.8 billion. It imported US$61.9 billion worth of goods in the same year. In 2017 total exports (goods and services) amounted to US$102.3 billion, while imports totaled $96.7 billion.
Israel usually posts a modest trade deficit in goods. Its main goods imports consist of raw materials, crude oil, production inputs and finished consumer goods. Most of its exports are high-value-added items such as electronic components and other high-technology equipment, tools, and machinery, cut diamonds, refined petrochemicals, and pharmaceuticals. It normally posts a substantial trade surplus in services thanks to tourism and service industries such as software development, engineering services, and biomedical and scientific research and development. Therefore, overall external trade is positive, contributing to a significant current account surplus which as of 2017 stood at 4.7% of GDP.
The United States is Israel's largest trading partner, and Israel is the United States' 26th-largest trading partner; two-way trade totaled some $24.5 billion in 2010, up from $12.7 billion in 1997. The principal U.S. exports to Israel include computers, integrated circuits, aircraft parts and other defense equipment, wheat, and automobiles. Israel's chief exports to the U.S. include cut diamonds, jewelry, integrated circuits, printing machinery, and telecommunications equipment. The two countries signed a free trade agreement (FTA) in 1985 that progressively eliminated tariffs on most goods traded between the two countries over the following ten years. An agricultural trade accord was signed in November 1996, which addressed the remaining goods not covered in the FTA. Some non-tariff barriers and tariffs on goods remain, however. Israel also has trade and cooperation agreements in place with the European Union and Canada, and is seeking to conclude such agreements with a number of other countries, including Turkey, Jordan and several countries in Eastern Europe.

In regional terms, the European Union is the top destination for Israeli exports. In the four-month period between October 2011 and January 2012, Israel exported goods totalling $5 billion to the EU – amounting to 35% of Israel's overall exports. During the same period, Israeli exports to East Asia and the Far East totaled some $3.1 billion.

Until 1995, Israel's trade with the Arab world was minimal due to the Arab League boycott, which was begun against the Jewish community of Palestine in 1945. Arab nations not only refused to have direct trade with Israel (the primary boycott), but they also refused to do business with any corporation that operated in Israel (secondary boycott), or any corporation that did business with a corporation that did business with Israel (tertiary boycott).

In 2013, commercial trade between Israel and the Palestinian territories were valued at US$20 billion annually.

In 2012, ten companies were responsible for 47.7% of Israel's exports. These companies were Intel Israel, Elbit Systems, Oil Refineries Ltd, Teva Pharmaceuticals, Iscar, Israel Chemicals, Makhteshim Agan, Paz Oil Company, Israel Aerospace Industries and the Indigo division of Hewlett-Packard. The Bank of Israel and Israel's Export Institute have warned that the country is too dependent on a small number of exporters.

The Global Competitiveness Report of 2016 to 2017 ranked Israel as having the world's second most innovative economy. It was also ranked 18th among 188 world nations on the UN's Human Development Index, which places it in the category of "Very Highly Developed." As of 2014, Israel ranks 19th out of 124 countries on the economic complexity index. The IMD World Competitiveness Yearbook of 2016 ranked Israel's economy as world 21st most competitive out of the 61 economies surveyed. The Israeli economy was ranked as the world's most durable economy in the face of crises, and was also ranked first in the rate research and development center investments. The Bank of Israel was ranked first among central banks for its efficient functioning, up from the 8th place in 2009. Israel was ranked first also in its supply of skilled manpower. Israeli companies, particularly in the high-tech area, have enjoyed considerable success raising money on Wall Street and other world financial markets: Israel ranked second among foreign countries in the number of its companies listed on U.S. stock exchanges.

Having moved away from the socialist economic model since the mid-1980s and early 1990s, Israel has made dramatic moves toward the free-market capitalist paradigm. , Israel's economic freedom score is 67.8, making its economy the 48th freest in the 2012 Index of Economic Freedom. Israel's economic competitiveness is helped by strong protection of property rights, relatively low corruption levels, and high openness to global trade and investment. Income and corporate tax rates remain relatively high. , Israel ranks 36th out of 182 countries in Transparency International's Corruption Perceptions Index. Bribery and other forms of corruption are illegal in Israel, which is a signatory to the OECD Bribery Convention since 2008.





</doc>
<doc id="14696" url="https://en.wikipedia.org/wiki?curid=14696" title="Israeli Declaration of Independence">
Israeli Declaration of Independence

The Israeli Declaration of Independence, formally the Declaration of the Establishment of the State of Israel (), was proclaimed on 14 May 1948 (5 Iyar 5708) by David Ben-Gurion, the Executive Head of the World Zionist Organization, Chairman of the Jewish Agency for Palestine, and soon to be first Prime Minister of Israel. It declared the establishment of a Jewish state in Eretz-Israel, to be known as the State of Israel, which would come into effect on termination of the British Mandate at midnight that day. The event is celebrated annually in Israel with a national holiday Independence Day on 5 Iyar of every year according to the Hebrew calendar.

The possibility of a Jewish homeland in Palestine had been a goal of Zionist organizations since the late 19th century. In 1917 British Foreign Secretary Arthur Balfour stated in a letter to British Jewish community leader Walter, Lord Rothschild that:

His Majesty's government view with favour the establishment in Palestine of a national home for the Jewish people, and will use their best endeavours to facilitate the achievement of this object, it being clearly understood that nothing shall be done which may prejudice the civil and religious rights of existing non-Jewish communities in Palestine, or the rights and political status enjoyed by Jews in any other country.

Through this letter, which became known as the Balfour Declaration, British government policy officially endorsed Zionism. After World War I, the United Kingdom was given a mandate for Palestine, which it had conquered from the Ottomans during the war. In 1937 the Peel Commission suggested partitioning Mandate Palestine into an Arab state and a Jewish state, though the proposal was rejected as unworkable by the government and was at least partially to blame for the renewal of the 1936–39 Arab revolt.
In the face of increasing violence after World War II, the British handed the issue over to the recently established United Nations. The result was Resolution 181(II), a plan to partition Palestine into "Independent Arab and Jewish States and the Special International Regime for the City of Jerusalem". The Jewish state was to receive around 56% of the land area of Mandate Palestine, encompassing 82% of the Jewish population, though it would be separated from Jerusalem. The plan was accepted by most of the Jewish population, but rejected by much of the Arab populace. On 29 November 1947, the resolution to recommend "to the United Kingdom, as the mandatory Power for Palestine, and to all other Members of the United Nations the adoption and implementation, with regard to the future government of Palestine, of the Plan of Partition with Economic Union" was put to a vote in the United Nations General Assembly.
The result was 33 to 13 in favour of the resolution, with 10 abstentions. Resolution 181(II): "PART I: Future constitution and government of Palestine: A. TERMINATION OF MANDATE, PARTITION AND INDEPENDENCE: Clause 3" provides:Independent Arab and Jewish States and the Special International Regime for the City of Jerusalem, ... shall come into existence in Palestine two months after the evacuation of the armed forces of the mandatory Power has been completed but in any case not later than 1 October 1948.

The Arab countries (all of which had opposed the plan) proposed to query the International Court of Justice on the competence of the General Assembly to partition a country, but the resolution was rejected.

The first draft of the declaration was made by Zvi Berenson, the legal advisor of the Histadrut trade union and later a Justice of the Supreme Court, at the request of Pinchas Rosen. A revised second draft was made by three lawyers, A. Beham, A. Hintzheimer and Z.E. Baker, and was framed by a committee including David Remez, Pinchas Rosen, Haim-Moshe Shapira, Moshe Sharett and Aharon Zisling. A second committee meeting, which included David Ben-Gurion, Yehuda Leib Maimon, Sharett and Zisling produced the final text.

On 12 May 1948, the Minhelet HaAm (, lit. "People's Administration") was convened to vote on declaring independence. Three of the thirteen members were missing, with Yehuda Leib Maimon and Yitzhak Gruenbaum being blocked in besieged Jerusalem, while Yitzhak-Meir Levin was in the United States.

The meeting started at 13:45 and ended after midnight. The decision was between accepting the American proposal for a truce, or declaring independence. The latter option was put to a vote, with six of the ten members present supporting it:

Chaim Weizmann, the Chairman of the World Zionist Organization, and soon to be first President of Israel, endorsed the decision, after reportedly asking "What are they waiting for, the idiots?"

The draft text was submitted for approval to a meeting of Moetzet HaAm at the JNF building in Tel Aviv on 14 May. The meeting started at 13:50 and ended at 15:00, an hour before the declaration was due to be made. Despite ongoing disagreements, members of the Council unanimously voted in favour of the final text. During the process, there were two major debates, centring on the issues of borders and religion.

The borders were not specified in the Declaration, although its 14th paragraph indicated a willingness to cooperate in the implementation of the UN Partition Plan. The original draft had declared that the borders would be decided by the UN partition plan. While this was supported by Rosen and Bechor-Shalom Sheetrit, it was opposed by Ben-Gurion and Zisling, with Ben-Gurion stating, "We accepted the UN Resolution, but the Arabs did not. They are preparing to make war on us. If we defeat them and capture western Galilee or territory on both sides of the road to Jerusalem, these areas will become part of the state. Why should we obligate ourselves to accept boundaries that in any case the Arabs don't accept?" The inclusion of the designation of borders in the text was dropped after the provisional government of Israel, the Minhelet HaAm, voted 5–4 against it. The Revisionists, committed to a Jewish state on both sides of the Jordan River (that is, including Transjordan), wanted the phrase "within its historic borders" included, but were unsuccessful.

The second major issue was over the inclusion of God in the last section of the document, with the draft using the phrase "and placing our trust in the Almighty". The two rabbis, Shapira and Yehuda Leib Maimon, argued for its inclusion, saying that it could not be omitted, with Shapira supporting the wording "God of Israel" or "the Almighty and Redeemer of Israel". It was strongly opposed by Zisling, a member of the secularist Mapam. In the end the phrase "Rock of Israel" was used, which could be interpreted as either referring to God, or the land of Eretz Israel, Ben-Gurion saying "Each of us, in his own way, believes in the 'Rock of Israel' as he conceives it. I should like to make one request: Don't let me put this phrase to a vote." Although its use was still opposed by Zisling, the phrase was accepted without a vote.

The writers also had to decide on the name for the new state. Eretz Israel, Ever (from the name Eber), Judea, and Zion were all suggested, as were Ziona, Ivriya and Herzliya. Judea and Zion were rejected because, according to the partition plan, Jerusalem (Zion) and most of the Judean mountains would be outside the new state. Ben-Gurion put forward "Israel" and it passed by a vote of 6–3. Official documents released in April 2013 by the State Archive of Israel show that days before the establishment of the State of Israel in May 1948, officials were still debating about what the new country would be called in Arabic: Palestine (فلسطين Filastin), Zion (صهيون Sayoun) or Israel (إسرائيل Eesra’il). Two assumptions were made: "That an Arab state was about to be established alongside the Jewish one in keeping with the UN’s partition resolution the year before, and that the Jewish state would include a large Arab minority whose feelings needed to be taken into account". In the end, the officials rejected the name Palestine because they thought that would be the name of the new Arab state and could cause confusion so they opted for the most straightforward option of Israel.

At the meeting on 14 May, several other members of Moetzet HaAm suggested additions to the document. Meir Vilner wanted it to denounce the British Mandate and military but Sharett said it was out of place. Meir Argov pushed to mention the Displaced Persons camps in Europe and to guarantee freedom of language. Ben-Gurion agreed with the latter but noted that Hebrew should be the main language of the state.

The debate over wording did not end completely even after the Declaration had been made. Declaration signer Meir David Loewenstein later claimed, "It ignored our sole right to Eretz Israel, which is based on the covenant of the Lord with Abraham, our father, and repeated promises in the Tanach. It ignored the aliya of the Ramban and the students of the Vilna Gaon and the Ba'al Shem Tov, and the [rights of] Jews who lived in the 'Old Yishuv'."

The ceremony was held in the Tel Aviv Museum (today known as Independence Hall) but was not widely publicised as it was feared that the British Authorities might attempt to prevent it or that the Arab armies might invade earlier than expected. An invitation was sent out by messenger on the morning of 14 May telling recipients to arrive at 15:30 and to keep the event a secret. The event started at 16:00 (a time chosen so as not to breach the sabbath) and was broadcast live as the first transmission of the new radio station Kol Yisrael.

The final draft of the declaration was typed at the Jewish National Fund building following its approval earlier in the day. Ze'ev Sherf, who stayed at the building in order to deliver the text, had forgotten to arrange transport for himself. Ultimately, he had to flag down a passing car and ask the driver (who was driving a borrowed car without a license) to take him to the ceremony. Sherf's request was initially refused but he managed to persuade the driver to take him. The car was stopped by a policeman for speeding while driving across the city though a ticket was not issued after it was explained that he was delaying the declaration of independence. Sherf arrived at the museum at 15:59.

At 16:00, Ben-Gurion opened the ceremony by banging his gavel on the table, prompting a spontaneous rendition of Hatikvah, soon to be Israel's national anthem, from the 250 guests. On the wall behind the podium hung a picture of Theodor Herzl, the founder of modern Zionism, and two flags, later to become the official flag of Israel.

After telling the audience "I shall now read to you the scroll of the Establishment of the State, which has passed its first reading by the National Council", Ben-Gurion proceeded to read out the declaration, taking 16 minutes, ending with the words "Let us accept the Foundation Scroll of the Jewish State by rising" and calling on Rabbi Fishman to recite the Shehecheyanu blessing.

As leader of the Yishuv, David Ben-Gurion was the first person to sign. The declaration was due to be signed by all 37 members of Moetzet HaAm. However, twelve members could not attend, with eleven of them trapped in besieged Jerusalem and one abroad. The remaining 25 signatories present were called up in alphabetical order to sign, leaving spaces for those absent. Although a space was left for him between the signatures of Eliyahu Dobkin and Meir Vilner, Zerach Warhaftig signed at the top of the next column, leading to speculation that Vilner's name had been left alone to isolate him, or to stress that even a communist had agreed with the declaration. However, Warhaftig later denied this, stating that a space had been left for him (as he was one of the signatories trapped in Jerusalem) where a Hebraicised form of his name would have fitted alphabetically, but he insisted on signing under his actual name so as to honour his father's memory and so moved down two spaces. He and Vilner would be the last surviving signatories, and remained close for the rest of their lives. Of the signatories, two were women (Golda Meir and Rachel Cohen-Kagan).

When Herzl Rosenblum, a journalist, was called up to sign, Ben-Gurion instructed him to sign under the name Herzl Vardi, his pen name, as he wanted more Hebrew names on the document. Although Rosenblum acquiesced to Ben-Gurion's request and legally changed his name to Vardi, he later admitted to regretting not signing as Rosenblum. Several other signatories later Hebraised their names, including Meir Argov (Grabovsky), Peretz Bernstein (then Fritz Bernstein), Avraham Granot (Granovsky), Avraham Nissan (Katznelson), Moshe Kol (Kolodny), Yehuda Leib Maimon (Fishman), Golda Meir (Meyerson/Myerson), Pinchas Rosen (Felix Rosenblueth) and Moshe Sharett (Shertok). Other signatories added their own touches, including Saadia Kobashi who added the phrase "HaLevy", referring to the tribe of Levi.

After Sharett, the last of the signatories, had put his name to paper, the audience again stood and the Israel Philharmonic Orchestra played "Hatikvah". Ben-Gurion concluded the event with the words "The State of Israel is established! This meeting is adjourned!"

The declaration was signed in the context of civil war between the Arab and Jewish populations of the Mandate that had started the day after the partition vote at the UN six months earlier. Neighbouring Arab states and the Arab League were opposed to the vote and had declared they would intervene to prevent its implementation. In a on 15 May 1948 to the Secretary-General of the United Nations, the Secretary-General of the League of Arab States claimed that "the Arab states find themselves compelled to intervene in order to restore law and order and to check further bloodshed".

Over the next few days after the declaration, armies of Egypt, Trans-Jordan, Iraq, and Syria engaged Israeli troops inside the area of what had just ceased to be Mandatory Palestine, thereby starting the 1948 Arab–Israeli War. A truce began on 11 June, but fighting resumed on 8 July and stopped again on 18 July, before restarting in mid-October and finally ending on 24 July 1949 with the signing of the armistice agreement with Syria. By then Israel had retained its independence and increased its land area by almost 50% compared to the 1947 UN Partition Plan.

Following the declaration, Moetzet HaAm became the Provisional State Council, which acted as the legislative body for the new state until the first elections in January 1949.

Many of the signatories would play a prominent role in Israeli politics following independence; Moshe Sharett and Golda Meir both served as Prime Minister, Yitzhak Ben-Zvi became the country's second president in 1952, and several others served as ministers. David Remez was the first signatory to pass away, dying in May 1951, while Meir Vilner, the youngest signatory at just 29, was the longest living, serving in the Knesset until 1990 and dying in June 2003. Eliyahu Berligne, the oldest signatory at 82, died in 1959.

Eleven minutes after midnight, the United States "de facto" recognized the State of Israel. This was followed by Iran (which had voted against the UN partition plan), Guatemala, Iceland, Nicaragua, Romania, and Uruguay. The Soviet Union was the first nation to fully recognize Israel de jure on 17 May 1948, followed by Poland, Czechoslovakia, Yugoslavia, Ireland, and South Africa. The United States extended official recognition after the first Israeli election, as Truman had promised on 31 January 1949. By virtue of General Assembly Resolution 273 (III), Israel was admitted to membership in the United Nations on 11 May 1949.

In the three years following the 1948 Palestine war, about 700,000 Jews immigrated to Israel, residing mainly along the borders and in former Arab lands. Around 136,000 were some of the 250,000 displaced Jews of World War II. And from the 1948 Arab–Israeli War until the early 1970s, 800,000–1,000,000 Jews left, fled, or were expelled from their homes in Arab countries; 260,000 of them reached Israel between 1948 and 1951; and 600,000 by 1972.

At the same time, a large number of Arabs left, fled or were expelled from, what became Israel. In the "Report of the Technical Committee on Refugees (Submitted to the United Nations Conciliation Commission for Palestine in Lausanne on 7 September 1949) – (A/1367/Rev.1)", in paragraph 15, the estimate of the statistical expert, which the Committee believed to be as accurate as circumstances permitted, indicated that the number of refugees from Israel-controlled territory amounted to approximately 711,000.

Paragraph 13 of the Declaration provides that the State of Israel would "be based on freedom, justice and peace as envisaged by the prophets of Israel; it will ensure complete equality of social and political rights to all its inhabitants irrespective of religion, race or sex;". However, the Knesset maintains that the declaration is neither a law nor an ordinary legal document. The Supreme Court has ruled that the guarantees were merely guiding principles, and that the declaration is not a constitutional law making a practical ruling on the upholding or nullification of various ordinances and statutes.

In 1994 the Knesset amended two basic laws, and Freedom of Occupation, introducing (among other changes) a statement saying "the fundamental human rights in Israel will be honored (...) in the spirit of the principles included in the declaration of the establishment of the State of Israel."

Although Ben-Gurion had told the audience that he was reading from the scroll of independence, he was actually reading from handwritten notes because only the bottom part of the scroll had been finished by artist and calligrapher Otte Wallish by the time of the declaration (he did not complete the entire document until June). The scroll, which is bound together in three parts, is generally kept in the country's National Archives.




</doc>
<doc id="14699" url="https://en.wikipedia.org/wiki?curid=14699" title="Geography of Italy">
Geography of Italy

Italy is located in southern Europe and comprises the long, boot-shaped Italian Peninsula, the southern side of Alps, the large plain of the Po Valley and some islands including Sicily and Sardinia. Corsica, although belonging to the Italian geographical region, has been a part of France since 1769. Italy is part of the Northern Hemisphere. Two of the Pelagie islands (Lampedusa and Lampione) are located in the African continent. 

Its total area is , of which is land and . It lies between latitudes 35° and 48° N, and longitudes 6° and 19° E.

Italy borders Switzerland (), France (), Austria () and Slovenia (). San Marino () and Vatican city () are enclaves. The total border length is .

Including islands, Italy has a coastline of on the Adriatic Sea, Ionian Sea, Tyrrhenian Sea, Ligurian Sea, Sea of Sardinia and Strait of Sicily.

Almost 40% of the Italian territory is mountainous, with the Alps as the northern boundary and the Apennine Mountains forming the backbone of the peninsula and extending for . In between the two lies a large plain in the valley of the Po, the largest river in Italy, which flows eastward from the Cottian Alps to the Adriatic. The Po Valley is the largest plain in Italy, with , and it represents over 70% of the total plain area in the country.

The Alpine mountain range is linked with the Apennines with the Colle di Cadibona pass in the Ligurian Alps.

Worldwide-known mountains in Italy are Monte Cervino (Matterhorn), Monte Rosa, Gran Paradiso in the West Alps, and Bernina, Stelvio and Dolomites along the eastern side of the Alps. The highest peak in Italy is Mont Blanc, at above sea level.

Many elements of the Italian territory are of volcanic origin. Most of the small islands and archipelagos in the south, like Capraia, Ponza, Ischia, Eolie, Ustica and Pantelleria are volcanic islands.
There are also active volcanoes: Etna, in Sicily, the largest active volcano in Europe; Vulcano, Stromboli, and Vesuvius, near Naples, the only active volcano on mainland Europe.

Most of Italy's rivers drain either into the Adriatic Sea (like Po, Piave, Adige, Brenta, Tagliamento, Reno) or into the Tyrrhenian (like Arno, Tiber and Volturno), though the waters from some border municipalities (Livigno in Lombardy, Innichen and Sexten in Trentino-Alto Adige/Südtirol) drain into the Black Sea through the basin of the Drava, a tributary of the Danube, and the waters from the Lago di Lei in Lombardy drain into the North Sea through the basin of the Rhine.


In the north of the country are a number of subalpine moraine-dammed lakes, the largest of which is Garda (). Other well known of these subalpine lakes are Lake Maggiore (), whose most northerly section is part of Switzerland, Como (), Orta, Lugano, Iseo, Idro.

Other notable lakes in the Italian peninsula are Trasimeno, Bolsena, Bracciano, Vico, Varano and Lesina in Gargano and Omodeo in Sardinia.

Italy includes several islands. The largest are Sicily and Sardinia . The third largest island is Elba, the largest island of the Tuscan Archipelago ().









</doc>
