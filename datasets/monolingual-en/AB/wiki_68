<doc id="19838" url="https://en.wikipedia.org/wiki?curid=19838" title="Metallic bonding">
Metallic bonding

Metallic bonding is a type of chemical bonding that rises from the electrostatic attractive force between conduction electrons (in the form of an electron cloud of delocalized electrons) and positively charged metal ions. It may be described as the sharing of "free" electrons among a structure of positively charged ions (cations). Metallic bonding accounts for many physical properties of metals, such as strength, ductility, thermal and electrical resistivity and conductivity, opacity, and luster.

Metallic bonding is not the only type of chemical bonding a metal can exhibit, even as a pure substance. For example, elemental gallium consists of covalently-bound pairs of atoms in both liquid and solid state—these pairs form a crystal structure with metallic bonding between them. Another example of a metal–metal covalent bond is mercurous ion ().

As chemistry developed into a science it became clear that metals formed the large majority of the periodic table of the elements and great progress was made in the description of the salts that can be formed in reactions with acids. With the advent of electrochemistry, it became clear that metals generally go into solution as positively charged ions and the oxidation reactions of the metals became well understood in the electrochemical series. A picture emerged of metals as positive ions held together by an ocean of negative electrons.

With the advent of quantum mechanics, this picture was given more formal interpretation in the form of the free electron model and its further extension, the nearly free electron model. In both of these models, the electrons are seen as a gas traveling through the structure of the solid with an energy that is essentially isotropic in that it depends on the square of the magnitude, "not" the direction of the momentum vector k. In three-dimensional k-space, the set of points of the highest filled levels (the Fermi surface) should therefore be a sphere. In the nearly free correction of the model, box-like Brillouin zones are added to k-space by the periodic potential experienced from the (ionic) structure, thus mildly breaking the isotropy.

The advent of X-ray diffraction and thermal analysis made it possible to study the structure of crystalline solids, including metals and their alloys, and the construction of phase diagrams became accessible. Despite all this progress, the nature of intermetallic compounds and alloys largely remained a mystery and their study was often empirical. Chemists generally steered away from anything that did not seem to follow Dalton's and the problem was considered the domain of a different science, metallurgy.

The almost-free electron model was eagerly taken up by some researchers in this field, notably Hume-Rothery, in an attempt to explain why certain intermetallic alloys with certain compositions would form and others would not. Initially his attempts were quite successful. His idea was to add electrons to inflate the spherical Fermi-balloon inside the series of Brillouin-boxes and determine when a certain box would be full. This indeed predicted a fairly large number of observed alloy compositions. Unfortunately, as soon as cyclotron resonance became available and the shape of the balloon could be determined, it was found that the assumption that the balloon was spherical did not hold at all, except perhaps in the case of caesium. This reduced many of the conclusions to examples of how a model can sometimes give a whole series of correct predictions, yet still be wrong.
The free-electron debacle showed researchers that the model assuming that the ions were in a sea of free electrons needed modification, and so a number of quantum mechanical models such as band structure calculations based on molecular orbitals or the density functional theory were developed. In these models, one either departs from the atomic orbitals of neutral atoms that share their electrons or (in the case of density functional theory) departs from the total electron density. The free-electron picture has, nevertheless, remained a dominant one in education.

The electronic band structure model became a major focus not only for the study of metals but even more so for the study of semiconductors. Together with the electronic states, the vibrational states were also shown to form bands. Rudolf Peierls showed that, in the case of a one-dimensional row of metallic atoms, say hydrogen, an instability had to arise that would lead to the breakup of such a chain into individual molecules. This sparked an interest in the general question: When is collective metallic bonding stable and when will a more localized form of bonding take its place? Much research went into the study of clustering of metal atoms.

As powerful as the concept of the band structure proved to be in the description of metallic bonding, it does have a drawback. It remains a one-electron approximation to a multitudinous many-body problem. In other words, the energy states of each electron are described as if all the other electrons simply form a homogeneous background. Researchers like Mott and Hubbard realized that this was perhaps appropriate for strongly delocalized s- and p-electrons but for d-electrons, and even more for f-electrons the interaction with electrons (and atomic displacements) in the local environment may become stronger than the delocalization that leads to broad bands. Thus, the transition from localized unpaired electrons to itinerant ones partaking in metallic bonding became more comprehensible.

The combination of two phenomena gives rise to metallic bonding: delocalization of electrons and the availability of a far larger number of delocalized energy states than of delocalized electrons. The latter could be called electron deficiency.

Graphene is an example of two-dimensional metallic bonding. Its metallic bonds are similar to aromatic bonding in benzene, naphthalene, anthracene, ovalene, and so on.

Metal aromaticity in metal clusters is another example of delocalization, this time often in three-dimensional entities. Metals take the delocalization principle to its extreme and one could say that a crystal of a metal represents a single molecule over which all conduction electrons are delocalized in all three dimensions. This means that inside the metal one can generally not distinguish molecules, so that the metallic bonding is neither intra- nor intermolecular. 'Nonmolecular' would perhaps be a better term. Metallic bonding is mostly non-polar, because even in alloys there is little difference among the electronegativities of the atoms participating in the bonding interaction (and, in pure elemental metals, none at all). Thus, metallic bonding is an extremely delocalized communal form of covalent bonding. In a sense, metallic bonding is not a 'new' type of bonding at all, therefore, and it describes the bonding only as present in a "chunk" of condensed matter, be it crystalline solid, liquid, or even glass. Metallic vapors by contrast are often atomic (Hg) or at times contain molecules like Na held together by a more conventional covalent bond. This is why it is not correct to speak of a single 'metallic bond'.

The delocalization is most pronounced for - and -electrons. For caesium it is so strong that the electrons are virtually free from the caesium atoms to form a gas constrained only by the surface of the metal. For caesium, therefore, the picture of Cs ions held together by a negatively charged electron gas is not too inaccurate. For other elements the electrons are less free, in that they still experience the potential of the metal atoms, sometimes quite strongly. They require a more intricate quantum mechanical treatment (e.g., tight binding) in which the atoms are viewed as neutral, much like the carbon atoms in benzene. For - and especially -electrons the delocalization is not strong at all and this explains why these electrons are able to continue behaving as unpaired electrons that retain their spin, adding interesting magnetic properties to these metals.

Metal atoms contain few electrons in their valence shells relative to their periods or energy levels. They are electron deficient elements and the communal sharing does not change that. There remain far more available energy states than there are shared electrons. Both requirements for conductivity are therefore fulfilled: strong delocalization and partly filled energy bands. Such electrons can therefore easily change from one energy state into a slightly different one. Thus, not only do they become delocalized, forming a sea of electrons permeating the structure, but they are also able to migrate through the structure when an external electrical field is imposed, leading to electrical conductivity. Without the field, there are electrons moving equally in all directions. Under the field, some will adjust their state slightly, adopting a different wave vector. As a consequence, there will be more moving one way than the other and a net current will result.

The freedom of conduction electrons to migrate also give metal atoms, or layers of them, the capacity to slide past each other. Locally, bonds can easily be broken and replaced by new ones after the deformation. This process does not affect the communal metallic bonding very much. This gives rise to metals' typical characteristic phenomena of malleability and ductility. This is particularly true for pure elements. In the presence of dissolved impurities, the defects in the structure that function as cleavage points may get blocked and the material becomes harder. Gold, for example, is very soft in pure form (24-karat), which is why alloys of 18-karat or lower are preferred in jewelry.

Metals are typically also good conductors of heat, but the conduction electrons only contribute partly to this phenomenon. Collective (i.e., delocalized) vibrations of the atoms known as phonons that travel through the solid as a wave, contribute strongly.

However, the latter also holds for a substance like diamond. It conducts heat quite well but "not" electricity. The latter is "not" a consequence of the fact that delocalization is absent in diamond, but simply that carbon is not electron deficient.
The electron deficiency is an important point in distinguishing metallic from more conventional covalent bonding. Thus, we should amend the expression given above into: "Metallic bonding is an extremely delocalized communal form of electron deficient covalent bonding".

Metallic radius is defined as one-half of the distance between the two adjacent metal ions in the metallic structure. This radius depends on the nature of the atom as well as its environment—specifically, on the coordination number (CN), which in turn depends on the temperature and applied pressure.

When comparing periodic trends in the size of atoms it is often desirable to apply so-called Goldschmidt correction, which converts the radii to the values the atoms would have if they were 12-coordinated. Since metallic radii are always biggest for the highest coordination number, correction for less dense coordinations involves multiplying by x, where 0 < x < 1. Specifically, for CN = 4, x = 0.88; for CN = 6, x = 0.96, and for CN = 8, x = 0.97. The correction is named after Victor Goldschmidt who obtained the numerical values quoted above.

The radii follow general periodic trends: they decrease across the period due to increase in the effective nuclear charge, which is not offset by the increased number of valence electrons. The radii also increase down the group due to increase in principal quantum number. Between rows 3 and 4, the lanthanide contraction is observed – there is very little increase of the radius down the group due to the presence of poorly shielding f orbitals.

The atoms in metals have a strong attractive force between them. Much energy is required to overcome it. Therefore, metals often have high boiling points, with tungsten (5828 K) being extremely high. A remarkable exception is the elements of the zinc group: Zn, Cd, and Hg. Their electron configuration ends in ...ns and this comes to resemble a noble gas configuration like that of helium more and more when going down in the periodic table because the energy distance to the empty np orbitals becomes larger. These metals are therefore relatively volatile, and are avoided in ultra-high vacuum systems.

Otherwise, metallic bonding can be very strong, even in molten metals, such as Gallium. Even though gallium will melt from the heat of one's hand just above room temperature, its boiling point is not far from that of copper. Molten gallium is, therefore, a very nonvolatile liquid thanks to its strong metallic bonding.

The strong bonding of metals in the liquid form demonstrates that the energy of a metallic bond is not a strong function of the direction of the metallic bond; this lack of bond directionality is a direct consequence of electron delocalization, and is best understood in contrast to the directional bonding of covalent bonds. The energy of a metallic bond is thus mostly a function of the number of electrons which surround the metallic atom, as exemplified by the Embedded atom model. This typically results in metals assuming relatively simple, close-packed crystal structures, such as FCC, BCC, and HCP.

Given high enough cooling rates and appropriate alloy composition, metallic bonding can occur even in glasses with an amorphous structure.

Much biochemistry is mediated by the weak interaction of metal ions and biomolecules. Such interactions and their associated conformational change has been measured using dual polarisation interferometry.

Metals are insoluble in water or organic solvents unless they undergo a reaction with them. Typically this is an oxidation reaction that robs the metal atoms of their itinerant electrons, destroying the metallic bonding. However metals are often readily soluble in each other while retaining the metallic character of their bonding. Gold, for example, dissolves easily in mercury, even at room temperature. Even in solid metals, the solubility can be extensive. If the structures of the two metals are the same, there can even be complete solid solubility, as in the case of electrum, the alloys of silver and gold. At times, however, two metals will form alloys with different structures than either of the two parents. One could call these materials metal compounds, but, because materials with metallic bonding are typically not molecular, Dalton's law of integral proportions is not valid and often a range of stoichiometric ratios can be achieved. It is better to abandon such concepts as 'pure substance' or 'solute' is such cases and speak of phases instead. The study of such phases has traditionally been more the domain of metallurgy than of chemistry, although the two fields overlap considerably.

The metallic bonding in complicated compounds does not necessarily involve all constituent elements equally. It is quite possible to have an element or more that do not partake at all. One could picture the conduction electrons flowing around them like a river around an island or a big rock. It is possible to observe which elements do partake, e.g., by looking at the core levels in an X-ray photoelectron spectroscopy (XPS) spectrum. If an element partakes, its peaks tend to be skewed.

Some intermetallic materials e.g. do exhibit metal clusters, reminiscent of molecules and these compounds are more a topic of chemistry than of metallurgy. The formation of the clusters could be seen as a way to 'condense out' (localize) the electron deficient bonding into bonds of a more localized nature. Hydrogen is an extreme example of this form of condensation. At high pressures it is a metal. The core of the planet Jupiter could be said to be held together by a combination of metallic bonding and high pressure induced by gravity. At lower pressures however the bonding becomes entirely localized into a regular covalent bond. The localization is so complete that the (more familiar) H gas results. A similar argument holds for an element like boron. Though it is electron deficient compared to carbon, it does not form a metal. Instead it has a number of complicated structures in which icosahedral B clusters dominate. Charge density waves are a related phenomenon.

As these phenomena involve the movement of the atoms towards or away from each other, they can be interpreted as the coupling between the electronic and the vibrational states (i.e. the phonons) of the material. A different such electron-phonon interaction is thought to cause a very different result at low temperatures, that of superconductivity. Rather than blocking the mobility of the charge carriers by forming electron pairs in localized bonds, Cooper-pairs are formed that no longer experience any resistance to their mobility.

The presence of an ocean of mobile charge carriers has profound effects on the optical properties of metals. They can only be understood by considering the electrons as a "collective" rather than considering the states of individual electrons involved in more conventional covalent bonds.

Light consists of a combination of an electrical and a magnetic field. The electrical field is usually able to excite an elastic response from the electrons involved in the metallic bonding. The result is that photons are not able to penetrate very far into the metal and are typically reflected. They bounce off, although some may also be absorbed. This holds equally for all photons of the visible spectrum, which is why metals are often silvery white or grayish with the characteristic specular reflection of metallic luster. The balance between reflection and absorption determines how white or how gray they are, although surface tarnish can obscure such observations. Silver, a very good metal with high conductivity is one of the whitest.

Notable exceptions are reddish copper and yellowish gold. The reason for their color is that there is an upper limit to the frequency of the light that metallic electrons can readily respond to, the plasmon frequency. At the plasmon frequency, the frequency-dependent dielectric function of the free electron gas goes from negative (reflecting) to positive (transmitting); higher frequency photons are not reflected at the surface, and do not contribute to the color of the metal. There are some materials like indium tin oxide (ITO) that are metallic conductors (actually degenerate semiconductors) for which this threshold is in the infrared, which is why they are transparent in the visible, but good mirrors in the IR.

For silver the limiting frequency is in the far UV, but for copper and gold it is closer to the visible. This explains the colors of these two metals. At the surface of a metal resonance effects known as surface plasmons can result. They are collective oscillations of the conduction electrons like a ripple in the electronic ocean. However, even if photons have enough energy they usually do not have enough momentum to set the ripple in motion. Therefore, plasmons are hard to excite on a bulk metal. This is why gold and copper still look like lustrous metals albeit with a dash of color. However, in colloidal gold the metallic bonding is confined to a tiny metallic particle, preventing the oscillation wave of the plasmon from 'running away'. The momentum selection rule is therefore broken, and the plasmon resonance causes an extremely intense absorption in the green with a resulting beautiful purple-red color. Such colors are orders of magnitude more intense than ordinary absorptions seen in dyes and the like that involve individual electrons and their energy states.



</doc>
<doc id="19839" url="https://en.wikipedia.org/wiki?curid=19839" title="Methyl group">
Methyl group

A methyl group is an alkyl derived from methane, containing one carbon atom bonded to three hydrogen atoms—CH. In formulas, the group is often abbreviated Me. Such hydrocarbon groups occur in many organic compounds. It is a very stable group in most molecules. While the methyl group is usually part of a larger molecule, it can be found on its own in any of three forms: anion, cation or radical. The anion has eight valence electrons, the radical seven and the cation six. All three forms are highly reactive and rarely observed.

The methylium cation (CH) exists in the gas phase, but is otherwise not encountered. Some compounds are considered to be sources of the CH cation, and this simplification is used pervasively in organic chemistry. For example, protonation of methanol gives an electrophilic methylating reagent that reacts by the S2 pathway:

Similarly, methyl iodide and methyl triflate are viewed as the equivalent of the methyl cation because they readily undergo S2 reactions by weak nucleophiles.

The methanide anion (CH) exists only in rarefied gas phase or under exotic conditions. It can be produced by electrical discharge in ketene at low pressure (less than one torr) and its enthalpy of reaction is determined to be about 252.2±3.3 kJ/mol.

In discussing mechanisms of organic reactions, methyl lithium and related Grignard reagents are often considered to be salts of "CH"; and though the model may be useful for description and analysis, it is only a useful fiction. Such reagents are generally prepared from the methyl halides:
where M is an alkali metal.

The methyl radical has the formula CH. It exists in dilute gases, but in more concentrated form it readily dimerizes to ethane. It can be produced by thermal decomposition of only certain compounds, especially those with an -N=N- linkage.

The reactivity of a methyl group depends on the adjacent substituents. Methyl groups can be quite unreactive. For example, in organic compounds, the methyl group resists attack by even the strongest acids.

The oxidation of a methyl group occurs widely in nature and industry. The oxidation products derived from methyl are CHOH, CHO, and COH. For example, permanganate often converts a methyl group to a carboxyl (-COOH) group, e.g. the conversion of toluene to benzoic acid. Ultimately oxidation of methyl groups gives protons and carbon dioxide, as seen in combustion.

Demethylation (the transfer of the methyl group to another compound) is a common process, and reagents that undergo this reaction are called methylating agents. Common methylating agents are dimethyl sulfate, methyl iodide, and methyl triflate. Methanogenesis, the source of natural gas, arises via a demethylation reaction. Together with ubiquitin and phosphorylation, methylation is a major biochemical process for modifying protein function.

Certain methyl groups can be deprotonated. For example, the acidity of the methyl groups in acetone ((CH)CO) is about 10 more acidic than methane. The resulting carbanions are key intermediates in many reactions in organic synthesis and biosynthesis. Fatty acids are produced in this way.

When placed in benzylic or allylic positions, the strength of the C-H bond is decreased, and the reactivity of the methyl group increases. One manifestation of this enhanced reactivity is the photochemical chlorination of the methyl group in toluene to give benzyl chloride.

In the special case where one hydrogen is replaced by deuterium (D) and another hydrogen by tritium (T), the methyl substituent becomes chiral. Methods exist to produce optically pure methyl compounds, e.g., chiral acetic acid (CHDTCOH). Through the use of chiral methyl groups, the stereochemical course of several biochemical transformations have been analyzed.

A methyl group may rotate around the R—C-axis. This is a free rotation only in the simplest cases like gaseous CClH. In most molecules, the remainder R breaks the formula_1 symmetry of the R—C-axis and creates a potential formula_2 that restricts the free motion of the three protons. For the model case of CH this is discussed under the name ethane barrier.
In condensed phases, neighbour molecules also contribute to the potential. Methyl group rotation can be experimentally studied using quasielastic neutron scattering.

French chemists Jean-Baptiste Dumas and Eugene Peligot, after determining methanol's chemical structure, introduced "methylene" from the Greek "methy" "wine" and "hȳlē" "wood, patch of trees" with the intention of highlighting its origins, "alcohol made from wood (substance)". The term "methyl" was derived in about 1840 by back-formation from "methylene", and was then applied to describe "methyl alcohol" (which since 1892 is called "methanol").

"Methyl" is the IUPAC nomenclature of organic chemistry term for an alkane (or alkyl) molecule, using the prefix "meth-" to indicate the presence of a single carbon.


</doc>
<doc id="19842" url="https://en.wikipedia.org/wiki?curid=19842" title="Mild ale">
Mild ale

Mild ale is a type of ale, with a predominantly malty palate. Modern mild ales are mainly dark-coloured with an alcohol by volume (ABV) of 3% to 3.6%, although there are lighter-hued examples as well as stronger examples reaching 6% abv and higher. It originated in Britain in the 17th century or earlier, and originally meant a young ale, as opposed to a "stale" aged or old ale. It is now more often interpreted as being mildly hopped.

Light mild is generally similar, but pale in colour, for instance Harveys Brewery Knots of May. There is some overlap between the weakest styles of bitter and light mild, with the term AK being used to refer to both. The designation of such beers as "bitter" or "mild" has tended to change with fashion. A good example is McMullen's AK, which was re-badged as a bitter after decades as a light mild. AK (a very common beer name in the 19th century) was often referred to as a "mild bitter beer", interpreting "mild" as "unaged".

Once sold in most pubs, mild experienced a sharp decline in popularity in the 1960s, and was in danger of completely disappearing, but the increase of microbreweries has led to a modest renaissance and an increasing number of milds (sometimes labelled "Dark") being brewed.

The Campaign for Real Ale has designated May as Mild Month. In the United States, a group of beer bloggers organised the first American Mild Month for May 2015, with forty-five participating breweries across the country.

"Mild" was originally used to designate any beer which was young, fresh or unaged and did not refer to a specific style of beer. Thus there was Mild Ale but also Mild Porter and even Mild Bitter Beer. These young beers were often blended with aged "stale" beer to improve their flavour. As the 19th century progressed public taste moved away from the aged taste; unblended young beer, mostly in the form of Mild Ale or Light Bitter Beer, began to dominate the market.

In the 19th century a typical brewery produced three or four mild ales, usually designated by a number of X marks, the weakest being X, the strongest XXXX. They were considerably stronger than the milds of today, with the gravity ranging from around 1.055 to 1.072 (about 5.5% to 7% abv). Gravities dropped throughout the late 19th century and by 1914 the weakest milds were down to about 1.045, still considerably stronger than modern versions.

The draconian measures applied to the brewing industry during the First World War had a particularly dramatic effect upon mild. As the biggest-selling beer, it suffered the largest cut in gravity when breweries had to limit the average OG of their beer to 1.030. In order to be able to produce some stronger beer - which was exempt from price controls and thus more profitable - mild was reduced to 1.025 or lower.

Modern dark mild varies from dark amber to near-black in colour and is very light-bodied. Its flavour is dominated by malt, sometimes with roasty notes derived from the use of black malt, with a subdued hop character, though there are some quite bitter examples. Most are in the range 1.030–1.036 (3–3.6% abv).

Light mild is generally similar, but paler in colour. Some dark milds are created by the addition of caramel to a pale beer.

Until the 1960s mild was the most popular beer style in England. Pockets of demand remain, particularly in the West Midlands and North West England, but has been largely ousted by bitter and lager elsewhere. In 2002, only 1.3% of beer sold in pubs was Mild. Mild's popularity in Wales, in particular, persisted as a relatively low-alcohol, sweet drink for coal miners. Some brewers have continued to produce mild, but have found it sells better under a different name: for instance, Brains's mild was renamed Dark. Outside the United Kingdom mild is virtually unknown, with the exception of Old in New South Wales and some microbrewery recreations in North America and Scandinavia. Some notable examples of Milds are: Bank's Mild, Cain's Dark Mild, Highgate Dark Mild, Brain's Dark, Moorehouse Blackcat, Rudgate Ruby Mild, and Theakston Traditional Mild

A popular drink in the West Midlands, "brown and mild" (also known as a "boilermaker") is a half pint of draught mild served mixed with a half pint of bottled brown ale in a pint glass. In North West England, a mixture of half a pint of mild and half a pint of bitter is known as a "mixed". In Norfolk, the same mixture was called a pint of "twos".

Mild ales are generally based on mild malt or pale malt. Most milds contain, in addition, a quantity of crystal malt; dark milds, meanwhile, make use of chocolate malt, black malt or dark brewing sugars. Milds tend to be lightly hopped compared to pale ale and are usually low in alcohol; strong mild ales used to reach six or seven per cent abv, but very few such beers are still brewed. Sarah Hughes Dark Ruby Mild, brewed to a pre-World War I recipe, is a rare example of a strong Mild (6.0% ABV).

As part of the first American Mild Month, the project organizers challenged participating breweries to create a new variation on the mild ale style by brewing with American malts and hops. They defined American Mild as "a restrained, darkish ale, with gentle hopping and a clean finish so that the malt and what hops are present, shine through".


</doc>
<doc id="19843" url="https://en.wikipedia.org/wiki?curid=19843" title="Mars Society">
Mars Society

The Mars Society is an American worldwide volunteer-driven space-advocacy non-profit organization dedicated to promoting the human exploration and settlement of the planet Mars. Inspired by "The Case for Mars" conferences which were hosted by The Mars Underground at the University of Colorado Boulder, the Mars Society was established by Dr. Robert Zubrin and others in 1998 with the goal of educating the public, the media and government on the benefits of exploring Mars, the importance of planning for a humans-to-Mars mission in the coming decades and the need to create a permanent human presence on the Red Planet.

Mars Society, Inc. was formally established in September 1997 under the Colorado Non-Profit Corporation Act. In August 1998 more than 700 delegates – astronomers, scientists, engineers, astronauts, entrepreneurs, educators, students and space enthusiasts – attended a week-end of talks and presentations from leading Mars exploration advocates. Since then, the Mars Society, guided by its steering committee, has grown to over 5,000 members and some 6,000 associate supporters across more than 50 countries around the world. Members of the Mars Society are from all walks of life and actively work to promote the ideals of space exploration and the opportunities for exploring the Red Planet. In 2017 the Marspedia encyclopedia became an official project of the Mars Society.

The Mars Society's goals aren't purely theoretical. Its aim is to show that Mars is an achievable goal through a practical series of technical and other projects, including:


In addition, the Society:


The current board of directors of the Mars Society includes Robert Zubrin (chairman) and James Heiser.

Notable members of its steering committee include Buzz Aldrin and Peter H. Smith.

Notable former members of the board of directors or steering committee of the Mars Society include Kim Stanley Robinson, Michael D. Griffin, Christopher McKay, and Pascal Lee.

The Society is an organization member of the Alliance for Space Development.

The Mars Society has chapters in the U.S. and around the world. Many of these chapters undertake scientific, engineering and political initiatives to further the Mars Society's goals. Some accomplishments of Mars Society chapters are listed below:

Mars Society of Canada:

Northern California Chapter of the Mars Society:

The San Diego Chapter of the Mars Society

Dallas Chapter of the Mars Society:

Mars Society Seattle:

The ASF (Österreichisches Weltraum Forum, OeWF) is a national network for aerospace and space enthusiasts, being the Austrian chapter of the Mars Society. The Forum serves as a communication platform between the space sector and the public; it is embedded in a global network of specialists from the space industry, research and policy. Hence, the OeWF facilitates a strengthening of the national space sector through enhancing the public visibility of space activities, technical workshops, and conferences as well as Forum-related projects.

Their research focus is Mars Analogue Research, e.g. the AustroMars mission with roughly 130 volunteers supporting a mission simulation at the Mars Desert Research Station (MDRS) and the ongoing PolAres, a multi-year research program which encompass the development of a Mars analogue rover system and a novel spacesuit prototype dubbed "Aouda.X", culminating in an arctic expedition in 2011.

The Forum has a small, but a highly active pool of professional members contributing to space endeavors, mostly in cooperation with other nations as well as international space organizations. The spectrum of their activities ranges from simple classroom presentation to 15.000-visitors space exhibitions, from expert reports for the Austrian Federal Ministry for Technology to space technology transfer activities for terrestrial applications.

The Mars Society French chapter (Association Planète Mars) was established in 1999 as "Association Planète Mars", a non-profit organization with its headquarters in Paris. Its founder and president is Richard Heidmann, a space propulsion engineer, who participated in the founding convention of the Mars Society in August 1998 and is a member of the Mars Society Steering Committee.

While fully supporting the ideas and actions of the Mars Society, it considers that those must be adapted to the specific cultural and political context of France and Europe.
The main activities of Association Planète Mars are devoted to public communication, through conferences, exhibits, events, media appearances (TV, radio, magazines...). It also acts occasionally as an adviser for journalists or film makers.

Whenever possible, it cooperates with other associations or science outreach organisms, which permits to reinforce its action and reach a wider public.

Association Planète Mars seeks to interest younger people: 25% of its paid members are under the age of 25. It aims to encourage Mars-related projects to be undertaken by engineering students. The association also encourages the formation of working groups on miscellaneous topics. Today, three groups are active, respectively on mission safety, Martian architecture and medical aspects. It has participated in several MDRS and FMARS missions, including a prototype of a "Cliff Exploration Vehicle".

Another major field of action is lobbying, aiming at both political and institutional groups, in France and at the European level (European Council, ESA). In doing so, it relies on the networks established by some of its managers. On the occasion of most critical events, the association publishes political documents to support its views, which are distributed both to opinion formers and to the press. This has been the case in June 2004, in the wake of the US Space Exploration Initiative, and in September 2008 in preparation of the ESA ministerial council.

The German Chapter of the Mars Society (Mars Society Deutschland e.V. | "eingetragener Verein" | - MSD) was founded in 2001 based on the Founding Declaration of the Mars Society of the US from 1998 and has about 230 members. The MSD is registered in Germany as a non-profit association ("gemeinnütziger Verein"). Registered members pay a yearly membership fee of 60 Euro. However, students and firms pay a different fee. The activities of the MSD are focused on technical-scientific projects such as the Mars Balloon Probe ARCHIMEDES as well as on all Mars exploration and general manned space matters. The main means of communication with members and the general public is the MSD Website with information on the ARCHIMEDES project, publications on Mars and other space subjects, the regular news, which can be commented by visitors of the website, the Space Forum and informative meetings.

The MSD Board comprises five members. Since June 2009 its president is the Space Physicist Dr. Michael Danielides.
The development of ARCHIMEDES is led by Dipl. Ing. Hannes Griebel, who is also a member of the MSD Board and prepares his doctorate thesis on ARCHIMEDES.

ARCHIMEDES is presently under development and the major project of the MSD since 2001. Starting in 2006, flight tests have been undertaken for testing the innovative balloon system in the low-gravity environment. Test carriers were so far the Airbus A300 for short duration parabolic flights and the sounding rocket test campaigns REXUS3-REGINA and REXUS4-MIRIAM for longer duration flight tests under free space conditions. Further flights tests are planned for the coming years (e.g. MIRIAM II) with the objective of qualifying ARCHIMEDES for its Mars mission by 2018. ARCHIMEDES will be carried to Mars on board an AMSAT Mars Probe or a similar satellite. ARCHIMEDES is developed by the MSD with the support of the Bundeswehr University Munich, of the IABG in Ottobrunn, the DLR-MORABA for rocket flight opportunities, other universities, and several industrial companies supporting specific technical areas.

The Mars Society Netherlands chapter was wound up in 2011. The board and members moved over to a new Mars-oriented organization.
The Dutch Mars Society is being relaunched in 2019.

The Polish Mars society (Mars Society Polska (MSP)) is actively participating in the creation of the Polish space industry. Since this sector is still developing, the organization is taking the opportunity to provide a strong Mars-related element for the years to come. Poland was the last member state of the EU to sign the cooperation agreement with ESA. Most projects in Poland currently focus on satellite technology, so MSP is the only leading organization promoting exploration and manned spaceflight. Besides private sponsors, it relies on resources obtained from the Ministry of Science and Higher Education and local authorities, proposing projects to be undertaken with local communities and thus engaging with the general public.

MSP's first project was the Polish MPV (pressurized rover) design, for which some hardware was produced. This enabled development of the Polish Mars Society itself, together with a number of educational activities for Polish schools. This was followed by the joint organization of the Polish edition of the Red Rover Goes to Mars contest and organization of a Mars colonization negotiation game (Columbia Memorial Negotiations). In 2007 MSP organized the first Mars Festival, a two-day event which drew 600 visitors, with Discovery Channel as the main sponsor. Mars Festival 2008 was smaller due to the efforts being made in other projects, particularly the Polish URC rover, named Skarabeusz.

The flagship MSP project is the Polish Martian habitat, based on a design by Janek Kozicki. It has three inflatable modules attached and a usable surface of 900 m². The habitat is to be located close to a large town, meaning that beyond its role as a test site, largely for materials and design, it will be accessible to the wider public and media.

MSP has established a constant presence in the mainstream Polish media and is working on a documentary about itself. It is also developing software projects, IT systems for the future martian habitat, with a Virtual Mars Base and remote access. Jan Kotlarz of MSP has created RODM software for the modeling of the Martian surface based on high-resolution photographs from Mars Reconnaissance Orbiter. RODM is currently being tested by NASA and ESA.

The Mars Society Switzerland ("MSS") was founded in February 2010. It covers the French and German speaking parts of Switzerland. It keeps close links with the French branch ("association planète Mars", see above).
Its aim is to convince the Swiss public of the interest and feasibility of the Martian exploration with inhabited flights through the Mars direct concept such as described by Robert Zubrin. It wants to gather around the scientists working on Mars in Switzerland, all people who share their interest on the matter.

In November 2010, MSS participated to the 8th Swiss Geoscience Meeting which was the opportunity to discuss the main topics related to Mars geology, the making of the planet, the role of water and the atmosphere.

In 2011 (September 30 until October 2), MSS held the 11th European Mars Convention ("EMC11") in the frame of the University of Neuchâtel. Through 24 presentations and two debates with major Swiss media, this convention covered all subjects related to Mars exploration; from astronautics to architecture, including the study of geology which remains its key objective.

On September 10, 2012, in the Natural History Museum Bern ("NHMB"), it held a conference on the theme "Searching for Life on Mars". 
The conference was centered upon a presentation by Professor André Maeder (a well-known astrophysicist at the University of Geneva) following the publishing of his book "L'unique Terre habitée?" (Favre editions). Another presentation was made by Dr. Beda Hofmann, Head of the Earth Science Dept. of the NHMB. He showed and commented photos of primitive forms of life which he gathered to serve as references for the observations to be made by the ESA ExoMars mission (to be launched in 2018).
Pierre Brisson, president of the Mars Society Switzerland introduced the conference, speaking about the instruments aboard Curiosity and the targets of exploration of the rover.

In October (12th till 14th) The Mars Society Switzerland participated to the 12th EMC ("EMC12") in Neubiberg, Germany (University of the German Armed Forces, near Münich). In this frame, Pierre Brisson discussed the past possibility of an Ocean in the Northern Lowlands of the planet.

A key event of the year 2013 (March 26), was a conference organized with "Club 44" in La Chaux de Fonds, during which Professor Michel Cabane, LATMOS and co-PI of the SAM Instruments aboard Curiosity, presented the findings of his instruments dedicated to the study of the molecular and atomic compositions of the rocks and atmosphere of the planet Mars.

The Mars Society UK is the oldest Mars Society outside the United States. It held its first public meeting on July 4, 1998, in London. Professor Colin Pillinger, head of the Beagle 2 project, was the Guest Speaker, and the event marked the first time Beagle 2 had been presented to the general public in the UK. From 1998 through to 2003, the Mars society UK (MSUK) continued to support Beagle 2, providing numerous public events at which members of the Beagle 2 project team could speak, and the Beagle 2 model be displayed.

Highlights of the MSUK's history include:

The Mars Society India chapter (MSI) was founded in January 2012 by Dhruv Joshi, an alumnus of the Indian Institute of Technology Bombay. Dhruv Joshi was inspired to set up the chapter in India after he attended a presentation by Mars society Switzerland chapter; during his visit to Switzerland. MSI was launched on March 2, 2012 at Mumbai, with collaboration from Nehru center (Planetarium) and students of Indian Institute of Technology - Bombay (IIT-B). MSI endeavors to set a platform for bringing immense talent pool of Indian students to the forefront and achieve country's ambitious space missions.

Mars Society Bangladesh chapter was found in 2016. A group of 40 students and three teams from Bangladesh participated in 2016 University Rover Challenge (URC 2016) powered by Mars Society, held in June 2016 at Utah, USA.

There is a chapter in Australia, with branches in Australian Capital Territory (ACT), New South Wales (NSW), Northern Territory, Queensland, South Australia, Tasmania, Victoria, and Western Australia. The main goals for Mars Society Australia are to support government funded programs geared towards exploring Mars and reach out to the public about both exploring Mars and the importance of studying planetary sciences and engineering.

The NZ Mars Society has the same list of goals as Australia. In an effort to help put people on Mars, they plan to have their members test surface exploration strategies and technologies in locations dedicated to Mars analogue. One of these Mars analogue locations is Mars Desert Research Station in Utah.


</doc>
<doc id="19845" url="https://en.wikipedia.org/wiki?curid=19845" title="Minerva">
Minerva

Minerva (; ) is the Roman goddess of wisdom and strategic warfare, and the sponsor of arts, trade, and strategy. Minerva is not a patron of violence such as Mars, but of defensive war only. From the second century BC onward, the Romans equated her with the Greek goddess Athena. Minerva is one of the three Roman deities in the Capitoline Triad, along with Jupiter and Juno.

She was the virgin goddess of music, poetry, medicine, wisdom, commerce, weaving, and the crafts. She is often depicted with her sacred creature, an owl usually named as the "owl of Minerva", which symbolised her association with wisdom and knowledge as well as, less frequently, the snake and the olive tree. Minerva is commonly depicted as tall with an athletic and muscular build, as well as wearing armour and carrying a spear. Marcus Terentius Varro considered her to be ideas and the plan for the universe personified.

The name "Minerva" stems from Proto-Italic "*meneswo" ('intelligent, understanding'), and ultimately from Proto-Indo-European (PIE) "*menos" ('thought'). Helmut Rix (1981) and Gerhard Meiser (1998) have proposed the PIE derivative "*menes-ueh₂" ('provided with a mind, intelligent') as the transitional form.

Following the Greek myths around Athena, she was born of Metis, who had been swallowed by Jupiter, and burst from her father's head, fully armed and clad in armor. Jupiter forcibly impregnated the titaness Metis, which resulted in her attempting to change shape (or shapeshift) to escape him. Jupiter then recalled the prophecy that his own child would overthrow him as he had Saturn, and in turn, Saturn had Caelus.

Fearing that their child would be male, and would grow stronger than he was and rule the Heavens in his place, Jupiter swallowed Metis whole after tricking her into turning herself into a fly. The titaness gave birth to Minerva and forged weapons and armor for her child while within Jupiter's body. In some versions of the story, Metis continued to live inside of Jupiter's mind as the source of his wisdom. Others say she was simply a vessel for the birth of Minerva. The constant pounding and ringing left Jupiter with agonizing pain. To relieve the pain, Vulcan used a hammer to split Jupiter's head and, from the cleft, Minerva emerged, whole, adult, and in full battle armor.

Minerva is a prominent figure in Roman Mythology. She appears throughout many famous myths. Many of the stories of her Greek counterpart Athena are attributed to Minerva in Roman mythology, such as that of the naming of Athens resulting from a competition between Minerva and Neptune (mythology), in which Minerva created the olive tree.

Arachne was a mortal highly proficient in weaving and embroidery. Not only were her finished works that were beautiful, but also her process, so much so that nymphs would come out of their natural environments to watch her work. Arachne boasted that her skills could beat those of Minerva, and if she were wrong she would pay the price for it. This angered Minerva, and she took the form of an old woman to approach Arachne, offering her a chance to take back her challenge and ask forgiveness. When Arachne refused, Minerva rid herself of her disguise and took Arachne up on her challenge. Arcachne began to weave a tapestry which showed the shortcomings of the gods, while Minerva depicted her competition with Neptune and the gods looking down with disgust on mortals who would dare to challenge them. Minerva's weaving was meant as a final warning to her foe to back down. Minerva was insulted by the scenes which Arachne was weaving, and destroyed it. She then touched Arachne on the forehead which made her feel shame for what she had done, leading her to hang herself. Minerva then felt bad for the woman, and brought her back to life. However, Minerva transformed her into a spider as punishment for her actions, and hanging from a web would forever be a reminder to Arachne of her actions which offended the gods. This story also acted as a warning to mortals not to challenge the gods.

Medusa was once a beautiful human, her beauty rivaled that of Minerva. Later on, Minerva found out that Neptune and Medusa were kissing in a temple dedicated to Minerva herself. Because of this Minerva turned her into a monster, replacing her hair with hissing snakes and removing her charm. Medusa turned any living creature she looked upon into stone. When Perseus approached Medusa he used her reflection in his shield to avoid contact with her eyes, and then beheaded her. He delivered the severed head to Minerva, who placed its image on her Aegis.

When Perseus beheaded Medusa some of the blood spilled onto the ground, and from it came Pegasus. Minerva caught the horse and tamed it before gifting the horse to the Muses. It was a kick from the hoof of Pegasus which opened the fountain Hippocrene. When Bellerophon later went to fight the Chimera (mythology) he sought to use Pegasus in the fight. In order to do this he slept in Minerva's temple, and she came to him with a golden bridle. When Pegasus saw Bellerophon with the bridle the horse immediately allowed Bellerophon to mount, and they defeated the Chimera.
Metamorphoses by Ovid tell the story of Minerva and Aglauros. When Mercury comes to seduce mortal virgin Herse, her sister Aglauros is driven by her greed to help him. Minerva discovers this and is furious with Aglauros. She seeks the assistance of Envy, who fills Aglauros with so much envy for the good fortune of others that she turns to stone. Mercury fails to seduce Herse.

Minerva assisted the hero Hercules. In Hyginus' "Fabulae" she is said to have helped him kill the Hydra (30.3).

Minerva assisted the hero Odysseus. Hyginus describes in his work "Fabulae" that Minerva changes Odysseus' appearance in order to protect and assist him multiple times (126).

Minerva is thought to have invented the flute by piercing holes into boxwood. She enjoyed the music, but became embarrassed by how it made her face look when her cheeks puffed out to play. Because of this she threw it away and it landed on a riverbank where it was found by a satyr.

Minerva was worshipped at several locations in Rome, most prominently as part of the Capitoline Triad. She was also worshipped at the Temple of Minerva Medica, and at the "Delubrum Minervae", a temple founded around 50 BC by Pompey on the site now occupied by the church of "Santa Maria sopra Minerva".

The Romans celebrated her festival from March 19 to March 23 during the day which is called, in the neuter plural, Quinquatria, the fifth day after the Ides of March, the nineteenth, an artisans' holiday. This festival was of deepest importance to artists and craftsmen as she was the patron goddess of crafting and arts. According to Ovid (Fasti 3.809) the festival was 5 days long, and the first day was said to be the anniversary of Minerva's birth, so no blood was to be shed. The following four days were full of games of "drawn swords" in honour of Minerva's military association. Suetonius tells us (Life of Domitian 4.4) that Domitian celebrated the Quinquatria by appointing a college of priests who were to stage plays and animal games in addition to poetry and oratory competitions. A lesser version, the "Minusculae Quinquatria", was held on the Ides of June, June 13, by the flute-players, as Minerva was thought to have invented the flute. In 207 BC, a guild of poets and actors was formed to meet and make votive offerings at the temple of Minerva on the Aventine Hill. Among others, its members included Livius Andronicus. The Aventine sanctuary of Minerva continued to be an important center of the arts for much of the middle Roman Republic.

As "Minerva Medica", she was the goddess of medicine and physicians. As "Minerva Achaea", she was worshipped at Lucera in Apulia where votive gifts and arms said to be those of Diomedes were preserved in her temple.

We know due to the Acta Arvalia that a cow was sacrificed to Minerva on October 13th 58 AD along with many other scrifices to celebrate the anniversary of Nero coming to power. On January 3rd 81 AD, as a part of the New Year vows, two cows were sacrificed to Minerva (among many others) to secure the well-being of the emperor Titus, Domitian Caesar, Julia Augusta, and their children. On January 3rd 87 AD there is again record of a cow being sacrificed to Minerva among the many sacrifices made as a part of the New Year vows.

In "Fasti" III, Ovid called her the "goddess of a thousand works" due to all of the things she was associated with. Minerva was worshipped throughout Italy, and when she eventually became equated with the Greek goddess Athena, she also became a goddess of battle. Unlike Mars, god of war, she was sometimes portrayed with sword lowered, in sympathy for the recent dead, rather than raised in triumph and battle lust. In Rome her bellicose nature was emphasized less than elsewhere.

According to Livy's "History of Rome" (7.3), the annual nail marking the year, a process where the praetor maximus drove a nail into to formally keep track of the current year, happened in the temple of Minerva because she was thought to have invented numbers.

There is archaeological evidence to suggest that Minerva was worshipped not only in a formal civic fashion, but also by individuals on a more personal level.

Minerva is featured on the coinage of different Roman emperors. She often is represented on the reverse side of a coin holding an owl and a spear among her attributes.

During the Roman occupation of Britain, it was common for carpenters to own tools ornamented with images of Minerva to invoke a greater amount of protection from the goddess of crafts. Some women would also have images of her on accessories such as hairpins or jewellery. She was even featured on some funerary art on coffins and signet rings. 

During Roman rule Minerva became equated with the Celtic goddess Sulis, to the degree where their names were used both together and interchangeably. and was believed to preside over the healing hot springs located in Bath. Though Minerva is not a water deity, her association with intellectual professions as "Minerva Medica" she could also be thought of as a healing goddess, the epigraphic evidence present makes it clear that this is how Minerva was thought of in Bath.

Some of the archaeological evidence present in Bath leads scholars to believe that it was thought Minerva could provide full healing from things such as rheumatism via the hot springs if she was given full credit for the healing.

The temple of Sulis Minerva was known for having a miraculous altar-fire which burned coal as opposed to the traditional wood.

There is evidence of worship of Minerva Medica in Carrawburgh due to archaeological evidence such as a relief depicting her and Aesculapius.

Stemming from an Italic moon goddess "*Meneswā" ('She who measures'), the Etruscans adopted the inherited Old Latin name, "*Menerwā", thereby calling her Menrva. It is presumed that her Roman name, Minerva, is based on this Etruscan mythology. Minerva was the goddess of wisdom, war, art, schools, and commerce. She was the Etruscan counterpart to Greek Athena. Like Athena, Minerva burst from the head of her father, Jupiter (Greek Zeus), who had devoured her mother (Metis) in an unsuccessful attempt to prevent her birth.

By a process of folk etymology, the Romans could have linked her foreign name to the root "men-" in Latin words such as "mens" meaning "mind", perhaps because one of her aspects as goddess pertained to the intellectual. The word "mens" is built from the Proto-Indo-European root "*men-" 'mind' (linked with memory as in Greek Mnemosyne/μνημοσύνη and "mnestis"/μνῆστις: memory, remembrance, recollection, "manush" in Sanskrit meaning mind).

The Etruscan Menrva was part of a holy triad with Tinia and Uni, equivalent to the Roman Capitoline Triad of Jupiter-Juno-Minerva.

As a patron goddess of wisdom, Minerva frequently features in statuary, as an image on seals, and in other forms at educational institutions. Listings of this can be found on Minerva in the emblems of educational establishments.



She is remembered in "De Mulieribus Claris", a collection of biographies of historical and mythological women by the Florentine author Giovanni Boccaccio, composed in 136162. It is notable as the first collection devoted exclusively to biographies of women in Western literature.. Poet Elizabeth Carter is famously portrayed in an outfit inspired by Minerva, and also wrote poems in her honour.





</doc>
<doc id="19846" url="https://en.wikipedia.org/wiki?curid=19846" title="Mars Direct">
Mars Direct

Mars Direct is a proposal for a human mission to Mars which purports to be both cost-effective and possible with current technology. It was originally detailed in a research paper by Martin Marietta engineers Robert Zubrin and David Baker in 1990, and later expanded upon in Zubrin's 1996 book "The Case for Mars". It now serves as a staple of Zubrin's speaking engagements and general advocacy as head of the Mars Society, an organization devoted to the colonization of Mars.

On July 20, 1989, George H. W. Bush – then President of the United States – announced plans for what came to be known as the Space Exploration Initiative (SEI). In a speech on the steps of the National Air and Space Museum he described long-term plans which would culminate in a manned mission to the surface of Mars.

By December 1990, a study to estimate the project's cost determined that long-term expenditure would total approximately 450 billion dollars spread over 20 to 30 years. The "90 Day Study" as it came to be known, evoked a hostile Congressional reaction towards SEI given that it would have required the largest single government expenditure since World War II. Within a year, all funding requests for SEI had been denied.

Dan Goldin became NASA Administrator on April 1, 1992, officially abandoning plans for near-term human exploration beyond Earth orbit with the shift towards a "faster, better, cheaper" strategy for robotic exploration.

While working at Martin Marietta designing interplanetary mission architectures, Robert Zubrin perceived a fundamental flaw in the SEI program. Zubrin came to understand that if NASA's plan was to fully utilize as many technologies as possible in support of sending the mission to Mars, it would become politically untenable. In his own words:

The exact opposite of the correct way to do engineering.

Zubrin's alternative to this "Battlestar Galactica" mission strategy (dubbed so by its detractors for the large, nuclear powered spaceships that supposedly resembled the science-fiction spaceship of the same name) involved a longer surface stay, a faster flight-path in the form of a conjunction class mission, in situ resource utilization and craft launched directly from the surface of Earth to Mars as opposed to be being assembled in orbit or by a space-based drydock. After receiving approval from management at Marietta, a 12-man team within the company began to work out the details of the mission. While they focused primarily on more traditional mission architectures, Zubrin began to collaborate with colleague David Baker's extremely simple, stripped-down and robust strategy. Their goal to "use local resources, travel light, and live off the land" became the hallmark of Mars Direct.

The first flight of the Ares rocket (not to be confused with the similarly named rocket of the now defunct Constellation program) would take an unmanned Earth Return Vehicle to Mars after a 6-month cruise phase, with a supply of hydrogen, a chemical plant and a small nuclear reactor. Once there, a series of chemical reactions (the Sabatier reaction coupled with electrolysis) would be used to combine a small amount of hydrogen (8 tons) carried by the "Earth Return Vehicle" with the carbon dioxide of the Martian atmosphere to create up to 112 tonnes of methane and oxygen. This relatively simple chemical-engineering procedure was used regularly in the 19th and 20th centuries, and would ensure that only 7% of the return propellant would need to be carried to the surface of Mars.

96 tonnes of methane and oxygen would be needed to send the "Earth Return Vehicle" on a trajectory back home at the conclusion of the surface stay; the rest would be available for Mars rovers. The process of generating fuel is expected to require approximately ten months to complete.

Some 26 months after the "Earth Return Vehicle" is originally launched from Earth, a second vehicle, the Mars Habitat Unit, would be launched on a 6-month long low-energy transfer trajectory to Mars, and would carry a crew of four astronauts (the minimum number required so that the team can be split in two without leaving anyone alone). The Habitat Unit would not be launched until the automated factory aboard the ERV had signaled the successful production of chemicals required for operation on the planet and the return trip to Earth. During the trip, artificial gravity would be generated by tethering the Habitat Unit to the spent upper stage of the booster, and setting them rotating about a common axis. This rotation would produce a comfortable 1 "g" working environment for the astronauts, freeing them of the debilitating effects of long-term exposure to weightlessness.

Upon reaching Mars, the upper stage would be jettisoned, with the Habitat Unit aerobraking into Mars orbit before soft-landing in proximity to the "Earth Return Vehicle". Precise landing would be supported by a radar beacon started by the first lander. Once on Mars, the crew would spend 18 months on the surface, carrying out a range of scientific research, aided by a small rover vehicle carried aboard their Mars Habitat Unit, and powered by the methane produced by the Earth Return Vehicle.

To return, the crew would use the "Earth Return Vehicle", leaving the Mars Habitat Unit for the possible use of subsequent explorers. On the return trip to Earth, the propulsion stage of the Earth Return Vehicle would be used as a counterweight to generate artificial gravity for the trip back.

Follow-up missions would be dispatched at 2 year intervals to Mars to ensure that a redundant ERV would be on the surface at all times, waiting to be used by the next crewed mission or the current crew in an emergency. In such an emergency scenario, the crew would trek hundreds of kilometers to the other ERV in their long-range vehicle.

The Mars Direct proposal includes a component for a Launch Vehicle "Ares", an Earth Return Vehicle (ERV) and a Mars Habitat Unit (MHU).

The plan involves several launches making use of heavy-lift boosters of similar size to the Saturn V used for the Apollo missions, which would potentially be derived from Space Shuttle components. This proposed rocket is dubbed "Ares", which would use space shuttle Advanced Solid Rocket Boosters, a modified shuttle external tank, and a new Lox/LH2 third stage for the trans-Mars injection of the payload. Ares would put 121 tonnes into a 300 km circular orbit, and boost 47 tonnes toward Mars.

The Earth Return Vehicle is a two-stage vehicle. The upper stage comprises the living accommodation for the crew during their six-month return trip to Earth from Mars. The lower stage contains the vehicle's rocket engines and a small chemical production plant.

The Mars Habitat Unit is a 2- or 3-deck vehicle providing a comprehensive living and working environment for a Mars crew. In addition to individual sleeping quarters which provide a degree of privacy for each of the crew and a place for personal effects, the Mars Habitat Unit includes a communal living area, a small galley, exercise area, and hygiene facilities with closed-cycle water purification. The lower deck of the Mars Habitat Unit provides the primary working space for the crew: small laboratory areas for carrying out geology and life science research; storage space for samples, airlocks for reaching the surface of Mars, and a suiting-up area where crew members prepare for surface operations. Protection from harmful radiation while in space and on the surface of Mars (e.g. from solar flares) would be provided by a dedicated "storm shelter" in the core of the vehicle.

The Mars Habitat Unit would also include a small pressurized rover that is stored in the lower deck area and assembled on the surface of Mars. Powered by a methane engine, it is designed to extend the range over which astronauts can explore the surface of Mars out to 320 km.

Since it was first proposed as a part of Mars Direct, the Mars Habitat Unit has been adopted by NASA as a part of their Mars Design Reference Mission, which uses two Mars Habitat Units – one of which flies to Mars unmanned, providing a dedicated laboratory facility on Mars, together with the capacity to carry a larger rover vehicle. The second Mars Habitat Unit flies to Mars with the crew, its interior given over completely to living and storage space.

To prove the viability of the Mars Habitat Unit, the Mars Society has implemented the Mars Analogue Research Station Program (MARS), which has established a number of prototype Mars Habitat Units around the world.

Baker pitched Mars Direct at the Marshall Spaceflight Center in April 1990, where reception was very positive. The engineers flew around the country to present their plan, which generated significant interest. When their tour culminated in a demonstration at the National Space Society they received a standing ovation. The plan gained rapid media attention shortly afterwards.

Resistance to the plan came from teams within NASA working on the Space Station and advanced propulsion concepts. The NASA administration rejected Mars Direct. Zubrin remained committed to the strategy, and after parting with David Baker attempted to convince the new NASA administration of Mars Direct's merits in 1992.

After being granted a small research fund at Martin Marietta, Zubrin and his colleagues successfully demonstrated an in-situ propellant generator which achieved an efficiency of 94%. No chemical engineers partook in the development of the demonstration hardware. After showing the positive results to the Johnson Space Center, the NASA administration still held several reservations about the plan.

In November 2003, Zubrin was invited to speak to the U.S. Senate committee on the future of space exploration. Two months later the Bush administration announced the creation of the Constellation program, a manned spaceflight initiative with the goal of sending humans to the Moon by 2020. While a Mars mission was not specifically detailed, a plan to reach Mars based on utilizing the Orion spacecraft was tentatively developed for implementation in the 2030s. In 2009 the Obama administration began a review of the Constellation program, and after budgetary concerns the program was cancelled in 2010.

There are a variety of psychological and sociological issues that could affect long-duration expeditionary space missions. Early human spaceflight missions to Mars are expected by some to have significant psycho-social problems to overcome, as well as provide considerable data for refining mission design, mission planning, and crew selection for future missions.

Since Mars Direct was initially conceived, it has undergone regular review and development by Zubrin himself, the Mars Society, NASA, Stanford University and others.

Zubrin and Weaver developed a modified version of Mars Direct, called Mars Semi-Direct, in response to some specific criticisms. This mission consists of three spacecraft and includes a "Mars Ascent Vehicle" (MAV). The ERV remains in Mars orbit for the return journey, while the unmanned MAV lands and manufactures propellants for the ascent back up to Mars orbit. The Mars Semi-Direct architecture has been used as the basis of a number of studies, including the NASA Design Reference Missions.

When subjected to the same cost-analysis as the 90-day report, Mars Semi-Direct was predicted to cost 55 billion dollars over 10 years, capable of fitting into the existing NASA budget.

Mars Semi-Direct became the basis of the Design Reference Mission 1.0 of NASA, replacing the Space Exploration Initiative.

The NASA model, referred to as the Design Reference Mission, on version 5.0 as of September 1, 2012, calls for a significant upgrade in hardware (at least three launches per mission, rather than two), and sends the ERV to Mars fully fueled, parking it in orbit above the planet for subsequent rendezvous with the MAV.

With the potentially imminent advent of low-cost heavy lift capability, Zubrin has posited a dramatically lower cost manned Mars mission using hardware developed by space transport company SpaceX. In this simpler plan, a crew of two would be sent to Mars by a single Falcon Heavy launch, the Dragon spacecraft acting as their interplanetary cruise habitat. Additional living space for the journey would be enabled through the use of inflatable add-on modules if required. The problems associated with long-term weightlessness would be addressed in the same manner as the baseline Mars Direct plan, a tether between the Dragon habitat and the TMI (Trans-Mars Injection) stage acting to allow rotation of the craft.

The Dragon's heatshield characteristics could allow for a safe descent if landing rockets of sufficient power were made available. Research at NASA's Ames Research Center has demonstrated that a robotic Dragon would be capable of a fully propulsive landing on the Martian surface. On the surface, the crew would have at their disposal two Dragon spacecraft with inflatable modules as habitats, two ERVs, two Mars ascent vehicles and 8 tonnes of cargo.

The Mars Society and Stanford studies retain the original two-vehicle mission profile of Mars Direct, but increase the crew size to six.

Mars Society Australia developed their own four-person "Mars Oz" reference mission, based on Mars Semi-Direct. This study uses horizontally landing, bent biconic shaped modules, and relies on solar power and chemical propulsion throughout, where Mars Direct and the DRMs used nuclear reactors for surface power and, in the case of the DRMs for propulsion as well. The Mars Oz reference mission also differs in assuming, based on space station experience, that spin gravity will not be required.

The Mars Society has argued the viability of the Mars Habitat Unit concept through their Mars Analogue Research Station program. These are two or three decked vertical cylinders ~8 m in diameter and 8 m high. Mars Society Australia plans to build its own station based on the Mars Oz design. The Mars Oz design features a horizontal cylinder 4.7 m in diameter and 18 m long, with a tapered nose. A second similar module will function as a garage and power and logistics module.

Mars Direct was featured on a Discovery Channel programs "Mars: The Next Frontier" in which issues were discussed surrounding NASA funding of the project, and on "Mars Underground", where the plan is discussed more in-depth.

"Mars to Stay" proposals involve not returning the first immigrant/explorers immediately, or ever. It has been suggested the cost of sending a four or six person team could be one fifth to one tenth the cost of returning that same four or six person team. Depending on the precise approach taken, a quite complete lab could be sent and landed for less than the cost of sending back even 50 kilos of Martian rocks. Twenty or more persons could be sent for the cost of returning four.






</doc>
<doc id="19848" url="https://en.wikipedia.org/wiki?curid=19848" title="Max Planck">
Max Planck

Max Karl Ernst Ludwig Planck, ForMemRS (; ; 23 April 1858 – 4 October 1947) was a German theoretical physicist whose discovery of energy quanta won him the Nobel Prize in Physics in 1918.

Planck made many contributions to theoretical physics, but his fame as a physicist rests primarily on his role as the originator of quantum theory, which revolutionized human understanding of atomic and subatomic processes. In 1948 the German scientific institution Kaiser Wilhelm Society (of which Planck was twice president) was renamed Max Planck Society (MPS). The MPS now includes 83 institutions representing a wide range of scientific directions.

Planck came from a traditional, intellectual family. His paternal great-grandfather and grandfather were both theology professors in Göttingen; his father was a law professor at the University of Kiel and Munich. One of his uncles was also a judge.
Planck was born in 1858 in Kiel, Holstein, to Johann Julius Wilhelm Planck and his second wife, Emma Patzig. He was baptized with the name of "Karl Ernst Ludwig Marx Planck"; of his given names, "Marx" (a now obsolete variant of "Markus" or maybe simply an error for "Max", which is actually short for "Maximilian") was indicated as the "appellation name". However, by the age of ten he signed with the name "Max" and used this for the rest of his life.

He was the 6th child in the family, though two of his siblings were from his father's first marriage. War was common during Planck's early years and among his earliest memories was the marching of Prussian and Austrian troops into Kiel during the Second Schleswig War in 1864. In 1867 the family moved to Munich, and Planck enrolled in the Maximilians gymnasium school, where he came under the tutelage of Hermann Müller, a mathematician who took an interest in the youth, and taught him astronomy and mechanics as well as mathematics. It was from Müller that Planck first learned the principle of conservation of energy. Planck graduated early, at age 17. This is how Planck first came in contact with the field of physics.

Planck was gifted when it came to music. He took singing lessons and played piano, organ and cello, and composed songs and operas. However, instead of music he chose to study physics.
The Munich physics professor Philipp von Jolly advised Planck against going into physics, saying, "In this field, almost everything is already discovered, and all that remains is to fill a few holes." Planck replied that he did not wish to discover new things, but only to understand the known fundamentals of the field, and so began his studies in 1874 at the University of Munich. Under Jolly's supervision, Planck performed the only experiments of his scientific career, studying the diffusion of hydrogen through heated platinum, but transferred to theoretical physics.

In 1877 he went to the Friedrich Wilhelms University in Berlin for a year of study with physicists Hermann von Helmholtz and Gustav Kirchhoff and mathematician Karl Weierstrass. He wrote that Helmholtz was never quite prepared, spoke slowly, miscalculated endlessly, and bored his listeners, while Kirchhoff spoke in carefully prepared lectures which were dry and monotonous. He soon became close friends with Helmholtz. While there he undertook a program of mostly self-study of Clausius's writings, which led him to choose thermodynamics as his field.

In October 1878 Planck passed his qualifying exams and in February 1879 defended his dissertation, "Über den zweiten Hauptsatz der mechanischen Wärmetheorie" ("On the second law of thermodynamics"). He briefly taught mathematics and physics at his former school in Munich.

By the year 1880, Planck had obtained the two highest academic degrees offered in Europe. The first was a doctorate degree after he completed his paper detailing his research and theory of thermodynamics. He then presented his thesis called "Gleichgewichtszustände isotroper Körper in verschiedenen Temperaturen" ("Equilibrium states of isotropic bodies at different temperatures"), which earned him a habilitation.

With the completion of his habilitation thesis, Planck became an unpaid Privatdozent (German academic rank comparable to lecturer/assistant professor) in Munich, waiting until he was offered an academic position. Although he was initially ignored by the academic community, he furthered his work on the field of heat theory and discovered one after another the same thermodynamical formalism as Gibbs without realizing it. Clausius's ideas on entropy occupied a central role in his work.

In April 1885 the University of Kiel appointed Planck as associate professor of theoretical physics. Further work on entropy and its treatment, especially as applied in physical chemistry, followed. He published his "Treatise on Thermodynamics" in 1897. He proposed a thermodynamic basis for Svante Arrhenius's theory of electrolytic dissociation.

In 1889 he was named the successor to Kirchhoff's position at the Friedrich-Wilhelms-Universität in Berlin – presumably thanks to Helmholtz's intercession – and by 1892 became a full professor. In 1907 Planck was offered Boltzmann's position in Vienna, but turned it down to stay in Berlin. During 1909, as a University of Berlin professor, he was invited to become the Ernest Kempton Adams Lecturer in Theoretical Physics at Columbia University in New York City. A series of his lectures were translated and co-published by Columbia University professor A. P. Wills. He retired from Berlin on 10 January 1926, and was succeeded by Erwin Schrödinger.

In March 1887 Planck married Marie Merck (1861–1909), sister of a school fellow, and moved with her into a sublet apartment in Kiel. They had four children: Karl (1888–1916), the twins Emma (1889–1919) and Grete (1889–1917), and Erwin (1893–1945).

After the apartment in Berlin, the Planck family lived in a villa in Berlin-Grunewald, Wangenheimstrasse 21. Several other professors from University of Berlin lived nearby, among them theologian Adolf von Harnack, who became a close friend of Planck. Soon the Planck home became a social and cultural center. Numerous well-known scientists, such as Albert Einstein, Otto Hahn and Lise Meitner were frequent visitors. The tradition of jointly performing music had already been established in the home of Helmholtz.

After several happy years, in July 1909 Marie Planck died, possibly from tuberculosis. In March 1911 Planck married his second wife, Marga von Hoesslin (1882–1948); in December his fifth child Hermann was born.

During the First World War Planck's second son Erwin was taken prisoner by the French in 1914, while his oldest son Karl was killed in action at Verdun. Grete died in 1917 while giving birth to her first child. Her sister died the same way two years later, after having married Grete's widower. Both granddaughters survived and were named after their mothers. Planck endured these losses stoically.

In January 1945 Erwin, to whom he had been particularly close, was sentenced to death by the Nazi Volksgerichtshof because of his participation in the failed attempt to assassinate Hitler in July 1944. Erwin was executed on 23 January 1945.

As a professor at the Friedrich-Wilhelms-Universität in Berlin, Planck joined the local Physical Society. He later wrote about this time: "In those days I was essentially the only theoretical physicist there, whence things were not so easy for me, because I started mentioning entropy, but this was not quite fashionable, since it was regarded as a mathematical spook". Thanks to his initiative, the various local Physical Societies of Germany merged in 1898 to form the German Physical Society (Deutsche Physikalische Gesellschaft, DPG); from 1905 to 1909 Planck was the president.

Planck started a six-semester course of lectures on theoretical physics, "dry, somewhat impersonal" according to Lise Meitner, "using no notes, never making mistakes, never faltering; the best lecturer I ever heard" according to an English participant, James R. Partington, who continues: "There were always many standing around the room. As the lecture-room was well heated and rather close, some of the listeners would from time to time drop to the floor, but this did not disturb the lecture." Planck did not establish an actual "school"; the number of his graduate students was only about 20, among them:


In 1894 Planck turned his attention to the problem of black-body radiation. The problem had been stated by Kirchhoff in 1859: "how does the intensity of the electromagnetic radiation emitted by a black body (a perfect absorber, also known as a cavity radiator) depend on the frequency of the radiation (i.e., the color of the light) and the temperature of the body?". The question had been explored experimentally, but no theoretical treatment agreed with experimental values. Wilhelm Wien proposed Wien's law, which correctly predicted the behaviour at high frequencies, but failed at low frequencies. The Rayleigh–Jeans law, another approach to the problem, agreed with experimental results at low frequencies, but created what was later known as the "ultraviolet catastrophe" at high frequencies. However, contrary to many textbooks this was not a motivation for Planck.

Planck's first proposed solution to the problem in 1899 followed from what Planck called the "principle of elementary disorder", which allowed him to derive Wien's law from a number of assumptions about the entropy of an ideal oscillator, creating what was referred-to as the Wien–Planck law. Soon it was found that experimental evidence did not confirm the new law at all, to Planck's frustration. Planck revised his approach, deriving the first version of the famous Planck black-body radiation law, which described the experimentally observed black-body spectrum well. It was first proposed in a meeting of the DPG on 19 October 1900 and published in 1901. This first derivation did not include energy quantisation, and did not use statistical mechanics, to which he held an aversion. In November 1900 Planck revised this first approach, relying on Boltzmann's statistical interpretation of the second law of thermodynamics as a way of gaining a more fundamental understanding of the principles behind his radiation law. As Planck was deeply suspicious of the philosophical and physical implications of such an interpretation of Boltzmann's approach, his recourse to them was, as he later put it, "an act of despair ... I was ready to sacrifice any of my previous convictions about physics".

The central assumption behind his new derivation, presented to the DPG on 14 December 1900, was the supposition, now known as the Planck postulate, that electromagnetic energy could be emitted only in quantized form, in other words, the energy could only be a multiple of an elementary unit:

where is Planck's constant, also known as Planck's action quantum (introduced already in 1899), and is the frequency of the radiation. Note that the elementary units of energy discussed here are represented by and not simply by . Physicists now call these quanta photons, and a photon of frequency will have its own specific and unique energy. The total energy at that frequency is then equal to multiplied by the number of photons at that frequency.
At first Planck considered that quantisation was only "a purely formal assumption ... actually I did not think much about it ..."; nowadays this assumption, incompatible with classical physics, is regarded as the birth of quantum physics and the greatest intellectual accomplishment of Planck's career (Ludwig Boltzmann had been discussing in a theoretical paper in 1877 the possibility that the energy states of a physical system could be discrete). The discovery of Planck's constant enabled him to define a new universal set of physical units (such as the Planck length and the Planck mass), all based on fundamental physical constants upon which much of quantum theory is based. In recognition of Planck's fundamental contribution to a new branch of physics, he was awarded the Nobel Prize in Physics for 1918 (he actually received the award in 1919).

Subsequently, Planck tried to grasp the meaning of energy quanta, but to no avail. "My unavailing attempts to somehow reintegrate the action quantum into classical theory extended over several years and caused me much trouble." Even several years later, other physicists like Rayleigh, Jeans, and Lorentz set Planck's constant to zero in order to align with classical physics, but Planck knew well that this constant had a precise nonzero value. "I am unable to understand Jeans' stubbornness – he is an example of a theoretician as should never be existing, the same as Hegel was for philosophy. So much the worse for the facts if they don't fit."

Max Born wrote about Planck: "He was, by nature, a conservative mind; he had nothing of the revolutionary and was thoroughly skeptical about speculations. Yet his belief in the compelling force of logical reasoning from facts was so strong that he did not flinch from announcing the most revolutionary idea which ever has shaken physics."

In 1905 the three epochal papers by Albert Einstein were published in the journal "Annalen der Physik". Planck was among the few who immediately recognized the significance of the special theory of relativity. Thanks to his influence, this theory was soon widely accepted in Germany. Planck also contributed considerably to extend the special theory of relativity. For example, he recast the theory in terms of classical action.

Einstein's hypothesis of light "quanta" (photons), based on Heinrich Hertz's 1887 discovery (and further investigation by Philipp Lenard) of the photoelectric effect, was initially rejected by Planck. He was unwilling to discard completely Maxwell's theory of electrodynamics. "The theory of light would be thrown back not by decades, but by centuries, into the age when Christiaan Huygens dared to fight against the mighty emission theory of Isaac Newton ..."

In 1910 Einstein pointed out the anomalous behavior of specific heat at low temperatures as another example of a phenomenon which defies explanation by classical physics. Planck and Nernst, seeking to clarify the increasing number of contradictions, organized the First Solvay Conference (Brussels 1911). At this meeting Einstein was able to convince Planck.

Meanwhile, Planck had been appointed dean of Berlin University, whereby it was possible for him to call Einstein to Berlin and establish a new professorship for him (1914). Soon the two scientists became close friends and met frequently to play music together.

At the onset of the First World War Planck endorsed the general excitement of the public, writing that, "Besides much that is horrible, there is also much that is unexpectedly great and beautiful: the smooth solution of the most difficult domestic political problems by the unification of all parties (and) ... the extolling of everything good and noble."

Nonetheless, Planck refrained from the extremes of nationalism. In 1915, at a time when Italy was about to join the Allied Powers, he voted successfully for a scientific paper from Italy, which received a prize from the Prussian Academy of Sciences, where Planck was one of four permanent presidents.

Planck also signed the infamous "Manifesto of the 93 intellectuals", a pamphlet of polemic war propaganda (while Einstein retained a strictly pacifistic attitude which almost led to his imprisonment, only being spared thanks to his Swiss citizenship).

In the turbulent post-war years, Planck, now the highest authority of German physics, issued the slogan "persevere and continue working" to his colleagues.

In October 1920 he and Fritz Haber established the "Notgemeinschaft der Deutschen Wissenschaft" (Emergency Organization of German Science), aimed at providing financial support for scientific research. A considerable portion of the money the organization would distribute was raised abroad.

Planck also held leading positions at Berlin University, the Prussian Academy of Sciences, the German Physical Society and the Kaiser Wilhelm Society (which became the Max Planck Society in 1948). During this time economic conditions in Germany were such that he was hardly able to conduct research. In 1926, Planck became a foreign member of the Royal Netherlands Academy of Arts and Sciences.

During the interwar period, Planck became a member of the Deutsche Volks-Partei (German People's Party), the party of Nobel Peace Prize laureate Gustav Stresemann, which aspired to liberal aims for domestic policy and rather revisionistic aims for politics around the world.

Planck disagreed with the introduction of universal suffrage and later expressed the view that the Nazi dictatorship resulted from "the ascent of the rule of the crowds".

At the end of the 1920s Bohr, Heisenberg and Pauli had worked out the Copenhagen interpretation of quantum mechanics, but it was rejected by Planck, and by Schrödinger, Laue, and Einstein as well. Planck expected that wave mechanics would soon render quantum theory—his own child—unnecessary. This was not to be the case, however. Further work only cemented quantum theory, even against his and Einstein's philosophical revulsions. Planck experienced the truth of his own earlier observation from his struggle with the older views in his younger years: "A new scientific truth does not triumph by convincing its opponents and making them see the light, but rather because its opponents eventually die, and a new generation grows up that is familiar with it."

When the Nazis came to power in 1933, Planck was 74. He witnessed many Jewish friends and colleagues expelled from their positions and humiliated, and hundreds of scientists emigrate from Nazi Germany. Again he tried to "persevere and continue working" and asked scientists who were considering emigration to remain in Germany. Nevertheless, he did help his nephew, the economist Hermann Kranold, to emigrate to London after his arrest. He hoped the crisis would abate soon and the political situation would improve.

Otto Hahn asked Planck to gather well-known German professors in order to issue a public proclamation against the treatment of Jewish professors, but Planck replied, "If you are able to gather today 30 such gentlemen, then tomorrow 150 others will come and speak against it, because they are eager to take over the positions of the others." Under Planck's leadership, the Kaiser Wilhelm Society (KWG) avoided open conflict with the Nazi regime, except concerning Fritz Haber. Planck tried to discuss the issue with Adolf Hitler but was unsuccessful. In the following year, 1934, Haber died in exile.

One year later, Planck, having been the president of the KWG since 1930, organized in a somewhat provocative style an official commemorative meeting for Haber. He also succeeded in secretly enabling a number of Jewish scientists to continue working in institutes of the KWG for several years. In 1936, his term as president of the KWG ended, and the Nazi government pressured him to refrain from seeking another term.

As the political climate in Germany gradually became more hostile, Johannes Stark, prominent exponent of Deutsche Physik ("German Physics", also called "Aryan Physics") attacked Planck, Sommerfeld and Heisenberg for continuing to teach the theories of Einstein, calling them "white Jews". The "Hauptamt Wissenschaft" (Nazi government office for science) started an investigation of Planck's ancestry, claiming that he was "1/16 Jewish", but Planck himself denied it.
In 1938 Planck celebrated his 80th birthday. The DPG held a celebration, during which the Max-Planck medal (founded as the highest medal by the DPG in 1928) was awarded to French physicist Louis de Broglie. At the end of 1938, the Prussian Academy lost its remaining independence and was taken over by Nazis ("Gleichschaltung"). Planck protested by resigning his presidency. He continued to travel frequently, giving numerous public talks, such as his talk on Religion and Science, and five years later he was sufficiently fit to climb 3,000-metre peaks in the Alps.

During the Second World War the increasing number of Allied bombing missions against Berlin forced Planck and his wife to temporarily leave the city and live in the countryside. In 1942 he wrote: "In me an ardent desire has grown to persevere this crisis and live long enough to be able to witness the turning point, the beginning of a new rise." In February 1944, his home in Berlin was completely destroyed by an air raid, annihilating all his scientific records and correspondence. His rural retreat was threatened by the rapid advance of the Allied armies from both sides.

In 1944 Planck's son Erwin was arrested by the Gestapo following the attempted assassination of Hitler in the 20 July plot. He was tried and sentenced to death by the People's Court in October 1944. Erwin was hanged at Berlin's Plötzensee Prison in January 1945. The death of his son destroyed much of Planck's will to live. After the end of the war Planck, his second wife, and his son by her were brought to a relative in Göttingen, where Planck died on 4 October 1947. His grave is situated in the old Stadtfriedhof (City Cemetery) in Göttingen.

Planck was a member of the Lutheran Church in Germany. He was very tolerant towards alternative views and religions.
In a lecture in 1937 entitled "Religion und Naturwissenschaft" (Religion and Natural Science) he suggested the importance of these symbols and rituals related directly with a believer's ability to worship God, but that one must be mindful that the symbols provide an imperfect illustration of divinity. He criticized atheism for being focused on the derision of such symbols, while at the same time warned of the over-estimation of the importance of such symbols by believers.

Planck was tolerant and favorable to all religions. Although he remained in the Lutheran Church, he did not promote Christian or Biblical views. He believed "the faith in miracles must yield, step by step, before the steady and firm advance of the facts of science, and its total defeat is undoubtedly a matter of time." 

In his 1937 lecture "Religion and Naturwissenschaft", Planck expressed the view that God is everywhere present, and held that "the holiness of the unintelligible Godhead is conveyed by the holiness of symbols." Atheists, he thought, attach too much importance to what are merely symbols. He was a churchwarden from 1920 until his death, and believed in an almighty, all-knowing, beneficent God (though not necessarily a personal one). Both science and religion wage a "tireless battle against skepticism and dogmatism, against unbelief and superstition" with the goal "toward God!"

Planck said in 1944, "As a man who has devoted his whole life to the most clear headed science, to the study of matter, I can tell you as a result of my research about atoms this much: There is no matter as such. All matter originates and exists only by virtue of a force which brings the particle of an atom to vibration and holds this most minute solar system of the atom together. We must assume behind this force the existence of a conscious and intelligent spirit (orig. geist). This spirit is the matrix of all matter."

Planck regarded the scientist as a man of imagination and Christian faith. He said: "Both religion and science require a belief in God. For believers, God is in the beginning, and for physicists He is at the end of all considerations… To the former He is the foundation, to the latter, the crown of the edifice of every generalized world view".

On the other hand, Planck wrote, "...'to believe' means 'to recognize as a truth,' and the knowledge of nature, continually advancing on incontestably safe tracks, has made it utterly impossible for a person possessing some training in natural science to recognize as founded on truth the many reports of extraordinary occurrences contradicting the laws of nature, of miracles which are still commonly regarded as essential supports and confirmations of religious doctrines, and which formerly used to be accepted as facts pure and simple, without doubt or criticism. The belief in miracles must retreat step by step before relentlessly and reliably progressing science and we cannot doubt that sooner or later it must vanish completely."

Later in life, Planck's views on God were that of a deist. For example, six months before his death a rumour started that he had converted to Catholicism, but when questioned what had brought him to make this step, he declared that, although he had always been deeply religious, he did not believe "in a personal God, let alone a Christian God".






</doc>
<doc id="19849" url="https://en.wikipedia.org/wiki?curid=19849" title="March 30">
March 30





</doc>
<doc id="19852" url="https://en.wikipedia.org/wiki?curid=19852" title="Madhuri Dixit">
Madhuri Dixit

Madhuri Dixit Nene (; born 15 May 1967) is an Indian actress, producer, television personality and a music artist. One of the most popular actresses of Hindi cinema, she has appeared in over 70 Bollywood films. The recipient of such accolades as six Filmfare Awards, she was one of the country's highest-paid actresses in the 1990s and early 2000s, and has featured seven times on "Forbes India" Celebrity 100 list. In 2008, the Government of India awarded her with Padma Shri, the fourth highest civilian honour of the country.

Born and raised in Bombay, Dixit initially aspired to study microbiology, but discontinued her studies when she received offers for film roles and made her acting debut in 1984 with a leading role in the drama "Abodh". After a few commercially failed films, she had her breakthrough with the action romance "Tezaab" (1988) and established herself with starring roles in the top-grossing romantic dramas "Dil" (1990), "Beta" (1992), "Hum Aapke Hain Koun..!" (1994), and "Dil To Pagal Hai" (1997). She won four Best Actress awards at the Filmfare Awards for her performances in them. Her other commercially successful films during this period include "Ram Lakhan" (1989), "Tridev" (1989), "Thanedaar" (1990), "Kishen Kanhaiya" (1990), "Saajan" (1991), "Khalnayak" (1993), and "Raja" (1995).

Dixit also earned praise for her dramatic performances in the crime film "Parinda" (1989), the romantic dramas "Prem Pratigyaa" (1989) and "Devdas" (2002), receiving the Filmfare Award for Best Supporting Actress for the latter, the thrillers "Anjaam" (1994) and "Pukar" (2000), and the social dramas "Mrityudand" (1997) and "Lajja" (2001). Following a sabbatical from acting in 2002, Dixit starred in the musical "Aaja Nachle" (2007), and worked intermittently in the next decade, gaining appreciation for her starring roles in the black comedy "Dedh Ishqiya" (2014) and the Marathi comedy drama "Bucket List" (2018). Her highest-grossing release came with the adventure comedy "Total Dhamaal" (2019).

In addition to acting in films, Dixit has been engaged in philanthropic activities. She has worked with UNICEF since 2014 to advocate the rights of children and prevent child labour, and is a prominent celebrity endorser for brands and products. She participates in concert tours and stage shows, features frequently as a talent judge for dance reality shows, has launched an online dance academy and is the co-founder of the production company RnM Moving Pictures. Dixit has been married to Shriram Nene since 1999, with whom she has two children.

Madhuri Dixit was born on 15 May 1967 into a Marathi Kokanastha Brahmin family in Bombay (present-day Mumbai) to Shankar and Snehlata Dixit. She has two elder sisters and an elder brother. She kindled an interest in dance at an early age of three, and went on to train in Kathak for eight years; later on becoming a professionally trained Kathak dancer.

Dixit received her education at Divine Child High School in Andheri. Apart from her studies, she participated in extra-curricular activities, such as dramatics. Aspiring to become a microbiologist, Dixit enrolled at the Sathaye college in Vile Parle (Mumbai) where she studied microbiology as one of her subjects in BSc. However, six months after she had commenced her course, Dixit decided to discontinue studies and pursue a full-time career in films.

Dixit made her cinema debut in 1984 with Rajshri Productions' drama "Abodh", opposite Bengali actor, Tapas Paul. Upon release, the film failed commercially but Dixit's performance earned her positive reviews from critics. Aakash Barvalia of Gomolo wrote, "Madhuri excels in her role as a young bride who acquits herself well as the naive village girl and does not realise what marriage actually entails."
Her only release of 1985 - "Awara Baap" – flopped at the box office. During this time, a monochrome photograph of hers, shot by Gautam Rajadhyaksha was featured on the cover of the then popular magazine "Debonair" and she appeared as the cover girl of Filmfare in April 1986.

Dixit's next four releases were the dramas "Swati" (1986), "Manav Hatya" (1986), "Hifazat" (1987) and "Uttar Dakshin" (1987). None of these films performed well either critically or commercially. Hifazat marked Dixit's first of several collaborations with Anil Kapoor. In 1988, Dixit had four film releases; three of them —"Mohre", "Khatron Ke Khiladi" and "Dayavan" —were commercial failures.

In 1988, Dixit finally attained recognition when she played Mohini, an impoverished and miserable woman, who is forced to dance to make money for her father in N. Chandra's action romance "Tezaab" opposite Anil Kapoor. It went on to become the highest-grossing film of the year and she received her first Filmfare Best Actress Award nomination; the film's success established Dixit as a leading actress of Hindi cinema, and marked a significant turning point in her career. Akshay Shah of Planet Bollywood wrote, "Madhuri Dixit also gives a fine tuned performance. Though she is more remembered for her crowd pleasing dance act Ek Do Teen, her acting needs to be noted, specially in the scenes where she is pitted against Anupam Kher."

Her first release of 1989, "Vardi", did fairly well at the box office. She next re-united with Anil Kapoor for Subhash Ghai's "Ram Lakhan". She played Radha Shastri, a girl who falls in love with her childhood friend, but finds it hard to convince her father. Finishing up as the second highest-grossing film of the year, "Ram Lakhan" emerged as a "super-hit" at the box office. Dixit's next release was the romantic drama "Prem Pratigyaa", in which she was paired opposite Mithun Chakraborty. Her portrayal of Laxmi Rao, a distraught woman who influences a local underworld don letting him give up his bad habits, earned her a second nomination for the Filmfare Best Actress Award. Dixit collaborated with Trimurti Films for the action thriller "Tridev" which featured an ensemble cast (Sunny Deol, Naseeruddin Shah, Jackie Shroff, Sangeeta Bijlani, Sonam and Amrish Puri). It finished up as one of the biggest hits and the third highest-grossing film of the year.

Her next release of the year, Vidhu Vinod Chopra's drama "Parinda", co-starring Anil Kapoor, Jackie Shroff and Nana Patekar was another box office hit. She played Paro, who is killed on her wedding night along with Karan (played by Kapoor) by a gangster (played by Patekar). A major critical success, the film was included in CNN-News18's 2013 list of the "100 greatest Indian films of all time". It was selected as the official Indian submission for the 1990 Academy Award for Best Foreign Language Film but was not nominated. "Rediff.com" opined that Dixit added "touching vulnerability and soft focus appeal to the heavy duty proceedings". Also that year, she starred in "Ilaaka", "Mujrim" (both opposite Mithun Chakrobarty), and "Paap Ka Ant" (opposite Govinda). "Kanoon Apna Apna" opposite Sanjay Dutt was an average grosser.

In 1990, Dixit appeared in nine films. Five of them—"Maha-Sangram", "Deewana Mujh Sa Nahin", "Jeevan Ek Sanghursh", "Sailaab" and "Jamai Raja"—were commercially unsuccessful. Her next release that year was Rakesh Roshan's action comedy "Kishen Kanhaiya" (alongside Anil Kapoor and Shilpa Shirodkar). It tells the story of twin brothers who are separated at birth and re-unite in their youth. Dixit and Shirodkar played the love interests of Kapoor's characters. It was the fourth-highest-grossing film of the year in India. Dixit next played a strong-willed woman in the box-office average action drama "Izzatdaar". She won her first Filmfare Best Actress Award for portraying Madhu, a rich and arrogant girl who falls in love with a poorer boy, in Indra Kumar's romantic drama "Dil" opposite Aamir Khan. It emerged as the highest-grossing film of the year. Rediff.com hailed her performance, commenting "..she showed her range as a performer. She breathed fire as the rebellious lover defying her family, or the forlorn estranged wife longing to be with her ailing better half." Dixit's final release of the year was the action drama "Thanedaar", opposite Dutt, which was another commercial hit.

In 1991, Dixit had five film releases, the first of which was the romance "Pyar Ka Devta". She next starred alongside Jackie Shroff in the psychological thriller "100 Days". She played Devi, a clairvoyant woman who has a vision of a murder and sets out to uncover the truth. The film was a moderately successful. She next starred in "Saajan" opposite Dutt and Salman Khan. A major critical and commercial success, the film earned Dixit praise for her portrayal of Pooja Saxena, who is in love with her idol - Sagar. She received her fourth Best Actress nomination at Filmfare for her work in the film. Tatineni Rama Rao's "Pratikar" and Nana Patekar's "" were her other releases.

Dixit's first release of 1992 was Kumar's drama "Beta", co-starring Anil Kapoor and Aruna Irani. Dixit's portrayal of Saraswati, an educated woman who rebels against her manipulative mother-in-law, earned her critical acclaim. Sukanya Verma mentioned that Dixit delivered "a powerhouse performance against an equally lethal looking Irani, even as Kapoor was overshadowed between the ladies." The film finished up as the biggest hit of the year and won her a second Filmfare Best Actress Award. Following the film's success, Dixit became famously known as the "Dhak Dhak Girl". "Zindagi Ek Jua", "Prem Deewane", "Khel" and "Sangeet" were her other releases of the year.

In 1993, her first release was Sudhir Mishra's "Dharavi" alongside Shabana Azmi, Om Puri and Anil Kapoor. The film was a joint NFDC-Doordarshan production and went on to win the National Film Award for Best Feature Film in Hindi. Her next release was Ramesh Talwar's "Sahibaan" which was commercially successful. Dixit next reunited with Sanjay Dutt and Jackie Shroff in Subhash Ghai's crime drama "Khalnayak". Her portrayal of Ganga, a police officer, who volunteers to go undercover, to trap an escaped criminal, garnered her critical acclaim. India Today wrote, "..she grinds and thrusts in her trademark dhak dhak style. The whistles grow deafening when she stares into the camera, looks at every man in the dark, and promises him her heart-and much more. In one Bangalore theatre, the police were kept on stand-by in case the crowds went berserk." Dixit's performance in "Khalnayak" earned her a sixth nomination for the Filmfare Best Actress Award and became the second highest-grossing film of the year in India. Singeetam Srinivasa Rao's "Phool" and Lawrence D'Souza's "Dil Tera Aashiq" were her other releases of the year.

In 1994, Dixit starred in Rahul Rawail's psychological thriller "Anjaam", which marked her first of many collaborations with Shah Rukh Khan. Dixit's portrayal of Shivani Chopra, a revenge-seeking wife and mother earned her a seventh nomination for the Filmfare Best Actress Award. The film performed moderately well at the box office. Her next release was Rajshri Productions' family drama "Hum Aapke Hain Koun..!" opposite Salman Khan. The film emerged as one of the biggest hits in the history of Hindi cinema and made 1.35 billion worldwide, breaking the record of the film "Sholay" (1975). It became the highest grossing Bollywood film in Hindi cinema history after its theatrical run and held the record for 7 years till the release of "" (2001). Dixit's portrayal of Nisha, who falls in love with Prem (Khan's character) but their plans to be together are put in jeopardy when Nisha's sister dies, fetched her a third Filmfare Best Actress Award and her first Screen Award for Best Actress. Critics believed the film to be "too sweet" but appreciated Dixit's performance. Tripat Narayanan of "New Straits Times" wrote "The Madhuri magic looms large throughout the film. As she emotes through dance, you simply cannot take your eyes off her." In a retrospect review, Rediff wrote, "Madhuri's Nisha was stunning, enthused, plucky and irresistible." Film critic K Hariharan noted, "She is seducing every person on screen, but does it in ways that are so graceful, there is a good balance between profanity and the sacred." The film won two National Award's, including the Best Popular Film Providing Wholesome Entertainment and in the Millennium Edition of the "Guinness Book of World Records", "Hum Aapke Hain Kaun" became Bollywood's highest-grossing film.

Dixit achieved further success when she reunited with Indra Kumar for the romantic drama "Raja" opposite Sanjay Kapoor. She portrayed Madhu, a rich girl who falls for her childhood friend (played by Kapoor), however, she finds it tough to convince her two brothers of this relationship. It emerged as the third highest-grossing film of the year and its success was attributed to Dixit's immense popularity. She won a second Screen Award for Best Actress for her performance. Her next release was David Dhawan's "Yaraana" opposite Rishi Kapoor, in which she played Lalita, a dancer on the run from her abusive lover. The film underperformed at the box office. Both the films earned her nominations for the Filmfare Best Actress Award.

The following year, both her films "Prem Granth" and "Rajkumar" flopped at the box office. In 1997, Dixit received critical acclaim for her portrayal of Ketki Singh, a village woman who struggles to confront and defeat the forces of oppression and male domination in Prakash Jha's "Mrityudand" alongside Shabana Azmi and Shilpa Shirodkar. In a review for India Today, Anupama Chopra wrote, " Dixit gives her career's best performance. Simply dressed, she looks stunning and acts even better. She is by turns romantic, vulnerable, angry - the perfect foil to Azmi's long-suffering 'badi bahu'." "Screen" magazine deemed her portrayal "fiery" and appreciated the lack of glamour in the part. For her performance, Dixit won a third Screen Award for Best Actress. She next starred in the dramas "Koyla", "Mahaanta" and "Mohabbat". With the exception of Koyla, none of these films performed well either critically or commercially.

Dixit's fifth and final release of 1997 was Yash Chopra's musical romantic drama "Dil To Pagal Hai". Co-starring Shah Rukh Khan and Karisma Kapoor, the film depicts the love stories of the dancers in a musical dance troupe. Her role of Pooja, a woman faced with a moral dilemma in a love triangle fetched her a fourth Filmfare Best Actress Award and the Zee Cine Award for Best Actor – Female. "Dil To Pagal Hai" emerged as a 'blockbuster' and was the second highest-grossing film of the year in India. At the 45th National Film Awards, the film won three awards, including the Best Popular Film Providing Wholesome Entertainment.

She next starred in the N.Chandra- directed drama "Wajood" (1998) opposite Nana Patekar and Mukul Dev. She played Apoorva, a very rich girl who is misunderstood by Malhar, played by Patekar. Suparn Verma of "Rediff" commented: "..She nevertheless shows that even a weak role cannot stifle her as she animates the screen like only she can. Truly, the coming together of Nana, Madhuri and Chandra in one film is a tour de force." Her next and only release of 1999 was the romance "Aarzoo" (1999) opposite Akshay Kumar and Saif Ali Khan. Upon release, the film emerged commercially unsuccessful.

In 2000, Dixit starred in Rajkumar Santoshi's "Pukar" opposite Anil Kapoor. A love story based on the backdrop of the Indian Army, the film was shot over a course of 350 days. Dixit's portrayal of Anjali, a heartbroken and jealous woman who swears revenge on Jai (played by Kapoor) for rejecting her, garnered her several Best Actress nominations at various award ceremonies, including Filmfare and Screen. A review in "Filmfare" said that both "Anil Kapoor and Madhuri, veterans in their field, outdo themselves in the film". It won two National Film Awards, including the Nargis Dutt Award for Best Feature Film on National Integration. She then played the title character in "Gaja Gamini", the first feature film directed by painter M. F. Husain. Hussain got fixated with Dixit, and watched her movie "Hum Aapke Hain Koun..!" several times, and was certain that he would make a film only with her. The film followed the story of Gaja Gamini, who appears in various incarnations as Mona Lisa, Shakuntala and others. "Pukar" was an average grosser, while the latter underperformed at the box office.

In 2001, Dixit starred in Deepak Shivdasani's love triangle "Yeh Raaste Hain Pyaar Ke" opposite Ajay Devgan and Preity Zinta. Upon release, the film met with largely negative reviews. Critic Gautam Buragohain, however, described her as "the saving grace of the film", adding that "she gives a delightful performance". Commercially too, the film failed to do well. Subsequently, Dixit reunited with Rajkumar Santoshi for the social drama "Lajja" (2001). Dealing with the issue of gender inequality, Dixit played Janki, a theatre actress who gets pre-maritally pregnant. Anita Bora of Rediff.com wrote: "Madhuri slips into her role as Janaki..with consummate ease..and..dazzles us with a class act." The film was a box-office failure in India but was an overseas success. Dixit's performance fetched her a Filmfare Award for Best Supporting Actress nomination and won her the Zee Cine Award for Best Actor in a Supporting Role – Female. Dixit's first release of 2002 was the love triangle "Hum Tumhare Hain Sanam" opposite Shah Rukh Khan and Salman Khan, where she played Radha whose married life blemishes when she gets obsessed with the career of her friend. A remake of director K. S. Adhiyaman's own Tamil film "Thotta Chinungi" (1995), the film took six years in making, with huge sabbaticals in between shoots due to several production problems. The film emerged moderately successful at the Indian box office. Few critics noted that the delay made the film look outdated.

Dixit's next release was Sanjay Leela Bhansali's period romance "Devdas", co-starring Shah Rukh Khan and Aishwarya Rai. It was based on Sharat Chandra Chattopadhyay's novel of the same name. She portrayed Chandramukhi, a courtesan who is in love with the title character. Sita Menon of Rediff.com wrote: "The most understated role and perhaps the one that is most lingering, in terms of virtuosity, is that played by Madhuri Dixit. As Chandramukhi, she is simply stunning, lending passion, fire and gentleness with such consummate ease that watching her perform is sheer delight." The film was screened at the 2002 Cannes Film Festival and was featured by "Time" in their listing of the "10 best films of the millennium". The film emerged as a major commercial success with revenues of over . "Devdas" was chosen as India's official entry for the Academy Award for Best Foreign Language Film and received a nomination for the BAFTA Award for Best Film Not in the English Language. At the 50th National Film Awards, the film won five awards, including the Best Popular Film Providing Wholesome Entertainment. Dixit eventually won the Filmfare Best Supporting Actress Award and the Screen Award for Best Supporting Actress for her performance in the film.

The following year a film named after her, "Main Madhuri Dixit Banna Chahti Hoon", was released in which a woman (played by Antara Mali) aspires to become the new Madhuri Dixit by trying her luck in Bollywood. Dixit also made an appearance on television as a host for the reality show "Kahin Na Kahin Koi Hai" on Sony TV.

Dixit made her comeback as an actress after five years with a leading role in cinematographer Anil Mehta's dance film "Aaja Nachle" (2007). She played Dia, a choreographer who returns to her town to save the endangered theatre where she learnt to dance. A box office failure, the film generated positive reviews for Dixit's portrayal. Rajeev Masand of CNN-IBN criticised the plot, while he wrote about Dixit's performance: "It's hard to take your eyes off the screen when she's up there, dazzling you with her spontaneity, her easy charm and her 100-watt smile." Her performance earned her another nomination for the Filmfare Best Actress Award.
In 2011, Dixit was felicitated by Filmfare with a special jury recognition for completing 25 years in the Indian film industry.

Dixit relocated to India in 2011, and after another seven-year absence from the screen, starred in the black comedy "Dedh Ishqiya" in 2014. The film was a sequel to the 2010 film "Ishqiya". She played a con-woman "Begum Para" opposite Naseeruddin Shah, Arshad Warsi and Huma Qureshi and expressed that she agreed to do the film because of the "unapologetic way" director Abhishek Chaubey presented Vidya Balan's character in "Ishqiya". The film opened to positive response from critics who called it "one of the year's most important releases". Anupama Chopra called Dixit "compelling", while Deepanjana Pal of Firstpost wrote "She's still capable of keeping an audience glued to their seats when the credits start rolling, all because she's dancing on screen.". The film earned Dixit her fourteenth nomination for Filmfare Best Actress Award. Dedh Ishqiya earned little at the box-office.

Her next release of the year was debutant director Soumik Sen's "Gulaab Gang", alongside Juhi Chawla. Dixit portrayed Rajjo, the leader of a women's activist group. The film and her role was inspired by the real vigilante activist Sampat Pal Devi and her group Gulabi Gang. Pal filed a case against the film claiming that the makers did not take permission to make a film on her life, but the court later lifted the stay from the film. To prepare for her role, Dixit practised Shaolin Kung fu, stick training, and close combat. "Gulaab Gang" failed at the box office, earning mixed reviews. Subhash K. Jha labelled Dixit's performance and demeanour "inconsistent". However, Sampat Pal claimed that in Dixit's character she finds a "reflection of her own life so stark" that it makes her feel "it was she on screen". The film was a box-office failure.

In 2018, Dixit made her debut in Marathi Cinema with the comedy-drama "Bucket List". She played Madhura Sane, a middle aged housewife who takes the initiative to complete the bucket list of her deceased teenage heart donor. Dixit garnered critical acclaim for her portrayal; Mihir Bhanage of The Times of India
wrote "Madhuri owns the film and sails through it with flying colours." Kunal Guha of Mumbai Mirror said, "Madhuri Dixit long-overdue debut in Marathi cinema is a comfort watch even if a tad predictable and sappy."

Dixit reunited with Anil Kapoor and Ajay Devgn in Indra Kumar's adventure comedy "Total Dhamaal" (2019). She portrayed Bindu Patel, who along with a group of people learns about a hidden treasure and then races to claim it. The film received mixed to negative reviews, however, Dixit's performance received a mixed-to-positive reception. Lakshana N Palat of "India Today" wrote: "The little respite in this adventure-comedy is the pairing of Anil Kapoor and Madhuri Dixit, who prove that they still have the same impeccable chemistry and partnership almost two decades later." "Total Dhamaal" emerged as a major commercial success at the box office, grossing more than worldwide, and ranks as the ninth highest-grossing Hindi film of the year. Dixit produced the Marathi Netflix-drama "15 August" under her production company RnM Moving Pictures. In an interview with Scroll.in, Dixit said, "The film is about the freedom to love, the freedom to choose your career and the freedom to die".

She next starred in Abhishek Varman's period drama "Kalank", featuring an ensemble cast including Sanjay Dutt, Sonakshi Sinha, Alia Bhatt, Varun Dhawan and Aditya Roy Kapur. Set in the 1940s prior to the partition of India, the film featured her as Bahaar Begum, the madam of a brothel. Saibal Chatterjee of NDTV wrote, "In the blinding glow of Dixit's presence as a nautch girl who can turn on the magic at will, the younger cast members pale somewhat in comparison. She lights up the screen as only she can, pushing the others to strive harder." It did not perform well at the box office; however, she gained a third nomination for the Filmfare Award for Best Supporting Actress.

Dixit will next produce "Panchak", a Marathi film under her company RnM Moving Pictures and will next star in Netflix's series "The Heroine", produced by Karan Johar.

Dixit has participated in several stage shows, concert tours and televised award ceremonies. In 1993, Dixit participated in Live 93' Bollywood Concert alongside Amitabh Bachchan and Mithun Chakraborty. Since the mid 1990s to early 2000s, she performed at the "Madhuri Dixit Live" concert in India, the Middle East and United States. In 2000, she performed at the Pepsi W2K Millennium Concert in Mumbai. Between July to August 2008, Dixit, and actors Abhishek Bachchan, Amitabh Bachchan, Preity Zinta, Ritesh Deshmukh and Aishwarya Rai starred in the "Unforgettable World Tour" stage production in a 40-day show staged in 11 cities across North America, Europe and the Caribbean.

In 2013, Dixit participated in the Access All Areas concert in Dubai with Shah Rukh Khan, Jacqueline Fernandez and Deepika Padukone. The same year, she joined the fourth instalment of "Temptation Reloaded" where she performed with Khan, Rani Mukerji, Fernandez and Meiyang Chang in Auckland, Perth, Sydney and Dubai; and in 2014 she performed in Malaysia with Khan, Mukerji and Arijit Singh. She also performed in SLAM! The Tour which was held in the US, Canada, and London. In 2015, Dixit participated in the show Fusion in Houston, along with Akshay Kumar, Sonakshi Sinha and Prabhu deva. In 2018, she performed at the inaugural ceremony of Men's Hockey World Cup.

She participated in the Hiru Golden Film Awards 2016 in Sri Lanka as a special guest along with Sunil Shetty, Neil Nitin Mukesh, Jackie Shroff, Sridevi and Karisma Kapoor.

In 2013, Dixit launched her own online dance academy "Dance With Madhuri", where the users get an opportunity to learn to dance various dance styles and have one-on-one lessons.

During her years in the film industry, Dixit has been actively involved in promoting children's education and the safety of women. She featured in a series of one-minute telespots on preventing AIDS for the Maharashtra State AIDS Control Society in 2000. In 2001, Dixit won on Kaun Banega Crorepati, a game show then in its first season on the air. She donated her winnings for the welfare of the victims of 2001 Gujarat earthquake and to an orphanage in Pune.

In 2009, Dixit performed for NDTV Toyota Greenathon—India's first-ever nationwide campaign for saving the environment and creating awareness about environmental issues. NDTV organised India's first 24-hour live telethon, a fund-raising event that brings in people to donate money to support TERI's initiative—Lighting a Billion Lives which aims at providing solar power to villages without electricity.

On 3 February 2011, Dixit spent an evening with 75 orphanage kids of farmers at an ashram in Trimbakeshwar and participated in the birthdays of two children: Hrishikesh and Rani. "We artists are ready to help such children. People from the higher society should come forward and stand firmly behind them," she said on the occasion. Dixit is a Goodwill Ambassador and a patron for "Emeralds for Elephants" – a charity project for the conservation of Asian elephants and other endangered species. The project has been designed to create awareness and raise vital funds for the protection of the critically endangered Asian elephant. A collaborative project between the World Land Trust (a UK based nonprofit environmental organisation) and the Wildlife Trust of India that is creating protected wildlife corridors connecting National Parks and protected areas to others. Speaking about the issue she said: "Elephants are one of my favourite animals and I love them. So what we need to do today is to see how we can preserve our animals. I feel very strongly about this." Two years later, she made donations to the Uttarakhand flood relief.

Since 2014, Dixit began working with UNICEF to advocate the rights of children and prevent child labour and child trafficking. She participated in a fashion show organised by Lilavati hospital, to support the 'Save & Empower the Girl Child' initiative by the organisation. The same year, the Government of Madhya Pradesh appointed her as the brand ambassador for its Mamta Abhiyaan (maternal and child health) campaign. Dixit collaborated with Vogue for its Vogue Empower series on a short film on gender policing, 'Boys don't cry', directed by Vinil Mathew. She was appointed as the brand ambassador for the Beti Bachao Beti Padhao campaign, by the Government of India in 2015, that aims to generate awareness and improve the efficiency of welfare services intended for girls. She lent her voice for narrating the story of one of the eight girls who featured in Girl Rising: Woh Padhegi, Woh Udegi, a film on the education and empowerment of girls. Dixit was appointed the brand ambassador and launched MAA (Mothers Absolute Affection), a flagship programme to ensure adequate awareness is generated on the benefits of breastfeeding.

Additionally, Dixit has made public appearances to support charities and causes. On 4 February 2012, Madhuri Dixit interacted with Cancer affected children on World Cancer Day which was organised by Pawan Hans Helicopters Ltd at Juhu, Mumbai. In 2013, she launched Sanofi India's campaign on World Diabetes Day (WDD), that encourages people to take proactive steps to effectively prevent, manage and control diabetes. A year later, on 24 February 2014, she visited a school in Andheri, Mumbai to support the "Support My School" campaign. She participated in 'Set Beautiful Free'– an event by One Foundation to provide home, education, food and healthcare to the daughters of trafficking victims. In 2018, she attended a charity event by 'Nanhi Kali' NGO.

In 1985, Dixit made her television debut in the Rajshri Production's series "Paying Guest", in which she played Neena.
In 2002, Dixit hosted Sony Entertainment's matrimonial show "Kahi Na Kahi Koi Hai".
Dixit featured as a talent judge for four seasons of the dance reality show "Jhalak Dikhhla Jaa" alongside Remo D'Souza and Malaika Arora Khan for the fourth season and alongside Remo D'Souza and Karan Johar for the fifth, sixth and seventh seasons.

In 2011, she featured as an anchor to launch a new entertainment channel, Life OK. The same year, she hosted a competitive cooking game show, Food Food Maha Challenge along with Sanjeev Kapoor. In 2016, Dixit featured as one of the jury of "So You Think You Can Dance", an officially incensed version of the "So You Think You Can Dance" franchise, based on the original "American production" created by Dick Clark Productions. Dixit co-judged first and second seasons of Colors TV's "Dance Deewane", which gives an opportunity to contestants from three different generations.

In May–June 2015 the Tamil Nadu Consumer's Forum sent her notices for "false representation" in advertisements of Maggi, a noodle brand in which toxic levels of lead were found. She continued endorsing the safety of the product on Twitter, even when food regulators had already found more than 17 times the permissible limits of lead and the product was banned.

Dixit made her singing debut in 2020 with an English single, "Candle", dedicating it to frontline workers fighting the COVID-19 pandemic.

Dixit is regarded as one of the most popular and accomplished actresses of Indian cinema. Throughout the late 1980s, the 1990s and the early 2000s, Dixit was among the highest paid actresses in the Indian entertainment industry. In 2000, the Guinness World Records book featured her as the highest paid Indian actress. In 2003, Dixit won Zee and BBC polls of "Best Actress Ever". In 2012, Dixit was placed at the first position by NDTV in the listing of "The most popular Bollywood actresses of all time". The same year, she was featured by Yahoo.com at the first position as one of the ten most iconic beauties of Hindi cinema. In 2013, she was placed at the fourth position, behind Amitabh Bachchan, Dilip Kumar and Shah Rukh Khan and topped among female actors as the greatest Bollywood star in a UK poll celebrating 100 years of Indian cinema. The same year, in a national poll conducted by CNN-IBN on the occasion of the centenary of Indian cinema, Dixit was voted at the second position, behind "Sridevi", as "India's Greatest Actress in 100 Years". In 2017, Dixit topped an India Today poll as the most popular actress of Hindi cinema till date.

Dixit has a significant following in the South Asian diaspora. While analysing her career, Reuters published, "In her prime, Dixit was the undisputed queen of Bollywood, the world's largest film industry by audience size, and her popularity and fees rivaled even the biggest male stars." Filmfare wrote that, "In a world of megastar males, she balances the power equation in favour of the fairer sex. She's one actress who sold films. Who overshadowed her heroes. Madhuri Dixit's box-office power was indestructible." The New York Times called Dixit, "India's biggest female star". The Guardian noted, "Dixit's reign as Bollywood's biggest star began in the 80s. She was given top billing on several pictures, and was considered so bankable that directors often paired her with lesser-known - and younger - heroes." According to Encyclopædia Britannica, Dixit "gave mass
hysteria a whole new meaning, achieving near-cult status." Saibal Chatterjee of Outlook credited "Hum Aapke Hain Koun..!" as metamorphosing Dixit into a "subcontinental icon". 
While discussing her performances, film critic Raja Sen noted: "Dixit’s acting chops have proven as impressive as her stellar screen-presence [...], her eyes sparkle with eagerness, and a seemingly effortless spontaneity colours her performances, infectious energy carrying her through moments of tremendous farce." Baradwaj Rangan labelled her as "the last of the all-in-one female stars who could do drama and comedy and dance." Firstpost called her, "one of the last superstars of Hindi cinema", and added, "the dexterity with which she could blend into the background in "Lajja" or not be overwhelming as Chandramukhi in "Devdas" and make "Dedh Ishqiya"'s Begum Para traverse finely between being desirable and diabolical, shows just how fine an artist she is." Rediff commented, "She shines in every role, blending with ease the vulnerability and the fierceness her character requires of her." In 2010, Filmfare Magazine included her performance from "Mrityudand" in its list of "80 Iconic Performances". Dixit is credited in the media for her versatility and achieving a "balance of critical acclaim and commercial success."

In addition to acting, she has been noted for her skills as a dancer. Kathak dancer Pandit Birju Maharaj, who choreographed Dixit in "Devdas", calls her "the best Bollywood dancer" due to her versatility. Saroj Khan, who has collaborated with her on numerous occasions, calls her a "choreographer's delight". Hindustan Times attributed her for giving a 'technical twist' to dance sequences in Hindi films. Raja Sen describes Dixit as "the industry's numero uno in every sense." Further he elaborates, "She is an exemplary dancer. From Kathak to Dhak Dhak, she's done it all and wowed us every step of the way." Dixit was the muse for Indian painter M. F. Husain. He got fascinated by Dixit's performance in "Hum Aapke Hain Koun..!"; watching the film 67 times, and booked an entire theatre to see her comeback "Aaja Nachle". He made a series of paintings of her, and in 2000 directed "Gaja Gamini" starring her, which was intended as a tribute to Dixit herself.

Dixit featured in Box Office India's "Top Actresses" list for ten consecutive years (1988–97). In 2001, Forbes placed her at fifth position in the list of "top five most powerful Indian film stars". In 2002 and 2014, Dixit featured in Rediff's annual "Top Bollywood actresses" listing. She has been featured frequently on other Rediff lists, including "Bollywood's Most Beautiful Actresses", "Bollywood's Best Actresses Ever" and "Top 10 Bollywood Actresses of all Time". "The Economic Times" featured her in the list of "33 women who made India proud" in 2010. In 1997, the Government of Andhra Pradesh honoured her with the "Kalabhinetri Award". In 2001, Dixit was awarded the National Citizens' Award for her work and contribution to Indian cinema. In 2008, the Government of India honoured her with the Padma Shri for her contribution to Indian Cinema. The Sathyabama University honoured her as the "Inspiring Icon of India" in 2015. An unauthorised biography of her named "Madhuri Dixit", written by professor Nandana Bose was released in 2019.

Dixit is frequently referred to as one of the most attractive Indian celebrities and has been described as a sex symbol. Her eyes, sex appeal and urban looks have been cited by the media as her distinctive features; her smile being identified as her trademark. She featured in The Times of India's list of 50 Beautiful Faces of cinema and Hindustan Times called her "a classic Indian beauty". Her look and performances have established her as a style icon. In 2007, 2013–16 and 2018, the UK magazine "Eastern Eye" ranked her as one of "World's Sexiest Asian Women".

Sangestar Tso lake in Arunachal Pradesh was renamed "Madhuri Lake" after her, where a song from "Koyla" was picturised. She has a star named after her in the Orion constellation. In 1997, a Zee TV television serial Mrs. Madhuri Dixit was named after her and in 2003, Ram Gopal Varma produced a feature film "Main Madhuri Dixit Banna Chahti Hoon", which was dedicated to her. In March 2012, a wax figure of Dixit was put on display in London's Madame Tussaud's wax museum. In 2017, two other figures were displayed at Madame Tussaud's Museum in Singapore and Delhi. Every year since its inception in 2012, Dixit has featured on "Forbes India"s "Celebrity 100," a list based on the income and popularity of India's celebrities with the exception of 2017. In 2018, she was among the twenty Indians invited for the Oscar Academy's Class of 2018.

Following widespread media speculation over years on her personal life, Dixit married Shriram Madhav Nene, a cardiovascular surgeon from Los Angeles, California on 17 October 1999, in a traditional ceremony held at the residence of Dixit's elder brother in Southern California. Nene had never seen any of her films, and was unaware of her celebrity status. Dixit explained their relationship by saying, "It was very important that he didn't know me as an actress because then he would know me as a person first. When people have seen you as an actress, they have pre-conceived notions... None of it was there here with him. I found the right person, I wanted to get married and I did."

Following her marriage, Dixit relocated to Denver, Colorado, for over a decade. She moved back to Mumbai with her family in October 2011. Speaking about it, Dixit said, "I always love being here. I have grown up here in Mumbai so for me it is like coming back home. It was a different phase in my life, where I wanted to have a home, family, husband and children... everything that I had dreamt of." In 2018, Dixit along with her husband, founded the production company, RnM Moving Pictures.

On 17 March 2003, Dixit gave birth to a son, Arin. Two years later, on 8 March 2005, she gave birth to another son, Ryan. She described motherhood as "amazing" and added that her kids kept "the child in her alive".

Dixit has received six Filmfare Awards from seventeen nominations, including four Best Actress awards for "Dil" (1990), "Beta" (1992), "Hum Aapke Hain Kaun!" (1994) and "Dil To Pagal Hai" (1997), and a Filmfare Award for Best Supporting Actress for "Devdas" (2002). She earned a Filmfare Special Award for completing twenty-five years in the Indian film industry. In 2008, she was awarded Padma Shri, the fourth-highest Indian civilian award, by the Government of India for her contributions to the arts.




</doc>
<doc id="19855" url="https://en.wikipedia.org/wiki?curid=19855" title="Mars Attacks">
Mars Attacks

Mars Attacks is a science fiction-themed trading card series released in 1962 by Topps. The cards feature artwork by science fiction artists Wally Wood and Norman Saunders. The cards form a story arc, which tell of the invasion of Earth by cruel, hideous Martians, under the command of a corrupt Martian government who conceal the fact from the Martian populace that Mars is doomed to explode and therefore proposes a colonization of Earth to turn it into their new homeworld. The cards depict futuristic battle scenes and bizarre methods of Martian attack, torture and slaughter of humans, as well as various Earth nations being attacked. The story concludes with an expeditionary force of humans volunteering to embark on a counterattack on Mars, in which the Earth force attacks the Martians in their manner (bayoneting and bullets). This necessitates the Martians that are still on Mars to defend their homeworld. The Earth attack forces, after destroying the Martian cities and killing the Martians, depart just before Mars is destroyed in the predicted cataclysm, thus ensuring the peace and safety of Earth as the Martian race is seemingly doomed to extinction (but see "Adaptations and merchandising" below). Scholar Nathan Brownstone noted that "The "Mars Attacks" cards achieved their popularity at the very time when the Cuban Missile Crisis captured the headlines, the moment when Cold War came closest to become radioactively hot. That was when that a brutal zero sum game scenario - for Humanity to survive the Martians must die - established a solid niche in Americana popular culture" . 

The cards proved popular with children, but depictions of explicit gore and implied sexual content caused an outcry, leading the company to halt production. The cards have since become collectors' items, with certain cards commanding over $3,500 at auction.

In the 1980s, Topps began developing merchandise based on the "Mars Attacks" storyline, including mini-comic books and card reprints. An expanded set of 100 cards called "Mars Attacks Archives" was issued in 1994 by Topps and spawned a second round of merchandising. Director Tim Burton released a film called "Mars Attacks!" in 1996 based on the series, spawning a third round of merchandising. In 2012, Topps released a 50th anniversary expanded set of 75 cards called "Mars Attacks Heritage", leading to a fourth round of merchandising that continued into 2017 with the release of a sequel series, "Mars Attacks: The Revenge!"

The "Mars Attacks" trading card series was created by Topps in 1962. Product developer Len Brown, inspired by Wally Wood's cover for EC Comics' "Weird Science" #16, pitched the idea to Woody Gelman. Gelman and Brown created the story—with Brown writing the copy—and created rough sketches. They enlisted Wood to flesh out the sketches and Bob Powell to finish them. Norman Saunders painted the 55-card set.

The cards, which sold for five cents per pack of five, were test marketed by Topps through the dummy corporation Bubbles, Inc. under the name "Attack from Space". Sales were sufficient to expand the marketing and the name was changed to "Mars Attacks". The cards sparked parental and community outrage over their graphic violence and implied sexuality. Topps responded initially by repainting 13 of the 55 cards to reduce the gore and sexuality. However, inquiries from a Connecticut district attorney caused Topps to halt production of the series altogether before the replacements could be printed.

In 1994, Topps re-released the cards as the expanded "Mars Attacks Archives", with the original 55 cards and 45 "New Visions" cards. The new cards are further divided into a #0 card, three subsets ("The Unpublished 11" (with 11 cards), "Mars Attacks: The Comics" (with 10 cards) and "Visions: New and Original" (a.k.a. "New Visions"; with 22 cards)) and one card called "Norm Saunders: A Self-Portrait". 21 artists collaborated on the new cards, including Zina Saunders, daughter of the original artist Norman Saunders. Topps Comics, in conjunction with the trading cards, issued a five-issue comic book miniseries based on the original 55 cards written by Keith Giffen and drawn by Charles Adlard. Topps Comics continued the story in an ongoing series that lasted seven issues, a one-shot special and three more miniseries, one of them a crossover with the Martians battling the Image Comics superhero the Savage Dragon and another one a crossover with the Martians battling other characters from the Image Comics universe. "Wizard" magazine and Topps Comics also published a #1/2 issue and an Ace Edition issue (#65).

In 1995, one year after the "Archives" series, Screamin' Productions and Topps released a tie-in set of eight "Mars Attacks" vinyl model kits with an accompanying series of eight new trading cards, each one inside one of the kits. Bonus items that could be acquired by sending in proof-of-purchase certificates from all eight of the kits were two new nearly identical bonus cards (one oversized with the "Mars Attacks" logo on it and one regular-sized without it) and a limited edition 9th model kit.

In 1996, Warner Bros. released Tim Burton's film "Mars Attacks!" In conjunction, two hardcover novels were released: "Mars Attacks: Martian Deathtrap" by Nathan Archer; and "Mars Attacks: War Dogs of the Golden Horde" by Ray W. Murrill. Each contained two new trading cards in the middle of each book (the paperback editions, however, did not have the trading cards in them). A paperback movie tie-in novelization by the film's screenwriter was also published. Trendmasters also produced a series of toy figures based on the film.

In 2012, to commemorate the franchise's 50th anniversary, Topps partnered with a variety of companies on comic books (via IDW Publishing), bobbleheads and vinyl figures (Funko POP!), action figures and plush toys (Mezco Toyz), costumes (Incogneato), statues and busts (Quarantine Studio), electronics skins (Gelaskins) and a commemorative hardcover book and 2013 calendar, both with nearly identical sets of four new trading cards (the only difference being that the book's cards had white borders on the front of the cards and the calendar's cards had green borders) (Abrams Books). Topps also re-released the original 55-card series again as the expanded "Mars Attacks Heritage", including two subsets ("Deleted Scenes" (with 10 cards) and "Guide to the New Universe" (with 15 cards)). 

In 2013, Topps issued "Mars Attacks: Invasion", a reboot series of 95 trading cards featuring a new story ("Mars Attacks: Invasion" (cards #1-58, plus a #0 promo card from the 2013 San Diego Comic-Con)) with new artwork cards (divided into "Mars Invades IDW" (cards #59-77 and #91-92) and "Art of Mars Attacks" (cards #78-90 and #93-95)) and including four new subsets ("Mars Attacks: Early Missions" (with six cards), "Mars Attacks Masterpieces" (with five cards), "Join the Fight!" (with four cards) and "Anatomy of a Martian" (also with six cards)). This was the last "Mars Attacks" trading card series to be sold in retail stores as of this date; all other such series have been sold online ever since.

A second series of 81 trading cards, "Mars Attacks: Occupation", also featuring a second reboot series that picked up where "Mars Attacks: Invasion" left off ("Mars Attacks: Occupation" (cards #1-45) with new artwork cards (divided into "Art of Mars Attacks" (cards #46-63), "Factions" (cards #64-72), "Occupation Profiles" (cards #73-78) and "The Kickstarter Video" (cards #79-81)) and including six new subsets ("Mars Attacks Superstars", Mars Attacks: Then and Now!", "Mars Attacks All-Star Art" and "Dinosaurs Attack! vs. Mars Attacks" (each with nine cards (the last one of which was also available as a foil card set)), "Attacky Packages" (with 13 cards; the last three cards were titled "Attacky Packages Old School" (like "Dinosaurs Attack! vs. Mars Attacks", this one, too, was also available as a foil card set)) and "Mars Attacks/Judge Dredd" (with 18 cards)) was funded by Topps on Kickstarter in 2015 and released in 2016.

On October 27, 2016, "Day 10" of "13 Days of ERMA-Ween", an annual series of comic strips from the Brandon J. Santiago webcomic "Erma", focuses on the Martians of the "Mars Attacks" franchise, showing Erma Williams, the series' titular character, wearing a nurse's cap and preparing to dissect a living Martian with a buzz saw.

In 2017, to commemorate the franchise's 55th anniversary, Topps released a sequel series to the original 1962 55-card series called "Mars Attacks: The Revenge!", which takes place five years after the events in the original series, and chronicles a second invasion. It contains 110 cards-the story itself (cards #1-55) and rough pencil art for the story cards (cards #P-1-P-55). No subsets were made for this series. It was sold as a complete boxed set containing only the unwrapped 110 cards.





</doc>
<doc id="19856" url="https://en.wikipedia.org/wiki?curid=19856" title="Montreal Protocol">
Montreal Protocol

The Montreal Protocol is an international treaty designed to protect the ozone layer by phasing out the production of numerous substances that are responsible for ozone depletion. It was agreed on 16th September 1987, and entered into force on 1st January 1989. Since then, it has undergone nine revisions, in 1990 (London), 1991 (Nairobi), 1992 (Copenhagen), 1993 (Bangkok), 1995 (Vienna), 1997 (Montreal), 1998 (Australia), 1999 (Beijing) and 2016 (Kigali) As a result of the international agreement, the ozone hole in Antarctica is slowly recovering. Climate projections indicate that the ozone layer will return to 1980 levels between 2050 and 2070. Due to its widespread adoption and implementation it has been hailed as an example of exceptional international co-operation, with Kofi Annan quoted as saying that "perhaps the single most successful international agreement to date has been the Montreal Protocol". In comparison, effective burden sharing and solution proposals mitigating regional conflicts of interest have been among the success factors for the ozone depletion challenge, where global regulation based on the Kyoto Protocol has failed to do so. In this case of the ozone depletion challenge, there was global regulation already being installed before a scientific consensus was established. Also, overall public opinion was convinced of possible imminent risks.

The two ozone treaties have been ratified by 197 parties (196 states and the European Union), making them the first universally ratified treaties in United Nations history.

These truly universal treaties have also been remarkable in the expedience of the policy-making process at the global scale, where only 14 years lapsed between a basic scientific research discovery (1973) and the international agreement signed (1985 and 1987).

The treaty is structured around several groups of halogenated hydrocarbons that deplete stratospheric ozone. All of the ozone depleting substances controlled by the Montreal Protocol contain either chlorine or bromine (substances containing only fluorine do not harm the ozone layer). Some ozone-depleting substances (ODSs) are not yet controlled by the Montreal Protocol, including nitrous oxide (NO) For a table of ozone-depleting substances controlled by the Montreal Protocol see:

For each group of ODSs, the treaty provides a timetable on which the production of those substances must be shot out and eventually eliminated. This included a 10-year phase-in for developing countries identified in Article 5 of the treaty.

The stated purpose of the treaty is that the signatory states

There was a faster phase-out of halon-1211, -2402, -1301, There was a slower phase-out (to zero by 2010) of other substances (halon 1211, 1301, 2402; CFCs 13, 111, 112, etc.) and some chemicals were given individual attention (Carbon tetrachloride; 1,1,1-trichloroethane). The phasing-out of the less damaging HCFCs only began in 1996 and will go on until a complete phasing-out is achieved by 2030.

There were a few exceptions for "essential uses" where no acceptable substitutes were initially found (for example, in the past metered dose inhalers commonly used to treat asthma and chronic obstructive pulmonary disease were exempt) or Halon fire suppression systems used in submarines and aircraft (but not in general industry).

The substances in Group I of Annex A are:


The provisions of the Protocol include the requirement that the Parties to the Protocol base their future decisions on the current scientific, environmental, technical, and economic information that is assessed through panels drawn from the worldwide expert communities. To provide that input to the decision-making process, advances in understanding on these topics were assessed in 1989, 1991, 1994, 1998 and 2002 in a series of reports entitled Scientific assessment of ozone depletion, by the Scientific Assessment Panel (SAP).

In 1990 a Technology and Economic Assessment Panel was also established as the technology and economics advisory body to the Montreal Protocol Parties. The Technology and Economic Assessment Panel (TEAP) provides, at the request of Parties, technical information related to the alternative technologies that have been investigated and employed to make it possible to virtually eliminate use of Ozone Depleting Substances (such as CFCs and Halons), that harm the ozone layer. The TEAP is also tasked by the Parties every year to assess and evaluate various technical issues including evaluating nominations for essential use exemptions for CFCs and halons, and nominations for critical use exemptions for methyl bromide. TEAP's annual reports are a basis for the Parties’ informed decision-making.

Numerous reports have been published by various inter-governmental, governmental and non-governmental organizations to catalogue and assess alternatives to the ozone depleting substances, since the substances have been used in various technical sectors, like in refrigeration, air conditioning, flexible and rigid foam, fire protection, aerospace, electronics, agriculture, and laboratory measurements.

Under the Montreal Protocol on Substances that Deplete the Ozone Layer, especially Executive Committee (ExCom) 53/37 and ExCom 54/39, Parties to this Protocol agreed to set year 2013 as the time to freeze the consumption and production of HCFCs for developing countries. For developed countries, reduction of HCFC consumption and production began in 2004 and 2010, respectively, with 100% reduction set for 2020. Developing countries agreed to start reducing its consumption and production of HCFCs by 2015, with 100% reduction set for 2030.

Hydrochlorofluorocarbons, commonly known as HCFCs, are a group of man-made compounds containing hydrogen, chlorine, fluorine and carbon. They are not found anywhere in nature. HCFC production began to take off after countries agreed to phase out the use of CFCs in the 1980s, which were found to be destroying the ozone layer. Like CFCs, HCFCs are used for refrigeration, aerosol propellants, foam manufacture and air conditioning. Unlike the CFCs, however, most HCFCs are broken down in the lowest part of the atmosphere and pose a much smaller risk to the ozone layer. Nevertheless, HCFCs are very potent greenhouse gases, despite their very low atmospheric concentrations, measured in parts per trillion (million million).

The HCFCs are transitional CFCs replacements, used as refrigerants, solvents, blowing agents for plastic foam manufacture, and fire extinguishers. In terms of ozone depletion potential (ODP), in comparison to CFCs that have ODP 0.6 – 1.0, these HCFCs have lower ODPs (0.01 – 0.5). In terms of global warming potential (GWP), in comparison to CFCs that have GWP 4,680 – 10,720, HCFCs have lower GWPs (76 – 2,270).

On January 1, 2019 the Kigali Amendment to the Montreal Protocol came into force. Under the Kigali Amendment countries promised to reduce the use of hydrofluorocarbons (HFCs) by more than 80% over the next 30 years. By December 27, 2018, 65 countries had ratified the Amendment.

Produced mostly in developed countries, hydrofluorocarbons (HFCs) replaced CFCs and HCFCs. HFCs pose no harm to the ozone layer because, unlike CFCs and HCFCs, they do not contain chlorine. They are, however, greenhouse gases, with a high global warming potential (GWP), comparable to that of CFCs and HCFCs. In 2009, a study calculated that a fast phasedown of high-GWP HFCs could potentially prevent the equivalent of up to 8.8 Gt CO2-eq "per year" in emissions by 2050. A proposed phasedown of HFCs was hence projected to avoid up to 0.5C of warming by 2100 under the high-HFC growth scenario, and up to 0.35C under the low-HFC growth scenario. Recognizing the opportunity presented for fast and effective phasing down of HFCs through the Montreal Protocol, starting in 2009 the Federated States of Micronesia proposed an amendment to phase down high-GWP HFCs, with the U.S., Canada, and Mexico following with a similar proposal in 2010.

After seven years of negotiations, in October 2016 at the 28th Meeting of the Parties to the Montreal Protocol in Kigali, the Parties to the Montreal Protocol adopted the Kigali Amendment whereby the Parties agreed to phase down HFCs under the Montreal Protocol. The amendment to the legally-binding Montreal Protocol will ensure that industrialised countries bring down their HFC production and consumption by at least 85 per cent compared to their annual average values in the period 2011–2013. A group of developing countries including China, Brazil and South Africa are mandated to reduce their HFC use by 85 per cent of their average value in 2020-22 by the year 2045. India and some other developing countries — Iran, Iraq, Pakistan, and some oil economies like Saudi Arabia and Kuwait — will cut down their HFCs by 85 per cent of their values in 2024-26 by the year 2047.

On 17 November 2017, ahead of the 29th Meeting of the Parties of the Montreal Protocol, Sweden became the 20th Party to ratify the Kigali Amendment, pushing the Amendment over its ratification threshold ensuring that the Amendment would enter into force 1 January 2019.

In 1973, the chemists Frank Sherwood Rowland and Mario Molina, who were then at the University of California, Irvine, began studying the impacts of CFCs in the Earth's atmosphere. They discovered that CFC molecules were stable enough to remain in the atmosphere until they got up into the middle of the stratosphere where they would finally (after an average of 50–100 years for two common CFCs) be broken down by ultraviolet radiation releasing a chlorine atom. Rowland and Molina then proposed that these chlorine atoms might be expected to cause the breakdown of large amounts of ozone (O) in the stratosphere. Their argument was based upon an analogy to contemporary work by Paul J. Crutzen and Harold Johnston, which had shown that nitric oxide (NO) could catalyze the destruction of ozone. (Several other scientists, including Ralph Cicerone, Richard Stolarski, Michael McElroy, and Steven Wofsy had independently proposed that chlorine could catalyze ozone loss, but none had realized that CFCs were a potentially large source of chlorine.) Crutzen, Molina and Rowland were awarded the 1995 Nobel Prize for Chemistry for their work on this problem.

The environmental consequence of this discovery was that, since stratospheric ozone absorbs most of the ultraviolet-B (UV-B) radiation reaching the surface of the planet, depletion of the ozone layer by CFCs would lead to an increase in UV-B radiation at the surface, resulting in an increase in skin cancer and other impacts such as damage to crops and to marine phytoplankton.

But the Rowland-Molina hypothesis was strongly disputed by representatives of the aerosol and halocarbon industries. The chair of the board of DuPont was quoted as saying that ozone depletion theory is "a science fiction tale...a load of rubbish...utter nonsense". Robert Abplanalp, the president of Precision Valve Corporation (and inventor of the first practical aerosol spray can valve), wrote to the Chancellor of UC Irvine to complain about Rowland's public statements (Roan, p. 56.)

After publishing their pivotal paper in June 1974, Rowland and Molina testified at a
hearing before the U.S. House of Representatives in December 1974. As a result, significant funding was made available to study various aspects of the problem and to confirm the initial findings. In 1976, the U.S. National Academy of Sciences (NAS) released a report that confirmed the scientific credibility of the ozone depletion hypothesis. NAS continued to publish assessments of related science for the next decade.

Then, in 1985, British Antarctic Survey scientists Joe Farman, Brian Gardiner and Jon Shanklin published results of abnormally low ozone concentrations above Halley Bay near the South Pole. They speculated that this was connected to increased levels of CFCs in the atmosphere. It took several other attempts to establish the Antarctic losses as real and significant, especially after NASA had retrieved matching data from its satellite recordings. The impact of these studies, the metaphor 'ozone hole', and the colourful visual representation in a time lapse animation proved shocking enough for negotiators in Montreal, Canada to take the issue seriously.

Also in 1985, 20 nations, including most of the major CFC producers, signed the Vienna Convention, which established a framework for negotiating international regulations on ozone-depleting substances. After the discovery of the ozone hole 
by SAGE 2 it only took 18 months to reach a binding agreement in Montreal, Canada.

But the CFC industry did not give up that easily. As late as 1986, the Alliance for Responsible CFC Policy (an association representing the CFC industry founded by DuPont) was still arguing that the science was too uncertain to justify any action. In 1987, DuPont testified before the US Congress that "We believe there is no imminent crisis that demands unilateral regulation." And even in March 1988, Du Pont Chair Richard E. Heckert would write in a letter to the United States Senate, "we will not produce a product unless it can be made, used, handled and disposed of safely and consistent with appropriate safety, health and environmental quality criteria. At the moment, scientific evidence does not point to the need for dramatic CFC emission reductions. There is no available measure of the contribution of CFCs to any observed ozone change..."

The main objective of the "Multilateral Fund for the Implementation of the Montreal Protocol" is to assist developing country parties to the Montreal Protocol whose annual per capita consumption and production of ozone depleting substances (ODS) is less than 0.3 kg to comply with the control measures of the Protocol. Currently, 147 of the 196 Parties to the Montreal Protocol meet these criteria (they are referred to as Article 5 countries).

It embodies the principle agreed at the United Nations Conference on Environment and Development in 1992 that countries have a common but differentiated responsibility to protect and manage the global commons.

The Fund is managed by an Executive Committee with an equal representation of seven industrialized and seven Article 5 countries, which are elected annually by a Meeting of the Parties. The Committee reports annually to the Meeting of the Parties on its operations. The work of the Multilateral Fund on the ground in developing countries is carried out by four Implementing Agencies, which have contractual agreements with the Executive Committee:


Up to 20 percent of the contributions of contributing parties can also be delivered through their bilateral agencies in the form of eligible projects and activities.

The fund is replenished on a three-year basis by the donors. Pledges amounted to US$3.1 billion over the period 1991 to 2005. Funds are used, for example, to finance the conversion of existing manufacturing processes, train personnel, pay royalties and patent rights on new technologies, and establish national ozone offices. As of December 2019, the fund stood at just over US$4.1 billion in income and US$3.8 billion in disbursements.

As of 23 June 2015, all countries in the United Nations, the Cook Islands, Holy See, Niue as well as the European Union have ratified the original Montreal Protocol (see external link below), with South Sudan being the last country to ratify the agreement, bringing the total to 197. These countries have also ratified the London, Copenhagen, Montreal, and Beijing amendments.

Since the Montreal Protocol came into effect, the atmospheric concentrations of the most important chlorofluorocarbons and related chlorinated hydrocarbons have either leveled off or decreased. Halon concentrations have continued to increase, as the halons presently stored in fire extinguishers are released, but their rate of increase has slowed and their abundances are expected to begin to decline by about 2020. Also, the concentration of the HCFCs increased drastically at least partly because of many uses (e.g. used as solvents or refrigerating agents) CFCs were substituted with HCFCs. While there have been reports of attempts by individuals to circumvent the ban, e.g. by smuggling CFCs from undeveloped to developed nations, the overall level of compliance has been high. Statistical analysis from 2010 show a clear positive signal from the Montreal Protocol to the stratospheric ozone. In consequence, the Montreal Protocol has often been called the most successful international environmental agreement to date. In a 2001 report, NASA found the ozone thinning over Antarctica had remained the same thickness for the previous three years, however in 2003 the ozone hole grew to its second largest size. The most recent (2006) scientific evaluation of the effects of the Montreal Protocol states, "The Montreal Protocol is working: There is clear evidence of a decrease in the atmospheric burden of ozone-depleting substances and some early signs of stratospheric ozone recovery." However, a more recent study seems to point to a relative increase in CFCs due to an unknown source.

Reported in 1997, significant production of CFCs occurred in Russia for sale on the black market to the EU throughout the 90s. Related US production and consumption was enabled by fraudulent reporting due to poor enforcement mechanisms. Similar illegal markets for CFCs were detected in Taiwan, Korea, and Hong Kong.

The Montreal Protocol is also expected to have effects on human health. A 2015 report by the U. S. Environmental Protection Agency estimates that the protection of the ozone layer under the treaty will prevent over 280 million cases of skin cancer, 1.5 million skin cancer deaths, and 45 million cataracts in the United States.

However, the hydrochlorofluorocarbons, or HCFCs, and hydrofluorocarbons, or HFCs, are now thought to contribute to anthropogenic global warming. On a molecule-for-molecule basis, these compounds are up to 10,000 times more potent greenhouse gases than carbon dioxide. The Montreal Protocol currently calls for a complete phase-out of HCFCs by 2030, but does not place any restriction on HFCs. Since the CFCs themselves are equally powerful greenhouse gases, the mere substitution of HFCs for CFCs does not significantly increase the rate of anthropogenic climate change, but over time a steady increase in their use could increase the danger that human activity will change the climate.

Policy experts have advocated for increased efforts to link ozone protection efforts to climate protection efforts. Policy decisions in one arena affect the costs and effectiveness of environmental improvements in the other.

In 2018, scientists monitoring the atmosphere following the 2010 phaseout date have reported evidence of continuing industrial production of CFC-11, likely in eastern Asia, with detrimental global effects on the ozone layer. A monitoring study detected fresh atmospheric releases of carbon tetrachloride from China's Shandong province, beginning sometime after 2012, and accounting for a large part of emissions exceeding global estimates under the Montreal Protocol.

The year 2012 marked the 25th anniversary of the signing of the Montreal Protocol. Accordingly, the Montreal Protocol community organized a range of celebrations at the national, regional and international levels to publicize its considerable success to date and to consider the work ahead for the future.
Among its accomplishments are: The Montreal Protocol was the first international treaty to address a global environmental regulatory challenge; the first to embrace the "precautionary principle" in its design for science-based policymaking; the first treaty where independent experts on atmospheric science, environmental impacts, chemical technology, and economics, reported directly to Parties, without edit or censorship, functioning under norms of professionalism, peer review, and respect; the first to provide for national differences in responsibility and financial capacity to respond by establishing a multilateral fund for technology transfer; the first MEA with stringent reporting, trade, and binding chemical phase-out obligations for both developed and developing countries; and, the first treaty with a financial mechanism managed democratically by an Executive Board with equal representation by developed and developing countries.

Within 25 years of signing, parties to the MP celebrate significant milestones. Significantly, the world has phased-out 98% of the Ozone-Depleting Substances (ODS) contained in nearly 100 hazardous chemicals worldwide; every country is in compliance with stringent obligations; and, the MP has achieved the status of the first global regime with universal ratification; even the newest member state, South Sudan, ratified in 2013. UNEP received accolades for achieving global consensus that "demonstrates the world’s commitment to ozone protection, and more broadly, to global environmental protection".





</doc>
<doc id="19857" url="https://en.wikipedia.org/wiki?curid=19857" title="Moncton">
Moncton

Moncton (; ) is one of three major urban centres in the Canadian province of New Brunswick, along with Saint John and the capital city of Fredericton. Situated in the Petitcodiac River Valley, Moncton lies at the geographic centre of the Maritime Provinces. The city has earned the nickname "Hub City" because of its central inland location in the region and its history as a railway and land transportation hub for the Maritimes.

The city proper has a population of 71,889 (2016) and a land area of . Greater Moncton has a population of 144,810 (2016), making it the largest city and census metropolitan area (CMA) in New Brunswick, and the second-largest city and CMA in the Maritime Provinces. The CMA includes the neighbouring city of Dieppe and the town of Riverview, as well as adjacent suburban areas in Westmorland and Albert counties.

Although the Moncton area was first settled in 1733, Moncton was officially founded in 1766 with the arrival of Pennsylvania Dutch immigrants from Philadelphia. Initially an agricultural settlement, Moncton was not incorporated until 1855. The city was named for Lt. Col. Robert Monckton, the British officer who had captured nearby Fort Beauséjour a century earlier. A significant wooden shipbuilding industry had developed in the community by the mid-1840s, allowing for the civic incorporation in 1855. However, the shipbuilding economy collapsed in the 1860s, causing the town to lose its civic charter in 1862. Moncton regained its charter in 1875 after the community's economy rebounded, mainly due to a growing railway industry. In 1871, the Intercolonial Railway of Canada had chosen Moncton as its headquarters, and Moncton remained a railway town for well over a century until the closure of the Canadian National Railway (CNR) locomotive shops in the late 1980s.

Although the economy of Moncton was traumatized twice—by the collapse of the shipbuilding industry in the 1860s and by the closure of the CNR locomotive shops in the 1980s—the city was able to rebound strongly on both occasions. The city adopted the motto "Resurgo" (Latin: I rise again) after its rebirth as a railway town. The city's economy is stable and diversified, primarily based on its traditional transportation, distribution, retailing, and commercial heritage, and supplemented by strength in the educational, health care, financial, information technology, and insurance sectors. The strength of Moncton's economy has received national recognition and the local unemployment rate is consistently less than the national average.

Acadians settled the head of the Bay of Fundy in the 1670s. The first reference to the "Petcoucoyer River" was on the De Meulles map of 1686. Settlement of the Petitcodiac and Memramcook river valleys began about 1700, gradually extending inland and reaching the site of present-day Moncton in 1733. The first Acadian settlers in the Moncton area established a marshland farming community and chose to name their settlement "Le Coude" (The Elbow), an allusion to the 90° bend in the river near the site of the settlement.

In 1755, nearby Fort Beausejour was captured by British forces under the command of Lt. Col. Robert Monckton. The Beaubassin region including the Memramcook and Petitcodiac river valleys subsequently fell under English control. Later that year, Governor Charles Lawrence issued a decree ordering the expulsion of the Acadian population from Nova Scotia (including recently captured areas of Acadia such as le Coude). This action came to be known as the "Great Upheaval".

The reaches of the upper Petitcodiac River valley then came under the control of the Philadelphia Land Company (one of the principals of which was Benjamin Franklin.) In 1766, Pennsylvania Dutch settlers arrived to re-establish the pre-existing farming community at Le Coude. The Settlers consisted of eight families: Heinrick Stief (Steeves); Jacob Treitz (Trites;, Matthias Sommer (Somers); Jacob Reicker (Ricker); Charles Jones (Schantz); George Wortmann (Wortman); Michael Lutz (Lutes; and George Koppel (Copple). There is a plaque dedicated in their honor at the mouth of Hall's Creek. They renamed the settlement "The Bend".
The Bend remained an agricultural settlement for nearly 80 more years. Even by 1836, there were only 20 households in the community. At this time, the Westmorland Road became open to year-round travel and a regular mail coach service was established between Saint John and Halifax. The Bend became an important transfer and rest station along the route. Over the next decade, lumbering and then shipbuilding would become important industries in the area.

The turning point for the community was when Joseph Salter took over (and expanded) a shipyard at the Bend in 1847. The expanded shipyard ultimately grew to employ about 400 workers. The Bend subsequently developed a service-based economy to support the shipyard and gradually began to acquire all the amenities of a growing town. The prosperity engendered by the wooden shipbuilding industry allowed The Bend to incorporate as the town of Moncton in 1855. Although the town was named for Lt. Col. Robert Monckton, a clerical error at the time the town was incorporated resulted in the misspelling of the community's name, which has been remained to the present day. The first mayor of Moncton was the shipbuilder Joseph Salter.

Two years later, in 1857, the European and North American Railway opened its line from Moncton to nearby Shediac. This was followed by a line from Moncton to Saint John opening in 1859. At about the time of the arrival of the railway, the popularity of steam-powered ships forced an end to the era of wooden shipbuilding. The Salter shipyard closed in 1858. The resulting industrial collapse caused Moncton to surrender its civic charter in 1862.

Moncton's economic depression did not last long and a second era of prosperity came to the area in 1871 when Moncton was selected to be the headquarters of the Intercolonial Railway of Canada (ICR). The arrival of the ICR in Moncton was a seminal event for the community. For the next 120 years, the history of the city would be firmly linked with that of the railway. In 1875, Moncton was able to reincorporate as a town and one year later, the ICR line to Quebec was opened. The railway boom that emanated from this and the associated employment growth allowed Moncton to achieve city status on April 23, 1890.

Moncton grew rapidly during the early 20th century, particularly after provincial lobbying helped the city become the eastern terminus of the massive National Transcontinental Railway project in 1912. In 1918, the ICR and National Transcontinental Railway (NTR) were merged by the federal government into the newly formed Canadian National Railways (CNR) system. The ICR shops would become CNR's major locomotive repair facility for the Maritimes and Moncton became the headquarters for CNR's Maritime division. The T. Eaton Company's catalogue warehouse moved to the city in the early 1920s, employing over 700 people. Transportation and distribution became increasingly important to the Moncton economy throughout the middle part of the 20th century. The first scheduled air service out of Moncton was established in 1928. During the Second World War the Canadian Army built a large military supply base in the city to service the Maritime military establishment. The CNR continued to dominate the economy of the city with railway employment in Moncton peaked at nearly six thousand workers in the 1950s before beginning a slow decline.

Moncton was placed on the Trans-Canada Highway network in the early 1960s after Route 2 was built along the northern perimeter of the city. Later, the Route 15 was built between the city and Shediac. At the same time, the Petitcodiac River Causeway was constructed. The Université de Moncton was founded in 1963. This institution became an important resource in the development of Acadian culture in the area.

The late 1970s and the 1980s were a period of economic hardship for the city as several major employers closed or restructured. The Eatons catalogue division, CNR's locomotive shops facility and CFB Moncton were closed during this time throwing thousands of citizens out of work.

The city diversified in the early 1990s with the rise of information technology, led by call centres which made use of the city's bilingual workforce. By the late 1990s, retail, manufacturing and service expansion began to occur in all sectors and within a decade of the closure of the CNR locomotive shops Moncton had more than made up for its employment losses. This dramatic turnaround in the fortunes of the city has been termed the "Moncton Miracle".

The growth of the community has continued unabated since the 1990s and has actually been accelerating. The confidence of the community has been bolstered by its ability to host major events such as the Francophonie Summit in 1999, a Rolling Stones concert in 2005, the Memorial Cup in 2006 and both the IAAF World Junior Championships in Athletics and a neutral site regular season CFL football game in 2010. Positive developments include the Atlantic Baptist University (later renamed Crandall University) achieving full university status and relocating to a new campus in 1996, the Greater Moncton Roméo LeBlanc International Airport opening a new terminal building and becoming a designated international airport in 2002, and the opening of the new Gunningsville Bridge to Riverview in 2005. In 2002, Moncton became Canada's first officially bilingual city. In the 2006 census, Moncton was designated a Census Metropolitan Area and became the largest metropolitan area in the province of New Brunswick.

Moncton lies in southeastern New Brunswick, at the geographic centre of the Maritime Provinces. The city is located along the north bank of the Petitcodiac River at a point where the river bends acutely from a west−east to north−south flow. This geographical feature has contributed significantly to historical names given to the community. "Petitcodiac" in the Mi'kmaq language has been translated as meaning "bends like a bow". The early Acadian settlers in the region named their community "Le Coude" which means "the elbow". Subsequent English immigrants changed the name of the settlement to "The Bend of the Petitcodiac" (or simply The Bend).

The Petitcodiac river valley at Moncton is broad and relatively flat, bounded by a long ridge to the north (Lutes Mountain) and by the rugged Caledonia Highlands to the south. Moncton lies at the original head of navigation on the river, however a causeway to Riverview (constructed in 1968) resulted in extensive sedimentation of the river channel downstream and rendered the Moncton area of the waterway unnavigable. On April 14, 2010, the causeway gates were opened in an effort to restore the silt-laden river.

The Petitcodiac River exhibits one of North America's few tidal bores: a regularly occurring wave that travels up the river on the leading edge of the incoming tide. The bore is as a result of the extreme tides of the Bay of Fundy. Originally, the bore was very impressive, sometimes between in height and extending across the width of the Petitcodiac River in the Moncton area. This wave would occur twice a day at high tide, travelling at an average speed of and producing an audible roar. Unsurprisingly, the "bore" became a very popular early tourist attraction for the city, but when the Petitcodiac causeway was built in the 1960s, the river channel quickly silted in and reduced the bore so that it rarely exceeds in height. On April 14, 2010, the causeway gates were opened in an effort to restore the silt-laden river. A recent tidal bore since the opening of the causeway gates measured a wave, unseen for many years.

Despite being less than from the Bay of Fundy and less than from the Northumberland Strait, the climate tends to be more continental than maritime during the summer and winter seasons, with maritime influences somewhat tempering the transitional seasons of spring and autumn.

Moncton has a warm summer continental climate (Köppen climate classification "Dfb") with uniform precipitation distribution. Winter days are typically cold but generally sunny with solar radiation generating some warmth. Daytime high temperatures usually range a few degrees below the freezing point. Major snowfalls can result from Nor'easter ocean storms moving up the east coast of North America. These major snowfalls typically average 20–30 cm (8–12 in) and are frequently mixed with rain or freezing rain. Spring is frequently delayed because the sea ice that forms in the nearby Gulf of St. Lawrence during the previous winter requires time to melt, and this will cool onshore winds, which can extend inland as far as Moncton. The ice burden in the gulf has diminished considerably over the course of the last decade (which may be a consequence of global warming), and the springtime cooling effect has weakened as a result. Daytime temperatures above freezing are typical by late February. Trees are usually in full leaf by late May. Summers are warm, sometimes hot, as well as humid due to the seasonal prevailing westerly winds strengthening the continental tendencies of the local climate. Daytime highs sometimes reach more than 30 °C (86 °F). Rainfall is generally modest, especially in late July and August, and periods of drought are not uncommon. Autumn daytime temperatures remain mild until late October. First snowfalls usually do not occur until late November and consistent snow cover on the ground does not happen until late December. The Fundy coast of New Brunswick occasionally experiences the effects of post-tropical storms. The stormiest weather of the year, with the greatest precipitation and the strongest winds, usually occurs during the fall/winter transition (November to mid-January).

The highest temperature ever recorded in Moncton was on August 18 & 19, 1935. The coldest temperature ever recorded was on February 5, 1948.

Moncton generally remains a "low rise" city. The city's skyline however encompasses many buildings and structures with varying architectural styles from many periods. The most dominant structure in the city is the Bell Aliant Tower, a microwave communications tower built in 1971. When it was constructed, it was the tallest microwave communications tower of its kind in North America. It remains the tallest structure in Moncton, dwarfing the neighbouring Place L’Assomption by . Indeed, the Bell Aliant Tower is also the tallest free-standing structure in all four Atlantic provinces. Assumption Place is a 20-story office building and is the headquarters of Assumption Mutual Life Insurance. This building is in height and is tied with Brunswick Square (Saint John) as the tallest building in the province. The Blue Cross Centre is a large nine-story building in Downtown Moncton. Although only nine stories tall, the building is architecturally distinctive, encompasses a full city block, and is the largest office building in the city in terms of square footage. It is the home of Medavie Blue Cross and the Moncton Public Library. There are about a half dozen other buildings in Moncton that range between eight and twelve stories in height, including the Delta Beausejour and Brunswick Crowne Plaza Hotels and the Terminal Plaza office complex.
The most popular park in the area is Centennial Park, which contains an artificial beach, lighted cross country skiing and hiking trails, the city's largest playground, lawn bowling and tennis facilities, a boating pond, a treetop adventure course, and Rocky Stone Field, a city owned 2,500 seat football stadium with artificial turf, and home to the Moncton Minor Football Association.
The city's other main parks are Mapleton Park in the city's north end, Irishtown Nature Park (one of the largest urban nature parks in Canada) and St. Anselme Park (located in Dieppe). The numerous neighbourhood parks throughout the metro Moncton area include Bore View Park (which overlooks the Petitcodiac River), and the downtown Victoria Park, which features a bandshell, flower gardens, fountain, and the city's cenotaph. There is an extensive system of hiking and biking trails in Metro Moncton. The Riverfront Trail is part of the Trans Canada Trail system, and various monuments and pavilions can be found along its length.

The population of Moncton is 71,889 (2016 Census). Along with Fredericton and Halifax, Moncton is one of only three Maritime cities to register a population increase in recent years. The median age in Moncton is 41.4, close to the national median age of 41.2.

Moncton is a bilingual city. About two-thirds of its residents are native English speakers, while the remaining third is French-speaking. Almost all Monctonians speak English (64.6%) or French (31.9%) as first languages; 1.6% speak both languages as a first language, and 6.9% speak another language. About 46% of the city population is bilingual and understands both English and French; the only other Canadian cities that approach this level of linguistic duality are Ottawa, Sudbury, and Montreal. Moncton became the first officially bilingual city in the country in 2002. The adjacent city of Dieppe is about 73% Francophone and has benefited from an ongoing rural depopulation of the Acadian Peninsula and areas in northern and eastern New Brunswick. The town of Riverview meanwhile is heavily (95%) Anglophone.

As of 2016, approximately 87.6% of Moncton's residents were white, while 7.4% were visible minorities and 5% were aboriginal. The largest visible minority groups in Moncton were Black (2.6%), Arab (1.3%), Chinese (0.9%), and Korean, Southeast Asian, South Asian and Filipino (0.5% each).

The Moncton census metropolitan area (CMA) had a population of 144,810 in 2016, ranking it as the 29th largest CMA in Canada.

The underpinnings of the local economy are based on Moncton's heritage as a commercial, distribution, transportation, and retailing centre. This is due to Moncton's central location in the Maritimes: it has the largest catchment area in Atlantic Canada with 1.6 million people living within a three-hour drive of the city. The insurance, information technology, educational, and health care sectors also are major factors in the local economy with the city's two hospitals alone employing over five thousand people.

Moncton has garnered national attention because of the strength of its economy. The local unemployment rate averages around 6%, which is below the national average. In 2004 Canadian Business Magazine named it "The best city for business in Canada", and in 2007 FDi magazine named it the fifth most business-friendly small-sized city in North America.

A number of nationally or regionally prominent corporations have their head offices in Moncton including Atlantic Lottery Corporation, Assumption Life Insurance, Medavie Blue Cross Insurance, Armour Transportation Systems and Major Drilling Group International. Moncton also has federal public service employment, with regional head offices for Corrections Canada, Transport Canada, the Gulf Fisheries Centre and the Atlantic Canada Opportunities Agency.

There are 37 call centres in the city which employ over 5000 people. Some of the larger centres include Asurion, Numeris (formerly BBM Canada), Exxon Mobil, Royal Bank of Canada, Tangerine Bank (formerly ING Direct), UPS, Fairmont Hotels and Resorts, Rogers Communications, and Nordia Inc.. A growing high tech sector includes companies such as Gtech, Nanoptix, International Game Technology, OAO Technology Solutions, BMM Test Labs, TrustMe, and BelTek Systems Design. TD Bank announced in 2018 a new banking services centre to be located in Moncton which will employ over 1,000 people (including a previously announced customer contact centre).

Several arms of the Irving corporation have their head offices and/or major operations in greater Moncton. These include Midland Transport, Majesta/Royale Tissues, Irving Personal Care, Master Packaging, Brunswick News, and Cavendish Farms. Kent Building Supplies (an Irving subsidiary) opened their main distribution centre in the Caledonia Industrial Park in 2014. The Irving group of companies employs several thousand people in the Moncton region.

There are three large industrial parks in the metropolitan area. The Irving operations are concentrated in the Dieppe Industrial Park. The Moncton Industrial Park in the city's west end has been expanded. Molson/Coors opened a brewery in the Caledonia Industrial Park in 2007, its first new brewery in over fifty years. All three industrial parks also have large concentrations of warehousing and regional trucking facilities.

A new four-lane Gunningsville Bridge was opened in 2005, connecting downtown Riverview directly with downtown Moncton. On the Moncton side, the bridge connects with an extension of Vaughan Harvey Boulevard as well as to Assumption Boulevard and will serve as a catalyst for economic growth in the downtown area. This has become already evident as an expansion to the Blue Cross Centre was completed in 2006 and a Marriott Residence Inn opened in 2008. The new regional law courts on Assumption Blvd opened in 2011. A new 8,800 seat downtown arena (the Avenir Centre) recently opened in September 2018. On the Riverview side, the Gunningsville Bridge now connects to a new ring road around the town and is expected to serve as a catalyst for development in east Riverview.

The retail sector in Moncton has become one of the most important pillars of the local economy. Major retail projects such as Champlain Place in Dieppe and the Wheeler Park Power Centre on Trinity Drive have become major destinations for locals and for tourists alike.

Tourism is an important industry in Moncton and historically owes its origins to the presence of two natural attractions, the tidal bore of the Petitcodiac River (see above) and the optical illusion of Magnetic Hill. The tidal bore was the first phenomenon to become an attraction but the construction of the Petitcodiac causeway in the 1960s effectively extirpated the attraction. Magnetic Hill, on the city's northwest outskirts, is the city's most famous attraction. The Magnetic Hill area includes (in addition to the phenomenon itself), a golf course, major water park, zoo, and an outdoor concert facility. A $90 million casino/hotel/entertainment complex opened at Magnetic Hill in 2010.

Moncton's Capitol Theatre, an 800-seat restored 1920s-era vaudeville house on Main Street, is the main centre for cultural entertainment for the city. The theatre hosts a performing arts series and provides a venue for various theatrical performances as well as Symphony New Brunswick and the Atlantic Ballet Theatre of Canada. The adjacent Empress Theatre offers space for smaller performances and recitals. The Molson Canadian Centre at Casino New Brunswick provides a 2,000 seat venue for major touring artists and performing groups.

The Moncton-based Atlantic Ballet Theatre tours mainly in Atlantic Canada but also tours nationally and internationally on occasion. Théâtre l'Escaouette is a Francophone live theatre company which has its own auditorium and performance space on Botsford Street. The Anglophone Live Bait Theatre is based in the nearby university town of Sackville. There are several private dance and music academies in the metropolitan area, including the Capitol Theatre's own performing arts school.

The Aberdeen Cultural Centre is a major Acadian cultural cooperative containing multiple studios and galleries. Among other tenants, the centre houses the Galerie Sans Nom, the principal private art gallery in the city.

The city's two main museums are the Moncton Museum at Resurgo Place on Mountain Road and the Musée acadien at Université de Moncton. The Moncton Museum reopened following major renovations and an expansion to include the Transportation Discovery Centre. The Discovery Centre includes many hands on exhibits highlighting the city's transportation heritage. The city also has several recognized historical sites. The Free Meeting House was built in 1821 and is a New England-style meeting house located adjacent to the Moncton Museum. The Thomas Williams House, a former home of a city industrialist built in 1883, is now maintained in period style and serves as a genealogical research centre and is also home to several multicultural organizations. The Treitz Haus is located on the riverfront adjacent to Bore View Park and has been dated to 1769 both by architectural style and by dendrochronology. It is the only surviving building from the Pennsylvania Dutch era and is the oldest surviving building in the province of New Brunswick.

In film production, the city has since 1974 been home to the National Film Board of Canada's French-language Studio Acadie.

Moncton is home to the Frye Festival, an annual bilingual literary celebration held in honour of world-renowned literary critic and favourite son Northrop Frye. This event attracts noted writers and poets from around the world and takes place in the month of April.

The Atlantic Nationals Automotive Extravaganza, held each July, is the largest annual gathering of classic cars in Canada. Other notable events include The Atlantic Seafood Festival in August, The HubCap Comedy Festival, and the World Wine Festival, both held in the spring.

Our Lady of the Assumption Cathedral is the location of an interpretation centre, Monument for Recognition in the 21st century (MR21).

The Avenir Centre is an 8,800 seat arena which serves as a venue for major concerts and sporting events and is the home of the Moncton Wildcats of the Quebec Major Junior Hockey League and the Moncton Magic of the National Basketball League of Canada. The CN Sportplex is a major recreational facility which has been built on the former CN Shops property. It includes ten ballfields, six soccer fields, an indoor rink complex with four ice surfaces (the Superior Propane Centre) and the Hollis Wealth Sports Dome, an indoor air supported multi-use building. The Sports Dome is large enough to allow for year-round football, soccer and golf activities. A newly constructed YMCA near the CN Sportsplex has extensive cardio and weight training facilities, as well as three indoor pools. The CEPS at Université de Moncton contains an indoor track and a swimming pool with diving towers. The new Moncton Stadium, also located at the U de M campus was built for the 2010 IAAF World Junior Track & Field Championships. It has a permanent seating for 10,000, but is expandable to a capacity of over 20,000 for events such as professional Canadian football. The only velodrome in Atlantic Canada is in Dieppe. It has since been closed after 17 years of existence due to safety concerns in May 2018. The metro area has a total of 12 indoor hockey rinks and three curling clubs. Other public sporting and recreational facilities are scattered throughout the metropolitan area, including a new $18 million aquatic centre in Dieppe opened in 2009.

The Moncton Wildcats play major junior hockey in the Quebec Major Junior Hockey League (QMJHL). They won the President's Cup, the QMJHL championship in both 2006 and 2010. Historically there has been a longstanding presence of a Moncton-based team in the Maritime Junior A Hockey League, but the Dieppe Commandos (formerly known as the Moncton Beavers) relocated to Edmundston at the end of the 2017 season. Historically, Moncton also was home to a professional American Hockey League franchise from 1978 to 1994. The New Brunswick Hawks won the AHL Calder Cup by defeating the Binghamton Whalers in 1981–1982. The Moncton Mets played baseball in the New Brunswick Senior Baseball League and won the Canadian Senior Baseball Championship in 2006. In 2015, the Moncton Fisher Cats began play in the New Brunswick Senior Baseball League. They were formed by a merger between the Moncton Mets and the Hub City Brewers of the NBSBL. In 2011, the Moncton Miracles began play as one of the seven charter franchises of the professional National Basketball League of Canada. The franchise failed at the end of the 2016/17 season, to be immediately replaced by a new NBL franchise, the Moncton Magic, who played their inaugural season in 2017/18. The Universite de Moncton has a number of active CIS university sports programs including hockey, soccer, and volleyball. These teams are a part of the Canadian Interuniversity Sport program.

Moncton has hosted many large sporting events. The 2006 Memorial Cup was held in Moncton with the hometown Moncton Wildcats losing in the championship final to rival Quebec Remparts. Moncton hosted the Canadian Interuniversity Sports (CIS) Men's University Hockey Championship in 2007 and 2008. The World Men's Curling Championship was held in Moncton in 2009; the second time this event has taken place in the city.

Moncton also hosted the 2010 IAAF World Junior Championships in Athletics. This was the largest sporting event ever held in Atlantic Canada, with athletes from over 170 countries in attendance. The new 10,000 seat capacity Moncton Stadium was built for this event on the Université de Moncton campus. The construction of this new stadium led directly to Moncton being awarded a regular season neutral site CFL game between the Toronto Argonauts and the Edmonton Eskimos, which was held on September 26, 2010. This was the first neutral site regular season game in the history of the Canadian Football League and was played before a capacity crowd of 20,750. Additional CFL regular season games were held in 2011 and 2013, and again on August 25, 2019.

Moncton was one of only six Canadian cities chosen to host the 2015 FIFA Women's World Cup.

Major sporting events hosted by Moncton include:
The municipal government consists of a mayor and ten city councillors elected to four-year terms of office. The council is non-partisan with the mayor serving as the chairman, casting a ballot only in cases of a tie vote. There are four wards electing two councillors each with an additional two councillors selected at large by the general electorate. Day-to-day operation of the city is under the control of a City Manager.

Moncton is in the federal riding of Moncton—Riverview—Dieppe. Portions of Dieppe are in the federal riding of Beauséjour, and portions of Riverview are in the riding of Fundy Royal. In the current federal parliament, all three members from the metropolitan area belong to the Liberal party.

Aside from locally formed militia units, the military did not have a significant presence in the Moncton area until the beginning of the Second World War. In 1940, a large military supply base (later known as CFB Moncton) was constructed on a railway spur line north of downtown next to the CNR shops. This base served as the main supply depot for the large wartime military establishment in the Maritimes. In addition, two Commonwealth Air Training Plan bases were also built in the Moncton area during the war: No. 8 Service Flying Training School, RCAF, and No. 31 Personnel Depot, RAF. The RCAF also operated No. 5 Supply Depot in Moncton. A naval listening station was also constructed in Coverdale (Riverview) in 1941 to help in coordinating radar activities in the North Atlantic. Military flight training in the Moncton area terminated at the end of World War II and the naval listening station closed in 1971. CFB Moncton remained open to supply the maritime military establishment until just after the end of the Cold War.

With the closure of CFB Moncton in the early 1990s, the military presence in Moncton has been significantly reduced. The northern portion of the former base property has been turned over to the Canada Lands Corporation and is slowly being redeveloped. The southern part of the former base remains an active DND property and is now termed the Moncton Garrison. It is affiliated with CFB Gagetown. Resident components of the garrison include the 1 Engineer Support Unit(Regular force). The garrison also houses the 37 Canadian Brigade Group Headquarters (reserve force) and one of the 37 Brigades constituent units; the 8th Canadian Hussars (Princess Louise's), which is an armoured reconnaissance regiment. 3 Area support unit Det Moncton, and 42 Canadian Forces Health Services Centre Det Moncton provide logistical support for the base. In 2013, the last regular forces units left the Moncton base, but the reserve units remain active and Moncton remains the 37 Canadian Brigade Unit headquarters.

There are two major regional referral and teaching hospitals in Moncton. The Moncton Hospital has approximately 381 inpatient beds and is affiliated with Dalhousie University Medical School. It is home to the Northumberland family medicine residency training program and is a site for third and fourth year clinical training for medical students in the Dalhousie Medicine New Brunswick Training Program. The hospital hosts UNB degree programs in nursing and medical x-ray technology and professional internships in fields such as dietetics. Specialized medical services at the hospital include neurosurgery, peripheral and neuro-interventional radiology, vascular surgery, thoracic surgery, hepatobiliary surgery, orthopedics, trauma, burn unit, medical oncology, neonatal intensive care, and adolescent psychiatry. A$48 million expansion to the hospital was completed in 2009 and contains a new laboratory, ambulatory care centre, and provincial level one trauma centre. A new oncology clinic was built at the hospital and opened in late 2014. The Moncton Hospital is managed by Horizon Health Network (formerly the South East Regional Health Authority).

The Dr. Georges-L.-Dumont University Hospital Centre has about 302 beds and hosts a medical training program through the local CFMNB and distant Université de Sherbrooke Medical School. There are also degree programs in nursing, medical x-ray technology, medical laboratory technology and inhalotherapy which are administered by Université de Moncton. Specialized medical services include medical oncology, radiation oncology, orthopedics, vascular surgery, and nephrology. 
A cardiac cath lab is being studied for the hospital and a new PET/CT scanner has been installed. A$75 million expansion for ambulatory care, expanded surgery suites, and medical training is currently under construction. The hospital is also the location of the Atlantic Cancer Research Institute. This hospital is managed by francophone Vitalité Health Network.

The internal working languages of the hospitals are English for the Moncton Hospital (Horizon Health Network) and French for the Dumont Hospital (Vitalité). However both health networks and their hospitals are required to provide services to the public in both official languages, in accordance with the New Brunswick Official Languages Act.

Moncton is served by the Greater Moncton Roméo LeBlanc International Airport (YQM). It was renamed for former Canadian Governor-General (and native son) Roméo LeBlanc in 2016. A new airport terminal with an international arrivals area was opened in 2002 by Her Majesty Queen Elizabeth II. The GMIA handles about 677,000 passengers per year, making it the second busiest airport in the Maritimes in terms of passenger volume. The GMIA is the 10th busiest airport in Canada in terms of freight. Regular scheduled destinations include Halifax, Montreal, Ottawa, and Toronto. Scheduled service providers include Air Canada, Air Canada Rouge, Westjet and Porter Airlines. Seasonal direct air service is provided to destinations in Cuba, Mexico, the Dominican Republic, Jamaica, and Florida, with operators including Sunwing Airlines, Air Transat, and Westjet. FedEx, UPS, and Purolator all have their Atlantic Canadian air cargo bases at the facility. The GMIA is the home of the Moncton Flight College; the largest pilot training institution in Canada, and is also the base for the regional RCMP air service, the New Brunswick Air Ambulance Service and the regional Transport Canada hangar and depot.

There is a second smaller aerodrome near Elmwood Drive. McEwen Airfield (CCG4) is a private airstrip used for general aviation. Skydive Moncton operates the province's only nationally certified sports parachute club out of this facility.

The Moncton Area Control Centre is one of only seven regional air traffic control centres in Canada. This centre monitors over 430,000 flights a year, 80% of which are either entering or leaving North American airspace.

Moncton lies on Route 2 of the Trans-Canada Highway, which leads to Nova Scotia in the east and to Fredericton and Quebec in the west. Route 15 intersects Route 2 at the eastern outskirts of Moncton, heads northeast leading to Shediac and northern New Brunswick, Route 16 connects to route 15 at Shediac and leads to Port Elgin and Prince Edward Island. Route 1 intersects Route 2 approximately west of the city and leads to Saint John and the U.S. border. Wheeler Boulevard (Route 15) serves as an internal ring road, extending from the Petitcodiac River Causeway to Dieppe before exiting the city and heading for Shediac. Inside the city it is an expressway bounded at either end by traffic circles.

Greater Moncton is served by Codiac Transpo, which is operated by the City of Moncton. It operates 40 buses on 19 routes throughout Moncton, Dieppe, and Riverview.

Maritime Bus provides intercity service to the region. Moncton is the largest hub in the system. All other major centres in New Brunswick, as well as Charlottetown, Halifax, and Truro are served out of the Moncton terminal.

Freight rail transportation in Moncton is provided by Canadian National Railway. Although the presence of the CNR in Moncton has diminished greatly since the 1970s, the railway still maintains a large classification yard and intermodal facility in the west end of the city, and the regional headquarters for Atlantic Canada is still located here as well. Passenger rail transportation is provided by Via Rail Canada, with their train the "Ocean" serving the Moncton railway station three days per week to Halifax and to Montreal, Quebec. The downtown Via station has been refurbished and also serves as the terminal for the Maritime Bus intercity bus service.

The South School Board administers 10 Francophone schools, including high schools École Mathieu-Martin and École L'Odyssée. The East School Board administers 25 Anglophone schools including Moncton, Harrison Trimble, Bernice MacNaughton, and Riverview high schools.

Post secondary education in Moncton:

Moncton's daily newspaper is the "Times & Transcript", which has the highest circulation of any daily newspaper in New Brunswick. More than 60 percent of city households subscribe daily, and more than 90 percent of Moncton residents read the Times & Transcript at least once a week. The city's other publications include "L'Acadie Nouvelle", a French newspaper published in Caraquet in northern New Brunswick.

There are 16 broadcast radio stations in the city covering a variety of genres and interests, all on the FM dial. Ten of these stations are English and six are French.

Rogers Cable has its provincial headquarters and main production facilities in Moncton and broadcasts on two community channels, Cable 9 in French and Cable 10 in English. The French-language arm of the CBC, Radio-Canada, maintains its Atlantic Canadian headquarters in Moncton. There are three other broadcast television stations in Moncton and these represent all of the major national networks.

Moncton has been the home of a number of notable people, including National Hockey League Hall of Famer and NHL scoring champion Gordie Drillon, World and Olympic champion curler Russ Howard, distinguished literary critic and theorist Northrop Frye, former Governor-General of Canada Roméo LeBlanc, and former Supreme Court Justice Ivan Cleveland Rand, developer of the Rand Formula and Canada's representative on the UNSCOP commission. Trudy Mackay FRS, renowned quantitative geneticist, member of the Royal Society and National Academy of Sciences, and recipient of the prestigious Wolf Prize for agriculture (2016), was born in Moncton. Robb Wells, the actor who plays Ricky on the Showcase hit comedy "Trailer Park Boys" hails from Moncton, along with Chris Lee, Jacques Daigle, Julie Doiron, an indie rock musician, and Holly Dignard the actress who plays Nicole Miller on the CTV series "Whistler". Harry Currie, noted Canadian conductor, musician, educator, journalist and author was born in Moncton and graduated from MHS. Antonine Maillet, a francophone author, recipient of the Order of Canada and the "Prix Goncourt", the highest honour in francophone literature, is also from Moncton. France Daigle, another acclaimed Acadian novelist and playwright, was born and resides in Moncton, and is noted for her pioneering use of chiac in Acadian literature, was the recipient of the 2012 Governor General's Literary Prize in French Fiction, for her novel "Pour Sûr" (translated into English as "For Sure"). Canadian hockey star Sidney Crosby graduated from Harrison Trimble High School in Moncton.






</doc>
<doc id="19858" url="https://en.wikipedia.org/wiki?curid=19858" title="Model theory">
Model theory

In mathematics, model theory is the study of classes of mathematical structures (e.g. groups, fields, graphs, universes of set theory) from the perspective of mathematical logic. The objects of study are models of theories in a formal language. A set of sentences in a formal language is one of the components that form a theory. A model of a theory is a structure (e.g. an interpretation) that satisfies the sentences of that theory.

Model theory recognizes and is intimately concerned with a duality: it examines semantical elements (meaning and truth) by means of syntactical elements (formulas and proofs) of a corresponding language. In a summary definition, dating from 1973:

Model theory developed rapidly during the 1990s, and a more modern definition is provided by Wilfrid Hodges (1997):

Other nearby areas of mathematics include combinatorics, number theory, arithmetic dynamics, analytic functions, and non-standard analysis.

In a similar way to proof theory, model theory is situated in an area of interdisciplinarity among mathematics, philosophy, and computer science. The most prominent professional organization in the field of model theory is the Association for Symbolic Logic.

This page focuses on finitary first order model theory of infinite structures. Finite model theory, which concentrates on finite structures, diverges significantly from the study of infinite structures in both the problems studied and the techniques used. Model theory in higher-order logics or infinitary logics is hampered by the fact that completeness and compactness do not in general hold for these logics. However, a great deal of study has also been done in such logics.

Informally, model theory can be divided into classical model theory, model theory applied to groups and fields, and geometric model theory. A missing subdivision is computable model theory, but this can arguably be viewed as an independent subfield of logic.

Examples of early theorems from classical model theory include Gödel's completeness theorem, the upward and downward Löwenheim–Skolem theorems, Vaught's two-cardinal theorem, Scott's isomorphism theorem, the omitting types theorem, and the Ryll-Nardzewski theorem. Examples of early results from model theory applied to fields are Tarski's elimination of quantifiers for real closed fields, Ax's theorem on pseudo-finite fields, and Robinson's development of non-standard analysis. An important step in the evolution of classical model theory occurred with the birth of stability theory (through Morley's theorem on uncountably categorical theories and Shelah's classification program), which developed a calculus of independence and rank based on syntactical conditions satisfied by theories.

During the last several decades applied model theory has repeatedly merged with the more pure stability theory. The result of this synthesis is called geometric model theory in this article (which is taken to include o-minimality, for example, as well as classical geometric stability theory). An example of a proof from geometric model theory is Hrushovski's proof of the Mordell–Lang conjecture for function fields. The ambition of geometric model theory is to provide a "geography of mathematics" by embarking on a detailed study of definable sets in various mathematical structures, aided by the substantial tools developed in the study of pure model theory.

Fundamental concepts in universal algebra are signatures σ and σ-algebras. Since these concepts are formally defined in the article on structures, the present article is an informal introduction which consists of examples of the way these terms are used.

This is a very efficient way to define most classes of algebraic structures, because there is also the concept of σ-homomorphism, which correctly specializes to the usual notions of homomorphism for groups, semigroups, magmas and rings. For this to work, the signature must be chosen well.

Terms such as the σ-term "t"("u","v","w") given by are used to define identities but also to construct free algebras. An equational class is a class of structures which, like the examples above and many others, is defined as the class of all σ-structures which satisfy a certain set of identities. Birkhoff's theorem states:

An important non-trivial tool in universal algebra are ultraproducts formula_1, where "I" is an infinite set indexing a system of σ-structures "A", and "U" is an ultrafilter on "I".

While model theory is generally considered a part of mathematical logic, universal algebra, which grew out of Alfred North Whitehead's (1898) work on abstract algebra, is part of algebra. This is reflected by their respective MSC classifications. Nevertheless, model theory can be seen as an extension of universal algebra.

Finite model theory is the area of model theory which has the closest ties to universal algebra. Like some parts of universal algebra, and in contrast with the other areas of model theory, it is mainly concerned with finite algebras, or more generally, with finite σ-structures for signatures σ which may contain relation symbols as in the following example:

A σ-homomorphism is a map that commutes with the operations and preserves the relations in σ. This definition gives rise to the usual notion of graph homomorphism, which has the interesting property that a bijective homomorphism need not be invertible. Structures are also a part of universal algebra; after all, some algebraic structures such as ordered groups have a binary relation <. What distinguishes finite model theory from universal algebra is its use of more general logical sentences (as in the example above) in place of identities. (In a model-theoretic context an identity "t"="t<nowiki>'</nowiki>" is written as a sentence formula_3.)

The logics employed in finite model theory are often substantially more expressive than first-order logic, the standard logic for model theory of infinite structures.

Whereas universal algebra provides the semantics for a signature, logic provides the syntax. With terms, identities and quasi-identities, even universal algebra has some limited syntactic tools; first-order logic is the result of making quantification explicit and adding negation into the picture.

A first-order formula is built out of atomic formulas such as "R"("f"("x","y"),"z") or "y" = "x" + 1 by means of the Boolean connectives formula_4 and prefixing of quantifiers formula_5 or formula_6. A sentence is a formula in which each occurrence of a variable is in the scope of a corresponding quantifier. Examples for formulas are φ (or φ(x) to mark the fact that at most x is an unbound variable in φ) and ψ defined as follows:

(Note that the equality symbol has a double meaning here.) It is intuitively clear how to translate such formulas into mathematical meaning. In the σ-structure formula_9 of the natural numbers, for example, an element "n" satisfies the formula φ if and only if "n" is a prime number. The formula ψ similarly defines irreducibility. Tarski gave a rigorous definition, sometimes called "Tarski's definition of truth", for the satisfaction relation formula_10, so that one easily proves:

A set "T" of sentences is called a (first-order) theory. A theory is satisfiable if it has a model formula_13, i.e. a structure (of the appropriate signature) which satisfies all the sentences in the set "T". Consistency of a theory is usually defined in a syntactical way, but in first-order logic by the completeness theorem there is no need to distinguish between satisfiability and consistency. Therefore, model theorists often use "consistent" as a synonym for "satisfiable".

A theory is called categorical if it determines a structure up to isomorphism, but it turns out that this definition is not useful, due to serious restrictions in the expressivity of first-order logic. The Löwenheim–Skolem theorem implies that for every theory "T" having a countable signature which has an infinite model for some infinite cardinal number, then it has a model of size κ for any infinite cardinal number κ. Since two models of different sizes cannot possibly be isomorphic, only finitary structures can be described by a categorical theory.

Lack of expressivity (when compared to higher logics such as second-order logic) has its advantages, though. For model theorists, the Löwenheim–Skolem theorem is an important practical tool rather than the source of Skolem's paradox. In a certain sense made precise by Lindström's theorem, first-order logic is the most expressive logic for which both the Löwenheim–Skolem theorem and the compactness theorem hold.

As a corollary (i.e., its contrapositive), the compactness theorem says that every unsatisfiable first-order theory has a finite unsatisfiable subset. This theorem is of central importance in infinite model theory, where the words "by compactness" are commonplace. One way to prove it is by means of ultraproducts. An alternative proof uses the completeness theorem, which is otherwise reduced to a marginal role in most of modern model theory.

As observed in the section on first-order logic, first-order theories cannot be categorical, i.e. they cannot describe a unique model up to isomorphism, unless that model is finite. But two famous model-theoretic theorems deal with the weaker notion of κ-categoricity for a cardinal κ. A theory "T" is called κ-categorical if any two models of "T" that are of cardinality κ are isomorphic. It turns out that the question of κ-categoricity depends critically on whether κ is bigger than the cardinality of the language (i.e. formula_14 + |σ|, where |σ| is the cardinality of the signature). For finite or countable signatures this means that there is a fundamental difference between formula_14-cardinality and κ-cardinality for uncountable κ.

A few characterizations of formula_14-categoricity include:

This result, due independently to Engeler, Ryll-Nardzewski and Svenonius, is sometimes referred to as the Ryll-Nardzewski theorem.

Further, formula_14-categorical theories and their countable models have strong ties with oligomorphic groups. They are often constructed as Fraïssé limits.

Michael Morley's highly non-trivial result that (for countable languages) there is only "one" notion of uncountable categoricity was the starting point for modern model theory, and in particular classification theory and stability theory:

Uncountably categorical (i.e. κ-categorical for all uncountable cardinals κ) theories are from many points of view the most well-behaved theories. A theory that is both formula_14-categorical and uncountably categorical is called totally categorical.

Set theory (which is expressed in a countable language), if it is consistent, has a countable model; this is known as Skolem's paradox, since there are sentences in set theory which postulate the existence of uncountable sets and yet these sentences are true in our countable model. Particularly the proof of the independence of the continuum hypothesis requires considering sets in models which appear to be uncountable when viewed from "within" the model, but are countable to someone "outside" the model.

The model-theoretic viewpoint has been useful in set theory; for example in Kurt Gödel's work on the constructible universe, which, along with the method of forcing developed by Paul Cohen can be shown to prove the (again philosophically interesting) independence of the axiom of choice and the continuum hypothesis from the other axioms of set theory.

In the other direction, model theory itself can be formalized within ZFC set theory. The development of the fundamentals of model theory (such as the compactness theorem) rely on the axiom of choice, or more exactly the Boolean prime ideal theorem. Other results in model theory depend on set-theoretic axioms beyond the standard ZFC framework. For example, if the Continuum Hypothesis holds then every countable model has an ultrapower which is saturated (in its own cardinality). Similarly, if the Generalized Continuum Hypothesis holds then every model has a saturated elementary extension. Neither of these results are provable in ZFC alone. Finally, some questions arising from model theory (such as compactness for infinitary logics) have been shown to be equivalent to large cardinal axioms.

A field or a vector space can be regarded as a (commutative) group by simply ignoring some of its structure. The corresponding notion in model theory is that of a reduct of a structure to a subset of the original signature. The opposite relation is called an "expansion" - e.g. the (additive) group of the rational numbers, regarded as a structure in the signature {+,0} can be expanded to a field with the signature {×,+,1,0} or to an ordered group with the signature {+,0,<}.

Similarly, if σ' is a signature that extends another signature σ, then a complete σ'-theory can be restricted to σ by intersecting the set of its sentences with the set of σ-formulas. Conversely, a complete σ-theory can be regarded as a σ'-theory, and one can extend it (in more than one way) to a complete σ'-theory. The terms reduct and expansion are sometimes applied to this relation as well.

Given a mathematical structure, there are very often associated structures which can be constructed as a quotient of part of the original structure via an equivalence relation. An important example is a quotient group of a group.

One might say that to understand the full structure one must understand these quotients. When the equivalence relation is definable, we can give the previous sentence a precise meaning. We say that these structures are interpretable.

A key fact is that one can translate sentences from the language of the interpreted structures to the language of the original structure. Thus one can show that if a structure "M" interprets another whose theory is undecidable, then "M" itself is undecidable.

Gödel's completeness theorem (not to be confused with his incompleteness theorems) says that a theory has a model if and only if it is consistent, i.e. no contradiction is proved by the theory. This is the heart of model theory as it lets us answer questions about theories by looking at models and vice versa. One should not confuse the completeness theorem with the notion of a complete theory. A complete theory is a theory that contains every sentence or its negation. Importantly, one can find a complete consistent theory extending any consistent theory. However, as shown by Gödel's incompleteness theorems only in relatively simple cases will it be possible to have a complete consistent theory that is also recursive, i.e. that can be described by a recursively enumerable set of axioms. In particular, the theory of natural numbers has no recursive complete and consistent theory. Non-recursive theories are of little practical use, since it is undecidable if a proposed axiom is indeed an axiom, making proof-checking a supertask.

The compactness theorem states that a set of sentences S is satisfiable if every finite subset of S is satisfiable. In the context of proof theory the analogous statement is trivial, since every proof can have only a finite number of antecedents used in the proof. In the context of model theory, however, this proof is somewhat more difficult. There are two well known proofs, one by Gödel (which goes via proofs) and one by Malcev (which is more direct and allows us to restrict the cardinality of the resulting model).

Model theory is usually concerned with first-order logic, and many important results (such as the completeness and compactness theorems) fail in second-order logic or other alternatives. In first-order logic all infinite cardinals look the same to a language which is countable. This is expressed in the Löwenheim–Skolem theorems, which state that any countable theory with an infinite model formula_20 has models of all infinite cardinalities (at least that of the language) which agree with formula_20 on all sentences, i.e. they are 'elementarily equivalent'.

Fix an formula_22-structure formula_23, and a natural number formula_24. The set of definable subsets of formula_25 over some parameters formula_26 is a Boolean algebra. By Stone's representation theorem for Boolean algebras there is a natural dual notion to this. One can consider this to be the topological space consisting of maximal consistent sets of formulae over formula_26. We call this the space of (complete) formula_24-types over formula_26, and write formula_30.

Now consider an element formula_31. Then the set of all formulae formula_32 with parameters in formula_26 in free variables formula_34 so that formula_35 is consistent and maximal such. It is called the "type" of formula_36 over formula_26.

One can show that for any formula_24-type formula_39, there exists some elementary extension formula_40 of formula_23 and some formula_42 so that formula_39 is the type of formula_44 over formula_26.

Many important properties in model theory can be expressed with types. Further many proofs go via constructing models with elements that contain elements with certain types and then using these elements.

Illustrative example: Suppose formula_23 is an algebraically closed field. The theory has quantifier elimination . This allows us to show that a type is determined exactly by the polynomial equations it contains. Thus the space of formula_24-types over a subfield formula_26 is bijective with the set of prime ideals of the polynomial ring formula_49. This is the same set as the spectrum of formula_49. Note however that the topology considered on the type space is the constructible topology: a set of types is basic open iff it is of the form formula_51 or of the form formula_52. This is finer than the Zariski topology.

Model theory as a subject has existed since approximately the middle of the 20th century. However some earlier research, especially in mathematical logic, is often regarded as being of a model-theoretical nature in retrospect. The first significant result in what is now model theory was a special case of the downward Löwenheim–Skolem theorem, published by Leopold Löwenheim in 1915. The compactness theorem was implicit in work by Thoralf Skolem, but it was first published in 1930, as a lemma in Kurt Gödel's proof of his completeness theorem. The Löwenheim–Skolem theorem and the compactness theorem received their respective general forms in 1936 and 1941 from Anatoly Maltsev.

The development of model theory can be traced to Alfred Tarski, a member of the Lwów–Warsaw school during the interbellum. Tarski's work included logical consequence, deductive systems, the algebra of logic, the theory of definability, and the semantic definition of truth, among other topics. His semantic methods culminated in the model theory he and a number of his Berkeley students developed in the 1950s and '60s. These modern concepts of model theory influenced Hilbert's program and modern mathematics.








</doc>
<doc id="19859" url="https://en.wikipedia.org/wiki?curid=19859" title="Moby-Dick">
Moby-Dick

Moby-Dick; or, The Whale is an 1851 novel by American writer Herman Melville. The book is the sailor Ishmael's narrative of the obsessive quest of Ahab, captain of the whaling ship "Pequod", for revenge on Moby Dick, the giant white sperm whale that on the ship's previous voyage bit off Ahab's leg at the knee. A contribution to the literature of the American Renaissance, "Moby-Dick" was published to mixed reviews, was a commercial failure, and was out of print at the time of the author's death in 1891. Its reputation as a "Great American Novel" was established only in the 20th century, after the centennial of its author's birth. William Faulkner said he wished he had written the book himself, and D. H. Lawrence called it "one of the strangest and most wonderful books in the world" and "the greatest book of the sea ever written". Its opening sentence, "Call me Ishmael", is among world literature's most famous.

Melville began writing "Moby-Dick" in February 1850, and finished 18 months later, a year longer than he had anticipated. Melville drew on his experience as a common sailor from 1841 to 1844, including several years on whalers, and on wide reading in whaling literature. The white whale is modeled on the notoriously hard-to-catch albino whale Mocha Dick, and the book's ending is based on the sinking of the whaleship "Essex" in 1820. His literary influences include Shakespeare and the Bible. The detailed and realistic descriptions of whale hunting and of extracting whale oil, as well as life aboard ship among a culturally diverse crew, are mixed with exploration of class and social status, good and evil, and the existence of God. In addition to narrative prose, Melville uses styles and literary devices ranging from songs, poetry, and catalogs to Shakespearean stage directions, soliloquies, and asides. In August 1850, with the manuscript perhaps half finished, he met Nathaniel Hawthorne and was deeply moved by his "Mosses from an Old Manse", which he compared to Shakespeare in its cosmic ambitions. This encounter may have inspired him to revise and expand "Moby-Dick", which is dedicated to Hawthorne, "in token of my admiration for his genius".

The book was first published (in three volumes) as "The Whale" in London in October 1851, and under its definitive title in a single-volume edition in New York in November. The London publisher, Richard Bentley, censored or changed sensitive passages; Melville made revisions as well, including a last-minute change to the title for the New York edition. The whale, however, appears in the text of both editions as "Moby Dick", without the hyphen. Reviewers in Britain were largely favorable, though some objected that the tale seemed to be told by a narrator who perished with the ship, as the British edition lacked the Epilogue recounting Ishmael's survival. American reviewers were more hostile. About 3,200 copies of the book were sold during the author's life.

Ishmael travels in December from Manhattan Island to New Bedford, Massachusetts with plans to sign up for a whaling voyage. The inn where he arrives is overcrowded, so he must share a bed with the tattooed cannibal Polynesian Queequeg, a harpooneer whose father was king of the fictional island of Rokovoko. The next morning, Ishmael and Queequeg attend Father Mapple's sermon on Jonah, then head for Nantucket. Ishmael signs up with the Quaker ship-owners Bildad and Peleg for a voyage on their whaler "Pequod". Peleg describes Captain Ahab: "He's a grand, ungodly, god-like man" who nevertheless "has his humanities". They hire Queequeg the following morning. A man named Elijah prophesies a dire fate should Ishmael and Queequeg join Ahab. While provisions are loaded, shadowy figures board the ship. On a cold Christmas Day, the "Pequod" leaves the harbor.

Ishmael discusses cetology (the zoological classification and natural history of the whale), and describes the crew members. The chief mate is 30-year-old Starbuck, a Nantucket Quaker with a realist mentality, whose harpooneer is Queequeg; second mate is Stubb, from Cape Cod, happy-go-lucky and cheerful, whose harpooneer is Tashtego, a proud, pure-blooded Indian from Gay Head, and the third mate is Flask, also from Martha's Vineyard, short, stout, whose harpooneer is Daggoo, a tall African, now a resident of Nantucket.

When Ahab finally appears on the quarterdeck, he announces he is out for revenge on the white whale which took one leg from the knee down and left him with a prosthesis fashioned from a whale's jawbone. Ahab will give the first man to sight Moby Dick a doubloon, a gold coin, which he nails to the mast. Starbuck objects that he has not come for vengeance but for profit. Ahab's purpose exercises a mysterious spell on Ishmael: "Ahab's quenchless feud seemed mine". Instead of rounding Cape Horn, Ahab heads for the equatorial Pacific Ocean via southern Africa. One afternoon, as Ishmael and Queequeg are weaving a mat — "its warp seemed necessity, his hand free will, and Queequeg's sword chance" — Tashtego sights a sperm whale. Five previously unknown men appear on deck and are revealed to be a special crew selected by Ahab and explain the shadowy figures seen boarding the ship. Their leader, Fedallah, a Parsee, is Ahab's harpooneer. The pursuit is unsuccessful.
Southeast of the Cape of Good Hope, the "Pequod" makes the first of nine sea-encounters, or "gams", with other ships: Ahab hails the "Goney" (Albatross) to ask whether they have seen the White Whale, but the trumpet through which her captain tries to speak falls into the sea before he can answer. Ishmael explains that because of Ahab's absorption with Moby Dick, he sails on without the customary "gam", which defines as a "social meeting of two (or more) Whale-ships", in which the two captains remain on one ship and the chief mates on the other. In the second gam off the Cape of Good Hope, with the "Town-Ho", a Nantucket whaler, the concealed story of a "judgment of God" is revealed, but only to the crew: a defiant sailor who struck an oppressive officer is flogged, and when that officer led the chase for Moby Dick, he fell from the boat and was killed by the whale.

Ishmael digresses on pictures of whales, brit (microscopic sea creatures on which whales feed), squid and — after four boats lowered in vain because Daggoo mistook a giant squid for the white whale — whale-lines. The next day, in the Indian Ocean, Stubb kills a sperm whale, and that night Fleece, the "Pequod"s black cook, prepares him a rare whale steak. Fleece, at Stubb's request, delivers a sermon to the sharks that fight each other to feast on the whale's carcass, tied to the ship, saying that their nature is to be voracious, but they must overcome it. The whale is prepared, beheaded, and barrels of oil are tried out. Standing at the head of the whale, Ahab begs it to speak of the depths of the sea. The "Pequod" next encounters the "Jeroboam", which not only lost its chief mate to Moby Dick, but also is now plagued by an epidemic.

The whale carcass still lies in the water. Queequeg mounts it, tied to Ishmael's belt by a monkey-rope as if they were Siamese twins. Stubb and Flask kill a right whale whose head is fastened to a yardarm opposite the sperm whale's head. Ishmael compares the two heads in a philosophical way: the right whale is Lockean, stoic, and the sperm whale as Kantean, platonic. Tashtego cuts into the head of the sperm whale and retrieves buckets of spermaceti. He falls into the head, which in turn falls off the yardarm into the sea. Queequeg dives after him and frees his mate with his sword.

The "Pequod" next gams with the "Jungfrau" from Bremen. Both ships sight whales simultaneously, with the "Pequod" winning the contest. The three harpooneers dart their harpoons, and Flask delivers the mortal strike with a lance. The carcass sinks, and Queequeg barely manages to escape. The "Pequod"s next gam is with the French whaler "Bouton de Rose", whose crew is ignorant of the ambergris in the gut of the diseased whale in their possession. Stubb talks them out of it, but Ahab orders him away before he can recover more than a few handfuls. Days later, an encounter with a harpooned whale prompts Pip, a little black cabin-boy from Connecticut, to jump out of his whale boat. The whale must be cut loose, because the line has Pip so entangled in it. Furious, Stubb orders Pip to stay in the whale boat, but Pip later jumps again, and is left alone in the immense sea and has gone insane by the time he is picked up.

Cooled spermaceti congeals and must be squeezed back into liquid state; blubber is boiled in the try-pots on deck; the warm oil is decanted into casks, and then stowed in the ship. After the operation, the decks are scrubbed. The coin hammered to the main mast shows three Andes summits, one with a flame, one with a tower, and one a crowing cock. Ahab stops to look at the doubloon and interprets the coin as signs of his firmness, volcanic energy, and victory; Starbuck takes the high peaks as evidence of the Trinity; Stubb focuses on the zodiacal arch over the mountains; and Flask sees nothing of any symbolic value at all. The Manxman mutters in front of the mast, and Pip declines the verb "look".

The "Pequod" next gams with the "Samuel Enderby" of London, captained by Boomer, a down-to-earth fellow who lost his right arm to Moby Dick. Nevertheless, he carries no ill will toward the whale, which he regards not as malicious, but as awkward. Ahab puts an end to the gam by rushing back to his ship. The narrator now discusses the subjects of (1) whalers supply; (2) a glen in Tranque in the Arsacides islands full of carved whale bones, fossil whales, whale skeleton measurements; (3) the chance that the magnitude of the whale will diminish and that the leviathan might perish.

Leaving the "Samuel Enderby", Ahab wrenches his ivory leg and orders the carpenter to fashion him another. Starbuck informs Ahab of oil leakage in the hold. Reluctantly, Ahab orders the harpooneers to inspect the casks. Queequeg, sweating all day below decks, develops a chill and soon is almost mortally feverish. The carpenter makes a coffin for Queequeg, who fears an ordinary burial at sea. Queequeg tries it for size, with Pip sobbing and beating his tambourine, standing by and calling himself a coward while he praises Queequeg for his gameness. Yet Queequeg suddenly rallies, briefly convalesces, and leaps up, back in good health. Henceforth, he uses his coffin for a spare seachest, which is later caulked and pitched to replace the "Pequod"s life buoy.

The "Pequod" sails northeast toward Formosa and into the Pacific Ocean. Ahab, with one nostril, smells the musk from the Bashee isles, and with the other, the salt of the waters where Moby Dick swims. Ahab goes to Perth, the blacksmith, with a bag of racehorse shoenail stubs to be forged into the shank of a special harpoon, and with his razors for Perth to melt and fashion into a harpoon barb. Ahab tempers the barb in blood from Queequeg, Tashtego, and Daggoo.

The "Pequod" gams next with the "Bachelor", a Nantucket ship heading home full of sperm oil. Every now and then, the "Pequod" lowers for whales with success. On one of those nights in the whaleboat, Fedallah prophesies that neither hearse nor coffin can be Ahab's, that before he dies, Ahab must see two hearses — one not made by mortal hands and the other made of American wood — that Fedallah will precede his captain in death, and finally that only hemp can kill Ahab.

As the "Pequod" approaches the Equator, Ahab scolds his quadrant for telling him only where he is and not where he will be. He dashes it to the deck. That evening, an impressive typhoon attacks the ship. Lightning strikes the mast, setting the doubloon and Ahab's harpoon aglow. Ahab delivers a speech on the spirit of fire, seeing the lightning as a portent of Moby Dick. Starbuck sees the lightning as a warning, and feels tempted to shoot the sleeping Ahab with a musket. Next morning, when he finds that the lightning disoriented the compass, Ahab makes a new one out of a lance, a maul, and a sailmaker's needle. He orders the log be heaved, but the weathered line snaps, leaving the ship with no way to fix its location.
The "Pequod" is now heading southeast toward Moby Dick. A man falls overboard from the mast. The life buoy is thrown, but both sink. Now Queequeg proposes that his superfluous coffin be used as a new life buoy. Starbuck orders the carpenter to seal and waterproof it. Next morning, the ship meets in another truncated gam with the "Rachel", commanded by Captain Gardiner from Nantucket. The "Rachel" is seeking survivors from one of her whaleboats which had gone after Moby Dick. Among the missing is Gardiner's young son. Ahab refuses to join the search.

Twenty-four hours a day, Ahab now stands and walks the deck, while Fedallah shadows him. Suddenly, a sea hawk grabs Ahab's slouched hat and flies off with it. Next, the "Pequod", in a ninth and final gam, meets the "Delight", badly damaged and with five of her crew left dead by Moby Dick. Her captain shouts that the harpoon which can kill the white whale has yet to be forged, but Ahab flourishes his special lance and once more orders the ship forward. Ahab shares a moment of contemplation with Starbuck. Ahab speaks about his wife and child, calls himself a fool for spending 40 years on whaling, and claims he can see his own child in Starbuck's eye. Starbuck tries to persuade Ahab to return to Nantucket to meet both their families, but Ahab simply crosses the deck and stands near Fedallah.

On the first day of the chase, Ahab smells the whale, climbs the mast, and sights Moby Dick. He claims the doubloon for himself, and orders all boats to lower except for Starbuck's. The whale bites Ahab's boat in two, tosses the captain out of it, and scatters the crew. On the second day of the chase, Ahab leaves Starbuck in charge of the "Pequod". Moby Dick smashes the three boats that seek him into splinters and tangles their lines. Ahab is rescued, but his ivory leg and Fedallah are lost. Starbuck begs Ahab to desist, but Ahab vows to slay the white whale, even if he would have to dive through the globe itself to get his revenge.

On the third day of the chase, Ahab sights Moby Dick at noon, and sharks appear, as well. Ahab lowers his boat for a final time, leaving Starbuck again on board. Moby Dick breaches and destroys two boats. Fedallah's corpse, still entangled in the fouled lines, is lashed to the whale's back, so Moby Dick turns out to be the hearse Fedallah prophesied.

"Possessed by all the fallen angels", Ahab plants his harpoon in the whale's flank. Moby Dick smites the whaleboat, tossing its men into the sea. Only Ishmael is unable to return to the boat. He is left behind in the sea, and so is the only crewman of the "Pequod" to survive the final encounter. The whale now fatally attacks the "Pequod". Ahab then realizes that the destroyed ship is the hearse made of American wood in Fedallah's prophecy.

The whale returns to Ahab, who stabs at him again. As he does so, the line gets tangled, and Ahab bends over to free it. In doing so the line loops around Ahab's neck, and as the stricken whale swims away, the captain is drawn with him out of sight. Queequeg's coffin comes to the surface, the only thing to escape the vortex when "Pequod" sank. For a day and a night, Ishmael floats on it, until the "Rachel", still looking for its lost seamen, rescues him.

Ishmael is the narrator, shaping his story with use of many different genres including sermons, stage plays, soliloquies, and emblematical readings. Repeatedly, Ishmael refers to his writing of the book: "But how can I hope to explain myself here; and yet, in some dim, random way, explain myself I must, else all these chapters might be naught." Scholar John Bryant calls him the novel's "central consciousness and narrative voice." Walter Bezanson first distinguishes Ishmael as narrator from Ishmael as character, whom he calls "forecastle Ishmael", the younger Ishmael of some years ago. Narrator Ishmael, then, is "merely young Ishmael grown older." A second distinction avoids confusion of either of both Ishmaels with the author Herman Melville. Bezanson warns readers to "resist any one-to-one equation of Melville and Ishmael."

According to critic Walter Bezanson, the chapter structure can be divided into "chapter sequences", "chapter clusters", and "balancing chapters". The simplest sequences are of narrative progression, then sequences of theme such as the three chapters on whale painting, and sequences of structural similarity, such as the five dramatic chapters beginning with "The Quarter-Deck" or the four chapters beginning with "The Candles". Chapter clusters are the chapters on the significance of the colour white, and those on the meaning of fire. Balancing chapters are chapters of opposites, such as "Loomings" versus the "Epilogue," or similars, such as "The Quarter-Deck" and "The Candles".

Scholar Lawrence Buell describes the arrangement of the non-narrative chapters as structured around three patterns: first, the nine meetings of the "Pequod" with ships that have encountered Moby Dick. Each has been more and more severely damaged, foreshadowing the "Pequod"s own fate. Second, the increasingly impressive encounters with whales. In the early encounters, the whaleboats hardly make contact; later there are false alarms and routine chases; finally, the massive assembling of whales at the edges of the China Sea in "The Grand Armada". A typhoon near Japan sets the stage for Ahab's confrontation with Moby Dick.

The third pattern is the cetological documentation, so lavish that it can be divided into two subpatterns. These chapters start with the ancient history of whaling and a bibliographical classification of whales, getting closer with second-hand stories of the evil of whales in general and of Moby Dick in particular, a chronologically ordered commentary on pictures of whales. The climax to this section is chapter 57, "Of whales in paint etc.", which begins with the humble (a beggar in London) and ends with the sublime (the constellation Cetus). The next chapter ("Brit"), thus the other half of this pattern, begins with the book's first description of live whales, and next the anatomy of the sperm whale is studied, more or less from front to rear and from outer to inner parts, all the way down to the skeleton. Two concluding chapters set forth the whale's evolution as a species and claim its eternal nature.

Some "ten or more" of the chapters on whale killings, beginning at two-fifths of the book, are developed enough to be called "events". As Bezanson writes, "in each case a killing provokes either a chapter sequence or a chapter cluster of cetological lore growing out of the circumstance of the particular killing," thus these killings are "structural occasions for ordering the whaling essays and sermons".

Buell observes that the "narrative architecture" is an "idiosyncratic variant of the bipolar observer/hero narrative", that is, the novel is structured around the two main characters, Ahab and Ishmael, who are intertwined and contrasted with each other, with Ishmael the observer and narrator. As the story of Ishmael, remarks Robert Milder, it is a "narrative of education".

Bryant and Springer find that the book is structured around the two consciousnesses of Ahab and Ishmael, with Ahab as a force of linearity and Ishmael a force of digression. While both have an angry sense of being orphaned, they try to come to terms with this hole in their beings in different ways: Ahab with violence, Ishmael with meditation. And while the plot in "Moby-Dick" may be driven by Ahab's anger, Ishmael's desire to get a hold of the "ungraspable" accounts for the novel's lyricism. Buell sees a double quest in the book: Ahab's is to hunt Moby Dick, Ishmael's is "to understand what to make of both whale and hunt".

One of the most distinctive features of the book is the variety of genres. Bezanson mentions sermons, dreams, travel account, autobiography, Elizabethan plays, and epic poetry. He calls Ishmael's explanatory footnotes to establish the documentary genre "a Nabokovian touch".

A significant structural device is the series of nine meetings (gams) between the "Pequod" and other ships. These meetings are important in three ways. First, their placement in the narrative. The initial two meetings and the last two are both close to each other. The central group of five gams are separated by about 12 chapters, more or less. This pattern provides a structural element, remarks Bezanson, as if the encounters were "bones to the book's flesh". Second, Ahab's developing responses to the meetings plot the "rising curve of his passion" and of his monomania. Third, in contrast to Ahab, Ishmael interprets the significance of each ship individually: "each ship is a scroll which the narrator unrolls and reads."

Bezanson sees no single way to account for the meaning of all of these ships. Instead, they may be interpreted as "a group of metaphysical parables, a series of biblical analogues, a masque of the situation confronting man, a pageant of the humors within men, a parade of the nations, and so forth, as well as concrete and symbolic ways of thinking about the White Whale".

Scholar Nathalia Wright sees the meetings and the significance of the vessels along other lines. She singles out the four vessels which have already encountered Moby Dick. The first, the "Jeroboam", is named after the predecessor of the biblical King Ahab. Her "prophetic" fate is "a message of warning to all who follow, articulated by Gabriel and vindicated by the "Samuel Enderby", the "Rachel", the "Delight", and at last the "Pequod"". None of the other ships has been completely destroyed because none of their captains shared Ahab's monomania; the fate of the "Jeroboam" reinforces the structural parallel between Ahab and his biblical namesake: "Ahab did more to provoke the Lord God of Israel to anger than all the kings of Israel that were before him" (I Kings 16:33).

An early enthusiast for the Melville Revival, British author E. M. Forster, remarked in 1927: ""Moby-Dick" is full of meanings: its meaning is a different problem." Yet he saw as "the essential" in the book "its prophetic song", which flows "like an undercurrent" beneath the surface action and morality.

Biographer Laurie Robertson-Lorant sees epistemology as the book's theme. Ishmael's taxonomy of whales merely demonstrates "the limitations of scientific knowledge and the impossibility of achieving certainty". She also contrasts Ishmael and Ahab's attitudes toward life, with Ishmael's open-minded and meditative, "polypositional stance" as antithetical to Ahab's monomania, adhering to dogmatic rigidity.

Melville biographer Andrew Delbanco cites race as an example of this search for truth beneath surface differences. All races are represented among the crew members of the "Pequod". Although Ishmael initially is afraid of Queequeg as a tattooed cannibal, he soon decides, "Better sleep with a sober cannibal than a drunken Christian." While it may be rare for a mid-19th century American book to feature black characters in a nonslavery context, slavery is frequently mentioned. The theme of race is primarily carried by Pip, the diminutive black cabin boy. When Pip has almost drowned, Ahab, genuinely touched by Pip's suffering, questions him gently, Pip "can only parrot the language of an advertisement for the return of a fugitive slave: 'Pip! Reward for Pip!'".

Editors Bryant and Springer suggest perception is a central theme, the difficulty of seeing and understanding, which makes deep reality hard to discover and truth hard to pin down. Ahab explains that, like all things, the evil whale wears a disguise: "All visible objects, man, are but pasteboard masks" — and Ahab is determined to "strike through the mask! How can the prisoner reach outside, except by thrusting through the wall? To me, the white whale is that wall" (Ch. 36, "The Quarter-Deck"). This theme pervades the novel, perhaps never so emphatically as in "The Doubloon" (Ch. 99), where each crewmember perceives the coin in a way shaped by his own personality. Later, the American edition has Ahab "discover no sign" (Ch. 133) of the whale when he is staring into the deep. In fact, Moby Dick is then swimming up at him. In the British edition, Melville changed the word "discover" to "perceive", and with good reason, for "discovery" means finding what is already there, but "perceiving", or better still, perception, is "a matter of shaping what exists by the way in which we see it". The point is not that Ahab would discover the whale as an object, but that he would perceive it as a symbol of his making.

Yet Melville does not offer easy solutions. Ishmael and Queequeg's sensual friendship initiates a kind of racial harmony that is shattered when the crew's dancing erupts into racial conflict in "Midnight, Forecastle" (Ch. 40). Fifty chapters later, Pip suffers mental disintegration after he is reminded that as a slave he would be worth less money than a whale. Commodified and brutalized, "Pip becomes the ship's conscience". His views of property are another example of wrestling with moral choice. In Chapter 89, Ishmael expounds the concept of the fast-fish and the loose-fish, which gives right of ownership to those who take possession of an abandoned fish or ship, and observes that the British Empire took possession of American Indian lands in colonial times in just the way that whalers take possession of an unclaimed whale.

The novel has also been read as being critical of the contemporary literary and philosophical movement Transcendentalism, attacking the thought of leading Transcendentalist Ralph Waldo Emerson in particular. The life and death of Ahab has been read as an attack on Emerson's philosophy of self-reliance, for one, in its destructive potential and potential justification for egoism. Richard Chase writes that for Melville, 'Death–spiritual, emotional, physical–is the price of self-reliance when it is pushed to the point of solipsism, where the world has no existence apart from the all-sufficient self.' In that regard, Chase sees Melville's art as antithetical to that of Emerson's thought, in that Melville '[points] up the dangers of an exaggerated self-regard, rather than, as ... Emerson loved to do, [suggested] the vital possibilities of the self.' Newton Arvin further suggests that self-reliance was, for Melville, really the '[masquerade in kingly weeds of] a wild egoism, anarchic, irresponsible, and destructive.'

"Above all", say the scholars Bryant and Springer, "Moby-Dick" is language: "nautical, biblical, Homeric, Shakespearean, Miltonic, cetological, alliterative, fanciful, colloquial, archaic and unceasingly allusive". Melville stretches grammar, quotes well-known or obscure sources, or swings from calm prose to high rhetoric, technical exposition, seaman's slang, mystic speculation, or wild prophetic archaism. Melville coined words, critic Newton Arvin recognizes, as if the English vocabulary were too limited for the complex things he had to express. Perhaps the most striking example is the use of verbal nouns, mostly plural, such as "allurings", "coincidings", and "leewardings". Equally abundant are unfamiliar adjectives and adverbs, including participial adjectives such as "officered", "omnitooled", and "uncatastrophied"; participial adverbs such as "intermixingly", "postponedly", and "uninterpenetratingly"; rarities such as the adjectives "unsmoothable", "spermy", and "leviathanic", and adverbs such as "sultanically", "Spanishly", and "Venetianly"; and adjectival compounds ranging from odd to magnificent, such as "the "message-carrying" air", "the "circus-running" sun", and ""teeth-tiered" sharks". It is rarer for Melville to create his own verbs from nouns, but he does this with what Arvin calls "irresistible effect", such as in "who didst "thunder" him higher than a throne", and "my fingers ... began ... to "serpentine" and "spiralize"". For Arvin, the essence of the writing style of "Moby-Dick" lies in

Later critics have expanded Arvin's categories. The superabundant vocabulary can be broken down into strategies used individually and in combination. First, the original modification of words as "Leviathanism" and the exaggerated repetition of modified words, as in the series "pitiable", "pity", "pitied" and "piteous" (Ch. 81, "The Pequod Meets the Virgin"). Second, the use of existing words in new ways, as when the whale "heaps" and "tasks". Third, words lifted from specialized fields, as "fossiliferous". Fourth, the use of unusual adjective-noun combinations, as in "concentrating brow" and "immaculate manliness" (Ch. 26, "Knights and Squires"). Fifth, using the participial modifier to emphasize and to reinforce the already established expectations of the reader, as the words "preluding" and "foreshadowing" ("so still and subdued and yet somehow preluding was all the scene ..."; "In this foreshadowing interval ...").

Other characteristic stylistic elements are the echoes and overtones, both imitation of distinct styles and habitual use of sources to shape his own work. His three most important sources, in order, are the Bible, Shakespeare, and Milton.

The novel uses several levels of rhetoric. The simplest is "a relatively straightforward "expository" style", such as in the cetological chapters, though they are "rarely sustained, and serve chiefly as transitions" between more sophisticated levels. A second level is the ""poetic"", such as in Ahab's quarter-deck monologue, to the point that it can be set as blank verse. Set over a metrical pattern, the rhythms are "evenly controlled—too evenly perhaps for prose," Bezanson suggests. A third level is the "idiomatic", and just as the poetic it hardly is present in pure form. Examples of this are "the consistently excellent idiom" of Stubb, such as in the way he encourages the rowing crew in a rhythm of speech that suggests "the beat of the oars takes the place of the metronomic meter". The fourth and final level of rhetoric is the "composite", "a magnificent blending" of the first three and possible other elements:

The Nantucketer, he alone resides and riots on the sea; he alone, in Bible language, goes down to it in ships; to and fro ploughing it as his own special plantation. "There" is his home; "there" lies his business, which a Noah's flood would not interrupt, though it overwhelmed all the millions in China. He lives on the sea, as prairie cocks in the prairie; he hides among the waves, he climbs them as chamois hunters climb the Alps. For years he knows not the land; so that when he comes to it at last, it smells like another world, more strangely than the moon would to an Earthsman. With the landless gull, that at sunset folds her wings and is rocked to sleep between billows; so at nightfall, the Nantucketer, out of sight of land, furls his sails, and lays him to his rest, while under his very pillow rush herds of walruses and whales.
("Nantucket," Ch. 14).

Bezanson calls this chapter a comical "prose poem" that blends "high and low with a relaxed assurance". Similar passages include the "marvelous hymn to spiritual democracy" in the middle of "Knights and Squires".

The elaborate use of the Homeric simile may not have been learned from Homer himself, yet Matthiessen finds the writing "more consistently alive" on the Homeric than on the Shakespearean level, especially during the final chase the "controlled accumulation" of such similes emphasizes Ahab's hubris through a succession of land-images, for instance: "The ship tore on; leaving such a furrow in the sea as when a cannon-ball, missent, becomes a ploughshare and turns up the level field" ("The Chase – Second Day," Ch. 134). A paragraph-long simile describes how the 30 men of the crew became a single unit:

For as the one ship that held them all; though it was put together of all contrasting things—oak, and maple, and pine wood; iron, and pitch, and hemp—yet all these ran into each other in the one concrete hull, which shot on its way, both balanced and directed by the long central keel; even so, all the individualities of the crew, this man's valor, that man's fear; guilt and guiltiness, all varieties were welded into oneness, and were all directed to that fatal goal which Ahab their one lord and keel did point to.
("The Chase – Second Day," Ch. 134).

The final phrase fuses the two halves of the comparison; the men become identical with the ship, which follows Ahab's direction. The concentration only gives way to more imagery, with the "mastheads, like the tops of tall palms, were outspreadingly tufted with arms and legs". All these images contribute their "startling energy" to the advance of the narrative. When the boats are lowered, the imagery serves to dwarf everything but Ahab's will in the presence of Moby Dick. These similes, with their astonishing "imaginative abundance," are not only create dramatic movement, Matthiessen observes: "They are no less notable for breadth; and the more sustained among them, for an heroic dignity."

F. O. Matthiessen in 1941 declared that Melville's "possession by Shakespeare went far beyond all other influences" in that it made Melville discover his own full strength "through the challenge of the most abundant imagination in history". This insight was then reinforced by the study of Melville's annotatations in his reading copy of Shakespeare, which show that he immersed himself in Shakespeare when he was preparing for "Moby-Dick" , especially "King Lear" and "Macbeth". Reading Shakespeare, Matthiessen observes, was "a catalytic agent", one that transformed his writing "from limited reporting to the expression of profound natural forces". 

The creation of Ahab, Melville biographer Leon Howard discovered, followed an observation by Coleridge in his lecture on "Hamlet": "one of Shakespeare's modes of creating characters is to conceive any one intellectual or moral faculty in "morbid" excess, and then to place himself. ... thus "mutilated" or "diseased", under given circumstances". Coleridge's vocabulary is echoed in some phrases that describe Ahab. Ahab seemed to have "what seems a half-wilful "over-ruling morbidness" at the bottom of his nature", and "all men tragically great", Melville added, "are made so through a certain "morbidness"; "all mortal greatness is but "disease"". In addition to this, in Howard's view, the self-references of Ishmael as a "tragic dramatist", and his defense of his choice of a hero who lacked "all outward majestical trappings" is evidence that Melville "consciously thought of his protagonist as a tragic hero of the sort found in "Hamlet" and "King Lear"".

Matthiessen demonstrates the extent to which Melville was in full possession of his powers in the description of Ahab, which ends in language "that suggests Shakespeare's but is not an imitation of it: 'Oh, Ahab! what shall be grand in thee, it must needs be plucked from the skies and dived for in the deep, and featured in the unbodied air!' The imaginative richness of the final phrase seems particularly Shakespearean, "but its two key words appear only once each in the plays ... and to neither of these usages is Melville indebted for his fresh combination." Melville's assimilation of Shakespeare, Matthiessen concludes, gave "Moby-Dick" "a kind of diction that depended upon no source", and that could, as D.H. Lawrence put it, convey something "almost superhuman or inhuman, bigger than life". The prose is not based on anybody else's verse but on "a sense of speech rhythm".

Matthiessen finds debts to Shakespeare, whether hard or easy to recognize, on almost every page. He points out that the phrase "mere sounds, full of Leviathanism, but signifying nothing" at the end of "Cetology" (Ch.32) echo the famous phrase in "Macbeth": "Told by an idiot, full of sound and fury, Signifying nothing." Matthiessen shows that Ahab's first extended speech to the crew, in the "Quarter-Deck" (Ch.36), is "virtually blank verse, and can be printed as such":

But look ye, Starbuck, what is said in heat,
That thing unsays itself. There are men
From whom warm words are small indignity.
I mean not to incense thee. Let it go.
Look! see yonder Turkish cheeks of spotted tawn--
Living, breathing pictures painted by the sun.
The pagan leopards—the unrecking and
Unworshipping things, that live; and seek and give
No reason for the torrid life they feel!

In addition to this sense of rhythm, Matthiessen shows that Melville "now mastered Shakespeare's mature secret of how to make language itself dramatic". He had learned three essential things, Matthiessen sums up:

"Moby-Dick" draws on Melville's experience on the whaler "Acushnet", but is not autobiographical. On December 30, 1840, Melville signed on as a green hand for the maiden voyage of the "Acushnet", planned to last for 52 months. Its owner, Melvin O. Bradford, like Bildad, was a Quaker: on several instances when he signed documents, he erased the word "swear" and replaced it with "affirm". But the shareholders of the "Acushnet" were relatively wealthy, whereas the owners of the "Pequod" included poor widows and orphaned children. 

The model for the Whaleman's Chapel of chapter 7 is the Seamen's Bethel on Johnny Cake Hill. Melville attended a service there shortly before he shipped out on the "Acushnet", and he heard a sermon by Reverend Enoch Mudge, who is at least in part the inspiration for Father Mapple. Even the topic of Jonah and the Whale may be authentic, for Mudge contributed sermons on Jonah to "Sailor's Magazine" 

The crew was not as heterogenous or exotic as the crew of the "Pequod". Five were foreigners, four of them Portuguese, and the others were American either at birth or naturalized. Three black men were in the crew, two seamen and the cook. Fleece, the black cook of the "Pequod", was probably modeled on this Philadelphia-born William Maiden. A first mate, actually called Edward C. Starbuck was discharged at Tahiti under mysterious circumstances. The second mate, John Hall, is identified as Stubb in an annotation in the book's copy of crew member Henry Hubbard, who also identified the model for Pip: John Backus, a little black man added to the crew during the voyage. Hubbard witnessed Pip's fall into the water. 

Ahab seems to have had no model, though his death may have been based on an actual event. Melville was aboard "The Star" in May 1843 with two sailors from the "Nantucket" who could have told him that they had seen their second mate "taken out of a whaleboat by a foul line and drowned".

In addition to his own experience on the whaling ship "Acushnet", two actual events served as the genesis for Melville's tale. One was the sinking of the Nantucket ship "Essex" in 1820, after a sperm whale rammed her 2,000 miles (3,200 km) from the western coast of South America. First mate Owen Chase, one of eight survivors, recorded the events in his 1821 "Narrative of the Most Extraordinary and Distressing Shipwreck of the Whale-Ship Essex".

The other event was the alleged killing in the late 1830s of the albino sperm whale Mocha Dick, in the waters off the Chilean island of Mocha. Mocha Dick was rumored to have 20 or so harpoons in his back from other whalers, and appeared to attack ships with premeditated ferocity. One of his battles with a whaler served as subject for an article by explorer Jeremiah N. Reynolds in the May 1839 issue of "The Knickerbocker or New-York Monthly Magazine". Melville was familiar with the article, which described: Significantly, Reynolds writes a first-person narration that serves as a frame for the story of a whaling captain he meets. The captain resembles Ahab and suggests a similar symbolism and single-minded motivation in hunting this whale, in that when his crew first encounters Mocha Dick and cowers from him, the captain rallies them: 

Mocha Dick had over 100 encounters with whalers in the decades between 1810 and the 1830s. He was described as being gigantic and covered in barnacles. Although he was the most famous, Mocha Dick was not the only white whale in the sea, nor the only whale to attack hunters.

While an accidental collision with a sperm whale at night accounted for sinking of the "Union" in 1807, it was not until August 1851 that the whaler "Ann Alexander", while hunting in the Pacific off the Galápagos Islands, became the second vessel since the "Essex" to be attacked, holed, and sunk by a whale. Melville remarked, "Ye Gods! What a commentator is this "Ann Alexander" whale. What he has to say is short & pithy & very much to the point. I wonder if my evil art has raised this monster."

While Melville had already drawn on his different sailing experiences in his previous novels, such as "Mardi", he had never focused specifically on whaling. The 18 months he spent as an ordinary seaman aboard the whaler "Acushnet" in 1841–42, and one incident in particular, now served as inspiration. During a mid-ocean "gam" (rendezvous at sea between ships), he met Chase's son William, who lent him his father's book. Melville later wrote: 

The book was out of print, and rare. Melville let his interest in the book be known to his father-in-law, Lemuel Shaw, whose friend in Nantucket procured an imperfect but clean copy which Shaw gave to Melville in April 1851. Melville read this copy avidly, made copious notes in it, and had it bound, keeping it in his library for the rest of his life. 

"Moby-Dick" contains large sections—most of them narrated by Ishmael—that seemingly have nothing to do with the plot, but describe aspects of the whaling business. Although a successful earlier novel about Nantucket whalers had been written, "Miriam Coffin or The Whale-Fisherman" (1835) by Joseph C. Hart, which is credited with influencing elements of Melville's work, most accounts of whaling tended to be sensational tales of bloody mutiny, and Melville believed that no book up to that time had portrayed the whaling industry in as fascinating or immediate a way as he had experienced it.

Melville found the bulk of his data on whales and whaling in five books, the most important of which was by the English ship's surgeon Thomas Beale, "Natural History of the Sperm Whale" (1839), a book of reputed authority which Melville bought on July 10, 1850. "In scale and complexity," scholar Steven Olsen-Smith writes, "the significance of [this source] to the composition of "Moby-Dick" surpasses that of any other source book from which Melville is known to have drawn." According to scholar Howard P. Vincent, the general influence of this source is to supply the arrangement of whaling data in chapter groupings. Melville followed Beale's grouping closely, yet adapted it to what art demanded, and he changed the original's prosaic phrases into graphic figures of speech. The second most important whaling book is Frederick Debell Bennett, "A Whaling Voyage Round the Globe, from the Year 1833 to 1836" (1840), from which Melville also took the chapter organization, but in a lesser degree than he learned from Beale.

The third book was the one Melville reviewed for the "Literary World" in 1847, J. Ross Browne's "Etchings of a Whaling Cruise" (1846), which may have given Melville the first thought for a whaling book, and in any case contains passages embarrassingly similar to passages in "Moby-Dick". The fourth book, Reverend Henry T. Cheever's "The Whale and His Captors" (1850), was used for two episodes in "Moby-Dick" but probably appeared too late in the writing of the novel to be of much more use. Melville did plunder a fifth book, William Scoresby, Jr., "An Account of the Arctic Regions with a History and Description of the Northern Whale Fishery" (1820), though—unlike the other four books—its subject is the Greenland whale rather than the sperm whale. Although the book became the standard whaling reference soon after publication, Melville satirized and parodied it on several occasions—for instance in the description of narwhales in the chapter "Cetology", where he called Scoresby "Charley Coffin" and gave his account "a humorous twist of fact": "Scoresby will help out Melville several times, and on each occasion Melville will satirize him under a pseudonym." Vincent suggests several reasons for Melville's attitude towards Scoresby, including his dryness and abundance of irrelevant data, but the major reason seems to have been that the Greenland whale was the sperm whale's closest competitor for the public's attention, so Melville felt obliged to dismiss anything dealing with it.

Scholars have concluded that Melville composed "Moby-Dick" in two or even three stages. Reasoning from biographical evidence, analysis of the functions of characters, and a series of unexplained but perhaps meaningful inconsistencies in the final version, they hypothesize that reading Shakespeare and his new friendship with Hawthorne, in the words of Lawrence Buell, inspired Melville to rewrite a "relatively straightforward" whaling adventure into "an epic of cosmic encyclopedic proportions". 

The earliest surviving mention of what became "Moby-Dick" is a letter Melville wrote to Richard Henry Dana, Jr. on May 1, 1850:

Bezanson objects that the letter contains too many ambiguities to assume "that Dana's 'suggestion' would obviously be that Melville do for whaling what he had done for life on a man-of-war in "White-Jacket"". Dana had experienced how incomparable Melville was in dramatic storytelling when he met him in Boston, so perhaps "his 'suggestion' was that Melville do a book that captured that gift". And the long sentence in the middle of the above quotation simply acknowledges that Melville is struggling with the problem, not of choosing between fact and fancy but of how to interrelate them. The most positive statements are that it will be a strange sort of a book and that Melville means to give the truth of the thing, but what thing exactly is not clear.

Melville may have found the plot before writing or developed it after the writing process was underway. Considering his elaborate use of sources, "it is safe to say" that they helped him shape the narrative, its plot included. Scholars John Bryant and Haskell Springer cite the development of the character Ishmael as another factor which prolonged Melville's process of composition and which can be deduced from the structure of the final version of the book. Ishmael, in the early chapters, is simply the narrator, just as the narrators in Melville's earlier sea adventures had been, but in later chapters becomes a mystical stage manager who is central to the tragedy.

Less than two months after mentioning the project to Dana, Melville reported in a letter of June 27 to Richard Bentley, his English publisher:

Nathaniel Hawthorne and his family had moved to a small red farmhouse near Lenox, Massachusetts, at the end of March 1850. He became friends with Oliver Wendell Holmes Sr. and Melville beginning on August 5, 1850, when the authors met at a picnic hosted by a mutual friend. Melville wrote an unsigned review of Hawthorne's short story collection "Mosses from an Old Manse" titled "Hawthorne and His Mosses", which appeared in "The Literary World" on August 17 and 24. Bezanson finds the essay "so deeply related to Melville's imaginative and intellectual world while writing "Moby-Dick"" that it could be regarded as a virtual preface and should be "everybody's prime piece of contextual reading". In the essay, Melville compares Hawthorne to Shakespeare and Dante, and his "self-projection" is evident in the repeats of the word "genius", the more than two dozen references to Shakespeare, and in the insistence that Shakespeare's "unapproachability" is nonsense for an American.

The most intense work on the book was done during the winter of 1850–1851, when Melville had changed the noise of New York City for a farm in Pittsfield, Massachusetts. The move may well have delayed finishing the book. During these months, he wrote several excited letters to Hawthorne, including one of June 1851 in which he summarizes his career: "What I feel most moved to write, that is banned, — it will not pay. Yet, altogether, write the "other" way I cannot. So the product is a final hash, and all my books are botches."

This is the stubborn Melville who stood by "Mardi" and talked about his other, more commercial books with contempt. The letter also reveals how Melville experienced his development from his 25th year: "Three weeks have scarcely passed, at any time between then and now, that I have not unfolded within myself. But I feel that I am now come to the inmost leaf of the bulb, and that shortly the flower must fall to the mould."

Buell finds the evidence that Melville changed his ambitions during writing "on the whole convincing", since the impact of Shakespeare and Hawthorne was "surely monumental", but others challenge the theories of the composition in three ways. The first raises objections on the use of evidence and the evidence itself. Bryant finds "little concrete evidence, and nothing at all conclusive, to show that Melville radically altered the structure or conception of the book". and scholar Robert Milder sees "insufficient evidence and doubtful methodology" at work. A second type of objection is based on assumptions about Melville's intellectual development. Bryant and Springer object to the conclusion that Hawthorne inspired Melville to write Ahab's tragic obsession into the book; Melville already had experienced other encounters which could just as well have triggered his imagination, such as the Bible's Jonah and Job, Milton's Satan, Shakespeare's King Lear, Byron's heroes. Bezanson is also not convinced that before he met Hawthorne, "Melville was "not" ready for the kind of book "Moby-Dick" became", because in his letters from the time Melville denounces his last two "straight narratives, "Redburn" and "White-Jacket", as two books written just for the money, and he firmly stood by "Mardi" as the kind of book he believed in. His language is already "richly steeped in 17th-century mannerisms", characteristics of "Moby-Dick". A third type calls upon the literary nature of passages used as evidence. According to Milder, the cetological chapters cannot be leftovers from an earlier stage of composition and any theory that they are "will eventually founder on the stubborn meaningfulness of these chapters", because no scholar adhering to the theory has yet explained how these chapters "can bear intimate thematic relation to a symbolic story not yet conceived".

Buell finds that theories based on a combination of selected passages from letters and what are perceived as "loose ends" in the book not only "tend to dissolve into guesswork", but he also suggests that these so-called loose ends may be intended by the author: repeatedly the book mentions "the necessary unfinishedness of immense endeavors".

Melville first proposed the British publication in a June 27, 1850 letter to Richard Bentley, London publisher of his earlier works. Textual scholar G. Thomas Tanselle explains that for these earlier books, American proof sheets had been sent to the British publisher and that publication in the United States had been held off until the work had been set in type and published in England. This procedure was intended to provide the best (though still uncertain) claim for the UK copyright of an American work. In the case of "Moby-Dick", Melville had taken almost a year longer than promised, and could not rely on Harpers to prepare the proofs as they had done for the earlier books. Indeed, Harpers had denied him an advance, and since he was already in debt to them for almost $700, he was forced to borrow money and to arrange for the typesetting and plating himself. John Bryant suggests that he did so "to reduce the number of hands playing with his text".

The final stages of composition overlapped with the early stages of publication. In June 1851, Melville wrote to Hawthorne that he was in New York to "work and slave on my 'Whale' while it is driving through the press". By the end of the month, "wearied with the long delay of printers", Melville came back to finish work on the book in Pittsfield. Three weeks later, the typesetting was almost done, as he announced to Bentley on July 20: "I am now passing thro' the press, the closing sheets of my new work". While Melville was simultaneously writing and proofreading what had been set, the corrected proof would be plated, that is, the type fixed in final form. Since earlier chapters were already plated when he was revising the later ones, Melville must have "felt restricted in the kinds of revisions that were feasible".

On July 3, 1851, Bentley offered Melville £150 and "half profits", that is, half the profits that remained after the expenses of production and advertising. On July 20, Melville accepted, after which Bentley drew up a contract on August 13. Melville signed and returned the contract in early September, and then went to New York with the proof sheets, made from the finished plates, which he sent to London by his brother Allan on September 10. For over a month, these proofs had been in Melville's possession, and because the book would be set anew in London he could devote all his time to correcting and revising them. He still had no American publisher, so the usual hurry about getting the British publication to precede the American was not present. Only on September 12 was the Harper publishing contract signed. Bentley received the proof sheets with Melville's corrections and revisions marked on them on September 24. He published the book less than four weeks later.

In the October 1851 issue of "Harper's New Monthly Magazine" "The Town Ho's Story" was published, with a footnote reading: "From 'The Whale'. The title of a new work by Mr. Melville, in the press of Harper and Brothers, and now publishing in London by Mr. Bentley."

On October 18, the British edition, "The Whale", was published in a printing of only 500 copies, fewer than Melville's previous books. Their slow sales had convinced Bentley that a smaller number was more realistic. The London "Morning Herald" on October 20 printed the earliest known review. On November 14, the American edition, "Moby-Dick", was published and the same day reviewed in both the Albany "Argus" and the "Morning Courier and New-York Enquirer". On November 19, Washington received the copy to be deposited for copyright purposes. The first American printing of 2,915 copies was almost the same as the first of "Mardi", but the first printing of Melville's other three Harper books had been a thousand copies more.

The British edition, set by Bentley's printers from the American page proofs with Melville's revisions and corrections, differs from the American edition in over 700 wordings and thousands of punctuation and spelling changes.

Excluding the preliminaries and the one extract, the three volumes of the British edition came to 927 pages and the single American volume to 635 pages. Accordingly, the dedication to Hawthorne in the American edition — "this book is inscribed to"— became "these volumes are inscribed to" in the British. The table of contents in the British edition generally follows the actual chapter titles in the American edition, but 19 titles in the American table of contents differ from the titles above the chapters themselves. This list was probably drawn up by Melville himself: the titles of chapters describing encounters of the "Pequod" with other ships had—apparently to stress the parallelisms between these chapters—been standardized to "The Pequod meets the ...," with the exception of the already published 'The Town-Ho's Story'.

For unknown reasons, the "Etymology" and "Extracts" were moved to the end of the third volume. An epigraph from "Paradise Lost", taken from the second of the two quotations from that work in the American edition, appears on the title page of each of the three British volumes. Melville's involvement with this rearrangement is not clear: if it was Bentley's gesture toward accommodating Melville, as Tanselle suggests, its selection put an emphasis on the quotation Melville might not have agreed with.

The largest of Melville's revisions is the addition to the British edition of a 139-word footnote in Chapter 87 explaining the word "gally". The edition also contains six short phrases and some 60 single words lacking in the American edition. In addition, about 35 changes produce genuine improvements, as opposed to mere corrections: "Melville may not have made every one of the changes in this category, but it seems certain that he was responsible for the great majority of them."

The British publisher hired one or more revisers who were, in the evaluation of scholar Steven Olsen-Smith, responsible for "unauthorized changes ranging from typographical errors and omissions to acts of outright censorship". According to biographer Robertson-Lorant, the result was that the British edition was "badly mutilated". The expurgations fall into four categories, ranked according to the apparent priorities of the censor:
These expurgations also meant that any corrections or revisions Melville had marked upon these passages are now lost.

The final difference in the material not already plated is that the "Epilogue", thus Ishmael's miraculous survival, is omitted from the British edition. Obviously, the epilogue was not an afterthought supplied too late for the edition, for it is referred to in "The Castaway": "in the sequel of the narrative, it will then be seen what like abandonment befell myself." Why the "Epilogue" is missing is unknown. Since nothing objectionable was in it, most likely it was somehow lost by Bentley's printer when the "Etymology" and "Extracts" were moved.

After the sheets had been sent, Melville changed the title. Probably late in September, Allan sent Bentley two pages of proof with a letter of which only a draft survives which informed him that Melville "has determined upon a new title & dedication—Enclosed you have proof of both—It is thought here that the new title will be a better "selling" title". After expressing his hope that Bentley would receive this change in time, Allan said that "Moby-Dick is a legitimate title for the book, being the name given to a particular whale who if I may so express myself is the hero of the volume". Biographer Hershel Parker suggests that the reason for the change was that Harper's had two years earlier published a book with a similar title, "The Whale and His Captors".

Changing the title was not a problem for the American edition, since the running heads throughout the book only showed the titles of the chapters, and the title page, which would include the publisher's name, could not be printed until a publisher was found. In October "Harper's New Monthly Magazine" printed chapter 54, "The Town-Ho's Story", with a footnote saying: "From "The Whale." The title of a new work by Mr. Melville". The one surviving leaf of proof, "a 'trial' page bearing the title 'The Whale' and the Harper imprint," shows that at this point, after the publisher had been found, the original title still stood. When Allan's letter arrived, no sooner than early October, Bentley had already announced "The Whale" in both the "Athenaem" and the "Spectator" of October 4 and 11. Probably to accommodate Melville, Bentley inserted a half-title page in the first volume only, which reads "The Whale; or, Moby Dick".

The British printing of 500 copies sold fewer than 300 within the first four months. In 1852, some remaining sheets were bound in a cheaper casing, and in 1853, enough sheets were still left to issue a cheap edition in one volume. Bentley recovered only half on the £150 he advanced Melville, whose share from actual sales would have been just £38, and he did not print a new edition. Harper's first printing was 2,915 copies, including the standard 125 review copies. The selling price was $1.50, about a fifth of the price of the British three-volume edition.

About 1,500 copies were sold within 11 days, and then sales slowed down to less than 300 the next year. After three years, the first edition was still available, almost 300 copies of which were lost when a fire broke out at the firm in December 1853. In 1855, a second printing of 250 copies was issued, in 1863, a third of 253 copies, and finally in 1871, a fourth printing of 277 copies, which sold so slowly that no new printing was ordered. "Moby-Dick" was out of print during the last four years of Melville's life, having sold 2,300 in its first year and a half and on average 27 copies a year for the next 34 years, totaling 3,215 copies.

Melville's earnings from the book add up to $1,260: the £150 advance from Bentley was equivalent to $703, and the American printings earned him $556, which was $100 less than he earned from any of his five previous books. Melville's widow received another $81 when the United States Book Company issued the book and sold almost 1,800 copies between 1892 and 1898.

The reception of "The Whale" in Britain and of "Moby-Dick" in the United States differed in two ways, according to Parker. First, British literary criticism was more sophisticated and developed than in the still-young republic, with British reviewing done by "cadres of brilliant literary people" who were "experienced critics and trenchant prose stylists", while the United States had only "a handful of reviewers" capable enough to be called critics, and American editors and reviewers habitually echoed British opinion. American reviewing was mostly delegated to "newspaper staffers" or else by "amateur contributors more noted for religious piety than critical acumen." Second, the differences between the two editions caused "two distinct critical receptions."
Twenty-one reviews appeared in London, and later one in Dublin. The British reviewers, according to Parker, mostly regarded "The Whale" as "a phenomenal literary work, a philosophical, metaphysical, and poetic romance". The "Morning Advertiser" for October 24 was in awe of Melville's learning, of his "dramatic ability for producing a prose poem", and of the whale adventures which were "powerful in their cumulated horrors." To its surprise, "John Bull" found "philosophy in whales" and "poetry in blubber", and concluded that few books that claimed to be either philosophical or literary works "contain as much true philosophy and as much genuine poetry as the tale of the "Pequod"s whaling expedition", making it a work "far beyond the level of an ordinary work of fiction". The "Morning Post" found it "one of the cleverest, wittiest, and most amusing of modern books", and predicted that it was a book "which will do great things for the literary reputation of its author".

Melville himself never saw these reviews, and Parker calls it a "bitter irony" that the reception overseas was "all he could possibly have hoped for, short of a few conspicuous proclamations that the distance between him and Shakespeare was by no means immeasurable."

One of the earliest reviews, by the extremely conservative critic Henry Chorley in the highly regarded London "Athenaeum", described it as 

According to the London "Literary Gazette and Journal of Science and Art" for December 6, 1851, "Mr. Melville cannot do without savages, so he makes half of his "dramatis personae" wild Indians, Malays, and other untamed humanities", who appeared in "an odd book, professing to be a novel; wantonly eccentric, outrageously bombastic; in places charmingly and vividly descriptive". Most critics regretted the extravagant digressions because they distracted from an otherwise interesting and even exciting narrative, but even critics who did not like the book as a whole praised Melville's originality of imagination and expression.

Because the English edition omitted the epilogue describing Ishmael's escape, British reviewers read a book with a first-person narrator who apparently did not survive. The reviewer of the "Literary Gazette" asked how Ishmael, "who appears to have been drowned with the rest, communicated his notes to Mr. Bentley". The reviewer in the "Spectator" objected that "nothing should be introduced into a novel which it is physically impossible for the writer to have known: thus, he must not describe the conversation of miners in a pit if they "all" perish." The "Dublin University Magazine" asked "how does it happen that the author is alive to tell the story?" A few other reviewers, who did not comment upon the apparent impossibility of Ishmael telling the story, pointed out violations of narrative conventions in other passages.

Other reviewers accepted the flaws they perceived. "John Bull" praised the author for making literature out of unlikely and even unattractive matter, and the "Morning Post" found that delight far outstripped the improbable character of events. Though some reviewers viewed the characters, especially Ahab, as exaggerated, others felt that it took an extraordinary character to undertake the battle with the white whale. Melville's style was often praised, although some found it excessive or too American.

Some sixty reviews appeared in America, the criterion for counting as a review being more than two lines of comment. Only a couple of reviewers expressed themselves early enough not to be influenced by news of the British reception. Though "Moby-Dick" did contain the "Epilogue" and so accounted for Ishmael's survival, the British reviews influenced the American reception. The earliest American review, in the Boston "Post" for November 20, quoted the London "Athenaeum"s scornful review, not realizing that some of the criticism of "The Whale" did not pertain to "Moby-Dick". This last point, and the authority and influence of British criticism in American reviewing, is clear from the review's opening: "We have read nearly one half of this book, and are satisfied that the London Athenaeum is right in calling it 'an ill-compounded mixture of romance and matter-of-fact'". Though the "Post" quoted the greater portion of the review, it omitted the condensed extract of Melville's prose the "Athenaeum" had included to give readers an example of it. The "Post" deemed the price of one dollar and fifty cents far too much: "'The Whale' is not worth the money asked for it, either as a literary work or as a mass of printed paper".

The New York "North American Miscellany" for December summarized the verdict in the "Athenaeum". The reviewer of the December New York "Eclectic Magazine" had actually read "Moby-Dick" in full, and was puzzled why the "Athenaeum" was so scornful of the ending. The attack on "The Whale" by the "Spectator" was reprinted in the December New York "International Magazine", which inaugurated the influence of another unfavorable review. Rounding off what American readers were told about the British reception, in January "Harper's Monthly Magazine" attempted some damage control, and wrote that the book had "excited a general interest" among the London magazines.

The most influential American review, ranked according to the number of references to it, appeared in the weekly magazine "Literary World", which had printed Melville's "Mosses" essay the preceding year. The author of the unsigned review in two installments, on November 15 and 22, was later identified as publisher Evert Duyckinck. The first half of the first installment was devoted to an event of remarkable coincidence: early in the month, between the publishing of the British and the American edition, a whale had sunk the New Bedford whaler "Ann Alexander" near Chile.

In the second installment, Duyckinck described "Moby-Dick" as three books rolled into one: he was pleased with the book as far as it was a thorough account of the sperm whale, less so with it as far as the adventures of the "Pequod" crew were considered, perceiving the characters as unrealistic and expressing inappropriate opinions on religions, and condemned the essayistic rhapsodizing and moralizing with what he thought was little respect of what "must be to the world the most sacred associations of life violated and defaced." The review prompted Hawthorne to take the "unusually aggressive step of reproving Duyckinck" by criticizing the review in a letter to Duyckinck of December 1:

What a book Melville has written! It gives me an idea of much greater power than his preceding ones. It hardly seemed to me that the review of it, in the Literary World, did justice to its best points.

The Transcendental socialist George Ripley published a review in the New York "Tribune" for November 22, in which he compared the book favorably to "Mardi", because the "occasional touches of the subtle mysticism" was not carried on to excess but kept within boundaries by the solid realism of the whaling context. Ripley was almost surely also the author of the review in "Harper's" for December, which saw in Ahab's quest the "slight framework" for something else: "Beneath the whole story, the subtle, imaginative reader may perhaps find a pregnant allegory, intended to illustrate the mystery of human life." Among the handful of other favorable reviews was one in the "Albion" on November 22 which saw the book as a blend of truth and satire.

Melville's friend Nathaniel Parker Willis, reviewing the book in November 29 "Home Journal", found it "a very racy, spirited, curious and entertaining book ... it enlists the curiosity, excites the sympathies, and often charms the fancy". In December 6 "Spirit of the Times", editor William T. Porter praised the book, and all of Melville's five earlier works, as the writings "of a man who is at once philosopher, painter, and poet". Some other, shorter reviews mixed their praise with genuine reservations about the "irreverence and profane jesting", as the New Haven "Daily Palladium" for November 17 phrased it. Many reviewers, Parker observes, had come to the conclusion that Melville was capable of producing enjoyable romances, but they could not see in him the author of great literature.

Within a year after Melville's death in 1891, "Moby-Dick", along with "Typee", "Omoo", and "Mardi", was reprinted by Harper & Brothers, giving it a chance to be rediscovered. However, only New York's literary underground showed interest, just enough to keep Melville's name circulating for the next 25 years in the capital of American publishing. During this time, a few critics were willing to devote time, space, and a modicum of praise to Melville and his works, or at least those that could still be easily obtained or remembered. Other works, especially the poetry, went largely forgotten.

In 1917, American author Carl Van Doren became the first of this period to proselytize about Melville's value in his 1921 study, "The American Novel", calling "Moby-Dick" a pinnacle of American Romanticism.

In his 1923 idiosyncratic but influential "Studies in Classic American Literature", novelist, poet, and short story writer D. H. Lawrence celebrated the originality and value of American authors, among them Melville. Perhaps surprisingly, Lawrence saw "Moby-Dick" as a work of the first order despite his using the expurgated original English edition which also lacked the epilogue.

The Modern Library brought out "Moby-Dick" in 1926 and the Lakeside Press in Chicago commissioned Rockwell Kent to design and illustrate a striking three-volume edition which appeared in 1930. Random House then issued a one-volume trade version of Kent's edition, which in 1943 they reprinted as a less expensive Modern Library Giant.

The novel has been adapted or represented in art, film, books, cartoons, television, and more than a dozen versions in comic-book format. The first adaptation was the 1926 silent movie "The Sea Beast", starring John Barrymore, in which Ahab returns to marry his fiancée after killing the whale. The most famous adaptation was the John Huston 1956 film produced from a screenplay by author Ray Bradbury. The long list of adaptations, as Bryant and Springer put it, demonstrates that "the iconic image of an angry embittered American slaying a mythic beast seemed to capture the popular imagination." They conclude that "different readers in different periods of popular culture have rewritten "Moby-Dick"" to make it a "true cultural icon". American artist David Klamen has cited the novel as an important influence on his dark, slow-to-disclose paintings, noting a passage in the book in which a mysterious, undecipherable painting in a bar is gradually revealed to depict a whale.

American author Ralph Ellison wrote a tribute to the book in the prologue of his 1952 novel "Invisible Man". The narrator remembers a moment of truth under the influence of marijuana and evokes a church service: "Brothers and sisters, my text this morning is the 'Blackness of Blackness.' And the congregation answers: 'That blackness is most black, brother, most black ... '" This scene, Ellison biographer Arnold Rampersad observes, "reprises a moment in the second chapter of "Moby-Dick"", where Ishmael wanders around New Bedford looking for a place to spend the night, and momentarily joins a congregation: "It was a negro church; and the preacher's text was about the blackness of darkness, and the weeping and wailing and teeth-gnashing there." According to Rampersad, it was Melville who "empowered Ellison to insist on a place in the American literary tradition" by his example of "representing the complexity of race and racism so acutely and generously in his text". Rampersad also believes Ellison's choice of a first-person narrator was inspired above all by "Moby-Dick", and the novel even has a similar opening sentence with the narrator introducing himself ("I am an invisible man"). The oration by Ellison's blind preacher Barbee resembles Father Mapple's sermon in that both prepare the reader for what is to come.

American songwriter Bob Dylan's Nobel Prize Acceptance Speech of 2017 cited "Moby-Dick" as one of the three books that influenced him most. Dylan's description ends with an acknowledgment: "That theme, and all that it implies, would work its way into more than a few of my songs."






</doc>
<doc id="19862" url="https://en.wikipedia.org/wiki?curid=19862" title="Underground">
Underground

Underground most commonly refers to:

Underground may also refer to:


















</doc>
<doc id="19863" url="https://en.wikipedia.org/wiki?curid=19863" title="Madeira River">
Madeira River

The Madeira River ( ) is a major waterway in South America. It is estimated to be in length, while the Madeira-Mamoré is estimated near or 3380 km in length depending on the measuring party and their methods. The Madeira is the biggest tributary of the Amazon, accounting for about 15% of the water in the basin. A map from Emanuel Bowen in 1747, held by the David Rumsey Map Collection, refers to the Madeira by the pre-colonial, indigenous name Cuyari: 
The River of Cuyari, called by the Portuguese Madeira or the Wood River, is formed by two great rivers, which join near its mouth. It was by this River, that the Nation of Topinambes passed into the River Amazon.
The mean inter-annual precipitations on the great basins vary from , the entire upper Madeira basin receiving . The greatest extremes of rainfall are between . At its head, the Madeira on its own is one of the largest rivers of the world, with a mean inter-annual discharge of , i.e., per year, approximately half the discharge of the Congo River. The mean inter-annual contribution of the Bolivian Andes is , i.e., per year, representing 25% of the discharge of the entire upper Madeira basin. On the further course towards the Amazon, the mean discharge of the Madeira increases up to .

Between Guajará-Mirim and the falls of Teotônio, the Madeira receives the drainage of the north-eastern slopes of the Andes from Santa Cruz de la Sierra to Cuzco, the whole of the south-western slope of Brazilian Mato Grosso and the northern slope of the Chiquitos sierras. In total, the catchment area is , almost equal in area to France and Spain combined. The waters flow into the Madeira from many large rivers, the principal of which, (from east to west), are the Guaporé or Itenez, the Baures and Blanco, the Itonama or San Miguel, the Mamoré, Beni, and Mayutata or Madre de Dios, all of which are reinforced by numerous secondary but powerful affluents. The climate of the upper catchment area varies from humid in the western edge with the origin of the river's main stem by volume (Río Madre de Dios, Río Beni) to semi arid in the southernmost part with the andine headwaters of the main stem by length (Río Caine, Río Rocha, Río Grande, Mamoré).

All of the upper branches of the river Madeira find their way to the falls across the open, almost level Mojos and Beni plains, of which are yearly flooded to an average depth of about for a period of from three to four months.

From its source in the confluence of Madre de Dios and Mamoré rivers and downstream to Abuna river the Madeira flows northward forming border between Bolivia and Brazil. Below its confluence with the latter tributary the flow of river changes to north-eastward direction, inland of Rondônia state of Brazil. The section of the river from the border to Porto Velho has notable drop of bed and was not navigable. Before 2012 the falls of Teotônio and of San Antonio existed here, they had higher flow rate and bigger level drop than more famous Boyoma Falls in Africa. Currently these rapids are submerged by the reservoir of Santo Antônio Dam. Below Porto Velho the Madeira meanders north-eastward through the Rondônia and Amazonas states of north west Brazil to its junction with the Amazon.

The Rio Madeira Sustainable Development Reserve, created in 2006, extends along the north bank of the river opposite the town of Novo Aripuanã.
At its mouth is Ilha Tupinambaranas, an extensive marshy region formed by the Madeira's distributaries.

The Madeira river rises more than 15 m (50 ft) during the rainy season, and ocean vessels may ascend it to the Falls of San Antonio, near Porto Velho, Brazil, above its mouth; but in the dry months, from June to November, it is only navigable for the same distance for craft drawing about of water. The Madeira-Mamoré Railroad runs in a loop around the unnavigable section to Guajará-Mirim on the Mamoré River, but is not functional, limiting shipping from the Atlantic at Porto Velho.

Today, it is also one of the Amazon Basin's most active waterways, and helps export close to four million tons of grains, which are loaded onto barges in Porto Velho, where both Cargill and Amaggi have loading facilities, and then shipped down the Madeira to the ports of Itacoatiara, near the mouth of the Madeira, just upstream on the left bank of the Amazon, or further down the Amazon, to the port of Santarem, at the mouth of the Tapajos River. From these two ports, Panamax type ships then export the grains - mainly soy and corn - to Europe and Asia. The Madeira waterway is also used to take fuel from the REMAN refinery (Petrobras) in Manaus, state capital of Amazonas, to Porto Velho, from where the states of Acre, Rondonia and parts of Mato Grosso are supplied mainly with gasoline (petrol) refined in Manaus. Cargo barges also use the Madeira on the route between Manaus and Porto Velho, which is along the Rio Negro, Amazon and Madeira, connecting Manaus' industrial district with the rest of Brazil, as Manaus is land-locked as far as logistics with the rest of the country are concerned, to bring in part of its raw materials, and export its produce to the major consumer centres of São Paulo and Rio de Janeiro. In 2012, the cargo amounted to 287,835 tons (both directions). The total tonnage shipped in 2012 on the Madeira accounted to 5,076,014.

Two large dams (see below) are under construction as part of the IIRSA regional integration project. The dam projects include large ship-locks capable of moving oceangoing vessels between the impounded reservoir and the downstream river. If the project is completed, "more than of waterways upstream from the dams in Brazil, Bolivia, and Peru would become navigable."

As typical of Amazonian rivers with the primary headwaters in the Andes, the Madeira River is turbid because of high sediment levels and it is whitewater, but some of its tributaries are clearwater (e.g., Aripuanã and Ji-Paraná) or blackwater (e.g., Manicoré).

The Bolivian river dolphin, variously considered a subspecies of the Amazon river dolphin or a separate species, is restricted to the upper Madeira River system. It has been estimated that there are more than 900 fish species in the Madeira River Basin, making it one of the freshwater systems in the world with the highest species richness.

The river is the fifth title of the 1993/1999 Philip Glass album Aguas da Amazonia.

In July 2007, plans have been approved by the Brazilian Government to construct two hydroelectric dams on the Madeira River, the Santo Antonio Dam near Porto Velho and the Jirau Dam about 100 km upstream. Both the Jirau and Santo Antonio dams are run-of-the-river projects that do not impound a large reservoir. Both dams also feature some environmental re-mediation efforts (such as fish ladders). As a consequence, it has been suggested that there has not been strong environmental opposition to the implementation of the Madeira river complex. Yet, if the fish ladders fail, "several valuable migratory fish species could suffer near-extinction as a result of the Madeira dams."

There are also concerns with deforestation and pressure on conservation areas and indigenous peoples' territories.
The Worldwatch institute has also criticized the fast-track approval process for "kindler, gentler dams with smaller reservoirs, designed to lessen social and environmental impacts", claiming that no project should "fast-track the licensing of new dams in Amazonia and allow projects to circumvent Brazil's tough environmental laws".



</doc>
<doc id="19864" url="https://en.wikipedia.org/wiki?curid=19864" title="Marañón River">
Marañón River

The Marañón River (, ) is the principal or mainstem source of the Amazon River, arising about 160 km to the northeast of Lima, Peru, and flowing through a deeply eroded Andean valley in a northwesterly direction, along the eastern base of the Cordillera of the Andes, as far as 5° 36′ southern latitude; from where it makes a great bend to the northeast, and cuts through the jungle Andes, until at the Pongo de Manseriche it flows into the flat Amazon basin. Although historically, the term "Marañon River" often was applied to the river all the way to the Atlantic Ocean, nowadays the Marañon River is generally thought to end at the confluence with the Ucayali River, after which most cartographers label the ensuing waterway the Amazon River.

The Marañón River is Peru's second longest river according to a 2005 statistical publication by the Instituto Nacional de Estadística e Informática.

The Marañon River was considered the source of the Amazon River starting with the 1707 map published by Padre Samuel Fritz, who indicated the great river “has its source on the southern shore of a lake that is called Lauricocha, near Huánuco." Fritz's reasoning was based on the fact that the Marañon River is the largest river branch one encounters when journeying upstream, something clearly evident on his map. For most of the 18th–19th centuries and into the 20th century, the Marañon River was generally considered the source of the Amazon. The Marañon River continues to claim the title of the "mainstem source" or "hydrological source" of the Amazon due to its contribution of the highest annual discharge rates.

The initial section of the Marañon contains a plethora of pongos, which are gorges in the jungle areas often with difficult rapids.
The Pongo de Manseriche is the final pongo on the Marañon located just before the river enters the flat Amazon basin. It is long and located between the confluence with the Rio Santiago, and the village of Borja. According to Captain Carbajal, who attempted ascent through the Pongo de Manseriche in the little steamer "Napo," in 1868, it is a vast rent in the Andes about 600 m (2000 ft) deep, narrowing in places to a width of only 30 m (100 ft), the precipices "seeming to close in at the top." Through this canyon the Marañón leaps along, at times, at the rate of 20 km/h (12 miles an hour). The pongo is known for wrecking many ships and many drownings.

Downstream of the Pongo de Manseriche the river often has islands, and there is usually nothing visible from its low banks but an immense forest-covered plain known as the "selva baja" ("low jungle") or Peruvian Amazonia. It is home to indigenous peoples such as the Urarina of the Chambira Basin , the Candoshi, and the Cocama-Cocamilla peoples.

A 552 km (343 mile) section of the Marañon River between Puente Copuma (Puchka confluence) and Corral Quemado is a class IV raftable river that is similar in many ways to the Grand Canyon of the United States and has been labeled the "Grand Canyon of the Amazon". Most of this section of the river is in a canyon that is up to 3000 m deep on both sides – over twice the depth of the Colorado's Grand Canyon. It is in dry desert-like terrain, much of which receives only 250–350 mm/rain per year (10–14"/year) with parts such as from Balsas to Jaén known as the hottest "infierno" area of Peru. The Marañon Grand Canyon section flows by the village of Calemar, where Peruvian writer Ciro Alegría based one of his most important novels: "La serpiente de oro" (1935).

One of the first popular descents of the Marañon River occurred In 1743 the Frenchman Charles Marie de La Condamine, who journeyed from the Chinchipe confluence all the way to the Atlantic Ocean. La Condamine did not descend the initial section of the Marañon by boat due to the plethora of pongos. From where he began his boating descent at the Chiriaco confluence, La Condamine still had to confront several pongos, including the Pongo de Huaracayo (or Guaracayo) and the Pongo de Manseriche.

The upper Marañon River has seen a number of descents. An attempt to paddle the river was made by Herbert Rittlinger in 1936. Sebastian Snow was an adventurer who journeyed down most of the river by trekking to Chiriaco River starting at the source near Lake Niñacocha. 

In 1976 and/or 1977 Laszlo Berty descended the section from Chagual to the jungle in raft. In 1977, a group composed of Tom Fisher, Steve Gaskill, Ellen Toll, and John Wasson spent over a month descending the river from Rondos to Nazareth with kayaks and a raft. In 2004, Tim Biggs and companions kayaked the entire river from the Nupe River to Iquitos. In 2012, Rocky Contos descended the entire river with various companions along the way.

The Marañon River may supply 20 hydroelectric mega-dams planned in the Andes, and it has been speculated that most of the power is destined for export to Brazil, Chile or Ecuador. Dam survey crews have drafted construction blueprints and the Environmental Impact Statements have been available since November 2009 for the Veracruz dam and since November 2011 the Chadin2 dam. 
A 2011 law stated "national demand" for the hydroelectric energy, while in 2013 Peruvian president Ollanta Humala explicitly made a connection with mining; the energy is to supply mines in the Cajamarca Region, La Libertad, Ancash Region and Piura Region. Construction of the 406 MW dam in Chaglla District started in 2012.

Opposition arose because the dams are expected to disrupt the major source of the Amazon, alter normal silt deposition into the lower river, damage habitat and migration patterns for fish and other aquatic life, displace thousands of residents along the river, and damage a national treasure "at least as nice as the Grand Canyon in the USA". Residents have launched efforts to halt the dams along the river with conservation groups such as SierraRios and International Rivers.

Potential ecological impacts of 151 new dams greater than 2 MW on five of the six major Andean tributaries of the Amazon over the next 20 years are estimated to be high, including the first major break in connectivity between Andean headwaters and lowland Amazon and deforestation due to infrastructure.


</doc>
<doc id="19865" url="https://en.wikipedia.org/wiki?curid=19865" title="March 6">
March 6





</doc>
<doc id="19866" url="https://en.wikipedia.org/wiki?curid=19866" title="Morona River">
Morona River

The Morona River is a tributary to the Marañón River, and flows parallel to the Pastaza River and immediately to the west of it, and is the last stream of any importance on the northern side of the Amazon before reaching the Pongo de Manseriche.

It is formed from a multitude of water-courses which descend the slopes of the Ecuadorian Andes south of the gigantic volcano of Sangay; but it soon reaches the plain, which commences where it receives its Cusulima branch. The Morona is navigable for small craft for about 300 miles above its mouth, but it is extremely tortuous. Canoes may ascend many of its branches, especially the Cusuhma and the Miazal, the latter almost to the base of Sangay. The Morona has been the scene of many rude explorations, with the hope of finding it serviceable as a commercial route between the inter-Andean tableland of Ecuador and the Amazon river.


</doc>
<doc id="19867" url="https://en.wikipedia.org/wiki?curid=19867" title="Max Newman">
Max Newman

Maxwell Herman Alexander Newman, FRS, (7 February 1897 – 22 February 1984), generally known as Max Newman, was a British mathematician and codebreaker. His work in World War II led to the construction of Colossus, the world's first operational, programmable electronic computer, and he established the Royal Society Computing Machine Laboratory at the University of Manchester, which produced the world's first working, electronic stored-program electronic computer in 1948, the Manchester Baby.

Max Newman was born Maxwell Herman Alexander Neumann in Chelsea, London, England, to a Jewish family, on 7 February 1897. His father was Herman Alexander Neumann, originally from the German city of Bromberg (now in Poland) who had emigrated with his family to London at the age of 15. Herman worked as a secretary in a company, and married Sarah Ann (Pike), an English schoolteacher, in 1896.

The family moved to Dulwich in 1903, and Newman attended Goodrich Road school, then City of London School from 1908. At school, he excelled in classics and in mathematics. He played chess and the piano well.

Newman won a scholarship to study mathematics at St John's College, Cambridge in 1915, and in 1916 gained a First in Part I of the Cambridge Mathematical Tripos.

His studies were interrupted by World War I. His father was interned as an enemy alien after the start of the war in 1914, and upon his release he returned to Germany. In 1916, Herman changed his name by deed poll to the anglicised "Newman" and Sarah did likewise in 1920. In January 1917 Newman took up a teaching post at Archbishop Holgate's Grammar School in York, leaving in April 1918. He spent some months in the Royal Army Pay Corps, and then taught at Chigwell School for six months in 1919 before returning to Cambridge. He was called up for military service in February 1918, but claimed conscientious objection due to his beliefs and his father's country of origin, and thereby avoided any direct role in the fighting.

He resumed his interrupted studies in October 1919, and graduated in 1921 as a Wrangler (equivalent to a First) in Part II of the Mathematical Tripos, and gained distinction in Schedule B (the equivalent of Part III). His dissertation considered the use of "symbolic machines" in physics, foreshadowing his later interest in computing machines.

On 5 November 1923 he was elected a Fellow of St John's. He worked on the foundations of combinatorial topology, and proposed that a notion of equivalence be defined using only three elementary "moves". Newman's definition avoided difficulties that had arisen from previous definitions of the concept. Publishing over twenty papers established his reputation as an "expert in modern topology". Newman wrote "Elements of the topology of plane sets of points", a work on general topology and undergraduate text. He also published papers on mathematical logic, and solved a special case of Hilbert's fifth problem.

He was appointed a lecturer in mathematics at Cambridge in 1927, where his 1935 lectures on the Foundations of Mathematics and Gödel's theorem inspired Alan Turing to embark on his pioneering work on the "Entscheidungsproblem" (decision problem) using a hypothetical computing machine. In spring 1936, Newman was presented by Turing with a draft of "On Computable Numbers with an Application to the Entscheidungsproblem". He realised the paper's importance and helped ensure swift publication. Newman subsequently arranged for Turing to visit Princeton where Alonzo Church was working on the same problem but using his Lambda calculus. During this period, Newman started to share Turing's dream of building a stored-program computing machine.

During this time at Cambridge, he developed close friendships with Patrick Blackett, Henry Whitehead and Lionel Penrose.

In September 1937, Newman and his family accepted an invitation to work for six months at Princeton. At Princeton, he worked on the Poincaré Conjecture and, in his final weeks there, presented a proof. However, in July 1938, after he returned to Cambridge, Newman discovered that his proof was fatally flawed.

In 1939, Newman was elected a Fellow of the Royal Society.

In December 1934 he married Lyn Lloyd Irvine, a writer, with Patrick Blackett as best man. They had two sons, Edward (born 1935) and William (born 1939).

The United Kingdom declared war on Germany on 3 September 1939. Newman's father was Jewish, which was of particular concern in the face of Nazi Germany, and Lyn, Edward and William were evacuated to America in July 1940 (where they spent three years before returning to England in October 1943). After Oswald Veblen—maintaining 'that every able-bodied man ought to be carrying a gun or hand-grenade and fight for his country'—opposed moves to bring him to Princeton, Newman remained at Cambridge and at first continued research and lecturing.

By spring 1942, he was considering involvement in war work. He made enquiries. After Patrick Blackett recommended him to the Director of Naval Intelligence, Newman was sounded out by Frank Adcock in connection with the Government Code and Cypher School at Bletchley Park.

Newman was cautious, concerned to ensure that the work would be sufficiently interesting and useful, and there was also the possibility that his father's German nationality would rule out any involvement in top-secret work. The potential issues were resolved by the summer, and he agreed to arrive at Bletchley Park on 31 August 1942. Newman was invited by F. L. (Peter) Lucas to work on Enigma but decided to join Tiltman's group working on Tunny.

He was assigned to the Research Section and set to work on a German teleprinter cipher known as "Tunny". He joined the "Testery" in October. Newman enjoyed the company but disliked the work and found that it was not suited to his talents. He persuaded his superiors that Tutte's method could be mechanised, and he was assigned to develop a suitable machine in December 1942. Shortly afterwards, Edward Travis (then operational head of Bletchley Park) asked Newman to lead research into mechanised codebreaking.

When the war ended, Newman was presented with a silver tankard inscribed 'To MHAN from the Newmanry, 1943-45'.

Construction started in January 1943, and the first prototype was delivered in June 1943. It was operated in Newman's new section, termed the "Newmanry", was housed initially in Hut 11 and initially staffed by himself, Donald Michie, two engineers, and 16 Wrens. The Wrens nicknamed the machine the "Heath Robinson", after the cartoonist of the same name who drew humorous drawings of absurd mechanical devices.

The Robinson machines were limited in speed and reliability. Tommy Flowers of the Post Office Research Station, Dollis Hill had experience of thermionic valves and built an electronic machine, the Colossus computer which was installed in the Newmanry. This was a great success and ten were in use by the end of the war.

In September 1945, Newman was appointed head of the Mathematics Department and to the Fielden Chair of Pure Mathematics at the University of Manchester.

Newman lost no time in establishing the renowned Royal Society Computing Machine Laboratory at the University. In February 1946, he wrote to John von Neumann, expressing his desire to build a computing machine. The Royal Society approved Newman's grant application in July 1946. Frederic Calland Williams and Thomas Kilburn, experts in electronic circuit design, were recruited from the Telecommunications Research Establishment. Kilburn and Williams built Baby, the world's first electronic stored-program digital computer based on Alan Turing's and John von Neumann's ideas.

After the Automatic Computing Engine suffered delays and set backs, Turing accepted Newman's offer and joined the Computer Machine Laboratory in May 1948 as Deputy Director (there being no Director). Turing joined Kilburn and Williams to work on Baby's successor, the Manchester Mark I. Collaboration between the University and Ferranti later produced the Ferranti Mark I, the first mass-produced computer to go on sale.

Newman retired in 1964 to live in Comberton, near Cambridge. After Lyn's death in 1973 he married Margaret Penrose, widow of his friend Lionel Penrose.

He continued to do research on combinatorial topology during a period when England was a major centre of activity notably Cambridge under the leadership of Christopher Zeeman. Newman made important contributions leading to an invitation to present his work at the 1962 International Congress of Mathematicians in Stockholm at the age of 65, and proved a Generalized Poincaré conjecture for topological manifolds in 1966.

At the age of 85, Newman began to suffer from Alzheimer's disease. He died in Cambridge two years later.


The Newman Building at Manchester was named in his honour. The building housed the pure mathematicians from the Victoria University of Manchester between moving out of the Mathematics Tower in 2004 and July 2007 when the School of Mathematics moved into its new Alan Turing Building, where a lecture room is named in his honour.

In 1946, Newman declined the offer of an OBE as he considered the offer derisory. Alan Turing had been appointed an OBE six months earlier and Newman felt that it was inadequate recognition of Turing's contribution to winning the war, referring to it as the "ludicrous treatment of Turing".




</doc>
<doc id="19868" url="https://en.wikipedia.org/wiki?curid=19868" title="Measure">
Measure

Measure may refer to:






</doc>
<doc id="19869" url="https://en.wikipedia.org/wiki?curid=19869" title="Massachusetts Bay Transportation Authority">
Massachusetts Bay Transportation Authority

The Massachusetts Bay Transportation Authority (abbreviated MBTA and known colloquially as "the T") is the public agency responsible for operating most public transportation services in Greater Boston, Massachusetts. Earlier modes of public transportation in Boston were independently owned and operated; many were first folded into a single agency with the formation of the Metropolitan Transit Authority (MTA) in 1947. The MTA was replaced in 1964 with the present-day MBTA, which was established as an individual department within the Commonwealth of Massachusetts before becoming a division of the Massachusetts Department of Transportation (MassDOT) in 2009.

The MBTA and Philadelphia's Southeastern Pennsylvania Transportation Authority (SEPTA) are the only US transit agencies that operate all five major types of terrestrial mass transit vehicles: light rail vehicles (the Ashmont–Mattapan High-Speed and Green Lines); heavy rail trains (the Blue, Orange, and Red Lines); regional rail trains (the Commuter Rail); electric trolleybuses (the Silver Line and several routes in the northern suburbs of Boston); and motor buses (MBTA bus). In 2016, the system averaged 1,277,200 passengers per weekday, of which heavy rail averaged 552,500 and the light-rail lines 226,500, making it the fourth-busiest subway system and the busiest light rail system in the United States.

The MBTA is the largest consumer of electricity in Massachusetts, and the second-largest land owner (after the Department of Conservation and Recreation).
In 2007, its CNG bus fleet was the largest consumer of alternative fuels in the state. The MBTA operates an independent law enforcement agency, the Massachusetts Bay Transportation Authority Police.

Mass transportation in Boston was provided by private companies, often granted charters by the state legislature for limited monopolies, with powers of eminent domain to establish a right-of-way, until the creation of the MTA in 1947. Development of mass transportation both followed and shaped economic and population patterns.

Shortly after the steam locomotive became practical for mass transportation, the private Boston and Lowell Railroad was chartered in 1830. The rail, which opened in 1835, connected Boston to Lowell, a major northerly mill town in northeast Massachusetts' Merrimack Valley, via one of the oldest railroads in North America. This marked the beginning of the development of American intercity railroads, which in Massachusetts would later become the MBTA Commuter Rail system and the Green Line D branch.

Starting with the opening of the Cambridge Railroad on March 26, 1856, a profusion of streetcar lines appeared in Boston under chartered companies. Despite the change of companies, Boston is the city with the oldest continuously working streetcar system in the world. Many of these companies consolidated, and animal-drawn vehicles were converted to electric propulsion.

Streetcar congestion in downtown Boston led to the subways in 1897 and elevated rail in 1901. The Tremont Street subway was the first rapid transit tunnel in the United States. Grade-separation added capacity and avoided delays caused by cross streets. The first elevated railway and the first rapid transit line in Boston were built three years before the first underground line of the New York City Subway, but 34 years after the first London Underground lines, and long after the first elevated railway in New York City; its Ninth Avenue El started operations on July 1, 1868 in Manhattan as an elevated cable car line.

Various extensions and branches were added at both ends, bypassing more surface tracks. As grade-separated lines were extended, street-running lines were cut back for faster downtown service. The last elevated heavy rail or "El" segments in Boston were at the extremities of the Orange Line: its northern end was relocated in 1975 from Everett to Malden, MA, and its southern end was relocated into the Southwest Corridor in 1987. However, the Green Line's Causeway Street Elevated remained in service until 2004, when it was relocated into a tunnel with an incline to reconnect to the Lechmere Viaduct. The Lechmere Viaduct and a short section of steel-framed elevated at its northern end remain in service, though the elevated section will be cut back slightly and connected to a northwards viaduct extension in 2017 as part of the Green Line Extension.

The old elevated railways proved to be an eyesore and required several sharp curves in Boston's twisty streets. The Atlantic Avenue Elevated was closed in 1938 amidst declining ridership and was demolished in 1942. As rail passenger service became increasingly unprofitable, largely due to rising automobile ownership, government takeover prevented abandonment and dismantlement. The MTA purchased and took over subway, elevated, streetcar, and bus operations from the Boston Elevated Railway in 1947.

In the 1950s, the MTA ran new subway extensions, while the last two streetcar lines running into the Pleasant Street Portal of the Tremont Street Subway were substituted with buses in 1953 and 1962. In 1958 the MTA purchased the Highland Branch from the Boston and Albany Railroad, reopening a year later as rapid transit line (now the Green Line D branch).

While the operations of the MTA were relatively stable by the early 1960s, the privately operated commuter rail lines were in freefall. The New Haven Railroad, New York Central Railroad, and Boston and Maine Railroad were all financially struggling; deferred maintenance was hurting the mainlines while most branch lines had been discontinued. The 1945 Coolidge Commission plan assumed that most of the commuter rail lines would be replaced by shorter rapid transit extensions, or simply feed into them at reduced service levels. Passenger service on the entire Old Colony Railroad system serving the southeastern part of the state was abandoned by the New Haven Railroad in 1959, triggering calls for state intervention. Between January 1963 and March 1964, the Mass Transportation Commission tested different fare and service levels on the B&M and New Haven systems. Determining that commuter rail operations were important but could not be financially self-sustaining, the MTC recommended an expansion of the MTA to commuter rail territory.

On August 3, 1964, the MBTA succeeded the MTA, with an enlarged service area intended to subsidize continued commuter rail operations. The original 14-municipality MTA district was expanded to 78 cities and towns. Several lines were briefly cut back while contracts with out-of-district towns were reached, but, except for the outer portions of the Central Mass Branch (cut back from Hudson to South Sudbury), West Medway Branch (cut back from West Medway to Millis), Blackstone Line (cut back from Blackstone to Franklin), and B&M New Hampshire services (cut back from Portsmouth to Newburyport), these cuts were temporary; however, service on three branch lines (all of them with only one round trip daily: one morning rush-hour trip in to Boston, and one evening rush-hour trip back out to the suburbs) was dropped permanently between 1965 and 1976 (the Millis (the new name of the truncated West Medway Branch) and Dedham Branches were discontinued in 1967, while the Central Mass Branch was abandoned in 1971). The MBTA bought the Penn Central (New York Central and New Haven) commuter rail lines in January 1973, Penn Central equipment in April 1976, and all B&M commuter assets in December 1976; these purchases served to make the system state-owned with the private railroads retained solely as operators. Only two branch lines were abandoned after 1976: service on the Lexington Branch (also with only one round trip daily) was discontinued in January 1977 after a snowstorm blocked the line, while the Lowell Line's full-service Woburn Branch was eliminated in January 1981 due to poor track conditions.

The MBTA assigned colors to its four rapid transit lines in 1965, and lettered the branches of the Green Line from north to south. Shortages of streetcars, among other factors, caused bustitution of rail service on two branches of the Green Line. The A branch ceased operating entirely in 1969 and was replaced by the 57 bus, while the E branch was truncated from Arborway to Heath Street in 1985, with the section between Heath Street and Arborway being replaced by the 39 bus.

The MBTA purchased bus routes in the outer suburbs to the north and south from the Eastern Massachusetts Street Railway in 1968. As with the commuter rail system, many of the outlying routes were dropped shortly before or after the takeover due to low ridership and high operating costs.

In the 1970s, the MBTA received a boost from the Boston Transportation Planning Review area-wide re-evaluation of the role of mass transit relative to highways. Producing a moratorium on highway construction inside Route 128, numerous mass transit lines were planned for expansion by the Voorhees-Skidmore, Owings and Merrill-ESL consulting team. The removal of elevated lines continued, and the closure of the Washington Street Elevated in 1987 brought the end of rapid transit service to the Roxbury neighborhood. Between 1971 and 1985, the Red Line was extended both north and south, providing not only additional subway system coverage, but also major parking structures at several of the terminal and intermediate stations.

In 1981, seventeen people and one corporation were indicted for their roles in a number of kickback schemes at the MBTA. Massachusetts Secretary of Transportation and MBTA Chairman Barry Locke was convicted of five counts of bribery and sentenced to 7 to 10 years in prison.

By 1999, the district was expanded further to 175 cities and towns, adding most that were served by or adjacent to commuter rail lines, though the MBTA did not assume responsibility for local service in those communities adjacent to or served by commuter rail.

A turning point in funding occurred in 2000. Prior to July 1, 2000, the MBTA was reimbursed by the Commonwealth of Massachusetts for all costs above revenue collected (net cost of service). Beginning on that date, the T was granted a dedicated revenue stream consisting of amounts assessed on served cities and towns, along with a dedicated 20% portion of the 5% state sales tax. The MBTA now had to live within this "forward funding" budget.

The Commonwealth assigned to the MBTA responsibility for increasing public transit to compensate for increased automobile pollution from the Big Dig. However, these projects have strained the MBTA's limited resources, since the Big Dig project did not include funding for these improvements. Since 1988, the MBTA has been the fastest expanding transit system in the country, even as Greater Boston has been one of the slowest growing metropolitan areas in the United States. The MBTA subsequently went into debt, and rates underwent an appreciable hike on January 1, 2007.

In 2006, the creation of the MetroWest Regional Transit Authority saw several towns subtract their MWRTA assessment from their MBTA assessment, though the amount of funding the MBTA received remained the same. The next year, the MBTA started commuter rail service to the Greenbush section of Scituate, the third branch of the Old Colony service. Rhode Island also paid for extensions of the Providence/Stoughton Line to T.F. Green Airport in 2010 and Wickford Junction in 2012. A new station on the Fairmount Line, the Talbot Avenue station, opened in November 2012.

On June 26, 2009, Governor Deval Patrick signed a law to place the MBTA along with other state transportation agencies within the administrative authority of the Massachusetts Department of Transportation (MassDOT), with the MBTA now part of the Mass Transit division (MassTrans).
The 2009 transportation law continued the MBTA corporate structure and changed the MBTA board membership to the five Governor-appointed members of the Mass DOT Board.

In February 2015, there was record breaking snowfall in Boston from the 2014–15 North American winter causing severe delays on all MBTA subway lines. and many long-term operational and financial problems with the entire MBTA system coming under greater public attention, Massachusetts Governor Charlie Baker indicated at the time that he was reluctant to discuss the financing issues but that he would "have more to say about that in a couple of weeks." Baker subsequently announced the formation of a special advisory panel to diagnose the MBTA's problems and write a report recommending proposals to address them. The special advisory panel formed the previous February released its report in April 2015. The next month, Baker appointed a new MassDOT Board of Directors and proposed a five-year winter resiliency plan with $83 million being spent to update infrastructure, purchase new equipment, and improve operations during severe weather. A new state law established the MBTA Fiscal and Management Control Board, effective July 17, 2015, with expanded powers to reform the agency during a five-year period. Its term was extended by another year in 2020.

Ground was broken for the $38.5 million renovation of Ruggles Station, in Roxbury, in August 2017. This was followed by the start of construction on the Green Line Extension the following June. In April 2018, the MBTA Silver Line began operating a route from Chelsea to South Station.

A Red Line derailment that resulted in train delays for several months brought more attention to capital maintenance problems at the T. After complaints from many riders and business groups, the governor proposed adding $50 million for an independent team to speed up inspections and capital projects, and general efforts to speed up existing capital spending from $1 billion to $1.5 billion per year. Replacement of the Red Line signal system were accelerated, including equipment that was damaged in the derailment. Baker proposed allocating to the MBTA $2.7 billion from the state's five-year transportation bond bill plus more money from the proposed multi-state Transportation Climate Initiative.

A December 2019 report by the MBTA's Fiscal and Management Control Board panel found "safety is not the priority at the T, but it must be." The report said "there is a general feeling that fiscal controls over the years may have gone too far, which coupled with staff cutting has resulted in the inability to accomplish required maintenance and inspections, or has hampered work keeping legacy system assets fully functional."

In February 2020, the COVID-19 pandemic began to impact Massachusetts. When the stay-at-home order was issued the following month, businesses closed or sent staff to work from home, and people were advised to avoid riding public transit unless necessary. At the lowest point, MBTA ridership dropped about 78% on buses, 92% on the subway, on 71% paratransit, and 97% on commuter rail. Bus and subway ran on a modified Saturday schedule; commuter rail was on a reduced schedule and ferries were shut down completely. To facilitate social distancing from drivers, buses started running fare-free with rear-door-only boarding, passengers were required to wear face masks (except small children and people with relevant medical conditions), and the agency began frequently sanitizing vehicles and stations. Driver availability was limited as some employees contracted the virus. The T received $827 million in federal aid for FY2020 and FY2021 to make up for increased costs and lost revenue.

In June, the MBTA announced that commuter rail tickets and passes valid as of March 10 would be valid for 90 days, starting on June 22. It also made various fare changes to encourage riders to shift from potentially crowded bus or subway, including discounted ten-ride tickets, half-price tickets for youth, and Zone 1A fares extended to Lynn and River Works stations.

"See also:" List of MBTA bus routes
The MBTA bus system is the nation's sixth largest by ridership and comprises over 150 routes across the Greater Boston area. The area served by the MBTA's bus operations is somewhat larger than its subway and light rail service area, but is significantly smaller than that served by the MBTA's commuter rail operation. At least eight other regional transit authorities also provide bus services within that larger area, these being the Rhode Island Public Transit Authority, Brockton Area Transit Authority, Cape Ann Transportation Authority, Greater Attleboro Taunton Regional Transit Authority, Lowell Regional Transit Authority, Merrimack Valley Regional Transit Authority, Montachusett Regional Transit Authority, and Worcester Regional Transit Authority. All of these authorities have their own fare structures and some subcontract operation to private bus companies. In many cases, their buses serve as feeders to the MBTA commuter rail.

Within MBTA's bus service area, transfers "from" the subway are free if using a CharlieCard (for local buses); transfers "to" the subway require paying the difference between bus and the higher subway fare (for local buses; if not using a CharlieCard, full subway fare must be paid in addition to full bus fare). Bus-to-bus transfers (for local buses) are free unless paying cash. Many of the outlying routes run express along major highways to downtown. The buses are colored yellow on maps and in station decor.

The Silver Line is the MBTA's first service designated as bus rapid transit (BRT), even though it lacks many of the characteristics of bus rapid transit. The first segment began operations in 2002, replacing the 49 bus, which in turn replaced the Washington Street Elevated section of the Orange Line. A full subway fare was charged, with free transfers to the subways downtown until January 1, 2007, when the fare system was revised to categorize the service as a "bus" for fare purposes. The "Washington Street" segment runs along various downtown streets, and mostly in dedicated bus lanes on Washington Street itself. Two Washington Street routes start at Dudley Station in Roxbury and one terminates at Downtown Crossing on Temple Place (SL5-the 2002 route) and one to South Station on Essex Street (SL4)

The "Waterfront" section opened at the end of 2004, and connects South Station to Logan Airport with route SL1 via Ted Williams Tunnel and South Boston (Design Center area) with route SL2. A new service to Chelsea opened April 21, 2018 via the same tunnel that SL1 uses and stops at the Airport Station of the Blue Line. The buses that run the Waterfront section are 2004-05 dual-mode buses, trackless trolley in the Silver Line tunnel and diesel outside. Service to Logan Airport began in June 2005. The Waterfront segment is classified as a "subway" for fare purposes. A transfer between segments is possible at South Station.

A "Phase III" tunneled segment was proposed to connect the two segments for through service, but it was controversial due to high cost and the fact that many did not consider Phase I to be adequate replacement service for the old Elevated. All Phase III tunneling proposals have been suspended due to lack of funds, as has the Urban Ring, which was intended to expand upon existing crosstown buses.

The MBTA contracts with private bus companies to provide subsidized service on certain routes outside of the usual fare structure. These are known collectively as the HI-RIDE Commuter Bus service, and are not numbered or mapped in the same way as integral bus services.

Four routes connecting to Harvard Station (Red Line) still run as trackless trolleys; there was once a much larger trackless trolley system. (See Trolleybuses in Greater Boston.)

In FY2005, there were on average 363,500 weekday boardings of MBTA-operated buses and trackless trolleys (not including the Silver Line), or 31.8% of the MBTA system. Another 4,400 boardings (0.38%) occurred on subsidized bus routes operated by private carriers.

In June 2020 in the aftermath of COVID-19 pandemic, the MBTA had begun providing real-time information on crowding. The information would be available on the MBTA website, E Ink screens, and in the Transit app. At conception the service is was only available on bus routes 1, 15, 16, 22, 23, 31, 32, 109, and 110, and it remains unclear if further lines or transit modes will be introduced in the future or if this feature will remain permanent. This feature however is not new, since 2019 Google Maps has provided this data.

The subway system has three heavy rail rapid transit lines (the Red, Orange and Blue Lines), and two light rail lines (the Green Line and the Ashmont–Mattapan High-Speed Line, the latter designated an extension of the Red Line). The system operates according to a spoke-hub distribution paradigm, with the lines running radially between central Boston and its environs. It is common usage in Boston to refer to all four of the color-coded rail lines which run underground as "the subway" or "the T", regardless of the actual railcar equipment used.

All four subway lines cross downtown, forming a quadrilateral configuration, and the Orange and Green Lines (which run approximately parallel in that district) also connect directly at two stations just north of downtown. The Red Line and Blue Line are the only pair of subway lines which do not have a direct transfer connection to each other. Because the various subway lines do not consistently run in any given compass direction, it is customary to refer to line directions as "inbound" or "outbound". Inbound trains travel towards the four downtown transfer stations, and outbound trains travel away from these hub stations.

The Green Line has four branches in the west: B (Boston College), C (Cleveland Circle), D (Riverside), and E (Heath Street). The A branch formerly went to Watertown, filling in the north-to-south letter assignment pattern, and the E branch formerly continued beyond Heath Street to Arborway.

The Red Line has two branches in the south, Ashmont and Braintree, named after their terminal stations.

The colors were assigned on August 26, 1965 in conjunction with design standards developed by Cambridge Seven Associates, and have served as the primary identifier for the lines since the 1964 reorganization of the MTA into the MBTA. The Orange Line is so named because it used to run along Orange Street (now lower Washington Street), as the former "Orange Street" also was the street that joined the city to the mainland through Boston Neck in colonial times; the Green Line because it runs adjacent to parts of the Emerald Necklace park system; the Blue Line because it runs under Boston Harbor; and the Red Line because its northernmost station used to be at Harvard University, whose school color is crimson.

The four transit lines all use standard rail gauge, but are otherwise incompatible; trains of one line would have to be modified to run on another. Orange and Blue Line trains are similar enough that modification of some Blue Line trains for operation on the Orange Line was considered, although ultimately rejected for cost reasons. Also, some of the new Blue Line cars from Siemens Transportation were tested on the Orange Line after hours, before acceptance for revenue service on the Blue Line. There are no direct track connections between lines, except between the Red Line and Ashmont-Mattapan High Speed Line, but all except the Blue Line have little-used connections to the national rail network, which have been used for deliveries of railcars and supplies.

Opened in September 1897, the four-track-wide segment of the Green Line tunnel between Park Street and Boylston stations was the first subway in the United States, and has been designated a National Historic Landmark. The downtown portions of what are now the Green, Orange, Blue, and Red line tunnels were all in service by 1912. Additions to the rapid transit network occurred in most decades of the 1900s, and continue in the 2000s with the addition of Silver Line bus rapid transit and planned Green Line expansion. (See History and Future plans sections.)

In FY2005, there were on average 628,400 weekday boardings on the rapid transit and light rail lines (including the Silver Line Bus Rapid Transit), or 55.0% of the MBTA system.

On January 29, 2014, the MBTA completed a countdown clock display system, alerting passengers to arriving trains, at all 53 heavy rail subway stations (the Red, Blue and Orange Lines). The MBTA introduced countdown clocks in underground Green Line stations during 2015. Unlike the other countdown clocks which count down in minutes, the Green Line clocks count down the number of stops away the train is.

The MBTA Commuter Rail system is a regional rail network that reaches from Boston into the suburbs of eastern Massachusetts. The system consists of twelve main lines, three of which have two branches. The rail network operates according to a spoke-hub distribution paradigm, with the lines running radially outward from the city of Boston. Eight of the lines converge at South Station, with four of these passing through Back Bay station. The other four converge at North Station. There is no passenger connection between the two sides; the Grand Junction Railroad is used for non-revenue equipment moves accessing the maintenance facility. The North–South Rail Link has been proposed to connect the two halves of the system; it would be constructed under the Central Artery tunnel of the Big Dig.

Special MBTA trains are run over the Franklin Line and the Providence/Stoughton Line to Foxborough station for New England Patriots home games and other events at Gillette Stadium. The "CapeFLYER" intercity service, operated on summer weekends, uses MBTA equipment and operates over the Middleborough/Lakeville Line. Amtrak runs regularly scheduled intercity rail service over four lines: the "Lake Shore Limited" over the Framingham/Worcester Line, "Acela Express" and "Northeast Regional" services over the Providence/Stoughton Line, and the "Downeaster" over sections of the Lowell Line and Haverhill Line. Freight trains run by Pan Am Southern, Pan Am Railways, CSX Transportation, the Providence and Worcester Railroad, and the Fore River Railroad also use parts of the network.

The first commuter rail service in the United States was operated over what is now the Framingham/Worcester Line beginning in 1834. Within the next several decades, Boston was the center of a massive rail network, with eight trunk lines and dozens of branches. By 1900, ownership was consolidated under the Boston and Maine Railroad to the north, the New York Central Railroad to the west, and the New York, New Haven and Hartford Railroad to the south. Most branches and one trunk line – the former Old Colony Railroad main – had their passenger services discontinued during the middle of the 20th century. In 1964, the MBTA was formed to subsidize the failing suburban railroad operations, with an eye towards converting many to extensions of the existing rapid transit system. The first unified branding of the system was applied on October 8, 1974, with "MBTA Commuter Rail" naming and purple coloration analogous to the four subway lines. The system continued to shrink – mostly with the loss of marginal lines with one daily round trip – until 1981. The system has been expanded since, with four lines restored (Fairmount Line in 1979, Old Colony Lines in 1997, and Greenbush Line in 2007), six extended., and a number of stations added and rebuilt.

Several further expansions are planned or proposed. The South Coast Rail project, for which preliminary construction began in 2014, would extend the Stoughton section of the Providence/Stoughton Line to Taunton, with two branches to New Bedford and Fall River. Extensions of the Providence/Stoughton Line to Kingston, the Middleborough/Lakeville Line to Buzzards Bay, and the Lowell Line into New Hampshire are also proposed. Infill stations at Boston Landing, Blue Hill Avenue, West Station, and South Salem are under construction or planned.

Each commuter rail line has up to eleven fare zones, numbered 1A and 1 through 10. Riders are charged based on the number of zones they travel through. Tickets can be purchased on the train, from ticket counters or machines in some rail stations, or with a mobile app. If a local vendor or ticket machine is available, riders will pay a surcharge for paying with cash on board. Fares range from $2.25 to $12.50, with multi-ride and monthly passes available. In 2016, the system averaged 122,600 daily riders, making it the fourth-busiest commuter rail system in the nation.

The MBTA commuter rail network was the first in the nation to offer free on-board Wi-Fi. It offers Wi-Fi-enabled coaches on all train sets.

The MBTA boat system comprises several ferry routes via Boston Harbor. One of these is an inner harbor service, linking the downtown waterfront with the Boston Navy Yard in Charlestown. The other routes are commuter routes, linking downtown to Hingham, Hull, and Salem. Some commuter services operate via Logan International Airport.

All boat services are operated by private sector companies under contract to the MBTA. In FY2005, the MBTA boat system carried 4,650 passengers (0.41% of total MBTA passengers) per weekday. The service is provided through contract of the MBTA by Boston Harbor Cruises (BHC).

The MBTA contracts out operation of "The Ride", a door to door service for people with disabilities. Paratransit services carry 5,400 passengers on a typical weekday, or 0.47% of the MBTA system ridership. The two private service providers under contractual agreement with the MBTA for The Ride: Veterans Transportation LLC, and National Express Transit (NEXT).

In September 2016, the MBTA announced that paratransit users would be able to get rides from Uber and Lyft. Riders would pay $2 for a pickup within a few minutes (more for longer trips worth more than $15) instead of $3.15 for a scheduled pickup the next day. The MBTA would pay $13 instead of $31 per ride ($46 per trip when fixed costs of The Ride are considered).

Conventional bicycles are generally allowed on MBTA commuter rail, commuter boat, and rapid transit lines during off-peak hours and all day on weekends and holidays. However, bicycles are "not" allowed at any time on the Green Line, or the Ashmont–Mattapan High-Speed Line segment of the Red Line. Buses equipped with bike racks at the front (including the Silver Line) may always accommodate bicycles, up to the capacity limit of the racks. The MBTA claims that 95% of its buses are now equipped with bike racks, except for trackless trolleys which still lack this capability.

Due to congestion and tight clearances, bicycles are banned from Park Street, Downtown Crossing, and Government Center stations at all times.

However, compact folding bicycles are permitted on all MBTA vehicles at all times, provided that they are kept completely folded for the duration of the trip, including passage through faregates. Gasoline-powered vehicles, bike trailers, and Segways are prohibited.

No special permit is required to take a bicycle onto an MBTA vehicle, but bicyclists are expected to follow the rules and hours of operation. Cyclists under 16 years old are supposed to be accompanied by a parent or legal guardian. Detailed rules, and an explanation of how to use front-of-bus bike racks and bike parking are on the MBTA website.

The MBTA says that over 95% of its stations are equipped with bike racks, many of them under cover from the weather. In addition, over a dozen stations are equipped with "Pedal & Park" fully enclosed areas protected with video surveillance and controlled door access, for improved security. To obtain access, a personally registered CharlieCard must be used. Registration is done online, and requires a valid email address and the serial number of the CharlieCard. All bike parking is free of charge.

, the MBTA operates park and ride facilities at 103 locations with a total capacity of 55,000 automobiles, and is the owner of the largest number of off-street paid parking spaces in New England. The number of spaces at stations with parking varies from a few dozen to over 2,500. The larger lots and garages are usually near a major highway exit, and most lots fill up during the morning rush hour. There are some 22,000 spaces on the southern portion of the commuter rail system, 9,400 on the northern portion and 14,600 at subway stations. The parking fee ranges from $4 to $7 per day, and overnight parking (maximum 7 days) is permitted at some stations.

Management for a number of parking lots owned by the MBTA is handled by a private contractor. The 2012 contract with LAZ Parking (which was not its first) was terminated in 2017 after employees were discovered "skimming" revenue; the company paid $5.5 million to settle the case. A new contract with stronger performance incentives and anti-fraud penalties was then awarded to Republic Parking System of Tennessee.

Customers parking in MBTA-owned and operated lots with existing cash "honor boxes" can pay for parking online or via phone while in their cars or once they board a train, bus, or commuter boat. , the MBTA switched from ParkMobile to PayByPhone as its provider for mobile parking payments by smartphone. Monthly parking permits are available, offering a modest discount. Detailed parking information by station is available online, including prices, estimated vacancy rate, and number of accessible and bicycle parking slots.

, the MBTA has a policy for electric vehicle charging stations in its parking spaces, but does not yet have such facilities available.

From time to time the MBTA has made various agreements with companies that contribute to commuting options. One company the MBTA selected was Zipcar; the MBTA provides Zipcar with a limited number of parking spaces at various subway stations throughout the system.

Traditionally, the MBTA has stopped running around 1 am each night, despite the fact that bars and clubs in most areas of Boston are open until 2 am. Like nearly all subways worldwide, the MBTA's subway does not have parallel express and local tracks, so much rail maintenance is only done when the trains are not running. An MBTA spokesperson has said, "with a 109-year-old system you have to be out there every night" to do necessary maintenance. The MBTA did experiment with "Night Owl" substitute bus service from 2001 to 2005, but abandoned it because of insufficient ridership, citing a $7.53 per rider cost to keep the service open, five times the cost per passenger of an average bus route.

A modified form of the MBTA's previous "Night Owl" service was experimentally reinstated starting in the spring of 2014 – this time, all subway lines were proposed to run until 3 am on weekends, along with the 15 most heavily used bus lines and the para-transit service "The Ride".

Starting March 28, 2014, the late-night service began operation on a one-year trial basis, with service continuation depending on late-night ridership and on possible corporate sponsorship. , late-night ridership was stable, and much higher than the earlier failed experimental service. However, it is still unclear whether and on what basis the program might be extended past its first year. The extended hours program has not been implemented on the MBTA commuter rail operations.

In early 2016, the MBTA decided that Late-Night service would be canceled because of lack of funding. The last night for late-night service was on March 19, 2016. The last train left at 2 a.m. on March 19, 2016.

in 2018 the MBTA further tried "Early Morning and Late Night Bus Service Pilots". 
In June 2019, a year after the trials the board voted to make some changes to the schedule which would allow for further late night service to be incorporated long term 

During Fiscal Year 2013, the entire MBTA system had a typical weekday passenger ridership of 1,297,650. The MBTA's rapid transit lines (Red, Green, Orange, and Blue) accounted for 59% of all rides, buses accounted for 30%, and commuter rail accounted for 10% of all rides. The MBTA's ferries and paratransit accounted for the remaining 1% of rides.

Passenger ridership has been steadily growing over the years, and between 2010 and 2013, the system saw passenger ridership grow 4.6% or an additional 57,000 daily passengers to the system.

The MBTA has various fare structures for its various types of service. The CharlieCard electronic farecard is accepted on the subway and bus systems, but not on commuter rail, ferry, or paratransit services. Passengers pay for subway and bus rides at faregates in station entrances or fareboxes in the front of vehicles; MBTA employees manually check tickets on the commuter rail and ferries.

Since the 1980s, the MBTA has offered discounted monthly passes on all modes for the convenience of daily commuters and other frequent riders. One-day and seven-day passes, intended primarily for tourists, are available for buses, subway, and inner harbor ferries.

The MBTA has periodically raised fares to match inflation and keep the system financially solvent. A substantial increase effective July 2012 raised public ire including an "Occupy the MBTA" protest. A transportation funding law passed in 2013 limits MBTA fare increases to 7% every two years. A 5% fare increase effective July 1, 2014 was implemented.

, all subway trips (Green Line, Blue Line, Orange Line, Red Line, Ashmont-Mattapan Line, and the Waterfront section of the Silver Line) cost $2.40 for CharlieCard holders and $2.90 for CharlieTicket or cash payers. Local bus and trackless trolley fares (including the Washington Street section of the Silver Line) are $1.70 for CharlieCard holders and $2.00 for others. All transfers between subway lines are free with all fare media. Passengers using CharlieCards can transfer free from a subway to a bus, and from a bus to a subway for the difference in price ("step-up fare"). CharlieTicket holders can transfer free between buses, but not between subway and bus, except between rapid transit and the Washington Street section of the Silver Line. Paying directly with cash is only available on buses, Green Line surface stops, and the Ashmont-Mattapan Line; the higher CharlieTicket price is charged.

The MBTA operates "Inner Express" and "Outer Express" buses to suburbs outside the subway system. Inner Express bus trips cost $3.65 with a CharlieCard or $4.75 without; Outer Express trips cost $5.25 with and $6.80 without. Free transfers are available to the subway and local buses with a CharlieCard, and to local buses with a CharlieTicket.

CharlieTickets are available from ticket vending machines in MBTA rapid transit stations. CharlieCards are not dispensed by the machines, but are available free of charge on request at most MBTA Customer Service booths in stations, or at the CharlieCard Store at Downtown Crossing station. As given out, the CharlieCards are "empty", and must have value added at an MBTA ticket machine before they can be used.

The fare system, including on-board and in-station fare vending machines, was purchased from German-based Scheidt and Bachmann, which developed the technology. The CharlieCards were developed by Gemalto and later by Giesecke & Devrient. In 2006 electronic fares replaced metal tokens, which had been used on and off on transit systems in Boston for over a century.

Until 2007, not all subway fares were identical – passengers were not charged for boarding outbound Green Line trains at surface stops, while double fares were charged for the outer ends of the Green Line D branch and the Red Line Braintree Branch. As part of a general fare hike effective January 1, 2007, the MBTA eliminated these inconsistent fares.

Commuter rail fares are on a zone-based system, with fares dependent on the distance from downtown. Rides between Zone 1A stations – South Station, Back Bay, most of the Fairmount Line, and eight other stations within several miles of downtown – cost $2.10, the same as a subway fare with a CharlieCard. Fares for other stations range from $5.75 from Zone 1 (~5–10 miles from downtown) to $14.50 from Zone 10 (~60 miles). All Massachusetts stations are Zone 8 or closer; only T.F. Green Airport and Wickford Junction in Rhode Island are Zone 9 and 10.

Interzone fares – for trips that do not go to Zone 1A – are offered at a substantial discount to encourage riders to take the commuter rail for less common commuting patterns for which transit is not usually taken. Discounted monthly passes are available for all trips; 10-ride passes at full price are also available for trips to Zone 1A. All monthly passes include unlimited trips on the subway and local bus; some outer-zone monthlies also offer free use of express buses and ferries. A cash-on-board surcharge of $3.00 is added for trips originating from stations with fare vending machines.

The Inner Harbor Ferry costs $3.25 per ride, and is grouped as a Zone 1A monthly commuter rail pass. Single rides cost $8.50 from Hull or Hingham to Boston, $17.00 from Hull or Hingham to Logan Airport, and $13.75 from Boston to Logan Airport.

Fares on The Ride, the MBTA's paratransit program, are structured differently from other modes. Passengers using The Ride must maintain an account with the MBTA in order to pay for service. Fares are $3.35for "ADA trips" originating within of fixed-route bus or subway service and booked in advance, and $5.60 for "premium trips" outside the mandated area.

Discounted fares (, $1.10 for the subway, $1.10 for a subway-bus transfer, and $0.85 for local buses including transfer) as well as discounted monthly local bus and subway passes are available to seniors over 65, and passengers who are permanently disabled who utilize a special photo CharlieCard (called "Senior ID" and "Transportation Access Pass", respectively). Holders of these passes are also entitled to 50% off the Commuter Rail fares. Passengers who are legally blind ride for free on all MBTA services (including express buses and the Commuter Rail) with a "Blind Access Card".

Children under 12 ride for free with an adult (up to 2 per adult). Military personnel, public servants, and certain government officials ride at no charge upon presentation of proper ID, or if dressed in official work uniforms.

Middle school and high school students receive the aforementioned discounts on fares. Student discounts require a "Student CharlieCard" or "S-Card" issued through the holder's school which is valid year-round. From the first day of school until June 31 of the next year, students can buy a 30-day LinkPass for $30 that allows for unlimited usage of the bus and rapid transit lines until the last day of that month. From July 1 to August 31, students can only load money on and pay as they would with a standard CharlieCard. Passes expire on August 31 and are reissued by the school the following school year.

College students are not eligible for reduced fares, but some colleges offer a "Semester Pass" program.

A special "Youth Pass" program was introduced in 2017, allowing young adults less than 25 years old who reside in participating cities or towns and are enrolled in specific low income programs to pay reduced fares.

Since the "forward funding" reform in 2000, the MBTA is funded primarily through 16% of the state sales tax excluding the meals tax (with minimum dollar amount guarantee), which is set at 6.25% statewide, and therefore equal to 1% of taxable non-meal purchases statewide. The authority is also funded by passenger fares and formula assessments of the cities and towns in its service area (excepting those which are assessed for the MetroWest Regional Transit Authority). Supplemental income is obtained from its paid parking lots, renting space to retail vendors in and around stations, rents from utility companies using MBTA rights of way, selling surplus land and movable property, advertising on vehicles and properties, and federal operating subsidies for special programs.

A May 2019 report found the MBTA had a maintenance backlog of approximately $10 billion, which it hopes to clear by 2032 by increasing spending on capital projects.

The Capital Investment Program is a rolling 5-year plan which programs capital expenses. The draft FY2009-2014 CIP allocates $3,795M, including $879M in projects funded from non-MBTA state sources (required for Clean Air Act compliance), and $299M in projects with one-time federal funding from the American Recovery and Reinvestment Act of 2009. Capital projects are paid for by federal grants, allocations from the general budget of the Commonwealth of Massachusetts (for legal commitments and expansion projects) and MBTA bonds (which are paid off through the operating budget). The FY2014 budget includes $1.422 billion for operating expenses and $443.8M in debt and lease payments.

The FY2010 budget was supplemented by $160 million in sales tax revenue when the statewide rate was raised from 5% to 6.25%, to avoid service cuts or a fare increase in a year when deferred debt payments were coming due.

The Boston Metropolitan Planning Organization is responsible for overall regional surface transportation planning. As required by federal law for projects to be eligible for federal funding (except earmarks), the MPO maintains a fiscally constrained 20+ year Regional Transportation Plan for surface transportation expansion, the current edition of which is called "Journey to 2030". The required 4-year MPO plan is called the Transportation Improvement Plan.

The MBTA maintains its own 25-year capital planning document, called the Program for Mass Transportation, which is fiscally unconstrained. The agency's 4-year plan is called the Capital Improvement Plan; it is the primary mechanism by which money is actually allocated to capital projects. Major capital spending projects must be approved by the MBTA Board, and except for unexpected needs, are usually included in the initial CIP.

In addition to federal funds programmed through the Boston MPO, and MBTA capital funds derived from fares, sales tax, municipal assessments, and other minor internal sources, the T receives funding from the Commonwealth of Massachusetts for certain projects. The state may fund items in the State Implementation Plan (SIP) – such as the Big Dig mitigation projects – which is the plan required under the Clean Air Act to reduce air pollution. (, all of Massachusetts is designated as a clean air "non-attainment" zone.)

In 2005, the administration of then-governor Mitt Romney announced a long range transportation plan that emphasized repair and maintenance over expansion.

Due to the financial constraints on the MBTA budget, it is expected that funds for all further expansion projects will be funded with money outside the MBTA's budget. A state transportation bond bill is being used to fund the Green Line Extension to Somerville and Medford, and planning South Coast Rail commuter rail service to Fall River and New Bedford.

There is a proposal to extend the Blue Line northward to Lynn, with two potential extension routes having been identified. One proposed path would run through marshland alongside the existing Newburyport/Rockport commuter rail line, while the other would extend the line along the remainder of the BRB&L right of way.

In addition, the MBTA has committed to designing an extension of the line's southern terminus westward to Charles/MGH, where it would connect with the Red Line. This was one of the mitigation measures the Commonwealth of Massachusetts agreed to offset increased automobile emissions from the Big Dig, but it was later replaced in this agreement by other projects.

To settle a lawsuit with the Conservation Law Foundation to mitigate increased automobile emissions from the Big Dig, the Commonwealth of Massachusetts agreed to extend the Green Line north to Somerville and Medford, two suburbs currently under-served by the MBTA. This plan starts at a relocated Lechmere station, and terminates at College Avenue in Medford and Union Square in Somerville. The original settlement-imposed deadline was December 31, 2014. There will be an expected daily ridership of 8,420. After projected costs increased to $3 billion, the project was halted in 2015 and scaled back. The revised project broke ground in June 2018 and is expected to serve passengers beginning in late 2021.

Another mitigation project in the initial settlement was restoration of service on the E branch between Heath Street and Arborway/Forest Hills. A revised settlement agreement resulted in the substitution of other projects with similar air quality benefits. The state Executive Office of Transportation promised to consider other transit enhancements in the Arborway corridor.

In October 2013, MassDOT announced plans for a $1.3 billion subway car order for the Orange and Red Lines, which would replace and expand the existing car fleets and add more frequent service. The MassDOT Board awarded a $566.6 million contract to a China based manufacturer CNR (which became part of CRRC the following year) to build 404 replacement railcars for the Orange Line and Red Line. The other bidders were Bombardier Transportation, Kawasaki Heavy Industries and Hyundai Rotem. CNR began building the cars at a new manufacturing plant in Springfield, Massachusetts, with initial deliveries expected in 2018 and all cars in service by 2023. The Board forwent federal funding to allow the contract to specify the cars be built in Massachusetts, in order to create a local railcar manufacturing industry. In addition to the new rolling stock, the $1.3 billion allocated for the project will pay for testing, signal improvements and expanded maintenance facilities, as well as other related expenses. Sixty percent of the car's components are sourced from the United States. Replacement of the signal systems, which will increase reliability and allow more frequent trains, is expected to be complete by 2022, with a total cost of $218 million for both lines.

The Urban Ring is a project of the Massachusetts Bay Transportation Authority and the Commonwealth of Massachusetts, to develop new public transportation routes that would provide improved circumferential connections among many existing transit lines that project radially from downtown Boston, allowing easier travel between locations outside of downtown. The project corridor passes through various neighborhoods of Boston, Chelsea, Everett, Malden, Medford, Somerville, Cambridge, and Brookline. The capital cost for this version of the plan is estimated at $2.2 billion, with a projected daily ridership of 170,000. 53% of the route is either in a bus-only lane, dedicated busway, or tunnel. The Urban Ring would have a higher collective ridership than the Orange Line, Blue Line, or the entire commuter rail system.

There are several proposed extensions to current commuter rail lines. An extension of the Stoughton Line known as South Coast Rail is proposed to serve Fall River, and New Bedford. Critics argue that building the extension does not make economic sense.

A extension of the Providence Line past Providence to T. F. Green Airport and Wickford Junction in Rhode Island opened in 2012. The Rhode Island Department of Transportation is also studying the feasibility of serving existing Amtrak stations in Kingston and Westerly as well as constructing new stations in Cranston, East Greenwich, and West Davisville. Federal funding has also been provided for preliminary planning of a new station in Pawtucket.

In September 2009, CSX Transportation and the Commonwealth of Massachusetts finalized a $100 million agreement to purchase CSX's Framingham to Worcester tracks, as well as some other track, to improve service on the Framingham/Worcester Line. A liability issue that had held up the agreement was resolved. There is also a project underway to upgrade the Fitchburg Line to have cab signaling and to construct a second track along a run near Acton which is shared with freight traffic, so that the Fitchburg to Boston trip will be able to take only about an hour. Completion is expected in December 2015.

The state of New Hampshire created the New Hampshire Rail Transit Authority and allocated money to build platforms at Nashua and Manchester. An article in "The Eagle-Tribune" claimed that Massachusetts was negotiating to buy property which has the potential to extend the Haverhill Line to Plaistow, New Hampshire.

Massachusetts agreed in 2005 to make improvements on the Fairmount Line part of its legally binding commitment to mitigate increased air pollution from the Big Dig. These improvements, including four new infill stations, were supposed to be complete by December 31, 2011. The total cost of the project was estimated at $79.4 million, and it was expected to divert 220 daily trips from automobiles to transit. , three of the new stations were open; the fourth station has been delayed by community opposition. In 2014, the MBTA announce it would purchase Diesel Multiple Unit (DMU) self-propelled rail cars for the Fairmount Line with eventual expansion to five other lines to be known as the Indigo Line. The planned DMU procurement was canceled in 2015.

No direct rail connection exists between North Station and South Station, effectively splitting the commuter rail network into separate pieces. A North–South Rail Link has been proposed to unite the two halves of the commuter rail system, to allow more convenient and efficient through-routed service. However, because of high cost, Massachusetts withdrew its sponsorship of the proposal in 2006, in communications with the United States Department of Transportation. Advocacy groups continue to press for the project as a better alternative than expanding South Station, which would also be costly but provide fewer overall improvements in service.

In 2015, Massachusetts Governor Charlie Baker signed new legislation creating a financial control board to oversee the MBTA. The Fiscal and Management Control Board started meeting in July 2015 and is charged with bringing financial stability to the agency. The Fiscal and Management Control Board reports to Massachusetts Secretary of Transportation Stephanie Pollack. Three of the five members of the MBTA Fiscal and Management Control Board are also members of the Massachusetts Department of Transportation. The Massachusetts Secretary of Transportation leads the executive management team of MassDOT in addition to serving in the Governor's Cabinet. The MBTA's executive management team is led by its General Manager, who is currently also serving as the MassDOT Rail and Transit Administrator, overseeing all public transit in the state.

The MBTA Advisory Board represents the cities and towns in the MBTA service district. The municipalities are assessed a total of $143M annually (). In return, the Advisory Board has veto power over the MBTA operating and capital budgets, including the power to reduce the overall amount.


The MBTA's buses are maintained and stored at several bus garages located throughout eastern Massachusetts:

Rail lines have their own maintenance facilities:

Major administrative facilities:

, the MBTA employs 6,346 workers, of which roughly 600 are in part-time jobs.

Structurally, the employees of the MBTA function as part of a handful of trade unions. The largest union of the MBTA is the Carmen's Union (Local 589), representing bus and subway operators. This includes full and part-time bus drivers, motorpersons and streetcar motorpersons, full and part-time train attendants, and Customer Service Agents (CSAs). Further unions include the Machinists Union, Local 264; Electrical Workers Union, Local 717; the Welder's Union, Local 651; the Executive Union; the Office and Professional Employees International Union, Local 453; the Professional and Technical Engineers Union, Local 105; and the Office and Professional Employees Union, Local 6.

Within the authority, employees are ranked according to seniority (or "rating"). This is categorized by an employee's five or six-digit badge number, though some of the longest serving employees still have only three or four-digits. An employee's badge number indicates the relative length of employment with the MBTA; badges are issued in sequential order. The rating structure determines many different things, including the rank in which perks are to be offered to employee, such as: When offering the choice for quarter-annual route assignments ("picks"), overtime offerings, and even the rank to transfer new hires from part-time roles to a full-time role.

The MBTA maintains its own police force which actively patrols all areas and vehicles used by the Authority. MBTA Police conduct routine vehicle patrol, routine foot patrol, incident investigations, and specialized patrol with K-9 dogs, and other specialized methods of explosive and narcotics detection.

The MBTA also maintains several closed-circuit television facilities located throughout its service area. The cameras monitor various areas including trains stations, and MBTA vehicles throughout the system on a 24-hour basis. MBTA phone numbers pasted onto the front of the fare gates can place customers having a problem directly into contact with one of these operations centers.

Ahead of the MBTA's 2009 restructuring with the Massachusetts Department of Transportation (MassDOT), the MBTA had a total debenture of over US$8 billion. As a direct result, MBTA fares and parking fees have increased significantly. On July 1, 2012, MBTA fares went up as well as multiple service cuts, another fare hike took place on July 1, 2016.

On the last day of Winter in 2015, seventy two Massachusetts legislators participated in the "GovOnTheT" an exercise where Steve Kropper and Michele Rapp challenged officials with a one-hour commute or less, to take a train, subway, bus or ferry to the State House in Boston.

When the Orange Line was rebuilt in the 1980s, it was rerouted from deteriorating elevated railway structures to instead follow existing rail right-of-way, to greatly reduce land acquisition and construction costs. This had the side effect of changing its course away from the lower income areas of Everett, Chelsea, and Roxbury (where residents are less likely to own cars, and depend more on public transit), toward the more affluent towns of Malden and Medford, as well as sections of the Jamaica Plain neighborhood (where car ownership is higher, and thus, reliance on public transit is far lower).

To mitigate this, the MBTA set up a new bus line served by articulated buses equipped with specialized dispatching equipment, and a few of the features of a bus rapid transit (BRT) route. The MBTA named this new service the Silver Line, and classified it as though it were a high-capacity rail transit service, though it fails to meet full service standards for a BRT route. The Silver Line service has been criticized in many respects, most notably for its slow speed and the fact that it operates in mixed street traffic, subject to gridlock and collisions, earning it the nickname "Silver Lie" among some critics. A rating from the Institute for Transportation and Development Policy (ITDP) determined that the MBTA Silver Line was best classified as "Not BRT" after local decision makers gradually decided to do away with most BRT-specific features.

Transportation advocates in Boston have complained that rail transit riders cannot travel from one outlying area to another without first traveling to the downtown hub stations, changing lines, and traveling outbound again. Some of the radial transit lines, notably the Green Line, are so overcrowded that service is very slow, unreliable, and capacity-limited because of rush-hour "crush loads". There are several crosstown bus lines, such as the #1, #66, CT2, and CT3 routes, but they are slow, unreliable, and subject to bus bunching because they must operate in mixed street traffic.

The MBTA Urban Ring Project would provide faster and more reliable circumferential service, and relieve overcrowding in the downtown hub stations. This issue has been studied as early as 1972, in the Boston Transportation Planning Review, and has been in detailed planning stages since before 2000, but has only been partially implemented due to lack of funding. A similar problem also occurs in the Washington Metro system, where customers cannot travel between suburbs on the same side of Washington without going through downtown, and Chicago's Metra and CTA systems, where all lines lead into and out of the central business district, rather than around it.

In 1951, the growing subway network was the setting of "A Subway Named Mobius", a science fiction short story written by the American astronomer Armin Joseph Deutsch. The tale described a Boston subway train which accidentally became a "phantom" by becoming lost in the fourth dimension, analogous to a topological Mobius strip. In 2001, a half-century later, the narrative was awarded a Retro Hugo Award for Best Short Story at the World Science Fiction Convention.

In 1959, the satirical song "M.T.A." (informally known as "Charlie on the MTA") was a hit single, as performed by the folksingers the Kingston Trio. It tells the absurd story of a passenger named Charlie, who cannot pay a newly imposed 5-cent exit fare, and thus remains trapped in the subway system. The song was still well known in 2006, when the MBTA named its new electronic farecards the "CharlieCard" and "CharlieTicket".




</doc>
<doc id="19870" url="https://en.wikipedia.org/wiki?curid=19870" title="Meson">
Meson

In particle physics, mesons ( or ) are hadronic subatomic particles composed of one quark and one antiquark, bound together by strong interactions. Because mesons are composed of quark subparticles, they have a meaningful physical size, a diameter of roughly one femtometer (1×10 m), which is about 1.2 times the size of a proton or neutron. All mesons are unstable, with the longest-lived lasting for only a few hundredths of a microsecond. Charged mesons decay (sometimes through mediating particles) to form electrons and neutrinos. Uncharged mesons may decay to photons. Both of these decays imply that color is no longer a property of the byproducts.

Outside the nucleus, mesons appear in nature only as short-lived products of very high-energy collisions between particles made of quarks, such as cosmic rays (high-energy protons and neutrons) and baryonic matter. Mesons are often produced artificially in a cyclotron in the collisions of protons, antiprotons, or other particles.

Higher-energy (more massive) mesons were created momentarily in the Big Bang, but are not thought to play a role in nature today. However, such heavy mesons are regularly created in particle accelerator experiments, in order to understand the nature of the heavier types of quark that compose the heavier mesons.

Mesons are part of the hadron particle family, and are defined simply as particles composed of an even number of quarks. The other members of the hadron family are the baryons: subatomic particles composed of odd numbers of valence quarks (at least 3), and some experiments show evidence of exotic mesons, which do not have the conventional valence quark content of two quarks (one quark and one antiquark), but 4 or more.

Because quarks have a spin , the difference in quark number between mesons and baryons results in conventional two-quark mesons being bosons, whereas baryons are fermions.

Each type of meson has a corresponding antiparticle (antimeson) in which quarks are replaced by their corresponding antiquarks and vice versa. For example, a positive pion () is made of one up quark and one down antiquark; and its corresponding antiparticle, the negative pion (), is made of one up antiquark and one down quark.

Because mesons are composed of quarks, they participate in both the weak and strong interactions. Mesons with net electric charge also participate in the electromagnetic interaction. Mesons are classified according to their quark content, total angular momentum, parity and various other properties, such as C-parity and G-parity. Although no meson is stable, those of lower mass are nonetheless more stable than the more massive, and hence are easier to observe and study in particle accelerators or in cosmic ray experiments. Mesons are also typically less massive than baryons, meaning that they are more easily produced in experiments, and thus exhibit certain higher-energy phenomena more readily than do baryons. For example, the charm quark was first seen in the J/Psi meson () in 1974, and the bottom quark in the upsilon meson () in 1977.

From theoretical considerations, in 1934 Hideki Yukawa predicted the existence and the approximate mass of the "meson" as the carrier of the nuclear force that holds atomic nuclei together. If there were no nuclear force, all nuclei with two or more protons would fly apart due to electromagnetic repulsion. Yukawa called his carrier particle the meson, from μέσος "mesos", the Greek word for "intermediate", because its predicted mass was between that of the electron and that of the proton, which has about 1,836 times the mass of the electron. Yukawa had originally named his particle the "mesotron", but he was corrected by the physicist Werner Heisenberg (whose father was a professor of Greek at the University of Munich). Heisenberg pointed out that there is no "tr" in the Greek word "mesos".

The first candidate for Yukawa's meson, now known in modern terminology as the muon, was discovered in 1936 by Carl David Anderson and others in the decay products of cosmic ray interactions. The mu meson had about the right mass to be Yukawa's carrier of the strong nuclear force, but over the course of the next decade, it became evident that it was not the right particle. It was eventually found that the "mu meson" did not participate in the strong nuclear interaction at all, but rather behaved like a heavy version of the electron, and was eventually classed as a lepton like the electron, rather than a meson. Physicists in making this choice decided that properties other than particle mass should control their classification.

There were years of delays in the subatomic particle research during World War II (1939–1945), with most physicists working in applied projects for wartime necessities. When the war ended in August 1945, many physicists gradually returned to peacetime research. The first true meson to be discovered was what would later be called the "pi meson" (or pion). This discovery was made in 1947, by Cecil Powell, César Lattes, and Giuseppe Occhialini, who were investigating cosmic ray products at the University of Bristol in England, based on photographic films placed in the Andes mountains. Some of those mesons had about the same mass as the already-known mu "meson", yet seemed to decay into it, leading physicist Robert Marshak to hypothesize in 1947 that it was actually a new and different meson. Over the next few years, more experiments showed that the pion was indeed involved in strong interactions. The pion (as a virtual particle) is also believed to be the primary force carrier for the nuclear force in atomic nuclei. Other mesons, such as the virtual rho mesons are involved in mediating this force as well, but to a lesser extent. Following the discovery of the pion, Yukawa was awarded the 1949 Nobel Prize in Physics for his predictions.

In the past, the word "meson" was sometimes used to mean "any" force carrier, such as "the Z meson", which is involved in mediating the weak interaction. However, this use has fallen out of favor, and mesons are now defined as particles composed of pairs of quarks and antiquarks.

Spin (quantum number S) is a vector quantity that represents the "intrinsic" angular momentum of a particle. It comes in increments of  "ħ". The "ħ" is often dropped because it is the "fundamental" unit of spin, and it is implied that "spin 1" means "spin 1 "ħ"". (In some systems of natural units, "ħ" is chosen to be 1, and therefore does not appear in equations.)

Quarks are fermions—specifically in this case, particles having spin ("S" = ). Because spin projections vary in increments of 1 (that is 1 "ħ"), a single quark has a spin vector of length , and has two spin projections ("S" = + and "S" = ). Two quarks can have their spins aligned, in which case the two spin vectors add to make a vector of length "S" = 1 and three spin projections ("S" = +1, "S" = 0, and "S" = −1), called the spin-1 triplet. If two quarks have unaligned spins, the spin vectors add up to make a vector of length S = 0 and only one spin projection ("S" = 0), called the spin-0 singlet. Because mesons are made of one quark and one antiquark, they can be found in triplet and singlet spin states. The later are called scalar mesons or pseudoscalar mesons, depending on their parity (see below).

There is another quantity of quantized angular momentum, called the orbital angular momentum (quantum number "L"), that is the angular momentum due to quarks orbiting each other, and comes in increments of 1 "ħ". The total angular momentum (quantum number "J") of a particle is the combination of intrinsic angular momentum (spin) and orbital angular momentum. It can take any value from to , in increments of 1.

Particle physicists are most interested in mesons with no orbital angular momentum ("L" = 0), therefore the two groups of mesons most studied are the "S" = 1; "L" = 0 and "S" = 0; "L" = 0, which corresponds to "J" = 1 and "J" = 0, although they are not the only ones. It is also possible to obtain "J" = 1 particles from "S" = 0 and "L" = 1. How to distinguish between the "S" = 1, "L" = 0 and "S" = 0, "L" = 1 mesons is an active area of research in meson spectroscopy.

If the universe were reflected in a mirror, most laws of physics would be identical—things would behave the same way regardless of what we call "left" and what we call "right". This concept of mirror reflection is called parity ("P"). Gravity, the electromagnetic force, and the strong interaction all behave in the same way regardless of whether or not the universe is reflected in a mirror, and thus are said to conserve parity (P-symmetry). However, the weak interaction does" "distinguish "left" from "right", a phenomenon called parity violation (P-violation).

Based on this, one might think that, if the wavefunction for each particle (more precisely, the quantum field for each particle type) were simultaneously mirror-reversed, then the new set of wavefunctions would perfectly satisfy the laws of physics (apart from the weak interaction). It turns out that this is not quite true: In order for the equations to be satisfied, the wavefunctions of certain types of particles have to be multiplied by −1, in addition to being mirror-reversed. Such particle types are said to have "negative" or "odd" parity ("P" = −1, or alternatively "P" = −), whereas the other particles are said to have "positive" or "even" parity ("P" = +1, or alternatively "P" = +).

For mesons, parity is related to the orbital angular momentum by the relation:

where the "L" is a result of the parity of the corresponding spherical harmonic of the wavefunction. The "+1" comes from the fact that, according to the Dirac equation, a quark and an antiquark have opposite intrinsic parities. Therefore, the intrinsic parity of a meson is the product of the intrinsic parities of the quark (+1) and antiquark (−1). As these are different, their product is −1, and so it contributes the "+1" that appears in the exponent.

As a consequence, all mesons with no orbital angular momentum ("L" = 0) have odd parity ("P" = −1).

C-parity is only defined for mesons that are their own antiparticle (i.e. neutral mesons). It represents whether or not the wavefunction of the meson remains the same under the interchange of their quark with their antiquark. If
then, the meson is "C even" (C = +1). On the other hand, if
then the meson is "C odd" (C = −1).

C-parity rarely is studied on its own, but more commonly in combination with P-parity into CP-parity. CP-parity was thought to be conserved, but was later found to be violated in weak interactions.

G parity is a generalization of the C-parity. Instead of simply comparing the wavefunction after exchanging quarks and antiquarks, it compares the wavefunction after exchanging the meson for the corresponding antimeson, regardless of quark content.

If
then, the meson is "G even" (G = +1). On the other hand, if
then the meson is "G odd" (G = −1).

The concept of isospin was first proposed by Werner Heisenberg in 1932 to explain the similarities between protons and neutrons under the strong interaction. Although they had different electric charges, their masses were so similar that physicists believed that they were actually the same particle. The different electric charges were explained as being the result of some unknown excitation similar to spin. This unknown excitation was later dubbed "isospin" by Eugene Wigner in 1937. When the first mesons were discovered, they too were seen through the eyes of isospin and so the three pions were believed to be the same particle, but in different isospin states.

This belief lasted until Murray Gell-Mann proposed the quark model in 1964 (containing originally only the u, d, and s quarks). The success of the isospin model is now understood to be the result of the similar masses of the u and d quarks. Because the u and d quarks have similar masses, particles made of the same number of them also have similar masses. The exact specific u and d quark composition determines the charge, because u quarks carry charge whereas d quarks carry charge . For example, the three pions all have different charges ( (), (a quantum superposition of and states), ()), but have similar masses (c. ) as they are each composed of a same total number of up and down quarks and antiquarks. Under the isospin model, they were considered a single particle in different charged states.

The mathematics of isospin was modeled after that of spin. Isospin projections varied in increments of 1 just like those of spin, and to each projection was associated a "charged state". Because the "pion particle" had three "charged states", it was said to be of isospin "I" = 1. Its "charged states" , , and , corresponded to the isospin projections "I" = +1, "I" = 0, and "I" = −1 respectively. Another example is the "rho particle", also with three charged states. Its "charged states" , , and , corresponded to the isospin projections "I" = +1, "I" = 0, and "I" = −1 respectively. It was later noted that the isospin projections were related to the up and down quark content of particles by the relation

where the "n"'s are the number of up and down quarks and antiquarks.

In the "isospin picture", the three pions and three rhos were thought to be the different states of two particles. However, in the quark model, the rhos are excited states of pions. Isospin, although conveying an inaccurate picture of things, is still used to classify hadrons, leading to unnatural and often confusing nomenclature. Because mesons are hadrons, the isospin classification is also used, with "I" =  for up quarks and down antiquarks, and "I" =  for up antiquarks and down quarks.

The strangeness quantum number "S" (not to be confused with spin) was noticed to go up and down along with particle mass. The higher the mass, the lower the strangeness (the more s quarks). Particles could be described with isospin projections (related to charge) and strangeness (mass) (see the uds nonet figures). As other quarks were discovered, new quantum numbers were made to have similar description of udc and udb nonets. Because only the u and d mass are similar, this description of particle mass and charge in terms of isospin and flavour quantum numbers only works well for the nonets made of one u, one d and one other quark and breaks down for the other nonets (for example ucb nonet). If the quarks all had the same mass, their behaviour would be called "symmetric", because they would all behave in exactly the same way with respect to the strong interaction. However, as quarks do not have the same mass, they do not interact in the same way (exactly like an electron placed in an electric field will accelerate more than a proton placed in the same field because of its lighter mass), and the symmetry is said to be broken.

It was noted that charge ("Q") was related to the isospin projection ("I"), the baryon number ("B") and flavour quantum numbers ("S", "C", "B"′, "T") by the Gell-Mann–Nishijima formula:

where "S", "C", "B"′, and "T" represent the strangeness, charm, bottomness and topness flavour quantum numbers respectively. They are related to the number of strange, charm, bottom, and top quarks and antiquark according to the relations:

meaning that the Gell-Mann–Nishijima formula is equivalent to the expression of charge in terms of quark content:

Mesons are classified into groups according to their isospin ("I"), total angular momentum ("J"), parity ("P"), G-parity ("G") or C-parity ("C") when applicable, and quark (q) content. The rules for classification are defined by the Particle Data Group, and are rather convoluted. The rules are presented below, in table form for simplicity.

Mesons are classified into types according to their spin configurations. Some specific configurations are given special names based on the mathematical properties of their spin configuration.

Flavourless mesons are mesons made of pair of quark and antiquarks of the same flavour (all their flavour quantum numbers are zero: "S" = 0, "C" = 0, "B"′ = 0, "T" = 0). The rules for flavourless mesons are:
In addition:

Flavoured mesons are mesons made of pair of quark and antiquarks of different flavours. The rules are simpler in this case: the main symbol depends on the heavier quark, the superscript depends on the charge, and the subscript (if any) depends on the lighter quark. In table form, they are:

In addition:

There is experimental evidence for particles that are hadrons (i.e., are composed of quarks) and are color-neutral with zero baryon number, and thus by conventional definition are mesons. Yet, these particles do not consist of a single quark/antiquark pair, as all the other conventional mesons discussed above do. A tentative category for these particles is exotic mesons.

There are at least five exotic meson resonances that have been experimentally confirmed to exist by two or more independent experiments. The most statistically significant of these is the Z(4430), discovered by the Belle experiment in 2007 and confirmed by LHCb in 2014. It is a candidate for being a tetraquark: a particle composed of two quarks and two antiquarks. See the main article above for other particle resonances that are candidates for being exotic mesons.





</doc>
<doc id="19871" url="https://en.wikipedia.org/wiki?curid=19871" title="Marvel Super Heroes (role-playing game)">
Marvel Super Heroes (role-playing game)

Marvel Super Heroes (MSHRPG) is a role playing game set in the Marvel Universe, first published by TSR as "" under license from Marvel Comics in 1984. In 1986, TSR published an expanded edition, entitled the "Marvel Superheroes Advanced Game". Jeff Grubb designed both editions, and Steve Winter wrote both editions. Both use the same game system.

The basic game was designed to let players assume the roles of superheroes from Marvel Comics, such as Spider-Man, Daredevil, Hulk, Captain America, the Fantastic Four, the X-Men, and 
others. 
The game was designed to be easy to understand, and the simplest version, found in the 16-page "Battle Book" of the Basic Set, contains a bare-bones combat system sufficient to resolve comic book style superheroic fights.

Most game situations are resolved by rolling percentile dice and comparing the results against a column of the colorful "Universal Results Table". The column used is determined by the attribute used; different tasks are resolved by reference to different attributes. All characters have seven basic attributes:

Fighting, which determines hit probability in and defense against hand-to-hand attacks.

Agility, which determines hit probability in and defense against ranged attacks, feats of agility vs. the environment, and similar acrobatics.

Strength, which determines damage inflicted by hand-to-hand attacks as well as the success of tasks such as grappling or the lifting and breaking of heavy objects.

Endurance, which determines resistance to physical damage (e.g., poison, disease, death) it also determined how long a character can fight and how fast a character could move at top speed by exerting themselves.

Reason, which determines the success of tasks relating to knowledge, puzzle-solving, and advanced technology.

Intuition, which determines the success of tasks relating to awareness, perception, and instinct.

Psyche, which determines the success of tasks relating to willpower, psionics, and magic.

Players sometimes refer to this set of attributes, or the game system as a whole, by the acronym "FASERIP". Attribute scores for the majority of characters range from 1 to 100, where normal human ability is Typical (6), and peak (non-superheroic) human ability is Excellent (20). However, the designers minimize use of the numerical figures, instead preferring adjectives in the Marvel Comics tradition, such as "Incredible" (scores from 36-45) and "Amazing" (46-62). A "Typical" (5-7) attribute has a 50% base chance for success at most tasks relating to that attribute. For example, a character with "Typical" fighting skill has a base chance of 50% to connect with a punch. As an attribute increases, the chance of success increases by about 5% per 10 points. Thus a character with an "Amazing" (50) attribute has a 75% chance of success at tasks relating to that attribute.

Beyond the seven attributes, characters possessed superpowers, such as Spider-Man's wall crawling, or Mister Fantastic's elasticity. The powers function on a mostly "ad hoc" basis, and thus each character's description gives considerable space to a description of how his or her powers work in the game.

Each character had an origin, which put ceilings on a character's abilities and superpowers. The origins included: Altered Humans (normal people who acquired powers, such as Spider-Man or the Fantastic Four), High-Tech Wonders (normal people whose powers come from devices, e.g., Iron Man), Mutants (persons born with superpowers, such as the X-Men), Robots (created beings such as the Vision and Ultron), and Aliens (a blanket term used to cover non-humans, including extra-dimensional beings such as Thor and Hercules).

The game also features a simple skill system, referred to as Talents. Talents have to be learned and cover a wide range of areas of knowledge from Archery to Zoology. A Talent raises a character's ability by one rank when attempting actions related to that Talent. For example, a character uses his Agility score when attempting ranged attacks. A character with an Agility of Excellent would normally roll on that column when attacking with a rifle. However, if the character has the "Guns" Talent, they would treat their Agility as the next higher power rank (Remarkable). The GM is free to determine if a character would be unable to attempt an action without the appropriate Talent (such as a character with no medical background attempting to make a pill that can cure a rare disease).

Characters also had two variable attributes: Resources and Popularity. These attributes were described using the same terms as the character's seven attributes ("Poor," "Amazing," "Unearthly," etc.). But unlike the seven physical and mental attributes which changed very slowly, if at all, Resources and Popularity could change very quickly.

The first of the variables, Resources, represented the character's wealth and ability to obtain goods or services. Rather than have the player keep track of how much money the character had in the bank or with him, the Advanced Game assumed the character had enough money coming in to cover his basic living expenses. The Resources ability was used when the character wished to purchase something out of the ordinary like a new car or house. For example, the referee might decide a character with Typical resources would probably be unable to purchase a brand new sports car, but with a Yellow Resources roll might be able to afford a used car in good condition. The game books note that a character's Resources score can change for a variety of reasons, such as winning the lottery or having a major business transaction go bad.

The second variable, Popularity, reflected how much the character was liked (or disliked) in the Marvel Universe. Popularity could be used to influence non-player characters. A superhero with a high rating, like Captain America (whose popularity is Unearthly-the highest most characters can achieve), might be able to use his Popularity to gain entrance to a club because the general population of the Marvel Universe admires him. If he were to try the same thing as his secret identity Steve Rogers (whose Popularity is only Typical), he would probably be unable to do it. Villains also had a Popularity score, which was usually negative (a bouncer might let Doctor Doom or Magneto into the aforementioned club simply out of fear). There were several ways Popularity could change. For example, if Doctor Doom defeated Spider-Man in front of the general public, Spidey's Popularity would go down for a short time. But if everyone's favorite web-slinger managed to foil one of Doctor Doom's plans and the word got out, he would enjoy a temporary Popularity boost. Since mutants were generally feared and distrusted in the Marvel Universe, these characters start with a Popularity of 0 and have a hard time improving this attribute.

The game was intended to be played using existing Marvel characters as the heroes. The and "Advanced Set" both contained fairly simple systems for creating original superheroes, based on random ability rolls (as in "Dungeons & Dragons"). In addition, the Basic Set Campaign Book also allowed players to create original heroes by simply describing the desired kind of hero, and working together with the GM to assign the appropriate abilities, powers, and talents.

"The Ultimate Powers Book", by David Edward Martin, expanded and organized the game's list of powers, making a fairly comprehensive survey of comic book-style super-powers. Players were given a wide variety of body types, secret origins, weaknesses, and powers. The "UPB" gave a much greater range to characters one could create. Additionally, the book suffered from editing problems and omissions; several errata and partial revisions were released in the pages of TSR's "Dragon" magazine in issue #122 "The Ultimate Addenda to the Ultimate Powers Book", issue #134 "The Ultimate Addenda's Addenda", issue #150 "Death Effects on Superheroes", and issue #151 "Son of the Ultimate Addenda".

The game's equivalent of experience points was "Karma", a pool of points initially determined as the sum of a character's three mental attributes (Reason, Intuition, and Psyche).

The basic system allowed players to increase their chances of success at most tasks by spending points of Karma. For example, a player who wanted to make sure he would hit a villain in a critical situation could spend however many Karma points were necessary to raise the dice roll to the desired result. Additional Karma points were distributed by the referee at the end of game sessions, typically as rewards for accomplishing heroic goals, such as defeating villains, saving innocents, and foiling crimes. Conversely, Karma could be lost for unheroic actions such as fleeing from a villain, or failing to stop a crime: in fact, in a notable departure from many RPGs (but strongly in keeping with the genre), all Karma was lost if a hero killed someone or allowed someone to die.

In the Advanced Game, Karma points could also be spent to permanently increase character attributes and powers (at a relatively moderate cost, ten times the attribute number raised, powers were steeper, at twenty times the number). The Karma system thus united two RPG mechanics—"Action" or "Hero" points (which allow players to control random outcomes) and character advancement (e.g., "experience points")—in one system. Though this system could frustrate both referees and players (the former because a player willing and able to spend Karma could effectively overcome any challenge at least once; the latter because advancement was slow compared with most other RPGs), it had the virtue of emulating two central features of super-hero comics, namely, that heroes almost always win, even in improbable circumstances, and that heroes' power levels remain mostly static. Furthermore, the system encouraged players to keep their characters' behavior to the equivalent concept of their alignment by giving an incentive to behave heroically and morally correct.

Marvel Superheroes was driven by two primary game mechanics: column shifts and colored results. Both essentially influenced the difficulty of an action.

A column shift is used when a character is attempting an exceptionally hard or easy action. A column shift to the left indicates a penalty, while a shift to the right indicates a bonus. For example, Reed Richards (Mr. Fantastic) has an Intuition of Excellent, making him significantly more perceptive than the average person whose Intuition is Typical (two ranks lower). The GM might determine that spotting a trap hidden beneath a few sticks and leaves will be fairly easy, and give the player running Mr. Fantastic a +1 column shift. His Intuition will be treated as Remarkable (the next column to the right). However, a trap buried underground might be considerably harder to spot, and the GM might give the player a -1 column shift penalty. In this case, Mr. Fantastic's Intuition will only be treated as Good (the column to the left).

The column for each ability is divided into four colors: white, green, yellow, and red. A white result is always a failure or unfavorable outcome. In most cases, getting a green result was all that was needed to succeed at a particular action. Yellow and red results usually indicated more favorable results that could knock back, stun, or even kill an opponent. However, the GM could determine that succeeding at an exceptionally hard task might require a yellow or red result.

Additional rules in the "Campaign Book" of the , and the subsequent Advanced Set, used the same game mechanic to resolve non-violent tasks. For example, if a superhero needs to figure out how to operate a piece of alien technology, the hero would have to succeed at a Reason roll, where the chance of success is modified by the complexity of the device.

The original Marvel Super Heroes game received extensive support from TSR, covering a wide variety of Marvel Comics characters and settings, including a "Gamer's Handbook of the Marvel Universe" patterned after Marvel's "Official Handbook of the Marvel Universe". MSH even received its own column in the (at the time) TSR-published gaming magazine, Dragon, called "The Marvel-phile", which usually spotlighted a character or group of characters that hadn't yet appeared in a published game product.

In the July-August 1984 edition of "Space Gamer" (No. 70), Allen Varney thought this game was only suited to younger players and Marvel fanatics, saying, "this is a respectable effort, and an excellent introductory game for a devoted Marvel fan aged 10 to 12; older, more experienced, or less devoted buyers will probably be disappointed. 'Nuff said." 

Pete Tamlyn reviewed "Marvel Super Heroes" for "Imagine" magazine, and stated that "this game has been produced in collaboration with Marvel and that opportunity itself is probably worth a new game release. However, "Marvel Superheroes" is not just another Superhero game. In many ways it is substantially different from other SHrpgs."

Marcus L. Rowland reviewed "Marvel Super Heroes" for "White Dwarf" #62, giving it an overall rating of 8 out of 10, and stated that "All in all, a useful system which is suitable for beginning players and referees, but should still suit experienced gamers."

Seven years later, Varney revisited the game in the August 1991 edition of "Dragon" (Issue #172), reviewing the new Basic Set edition that had just been released. While Varney appreciated that the game was designed for younger players, he felt that it failed to recreate the excitement of the comics. "This is the gravest flaw of this system and support line: its apathy about recreating the spirit of Marvel stories. In this new Basic Set edition... you couldn’t find a miracle if you used microscopic vision. Look at this set’s few elementary mini-scenarios: all fight scenes. The four-color grandeur and narrative magic in the best Marvel stories are absent. Is this a good introduction to role-playing?" Varney instead suggested "Toon" by Steve Jackson Games or "Ghostbusters" by West End Games as better role-playing alteratives for new and beginning young players.
In the 2007 book "", Steve Kenson commented that "it's a testament to the game's longevity that it still has enthusiastic fan support on the Internet and an active play community more than a decade after its last product was published. Even more so that it continues to set a standard by which new superhero roleplaying games are measured. Like modern comic book writers and artists following the greats of the Silver Age, modern RPG designers have a tough act to follow."


Before losing the Marvel license back to Marvel Comics, TSR published a different game using their SAGA System game engine, called the "Marvel Super Heroes Adventure Game". This version, written by Mike Selinker, was published in the late 1990s as a card-based version of the Marvel role-playing game (though a method of converting characters from the prior format to the SAGA System was included in the core rules). Though critically praised in various reviews at the time, it never reached a large market and has since faded into obscurity.

In 2003, after the gaming license had reverted to Marvel Comics, the "Marvel Universe Roleplaying Game" was published by Marvel Comics. This edition uses mechanics that are totally different from any previous versions, using a diceless game mechanic that incorporated a Karma-based resolution system of "stones" (or tokens) to represent character effort. Since its initial publication, a few additional supplements were published by Marvel Comics. However, Marvel stopped supporting the game a little over a year after its initial release, despite going through several printings of the core rulebook.

In August 2011, Margaret Weis Productions acquired the licence to publish an RPG based on Marvel superheroes, and "Marvel Heroic Roleplaying" was released beginning in 2012. Margaret Weis Productions, however, found that although the game was critically acclaimed, winning two Origins Awards, "Marvel Heroic Roleplaying: Civil War" "didn’t garner the level of sales necessary to sustain the rest of the line" so they brought the game to a close at the end of April 2013.


</doc>
<doc id="19873" url="https://en.wikipedia.org/wiki?curid=19873" title="Measure (mathematics)">
Measure (mathematics)

In mathematical analysis, a measure on a set is a systematic way to assign a number to each suitable subset of that set, intuitively interpreted as its size. In this sense, a measure is a generalization of the concepts of length, area, and volume. A particularly important example is the Lebesgue measure on a Euclidean space, which assigns the conventional length, area, and volume of Euclidean geometry to suitable subsets of the -dimensional Euclidean space . For instance, the Lebesgue measure of the interval in the real numbers is its length in the everyday sense of the word, specifically, 1.

Technically, a measure is a function that assigns a non-negative real number or to (certain) subsets of a set ("see" Definition below). It must further be countably additive: the measure of a 'large' subset that can be decomposed into a finite (or countably infinite) number of 'smaller' disjoint subsets is equal to the sum of the measures of the "smaller" subsets. In general, if one wants to associate a "consistent" size to "each" subset of a given set while satisfying the other axioms of a measure, one only finds trivial examples like the counting measure. This problem was resolved by defining measure only on a sub-collection of all subsets; the so-called "measurable" subsets, which are required to form a -algebra. This means that countable unions, countable intersections and complements of measurable subsets are measurable. Non-measurable sets in a Euclidean space, on which the Lebesgue measure cannot be defined consistently, are necessarily complicated in the sense of being badly mixed up with their complement. Indeed, their existence is a non-trivial consequence of the axiom of choice.

Measure theory was developed in successive stages during the late 19th and early 20th centuries by Émile Borel, Henri Lebesgue, Johann Radon, and Maurice Fréchet, among others. The main applications of measures are in the foundations of the Lebesgue integral, in Andrey Kolmogorov's axiomatisation of probability theory and in ergodic theory. In integration theory, specifying a measure allows one to define integrals on spaces more general than subsets of Euclidean space; moreover, the integral with respect to the Lebesgue measure on Euclidean spaces is more general and has a richer theory than its predecessor, the Riemann integral. Probability theory considers measures that assign to the whole set the size 1, and considers measurable subsets to be events whose probability is given by the measure. Ergodic theory considers measures that are invariant under, or arise naturally from, a dynamical system.

Let be a set and a -algebra over . A function from to the extended real number line is called a measure if it satisfies the following properties:


If at least one set formula_4 has finite measure, then the requirement that formula_1 is met automatically. Indeed, by countable additivity,
and therefore formula_7

If only the second and third conditions of the definition of measure above are met, and takes on at most one of the values , then is called a signed measure.

The pair is called a measurable space, the members of Σ are called measurable sets. If formula_8 and formula_9 are two measurable spaces, then a function formula_10 is called measurable if for every -measurable set formula_11, the inverse image is -measurable – i.e.: formula_12. In this setup, the composition of measurable functions is measurable, making the measurable spaces and measurable functions a category, with the measurable spaces as objects and the set of measurable functions as arrows. See also Measurable function#Term usage variations about another setup.

A triple is called a measure space. A probability measure is a measure with total measure one – i.e. . A probability space is a measure space with a probability measure.

For measure spaces that are also topological spaces various compatibility conditions can be placed for the measure and the topology. Most measures met in practice in analysis (and in many cases also in probability theory) are Radon measures. Radon measures have an alternative definition in terms of linear functionals on the locally convex space of continuous functions with compact support. This approach is taken by Bourbaki (2004) and a number of other sources. For more details, see the article on Radon measures.

Some important measures are listed here.


Other 'named' measures used in various theories include: Borel measure, Jordan measure, ergodic measure, Euler measure, Gaussian measure, Baire measure, Radon measure, Young measure, and Loeb measure.
In physics an example of a measure is spatial distribution of mass (see e.g., gravity potential), or another non-negative extensive property, conserved (see conservation law for a list of these) or not. Negative values lead to signed measures, see "generalizations" below.


Let be a measure.

If and are measurable sets with then

For any countable sequence of (not necessarily disjoint) measurable sets in Σ:

If are measurable sets and formula_15 for all , then the union of the sets is measurable, and

If are measurable sets and, for all , formula_17 then the intersection of the sets is measurable; furthermore, if at least one of the has finite measure, then

This property is false without the assumption that at least one of the has finite measure. For instance, for each , let , which all have infinite Lebesgue measure, but the intersection is empty.

A measure space is called finite if is a finite real number (rather than ∞). Nonzero finite measures are analogous to probability measures in the sense that any finite measure is proportional to the probability measure formula_19. A measure is called "σ-finite" if can be decomposed into a countable union of measurable sets of finite measure. Analogously, a set in a measure space is said to have a "σ-finite measure" if it is a countable union of sets with finite measure.

For example, the real numbers with the standard Lebesgue measure are σ-finite but not finite. Consider the closed intervals for all integers ; there are countably many such intervals, each has measure 1, and their union is the entire real line. Alternatively, consider the real numbers with the counting measure, which assigns to each finite set of reals the number of points in the set. This measure space is not σ-finite, because every set with finite measure contains only finitely many points, and it would take uncountably many such sets to cover the entire real line. The σ-finite measure spaces have some very convenient properties; σ-finiteness can be compared in this respect to the Lindelöf property of topological spaces. They can be also thought of as a vague generalization of the idea that a measure space may have 'uncountable measure'.

A measure is said to be s-finite if it is a countable sum of bounded measures. S-finite measures are more general than sigma-finite ones and have applications in the theory of stochastic processes.

A measurable set is called a "null set" if . A subset of a null set is called a "negligible set". A negligible set need not be measurable, but every measurable negligible set is automatically a null set. A measure is called "complete" if every negligible set is measurable.

A measure can be extended to a complete one by considering the σ-algebra of subsets which differ by a negligible set from a measurable set , that is, such that the symmetric difference of and is contained in a null set. One defines to equal .

Measures are required to be countably additive. However, the condition can be strengthened as follows.
For any set formula_20 and any set of nonnegative formula_21 define:
That is, we define the sum of the formula_23 to be the supremum of all the sums of finitely many of them.

A measure formula_24 on formula_25 is formula_26-additive if for any formula_27 and any family of disjoint sets formula_28 the following hold:
Note that the second condition is equivalent to the statement that the ideal of null sets is formula_26-complete.

If the axiom of choice is assumed to be true, it can be proved that not all subsets of Euclidean space are Lebesgue measurable; examples of such sets include the Vitali set, and the non-measurable sets postulated by the Hausdorff paradox and the Banach–Tarski paradox.

For certain purposes, it is useful to have a "measure" whose values are not restricted to the non-negative reals or infinity. For instance, a countably additive set function with values in the (signed) real numbers is called a "signed measure", while such a function with values in the complex numbers is called a "complex measure". Measures that take values in Banach spaces have been studied extensively. A measure that takes values in the set of self-adjoint projections on a Hilbert space is called a "projection-valued measure"; these are used in functional analysis for the spectral theorem. When it is necessary to distinguish the usual measures which take non-negative values from generalizations, the term positive measure is used. Positive measures are closed under conical combination but not general linear combination, while signed measures are the linear closure of positive measures.

Another generalization is the "finitely additive measure", also known as a content. This is the same as a measure except that instead of requiring "countable" additivity we require only "finite" additivity. Historically, this definition was used first. It turns out that in general, finitely additive measures are connected with notions such as Banach limits, the dual of "L" and the Stone–Čech compactification. All these are linked in one way or another to the axiom of choice. Contents remain useful in certain technical problems in geometric measure theory; this is the theory of Banach measures. 

A charge is a generalization in both directions: it is a finitely additive, signed measure.




</doc>
<doc id="19876" url="https://en.wikipedia.org/wiki?curid=19876" title="Motorcycle">
Motorcycle

A motorcycle, often called a motorbike, bike, or cycle, is a two-wheeled, or less commonly three-wheeled, motor vehicle. Motorcycle design varies greatly to suit a range of different purposes: long-distance travel, commuting, cruising, sport including racing, and off-road riding. Motorcycling is riding a motorcycle and related social activity such as joining a motorcycle club and attending motorcycle rallies.

The 1885 Daimler Reitwagen made by Gottlieb Daimler and Wilhelm Maybach in Germany was the first internal combustion, petroleum fueled motorcycle. In 1894, Hildebrand & Wolfmüller became the first series production motorcycle. 

In 2014, the three top motorcycle producers globally by volume were Honda (28%), Yamaha (17%) (both from Japan), and Hero MotoCorp (India). In developing countries, motorcycles are considered utilitarian due to lower prices and greater fuel economy. Of all the motorcycles in the world, 58% are in the Asia-Pacific and Southern and Eastern Asia regions, excluding car-centric Japan.

According to the US Department of Transportation, the number of fatalities per vehicle mile traveled was 37 times higher for motorcycles than for cars.

The term motorcycle has different legal definitions depending on jurisdiction (see ).

There are three major types of motorcycle: street, off-road, and dual purpose. Within these types, there are many sub-types of motorcycles for different purposes. There is often a racing counterpart to each type, such as road racing and street bikes, or motocross including dirt bikes.

Street bikes include cruisers, sportbikes, scooters and mopeds, and many other types. Off-road motorcycles include many types designed for dirt-oriented racing classes such as motocross and are not street legal in most areas. Dual purpose machines like the dual-sport style are made to go off-road but include features to make them legal and comfortable on the street as well.

Each configuration offers either specialised advantage or broad capability, and each design creates a different riding posture.

In some countries the use of pillions (rear seats) is restricted.

The first internal combustion, petroleum fueled motorcycle was the Daimler "Reitwagen". It was designed and built by the German inventors Gottlieb Daimler and Wilhelm Maybach in Bad Cannstatt, Germany in 1885. This vehicle was unlike either the safety bicycles or the boneshaker bicycles of the era in that it had zero degrees of steering axis angle and no fork offset, and thus did not use the principles of bicycle and motorcycle dynamics developed nearly 70 years earlier. Instead, it relied on two outrigger wheels to remain upright while turning.

The inventors called their invention the "Reitwagen" ("riding car"). It was designed as an expedient testbed for their new engine, rather than a true prototype vehicle.
The first commercial design for a self-propelled cycle was a three-wheel design called the Butler Petrol Cycle, conceived of Edward Butler in England in 1884. He exhibited his plans for the vehicle at the Stanley Cycle Show in London in 1884. The vehicle was built by the Merryweather Fire Engine company in Greenwich, in 1888.

The Butler Petrol Cycle was a three-wheeled vehicle, with the rear wheel directly driven by a , displacement, bore × stroke, flat twin four-stroke engine (with magneto ignition replaced by coil and battery) equipped with rotary valves and a float-fed carburettor (five years before Maybach) and Ackermann steering, all of which were state of the art at the time. Starting was by compressed air. The engine was liquid-cooled, with a radiator over the rear driving wheel. Speed was controlled by means of a throttle valve lever. No braking system was fitted; the vehicle was stopped by raising and lowering the rear driving wheel using a foot-operated lever; the weight of the machine was then borne by two small castor wheels. The driver was seated between the front wheels. It wasn't, however, a success, as Butler failed to find sufficient financial backing.

Many authorities have excluded steam powered, electric motorcycles or diesel-powered two-wheelers from the definition of a 'motorcycle', and credit the Daimler "Reitwagen" as the world's first motorcycle. Given the rapid rise in use of electric motorcycles worldwide, defining only internal-combustion powered two-wheelers as 'motorcycles' is increasingly problematic. The first (petroleum fueled) internal-combustion motorcycles, like the German "Reitwagen", were, however, also the first practical motorcycles.

If a two-wheeled vehicle with steam propulsion is considered a motorcycle, then the first motorcycles built seem to be the French Michaux-Perreaux steam velocipede which patent application was filled in December 1868, constructed around the same time as the American Roper steam velocipede, built by Sylvester H. Roper Roxbury, Massachusetts.
who demonstrated his machine at fairs and circuses in the eastern U.S. in 1867, Roper built about 10 steam cars and cycles from the 1860s until his death in 1896.

In 1894, Hildebrand & Wolfmüller became the first series production motorcycle, and the first to be called a motorcycle (). Excelsior Motor Company, originally a bicycle manufacturing company based in Coventry, England, began production of their first motorcycle model in 1896. The first production motorcycle in the US was the Orient-Aster, built by Charles Metz in 1898 at his factory in Waltham, Massachusetts.

In the early period of motorcycle history, many producers of bicycles adapted their designs to accommodate the new internal combustion engine. As the engines became more powerful and designs outgrew the bicycle origins, the number of motorcycle producers increased. Many of the nineteenth-century inventors who worked on early motorcycles often moved on to other inventions. Daimler and Roper, for example, both went on to develop automobiles.

At the end of the 19th century the first major mass-production firms were set up. In 1898, Triumph Motorcycles in England began producing motorbikes, and by 1903 it was producing over 500 bikes. Other British firms were Royal Enfield, Norton and Birmingham Small Arms Company who began motorbike production in 1899, 1902 and 1910, respectively. Indian began production in 1901 and Harley-Davidson was established two years later. By the outbreak of World War I, the largest motorcycle manufacturer in the world was Indian,
producing over 20,000 bikes per year.

During the First World War, motorbike production was greatly ramped up for the war effort to supply effective communications with front line troops. Messengers on horses were replaced with despatch riders on motorcycles carrying messages, performing reconnaissance and acting as a military police. American company Harley-Davidson was devoting over 50% of its factory output toward military contract by the end of the war. The British company Triumph Motorcycles sold more than 30,000 of its Triumph Type H model to allied forces during the war. With the rear wheel driven by a belt, the Model H was fitted with a air-cooled four-stroke single-cylinder engine. It was also the first Triumph without pedals.

The Model H in particular, is regarded by many as having been the first "modern motorcycle". Introduced in 1915 it had a 550 cc side-valve four-stroke engine with a three-speed gearbox and belt transmission. It was so popular with its users that it was nicknamed the "Trusty Triumph".

By 1920, Harley-Davidson was the largest manufacturer, with their motorcycles being sold by dealers in 67 countries.

Amongst many British motorcycle manufacturers, Chater-Lea with its twin-cylinder models followed by its large singles in the 1920s stood out. Initially, using converted a Woodmann-designed ohv Blackburne engine it became the first 350 cc to exceed 100 mph (160 km/h), recording 100.81 mph (162.24 km/h) over the flying kilometre during April 1924.[7] Later, Chater-Lea set a world record for the flying kilometre for 350 cc and 500 cc motorcycles at 102.9 mph (165.6 km/h) for the firm. Chater-Lea produced variants of these world-beating sports models and became popular among racers at the Isle of Man TT. Today, the firm is probably best remembered for its long term contract to manufacture and supply AA Patrol motorcycles and sidecars.

By the late 1920s or early 1930s, DKW in Germany took over as the largest manufacturer.

In the 1950s, streamlining began to play an increasing part in the development of racing motorcycles and the "dustbin fairing" held out the possibility of radical changes to motorcycle design. NSU and Moto Guzzi were in the vanguard of this development, both producing very radical designs well ahead of their time.
NSU produced the most advanced design, but after the deaths of four NSU riders in the 1954–1956 seasons, they abandoned further development and quit Grand Prix motorcycle racing.

Moto Guzzi produced competitive race machines, and until the end of 1957 had a succession of victories. The following year, 1958, full enclosure fairings were banned from racing by the FIM in the light of the safety concerns.

From the 1960s through the 1990s, small two-stroke motorcycles were popular worldwide, partly as a result of East German MZs Walter Kaaden's engine work in the 1950s.

In the 21st century, the motorcycle industry is mainly dominated by the Indian motorcycle industry and by Japanese motorcycle companies. In addition to the large capacity motorcycles, there is a large market in smaller capacity (less than 300 cc) motorcycles, mostly concentrated in Asian and African countries and produced in China and India. A Japanese example is the 1958 Honda Super Cub, which went on to become the biggest selling vehicle of all time, with its 60 millionth unit produced in April 2008.
Today, this area is dominated by mostly with Hero MotoCorp emerging as the world's largest manufacturer of two wheelers. Its Splendor model has sold more than 8.5 million to date. Other major producers are Bajaj and TVS Motors.

Motorcycle construction is the engineering, manufacturing, and assembly of components and systems for a motorcycle which results in the performance, cost, and aesthetics desired by the designer. With some exceptions, construction of modern mass-produced motorcycles has standardised on a steel or aluminium frame, telescopic forks holding the front wheel, and disc brakes. Some other body parts, designed for either aesthetic or performance reasons may be added. A petrol-powered engine typically consisting of between one and four cylinders (and less commonly, up to eight cylinders) coupled to a manual five- or six-speed sequential transmission drives the swingarm-mounted rear wheel by a chain, driveshaft, or belt. The repair can be done using a Motorcycle lift.

Motorcycle fuel economy varies greatly with engine displacement and riding style. A streamlined, fully faired Matzu Matsuzawa Honda XL125 achieved in the Craig Vetter Fuel Economy Challenge "on real highways in real conditions."
Due to low engine displacements (), and high power-to-mass ratios, motorcycles offer good fuel economy. Under conditions of fuel scarcity like 1950s Britain and modern developing nations, motorcycles claim large shares of the vehicle market.

Very high fuel economy equivalents are often derived by electric motorcycles. Electric motorcycles are nearly silent, zero-emission electric motor-driven vehicles. Operating range and top speed are limited by battery technology. Fuel cells and petroleum-electric hybrids are also under development to extend the range and improve performance of the electric drive system.

A 2013 survey of 4,424 readers of the US "Consumer Reports" magazine collected reliability data on 4,680 motorcycles purchased new from 2009 to 2012. The most common problem areas were accessories, brakes, electrical (including starters, charging, ignition), and fuel systems, and the types of motorcycles with the greatest problems were touring, off-road/dual sport, sport-touring, and cruisers. There were not enough sport bikes in the survey for a statistically significant conclusion, though the data hinted at reliability as good as cruisers. These results may be partially explained by accessories including such equipment as fairings, luggage, and auxiliary lighting, which are frequently added to touring, adventure touring/dual sport and sport touring bikes. Trouble with fuel systems is often the result of improper winter storage, and brake problems may also be due to poor maintenance. Of the five brands with enough data to draw conclusions, Honda, Kawasaki and Yamaha were statistically tied, with 11 to 14% of those bikes in the survey experiencing major repairs. Harley-Davidsons had a rate of 24%, while BMWs did worse, with 30% of those needing major repairs. There were not enough Triumph and Suzuki motorcycles surveyed for a statistically sound conclusion, though it appeared Suzukis were as reliable as the other three Japanese brands while Triumphs were comparable to Harley-Davidson and BMW. Three fourths of the repairs in the survey cost less than US$200 and two thirds of the motorcycles were repaired in less than two days. In spite of their relatively worse reliability in this survey, Harley-Davidson and BMW owners showed the greatest owner satisfaction, and three-fourths of them said they would buy the same bike again, followed by 72% of Honda owners and 60 to 63% of Kawasaki and Yamaha owners.

Different types of motorcycles have different dynamics and these play a role in how a motorcycle performs in given conditions. For example, one with a longer wheelbase provides the feeling of more stability by responding less to disturbances. Motorcycle tyres have a large influence over handling.

Motorcycles must be leaned in order to make turns. This lean is induced by the method known as countersteering, in which the rider momentarily steers the handlebars in the direction opposite of the desired turn. This practice is counterintuitive and therefore often confusing to novices and even many experienced motorcyclists.

With such short wheelbase, motorcycles can generate enough torque at the rear wheel, and enough stopping force at the front wheel, to lift the opposite wheel off the road. These actions, if performed on purpose, are known as wheelies and stoppies (or endos) respectively.

Various features and accessories may be attached to a motorcycle either as OEM (factory-fitted) or aftermarket. Such accessories are selected by the owner to enhance the motorcycle's appearance, safety, performance, or comfort, and may include anything from mobile electronics to sidecars and trailers.


Motorcycles have a higher rate of fatal accidents than automobiles or trucks and buses. United States Department of Transportation data for 2005 from the Fatality Analysis Reporting System show that for passenger cars, 18.62 fatal crashes occur per 100,000 registered vehicles. For motorcycles this figure is higher at 75.19 per 100,000 registered vehicles four times higher than for cars.
The same data shows that 1.56 fatalities occur per 100 million vehicle miles travelled for passenger cars, whereas for motorcycles the figure is 43.47 which is 28 times higher than for cars (37 times more deaths per mile travelled in 2007).
Furthermore, for motorcycles the accident rates have increased significantly since the end of the 1990s, while the rates have dropped for passenger cars.

The most common configuration of motorcycle accidents in the United States is when a motorist pulls out or turns in front of a motorcyclist, violating their right-of-way. This is sometimes called a , an acronym formed from the motorists' common response of "Sorry mate, I didn't see you".
Motorcyclists can anticipate and avoid some of these crashes with proper training, increasing their visibility to other traffic, keeping to the speed limits, and not consuming alcohol or other drugs before riding.
The United Kingdom has several organisations dedicated to improving motorcycle safety by providing advanced rider training beyond what is necessary to pass the basic motorcycle licence test. These include the Institute of Advanced Motorists (IAM) and the Royal Society for the Prevention of Accidents (RoSPA). Along with increased personal safety, riders with these advanced qualifications may benefit from reduced insurance costs 

In South Africa, the Think Bike campaign is dedicated to increasing both motorcycle safety and the awareness of motorcycles on the country's roads. The campaign, while strongest in the Gauteng province, has representation in Western Cape, KwaZulu Natal and the Free State. It has dozens of trained marshals available for various events such as cycle races and is deeply involved in numerous other projects such as the annual Motorcycle Toy Run.
Motorcycle safety education is offered throughout the United States by organisations ranging from state agencies to non-profit organisations to corporations. Most states use the courses designed by the Motorcycle Safety Foundation (MSF), while Oregon and Idaho developed their own. All of the training programs include a Basic Rider Course, an Intermediate Rider Course and an Advanced Rider Course.

In Ireland, since 2010, in the UK and some Australian jurisdictions, such as Victoria, New South Wales,
the Australian Capital Territory, Tasmania
and the Northern Territory, it is compulsory to complete a basic rider training course before being issued a Learners Licence, after which they can ride on public roads.

In Canada, motorcycle rider training is compulsory in Quebec and Manitoba only, but all provinces and territories have graduated licence programs which place restrictions on new drivers until they have gained experience. Eligibility for a full motorcycle licence or endorsement for completing a Motorcycle Safety course varies by province. Without the Motorcycle Safety Course the chance of getting insurance for the motorcycle is very low. The Canada Safety Council, a non-profit safety organisation, offers the Gearing Up program across Canada and is endorsed by the Motorcycle and Moped Industry Council. Training course graduates may qualify for reduced insurance premiums.

The motorcyclist's riding position depends on rider body-geometry (anthropometry) combined with the geometry of the motorcycle itself. These factors create a set of three basic postures.




Factors of a motorcycle's ergonomic geometry that determine the seating posture include the height, angle and location of footpegs, seat and handlebars. Factors in a rider's physical geometry that contribute to seating posture include torso, arm, thigh and leg length, and overall rider height.

A motorcycle is broadly defined by law in most countries for the purposes of registration, taxation and rider licensing as a powered two-wheel motor vehicle. Most countries distinguish between mopeds of 49 cc and the more powerful, larger vehicles (scooters do not count as a separate category). Many jurisdictions include some forms of three-wheeled cars as motorcycles.

Motorcycles and scooters' low fuel consumption has attracted interest in the United States from environmentalists and those affected by increased fuel prices.
Piaggio Group Americas supported this interest with the launch of a "Vespanomics" website and platform, claiming lower per-mile carbon emissions of 0.4 lb/mile (113 g/km) less than the average car, a 65% reduction, and better fuel economy.

However, a motorcycle's exhaust emissions may contain 10–20 times more oxides of nitrogen (NOx), carbon monoxide, and unburned hydrocarbons than exhaust from a similar-year passenger car or SUV.
This is because many motorcycles lack a catalytic converter, and the emission standard is much more permissive for motorcycles than for other vehicles. While catalytic converters have been installed in most gasoline-powered cars and trucks since 1975 in the United States, they can present fitment and heat difficulties in motorcycle applications. 

United States Environmental Protection Agency 2007 certification result reports for all vehicles versus on highway motorcycles (which also includes scooters), the average certified emissions level for 12,327 vehicles tested was 0.734. The average "Nox+Co End-Of-Useful-Life-Emissions" for 3,863 motorcycles tested was 0.8531. 54% of the tested 2007-model motorcycles were equipped with a catalytic converter.

The following table shows maximum acceptable legal emissions of the combination of hydrocarbons, oxides of nitrogen, and carbon monoxide for new motorcycles sold in the United States with 280 cc or greater piston displacement.

The maximum acceptable legal emissions of hydrocarbon and carbon monoxide for new Class I and II motorcycles (50 cc–169 cc and 170 cc–279 cc respectively) sold in the United States are as follows:
European emission standards for motorcycles are similar to those for cars. New motorcycles must meet Euro 4 standards,
while cars must meet Euro 6D-temp standards. Motorcycle emission controls are being updated and it has been proposed to update to Euro 5 in 2020.


</doc>
<doc id="19877" url="https://en.wikipedia.org/wiki?curid=19877" title="Map">
Map

A map is a symbolic depiction emphasizing relationships between elements of some space, such as objects, regions, or themes.

Many maps are static, fixed to paper or some other durable medium, while others are dynamic or interactive. Although most commonly used to depict geography, maps may represent any space, real or fictional, without regard to context or scale, such as in brain mapping, DNA mapping, or computer network topology mapping. The space being mapped may be two dimensional, such as the surface of the earth, three dimensional, such as the interior of the earth, or even more abstract spaces of any dimension, such as arise in modeling phenomena having many independent variables.

Although the earliest maps known are of the heavens, geographic maps of territory have a very long tradition and exist from ancient times. The word "map" comes from the medieval Latin "Mappa mundi", wherein "mappa" meant napkin or cloth and "mundi" the world. Thus, "map" became a shortened term referring to a two-dimensional representation of the surface of the world.

Cartography or "map-making" is the study and practice of crafting representations of the Earth upon a flat surface (see History of cartography), and one who makes maps is called a cartographer.

Road maps are perhaps the most widely used maps today, and form a subset of navigational maps, which also include aeronautical and nautical charts, railroad network maps, and hiking and bicycling maps. In terms of quantity, the largest number of drawn map sheets is probably made up by local surveys, carried out by municipalities, utilities, tax assessors, emergency services providers, and other local agencies. Many national surveying projects have been carried out by the military, such as the British Ordnance Survey: a civilian government agency, internationally renowned for its comprehensively detailed work.

In addition to location information, maps may also be used to portray contour lines indicating constant values of elevation, temperature, rainfall, etc.

The orientation of a map is the relationship between the directions on the map and the corresponding compass directions in reality. The word "orient" is derived from Latin , meaning east. In the Middle Ages many maps, including the T and O maps, were drawn with east at the top (meaning that the direction "up" on the map corresponds to East on the compass). The most common cartographic convention, is that north is at the top of a map.

Maps not oriented with north at the top:

Many maps are drawn to a scale expressed as a ratio, such as 1:10,000, which means that 1 unit of measurement on the map corresponds to 10,000 of that same unit on the ground. The scale statement can be accurate when the region mapped is small enough for the curvature of the Earth to be neglected, such as a city map. Mapping larger regions, where curvature cannot be ignored, requires projections to map from the curved surface of the Earth to the plane. The impossibility of flattening the sphere to the plane without distortion means that the map cannot have constant scale. Rather, on most projections the best that can be attained is accurate scale along one or two paths on the projection. Because scale differs everywhere, it can only be measured meaningfully as point scale per location. Most maps strive to keep point scale variation within narrow bounds. Although the scale statement is nominal it is usually accurate enough for most purposes unless the map covers a large fraction of the earth. At the scope of a world map, scale as a single number is practically meaningless throughout most of the map. Instead, it usually refers to the scale along the equator.
Some maps, called cartograms, have the scale deliberately distorted to reflect information other than land area or distance. For example, this map (at the right) of Europe has been distorted to show population distribution, while the rough shape of the continent is still discernible.

Another example of distorted scale is the famous London Underground map. The basic geographical structure is respected but the tube lines (and the River Thames) are smoothed to clarify the relationships between stations. Near the center of the map stations are spaced out more than near the edges of map.

Further inaccuracies may be deliberate. For example, cartographers may simply omit military installations or remove features solely in order to enhance the clarity of the map. For example, a road map may not show railroads, smaller waterways or other prominent non-road objects, and even if it does, it may show them less clearly (e.g. dashed or dotted lines/outlines) than the main roads. Known as decluttering, the practice makes the subject matter that the user is interested in easier to read, usually without sacrificing overall accuracy. Software-based maps often allow the user to toggle decluttering between ON, OFF and AUTO as needed. In AUTO the degree of decluttering is adjusted as the user changes the scale being displayed.

Geographic maps use a projection to translate the three-dimensional real surface of the geoid to a two-dimensional picture. Projection always distorts the surface. There are many ways to apportion the distortion, and so there are many map projections. Which projection to use depends on the purpose of the map.

The various features shown on a map are represented by conventional signs or symbols. For example, colors can be used to indicate a classification of roads. Those signs are usually explained in the margin of the map, or on a separately published characteristic sheet.

Some cartographers prefer to make the map cover practically the entire screen or sheet of paper, leaving no room "outside" the map for information about the map as a whole.
These cartographers typically place such information in an otherwise "blank" region "inside" the mapcartouche, map legend, title, compass rose, bar scale, etc.
In particular, some maps contain smaller "sub-maps" in otherwise blank regions—often one at a much smaller scale showing the whole globe and where the whole map fits on that globe, and a few showing "regions of interest" at a larger scale in order to show details that wouldn't otherwise fit.
Occasionally sub-maps use the same scale as the large map—a few maps of the contiguous United States include a sub-map to the same scale for each of the two non-contiguous states.

The design and production of maps is a craft that has developed over thousands of years, from clay tablets to Geographic information systems. As a form of Design, particularly closely related to Graphic design, map making incorporates scientific knowledge about how maps are used, integrated with principles of artistic expression, to create a product that is aesthetically attractive, carries an aura of authority, and functionally serves a particular purpose for an intended audience.

Designing a map involves bringing together a number of elements and making a large number of decisions. The elements of design fall into several broad topics, each of which has its own theory, its own research agenda, and its own best practices. That said, there are synergistic effects between these elements, meaning that the overall design process is not just working on each element one at a time, but an iterative feedback process of adjusting each to achieve the desired gestalt.


Maps of the world or large areas are often either 'political' or 'physical'. The most important purpose of the political map is to show territorial borders; the purpose of the physical is to show features of geography such as mountains, soil type or land use including infrastructure such as roads, railroads and buildings. Topographic maps show elevations and relief with contour lines or shading. Geological maps show not only the physical surface, but characteristics of the underlying rock, fault lines, and subsurface structures.

From the last quarter of the 20th century, the indispensable tool of the cartographer has been the computer. Much of cartography, especially at the data-gathering survey level, has been subsumed by Geographic Information Systems (GIS). The functionality of maps has been greatly advanced by technology simplifying the superimposition of spatially located variables onto existing geographical maps. Having local information such as rainfall level, distribution of wildlife, or demographic data integrated within the map allows more efficient analysis and better decision making. In the pre-electronic age such superimposition of data led Dr. John Snow to identify the location of an outbreak of cholera. Today, it is used by agencies of the human kind, as diverse as wildlife conservationists and militaries around the world.

Even when GIS is not involved, most cartographers now use a variety of computer graphics programs to generate new maps.

Interactive, computerised maps are commercially available, allowing users to "zoom in" or "zoom out" (respectively meaning to increase or decrease the scale), sometimes by replacing one map with another of different scale, centered where possible on the same point. In-car global navigation satellite systems are computerised maps with route-planning and advice facilities which monitor the user's position with the help of satellites. From the computer scientist's point of view, zooming in entails one or a combination of:


For example:

"See also: Webpage (Graphics), PDF (Layers), MapQuest, Google Maps, Google Earth, OpenStreetMap or Yahoo! Maps."

The maps that reflect the territorial distribution of climatic conditions based on the results of long-term observations are called climatic maps. These maps can be compiled both for individual climatic features (temperature, precipitation, humidity) and for combinations of them at the earth's surface and in the upper layers of the atmosphere. Climatic maps show climatic features across a large region and permit values of climatic features to be compared in different parts of the region. When generating the map, interpolation can be used to synthesize values where there are no measurements, under the assumption that conditions change smoothly.

Climatic maps generally apply to individual months and to the year as a whole, sometimes to the four seasons, to the growing period, and so forth. On maps compiled from the observations of ground meteorological stations, atmospheric pressure is converted to sea level. Air temperature maps are compiled both from the actual values observed on the surface of the earth and from values converted to sea level. The pressure field in free atmosphere is represented either by maps of the distribution of pressure at different standard altitudes—for example, at every kilometer above sea level—or by maps of baric topography on which altitudes (more precisely geopotentials) of the main isobaric surfaces (for example, 900, 800, and 700 millibars) counted off from sea level are plotted. The temperature, humidity, and wind on aeroclimatic maps may apply either to standard altitudes or to the main isobaric surfaces.

Isolines are drawn on maps of such climatic features as the long-term mean values (of atmospheric pressure, temperature, humidity, total precipitation, and so forth) to connect points with equal values of the feature in question—for example, isobars for pressure, isotherms for temperature, and isohyets for precipitation. Isoamplitudes are drawn on maps of amplitudes (for example, annual amplitudes of air temperature—that is, the differences between the mean temperatures of the warmest and coldest month). Isanomals are drawn on maps of anomalies (for example, deviations of the mean temperature of each place from the mean temperature of the entire latitudinal zone). Isolines of frequency are drawn on maps showing the frequency of a particular phenomenon (for example, annual number of days with a thunderstorm or snow cover). Isochrones are drawn on maps showing the dates of onset of a given phenomenon (for example, the first frost and appearance or disappearance of the snow cover) or the date of a particular value of a meteorological element in the course of a year (for example, passing of the mean daily air temperature through zero). Isolines of the mean numerical value of wind velocity or isotachs are drawn on wind maps (charts); the wind resultants and directions of prevailing winds are indicated by arrows of different length or arrows with different plumes; lines of flow are often drawn. Maps of the zonal and meridional components of wind are frequently compiled for the free atmosphere. Atmospheric pressure and wind are usually combined on climatic maps. Wind roses, curves showing the distribution of other meteorological elements, diagrams of the annual course of elements at individual stations, and the like are also plotted on climatic maps.

Maps of climatic regionalization, that is, division of the earth's surface into climatic zones and regions according to some classification of climates, are a special kind of climatic map.

Climatic maps are often incorporated into climatic atlases of varying geographic range (globe, hemispheres, continents, countries, oceans) or included in comprehensive atlases. Besides general climatic maps, applied climatic maps and atlases have great practical value. Aeroclimatic maps, aeroclimatic atlases, and agroclimatic maps are the most numerous.

Maps exist of the Solar System, and other cosmological features such as star maps. In addition maps of other bodies such as the Moon and other planets are technically not "geo"graphical maps.

Diagrams such as schematic diagrams and Gantt charts and treemaps display logical relationships between items, rather than geographical relationships. Topological in nature, only the connectivity is significant. The London Underground map and similar subway maps around the world are a common example of these maps.

General-purpose maps provide many types of information on one map. Most atlas maps, wall maps, and road maps fall into this category. The following are some features that might be shown on general-purpose maps: bodies of water, roads, railway lines, parks, elevations, towns and cities, political boundaries, latitude and longitude, national and provincial parks. These maps give a broad understanding of location and features of an area. The reader may gain an understanding of the type of landscape, the location of urban places, and the location of major transportation routes all at once.



Some countries required that all published maps represent their national claims regarding border disputes. For example:

In 2010, the People's Republic of China began requiring that all online maps served from within China be hosted there, making them subject to Chinese laws.









</doc>
<doc id="19881" url="https://en.wikipedia.org/wiki?curid=19881" title="Management">
Management

Management (or managing) is the administration of an organization, whether it is a business, a not-for-profit organization, or government body. Management includes the activities of setting the strategy of an organization and coordinating the efforts of its employees (or of volunteers) to accomplish its objectives through the application of available resources, such as financial, natural, technological, and human resources. The term "management" may also refer to those people who manage an organization - individually: managers.

Social scientists study management as an academic discipline, investigating areas such as social organization and organizational leadership. Some people study management at colleges or universities; major degrees in management include the Bachelor of Commerce (B.Com.) Bachelor of Business Administration (BBA.) Master of Business Administration (MBA.) Master in Management (MScM or MIM) and, for the public sector, the Master of Public Administration (MPA) degree. Individuals who aim to become management specialists or experts, management researchers, or professors may complete the Doctor of Management (DM), the Doctor of Business Administration (DBA), or the PhD in Business Administration or Management. There has recently been a movement for evidence-based management.

Larger organizations generally have three levels of managers, which are typically organized in a hierarchical, pyramid structure:

In smaller organizations, a manager may have a much wider scope and may perform several roles or even all of the roles commonly observed in a large organization.

Views on the definition and scope of management include:

Management involves identifying the mission, objective, procedures, rules and manipulation
of the human capital of an enterprise to contribute to the success of the enterprise. This implies effective communication: an enterprise environment (as opposed to a physical or mechanical mechanism) implies human motivation and implies some sort of successful progress or system outcome. As such, management is not the manipulation of a mechanism (machine or automated program), not the herding of animals, and can occur either in a legal or in an illegal enterprise or environment. From an individual's perspective, management does not need to be seen solely from an enterprise point of view, because management is an essential function in improving one's life and relationships. Management is therefore everywhere and it has a wider range of application. Based on this, management must have humans. Communication and a positive endeavor are two main aspects of it either through enterprise or through independent pursuit. Plans, measurements, motivational psychological tools, goals, and economic measures (profit, etc.) may or may not be necessary components for there to be management. At first, one views management functionally, such as measuring quantity, adjusting plans, meeting goals. This applies even in situations where planning does not take place. From this perspective, Henri Fayol (1841–1925)
considers management to consist of five functions:


In another way of thinking, Mary Parker Follett (1868–1933), allegedly defined management as "the art of getting things done through people".
She described management as philosophy.

Critics, however, find this definition useful but far too narrow. The phrase "management is what managers do" occurs widely,
suggesting the difficulty of defining management without circularity, the shifting nature of definitions and the connection of managerial practices with the existence of a managerial cadre or of a class.

One habit of thought regards management as equivalent to "business administration" and thus excludes management in places outside commerce, as for example in charities and in the public sector. More broadly, every organization must "manage" its work, people, processes, technology, etc. to maximize effectiveness. Nonetheless, many people refer to university departments that teach management as "business schools". Some such institutions (such as the Harvard Business School) use that name, while others (such as the Yale School of Management) employ the broader term "management".

English-speakers may also use the term "management" or "the management" as a collective word describing the managers of an organization, for example of a corporation.
Historically this use of the term often contrasted with the term "labor" – referring to those being managed.

But in the present era the concept of management is identified in the wide areas and its frontiers have been pushed to a broader range. Apart from profitable organizations even non-profitable organizations (NGOs) apply management concepts. The concept and its uses are not constrained. Management on the whole is the process of planning, organizing, coordinating, leading
and controlling.

In profitable organizations, management's primary function is the satisfaction of a range of stakeholders. This typically involves making a profit (for the shareholders), creating valued products at a reasonable cost (for customers), and providing great employment opportunities for employees. In nonprofit management, add the importance of keeping the faith of donors. In most models of management and governance, shareholders vote for the board of directors, and the board then hires senior management. Some organizations have experimented with other methods (such as employee-voting models) of selecting or reviewing managers, but this is rare.

Some see management as a late-modern (in the sense of late modernity) conceptualization. On those terms it cannot have a pre-modern history – only harbingers (such as stewards). Others, however, detect management-like thought among ancient Sumerian traders and the builders of the pyramids of ancient Egypt. Slave-owners through the centuries faced the problems of exploiting/motivating a dependent but sometimes unenthusiastic or recalcitrant workforce, but many pre-industrial enterprises, given their small scale, did not feel compelled to face the issues of management systematically. However, innovations such as the spread of Hindu numerals (5th to 15th centuries) and the codification of double-entry book-keeping (1494) provided tools for management assessment, planning and control.


With the changing workplaces of industrial revolutions in the 18th and 19th centuries, military theory and practice contributed approaches to managing the newly popular factories.

Given the scale of most commercial operations and the lack of mechanized record-keeping and recording before the industrial revolution, it made sense for most owners of enterprises in those times to carry out management functions by and for themselves. But with growing size and complexity of organizations, a distinction between owners (individuals, industrial dynasties or groups of shareholders) and day-to-day managers (independent specialists in planning and control) gradually became more common.

The English verb "manage" comes from the Italian "maneggiare" (to handle, especially tools or a horse), which derives from the two Latin words "manus" (hand) and "agere" (to act). The French word for housekeeping, "ménagerie", derived from "ménager" ("to keep house"; compare "ménage" for "household"), also encompasses taking care of domestic animals. "Ménagerie" is the French translation of Xenophon's famous book "Oeconomicus" () on household matters and husbandry. The French word "mesnagement" (or "ménagement") influenced the semantic development of the English word "management" in the 17th and 18th centuries.

Management (according to some definitions) has existed for millennia, and several writers have produced background works that have contributed to modern management theories. Some theorists have cited as providing lessons for civilian managers. For example, Chinese general Sun Tzu in his 6th-century BC work "The Art of War" recommends (when re-phrased in modern terminology) being aware of and acting on strengths and weaknesses of both a manager's organization and a foe's. The writings of influential Chinese Legalist philosopher Shen Buhai may be considered to embody a rare premodern example of abstract theory of administration.

Various ancient and medieval civilizations produced "mirrors for princes" books, which aimed to advise new monarchs on how to govern. Plato described job specialization in 350 BC, and Alfarabi listed several leadership traits in AD 900. Other examples include the Indian "Arthashastra" by Chanakya (written around 300 BC), and "The Prince" by Italian author
Niccolò Machiavelli (c. 1515).

Written in 1776 by Adam Smith, a Scottish moral philosopher, "The Wealth of Nations" discussed efficient organization of work through division of labour.
Smith described how changes in processes could boost productivity in the manufacture of pins. While individuals could produce 200 pins per day, Smith analyzed the steps involved in manufacture and, with 10 specialists, enabled production of 48,000 pins per day.

Classical economists such as Adam Smith (1723–1790) and John Stuart Mill (1806–1873) provided a theoretical background to resource allocation, production (economics), and pricing issues. About the same time, innovators like Eli Whitney (1765–1825), James Watt (1736–1819), and Matthew Boulton (1728–1809) developed elements of technical production such as standardization, quality-control procedures, cost-accounting, interchangeability of parts, and work-planning. Many of these aspects of management existed in the pre-1861 slave-based sector of the US economy. That environment saw 4 million people, as the contemporary usages had it, "managed" in profitable quasi-mass production.

Salaried managers as an identifiable group first became prominent in the late 19th century.

By about 1900 one finds managers trying to place their theories on what they regarded as a thoroughly scientific basis (see scientism for perceived limitations of this belief). Examples include Henry R. Towne's "Science of management" in the 1890s, Frederick Winslow Taylor's "The Principles of Scientific Management" (1911), Lillian Gilbreth's "Psychology of Management" (1914), Frank and Lillian Gilbreth's "Applied motion study" (1917), and Henry L. Gantt's charts (1910s). J. Duncan wrote the first college management-textbook in 1911. In 1912 Yoichi Ueno introduced Taylorism to Japan and became the first management consultant of the "Japanese-management style". His son Ichiro Ueno pioneered Japanese quality assurance.

The first comprehensive theories of management appeared around 1920. The Harvard Business School offered the first Master of Business Administration degree (MBA) in 1921. People like Henri Fayol (1841–1925) and Alexander Church (1866–1936) described the various branches of management and their inter-relationships. In the early-20th century, people like Ordway Tead (1891–1973), Walter Scott (1869–1955) and J. Mooney applied the principles of psychology to management. Other writers, such as Elton Mayo (1880–1949), Mary Parker Follett (1868–1933), Chester Barnard (1886–1961), Max Weber (1864–1920), who saw what he called the "administrator" as bureaucrat, Rensis Likert (1903–1981), and Chris Argyris (born 1923) approached the phenomenon of management from a sociological perspective.

Peter Drucker (1909–2005) wrote one of the earliest books on applied management: "Concept of the Corporation" (published in 1946). It resulted from Alfred Sloan (chairman of General Motors until 1956) commissioning a study of the organisation. Drucker went on to write 39 books, many in the same vein.

H. Dodge, Ronald Fisher (1890–1962), and Thornton C. Fry introduced statistical techniques into management-studies. In the 1940s, Patrick Blackett worked in the development of the applied-mathematics science of operations research, initially for military operations. Operations research, sometimes known as "management science" (but distinct from Taylor's scientific management), attempts to take a scientific approach to solving decision-problems, and can apply directly to multiple management problems, particularly in the areas of logistics and operations.

Some of the more developments include the Theory of Constraints, management by objectives, reengineering, Six Sigma, the Viable system model, and various information-technology-driven theories such as agile software development, as well as group-management theories such as Cog's Ladder.

As the general recognition of managers as a class solidified during the 20th century and gave perceived practitioners of the art/science of management a certain amount of prestige, so the way opened for popularised systems of management ideas to peddle their wares. In this context many management fads may have had more to do with pop psychology than with scientific theories of management.

Business management includes the following branches:


In the 21st century observers find it increasingly difficult to subdivide management into functional categories in this way. More and more processes simultaneously involve several categories. Instead, one tends to think in terms of the various processes, tasks, and objects subject to management.

Branches of management theory also exist relating to nonprofits and to government: such as public administration, public management, and educational management. Further, management programs related to civil-society organizations have also spawned programs in nonprofit management and social entrepreneurship.

Note that many of the assumptions made by management have come under attack from business-ethics viewpoints, critical management studies, and anti-corporate activism.

As one consequence, workplace democracy (sometimes referred to as Workers' self-management) has become both more common and more advocated, in some places distributing all management functions among workers, each of whom takes on a portion of the work. However, these models predate any current political issue, and may occur more naturally than does a command hierarchy. All management embraces to some degree a democratic principle—in that in the long term, the majority of workers must support management. Otherwise, they leave to find other work or go on strike. Despite the move toward workplace democracy, command-and-control organization structures remain commonplace as "de facto" organization structures. Indeed, the entrenched nature of command-and-control is evident in the way that recent layoffs have been conducted with management ranks affected far less than employees at the lower levels. In some cases, management has even rewarded itself with bonuses after laying off lower-level workers.

According to leadership-academic Manfred F.R. Kets de Vries, a contemporary senior-management team will almost inevitably have some personality disorders.

According to Fayol, management operates through five basic functions: planning, organizing, coordinating, commanding, and controlling.

Figurehead, leader
Nerve centre, disseminator
Entrepreneur, negotiator, allocator

Management skills include:



Most organizations have three management levels: first-level, middle-level, and top-level managers. First-line managers are the lowest level of management and manage the work of nonmanagerial individuals who are directly involved with the production or creation of the organization's products. First-line managers are often called supervisors, but may also be called line managers, office managers, or even foremen. Middle managers include all levels of management between the first-line level and the top level of the organization. These managers manage the work of first-line managers and may have titles such as department head, project leader, plant manager, or division manager. Top managers are responsible for making organization-wide decisions and establishing the plans and goals that affect the entire organization. These individuals typically have titles such as executive vice president, president, managing director, chief operating officer, chief executive officer, or chairman of the board.

These managers are classified in a hierarchy of authority, and perform different tasks. In many organizations, the number of managers in every level resembles a pyramid. Each level is explained below in specifications of their different responsibilities and likely job titles.

The top or senior layer of management consists of the board of directors (including non-executive directors, executive directors and independent directors), president, vice-president, CEOs and other members of the C-level executives. Different organizations have various members in their C-suite, which may include a chief financial officer, chief technology officer, and so on. They are responsible for controlling and overseeing the operations of the entire organization. They set a "tone at the top" and develop strategic plans, company policies, and make decisions on the overall direction of the organization. In addition, top-level managers play a significant role in the mobilization of outside resources. Senior managers are accountable to the shareholders, the general public and to public bodies that oversee corporations and similar organizations. Some members of the senior management may serve as the public face of the organization, and they may make speeches to introduce new strategies or appear in marketing.

The board of directors is typically primarily composed of non-executives who owe a fiduciary duty to shareholders and are not closely involved in the day-to-day activities of the organization, although this varies depending on the type (e.g., public versus private), size and culture of the organization. These directors are theoretically liable for breaches of that duty and typically insured under directors and officers liability insurance. Fortune 500 directors are estimated to spend 4.4 hours per week on board duties, and median compensation was $212,512 in 2010. The board sets corporate strategy, makes major decisions such as major acquisitions, and hires, evaluates, and fires the top-level manager (chief executive officer or CEO). The CEO typically hires other positions. However, board involvement in the hiring of other positions such as the chief financial officer (CFO) has increased. In 2013, a survey of over 160 CEOs and directors of public and private companies found that the top weaknesses of CEOs were "mentoring skills" and "board engagement", and 10% of companies never evaluated the CEO. The board may also have certain employees (e.g., internal auditors) report to them or directly hire independent contractors; for example, the board (through the audit committee) typically selects the auditor.

Helpful skills of top management vary by the type of organization but typically include a broad understanding of competition, world economies, and politics. In addition, the CEO is responsible for implementing and determining (within the board's framework) the broad policies of the organization. Executive management accomplishes the day-to-day details, including: instructions for preparation of department budgets, procedures, schedules; appointment of middle level executives such as department managers; coordination of departments; media and governmental relations; and shareholder communication.

Consist of general managers, branch managers and department managers. They are accountable to the top management for their department's function. They devote more time to organizational and directional functions. Their roles can be emphasized as executing organizational plans in conformance with the company's policies and the objectives of the top management, they define and discuss information and policies from top management to lower management, and most importantly they inspire and provide guidance to lower-level managers towards better performance.

Middle management is the midway management of a categorized organization, being secondary to the senior management but above the deepest levels of operational members. An operational manager may be well-thought-out by middle management, or may be categorized as non-management operate, liable to the policy of the specific organization. Efficiency of the middle level is vital in any organization, since they bridge the gap between top level and bottom level staffs.

Their functions include:

Lower managers include supervisors, section leaders, forepersons and team leaders. They focus on controlling and directing regular employees. They are usually responsible for assigning employees' tasks, guiding and supervising employees on day-to-day activities, ensuring the quality and quantity of production and/or service, making recommendations and suggestions to employees on their work, and channeling employee concerns that they cannot resolve to mid-level managers or other administrators. First-level or "front line" managers also act as role models for their employees. In some types of work, front line managers may also do some of the same tasks that employees do, at least some of the time. For example, in some restaurants, the front line managers will also serve customers during a very busy period of the day.

Front-line managers typically provide:

Some front-line managers may also provide career planning for employees who aim to rise within the organization.

Colleges and universities around the world offer bachelor's degrees, graduate degrees, diplomas and certificates in management, generally within their colleges of business, business schools or faculty of management but also in other related departments. In the 2010s, there has been an increase in online management education and training in the form of electronic educational technology ( also called e-learning). Online education has increased the accessibility of management training to people who do not live near a college or university, or who cannot afford to travel to a city where such training is available.

While some professions require academic credentials in order to work in the profession (e.g., law, medicine, engineering, which require, respectively the Bachelor of Law, Doctor of Medicine and Bachelor of Engineering degrees), management and administration positions do not necessarily require the completion of academic degrees. Some well-known senior executives in the US who did not complete a degree include Steve Jobs, Bill Gates and Mark Zuckerberg. However, many managers and executives have completed some type of business or management training, such as a Bachelor of Commerce or a Master of Business Administration degree. Some major organizations, including companies, not-for-profit organizations and governments, require applicants to managerial or executive positions to hold at minimum bachelor's degree in a field related to administration or management, or in the case of business jobs, a Bachelor of Commerce or a similar degree.

At the undergraduate level, the most common business program are the Bachelor of Business Administration (BBA) and Bachelor of Commerce (B.Com.).
These typically comprise a four-year program designed to give students an overview of the role of managers in planning and directing within an organization. 
Course topics include accounting, financial management, statistics, marketing, strategy, and other related areas.

There are many other undergraduate degrees that include the study of management, such as Bachelor of Arts degrees with a major in business administration or management and Bachelor of Public Administration (B.P.A), a degree designed for individuals aiming to work as bureaucrats in the government jobs. 
Many colleges and universities also offer certificates and diplomas in business administration or management, which typically require one to two years of full-time study.

Note that to manage technological areas, one often needs an undergraduate degree in a STEM-area.

At the graduate level students aiming at careers as managers or executives may choose to specialize in major subareas of management or business administration such as entrepreneurship, human resources, international business, organizational behavior, organizational theory, strategic management, accounting, corporate finance, entertainment, global management, healthcare management, investment management, sustainability and real estate.

A Master of Business Administration (MBA) is the most popular professional degree at the master's level and can be obtained from many universities in the United States. MBA programs provide further education in management and leadership for graduate students. Other master's degrees in business and management include Master of Management (MM) and the Master of Science (M.Sc.) in business administration or management, which is typically taken by students aiming to become researchers or professors.

There are also specialized master's degrees in administration for individuals aiming at careers outside of business, such as the Master of Public Administration (MPA) degree (also offered as a Master of Arts in Public Administration in some universities), for students aiming to become managers or executives in the public service and the Master of Health Administration, for students aiming to become managers or executives in the health care and hospital sector.

Management doctorates are the most advanced terminal degrees in the field of business and management. Most individuals obtaining management doctorates take the programs to obtain the training in research methods, statistical analysis and writing academic papers that they will need to seek careers as researchers, senior consultants and/or professors in business administration or management. There are three main types of management doctorates: the Doctor of Management (D.M.), the Doctor of Business Administration (D.B.A.), and the Ph.D. in Business Administration or Management. In the 2010s, doctorates in business administration and management are available with many specializations.

While management trends can change so fast, the long-term trend in management has been defined by a market embracing diversity and a rising service industry. Managers are currently being trained to encourage greater equality for minorities and women in the workplace, by offering increased flexibility in working hours, better retraining, and innovative (and usually industry-specific) performance markers. Managers destined for the service sector are being trained to use unique measurement techniques, better worker support and more charismatic leadership styles. Human resources finds itself increasingly working with management in a training capacity to help collect management data on the success (or failure) of management actions with employees.

Evidence-based management is an emerging movement to use the current, best evidence in management and decision-making. It is part of the larger movement towards evidence-based practices. Evidence-based management entails managerial decisions and organizational practices informed by the best available evidence. As with other evidence-based practice, this is based on the three principles of: 1) published peer-reviewed (often in management or social science journals) research evidence that bears on whether and why a particular management practice works; 2) judgement and experience from contextual management practice, to understand the organization and interpersonal dynamics in a situation and determine the risks and benefits of available actions; and 3) the preferences and values of those affected.




</doc>
<doc id="19883" url="https://en.wikipedia.org/wiki?curid=19883" title="Mineralogy">
Mineralogy

Mineralogy is a subject of geology specializing in the scientific study of the chemistry, crystal structure, and physical (including optical) properties of minerals and mineralized artifacts. Specific studies within mineralogy include the processes of mineral origin and formation, classification of minerals, their geographical distribution, as well as their utilization.

Early writing on mineralogy, especially on gemstones, comes from ancient Babylonia, the ancient Greco-Roman world, ancient and medieval China, and Sanskrit texts from ancient India and the ancient Islamic World. Books on the subject included the "Naturalis Historia" of Pliny the Elder, which not only described many different minerals but also explained many of their properties, and Kitab al Jawahir (Book of Precious Stones) by Persian scientist Al-Biruni. The German Renaissance specialist Georgius Agricola wrote works such as "De re metallica" ("On Metals", 1556) and "De Natura Fossilium" ("On the Nature of Rocks", 1546) which began the scientific approach to the subject. Systematic scientific studies of minerals and rocks developed in post-Renaissance Europe. The modern study of mineralogy was founded on the principles of crystallography (the origins of geometric crystallography, itself, can be traced back to the mineralogy practiced in the eighteenth and nineteenth centuries) and to the microscopic study of rock sections with the invention of the microscope in the 17th century.

Nicholas Steno first observed the law of constancy of interfacial angles (also known as the first law of crystallography) in quartz crystals in 1669. This was later generalized and established experimentally by Jean-Baptiste L. Romé de l'Islee in 1783. René Just Haüy, the "father of modern crystallography", showed that crystals are periodic and established that the orientations of crystal faces can be expressed in terms of rational numbers, as later encoded in the Miller indices. In 1814, Jöns Jacob Berzelius introduced a classification of minerals based on their chemistry rather than their crystal structure. William Nicol developed the Nicol prism, which polarizes light, in 1827–1828 while studying fossilized wood; Henry Clifton Sorby showed that thin sections of minerals could be identified by their optical properties using a polarizing microscope. James D. Dana published his first edition of "A System of Mineralogy" in 1837, and in a later edition introduced a chemical classification that is still the standard. X-ray diffraction was demonstrated by Max von Laue in 1912, and developed into a tool for analyzing the crystal structure of minerals by the father/son team of William Henry Bragg and William Lawrence Bragg.

More recently, driven by advances in experimental technique (such as neutron diffraction) and available computational power, the latter of which has enabled extremely accurate atomic-scale simulations of the behaviour of crystals, the science has branched out to consider more general problems in the fields of inorganic chemistry and solid-state physics. It, however, retains a focus on the crystal structures commonly encountered in rock-forming minerals (such as the perovskites, clay minerals and framework silicates). In particular, the field has made great advances in the understanding of the relationship between the atomic-scale structure of minerals and their function; in nature, prominent examples would be accurate measurement and prediction of the elastic properties of minerals, which has led to new insight into seismological behaviour of rocks and depth-related discontinuities in seismograms of the Earth's mantle. To this end, in their focus on the connection between atomic-scale phenomena and macroscopic properties, the "mineral sciences" (as they are now commonly known) display perhaps more of an overlap with materials science than any other discipline.

 
An initial step in identifying a mineral is to examine its physical properties, many of which can be measured on a hand sample. These can be classified into density (often given as specific gravity); measures of mechanical cohesion (hardness, tenacity, cleavage, fracture, parting); macroscopic visual properties (luster, color, streak, luminescence, diaphaneity); magnetic and electric properties; radioactivity and solubility in hydrogen chloride ().

"Hardness" is determined by comparison with other minerals. In the Mohs scale, a standard set of minerals are numbered in order of increasing hardness from 1 (talc) to 10 (diamond). A harder mineral will scratch a softer, so an unknown mineral can be placed in this scale by which minerals it scratches and which scratch it. A few minerals such as calcite and kyanite have a hardness that depends significantly on direction. Hardness can also be measured on an absolute scale using a sclerometer; compared to the absolute scale, the Mohs scale is nonlinear.

"Tenacity" refers to the way a mineral behaves when it is broken, crushed, bent or torn. A mineral can be brittle, malleable, sectile, ductile, flexible or elastic. An important influence on tenacity is the type of chemical bond ("e.g.," ionic or metallic). Of the other measures of mechanical cohesion, "cleavage" is the tendency to break along certain crystallographic planes. It is described by the quality ("e.g.", perfect or fair) and the orientation of the plane in crystallographic nomenclature. "Parting" is the tendency to break along planes of weakness due to pressure, twinning or exsolution. Where these two kinds of break do not occur, "fracture" is a less orderly form that may be "conchoidal" (having smooth curves resembling the interior of a shell), "fibrous", "splintery", "hackly" (jagged with sharp edges), or "uneven".

If the mineral is well crystallized, it will also have a distinctive crystal habit (for example, hexagonal, columnar, botryoidal) that reflects the crystal structure or internal arrangement of atoms. It is also affected by crystal defects and twinning. Many crystals are polymorphic, having more than one possible crystal structure depending on factors such as pressure and temperature.

The crystal structure is the arrangement of atoms in a crystal. It is represented by a lattice of points which repeats a basic pattern, called a unit cell, in three dimensions. The lattice can be characterized by its symmetries and by the dimensions of the unit cell. These dimensions are represented by three "Miller indices". The lattice remains unchanged by certain symmetry operations about any given point in the lattice: reflection, rotation, inversion, and rotary inversion, a combination of rotation and reflection. Together, they make up a mathematical object called a "crystallographic point group" or "crystal class". There are 32 possible crystal classes. In addition, there are operations that displace all the points: translation, screw axis, and glide plane. In combination with the point symmetries, they form 230 possible space groups.

Most geology departments have X-ray powder diffraction equipment to analyze the crystal structures of minerals. X-rays have wavelengths that are the same order of magnitude as the distances between atoms. Diffraction, the constructive and destructive interference between waves scattered at different atoms, leads to distinctive patterns of high and low intensity that depend on the geometry of the crystal. In a sample that is ground to a powder, the X-rays sample a random distribution of all crystal orientations. Powder diffraction can distinguish between minerals that may appear the same in a hand sample, for example quartz and its polymorphs tridymite and cristobalite.

Isomorphous minerals of different compositions have similar powder diffraction patterns, the main difference being in spacing and intensity of lines. For example, the (halite) crystal structure is space group "Fm3m"; this structure is shared by sylvite (), periclase (), bunsenite (), galena (), alabandite (), chlorargyrite (), and osbornite ().

A few minerals are chemical elements, including sulfur, copper, silver, and gold, but the vast majority are compounds. The classical method for identifying composition is "wet chemical analysis", which involves dissolving a mineral in an acid such as hydrochloric acid (). The elements in solution are then identified using colorimetry, volumetric analysis or gravimetric analysis.

Since 1960, most chemistry analysis is done using instruments. One of these, atomic absorption spectroscopy, is similar to wet chemistry in that the sample must still be dissolved, but it is much faster and cheaper. The solution is vaporized and its absorption spectrum is measured in the visible and ultraviolet range. Other techniques are X-ray fluorescence, electron microprobe analysis atom probe tomography and optical emission spectrography.

In addition to macroscopic properties such as color or lustre, minerals have properties that require a polarizing microscope to observe.

When light passes from air or a vacuum into a transparent crystal, some of it is reflected at the surface and some refracted. The latter is a bending of the light path that occurs because the speed of light changes as it goes into the crystal; Snell's law relates the bending angle to the Refractive index, the ratio of speed in a vacuum to speed in the crystal. Crystals whose point symmetry group falls in the cubic system are "isotropic": the index does not depend on direction. All other crystals are "anisotropic": light passing through them is broken up into two plane polarized rays that travel at different speeds and refract at different angles.

A polarizing microscope is similar to an ordinary microscope, but it has two plane-polarized filters, a ("polarizer") below the sample and an analyzer above it, polarized perpendicular to each other. Light passes successively through the polarizer, the sample and the analyzer. If there is no sample, the analyzer blocks all the light from the polarizer. However, an anisotropic sample will generally change the polarization so some of the light can pass through. Thin sections and powders can be used as samples.

When an isotropic crystal is viewed, it appears dark because it does not change the polarization of the light. However, when it is immersed in a calibrated liquid with a lower index of refraction and the microscope is thrown out of focus, a bright line called a "Becke line" appears around the perimeter of the crystal. By observing the presence or absence of such lines in liquids with different indices, the index of the crystal can be estimated, usually to within .

Systematic mineralogy is the identification and classification of minerals by their properties. Historically, mineralogy was heavily concerned with taxonomy of the rock-forming minerals. In 1959, the International Mineralogical Association formed the Commission of New Minerals and Mineral Names to rationalize the nomenclature and regulate the introduction of new names. In July 2006, it was merged with the Commission on Classification of Minerals to form the Commission on New Minerals, Nomenclature, and Classification. There are over 6,000 named and unnamed minerals, and about 100 are discovered each year. The "Manual of Mineralogy" places minerals in the following classes: native elements, sulfides, sulfosalts, oxides and hydroxides, halides, carbonates, nitrates and borates, sulfates, chromates, molybdates and tungstates, phosphates, arsenates and vanadates, and silicates.

The environments of mineral formation and growth are highly varied, ranging from slow crystallization at the high temperatures and pressures of igneous melts deep within the Earth's crust to the low temperature precipitation from a saline brine at the Earth's surface.

Various possible methods of formation include:


Biomineralogy is a cross-over field between mineralogy, paleontology and biology. It is the study of how plants and animals stabilize minerals under biological control, and the sequencing of mineral replacement of those minerals after deposition. It uses techniques from chemical mineralogy, especially isotopic studies, to determine such things as growth forms in living plants and animals as well as things like the original mineral content of fossils.

A new approach to mineralogy called mineral evolution explores the co-evolution of the geosphere and biosphere, including the role of minerals in the origin of life and processes as mineral-catalyzed organic synthesis and the selective adsorption of organic molecules on mineral surfaces.

In 2011, several researchers began to develop a Mineral Evolution Database. This database integrates the crowd-sourced site Mindat.org, which has over 690,000 mineral-locality pairs, with the official IMA list of approved minerals and age data from geological publications.

This database makes it possible to apply statistics to answer new questions, an approach that has been called "mineral ecology". One such question is how much of mineral evolution is deterministic and how much the result of chance. Some factors are deterministic, such as the chemical nature of a mineral and conditions for its stability; but mineralogy can also be affected by the processes that determine a planet's composition. In a 2015 paper, Robert Hazen and others analyzed the number of minerals involving each element as a function of its abundance. They found that Earth, with over 4800 known minerals and 72 elements, has a power law relationship. The Moon, with only 63 minerals and 24 elements (based on a much smaller sample) has essentially the same relationship. This implies that, given the chemical composition of the planet, one could predict the more common minerals. However, the distribution has a long tail, with 34% of the minerals having been found at only one or two locations. The model predicts that thousands more mineral species may await discovery or have formed and then been lost to erosion, burial or other processes. This implies a role of chance in the formation of rare minerals occur.

In another use of big data sets, network theory was applied to a dataset of carbon minerals, revealing new patterns in their diversity and distribution. The analysis can show which minerals tend to coexist and what conditions (geological, physical, chemical and biological) are associated with them. This information can be used to predict where to look for new deposits and even new mineral species.

Minerals are essential to various needs within human society, such as minerals used as ores for essential components of metal products used in various commodities and machinery, essential components to building materials such as limestone, marble, granite, gravel, glass, plaster, cement, etc. Minerals are also used in fertilizers to enrich the growth of agricultural crops.

Mineral collecting is also a recreational study and collection hobby, with clubs and societies representing the field. Museums, such as the Smithsonian National Museum of Natural History Hall of Geology, Gems, and Minerals, the Natural History Museum of Los Angeles County, the Natural History Museum, London, and the private Mim Mineral Museum in Beirut, Lebanon, have popular collections of mineral specimens on permanent display.




</doc>
<doc id="19886" url="https://en.wikipedia.org/wiki?curid=19886" title="Maple syrup">
Maple syrup

Maple syrup is a syrup usually made from the xylem sap of sugar maple, red maple, or black maple trees, although it can also be made from other maple species. In cold climates, these trees store starch in their trunks and roots before winter; the starch is then converted to sugar that rises in the sap in late winter and early spring. Maple trees are tapped by drilling holes into their trunks and collecting the sap, which is processed by heating to evaporate much of the water, leaving the concentrated syrup. Most trees can produce of sap per season.

Maple syrup was first made and used by the indigenous peoples of North America, and the practice was adopted by European settlers, who gradually refined production methods. Technological improvements in the 1970s further refined syrup processing. The Canadian province of Quebec is by far the largest producer, responsible for 70 percent of the world's output; Canadian exports of maple syrup in 2016 were C$487 million (about US$360 million), with Quebec accounting for some 90 percent of this total.

Maple syrup is graded according to the Canada, United States, or Vermont scales based on its density and translucency. Sucrose is the most prevalent sugar in maple syrup. In Canada, syrups must be made exclusively from maple sap to qualify as maple syrup and must also be at least 66 percent sugar. In the United States, a syrup must be made almost entirely from maple sap to be labelled as "maple", though states such as Vermont and New York have more restrictive definitions.

Maple syrup is often used as a condiment for pancakes, waffles, French toast, oatmeal or porridge. It is also used as an ingredient in baking and as a sweetener or flavouring agent. Culinary experts have praised its unique flavour, although the chemistry responsible is not fully understood.

Three species of maple trees are predominantly used to produce maple syrup: the sugar maple ("Acer saccharum"), the black maple ("A. nigrum"), and the red maple ("A. rubrum"), because of the high sugar content (roughly two to five percent) in the sap of these species. The black maple is included as a subspecies or variety in a more broadly viewed concept of "A. saccharum", the sugar maple, by some botanists. Of these, the red maple has a shorter season because it buds earlier than sugar and black maples, which alters the flavour of the sap.

A few other species of maple ("Acer") are also sometimes used as sources of sap for producing maple syrup, including the box elder or Manitoba maple ("Acer negundo"), the silver maple ("A. saccharinum"), and the bigleaf maple ("A. macrophyllum"). In the Southeastern United States, Florida sugar maple ("Acer floridanum") is occasionally used for maple syrup production.

Similar syrups may also be produced from walnut, birch or palm trees, among other sources.

Indigenous peoples living in northeastern North America were the first groups known to have produced maple syrup and maple sugar. According to aboriginal oral traditions, as well as archaeological evidence, maple tree sap was being processed into syrup long before Europeans arrived in the region. There are no authenticated accounts of how maple syrup production and consumption began, but various legends exist; one of the most popular involves maple sap being used in place of water to cook venison served to a chief. Aboriginal tribes developed rituals around sugar-making, celebrating the Sugar Moon (the first full moon of spring) with a Maple Dance. Many aboriginal dishes replaced the salt traditional in European cuisine with maple sugar or syrup.

The Algonquians recognized maple sap as a source of energy and nutrition. At the beginning of the spring thaw, they made V-shaped incisions in tree trunks; they then inserted reeds or concave pieces of bark to run the sap into buckets, which were often made from birch bark. The maple sap was concentrated either by dropping hot cooking stones into the buckets or by leaving them exposed to the cold temperatures overnight and disposing of the layer of ice that formed on top.

In the early stages of European colonization in northeastern North America, local Indigenous peoples showed the arriving colonists how to tap the trunks of certain types of maples during the spring thaw to harvest the sap. André Thevet, the "Royal Cosmographer of France", wrote about Jacques Cartier drinking maple sap during his Canadian voyages. By 1680, European settlers and fur traders were involved in harvesting maple products. However, rather than making incisions in the bark, the Europeans used the method of drilling tapholes in the trunks with augers. During the 17th and 18th centuries, processed maple sap was used primarily as a source of concentrated sugar, in both liquid and crystallized-solid form, as cane sugar had to be imported from the West Indies.

Maple sugaring parties typically began to operate at the start of the spring thaw in regions of woodland with sufficiently large numbers of maples. Syrup makers first bored holes in the trunks, usually more than one hole per large tree; they then inserted wooden spouts into the holes and hung a wooden bucket from the protruding end of each spout to collect the sap. The buckets were commonly made by cutting cylindrical segments from a large tree trunk and then hollowing out each segment's core from one end of the cylinder, creating a seamless, watertight container. Sap filled the buckets, and was then either transferred to larger holding vessels (barrels, large pots, or hollowed-out wooden logs), often mounted on sledges or wagons pulled by draft animals, or carried in buckets or other convenient containers. The sap-collection buckets were returned to the spouts mounted on the trees, and the process was repeated for as long as the flow of sap remained "sweet". The specific weather conditions of the thaw period were, and still are, critical in determining the length of the sugaring season. As the weather continues to warm, a maple tree's normal early spring biological process eventually alters the taste of the sap, making it unpalatable, perhaps due to an increase in amino acids.

The boiling process was very time-consuming. The harvested sap was transported back to the party's base camp, where it was then poured into large vessels (usually made from metal) and boiled to achieve the desired consistency. The sap was usually transported using large barrels pulled by horses or oxen to a central collection point, where it was processed either over a fire built out in the open or inside a shelter built for that purpose (the "sugar shack").

Around the time of the American Civil War (1861-1865), syrup makers started using large, flat sheet metal pans as they were more efficient for boiling than heavy, rounded iron kettles, because of a greater surface area for evaporation. Around this time, cane sugar replaced maple sugar as the dominant sweetener in the US; as a result, producers focused marketing efforts on maple syrup. The first evaporator, used to heat and concentrate sap, was patented in 1858. In 1872, an evaporator was developed that featured two pans and a metal arch or firebox, which greatly decreased boiling time. Around 1900, producers bent the tin that formed the bottom of a pan into a series of flues, which increased the heated surface area of the pan and again decreased boiling time. Some producers also added a finishing pan, a separate batch evaporator, as a final stage in the evaporation process.

Buckets began to be replaced with plastic bags, which allowed people to see at a distance how much sap had been collected. Syrup producers also began using tractors to haul vats of sap from the trees being tapped (the sugarbush) to the evaporator. Some producers adopted motor-powered tappers and metal tubing systems to convey sap from the tree to a central collection container, but these techniques were not widely used. Heating methods also diversified: modern producers use wood, oil, natural gas, propane, or steam to evaporate sap. Modern filtration methods were perfected to prevent contamination of the syrup.

A large number of technological changes took place during the 1970s. Plastic tubing systems that had been experimental since the early part of the century were perfected, and the sap came directly from the tree to the evaporator house. Vacuum pumps were added to the tubing systems, and preheaters were developed to recycle heat lost in the steam. Producers developed reverse-osmosis machines to take a portion of water out of the sap before it was boiled, increasing processing efficiency.

Improvements in tubing and vacuum pumps, new filtering techniques, "supercharged" preheaters, and better storage containers have since been developed. Research continues on pest control and improved woodlot management. In 2009, researchers at the University of Vermont unveiled a new type of tap that prevents backflow of sap into the tree, reducing bacterial contamination and preventing the tree from attempting to heal the bore hole. Experiments show that it may be possible to use saplings in a plantation instead of mature trees, dramatically boosting productivity per acre.

Open pan evaporation methods have been streamlined since colonial days, but remain basically unchanged. Sap must first be collected and boiled down to obtain pure syrup without chemical agents or preservatives. Maple syrup is made by boiling between 20 and 50 volumes of sap (depending on its concentration) over an open fire until 1 volume of syrup is obtained, usually at a temperature over the boiling point of water. As the boiling point of water varies with changes in air pressure the correct value for pure water is determined at the place where the syrup is being produced, each time evaporation is begun and periodically throughout the day. Syrup can be boiled entirely over one heat source or can be drawn off into smaller batches and boiled at a more controlled temperature.

Boiling the syrup is a tightly controlled process, which ensures appropriate sugar content. Syrup boiled too long will eventually crystallize, whereas under-boiled syrup will be watery, and will quickly spoil. The finished syrup has a density of 66° on the Brix scale (a hydrometric scale used to measure sugar solutions). The syrup is then filtered to remove precipitated "sugar sand", crystals made up largely of sugar and calcium malate. These crystals are not toxic, but create a "gritty" texture in the syrup if not filtered out.

In addition to open pan evaporation methods, many large producers use the more fuel efficient reverse osmosis procedure to separate the water from the sap.

The higher the sugar content of the sap, the smaller the volume of sap is needed to obtain the same amount of syrup. 57 units of sap with 1.5 percent sugar content will yield 1 unit of syrup, but only 25 units of sap with a 3.5 percent sugar content are needed to obtain one unit of syrup. The sap's sugar content is highly variable and will fluctuate even within the same tree.

The filtered syrup is graded and packaged while still hot, usually at a temperature of or greater. The containers are turned over after being sealed to sterilize the cap with the hot syrup. Packages can be made of metal, glass, or coated plastic, depending on volume and target market. The syrup can also be heated longer and further processed to create a variety of other maple products, including maple sugar, maple butter or cream, and maple candy or taffy.

Off-flavours can sometimes develop during the production of maple syrup, resulting from contaminants in the boiling apparatus (such as disinfectants), microorganisms, fermentation products, metallic can flavours, and "buddy sap", an off-flavour occurring late in the syrup season when tree budding has begun. In some circumstances, it is possible to remove off-flavours through processing.

Maple syrup production is centred in northeastern North America; however, given the correct weather conditions, it can be made wherever suitable species of maple trees grow.

A maple syrup production farm is called a "sugarbush" or "sugarwood". Sap is often boiled in a "sugar house" (also known as a "sugar shack", "sugar shanty", or "cabane à sucre"), a building louvered at the top to vent the steam from the boiling sap.

Maples are usually tapped beginning at 30 to 40 years of age. Each tree can support between one and three taps, depending on its trunk diameter. The average maple tree will produce of sap per season, up to per day. This is roughly equal to seven percent of its total sap. Seasons last for four to eight weeks, depending on the weather. During the day, starch stored in the roots for the winter rises through the trunk as sugary sap, allowing it to be tapped. Sap is not tapped at night because the temperature drop inhibits sap flow, although taps are typically left in place overnight. Some producers also tap in autumn, though this practice is less common than spring tapping. Maples can continue to be tapped for sap until they are over 100 years old.

Until the 1930s, the United States produced most of the world's maple syrup. Today, after rapid growth in the 1990s, Canada produces more than 80 percent of the world's maple syrup, producing about in 2016. The vast majority of this comes from the province of Quebec, which is the world's largest producer, with about 70 percent of global production. Canada exported more than C$362 million of maple syrup in 2016. In 2015, 64 percent of Canadian maple syrup exports went to the United States (a value of C$229 million), 8 percent to Germany (C$31 million), 6 percent to Japan (C$26 million), and 5 percent to the United Kingdom (C$16 million).

In 2015, Quebec accounts for 90.83 percent of maple syrup produced in Canada, followed by New Brunswick at 4.83 percent, Ontario at 4.14 percent, and Nova Scotia at 0.2 percent. However, 94.28 percent of exported Canadian maple syrup originated from Quebec, whereas 4.91 percent of exported syrup originated from New Brunswick, and the remaining 0.81 percent from all other provinces. Ontario holds the most maple syrup farms in Canada outside of Quebec, with 2,240 maple syrup producers in 2011. This is followed by New Brunswick, with 191 maple syrup producers; and Nova Scotia, with 152 maple syrup producers.

As of 2016, Quebec had some 7,300 producers working with 13,500 farmers, collectively making over of syrup. Production in Quebec is controlled through a supply management system, with producers receiving quota allotments from the Federation of Quebec Maple Syrup Producers ("Fédération des producteurs acéricoles du Québec", FPAQ), which also maintains reserves of syrup, although there is a black-market trade in Quebec product. In 2017, the FPAQ mandated increased output of maple syrup production, attempting to establish Quebec's dominance in the world market.

The Canadian provinces of Manitoba and Saskatchewan produce maple syrup using the sap of the box elder or Manitoba maple ("Acer negundo"). In 2011, there were 67 maple syrup producers in Manitoba, and 24 in Saskatchewan. A Manitoba maple tree's yield is usually less than half that of a similar sugar maple tree. Manitoba maple syrup has a slightly different flavour from sugar-maple syrup, because it contains less sugar and the tree's sap flows more slowly. British Columbia is home to a growing maple sugar industry using sap from the bigleaf maple, which is native to the West Coast of the United States and Canada. In 2011, there were 82 maple syrup producers in British Columbia.

Vermont is the biggest US producer, with over during the 2013 season, followed by New York with and Maine with . Wisconsin, Ohio, New Hampshire, Michigan, Pennsylvania, Massachusetts, and Connecticut all produced marketable quantities of maple syrup of less than each in 2013. As of 2003, Vermont produced about 5.5 percent of the global syrup supply.

Maple syrup has been produced on a small scale in some other countries, notably Japan and South Korea. However, in South Korea in particular, it is traditional to consume maple sap, called "gorosoe", instead of processing it into syrup.

Under Canadian Maple Product Regulations, containers of maple syrup must include the words "maple syrup", its grade name and net quantity in litres or millilitres, on the main display panel with a minimum font size of 1.6 mm. If the maple syrup is of Canada Grade A level, the name of the colour class must appear on the label in both English and French. Also, the lot number or production code, and either: (1) the name and address of the sugar bush establishment, packing or shipper establishment, or (2) the first dealer and the registration number of the packing establishment, must be labeled on any display panel other than the bottom.

Following an effort from the International Maple Syrup Institute (IMSI) and many maple syrup producer associations, both Canada and the United States have altered their laws regarding the classification of maple syrup to be uniform. Whereas in the past each state or province had their own laws on the classification of maple syrup, now those laws define a unified grading system. This had been a work in progress for several years, and most of the finalization of the new grading system was made in 2014. The Canadian Food Inspection Agency (CFIA) announced in the "Canada Gazette" on 28 June 2014 that rules for the sale of maple syrup would be amended to include new descriptors, at the request of the IMSI.

As of December 31, 2014, the CFIA and as of March 2, 2015, the United States Department of Agriculture (USDA) Agricultural Marketing Service issued revised standards intended to harmonize Canada-United States regulations on the classification of maple syrup as follows:


As long as maple syrup does not have an off-flavour, is of a uniform colour, and is free from turbidity and sediment, it can be labelled as one of the A grades. If it exhibits any problems, it does not meet Grade A requirements, and then must be labelled as Processing Grade maple syrup and may not be sold in containers smaller than . If maple syrup does not meet the requirements of Processing Grade maple syrup (including a fairly characteristic maple taste), it is classified as Substandard.

This grading system was accepted and made law by most maple-producing states and provinces, and became compulsory in Canada as of 13 December 2016. Vermont, in an effort to "jump-start" the new grading regulations, adopted the new grading system as of January 1, 2014, after the grade changes passed the Senate and House in 2013. Maine passed a bill to take effect as soon as both Canada and the United States adopted the new grades. In New York, the new grade changes became law on January 1, 2015. New Hampshire did not require legislative approval and so the new grade laws became effective as of December 16, 2014, and producer compliance was required as of January 1, 2016.

Golden and Amber grades typically have a milder flavour than Dark and Very dark, which are both dark and have an intense maple flavour. The darker grades of syrup are used primarily for cooking and baking, although some specialty dark syrups are produced for table use. Syrup harvested earlier in the season tends to yield a lighter colour. With the new grading system, the classification of maple syrup depends ultimately on its internal transmittance at 560 nm wavelength through a 10 mm sample. Golden must have 75 percent or more transmittance, Amber must have 50.0 to 74.9 percent transmittance, Dark must have 25.0 to 49.9 percent transmittance, and Very Dark is any product having less than 25.0 percent transmittance.

In Canada, maple syrup was classified prior to December 31, 2014, by the Canadian Food Inspection Agency (CFIA) as one of three grades, each with several colour classes:

Producers in Ontario or Quebec may have followed either federal or provincial grading guidelines. Quebec's and Ontario's guidelines differed slightly from the federal:


A typical year's yield for a maple syrup producer will be about 25 to 30 percent of each of the #1 colours, 10 percent #2 Amber, and 2 percent #3 Dark.

The United States used different grading standards ⁠— ⁠some states still do as they await state regulation. Maple syrup was divided into two major grades: 

In Massachusetts, the Grade B was renamed as "Grade A Very Dark, Strong Taste."

The Vermont Agency of Agriculture Food and Markets used a similar grading system of colour, and is roughly equivalent, especially for lighter syrups, but using letters: "AA", "A", etc. The Vermont grading system differed from the US system in maintaining a slightly higher standard of product density (measured on the Baumé scale). New Hampshire maintained a similar standard, but not a separate state grading scale. The Vermont-graded product had 0.9 percent more sugar and less water in its composition than US-graded. One grade of syrup not for table use, called commercial or Grade C, was also produced under the Vermont system.

In Canada, the packing of maple syrup must follow the "Packing" conditions stated in the Maple Products Regulations, or utilize the equivalent Canadian or imported grading system.

As stated in the Maple Products Regulations, Canadian maple syrup can be classified as "Canadian Grade A" and "Canadian Processing Grade". Any maple syrup container under these classifications should be filled to at least 90% of the bottle size while still containing the net quantity of syrup product as stated on the label. Every container of maple syrup must be new if it has a capacity of 5 litres or less or is marked with a grade name. Every container of maple sugar must also be new if it has a capacity of less than 5 kg or is either exported out of Canada or conveyed from one province to another.

Each maple syrup product must be verified clean if it follows a grade name or if it is exported out of the province in which it was originally manufactured.

The basic ingredient in maple syrup is the sap from the xylem of sugar maple or various other species of maple trees. It consists primarily of sucrose and water, with small amounts of the monosaccharides glucose and fructose from the invert sugar created in the boiling process.

In a 100g amount, maple syrup provides 260 calories and is composed of 32 percent water by weight, 67 percent carbohydrates (90 percent of which are sugars), and no appreciable protein or fat (table). Maple syrup is generally low in overall micronutrient content, although manganese and riboflavin are at high levels along with moderate amounts of zinc and calcium (right table). It also contains trace amounts of amino acids which increase in content as sap flow occurs.

Maple syrup contains a wide variety of polyphenols and volatile organic compounds, including vanillin, hydroxybutanone, lignans, propionaldehyde, and numerous organic acids. It is not yet known exactly all compounds responsible for the distinctive flavour of maple syrup, although primary flavour-contributing compounds are maple furanone (5-ethyl-3-hydroxy-4-methyl-2(5H)-furanone), strawberry furanone, and maltol. New compounds have been identified in maple syrup, one of which is quebecol, a natural phenolic compound created when the maple sap is boiled to create syrup. Its sweetness derives from a high content of sucrose (99% of total sugars). Its brown colour – a significant factor in the appeal and quality grading of maple syrup – develops during thermal evaporation.

One author described maple syrup as "a unique ingredient, smooth- and silky-textured, with a sweet, distinctive flavour – hints of caramel with overtones of toffee will not do – and a rare colour, amber set alight. Maple flavour is, well, maple flavour, uniquely different from any other." Agriculture Canada has developed a "flavour wheel" that details 91 unique flavours that can be present in maple syrup. These flavours are divided into 13 families: vanilla, burnt, milky, fruity, floral, spicy, foreign (deterioration or fermentation), foreign (environment), maple, confectionery, plant (herbaceous), plant (forest, humus or cereals), and plant (ligneous). These flavours are evaluated using a procedure similar to wine tasting. Other culinary experts praise its unique flavour.

Maple syrup and its various artificial imitations are widely used as toppings for pancakes, waffles, and French toast in North America. They can also be used to flavour a variety of foods, including fritters, ice cream, hot cereal, fresh fruit, bacon, and sausages. It is also used as sweetener for granola, applesauce, baked beans, candied sweet potatoes, winter squash, cakes, pies, breads, tea, coffee, and hot toddies.

In Canada, maple syrup must be made entirely from maple sap, and syrup must have a density of 66° on the Brix scale to be marketed as maple syrup. In the United States, maple syrup must be made almost entirely from maple sap, although small amounts of substances such as salt may be added. Labeling laws prohibit imitation syrups from having "maple" in their names unless the finished product contains 10 percent or more of natural maple syrup.

"Maple-flavoured" syrups include maple syrup, but may contain additional ingredients. "Pancake syrup", "waffle syrup", "table syrup", and similarly named syrups are substitutes which are less expensive than maple syrup. In these syrups, the primary ingredient is most often high-fructose corn syrup flavoured with sotolon; they have little genuine maple content, and are usually thickened above the viscosity of maple syrup.

Imitation syrups are generally cheaper than maple syrup, with less natural flavour. In the United States, consumers generally prefer imitation syrups, likely because of the significantly lower cost and sweeter flavour; they typically cost about , whereas authentic maple syrup costs as of 2015.

In 2016, maple syrup producers from nine US states petitioned the Food and Drug Administration (FDA) to regulate labeling of products containing maple syrup or using the word "maple" in manufactured products, indicating that imitation maple products contained insignificant amounts of natural maple syrup. In September 2016, the FDA published a consumer advisory to carefully inspect the ingredient list of products labeled as "maple".

Maple products are considered emblematic of Canada, and are frequently sold in tourist shops and airports as souvenirs from Canada. The sugar maple's leaf has come to symbolize Canada, and is depicted on the country's flag. Several US states, including West Virginia, New York, Vermont and Wisconsin, have the sugar maple as their state tree. A scene of sap collection is depicted on the Vermont state quarter, issued in 2001.

Maple syrup and maple sugar were used during the American Civil War and by abolitionists in the years before the war because most cane sugar and molasses were produced by Southern slaves. Because of food rationing during the Second World War, people in the northeastern United States were encouraged to stretch their sugar rations by sweetening foods with maple syrup and maple sugar, and recipe books were printed to help housewives employ this alternative source.






</doc>
<doc id="19888" url="https://en.wikipedia.org/wiki?curid=19888" title="Matthew">
Matthew

Matthew may refer to:





</doc>
<doc id="19890" url="https://en.wikipedia.org/wiki?curid=19890" title="Male (disambiguation)">
Male (disambiguation)

Male, in biology, is the half of a reproduction system that produces sperm cells.

Male may also refer to:







</doc>
<doc id="19891" url="https://en.wikipedia.org/wiki?curid=19891" title="Macron (diacritic)">
Macron (diacritic)

A macron () is a diacritical mark: it is a straight bar placed above a letter, usually a vowel. Its name derives from Ancient Greek ("makrón") "long", since it was originally used to mark long or heavy syllables in Greco-Roman metrics. It now more often marks a long vowel. In the International Phonetic Alphabet, the macron is used to indicate a mid-tone; the sign for a long vowel is instead a modified triangular colon .

The opposite is the breve , which marks a short or light syllable or a short vowel.

In Greco-Roman metrics and in the description of the metrics of other literatures, the macron was introduced and is still widely used to mark a long (heavy) syllable. Even relatively recent classical Greek and Latin dictionaries are still concerned with indicating only the length (weight) of syllables; that is why most still do not indicate the length of vowels in syllables that are otherwise metrically determined. Many textbooks about Ancient Rome and Greece use the macron, even if it was not actually used at that time.

The following languages or transliteration systems use the macron to mark long vowels:


The following languages or alphabets use the macron to mark tones:


Sometimes the macron marks an omitted "n" or "m", like the tilde:

In romanizations of Hebrew, the macron below is typically used to mark the begadkefat consonant lenition. However, for typographical reasons a regular macron is used on "p" and "g" instead: "p̄, ḡ".

The macron is used in the orthography of a number of vernacular languages of the Solomon Islands and Vanuatu, particularly those first transcribed by Anglican missionaries. The macron has no unique value, and is simply used to distinguish between two different phonemes.

Thus, in several languages of the Banks Islands, including Mwotlap, the simple "m" stands for , but an "m" with a macron (m̄) is a rounded labial-velar nasal ; while the simple "n" stands for the common alveolar nasal , an "n" with macron (n̄) represents the velar nasal ; the vowel ē stands for a (short) higher by contrast with plain "e" ; likewise ō contrasts with plain "o" .

In Hiw orthography, the consonant "r̄" stands for the prestopped velar lateral approximant .
In Araki, the same symbol "r̄" encodes the alveolar trill – by contrast with "r", which encodes the alveolar flap .

In Bislama (orthography before 1995), Lamenu and Lewo, a macron is used on two letters "". "m̄" represents , and "p̄" represents . The orthography after 1995 (which has no diacritics) has these written as "mw" and "pw".

In Kokota, "ḡ" is used for the velar stop , but "g" without macron is the voiced velar fricative .

In Marshallese, a macron is used on four letters – ' – whose pronunciations differ from the unmarked '. Marshallese uses a vertical vowel system with three to four vowel phonemes, but traditionally their allophones have been written out, so vowel letters with macron are used for some of these allophones. Though the standard diacritic involved is a macron, there are no other diacritics used "above" letters, so in practice other diacritics can and have been used in less polished writing or print, yielding nonstandard letters like ", depending on displayability of letters in computer fonts.


Also, in some instances, a diacritic will be written like a macron, although it represents another diacritic whose standard form is different:


In medical prescriptions and other handwritten notes, macrons mean:

The overline is a typographical symbol similar to the macron, used in a number of ways in mathematics and science. For example, it is used to represent complex conjugation:

formula_1

and to represent line segments in geometry (e.g., formula_2), sample means in statistics (e.g., formula_3) and negations in logic. It is also used in Hermann–Mauguin notation.

In music, the tenuto marking resembles the macron.

The macron is also used in German lute tablature to distinguish repeating alphabetic characters.

The Unicode Standard encodes combining and precomposed macron characters:

Macron-related Unicode characters not included in the table above:

In LaTeX a macron is created with the command "\=", for example: M\=aori for Māori.
In OpenOffice, if the extension Compose Special Characters is installed, a macron may be added by following the letter with a hyphen and pressing the user's predefined shortcut key for composing special characters. A macron may also be added by following the letter with the character's four-digit hex-code, and pressing the user's predefined shortcut key for adding unicode characters.




</doc>
<doc id="19894" url="https://en.wikipedia.org/wiki?curid=19894" title="Mosque">
Mosque

A mosque (; from , ; literally "place of ritual prostration") is a place of worship for Muslims. Any act of worship that follows the Islamic rules of prayer can be said to create a mosque, whether or not it takes place in a special building. Informal and open-air places of worship are called "musalla", while mosques used for communal prayer on Fridays are known as "jāmiʿ". Mosque buildings typically contain an ornamental niche ("mihrab") set into the wall that indicates the direction of Mecca ("qiblah"), ablution facilities and minarets from which calls to prayer are issued. The pulpit ("minbar"), from which the Friday (jumu'ah) sermon ("khutba") is delivered, was in earlier times characteristic of the central city mosque, but has since become common in smaller mosques. Mosques typically have segregated spaces for men and women. This basic pattern of organization has assumed different forms depending on the region, period and denomination.

Mosques commonly serve as locations for prayer, Ramadan vigils, funeral services, Sufi ceremonies, marriage and business agreements, alms collection and distribution, as well as homeless shelters. Historically, mosques were also important centers of elementary education and advanced training in religious sciences. In modern times, they have preserved their role as places of religious instruction and debate, but higher learning now generally takes place in specialised institutions. Special importance is accorded to the Great Mosque of Mecca (centre of the hajj), the Prophet's Mosque in Medina (burial place of Muhammad) and Al-Aqsa Mosque in Jerusalem (believed to be the site of Muhammad's ascent to heaven). In the past, many mosques in the Muslim world were built over burial places of Sufi saints and other venerated figures, which has turned them into popular pilgrimage destinations.

With the spread of Islam, mosques multiplied across the Islamic world. Sometimes churches and temples were converted into mosques, which influenced Islamic architectural styles. While most pre-modern mosques were funded by charitable endowments, modern states in the Muslim world have attempted to bring mosques under government control. Increasing government regulation of large mosques has been countered by a rise of privately funded mosques of various affiliations and ideologies, many of which serve as bases for different Islamic revivalist currents and social activism. Mosques have played a number of political roles. The rates of mosque attendance vary widely depending on the region.

The word 'mosque' entered the English language from the French word "mosquée", probably derived from Italian "moschea" (a variant of Italian "moscheta"), from either Middle Armenian մզկիթ ("mzkit‘"), Medieval ("masgídion"), or Spanish "mezquita", from (meaning "site of prostration (in prayer)" and hence a place of worship), either from Nabataean "masgdhā́" or from Arabic (meaning "to bow down in prayer"), probably ultimately from Nabataean Arabic "masgdhā́" or Aramaic "sghēdh".

According to some scholars, Islam started during the lifetime of Muhammad in the 7th century CE, and so did architectural components such as the mosque. In this case, either the Mosque of the Companions in the Eritrean city of Massawa, or the Quba Mosque in the Hejazi city of Medina (the first structure built by Muhammad upon his emigration from Mecca in 622 CE), would be the first mosque that was built in the history of Islam.

Other scholars, referring to passages of the Quran, state that Islam as a religion preceded Muhammad, and includes previous prophets such as Abraham. Abraham in Islam is credited with having built the "Ka'bah" ('Cube') in Mecca, and consequently its sanctuary, "Al-Masjid Al-Haram" (The Sacred Mosque), which is seen as the first mosque that existed. A Hadith in Sahih al-Bukhari states that the sanctuary of the "Kaaba" was the first mosque on Earth, with the second mosque being Al-Aqsa Mosque in Jerusalem, which is also associated with Abraham. Since as early as 638 AD, the Sacred Mosque of Mecca has been expanded on several occasions to accommodate the increasing number of Muslims who either live in the area or make the annual pilgrimage known as "Hajj" to the city.

Either way, after the Quba Mosque, Muhammad went on to establish another mosque in Medina, which is now known as "Al-Masjid an-Nabawi" (The Prophet's Mosque). Built on the site of his home, Muhammad participated in the construction of the mosque himself and helped pioneer the concept of the mosque as the focal point of the Islamic city. The Prophet's mosque introduced some of the features still common in today's mosques, including the niche at the front of the prayer space known as the "mihrab" and the tiered pulpit called the "minbar". The mosque was also constructed with a large courtyard, a motif common among mosques built since then.

Mosques had been built in Iraq and North Africa by the end of the 7th century, as Islam spread outside the Arabian Peninsula with early caliphates. The Imam Husayn Shrine in Karbala is reportedly one of the oldest mosques in Iraq, although its present formtypical of Persian architectureonly goes back to the 11th century. The shrine, while still operating as a mosque, remains one of the holiest sites for Shi'ite Muslims, as it honors the death of the third Shia imam, and Muhammad's grandson, Hussein ibn Ali. The Mosque of Amr ibn al-As was reportedly the first mosque in Egypt, serving as a religious and social center for Fustat (present-day Cairo) during its prime. Like the Imam Husayn Shrine, though, nothing of its original structure remains. With the later Shia Fatimid Caliphate, mosques throughout Egypt evolved to include schools (known as "madrasas"), hospitals, and tombs.

The Great Mosque of Kairouan in present-day Tunisia was reportedly the first mosque built in northwest Africa, with its present form (dating from the 9th century) serving as a model for other Islamic places of worship in the Maghreb. It was the first to incorporate a square minaret (as opposed to the more common circular minaret) and includes naves akin to a basilica. Those features can also be found in Andalusian mosques, including the Grand Mosque of Cordoba, as they tended to reflect the architecture of the Moors instead of their Visigoth predecessors. Still, some elements of Visigothic architecture, like horseshoe arches, were infused into the mosque architecture of Spain and the Maghreb.

The first mosque in East Asia was reportedly established in the 8th century in Xi'an. However, the Great Mosque of Xi'an, whose current building dates from the 18th century, does not replicate the features often associated with mosques elsewhere. Minarets were initially prohibited by the state. Following traditional Chinese architecture, the Great Mosque of Xi'an, like many other mosques in eastern China, resembles a pagoda, with a green roof instead of the yellow roof common on imperial structures in China. Mosques in western China were more likely to incorporate elements, like domes and minarets, traditionally seen in mosques elsewhere.
A similar integration of foreign and local influences could be seen on the Indonesian islands of Sumatra and Java, where mosques, including the Demak Great Mosque, were first established in the 15th century. Early Javanese mosques took design cues from Hindu, Buddhist, and Chinese architectural influences, with tall timber, multi-level roofs similar to the pagodas of Balinese Hindu temples; the ubiquitous Islamic dome did not appear in Indonesia until the 19th century. In turn, the Javanese style influenced the styles of mosques in Indonesia's Austronesian neighbors—Malaysia, Brunei, and the Philippines.
Muslim empires were instrumental in the evolution and spread of mosques. Although mosques were first established in India during the 7th century, they were not commonplace across the subcontinent until the arrival of the Mughals in the 16th and 17th centuries. Reflecting their Timurid origins, Mughal-style mosques included onion domes, pointed arches, and elaborate circular minarets, features common in the Persian and Central Asian styles. The Jama Masjid in Delhi and the Badshahi Mosque in Lahore, built in a similar manner in the mid-17th century, remain two of the largest mosques on the Indian subcontinent.

The Umayyad Caliphate was particularly instrumental in spreading Islam and establishing mosques within the Levant, as the Umayyads constructed among the most revered mosques in the region — Al-Aqsa Mosque and Dome of the Rock in Jerusalem, and the Umayyad Mosque in Damascus. The designs of the Dome of the Rock and the Umayyad Mosque were influenced by Byzantine architecture, a trend that continued with the rise of the Ottoman Empire.

Several of the early mosques in the Ottoman Empire were originally churches or cathedrals from the Byzantine Empire, with the Hagia Sophia (one of those converted cathedrals) informing the architecture of mosques from after the Ottoman conquest of Constantinople. Still, the Ottomans developed their own architectural style characterized by large central rotundas (sometimes surrounded by multiple smaller domes), pencil-shaped minarets, and open facades.

Mosques from the Ottoman period are still scattered across Eastern Europe, but the most rapid growth in the number of mosques in Europe has occurred within the past century as more Muslims have migrated to the continent. Many major European cities are home to mosques, like the Grand Mosque of Paris, that incorporate domes, minarets, and other features often found with mosques in Muslim-majority countries. The first mosque in North America was founded by Albanian Americans in 1915, but the continent's oldest surviving mosque, the Mother Mosque of America, was built in 1934. As in Europe, the number of American mosques has rapidly increased in recent decades as Muslim immigrants, particularly from South Asia, have come in the United States. Greater than forty percent of mosques in the United States were constructed after 2000.

According to early Muslim historians, towns that surrendered without resistance and made treaties with the Muslims were allowed to retain their churches and the towns captured by Muslims had many of their churches converted to mosques. One of the earliest examples of these kinds of conversions was in Damascus, Syria, where in 705 Umayyad caliph Al-Walid I bought the church of St. John from the Christians and had it rebuilt as a mosque in exchange for building a number of new churches for the Christians in Damascus. Overall, Abd al-Malik ibn Marwan (Al-Waleed's father) is said to have transformed 10 churches in Damascus into mosques.

The process of turning churches into mosques were especially intensive in the villages where most of the inhabitants converted to Islam. The Abbasid caliph al-Ma'mun turned many churches into mosques. Ottoman Turks converted nearly all churches, monasteries, and chapels in Constantinople, including the famous Hagia Sophia, into mosques immediately after capturing the city in 1453. In some instances mosques have been established on the places of Jewish or Christian sanctuaries associated with Biblical personalities who were also recognized by Islam.

Mosques have also been converted for use by other religions, notably in southern Spain, following the conquest of the Moors in 1492. The most prominent of them is the Great Mosque of Cordoba, itself constructed on the site of a church demolished during the period of Muslim rule. Outside of the Iberian Peninsula, such instances also occurred in southeastern Europe once regions were no longer under Muslim rule.

The "masjid jāmiʿ" (), a central mosque, can play a role in religious activities such as teaching the Quran and educating future imams.

There are two holidays ("Eids") in the Islamic calendar: "ʿĪd al-Fiṭr" and "ʿĪd al-Aḍḥā", during which there are special prayers held at mosques in the morning. These Eid prayers are supposed to be offered in large groups, and so, in the absence of an outdoor "Eidgah", a large mosque will normally host them for their congregants as well as the congregants of smaller local mosques. Some mosques will even rent convention centers or other large public buildings to hold the large number of Muslims who attend. Mosques, especially those in countries where Muslims are the majority, will also host Eid prayers outside in courtyards, town squares or on the outskirts of town in an "Eidgah".

Islam's holiest month, "Ramaḍān", is observed through many events. As Muslims must fast during the day during Ramadan, mosques will host "Ifṭār" dinners after sunset and the fourth required prayer of the day, that is "Maghrib". Food is provided, at least in part, by members of the community, thereby creating daily potluck dinners. Because of the community contribution necessary to serve "iftar" dinners, mosques with smaller congregations may not be able to host the "iftar" dinners daily. Some mosques will also hold "Suḥūr" meals before dawn to congregants attending the first required prayer of the day, "Fajr". As with iftar dinners, congregants usually provide the food for suhoor, although able mosques may provide food instead. Mosques will often invite poorer members of the Muslim community to share in beginning and breaking the fasts, as providing charity during Ramadan is regarded in Islam as especially honorable.

Following the last obligatory daily prayer ("ʿIshāʾ") special, optional "Tarāwīḥ" prayers are offered in larger mosques. During each night of prayers, which can last for up to two hours each night, usually one member of the community who has memorized the entire Quran (a Hafiz) will recite a segment of the book. Sometimes, several such people (not necessarily of the local community) take turns to do this. During the last ten days of Ramadan, larger mosques will host all-night programs to observe "Laylat al-Qadr", the night Muslims believe that Muhammad first received Quranic revelations. On that night, between sunset and sunrise, mosques employ speakers to educate congregants in attendance about Islam. Mosques or the community usually provide meals periodically throughout the night
During the last ten days of Ramadan, larger mosques within the Muslim community will host "Iʿtikāf", a practice in which at least one Muslim man from the community must participate. Muslims performing itikaf are required to stay within the mosque for ten consecutive days, often in worship or learning about Islam. As a result, the rest of the Muslim community is responsible for providing the participants with food, drinks, and whatever else they need during their stay.

The third of the Five Pillars of Islam states that Muslims are required to give approximately one-fortieth of their wealth to charity as "Zakat". Since mosques form the center of Muslim communities, they are where Muslims go to both give "zakat" and, if necessary, collect it. Before the holiday of "Eid ul-Fitr", mosques also collect a special "zakat" that is supposed to assist in helping poor Muslims attend the prayers and celebrations associated with the holiday.

The frequency by which Muslims attend mosque services vary greatly around the world. In some countries, weekly attendance at religious services are common among Muslims while in others, attendance is rare.

In the United States in particular, it has been shown in a study done by the Institute for Social Policy and Understanding that Muslim Americans who regularly attend mosques are more likely to work with their neighbors to solve community problems (49 vs. 30 percent), be registered to vote (74 vs. 49 percent), and plan to vote (92 vs. 81 percent). The study also states that “there is no correlation between Muslim attitudes toward violence and their frequency of mosque attendance.” 

When it comes to mosque attendance, data shows that American Muslim women and American Muslim men attend the mosque at similar rates (45% for men and 35% for women). Additionally, when compared to the general public looking at the attendance of religious services, young Muslim Americans attend the mosque at closer rates to older Muslim Americans.

"Arab-plan" or hypostyle mosques are the earliest type of mosques, pioneered under the Umayyad Dynasty. These mosques have square or rectangular plans with an enclosed courtyard ("sahn") and covered prayer hall. Historically, in the warm Middle Eastern and Mediterranean climates, the courtyard served to accommodate the large number of worshippers during Friday prayers. Most early hypostyle mosques had flat roofs on prayer halls, which required the use of numerous columns and supports. One of the most notable hypostyle mosques is the Great Mosque of Cordoba in Spain, the building being supported by over 850 columns. Frequently, hypostyle mosques have outer arcades ("riwaq") so that visitors can enjoy the shade. Arab-plan mosques were constructed mostly under the Umayyad and Abbasid dynasties; subsequently, however, the simplicity of the Arab plan limited the opportunities for further development, the mosques consequently losing popularity.

The first departure within mosque design started in Persia (Iran). The Persians had inherited a rich architectural legacy from the earlier Persian dynasties, and they began incorporating elements from earlier Parthian and Sassanid designs into their mosques, influenced by buildings such as the Palace of Ardashir and the Sarvestan Palace. Thus, Islamic architecture witnessed the introduction of such structures as domes and large, arched entrances, referred to as "iwans". During Seljuq rule, as Islamic mysticism was on the rise, the four-iwan arrangement took form. The four-iwan format, finalized by the Seljuqs, and later inherited by the Safavids, firmly established the courtyard façade of such mosques, with the towering gateways at every side, as more important than the actual buildings themselves. They typically took the form of a square-shaped central courtyard with large entrances at each side, giving the impression of gateways to the spiritual world. The Persians also introduced Persian gardens into mosque designs. Soon, a distinctly Persian style of mosques started appearing that would significantly influence the designs of later Timurid, and also Mughal, mosque designs.

The Ottomans introduced central dome mosques in the 15th century. These mosques have a large dome centered over the prayer hall. In addition to having a large central dome, a common feature is smaller domes that exist off-center over the prayer hall or throughout the rest of the mosque, where prayer is not performed. This style was heavily influenced by Byzantine architecture with its use of large central domes.

Mosques built in Southeast Asia often represent the Indonesian-Javanese style architecture, which are different from the ones found throughout the Greater Middle East. The ones found in Europe and North America appear to have various styles but most are built on Western architectural designs, some are former churches or other buildings that were used by non-Muslims. In Africa, most mosques are old but the new ones are built in imitation of those of the Middle East. This can be seen in the Abuja National Mosque in Nigeria and others.

The prayer hall, also known as the "muṣallá" (), rarely has furniture; chairs and pews are generally absent from the prayer hall so as to allow as many worshipers as possible to line the room. Some mosques have Islamic calligraphy and Quranic verses on the walls to assist worshippers in focusing on the beauty of Islam and its holiest book, the Quran, as well as for decoration.
Often, a limited part of the prayer hall is sanctified formally as a masjid in the sharia sense (although the term masjid is also used for the larger mosque complex as well). Once designated, there are onerous limitations on the use of this formally designated masjid, and it may not be used for any purpose other than worship; restrictions that do not necessarily apply to the rest of the prayer area, and to the rest of the mosque complex (although such uses may be restricted by the conditions of the "waqf" that owns the mosque).

In many mosques, especially the early congregational mosques, the prayer hall is in the hypostyle form (the roof held up by a multitude of columns). One of the finest examples of the hypostyle-plan mosques is the Great Mosque of Kairouan (also known as the Mosque of Uqba) in Tunisia.

Usually opposite the entrance to the prayer hall is the "qiblah" wall, the visually emphasized area inside the prayer hall. The qiblah wall should, in a properly oriented mosque, be set perpendicular to a line leading to Mecca, the location of the Kaaba. Congregants pray in rows parallel to the qiblah wall and thus arrange themselves so they face Mecca. In the qiblah wall, usually at its center, is the mihrab, a niche or depression indicating the direction of Mecca. Usually the mihrab is not occupied by furniture either. A raised "minbar" or pulpit is located to the right side of the mihrab for a "Khaṭīb", or some other speaker, to offer a "Khuṭbah" (Sermon) during Friday prayers. The mihrab serves as the location where the imam leads the five daily prayers on a regular basis.
Left to the mihrab, in the front left corner of the mosque, sometimes there is a "kursu" (Turkish , Bosnian ""), a small elevated plateau (rarely with a chair or other type of seat) used for less formal preaching and speeches.

Women who pray in mosques are separated from men there. Their part for prayer is called "makhphil" or "maqfil" (Bosnian ""). It is located above the main prayer hall, elevated in the background as stairs-separated gallery or plateau (surface-shortened to the back relative to the bottom main part). It usually has a perforated fence at the front, through which imam (and male prayers in the main hall) can be partially seen. Makhphil is completely used by men when Jumu'ah is practised (due to lack of space).

A "miḥrāb", also spelled as "mehrab" is a semicircular niche in the wall of a mosque that indicates the "qiblah" (the direction of the Kaaba) in Mecca, and hence the direction that Muslims should face when praying. The wall in which a "mihrab" appears is thus the ""qibla" wall." "Mihrab"s should not be confused with the "minbar", which is the raised platform from which an Imam (leader of prayer) addresses the congregation.

A common feature in mosques is the minaret, the tall, slender tower that usually is situated at one of the corners of the mosque structure. The top of the minaret is always the highest point in mosques that have one, and often the highest point in the immediate area. The tallest minaret in the world is located at the Hassan II Mosque in Casablanca, Morocco. It has a height of and completed in 1993, it was designed by Michel Pinseau.
The first mosques had no minarets, and even nowadays the most conservative Islamic movements, like Wahhabis, avoid building minarets, seeing them as ostentatious and hazardous in case of collapse. The first minaret was constructed in 665 in Basra during the reign of the Umayyad caliph Muawiyah I. Muawiyah encouraged the construction of minarets, as they were supposed to bring mosques on par with Christian churches with their bell towers. Consequently, mosque architects borrowed the shape of the bell tower for their minarets, which were used for essentially the same purpose—calling the faithful to prayer. The oldest standing minaret in the world is the minaret of the Great Mosque of Kairouan in Tunisia, built between the 8th and the 9th century, it is a massive square tower consisting of three superimposed tiers of gradual size and decor.

Before the five required daily prayers, a "Mu’adhdhin" () calls the worshippers to prayer from the minaret. In many countries like Singapore where Muslims are not the majority, mosques are prohibited from loudly broadcasting the "Adhān" (, Call to Prayer), although it is supposed to be said loudly to the surrounding community. The "adhan" is required before every prayer. However, nearly every mosque assigns a "muezzin" for each prayer to say the "adhan" as it is a recommended practice or "Sunnah" () of the Islamic prophet Muhammad. At mosques that do not have minarets, the "adhan" is called instead from inside the mosque or somewhere else on the ground. The "Iqâmah" (), which is similar to the "adhan" and proclaimed right before the commencement of prayers, is usually not proclaimed from the minaret even if a mosque has one.
The domes, often placed directly above the main prayer hall, may signify the vaults of the heaven and sky. As time progressed, domes grew, from occupying a small part of the roof near the mihrab to encompassing the whole roof above the prayer hall. Although domes normally took on the shape of a hemisphere, the Mughals in India popularized onion-shaped domes in South Asia which has gone on to become characteristic of the Arabic architectural style of dome. Some mosques have multiple, often smaller, domes in addition to the main large dome that resides at the center.

As ritual purification precedes all prayers, mosques often have ablution fountains or other facilities for washing in their entryways or courtyards. However, worshippers at much smaller mosques often have to use restrooms to perform their ablutions. In traditional mosques, this function is often elaborated into a freestanding building in the center of a courtyard. This desire for cleanliness extends to the prayer halls where shoes are disallowed to be worn anywhere other than the cloakroom. Thus, foyers with shelves to put shoes and racks to hold coats are commonplace among mosques.

Modern mosques have a variety of amenities available to their congregants. As mosques are supposed to appeal to the community, they may also have additional facilities, from health clinics and clubs (gyms) to libraries to gymnasiums, to serve the community.

Certain symbols are represented in a mosque's architecture to allude to different aspects of the Islamic religion. One of these feature symbols is the spiral. The "cosmic spiral" found in designs and on minarets is a references to heaven as it has "no beginning and no end". Mosques also often have floral patterns or images of fruit and vegetables. These are allusions to the paradise after death.

Mosques, in accordance with Islamic practices, institute a number of rules intended to keep Muslims focused on worshiping God. While there are several rules, such as those regarding not allowing shoes in the prayer hall, that are universal, there are many other rules that are dealt with and enforced in a variety of ways from mosque to mosque.

Appointment of a prayer leader is considered desirable, but not always obligatory. The permanent prayer leader (imam) must be a free honest individual and is authoritative in religious matters. In mosques constructed and maintained by the government, the prayer leader is appointed by the ruler; in private mosques, however, appointment is made by members of the congregation through majority voting. According to the Hanafi school of Islamic jurisprudence, the individual who built the mosque has a stronger claim to the title of imam, but this view is not shared by the other schools.

Leadership at prayer falls into three categories, depending on the type of prayer: five daily prayers, Friday prayer, or optional prayers. According to the Hanafi and Maliki school of Islamic jurisprudence, appointment of a prayer leader for Friday service is mandatory because otherwise the prayer is invalid. The Shafi'i and Hanbali schools, however, argue that the appointment is not necessary and the prayer is valid as long as it is performed in a congregation. A slave may lead a Friday prayer, but Muslim authorities disagree over whether the job can be done by a minor. An imam appointed to lead Friday prayers may also lead at the five daily prayers; Muslim scholars agree to the leader appointed for five daily services may lead the Friday service as well.

All Muslim authorities hold the consensus opinion that only men may lead prayer for men. Nevertheless, women prayer leaders are allowed to lead prayer in front of all-female congregations.

All mosques have rules regarding cleanliness, as it is an essential part of the worshippers' experience. Muslims before prayer are required to cleanse themselves in an ablution process known as "wudu". However, even to those who enter the prayer hall of a mosque without the intention of praying, there are still rules that apply. Shoes must not be worn inside the carpeted prayer hall. Some mosques will also extend that rule to include other parts of the facility even if those other locations are not devoted to prayer. Congregants and visitors to mosques are supposed to be clean themselves. It is also undesirable to come to the mosque after eating something that smells, such as garlic.

Islam requires that its adherents wear clothes that portray modesty. Men are supposed to come to the mosque wearing loose and clean clothes that do not reveal the shape of the body. Likewise, it is recommended that women at a mosque wear loose clothing that covers to the wrists and ankles, and cover their heads with a "Ḥijāb" (), or other covering. Many Muslims, regardless of their ethnic background, wear Middle Eastern clothing associated with Arabic Islam to special occasions and prayers at mosques.

As mosques are places of worship, those within the mosque are required to remain respectful to those in prayer. Loud talking within the mosque, as well as discussion of topics deemed disrespectful, is forbidden in areas where people are praying. In addition, it is disrespectful to walk in front of or otherwise disturb Muslims in prayer. The walls within the mosque have few items, except for possibly Islamic calligraphy, so Muslims in prayer are not distracted. Muslims are also discouraged from wearing clothing with distracting images and symbols so as not to divert the attention of those standing behind them during prayer. In many mosques, even the carpeted prayer area has no designs, its plainness helping worshippers to focus.

There is nothing written in the Qur'an about the issue of space in mosques and gender separation. However, traditional rules have segregated women and men. By traditional rules, women are most often told to occupy the rows behind the men. In part, this was a practical matter as the traditional posture for prayerkneeling on the floor, head to the groundmade mixed-gender prayer uncomfortably revealing for many women and distracting for some men. Traditionalists try to argue that Muhammad preferred women to pray at home rather than at a mosque, and they cite a "ḥadīth" in which Muhammad supposedly said: "The best mosques for women are the inner parts of their houses," although women were active participants in the mosque started by Muhammad. Muhammad told Muslims not to forbid women from entering mosques. They are allowed to go in. The second Sunni caliph 'Umar at one time prohibited women from attending mosques especially at night because he feared they may be sexually harassed or assaulted by men, so he required them to pray at home. Sometimes a special part of the mosque was railed off for women; for example, the governor of Mecca in 870 had ropes tied between the columns to make a separate place for women.

Many mosques today will put the women behind a barrier or partition or in another room. Mosques in South and Southeast Asia put men and women in separate rooms, as the divisions were built into them centuries ago. In nearly two-thirds of American mosques, women pray behind partitions or in separate areas, not in the main prayer hall; some mosques do not admit women at all due to the lack of space and the fact that some prayers, such as the Friday Jumuʻah, are mandatory for men but optional for women. Although there are sections exclusively for women and children, the Grand Mosque in Mecca is desegregated.

Under most interpretations of "sharia", non-Muslims are permitted to enter mosques provided that they respect the place and the people inside it. A dissenting opinion and minority view is presented by followers of the Maliki school of Islamic jurisprudence, who argue that non-Muslims may not be allowed into mosques under any circumstances.

The Quran addresses the subject of non-Muslims, and particularly polytheists, in mosques in two verses in its ninth chapter, Sura At-Tawba. The seventeenth verse of the chapter prohibits those who "join gods with Allah"—polytheists—from maintaining mosques:
The twenty-eighth verse of the same chapter is more specific as it only considers polytheists in the Sacred Mosque, the Masjid al-Haram in Mecca:
According to Ahmad ibn Hanbal, these verses were followed to the letter at the times of Muhammad, when Jews and Christians, considered monotheists, were still allowed to "Al-Masjid Al-Haram". However, the Umayyad caliph Umar II later forbade non-Muslims from entering mosques, and his ruling remains in practice in present-day Saudi Arabia. Today, the decision on whether non-Muslims should be allowed to enter mosques varies. With few exceptions, mosques in the Arabian Peninsula as well as Morocco do not allow entry to non-Muslims. For example, the Hassan II Mosque in Casablanca is one of only two mosques in Morocco currently open to non-Muslims.

However, there are also many other places in the West as well as the Islamic world where non-Muslims are welcome to enter mosques. Most mosques in the United States, for example, report receiving non-Muslim visitors every month. Many mosques throughout the United States welcome non-Muslims as a sign of openness to the rest of the community as well as to encourage conversions to Islam.

In modern-day Saudi Arabia, the Grand Mosque and all of Mecca are open only to Muslims. Likewise, Al-Masjid Al-Nabawi and the city of Medina that surrounds it are also off-limits to those who do not practice Islam. For mosques in other areas, it has most commonly been taken that non-Muslims may only enter mosques if granted permission to do so by Muslims, and if they have a legitimate reason. All entrants regardless of religious affiliation are expected to respect the rules and decorum for mosques.

In modern Turkey, non-Muslim tourists are allowed to enter any mosque, but there are some strict rules. Visiting a mosque is allowed only between prayers; visitors are required to wear long trousers and not to wear shoes, women must cover their heads; visitors are not allowed to interrupt praying Muslims, especially by taking photos of them; no loud talk is allowed; and no references to other religions are allowed (no crosses on necklaces, no cross gestures, etc.) Similar rules apply to mosques in Malaysia, where larger mosques that are also tourist attractions (such as the Masjid Negara) provide robes and headscarves for visitors who are deemed inappropriately attired.

In certain times and places, non-Muslims were expected to behave a certain way in the vicinity of a mosque: in some Moroccan cities, Jews were required to remove their shoes when passing by a mosque; in 18th-century Egypt, Jews and Christians had to dismount before several mosques in veneration of their sanctity.

The association of the mosque with education remained one of its main characteristics throughout history, and the school became an indispensable appendage to the mosque. From the earliest days of Islam, the mosque was the center of the Muslim community, a place for prayer, meditation, religious instruction, political discussion, and a school. Anywhere Islam took hold, mosques were established; and basic religious and educational instruction began.

The late 20th century saw an increase in the number of mosques used for political purposes. While some governments in the Muslim world have attempted to limit the content of Friday sermons to strictly religious topics, there are also independent preachers who deliver "khutbas" that address social and political issues, often in emotionally charged terms. Common themes include social inequalities, necessity of jihad in the face of injustice, the universal struggle between good and evil, with the West often symbolizing moral and spiritual decadence, and criticism of local rulers for corruption and inefficiency. In Islamic countries like Bangladesh, Pakistan, Iran, and Saudi Arabia, political subjects are preached by imams at Friday congregations on a regular basis. Mosques often serve as meeting points for political opposition in times of crisis.

Countries with a minority Muslim population are more likely than Muslim-majority countries of the Greater Middle East to use mosques as a way to promote civic participation. Studies of US Muslims have consistently shown a positive correlation between mosque attendance and political involvement. Some of the research connects civic engagement specifically with mosque attendance for social and religious activities other than prayer. American mosques host voter registration and civic participation drives that promote involving Muslims, who are often first- or second-generation immigrants, in the political process. As a result of these efforts as well as attempts at mosques to keep Muslims informed about the issues facing the Muslim community, regular mosque attendants are more likely to participate in protests, sign petitions, and otherwise be involved in politics. Research on Muslim civic engagement in other Western countries "is less conclusive but seems to indicate similar trends."

As they are considered important to the Muslim community, mosques, like other places of worship, can be at the heart of social conflicts. The Babri Mosque was the subject of such a conflict up until the early 1990s when it was demolished. Before a mutual solution could be devised, the mosque was destroyed on December 6, 1992 as the mosque was built by Babur allegedly on the site of a previous Hindu temple marking the birthplace of Rama. The controversy surrounded the mosque was directly linked to rioting in Bombay (present-day Mumbai) as well as bombings in 1993 that killed 257 people.

Bombings in February 2006 and June 2007 seriously damaged Iraq's al-Askari Mosque and exacerbated existing tensions. Other mosque bombings in Iraq, both before and after the February 2006 bombing, have been part of the conflict between the country's groups of Muslims. However, mosque bombings have not been exclusive to Iraq; in June 2005, a suicide bomber killed at least 19 people at an Afghan Shia mosque near Jade Maivand. In April 2006, two explosions occurred at India's Jama Masjid. Following the al-Askari Mosque bombing in Iraq, imams and other Islamic leaders used mosques and Friday prayers as vehicles to call for calm and peace in the midst of widespread violence.

A study 2005 indicated that while support for suicide bombings is not correlated with personal devotion to Islam among Palestinian Muslims, it is correlated with mosque attendance because "participating in communal religious rituals of any kind likely encourages support for self-sacrificing behaviors that are done for the collective good."

Following the September 11 attacks, several American mosques were targeted in attacks ranging from simple vandalism to arson. Furthermore, the Jewish Defense League was suspected of plotting to bomb the King Fahd Mosque in Culver City, California. Similar attacks occurred throughout the United Kingdom following the 7 July 2005 London bombings. Outside the Western world, in June 2001, the Hassan Bek Mosque was the target of vandalism and attacks by hundreds of Israelis after a suicide bomber killed 19 people in a night club in Tel Aviv. Although mosquegoing is highly encouraged for men, it is permitted to stay at home when one feels at risk from Islamophobic persecution.

Although the Saudi involvement in Sunni mosques around the world can be traced back to the 1960s, it was not until later in the 20th century that the government of Saudi Arabia became a large influence in foreign Sunni mosques. Beginning in the 1980s, the Saudi Arabian government began to finance the construction of Sunni mosques in countries around the world. An estimated US$45 billion has been spent by the Saudi Arabian government financing mosques and Sunni Islamic schools in foreign countries. "Ain al-Yaqeen", a Saudi newspaper, reported in 2002 that Saudi funds may have contributed to building as many as 1,500 mosques and 2,000 other Islamic centers.

Saudi citizens have also contributed significantly to mosques in the Islamic world, especially in countries where they see Muslims as poor and oppressed. Following the fall of the Soviet Union, in 1992, mosques in war-torn Afghanistan saw many contributions from Saudi citizens. The King Fahd Mosque in Culver City, California and the Islamic Cultural Center of Italy in Rome represent two of Saudi Arabia's largest investments in foreign mosques as former Saudi king Fahd bin Abdul Aziz al-Saud contributed US$8 million and US$50 million to the two mosques, respectively.

In the western world, and in the United States in particular, Anti-Muslim sentiment and targeted domestic policy has created challenges for mosques and those looking to build them. There has been government and police surveillance of mosques in the US and local attempts to ban mosques and block constructions, despite data showing that in fact, most Americans opposing banning the building of mosques (79%) and the surveillance of U.S. mosques (63%) as shown in a 2018 study done by the Institute for Social Policy and Understanding.

Ningxia officials were notified on 3 August 2018 that the Weizhou Grand Mosque would be forcibly demolished because it had not received the proper permits before construction. Officials in the town said that the mosque had not been given proper building permits, because it is built in a Middle Eastern style and includes numerous domes and minarets. The residents of Weizhou alarmed each other through social media and finally stopped the mosque destruction by public demonstrations.




</doc>
<doc id="19895" url="https://en.wikipedia.org/wiki?curid=19895" title="Molecular cloud">
Molecular cloud

A molecular cloud, sometimes called a stellar nursery (if star formation is occurring within), is a type of interstellar cloud, the density and size of which permit the formation of molecules, most commonly molecular hydrogen (H). This is in contrast to other areas of the interstellar medium that contain predominantly ionized gas.

Molecular hydrogen is difficult to detect by infrared and radio observations, so the molecule most often used to determine the presence of H is carbon monoxide (CO). The ratio between CO luminosity and H mass is thought to be constant, although there are reasons to doubt this assumption in observations of some other galaxies.

Within molecular clouds are regions with higher density, where much dust and many gas cores reside, called clumps. These clumps are the beginning of star formation if gravitational forces are sufficient to cause the dust and gas to collapse.

Within the Milky Way, molecular gas clouds account for less than one percent of the volume of the interstellar medium (ISM), yet it is also the densest part of the medium, comprising roughly half of the total gas mass interior to the Sun's galactic orbit. The bulk of the molecular gas is contained in a ring between from the center of the Milky Way (the Sun is about 8.5 kiloparsecs from the center). Large scale CO maps of the galaxy show that the position of this gas correlates with the spiral arms of the galaxy. That molecular gas occurs predominantly in the spiral arms suggests that molecular clouds must form and dissociate on a timescale shorter than 10 million years—the time it takes for material to pass through the arm region.
Vertically to the plane of the galaxy, the molecular gas inhabits the narrow midplane of the galactic disc with a characteristic scale height, "Z", of approximately 50 to 75 parsecs, much thinner than the warm atomic ("Z "from 130 to 400 parsecs) and warm ionized ("Z "around 1000 parsecs) gaseous components of the ISM. The exception to the ionized-gas distribution are H II regions, which are bubbles of hot ionized gas created in molecular clouds by the intense radiation given off by young massive stars and as such they have approximately the same vertical distribution as the molecular gas.

This distribution of molecular gas is averaged out over large distances; however, the small scale distribution of the gas is highly irregular with most of it concentrated in discrete clouds and cloud complexes.

A vast assemblage of molecular gas that has more than 10 thousand times the mass of the Sun is called a giant molecular cloud (GMC). GMCs are around 15 to 600 light-years in diameter (5 to 200 parsecs) and typical masses of 10 thousand to 10 million solar masses. Whereas the average density in the solar vicinity is one particle per cubic centimetre, the average density of a GMC is a hundred to a thousand times as great. Although the Sun is much more dense than a GMC, the volume of a GMC is so great that it contains much more mass than the Sun. The substructure of a GMC is a complex pattern of filaments, sheets, bubbles, and irregular clumps.

The densest parts of the filaments and clumps are called "molecular cores", while the densest molecular cores are called "dense molecular cores" and have densities in excess of 10 to 10 particles per cubic centimeter. Observationally, typical molecular cores are traced with CO and dense molecular cores are traced with ammonia. The concentration of dust within molecular cores is normally sufficient to block light from background stars so that they appear in silhouette as dark nebulae.

GMCs are so large that "local" ones can cover a significant fraction of a constellation; thus they are often referred to by the name of that constellation, e.g. the Orion Molecular Cloud (OMC) or the Taurus Molecular Cloud (TMC). These local GMCs are arrayed in a ring in the neighborhood of the Sun coinciding with the Gould Belt. The most massive collection of molecular clouds in the galaxy forms an asymmetrical ring about the galactic center at a radius of 120 parsecs; the largest component of this ring is the Sagittarius B2 complex. The Sagittarius region is chemically rich and is often used as an exemplar by astronomers searching for new molecules in interstellar space.

Isolated gravitationally-bound small molecular clouds with masses less than a few hundred times that of the Sun are called Bok globules. The densest parts of small molecular clouds are equivalent to the molecular cores found in GMCs and are often included in the same studies.

In 1984 IRAS identified a new type of diffuse molecular cloud. These were diffuse filamentary clouds that are visible at high galactic latitudes. These clouds have a typical density of 30 particles per cubic centimeter.

The formation of stars occurs exclusively within molecular clouds. This is a natural consequence of their low temperatures and high densities, because the gravitational force acting to collapse the cloud must exceed the internal pressures that are acting "outward" to prevent a collapse. There is observed evidence that the large, star-forming clouds are confined to a large degree by their own gravity (like stars, planets, and galaxies) rather than by external pressure. The evidence comes from the fact that the "turbulent" velocities inferred from CO linewidth scale in the same manner as the orbital velocity (a virial relation).

The physics of molecular clouds is poorly understood and much debated. Their internal motions are governed by turbulence in a cold, magnetized gas, for which the turbulent motions are highly supersonic but comparable to the speeds of magnetic disturbances. This state is thought to lose energy rapidly, requiring either an overall collapse or a steady reinjection of energy. At the same time, the clouds are known to be disrupted by some process—most likely the effects of massive stars—before a significant fraction of their mass has become stars.

Molecular clouds, and especially GMCs, are often the home of astronomical masers.


</doc>
<doc id="19897" url="https://en.wikipedia.org/wiki?curid=19897" title="Minoru Yamasaki">
Minoru Yamasaki

Yamasaki was born in Seattle, Washington, the son of John Tsunejiro Yamasaki and Hana Yamasaki, "issei" Japanese immigrants. The family later moved to Auburn, Washington and he graduated from Garfield Senior High School in Seattle. He enrolled in the University of Washington program in architecture in 1929, and graduated with a Bachelor of Architecture (B.Arch.) in 1934. During his college years, he was strongly encouraged by faculty member Lionel Pries. He earned money to pay for his tuition by working at an Alaskan salmon cannery, working five summers and earning $50 a month, plus 25 cents an hour in overtime pay.

In part to escape anti-Japanese prejudice, he moved to Manhattan in 1934, with $40 and no prospects. He wrapped dishes for an importing company until he found work as a draftsman and engineer. After moving to New York City in the 1930s, he enrolled at New York University for a master's degree in architecture and got a job with the architecture firm Shreve, Lamb & Harmon, designers of the Empire State Building. In 1945, Yamasaki moved to Detroit, where he was hired by Smith, Hinchman & Grylls. The firm helped Yamasaki avoid internment as a Japanese-American during World War II, and he himself sheltered his parents in New York City. Yamasaki left the firm in 1949, and started his own partnership. He worked out of Birmingham and Troy, Michigan. One of the first projects he designed at his own firm was Ruhl's Bakery at 7 Mile Road and Monica Street in Detroit. In 1964, Yamasaki received a D.F.A. from Bates College.

His firm, Yamasaki & Associates, closed on December 31, 2009.

His first internationally recognized design, the Pacific Science Center with its iconic arches, was constructed by the City of Seattle for the 1962 Seattle World's Fair. His first significant project was the Pruitt–Igoe housing project in St. Louis in 1955. Despite his love of traditional Japanese design and ornamentation, this was a stark, modernist concrete structure. The housing project experienced so many problems that it was demolished in 1972, less than twenty years after its completion. Its destruction is considered by architecture historian Charles Jencks to be the end of modernist architecture.

In 1955, he also designed the "sleek" terminal at Lambert–St. Louis International Airport which led to his 1959 commission to design the Dhahran International Airport in Saudi Arabia. In the 1950s, Yamasaki was commissioned by the Reynolds Company to design an aluminum-wrapped building in Southfield, Michigan, which would "symbolize the auto industry's past and future progress with aluminum." The three-story glass building wrapped in aluminum, known as the Reynolds Metals Company's Great Lakes Sales Headquarters Building, was also supposed to reinforce the company's main product and showcase its admirable characteristics of strength and beauty. During this period, he created a number of office buildings which led to his innovative design of the towers of the World Trade Center in 1964, which began construction March 21, 1966. The first of the towers was finished in 1970. Many of his buildings feature superficial details inspired by the pointed arches of Gothic architecture, and make use of extremely narrow vertical windows. This narrow-windowed style arose from his own personal fear of heights. One particular design challenge of the World Trade Center's design related to the efficacy of the elevator system, which was unique in the world. Yamasaki integrated the fastest elevators at the time, running at 1,700 feet per minute. Instead of placing a large traditional elevator shaft in the core of each tower, Yamasaki created the Twin Towers' "Skylobby" system. The Skylobby design created three separate, connected elevator systems which would serve different segments of the building, depending on which floor was chosen, saving approximately 70% of the space used for a traditional shaft. The space saved was then used for office space.

In 1978, Yamasaki designed the Federal Reserve Bank tower in Richmond, Virginia. The work was designed with a similar appearance as the World Trade Center complex, with its narrow fenestration, and now stands at .

Yamasaki was a member of the Pennsylvania Avenue Commission, created in 1961 to restore the grand avenue in Washington, D.C., but resigned after disagreements and disillusionment with the design by committee approach.

After partnering with Emery Roth and Sons on the design of the World Trade Center, they collaborated on other projects including new buildings at Bolling Air Force Base in Washington, D.C.

The campus for the University of Regina was designed in tandem with Yamasaki's plan for Wascana Centre, a park built around Wascana Lake in Regina, Saskatchewan. The original campus design was approved in 1962. Yamasaki was awarded contracts to design the first three buildings: the Classroom Building; the Laboratory Building; and the Dr. John Archer Library, which were built between 1963 and 1967.

Yamasaki designed two notable synagogues during this period, North Shore Congregation Israel in Glencoe, Illinois in 1964 and Temple Beth El, in Bloomfield Hills, Michigan in 1973. He designed a number of buildings on the campus of Carleton College in Northfield, Minnesota between 1958 and 1968.

Yamasaki was first married in 1941 to Teruko "Teri" Hirashiki. They had three children together: Carol, Taro, and Kim. They divorced in 1961 and Yamasaki married Peggy Watty. He and Watty divorced two years later, and Yamasaki would marry a third time briefly before remarrying Teruko in 1969. In a 1969 "Detroit News" article about the remarriage, Yamasaki said "I'm just going to be nicer to her". Minoru Yamasaki died of stomach cancer when he was 73.

Mr. Yamasaki was survived by his wife; two sons, Kim and Taro, the latter of whom won a Pulitzer Prize while a photographer for The Detroit Free Press; a daughter, Carol Yamasaki Chakrin; a brother, and eight grandchildren.






</doc>
<doc id="19898" url="https://en.wikipedia.org/wiki?curid=19898" title="Madeira">
Madeira

Madeira ( , , ), officially the Autonomous Region of Madeira ("Região Autónoma da Madeira"), is one of the two autonomous regions of Portugal (the other being the Azores). It is an archipelago situated in the North Atlantic Ocean, in a region known as Macaronesia, just under to the north of the Canary Islands and west of Morocco. Madeira is geographically located in the African Tectonic Plate, even though the archipelago is culturally, economically and politically European. Its total population was estimated in 2016 at 289,000. The capital of Madeira is Funchal, which is located on the main island's south coast.

The archipelago includes the islands of Madeira, Porto Santo, and the Desertas, administered together with the separate archipelago of the Savage Islands. The region has political and administrative autonomy through the Administrative Political Statute of the Autonomous Region of Madeira provided for in the Portuguese Constitution. The autonomous region is an integral part of the European Union as an outermost region. Madeira generally has a very mild and moderated subtropical climate with mediterranean summer droughts and winter rain. There are many microclimates courtesy of the elevation changes.

Madeira was claimed by Portuguese sailors in the service of Prince Henry the Navigator in 1419 and settled after 1420. The archipelago is considered to be the first territorial discovery of the exploratory period of the Age of Discovery.

Today, it is a popular year-round resort, being visited every year by about 1.4 million tourists, almost five times its population. The region is noted for its Madeira wine, gastronomy, historical and cultural value, flora and fauna, landscapes (laurel forest) that are classified as a UNESCO World Heritage Site, and embroidery artisans. The main harbour in Funchal has long been the leading Portuguese port in cruise liner dockings, receiving more than half a million tourists through its main port in 2017, being an important stopover for commercial and trans-Atlantic passenger cruises between Europe, the Caribbean and North Africa. In addition, the International Business Centre of Madeira, also known as the Madeira Free Trade Zone, was created formally in the 1980s as a tool of regional economic policy. It consists of a set of incentives, mainly tax-related, granted with the objective of attracting foreign direct investment based on international services into Madeira.
Plutarch in his "Parallel Lives" ("Sertorius", 75 AD) referring to the military commander Quintus Sertorius (d. 72 BC), relates that after his return to Cádiz, he met sailors who spoke of idyllic Atlantic islands: "The islands are said to be two in number separated by a very narrow strait and lie from Africa. They are called the Isles of the Blessed."

Archaeological evidence suggests that the islands may have been visited by the Vikings sometime between 900 and 1030.

During the reign of King Edward III of England, lovers Robert Machim and Anna d'Arfet were said to have fled from England to France in 1346. Driven off course by a violent storm, their ship ran aground along the coast of an island that may have been Madeira. Later this legend was the basis of the naming of the city of Machico on the island, in memory of the young lovers.

Knowledge of some Atlantic islands, such as Madeira, existed before their formal discovery and settlement, as the islands were shown on maps as early as 1339.
In 1418, two captains under service to Prince Henry the Navigator, João Gonçalves Zarco and Tristão Vaz Teixeira, were driven off course by a storm to an island they named Porto Santo (English: "holy harbour") in gratitude for divine deliverance from a shipwreck. The following year, an organised expedition, under the captaincy of Zarco, Vaz Teixeira, and Bartolomeu Perestrello, traveled to the island to claim it on behalf of the Portuguese Crown. Subsequently, the new settlers observed "a heavy black cloud suspended to the southwest." Their investigation revealed it to be the larger island they called Madeira.

The first Portuguese settlers began colonizing the islands around 1420 or 1425.

Grain production began to fall and the ensuing crisis forced Henry the Navigator to order other commercial crops to be planted so that the islands could be profitable. These specialised plants, and their associated industrial technology, created one of the major revolutions on the islands and fuelled Portuguese industry. Following the introduction of the first water-driven sugar mill on Madeira, sugar production increased to over 6,000 "arrobas" (an "arroba" was equal to 11 to 12 kilograms) by 1455, using advisers from Sicily and financed by Genoese capital. (Genoa acted as an integral part of the island economy until the 17th century.) The accessibility of Madeira attracted Genoese and Flemish traders, who were keen to bypass Venetian monopolies.

Sugarcane production was the primary engine of the island's economy, increasing the demand for labour. Enslaved Africans were used during portions of the island's history to cultivate sugar cane, and the proportion of enslaved people brought from Africa reached 10% of the total population of Madeira by the 16th century. Barbary corsairs from North Africa, who enslaved Europeans from ships and coastal communities throughout the Mediterranean region, captured 1,200 people in Porto Santo in 1617. After the 17th century, as Portuguese sugar production was shifted to Brazil, São Tomé and Príncipe and elsewhere, Madeira's most important commodity product became its wine.

The British first amicably occupied the island in 1801 whereafter Colonel William Henry Clinton became governor. A detachment of the 85th Regiment of Foot under Lieutenant-colonel James Willoughby Gordon garrisoned the island.
After the Peace of Amiens, British troops withdrew in 1802, only to reoccupy Madeira in 1807 until the end of the Peninsular War in 1814. In 1856, British troops recovering from cholera, and widows and orphans of soldiers fallen in the Crimean War, were stationed in Funchal, Madeira.

On 31 December 1916, during the Great War, a German U-boat, , captained by Max Valentiner, entered Funchal harbour on Madeira. "U-38" torpedoed and sank three ships, bringing the war to Portugal by extension. The ships sunk were:

After attacking the ships, "U-38" bombarded Funchal for two hours from a range of about . Batteries on Madeira returned fire and eventually forced "U-38" to withdraw.

On 12 December 1917, two German U-boats, "SM U-156" and "SM U-157" (captained by Max Valentiner), again bombarded Funchal. This time the attack lasted around 30 minutes. The U-boats fired 40 shells. There were three fatalities and 17 wounded; a number of houses and Santa Clara church were hit.

Charles I (Karl I), the last Emperor of the Austro-Hungarian Empire, was exiled to Madeira after the war. Determined to prevent an attempt to restore Charles to the throne, the Council of Allied Powers agreed he could go into exile on Madeira because it was isolated in the Atlantic and easily guarded. He died there on 1 April 1922 and his coffin lies in a chapel of the Church of Our Lady of Monte.

The archipelago of Madeira is located from the African coast and from the European continent (approximately a one-and-a-half-hour flight from the Portuguese capital of Lisbon). Madeira is on the same parallel as Bermuda a few time zones further west in the Atlantic. The two archipelagos are the only land in the Atlantic on the 32nd parallel north. Madeira is found in the extreme south of the Tore-Madeira Ridge, a bathymetric structure of great dimensions oriented along a north-northeast to south-southwest axis that extends for . This submarine structure consists of long geomorphological relief that extends from the abyssal plain to 3500 metres; its highest submersed point is at a depth of about 150 metres (around latitude 36ºN). The origins of the Tore-Madeira Ridge are not clearly established, but may have resulted from a morphological "buckling" of the lithosphere.


The island of Madeira is at the top of a massive shield volcano that rises about from the floor of the Atlantic Ocean, on the Tore underwater mountain range. The volcano formed atop an east-west rift in the oceanic crust along the African Plate, beginning during the Miocene epoch over 5 million years ago, continuing into the Pleistocene until about 700,000 years ago. This was followed by extensive erosion, producing two large amphitheatres open to south in the central part of the island. Volcanic activity later resumed, producing scoria cones and lava flows atop the older eroded shield. The most recent volcanic eruptions were on the west-central part of the island only 6,500 years ago, creating more cinder cones and lava flows.

It is the largest island of the group with an area of , a length of (from Ponte de São Lourenço to Ponte do Pargo), while approximately at its widest point (from Ponte da Cruz to Ponte São Jorge), with a coastline of . It has a mountain ridge that extends along the centre of the island, reaching at its highest point (Pico Ruivo), while much lower (below 200 metres) along its eastern extent. The primitive volcanic foci responsible for the central mountainous area, consisted of the peaks: Ruivo (1,862 m), Torres (1,851 m), Arieiro (1,818 m), Cidrão (1,802 m), Cedro (1,759 m), Casado (1,725 m), Grande (1,657 m), Ferreiro (1,582 m). At the end of this eruptive phase, an island circled by reefs was formed, its marine vestiges are evident in a calcareous layer in the area of Lameiros, in São Vicente (which was later explored for calcium oxide production). Sea cliffs, such as Cabo Girão, valleys and ravines extend from this central spine, making the interior generally inaccessible. Daily life is concentrated in the many villages at the mouths of the ravines, through which the heavy rains of autumn and winter usually travel to the sea.

Madeira has many different bioclimates
Based on differences in sun exposure, humidity, and annual mean temperature, there are clear variations between north- and south-facing regions, as well as between some islands. The islands are strongly influenced by the Gulf Stream and Canary Current, giving mild year-round temperatures; according to the Instituto de Meteorologia (IM), the average annual temperature at Funchal weather station is for the 1980–2010 period. Due to the strong influence of the northern African dry air mass, pasture in Madeira is poor in Zink and Calcium fluoride. Because of that, cows in Madeira do not produce milk. Porto Santo has at least one weather station with a semiarid climate ("BSh"). On the highest windward slopes of Madeira, rainfall exceeds 1,250 mm (50 inches) per year, mostly falling between October and April. In most winters snowfall occurs in the mountains of Madeira. The main Madeira island has areas with an annual average temperature exceeding 20 °C (68 °F) along the coast (according to the Portuguese Meteorological Institute).

Madeira island is home to several endemic plant and animal species.
In the south, there is very little left of the indigenous subtropical rainforest that once covered the whole island (the original settlers set fire to the island to clear the land for farming) and gave it the name it now bears ("Madeira" means "wood" in Portuguese). However, in the north, the valleys contain native trees of fine growth. These "laurisilva" forests, called "lauraceas madeirense", notably the forests on the northern slopes of Madeira Island, are designated as a World Heritage Site by UNESCO. The paleobotanical record of Madeira reveals that laurisilva forest has existed in this island for at least 1.8 million years. Critically endangered species such as the vine "Jasminum azoricum" and the rowan "Sorbus maderensis" are endemic to Madeira. The Madeiran large white butterfly was an endemic subspecies of the Large white which inhabited the laurisilva forests but has not been seen since 1977 so may now be extinct.

The Madeiran wall lizard ("Lacerta dugesii") is a species of lizard in the family Lacertidae. The species is endemic to the Island where it is very common, and is the only small lizard, ranging from sea coasts to altitudes of . It is usually found in rocky places or among scrub and may climb into trees. It is also found in gardens and on the walls of buildings. It feeds on small invertebrates such as ants and also eats some vegetable matter. The tail is easily shed and the stump regenerates slowly. The colouring is variable and tends to match the colour of the animal's surroundings, being some shade of brown or grey with occasionally a greenish tinge. Most animals are finely flecked with darker markings. The underparts are white or cream, sometimes with dark spots, with some males having orange or red underparts and blue throats, but these bright colours may fade if the animal is disturbed. The Madeiran wall lizard grows to a snout-to-vent length of about with a tail about 1.7 times the length of its body. Females lay two to three clutches of eggs in a year with the juveniles being about when they hatch.

Two species of birds are endemic to Maderia, the Trocaz pigeon and the Madeira firecrest. In addition to these are the extinct Madeiran scops owl which may have died out soon after the islands were settled, and the Madeiran wood pigeon, a subspecies of the widespread Common wood pigeon and which was last seen in the early 20th century.

The island of Madeira is wet in the northwest, but dry in the southeast. In the 16th century the Portuguese started building levadas or aqueducts to carry water to the agricultural regions in the south. Madeira is very mountainous, and building the levadas was difficult and often convicts or slaves were used. Many are cut into the sides of mountains, and it was also necessary to dig of tunnels, some of which are still accessible.

Today the levadas not only supply water to the southern parts of the island, but provide hydro-electric power. There are over of levadas and they provide a network of walking paths. Some provide easy and relaxing walks through the countryside, but others are narrow, crumbling ledges where a slip could result in serious injury or death. Since 2011, some improvements have been made to these pathways, after the 2010 Madeira floods and mudslides on the Island, to clean and reconstruct some critical parts of the island, including the levadas. Such improvements involved the continuous maintenance of the water streams, cementing the trails, and positioning safety fences on dangerous paths.

Two of the most popular levadas to hike are the "Levada do Caldeirão Verde" and the "Levada do Caldeirão do Inferno", which should not be attempted by hikers prone to vertigo or without torches and helmets. The "Levada do Caniçal" is a much easier walk, running from Maroços to the "Caniçal Tunnel". It is known as the "mimosa levada", because "mimosa" trees, (the colloquial name for invasive acacia) are found all along the route.

Due to its distinct geography, economy, social and cultural situation, as well as the historical autonomic aspirations of the Madeiran island population, the Autonomous Regions of Madeira was established in 1976. Although it is a politico-administrative autonomic region the Portuguese constitution specifies both a regional and national connection, obliging their administrations to maintain democratic principles and promote regional interests, while still reinforcing national unity.

As defined by the Portuguese constitution and other laws, Madeira possesses its own political and administrative statute and has its own government. The branches of Government are the Regional Government and the Legislative Assembly, the later being elected by universal suffrage, using the D'Hondt method of proportional representation.

The president of the Regional Government is appointed by the Representative of the Republic according to the results of the election to the legislative assemblies.

The sovereignty of the Portuguese Republic was represented in Madeira by the Minister of the Republic, proposed by the Government of the Republic and appointed by the President of the Republic. However, after the sixth amendment to the Portuguese Constitution was passed in 2006, the Minister of the Republic was replaced by a less-powerful Representative of the Republic who is appointed by the President, after listening to the Government, but otherwise it is a presidential prerogative. The other tasks of Representative of the Republic are to sign and order the publication of regional legislative decrees and regional regulatory decrees or to exercise the right of veto over regional laws, should these laws be unconstitutional.

Madeira is also an Outermost Region (OMR) of the European Union, meaning that due to its geographical situation, it is entitled to derogation from some EU policies despite being part of the European Union.

According to the Treaty on the Functioning of the European Union, both primary and secondary European Union law applies automatically to Madeira, with possible derogations to take account of its "structural social and economic situation (...) which is compounded by their remoteness, insularity, small size, difficult topography and climate, economic dependence on a few products, the permanence and combination of which severely restrain their development". An example of such derogation is seen in the approval of the International Business Centre of Madeira and other state aid policies to help the rum industry.

Its forms part of the European Union customs area, the Schengen Area and the European Union Value Added Tax Area.

Administratively, Madeira (with a population of 267,302 inhabitants in 2011) and covering an area of is organised into eleven municipalities:

Funchal is the capital and principal city of the Autonomous Region of Madeira, located along the southern coast of the island of Madeira. It is a modern city, located within a natural geological "amphitheatre" composed of vulcanological structure and fluvial hydrological forces. Beginning at the harbour (Porto de Funchal), the neighbourhoods and streets rise almost , along gentle slopes that helped to provide a natural shelter to the early settlers.

The island was settled by Portuguese people, especially farmers from the Minho region, meaning that Madeirans (), as they are called, are ethnically Portuguese, though they have developed their own distinct regional identity and cultural traits.

The region has a total population of just under 270,000, the majority of whom live on the main island of Madeira where the population density is ; meanwhile only around 5,000 live on the Porto Santo island where the population density is .

About 247,000 (96%) of the population are Catholic and Funchal is the location of the Catholic cathedral.

Madeirans migrated to the United States, Venezuela, Brazil, British Guiana, St. Vincent and Trinidad. Madeiran immigrants in North America mostly clustered in the New England and mid-Atlantic states, Toronto, Northern California, and Hawaii. The city of New Bedford is especially rich in Madeirans, hosting the Museum of Madeira Heritage, as well as the annual Madeiran and Luso-American celebration, the Feast of the Blessed Sacrament, the world's largest celebration of Madeiran heritage, regularly drawing crowds of tens of thousands to the city's Madeira Field.

In 1846, when a famine struck Madeira over 6,000 of the inhabitants migrated to British Guiana. In 1891 they numbered 4.3% of the population. In 1902 in Honolulu, Hawaii there were 5,000 Portuguese people, mostly Madeirans. In 1910 this grew to 21,000.

1849 saw an emigration of Protestant religious exiles from Madeira to the United States, by way of Trinidad and other locations in the West Indies. Most of them settled in Illinois with financial and physical aid of the American Protestant Society, headquartered in New York City. In the late 1830s the Reverend Robert Reid Kalley, from Scotland, a Presbyterian minister as well as a physician, made a stop at Funchal, Madeira on his way to a mission in China, with his wife, so that she could recover from an illness. The Rev. Kalley and his wife stayed on Madeira where he began preaching the Protestant gospel and converting islanders from Catholicism. Eventually, the Rev. Kalley was arrested for his religious conversion activities and imprisoned. Another missionary from Scotland, William Hepburn Hewitson, took on Protestant ministerial activities in Madeira. By 1846, about 1,000 Protestant Madeirenses, who were discriminated against and the subjects of mob violence because of their religious conversions, chose to immigrate to Trinidad and other locations in the West Indies in answer for a call for sugar plantation workers. The Madeirenses exiles did not fare well in the West Indies. The tropical climate was unfamiliar and they found themselves in serious economic difficulties. By 1848, the American Protestant Society raised money and sent the Rev. Manuel J. Gonsalves, a Baptist minister and a naturalized U.S. citizen from Madeira, to work with the Rev. Arsénio da Silva, who had emigrated with the exiles from Madeira, to arrange to resettle those who wanted to come to the United States. The Rev. da Silva died in early 1849. Later in 1849, the Rev. Gonsalves was then charged with escorting the exiles from Trinidad to be settled in Sangamon and Morgan counties in Illinois on land purchased with funds raised by the American Protestant Society. Accounts state that anywhere from 700 to 1,000 exiles came to the United States at this time.

There are several large Madeiran communities around the world, such as the number in the UK, including Jersey, the Portuguese British community mostly made up of Madeirans celebrate Madeira Day.

Madeira is part of the Schengen Area.

The Venezuelan (14.4%), British (14.2%), Brazilian (12.1%) and German (7.0%) nationalities constituted the largest foreign communities residing in the Autonomous Region of Madeira in 2017. The Venezuelan community showed a sharp increase (38.0%) in 2017 after migration Socioeconomic crisis in Venezuela. In terms of geographical distribution, it is in Funchal that the foreign population mainly concentrates (59.2% of the total of the Region), followed by Santa Cruz (13.8%), Calheta (7.3%) and Porto Santo (4.0%). The foreign population with resident status in the Autonomous Region of Madeira totaled 6,720 (up by 10.0% from 2016), distributed between residence permits (6,692) and long-stay visas (28).

The Gross domestic product (GDP) of the region was 4.9 billion euros in 2018, accounting for 2.4% of Portugal's economic output. GDP per capita adjusted for purchasing power was 22,500 euros or 75% of the EU27 average in the same year. The GDP per employee was 71% of the EU average.

The setting-up of a free trade zone, also known as the Madeira International Business Center (MIBC) has led to the installation, under more favorable conditions, of infrastructure, production shops and essential services for small and medium-sized industrial enterprises. The International Business Centre of Madeira comprises presently three sectors of investment: the Industrial Free Trade Zone, the International Shipping Register – MAR and the International Services. Madeira's tax regime has been approved by the European Commission as legal State Aid and its deadline has recently been extended by the E.C. until the end of 2027. The International Business Center of Madeira, also known as Madeira Free Trade Zone, was created formally in the 1980s as a tool of regional economic policy. It consists of a set of incentives, mainly of a tax nature, granted with the objective of attracting inward investment into Madeira, recognized as the most efficient mechanism to modernize, diversify and internationalize the regional economy. The decision to create the International Business Center of Madeira was the result of a thorough process of analysis and study. Other small island economies, with similar geographical and economic restraints, had successfully implemented projects of attraction of foreign direct investment based on international services activities, becoming therefore examples of successful economic policies.

Since the beginning, favorable operational and fiscal conditions have been offered in the context of a preferential tax regime, fully recognized and approved by the European Commission in the framework of State aid for regional purposes and under the terms for the Ultra-peripheral Regions set in the Treaties, namely Article 299 of the Treaty on European Union. The IBC of Madeira has therefore been fully integrated in the Portuguese and EU legal systems and, as a consequence, it is regulated and supervised by the competent Portuguese and EU authorities in a transparent and stable business environment, marking a clear difference from the so-called "tax havens" and "offshore jurisdictions", since its inception. In 2015, the European Commission authorized the new state aid regime for new companies incorporated between 2015 and 2020 and the extension of the deadline of the tax reductions until the end of 2027. The present tax regime is outlined in Article 36°-A of the Portuguese Tax Incentives Statute. Available data clearly demonstrates the contribution that this development programme has brought to the local economy over its 20 years of existence: impact in the local labor market, through the creation of qualified jobs for the young population but also for Madeiran professionals who have returned to Madeira thanks to the opportunities now created; an increase in productivity due to the transfer of know how and the implementation of new business practices and technologies; indirect influence on other sectors of activity: business tourism benefits from the visits of investors and their clients and suppliers, and other sectors such as real estate, telecommunications and other services benefit from the growth of their client base; impact on direct sources of revenue: the companies attracted by the IBC of Madeira represent over 40% of the revenue in terms of corporate income tax for the Government of Madeira and nearly 3.000 jobs, most of which qualified, among other benefits. Also there are above average salaries paid by the companies in the IBC of Madeira in comparison with the wages paid in the other sectors of activity in Madeira.

Madeira has been a significant recipient of European Union funding, totaling up to €2 billion. In 2012, it was reported that despite a population of just 250,000, the local administration owes some €6 billion. Furthermore, the Portuguese treasury (IGCP) assumed Madeira's debt management between 2012 and 2015. The region continues to work with the central government on a long-term plan to reduce its debt levels and commercial debt stock. Moody's notes that the region has made significant fiscal consolidation efforts and that its tax revenue collection has increased significantly in recent years due to tax rate hikes. Madeira's tax revenues increased by 41% between 2012 and 2016, helping the region to reduce its deficit to operating revenue ratio to 10% in 2016 from 77% in 2013.

Tourism is an important sector in the region's economy, contributing 20% to the region's GDP, providing support throughout the year for commercial, transport and other activities and constituting a significant market for local products. The share in Gross Value Added of hotels and restaurants (9%) also highlights this phenomenon. The island of Porto Santo, with its beach and its climate, is entirely devoted to tourism.

Visitors are mainly from the European Union, with German, British, Scandinavian and Portuguese tourists providing the main contingents. The average annual occupancy rate was 60.3% in 2008, reaching its maximum in March and April, when it exceeds 70%.

Whale watching has become very popular in recent years. Many species of dolphins, such as common dolphin, spotted dolphin, striped dolphin, bottlenose dolphin, short-finned pilot whale, and whales such as Bryde's whale, Sei whale, fin whale, sperm whale, beaked whales can be spotted near the coast or offshore.

Electricity on Madeira is provided solely through EEM (Empresa de Electricidade da Madeira, SA, which holds a monopoly for the provision of electrical supply on the autonomous region) and consists largely of fossil fuels, but with a significant supply of seasonal hydroelectricity from the levada system, wind power and a small amount of solar. Energy production comes from conventional thermal and hydropower, as well as wind and solar energy. The Ribeira dos Soccoridos hydropower plant, rated at 15MW utilises a pumped hydropower reservoir to recycle mountain water during the dry summer.

In 2011, renewable energy formed 26.5% of the electricity used in Madeira. By 2020, half of Madeira's energy will come from renewable energy sources. This is due to the planned completion of the Pico da Urze / Calheta pumped storage hydropower plant, rated at 30MW.

Battery technologies are being tested to minimize Madeira's reliance on fossil fuel imports. Renault SA and EEM piloted the Sustainable Porto Santo—Smart Fossil Free Island project on Porto Santo to demonstrate how fossil fuels can be entirely replaced with renewable energy.

The Islands have two airports, Cristiano Ronaldo International Airport and Porto Santo Airport, on the islands of Madeira and Porto Santo respectively. From Cristiano Ronaldo International Airport the most frequent flights are to Lisbon. There are also direct flights to over 30 other airports in Europe and nearby islands.

Transport between the two main islands is by plane, or ferries from the Porto Santo Line, the latter also carrying vehicles. Visiting the interior of the islands is now easy thanks to construction of the "Vias Rápidas", major roads that cross the island. Modern roads reach all points of interest on the islands.

Funchal has an extensive public transportation system. Bus companies, including Horários do Funchal, which has been operating for over a hundred years, have regularly scheduled routes to all points of interest on the island.

Folklore music in Madeira is widespread and mainly uses local musical instruments such as the machete, rajao, brinquinho and cavaquinho, which are used in traditional folkloric dances like the "bailinho da Madeira".

Emigrants from Madeira also influenced the creation of new musical instruments. In the 1880s, the ukulele was created, based on two small guitar-like instruments of Madeiran origin, the cavaquinho and the rajao. The ukulele was introduced to the Hawaiian Islands by Portuguese immigrants from Madeira and Cape Verde. Three immigrants in particular, Madeiran cabinet makers Manuel Nunes, José do Espírito Santo, and Augusto Dias, are generally credited as the first ukulele makers. Two weeks after they disembarked from the "SS Ravenscrag" in late August 1879, the "Hawaiian Gazette" reported that "Madeira Islanders recently arrived here, have been delighting the people with nightly street concerts."

Because of the geographic situation of Madeira in the Atlantic Ocean, the island has an abundance of fish of various kinds. The species that are consumed the most are espada (black scabbardfish), blue fin tuna, white marlin, blue marlin, albacore, bigeye tuna, wahoo, spearfish, skipjack tuna and many others are found in the local dishes as they are found up and down the coast of Madeira. Espada is often served with banana. Bacalhau is also popular, as it is in Portugal.

There are many meat dishes on Madeira, one of the most popular being espetada. Espetada is traditionally made of large chunks of beef rubbed in garlic, salt and bay leaf and marinated for 4 to 6 hours in Madeira wine, red wine vinegar and olive oil then skewered onto a bay laurel stick and left to grill over smouldering wood chips. These are so integral a part of traditional eating habits that a special iron stand is available with a T-shaped end, each branch of the "T" having a slot in the middle to hold a brochette (espeto in Portuguese); a small plate is then placed underneath to collect the juices. The brochettes are very long and have a V-shaped blade in order to pierce the meat more easily. It is usually accompanied with the local bread called bolo do caco.

Other popular dishes in Madeira include açorda, feijoada, carne de vinha d'alhos.

Traditional pastries in Madeira usually contain local ingredients, one of the most common being "mel de cana", literally "sugarcane honey" (molasses). The traditional cake of Madeira is called "Bolo de Mel", which translates as (Sugarcane) "Honey Cake" and according to custom, is never cut with a knife, but broken into pieces by hand. It is a rich and heavy cake. The cake commonly well known as "Madeira cake" in England also finds its naming roots in the Island of Madeira.

Malasadas are a Madeiran creation that were taken around the world by emigrants to places such as Hawaii. In Madeira, Malasadas are mainly consumed during the Carnival of Madeira. Pastéis de nata, as in the rest of Portugal, are also very popular.

Milho Frito is a very popular dish in Madeira that is very similar to the Italian dish polenta. Açorda Madeirense is another popular local dish.

The island of Madeira is famous for the quality of its Cherimoya fruits. The Annona Festival is traditional and occurs annually in the parish of Faial. This event encourages the consumption of this fruit and its derivatives, such as liqueurs, puddings, ice cream and smoothies.

Madeira is a fortified wine, produced in the Madeira Islands; varieties may be sweet or dry. It has a history dating back to the Age of Exploration when Madeira was a standard port of call for ships heading to the New World or East Indies. To prevent the wine from spoiling, neutral grape spirits were added. However, wine producers of Madeira discovered, when an unsold shipment of wine returned to the islands after a round trip, that the flavour of the wine had been transformed by exposure to heat and movement. Today, Madeira is noted for its unique winemaking process that involves heating the wine and deliberately exposing the wine to some levels of oxidation. Most countries limit the use of the term "Madeira" to those wines that come from the Madeira Islands, to which the European Union grants Protected designation of origin (PDO) status.

A local beer called Coral is produced by the Madeira Brewery, which dates from 1872. It has achieved 2 Monde Selection Grand Gold Medals, 24 Monde Selection Gold Medals and 2 Monde Selection Silver Medals. Other alcoholic drinks are also popular in Madeira, such as the locally created Poncha, Niquita, Pé de Cabra, Aniz, as well as Portuguese drinks such as Macieira Brandy, Licor Beirão.

Laranjada is a type of carbonated soft drink with an orange flavour, its name being derived from the Portuguese word "laranja" ("orange"). Launched in 1872 it was the first soft drink to be produced in Portugal, and remains very popular to the present day. Brisa drinks, a brand name, are also very popular and come in a range of flavours.

There is also a huge coffee culture in Madeira. Like in mainland Portugal, popular coffee-based drinks include Garoto, Galão, Bica, Café com Cheirinho, Mazagran, Chinesa and many more.

Madeira Island has the following sister provinces:

Portugal has issued postage stamps for Madeira during several periods, beginning in 1868.

The following people were either born or have lived part of their lives in Madeira:





</doc>
<doc id="19901" url="https://en.wikipedia.org/wiki?curid=19901" title="M16 rifle">
M16 rifle

The M16 rifle, officially designated Rifle, Caliber 5.56 mm, M16, is a family of military rifles adapted from the ArmaLite AR-15 rifle for the United States military. The original M16 rifle was a 5.56mm automatic rifle with a 20-round magazine.

In 1964, the M16 entered US military service and the following year was deployed for jungle warfare operations during the Vietnam War. In 1969, the M16A1 replaced the M14 rifle to become the US military's standard service rifle. The M16A1 improvements include a bolt-assist, chrome-plated bore and a 30-round magazine.

In 1983, the US Marine Corps adopted the M16A2 rifle and the US Army adopted it in 1986. The M16A2 fires the improved 5.56×45mm NATO (M855/SS109) cartridge and has a newer adjustable rear sight, case deflector, heavy barrel, improved handguard, pistol grip and buttstock, as well as a semi-auto and three-round burst fire selector. Adopted in July 1997, the M16A4 is the fourth generation of the M16 series. It is equipped with a removable carrying handle and Picatinny rail for mounting optics and other ancillary devices.

The M16 has also been widely adopted by other armed forces around the world. Total worldwide production of M16s is approximately 8 million, making it the most-produced firearm of its 5.56 mm caliber. The US military has largely replaced the M16 in frontline combat units with a shorter and lighter version, the M4 carbine.

In 1928, a U.S. Army 'Caliber Board' conducted firing tests at Aberdeen Proving Grounds and recommended transitioning to smaller caliber rounds, mentioning in particular the .27. Largely in deference to tradition, this recommendation was ignored and the Army referred to the .30 caliber as "full sized" for the next 35 years. After World War II, the United States military started looking for a single automatic rifle to replace the M1 Garand, M1/M2 Carbines, M1918 Browning Automatic Rifle, M3 "Grease Gun" and Thompson submachine gun. However, early experiments with select-fire versions of the M1 Garand proved disappointing. During the Korean War, the select-fire M2 carbine largely replaced the submachine gun in US service and became the most widely used carbine variant. However, combat experience suggested that the .30 Carbine round was under-powered. American weapons designers concluded that an intermediate round was necessary, and recommended a small-caliber, high-velocity cartridge.

However, senior American commanders, having faced fanatical enemies and experienced major logistical problems during WWII and the Korean War, insisted that a single, powerful .30 caliber cartridge be developed, that could not only be used by the new automatic rifle, but by the new general-purpose machine gun (GPMG) in concurrent development. This culminated in the development of the 7.62×51mm NATO cartridge.
The U.S. Army then began testing several rifles to replace the obsolete M1. Springfield Armory's T44E4 and heavier T44E5 were essentially updated versions of the M1 chambered for the new 7.62 mm round, while Fabrique Nationale submitted their FN FAL as the T48. ArmaLite entered the competition late, hurriedly submitting several AR-10 prototype rifles in the fall of 1956 to the U.S. Army's Springfield Armory for testing. The AR-10 featured an innovative straight-line barrel/stock design, forged aluminum alloy receivers and with phenolic composite stocks. It had rugged elevated sights, an oversized aluminum flash suppressor and recoil compensator, and an adjustable gas system. The final prototype featured an upper and lower receiver with the now-familiar hinge and takedown pins, and the charging handle was on top of the receiver placed inside of the carry handle. For a 7.62mm NATO rifle, the AR-10 was incredibly lightweight at only 6.85 lb empty. Initial comments by Springfield Armory test staff were favorable, and some testers commented that the AR-10 was the best lightweight automatic rifle ever tested by the Armory. In the end the U.S. Army chose the T44 now named M14 rifle which was an improved M1 Garand with a 20-round magazine and automatic fire capability. The U.S. also adopted the M60 general purpose machine gun (GPMG). Its NATO partners adopted the FN FAL and HK G3 rifles, as well as the FN MAG and Rheinmetall MG3 GPMGs.

The first confrontations between the AK-47 and the M14 came in the early part of the Vietnam War. Battlefield reports indicated that the M14 was uncontrollable in full-auto and that soldiers could not carry enough ammunition to maintain fire superiority over the AK-47. And, while the M2 carbine offered a high rate of fire, it was under-powered and ultimately outclassed by the AK-47. A replacement was needed: a medium between the traditional preference for high-powered rifles such as the M14, and the lightweight firepower of the M2 Carbine.

As a result, the Army was forced to reconsider a 1957 request by General Willard G. Wyman, commander of the U.S. Continental Army Command (CONARC) to develop a .223-inch caliber (5.56 mm) select-fire rifle weighing when loaded with a 20-round magazine. The 5.56 mm round had to penetrate a standard U.S. helmet at 500 yards (460 meters) and retain a velocity in excess of the speed of sound, while matching or exceeding the wounding ability of the .30 Carbine cartridge.

This request ultimately resulted in the development of a scaled-down version of the Armalite AR-10, named ArmaLite AR-15 rifle. In the late 1950s, designer Eugene Stoner was completing his work on the AR-15. The AR-15 used .22-caliber bullets, which destabilized when they hit a human body, as opposed to the .30 round, which typically passed through in a straight line. The smaller caliber meant that it could be controlled in autofire due the reduced recoil. Being almost one-third the weight of the .30 meant that the soldier could sustain fire for longer with the same load. Due to design innovations, the AR-15 could fire 600 to 700 rounds a minute with an extremely low jamming rate. Parts were stamped out, not hand-machined, so could be mass-produced, and the stock was plastic to reduce weight.
In 1958, the Army's Combat Developments Experimentation Command ran experiments with small squads in combat situations using the M14, AR-15, and another rifle designed by Winchester. The resulting study recommended adopting a lightweight rifle like the AR-15. In response, the Army declared that all rifles and machine guns should use the same ammunition, and ordered full production of the M-14. However, advocates for the AR-15 gained the attention of Air Force Chief of Staff General Curtis LeMay. After testing the AR-15 with the ammunition manufactured by Remington that Armalite and Colt recommended, the Air Force declared that the AR-15 was its 'standard model' and ordered 8,500 rifles and 8.5 million rounds. Advocates for the AR-15 in the Defense Advanced Research Projects Agency acquired 1,000 Air Force AR-15s and shipped them to be tested by the Army of the Republic of Vietnam (ARVN). The South Vietnam soldiers issued glowing reports of the weapon's reliability, recording zero broken parts while firing 80,000 rounds in one stage of testing, and requiring only two replacement parts for the 1,000 weapons over the entire course of testing. The report of the experiment recommended that the U.S. provide the AR-15 as the standard rifle of the ARVN, but Admiral Harry Felt, then Commander in Chief, Pacific Forces, rejected the recommendations on the advice of the U.S. Army.

Throughout 1962 and 1963, the U.S. military extensively tested the AR-15. Positive evaluations emphasized its lightness, "lethality", and reliability. However, the Army Materiel Command criticized its inaccuracy at longer ranges and lack of penetrating power at higher ranges. In early 1963, the U.S. Special Forces asked, and was given permission, to make the AR-15 its standard weapon. Other users included Army Airborne units in Vietnam and some units affiliated with the Central Intelligence Agency. As more units adopted the AR-15, Secretary of the Army Cyrus Vance ordered an investigation into why the weapon had been rejected by the Army. The resulting report found that Army Materiel Command had rigged the previous tests, selecting tests that would favor the M14 and choosing match grade M14s to compete against AR-15s out of the box. At this point, the bureaucratic battle lines were well-defined, with the Army ordnance agencies opposed to the AR-15 and the Air Force and civilian leadership of the Defense Department in favor.

In January 1963, Secretary of Defense Robert McNamara concluded that the AR-15 was the superior weapon system and ordered a halt to M14 production. In late 1963, the Defense Department began mass procurement of rifles for the Air Force and special Army units. Secretary McNamara designated the Army as the procurer for the weapon with the Department, which allowed the Army ordnance establishment to modify the weapon as they wished. The first modification was the additions of a "manual bolt closure," allowing a soldier to ram in a round if it failed to seat properly. The Air Force, which was buying the rifle, and the Marine Corps, which had tested it both objected to this addition, with the Air Force noting, "During three years of testing and operation of the AR-15 rifle under all types of conditions the Air Force has no record of malfunctions that could have been corrected by a manual bolt closing device." They also noted that the closure added weight and complexity, reducing the reliability of the weapon. Colonel Howard Yount, who managed the Army procurement, would later state the bolt closure was added after direction from senior leadership, rather than as a result of any complaint or test result, and testified about the reasons: "the M-1, the M-14, and the carbine had always had something for the soldier to push on; that maybe this would be a comforting feeling to him, or something."

After modifications, the new redesigned rifle was subsequently adopted as the M16 Rifle. "(The M16) was much lighter compared to the M14 it replaced, ultimately allowing soldiers to carry more ammunition. The air-cooled, gas-operated, magazine-fed assault rifle was made of steel, aluminum alloy and composite plastics, truly cutting-edge for the time. Designed with full and semi-automatic capabilities, the weapon initially did not respond well to wet and dirty conditions, sometimes even jamming in combat. After a few minor modifications, the weapon gained in popularity among troops on the battlefield."
Despite its early failures the M16 proved to be a revolutionary design and stands as the longest continuously serving rifle in US military history. It has been adopted by many US allies and the 5.56×45mm NATO cartridge has become not only the NATO standard, but "the standard assault-rifle cartridge in much of the world." It also led to the development of small-caliber high-velocity service rifles by every major army in the world. It is a benchmark against which other assault rifles are judged.

M16s were produced by Colt until the late 1980s, when FN Herstal began to manufacture them.

In July 1960, General Curtis LeMay was impressed by a demonstration of the ArmaLite AR-15. In the summer of 1961, General LeMay was promoted to U.S. Air Force chief of staff, and requested 80,000 AR-15s. However, General Maxwell D. Taylor, chairman of the Joint Chiefs of Staff, advised President John F. Kennedy that having "two" different calibers within the military system at the same time would be problematic and the request was rejected. In October 1961, William Godel, a senior man at the Advanced Research Projects Agency, sent 10 AR-15s to South Vietnam. The reception was enthusiastic, and in 1962 another 1,000 AR-15s were sent. United States Army Special Forces personnel filed battlefield reports lavishly praising the AR-15 and the stopping-power of the 5.56 mm cartridge, and pressed for its adoption.

The damage caused by the 5.56 mm bullet was originally believed to be caused by "tumbling" due to the slow 1 turn in rifling twist rate. However, any pointed lead core bullet will "tumble" after penetration in flesh, because the center of gravity is towards the rear of the bullet. The large wounds observed by soldiers in Vietnam were actually caused by bullet fragmentation created by a combination of the bullet's velocity and construction. These wounds were so devastating, that the photographs remained classified into the 1980s.

However, despite overwhelming evidence that the AR-15 could bring more firepower to bear than the M14, the Army opposed the adoption of the new rifle. U.S. Secretary of Defense Robert McNamara now had two conflicting views: the ARPA report favoring the AR-15 and the Army's position favoring the M14. Even President Kennedy expressed concern, so McNamara ordered Secretary of the Army Cyrus Vance to test the M14, the AR-15 and the AK-47. The Army reported that only the M14 was suitable for service, but Vance wondered about the impartiality of those conducting the tests. He ordered the Army inspector general to investigate the testing methods used; the inspector general confirmed that the testers were biased towards the M14.

In January 1963, Secretary McNamara received reports that M14 production was insufficient to meet the needs of the armed forces and ordered a halt to M14 production. At the time, the AR-15 was the only rifle that could fulfill a requirement of a "universal" infantry weapon for issue to all services. McNamara ordered its adoption, despite receiving reports of several deficiencies, most notably the lack of a chrome-plated chamber.

After modifications (most notably, the charging handle was re-located from under the carrying handle like the AR-10, to the rear of the receiver), the new redesigned rifle was renamed the "Rifle, Caliber 5.56 mm, M16". Inexplicably, the modification to the new M16 did not include a chrome-plated barrel. Meanwhile, the Army relented and recommended the adoption of the M16 for jungle warfare operations. However, the Army insisted on the inclusion of a forward assist to help push the bolt into battery in the event that a cartridge failed to seat into the chamber. The Air Force, Colt and Eugene Stoner believed that the addition of a forward assist was an unjustified expense. As a result, the design was split into two variants: the Air Force's M16 without the forward assist, and the XM16E1 with the forward assist for the other service branches.

In November 1963, McNamara approved the U.S. Army's order of 85,000 XM16E1s; and to appease General LeMay, the Air Force was granted an order for another 19,000 M16s. In March 1964, the M16 rifle went into production and the Army accepted delivery of the first batch of 2,129 rifles later that year, and an additional 57,240 rifles the following year.

In 1964, the Army was informed that DuPont could not mass-produce the IMR 4475 stick powder to the specifications demanded by the M16. Therefore, Olin Mathieson Company provided a high-performance ball propellant. While the Olin WC 846 powder achieved the desired per second muzzle velocity, it produced much more fouling, that quickly jammed the M16s action (unless the rifle was cleaned well and often).

In March 1965, the Army began to issue the XM16E1 to infantry units. However, the rifle was initially delivered without adequate cleaning kits or instructions because Colt had claimed the M16 was self-cleaning. As a result, reports of stoppages in combat began to surface. The most severe problem was known as "failure to extract"—the spent cartridge case remained lodged in the chamber after the rifle was fired. Documented accounts of dead U.S. troops found next to disassembled rifles eventually led to a Congressional investigation.

In February 1967, the improved XM16E1 was standardized as the M16A1. The new rifle had a chrome-plated chamber and bore to eliminate corrosion and stuck cartridges, and other minor modifications. New cleaning kits, powder solvents, and lubricants were also issued. Intensive training programs in weapons cleaning were instituted including a comic book-style operations manual. As a result, reliability problems greatly diminished and the M16A1 rifle achieved widespread acceptance by U.S. troops in Vietnam.

In 1969, the M16A1 officially replaced the M14 rifle to become the U.S. military's standard service rifle. In 1970, the new WC 844 powder was introduced to reduce fouling.

During the early part of its career, the M16 had a reputation for poor reliability and a malfunction rate of two per 1000 rounds fired. The M16's action works by passing high pressure propellant gasses tapped from the barrel down a tube and into the carrier group within the upper receiver, and is commonly referred to as a "direct impingement gas system". The gas goes from the gas tube, through the bolt carrier key, and into the inside of the carrier where it expands in a donut shaped gas cylinder. Because the bolt is prevented from moving forward by the barrel, the carrier is driven to the rear by the expanding gases and thus converts the energy of the gas to movement of the rifle's parts. The back part of the bolt forms a piston head and the cavity in the bolt carrier is the piston sleeve. It is more correct to call it an "internal piston" system." 

This design is much lighter and more compact than a gas-piston design. However, this design requires that combustion byproducts from the discharged cartridge be blown into the receiver as well. This accumulating carbon and vaporized metal build-up within the receiver and bolt-carrier negatively affects reliability and necessitates more intensive maintenance on the part of the individual soldier. The channeling of gasses into the bolt carrier during operation increases the amount of heat that is deposited in the receiver while firing the M16 and causes essential lubricant to be "burned off". This requires frequent and generous applications of appropriate lubricant. Lack of proper lubrication is the most common source of weapon stoppages or jams.

The original M16 fared poorly in the jungles of Vietnam and was infamous for reliability problems in the harsh environment. As a result, it became the target of a Congressional investigation. The investigation found that:

When these issues were addressed and corrected by the M16A1, the reliability problems decreased greatly. According to a 1968 Department of Army report, the M16A1 rifle achieved widespread acceptance by U.S. troops in Vietnam. "Most men armed with the M16 in Vietnam rated this rifle's performance high, however, many men entertained some misgivings about the M16's reliability. When asked what weapon they preferred to carry in combat, 85 percent indicated that they wanted either the M16 or its [smaller]carbine-length version, the XM177E2." Also "the M14 was preferred by 15 percent, while less than one percent wished to carry either the Stoner rifle, the AK-47, the carbine or a pistol." In March 1970, the "President's Blue Ribbon Defense Panel" concluded that the issuance of the M16 saved the lives of 20,000 U.S. servicemen during the Vietnam War, who would have otherwise died had the M14 remained in service. However, the M16 rifle's reputation continues to suffer.
After the introduction of the M4 Carbine, it was found that the shorter barrel length of 14.5 inches also has a negative effect on reliability, as the gas port is located closer to the chamber than the gas port of the standard length M16 rifle: 7.5 inches instead of 13 inches. This affects the M4's timing and increases the amount of stress and heat on the critical components, thereby reducing reliability. In a 2002 assessment the USMC found that the M4 malfunctioned three times more often than the M16A4 (the M4 failed 186 times for 69,000 rounds fired, while the M16A4 failed 61 times). Thereafter, the Army and Colt worked to make modifications to the M4s and M16A4s in order to address the problems found. In tests conducted in 2005 and 2006 the Army found that on average, the new M4s and M16s fired approximately 5,000 rounds between stoppages.

In December 2006, the Center for Naval Analyses (CNA) released a report on U.S. small arms in combat. The CNA conducted surveys on 2,608 troops returning from combat in Iraq and Afghanistan over the past 12 months. Only troops who had fired their weapons at enemy targets were allowed to participate. 1,188 troops were armed with M16A2 or A4 rifles, making up 46 percent of the survey. 75 percent of M16 users (891 troops) reported they were satisfied with the weapon. 60 percent (713 troops) were satisfied with handling qualities such as handguards, size, and weight. Of the 40 percent dissatisfied, most were with its size. Only 19 percent of M16 users (226 troops) reported a stoppage, while 80 percent of those that experienced a stoppage said it had little impact on their ability to clear the stoppage and re-engage their target. Half of the M16 users never experienced failures of their magazines to feed. 83 percent (986 troops) did not need their rifles repaired while in theater. 71 percent (843 troops) were confident in the M16's reliability, defined as level of soldier confidence their weapon will fire without malfunction, and 72 percent (855 troops) were confident in its durability, defined as level of soldier confidence their weapon will not break or need repair. Both factors were attributed to high levels of soldiers performing their own maintenance. 60 percent of M16 users offered recommendations for improvements. Requests included greater bullet lethality, new-built instead of rebuilt rifles, better quality magazines, decreased weight, and a collapsible stock. Some users recommended shorter and lighter weapons such as the M4 carbine. Some issues have been addressed with the issuing of the Improved STANAG magazine in March 2009, and the M855A1 Enhanced Performance Round in June 2010.

In early 2010, two journalists from "The New York Times" spent three months with soldiers and Marines in Afghanistan. While there, they questioned around 100 infantry troops about the reliability of their M16 rifles, as well as the M4 carbine. The troops did not report reliability problems with their rifles. While only 100 troops were asked, they engaged in daily fighting in Marja, including least a dozen intense engagements in Helmand Province, where the ground is covered in fine powdered sand (called "moon dust" by troops) that can stick to firearms. Weapons were often dusty, wet, and covered in mud. Intense firefights lasted hours with several magazines being expended. Only one soldier reported a jam when his M16 was covered in mud after climbing out of a canal. The weapon was cleared and resumed firing with the next chambered round. Furthermore, the Marine Chief Warrant Officer responsible for weapons training and performance of the Third Battalion, Sixth Marines, reported that "We've had nil in the way of problems; we've had no issues", with his battalion's 350 M16s and 700 M4s.

The M16 is a lightweight, 5.56 mm, air-cooled, gas-operated, magazine-fed assault rifle, with a rotating bolt. The M16's receivers are made of 7075 aluminum alloy, its barrel, bolt, and bolt carrier of steel, and its handguards, pistol grip, and buttstock of plastics.

The M16 internal piston action was derived from the original ArmaLite AR-10 and ArmaLite AR-15 actions. This internal piston action system designed by Eugene Stoner is commonly called a direct impingement system, but it does not utilize a conventional direct impingement system. In , the designer states: ″This invention is a true expanding gas system instead of the conventional impinging gas system.″ 
The gas system, bolt carrier, and bolt-locking design were novel for the time.

The M16A1 was especially lightweight at with a loaded 30-round magazine. This was significantly less than the M14 that it replaced at with a loaded 20-round magazine. It is also lighter when compared to the AKM's with a loaded 30-round magazine.

The M16A2 weighs loaded with a 30-round magazine, because of the adoption of a thicker barrel profile. The thicker barrel is more resistant to damage when handled roughly and is also slower to overheat during sustained fire. Unlike a traditional "bull" barrel that is thick its entire length, the M16A2's barrel is only thick forward of the handguards. The barrel profile under the handguards remained the same as the M16A1 for compatibility with the M203 grenade launcher.

Early model M16 barrels had a rifling twist of 4 grooves, right hand twist, 1 turn in 14 inches (1:355.6 mm) bore – as it was the same rifling used by the .222 Remington sporting round. This was shown to make the light .223 Remington bullet yaw in flight at long ranges and it was soon replaced. Later models had an improved rifling with 6 grooves, right hand twist, 1 turn in 12 inches (1:304.8 mm) for increased accuracy and was optimized for use with the standard U.S. M193 cartridge. Current models are optimized for the heavier NATO SS109 bullet and have 6 grooves, right hand twist, 1 turn in 7 in (1:177.8 mm). Weapons designed to accept both the M193 or SS109 rounds (like civilian market clones) usually have a 6-groove, right hand twist, 1 turn in 9 inches (1:228.6 mm) bore, although 1:8 inches and 1:7 inches twist rates are available as well.

"The (M16's) Stoner system provides a very symmetric design that allows straight line movement of the operating components. This allows recoil forces to drive straight to the rear. Instead of connecting or other mechanical parts driving the system, high pressure gas performs this function, reducing the weight of moving parts and the rifle as a whole." The M16's straight-line recoil design, where the recoil spring is located in the stock directly behind the action, and serves the dual function of operating spring and recoil buffer. The stock being in line with the bore also reduces muzzle rise, especially during automatic fire. Because recoil does not significantly shift the point of aim, faster follow-up shots are possible and user fatigue is reduced. Also, current model M16 flash-suppressors also act as compensators to reduce recoil further.
Notes: Free recoil is mathematical equation calculated by using the rifle weight, bullet weight, muzzle velocity, and charge weight. It is that which would be measured if the rifle were fired suspended from strings, free to recoil. A rifle's perceived recoil is also dependent on many other factors which are not readily quantified.

The M16's most distinctive ergonomic feature is the carrying handle and rear sight assembly on top of the receiver. This is a by-product of the original design, where the carry handle served to protect the charging handle. As the line of sight is over the bore, the M16 has an inherent parallax problem. At closer ranges (typically inside 15–20 meters), the shooter must compensate by aiming high to place shots where desired. The M16 has a 500 mm (19.75 inches) sight radius. The M16 uses an L-type flip, aperture rear sight and it is adjustable with two settings: 0 to 300 meters and 300 to 400 meters. The front sight is a post adjustable for elevation in the field. The rear sight can be adjusted in the field for windage. The sights can be adjusted with a bullet tip or pointed tool, as troops are trained to zero their own rifles. The sight picture is the same as the M14, M1, M1 Carbine, and the M1917 Enfield. The M16 also has a "Low Light Level Sight System", which includes a front sight post with a weak light source provided by tritium radioluminescence in an embedded small glass vial and a larger aperture rear sight.

The M16 can also mount a scope on the carrying handle. With the advent of the M16A2, a new fully adjustable rear sight was added, allowing the rear sight to be dialed in for specific range settings between 300 and 800 meters and to allow windage adjustments without the need of a tool or cartridge. Modern versions such as M16A4 have a detachable carrying handle and use Picatinny rails, which allows for the use of various scopes and sighting devices. The current U.S. Army and Air Force issue M4 Carbine comes with the M68 Close Combat Optic and Back-up Iron Sight. The U.S. Marine Corps uses the ACOG Rifle Combat Optic and the U.S. Navy uses EOTech Holographic Weapon Sight.

The M16 rifle is considered to be very accurate. Its light recoil, high-velocity and flat trajectory allow shooters to take head shots out to 300 meters. Newer M16s use the newer M855 cartridge increasing their effective range to 600 meters. They are more accurate than their predecessors and are capable of shooting 1–3-inch groups at 100 yards. "In Fallujah, [Iraq] Marines with ACOG-equipped M16A4s created a stir by taking so many head shots that until the wounds were closely examined, some observers thought the insurgents had been executed." The newest M855A1 EPR cartridge is even more accurate and during testing "...has shown that, on average, 95 percent of the rounds will hit within an 8 × 8-inch target at 600 meters."

The 5.56×45mm cartridge had several advantages over the 7.62×51mm NATO round used in the M14 rifle. It enabled each soldier to carry more ammunition and was easier to control during automatic or burst fire. The 5.56×45mm NATO cartridge can also produce massive wounding effects when the bullet impacts at high speed and yaws ("tumbles") in tissue leading to fragmentation and rapid transfer of energy.

The original ammunition for the M16 was the 55-grain M193 cartridge. When fired from a 20" barrel at ranges of up to 100 meters, the thin-jacketed lead-cored round traveled fast enough (above 2900 ft/s) that the force of striking a human body would cause the round to yaw (or tumble) and fragment into about a dozen pieces of various sizes thus created wounds that were out of proportion to its caliber. These wounds were so devastating that many considered the M16 to be an inhumane weapon. As the 5.56mm round's velocity decreases, so does the number of fragments that it produces. The 5.56mm round does not normally fragment at distances beyond 200 meters or at velocities below 2500 ft/s, and its lethality becomes largely dependent on shot placement.

With the development of the M16A2, the new 62-grain M855 cartridge was adopted in 1983. The heavier bullet had more energy, and was made with a steel core to penetrate Soviet body armor. However, this caused less fragmentation on impact and reduced effects against targets without armor, both of which lessened kinetic energy transfer and wounding ability. Some soldiers and Marines coped with this through training, with requirements to shoot vital areas three times to guarantee killing the target.

However, there have been repeated and consistent reports of the M855's inability to wound effectively (i.e. fragment) when fired from the short barreled M4 carbine (even at close ranges). The M4's 14.5" barrel length reduces muzzle velocity to about 2900 ft/s. This reduced wounding ability is one reason that, despite the Army's transition to short-barrel M4's, the Marine Corps has decided to continue using the M16A4 with its 20″ barrel as the 5.56×45mm M855 is largely dependent upon high velocity in order to wound effectively.

In 2003, the U.S. Army contended that the lack of lethality of the 5.56×45mm was more a matter of perception than fact. With good shot placement to the head and chest, the target was usually defeated without issue. The majority of failures were the result of hitting the target in non-vital areas such as extremities. However, a minority of failures occurred in spite of multiple hits to the chest. In 2006, a study found that 20% of soldiers using the M4 Carbine wanted more lethality or stopping power. In June 2010, the U.S. Army announced it began shipping its new 5.56mm, lead-free, M855A1 Enhanced Performance Round to active combat zones. This upgrade is designed to maximize performance of the 5.56×45mm round, to extend range, improve accuracy, increase penetration and to consistently fragment in soft-tissue when fired from not only standard length M16s, but also the short-barreled M4 carbines. The U.S. Army has been impressed with the new M855A1 EPR round.

The M855A1 EPR may be green, and reports are still pretty thin, but it very well could be the ammunition the Army was asking for all along. It is more effective all around, with improved penetration through Kevlar, mild steel, concrete, and vehicle components like doors and auto glass and even helicopter bodies, to name a few, and better accuracy, higher velocities, less wind sensitivity, and more precision complementing its superior terminal results. that they developed a 7.62 NATO M80A1 EPR variant.

The M16's magazine was meant to be a lightweight, disposable item. As such, it is made of pressed/stamped aluminum and was not designed to be durable. The M16 originally used a 20-round magazine which was later replaced by a bent 30-round design. As a result, the magazine follower tends to rock or tilt, causing malfunctions. Many non-U.S. and commercial magazines have been developed to effectively mitigate these shortcomings (e.g., H&K's all-stainless-steel magazine, Magpul's polymer P-MAG, etc.).

Production of the 30-round magazine started late 1967 but did not fully replace the 20-round magazine until the mid-1970s. Standard USGI aluminum 30-round M16 magazines weigh empty and are long. The newer plastic magazines are about a half-inch longer. The newer steel magazines are about 0.5-inch longer and four ounces heavier. The M16's magazine has become the unofficial NATO STANAG magazine and is currently used by many Western Nations, in numerous weapon systems.

In 2009, the U.S. Military began fielding an "improved magazine" identified by a tan-colored follower. "The new follower incorporates an extended rear leg and modified bullet protrusion for improved round stacking and orientation. The self-leveling/anti-tilt follower minimizes jamming while a wider spring coil profile creates even force distribution. The performance gains have not added weight or cost to the magazines."

In July 2016, the U.S. Army introduced another improvement, the new Enhanced Performance Magazine, which it says will result in a 300% increase in reliability in the M4 Carbine. Developed by the United States Army Armament Research, Development and Engineering Center and the Army Research Laboratory in 2013, it is tan colored with blue follower to distinguish it from earlier, incompatible magazines.

Most M16 rifles have a barrel threaded in 1⁄2-28" threads to incorporate the use of a muzzle device such as a flash suppressor or sound suppressor. The initial flash suppressor design had three tines or prongs and was designed to preserve the shooter's night vision by disrupting the flash. Unfortunately it was prone to breakage and getting entangled in vegetation. The design was later changed to close the end to avoid this and became known as the "A1" or "bird cage" flash suppressor on the M16A1. Eventually on the M16A2 version of the rifle, the bottom port was closed to reduce muzzle climb and prevent dust from rising when the rifle was fired in the prone position. For these reasons, the U.S. military declared the A2 flash suppressor as a compensator or a muzzle brake; but it is more commonly known as the "GI" or "A2" flash suppressor.

The M16's Vortex Flash Hider weighs 3 ounces, is 2.25 inches long, and does not require a lock washer to attach to barrel. It was developed in 1984, and is one of the earliest privately designed muzzle devices. The U.S. military uses the Vortex Flash Hider on M4 carbines and M16 rifles. A version of the Vortex has been adopted by the Canadian Military for the Colt Canada C8 CQB rifle. Other flash suppressors developed for the M16 include the Phantom Flash Suppressor by Yankee Hill Machine (YHM) and the KX-3 by Noveske Rifleworks.

The threaded barrel allows sound suppressors with the same thread pattern to be installed directly to the barrel; however this can result in complications such as being unable to remove the suppressor from the barrel due to repeated firing on full auto or three-round burst. A number of suppressor manufacturers have designed "direct-connect" sound suppressors which can be installed over an existing M16's flash suppressor as opposed to using the barrel's threads.

All current M16 type rifles can mount under-barrel 40 mm grenade-launchers, such as the M203 and M320. Both use the same 40 mm grenades as the older, stand-alone M79 grenade launcher. The M16 can also mount under-barrel 12 gauge shotguns such as KAC Masterkey or the M26 Modular Accessory Shotgun System.

The M234 Riot Control Launcher is an M16-series rifle attachment firing an M755 blank round. The M234 mounts on the muzzle, bayonet lug, and front sight post of the M16. It fires either the M734 64 mm Kinetic Riot Control or the M742 64 mm CSI Riot Control Ring Airfoil Projectiles. The latter produces a 4 to 5-foot tear gas cloud on impact. The main advantage to using Ring Airfoil Projectiles is that their design does not allow them be thrown back by rioters with any real effect. The M234 is no longer used by U.S. forces. It has been replaced by the M203 40 mm grenade launcher and nonlethal ammunition.

The M16 is 44.25 inches (1124 mm) long with an M7 bayonet attached. The M7 bayonet is based on earlier designs such as the M4, M5, & M6 bayonets, all of which are direct descendants of the M3 Fighting Knife and have spear-point blade with a half sharpened secondary edge. The newer M9 bayonet has a clip-point blade with saw teeth along the spine, and can be used as a multi-purpose knife and wire-cutter when combined with its scabbard. The current USMC OKC-3S bayonet bears a resemblance to the Marines' iconic Ka-Bar fighting knife with serrations near the handle.

For use as an ad-hoc automatic rifle, the M16 and M16A1 could be equipped with the XM3 bipod, later standardized as the "Bipod, M3" (1966) and "Rifle Bipod M3" (1983). Weighing only 0.6 lb, the simple and non-adjustable bipod clamps to the barrel of the rifle to allow for supported fire.

The M3 bipod continues to be referenced in at least one official manual as late as 1985, where it is stated that one of the most stable firing positions is "the prone biped [sic] supported for automatic fire."

In March 1970, the U.S. recommended that all NATO forces adopt the 5.56×45mm cartridge. This shift represented a change in the philosophy of the military's long-held position about caliber size. By the mid 1970s, other armies were looking at M16-style weapons. A NATO standardization effort soon started and tests of various rounds were carried out starting in 1977. The U.S. offered the 5.56×45mm M193 round, but there were concerns about its penetration in the face of the wider introduction of body armor. In the end the Belgian 5.56×45mm SS109 round was chosen (STANAG 4172) in October 1980. The SS109 round was based on the U.S. cartridge but included a new stronger, heavier, 62 grain bullet design, with better long range performance and improved penetration (specifically, to consistently penetrate the side of a steel helmet at 600 meters). Due to its design and lower muzzle velocity (about 3110 ft/s) the Belgian SS109 round is considered more humane because it is less likely to fragment than the U.S. M193 round. The NATO 5.56×45mm standard ammunition produced for U.S. forces is designated M855.

In October 1980, shortly after NATO accepted the 5.56×45mm NATO rifle cartridge. Draft Standardization Agreement 4179 (STANAG 4179) was proposed to allow NATO members to easily share rifle ammunition and magazines down to the individual soldier level. The magazine chosen to become the "STANAG magazine" was originally designed for the U.S. M16 rifle. Many NATO member nations, but not all, subsequently developed or purchased rifles with the ability to accept this type of magazine. However, the standard was never ratified and remains a 'Draft STANAG'.

All current M16 type rifles are designed to fire STANAG 22 mm rifle grenades from their integral flash hiders without the use of an adapter. These 22 mm grenade types range from anti-tank rounds to simple finned tubes with a fragmentation hand grenade attached to the end. They come in the "standard" type which are propelled by a blank cartridge inserted into the chamber of the rifle. They also come in the "bullet trap" and "shoot through" types, as their names imply, they use live ammunition. The U.S. military does not generally use rifle grenades; however, they are used by other nations.

The NATO Accessory Rail STANAG 4694, or Picatinny rail STANAG 2324, or a "Tactical Rail" is a bracket used on M16 type rifles to provide a standardized mounting platform. The rail comprises a series of ridges with a T-shaped cross-section interspersed with flat "spacing slots". Scopes are mounted either by sliding them on from one end or the other; by means of a "rail-grabber" which is clamped to the rail with bolts, thumbscrews or levers; or onto the slots between the raised sections. The rail was originally for scopes. However, once established, the use of the system was expanded to other accessories, such as tactical lights, laser aiming modules, night vision devices, reflex sights, foregrips, bipods, and bayonets.

Currently, the M16 is in use by 15 NATO countries and more than 80 countries worldwide.

The weapon that eventually became the M16 series was basically a scaled down AR-10 with an ambidextrous charging handle located within the carrying handle, a narrower front sight "A" frame, and no flash suppressor.

Colt's first two models produced after the acquisition of the rifle from ArmaLite were the 601 and 602, and these rifles were in many ways clones of the original ArmaLite rifle (in fact, these rifles were often found stamped "Colt ArmaLite AR-15, Property of the U.S. Government caliber .223", with no reference to them being M16s). The 601 and 602 are easily identified by their flat lower receivers without raised surfaces around the magazine well and occasionally green or brown furniture. The 601 was adopted first of any of the rifles by the USAF, and was quickly supplemented with the XM16 (Colt Model 602) and later the M16 (Colt Model 604) as improvements were made. There was also a limited purchase of 602s, and a number of both of these rifles found their way to a number of Special Operations units then operating in South East Asia, most notably the U.S. Navy SEALs. The only major difference between the 601 and 602 is the switch from the original 1:14-inch rifling twist to the more common 1:12-inch twist. These weapons were equipped with a triangular charging handle and a bolt hold open device that lacked a raised lower engagement surface. The bolt hold open device had a slanted and serrated surface that had to be engaged with a bare thumb, index finger, or thumbnail because of the lack of this surface. The U.S. Air Force continued to use the ArmaLite AR-15 marked rifles in various configurations into the 1990s.

This was the first M16 variant adopted operationally, originally by the U.S. Air Force. It was equipped with triangular handguards, butt stocks without a compartment for the storage of a cleaning kit, a three-pronged flash suppressor, full auto, and no forward assist. Bolt carriers were originally chrome plated and slick-sided, lacking forward assist notches. Later, the chrome plated carriers were dropped in favor of Army issued notched and parkerized carriers though the interior portion of the bolt carrier is still chrome-lined. The Air Force continued to operate these weapons until around 2001, at which time the Air Force converted all of its M16s to the M16A2 configuration.

The M16 was also adopted by the British SAS, who used it during the Falklands War.

The U.S. Army XM16E1 was essentially the same weapon as the M16 with the addition of a forward assist and corresponding notches in the bolt carrier. The M16A1 was the finalized production model in 1967 and was produced until 1982.

To address issues raised by the XM16E1's testing cycle, a closed, bird-cage flash suppressor replaced the XM16E1's three-pronged flash suppressor which caught on twigs and leaves. Various other changes were made after numerous problems in the field. Cleaning kits were developed and issued while barrels with chrome-plated chambers and later fully lined bores were introduced.

With these and other changes, the malfunction rate slowly declined and new soldiers were generally unfamiliar with early problems. A rib was built into the side of the receiver on the XM16E1 to help prevent accidentally pressing the magazine release button while closing the ejection port cover. This rib was later extended on production M16A1s to help in preventing the magazine release from inadvertently being pressed. The hole in the bolt that accepts the cam pin was crimped inward on one side, in such a way that the cam pin may not be inserted with the bolt installed backwards, which would cause failures to eject until corrected. The M16A1 saw limited use in training capacities until the early 2000s, but is no longer in active service with the U.S., although is still standard issue in many world armies.

The development of the M16A2 rifle was originally requested by the United States Marine Corps as a result of combat experience in Vietnam with the XM16E1 and M16A1. It was officially adopted by the Department of Defense as the "US Rifle, 5.56mm, M16A2" in 1982. The Marines were the first branch of the U.S. Armed Forces to adopt it, in the early/mid-1980s, with the United States Army following suit in the late 1980s.

Modifications to the M16A2 were extensive. In addition to the new rifling, the barrel was made with a greater thickness in front of the front sight post, to resist bending in the field and to allow a longer period of sustained fire without overheating. The rest of the barrel was maintained at the original thickness to enable the M203 grenade launcher to be attached. A new adjustable rear sight was added, allowing the rear sight to be dialed in for specific range settings between 300 and 800 meters to take full advantage of the ballistic characteristics of the new SS109 rounds and to allow windage adjustments without the need of a tool or cartridge. The weapon's reliability allowed it to be widely used around the Marine Corps' special operations divisions as well. The flash suppressor was again modified, this time to be closed on the bottom so it would not kick up dirt or snow when being fired from the prone position, and acting as a recoil compensator.

The front grip was modified from the original triangular shape to a round one, which better fit smaller hands and could be fitted to older models of the M16. The new handguards were also symmetrical so armories need not separate left- and right-hand spares. The handguard retention ring was tapered to make it easier to install and uninstall the handguards. A notch for the middle finger was added to the pistol grip, as well as more texture to enhance the grip. The buttstock was lengthened by . The new buttstock became ten times stronger than the original due to advances in polymer technology since the early 1960s. Original M16 stocks were made from fiberglass-impregnated resin; the newer stocks were engineered from DuPont Zytel glass-filled thermoset polymers. The new stock included a fully textured polymer buttplate for better grip on the shoulder, and retained a panel for accessing a small compartment inside the stock, often used for storing a basic cleaning kit. The heavier bullet reduces muzzle velocity from , to about .

The A2 uses a faster 1:7 twist rifling to better stabilize the heavier NATO-standard ammunition. A spent case deflector was incorporated into the upper receiver immediately behind the ejection port to prevent cases from striking left-handed users. The action was also modified, replacing the fully automatic setting with a three-round burst setting. When using a fully automatic weapon, inexperienced troops often hold down the trigger and "spray" when under fire. The U.S. Army concluded that three-shot groups provide an optimum combination of ammunition conservation, accuracy, and firepower. The USMC has retired the M16A2 in favor of the newer M16A4; a few M16A2s remain in service with the U.S. Army Reserve and National Guard, Air Force, Navy and Coast Guard.

The M16A3 is a modified version of the M16A2 adopted in small numbers by the U.S. Navy SEAL, Seabee, and Security units. It features the M16A1 trigger group providing "safe", "semi-automatic" and "fully automatic" modes instead of the A2's "safe", "semi-automatic", and "burst" modes. Otherwise it is externally identical to the M16A2.

The M16A4 is the fourth generation of the M16 series. It is equipped with a removable carrying handle and a full length quad Picatinny rail for mounting optics and other ancillary devices. The FN M16A4, using safe/semi/burst selective fire, became standard issue for the U.S. Marine Corps.

Military issue rifles are also equipped with a Knight's Armament Company M5 RAS hand guard, allowing vertical grips, lasers, tactical lights, and other accessories to be attached, coining the designation M16A4 MWS (or Modular Weapon System) in U.S. Army field manuals.

Colt also produces M16A4 models for international purchases:

A study of significant changes to Marine M16A4 rifles released in February 2015 outlined several new features that could be added from inexpensive and available components. Those features included: a muzzle compensator in place of the flash suppressor to manage recoil and allow for faster follow-on shots, though at the cost of noise and flash signature and potential overpressure in close quarters; a heavier and/or free-floating barrel to increase accuracy from 4.5 MOA (Minute(s) Of Angle) to potentially 2 MOA; changing the reticle on the Rifle Combat Optic from chevron-shaped to the semi-circle with a dot at the center used in the M27 IAR's Squad Day Optic so as not to obscure the target at long distance; using a trigger group with a more consistent pull force, even a reconsideration of the burst capability; and the addition of ambidextrous charging handles and bolt catch releases for easier use with left-handed shooters.

In 2014, Marine units were provided with a limited number of adjustable stocks in place of the traditional fixed stock for their M16A4s to issue to smaller Marines who would have trouble comfortably reaching the trigger when wearing body armor. The adjustable stocks were added as a standard authorized accessory, meaning units can use operations and maintenance funds to purchase more if needed.

The Marine Corps had long maintained the full-length M16 as their standard infantry rifle, but in October 2015 the switch to the M4 carbine was approved as the standard-issue weapon, giving Marine infantrymen a smaller and more compact weapon. Enough M4s are already in the inventory to re-equip all necessary units by September 2016, and M16A4s will be moved to support and non-infantry Marines.

In the 1970s, Singapore was looking for an assault rifle for the Singapore Armed Forces and chose both the M16 and ArmaLite AR-15. Since importing M16s from the US would be difficult, they made their own copies of the M16, designated M16S1; "S" stood for Singapore. It was replaced by the SAR 21, which was introduced during 1999 and 2000, but is still kept for reserve forces.

In Vietnam, some soldiers were issued a carbine version of the M16 named XM177. The XM177 had a shorter barrel and a telescoping stock, which made it substantially more compact. It also possessed a combination flash hider/sound moderator to reduce problems with muzzle flash and loud report. The Air Force's GAU-5/A (XM177) and the Army's XM177E1 variants differed over the latter's inclusion of a forward assist, although some GAU-5s do have the forward assist. The final Air Force GAU-5/A and Army XM177E2 had an barrel with a longer flash/sound suppressor. The lengthening of the barrel was to support the attachment of Colt's own XM148 40 mm grenade launcher. These versions were also known as the Colt Commando model commonly referenced and marketed as the CAR-15. The variants were issued in limited numbers to special forces, helicopter crews, Air Force pilots, Air Force Security Police Military Working Dog (MWD) handlers, officers, radio operators, artillerymen, and troops other than front line riflemen. Some USAF GAU-5A/As were later equipped with even longer 1/12 rifled barrels as the two shorter versions were worn out. The barrel allowed the use of MILES gear and for bayonets to be used with the sub-machine guns (as the Air Force described them). By 1989, the Air Force started to replace the earlier barrels with 1/7 rifled models for use with the M855-round. The weapons were given the redesignation of GUU-5/P.

These were effectively used by the British Special Air Service during the Falklands War.

The M4 carbine was developed from various outgrowths of these designs, including a number of -barreled A1 style carbines. The XM4 (Colt Model 720) started its trials in 1984, with a barrel of . The weapon became the M4 in 1991. Officially adopted as a replacement for the M3 "Grease Gun" (and the Beretta M9 and M16A2 for select troops) in 1994, it was used with great success in the Balkans and in more recent conflicts, including the Afghanistan and Iraq theaters. The M4 carbine has a three-round burst firing mode, while the M4A1 carbine has a fully automatic firing mode. Both have a Picatinny rail on the upper receiver, allowing the carry handle/rear sight assembly to be replaced with other sighting devices.

Colt also returned to the original "Commando" idea, with its Model 733, essentially a modernized XM177E2 with many of the features introduced on the M16A2.

The Diemaco C7 and C8 are updated variants of the M16 developed and used by the Canadian Forces and are now manufactured by Colt Canada. The C7 is a further development of the experimental M16A1E1. Like earlier M16s, it can be fired in either semi-automatic or automatic mode, instead of the burst function selected for the M16A2. The C7 also features the structural strengthening, improved handguards, and longer stock developed for the M16A2. Diemaco changed the trapdoor in the buttstock to make it easier to access and a spacer of is available to adjust stock length to user preference. The most easily noticeable external difference between American M16A2s and Diemaco C7s is the retention of the A1 style rear sights. Not easily apparent is Diemaco's use of hammer-forged barrels. The Canadians originally desired to use a heavy barrel profile instead.

The C7 has been developed to the C7A1, with a Weaver rail on the upper receiver for a C79 optical sight, and to the C7A2, with different furniture and internal improvements. The Diemaco produced Weaver rail on the original C7A1 variants does not meet the M1913 "Picatinny" standard, leading to some problems with mounting commercial sights. This is easily remedied with minor modification to the upper receiver or the sight itself. Since Diemaco's acquisition by Colt to form Colt Canada, all Canadian produced flattop upper receivers are machined to the M1913 standard.

The C8 is the carbine version of the C7. The C7 and C8 are also used by "Hærens Jegerkommando", "Marinejegerkommandoen" and FSK (Norway), Military of Denmark (all branches), the Royal Netherlands Army and Netherlands Marine Corps as its main infantry weapon. Following trials, variants became the weapon of choice of the British SAS.

The Heckler & Koch HK416 is an assault rifle designed and manufactured by Heckler & Koch. It is based on the M16, and was originally conceived as an improvement based on the Colt M4 carbine family issued to the U.S. military, with the notable inclusion of an HK-proprietary short-stroke gas piston system derived from the Heckler & Koch G36. The HK416 was used by U.S. Navy SEALs to kill Osama bin Laden.

The Mk 4 Mod 0 was a variant of the M16A1 produced for the U.S. Navy SEALs during the Vietnam War and adopted in April 1970. It differed from the basic M16A1 primarily in being optimized for maritime operations and coming equipped with a sound suppressor. Most of the operating parts of the rifle were coated in Kal-Guard, a hole of was drilled through the stock and buffer tube for drainage, and an O-ring was added to the end of the buffer assembly. The weapon could reportedly be carried to the depth of 200 feet (60 m) in water without damage. The initial Mk 2 Mod 0 Blast Suppressor was based on the U.S. Army's Human Engineering Lab's (HEL) M4 noise suppressor. The HEL M4 vented gas directly from the action, requiring a modified bolt carrier. A gas deflector was added to the charging handle to prevent gas from contacting the user. Thus, the HEL M4 suppressor was permanently mounted though it allowed normal semi-automatic and automatic operation. If the HEL M4 suppressor were removed, the weapon would have to be manually loaded after each single shot. On the other hand, the Mk 2 Mod 0 blast suppressor was considered an integral part of the Mk 4 Mod 0 rifle, but it would function normally if the suppressor were removed. The Mk 2 Mod 0 blast suppressor also drained water much more quickly and did not require any modification to the bolt carrier or to the charging handle. In the late 1970s, the Mk 2 Mod 0 blast suppressor was replaced by the Mk 2 blast suppressor made by Knight's Armament Company (KAC). The KAC suppressor can be fully submerged and water will drain out in less than eight seconds. It will operate without degradation even if the rifle is fired at the maximum rate of fire. The U.S. Army replaced the HEL M4 with the much simpler Studies in Operational Negation of Insurgency and Counter-Subversion (SIONICS) MAW-A1 noise and flash suppressor.

Developed to increase the effective range of soldiers in the designated marksman role, the U.S. Navy developed the Mark 12 Special Purpose Rifle (SPR). Configurations in service vary, but the core of the Mark 12 SPR is an 18" heavy barrel with muzzle brake and free float tube. This tube relieves pressure on the barrel caused by standard handguards and greatly increases the potential accuracy of the system. Also common are higher magnification optics ranging from the 6× power Trijicon ACOG to the Leupold Mark 4 Tactical rifle scopes. Firing Mark 262 Mod 0 ammunition with a 77gr Open tip Match bullet, the system has an official effective range of 600+ meters. However published reports of confirmed kills beyond 800 m from Iraq and Afghanistan are not uncommon.

The M231 Firing Port Weapon (FPW) is an adapted version of the M16 assault rifle for firing from ports on the M2 Bradley. The infantry's normal M16s are too long for use in a "buttoned up" fighting vehicle, so the FPW was developed to provide a suitable weapon for this role.

With the expanding Vietnam War, Colt developed two rifles of the M16 pattern for evaluation as possible light sniper or designated marksman rifles. The Colt Model 655 M16A1 Special High Profile was essentially a standard A1 rifle with a heavier barrel and a scope bracket that attached to the rifle's carry handle. The Colt Model 656 M16A1 Special Low Profile had a special upper receiver with no carrying handle. Instead, it had a low-profile iron sight adjustable for windage and a Weaver base for mounting a scope, a precursor to the Colt and Picatinny rails. It also had a hooded front iron sight in addition to the heavy barrel. Both rifles came standard with either a Leatherwood/Realist scope 3–9× Adjustable Ranging Telescope. Some of them were fitted with a Sionics noise and flash suppressor. Neither of these rifles were ever standardized.

These weapons can be seen in many ways to be predecessors of the U.S. Army's SDM-R and the USMC's SAM-R weapons.

As of November 2019, no weapon manufactured as described in the above lines, has been produced.

The M16 is the most commonly manufactured 5.56×45mm rifle in the world. Currently, the M16 is in use by 15 NATO countries and more than 80 countries worldwide. Together, numerous companies in the United States, Canada, and China have produced more than 8,000,000 rifles of all variants. Approximately 90% are still in operation. The M16 replaced both the M14 rifle and M2 carbine as standard infantry rifle of the U.S. armed forces. Although, the M14 continues to see limited service, mostly in sniper, designated marksman, and ceremonial roles.





</doc>
<doc id="19903" url="https://en.wikipedia.org/wiki?curid=19903" title="Marlon Brando">
Marlon Brando

Marlon Brando Jr. (April 3, 1924 – July 1, 2004) was an American actor and film director with a career spanning 60 years, during which he won the Oscar for Best Actor twice. He is well-regarded for his cultural influence on 20th-century film. Brando was also an activist for many causes, notably the civil rights movement and various Native American movements. Having studied with Stella Adler in the 1940s, he is credited with being one of the first actors to bring the Stanislavski system of acting and method acting, derived from the Stanislavski system, to mainstream audiences.

He initially gained acclaim and an Academy Award nomination for reprising the role of Stanley Kowalski in the 1951 film adaptation of Tennessee Williams' play "A Streetcar Named Desire", a role that he originated successfully on Broadway. He received further praise, and an Academy Award, for his performance as Terry Malloy in "On the Waterfront", and his portrayal of the rebellious motorcycle gang leader Johnny Strabler in "The Wild One" proved to be a lasting image in popular culture. Brando received Academy Award nominations for playing Emiliano Zapata in "Viva Zapata!" (1952); Mark Antony in Joseph L. Mankiewicz's 1953 film adaptation of Shakespeare's "Julius Caesar"; and Air Force Major Lloyd Gruver in "Sayonara" (1957), an adaptation of James Michener's 1954 novel.

The 1960s saw Brando's career take a commercial and critical downturn. He directed and starred in the cult western "One-Eyed Jacks", a critical and commercial flop, after which he delivered a series of notable box-office failures, beginning with "Mutiny on the Bounty" (1962). After ten years of underachieving, he agreed to do a screen test as Vito Corleone in Francis Ford Coppola's "The Godfather" (1972). He got the part and subsequently won his second Academy Award in a performance critics consider among his greatest. He refused the award due to mistreatment and misportrayal of Native Americans by Hollywood. "The Godfather" was one of the most commercially successful films of all time, and alongside his Oscar-nominated performance in "Last Tango in Paris", Brando reestablished himself in the ranks of top box-office stars.

After a hiatus in the early 1970s, Brando was generally content with being a highly paid character actor in supporting roles, such as in "Superman" (1978), as Colonel Kurtz in "Apocalypse Now" (1979), and in "The Formula" (1980), before taking a nine-year break from film. According to the "Guinness Book of World Records", Brando was paid a record $3.7 million ($ million in inflation-adjusted dollars) and 11.75% of the gross profits for 13 days' work on "Superman".

Brando was ranked by the American Film Institute as the fourth-greatest movie star among male movie stars whose screen debuts occurred in or before 1950. He was one of only six actors named in 1999 by "Time" magazine in its list of the . In this list, "Time" also designated Brando as the "Actor of the Century".

Brando was born in Omaha, Nebraska on April 3, 1924 to Marlon Brando (1895–1965), a pesticide and chemical feed manufacturer, and Dorothy Julia Pennebaker (1897–1954). Brando had two older sisters named Jocelyn Brando (1919–2005) and Frances (1922–1994). His ancestry was German, Dutch, English, and Irish. His patrilineal immigrant ancestor, Johann Wilhelm Brandau, arrived in New York in the early 1700s from the Palatinate in Germany. He is also a descendant of Louis DuBois, a French Huguenot, who arrived in New York around 1660. Brando was raised a Christian Scientist.

His mother, known as Dodie, was unconventional for her time; she smoked, wore pants, and drove cars. An actress herself and a theater administrator, she helped Henry Fonda begin his acting career. However, she was an alcoholic and often had to be brought home from Chicago bars by her husband. In his autobiography, "Songs My Mother Taught Me", Brando expressed sadness when writing about his mother: "The anguish that her drinking produced was that she preferred getting drunk to caring for us." Dodie and Brando's father eventually joined Alcoholics Anonymous. Brando harbored far more enmity for his father, stating, "I was his namesake, but nothing I did ever pleased or even interested him. He enjoyed telling me I couldn't do anything right. He had a habit of telling me I would never amount to anything." Around 1930, Brando's parents moved to Evanston, Illinois, when his father's work took him to Chicago, but separated in 1935 when Brando was 11 years old. His mother took the three children to Santa Ana, California, where they lived with her mother. By 1937, Brando's parents reconciled, and by the next year left Evanston and moved together to a farm in Libertyville, Illinois, a small town north of Chicago. Between 1939 and 1941, he worked as an usher at the town's only movie theater, The Liberty.

Brando, whose childhood nickname was "Bud", was a mimic from his youth. He developed an ability to absorb the mannerisms of children he played with and display them dramatically while staying in character. He was introduced to neighborhood boy Wally Cox and the two were closest friends until Cox's death in 1973. In the 2007 TCM biopic, "Brando: The Documentary", childhood friend George Englund recalls Brando's earliest acting as imitating the cows and horses on the family farm as a way to distract his mother from drinking. His sister Jocelyn was the first to pursue an acting career, going to study at the American Academy of Dramatic Arts in New York City. She appeared on Broadway, then films and television. Brando's sister Frances left college in California to study art in New York. Brando had been held back a year in school and was later expelled from Libertyville High School for riding his motorcycle through the corridors.

He was sent to Shattuck Military Academy in Minnesota, where his father had studied before him. Brando exceled at theater and did well in the school. In his final year (1943), he was put on probation for being insubordinate to a visiting army colonel during maneuvers. He was confined to his room, but sneaked into town and was caught. The faculty voted to expel him, though he was supported by the students, who thought expulsion was too harsh. He was invited back for the following year, but decided instead to drop out of high school. Brando worked as a ditch-digger as a summer job arranged by his father. He tried to enlist in the Army, but his induction physical revealed that a football injury he had sustained at Shattuck had left him with a trick knee. He was classified 4-F and not inducted.

Brando decided to follow his sisters to New York, studying at the American Theatre Wing Professional School, part of the Dramatic Workshop of the New School, with influential German director Erwin Piscator. In a 1988 documentary, "Marlon Brando: The Wild One", Brando's sister Jocelyn remembered, "He was in a school play and enjoyed it ... So he decided he would go to New York and study acting because that was the only thing he had enjoyed. That was when he was 18." In the A&E "Biography" episode on Brando, George Englund said Brando fell into acting in New York because "he was accepted there. He wasn't criticized. It was the first time in his life that he heard good things about himself." He spent his first few months in New York sleeping on friends' couches. For a time he lived with Roy Somlyo, who later became a four time Emmy winning Broadway producer.

Brando was an avid student and proponent of Stella Adler, from whom he learned the techniques of the Stanislavski system. This technique encouraged the actor to explore both internal and external aspects to fully realize the character being portrayed. Brando's remarkable insight and sense of realism were evident early on. Adler used to recount that when teaching Brando, she had instructed the class to act like chickens, and added that a nuclear bomb was about to fall on them. Most of the class clucked and ran around wildly, but Brando sat calmly and pretended to lay an egg. Asked by Adler why he had chosen to react this way, he said, "I'm a chicken—what do I know about bombs?" Despite being commonly regarded as a method actor, Brando disagreed. He claimed to have abhorred Lee Strasberg's teachings:

Brando was the first to bring a natural approach to acting on film. According to Dustin Hoffman in his online Masterclass, Brando would often talk to camera men and fellow actors about their weekend even after the director would call action. Once Brando felt he could deliver the dialogue as natural as that conversation he would start the dialogue. In his 2015 documentary, "Listen To Me Marlon", he said before that actors were like breakfast cereals, meaning they were predictable. Critics would later say this was Brando being difficult, but actors who worked opposite would say it was just all part of his technique.

Brando used his Stanislavski System skills for his first summer stock roles in Sayville, New York, on Long Island. Brando established a pattern of erratic, insubordinate behavior in the few shows he had been in. His behavior had him kicked out of the cast of the New School's production in Sayville, but he was soon afterwards discovered in a locally produced play there. Then, in 1944, he made it to Broadway in the bittersweet drama "I Remember Mama", playing the son of Mady Christians. The Lunts wanted Brando to play the role of Alfred Lunt's son in "O Mistress Mine", and Lunt even coached him for his audition, but Brando's reading during the audition was so desultory that they couldn't hire him. New York Drama Critics voted him "Most Promising Young Actor" for his role as an anguished veteran in "Truckline Café", although the play was a commercial failure. In 1946, he appeared on Broadway as the young hero in the political drama "A Flag is Born", refusing to accept wages above the Actors' Equity rate. In that same year, Brando played the role of Marchbanks alongside Katharine Cornell in her production's revival of "Candida", one of her signature roles. Cornell also cast him as the Messenger in her production of Jean Anouilh's "Antigone" that same year. He was also offered the opportunity to portray one of the principal characters in the Broadway premiere of Eugene O'Neill's "The Iceman Cometh", but turned the part down after falling asleep while trying to read the massive script and pronouncing the play "ineptly written and poorly constructed".

In 1945, Brando's agent recommended he take a co-starring role in "The Eagle Has Two Heads" with Tallulah Bankhead, produced by Jack Wilson. Bankhead had turned down the role of Blanche Dubois in "A Streetcar Named Desire", which Williams had written for her, to tour the play for the 1946–1947 season. Bankhead recognized Brando's potential, despite her disdain (which most Broadway veterans shared) for method acting, and agreed to hire him even though he auditioned poorly. The two clashed greatly during the pre-Broadway tour, with Bankhead reminding Brando of his mother, being her age and also having a drinking problem. Wilson was largely tolerant of Brando's behavior, but he reached his limit when Brando mumbled through a dress rehearsal shortly before the November 28, 1946, opening. "I don't care what your grandmother did," Wilson exclaimed, "and that Method stuff, I want to know what you're going to do!" Brando in turn raised his voice, and acted with great power and passion. "It was marvelous," a cast member recalled. "Everybody hugged him and kissed him. He came ambling offstage and said to me, 'They don't think you can act unless you can yell.'"

Critics were not as kind, however. A review of Brando's performance in the opening assessed that Brando was "still building his character, but at present fails to impress." One Boston critic remarked of Brando's prolonged death scene, "Brando looked like a car in midtown Manhattan searching for a parking space." He received better reviews at subsequent tour stops, but what his colleagues recalled was only occasional indications of the talent he would later demonstrate. "There were a few times when he was really magnificent," Bankhead admitted to an interviewer in 1962. "He was a great young actor when he wanted to be, but most of the time I couldn't even hear him on the stage."

Brando displayed his apathy for the production by demonstrating some shocking onstage manners. He "tried everything in the world to ruin it for her," Bankhead's stage manager claimed. "He nearly drove her crazy: scratching his crotch, picking his nose, doing anything." After several weeks on the road, they reached Boston, by which time Bankhead was ready to dismiss him. This proved to be one of the greatest blessings of his career, as it freed him up to play the role of Stanley Kowalski in Tennessee Williams's 1947 play "A Streetcar Named Desire", directed by Elia Kazan. Bankhead had recommended him to Williams for the role of Stanley, thinking he was perfect for the part.

Pierpont writes that John Garfield was first choice for the role, but "made impossible demands." It was Kazan's decision to fall back on the far less experienced (and technically too young for the role) Brando. In a letter dated August 29, 1947, Williams confided to his agent Audrey Wood: "It had not occurred to me before what an excellent value would come through casting a very young actor in this part. It humanizes the character of Stanley in that it becomes the brutality and callousness of youth rather than a vicious old man ... A new value came out of Brando's reading which was by far the best reading I have ever heard." Brando based his portrayal of Kowalski on the boxer Rocky Graziano, whom he had studied at a local gymnasium. Graziano did not know who Brando was, but attended the production with tickets provided by the young man. He said, "The curtain went up and on the stage is that son of a bitch from the gym, and he's playing me."

In 1947, Brando performed a screen test for an early Warner Brothers script for the novel "Rebel Without a Cause" (1944), which bore no relation to the film eventually produced in 1955. The screen test is included as an extra in the 2006 DVD release of "A Streetcar Named Desire".
Brando's first screen role was a bitter paraplegic veteran in "The Men" (1950). He spent a month in bed at the Birmingham Army Hospital in Van Nuys to prepare for the role. "The New York Times" reviewer Bosley Crowther wrote that Brando as Ken "is so vividly real, dynamic and sensitive that his illusion is complete" and noted, "Out of stiff and frozen silences he can lash into a passionate rage with the tearful and flailing frenzy of a taut cable suddenly cut."

By Brando's own account, it may have been because of this film that his draft status was changed from 4-F to 1-A. He had had surgery on his trick knee, and it was no longer physically debilitating enough to incur exclusion from the draft. When Brando reported to the induction center, he answered a questionnaire by saying his race was "human", his color was "Seasonal-oyster white to beige", and he told an Army doctor that he was psychoneurotic. When the draft board referred him to a psychiatrist, Brando explained that he had been expelled from military school and had severe problems with authority. Coincidentally, the psychiatrist knew a doctor friend of Brando. Brando avoided military service during the Korean War.

Early in his career, Brando began using cue cards instead of memorizing his lines. Despite the objections of several of the film directors he worked with, Brando felt that this helped bring realism and spontaneity to his performances. He felt otherwise he would appear to be reciting a writer's speech. In the TV documentary "The Making of Superman: The Movie", Brando explained:

However, some thought Brando used the cards out of laziness or an inability to memorize his lines. Once on "The Godfather" set, Brando was asked why he wanted his lines printed out. He responded, "Because I can read them that way."

Brando brought his performance as Stanley Kowalski to the screen in Tennessee William's "A Streetcar Named Desire" (1951). The role is regarded as one of Brando's greatest. The reception of Brando's performance was so positive that Brando quickly became a male sex symbol in Hollywood. The role earned him his first Academy Award nomination in the Best Actor category.
He was also nominated the next year for "Viva Zapata!" (1952), a fictionalized account of the life of Mexican revolutionary Emiliano Zapata. It recounted his peasant upbringing, his rise to power in the early 20th century, and death. The film was directed by Elia Kazan and co-starred Anthony Quinn. In the biopic "Marlon Brando: The Wild One", Sam Shaw says, "Secretly, before the picture started, he went to Mexico to the very town where Zapata lived and was born in and it was there that he studied the speech patterns of people, their behavior, movement." Most critics focused on the actor rather than the film, with "Time" and "Newsweek" publishing rave reviews.

Years later, in his autobiography, Brando remarked: "Tony Quinn, whom I admired professionally and liked personally, played my brother, but he was extremely cold to me while we shot that picture. During our scenes together, I sensed a bitterness toward me, and if I suggested a drink after work, he either turned me down or else was sullen and said little. Only years later did I learn why." Brando related that, to create on-screen tension between the two, "Gadg" (Kazan) had told Quinn—who had taken over the role of Stanley Kowalski on Broadway after Brando had finished—that Brando had been unimpressed with his work. After achieving the desired effect, Kazan never told Quinn that he had misled him. It was only many years later, after comparing notes, that Brando and Quinn realized the deception.

Brando's next film, "Julius Caesar" (1953), received highly favorable reviews. Brando portrayed Mark Antony. While most acknowledged Brando's talent, some critics felt Brando's "mumbling" and other idiosyncrasies betrayed a lack of acting fundamentals and, when his casting was announced, many remained dubious about his prospects for success. Directed by Joseph L. Mankiewicz and co-starring British stage actor John Gielgud, Brando delivered an impressive performance, especially during Antony's noted "Friends, Romans, countrymen ..." speech. Gielgud was so impressed that he offered Brando a full season at the Hammersmith Theatre, an offer he declined. In his biography on the actor, Stefan Kanfer writes, "Marlon's autobiography devotes one line to his work on that film: Among all those British professionals, 'for me to walk onto a movie set and play Mark Anthony was asinine'—yet another example of his persistent self-denigration, and wholly incorrect." Kanfer adds that after a screening of the film, director John Huston commented, "Christ! It was like a furnace door opening—the heat came off the screen. I don't know another actor who could do that." During the filming of "Julius Caesar", Brando learned that Elia Kazan had cooperated with congressional investigators, naming a whole string of "subversives" to the House Committee on Un-American Activities (HUAC). By all accounts, Brando was upset by his mentor's decision, but he worked with him again in "On The Waterfront". "None of us is perfect," he later wrote in his memoir, "and I think that Gadg has done injury to others, but mostly to himself."

In 1953, Brando also starred in "The Wild One", riding his own Triumph Thunderbird 6T motorcycle. Triumph's importers were ambivalent at the exposure, as the subject matter was rowdy motorcycle gangs taking over a small town. The film was criticized for its perceived gratuitous violence at the time, with "Time" stating, "The effect of the movie is not to throw light on the public problem, but to shoot adrenaline through the moviegoer's veins." Brando allegedly did not see eye to eye with the Hungarian director László Benedek and did not get on with costar Lee Marvin.

To Brando's expressed puzzlement, the movie inspired teen rebellion and made him a role model to the nascent rock-and-roll generation and future stars such as James Dean and Elvis Presley. After the movie's release, the sales of leather jackets and blue jeans skyrocketed. Reflecting on the movie in his autobiography, Brando concluded that it had not aged very well but said:

Later that same year, Brando starred in Lee Falk's production of George Bernard Shaw's "Arms and the Man" in Boston. Falk was proud to tell people that Brando turned down an offer of $10,000 per week on Broadway, in favor of working in his production in Boston, for less than $500 per week.

In 1954, Brando starred in "On the Waterfront", a crime drama film about union violence and corruption among longshoremen. The film was directed by Elia Kazan and written by Budd Schulberg; it also starred Karl Malden, Lee J. Cobb, Rod Steiger and, in her film debut, Eva Marie Saint. When initially offered the role, Brando—still stung by Kazan's testimony to HUAC—demurred and the part of Terry Malloy nearly went to Frank Sinatra. According to biographer Stefan Kanfer, the director believed that Sinatra, who grew up in Hoboken (where the film takes place and was shot), would work as Malloy, but eventually producer Sam Spiegel wooed Brando to the part, signing him for $100,000. "Kazan made no protest because, he subsequently confessed, 'I always preferred Brando to anybody.'"
Brando won the Oscar for his role as Irish-American stevedore Terry Malloy in "On the Waterfront". His performance, spurred on by his rapport with Eva Marie Saint and Kazan's direction, was praised as a "tour de force". For the scene in which Terry laments his failings, saying "I coulda been a contender", he convinced Kazan that the scripted scene was unrealistic. Schulberg's script had Brando acting the entire scene with his character being held at gunpoint by his brother Charlie, played by Rod Steiger. Brando insisted on gently pushing away the gun, saying that Terry would never believe that his brother would pull the trigger and doubting that he could continue his speech while fearing a gun on him. Kazan let Brando improvise and later expressed deep admiration for Brando's instinctive understanding, saying:

Upon its release, "On the Waterfront" received glowing reviews from critics and was a commercial success, earning an estimated $4.2 million in rentals at the North American box office in 1954. In his July 29, 1954, review, "The New York Times" critic A. H. Weiler praised the film, calling it "an uncommonly powerful, exciting, and imaginative use of the screen by gifted professionals." Film critic Roger Ebert lauded the film, stating that Brando and Kazan changed acting in American films forever and added it to his "Great Movies" list. In his autobiography, Brando was typically dismissive of his performance: "On the day Gadg showed me the complete picture, I was so depressed by my performance I got up and left the screening room ... I thought I was a huge failure." After Brando won the Academy Award for Best Actor, the statue was stolen. Much later, it turned up at a London auction house, which contacted the actor and informed him of its whereabouts.

Following "On the Waterfront", Brando remained a top box office draw, but critics increasingly felt his performances were half-hearted, lacking the intensity and commitment found in his earlier work, especially in his work with Kazan. He portrayed Napoleon in the 1954 film "Désirée". According to co-star Jean Simmons, Brando's contract forced him to star in the movie. He put little effort into the role, claiming he didn't like the script, and later dismissed the entire movie as "superficial and dismal". Brando was especially contemptuous of director Henry Koster.

Brando and Simmons were paired together again in the film adaptation of the musical "Guys and Dolls" (1955). "Guys and Dolls" would be Brando's first and last musical role. "Time" found the picture "false to the original in its feeling", remarking that Brando "sings in a faraway tenor that sometimes tends to be flat." Appearing in Edward Murrow's "Person to Person" interview in early 1955, he admitted to having problems with his singing voice, which he called "pretty terrible." In the 1965 documentary "Meet Marlon Brando", he revealed that the final product heard in the movie was a result of countless singing takes being cut into one and later joked, "I couldn't hit a note with a baseball bat; some notes I missed by extraordinary margins ... They sewed my words together on one song so tightly that when I mouthed it in front of the camera, I nearly asphyxiated myself". Relations between Brando and costar Frank Sinatra were also frosty, with Stefan Kanfer observing: "The two men were diametrical opposites: Marlon required multiple takes; Frank detested repeating himself." Upon their first meeting Sinatra reportedly scoffed, "Don't give me any of that Actors Studio shit." Brando later quipped, "Frank is the kind of guy, when he dies, he's going to heaven and give God a hard time for making him bald." Frank Sinatra called Brando "the world's most overrated actor", and referred to him as "mumbles". The film was commercially though not critically successful, costing $5.5 million to make and grossing $13 million.

Brando played Sakini, a Japanese interpreter for the U.S. Army in postwar Japan, in "The Teahouse of the August Moon" (1956). Pauline Kael was not particularly impressed by the movie, but noted "Marlon Brando starved himself to play the pixie interpreter Sakini, and he looks as if he's enjoying the stunt—talking with a mad accent, grinning boyishly, bending forward, and doing tricky movements with his legs. He's harmlessly genial (and he is certainly missed when he's offscreen), though the fey, roguish role doesn't allow him to do what he's great at and it's possible that he's less effective in it than a lesser actor might have been." In "Sayonara" (1957) he appeared as a United States Air Force officer. "Newsweek" found the film a "dull tale of the meeting of the twain", but it was nevertheless a box-office success. According to Stefan Kanfer's biography of the actor, Brando's manager Jay Kanter negotiated a profitable contract with ten percent of the gross going to Brando, which put him in the millionaire category. The movie was controversial due to openly discussing interracial marriage, but proved a great success, earning 10 Academy Award nominations, with Brando being nominated for Best Actor. The film went on to win four Academy Awards. "Teahouse" and "Sayonara" were the first in a string of films Brando would strive to make over the next decade which contained socially relevant messages, and he formed a partnership with Paramount to establish his own production company called Pennebaker, its declared purpose to develop films that contained "social value that would improve the world." The name was a tribute in honor of his mother, who had died in 1954. By all accounts, Brando was devastated by her death, with biographer Peter Manso telling A&E's "Biography", "She was the one who could give him approval like no one else could and, after his mother died, it seems that Marlon stops caring." Brando appointed his father to run Pennebaker. In the same A&E special, George Englund claims that Brando gave his father the job because "it gave Marlon a chance to take shots at him, to demean and diminish him".

In 1958, Brando appeared in "The Young Lions", dyeing his hair blonde and assuming a German accent for the role, which he later admitted was not convincing. The film is based on the novel by Irwin Shaw, and Brando's portrayal of the character Christian Diestl was controversial for its time. He later wrote, "The original script closely followed the book, in which Shaw painted all Germans as evil caricatures, especially Christian, whom he portrayed as a symbol of everything that was bad about Nazism; he was mean, nasty, vicious, a cliché of evil ... I thought the story should demonstrate that there are no inherently 'bad' people in the world, but they can easily be misled." Shaw and Brando even appeared together for a televised interview with CBS correspondent David Schoenbrun and, during a bombastic exchange, Shaw charged that, like most actors, Brando was incapable of playing flat-out villainy; Brando responded by stating "Nobody creates a character but an actor. I play the role; now he exists. He is my creation." "The Young Lions" also features Brando's only appearance in a film with friend and rival Montgomery Clift (although they shared no scenes together). Brando closed out the decade by appearing in "The Fugitive Kind" (1960) opposite Anna Magnani. The film was based on another play by Tennessee Williams but was hardly the success "A Streetcar Named Desire" had been, with the "Los Angeles Times" labeling Williams's personae "psychologically sick or just plain ugly" and "The New Yorker" calling it a "cornpone melodrama".

In 1961, Brando made his directorial debut in the western "One-Eyed Jacks". The picture was originally directed by Stanley Kubrick, but he was fired early in the production. Paramount then made Brando the director. Brando portrays the lead character Rio, and Karl Malden plays his partner "Dad" Longworth. The supporting cast features Katy Jurado, Ben Johnson, and Slim Pickens. Brando's penchant for multiple retakes and character exploration as an actor carried over into his directing, however, and the film soon went over budget; Paramount expected the film to take three months to complete but shooting stretched to six and the cost doubled to more than six million dollars. Brando's inexperience as an editor also delayed postproduction and Paramount eventually took control of the film. Brando later wrote, "Paramount said it didn't like my version of the story; I'd had everyone lie except Karl Malden. The studio cut the movie to pieces and made him a liar, too. By then, I was bored with the whole project and walked away from it." "One-Eyed Jacks" was poorly reviewed by critics. While the film did solid business, it ran so over budget that it lost money.
Brando's revulsion with the film industry reportedly boiled over on the set of his next film, Metro-Goldwyn-Mayer's remake of "Mutiny on the Bounty", which was filmed in Tahiti. The actor was accused of deliberately sabotaging nearly every aspect of the production. On June 16, 1962, "The Saturday Evening Post" ran an article by Bill Davidson with the headline "Six million dollars down the drain: the mutiny of Marlon Brando". "Mutiny" director Lewis Milestone claimed that the executives "deserve what they get when they give a ham actor, a petulant child, complete control over an expensive picture." " Mutiny on the Bounty" nearly capsized MGM and, while the project had indeed been hampered with delays other than Brando's behavior, the accusations would dog the actor for years as studios began to fear Brando's difficult reputation. Critics also began taking note of his fluctuating weight.

Distracted by his personal life and becoming disillusioned with his career, Brando began to view acting as a means to a financial end. Critics protested when he started accepting roles in films many perceived as being beneath his talent, or criticized him for failing to live up to the better roles. Previously only signing short-term deals with film studios, in 1961 Brando uncharacteristically signed a five-picture deal with Universal Studios that would haunt him for the rest of the decade. "The Ugly American" (1963) was the first of these films. Based on the 1958 novel of the same title that Pennebaker had optioned, the film, which featured Brando's sister Jocelyn, was rated fairly positively but died at the box office. Brando was nominated for a Golden Globe for his performance. All of Brando's other Universal films during this period, including "Bedtime Story" (1964), "The Appaloosa" (1966), "A Countess from Hong Kong" (1967) and "The Night of the Following Day" (1969), were also critical and commercial flops. "Countess" in particular was a disappointment for Brando, who had looked forward to working with one of his heroes, director Charlie Chaplin. The experience turned out to be an unhappy one; Brando was horrified at Chaplin's didactic style of direction and his authoritarian approach. Brando had also appeared in the spy thriller "Morituri" in 1965; that, too, failed to attract an audience.

Brando acknowledged his professional decline, writing later, "Some of the films I made during the sixties were successful; some weren't. Some, like "The Night of the Following Day", I made only for the money; others, like "Candy", I did because a friend asked me to and I didn't want to turn him down ... In some ways I think of my middle age as the Fuck You Years." "Candy" was especially appalling for many; a 1968 sex farce film directed by Christian Marquand and based on the 1958 novel by Terry Southern, the film satirizes pornographic stories through the adventures of its naive heroine, Candy, played by Ewa Aulin. It is generally regarded as the nadir of Brando's career. "The Washington Post" observed: "Brando's self-indulgence over a dozen years is costing him and his public his talents." In the March 1966 issue of "The Atlantic", Pauline Kael wrote that in his rebellious days, Brando "was antisocial because he knew society was crap; he was a hero to youth because he was strong enough not to take the crap", but now Brando and others like him had become "buffoons, shamelessly, pathetically mocking their public reputations." In an earlier review of "The Appaloosa" in 1966, Kael wrote that the actor was "trapped in another dog of a movie ... Not for the first time, Mr. Brando gives us a heavy-lidded, adenoidally openmouthed caricature of the inarticulate, stalwart loner." Although he feigned indifference, Brando was hurt by the critical mauling, admitting in the 2015 film "Listen to Me Marlon", "They can hit you every day and you have no way of fighting back. I was very convincing in my pose of indifference, but I was very sensitive and it hurt a lot."

Brando portrayed a repressed gay army officer in "Reflections in a Golden Eye", directed by John Huston and costarring Elizabeth Taylor. The role turned out as one of his most acclaimed in years, with Stanley Crouch marveling, "Brando's main achievement was to portray the taciturn but stoic gloom of those pulverized by circumstances." The film overall received mixed reviews. Another notable film was "The Chase" (1966), which paired the actor with Arthur Penn, Robert Duvall, Jane Fonda and Robert Redford. The film deals with themes of racism, sexual revolution, small-town corruption, and vigilantism. The film was received mostly positively.

Brando cited "Burn!" (1969) as his personal favorite of the films he had made, writing in his autobiography, "I think I did some of the best acting I've ever done in that picture, but few people came to see it." Brando dedicated a full chapter to the film in his memoir, stating that the director, Gillo Pontecorvo, was the best director he had ever worked with next to Kazan and Bernardo Bertolucci. Brando also detailed his clashes with Pontecorvo on the set and how "we nearly killed each other." Loosely based on events in the history of Guadeloupe, the film got a hostile reception from critics. In 1971, Michael Winner directed him in the British horror film "The Nightcomers" with Stephanie Beacham, Thora Hird, Harry Andrews and Anna Palk. It is a prequel to "The Turn of the Screw", which later became the 1961 film "The Innocents". Brando's performance earned him a nomination for a Best Actor BAFTA, but the film bombed at the box office.

During the 1970s, Brando was considered "unbankable". Critics were becoming increasingly dismissive of his work and he had not appeared in a box office hit since "The Young Lions" in 1958, the last year he had ranked as one of the Top Ten Box Office Stars and the year of his last Academy Award nomination, for "Sayonara." Brando's performance as Vito Corleone, the "Don," in "The Godfather" (1972), Francis Ford Coppola's adaptation of Mario Puzo's 1969 bestselling novel of the same name, was a career turning point, putting him back in the Top Ten and winning him his second Best Actor Oscar.

Paramount production chief Robert Evans, who had given Puzo an advance to write "The Godfather" so that Paramount would own the film rights, hired Coppola after many major directors had turned the film down. Evans wanted an Italian-American director who could provide the film with cultural authenticity. Coppola also came cheap. Evans was conscious of the fact that Paramount's last Mafia film, "The Brotherhood" (1968) had been a box office bomb, and he believed it was partly due to the fact that the director, Martin Ritt, and the star, Kirk Douglas, were Jews and the film lacked an authentic Italian flavor. The studio originally intended the film to be a low-budget production set in contemporary times without any major actors, but the phenomenal success of the novel gave Evans the clout to turn "The Godfather" into a prestige picture.

Coppola had developed a list of actors for all the roles, and his list of potential Dons included the Oscar-winning Italian-American Ernest Borgnine, the Italian-American Frank de Kova (best known for playing Chief Wild Eagle on the TV sitcom "F-Troop"), John Marley (a Best Supporting Oscar-nominee for Paramount's 1970 hit film "Love Story" who was cast as the film producer Jack Woltz in the picture), the Italian-American Richard Conte (who was cast as Don Corleone's deadly rival Don Emilio Barzini), and Italian film producer Carlo Ponti. Coppola admitted in a 1975 interview, "We finally figured we had to lure the "best" actor in the world. It was that simple. That boiled down to Laurence Olivier or Marlon Brando, who "are" the greatest actors in the world." The holographic copy of Coppola's cast list shows Brando's name underlined.

Evans told Coppola that he had been thinking of Brando for the part two years earlier, and Puzo had imagined Brando in the part when he wrote the novel and had actually written to him about the part, so Coppola and Evans narrowed it down to Brando. (Ironically, Olivier would compete with Brando for the Best Actor Oscar for his part in "Sleuth." He bested Brando at the 1972 New York Film Critics Circle Awards.) Albert S. Ruddy, whom Paramount assigned to produce the film, agreed with the choice of Brando. However, Paramount studio heads were opposed to casting Brando due to his reputation for difficulty and his long string of box office flops. Brando also had "One-Eyed Jacks" working against him, a troubled production that lost money for Paramount when it was released in 1961. Paramount Pictures President Stanley Jaffe told an exasperated Coppola, "As long as I'm president of this studio, Marlon Brando will not be in this picture, and I will no longer allow you to discuss it."

Jaffe eventually set three conditions for the casting of Brando: That he would have to take a fee far below what he typically received; he'd have to agree to accept financial responsibility for any production delays his behavior cost; and he had to submit to a screen test. Coppola convinced Brando to a videotaped "make-up" test, in which Brando did his own makeup (he used cotton balls to simulate the character's puffed cheeks). Coppola had feared Brando might be too young to play the Don, but was electrified by the actor's characterization as the head of a crime family. Even so, he had to fight the studio in order to cast the temperamental actor. Brando had doubts himself, stating in his autobiography, "I had never played an Italian before, and I didn't think I could do it successfully." Eventually, Charles Bluhdorn, the president of Paramount parent Gulf+Western, was won over to letting Brando have the role; when he saw the screen test, he asked in amazement, "What are we watching? Who is this old guinea?" Brando was signed for a low fee of $50,000, but in his contract, he was given a percentage of the gross on a sliding scale: 1% of the gross for each $10 million over a $10 million threshold, up to 5% if the picture exceeded $60 million. According to Evans, Brando sold back his points in the picture for $100,000, as he was in dire need of funds. "That $100,000 cost him $11 million," Evans claimed.

In a 1994 interview that can be found on the Academy of Achievement website, Coppola insisted, ""The Godfather" was a very unappreciated movie when we were making it. They were very unhappy with it. They didn't like the cast. They didn't like the way I was shooting it. I was always on the verge of getting fired." When word of this reached Brando, he threatened to walk off the picture, writing in his memoir, "I strongly believe that directors are entitled to independence and freedom to realize their vision, though Francis left the characterizations in our hands and we had to figure out what to do." In a 2010 television interview with Larry King, Al Pacino also talked about how Brando's support helped him keep the role of Michael Corleone in the movie—despite the fact Coppola wanted to fire him. Brando was on his best behavior during filming, buoyed by a cast that included Pacino, Robert Duvall, James Caan, and Diane Keaton. In the "Vanity Fair" article "The Godfather Wars", Mark Seal writes, "With the actors, as in the movie, Brando served as the head of the family. He broke the ice by toasting the group with a glass of wine." 'When we were young, Brando was like the godfather of actors,' says Robert Duvall. 'I used to meet with Dustin Hoffman in Cromwell's Drugstore, and if we mentioned his name once, we mentioned it 25 times in a day.' Caan adds, 'The first day we met Brando everybody was in awe.'"

Brando's performance was glowingly reviewed by critics. "I thought it would be interesting to play a gangster, maybe for the first time in the movies, who wasn't like those bad guys Edward G. Robinson played, but who is kind of a hero, a man to be respected," Brando recalled in his autobiography. "Also, because he had so much power and unquestioned authority, I thought it would be an interesting contrast to play him as a gentle man, unlike Al Capone, who beat up people with baseball bats." Duvall later marveled to A&E's "Biography", "He minimized the sense of beginning. In other words he, like, deemphasized the word "action". He would go in front of that camera just like he was before. "Cut!" It was all the same. There was really no beginning. I learned a lot from watching that." Brando won the Academy Award for Best Actor for his performance, but he declined it, becoming the second actor to refuse a Best Actor award (after George C. Scott for "Patton"). He boycotted the award ceremony, instead sending indigenous American rights activist Sacheen Littlefeather, who appeared in full Apache attire, to state Brando's reasons, which were based on his objection to the depiction of indigenous Americans by Hollywood and television.

The actor followed "The Godfather" with Bernardo Bertolucci's 1972 film "Last Tango in Paris" opposite Maria Schneider, but Brando's highly noted performance threatened to be overshadowed by an uproar over the sexual content of the film. Brando portrays a recent American widower named Paul, who begins an anonymous sexual relationship with a young, betrothed Parisian woman named Jeanne. As with previous films, Brando refused to memorize his lines for many scenes; instead, he wrote his lines on cue cards and posted them around the set for easy reference, leaving Bertolucci with the problem of keeping them out of the picture frame. The film features several intense, graphic scenes involving Brando, including Paul anally raping Jeanne using butter as a lubricant, which it was alleged was not consensual, and Paul's angry, emotionally charged final confrontation with the corpse of his dead wife. The controversial movie was a hit, however, and Brando made the list of Top Ten Box Office Stars for the last time. His gross participation deal earned him $3 million. The voting membership of the Academy of Motion Picture Arts & Sciences again nominated Brando for Best Actor, his seventh nomination. Although Brando won the 1973 New York Film Critics Circle Awards, he did not attend the ceremony or send a representative to pick up the award if he won.

Critic Pauline Kael, in "The New Yorker" review, wrote "The movie breakthrough has finally come. Bertolucci and Brando have altered the face of an art form." Brando confessed in his autobiography, "To this day I can't say what "Last Tango in Paris" was about," and added the film "required me to do a lot of emotional arm wrestling with myself, and when it was finished, I decided that I wasn't ever again going to destroy myself emotionally to make a movie".

In 1973, Brando was devastated by the death of his childhood best friend Wally Cox. Brando slept in Cox's pajamas and wrenched his ashes from his widow. She was going to sue for their return, but finally said "I think Marlon needs the ashes more than I do."

In 1976, Brando appeared in "The Missouri Breaks" with his friend Jack Nicholson. The movie also reunited the actor with director Arthur Penn. As biographer Stefan Kanfer describes, Penn had difficulty controlling Brando, who seemed intent on going over the top with his border-ruffian-turned-contract-killer Robert E. Lee Clayton: "Marlon made him a cross-dressing psychopath. Absent for the first hour of the movie, Clayton enters on horseback, dangling upside down, caparisoned in white buckskin, Littlefeather-style. He speaks in an Irish accent for no apparent reason. Over the next hour, also for no apparent reason, Clayton assumes the intonation of a British upper-class twit and an elderly frontier woman, complete with a granny dress and matching bonnet. Penn, who believed in letting actors do their thing, indulged Marlon all the way." Critics were unkind, with "The Observer" calling Brando's performance "one of the most extravagant displays of "grandedamerie" since Sarah Bernhardt", while "The Sun" complained, "Marlon Brando at fifty-two has the sloppy belly of a sixty-two-year-old, the white hair of a seventy-two-year-old, and the lack of discipline of a precocious twelve-year-old." However, Kanfer noted: "Even though his late work was met with disapproval, a re-examination shows that often, in the middle of the most pedestrian scene, there would be a sudden, luminous occurrence, a flash of the old Marlon that showed how capable he remained."

In 1978, Brando narrated the English version of "Raoni", a French-Belgian documentary film directed by Jean-Pierre Dutilleux and Luiz Carlos Saldanha that focused on the life of Raoni Metuktire and issues surrounding the survival of the indigenous Indian tribes of north central Brazil. Brando portrayed Superman's father Jor-El in the 1978 film "Superman". He agreed to the role only on assurance that he would be paid a large sum for what amounted to a small part, that he would not have to read the script beforehand, and that his lines would be displayed somewhere off-camera. It was revealed in a documentary contained in the 2001 DVD release of "Superman" that he was paid $3.7 million for two weeks of work. Brando also filmed scenes for the movie's sequel, "Superman II", but after producers refused to pay him the same percentage he received for the first movie, he denied them permission to use the footage. "I asked for my usual percentage," he recollected in his memoir, "but they refused, and so did I." However, after Brando's death, the footage was reincorporated into the 2006 recut of the film, "" and in the 2006 "loose sequel" "Superman Returns", in which both used and unused archive footage of him as Jor-El from the first two "Superman" films was remastered for a scene in the Fortress of Solitude, and Brando's voice-overs were used throughout the film. In 1979, he made a rare television appearance in the miniseries "", portraying George Lincoln Rockwell; he won a Primetime Emmy Award for Outstanding Supporting Actor in a Miniseries or a Movie for his performance.

Brando starred as Colonel Walter E. Kurtz in Francis Ford Coppola's Vietnam epic "Apocalypse Now" (1979). He plays a highly decorated U.S. Army Special Forces officer who goes renegade, running his own operation based in Cambodia and is feared by the U.S. military as much as the Vietnamese. Brando was paid $1 million a week for 3 weeks work. The film drew attention for its lengthy and troubled production, as Eleanor Coppola's documentary "Hearts of Darkness: A Filmmaker's Apocalypse" documents: Brando showed up on the set overweight, Martin Sheen suffered a heart attack, and severe weather destroyed several expensive sets. The film's release was also postponed several times while Coppola edited millions of feet of footage. In the documentary, Coppola talks about how astonished he was when an overweight Brando turned up for his scenes and, feeling desperate, decided to portray Kurtz, who appears emaciated in the original story, as a man who had indulged every aspect of himself. Coppola: "He was already heavy when I hired him and he promised me that he was going to get in shape and I imagined that I would, if he were heavy, I could use that. But he was "so" fat, he was very, very shy about it ... He was very, very adamant about how he didn't want to portray himself that way." Brando admitted to Coppola that he had not read the book, "Heart of Darkness", as the director had asked him to, and the pair spent days exploring the story and the character of Kurtz, much to the actor's financial benefit, according to producer Fred Roos: "The clock was ticking on this deal he had and we had to finish him within three weeks or we'd go into this very expensive overage ... And Francis and Marlon would be talking about the character and whole days would go by. And this is at Marlon's urging—and yet he's getting paid for it."

Upon release, "Apocalypse Now" earned critical acclaim, as did Brando's performance. His whispering of Kurtz's final words ""The horror! The horror!"", has become particularly famous. Roger Ebert, writing in the "Chicago Sun-Times", defended the movie's controversial "denouement", opining that the ending, "with Brando's fuzzy, brooding monologues and the final violence, feels much more satisfactory than any conventional ending possibly could." Brando received a fee of $2 million plus 10% of the gross theatrical rental and 10% of the TV sale rights, earning him around $9 million.

After appearing as oil tycoon Adam Steiffel in 1980's "The Formula", which was poorly received critically, Brando announced his retirement from acting. However, he returned in 1989 in "A Dry White Season", based on André Brink's 1979 anti-apartheid novel. Brando agreed to do the film for free, but fell out with director Euzhan Palcy over how the film was edited; he even made a rare television appearance in an interview with Connie Chung to voice his disapproval. In his memoir, he maintained that Palcy "had cut the picture so poorly, I thought, that the inherent drama of this conflict was vague at best." Brando received praise for his performance, earning an Academy Award nomination for Best Supporting Actor and winning the Best Actor Award at the Tokyo Film Festival.

Brando scored enthusiastic reviews for his caricature of his Vito Corleone role as Carmine Sabatini in 1990's "The Freshman." In his original review, Roger Ebert wrote, "There have been a lot of movies where stars have repeated the triumphs of their parts—but has any star ever done it more triumphantly than Marlon Brando does in "The Freshman"?" "Variety" also praised Brando's performance as Sabatini and noted, "Marlon Brando's sublime comedy performance elevates "The Freshman" from screwball comedy to a quirky niche in film history." Brando also starred alongside his friend Johnny Depp in the box office hit "Don Juan DeMarco" (1995) and in Depp's controversial "The Brave" (1997), which was never released in the United States.

Later performances, such as his appearance in "" (1992) (for which he was nominated for a Raspberry as "Worst Supporting Actor"), "The Island of Dr. Moreau" (in which he won a "Worst Supporting Actor" Raspberry) (1996), and his barely recognizable appearance in "Free Money" (1998), resulted in some of the worst reviews of his career. "The Island of Dr. Moreau" screenwriter Ron Hutchinson would later say in his memoir, "Clinging to the Iceberg: Writing for a Living on the Stage and in Hollywood" (2017), that Brando sabotaged the film's production by feuding and refusing to cooperate with his colleagues and the film crew.

Unlike its immediate predecessors, Brando's last completed film, "The Score" (2001), was received generally positively. In the film, in which he portrays a fence, he starred with Robert De Niro.

After Brando's death, the novel "Fan-Tan" was released. Brando conceived the novel with director Donald Cammell in 1979, but it was not released until 2005.

Brando's notoriety, his troubled family life, and his obesity attracted more attention than his late acting career. He gained a great deal of weight in the 1970s and by the early to mid-1990s he weighed over and suffered from Type 2 diabetes. He had a history of weight fluctuation throughout his career that, by and large, he attributed to his years of stress-related overeating followed by compensatory dieting. He also earned a reputation for being difficult on the set, often unwilling or unable to memorize his lines and less interested in taking direction than in confronting the film director with odd demands. He also dabbled with some innovation in his last years. He had several patents issued in his name from the U.S. Patent and Trademark Office, all of which involve a method of tensioning drumheads, in June 2002 – November 2004. (For example, see and its equivalents).

In 2004, Brando recorded voice tracks for the character Mrs. Sour in the unreleased animated film "Big Bug Man". This was his last role and his only role as a female character.

A longtime close friend of entertainer Michael Jackson, he paid regular visits to his Neverland Ranch, resting there for weeks at a time. Brando also participated in the singer's two-day solo career in 2001, and starred in his 13-minute-long music video, "You Rock My World," in the same year.

The actor's son, Miko, was Jackson's bodyguard and assistant for several years, and was a friend of the singer. "The last time my father left his house to go anywhere, to spend any kind of time, it was with Michael Jackson", Miko stated. "He loved it ... He had a 24-hour chef, 24-hour security, 24-hour help, 24-hour kitchen, 24-hour maid service. Just carte blanche." "Michael was instrumental helping my father through the last few years of his life. For that I will always be indebted to him. Dad had a hard time breathing in his final days, and he was on oxygen much of the time. He loved the outdoors, so Michael would invite him over to Neverland. Dad could name all the trees there, and the flowers, but being on oxygen it was hard for him to get around and see them all, it's such a big place. So Michael got Dad a golf cart with a portable oxygen tank so he could go around and enjoy Neverland. They'd just drive around—Michael Jackson, Marlon Brando, with an oxygen tank in a golf cart." In April 2001, Brando was hospitalized with pneumonia.

In 2004, Brando signed with Tunisian film director Ridha Behi and began preproduction on a project to be titled "Brando and Brando". Up to a week before his death, he was working on the script in anticipation of a July/August 2004 start date. Production was suspended in July 2004 following Brando's death, at which time Behi stated that he would continue the film as an homage to Brando, with a new title of "Citizen Brando".

On July 1, 2004, Brando died of respiratory failure from pulmonary fibrosis with congestive heart failure at the UCLA Medical Center. The cause of death was initially withheld, with his lawyer citing privacy concerns. He also suffered from diabetes and liver cancer. Shortly before his death and despite needing an oxygen mask to breathe, he recorded his voice to appear in "The Godfather: The Game", once again as Don Vito Corleone. However, Brando recorded only one line due to his health, and an impersonator was hired to finish his lines. Some lines from his character were directly lifted from the film. Karl Malden—Brando's co-star in three films, "A Streetcar Named Desire", "On the Waterfront", and "One-Eyed Jacks" (the last being the only film directed by Brando) -- spoke in a documentary accompanying the DVD of "A Streetcar Named Desire" about a phone call he received from Brando shortly before Brando's death. A distressed Brando told Malden he kept falling over. Malden wanted to come over, but Brando put him off, telling him there was no point. Three weeks later, Brando was dead. Shortly before his death, he had apparently refused permission for tubes carrying oxygen to be inserted into his lungs, which, he was told, was the only way to prolong his life.

Brando was cremated, and his ashes were put in with those of his good friend, Wally Cox and another longtime friend, Sam Gilman. They were then scattered partly in Tahiti and partly in Death Valley. In 2007, a 165-minute biopic of Brando for Turner Classic Movies, "Brando: The Documentary", produced by Mike Medavoy (the executor of Brando's will), was released.

Brando was known for his tumultuous personal life and his large number of partners and children. He was the father to at least 11 children, three of whom were adopted. In 1976, he told a French journalist, "Homosexuality is so much in fashion, it no longer makes news. Like a large number of men, I, too, have had homosexual experiences, and I am not ashamed. I have never paid much attention to what people think about me. But if there is someone who is convinced that Jack Nicholson and I are lovers, may they continue to do so. I find it amusing."

In "Songs My Mother Taught Me", Brando wrote he met Marilyn Monroe at a party where she played piano, unnoticed by anybody else there, that they had an affair and maintained an intermittent relationship for many years, and that he received a telephone call from her several days before she died. He also claimed numerous other romances, although he did not discuss his marriages, his wives, or his children in his autobiography.

He met nisei actress and dancer Reiko Sato in the early 1950s; in 1954 Dorothy Kilgallen reported they were an item. Though their relationship cooled, they remained friends for the rest of Sato's life, with her dividing her time between Los Angeles and Tetiaroa in her later years.

Brando was smitten with the Mexican actress Katy Jurado after seeing her in "High Noon". They met when Brando was filming "Viva Zapata!" in Mexico. Brando told Joseph L. Mankiewicz that he was attracted to "her enigmatic eyes, black as hell, pointing at you like fiery arrows". However, their first date became the beginning of an extended affair that lasted many years and peaked at the time they worked together on "One-Eyed Jacks" (1960), a film directed by Brando.

Brando met actress Rita Moreno in 1954, and they began a love affair. Moreno later revealed in her memoir that when she became pregnant by Brando, he arranged for an abortion. After the abortion was botched, she attempted suicide by overdosing on Brando’s sleeping pills. Years after they broke up, Moreno played his love interest in the film "The Night of the Following Day".

Brando married actress Anna Kashfi in 1957. Kashfi was born in Calcutta and moved to Wales from India in 1947. She is said to have been the daughter of a Welsh steel worker of Irish descent, William O'Callaghan, who had been superintendent on the Indian State railways. However, in her book, "Brando for Breakfast", she claimed that she really is half Indian and that the press incorrectly thought that her stepfather, O'Callaghan, was her biological father. She said that her biological father was Indian and that she was the result of an "unregistered alliance" between her parents. Brando and Kashfi had a son, Christian Brando, on May 11, 1958; they divorced in 1959.

In 1960, Brando married Movita Castaneda, a Mexican-American actress; the marriage was annulled in 1968 after it was discovered her previous marriage was still active. Castaneda had appeared in the first "Mutiny on the Bounty" film in 1935, some 27 years before the 1962 remake with Brando as Fletcher Christian. They had two children together: Miko Castaneda Brando (born 1961) and Rebecca Brando (born 1966).

French actress Tarita Teriipaia, who played Brando's love interest in "Mutiny on the Bounty", became his third wife on August 10, 1962. She was 20 years old, 18 years younger than Brando, who was reportedly delighted by her naïveté. Because Teriipaia was a native French speaker, Brando became fluent in the language and gave numerous interviews in French. Teriipaia became the mother of two of his children: Simon Teihotu Brando (born 1963) and Tarita Cheyenne Brando (born 1970). Brando also adopted Teriipaia's daughter, Maimiti Brando (born 1977) and niece, Raiatua Brando (born 1982). Brando and Teriipaia divorced in July 1972.

After Brando's death, the daughter of actress Cynthia Lynn claimed that Brando had had a short-lived affair with her mother, who appeared with Brando in "Bedtime Story", and that this affair resulted in her birth in 1964. Throughout the late 1960s and into the early 1980s, he had a tempestuous, long-term relationship with actress Jill Banner.

Brando had a long-term relationship with his housekeeper Maria Cristina Ruiz, with whom he had three children: Ninna Priscilla Brando (born May 13, 1989), Myles Jonathan Brando (born January 16, 1992), and Timothy Gahan Brando (born January 6, 1994). Brando also adopted Petra Brando-Corval (born 1972), the daughter of his assistant Caroline Barrett and novelist James Clavell.

Brando's close friendship with Wally Cox was the subject of rumors. Brando told a journalist: "If Wally had been a woman, I would have married him and we would have lived happily ever after." Two of Cox's wives, however, dismissed the suggestion that the love was more than platonic.

Brando's grandson Tuki Brando (born 1990), son of Cheyenne Brando, is a fashion model. His numerous grandchildren also include Prudence Brando and Shane Brando, children of Miko C. Brando, the children of Rebecca Brando, and the three children of Teihotu Brando among others.

Stephen Blackehart has been reported to be the son of Brando, but Blackehart disputes this claim.

In 2018, Quincy Jones and Jennifer Lee claimed that Brando had had a sexual relationship with comedian and "Superman III" actor Richard Pryor. Pryor's daughter Rain later disputed the claim.

Brando earned a reputation as a 'bad boy' for his public outbursts and antics. According to "Los Angeles" magazine, "Brando was rock and roll before anybody knew what rock and roll was." His behavior during the filming of "Mutiny on the Bounty" (1962) seemed to bolster his reputation as a difficult star. He was blamed for a change in director and a runaway budget, though he disclaimed responsibility for either. On June 12, 1973, Brando broke paparazzo Ron Galella's jaw. Galella had followed Brando, who was accompanied by talk show host Dick Cavett, after a taping of "The Dick Cavett Show" in New York City. He paid a $40,000 out-of-court settlement and suffered an infected hand as a result. Galella wore a football helmet the next time he photographed Brando at a gala benefiting the American Indians Development Association in 1974.

The filming of "Mutiny on the Bounty" affected Brando's life in a profound way, as he fell in love with Tahiti and its people. He bought a 12-island atoll, Tetiaroa, and in 1970 hired an award-winning young Los Angeles architect, Bernard Judge, to build his home and natural village there without despoiling the environment. An environmental laboratory protecting sea birds and turtles was established, and for many years student groups visited. The 1983 hurricane destroyed many of the structures including his resort. A hotel using Brando's name, The Brando Resort opened in 2014. Brando was an active ham radio operator, with the call signs KE6PZH and FO5GJ (the latter from his island). He was listed in the Federal Communications Commission (FCC) records as Martin Brandeaux to preserve his privacy.

In the A&E "Biography" episode on Brando, biographer Peter Manso comments, "On the one hand, being a celebrity allowed Marlon to take his revenge on the world that had so deeply hurt him, so deeply scarred him. On the other hand he hated it because he knew it was false and ephemeral." In the same program another biographer, David Thomson, relates, "Many, many people who worked with him, and came to work with him with the best intentions, went away in despair saying he's a spoiled kid. It has to be done his way or he goes away with some vast story about how he was wronged, he was offended, and I think that fits with the psychological pattern that he was a wronged kid."

In 1946, Brando performed in Ben Hecht's Zionist play "A Flag is Born". He attended some fundraisers for John F. Kennedy in the 1960 presidential election. In August 1963, he participated in the March on Washington along with fellow celebrities Harry Belafonte, James Garner, Charlton Heston, Burt Lancaster and Sidney Poitier. Along with Paul Newman, Brando also participated in the freedom rides.

In the aftermath of the 1968 assassination of Martin Luther King Jr., Brando made one of the strongest commitments to furthering King's work. Shortly after King's death, he announced that he was bowing out of the lead role of a major film ("The Arrangement") (1969) which was about to begin production in order to devote himself to the civil rights movement. "I felt I'd better go find out where it is; what it is to be black in this country; what this rage is all about," Brando said on the late-night ABC-TV talk show "Joey Bishop Show". In A&E's "Biography" episode on Brando, actor and co-star Martin Sheen states, "I'll never forget the night that Reverend King was shot and I turned on the news and Marlon was walking through Harlem with Mayor Lindsay. And there were snipers and there was a lot of unrest and he kept walking and talking through those neighborhoods with Mayor Lindsay. It was one of the most incredible acts of courage I ever saw, and it meant a lot and did a lot."

Brando's participation in the civil rights movement actually began well before King's death. In the early 1960s, he contributed thousands of dollars to both the Southern Christian Leadership Conference (S.C.L.C.) and to a scholarship fund established for the children of slain Mississippi N.A.A.C.P. leader Medgar Evers. In 1964 Brando was arrested at a "fish-in" held to protest a broken treaty that had promised Native Americans fishing rights in Puget Sound. By this time, Brando was already involved in films that carried messages about human rights: "Sayonara", which addressed interracial romance, and "The Ugly American", depicting the conduct of U.S. officials abroad and the deleterious effect on the citizens of foreign countries. For a time, he was also donating money to the Black Panther Party and considered himself a friend of founder Bobby Seale. Brando ended his financial support for the group over his perception of its increasing radicalization, specifically a passage in a Panther pamphlet put out by Eldridge Cleaver advocating indiscriminate violence, "for the Revolution."

Brando was also a supporter of the American Indian Movement. At the 1973 Academy Awards ceremony, Brando refused to accept the Oscar for his performance in "The Godfather". Sacheen Littlefeather represented him at the ceremony. She appeared in full Apache attire and stated that owing to the "poor treatment of Native Americans in the film industry", Brando would not accept the award. This occurred while the standoff at Wounded Knee was ongoing. The event grabbed the attention of the US and the world media. This was considered a major event and victory for the movement by its supporters and participants.

Outside of his film work, Brando appeared before the California Assembly in support of a fair housing law and personally joined picket lines in demonstrations protesting discrimination in housing developments in 1963.

He was also an activist against apartheid. In 1964, he favored a boycott of his films in South Africa to prevent them from being shown to a segregated audience. He took part at a 1975 protest rally against American investments in South Africa and for the release of Nelson Mandela. In 1989, Brando also starred in the film "A Dry White Season", based upon André Brink's novel of the same name.

In an interview in "Playboy" magazine in January 1979, Brando said: "You've seen every single race besmirched, but you never saw an image of the kike because the Jews were ever so watchful for that—and rightly so. They never allowed it to be shown on screen. The Jews have done so much for the world that, I suppose, you get extra disappointed because they didn't pay attention to that."
Brando made a similar comment on "Larry King Live" in April 1996, saying "Hollywood is run by Jews; it is owned by Jews, and they should have a greater sensitivity about the issue of—of people who are suffering. Because they've exploited—we have seen the—we have seen the nigger and greaseball, we've seen the chink, we've seen the slit-eyed dangerous Jap, we have seen the wily Filipino, we've seen everything, but we never saw the kike. Because they knew perfectly well, that that is where you draw the wagons around." Larry King, who is Jewish, replied, "When you say—when you say something like that, you are playing right in, though, to anti-Semitic people who say the Jews are—" Brando interrupted: "No, no, because I will be the first one who will appraise the Jews honestly and say 'Thank God for the Jews'."
Jay Kanter, Brando's agent, producer, and friend, defended him in "Daily Variety": "Marlon has spoken to me for hours about his fondness for the Jewish people, and he is a well-known supporter of Israel." Similarly, Louie Kemp, in his article for "Jewish Journal", wrote: "You might remember him as Don Vito Corleone, Stanley Kowalski or the eerie Col. Walter E. Kurtz in 'Apocalypse Now', but I remember Marlon Brando as a mensch and a personal friend of the Jewish people when they needed it most."

Brando was one of the most respected actors of the post-war era. He is listed by the American Film Institute as the fourth greatest male star whose screen debut occurred before or during 1950 (it occurred in 1950). He earned respect among critics for his memorable performances and charismatic screen presence. He helped popularize Method acting. He is regarded as one of the greatest cinema actors of the 20th century.

"Encyclopedia Britannica" describes him as "the most celebrated of the method actors, and his slurred, mumbling delivery marked his rejection of classical dramatic training. His true and passionate performances proved him one of the greatest actors of his generation". It also notes the apparent paradox of his talent: "He is regarded as the most influential actor of his generation, yet his open disdain for the acting profession ... often manifested itself in the form of questionable choices and uninspired performances. Nevertheless, he remains a riveting screen presence with a vast emotional range and an endless array of compulsively watchable idiosyncrasies."

Marlon Brando is a cultural icon with enduring popularity. His rise to national attention in the 1950s had a profound effect on American culture.
According to film critic Pauline Kael, "Brando represented a reaction against the post-war mania for security. As a protagonist, the Brando of the early fifties had no code, only his instincts. He was a development from the gangster leader and the outlaw. He was antisocial because he knew society was crap; he was a hero to youth because he was strong enough not to take the crap ... Brando represented a contemporary version of the free American ... Brando is still the most exciting American actor on the screen." Sociologist Dr. Suzanne McDonald-Walker states: "Marlon Brando, sporting leather jacket, jeans, and moody glare, became a cultural icon summing up 'the road' in all its maverick glory." His portrayal of the gang leader Johnny Strabler in "The Wild One" has become an iconic image, used both as a symbol of rebelliousness and a fashion accessory that includes a Perfecto style motorcycle jacket, a tilted cap, jeans and sunglasses. Johnny's haircut inspired a craze for sideburns, followed by James Dean and Elvis Presley, among others. Dean copied Brando's acting style extensively and Presley used Brando's image as a model for his role in "Jailhouse Rock". The "I coulda been a contender" scene from "On the Waterfront", according to the author of" Brooklyn Boomer", Martin H. Levinson, is "one of the most famous scenes in motion picture history, and the line itself has become part of America's cultural lexicon." An example of the endurance of Brando's popular "Wild One" image was the 2009 release of replicas of the leather jacket worn by Brando's Johnny Strabler character. The jackets were marketed by Triumph, the manufacturer of the Triumph Thunderbird motorcycles featured in "The Wild One", and were officially licensed by Brando's estate.

Brando was also considered a male sex symbol. Linda Williams writes: "Marlon Brando [was] the quintessential American male sex symbol of the late fifties and early sixties". Brando was an early lesbian icon who, along with James Dean, influenced the butch look and self-image in the 1950s and after.

The character Dio Brando from the popular Japanese Manga series JoJo's Bizarre Adventure gets his name from Brando, as well as American heavy metal band Dio (band) and its lead singer, Ronnie James Dio.

Brando has also been immortalized in music; most notably, he was mentioned in the lyrics of "It's Hard to Be a Saint in the City" by Bruce Springsteen, "Vogue" by Madonna and "Eyeless" by Slipknot on their selftitled album.

In his autobiography "Songs My Mother Taught Me", Brando observed:

He also confessed that, while having great admiration for the theater, he did not return to it after his initial success primarily because the work left him drained emotionally:

Brando repeatedly credited Stella Adler and her understanding of the Stanislavski acting technique for bringing realism to American cinema, but also added:

In the 2015 documentary "Listen to Me Marlon", Brando shared his thoughts on playing a death scene, stating, "That's a tough scene to play. You have to make 'em believe that you are dying ... Try to think of the most intimate moment you've ever had in your life." Brando's favorite actors were Spencer Tracy, John Barrymore, Fredric March, James Cagney and Paul Muni. He also showed admiration for Sean Penn, Jack Nicholson, Johnny Depp, and Daniel Day-Lewis.

On his death in 2004 Brando left an estate valued at $21.6 million. Brando's estate still earned about $9 million in 2005, the following year, according to "Forbes". That year Brando was named one of the top-earning deceased celebrities in the world by the magazine.

In December 2019, the Rolex GMT Master Ref. 1675 worn by Brando in Francis Ford Coppola's Vietnam War epic "Apocalypse Now" was announced to be sold at an auction, with an expected price tag of up to $1 million.

Brando was named the fourth greatest male star whose screen debut occurred before or during 1950 by the American Film Institute, and part of "TIME" magazine's . He was also named one of the top 10 "Icons of the Century" by "Variety" magazine.


Notes
Citations
Bibliography



</doc>
<doc id="19904" url="https://en.wikipedia.org/wiki?curid=19904" title="Meteorology">
Meteorology

Meteorology is a branch of the atmospheric sciences which includes atmospheric chemistry and atmospheric physics, with a major focus on weather forecasting. The study of meteorology dates back millennia, though significant progress in meteorology did not occur until the 18th century. The 19th century saw modest progress in the field after weather observation networks were formed across broad regions. Prior attempts at prediction of weather depended on historical data. It was not until after the elucidation of the laws of physics and more particularly, the development of the computer, allowing for the automated solution of a great many equations that model the weather, in the latter half of the 20th century that significant breakthroughs in weather forecasting were achieved. An important domain of weather forecasting is marine weather forecasting as it relates to maritime and coastal safety, in which weather effects also include atmospheric interactions with large bodies of water.

Meteorological phenomena are observable weather events that are explained by the science of meteorology. Meteorological phenomena are described and quantified by the variables of Earth's atmosphere: temperature, air pressure, water vapour, mass flow, and the variations and interactions of those variables, and how they change over time. Different spatial scales are used to describe and predict weather on local, regional, and global levels.
Meteorology, climatology, atmospheric physics, and atmospheric chemistry are sub-disciplines of the atmospheric sciences. Meteorology and hydrology compose the interdisciplinary field of hydrometeorology. The interactions between Earth's atmosphere and its oceans are part of a coupled ocean-atmosphere system. Meteorology has application in many diverse fields such as the military, energy production, transport, agriculture, and construction.

The word "meteorology" is from the Ancient Greek μετέωρος "metéōros" ("meteor") and -λογία "-logia" ("-(o)logy"), meaning "the study of things high in the air."

The ability to predict rains and floods based on annual cycles was evidently used by humans at least from the time of agricultural settlement if not earlier. Early approaches to predicting weather were based on astrology and were practiced by priests. Cuneiform inscriptions on Babylonian tablets included associations between thunder and rain. The Chaldeans differentiated the 22° and 46° halos.

Ancient Indian Upanishads contain mentions of clouds and seasons. The Samaveda mentions sacrifices to be performed when certain phenomena were noticed. Varāhamihira's classical work "Brihatsamhita", written about 500 AD, provides evidence of weather observation.

In 350 BC, Aristotle wrote "Meteorology". Aristotle is considered the founder of meteorology. One of the most impressive achievements described in the "Meteorology" is the description of what is now known as the hydrologic cycle.

The book De Mundo (composed before 250 BC or between 350 and 200 BC) noted:

The Greek scientist Theophrastus compiled a book on weather forecasting, called the "Book of Signs". The work of Theophrastus remained a dominant influence in the study of weather and in weather forecasting for nearly 2,000 years. In 25 AD, Pomponius Mela, a geographer for the Roman Empire, formalized the climatic zone system. According to Toufic Fahd, around the 9th century, Al-Dinawari wrote the "Kitab al-Nabat" ("Book of Plants"), in which he deals with the application of meteorology to agriculture during the Muslim Agricultural Revolution. He describes the meteorological character of the sky, the planets and constellations, the sun and moon, the lunar phases indicating seasons and rain, the "anwa" (heavenly bodies of rain), and atmospheric phenomena such as winds, thunder, lightning, snow, floods, valleys, rivers, lakes.

Early attempts at predicting weather were often related to prophecy and divining, and were sometimes based on astrological ideas. Admiral FitzRoy tried to separate scientific approaches from prophetic ones.

Ptolemy wrote on the atmospheric refraction of light in the context of astronomical observations. In 1021, Alhazen showed that atmospheric refraction is also responsible for twilight; he estimated that twilight begins when the sun is 19 degrees below the horizon, and also used a geometric determination based on this to estimate the maximum possible height of the Earth's atmosphere as 52,000 "passim" (about 49 miles, or 79 km).

St. Albert the Great was the first to propose that each drop of falling rain had the form of a small sphere, and that this form meant that the rainbow was produced by light interacting with each raindrop. Roger Bacon was the first to calculate the angular size of the rainbow. He stated that a rainbow summit can not appear higher than 42 degrees above the horizon. In the late 13th century and early 14th century, Kamāl al-Dīn al-Fārisī and Theodoric of Freiberg were the first to give the correct explanations for the primary rainbow phenomenon. Theoderic went further and also explained the secondary rainbow. In 1716, Edmund Halley suggested that aurorae are caused by "magnetic effluvia" moving along the Earth's magnetic field lines.

In 1441, King Sejong's son, Prince Munjong of Korea, invented the first standardized rain gauge. These were sent throughout the Joseon dynasty of Korea as an official tool to assess land taxes based upon a farmer's potential harvest. In 1450, Leone Battista Alberti developed a swinging-plate anemometer, and was known as the first "anemometer". In 1607, Galileo Galilei constructed a thermoscope. In 1611, Johannes Kepler wrote the first scientific treatise on snow crystals: "Strena Seu de Nive Sexangula (A New Year's Gift of Hexagonal Snow)." In 1643, Evangelista Torricelli invented the mercury barometer. In 1662, Sir Christopher Wren invented the mechanical, self-emptying, tipping bucket rain gauge. In 1714, Gabriel Fahrenheit created a reliable scale for measuring temperature with a mercury-type thermometer. In 1742, Anders Celsius, a Swedish astronomer, proposed the "centigrade" temperature scale, the predecessor of the current Celsius scale. In 1783, the first hair hygrometer was demonstrated by Horace-Bénédict de Saussure. In 1802–1803, Luke Howard wrote "On the Modification of Clouds", in which he assigns cloud types Latin names. In 1806, Francis Beaufort introduced his system for classifying wind speeds. Near the end of the 19th century the first cloud atlases were published, including the "International Cloud Atlas", which has remained in print ever since. The April 1960 launch of the first successful weather satellite, TIROS-1, marked the beginning of the age where weather information became available globally.

In 1648, Blaise Pascal rediscovered that atmospheric pressure decreases with height, and deduced that there is a vacuum above the atmosphere. In 1738, Daniel Bernoulli published "Hydrodynamics", initiating the Kinetic theory of gases and established the basic laws for the theory of gases. In 1761, Joseph Black discovered that ice absorbs heat without changing its temperature when melting. In 1772, Black's student Daniel Rutherford discovered nitrogen, which he called "phlogisticated air", and together they developed the phlogiston theory. In 1777, Antoine Lavoisier discovered oxygen and developed an explanation for combustion. In 1783, in Lavoisier's essay "Reflexions sur le phlogistique," he deprecates the phlogiston theory and proposes a caloric theory. In 1804, Sir John Leslie observed that a matte black surface radiates heat more effectively than a polished surface, suggesting the importance of black-body radiation. In 1808, John Dalton defended caloric theory in "A New System of Chemistry" and described how it combines with matter, especially gases; he proposed that the heat capacity of gases varies inversely with atomic weight. In 1824, Sadi Carnot analyzed the efficiency of steam engines using caloric theory; he developed the notion of a reversible process and, in postulating that no such thing exists in nature, laid the foundation for the second law of thermodynamics.

In 1494, Christopher Columbus experienced a tropical cyclone, which led to the first written European account of a hurricane. In 1686, Edmund Halley presented a systematic study of the trade winds and monsoons and identified solar heating as the cause of atmospheric motions. In 1735, an "ideal" explanation of global circulation through study of the trade winds was written by George Hadley. In 1743, when Benjamin Franklin was prevented from seeing a lunar eclipse by a hurricane, he decided that cyclones move in a contrary manner to the winds at their periphery. Understanding the kinematics of how exactly the rotation of the Earth affects airflow was partial at first. Gaspard-Gustave Coriolis published a paper in 1835 on the energy yield of machines with rotating parts, such as waterwheels. In 1856, William Ferrel proposed the existence of a circulation cell in the mid-latitudes, and the air within deflected by the Coriolis force resulting in the prevailing westerly winds. Late in the 19th century, the motion of air masses along isobars was understood to be the result of the large-scale interaction of the pressure gradient force and the deflecting force. By 1912, this deflecting force was named the Coriolis effect. Just after World War I, a group of meteorologists in Norway led by Vilhelm Bjerknes developed the Norwegian cyclone model that explains the generation, intensification and ultimate decay (the life cycle) of mid-latitude cyclones, and introduced the idea of fronts, that is, sharply defined boundaries between air masses. The group included Carl-Gustaf Rossby (who was the first to explain the large scale atmospheric flow in terms of fluid dynamics), Tor Bergeron (who first determined how rain forms) and Jacob Bjerknes.

In the late 16th century and first half of the 17th century a range of meteorological instruments were invented – the thermometer, barometer, hydrometer, as well as wind and rain gauges. In the 1650s natural philosophers started using these instruments to systematically record weather observations. Scientific academies established weather diaries and organised observational networks. In 1654, Ferdinando II de Medici established the first "weather observing" network, that consisted of meteorological stations in Florence, Cutigliano, Vallombrosa, Bologna, Parma, Milan, Innsbruck, Osnabrück, Paris and Warsaw. The collected data were sent to Florence at regular time intervals. In the 1660s Robert Hooke of the Royal Society of London sponsored networks of weather observers. Hippocrates' treatise "Airs, Waters, and Places" had linked weather to disease. Thus early meteorologists attempted to correlate weather patterns with epidemic outbreaks, and the climate with public health.

During the Age of Enlightenment meteorology tried to rationalise traditional weather lore, including astrological meteorology. But there were also attempts to establish a theoretical understanding of weather phenomena. Edmond Halley and George Hadley tried to explain trade winds. They reasoned that the rising mass of heated equator air is replaced by an inflow of cooler air from high latitudes. A flow of warm air at high altitude from equator to poles in turn established an early picture of circulation. Frustration with the lack of discipline among weather observers, and the poor quality of the instruments, led the early modern nation states to organise large observation networks. Thus by the end of the 18th century, meteorologists had access to large quantities of reliable weather data. In 1832, an electromagnetic telegraph was created by Baron Schilling. The arrival of the electrical telegraph in 1837 afforded, for the first time, a practical method for quickly gathering surface weather observations from a wide area.

This data could be used to produce maps of the state of the atmosphere for a region near the Earth's surface and to study how these states evolved through time. To make frequent weather forecasts based on these data required a reliable network of observations, but it was not until 1849 that the Smithsonian Institution began to establish an observation network across the United States under the leadership of Joseph Henry. Similar observation networks were established in Europe at this time. The Reverend William Clement Ley was key in understanding of cirrus clouds and early understandings of Jet Streams. Charles Kenneth Mackinnon Douglas, known as 'CKM' Douglas read Ley's papers after his death and carried on the early study of weather systems.
Nineteenth century researchers in meteorology were drawn from military or medical backgrounds, rather than trained as dedicated scientists. In 1854, the United Kingdom government appointed Robert FitzRoy to the new office of "Meteorological Statist to the Board of Trade" with the task of gathering weather observations at sea. FitzRoy's office became the United Kingdom Meteorological Office in 1854, the second oldest national meteorological service in the world (the Central Institution for Meteorology and Geodynamics (ZAMG) in Austria was founded in 1851 and is the oldest weather service in the world). The first daily weather forecasts made by FitzRoy's Office were published in "The Times" newspaper in 1860. The following year a system was introduced of hoisting storm warning cones at principal ports when a gale was expected.

Over the next 50 years, many countries established national meteorological services. The India Meteorological Department (1875) was established to follow tropical cyclone and monsoon. The Finnish Meteorological Central Office (1881) was formed from part of Magnetic Observatory of Helsinki University. Japan's Tokyo Meteorological Observatory, the forerunner of the Japan Meteorological Agency, began constructing surface weather maps in 1883. The United States Weather Bureau (1890) was established under the United States Department of Agriculture. The Australian Bureau of Meteorology (1906) was established by a Meteorology Act to unify existing state meteorological services.

In 1904, Norwegian scientist Vilhelm Bjerknes first argued in his paper "Weather Forecasting as a Problem in Mechanics and Physics" that it should be possible to forecast weather from calculations based upon natural laws.

It was not until later in the 20th century that advances in the understanding of atmospheric physics led to the foundation of modern numerical weather prediction. In 1922, Lewis Fry Richardson published "Weather Prediction By Numerical Process," after finding notes and derivations he worked on as an ambulance driver in World War I. He described how small terms in the prognostic fluid dynamics equations that govern atmospheric flow could be neglected, and a numerical calculation scheme that could be devised to allow predictions. Richardson envisioned a large auditorium of thousands of people performing the calculations. However, the sheer number of calculations required was too large to complete without electronic computers, and the size of the grid and time steps used in the calculations led to unrealistic results. Though numerical analysis later found that this was due to numerical instability.

Starting in the 1950s, numerical forecasts with computers became feasible. The first weather forecasts derived this way used barotropic (single-vertical-level) models, and could successfully predict the large-scale movement of midlatitude Rossby waves, that is, the pattern of atmospheric lows and highs. In 1959, the UK Meteorological Office received its first computer, a Ferranti Mercury.

In the 1960s, the chaotic nature of the atmosphere was first observed and mathematically described by Edward Lorenz, founding the field of chaos theory. These advances have led to the current use of ensemble forecasting in most major forecasting centers, to take into account uncertainty arising from the chaotic nature of the atmosphere. Mathematical models used to predict the long term weather of the Earth (climate models), have been developed that have a resolution today that are as coarse as the older weather prediction models. These climate models are used to investigate long-term climate shifts, such as what effects might be caused by human emission of greenhouse gases.

Meteorologists are scientists who study and work in the field of meteorology. The American Meteorological Society publishes and continually updates an authoritative electronic "Meteorology Glossary". Meteorologists work in government agencies, private consulting and research services, industrial enterprises, utilities, radio and television stations, and in education. In the United States, meteorologists held about 10,000 jobs in 2018.

Although weather forecasts and warnings are the best known products of meteorologists for the public, weather presenters on radio and television are not necessarily professional meteorologists. They are most often reporters with little formal meteorological training, using unregulated titles such as "weather specialist" or "weatherman". The American Meteorological Society and National Weather Association issue "Seals of Approval" to weather broadcasters who meet certain requirements but this is not mandatory to be hired by the medias.

Each science has its own unique sets of laboratory equipment. In the atmosphere, there are many things or qualities of the atmosphere that can be measured. Rain, which can be observed, or seen anywhere and anytime was one of the first atmospheric qualities measured historically. Also, two other accurately measured qualities are wind and humidity. Neither of these can be seen but can be felt. The devices to measure these three sprang up in the mid-15th century and were respectively the rain gauge, the anemometer, and the hygrometer. Many attempts had been made prior to the 15th century to construct adequate equipment to measure the many atmospheric variables. Many were faulty in some way or were simply not reliable. Even Aristotle noted this in some of his work as the difficulty to measure the air.

Sets of surface measurements are important data to meteorologists. They give a snapshot of a variety of weather conditions at one single location and are usually at a weather station, a ship or a weather buoy. The measurements taken at a weather station can include any number of atmospheric observables. Usually, temperature, pressure, wind measurements, and humidity are the variables that are measured by a thermometer, barometer, anemometer, and hygrometer, respectively. Professional stations may also include air quality sensors (carbon monoxide, carbon dioxide, methane, ozone, dust, and smoke), ceilometer (cloud ceiling), falling precipitation sensor, flood sensor, lightning sensor, microphone (explosions, sonic booms, thunder), pyranometer/pyrheliometer/spectroradiometer (IR/Vis/UV photodiodes), rain gauge/snow gauge, scintillation counter (background radiation, fallout, radon), seismometer (earthquakes and tremors), transmissometer (visibility), and a GPS clock for data logging. Upper air data are of crucial importance for weather forecasting. The most widely used technique is launches of radiosondes. Supplementing the radiosondes a network of aircraft collection is organized by the World Meteorological Organization.

Remote sensing, as used in meteorology, is the concept of collecting data from remote weather events and subsequently producing weather information. The common types of remote sensing are Radar, Lidar, and satellites (or photogrammetry). Each collects data about the atmosphere from a remote location and, usually, stores the data where the instrument is located. Radar and Lidar are not passive because both use EM radiation to illuminate a specific portion of the atmosphere. Weather satellites along with more general-purpose Earth-observing satellites circling the earth at various altitudes have become an indispensable tool for studying a wide range of phenomena from forest fires to El Niño.

The study of the atmosphere can be divided into distinct areas that depend on both time and spatial scales. At one extreme of this scale is climatology. In the timescales of hours to days, meteorology separates into micro-, meso-, and synoptic scale meteorology. Respectively, the geospatial size of each of these three scales relates directly with the appropriate timescale.

Other subclassifications are used to describe the unique, local, or broad effects within those subclasses.
Microscale meteorology is the study of atmospheric phenomena on a scale of about or less. Individual thunderstorms, clouds, and local turbulence caused by buildings and other obstacles (such as individual hills) are modeled on this scale.

Mesoscale meteorology is the study of atmospheric phenomena that has horizontal scales ranging from 1 km to 1000 km and a vertical scale that starts at the Earth's surface and includes the atmospheric boundary layer, troposphere, tropopause, and the lower section of the stratosphere. Mesoscale timescales last from less than a day to weeks. The events typically of interest are thunderstorms, squall lines, fronts, precipitation bands in tropical and extratropical cyclones, and topographically generated weather systems such as mountain waves and sea and land breezes.

Synoptic scale meteorology predicts atmospheric changes at scales up to 1000 km and 10 sec (28 days), in time and space. At the synoptic scale, the Coriolis acceleration acting on moving air masses (outside of the tropics) plays a dominant role in predictions. The phenomena typically described by synoptic meteorology include events such as extratropical cyclones, baroclinic troughs and ridges, frontal zones, and to some extent jet streams. All of these are typically given on weather maps for a specific time. The minimum horizontal scale of synoptic phenomena is limited to the spacing between surface observation stations.

Global scale meteorology is the study of weather patterns related to the transport of heat from the tropics to the poles. Very large scale oscillations are of importance at this scale. These oscillations have time periods typically on the order of months, such as the Madden–Julian oscillation, or years, such as the El Niño–Southern Oscillation and the Pacific decadal oscillation. Global scale meteorology pushes into the range of climatology. The traditional definition of climate is pushed into larger timescales and with the understanding of the longer time scale global oscillations, their effect on climate and weather disturbances can be included in the synoptic and mesoscale timescales predictions.

Numerical Weather Prediction is a main focus in understanding air–sea interaction, tropical meteorology, atmospheric predictability, and tropospheric/stratospheric processes. The Naval Research Laboratory in Monterey, California, developed a global atmospheric model called Navy Operational Global Atmospheric Prediction System (NOGAPS). NOGAPS is run operationally at Fleet Numerical Meteorology and Oceanography Center for the United States Military. Many other global atmospheric models are run by national meteorological agencies.

Boundary layer meteorology is the study of processes in the air layer directly above Earth's surface, known as the atmospheric boundary layer (ABL). The effects of the surface – heating, cooling, and friction – cause turbulent mixing within the air layer. Significant movement of heat, matter, or momentum on time scales of less than a day are caused by turbulent motions. Boundary layer meteorology includes the study of all types of surface–atmosphere boundary, including ocean, lake, urban land and non-urban land for the study of meteorology.

Dynamic meteorology generally focuses on the fluid dynamics of the atmosphere. The idea of air parcel is used to define the smallest element of the atmosphere, while ignoring the discrete molecular and chemical nature of the atmosphere. An air parcel is defined as a point in the fluid continuum of the atmosphere. The fundamental laws of fluid dynamics, thermodynamics, and motion are used to study the atmosphere. The physical quantities that characterize the state of the atmosphere are temperature, density, pressure, etc. These variables have unique values in the continuum.

Weather forecasting is the application of science and technology to predict the state of the atmosphere at a future time and given location. Humans have attempted to predict the weather informally for millennia and formally since at least the 19th century. Weather forecasts are made by collecting quantitative data about the current state of the atmosphere and using scientific understanding of atmospheric processes to project how the atmosphere will evolve.

Once an all-human endeavor based mainly upon changes in barometric pressure, current weather conditions, and sky condition, forecast models are now used to determine future conditions. Human input is still required to pick the best possible forecast model to base the forecast upon, which involves pattern recognition skills, teleconnections, knowledge of model performance, and knowledge of model biases. The chaotic nature of the atmosphere, the massive computational power required to solve the equations that describe the atmosphere, error involved in measuring the initial conditions, and an incomplete understanding of atmospheric processes mean that forecasts become less accurate as the difference in current time and the time for which the forecast is being made (the "range" of the forecast) increases. The use of ensembles and model consensus help narrow the error and pick the most likely outcome.

There are a variety of end uses to weather forecasts. Weather warnings are important forecasts because they are used to protect life and property. Forecasts based on temperature and precipitation are important to agriculture, and therefore to commodity traders within stock markets. Temperature forecasts are used by utility companies to estimate demand over coming days. On an everyday basis, people use weather forecasts to determine what to wear. Since outdoor activities are severely curtailed by heavy rain, snow, and wind chill, forecasts can be used to plan activities around these events, and to plan ahead and survive them.

Aviation meteorology deals with the impact of weather on air traffic management. It is important for air crews to understand the implications of weather on their flight plan as well as their aircraft, as noted by the "Aeronautical Information Manual":
"The effects of ice on aircraft are cumulative—thrust is reduced, drag increases, lift lessens, and weight increases. The results are an increase in stall speed and a deterioration of aircraft performance. In extreme cases, 2 to 3 inches of ice can form on the leading edge of the airfoil in less than 5 minutes. It takes but 1/2 inch of ice to reduce the lifting power of some aircraft by 50 percent and increases the frictional drag by an equal percentage."

Meteorologists, soil scientists, agricultural hydrologists, and agronomists are people concerned with studying the effects of weather and climate on plant distribution, crop yield, water-use efficiency, phenology of plant and animal development, and the energy balance of managed and natural ecosystems. Conversely, they are interested in the role of vegetation on climate and weather.

Hydrometeorology is the branch of meteorology that deals with the hydrologic cycle, the water budget, and the rainfall statistics of storms. A hydrometeorologist prepares and issues forecasts of accumulating (quantitative) precipitation, heavy rain, heavy snow, and highlights areas with the potential for flash flooding. Typically the range of knowledge that is required overlaps with climatology, mesoscale and synoptic meteorology, and other geosciences.

The multidisciplinary nature of the branch can result in technical challenges, since tools and solutions from each of the individual disciplines involved may behave slightly differently, be optimized for different hard- and software platforms and use different data formats. There are some initiatives – such as the DRIHM project – that are trying to address this issue.

Nuclear meteorology investigates the distribution of radioactive aerosols and gases in the atmosphere.

Maritime meteorology deals with air and wave forecasts for ships operating at sea. Organizations such as the Ocean Prediction Center, Honolulu National Weather Service forecast office, United Kingdom Met Office, and JMA prepare high seas forecasts for the world's oceans.

Military meteorology is the research and application of meteorology for military purposes. In the United States, the United States Navy's Commander, Naval Meteorology and Oceanography Command oversees meteorological efforts for the Navy and Marine Corps while the United States Air Force's Air Force Weather Agency is responsible for the Air Force and Army.

Environmental meteorology mainly analyzes industrial pollution dispersion physically and chemically based on meteorological parameters such as temperature, humidity, wind, and various weather conditions.

Meteorology applications in renewable energy includes basic research, "exploration," and potential mapping of wind power and solar radiation for wind and solar energy.



"Please see weather forecasting for weather forecast sites."


</doc>
<doc id="19908" url="https://en.wikipedia.org/wiki?curid=19908" title="Mount">
Mount

Mount is often used as part of the name of specific mountains, e.g. Mount Everest.

Mount or Mounts may also refer to:








</doc>
<doc id="19916" url="https://en.wikipedia.org/wiki?curid=19916" title="Meitnerium">
Meitnerium

Meitnerium is a synthetic chemical element with the symbol Mt and atomic number 109. It is an extremely radioactive synthetic element (an element not found in nature, but can be created in a laboratory). The most stable known isotope, meitnerium-278, has a half-life of 4.5 seconds, although the unconfirmed meitnerium-282 may have a longer half-life of 67 seconds. The GSI Helmholtz Centre for Heavy Ion Research near Darmstadt, Germany, first created this element in 1982. It is named after Lise Meitner.

In the periodic table, meitnerium is a d-block transactinide element. It is a member of the 7th period and is placed in the group 9 elements, although no chemical experiments have yet been carried out to confirm that it behaves as the heavier homologue to iridium in group 9 as the seventh member of the 6d series of transition metals. Meitnerium is calculated to have similar properties to its lighter homologues, cobalt, rhodium, and iridium.

Meitnerium was first synthesized on August 29, 1982 by a German research team led by Peter Armbruster and Gottfried Münzenberg at the Institute for Heavy Ion Research (Gesellschaft für Schwerionenforschung) in Darmstadt. The team bombarded a target of bismuth-209 with accelerated nuclei of iron-58 and detected a single atom of the isotope meitnerium-266:

This work was confirmed three years later at the Joint Institute for Nuclear Research at Dubna (then in the Soviet Union).

Using Mendeleev's nomenclature for unnamed and undiscovered elements, meitnerium should be known as "eka-iridium". In 1979, during the Transfermium Wars (but before the synthesis of meitnerium), IUPAC published recommendations according to which the element was to be called "unnilennium" (with the corresponding symbol of "Une"), a systematic element name as a placeholder, until the element was discovered (and the discovery then confirmed) and a permanent name was decided on. Although widely used in the chemical community on all levels, from chemistry classrooms to advanced textbooks, the recommendations were mostly ignored among scientists in the field, who either called it "element 109", with the symbol of "E109", "(109)" or even simply "109", or used the proposed name "meitnerium".

The naming of meitnerium was discussed in the element naming controversy regarding the names of elements 104 to 109, but "meitnerium" was the only proposal and thus was never disputed. The name "meitnerium" (Mt) was suggested by the GSI team in September 1992 in honor of the Austrian physicist Lise Meitner, a co-discoverer of protactinium (with Otto Hahn), and one of the discoverers of nuclear fission. In 1994 the name was recommended by IUPAC, and was officially adopted in 1997. It is thus the only element named specifically after a non-mythological woman (curium being named for both Pierre and Marie Curie).

Meitnerium has no stable or naturally occurring isotopes. Several radioactive isotopes have been synthesized in the laboratory, either by fusing two atoms or by observing the decay of heavier elements. Eight different isotopes of meitnerium have been reported with atomic masses 266, 268, 270, and 274–278, two of which, meitnerium-268 and meitnerium-270, have known but unconfirmed metastable states. A ninth isotope with atomic mass 282 is unconfirmed. Most of these decay predominantly through alpha decay, although some undergo spontaneous fission.

All meitnerium isotopes are extremely unstable and radioactive; in general, heavier isotopes are more stable than the lighter. The most stable known meitnerium isotope, Mt, is also the heaviest known; it has a half-life of 4.5 seconds. The unconfirmed Mt is even heavier and appears to have a longer half-life of 67 seconds. The isotopes Mt and Mt have half-lives of 0.45 and 0.44 seconds respectively. The remaining five isotopes have half-lives between 1 and 20 milliseconds.

The isotope Mt, created as the final decay product of Ts for the first time in 2012, was observed to undergo spontaneous fission with a half-life of 5 milliseconds. Preliminary data analysis considered the possibility of this fission event instead originating from Hs, for it also has a half-life of a few milliseconds, and could be populated following undetected electron capture somewhere along the decay chain. This possibility was later deemed very unlikely based on observed decay energies of Ds and Rg and the short half-life of Mt, although there is still some uncertainty of the assignment. Regardless, the rapid fission of Mt and Hs is strongly suggestive of a region of instability for superheavy nuclei with "N" = 168–170. The existence of this region, characterized by a decrease in fission barrier height between the deformed shell closure at "N" = 162 and spherical shell closure at "N" = 184, is consistent with theoretical models.
No properties of meitnerium or its compounds have been measured; this is due to its extremely limited and expensive production and the fact that meitnerium and its parents decay very quickly. Properties of meitnerium metal remain unknown and only predictions are available.

Meitnerium is the seventh member of the 6d series of transition metals. Since element 112 (copernicium) has been shown to be a group 12 metal, it is expected that all the elements from 104 to 111 would continue a fourth transition metal series, with meitnerium as part of the platinum group metals. Calculations on its ionization potentials and atomic and ionic radii are similar to that of its lighter homologue iridium, thus implying that meitnerium's basic properties will resemble those of the other group 9 elements, cobalt, rhodium, and iridium.

Prediction of the probable chemical properties of meitnerium has not received much attention recently. Meitnerium is expected to be a noble metal. The standard electrode potential for the Mt/Mt couple is expected to be 0.8 V. Based on the most stable oxidation states of the lighter group 9 elements, the most stable oxidation states of meitnerium are predicted to be the +6, +3, and +1 states, with the +3 state being the most stable in aqueous solutions. In comparison, rhodium and iridium show a maximum oxidation state of +6, while the most stable states are +4 and +3 for iridium and +3 for rhodium. The oxidation state +9, represented only by iridium in [IrO], might be possible for its congener meitnerium in the nonafluoride (MtF) and the [MtO] cation, although [IrO] is expected to be more stable than these meitnerium compounds. The tetrahalides of meitnerium have also been predicted to have similar stabilities to those of iridium, thus also allowing a stable +4 state. It is further expected that the maximum oxidation states of elements from bohrium (element 107) to darmstadtium (element 110) may be stable in the gas phase but not in aqueous solution.

Meitnerium is expected to be a solid under normal conditions and assume a face-centered cubic crystal structure, similarly to its lighter congener iridium. It should be a very heavy metal with a density of around 37.4 g/cm, which would be the second-highest of any of the 118 known elements, second only to that predicted for its neighbor hassium (41 g/cm). In comparison, the densest known element that has had its density measured, osmium, has a density of only 22.61 g/cm. This results from meitnerium's high atomic weight, the lanthanide and actinide contractions, and relativistic effects, although production of enough meitnerium to measure this quantity would be impractical, and the sample would quickly decay. Meitnerium is also predicted to be paramagnetic.

Theoreticians have predicted the covalent radius of meitnerium to be 6 to 10 pm larger than that of iridium. The atomic radius of meitnerium is expected to be around 128 pm.

Meitnerium is the first element on the periodic table whose chemistry has not yet been investigated. Unambiguous determination of the chemical characteristics of meitnerium has yet to have been established due to the short half-lives of meitnerium isotopes and a limited number of likely volatile compounds that could be studied on a very small scale. One of the few meitnerium compounds that are likely to be sufficiently volatile is meitnerium hexafluoride (), as its lighter homologue iridium hexafluoride () is volatile above 60 °C and therefore the analogous compound of meitnerium might also be sufficiently volatile; a volatile octafluoride () might also be possible. For chemical studies to be carried out on a transactinide, at least four atoms must be produced, the half-life of the isotope used must be at least 1 second, and the rate of production must be at least one atom per week. Even though the half-life of Mt, the most stable confirmed meitnerium isotope, is 4.5 seconds, long enough to perform chemical studies, another obstacle is the need to increase the rate of production of meitnerium isotopes and allow experiments to carry on for weeks or months so that statistically significant results can be obtained. Separation and detection must be carried out continuously to separate out the meitnerium isotopes and have automated systems experiment on the gas-phase and solution chemistry of meitnerium, as the yields for heavier elements are predicted to be smaller than those for lighter elements; some of the separation techniques used for bohrium and hassium could be reused. However, the experimental chemistry of meitnerium has not received as much attention as that of the heavier elements from copernicium to livermorium.

The Lawrence Berkeley National Laboratory attempted to synthesize the isotope Mt in 2002–2003 for a possible chemical investigation of meitnerium because it was expected that it might be more stable than the isotopes around it as it has 162 neutrons, a magic number for deformed nuclei; its half-life was predicted to be a few seconds, long enough for a chemical investigation. However, no atoms of Mt were detected, and this isotope of meitnerium is currently unknown.

An experiment determining the chemical properties of a transactinide would need to compare a compound of that transactinide with analogous compounds of some of its lighter homologues: for example, in the chemical characterization of hassium, hassium tetroxide (HsO) was compared with the analogous osmium compound, osmium tetroxide (OsO). In a preliminary step towards determining the chemical properties of meitnerium, the GSI attempted sublimation of the rhodium compounds rhodium(III) oxide (RhO) and rhodium(III) chloride (RhCl). However, macroscopic amounts of the oxide would not sublimate until 1000 °C and the chloride would not until 780 °C, and then only in the presence of carbon aerosol particles: these temperatures are far too high for such procedures to be used on meitnerium, as most of the current methods used for the investigation of the chemistry of superheavy elements do not work above 500 °C.

Following the 2014 successful synthesis of seaborgium hexacarbonyl, Sg(CO), studies were conducted with the stable transition metals of groups 7 through 9, suggesting that carbonyl formation could be extended to further probe the chemistries of the early 6d transition metals from rutherfordium to meitnerium inclusive. Nevertheless, the challenges of low half-lives and difficult production reactions make meitnerium difficult to access for radiochemists, though the isotopes Mt and Mt are long-lived enough for chemical research and may be produced in the decay chains of Ts and Mc respectively. Mt is likely more suitable, since producing tennessine requires a rare and rather short-lived berkelium target. The isotope Mt, observed in the decay chain of Nh with a half-life of 0.69 seconds, may also be sufficiently long-lived for chemical investigations, though a direct synthesis route leading to this isotope and more precise measurements of its decay properties would be required.




</doc>
<doc id="19918" url="https://en.wikipedia.org/wiki?curid=19918" title="Megabyte">
Megabyte

The megabyte is a multiple of the unit byte for digital information. Its recommended unit symbol is MB. The unit prefix "mega" is a multiplier of (10) in the International System of Units (SI). Therefore, one megabyte is one million bytes of information. This definition has been incorporated into the International System of Quantities.

However, in the computer and information technology fields, several other definitions are used that arose for historical reasons of convenience. A common usage has been to designate one megabyte as (2 B), a measurement that conveniently expresses the binary multiples inherent in digital computer memory architectures. However, most standards bodies have deprecated this usage in favor of a set of binary prefixes, in which this quantity is designated by the unit mebibyte (MiB). Less common is a convention that uses the megabyte to mean 1000×1024 () bytes.

The megabyte is commonly used to measure either 1000 bytes or 1024 bytes. The interpretation of using base 1024 originated as a compromise technical jargon for the byte multiples that needed to be expressed by the powers of 2 but lacked a convenient name. As 1024 (2) approximates 1000 (10), roughly corresponding to the SI prefix kilo-, it was a convenient term to denote the binary multiple. In 1998 the International Electrotechnical Commission (IEC) proposed standards for binary prefixes requiring the use of megabyte to strictly denote 1000 bytes and mebibyte to denote 1024 bytes. By the end of 2009, the IEC Standard had been adopted by the IEEE, EU, ISO and NIST. Nevertheless, the term megabyte continues to be widely used with different meanings:

In this convention, one thousand megabytes (1000 MB) is equal to one gigabyte (1 GB), where 1 GB is one billion bytes.


In this convention, one thousand and twenty-four megabytes (1024 MB) is equal to one gigabyte (1 GB), where 1 GB is 1024 bytes.


Semiconductor memory doubles in size for each address lane added to an integrated circuit package, which favors counts that are powers of two. The capacity of a disk drive is the product of the sector size, number of sectors per track, number of tracks per side, and the number of disk platters in the drive. Changes in any of these factors would not usually double the size. Sector sizes were set as powers of two (most common 512 bytes or 4096 bytes) for convenience in processing. It was a natural extension to give the capacity of a disk drive in multiples of the sector size, giving a mix of decimal and binary multiples when expressing total disk capacity.

Depending on compression methods and file format, a megabyte of data can roughly be:

The human genome consists of DNA representing 800 MB of data. The parts that differentiate one person from another can be compressed to 4 MB.




</doc>
<doc id="19919" url="https://en.wikipedia.org/wiki?curid=19919" title="Monosaccharide">
Monosaccharide

Monosaccharides (from Greek "monos": single, "sacchar": sugar), also called simple sugar, are the simplest form of sugar and the most basic units of carbohydrates. They cannot be further hydrolyzed to simpler chemical compounds. The general formula is . They are usually colorless, water-soluble, and crystalline solids. Some monosaccharides have a sweet taste. But all the compounds which fit into this general formula may not be classified as carbohydrates. For example, Acetic Acid which fits in the formula is not a carbohydrate.

Examples of monosaccharides include glucose (dextrose), fructose (levulose), and galactose. Monosaccharides are the building blocks of disaccharides (such as sucrose and lactose) and polysaccharides (such as cellulose and starch). Each carbon atom that supports a hydroxyl group is chiral, except those at the end of the chain. This gives rise to a number of isomeric forms, all with the same chemical formula. For instance, galactose and glucose are both aldohexoses, but have different physical structures and chemical properties.

The monosaccharide glucose plays a pivotal role in metabolism, where the chemical energy is extracted through glycolysis and the citric acid cycle to provide energy to living organisms. Some other monosaccharides can be converted in the living organism to glucose.

With few exceptions (e.g., deoxyribose), monosaccharides have this chemical formula: (CHO), where conventionally "x" ≥ 3. Monosaccharides can be classified by the number "x" of carbon atoms they contain: triose (3), tetrose (4), pentose (5), hexose (6), heptose (7), and so on.

Glucose, used as an energy source and for the synthesis of starch, glycogen and cellulose, is a hexose. Ribose and deoxyribose (in RNA and DNA respectively) are pentose sugars. Examples of heptoses include the ketoses, mannoheptulose and sedoheptulose. Monosaccharides with eight or more carbons are rarely observed as they are quite unstable. In aqueous solutions monosaccharides exist as rings if they have more than four carbons.

Simple monosaccharides have a linear and unbranched carbon skeleton with one carbonyl (C=O) functional group, and one hydroxyl (OH) group on each of the remaining carbon atoms. Therefore, the molecular structure of a simple monosaccharide can be written as H(CHOH)(C=O)(CHOH)H, where "n" + 1 + "m" = "x"; so that its elemental formula is CHO.

By convention, the carbon atoms are numbered from 1 to "x" along the backbone, starting from the end that is closest to the C=O group. Monosaccharides are the simplest units of carbohydrates and the simplest form of sugar.

If the carbonyl is at position 1 (that is, "n" or "m" is zero), the molecule begins with a formyl group H(C=O)− and is technically an aldehyde. In that case, the compound is termed an aldose. Otherwise, the molecule has a keto group, a carbonyl −(C=O)− between two carbons; then it is formally a ketone, and is termed a ketose. Ketoses of biological interest usually have the carbonyl at position 2.

The various classifications above can be combined, resulting in names such as "aldohexose" and "ketotriose".

A more general nomenclature for open-chain monosaccharides combines a Greek prefix to indicate the number of carbons (tri-, tetr-, pent-, hex-, etc.) with the suffixes "-ose" for aldoses and "-ulose" for ketoses. In the latter case, if the carbonyl is not at position 2, its position is then indicated by a numeric infix. So, for example, H(C=O)(CHOH)H is pentose, H(CHOH)(C=O)(CHOH)H is pentulose, and H(CHOH)(C=O)(CHOH)H is pent-3-ulose.

Two monosaccharides with equivalent molecular graphs (same chain length and same carbonyl position) may still be distinct stereoisomers, whose molecules differ in spatial orientation. This happens only if the molecule contains a stereogenic center, specifically a carbon atom that is chiral (connected to four distinct molecular sub-structures). Those four bonds can have any of two configurations in space distinguished by their handedness. In a simple open-chain monosaccharide, every carbon is chiral except the first and the last atoms of the chain, and (in ketoses) the carbon with the keto group.

For example, the triketose H(CHOH)(C=O)(CHOH)H (glycerone, dihydroxyacetone) has no stereogenic center, and therefore exists as a single stereoisomer. The other triose, the aldose H(C=O)(CHOH)H (glyceraldehyde), has one chiral carbon — the central one, number 2 — which is bonded to groups −H, −OH, −C(OH)H, and −(C=O)H. Therefore, it exists as two stereoisomers whose molecules are mirror images of each other (like a left and a right glove). Monosaccharides with four or more carbons may contain multiple chiral carbons, so they typically have more than two stereoisomers. The number of distinct stereoisomers with the same diagram is bounded by 2, where "c" is the total number of chiral carbons.

The Fischer projection is a systematic way of drawing the skeletal formula of an acyclic monosaccharide so that the handedness of each chiral carbon is well specified. Each stereoisomer of a simple open-chain monosaccharide can be identified by the positions (right or left) in the Fischer diagram of the chiral hydroxyls (the hydroxyls attached to the chiral carbons).

Most stereoisomers are themselves chiral (distinct from their mirror images). In the Fischer projection, two mirror-image isomers differ by having the positions of all chiral hydroxyls reversed right-to-left. Mirror-image isomers are chemically identical in non-chiral environments, but usually have very different biochemical properties and occurrences in nature.

While most stereoisomers can be arranged in pairs of mirror-image forms, there are some non-chiral stereoisomers that are identical to their mirror images, in spite of having chiral centers. This happens whenever the molecular graph is symmetrical, as in the 3-ketopentoses H(CHOH)(CO)(CHOH)H, and the two halves are mirror images of each other. In that case, mirroring is equivalent to a half-turn rotation. For this reason, there are only three distinct 3-ketopentose stereoisomers, even though the molecule has two chiral carbons.

Distinct stereoisomers that are not mirror-images of each other usually have different chemical properties, even in non-chiral environments. Therefore, each mirror pair and each non-chiral stereoisomer may be given a specific monosaccharide name. For example, there are 16 distinct aldohexose stereoisomers, but the name "glucose" means a specific pair of mirror-image aldohexoses. In the Fischer projection, one of the two glucose isomers has the hydroxyl at left on C3, and at right on C4 and C5; while the other isomer has the reversed pattern. These specific monosaccharide names have conventional three-letter abbreviations, like "Glu" for glucose and "Thr" for threose.

Generally, a monosaccharide with "n" asymmetrical carbons has 2 stereoisomers. The number of open chain stereoisomers for an aldose monosaccharide is larger by one than that of a ketose monosaccharide of the same length. Every ketose will have 2 stereoisomers where "n" > 2 is the number of carbons. Every aldose will have 2 stereoisomers where "n" > 2 is the number of carbons.
These are also referred to as epimers which have the different arrangement of −OH and −H groups at the asymmetric or chiral carbon atoms (this does not apply to those carbons having the carbonyl functional group).

Like many chiral molecules, the two stereoisomers of glyceraldehyde will gradually rotate the polarization direction of linearly polarized light as it passes through it, even in solution. The two stereoisomers are identified with the prefixes - and -, according to the sense of rotation: -glyceraldehyde is dextrorotatory (rotates the polarization axis clockwise), while -glyceraldehyde is levorotatory (rotates it counterclockwise).
The - and - prefixes are also used with other monosaccharides, to distinguish two particular stereoisomers that are mirror-images of each other. For this purpose, one considers the chiral carbon that is furthest removed from the C=O group. Its four bonds must connect to −H, −OH, −C(OH)H, and the rest of the molecule. If the molecule can be rotated in space so that the directions of those four groups match those of the analog groups in -glyceraldehyde's C2, then the isomer receives the - prefix. Otherwise, it receives the - prefix.

In the Fischer projection, the - and - prefixes specifies the configuration at the carbon atom that is second from bottom: - if the hydroxyl is on the right side, and - if it is on the left side.

Note that the - and - prefixes do not indicate the direction of rotation of polarized light, which is a combined effect of the arrangement at all chiral centers. However, the two enantiomers will always rotate the light in opposite directions, by the same amount. See also .

A monosaccharide often switches from the acyclic (open-chain) form to a cyclic form, through a nucleophilic addition reaction between the carbonyl group and one of the hydroxyls of the same molecule. The reaction creates a ring of carbon atoms closed by one bridging oxygen atom. The resulting molecule has a hemiacetal or hemiketal group, depending on whether the linear form was an aldose or a ketose. The reaction is easily reversed, yielding the original open-chain form.

In these cyclic forms, the ring usually has five or six atoms. These forms are called furanoses and pyranoses, respectively — by analogy with furan and pyran, the simplest compounds with the same carbon-oxygen ring (although they lack the double bonds of these two molecules). For example, the aldohexose glucose may form a hemiacetal linkage between the hydroxyl on carbon 1 and the oxygen on carbon 4, yielding a molecule with a 5-membered ring, called glucofuranose. The same reaction can take place between carbons 1 and 5 to form a molecule with a 6-membered ring, called glucopyranose. Cyclic forms with a seven-atom ring (the same of oxepane), rarely encountered, are called heptoses.

For many monosaccharides (including glucose), the cyclic forms predominate, in the solid state and in solutions, and therefore the same name commonly is used for the open- and closed-chain isomers. Thus, for example, the term "glucose" may signify glucofuranose, glucopyranose, the open-chain form, or a mixture of the three.

Cyclization creates a new stereogenic center at the carbonyl-bearing carbon. The −OH group that replaces the carbonyl's oxygen may end up in two distinct positions relative to the ring's midplane. Thus each open-chain monosaccharide yields two cyclic isomers (anomers), denoted by the prefixes α- and β-. The molecule can change between these two forms by a process called mutarotation, that consists in a reversal of the ring-forming reaction followed by another ring formation.

The stereochemical structure of a cyclic monosaccharide can be represented in a Haworth projection. In this diagram, the α-isomer for the pyranose form of a -aldohexose has the −OH of the anomeric carbon below the plane of the carbon atoms, while the β-isomer has the −OH of the anomeric carbon above the plane. Pyranoses typically adopt a chair conformation, similar to that of cyclohexane. In this conformation, the α-isomer has the −OH of the anomeric carbon in an axial position, whereas the β-isomer has the −OH of the anomeric carbon in equatorial position (considering -aldohexose sugars).

A large number of biologically important modified monosaccharides exist:






</doc>
<doc id="19924" url="https://en.wikipedia.org/wiki?curid=19924" title="Microscopium">
Microscopium

Microscopium ("the Microscope") is a minor constellation in the southern celestial hemisphere, one of twelve created in the 18th century by French astronomer Nicolas-Louis de Lacaille and one of several depicting scientific instruments. The name is a Latinised form of the Greek word for microscope. Its stars are faint and hardly visible from most of the non-tropical Northern Hemisphere.

The constellation's brightest star is Gamma Microscopii of apparent magnitude 4.68, a yellow giant 2.5 times the Sun's mass located 223 ± 8 light-years distant. It passed within 1.14 and 3.45 light-years of the Sun some 3.9 million years ago, possibly disturbing the outer Solar System. Two star systems—WASP-7 and HD 205739—have been determined to have planets, while two others—the young red dwarf star AU Microscopii and the sunlike HD 202628—have debris disks. AU Microscopii and the binary red dwarf system AT Microscopii are probably a wide triple system and members of the Beta Pictoris moving group. Nicknamed "Speedy Mic", BO Microscopii is a star with an extremely fast rotation period of 9 hours, 7 minutes.

Microscopium is a small constellation bordered by Capricornus to the north, Piscis Austrinus and Grus to the east, Sagittarius to the west, and Indus to the south, touching on Telescopium to the southwest. The recommended three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is "Mic". The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of four segments ("illustrated in infobox"). In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between −27.45° and −45.09°. The whole constellation is visible to observers south of latitude 45°N. Given that its brightest stars are of fifth magnitude, the constellation is invisible to the naked eye in areas with light polluted skies.

French astronomer Nicolas-Louis de Lacaille charted and designated ten stars with the Bayer designations Alpha through to Iota in 1756. A star in neighbouring Indus that Lacaille had labelled Nu Indi turned out to be in Microscopium, so Gould renamed it Nu Microscopii. Francis Baily considered Gamma and Epsilon Microscopii to belong to the neighbouring constellation Piscis Austrinus, but subsequent cartographers did not follow this. In his 1725 "Catalogus Britannicus", John Flamsteed labelled the stars 1, 2, 3 and 4 Piscis Austrini, which became Gamma Microscopii, HR 8076, HR 8110 and Epsilon Microscopii respectively. Within the constellation's borders, there are 43 stars brighter than or equal to apparent magnitude 6.5.

Depicting the eyepiece of the microscope is Gamma Microscopii, which—at magnitude of 4.68—is the brightest star in the constellation. Having spent much of its 620-million-year lifespan as a blue-white main sequence star, it has swollen and cooled to become a yellow giant of spectral type G6III, with a diameter ten times that of the Sun. Measurement of its parallax yields a distance of 223 ± 8 light years from Earth. It likely passed within 1.14 and 3.45 light-years of the Sun some 3.9 million years ago, at around 2.5 times the mass of the Sun, it is possibly massive enough and close enough to disturb the Oort cloud. Alpha Microscopii is also an ageing yellow giant star of spectral type G7III with an apparent magnitude of 4.90. Located 400 ± 30 light-years away from Earth, it has swollen to 17.5 times the diameter of the Sun. Alpha has a 10th magnitude companion, visible in 7.5 cm telescopes, though this is a coincidental closeness rather than a true binary system. Epsilon Microscopii lies 166 ± 5 light-years away, and is a white star of apparent magnitude 4.7, and spectral type A1V. Theta and Theta Microscopii make up a wide double whose components are splittable to the naked eye. Both are white A-class magnetic spectrum variable stars with strong metallic lines, similar to Cor Caroli. They mark the constellation's specimen slide.

Many notable objects are too faint to be seen with the naked eye. AX Microscopii, better known as Lacaille 8760, is a red dwarf which lies only 12.9 light-years from the Solar System. At magnitude 6.68, it is the brightest red dwarf in the sky. BO Microscopii is a rapidly rotating star that has 80% the diameter of the Sun. Nicknamed "Speedy Mic", it has a rotation period of 9 hours 7 minutes. An active star, it has prominent stellar flares that average 100 times stronger than those of the Sun, and are emitting energy mainly in the X-ray and ultraviolet bands of the spectrum. It lies 218 ± 4 light-years away from the Sun. AT Microscopii is a binary star system, both members of which are flare star red dwarfs. The system lies close to and may form a very wide triple system with AU Microscopii, a young star which appears to be a planetary system in the making with a debris disk. The three stars are candidate members of the Beta Pictoris moving group, one of the nearest associations of stars that share a common motion through space.

The Astronomical Society of Southern Africa in 2003 reported that observations of four of the Mira variables in Microscopium were very urgently needed as data on their light curves was incomplete. Two of them—R and S Microscopii—are challenging stars for novice amateur astronomers, and the other two, U and RY Microscopii, are more difficult still. Another red giant, T Microscopii, is a semiregular variable that ranges between magnitudes 7.7 and 9.6 over 344 days. Of apparent magnitude 11, DD Microscopii is a symbiotic star system composed of an orange giant of spectral type K2III and white dwarf in close orbit, with the smaller star ionizing the stellar wind of the larger star. The system has a low metallicity. Combined with its high galactic latitude, this indicates that the star system has its origin in the galactic halo of the Milky Way.

HD 205739 is a yellow-white main sequence star of spectral type F7V that is around 1.22 times as massive and 2.3 times as luminous as the Sun. It has a Jupiter-sized planet with an orbital period of 280 days that was discovered by the radial velocity method. WASP-7 is a star of spectral type F5V with an apparent magnitude of 9.54, about 1.28 times as massive as the Sun. Its hot Jupiter planet—WASP-7b—was discovered by transit method and found to orbit the star every 4.95 days. HD 202628 is a sunlike star of spectral type G2V with a debris disk that ranges from 158 to 220 AU distant. Its inner edge is sharply defined, indicating a probable planet orbiting between 86 and 158 AU from the star.

Describing Microscopium as "totally unremarkable", astronomer Patrick Moore concluded there was nothing of interest for amateur observers. NGC 6925 is a barred spiral galaxy of apparent magnitude 11.3 which is lens-shaped, as it lies almost edge-on to observers on Earth, 3.7 degrees west-northwest of Alpha Microscopii. SN 2011ei, a Type II Supernova in NGC 6925, was discovered by Stu Parker in New Zealand in July 2011. NGC 6923 lies nearby and is a magnitude fainter still. The Microscopium Void is a roughly rectangular region of relatively empty space, bounded by incomplete sheets of galaxies from other voids. The Microscopium Supercluster is an overdensity of galaxy clusters that was first noticed in the early 1990s. The component Abell clusters 3695 and 3696 are likely to be gravitationally bound, while the relations of Abell clusters 3693 and 3705 in the same field are unclear.

The Microscopids are a minor meteor shower that appear from June to mid-July.

The stars that comprise Microscopium are in a region previously considered the hind feet of Sagittarius, a neighbouring constellation. John Ellard Gore wrote that al-Sufi seems to have reported that Ptolemy had seen the stars but he (Al Sufi) did not pinpoint their positions. Microscopium itself was introduced in 1751–52 by Lacaille with the French name "le Microscope", after he had observed and catalogued 10,000 southern stars during a two-year stay at the Cape of Good Hope. He devised fourteen new constellations in uncharted regions of the Southern Celestial Hemisphere not visible from Europe. All but one honoured instruments that symbolised the Age of Enlightenment. Commemorating the compound microscope, the Microscope's name had been Latinised by Lacaille to "Microscopium" by 1763.



</doc>
<doc id="19925" url="https://en.wikipedia.org/wiki?curid=19925" title="IC 342/Maffei Group">
IC 342/Maffei Group

The IC 342/Maffei Group (also known as the IC 342 Group or the Maffei 1 Group) is the nearest group of galaxies to the Local Group. The group can be described as a binary group; the member galaxies are mostly concentrated around either IC 342 or Maffei 1, both of which are the brightest galaxies within the group. The group is part of the Virgo Supercluster.

The table below lists galaxies that have been identified as associated with the IC342/Maffei 1 Group by I. D. Karachentsev. Note that Karachentsev divides this group into two subgroups centered around IC 342 and Maffei 1.

Additionally, KKH 37 is listed as possibly being a member of the IC 342 Subgroup, and KKH 6 is listed as possibly being a member of the Maffei 1 Subgroup.

As seen from Earth, the group lies near the plane of the Milky Way (a region sometimes called the Zone of Avoidance). Consequently, the light from many of the galaxies is severely affected by dust obscuration within the Milky Way. This complicates observational studies of the group, as uncertainties in the dust obscuration also affect measurements of the galaxies' luminosities and distances as well as other related quantities.

Moreover, the galaxies within the group have historically been difficult to identify. Many galaxies have only been discovered using late 20th century astronomical instrumentation. For example, while many fainter, more distant galaxies, such as the galaxies in the New General Catalogue, were already identified visually by the end of the nineteenth century, Maffei 1 and Maffei 2 were only discovered in 1968 using infrared photographic images of the region. Furthermore, it is difficult to determine whether some objects near IC 342 or Maffei 1 are galaxies associated with the IC 342/Maffei Group or diffuse foreground objects within the Milky Way that merely look like galaxies. For example, the objects MB 2 and Camelopardalis C were once thought to be dwarf galaxies in the IC 342/Maffei Group but are now known to be objects within the Milky Way.

Since the IC 342/Maffei Group and the Local Group are located physically close to each other, the two groups may have influenced each other's evolution during the early stages of galaxy formation. An analysis of the velocities and distances to the IC 342/Maffei Group as measured by M. J. Valtonen and collaborators suggested that IC 342 and Maffei 1 were moving faster than what could be accounted for in the expansion of the universe. They therefore suggested that IC 342 and Maffei 1 were ejected from the Local Group after a violent gravitational interaction with the Andromeda Galaxy during the early stages of the formation of the two groups.

However, this interpretation is dependent on the distances measured to the galaxies in the group, which in turn is dependent on accurately measuring the degree to which interstellar dust in the Milky Way obscures the group. More recent observations have demonstrated that the dust obscuration may have been previously overestimated, so the distances may have been underestimated. If these new distance measurements are correct, then the galaxies in the IC 342/Maffei Group appear to be moving at the rate expected from the expansion of the universe, and the scenario of a collision between the IC 342/Maffei Group and the Local Group would be implausible.


</doc>
<doc id="19926" url="https://en.wikipedia.org/wiki?curid=19926" title="M81 Group">
M81 Group

The M81 Group is a galaxy group in the constellations Ursa Major and Camelopardalis that includes the galaxies Messier 81 and Messier 82, as well as several other galaxies with high apparent brightnesses. The approximate center of the group is located at a distance of 3.6 Mpc, making it one of the nearest groups to the Local Group. The group is estimated to have a total mass of (1.03 ± 0.17).
The M81 Group, the Local Group, and other nearby groups all lie within the Virgo Supercluster (i.e. the Local Supercluster).

The table below lists galaxies that have been identified as associated with the M81 Group by I. D. Karachentsev.

Note that the object names used in the above table differ from the names used by Karachentsev. NGC, IC, UGC, and PGC numbers have been used in many cases to allow for easier referencing.

Messier 81, Messier 82, and NGC 3077 are all strongly interacting with each other. Observations of the 21-centimeter hydrogen line indicate how the galaxies are connected. 
The gravitational interactions have stripped some hydrogen gas away from all three galaxies, leading to the formation of filamentary gas structures within the group. Bridges of neutral hydrogen have been shown to connect M81 with M82 and NGC 3077. Moreover, the interactions have also caused some interstellar gas to fall into the centers of Messier 82 and NGC 3077, which has led to strong starburst activity (or the formation of many stars) within the centers of these two galaxies. Computer simulations of tidal interactions have been used to show how the current structure of the group could have been created.



</doc>
<doc id="19929" url="https://en.wikipedia.org/wiki?curid=19929" title="Mensa">
Mensa

Mensa may refer to:


</doc>
<doc id="19930" url="https://en.wikipedia.org/wiki?curid=19930" title="Metre (poetry)">
Metre (poetry)

In poetry, metre (British) or meter (American; see spelling differences) is the basic rhythmic structure of a verse or lines in verse. Many traditional verse forms prescribe a specific verse metre, or a certain set of metres alternating in a particular order. The study and the actual use of metres and forms of versification are both known as prosody. (Within linguistics, "prosody" is used in a more general sense that includes not only poetic metre but also the rhythmic aspects of prose, whether formal or informal, that vary from language to language, and sometimes between poetic traditions.)

An assortment of features can be identified when classifying poetry and its metre.

The metre of most poetry of the Western world and elsewhere is based on patterns of syllables of particular types. The familiar type of metre in English-language poetry is called qualitative metre, with stressed syllables coming at regular intervals (e.g. in iambic pentameters, usually every even-numbered syllable). Many Romance languages use a scheme that is somewhat similar but where the position of only one particular stressed syllable (e.g. the last) needs to be fixed. The metre of the old Germanic poetry of languages such as Old Norse and Old English was radically different, but was still based on stress patterns.

Some classical languages, in contrast, used a different scheme known as quantitative metre, where patterns were based on syllable weight rather than stress. In the dactylic hexameters of Classical Latin and Classical Greek, for example, each of the six feet making up the line was either a dactyl (long-short-short) or a spondee (long-long): a "long syllable" was literally one that took longer to pronounce than a short syllable: specifically, a syllable consisting of a long vowel or diphthong or followed by two consonants. The stress pattern of the words made no difference to the metre. A number of other ancient languages also used quantitative metre, such as Sanskrit and Classical Arabic (but not Biblical Hebrew).

Finally, non-stressed languages that have little or no differentiation of syllable length, such as French or Chinese, base their verses on the number of syllables only. The most common form in French is the , with twelve syllables a verse, and in classical Chinese five characters, and thus five syllables. But since each Chinese character is pronounced using one syllable in a certain tone, classical Chinese poetry also had more strictly defined rules, such as thematic parallelism or tonal antithesis between lines.

In many Western classical poetic traditions, the metre of a verse can be described as a sequence of "feet", each foot being a specific sequence of syllable types — such as relatively unstressed/stressed (the norm for English poetry) or long/short (as in most classical Latin and Greek poetry).

Iambic pentameter, a common metre in English poetry, is based on a sequence of five "iambic feet" or "iambs", each consisting of a relatively unstressed syllable (here represented with "-" above the syllable) followed by a relatively stressed one (here represented with "/" above the syllable) — "da-DUM" = "- /" :

This approach to analyzing and classifying metres originates from Ancient Greek tragedians and poets such as Homer, Pindar, Hesiod, and Sappho.

However some metres have an overall rhythmic pattern to the line that cannot easily be described using feet. This occurs in Sanskrit poetry; see Vedic metre and Sanskrit metre. (Although this poetry is in fact specified using feet, each "foot" is more or less equivalent to an entire line.) It also occurs in some Western metres, such as the hendecasyllable favoured by Catullus and Martial, which can be described as:

x x — ∪ ∪ — ∪ — ∪ — —

If the line has only one foot, it is called a "monometer"; two feet, "dimeter"; three is "trimeter"; four is "tetrameter"; five is "pentameter"; six is "hexameter", seven is "heptameter" and eight is "octameter". For example, if the feet are iambs, and if there are five feet to a line, then it is called an iambic pentameter. If the feet are primarily "dactyls" and there are six to a line, then it is a dactylic hexameter.

Sometimes a natural pause occurs in the middle of a line rather than at a line-break. This is a caesura (cut). A good example is from "The Winter's Tale" by William Shakespeare; the caesurae are indicated by '/':
In Latin and Greek poetry, a caesura is a break within a foot caused by the end of a word.

Each line of traditional Germanic alliterative verse is divided into two half-lines by a caesura. This can be seen in Piers Plowman:

By contrast with caesura, enjambment is incomplete syntax at the end of a line; the meaning runs over from one poetic line to the next, without terminal punctuation. Also from Shakespeare's "The Winter's Tale":
Poems with a well-defined overall metric pattern often have a few lines that violate that pattern. A common variation is the "inversion" of a foot, which turns an iamb ("da-DUM") into a trochee ("DUM-da"). A second variation is a "headless" verse, which lacks the first syllable of the first foot. A third variation is catalexis, where the end of a line is shortened by a foot, or two or part thereof – an example of this is at the end of each verse in Keats' 'La Belle Dame sans Merci':

Most English metre is classified according to the same system as Classical metre with an important difference. English is an accentual language, and therefore beats and offbeats (stressed and unstressed syllables) take the place of the long and short syllables of classical systems. In most English verse, the metre can be considered as a sort of back beat, against which natural speech rhythms vary expressively. The most common characteristic feet of English verse are the iamb in two syllables and the anapest in three. (See Foot (prosody) for a complete list of the metrical feet and their names.)

The number of metrical systems in English is not agreed upon. The four major types are: accentual verse, accentual-syllabic verse, syllabic verse and quantitative verse. The alliterative verse of Old English could also be added to this list, or included as a special type of accentual verse. Accentual verse focuses on the number of stresses in a line, while ignoring the number of offbeats and syllables; accentual-syllabic verse focuses on regulating both the number of stresses and the total number of syllables in a line; syllabic verse only counts the number of syllables in a line; quantitative verse regulates the patterns of long and short syllables (this sort of verse is often considered alien to English). The use of foreign metres in English is all but exceptional.

The most frequently encountered metre of English verse is the iambic pentameter, in which the metrical norm is five iambic feet per line, though metrical substitution is common and rhythmic variations practically inexhaustible. John Milton's "Paradise Lost", most sonnets, and much else besides in English are written in iambic pentameter. Lines of unrhymed iambic pentameter are commonly known as blank verse. Blank verse in the English language is most famously represented in the plays of William Shakespeare and the great works of Milton, though Tennyson ("Ulysses", "The Princess") and Wordsworth ("The Prelude") also make notable use of it.

A rhymed pair of lines of iambic pentameter make a heroic couplet, a verse form which was used so often in the 18th century that it is now used mostly for humorous effect (although see Pale Fire for a non-trivial case). The most famous writers of heroic couplets are Dryden and Pope.

Another important metre in English is the ballad metre, also called the "common metre", which is a four-line stanza, with two pairs of a line of iambic tetrameter followed by a line of iambic trimeter; the rhymes usually fall on the lines of trimeter, although in many instances the tetrameter also rhymes. This is the metre of most of the Border and Scots or English ballads. In hymnody it is called the "common metre", as it is the most common of the named hymn metres used to pair many hymn lyrics with melodies, such as "Amazing Grace":

Emily Dickinson is famous for her frequent use of ballad metre:

Versification in Classical Sanskrit poetry is of three kinds.


Standard traditional works on metre are Pingala's and Kedāra's . The most exhaustive compilations, such as the modern ones by Patwardhan and Velankar contain over 600 metres. This is a substantially larger repertoire than in any other metrical tradition.

The metrical "feet" in the classical languages were based on the length of time taken to pronounce each syllable, which were categorized according to their weight as either "long" syllables or "short" syllables (indicated as "dum" and "di" below). These are also called "heavy" and "light" syllables, respectively, to distinguish from long and short vowels. The foot is often compared to a musical measure and the long and short syllables to whole notes and half notes. In English poetry, feet are determined by emphasis rather than length, with stressed and unstressed syllables serving the same function as long and short syllables in classical metre.

The basic unit in Greek and Latin prosody is a mora, which is defined as a single short syllable. A long syllable is equivalent to two morae. A long syllable contains either a long vowel, a diphthong, or a short vowel followed by two or more consonants. Various rules of elision sometimes prevent a grammatical syllable from making a full syllable, and certain other lengthening and shortening rules (such as correption) can create long or short syllables in contexts where one would expect the opposite.

The most important Classical metre is the dactylic hexameter, the metre of Homer and Virgil. This form uses verses of six feet. The word "dactyl" comes from the Greek word "daktylos" meaning "finger", since there is one long part followed by two short stretches. The first four feet are dactyls ("daa-duh-duh"), but can be spondees ("daa-daa"). The fifth foot is almost always a dactyl. The sixth foot is either a spondee or a trochee ("daa-duh"). The initial syllable of either foot is called the "ictus", the basic "beat" of the verse. There is usually a caesura after the ictus of the third foot. The opening line of the "Æneid" is a typical line of dactylic hexameter:

In this example, the first and second feet are dactyls; their first syllables, "Ar" and "rum" respectively, contain short vowels, but count as long because the vowels are both followed by two consonants. The third and fourth feet are spondees, the first of which is divided by the main caesura of the verse. The fifth foot is a dactyl, as is nearly always the case. The final foot is a spondee.

The dactylic hexameter was imitated in English by Henry Wadsworth Longfellow in his poem "Evangeline":
Notice how the first line:

Follows this pattern:

Also important in Greek and Latin poetry is the dactylic pentameter. This was a line of verse, made up of two equal parts, each of which contains two dactyls followed by a long syllable, which counts as a half foot. In this way, the number of feet amounts to five in total. Spondees can take the place of the dactyls in the first half, but never in the second. The long syllable at the close of the first half of the verse always ends a word, giving rise to a caesura.

Dactylic pentameter is never used in isolation. Rather, a line of dactylic pentameter follows a line of dactylic hexameter in the elegiac distich or elegiac couplet, a form of verse that was used for the composition of elegies and other tragic and solemn verse in the Greek and Latin world, as well as love poetry that was sometimes light and cheerful. An example from Ovid's "Tristia":

The Greeks and Romans also used a number of lyric metres, which were typically used for shorter poems than elegiacs or hexameter. In Aeolic verse, one important line was called the hendecasyllabic, a line of eleven syllables. This metre was used most often in the Sapphic stanza, named after the Greek poet Sappho, who wrote many of her poems in the form. A hendecasyllabic is a line with a never-varying structure: two trochees, followed by a dactyl, then two more trochees. In the Sapphic stanza, three hendecasyllabics are followed by an "Adonic" line, made up of a dactyl and a trochee. This is the form of Catullus 51 (itself an homage to Sappho 31):

The Sapphic stanza was imitated in English by Algernon Charles Swinburne in a poem he simply called "Sapphics":

The metrical system of Classical Arabic poetry, like those of classical Greek and Latin, is based on the weight of syllables classified as either "long" or "short". The basic principles of Arabic poetic metre "Arūḍ" or Arud ( ') Science of Poetry ( '), were put forward by Al-Farahidi (786 - 718 CE) who did so after noticing that poems consisted of repeated syllables in each verse. In his first book, "Al-Ard" ( ""), he described 15 types of verse. Al-Akhfash described one extra, the 16th.

A short syllable contains a short vowel with no following consonants. For example, the word "kataba," which syllabifies as "ka-ta-ba", contains three short vowels and is made up of three short syllables. A long syllable contains either a long vowel or a short vowel followed by a consonant as is the case in the word "maktūbun" which syllabifies as "mak-tū-bun". These are the only syllable types possible in Classical Arabic phonology which, by and large, does not allow a syllable to end in more than one consonant or a consonant to occur in the same syllable after a long vowel. In other words, syllables of the type "-āk-" or "-akr-" are not found in classical Arabic.

Each verse consists of a certain number of metrical feet ("tafāʿīl" or "ʾaǧzāʾ") and a certain combination of possible feet constitutes a metre ("baḥr").

The traditional Arabic practice for writing out a poem's metre is to use a concatenation of various derivations of the verbal root "F-ʿ-L" (فعل). Thus, the following hemistich

قفا نبك من ذكرى حبيبٍ ومنزلِ

Would be traditionally scanned as:

فعولن مفاعيلن فعولن مفاعلن

That is, Romanized and with traditional Western scansion:

Al-Kʰalīl b. ˀAḫmad al-Farāhīdī's contribution to the study of Arabic prosody is undeniably significant: he was the first scholar to subject Arabic poetry to a meticulous, painstaking metrical analysis. Unfortunately, he fell short of producing a coherent theory; instead, he was content to merely gather, classify, and categorize the primary data—a first step which, though insufficient, represents no mean accomplishment. Therefore al-Kʰalīl has left a formulation of utmost complexity and difficulty which requires immense effort to master; even the accomplished scholar cannot utilize and apply it with ease and total confidence. Dr. ˀIbrāhīm ˀAnīs, one of the most distinguished and celebrated pillars of Arabic literature and the Arabic language in the 20th century, states the issue clearly in his book Mūsīqā al-Sʰiˁr:

“I am aware of no [other] branch of Arabic studies which embodies as many [technical] terms as does [al-Kʰalīl’s] prosody, few and distinct as the meters are: al-Kʰalīl’s disciples employed a large number of infrequent items, assigning to those items certain technical denotations which—invariably—require definition and explanation. …. As to the rules of metric variation, they are numerous to the extent that they defy memory and impose a taxing course of study. …. In learning them, a student faces severe hardship which obscures all connection with an artistic genre—indeed, the most artistic of all—namely, poetry. ………. It is in this fashion that [various] authors dealt with the subject under discussion over a period of eleven centuries: none of them attempted to introduce a new approach or to simplify the rules. ………. Is it not time for a new, simple presentation which avoids contrivance, displays close affinity to [the art of] poetry, and perhaps renders the science of prosody palatable as well as manageable?”

In the 20th and the 21st centuries, numerous scholars have endeavored to supplement al-Kʰalīl's contribution.

Classical Arabic has sixteen established metres. Though each of them allows for a certain amount of variation, their basic patterns are as follows, using:

The terminology for metrical system used in classical and classical-style Persian poetry is the same as that of Classical Arabic, even though these are quite different in both origin and structure. This has led to serious confusion among prosodists, both ancient and modern, as to the true source and nature of the Persian metres, the most obvious error being the assumption that they were copied from Arabic.

Persian poetry is quantitative, and the metrical patterns are made of long and short syllables, much as in Classical Greek, Latin and Arabic. "Anceps" positions in the line, however, that is places where either a long or short syllable can be used (marked "x" in the schemes below), are not found in Persian verse except in some metres at the beginning of a line.

Persian poetry is written in couplets, with each half-line (hemistich) being 10-14 syllables long. Except in the ruba'i (quatrain), where either of two very similar metres may be used, the same metre is used for every line in the poem. Rhyme is always used, sometimes with double rhyme or internal rhymes in addition. In some poems, known as masnavi, the two halves of each couplet rhyme, with a scheme "aa", "bb", "cc" and so on. In lyric poetry, the same rhyme is used throughout the poem at the end of each couplet, but except in the opening couplet, the two halves of each couplet do not rhyme; hence the scheme is "aa", "ba", "ca", "da". A "ruba'i" (quatrain) also usually has the rhyme "aa, ba".

A particular feature of classical Persian prosody, not found in Latin, Greek or Arabic, is that instead of two lengths of syllables (long and short), there are three lengths (short, long, and overlong). Overlong syllables can be used anywhere in the line in place of a long + a short, or in the final position in a line or half line. When a metre has a pair of short syllables (⏑ ⏑), it is common for a long syllable to be substituted, especially at the end of a line or half-line.

About 30 different metres are commonly used in Persian. 70% of lyric poems are written in one of the following seven metres:

"Masnavi" poems (that is, long poems in rhyming couplets) are always written in one of the shorter 11 or 10-syllable metres (traditionally seven in number) such as the following:

The two metres used for "ruba'iyat" (quatrains), which are only used for this, are the following, of which the second is a variant of the first:

Classical Chinese poetic metric may be divided into fixed and variable length line types, although the actual scansion of the metre is complicated by various factors, including linguistic changes and variations encountered in dealing with a tradition extending over a geographically extensive regional area for a continuous time period of over some two-and-a-half millennia. Beginning with the earlier recorded forms: the Classic of Poetry tends toward couplets of four-character lines, grouped in rhymed quatrains; and, the Chuci follows this to some extent, but moves toward variations in line length. Han Dynasty poetry tended towards the variable line-length forms of the folk ballads and the Music Bureau yuefu. Jian'an poetry, Six Dynasties poetry, and Tang Dynasty poetry tend towards a poetic metre based on fixed-length lines of five, seven, (or, more rarely six) characters/verbal units tended to predominate, generally in couplet/quatrain-based forms, of various total verse lengths. The Song poetry is specially known for its use of the "ci", using variable line lengths which follow the specific pattern of a certain musical song's lyrics, thus "ci" are sometimes referred to as "fixed-rhythm" forms. Yuan poetry metres continued this practice with their "qu" forms, similarly fixed-rhythm forms based on now obscure or perhaps completely lost original examples (or, ur-types). Not that Classical Chinese poetry ever lost the use of the "shi" forms, with their metrical patterns found in the "old style poetry" ("gushi") and the regulated verse forms of ("lüshi" or "jintishi"). The regulated verse forms also prescribed patterns based upon linguistic tonality. The use of caesura is important in regard to the metrical analysis of Classical Chinese poetry forms.

The metric system of Old English poetry was different from that of modern English, and related more to the verse forms of most of the older Germanic languages such as Old Norse. It used alliterative verse, a metrical pattern involving varied numbers of syllables but a fixed number (usually four) of strong stresses in each line. The unstressed syllables were relatively unimportant, but the caesurae (breaks between the half-lines) played a major role in Old English poetry.

In place of using feet, alliterative verse divided each line into two half-lines. Each half-line had to follow one of five or so patterns, each of which defined a sequence of stressed and unstressed syllables, typically with two stressed syllables per half line. Unlike typical Western poetry, however, the number of unstressed syllables could vary somewhat. For example, the common pattern "DUM-da-DUM-da" could allow between one and five unstressed syllables between the two stresses.

The following is a famous example, taken from The Battle of Maldon, a poem written shortly after the date of that battle (AD 991):

<poem style="margin-left: 2em">
"Hige sceal þe heardra," || "heorte þe cēnre,"
"mōd sceal þe māre," || "swā ūre mægen lȳtlað"

("Will must be the harder, courage the bolder,
spirit must be the more, as our might lessens.")
</poem>

In the quoted section, the stressed syllables have been underlined. (Normally, the stressed syllable must be long if followed by another syllable in a word. However, by a rule known as "syllable resolution", two short syllables in a single word are considered equal to a single long syllable. Hence, sometimes two syllables have been underlined, as in "hige" and "mægen".) The German philologist Eduard Sievers (died 1932) identified five different patterns of half-line in Anglo-Saxon alliterative poetry. The first three half-lines have the type A pattern "DUM-da-(da-)DUM-da", while the last one has the type C pattern "da-(da-da-)DUM-DUM-da", with parentheses indicating optional unstressed syllables that have been inserted. Note also the pervasive pattern of alliteration, where the first and/or second stressed syllables alliterate with the third, but not with the fourth.

In French poetry, metre is determined solely by the number of syllables in a line. A silent 'e' counts as a syllable before a consonant, but is elided before a vowel (where "h aspiré" counts as a consonant). At the end of a line, the "e" remains unelided but is hypermetrical (outside the count of syllables, like a feminine ending in English verse), in that case, the rhyme is also called "feminine", whereas it is called "masculine" in the other cases.

The most frequently encountered metre in Classical French poetry is the alexandrine, composed of two hemistiches of six syllables each. Two famous alexandrines are

(the daughter of Minos and of Pasiphaë), and

Classical French poetry also had a complex set of rules for rhymes that goes beyond how words merely sound. These are usually taken into account when describing the metre of a poem.

In Spanish poetry the metre is determined by the number of syllables the verse has. Still it is the phonetic accent in the last word of the verse that decides the final count of the line. If the accent of the final word is at the last syllable, then the poetic rule states that one syllable shall be added to the actual count of syllables in the said line, thus having a higher number of poetic syllables than the number of grammatical syllables. If the accent lies on the second to last syllable of the last word in the verse, then the final count of poetic syllables will be the same as the grammatical number of syllables. Furthermore, if the accent lies on the third to last syllable, then one syllable is subtracted from the actual count, having then less poetic syllables than grammatical syllables.

Spanish poetry uses poetic licenses, unique to Romance languages, to change the number of syllables by manipulating mainly the vowels in the line.

Regarding these poetic licenses one must consider three kinds of phenomena: (1) syneresis, (2) dieresis and (3) hiatus

There are many types of licenses, used either to add or subtract syllables, that may be applied when needed after taking in consideration the poetic rules of the last word. Yet all have in common that they only manipulate vowels that are close to each other and not interrupted by consonants.

Some common metres in Spanish verse are:

In Italian poetry, metre is determined solely by the position of the last accent in a line, the position of the other accents being however important for verse equilibrium. Syllables are enumerated with respect to a verse which ends with a paroxytone, so that a Septenary (having seven syllables) is defined as a verse whose last accent falls on the sixth syllable: it may so contain eight syllables ("Ei fu. Siccome immobile") or just six ("la terra al nunzio sta"). Moreover, when a word ends with a vowel and the next one starts with a vowel, they are considered to be in the same syllable (synalepha): so "Gli anni e i giorni" consists of only four syllables ("Gli an" "ni e i" "gior" "ni"). Even-syllabic verses have a fixed stress pattern. Because of the mostly trochaic nature of the Italian language, verses with an even number of syllables are far easier to compose, and the Novenary is usually regarded as the most difficult verse.

Some common metres in Italian verse are:

Apart from Ottoman poetry, which was heavily influenced by Persian traditions and created a unique Ottoman style, traditional Turkish poetry features a system in which the number of syllables in each verse must be the same, most frequently 7, 8, 11, 14 syllables. These verses are then divided into syllable groups depending on the number of total syllables in a verse: 4+3 for 7 syllables, 4+4 or 5+3 for 8, 4+4+3 or 6+5 for 11 syllables. The end of each group in a verse is called a "durak" (stop), and must coincide with the last syllable of a word.

The following example is by Faruk Nafiz Çamlıbel (died 1973), one of the most devoted users of traditional Turkish metre:

In this poem the 6+5 metre is used, so that there is a word-break ("durak" = "stop" or caesura) after the sixth syllable of every line, as well as at the end of each line.

In the Ottoman Turkish language, the structures of the poetic foot (تفعل "tef'ile") and of poetic metre (وزن "vezin") were imitated from Persian poetry. About twelve of the most common Persian metres were used for writing Turkish poetry. As was the case with Persian, no use at all was made of the commonest metres of Arabic poetry (the "tawīl", "basīt", "kāmil", and "wāfir"). However, the terminology used to described the metres was indirectly borrowed from the Arabic poetic tradition through the medium of the Persian language.

As a result, Ottoman poetry, also known as Dîvân poetry, was generally written in quantitative, mora-timed metre. The moras, or syllables, are divided into three basic types:


In writing out a poem's poetic metre, open syllables are symbolized by "." and closed syllables are symbolized by "–". From the different syllable types, a total of sixteen different types of poetic foot—the majority of which are either three or four syllables in length—are constructed, which are named and scanned as follows:

These individual poetic feet are then combined in a number of different ways, most often with four feet per line, so as to give the poetic metre for a line of verse. Some of the most commonly used metres are the following:


Portuguese poetry uses a syllabic metre in which the verse is classified according to the last stressed syllable. The Portuguese system is quite similar to those of Spanish and Italian, as they are closely related languages. The most commonly used verses are:

There is a continuing tradition of strict metre poetry in the Welsh language that can be traced back to at least the sixth century. At the annual National Eisteddfod of Wales a bardic chair is awarded to the best , a long poem that follows the conventions of regarding stress, alliteration and rhyme.

Metrical texts are first attested in early Indo-European languages. The earliest known unambiguously metrical texts, and at the same time the only metrical texts with a claim of dating to the Late Bronze Age, are the hymns of the Rigveda. That the texts of the Ancient Near East (Sumerian, Egyptian or Semitic) should not exhibit metre is surprising, and may be partly due to the nature of Bronze Age writing. There were, in fact, attempts to reconstruct metrical qualities of the poetic portions of the Hebrew Bible, e.g. by Gustav Bickell or Julius Ley, but they remained inconclusive (see Biblical poetry). Early Iron Age metrical poetry is found in the Iranian Avesta and in the Greek works attributed to Homer and Hesiod.
Latin verse survives from the Old Latin period (c. 2nd century BC), in the Saturnian metre. Persian poetry arises in the Sassanid era. Tamil poetry of the early centuries AD may be the earliest known non-Indo-European

Medieval poetry was metrical without exception, spanning traditions as diverse as European Minnesang, Trouvère or Bardic poetry, Classical Persian and Sanskrit poetry, Tang dynasty Chinese poetry or the Japanese Nara period "Man'yōshū". Renaissance and Early Modern poetry in Europe is characterized by a return to templates of Classical Antiquity, a tradition begun by Petrarca's generation and continued into the time of Shakespeare and Milton.

Not all poets accept the idea that metre is a fundamental part of poetry. 20th-century American poets Marianne Moore, William Carlos Williams and Robinson Jeffers believed that metre was an artificial construct imposed upon poetry rather than being innate to poetry. In an essay titled "Robinson Jeffers, & The Metric Fallacy" Dan Schneider echoes Jeffers' sentiments: "What if someone actually said to you that all music was composed of just 2 notes? Or if someone claimed that there were just 2 colors in creation? Now, ponder if such a thing were true. Imagine the clunkiness & mechanicality of such music. Think of the visual arts devoid of not just color, but sepia tones, & even shades of gray." Jeffers called his technique "rolling stresses".

Moore went further than Jeffers, openly declaring her poetry was written in syllabic form, and wholly denying metre. These syllabic lines from her famous poem illustrate her contempt for metre and other poetic tools. Even the syllabic pattern of this poem does not remain perfectly consistent:

Williams tried to form poetry whose subject matter was centered on the lives of common people. He came up with the concept of the variable foot. Williams spurned traditional metre in most of his poems, preferring what he called "colloquial idioms." Another poet who turned his back on traditional concepts of metre was Britain's Gerard Manley Hopkins. Hopkins' major innovation was what he called sprung rhythm. He claimed most poetry was written in this older rhythmic structure inherited from the Norman side of the English literary heritage, based on repeating groups of two or three syllables, with the stressed syllable falling in the same place on each repetition. Sprung rhythm is structured around feet with a variable number of syllables, generally between one and four syllables per foot, with the stress always falling on the first syllable in a foot.




</doc>
<doc id="19932" url="https://en.wikipedia.org/wiki?curid=19932" title="Majed Moqed">
Majed Moqed

Majed Mashaan Ghanem Moqed (, ; also transliterated as Moqued) (June 18, 1977 – September 11, 2001) was one of five hijackers of American Airlines Flight 77 as part of the September 11 attacks.

A Saudi, Moqed was studying law at a university in Saudi Arabia before joining Al-Qaeda in 1999 and being chosen to participate in the 9/11 attacks. He arrived in the United States in May 2001 and helped with the planning of how the attacks would be carried out.

On September 11, 2001, Moqed boarded American Airlines Flight 77 and assisted in the hijacking of the plane so that it could be crashed into the Pentagon.

Moqed was a law student from the small town of Al-Nakhil, Saudi Arabia (west of Medina), studying at King Fahd University's Faculty of Administration and Economics. Before he dropped out, he was apparently recruited into al-Qaeda in 1999 along with friend Satam al-Suqami, with whom he had earlier shared a college room. 

The two trained at Khalden, a large training facility near Kabul that was run by Ibn al-Shaykh al-Libi. A friend in Saudi Arabia claimed he was last seen there in 2000, before leaving to study English in the United States. In November 2000, Moqed and Suqami flew into Iran from Bahrain together.

Some time late in 2000, Moqed traveled to the United Arab Emirates, where he purchased traveler's cheques presumed to have been paid for by 9/11 financier Mustafa Ahmed al-Hawsawi. Five other hijackers also passed through the UAE and purchased travellers cheques, including Wail al-Shehri, Saeed al-Ghamdi, Hamza al-Ghamdi, Ahmed al-Haznawi and Ahmed al-Nami.

Known as "al-Ahlaf" during the preparations, Moqed then moved in with hijackers Salem al-Hazmi, Abdulaziz al-Omari and Khalid al-Mihdhar in an apartment in Paterson, New Jersey.

According to the FBI, Moqed first arrived in the United States on May 2, 2001.

In March 2001, Moqed, Hani Hanjour, Hazmi and Ahmed al-Ghamdi rented a minivan and travelled to Fairfield, Connecticut. There they met a contact in the parking lot of a local convenience store who provided them with false IDs. (This was possibly Eyad Alrababah, a Jordanian charged with document fraud).

Moqed was one of the five hijackers who asked for a state identity card on August 2, 2001. On August 24, both Mihdhar and Moqed tried to purchase flight tickets from the American Airlines online ticket-merchant, but had technical difficulties resolving their address and gave up.

Employees at Advance Travel Service in Totowa, New Jersey later claimed that Moqed and Hanjour had both purchased tickets there. They claimed that Hani Hanjour spoke very little English, and Moqed did most of the speaking. Hanjour requested a seat in the front row of the airplane. Their credit card failed to authorize, and after being told the agency did not accept personal cheques, the pair left to withdraw cash. They returned shortly afterwards and paid $1842.25 total in cash. 
During this time, Moqed was staying in Room 343 of the "Valencia Motel". On September 2, Moqed paid cash for a $30 weekly membership at Gold's Gym in Greenbelt, Maryland.

Three days later he was seen on an ATM camera with Hani Hanjour. After the attacks, employees at an adult video store, "Adult Lingerie Center", in Beltsville claimed that Moqed had been in the store three times, although there were no transactions slips that confirmed this.

On September 11, 2001, Moqed arrived at Washington Dulles International Airport.

According to the 9/11 Commission Report, Moqed set off the metal detector at the airport and was screened with a hand-wand. He passed the cursory inspection, and was able board his flight at 7:50. He was seated in 12A, adjacent to Mihdhar who was in 12B. Moqed helped to hijack the plane and assisted Hani Hanjour in crashing the plane into the Pentagon at 9:37 A.M., killing 189 people (64 on the plane and 125 on the ground).

The flight was scheduled to depart at 08:10, but ended up departing 10 minutes late from Gate D26 at Dulles. The last normal radio communications from the aircraft to air traffic control occurred at 08:50:51. At 08:54, Flight 77 began to deviate from its normal, assigned flight path and turned south, and then hijackers set the flight's autopilot heading for Washington, D.C. Passenger Barbara Olson called her husband, United States Solicitor General Theodore Olson, and reported that the plane had been hijacked and that the assailants had box cutters and knives. At 09:37, American Airlines Flight 77 crashed into the west facade of the Pentagon, killing all 64 aboard (including the hijackers), along with 125 on the ground in the Pentagon. In the recovery process at the Pentagon, remains of all five Flight 77 hijackers were identified through a process of elimination, as not matching any DNA samples for the victims, and put into custody of the FBI.

After the attacks his family told Arab News that Moqed had been a fan of sports, and enjoyed travelling. Additionally, the U.S. announced it had found a "Kingdom of Saudi Arabia Student Identity Card" bearing Moqed's name in the rubble surrounding the Pentagon. They also stated that it appeared to have been a forgery.




</doc>
<doc id="19933" url="https://en.wikipedia.org/wiki?curid=19933" title="Matthew Perry (disambiguation)">
Matthew Perry (disambiguation)

Matthew Perry (born 1969) is a Canadian-American television and film actor.

Matthew Perry or Matt Perry may also refer to:




</doc>
<doc id="19935" url="https://en.wikipedia.org/wiki?curid=19935" title="Mimeograph">
Mimeograph

The stencil duplicator or mimeograph machine (often abbreviated to mimeo) is a low-cost duplicating machine that works by forcing ink through a stencil onto paper. The mimeograph process should not be confused with the spirit duplicator process.

Mimeographs, along with spirit duplicators and hectographs, were a common technology in printing small quantities, as in office work, classroom materials, and church bulletins. Early fanzines were printed with this technology, because it was widespread and cheap. In the late 1960s, mimeographs, spirit duplicators, and hectographs began to be gradually displaced by photocopying.

Use of stencils is an ancient art, butthrough chemistry, papers, and pressestechniques advanced rapidly in the late nineteenth century:

A description of the Papyrograph method of duplication was published by David Owen: 

A major beneficiary of the invention of synthetic dyes was a document reproduction technique known as stencil duplicating. Its earliest form was invented in 1874 by Eugenio de Zuccato, a young Italian studying law in London, who called his device the Papyrograph. Zuccato’s system involved writing on a sheet of varnished paper with caustic ink, which ate through the varnish and paper fibers, leaving holes where the writing had been. This sheet – which had now become a stencil – was placed on a blank sheet of paper, and ink rolled over it so that the ink oozed through the holes, creating a duplicate on the second sheet.

The process was commercialized and Zuccato applied for a patent in 1895 having stencils prepared by typewriting.

Thomas Edison received US patent 180,857 for Autographic Printing on August 8, 1876. The patent covered the electric pen, used for making the stencil, and the flatbed duplicating press. In 1880 Edison obtained a further patent, US 224,665: "Method of Preparing Autographic Stencils for Printing," which covered the making of stencils using a file plate, a grooved metal plate on which the stencil was placed which perforated the stencil when written on with a blunt metal stylus.

The word mimeograph was first used by Albert Blake Dick when he licensed Edison's patents in 1887.

Dick received Trademark Registration no. 0356815 for the term "Mimeograph" in the US Patent Office. It is currently listed as a dead entry, but shows the A.B. Dick Company of Chicago as the owner of the name.

Over time, the term became generic and is now an example of a genericized trademark. ("Roneograph," also "Roneo machine," was another trademark used for mimeograph machines, the name being a contraction of Rotary Neostyle.)

In 1891, David Gestetner patented his Automatic Cyclostyle. This was one of the first rotary machines that retained the flatbed, which passed back and forth under inked rollers. This invention provided for more automated, faster reproductions since the pages were produced and moved by rollers instead of pressing one single sheet at a time.

By 1900, two primary types of mimeographs had come into use: a single-drum machine and a dual-drum machine. The single-drum machine used a single drum for ink transfer to the stencil, and the dual-drum machine used two drums and silk-screens to transfer the ink to the stencils. The single drum (example Roneo) machine could be easily used for multi-color work by changing the drum - each of which contained ink of a different color. This was spot color for mastheads. Colors could not be mixed.

The mimeograph became popular because it was much cheaper than traditional print - there was neither typesetting nor skilled labor involved. One individual with a typewriter and the necessary equipment became their own printing factory, allowing for greater circulation of printed material.

The image transfer medium was originally a stencil made from waxed mulberry paper. Later this became an immersion-coated long-fibre paper, with the coating being a plasticized nitrocellulose. This flexible waxed or coated sheet is backed by a sheet of stiff card stock, with the two sheets bound at the top.

Once prepared, the stencil is wrapped around the ink-filled drum of the rotary machine. When a blank sheet of paper is drawn between the rotating drum and a pressure roller, ink is forced through the holes on the stencil onto the paper. Early flatbed machines used a kind of squeegee.

The ink originally had a lanolin base and later became an oil in water emulsion. This emulsion commonly uses Turkey-Red Oil (Sulfated Castor Oil) which gives it a distinctive and heavy scent.

One uses a regular typewriter, with a stencil setting, to create a stencil. The operator loads a stencil assemblage into the typewriter like paper and uses a switch on the typewriter to put it in stencil mode. In this mode, the part of the mechanism which lifts the ribbon between the type element and the paper is disabled so that the bare, sharp type element strikes the stencil directly. The impact of the type element displaces the coating, making the tissue paper permeable to the oil-based ink. This is called "cutting a stencil".

A variety of specialized styluses were used on the stencil to render lettering, illustrations, or other artistic features by hand against a textured plastic backing plate.

Mistakes were corrected by brushing them out with a specially formulated correction fluid, and retyping once it has dried. ("Obliterine" was a popular brand of correction fluid in Australia and the United Kingdom.)

Stencils were also made with a thermal process, an infrared method similar to that used by early photocopiers. The common machine was a Thermofax. 

Another device, called an electrostencil machine, sometimes was used to make mimeo stencils from a typed or printed original. It worked by scanning the original on a rotating drum with a moving optical head and burning through the blank stencil with an electric spark in the places where the optical head detected ink. It was slow and produced ozone. Text from electrostencils had lower resolution than that from typed stencils, although the process was good for reproducing illustrations. A skilled mimeo operator using an electrostencil and a very coarse halftone screen could make acceptable printed copies of a photograph.

During the declining years of the mimeograph, some people made stencils with early computers and dot-matrix impact printers.

Unlike spirit duplicators (where the only ink available is depleted from the master image), mimeograph technology works by forcing a replenishable supply of ink through the stencil master. In theory, the mimeography process could be continued indefinitely, especially if a durable stencil master were used (e.g. a thin metal foil). In practice, most low-cost mimeo stencils gradually wear out over the course of producing several hundred copies. Typically the stencil deteriorates gradually, producing a characteristic degraded image quality until the stencil tears, abruptly ending the print run. If further copies are desired at this point, another stencil must be made.

Often, the stencil material covering the interiors of closed letterforms (e.g. "a", "b", "d", "e", "g", etc.) would fall away during continued printing, causing ink-filled letters in the copies. The stencil would gradually stretch, starting near the top where the mechanical forces were greatest, causing a characteristic "mid-line sag" in the textual lines of the copies, that would progress until the stencil failed completely. 

The Gestetner Company (and others) devised various methods to make mimeo stencils more durable.

Compared to spirit duplication, mimeography produced a darker, more legible image. Spirit duplicated images were usually tinted a light purple or lavender, which gradually became lighter over the course of some dozens of copies. Mimeography was often considered "the next step up" in quality, capable of producing hundreds of copies. Print runs beyond that level were usually produced by professional printers or, as the technology became available, xerographic copiers.

Mimeographed images generally have much better durability than spirit-duplicated images, since the inks are more resistant to ultraviolet light. The primary preservation challenge is the low-quality paper often used, which would yellow and degrade due to residual acid in the treated pulp from which the paper was made. In the worst case, old copies can crumble into small particles when handled. Mimeographed copies have moderate durability when acid-free paper is used.

Gestetner, Risograph, and other companies still make and sell highly automated mimeograph-like machines that are externally similar to photocopiers. The modern version of a mimeograph, called a digital duplicator, or copyprinter, contains a scanner, a thermal head for stencil cutting, and a large roll of stencil material entirely inside the unit. The stencil material consists of a very thin polymer film laminated to a long-fibre non-woven tissue. It makes the stencils and mounts and unmounts them from the print drum automatically, making it almost as easy to operate as a photocopier. The Risograph is the best known of these machines.

Although mimeographs remain more economical and energy-efficient in mid-range quantities, easier-to-use photocopying and offset printing have replaced mimeography almost entirely in developed countries. Mimeograph machines continue to be used in developing countries because it is a simple, cheap, and robust technology. Many mimeographs can be hand-cranked, requiring no electricity.

Mimeographs and the closely related but distinctly different spirit duplicator process were both used extensively in schools to copy homework assignments and tests. They were also commonly used for low-budget amateur publishing, including club newsletters and church bulletins. They were especially popular with science fiction fans, who used them extensively in the production of fanzines in the middle 20th century, before photocopying became inexpensive.

Letters and typographical symbols were sometimes used to create illustrations, in a precursor to ASCII art. Because changing ink color in a mimeograph could be a laborious process, involving extensively cleaning the machine or, on newer models, replacing the drum or rollers, and then running the paper through the machine a second time, some fanzine publishers experimented with techniques for painting several colors on the pad.




</doc>
<doc id="19937" url="https://en.wikipedia.org/wiki?curid=19937" title="Meteorite">
Meteorite

A meteorite is a solid piece of debris from an object, such as a comet, asteroid, or meteoroid, that originates in outer space and survives its passage through the atmosphere to reach the surface of a planet or moon. When the original object enters the atmosphere, various factors such as friction, pressure, and chemical interactions with the atmospheric gases cause it to heat up and radiate energy. It then becomes a meteor and forms a fireball, also known as a shooting star or falling star; astronomers call the brightest examples "bolides". Once it settles on the larger body's surface, the meteor becomes a meteorite. Meteorites vary greatly in size. For geologists, a bolide is a meteorite large enough to create an impact crater.

Meteorites that are recovered after being observed as they transit the atmosphere and impact the Earth are called meteorite falls. All others are known as meteorite finds. , there were about 1,412 witnessed falls that have specimens in the world's collections. , there are more than 59,200 well-documented meteorite finds.

Meteorites have traditionally been divided into three broad categories: stony meteorites that are rocks, mainly composed of silicate minerals; iron meteorites that are largely composed of metallic iron-nickel; and stony-iron meteorites that contain large amounts of both metallic and rocky material. Modern classification schemes divide meteorites into groups according to their structure, chemical and isotopic composition and mineralogy. Meteorites smaller than 2 mm are classified as micrometeorites. Extraterrestrial meteorites are such objects that have impacted other celestial bodies, whether or not they have passed through an atmosphere. They have been found on the Moon. and Mars.

Meteorites are always named for the places they were found, where practical, usually a nearby town or geographic feature. In cases where many meteorites were found in one place, the name may be followed by a number or letter (e.g., Allan Hills 84001 or Dimmitt (b)). The name designated by the Meteoritical Society is used by scientists, catalogers, and most collectors.

Most meteoroids disintegrate when entering the Earth's atmosphere. Usually, five to ten a year are observed to fall and are subsequently recovered and made known to scientists. Few meteorites are large enough to create large impact craters. Instead, they typically arrive at the surface at their terminal velocity and, at most, create a small pit.

Large meteoroids may strike the earth with a significant fraction of their escape velocity (second cosmic velocity), leaving behind a hypervelocity impact crater. The kind of crater will depend on the size, composition, degree of fragmentation, and incoming angle of the impactor. The force of such collisions has the potential to cause widespread destruction. The most frequent hypervelocity cratering events on the Earth are caused by iron meteoroids, which are most easily able to transit the atmosphere intact. Examples of craters caused by iron meteoroids include Barringer Meteor Crater, Odessa Meteor Crater, Wabar craters, and Wolfe Creek crater; iron meteorites are found in association with all of these craters. In contrast, even relatively large stony or icy bodies like small comets or asteroids, up to millions of tons, are disrupted in the atmosphere, and do not make impact craters. Although such disruption events are uncommon, they can cause a considerable concussion to occur; the famed Tunguska event probably resulted from such an incident. Very large stony objects, hundreds of meters in diameter or more, weighing tens of millions of tons or more, can reach the surface and cause large craters but are very rare. Such events are generally so energetic that the impactor is completely destroyed, leaving no meteorites. (The very first example of a stony meteorite found in association with a large impact crater, the Morokweng crater in South Africa, was reported in May 2006.)

Several phenomena are well documented during witnessed meteorite falls too small to produce hypervelocity craters. The fireball that occurs as the meteoroid passes through the atmosphere can appear to be very bright, rivaling the sun in intensity, although most are far dimmer and may not even be noticed during the daytime. Various colors have been reported, including yellow, green, and red. Flashes and bursts of light can occur as the object breaks up. Explosions, detonations, and rumblings are often heard during meteorite falls, which can be caused by sonic booms as well as shock waves resulting from major fragmentation events. These sounds can be heard over wide areas, with a radius of a hundred or more kilometers. Whistling and hissing sounds are also sometimes heard but are poorly understood. Following the passage of the fireball, it is not unusual for a dust trail to linger in the atmosphere for several minutes.

As meteoroids are heated during atmospheric entry, their surfaces melt and experience ablation. They can be sculpted into various shapes during this process, sometimes resulting in shallow thumbprint-like indentations on their surfaces called regmaglypts. If the meteoroid maintains a fixed orientation for some time, without tumbling, it may develop a conical "nose cone" or "heat shield" shape. As it decelerates, eventually the molten surface layer solidifies into a thin fusion crust, which on most meteorites is black (on some achondrites, the fusion crust may be very light-colored). On stony meteorites, the heat-affected zone is at most a few mm deep; in iron meteorites, which are more thermally conductive, the structure of the metal may be affected by heat up to below the surface. Reports vary; some meteorites are reported to be "burning hot to the touch" upon landing, while others are alleged to have been cold enough to condense water and form a frost.

Meteoroids that experience disruption in the atmosphere may fall as meteorite showers, which can range from only a few up to thousands of separate individuals. The area over which a meteorite shower falls is known as its strewn field. Strewn fields are commonly elliptical in shape, with the major axis parallel to the direction of flight. In most cases, the largest meteorites in a shower are found farthest down-range in the strewn field.

Most meteorites are stony meteorites, classed as chondrites and achondrites. Only about 6% of meteorites are iron meteorites or a blend of rock and metal, the stony-iron meteorites. Modern classification of meteorites is complex. The review paper of Krot et al. (2007) summarizes modern meteorite taxonomy.

About 86% of the meteorites are chondrites, which are named for the small, round particles they contain. These particles, or chondrules, are composed mostly of silicate minerals that appear to have been melted while they were free-floating objects in space. Certain types of chondrites also contain small amounts of organic matter, including amino acids, and presolar grains. Chondrites are typically about 4.55 billion years old and are thought to represent material from the asteroid belt that never coalesced into large bodies. Like comets, chondritic asteroids are some of the oldest and most primitive materials in the solar system. Chondrites are often considered to be "the building blocks of the planets".

About 8% of the meteorites are achondrites (meaning they do not contain chondrules), some of which are similar to terrestrial igneous rocks. Most achondrites are also ancient rocks, and are thought to represent crustal material of differentiated planetesimals. One large family of achondrites (the HED meteorites) may have originated on the parent body of the Vesta Family, although this claim is disputed. Others derive from unidentified asteroids. Two small groups of achondrites are special, as they are younger and do not appear to come from the asteroid belt. One of these groups comes from the Moon, and includes rocks similar to those brought back to Earth by Apollo and Luna programs. The other group is almost certainly from Mars and constitutes the only materials from other planets ever recovered by humans.

About 5% of meteorites that have been seen to fall are iron meteorites composed of iron-nickel alloys, such as kamacite and/or taenite. Most iron meteorites are thought to come from the cores of planetesimals that were once molten. As with the Earth, the denser metal separated from silicate material and sank toward the center of the planetesimal, forming its core. After the planetesimal solidified, it broke up in a collision with another planetesimal. Due to the low abundance of iron meteorites in collection areas such as Antarctica, where most of the meteoric material that has fallen can be recovered, it is possible that the percentage of iron-meteorite falls is lower than 5%. This would be explained by a recovery bias; laypeople are more likely to notice and recover solid masses of metal than most other meteorite types. The abundance of iron meteorites relative to total Antarctic finds is 0.4%.

Stony-iron meteorites constitute the remaining 1%. They are a mixture of iron-nickel metal and silicate minerals. One type, called pallasites, is thought to have originated in the boundary zone above the core regions where iron meteorites originated. The other major type of stony-iron meteorites is the mesosiderites.

Tektites (from Greek "tektos", molten) are not themselves meteorites, but are rather natural glass objects up to a few centimeters in size that were formed—according to most scientists—by the impacts of large meteorites on Earth's surface. A few researchers have favored tektites originating from the Moon as volcanic ejecta, but this theory has lost much of its support over the last few decades.

In March 2015, NASA scientists reported that complex organic compounds found in DNA and RNA, including uracil, cytosine, and thymine, have been formed in the laboratory under outer space conditions, using starting chemicals, such as pyrimidine, found in meteorites. Pyrimidine and polycyclic aromatic hydrocarbons (PAHs) may have been formed in red giants or in interstellar dust and gas clouds, according to the scientists.

In January 2018, researchers found that 4.5 billion-year-old meteorites found on Earth contained liquid water along with prebiotic complex organic substances that may be ingredients for life.

In November 2019, scientists reported detecting Sugar molecules in meteorites for the first time, including ribose, suggesting that chemical processes on asteroids can produce some organic compounds fundamental to life, and supporting the notion of an RNA world prior to a DNA-based origin of life on Earth.

Most meteorite falls are recovered on the basis of eyewitness accounts of the fireball or the impact of the object on the ground, or both. Therefore, despite the fact that meteorites fall with virtually equal probability everywhere on Earth, verified meteorite falls tend to be concentrated in areas with high human population densities such as Europe, Japan, and northern India.

A small number of meteorite falls have been observed with automated cameras and recovered following calculation of the impact point. The first of these was the Přibram meteorite, which fell in Czechoslovakia (now the Czech Republic) in 1959. In this case, two cameras used to photograph meteors captured images of the fireball. The images were used both to determine the location of the stones on the ground and, more significantly, to calculate for the first time an accurate orbit for a recovered meteorite.

Following the Pribram fall, other nations established automated observing programs aimed at studying infalling meteorites. One of these was the "Prairie Network", operated by the Smithsonian Astrophysical Observatory from 1963 to 1975 in the midwestern US. This program also observed a meteorite fall, the "Lost City" chondrite, allowing its recovery and a calculation of its orbit. Another program in Canada, the Meteorite Observation and Recovery Project, ran from 1971 to 1985. It too recovered a single meteorite, "Innisfree", in 1977. Finally, observations by the European Fireball Network, a descendant of the original Czech program that recovered Pribram, led to the discovery and orbit calculations for the "Neuschwanstein" meteorite in 2002.
NASA has an automated system that detects meteors and calculates the orbit, magnitude, ground track, and other parameters over the southeast USA, which often detects a number of events each night.

Until the twentieth century, only a few hundred meteorite finds had ever been discovered. More than 80% of these were iron and stony-iron meteorites, which are easily distinguished from local rocks. To this day, few stony meteorites are reported each year that can be considered to be "accidental" finds. The reason there are now more than 30,000 meteorite finds in the world's collections started with the discovery by Harvey H. Nininger that meteorites are much more common on the surface of the Earth than was previously thought.

Nininger's strategy was to search for meteorites in the Great Plains of the United States, where the land was largely cultivated and the soil contained few rocks. Between the late 1920s and the 1950s, he traveled across the region, educating local people about what meteorites looked like and what to do if they thought they had found one, for example, in the course of clearing a field. The result was the discovery of over 200 new meteorites, mostly stony types.

In the late 1960s, Roosevelt County, New Mexico in the Great Plains was found to be a particularly good place to find meteorites. After the discovery of a few meteorites in 1967, a public awareness campaign resulted in the finding of nearly 100 new specimens in the next few years, with many being by a single person, Ivan Wilson. In total, nearly 140 meteorites were found in the region since 1967. In the area of the finds, the ground was originally covered by a shallow, loose soil sitting atop a hardpan layer. During the dustbowl era, the loose soil was blown off, leaving any rocks and meteorites that were present stranded on the exposed surface.

A few meteorites were found in Antarctica between 1912 and 1964. In 1969, the 10th Japanese Antarctic Research Expedition found nine meteorites on a blue ice field near the Yamato Mountains. With this discovery, came the realization that movement of ice sheets might act to concentrate meteorites in certain areas. After a dozen other specimens were found in the same place in 1973, a Japanese expedition was launched in 1974 dedicated to the search for meteorites. This team recovered nearly 700 meteorites.

Shortly thereafter, the United States began its own program to search for Antarctic meteorites, operating along the Transantarctic Mountains on the other side of the continent: the Antarctic Search for Meteorites (ANSMET) program. European teams, starting with a consortium called "EUROMET" in the 1990/91 season, and continuing with a program by the Italian Programma Nazionale di Ricerche in Antartide have also conducted systematic searches for Antarctic meteorites.

The Antarctic Scientific Exploration of China has conducted successful meteorite searches since 2000. A Korean program (KOREAMET) was launched in 2007 and has collected a few meteorites. The combined efforts of all of these expeditions have produced more than 23,000 classified meteorite specimens since 1974, with thousands more that have not yet been classified. For more information see the article by Harvey (2003).

At about the same time as meteorite concentrations were being discovered in the cold desert of Antarctica, collectors discovered that many meteorites could also be found in the hot deserts of Australia. Several dozen meteorites had already been found in the Nullarbor region of Western and South Australia. Systematic searches between about 1971 and the present recovered more than 500 others, ~300 of which are currently well characterized. The meteorites can be found in this region because the land presents a flat, featureless, plain covered by limestone. In the extremely arid climate, there has been relatively little weathering or sedimentation on the surface for tens of thousands of years, allowing meteorites to accumulate without being buried or destroyed. The dark colored meteorites can then be recognized among the very different looking limestone pebbles and rocks.

In 1986–87, a German team installing a network of seismic stations while prospecting for oil discovered about 65 meteorites on a flat, desert plain about southeast of Dirj (Daraj), Libya. A few years later, a desert enthusiast saw photographs of meteorites being recovered by scientists in Antarctica, and thought that he had seen similar occurrences in northern Africa. In 1989, he recovered about 100 meteorites from several distinct locations in Libya and Algeria. Over the next several years, he and others who followed found at least 400 more meteorites. The find locations were generally in regions known as regs or hamadas: flat, featureless areas covered only by small pebbles and minor amounts of sand. Dark-colored meteorites can be easily spotted in these places. In the case of several meteorite fields, such as Dar al Gani, Dhofar, and others, favorable light-colored geology consisting of basic rocks (clays, dolomites, and limestones) makes meteorites particularly easy to identify.

Although meteorites had been sold commercially and collected by hobbyists for many decades, up to the time of the Saharan finds of the late 1980s and early 1990s, most meteorites were deposited in or purchased by museums and similar institutions where they were exhibited and made available for scientific research. The sudden availability of large numbers of meteorites that could be found with relative ease in places that were readily accessible (especially compared to Antarctica), led to a rapid rise in commercial collection of meteorites. This process was accelerated when, in 1997, meteorites coming from both the Moon and Mars were found in Libya. By the late 1990s, private meteorite-collecting expeditions had been launched throughout the Sahara. Specimens of the meteorites recovered in this way are still deposited in research collections, but most of the material is sold to private collectors. These expeditions have now brought the total number of well-described meteorites found in Algeria and Libya to more than 500.

Meteorite markets came into existence in the late 1990s, especially in Morocco. This trade was driven by Western commercialization and an increasing number of collectors. The meteorites were supplied by nomads and local people who combed the deserts looking for specimens to sell. Many thousands of meteorites have been distributed in this way, most of which lack any information about how, when, or where they were discovered. These are the so-called "Northwest Africa" meteorites. When they get classified, they are named "Northwest Africa" (abbreviated NWA) followed by a number. It is generally accepted that NWA meteorites originate in Morocco, Algeria, Western Sahara, Mali, and possibly even further afield. Nearly all of these meteorites leave Africa through Morocco. Scores of important meteorites, including Lunar and Martian ones, have been discovered and made available to science via this route. A few of the more notable meteorites recovered include Tissint and Northwest Africa 7034. Tissint was the first witnessed Martian meteorite fall in over fifty years; NWA 7034 is the oldest meteorite known to come from Mars, and is a unique water-bearing regolith breccia.

In 1999, meteorite hunters discovered that the desert in southern and central Oman were also favorable for the collection of many specimens. The gravel plains in the Dhofar and Al Wusta regions of Oman, south of the sandy deserts of the Rub' al Khali, had yielded about 5,000 meteorites as of mid-2009. Included among these are a large number of lunar and Martian meteorites, making Oman a particularly important area both for scientists and collectors. Early expeditions to Oman were mainly done by commercial meteorite dealers, however international teams of Omani and European scientists have also now collected specimens.

The recovery of meteorites from Oman is currently prohibited by national law, but a number of international hunters continue to remove specimens now deemed national treasures. This new law provoked a small international incident, as its implementation preceded any public notification of such a law, resulting in the prolonged imprisonment of a large group of meteorite hunters, primarily from Russia, but whose party also consisted of members from the US as well as several other European countries.

Beginning in the mid-1960s, amateur meteorite hunters began scouring the arid areas of the southwestern United States. To date, thousands of meteorites have been recovered from the Mojave, Sonoran, Great Basin, and Chihuahuan Deserts, with many being recovered on dry lake beds. Significant finds include the three tonne Old Woman meteorite, currently on display at the Desert Discovery Center in Barstow, California, and the Franconia and Gold Basin meteorite strewn fields; hundreds of kilograms of meteorites have been recovered from each.
A number of finds from the American Southwest have been submitted with false find locations, as many finders think it is unwise to publicly share that information for fear of confiscation by the federal government and competition with other hunters at published find sites. 
Several of the meteorites found recently are currently on display in the Griffith Observatory in Los Angeles, and at UCLA's Meteorite Gallery.

Meteorite falls may have been the source of cultish worship. The cult in the Temple of Artemis at Ephesus, one of the Seven Wonders of the Ancient World, possibly originated with the observation and recovery of a meteorite that was understood by contemporaries to have fallen to the earth from Jupiter, the principal Roman deity.
There are reports that a sacred stone was enshrined at the temple that may have been a meteorite. The Black Stone set into the wall of the Kaaba has often been presumed to be a meteorite, but the little available evidence for this is inconclusive. Although the use of the metal found in meteorites is also recorded in myths of many countries and cultures where the celestial source was often acknowledged, scientific documentation only began in the last few centuries.

The oldest known iron artifacts are nine small beads hammered from meteoritic iron. They were found in northern Egypt and have been securely dated to 3200 BC.

In the 1970s, a stone meteorite was uncovered during an archaeological dig at Danebury Iron Age hillfort, Danebury England. It was found deposited part way down in an Iron Age pit (c. 1200 BC). Since it must have been deliberately placed there, this could indicate one of the first (known) human finds of a meteorite in Europe.

Some Native Americans treated meteorites as ceremonial objects. In 1915, a iron meteorite was found in a Sinagua (c. 1100–1200 AD) burial cyst near Camp Verde, Arizona, respectfully wrapped in a feather cloth. A small pallasite was found in a pottery jar in an old burial found at Pojoaque Pueblo, New Mexico. Nininger reports several other such instances, in the Southwest US and elsewhere, such as the discovery of Native American beads of meteoric iron found in Hopewell burial mounds, and the discovery of the Winona meteorite in a Native American stone-walled crypt.
Indigenous peoples often prized iron-nickel meteorites as an easy, if limited, source of iron metal. For example, the Inuit used chips of the Cape York meteorite to form cutting edges for tools and spear tips.

Two of the oldest recorded meteorite falls in Europe are the Elbogen (1400) and Ensisheim (1492) meteorites. The German physicist, Ernst Florens Chladni, was the first to publish (in 1794) the idea that meteorites might be rocks that originated not from Earth, but from space. His booklet was ""On the Origin of the Iron Masses Found by Pallas and Others Similar to it, and on Some Associated Natural Phenomena"". In this he compiled all available data on several meteorite finds and falls concluded that they must have their origins in outer space. The scientific community of the time responded with resistance and mockery. It took nearly ten years before a general acceptance of the origin of meteorites was achieved through the work of the French scientist Jean-Baptiste Biot and the British chemist, Edward Howard. Biot's study, initiated by the French Academy of Sciences, was compelled by a fall of thousands of meteorites on 26 April 1803 from the skies of L'Aigle, France.

One of the leading theories for the cause of the Cretaceous–Paleogene extinction event that included the dinosaurs is a large meteorite impact. The Chicxulub Crater has been identified as the site of this impact. There has been a lively scientific debate as to whether other major extinctions, including the ones at the end of the Permian and Triassic periods might also have been the result of large impact events, but the evidence is much less compelling than for the end Cretaceous extinction.

Throughout history, many first- and second-hand reports speak of meteorites killing humans and other animals. One example is from 1490 AD in China, which purportedly killed thousands of people. In 1888, a meteorite reportedly killed a man and left another paralyzed in Sulaymaniyah, Iraq, according to the Ottoman Empire governor, Sultan Abdul Hamid II. John Lewis has compiled some of these reports, and summarizes, "No one in recorded history has ever been killed by a meteorite in the presence of a meteoriticist and a medical doctor" and "reviewers who make sweeping negative conclusions usually do not cite any of the primary publications in which the eyewitnesses describe their experiences, and give no evidence of having read them".

The most well-known reported fatality from a meteorite impact is that of a dog killed by the fall of the Nakhla meteorite in Egypt, in 1911. This meteorite was identified in the 1980s as Martian in origin. A meteorite known as Valera reportedly hit and killed a cow upon impact, but the incident was not reported for several decades and no evidence was preserved. There are similar unsubstantiated reports of a horse being struck and killed by a stone from the New Concord strike. Shortly after the 2007 Carancas impact event, there were rumors of a goat and a llama being killed by the impact.

The first known modern case of a human hit by a space rock occurred on 30 November 1954 in Sylacauga, Alabama. A stone chondrite crashed through a roof and hit Ann Hodges in her living room after it bounced off her radio. She was badly bruised. The Hodges meteorite, or Sylacauga meteorite, is currently on exhibit at the Alabama Museum of Natural History.

Another claim was put forth by a young boy who stated that he had been hit by a small (~3-gram) stone of the Mbale meteorite fall from Uganda, and who stood to gain nothing from this assertion. The stone reportedly fell through banana leaves before striking the boy on the head, causing little to no pain, as it was small enough to have been slowed by both friction with the atmosphere as well as that with banana leaves, before striking the boy.

Several persons have since claimed to have been struck by "meteorites" but no verifiable meteorites have resulted.

Most meteorites date from the oldest times in the solar system and are by far the oldest material available on the planet. Despite their age, they are fairly vulnerable to terrestrial environment: water, salt, and oxygen attack the meteorites as soon they reach the ground.

The terrestrial alteration of meteorites is called weathering. In order to quantify the degree of alteration that a meteorite experienced, several qualitative weathering indices have been applied to Antarctic and desertic samples.

The most known weathering scale, used for ordinary chondrites, ranges from W0 (pristine state) to W6 (heavy alteration).

"Fossil" meteorites are sometimes discovered by geologists. They represent the deeply weathered remains of meteorites that fell to Earth in the remote past and were preserved in sedimentary deposits sufficiently well that they can be recognized through mineralogical and geochemical studies. One limestone quarry in Sweden has produced an anomalously large number (more than a hundred) fossil meteorites from the Ordovician, nearly all of which are deeply weathered L-chondrites that still resemble the original meteorite under a petrographic microscope, but which have had their original material almost entirely replaced by terrestrial secondary mineralization. The extraterrestrial provenance was demonstrated in part through isotopic analysis of relict spinel grains, a mineral that is common in meteorites, is insoluble in water, and is able to persist chemically unchanged in the terrestrial weathering environment. One of these fossil meteorites, dubbed Österplana 065, appears to represent a distinct type of meteorite that is "extinct" in the sense that it is no longer falling to Earth, the parent body having already been completely depleted from reservoir of Near Earth Objects.

Acfer 049, a meteorite discovered in Algeria in 1990, was shown in 2019 to have ice fossils inside it – the first direct evidence of water ice in the composition of asteroids.


Apart from meteorites fallen onto the Earth, two tiny fragments of asteroids were found among the samples collected on the Moon; these were the Bench Crater meteorite (Apollo 12, 1969) and the Hadley Rille meteorite (Apollo 15, 1971).




</doc>
<doc id="19938" url="https://en.wikipedia.org/wiki?curid=19938" title="Mega-">
Mega-

Mega is a unit prefix in metric systems of units denoting a factor of one million (10 or ). It has the unit symbol M. It was confirmed for use in the International System of Units (SI) in 1960. "Mega" comes from .


When units occur in exponentiation, such as in square and cubic forms, any multiples-prefix is considered part of the unit, and thus included in the exponentiation.

In some fields of computing, "mega" may sometimes denote 1,048,576 (2) of information units, for example, a megabyte, a megaword, but denotes (10) units of other quantities, for example, transfer rates: = . The prefix "mebi-" has been suggested as a prefix for 2 to avoid ambiguity.




</doc>
<doc id="19940" url="https://en.wikipedia.org/wiki?curid=19940" title="Maciej Płażyński">
Maciej Płażyński

Maciej Płażyński (; 10 February 1958 – 10 April 2010) was a Polish liberal-conservative politician.

Płażyński was born in Młynary. He began his political career in 1980 / 1981 as one of the leaders of the Students' Solidarity; he was governor of the Gdańsk Voivodship from August 1990 to July 1996, and was elected to the Sejm (the lower house of the Polish parliament) in September 1997. To date he is longest serving Marshal of the Sejm of the Third Republic of Poland

In January 2001, he founded the Civic Platform political party with Donald Tusk and Andrzej Olechowski. He left Civic Platform for personal reasons and at the time of his death was an independent MP. He was member of Kashubian-Pomeranian Association. He was later chosen as a chairman of the Association "Polish Community".

Maciej Płażyński was married to Elżbieta Płażyńska and together they had three children: Jakub, Katarzyna, and Kacper.

He was listed on the flight manifest of the Tupolev Tu-154 of the 36th Special Aviation Regiment carrying the President of Poland Lech Kaczyński which crashed while landing at Smolensk-North airport near Pechersk near Smolensk, Russia, on 10 April 2010, killing all aboard.

In 2000, Płażyński was awarded the Order of Merit of the Italian Republic, First Class. He received the titles of honorary citizen of Młynary, Puck, Pionki and Lidzbark Warmiński.

On 16 April 2010 he was posthumously awarded the Grand Cross of the Order of Polonia Restituta. He was also awarded a Gold Medal of Gloria Artis.




</doc>
<doc id="19941" url="https://en.wikipedia.org/wiki?curid=19941" title="Mark Bingham">
Mark Bingham

Mark Kendall Bingham (May 22, 1970 – September 11, 2001) was an American public relations executive who founded his own company, the Bingham Group. During the September 11 attacks in 2001, he was a passenger on board United Airlines Flight 93. Bingham was among the passengers who, along with Todd Beamer, Tom Burnett and Jeremy Glick, formed the plan to retake the plane from the hijackers, and led the effort that resulted in the crash of the plane into a field near Shanksville, Pennsylvania, thwarting the hijackers' plan to crash the plane into a building in Washington, D.C., most likely either the U.S. Capitol Building or the White House.

Both for his presence on United 93, as well as his athletic physique, Bingham has been widely honored posthumously for having "smashed the gay stereotype mold and really opened the door to many others who came after him."

Mark Bingham was born in 1970, the only child of Alice Hoagland and Gerald Bingham. When Mark was two years old, his parents divorced. Raised by his mother and her family, Mark grew up in Miami, Florida, and Southern California before moving to the San Jose area in 1983. Bingham was an aspiring filmmaker, and as a teenager he began using a video camera as a personal diary to document his life and those of his family and friends. He graduated from Los Gatos High School as a two-year captain of his rugby team in 1988. As an undergraduate at the University of California, Berkeley, Bingham played on two of Coach Jack Clark's national-championship-winning rugby teams in the early 1990s. He also joined the Chi Psi fraternity, eventually becoming its president. Upon graduation at the age of twenty-one, Bingham came out as gay to his family and friends.

A large athlete at and , Bingham also played for the gay-inclusive rugby union team San Francisco Fog RFC. Bingham played No. 8 in their first two friendly matches. He played in their first tournament, and taught his teammates his favorite rugby songs.

Bingham had recently opened a satellite office of his public relations firm in New York City and was spending more time on the East Coast. He discussed plans with his friend Scott Glaessgen to form a New York City rugby team, the Gotham Knights.

On the morning of September 11, Bingham overslept and nearly missed his flight, on his way to San Francisco to be an usher in his fraternity brother Joseph Salama's wedding. He arrived at the Terminal A at 7:40am, ran to Gate 17, and was the last passenger to board United Airlines Flight 93, taking seat 4D, next to passenger Tom Burnett.

United Flight 93 was scheduled to depart at 8:00am, but the Boeing 757 did not depart until 42 minutes later due to runway traffic delays. Four minutes later, American Airlines Flight 11 crashed into the World Trade Center's North Tower. Fifteen minutes later, at 9:03 am, as United Flight 175 crashed into the South Tower, United 93 was climbing to cruising altitude, heading west over New Jersey and into Pennsylvania. At 9:25 am, Flight 93 was above eastern Ohio, and pilots Jason Dahl and LeRoy Homer received an alert, "beware of cockpit intrusion," on the cockpit computer device ACARS (Aircraft Communications and Reporting System). Three minutes later, Cleveland controllers could hear screams over the cockpit's open microphone. Moments later, the hijackers, led by the Lebanese Ziad Samir Jarrah, took over the plane's controls and told passengers, "Keep remaining sitting. We have a bomb on board". Bingham and the other passengers were herded into the back of the plane. Within six minutes, the plane changed course and was heading for Washington, D.C. Several of the passengers made phone calls to loved ones, who informed them about the two planes that had crashed into the World Trade Center.

After the hijackers veered the plane sharply south, the passengers decided to act. Bingham, along with Todd Beamer, Tom Burnett and Jeremy Glick, formed a plan to take the plane back from the hijackers. They relayed this to their loved ones and the authorities via telephone. Bingham got through to his aunt's home in California. Bingham stated, "This is Mark. I want to let you guys know that I love you, in case I don't see you again...I'm on United Airlines, Flight 93. It's being hijacked." According to "The Week", Hoagland formed the impression that her son was talking "confidentially" with a fellow passenger, to form a plan to retake the plane. According to ABC News, the call was cut off after about three minutes. Hoagland, after seeing news reports of the plane's hijacking, called him back and left two messages for him, calmly saying, "Mark, this is your mom. The news is that it's been hijacked by terrorists. They are planning to probably use the plane as a target to hit some site on the ground. I would say go ahead and do everything you can to overpower them, because they are hellbent. Try to call me back if you can." Bingham, Burnett, and Glick were each more than 6 feet tall, well-built and fit. As they made their decision to retake the plane, Glick related this over the phone to his wife, Lyz. Fellow passenger Todd Beamer, speaking to GTE-Verizon Lisa Jefferson and the FBI, related that he too was part of this group. They were joined by other passengers, including Lou Nacke, Rich Guadagno, Alan Beaven, Honor Elizabeth Wainio, Linda Gronlund, and William Cashman, along with flight attendants Sandra Bradshaw and Cee Cee Ross-Lyles, in discussing their options and voting on a course of action, ultimately deciding to storm the cockpit and take over the plane.

According to the "9/11 Commission Report", after the plane's voice data recorder was recovered, it revealed pounding and crashing sounds against the cockpit door and shouts and screams in English. "Let's get them!" a passenger cries. A hijacker shouts, "Allah akbar!" ("God is great"). Jarrah repeatedly pitched the plane to knock passengers off their feet, but the passengers apparently managed to invade the cockpit, where one was heard shouting, "In the cockpit. If we don't, we'll die." At 10:02 am, a hijacker ordered, "Pull it down! Pull it down!" The 9/11 Commission later reported that the plane's control wheel was turned hard to the right, causing it to roll on its back and plow into an empty field in Shanksville, Pennsylvania at 580 miles an hour, killing everyone on board. The plane was twenty minutes of flying time away from its suspected target, the White House or the U.S. Capitol Building in Washington, D.C. According to Vice President Dick Cheney, President George W. Bush had given the order to shoot the plane down.

Bingham is survived by his parents and the Hoagland family members who played a part in his upbringing, by his stepmother and various stepsiblings, and by his former partner of six years, Paul Holm. Holm described Bingham as a brave, competitive man, saying, "He hated to lose—at anything." He was known to proudly display a scar he received after being gored at the Running of the Bulls in Pamplona, Spain. He is buried at Madronia Cemetery, Saratoga, California.
U.S. Senators John McCain and Barbara Boxer honored Bingham on September 17, 2001, in a ceremony for San Francisco Bay Area victims of the attacks, presenting a folded American flag to Paul Holm.

The Mark Kendall Bingham Memorial Tournament (referred to as the Bingham Cup), a biennial international rugby union competition predominantly for gay and bisexual men, was established in 2002 in his memory.

Bingham, along with the other passengers on Flight 93, was posthumously awarded the Arthur Ashe Courage Award in 2002.

The Eureka Valley Recreation Center's Gymnasium in San Francisco was renamed the Mark Bingham Gymnasium in August 2002.

Singer Melissa Etheridge dedicated the song "Tuesday Morning" in 2004 to his memory.

Beginning in 2005, the Mark Bingham Award for Excellence in Achievement has been awarded by the California Alumni Association of the University of California, Berkeley to a young alumnus or alumna at its annual Charter Gala.

At the National 9/11 Memorial, Bingham and other passengers from Flight 93 are memorialized at the South Pool, on Panel S-67.

At the Flight 93 National Memorial in Pennsylvania, Bingham's name is located on one of the 40 8-foot-tall panels of polished, 3-inch thick granite that comprise the Memorial's Wall of Names.

The 2013 feature-length documentary "The Rugby Player" focuses on Bingham and the bond he had with his mother, Alice Hoagland, a former United Airlines flight attendant who, following his death, became an authority on airline safety and a champion of LGBT rights. Directed by Scott Gracheff, the film relies on the vast amount of video footage Bingham himself shot beginning in his teens until weeks before his death. The film's alternate title, "With You", is a popular rugby term, and one of Bingham's favorite expressions.




</doc>
<doc id="19942" url="https://en.wikipedia.org/wiki?curid=19942" title="Manner of articulation">
Manner of articulation

In articulatory phonetics, the manner of articulation is the configuration and interaction of the articulators (speech organs such as the tongue, lips, and palate) when making a speech sound. One parameter of manner is "stricture," that is, how closely the speech organs approach one another. Others include those involved in the r-like sounds (taps and trills), and the sibilancy of fricatives.

The concept of manner is mainly used in the discussion of consonants, although the movement of the articulators will also greatly alter the resonant properties of the vocal tract, thereby changing the formant structure of speech sounds that is crucial for the identification of vowels. For consonants, the place of articulation and the degree of phonation of voicing are considered separately from manner, as being independent parameters. Homorganic consonants, which have the same place of articulation, may have different manners of articulation. Often nasality and laterality are included in manner, but some phoneticians, such as Peter Ladefoged, consider them to be independent.

Manners of articulation with substantial obstruction of the airflow (stops, fricatives, affricates) are called obstruents. These are prototypically voiceless, but voiced obstruents are extremely common as well. Manners without such obstruction (nasals, liquids, approximants, and also vowels) are called sonorants because they are nearly always voiced. Voiceless sonorants are uncommon, but are found in Welsh and Classical Greek (the spelling "rh"), in Standard Tibetan (the "lh" of Lhasa), and the "wh" in those dialects of English that distinguish "which" from "witch".

Sonorants may also be called resonants, and some linguists prefer that term, restricting the word 'sonorant' to non-vocoid resonants (that is, nasals and liquids, but not vowels or semi-vowels). Another common distinction is between occlusives (stops, nasals and affricates) and continuants (all else).

From greatest to least stricture, speech sounds may be classified along a cline as stop consonants (with "occlusion", or blocked airflow), fricative consonants (with partially blocked and therefore strongly turbulent airflow), approximants (with only slight turbulence), and vowels (with full unimpeded airflow). Affricates often behave as if they were intermediate between stops and fricatives, but phonetically they are sequences of a stop and fricative.

Over time, sounds in a language may move along the cline toward less stricture in a process called lenition or towards more stricture in a process called fortition.

Sibilants are distinguished from other fricatives by the shape of the tongue and how the airflow is directed over the teeth. Fricatives at coronal places of articulation may be sibilant or non-sibilant, sibilants being the more common.

Flaps (also called taps) are similar to very brief stops. However, their articulation and behavior are distinct enough to be considered a separate manner, rather than just length. The main articulatory difference between flaps and stops is that, due to the greater length of stops compared to flaps, a build-up of air pressure occurs behind a stop which does not occur behind a flap. This means that when the stop is released, there is a burst of air as the pressure is relieved, while for flaps there is no such burst.

Trills involve the vibration of one of the speech organs. Since trilling is a separate parameter from stricture, the two may be combined. Increasing the stricture of a typical trill results in a trilled fricative. Trilled affricates are also known.

Nasal airflow may be added as an independent parameter to any speech sound. It is most commonly found in nasal occlusives and nasal vowels, but nasalized fricatives, taps, and approximants are also found. When a sound is not nasal, it is called "oral."

Laterality is the release of airflow at the side of the tongue. This can be combined with other manners, resulting in lateral approximants (such as the pronunciation of the letter L in the English word "let"), lateral flaps, and lateral fricatives and affricates.


All of these manners of articulation are pronounced with an airstream mechanism called pulmonic egressive, meaning that the air flows outward, and is powered by the lungs (actually the ribs and diaphragm). Other airstream mechanisms are possible. Sounds that rely on some of these include:





</doc>
<doc id="19943" url="https://en.wikipedia.org/wiki?curid=19943" title="Mostaganem Province">
Mostaganem Province

Mostaganem () is a province ("wilaya") of Algeria. The capital is Mostaganem. Other localities include Ain Nouissi, Ain Tadles, Tazgait, Mezghrane, and Stidia.

The province is divided into 10 districts ("daïras"), which are further divided into 32 "communes" or municipalities.



</doc>
<doc id="19945" url="https://en.wikipedia.org/wiki?curid=19945" title="Motherboard">
Motherboard

A motherboard (also called mainboard, main circuit board, system board, baseboard, planar board, logic board, and mobo) is the main printed circuit board (PCB) in general-purpose computers and other expandable systems. It holds and allows communication between many of the crucial electronic components of a system, such as the central processing unit (CPU) and memory, and provides connectors for other peripherals. Unlike a backplane, a motherboard usually contains significant sub-systems, such as the central processor, the chipset's input/output and memory controllers, interface connectors, and other components integrated for general use.

"Motherboard" means specifically a PCB with expansion capabilities. As the name suggests, this board is often referred to as the "mother" of all components attached to it, which often include peripherals, interface cards, and daughtercards: sound cards, video cards, network cards, hard drives, and other forms of persistent storage; TV tuner cards, cards providing extra USB or FireWire slots; and a variety of other custom components.

Similarly, the term "mainboard" describes a device with a single board and no additional expansions or capability, such as controlling boards in laser printers, television sets, washing machines, mobile phones, and other embedded systems with limited expansion abilities.

The term "Logic board" is brand specific, coined by Apple in the early 1980s for the motherboards in Macintosh computers.

Prior to the invention of the microprocessor, the digital computer consisted of multiple printed circuit boards in a card-cage case with components connected by a backplane, a set of interconnected sockets. In very old designs, copper wires were the discrete connections between card connector pins, but printed circuit boards soon became the standard practice. The central processing unit (CPU), memory, and peripherals were housed on individual printed circuit boards, which were plugged into the backplane. The ubiquitous S-100 bus of the 1970s is an example of this type of backplane system.

The most popular computers of the 1990s such as the Apple II and IBM PC had published schematic diagrams and other documentation which permitted rapid reverse-engineering and third-party replacement motherboards. Usually intended for building new computers compatible with the exemplars, many motherboards offered additional performance or other features and were used to upgrade the manufacturer's original equipment.

During the late 1980s and early 1990s, it became economical to move an increasing number of peripheral functions onto the motherboard. In the late 1980s, personal computer motherboards began to include single ICs (also called Super I/O chips) capable of supporting a set of low-speed peripherals: keyboard, mouse, floppy disk drive, serial ports, and parallel ports. By the late 1970s, many personal computer motherboards included consumer-grade embedded audio, video, storage, and networking functions without the need for any expansion cards at all; higher-end systems for 4D gaming and computer graphics typically retained only the graphics card as a separate component. Business PCs, workstations, and servers were more likely to need expansion cards, either for more robust functions, or for higher speeds; those systems often had fewer embedded components.

Laptop and notebook computers that were developed in the 1990s integrated the most common peripherals. This even included motherboards with no upgradeable components, a trend that would continue as smaller systems were introduced after the turn of the century (like the tablet computer and the netbook). Memory, processors, network controllers, power source, and storage would be integrated into some systems.

A motherboard provides the electrical connections by which the other components of the system communicate. Unlike a backplane, it also contains the central processing unit and hosts other subsystems and devices.

A typical desktop computer has its microprocessor, main memory, and other essential components connected to the motherboard. Other components such as external storage, controllers for video display and sound, and peripheral devices may be attached to the motherboard as plug-in cards or via cables; in modern microcomputers it is increasingly common to integrate some of these peripherals into the motherboard itself.

An important component of a motherboard is the microprocessor's supporting chipset, which provides the supporting interfaces between the CPU and the various buses and external components. This chipset determines, to an extent, the features and capabilities of the motherboard.

Modern motherboards include:

Additionally, nearly all motherboards include logic and connectors to support commonly used input devices, such as USB for mouse devices and keyboards. Early personal computers such as the Apple II or IBM PC included only this minimal peripheral support on the motherboard. Occasionally video interface hardware was also integrated into the motherboard; for example, on the Apple II and rarely on IBM-compatible computers such as the IBM PC Jr. Additional peripherals such as disk controllers and serial ports were provided as expansion cards.

Given the high thermal design power of high-speed computer CPUs and components, modern motherboards nearly always include heat sinks and mounting points for fans to dissipate excess heat.

Motherboards are produced in a variety of sizes and shape called computer form factor, some of which are specific to individual computer manufacturers. However, the motherboards used in IBM-compatible systems are designed to fit various case sizes. , most desktop computer motherboards use the ATX standard form factor — even those found in Macintosh and Sun computers, which have not been built from commodity components. A case's motherboard and power supply unit (PSU) form factor must all match, though some smaller form factor motherboards of the same family will fit larger cases. For example, an ATX case will usually accommodate a microATX motherboard. Computers generally use highly integrated, miniaturized and customized motherboards. This is one of the reasons that laptop computers are difficult to upgrade and expensive to repair. Often the failure of one laptop component requires the replacement of the entire motherboard, which is usually more expensive than a desktop motherboard

A CPU socket (central processing unit) or slot is an electrical component that attaches to a Printed Circuit Board (PCB) and is designed to house a CPU (also called a microprocessor). It is a special type of integrated circuit socket designed for very high pin counts. A CPU socket provides many functions, including a physical structure to support the CPU, support for a heat sink, facilitating replacement (as well as reducing cost), and most importantly, forming an electrical interface both with the CPU and the PCB. CPU sockets on the motherboard can most often be found in most desktop and server computers (laptops typically use surface mount CPUs), particularly those based on the Intel x86 architecture. A CPU socket type and motherboard chipset must support the CPU series and speed.

With the steadily declining costs and size of integrated circuits, it is now possible to include support for many peripherals on the motherboard. By combining many functions on one PCB, the physical size and total cost of the system may be reduced; highly integrated motherboards are thus especially popular in small form factor and budget computers.

A typical motherboard will have a different number of connections depending on its standard and form factor.

A standard, modern ATX motherboard will typically have two or three PCI-Express 16x connection for a graphics card, one or two legacy PCI slots for various expansion cards, and one or two PCI-E 1x (which has superseded PCI). A standard EATX motherboard will have two to four PCI-E 16x connection for graphics cards, and a varying number of PCI and PCI-E 1x slots. It can sometimes also have a PCI-E 4x slot (will vary between brands and models).

Some motherboards have two or more PCI-E 16x slots, to allow more than 2 monitors without special hardware, or use a special graphics technology called SLI (for Nvidia) and Crossfire (for AMD). These allow 2 to 4 graphics cards to be linked together, to allow better performance in intensive graphical computing tasks, such as gaming, video editing, etc.

Motherboards are generally air cooled with heat sinks often mounted on larger chips in modern motherboards. Insufficient or improper cooling can cause damage to the internal components of the computer, or cause it to crash. Passive cooling, or a single fan mounted on the power supply, was sufficient for many desktop computer CPU's until the late 1990s; since then, most have required CPU fans mounted on their heat sinks, due to rising clock speeds and power consumption. Most motherboards have connectors for additional computer fans and integrated temperature sensors to detect motherboard and CPU temperatures and controllable fan connectors which the BIOS or operating system can use to regulate fan speed. Alternatively computers can use a water cooling system instead of many fans.

Some small form factor computers and home theater PCs designed for quiet and energy-efficient operation boast fan-less designs. This typically requires the use of a low-power CPU, as well as a careful layout of the motherboard and other components to allow for heat sink placement.

A 2003 study found that some spurious computer crashes and general reliability issues, ranging from screen image distortions to I/O read/write errors, can be attributed not to software or peripheral hardware but to aging capacitors on PC motherboards. Ultimately this was shown to be the result of a faulty electrolyte formulation, an issue termed capacitor plague.

Standard motherboards use electrolytic capacitors to filter the DC power distributed around the board. These capacitors age at a temperature-dependent rate, as their water based electrolytes slowly evaporate. This can lead to loss of capacitance and subsequent motherboard malfunctions due to voltage instabilities. While most capacitors are rated for 2000 hours of operation at , their expected design life roughly doubles for every below this. At a lifetime of 3 to 4 years can be expected. However, many manufacturers deliver substandard capacitors, which significantly reduce life expectancy. Inadequate case cooling and elevated temperatures around the CPU socket exacerbate this problem. With top blowers, the motherboard components can be kept under , effectively doubling the motherboard lifetime.

Mid-range and high-end motherboards, on the other hand, use solid capacitors exclusively. For every 10 °C less, their average lifespan is multiplied approximately by three, resulting in a 6-times higher lifetime expectancy at . These capacitors may be rated for 5000, 10000 or 12000 hours of operation at , extending the projected lifetime in comparison with standard solid capacitors.

Motherboards contain some non-volatile memory to initialize the system and load some startup software, usually an operating system, from some external peripheral device. Microcomputers such as the Apple II and IBM PC used ROM chips mounted in sockets on the motherboard. At power-up, the central processor would load its program counter with the address of the boot ROM and start executing instructions from the ROM. These instructions initialized and tested the system hardware displayed system information on the screen, performed RAM checks, and then loaded an initial program from a peripheral device. If none was available, then the computer would perform tasks from other memory stores or display an error message, depending on the model and design of the computer and the ROM version. For example, both the Apple II and the original IBM PC had Microsoft Cassette BASIC in ROM and would start that if no program could be loaded from disk.

Most modern motherboard designs use a BIOS, stored in an EEPROM chip soldered to or socketed on the motherboard, to boot an operating system. Non-operating system boot programs are still supported on modern IBM PC-descended machines, but nowadays it is assumed that the boot program will be a complex operating system such as Microsoft Windows or Linux. When power is first supplied to the motherboard, the BIOS firmware tests and configures memory, circuitry, and peripherals. This Power-On Self Test (POST) may include testing some of the following things:

On recent motherboards, the BIOS may also patch the central processor microcode if the BIOS detects that the installed CPU is one for which errata have been published.

Many motherboards now use a successor to BIOS called UEFI. It became popular after Microsoft began requiring it for a system to be certified to run Windows 8.



</doc>
<doc id="19947" url="https://en.wikipedia.org/wiki?curid=19947" title="Mannerism">
Mannerism

Mannerism, also known as Late Renaissance, is a style in European art that emerged in the later years of the Italian High Renaissance around 1520, spreading by about 1530 and lasting until about the end of the 16th century in Italy, when the Baroque style largely replaced it. Northern Mannerism continued into the early 17th century.

Stylistically, Mannerism encompasses a variety of approaches influenced by, and reacting to, the harmonious ideals associated with artists such as Leonardo da Vinci, Raphael, and early Michelangelo. Where High Renaissance art emphasizes proportion, balance, and ideal beauty, Mannerism exaggerates such qualities, often resulting in compositions that are asymmetrical or unnaturally elegant. The style is notable for its intellectual sophistication as well as its artificial (as opposed to naturalistic) qualities. This artistic style privileges compositional tension and instability rather than the balance and clarity of earlier Renaissance painting. Mannerism in literature and music is notable for its highly florid style and intellectual sophistication.

The definition of Mannerism and the phases within it continues to be a subject of debate among art historians. For example, some scholars have applied the label to certain early modern forms of literature (especially poetry) and music of the 16th and 17th centuries. The term is also used to refer to some late Gothic painters working in northern Europe from about 1500 to 1530, especially the Antwerp Mannerists—a group unrelated to the Italian movement. Mannerism has also been applied by analogy to the Silver Age of Latin literature.

The word, "Mannerism" derives from the Italian "maniera", meaning "style" or "manner". Like the English word "style", "maniera" can either indicate a specific type of style (a beautiful style, an abrasive style) or indicate an absolute that needs no qualification (someone "has style"). In the second edition of his "Lives of the Most Excellent Painters, Sculptors, and Architects" (1568), Giorgio Vasari used "maniera" in three different contexts: to discuss an artist's manner or method of working; to describe a personal or group style, such as the term "maniera greca" to refer to the Byzantine style or simply to the "maniera" of Michelangelo; and to affirm a positive judgment of artistic quality. Vasari was also a Mannerist artist, and he described the period in which he worked as "la maniera moderna", or the "modern style". James V. Mirollo describes how "bella maniera" poets attempted to surpass in virtuosity the sonnets of Petrarch. This notion of "bella maniera" suggests that artists who were thus inspired looked to copying and bettering their predecessors, rather than confronting nature directly. In essence, "bella maniera" utilized the best from a number of source materials, synthesizing it into something new.

As a stylistic label, "Mannerism" is not easily defined. It was used by Swiss historian Jacob Burckhardt and popularized by German art historians in the early 20th century to categorize the seemingly uncategorizable art of the Italian 16th century – art that was no longer found to exhibit the harmonious and rational approaches associated with the High Renaissance. "High Renaissance" connoted a period distinguished by harmony, grandeur and the revival of classical antiquity. The term "Mannerist" was redefined in 1967 by John Shearman following the exhibition of Mannerist paintings organised by Fritz Grossmann at Manchester City Art Gallery in 1965. The label "Mannerism" was used during the 16th century to comment on social behaviour and to convey a refined virtuoso quality or to signify a certain technique. However, for later writers, such as the 17th-century Gian Pietro Bellori, "la maniera" was a derogatory term for the perceived decline of art after Raphael, especially in the 1530s and 1540s. From the late 19th century on, art historians have commonly used the term to describe art that follows Renaissance classicism and precedes the Baroque.

Yet historians differ as to whether Mannerism is a style, a movement, or a period; and while the term remains controversial it is still commonly used to identify European art and culture of the 16th century.

By the end of the High Renaissance, young artists experienced a crisis: it seemed that everything that could be achieved was already achieved. No more difficulties, technical or otherwise, remained to be solved. The detailed knowledge of anatomy, light, physiognomy and the way in which humans register emotion in expression and gesture, the innovative use of the human form in figurative composition, the use of the subtle gradation of tone, all had reached near perfection. The young artists needed to find a new goal, and they sought new approaches. At this point Mannerism started to emerge. The new style developed between 1510 and 1520 either in Florence, or in Rome, or in both cities simultaneously.
This period has been described as a "natural extension" of the art of Andrea del Sarto, Michelangelo, and Raphael. Michelangelo developed his own style at an early age, a deeply original one which was greatly admired at first, then often copied and imitated by other artists of the era. One of the qualities most admired by his contemporaries was his "terribilità", a sense of awe-inspiring grandeur, and subsequent artists attempted to imitate it. Other artists learned Michelangelo's impassioned and highly personal style by copying the works of the master, a standard way that students learned to paint and sculpt. His Sistine Chapel ceiling provided examples for them to follow, in particular his representation of collected figures often called "ignudi" and of the Libyan Sibyl, his vestibule to the Laurentian Library, the figures on his Medici tombs, and above all his "Last Judgment". The later Michelangelo was one of the great role models of Mannerism. Young artists broke into his house and stole drawings from him. In his book "Lives of the Most Eminent Painters, Sculptors, and Architects", Giorgio Vasari noted that Michelangelo stated once: "Those who are followers can never pass by whom they follow".

The competitive spirit was cultivated by patrons who encouraged sponsored artists to emphasize virtuosic technique and to compete with one another for commissions. It drove artists to look for new approaches and dramatically illuminated scenes, elaborate clothes and compositions, elongated proportions, highly stylized poses, and a lack of clear perspective. Leonardo da Vinci and Michelangelo were each given a commission by Gonfaloniere Piero Soderini to decorate a wall in the Hall of Five Hundred in Florence. These two artists were set to paint side by side and compete against each other, fueling the incentive to be as innovative as possible.

The early Mannerists in Florence—especially the students of Andrea del Sarto such as Jacopo da Pontormo and Rosso Fiorentino who are notable for elongated forms, precariously balanced poses, a collapsed perspective, irrational settings, and theatrical lighting. Parmigianino (a student of Correggio) and Giulio Romano (Raphael's head assistant) were moving in similarly stylized aesthetic directions in Rome. These artists had matured under the influence of the High Renaissance, and their style has been characterized as a reaction to or exaggerated extension of it. Instead of studying nature directly, younger artists began studying Hellenistic sculpture and paintings of masters past. Therefore, this style is often identified as "anti-classical", yet at the time it was considered a natural progression from the High Renaissance. The earliest experimental phase of Mannerism, known for its "anti-classical" forms, lasted until about 1540 or 1550. Marcia B. Hall, professor of art history at Temple University, notes in her book "After Raphael" that Raphael's premature death marked the beginning of Mannerism in Rome.

In past analyses, it has been noted that mannerism arose in the early 16th century contemporaneously with a number of other social, scientific, religious and political movements such as the Copernican heliocentrism, the Sack of Rome in 1527, and the Protestant Reformation's increasing challenge to the power of the Catholic Church. Because of this, the style's elongated forms and distorted forms were once interpreted as a reaction to the idealized compositions prevalent in High Renaissance art. This explanation for the radical stylistic shift c. 1520 has fallen out of scholarly favor, though early Mannerist art is still sharply contrasted with High Renaissance conventions; the accessibility and balance achieved by Raphael's "School of Athens" no longer seemed to interest young artists.

The second period of Mannerism is commonly differentiated from the earlier, so-called "anti-classical" phase.
Subsequent mannerists stressed intellectual conceits and artistic virtuosity, features that have led later critics to accuse them of working in an unnatural and affected "manner" ("maniera"). Maniera artists looked to their older contemporary Michelangelo as their principal model; theirs was an art imitating art, rather than an art imitating nature. Art historian Sydney Joseph Freedberg argues that the intellectualizing aspect of maniera art involves expecting its audience to notice and appreciate this visual reference—a familiar figure in an unfamiliar setting enclosed between "unseen, but felt, quotation marks". The height of artifice is the Maniera painter's penchant for deliberately misappropriating a quotation. Agnolo Bronzino and Giorgio Vasari exemplify this strain of Maniera that lasted from about 1530 to 1580. Based largely at courts and in intellectual circles around Europe, Maniera art couples exaggerated elegance with exquisite attention to surface and detail: porcelain-skinned figures recline in an even, tempered light, acknowledging the viewer with a cool glance, if they make eye contact at all. The Maniera subject rarely displays much emotion, and for this reason works exemplifying this trend are often called 'cold' or 'aloof.' This is typical of the so-called "stylish style" or "Maniera" in its maturity.

The cities Rome, Florence, and Mantua were Mannerist centers in Italy. Venetian painting pursued a different course, represented by Titian in his long career. A number of the earliest Mannerist artists who had been working in Rome during the 1520s fled the city after the Sack of Rome in 1527. As they spread out across the continent in search of employment, their style was disseminated throughout Italy and Northern Europe. The result was the first international artistic style since the Gothic. Other parts of Northern Europe did not have the advantage of such direct contact with Italian artists, but the Mannerist style made its presence felt through prints and illustrated books. European rulers, among others, purchased Italian works, while northern European artists continued to travel to Italy, helping to spread the Mannerist style. Individual Italian artists working in the North gave birth to a movement known as the Northern Mannerism. Francis I of France, for example, was presented with Bronzino's "Venus, Cupid, Folly and Time". The style waned in Italy after 1580, as a new generation of artists, including the Carracci brothers, Caravaggio and Cigoli, revived naturalism. Walter Friedlaender identified this period as "anti-mannerism", just as the early Mannerists were "anti-classical" in their reaction away from the aesthetic values of the High Renaissance and today the Carracci brothers and Caravaggio are agreed to have begun the transition to Baroque-style painting which was dominant by 1600.

Outside of Italy, however, Mannerism continued into the 17th century. In France, where Rosso traveled to work for the court at Fontainebleau, it is known as the "Henry II style" and had a particular impact on architecture. Other important continental centers of Northern Mannerism include the court of Rudolf II in Prague, as well as Haarlem and Antwerp. Mannerism as a stylistic category is less frequently applied to English visual and decorative arts, where native labels such as "Elizabethan" and "Jacobean" are more commonly applied. Seventeenth-century Artisan Mannerism is one exception, applied to architecture that relies on pattern books rather than on existing precedents in Continental Europe.

Of particular note is the Flemish influence at Fontainebleau that combined the eroticism of the French style with an early version of the vanitas tradition that would dominate seventeenth-century Dutch and Flemish painting. Prevalent at this time was the "pittore vago", a description of painters from the north who entered the workshops in France and Italy to create a truly international style.

As in painting, early Italian Mannerist sculpture was very largely an attempt to find an original style that would top the achievement of the High Renaissance, which in sculpture essentially meant Michelangelo, and much of the struggle to achieve this was played out in commissions to fill other places in the Piazza della Signoria in Florence, next to Michelangelo's "David". Baccio Bandinelli took over the project of "Hercules and Cacus" from the master himself, but it was little more popular then than it is now, and maliciously compared by Benvenuto Cellini to "a sack of melons", though it had a long-lasting effect in apparently introducing relief panels on the pedestal of statues. Like other works of his and other Mannerists, it removes far more of the original block than Michelangelo would have done. Cellini's bronze "Perseus with the head of Medusa" is certainly a masterpiece, designed with eight angles of view, another Mannerist characteristic, and artificially stylized in comparison with the "David"s of Michelangelo and Donatello. Originally a goldsmith, his famous gold and enamel Salt Cellar (1543) was his first sculpture, and shows his talent at its best.

Small bronze figures for collector's cabinets, often mythological subjects with nudes, were a popular Renaissance form at which Giambologna, originally Flemish but based in Florence, excelled in the later part of the century. He also created life-size sculptures, of which two entered the collection in the Piazza della Signoria. He and his followers devised elegant elongated examples of the "figura serpentinata", often of two intertwined figures, that were interesting from all angles.

Giorgio Vasari's opinions about the art of painting emerge in the praise he bestows on fellow artists in his multi-volume "Lives of the Artists": he believed that excellence in painting demanded refinement, richness of invention ("invenzione"), expressed through virtuoso technique ("maniera"), and wit and study that appeared in the finished work, all criteria that emphasized the artist's intellect and the patron's sensibility. The artist was now no longer just a trained member of a local Guild of St Luke. Now he took his place at court alongside scholars, poets, and humanists, in a climate that fostered an appreciation for elegance and complexity. The coat-of-arms of Vasari's Medici patrons appears at the top of his portrait, quite as if it were the artist's own. The framing of the woodcut image of Vasari's "Lives of the Artists" would be called "Jacobean" in an English-speaking milieu. In it, Michelangelo's Medici tombs inspire the anti-architectural "architectural" features at the top, the papery pierced frame, the satyr nudes at the base. As a mere frame it is extravagant: Mannerist, in short.

Another literary figure from the period is Gian Paolo Lomazzo, who produced two works—one practical and one metaphysical—that helped define the Mannerist artist's self-conscious relation to his art. His "Trattato dell'arte della pittura, scoltura et architettura" (Milan, 1584) is in part a guide to contemporary concepts of decorum, which the Renaissance inherited in part from Antiquity but Mannerism elaborated upon. Lomazzo's systematic codification of aesthetics, which typifies the more formalized and academic approaches typical of the later 16th century, emphasized a consonance between the functions of interiors and the kinds of painted and sculpted decors that would be suitable. Iconography, often convoluted and abstruse, is a more prominent element in the Mannerist styles. His less practical and more metaphysical "Idea del tempio della pittura" ("The ideal temple of painting", Milan, 1590) offers a description along the lines of the "four temperaments" theory of human nature and personality, defining the role of individuality in judgment and artistic invention.

Mannerism was an anti-classical movement which differed greatly from the aesthetic ideologies of the Renaissance. Though Mannerism was initially accepted with positivity based on the writings of Vasari, it was later regarded in a negative light because it solely view as, "an alteration of natural truth and a trite repetition of natural formulas." As an artistic moment, Mannerism involves many characteristics that are unique and specific to experimentation of how art is perceived. Below is a list of many specific characteristics that Mannerist artists would employ in their artworks.

Jacopo da Pontormo's work has been known as some of the most important contributions to Mannerism. Much of his subject matter drew upon religious narratives as well as the influence of the works of Michelangelo and referencing sculpture for composing human forms. A well-known element of his work is the rendering of gazes by various figures which often pierce out at the viewer in various directions. Dedicated to his work, Pontormo, often expressed anxiety about the quality of his work and was known to work slow and methodically. His legacy is highly regarded, as he influenced artists such as Agnolo Bronzino and the aesthetic ideals of late Mannerism.

Pontomoro's "Joseph in Egypt", painted in 1517, portrays a running narrative of four Biblical scenes in which Joseph reconnects with his family. On the left side of the composition, Pontomoro depicts a scene of Joseph introducing his family to the Pharaoh of Egypt. On the right, Joseph is riding on a rolling bench, as cherubs fill the composition around him in addition to other figures and large rocks on a path in the distance. Above these scenes, is a spiral staircase which Joseph guides one his sons to their mother at the top. The final scene, on the right, is the final stage of Jacob's death as his sons watch nearby.

Pontormo's "Joseph in Egypt" features many Mannerist elements. One element is utilization of incongruous colors such as various shades of pinks and blues which make up a majority of the canvas. An additional element of Mannerism is the incoherent handling of time about the story of Joseph through various scenes and use of space. Through the inclusion of the four different narratives, Ponotormo creates a cluttered composition and overall sense of busyness.

Rosso Fiorentino, who had been a fellow pupil of Pontormo in the studio of Andrea del Sarto, in 1530 brought Florentine Mannerism to Fontainebleau, where he became one of the founders of French 16th-century Mannerism, popularly known as the School of Fontainebleau.

The examples of a rich and hectic decorative style at Fontainebleau further disseminated the Italian style through the medium of engravings to Antwerp, and from there throughout Northern Europe, from London to Poland. Mannerist design was extended to luxury goods like silver and carved furniture. A sense of tense, controlled emotion expressed in elaborate symbolism and allegory, and an ideal of female beauty characterized by elongated proportions are features of this style.

Agnolo Bronzino was a pupil of Pontormo, whose style was very influential and often confusing in terms of figuring out the attribution of many artworks. During his career, Bronzino also collaborated with Vasari as a set designer for the production "Comedy of Magicians", where he painted many portraits. Bronzino's work was sought after, and he enjoyed great success when he became a court painter for the Medici family in 1539. A unique Mannerist characteristic of Bronzino's work was the rendering of milky complexions.

In the painting, "Venus, Cupid, Folly and Time", Bronzino portrays an erotic scene that leaves the viewer with more questions than answers. In the foreground, Cupid and Venus are nearly engaged in a kiss, but pause as if caught in the act. Above the pair are mythological figures, Father Time on the right, who pulls a curtain to reveal the pair and the representation of the goddess of the night on the left. The composition also involves a grouping of masks, a hybrid creature composed of features of a girl and a serpent, and a man depicted in agonizing pain. Many theories are available for the painting, such as it conveying the dangers of syphilis, or that the painting functioned as a court game.

Mannerist portraits by Bronzino are distinguished by a serene elegance and meticulous attention to detail. As a result, Bronzino's sitters have been said to project an aloofness and marked emotional distance from the viewer. There is also a virtuosic concentration on capturing the precise pattern and sheen of rich textiles. Specifically, within the "Venus, Cupid, Folly and Time", Bronzino utilizes the tactics of Mannerist movement, attention to detail, color, and sculptural forms. Evidence of Mannerist movement is apparent in the awkward movements of Cupid and Venus, as they contort their bodies to partly embrace. Particularly, Bronzino paints the complexion with the many forms as a perfect porcelain white with a smooth effacement of their muscles which provides a reference to the smoothness of sculpture.

Alessandro Allori's (1535–1607) "Susanna and the Elders" ("below") is distinguished by latent eroticism and consciously brilliant still life detail, in a crowded, contorted composition.

Jacopo Tintoretto has been known for his vastly different contributions to Venetian painting after the legacy of Titian. His work, which differed greatly from his predecessors, had been criticized by Vasari for its, "fantastical, extravagant, bizarre style." Within his work, Tinitoretto adopted Mannerist elements that have distanced him from the classical notion of Venetian painting, as he often created artworks which contained elements of fantasy and retained naturalism. Other unique elements of Tintoretto's work include his attention to color through the regular utilization of rough brushstrokes and experimentation with pigment to create illusion.

An artwork that is associated with Mannerist characteristics is the "Last Supper"; it was commissioned by Michele Alabardi for the San Giorgio Maggiore in 1591. In Tintoretto's "Last Supper", the scene is portrayed from the angle of group of people along the right side of the composition. On the left side of the painting, Christ and the Apostles occupy one side of the table and single out Judas. Within the dark space, there are few sources of light; one source is emitted by Christ's halo and hanging torch above the table.

In its distinct composition, the "Last Supper" portrays Mannerist characteristics. One characteristic that Tintoretto utilizes is a black background. Though the painting gives some indication of an interior space through the use of perspective, the edges of the composition are mostly shrouded in shadow which provides drama for the central scene of the "Last Supper". Additionally, Tintoretto utilizes the spotlight effects with light, especially with the halo of Christ and the hanging torch above the table. A third Mannerist characteristic that Tintoretto employs are the atmospheric effects of figures shaped in smoke and float about the composition.

El Greco attempted to express religious emotion with exaggerated traits. After the realistic depiction of the human form and the mastery of perspective achieved in High Renaissance, some artists started to deliberately distort proportions in disjointed, irrational space for emotional and artistic effect. El Greco still is a deeply original artist. He has been characterized by modern scholars as an artist so individual that he belongs to no conventional school. Key aspects of Mannerism in El Greco include the jarring "acid" palette, elongated and tortured anatomy, irrational perspective and light, and obscure and troubling iconography. El Greco's style was a culmination of unique developments based on his Greek heritage and travels to Spain and Italy.

El Greco's work reflects a multitude of styles including Byzantine elements as well as the influence of Caravaggio and Parmigianino in addition to Venetian coloring. An important element is his attention to color as he regarded it to be one of the most important aspects of his painting. Over the course of his career, El Greco's work remained in high demand as he completed important commissions in locations such as the Colegio de la Encarnación de Madrid.
El Greco's unique painting style and connection to Mannerist characteristics is especially prevalent in the work "Laocoön". Painted in 1610, it depicts the mythological tale of Laocoön, who warned the Trojans about the danger of the wooden horse which was presented by the Greeks as peace offering to the goddess Minerva. As a result, Minerva retaliated in revenge by summoning serpents to kill Laocoön and his two sons. Instead of being set against the backdrop of Troy, El Greco situated the scene near Toledo, Spain in order to "universalize the story by drawing out its relevance for the contemporary world."

El Greco's unique style in "Laocoön" exemplifies many Mannerist characteristics. One that they are prevalent is the elongation of many of the human forms throughout the composition in conjunction with their serpentine movement, which provides a sense of elegance. An additional element of Mannerist style is the atmospheric effects in which El Greco creates a hazy sky and blurring of landscape in the background. 

Benvenuto Cellini created the "Cellini Salt Cellar" of gold and enamel in 1540 featuring Poseidon and Amphitrite (water and earth) placed in uncomfortable positions and with elongated proportions. It is considered a masterpiece of Mannerist sculpture.
Lavinia Fontana (1552–1614) was a Mannerist portraitist often acknowledged to be the first female career artist in Western Europe. She was appointed to be the Portraitist in Ordinary at the Vatican. Her style is characterized as being influenced by the Carracci family of painters by the colors of the Venetian School. She is known for her portraits of noblewomen, and for her depiction of nude figures, which was unusual for a woman of her time.

Taddeo Zuccaro was born in Sant'Angelo in Vado, near Urbino, the son of Ottaviano Zuccari, an almost unknown painter. His brother Federico, born around 1540, was also a painter and architect.

Federico Zuccaro’s documented career as a painter began in 1550, when he moved to Rome to work under Taddeo, his elder brother. He went on to complete decorations for Pius IV, and help complete the fresco decorations at the Villa Farnese at Caprarola. Between 1563 and 1565, he was active in Venice with the Grimani family of Santa Maria Formosa. During his Venetian period, he traveled alongside Palladio in Friuli.

Joachim Wtewael (1566–1638) continued to paint in a Northern Mannerist style until the end of his life, ignoring the arrival of the Baroque art, and making him perhaps the last significant Mannerist artist still to be working. His subjects included large scenes with still life in the manner of Pieter Aertsen, and mythological scenes, many small cabinet paintings beautifully executed on copper, and most featuring nudity.

Giuseppe Arcimboldo is most readily known for his artworks that incorporate still life and portraiture. His style is viewed as Mannerist with the assemblage style of fruits and vegetables in which its composition can be depicted in various ways—right side up and upside down. Arcimboldo's artworks have also applied to Mannerism in terms of humor that it conveys to viewers, because it does not hold the same degree of seriousness as Renaissance works. Stylistically, Arcimboldo's paintings are known for their attention to nature and concept of a "monstrous appearance."

One of Arcimboldo's paintings which contains various Mannerist characteristics is, "Vertumnus". Painted against a black background is a portrait of Rudolf II, whose body is composed of various vegetables, flowers, and fruits. The painting is viewed as various levels as a joke and conveying a serious message. The joke of the painting communicates the humor of power which is that Emperor Rudolf II is hiding a dark inner self behind his public image. On the other hand, the serious tone of the painting foreshadows the good fortune that would be prevalent during his reign.

"Vertumnus" contains various Mannerist elements in terms of its composition and message. One element is the flat, black background which Arcimboldo utilizes to emphasize the status and identity of the Emperor, as well as highlighting the fantasy of his reign. In the portrait of Rudolf II, Arcimboldo also strays away from the naturalistic representation of the Renaissance, and explores the construction of composition by rendering him from a jumble of fruits, vegetables, plants and flowers. Another element of Mannerism which the painting portrays is the dual narrative of a joke and serious message; humor wasn't normally utilized in Renaissance artworks.

Mannerist architecture was characterized by visual trickery and unexpected elements that challenged the Renaissance norms. Flemish artists, many of whom had traveled to Italy and were influenced by Mannerist developments there, were responsible for the spread of Mannerist trends into Europe north of the Alps, including into the realm of architecture. During the period, architects experimented with using architectural forms to emphasize solid and spatial relationships. The Renaissance ideal of harmony gave way to freer and more imaginative rhythms. The best known architect associated with the Mannerist style, and a pioneer at the Laurentian Library, was Michelangelo (1475–1564). He is credited with inventing the giant order, a large pilaster that stretches from the bottom to the top of a façade. He used this in his design for the Piazza del Campidoglio in Rome.

Prior to the 20th century, the term "Mannerism" had negative connotations, but it is now used to describe the historical period in more general, non-judgmental terms. Mannerist architecture has also been used to describe a trend in the 1960s and 1970s that involved breaking the norms of modernist architecture while at the same time recognizing their existence. Defining Mannerism in this context, architect and author Robert Venturi wrote "Mannerism for architecture of our time that acknowledges conventional order rather than original expression but breaks the conventional order to accommodate complexity and contradiction and thereby engages ambiguity unambiguously."

An example of Mannerist architecture is the Villa Farnese at Caprarola, in the rugged country side outside of Rome. The proliferation of engravers during the 16th century spread Mannerist styles more quickly than any previous styles.

Dense with ornament of "Roman" detailing, the display doorway at Colditz Castle exemplifies the northern style, characteristically applied as an isolated "set piece" against unpretentious vernacular walling.

From the late 1560s onwards, many buildings in Valletta, the new capital city of Malta, were designed by the architect Girolamo Cassar in the Mannerist style. Such buildings include St. John's Co-Cathedral, the Grandmaster's Palace and the seven original auberges. Many of Cassar's buildings were modified over the years, especially in the Baroque period. However, a few buildings, such as Auberge d'Aragon and the exterior of St. John's Co-Cathedral, still retain most of Cassar's original Mannerist design.

In English literature, Mannerism is commonly identified with the qualities of the "Metaphysical" poets of whom the most famous is John Donne. The witty sally of a Baroque writer, John Dryden, against the verse of Donne in the previous generation, affords a concise contrast between Baroque and Mannerist aims in the arts:

The rich musical possibilities in the poetry of the late 16th and early 17th centuries provided an attractive basis for the madrigal, which quickly rose to prominence as the pre-eminent musical form in Italian musical culture, as discussed by Tim Carter:

The word Mannerism has also been used to describe the style of highly florid and contrapuntally complex polyphonic music made in France in the late 14th century. This period is now usually referred to as the "ars subtilior".

"The Early Commedia dell'Arte (1550–1621): The Mannerist Context" by Paul Castagno discusses Mannerism's effect on the contemporary professional theatre. Castagno's was the first study to define a theatrical form as Mannerist, employing the vocabulary of Mannerism and maniera to discuss the typification, exaggerated, and "effetto meraviglioso" of the "comici dell'arte". See Part II of the above book for a full discussion of Mannerist characteristics in the commedia dell'arte. The study is largely iconographic, presenting a pictorial evidence that many of the artists who painted or printed commedia images were in fact, coming from the workshops of the day, heavily ensconced in the maniera tradition.

The preciosity in Jacques Callot's minute engravings seem to belie a much larger scale of action. Callot's "Balli di Sfessania" (literally, dance of the buttocks) celebrates the commedia's blatant eroticism, with protruding phalli, spears posed with the anticipation of a comic ream, and grossly exaggerated masks that mix the bestial with human. The eroticism of the "innamorate" (lovers) including the baring of breasts, or excessive veiling, was quite in vogue in the paintings and engravings from the second School of Fontainebleau, particularly those that detect a Franco-Flemish influence. Castagno demonstrates iconographic linkages between genre painting and the figures of the commedia dell'arte that demonstrate how this theatrical form was embedded within the cultural traditions of the late cinquecento.

Important corollaries exist between the "disegno interno", which substituted for the "disegno esterno" (external design) in Mannerist painting. This notion of projecting a deeply subjective view as superseding nature or established principles (perspective, for example), in essence, the emphasis away from the object to its subject, now emphasizing execution, displays of virtuosity, or unique techniques. This inner vision is at the heart of commedia performance. For example, in the moment of improvisation the actor expresses his virtuosity without heed to formal boundaries, decorum, unity, or text. Arlecchino became emblematic of the mannerist "discordia concors" (the union of opposites), at one moment he would be gentle and kind, then, on a dime, become a thief violently acting out with his battle. Arlecchino could be graceful in movement, only in the next beat, to clumsily trip over his feet. Freed from the external rules, the actor celebrated the evanescence of the moment; much the way Benvenuto Cellini would dazzle his patrons by draping his sculptures, unveiling them with lighting effects and a sense of the marvelous. The presentation of the object became as important as the object itself.

According to art critic Jerry Saltz, "Neo-Mannerism" (new Mannerism) is among several clichés that are "squeezing the life out of the art world". Neo-Mannerism describes art of the 21st century that is turned out by students whose academic teachers "have scared [them] into being pleasingly meek, imitative, and ordinary".


Harmondsworth and New York: Penguin. (cased) (pbk) [Reprinted with corrections, 1986; 8th edition, Harmondsworth and New York: Penguin, 1991.]



</doc>
<doc id="19948" url="https://en.wikipedia.org/wiki?curid=19948" title="Monica Lewinsky">
Monica Lewinsky

Monica Samille Lewinsky (born July 23, 1973) is an American activist, television personality, fashion designer, and former White House intern. President Bill Clinton admitted to having had an affair with Lewinsky while she worked at the White House in 1995–1996. The affair and its repercussions (which included Clinton's impeachment) became known later as the Clinton–Lewinsky scandal.

As a result of the public coverage of the political scandal, Lewinsky gained international celebrity status. She subsequently engaged in a variety of ventures that included designing a line of handbags under her name, being an advertising spokesperson for a diet plan, and working as a television personality. Lewinsky later decided to leave the public spotlight to pursue a master's degree in psychology in London. In 2014, she returned to public view as a social activist speaking out against cyberbullying.

Lewinsky was born in San Francisco, California, and grew up in an affluent family in Southern California in the Westside Brentwood area of Los Angeles and in Beverly Hills. Her father is Bernard Lewinsky, an oncologist, who is the son of German Jews who escaped from Nazi Germany and moved to El Salvador and then to the United States when he was 14. Her mother, born Marcia Kay Vilensky, is an author who uses the name Marcia Lewis. In 1996, she wrote her only book, the gossip biography, "The Private Lives of the Three Tenors". During the Lewinsky scandal, the press compared Lewis' unproven "hints" that she had an affair with opera star Plácido Domingo to her daughter's sexual relationship with Clinton. Monica's maternal grandfather, Samuel M. Vilensky, was a Lithuanian Jew, and Monica's maternal grandmother, Bronia Poleshuk, was born in the British Concession of Tianjin, China, to a Russian Jewish family. Monica's parents' acrimonious separation and divorce during 1987 and 1988 had a significant effect on her. Her father later married his current wife, Barbara; her mother later married R. Peter Straus, a media executive and former director of the Voice of America under President Jimmy Carter.

The family attended Sinai Temple in Los Angeles and Monica attended Sinai Akiba Academy, its religious school. For her primary education she attended the John Thomas Dye School in Bel-Air. She then attended Beverly Hills High School, but for her senior year transferred to, and graduated from, Bel Air Prep (later known as Pacific Hills School) in 1991.

Following high school graduation, Lewinsky attended Santa Monica College, a two-year community college, and worked for the drama department at Beverly Hills High School and at a tie shop. In 1992, she allegedly began a five-year affair with Andy Bleiler, her married former high school drama instructor. In 1993, she enrolled at Lewis & Clark College in Portland, Oregon, graduating with a bachelor's degree in psychology in 1995.

With the assistance of a family connection, Lewinsky got an unpaid summer White House internship in the office of White House Chief of Staff Leon Panetta. Lewinsky moved to Washington, D.C. and took up the position in July 1995. She moved to a paid position in the White House Office of Legislative Affairs in December 1995.

Lewinsky stated that she had nine sexual encounters in the Oval Office with President Bill Clinton between November 1995 and March 1997. According to her testimony, these involved fellatio and other sexual acts, but not sexual intercourse.

Clinton had previously been confronted with allegations of sexual misconduct during his time as Governor of Arkansas. Former Arkansas state employee Paula Jones filed a civil lawsuit against him alleging that he had sexually harassed her. Lewinsky's name surfaced during the discovery phase of Jones' case, when Jones' lawyers sought to show a pattern of behavior by Clinton which involved inappropriate sexual relationships with other government employees.

In April 1996, Lewinsky's superiors transferred her from the White House to the Pentagon because they felt that she was spending too much time around Clinton. At the Pentagon, she worked as an assistant to chief Pentagon spokesman Kenneth Bacon. Lewinsky told co-worker Linda Tripp about her relationship with Clinton, and Tripp began secretly recording their telephone conversations beginning in September 1997. Lewinsky left the Pentagon position in December 1997. Lewinsky submitted an affidavit in the Paula Jones case in January 1998 denying any physical relationship with Clinton, and she attempted to persuade Tripp to lie under oath in that case. Tripp gave the tapes to Independent Counsel Kenneth Starr, adding to his on-going investigation into the Whitewater controversy. Starr then broadened his investigation beyond the Arkansas land use deal to include Lewinsky, Clinton, and others for possible perjury and subornation of perjury in the Jones case. Tripp reported the taped conversations to literary agent Lucianne Goldberg. She also convinced Lewinsky to save the gifts that Clinton had given her during their relationship and not to dry clean a blue dress that was stained with Clinton's semen. Under oath, Clinton denied having had "a sexual affair", "sexual relations", or "a sexual relationship" with Lewinsky.

News of the Clinton–Lewinsky relationship broke in January 1998. On January 26, 1998, Clinton stated, "I did not have sexual relations with that woman, Miss Lewinsky" in a nationally televised White House news conference. The matter instantly occupied the news media, and Lewinsky spent the next weeks hiding from public attention in her mother's residence at the Watergate complex. News of Lewinsky's affair with Andy Bleiler, her former high school drama instructor, also came to light, and he turned over to Starr various souvenirs, photographs, and documents that Lewinsky had sent him and his wife during the time that she was in the White House.

Clinton had also said, "There is not a sexual relationship, an improper sexual relationship or any other kind of improper relationship" which he defended as truthful on August 17, 1998 because of his use of the present tense, arguing "it depends on what the meaning of the word 'is' is". Starr obtained a blue dress from Lewinsky with Clinton's semen stained on it, as well as testimony from her that the President had inserted a cigar into her vagina. Clinton stated, "I did have a relationship with Miss Lewinsky that was not appropriate", but he denied committing perjury because, according to Clinton, the legal definition of oral sex was not encompassed by "sex" "per se". In addition, he relied on the definition of "sexual relations" as proposed by the prosecution and agreed by the defense and by Judge Susan Webber Wright, who was hearing the Paula Jones case. Clinton claimed that certain acts were performed "on" him, not "by" him, and therefore he did not engage in sexual relations. Lewinsky's testimony to the Starr Commission, however, contradicted Clinton's claim of being totally passive in their encounters.

Clinton and Lewinsky were both called before a grand jury; he testified via closed-circuit television, she in person. She was granted transactional immunity by the Office of the Independent Counsel in exchange for her testimony.

The affair led to pop culture celebrity for Lewinsky, as she had become the focus of a political storm. Her immunity agreement restricted what she could talk about publicly, but she was able to cooperate with Andrew Morton in his writing of "Monica's Story", her biography which included her side of the Clinton affair. The book was published in March 1999; it was also excerpted as a cover story in "Time" magazine. On March 3, 1999, Barbara Walters interviewed Lewinsky on ABC's "20/20". The program was watched by 70 million Americans, which ABC said was a record for a news show. Lewinsky made about $500,000 from her participation in the book and another $1 million from international rights to the Walters interview, but was still beset by high legal bills and living costs.

In June 1999, "Ms." magazine published a series of articles by writer Susan Jane Gilman, sexologist Susie Bright, and author-host Abiola Abrams arguing from three generations of women whether Lewinsky's behavior had any meaning for feminism. Also in 1999, Lewinsky declined to sign an autograph in an airport, saying, "I'm kind of known for something that's not so great to be known for." She made a cameo appearance as herself in two sketches during the May 8, 1999, episode of NBC's "Saturday Night Live", a program that had lampooned her relationship with Clinton over the prior 16 months.

By her own account, Lewinsky had survived the intense media attention during the scandal period by knitting. In September 1999, she took this interest further by beginning to sell a line of handbags bearing her name, under the company name The Real Monica, Inc. They were sold online as well as at Henri Bendel in New York, Fred Segal in California, and The Cross in London. Lewinsky designed the bags—described by "New York" magazine as "hippie-ish, reversible totes"—and traveled frequently to supervise their manufacture in Louisiana.

At the start of 2000, Lewinsky began appearing in television commercials for the diet company Jenny Craig, Inc. The $1 million endorsement deal, which required Lewinsky to lose 40 or more pounds in six months, gained considerable publicity at the time. Lewinsky said that despite her desire to return to a more private life, she needed the money to pay off legal fees, and she believed in the product. A Jenny Craig spokesperson said of Lewinsky, "She represents a busy active woman of today with a hectic lifestyle. And she has had weight issues and weight struggles for a long time. That represents a lot of women in America." The choice of Lewinsky as a role model proved controversial for Jenny Craig, and some of its private franchises switched to an older advertising campaign. The company stopped running the Lewinsky ads in February 2000, concluded her campaign entirely in April 2000, and paid her only $300,000 of the $1 million contracted for her involvement.

Also at the start of 2000, Lewinsky moved to New York City, lived in the West Village, and became an A-list guest in the Manhattan social scene. In February 2000, she appeared on MTV's "The Tom Green Show", in an episode in which the host took her to his parents' home in Ottawa in search of fabric for her new handbag business. Later in 2000, Lewinsky worked as a correspondent for Channel 5 in the UK, on the show "Monica's Postcards", reporting on U.S. culture and trends from a variety of locations.

In March 2002, Lewinsky, no longer bound by the terms of her immunity agreement, appeared in the HBO special, "Monica in Black and White", part of the "America Undercover" series. In it she answered a studio audience's questions about her life and the Clinton affair.

Lewinsky hosted the reality television dating program, "Mr. Personality", on Fox Television Network in 2003, where she advised young women contestants who were picking men hidden by masks. Some Americans tried to organize a boycott of advertisers on the show, to protest Lewinsky's capitalizing on her notoriety. Nevertheless, the show debuted to very high ratings, and Alessandra Stanley wrote in "The New York Times": "after years of trying to cash in on her fame by designing handbags and other self-marketing schemes, Ms. Lewinsky has finally found a fitting niche on television." The ratings, however, slid downward each successive week, and after the show completed its initial limited run, it did not reappear. The same year she appeared as a guest on the programs "V Graham Norton" in the UK, "High Chaparall" in Sweden, and "The View" and "Jimmy Kimmel Live!" in the U.S.

After Clinton's autobiography, "My Life", appeared in 2004, Lewinsky said in an interview with the British tabloid "Daily Mail":
By 2005, Lewinsky found that she could not escape the spotlight in the U.S., which made both her professional and personal life difficult. She stopped selling her handbag line and moved to London to study social psychology at the London School of Economics. In December 2006, Lewinsky graduated with a Master of Science degree. Her thesis was titled, "In Search of the Impartial Juror: An Exploration of the Third-Person Effect and Pre-Trial Publicity." For the next decade she tried to avoid publicity.

Lewinsky did correspond in 2009 with scholar Ken Gormley, who was writing an in-depth study of the Clinton scandals, maintaining that Clinton had lied under oath when asked detailed and specific questions about his relationship with her. In 2013, the items associated with Lewinsky that Bleiler had turned over to Starr were put up for auction by Bleiler's ex-wife, who had come into possession of them.

During her decade out of the public eye, Lewinsky lived in London, Los Angeles, New York, and Portland but, due to her notoriety, had trouble finding employment in the communications and marketing jobs for nonprofit organizations where she had been interviewed.

In May 2014, Lewinsky wrote an essay for "Vanity Fair" magazine titled "Shame and Survival", wherein she discussed her life and the scandal. She continued to maintain that the relationship was mutual and wrote that while Clinton took advantage of her, it was a consensual relationship. She added: "I, myself, deeply regret what happened between me and President Clinton. Let me say it again: I. Myself. Deeply. Regret. What. Happened." However, she said it was now time to "stick my head above the parapet so that I can take back my narrative and give a purpose to my past." The magazine later announced her as a "Vanity Fair" contributor, stating she would "contribute to their website on an ongoing basis, on the lookout for relevant topics of interest".
In July 2014, Lewinsky was interviewed in a three-part television special for the National Geographic Channel, titled "The 90s: The Last Great Decade". The series looked at various events of the 1990s, including the scandal that brought Lewinsky into the national spotlight. This was Lewinsky's first such interview in more than ten years.

In October 2014, she took a public stand against cyberbullying, calling herself "patient zero" of online harassment. Speaking at a "Forbes" magazine "30 Under 30" summit about her experiences in the aftermath of the scandal, she said, "Having survived myself, what I want to do now is help other victims of the shame game survive, too." She said she was influenced by reading about the suicide of Tyler Clementi, a Rutgers University freshman, involving cyberbullying and joined Twitter to facilitate her efforts. In March 2015, Lewinsky continued to speak out publicly against cyberbullying, delivering a TED talk calling for a more compassionate Internet. In June 2015, she became an ambassador and strategic advisor for anti-bullying organization Bystander Revolution. The same month, she gave an anti-cyberbullying speech at the Cannes Lions International Festival of Creativity. In September 2015, Lewinsky was interviewed by Amy Robach on "Good Morning America", about Bystander Revolution's Month of Action campaign for National Bullying Prevention Month. Lewinsky wrote the foreword to an October 2017 book by Sue Scheff and Melissa Schorr, "Shame Nation: The Global Epidemic of Online Hate".

In October 2017, Lewinsky tweeted the #MeToo hashtag to indicate that she was a victim of sexual harassment and/or sexual assault, but did not provide details. She wrote an essay in the March 2018 issue of "Vanity Fair" in which she did not directly explain why she used the #MeToo hashtag in October. She did write that looking back at her relationship with Bill Clinton, although it was consensual, because he was 27 years older than her and in a position with a lot more power than she had, in her opinion the relationship constituted an "abuse of power" on Clinton's part. She added that she had been diagnosed with post-traumatic stress disorder due to the experiences involved after the relationship was disclosed. In May 2018, Lewinsky was disinvited from an event hosted by "Town & Country" when Bill Clinton accepted an invitation to the event.

In September 2018, Lewinsky spoke at a conference in Jerusalem. Following her speech, she sat for a Q&A session with the host, journalist Yonit Levi. The first question Levi asked was whether Lewinsky thinks that Clinton owes her a private apology. Lewinsky refused to answer the question, and walked off the stage. She later tweeted that the question was posed in a pre-event meeting with Levi, and Lewinsky told her that such a question was off limits. A spokesman for the Israel Television News Company, which hosted the conference and is Levi's employer, responded that Levi had kept all the agreements she made with Lewinsky and honored her requests.

In 2019, she was interviewed by John Oliver on his HBO show, where they discussed the importance of solving the problem of public shaming and how her situation may have been different if social media had existed at the time that the scandal broke in the late 1990s.




</doc>
<doc id="19951" url="https://en.wikipedia.org/wiki?curid=19951" title="Pressure measurement">
Pressure measurement

Pressure measurement is the analysis of an applied force by a fluid (liquid or gas) on a surface. Pressure is typically measured in units of force per unit of surface area. Many techniques have been developed for the measurement of pressure and vacuum. Instruments used to measure and display pressure in an integral unit are called pressure meters or pressure gauges or vacuum gauges. A manometer is a good example, as it uses the surface area and weight of a column of liquid to both measure and indicate pressure. Likewise the widely used Bourdon gauge is a mechanical device, which both measures and indicates and is probably the best known type of gauge.

A vacuum gauge is a pressure gauge used to measure pressures lower than the ambient atmospheric pressure, which is set as the zero point, in negative values (e.g.: −15 psig or −760 mmHg equals total vacuum). Most gauges measure pressure relative to atmospheric pressure as the zero point, so this form of reading is simply referred to as "gauge pressure". However, anything greater than total vacuum is technically a form of pressure. For very accurate readings, especially at very low pressures, a gauge that uses total vacuum as the zero point may be used, giving pressure readings in an absolute scale.

Other methods of pressure measurement involve sensors that can transmit the pressure reading to a remote indicator or control system (telemetry).

Everyday pressure measurements, such as for vehicle tire pressure, are usually made relative to ambient air pressure. In other cases measurements are made relative to a vacuum or to some other specific reference. When distinguishing between these zero references, the following terms are used:

The zero reference in use is usually implied by context, and these words are added only when clarification is needed. Tire pressure and blood pressure are gauge pressures by convention, while atmospheric pressures, deep vacuum pressures, and altimeter pressures must be absolute.

For most working fluids where a fluid exists in a closed system, gauge pressure measurement prevails. Pressure instruments connected to the system will indicate pressures relative to the current atmospheric pressure. The situation changes when extreme vacuum pressures are measured, then absolute pressures are typically used instead.

Differential pressures are commonly used in industrial process systems. Differential pressure gauges have two inlet ports, each connected to one of the volumes whose pressure is to be monitored. In effect, such a gauge performs the mathematical operation of subtraction through mechanical means, obviating the need for an operator or control system to watch two separate gauges and determine the difference in readings.

Moderate vacuum pressure readings can be ambiguous without the proper context, as they may represent absolute pressure or gauge pressure without a negative sign. Thus a vacuum of 26 inHg gauge is equivalent to an absolute pressure of 4 inHg, calculated as 30 inHg (typical atmospheric pressure) − 26 inHg (gauge pressure).

Atmospheric pressure is typically about 100 kPa at sea level, but is variable with altitude and weather. If the absolute pressure of a fluid stays constant, the gauge pressure of the same fluid will vary as atmospheric pressure changes. For example, when a car drives up a mountain, the (gauge) tire pressure goes up because atmospheric pressure goes down. The absolute pressure in the tire is essentially unchanged.

Using atmospheric pressure as reference is usually signified by a "g" for gauge after the pressure unit, e.g. 70 psig, which means that the pressure measured is the total pressure minus atmospheric pressure. There are two types of gauge reference pressure: vented gauge (vg) and sealed gauge (sg).

A vented-gauge pressure transmitter, for example, allows the outside air pressure to be exposed to the negative side of the pressure-sensing diaphragm, through a vented cable or a hole on the side of the device, so that it always measures the pressure referred to ambient barometric pressure. Thus a vented-gauge reference pressure sensor should always read zero pressure when the process pressure connection is held open to the air.

A sealed gauge reference is very similar, except that atmospheric pressure is sealed on the negative side of the diaphragm. This is usually adopted on high pressure ranges, such as hydraulics, where atmospheric pressure changes will have a negligible effect on the accuracy of the reading, so venting is not necessary. This also allows some manufacturers to provide secondary pressure containment as an extra precaution for pressure equipment safety if the burst pressure of the primary pressure sensing diaphragm is exceeded.

There is another way of creating a sealed gauge reference, and this is to seal a high vacuum on the reverse side of the sensing diaphragm. Then the output signal is offset, so the pressure sensor reads close to zero when measuring atmospheric pressure.

A sealed gauge reference pressure transducer will never read exactly zero because atmospheric pressure is always changing and the reference in this case is fixed at 1 bar.

To produce an absolute pressure sensor, the manufacturer seals a high vacuum behind the sensing diaphragm. If the process-pressure connection of an absolute-pressure transmitter is open to the air, it will read the actual barometric pressure.

The SI unit for pressure is the pascal (Pa), equal to one newton per square metre (N·m or kg·m·s). This special name for the unit was added in 1971; before that, pressure in SI was expressed in units such as N·m. When indicated, the zero reference is stated in parenthesis following the unit, for example 101 kPa (abs). The pound per square inch (psi) is still in widespread use in the US and Canada, for measuring, for instance, tire pressure. A letter is often appended to the psi unit to indicate the measurement's zero reference; psia for absolute, psig for gauge, psid for differential, although this practice is discouraged by the NIST.

Because pressure was once commonly measured by its ability to displace a column of liquid in a manometer, pressures are often expressed as a depth of a particular fluid ("e.g.," inches of water). Manometric measurement is the subject of pressure head calculations. The most common choices for a manometer's fluid are mercury (Hg) and water; water is nontoxic and readily available, while mercury's density allows for a shorter column (and so a smaller manometer) to measure a given pressure. The abbreviation "W.C." or the words "water column" are often printed on gauges and measurements that use water for the manometer.
Fluid density and local gravity can vary from one reading to another depending on local factors, so the height of a fluid column does not define pressure precisely. So measurements in "millimetres of mercury" or "inches of mercury" can be converted to SI units as long as attention is paid to the local factors of fluid density and gravity. Temperature fluctuations change the value of fluid density, while location can affect gravity.

Although no longer preferred, these manometric units are still encountered in many fields. Blood pressure is measured in millimetres of mercury (see torr) in most of the world, central venous pressure and lung pressures in centimeters of water are still common, as in settings for CPAP machines. Natural gas pipeline pressures are measured in inches of water, expressed as "inches W.C."

Underwater divers use manometric units: the ambient pressure is measured in units of metres sea water (msw) which is defined as equal to one tenth of a bar. The unit used in the US is the foot sea water (fsw), based on standard gravity and a sea-water density of 64 lb/ft. According to the US Navy Diving Manual, one fsw equals 0.30643 msw, , or , though elsewhere it states that 33 fsw is (one atmosphere), which gives one fsw equal to about 0.445 psi. The msw and fsw are the conventional units for measurement of diver pressure exposure used in decompression tables and the unit of calibration for pneumofathometers and hyperbaric chamber pressure gauges. Both msw and fsw are measured relative to normal atmospheric pressure.

In vacuum systems, the units torr (millimeter of mercury), micron (micrometer of mercury), and inch of mercury (inHg) are most commonly used. Torr and micron usually indicates an absolute pressure, while inHg usually indicates a gauge pressure.

Atmospheric pressures are usually stated using hectopascal (hPa), kilopascal (kPa), millibar (mbar) or atmospheres (atm). In American and Canadian engineering, stress is often measured in kip. Note that stress is not a true pressure since it is not scalar. In the cgs system the unit of pressure was the barye (ba), equal to 1 dyn·cm. In the mts system, the unit of pressure was the pieze, equal to 1 sthene per square metre.

Many other hybrid units are used such as mmHg/cm or grams-force/cm (sometimes as kg/cm without properly identifying the force units). Using the names kilogram, gram, kilogram-force, or gram-force (or their symbols) as a unit of force is prohibited in SI; the unit of force in SI is the newton (N).

Static pressure is uniform in all directions, so pressure measurements are independent of direction in an immovable (static) fluid. Flow, however, applies additional pressure on surfaces perpendicular to the flow direction, while having little impact on surfaces parallel to the flow direction. This directional component of pressure in a moving (dynamic) fluid is called dynamic pressure. An instrument facing the flow direction measures the sum of the static and dynamic pressures; this measurement is called the total pressure or stagnation pressure. Since dynamic pressure is referenced to static pressure, it is neither gauge nor absolute; it is a differential pressure.

While static gauge pressure is of primary importance to determining net loads on pipe walls, dynamic pressure is used to measure flow rates and airspeed. Dynamic pressure can be measured by taking the differential pressure between instruments parallel and perpendicular to the flow. Pitot-static tubes, for example perform this measurement on airplanes to determine airspeed. The presence of the measuring instrument inevitably acts to divert flow and create turbulence, so its shape is critical to accuracy and the calibration curves are often non-linear.


Many instruments have been invented to measure pressure, with different advantages and disadvantages. Pressure range, sensitivity, dynamic response and cost all vary by several orders of magnitude from one instrument design to the next. The oldest type is the liquid column (a vertical tube filled with mercury) manometer invented by Evangelista Torricelli in 1643. The U-Tube was invented by Christiaan Huygens in 1661.

Hydrostatic gauges (such as the mercury column manometer) compare pressure to the hydrostatic force per unit area at the base of a column of fluid. Hydrostatic gauge measurements are independent of the type of gas being measured, and can be designed to have a very linear calibration. They have poor dynamic response.

Piston-type gauges counterbalance the pressure of a fluid with a spring (for example tire-pressure gauges of comparatively low accuracy) or a solid weight, in which case it is known as a deadweight tester and may be used for calibration of other gauges.

Liquid-column gauges consist of a column of liquid in a tube whose ends are exposed to different pressures. The column will rise or fall until its weight (a force applied due to gravity) is in equilibrium with the pressure differential between the two ends of the tube (a force applied due to fluid pressure). A very simple version is a U-shaped tube half-full of liquid, one side of which is connected to the region of interest while the reference pressure (which might be the atmospheric pressure or a vacuum) is applied to the other. The difference in liquid levels represents the applied pressure. The pressure exerted by a column of fluid of height "h" and density "ρ" is given by the hydrostatic pressure equation, "P" = "hgρ". Therefore, the pressure difference between the applied pressure "P" and the reference pressure "P" in a U-tube manometer can be found by solving . In other words, the pressure on either end of the liquid (shown in blue in the figure) must be balanced (since the liquid is static), and so .

In most liquid-column measurements, the result of the measurement is the height "h", expressed typically in mm, cm, or inches. The "h" is also known as the pressure head. When expressed as a pressure head, pressure is specified in units of length and the measurement fluid must be specified. When accuracy is critical, the temperature of the measurement fluid must likewise be specified, because liquid density is a function of temperature. So, for example, pressure head might be written "742.2 mm" or "4.2 in at 59 °F" for measurements taken with mercury or water as the manometric fluid respectively. The word "gauge" or "vacuum" may be added to such a measurement to distinguish between a pressure above or below the atmospheric pressure. Both mm of mercury and inches of water are common pressure heads, which can be converted to S.I. units of pressure using unit conversion and the above formulas.

If the fluid being measured is significantly dense, hydrostatic corrections may have to be made for the height between the moving surface of the manometer working fluid and the location where the pressure measurement is desired, except when measuring differential pressure of a fluid (for example, across an orifice plate or venturi), in which case the density ρ should be corrected by subtracting the density of the fluid being measured.

Although any fluid can be used, mercury is preferred for its high density (13.534 g/cm) and low vapour pressure. Its convex meniscus is advantageous since this means there will be no pressure errors from wetting the glass, though under exceptionally clean circumstances, the mercury will stick to glass and the barometer may become stuck (the mercury can sustain a negative absolute pressure) even under a strong vacuum. For low pressure differences, light oil or water are commonly used (the latter giving rise to units of measurement such as inches water gauge and millimetres HO). Liquid-column pressure gauges have a highly linear calibration. They have poor dynamic response because the fluid in the column may react slowly to a pressure change.

When measuring vacuum, the working liquid may evaporate and contaminate the vacuum if its vapor pressure is too high. When measuring liquid pressure, a loop filled with gas or a light fluid can isolate the liquids to prevent them from mixing, but this can be unnecessary, for example, when mercury is used as the manometer fluid to measure differential pressure of a fluid such as water. Simple hydrostatic gauges can measure pressures ranging from a few torrs (a few 100 Pa) to a few atmospheres (approximately ).

A single-limb liquid-column manometer has a larger reservoir instead of one side of the U-tube and has a scale beside the narrower column. The column may be inclined to further amplify the liquid movement. Based on the use and structure, following types of manometers are used

A McLeod gauge isolates a sample of gas and compresses it in a modified mercury manometer until the pressure is a few millimetres of mercury. The technique is very slow and unsuited to continual monitoring, but is capable of good accuracy. Unlike other manometer gauges, the McLeod gauge reading is dependent on the composition of the gas, since the interpretation relies on the sample compressing as an ideal gas. Due to the compression process, the McLeod gauge completely ignores partial pressures from non-ideal vapors that condense, such as pump oils, mercury, and even water if compressed enough.

0.1 mPa is the lowest direct measurement of pressure that is possible with current technology. Other vacuum gauges can measure lower pressures, but only indirectly by measurement of other pressure-dependent properties. These indirect measurements must be calibrated to SI units by a direct measurement, most commonly a McLeod gauge.

Aneroid gauges are based on a metallic pressure-sensing element that flexes elastically under the effect of a pressure difference across the element. "Aneroid" means "without fluid", and the term originally distinguished these gauges from the hydrostatic gauges described above. However, aneroid gauges can be used to measure the pressure of a liquid as well as a gas, and they are not the only type of gauge that can operate without fluid. For this reason, they are often called mechanical gauges in modern language. Aneroid gauges are not dependent on the type of gas being measured, unlike thermal and ionization gauges, and are less likely to contaminate the system than hydrostatic gauges. The pressure sensing element may be a Bourdon tube, a diaphragm, a capsule, or a set of bellows, which will change shape in response to the pressure of the region in question. The deflection of the pressure sensing element may be read by a linkage connected to a needle, or it may be read by a secondary transducer. The most common secondary transducers in modern vacuum gauges measure a change in capacitance due to the mechanical deflection. Gauges that rely on a change in capacitance are often referred to as capacitance manometers.

The Bourdon pressure gauge uses the principle that a flattened tube tends to straighten or regain its circular form in cross-section when pressurized. This change in cross-section may be hardly noticeable, involving moderate stresses within the elastic range of easily workable materials. The strain of the material of the tube is magnified by forming the tube into a C shape or even a helix, such that the entire tube tends to straighten out or uncoil elastically as it is pressurized. Eugène Bourdon patented his gauge in France in 1849, and it was widely adopted because of its superior sensitivity, linearity, and accuracy; Edward Ashcroft purchased Bourdon's American patent rights in 1852 and became a major manufacturer of gauges. Also in 1849, Bernard Schaeffer in Magdeburg, Germany patented a successful diaphragm (see below) pressure gauge, which, together with the Bourdon gauge, revolutionized pressure measurement in industry. But in 1875 after Bourdon's patents expired, his company Schaeffer and Budenberg also manufactured Bourdon tube gauges.

In practice, a flattened thin-wall, closed-end tube is connected at the hollow end to a fixed pipe containing the fluid pressure to be measured. As the pressure increases, the closed end moves in an arc, and this motion is converted into the rotation of a (segment of a) gear by a connecting link that is usually adjustable. A small-diameter pinion gear is on the pointer shaft, so the motion is magnified further by the gear ratio. The positioning of the indicator card behind the pointer, the initial pointer shaft position, the linkage length and initial position, all provide means to calibrate the pointer to indicate the desired range of pressure for variations in the behavior of the Bourdon tube itself. Differential pressure can be measured by gauges containing two different Bourdon tubes, with connecting linkages.

Bourdon tubes measure gauge pressure, relative to ambient atmospheric pressure, as opposed to absolute pressure; vacuum is sensed as a reverse motion. Some aneroid barometers use Bourdon tubes closed at both ends (but most use diaphragms or capsules, see below). When the measured pressure is rapidly pulsing, such as when the gauge is near a reciprocating pump, an orifice restriction in the connecting pipe is frequently used to avoid unnecessary wear on the gears and provide an average reading; when the whole gauge is subject to mechanical vibration, the entire case including the pointer and indicator card can be filled with an oil or glycerin. Tapping on the face of the gauge is not recommended as it will tend to falsify actual readings initially presented by the gauge. The Bourdon tube is separate from the face of the gauge and thus has no effect on the actual reading of pressure. Typical high-quality modern gauges provide an accuracy of ±2% of span, and a special high-precision gauge can be as accurate as 0.1% of full scale.

Force-balanced fused quartz bourdon tube sensors work on the same principle but uses the reflection of a beam of light from a mirror to sense the angular displacement and current is applied to electromagnets to balance the force of the tube and bring the angular displacement back to zero, the current that is applied to the coils is used as the measurement. Due to the extremely stable and repeatable mechanical and thermal properties of quartz and the force balancing which eliminates nearly all physical movement these sensors can be accurate to around 1 PPM of full scale. Due to the extremely fine fused quartz structures which must be made by hand these sensors are generally limited to scientific and calibration purposes.

In the following illustrations the transparent cover face of the pictured combination pressure and vacuum gauge has been removed and the mechanism removed from the case. This particular gauge is a combination vacuum and pressure gauge used for automotive diagnosis:

Stationary parts:

Moving parts:

A second type of aneroid gauge uses deflection of a flexible membrane that separates regions of different pressure. The amount of deflection is repeatable for known pressures so the pressure can be determined by using calibration. The deformation of a thin diaphragm is dependent on the difference in pressure between its two faces. The reference face can be open to atmosphere to measure gauge pressure, open to a second port to measure differential pressure, or can be sealed against a vacuum or other fixed reference pressure to measure absolute pressure. The deformation can be measured using mechanical, optical or capacitive techniques. Ceramic and metallic diaphragms are used.
For absolute measurements, welded pressure capsules with diaphragms on either side are often used.

shape:

In gauges intended to sense small pressures or pressure differences, or require that an absolute pressure be measured, the gear train and needle may be driven by an enclosed and sealed bellows chamber, called an aneroid, which means "without liquid". (Early barometers used a column of liquid such as water or the liquid metal mercury suspended by a vacuum.) This bellows configuration is used in aneroid barometers (barometers with an indicating needle and dial card), altimeters, altitude recording barographs, and the altitude telemetry instruments used in weather balloon radiosondes. These devices use the sealed chamber as a reference pressure and are driven by the external pressure. Other sensitive aircraft instruments such as air speed indicators and rate of climb indicators (variometers) have connections both to the internal part of the aneroid chamber and to an external enclosing chamber.

These gauges use the attraction of two magnets to translate differential pressure into motion of a dial pointer. As differential pressure increases, a magnet attached to either a piston or rubber diaphragm moves. A rotary magnet that is attached to a pointer then moves in unison. To create different pressure ranges, the spring rate can be increased or decreased.

The spinning-rotor gauge works by measuring the amount a rotating ball is slowed by the viscosity of the gas being measured. The ball is made of steel and is magnetically levitated inside a steel tube closed at one end and exposed to the gas to be measured at the other. The ball is brought up to speed (about 2500 rad/s), and the speed measured after switching off the drive, by electromagnetic transducers. The range of the instrument is 10 to 10 Pa (10 Pa with less accuracy). It is accurate and stable enough to be used as a secondary standard. The instrument requires some skill and knowledge to use correctly. Various corrections must be applied and the ball must be spun at a pressure well below the intended measurement pressure for five hours before using. It is most useful in calibration and research laboratories where high accuracy is required and qualified technicians are available.


This is an over simplified diagram, but you can see fundamental design of the internal ports in the sensor. The important item here to note is the “Diaphragm” as this is the sensor itself. Please note that is it slightly convex in shape (highly exaggerated in the drawing), this is important as it effects the accuracy of the sensor in use. 
The shape of the sensor is important because it is calibrated to work in the direction of Air flow as shown by the RED Arrows. This is normal operation for the pressure sensor, providing a positive reading on the display of the digital pressure meter. Applying pressure in the reverse direction can induce errors in the results as the movement of the air pressure is trying to force the diaphragm to move in the opposite direction. The errors induced by this are small but, can be significant and therefore it is always preferable to ensure that the more positive pressure is always applied to the positive (+ve) port and the lower pressure is applied to the negative (-ve) port, for normal 'Gauge Pressure' application. The same applies to measuring the difference between two vacuums, the larger vacuum should always be applied to the negative (-ve) port.
The measurement of pressure via the Wheatstone Bridge looks something like this...

The effective electrical model of the transducer, together with a basic signal conditioning circuit, is shown in the application schematic. The pressure sensor is a fully active Wheatstone bridge which has been temperature compensated and offset adjusted by means of thick film, laser trimmed resistors. The excitation to the bridge is applied via a constant current. The low-level bridge output is at +O and -O, and the amplified span is set by the gain programming resistor (r). The electrical design is microprocessor controlled, which allows for calibration, the additional functions for the user, such as Scale Selection, Data Hold, Zero and Filter functions, the Record function that stores/displays MAX/MIN. 

Generally, as a real gas increases in density -which may indicate an increase in pressure- its ability to conduct heat increases. In this type of gauge, a wire filament is heated by running current through it. A thermocouple or resistance thermometer (RTD) can then be used to measure the temperature of the filament. This temperature is dependent on the rate at which the filament loses heat to the surrounding gas, and therefore on the thermal conductivity. A common variant is the Pirani gauge, which uses a single platinum filament as both the heated element and RTD. These gauges are accurate from 10 Torr to 10 Torr, but their calibration is sensitive to the chemical composition of the gases being measured.

A Pirani gauge consists of a metal wire open to the pressure being measured. The wire is heated by a current flowing through it and cooled by the gas surrounding it. If the gas pressure is reduced, the cooling effect will decrease, hence the equilibrium temperature of the wire will increase. The resistance of the wire is a function of its temperature: by measuring the voltage across the wire and the current flowing through it, the resistance (and so the gas pressure) can be determined. This type of gauge was invented by Marcello Pirani.

In two-wire gauges, one wire coil is used as a heater, and the other is used to measure temperature due to convection. Thermocouple gauges and thermistor gauges work in this manner using thermocouple or thermistor, respectively, to measure the temperature of the heated wire.

Ionization gauges are the most sensitive gauges for very low pressures (also referred to as hard or high vacuum). They sense pressure indirectly by measuring the electrical ions produced when the gas is bombarded with electrons. Fewer ions will be produced by lower density gases. The calibration of an ion gauge is unstable and dependent on the nature of the gases being measured, which is not always known. They can be calibrated against a McLeod gauge which is much more stable and independent of gas chemistry.

Thermionic emission generates electrons, which collide with gas atoms and generate positive ions. The ions are attracted to a suitably biased electrode known as the collector. The current in the collector is proportional to the rate of ionization, which is a function of the pressure in the system. Hence, measuring the collector current gives the gas pressure. There are several sub-types of ionization gauge.

Most ion gauges come in two types: hot cathode and cold cathode. In the hot cathode version, an electrically heated filament produces an electron beam. The electrons travel through the gauge and ionize gas molecules around them. The resulting ions are collected at a negative electrode. The current depends on the number of ions, which depends on the pressure in the gauge. Hot cathode gauges are accurate from 10 Torr to 10 Torr. The principle behind cold cathode version is the same, except that electrons are produced in the discharge of a high voltage. Cold cathode gauges are accurate from 10 Torr to 10 Torr. Ionization gauge calibration is very sensitive to construction geometry, chemical composition of gases being measured, corrosion and surface deposits. Their calibration can be invalidated by activation at atmospheric pressure or low vacuum. The composition of gases at high vacuums will usually be unpredictable, so a mass spectrometer must be used in conjunction with the ionization gauge for accurate measurement.

A hot-cathode ionization gauge is composed mainly of three electrodes acting together as a triode, wherein the cathode is the filament. The three electrodes are a collector or plate, a filament, and a grid. The collector current is measured in picoamperes by an electrometer. The filament voltage to ground is usually at a potential of 30 volts, while the grid voltage at 180–210 volts DC, unless there is an optional electron bombardment feature, by heating the grid, which may have a high potential of approximately 565 volts.

The most common ion gauge is the hot-cathode Bayard–Alpert gauge, with a small ion collector inside the grid. A glass envelope with an opening to the vacuum can surround the electrodes, but usually the nude gauge is inserted in the vacuum chamber directly, the pins being fed through a ceramic plate in the wall of the chamber. Hot-cathode gauges can be damaged or lose their calibration if they are exposed to atmospheric pressure or even low vacuum while hot. The measurements of a hot-cathode ionization gauge are always logarithmic.

Electrons emitted from the filament move several times in back-and-forth movements around the grid before finally entering the grid. During these movements, some electrons collide with a gaseous molecule to form a pair of an ion and an electron (electron ionization). The number of these ions is proportional to the gaseous molecule density multiplied by the electron current emitted from the filament, and these ions pour into the collector to form an ion current. Since the gaseous molecule density is proportional to the pressure, the pressure is estimated by measuring the ion current.

The low-pressure sensitivity of hot-cathode gauges is limited by the photoelectric effect. Electrons hitting the grid produce x-rays that produce photoelectric noise in the ion collector. This limits the range of older hot-cathode gauges to 10 Torr and the Bayard–Alpert to about 10 Torr. Additional wires at cathode potential in the line of sight between the ion collector and the grid prevent this effect. In the extraction type the ions are not attracted by a wire, but by an open cone. As the ions cannot decide which part of the cone to hit, they pass through the hole and form an ion beam. This ion beam can be passed on to a:

There are two subtypes of cold-cathode ionization gauges: the Penning gauge (invented by Frans Michel Penning), and the inverted magnetron, also called a Redhead gauge. The major difference between the two is the position of the anode with respect to the cathode. Neither has a filament, and each may require a DC potential of about 4 kV for operation. Inverted magnetrons can measure down to 1  Torr.

Likewise, cold-cathode gauges may be reluctant to start at very low pressures, in that the near-absence of a gas makes it difficult to establish an electrode current - in particular in Penning gauges, which use an axially symmetric magnetic field to create path lengths for electrons that are of the order of metres. In ambient air, suitable ion-pairs are ubiquitously formed by cosmic radiation; in a Penning gauge, design features are used to ease the set-up of a discharge path. For example, the electrode of a Penning gauge is usually finely tapered to facilitate the field emission of electrons.

Maintenance cycles of cold cathode gauges are, in general, measured in years, depending on the gas type and pressure that they are operated in. Using a cold cathode gauge in gases with substantial organic components, such as pump oil fractions, can result in the growth of delicate carbon films and shards within the gauge that eventually either short-circuit the electrodes of the gauge or impede the generation of a discharge path.

When fluid flows are not in equilibrium, local pressures may be higher or lower than the average pressure in a medium. These disturbances propagate from their source as longitudinal pressure variations along the path of propagation. This is also called sound. Sound pressure is the instantaneous local pressure deviation from the average pressure caused by a sound wave. Sound pressure can be measured using a microphone in air and a hydrophone in water. The effective sound pressure is the root mean square of the instantaneous sound pressure over a given interval of time. Sound pressures are normally small and are often expressed in units of microbar.

The American Society of Mechanical Engineers (ASME) has developed two separate and distinct standards on pressure measurement, B40.100 and PTC 19.2. B40.100 provides guidelines on Pressure Indicated Dial Type and Pressure Digital Indicating Gauges, Diaphragm Seals, Snubbers, and Pressure Limiter Valves. PTC 19.2 provides instructions and guidance for the accurate determination of pressure values in support of the ASME Performance Test Codes. The choice of method, instruments, required calculations, and corrections to be applied depends on the purpose of the measurement, the allowable uncertainty, and the characteristics of the equipment being tested.

The methods for pressure measurement and the protocols used for data transmission are also provided. Guidance is given for setting up the instrumentation and determining the uncertainty of the measurement. Information regarding the instrument type, design, applicable pressure range, accuracy, output, and relative cost is provided. Information is also provided on pressure-measuring devices that are used in field environments i.e., piston gauges, manometers, and low-absolute-pressure (vacuum) instruments.

These methods are designed to assist in the evaluation of measurement uncertainty based on current technology and engineering knowledge, taking into account published instrumentation specifications and measurement and application techniques. This Supplement provides guidance in the use of methods to establish the pressure-measurement uncertainty.





</doc>
