<doc id="22133" url="https://en.wikipedia.org/wiki?curid=22133" title="Nuclear chain reaction">
Nuclear chain reaction

Nuclear chain reaction occurs when one single nuclear reaction causes an average of one or more subsequent nuclear reactions, thus leading to the possibility of a self-propagating series of these reactions. The specific nuclear reaction may be the fission of heavy isotopes (e.g., uranium-235, U). The nuclear chain reaction releases several million times more energy per reaction than any chemical reaction.

Chemical chain reactions were first proposed by German chemist Max Bodenstein in 1913, and were reasonably well understood before nuclear chain reactions were proposed. It was understood that chemical chain reactions were responsible for exponentially increasing rates in reactions, such as produced in chemical explosions.

The concept of a nuclear chain reaction was reportedly first hypothesized by Hungarian scientist Leó Szilárd on September 12, 1933. Szilárd that morning had been reading in a London paper of an experiment in which protons from an accelerator had been used to split lithium-7 into alpha particles, and the fact that much greater amounts of energy were produced by the reaction than the proton supplied. Ernest Rutherford commented in the article that inefficiencies in the process precluded use of it for power generation. However, the neutron had been discovered in 1932, shortly before, as the product of a nuclear reaction. Szilárd, who had been trained as an engineer and physicist, put the two nuclear experimental results together in his mind and realized that if a nuclear reaction produced neutrons, which then caused further similar nuclear reactions, the process might be a self-perpetuating nuclear chain-reaction, spontaneously producing new isotopes and power without the need for protons or an accelerator. Szilárd, however, did not propose fission as the mechanism for his chain reaction, since the fission reaction was not yet discovered, or even suspected. Instead, Szilárd proposed using mixtures of lighter known isotopes which produced neutrons in copious amounts. He filed a patent for his idea of a simple nuclear reactor the following year.

In 1936, Szilárd attempted to create a chain reaction using beryllium and indium, but was unsuccessful. Nuclear fission was discovered by Otto Hahn and Fritz Strassmann in December 1938 and explained theoretically in January 1939 by Lise Meitner and her nephew Otto Robert Frisch. A few months later, Frédéric Joliot-Curie, H. Von Halban and L. Kowarski in Paris searched for, and discovered, neutron multiplication in uranium, proving that a nuclear chain reaction by this mechanism was indeed possible.

On May 4, 1939, Joliot-Curie, Halban, and Kowarski filed three patents. The first two described power production from a nuclear chain reaction, the last one called "Perfectionnement aux charges explosives" was the first patent for the atomic bomb and is filed as patent No. 445686 by the Caisse nationale de Recherche Scientifique.

In parallel, Szilárd and Enrico Fermi in New York made the same analysis. This discovery prompted the letter from Szilárd and signed by Albert Einstein to President Franklin D. Roosevelt, warning of the possibility that Nazi Germany might be attempting to build an atomic bomb.

On December 2, 1942, a team led by Fermi (and including Szilárd) produced the first artificial self-sustaining nuclear chain reaction with the Chicago Pile-1 (CP-1) experimental reactor in a racquets court below the bleachers of Stagg Field at the University of Chicago. Fermi's experiments at the University of Chicago were part of Arthur H. Compton's Metallurgical Laboratory of the Manhattan Project; the lab was later renamed Argonne National Laboratory, and tasked with conducting research in harnessing fission for nuclear energy.

In 1956, Paul Kuroda of the University of Arkansas postulated that a natural fission reactor may have once existed. Since nuclear chain reactions may only require natural materials (such as water and uranium, if the uranium has sufficient amounts of U), it was possible to have these chain reactions occur in the distant past when uranium-235 concentrations were higher than today, and where there was the right combination of materials within the Earth's crust. Kuroda's prediction was verified with the discovery of evidence of natural self-sustaining nuclear chain reactions in the past at Oklo in Gabon in September 1972.

Fission chain reactions occur because of interactions between neutrons and fissile isotopes (such as U). The chain reaction requires both the release of neutrons from fissile isotopes undergoing nuclear fission and the subsequent absorption of some of these neutrons in fissile isotopes. When an atom undergoes nuclear fission, a few neutrons (the exact number depends on uncontrollable and unmeasurable factors; the expected number depends on several factors, usually between 2.5 and 3.0) are ejected from the reaction. These free neutrons will then interact with the surrounding medium, and if more fissile fuel is present, some may be absorbed and cause more fissions. Thus, the cycle repeats to give a reaction that is self-sustaining.

Nuclear power plants operate by precisely controlling the rate at which nuclear reactions occur. Nuclear weapons, on the other hand, are specifically engineered to produce a reaction that is so fast and intense it cannot be controlled after it has started. When properly designed, this uncontrolled reaction will lead to an explosive energy release.

Nuclear weapons employ high quality, highly enriched fuel exceeding the critical size and geometry (critical mass) necessary in order to obtain an explosive chain reaction. The fuel for energy purposes, such as in a nuclear fission reactor, is very different, usually consisting of a low-enriched oxide material (e.g. UO). There are two primary isotopes used for fission reactions inside of nuclear reactors. The first and most common is U-235 or uranium-235. This is the fissile isotope of uranium and it makes up approximately 0.7% of all naturally occurring uranium. Because of the small amount of uranium-235 that exists, it is considered a non-renewable energy source despite being found in rock formations around the world. U-235 cannot be used as fuel in its base form for energy production. It must undergo a process known as enrichment to produce the compound UO or uranium dioxide. The uranium dioxide is then pressed and formed into ceramic pellets, which can subsequently be placed into fuel rods. This is when the compound uranium dioxide can be used for nuclear power production. The second most common isotope used in nuclear fission is Pu-239 or plutonium-239. This is due to its ability to become fissile with slow neutron interaction. This isotope is formed inside nuclear reactors through exposing U-238 to the neutrons released by the radioactive U-235 isotope. This neutron capture causes beta particle decay that enables U-238 to transform into Pu-239. Plutonium was once found naturally in the earth's crust but only trace amounts remain. The only way it is accessible in large quantities for energy production is through the neutron capture method. 

The fissile isotope uranium-235 in its natural state is unfit for nuclear reactors. In order to be prepared for use as fuel in energy production, it must be enriched. The enrichment process does not apply to plutonium. Reactor-grade plutonium is created as a byproduct of neutron interaction between two different isotopes of uranium. The first step to enriching uranium begins by converting uranium oxide (created through the uranium milling process) into a gaseous form. This gas is known as uranium hexafluoride, which is created by combining hydrogen fluoride, fluorine gas, and uranium oxide. Uranium dioxide is also present in this process and it is sent off to be used in reactors not requiring enriched fuel. The remaining uranium hexafluoride compound is drained into strong metal cylinders where it solidifies. The next step is separating the uranium hexafluoride from the depleted U-235 left over. This is typically done with centrifuges that spin fast enough to allow for the 1% mass difference in uranium isotopes to separate themselves. A laser is then used to enrich the hexafluoride compound. The final step involves reconverting the now enriched compound back into uranium oxide, leaving the final product: enriched uranium oxide. This form of UO can now be used in fission reactors inside power plants to produce energy.

When a fissile atom undergoes nuclear fission, it breaks into two or more fission fragments. Also, several free neutrons, gamma rays, and neutrinos are emitted, and a large amount of energy is released. The sum of the rest masses of the fission fragments and ejected neutrons is less than the sum of the rest masses of the original atom and incident neutron (of course the fission fragments are not at rest). The mass difference is accounted for in the release of energy according to the equation "E"=Δ"mc":

Due to the extremely large value of the speed of light, "c", a small decrease in mass is associated with a tremendous release of active energy (for example, the kinetic energy of the fission fragments). This energy (in the form of radiation and heat) carries the missing mass, when it leaves the reaction system (total mass, like total energy, is always conserved). While typical chemical reactions release energies on the order of a few eVs (e.g. the binding energy of the electron to hydrogen is 13.6 eV), nuclear fission reactions typically release energies on the order of hundreds of millions of eVs.

Two typical fission reactions are shown below with average values of energy released and number of neutrons ejected:

Note that these equations are for fissions caused by slow-moving (thermal) neutrons. The average energy released and number of neutrons ejected is a function of the incident neutron speed. Also, note that these equations exclude energy from neutrinos since these subatomic particles are extremely non-reactive and, therefore, rarely deposit their energy in the system.

The prompt neutron lifetime, "l", is the average time between the emission of neutrons and either their absorption in the system or their escape from the system. The neutrons that occur directly from fission are called "prompt neutrons," and the ones that are a result of radioactive decay of fission fragments are called "delayed neutrons". The term lifetime is used because the emission of a neutron is often considered its "birth," and the subsequent absorption is considered its "death". For thermal (slow-neutron) fission reactors, the typical prompt neutron lifetime is on the order of 10 seconds, and for fast fission reactors, the prompt neutron lifetime is on the order of 10 seconds. These extremely short lifetimes mean that in 1 second, 10,000 to 10,000,000 neutron lifetimes can pass. The "average" (also referred to as the "adjoint unweighted") prompt neutron lifetime takes into account all prompt neutrons regardless of their importance in the reactor core; the "effective" prompt neutron lifetime (referred to as the "adjoint weighted" over space, energy, and angle) refers to a neutron with average importance.

The mean generation time, Λ, is the average time from a neutron emission to a capture that results in fission. The mean generation time is different from the prompt neutron lifetime because the mean generation time only includes neutron absorptions that lead to fission reactions (not other absorption reactions). The two times are related by the following formula:

In this formula, k is the effective neutron multiplication factor, described below.

The six factor formula effective neutron multiplication factor, "k", is the average number of neutrons from one fission that cause another fission. The remaining neutrons either are absorbed in non-fission reactions or leave the system without being absorbed. The value of "k" determines how a nuclear chain reaction proceeds:
When describing kinetics and dynamics of nuclear reactors, and also in the practice of reactor operation, the concept of reactivity is used, which characterizes the deflection of reactor from the critical state: ρ = ("k" − 1)/"k". InHour (from "inverse of an hour", sometimes abbreviated ih or inhr) is a unit of reactivity of a nuclear reactor.

In a nuclear reactor, "k" will actually oscillate from slightly less than 1 to slightly more than 1, due primarily to thermal effects (as more power is produced, the fuel rods warm and thus expand, lowering their capture ratio, and thus driving "k" lower). This leaves the average value of "k" at exactly 1. Delayed neutrons play an important role in the timing of these oscillations.

In an infinite medium, the multiplication factor may be described by the four factor formula; in a non-infinite medium, the multiplication factor may be described by the six factor formula.

Not all neutrons are emitted as a direct product of fission; some are instead due to the radioactive decay of some of the fission fragments. The neutrons that occur directly from fission are called "prompt neutrons," and the ones that are a result of radioactive decay of fission fragments are called "delayed neutrons". The fraction of neutrons that are delayed is called β, and this fraction is typically less than 1% of all the neutrons in the chain reaction.

The delayed neutrons allow a nuclear reactor to respond several orders of magnitude more slowly than just prompt neutrons would alone. Without delayed neutrons, changes in reaction rates in nuclear reactors would occur at speeds that are too fast for humans to control.

The region of supercriticality between "k" = 1 and "k" = 1/(1 − β) is known as delayed supercriticality (or delayed criticality). It is in this region that all nuclear power reactors operate. The region of supercriticality for "k" > 1/(1 − β) is known as prompt supercriticality (or prompt criticality), which is the region in which nuclear weapons operate.

The change in "k" needed to go from critical to prompt critical is defined as a dollar.

Nuclear fission weapons require a mass of fissile fuel that is prompt supercritical.

For a given mass of fissile material the value of "k" can be increased by increasing the density. Since the probability per distance travelled for a neutron to collide with a nucleus is proportional to the material density, increasing the density of a fissile material can increase "k". This concept is utilized in the implosion method for nuclear weapons. In these devices, the nuclear chain reaction begins after increasing the density of the fissile material with a conventional explosive.

In the gun-type fission weapon, two subcritical pieces of fuel are rapidly brought together. The value of "k" for a combination of two masses is always greater than that of its components. The magnitude of the difference depends on distance, as well as the physical orientation.

The value of "k" can also be increased by using a neutron reflector surrounding the fissile material

Once the mass of fuel is prompt supercritical, the power increases exponentially. However, the exponential power increase cannot continue for long since k decreases when the amount of fission material that is left decreases (i.e. it is consumed by fissions). Also, the geometry and density are expected to change during detonation since the remaining fission material is torn apart from the explosion.

Detonation of a nuclear weapon involves bringing fissile material into its optimal supercritical state very rapidly. During part of this process, the assembly is supercritical, but not yet in an optimal state for a chain reaction. Free neutrons, in particular from spontaneous fissions, can cause the device to undergo a preliminary chain reaction that destroys the fissile material before it is ready to produce a large explosion, which is known as predetonation.

To keep the probability of predetonation low, the duration of the non-optimal assembly period is minimized and fissile and other materials are used that have low spontaneous fission rates. In fact, the combination of materials has to be such that it is unlikely that there is even a single spontaneous fission during the period of supercritical assembly. In particular, the gun method cannot be used with plutonium (see nuclear weapon design).

Chain reactions naturally give rise to reaction rates that grow (or shrink) exponentially, whereas a nuclear power reactor needs to be able to hold the reaction rate reasonably constant. To maintain this control, the chain reaction criticality must have a slow enough time scale to permit intervention by additional effects (e.g., mechanical control rods or thermal expansion). Consequently, all nuclear power reactors (even fast-neutron reactors) rely on delayed neutrons for their criticality. An operating nuclear power reactor fluctuates between being slightly subcritical and slightly delayed-supercritical, but must always remain below prompt-critical.

It is impossible for a nuclear power plant to undergo a nuclear chain reaction that results in an explosion of power comparable with a nuclear weapon, but even low-powered explosions due to uncontrolled chain reactions (that would be considered "fizzles" in a bomb) may still cause considerable damage and meltdown in a reactor. For example, the Chernobyl disaster involved a runaway chain reaction but the result was a low-powered steam explosion from the relatively small release of heat, as compared with a bomb. However, the reactor complex was destroyed by the heat, as well as by ordinary burning of the graphite exposed to air. Such steam explosions would be typical of the very diffuse assembly of materials in a nuclear reactor, even under the worst conditions.

In addition, other steps can be taken for safety. For example, power plants licensed in the United States require a negative void coefficient of reactivity (this means that if water is removed from the reactor core, the nuclear reaction will tend to shut down, not increase). This eliminates the possibility of the type of accident that occurred at Chernobyl (which was due to a positive void coefficient). However, nuclear reactors are still capable of causing smaller explosions even after complete shutdown, such as was the case of the Fukushima Daiichi nuclear disaster. In such cases, residual decay heat from the core may cause high temperatures if there is loss of coolant flow, even a day after the chain reaction has been shut down (see SCRAM). This may cause a chemical reaction between water and fuel that produces hydrogen gas, which can explode after mixing with air, with severe contamination consequences, since fuel rod material may still be exposed to the atmosphere from this process. However, such explosions do not happen during a chain reaction, but rather as a result of energy from radioactive beta decay, after the fission chain reaction has been stopped.




</doc>
<doc id="22135" url="https://en.wikipedia.org/wiki?curid=22135" title="Nichiren">
Nichiren

Nichiren (日蓮; born as , Dharma name: "Rencho", 16 February 1222 – 13 October 1282) was a Japanese Buddhist priest of the Kamakura period (1185–1333), who developed the teachings of Nichiren Buddhism, a branch school of Mahayana Buddhism.

Nichiren declared that the Lotus Sutra alone contains the highest truth of Buddhist teachings suited for the Third Age of Buddhism. He advocated the repeated recitation of its title, "Nam(u)-myoho-renge-kyo" and held that Shakyamuni Buddha and all other Buddhist deities were extraordinary manifestations of a particular Buddha-nature termed “"Myoho—Renge"” that is equally accessible to all. He declared that believers of the Sutra must propagate it even under persecution.

Nichiren was a prolific writer and his biography, temperament, and the evolution of his beliefs has been gleaned primarily from his own writings. He considered himself a reincarnation of Jōgyō bodhisattva. After his death, he was bestowed the title "Nichiren Dai-Bosatsu" (日蓮大菩薩) ("Great Bodhisattva Nichiren") by Emperor Go-Kōgon (1358) and the title "Risshō Daishi" (立正大師) ("Great Teacher of Rectification") was conferred posthumously in year 1922 by imperial edict.
Today, Nichiren Buddhism includes traditional temple schools such as Nichiren-shu and Nichiren Shōshū, as well as lay movements such as Soka Gakkai, Risshō Kōsei Kai, Reiyūkai, Kenshōkai, Honmon Butsuryū-shū, Kempon Hokke, and Shōshinkai among many others. Each group has varying views of Nichiren's teachings with claims and interpretations of Nichiren's identity ranging from the rebirth of Bodhisattva Visistacaritra to the Primordial or "True Buddha" (本仏: "Honbutsu") of the Third Age of Buddhism.

The main narrative of Nichiren's life has been constructed from extant letters and treatises he wrote, counted in one collection as 523 complete writings and 248 fragments. Aside from historical documents stored in the repositories of various Nichiren sects, the first extensive non-religious biographical account of Nichiren did not appear until more than 200 years after his death.

He launched his teachings in 1253, advocating an exclusive return to the Lotus Sutra as based on its original Tendai interpretations. His 1260 treatise "Risshō Ankoku Ron" (立正安国論) ("On Establishing the Correct Teaching for the Peace of the Land") argued that a nation that embraces the Lotus Sutra will experience peace and prosperity whereas rulers who support inferior religious teachings invite disorder and disaster into their realms. In a 1264 essay, he stated that the title of the Lotus Sutra, ""Nam(u)-myoho-renge-kyo,"" encompasses all Buddhist teachings and its recitation leads to enlightenment. As a result of his adamant stance, he experienced severe persecution imposed by the Kamakura Shogunate and consequently began to see himself as "bodily reading the Lotus Sutra ("Jpn. Hokke shikidoku")." In some of his writings during a second exile (1271-1274) he began to identify himself with the key Lotus Sutra characters Sadāparibhūta and Visistacaritra and saw himself in the role of leading a vast outpouring of Bodhisattvas of the Earth.

In 1274, after his two predictions of foreign invasion and political strife were seemingly actualized by the first attempted Mongol invasion of Japan along with an unsuccessful coup within the Hōjō clan, Nichiren was pardoned by the Shogunate authorities and his advice was sought but not heeded. The "Risshō Ankoku Ron" in which he first predicted foreign invasion and civil disorder is now considered by Japanese historians to be a literary classic illustrating the apprehensions of that period. 

Several hagiographies about Nichiren and are reflected in various pieces of artwork about incidents in his life.

Nichiren remains a controversial figure among scholars who cast him as either a fervent nationalist or a social reformer with a transnational religious vision. Critical scholars have used words such as intolerant, nationalistic, militaristic, and self-righteous to portray him. On the other hand, Nichiren has been presented as a revolutionary, a classic reformer, and as a prophet. 
Nichiren is often compared to other religious figures who shared similar rebellious and revolutionary drives to reform degeneration in their respective societies or schools.

According to the lunar Chinese calendar, Nichiren was born on 27th of the first month in 1222, which is 16 February in the Gregorian calendar.

Nichiren was born in the village of Kominato (today part of the city of Kamogawa), Nagase District, Awa Province (within present-day Chiba Prefecture). Accounts of his lineage vary. Nichiren described himself as "the son of a "Sendara" ("Skt: chandala", despised outcast), "a son born of the lowly people living on a rocky strand of the out-of-the-way sea," and "the son of a sea-diver." In contrast, Hōnen, Shinran, Dōgen, and Eisai, the other founders of religious schools who predated Nichiren, were all born in the Kyoto region and came from noble or samurai backgrounds. Although his writings reflect a fierce pride of his lowly birth, followers after his death began to ascribe to him a more noble lineage, perhaps to attract more adherents. Some have claimed his father was a rōnin, a manorial functionary ("shokan"), or a political refugee.

Nichiren's father was Mikuni-no-Tayu Shigetada, also known as Nukina Shigetada Jiro (d. 1258) and his mother was Umegiku-nyo (d. 1267). On his birth, his parents named him which has variously been translated into English as "Splendid Sun" and "Virtuous Sun Boy" among others. The exact site of Nichiren's birth is believed to be currently submerged off the shore from present-day Kominato-zan Tanjō-ji (小湊山　誕生寺) near a temple in Kominato that commemorates his birth.

Between the years 1233 and 1253 Nichiren engaged in an intensive study of all of the ten schools of Buddhism prevalent in Japan at that time as well as the Chinese classics and secular literature. During these years, he became convinced of the preeminence of the "Lotus Sutra" and in 1253 returned to the temple where he first studied to present his findings.

In a 1271 letter Nichiren outlined his rationale for deeply studying Buddhism:

At the age of 12 he began his Buddhist study at a temple of the Tendai school, Seichō-ji (清澄寺, also called Kiyosumi-dera). He was formally ordained at sixteen years old and took the Buddhist name , "Renchō" meaning "Lotus Growth." He left Seichō-ji for Kamakura where he studied Pure Land Buddhism, a school that stressed salvation through nianfo (Japanese "nembutsu") or the invocation of Amitābha (Japanese "Amida"), and then studied Zen which had been growing in popularity in both Kamakura and Kyoto. He next traveled to Mount Hiei, the center of Japanese Tendai Buddhism, where he scrutinized the school's original doctrines and its subsequent incorporation of the theories and practices of Pure Land and Esoteric Buddhism. In the final stage of this twenty-year period he traveled to Mount Kōya, the center of Shingon esoteric Buddhism, and to Nara where he studied its six established schools, especially the Ritsu sect which emphasized strict monastic discipline.

According to one of his letters, Nichiren returned to Seicho-ji Temple on 28 April 1253 to lecture on his twenty years of scholarship. What followed was his first public declaration of "Nam(u) Myoho Renge Kyo" atop Mount Kiyosumi. This marked the start of his campaign to return Tendai to the exclusive reliance of the Lotus Sutra and his efforts to convert the entire Japanese nation to this belief. This declaration also marks the start of his efforts to make profound Buddhist theory practical and actionable so an ordinary person could manifest Buddhahood within his or her own lifetime in the midst of day-to-day realities.

At the same event, according to his own account and subsequent hagiography, he changed his name to "Nichiren", an abbreviation of "Nichi" (日 "Sun") and "Ren" (蓮 "Lotus"). "Nichi" represents both the light of truth and the sun goddess Amaterasu, symbolizing Japan itself. "Ren" signifies the Lotus Sutra. Nichiren envisioned Japan as the country where the true teaching of Buddhism would be revived and the starting point for its worldwide spread.

At his lecture, it is construed, Nichiren vehemently attacked Honen, the founder of Pure Land Buddhism, and its practice of chanting the Nembutsu, "Nam(u) Amida Butsu". It is likely he also denounced the core teachings of Seicho-ji which had incorporated non-exclusive Lotus Sutra teachings and practices. In so doing he earned the animosity of the local steward, Hojo Kagenobu, who attempted to have Nichiren killed. Modern scholarship suggests that events unfolded not in a single day but over a longer period of time and had social, and political dimensions.

Nichiren then developed a base of operation in Kamakura where he converted several Tendai priests, directly ordained others, and attracted lay disciples who were drawn mainly from the strata of the lower and middle samurai class. Their households provided Nichiren with economic support and became the core of Nichiren communities in several locations in the Kanto region of Japan.

Nichiren arrived in Kamakura in 1254. Between 1254 and 1260 half of the population had perished due to a tragic succession of calamities that included drought, earthquakes, epidemics, famine, fires, and storms. Nichiren sought scriptual references to explain the unfolding of natural disasters and then wrote a series of works which, based on the Buddhist theory of the non-duality of the human mind and the environment, attributed the sufferings to the weakened spiritual condition of people, thereby causing the "Kami" (protective forces or traces of the Buddha) to abandon the nation. The root cause of this, he argued, was the widespread decline of the Dharma due to the mass adoption of the Pure Land teachings.

The most renowned of these works, considered his first major treatise, was the "Risshō Ankoku Ron" (立正安国論), "On Securing the Peace of the Land through the Propagation of True Buddhism." Nichiren submitted it to Hōjō Tokiyori, the "de facto" leader of the Kamakura shogunate, as a political move to effectuate radical reform. In it he argued the necessity for "the Sovereign to recognize and accept the singly true and correct form of Buddhism (i.e., 立正: "risshō") as the only way to achieve peace and prosperity for the land and its people and end their suffering (i.e., 安国: "ankoku")."

Using a dialectic form well-established in China and Japan, the treatise is a 10-segment fictional dialogue between a Buddhist wise man, presumably Nichiren, and a visitor who together lament the tragedies that have beleaguered the nation. The wise man answers the guest's questions and, after a heated exchange, gradually leads him to enthusiastically embrace the vision of a country grounded firmly on the ideals of the Lotus Sutra. In this writing Nichiren displays a skill in using analogy, anecdote, and detail to persuasively appeal to an individual's unique psychology, experiences, and level of understanding.

The teacher builds his argument by quoting extensively from a set of Buddhist sutras and commentaries. In his future writings Nichiren continued to draw from the same sutras and commentaries, effectively forming Nichiren's canon of sources out of the Buddhist library which he deemed supportive of the Lotus Sutra including the Konkomyo, Daijuku, Ninno, Yakushi, and Nirvana sutras. They share in common apocalyptic or nation-protecting teachings and prophecies.

The "Risshō Ankoku Ron" concludes with an urgent appeal to the ruler to cease all financial support for Buddhist schools promoting inferior teachings. Otherwise, Nichiren warns, as predicted by the sutras, the continued influence of inferior teachings would invite even more natural disasters as well as the outbreak of civil strife and foreign invasion.

Nichiren submitted his treatise on 16 July 1260 but it drew no official response. It did, however, prompt a severe backlash from the Buddhist priests of other schools. Nichiren was challenged to a religious debate with leading Kamakura prelates in which, by his account, they were swiftly dispatched. Their lay followers, however, attempted to kill him at his dwelling which forced him to flee Kamakura. His critics had influence with key governmental figures and spread slanderous rumors about him. One year after he submitted the "Rissho Ankoku Ron" the authorities had him arrested and exiled to the Izu peninsula.

Nichiren's Izu exile lasted two years. In his extant writings from this time period, Nichiren began to strongly draw from chapters 10-22 of the Lotus Sutra, what Tanabe calls its "third realm" "(daisan hōmon)". Nichiren began to emphasize the purpose of human existence as being the practice of the bodhisattva ideal in the real world which entails undertaking struggle and manifesting endurance. He suggested that he is a model of this behavior, a "votary" ("gyōja") of the Lotus Sutra.

Upon being pardoned in 1263 Nichiren returned to Kamakura. In November 1264 he was ambushed and nearly killed at Komatsubara in Awa Province by a force led by Lord Tōjō Kagenobu. For the next few years he preached in provinces outside of Kamakura but returned in 1268. At this point the Mongols sent envoys to Japan demanding tribute and threatening invasion. Nichiren sent 11 letters to influential leaders reminding them about his predictions in the "Rissho Ankoku Ron".

The threat and execution of Mongol invasion was the worst crisis in pre-modern Japanese history. In 1269 Mongol envoys again arrived to demand Japanese submission to their hegemony and the "bakufu" responded by mobilizing military defenses.

The role of Buddhism in "nation-protection" ("chingo kokka") was long established in Japan at this time and the government galvanized prayers from Buddhist schools for this purpose. Nichiren and his followers, however, felt emboldened that the predictions he had made in 1260 of foreign invasion seemingly were being fulfilled and more people joined their movement. Daring a rash response from the "bakufu", Nichiren vowed in letters to his followers that he was giving his life to actualize the Lotus Sutra. He accelerated his polemics against the non-Lotus teachings the government had been patronizing at the very time it was attempting to solidify national unity and resolve. In a series of letters to prominent leaders he directly provoked the major prelates of Kamakura temples that the Hojo family patronized, criticized the principles of Zen which was popular among the samurai class, critiqued the esoteric practices of Shingon just as the government was invoking them, and condemned the ideas underlying Risshū as it was enjoying a revival. His actions at that time have been described by modern scholars either as a high form of altruisim or the ravings of a fanatic and madman.

His claims drew the ire of the influential religious figures of the time and their followers, especially the Shingon priest Ryōkan (良観). In September 1271, after a fiery exchange of letters between the two, Nichiren was arrested by a band of soldiers and tried by Hei no Saemon (平の左衛門, also called 平頼綱 "Taira no Yoritsuna"), the deputy chief of the Hojo clan's Board of Retainers. Nichiren considered this as his second remonstration to the government.

According to Nichiren's own account, he was sentenced to exile but was brought to Tatsunukuchi beach in Shichirigahama for execution. At the final moment an astronomical phenomenon, "a brilliant orb as bright as the moon," arced over the execution grounds, terrifying Nichiren's executioners into inaction. Some scholars have proposed alternative narratives for this story.

Regardless of the account, Nichiren's life was spared and he was exiled to Sado Island. The incident has become known as the "Tatsunokuchi Persecution" and was regarded by Nichiren as a death-and-resurrection turning point. In the Nichiren tradition this is called his moment of "Hosshaku kenpon" (発迹顕本), translated as "casting off the transient and revealing the true" or "outgrowing the provisional and revealing the essential."

After the failed execution authorities carried out Nichiren's original sentence of exile to Sado Island in the Sea of Japan. Upon arriving, he was dispatched to a small dilapidated temple located in a graveyard. Nichiren was accompanied by a few disciples and in the first winter they endured terrible cold, food deprivation, and threats from local inhabitants.
Nichiren scholars describe a clear shift in both tone and message in letters written before his Sado exile and those written during and after. Initially, Nichiren's urgent concern was to rally his followers in Kamakura. The tactics of the "bakufu" suppression of the Nichiren community included exile, imprisonment, land confiscation, or ousting from clan membership. Apparently a majority of his disciples abandoned their faith and others questioned why they and Nichiren were facing such adversity in light of the Lotus Sutra's promise of "peace and security in the present life."

In response he began to identify himself with Sadāparibhūta, a key figure in the Lotus Sutra, who in the 20th chapter invited repeated persecution in his efforts to propagate the sutra. Such hardship, Nichiren argued, fulfilled and validated the Lotus Sutra. He also identified himself with the bodhisattva Visistacaritra to whom Shakyamuni entrusted the future propagation of the Lotus Sutra, seeing himself in the role of leading a vast outpouring of Bodhisattvas of the Earth who pledged to liberate the oppressed.

The numerous letters and minor treatises he wrote in Sado include what is considered his two most significant works, the "Kanjin no Honzon Shō" (観心本尊抄: "The Object of Devotion for Observing the Mind") and the "Kaimoku Shō" (開目抄: "On the Opening of the Eyes"). In the latter he stated that facing adversity should be regarded as a matter of course and that the resolve to carry on with the mission to propagate the sutra was for him more important than guarantees of protection: "Let Heaven forsake me. Let ordeals confront me. I will not begrudge bodily life... . No matter what trials we may encounter, so long as we do not have a mind of doubt, I and my disciples will naturally achieve the Buddha realm." He concluded this work with the vow to be the "pillar of Japan, the eyes of Japan, the great ship of Japan."

At the end of the 1271-1272 winter Nichiren's conditions had improved. He had attracted a small band of followers in Sado who provided him with support and disciples from the mainland began visiting him and providing supplies. In 1272 there was an attempted coup in Kamakura and Kyoto, seemingly fulfilling the prediction he had made in the "Rissho Ankoku Ron" of rebellion in the domain. At this point Nichiren was transferred to much better accommodations.

While on Sado island, Nichiren inscribed the first Mandala "Gohonzon" (御本尊). Although there is evidence of a Gohonzon in embryonic form as far back as the days right before his exile, the first in full form is dated to July 8, 1273 and includes the inscription of "Nichiren inscribes this for the first time."

His writings on Sado provide his rationale for a calligraphic mandala depicting the assembly at Eagle Peak which was to be used as an object of devotion or worship. By increasingly associating himself with Visistacaritra he implied a direct link to the original and universal Buddha. He read in the 16th ("Life span") chapter of the Lotus Sutra a three-fold "secret Dharma" of the "daimoku", the object of worship ("honzon"), and the ordination platform ("kaidan"). These became the means for people to directly access the Buddha's enlightenment.

At the bottom of each mandala he wrote: "This is the great mandala never before revealed in Jambudvipa during the more than 2,200 years since the Buddha's nirvana." He inscribed many Mandala Gohonzon during the rest of his life. More than a hundred Mandala Gohonzon preserved today are attributed to Nichiren's own hand.

Nichiren was pardoned on February 14, 1274 and returned to Kamakura one month later on March 26. Nichiren wrote that his innocence and the accuracy of his predictions caused the regent Hōjō Tokimune to intercede on his behalf. Scholars have suggested that some of his well-connected followers might have had influence on the government's decision to release him.

On April 8 he was summoned by Hei no Saemon, who inquired about the timing of the next Mongol invasion. Nichiren predicted that it would occur within the year. He used the audience as yet another opportunity to remonstrate with the government. Claiming that reliance on prayers based on esoteric rituals would invite further calamity, he urged the "bakufu" to ground itself exclusively on the Lotus Sutra.

Deeply disappointed by the government's refusal to heed his advice, Nichiren left Kamakura one month later, on May 12, determined to become a solitary wayfarer. Five days later, however, on a visit to the residence of Lord Hakii Sanenaga of Mt. Minobu, he learned that followers in nearby regions had held steadfast during his exile. Despite severe weather and deprivation, Nichiren remained in Minobu for the rest of his career.

During his self-imposed exile at Mount Minobu, a location 100 miles west of Kamakura, Nichiren led a widespread movement of followers in Kanto and Sado mainly through his prolific letter-writing. During the so-called "Atsuhara affair" of 1279 when governmental attacks were aimed at Nichiren's followers rather than himself, Nichiren's letters reveal an assertive and well-informed leader who provided detailed instructions through a sophisticated network of disciples serving as liaisons between Minobu and other affected areas in Japan. He also showed the ability to provide a compelling narrative of events that gave his followers a broad perspective of what was unfolding.

More than half of the extant letters of Nichiren were written during his years at Minobu. Some consisted of moving letters to followers expressing appreciation for their assistance, counseling on personal matters, and explaining his teachings in more understandable terms. Two of his works from this period, the "Senji Shō" (撰時抄: "The Selection of the Time") and the "Hōon Shō" (報恩抄: "On Repaying Debts of Gratitude") constitute, along with his "Risshō Ankoku Ron" (立正安国論: "On Establishing the Correct Teaching for the Peace of the Land"), "Kaimoku Shō" ("The Opening of the Eyes"), and "Kanjin no Honzon Shō" ("The Object of Devotion for Observing the Mind"), what is commonly regarded as his five major writings.

During his years at Minobu Nichiren intensified his attacks on mystical and esoteric practices (mikkyō 密教) that had been incorporated into the Japanese Tendai school. It becomes clear at this point that he understood that he was creating his own form of Lotus Buddhism.

Nichiren and his disciples completed the Myō-hōkke-in Kuon-ji Temple (久遠寺) in 1281. In the 19th century this structure burned down to be replaced by a new structure completed in the second half of the Meiji era.

While at Minobu Nichiren also inscribed numerous Mandala Gohonzon for bestowal upon specific disciples and lay believers. Nichiren Shoshu believers claim that after the execution of the three Atsuhara farmers he inscribed the "Dai Gohonzon" on October 12, 1279, a Gohonzon specifically addressed to all humanity. This assertion has been disputed by other schools as historically and textually incorrect. It is enshrined currently at the "Tahō Fuji Dai-Nichirenge-Zan Taiseki-ji", informally known as the "Head Temple Taiseki-ji" of the Nichiren Shōshū Order of Buddhism, located at the foot of Mount Fuji in Fujinomiya, Shizuoka. Several of these Mandala Gohonzon are prominently retained by the Nichiren-shū in Yamanashi Prefecture. Others survive today in the repositories of Nichiren Shōshū temples such as Taiseki-ji (大石寺) in Fujinomiya, Shizuoka, which has a particularly large collection of scrolls that is publicly aired once a year.

It is apparent that Nichiren took great care in deciding which of his disciples were eligible to receive a Gohonzon inscribed by him. In the case of a letter written to Lady Niiama he took great care to explain why he would not inscribe a Gohonzon despite a deep personal bond. Among the Gohonzon he inscribed were several that were quite large and perhaps intended for congregational use in chapels maintained by some lay followers.

In 1282, after years of privation, Nichiren fell ill. His followers encouraged him to travel to the hot springs for their medicinal benefits. En route, unable to travel further, he stopped at the home of a disciple in Ikegami, outside of present-day Tokyo, and died on 13 October 1282. According to legend, he died in the presence of fellow disciples after having spent several days lecturing from his sickbed on the Lotus Sutra, writing a final letter, and leaving instructions for the future of his movement after his death, namely the designation of the six senior disciples. His funeral and cremation took place the following day.

His disciples left Ikegami with Nichiren's ashes on October 21, reaching back to Minobu on October 25.


Nichiren's teachings developed over the course of his career and their evolution can be seen through the study of his writings as well as in the annotations he made in his personal copy of the Lotus Sutra, the so-called "Chū-hokekyō".

Some scholars set a clear demarcation in his teachings at the time he arrived at Sado Island whereas others see a threefold division of thought: up to and through the Izu exile, from his return to Kamakura through the Sado Island exile, and during his years at Minobu.

According to Anesaki, Nichiren, upon his arrival at Minobu, quickly turned his attention to consolidating his teachings toward their perpetuation. The scope of his thinking was outlined in an essay "Hokke Shuyō-shō" [法華取要抄, "Choosing the Heart of the Lotus Sutra"], considered by Nikkō Shōnin as one of Nichiren's ten major writings.

Anesaki also claims that later during his Minobu years, in lectures he is said to have transmitted to his disciples, Nichiren summarized the key ideas of his teachings in one paragraph: Buddhahood is eternal, all people can and should manifest it in their lives; Nichiren is the personage in the Lotus Sutra whose mission it is to enable people to realize their enlightenment; his followers who share his vow are the Bodhisattvas of the Earth. This requires a spiritual and moral unity among followers based on their inherent Buddhahood; Nichiren established the seeds of this community and his followers to come must extend it globally. Thus the enlightened individual, country, and world are different expressions of the ideal of the Buddha land; and the enlightened heart of the individual plays out its role with the world and cosmos as its stage. This is Nichiren's vision of "Kosen-rufu", a time when the teachings of the Lotus Sutra would be widely spread throughout the world.

Nichiren set a precedent for Buddhist social activism centuries before its emergence in other Buddhist schools. The uniqueness of his teachings was his attempt to move Buddhism from the theoretical to the actualizable. He held adamantly that his teachings would permit a nation to right itself and ultimately lead to world peace.

Some of his religious thinking was derived from the Tendai understanding of the Lotus Sutra, syncretic beliefs that were deeply rooted in the culture of his times, and new perspectives that were products of Kamakura Buddhism. Other ideas were completely original and unique to him.

Nichiren was a product of his times and some of his teachings were drawn from existing schools of thought or from emerging ideas in Kamakura Buddhism. Nichiren appropriated and expanded on these ideas.

Nichiren stressed the concept of immanence, meaning that the Buddha's pure land is to be found in this present world ("shaba soku jakkōdo"). Related concepts such as attaining enlightenment in one's current form ("sokushin jōbutsu") and the belief that enlightenment is not attained but is originally existing within all people ("hongaku") had been introduced by Kūkai and Saicho several centuries earlier. These concepts were based on Chih-i's cosmology of the unity and interconnectedness of the universe called Three Thousand Realms in a Single Moment of Life ("ichinen sanzen").

Nichiren advanced these concepts by declaring that they were actualizable rather than theoretical. Cause and effect were simultaneous instead of linear. Contemplation of one's mind ("kanjin") took place within the singular belief in and commitment to the Lotus Sutra. According to Nichiren these phenomena manifest when a person chants the title of the Lotus Sutra ("date") and shares its validity with others, even at the cost of one's life if need be.

Nichiren constructed a triad relationship between faith, practice, and study. Faith meant embracing his new paradigm of the Lotus Sutra. It was something that needed to be continually deepened. "To accept ("ju") [faith in the sutra] is easy," he explained to a follower, "to uphold it ("ji") is difficult. But the realization of Buddhahood lies in upholding [faith]." This could only be manifested by the practice of chanting the "daimoku" as well as teaching others to do the same, and study.

Consequently, Nichiren consistently and vehemently objected to the perspective of the Pure Land school that stressed an other-worldly aspiration to some pure land. Behind his assertion is the concept of the nonduality of the subjective realm (the individual) and the objective realm (the land that the individual inhabits) which indicates that when the individual taps buddhahood, his or her present world becomes peaceful and harmonious. For Nichiren the widespread propagation of the Lotus Sutra and consequent world peace (""kosen-rufu"") was achievable and inevitable and tasked his future followers with a mandate to accomplish it.

The Kamakura period of 13th century Japan was characterized by a sense of foreboding. Nichiren, as well as the others of this time, believed that they had entered the Latter Day of the Law ("Mappō"), the time which Shakyamuni predicted his teachings would lose their efficacy. Indeed, Japan had entered an era of extreme natural disasters, internal strife and political conflict.

Although Nichiren attributed the turmoils and disasters in society to the widespread practice of what he deemed inferior Buddhist teachings that were under government sponsorship, he was enthusiastically upbeat about the portent of the age. He asserted, in contrast to other Mahayana schools, this was the best possible moment to be alive, the era in which the Lotus Sutra was to spread, and the time in which the Bodhisattvas of the Earth would appear to propagate it. "It is better to be a leper who chants Nam(u)-myōhō-renge-kyō than be a chief abbot of the Tendai school."
The tradition of conducting open and sustained debate to clarify matters of fundamental Buddhist principles has deep-seated roots in Tibet, China, and Korea. This tradition was also quite pronounced in Japan.

In addition to formalized religious debates, the Kamakura period was marked by flourishing and competitive oral religious discourse. Temples began to compete for the patronage of the wealthy and powerful through oratorical sermonizing and temple lecturers ("kōshi") faced pressure to attract crowds. Sermonizing spread from within the confines of temples to homes and the streets as wandering mendicants ("shidōso", "hijiri", or "inja") preached to both the educated and illiterate in exchange for alms. In order to teach principles of faith preachers incorporated colorful storytelling, music, vaudeville, and drama—which later evolved into Noh.

A predominant topic of debate in Kamakura Buddhism was the concept of rebuking "slander of the Dharma." The Lotus Sutra itself strongly warns about slander of the Dharma. Hōnen, in turn, employed harsh polemics instructing people to “discard” ("sha" 捨), “close” ("hei" 閉), “put aside” ("kaku" 閣), and “abandon” ("hō" 抛) the Lotus Sutra and other non-Pure Land teachings. His ideas were vociferously attacked by many including Nichiren.

Nichiren, however, elevated countering slander of the Dharma into a pillar of Buddhist practice. In fact, far more of his extant writings deal with the clarification of what constitutes the essence of Buddhist teachings than expositions of how to meditate.

At age 32, Nichiren began a career of denouncing other Mahayana Buddhist schools of his time and declaring what he asserted was the correct teaching, the Universal Dharma ("Nam(u)-Myōhō-Renge-Kyō"), and chanting its words as the only path for both personal and social salvation. The first target of his polemics was Pure Land Buddhism which had begun to gain ascendancy among the leaders and populace and even had established itself within the Tendai school. Nichiren's detailed rationale is most famously articulated in his : "Treatise On Establishing the Correct Teaching for the Peace of the Land," his first major treatise and the first of his three remonstrations with the "bakufu" authorities.

Although his times were harsh and permeated by "bakufu" culture, Nichiren always chose the power of language over bearing arms or resorting to violence. He didn't mince his words and was relentless to pursue dialogue whether in the form of debate, conversations, or correspondence. His spirit of engaging in discourse is captured in his statement, "Whatever obstacles I may encounter, as long as men [persons] of wisdom do not prove my teachings to be false, I will never yield."

Hōnen introduced the concept of "single practice" Buddhism. Basing himself on the writings of the Chinese Buddhist Shandao, he advocated the singular practice of Nianfo, the recitation of the Buddha Amida's name. This practice was revolutionary because it was accessible to all and minimalized the monopolistic role of the entire monastic establishment.

Nichiren appropriated the structure of a universally accessible single practice but substituted the Nianfo with the daimoku of "Nam(u)-myōhō-renge-kyō". This constituted renouncing the principle of aspirating to a Pure Land after death and asserting instead the Lotus perspective of attaining Buddhahood in one's present form in this lifetime.

Japan had a long-established system of folk beliefs that existed outside of and parallel to the schools of the Buddhist establishment. Many of these beliefs had an influence on the various religious schools which, in turn, influenced each other, a phenomenon known as syncretism. Among these beliefs were the existence of "kami", indigenous gods and goddesses or protective forces, that influenced human and natural occurrences in a holistic universe. Some beliefs ascribed "kami" to traces of the Buddha. The belief in "kami" was deeply embedded in the episteme of the time. Human agency through prayers and rituals could summon forth "kami" who would engage in nation-protection ("chingo kokka").

According to some of his accounts, Nichiren undertook his study of Buddhism to largely understand why the "kami" had seemingly abandoned Japan, as witnessed by the decline of the imperial court. Because the court and the people had turned to teachings that had weakened their minds and resolve, he came to conclude, both people of wisdom and the protective forces had abandoned the nation.

By extension, he argued, through proper prayer and action his troubled society would transform into an ideal world in which peace and wisdom prevail and "the wind will not thrash the branches nor the rain fall hard enough to break clods."

From Nichiren's corpus appear several lines of unique Buddhist thought.

Developed during his Izu exile, the Five Guides ("gogi") are five criteria through which Buddhist teachings can be evaluated and ranked. They are the quality of the teaching (kyō), the innate human capacity ("ki") of the people, the time ("ji"), the characteristic of the land or country ("koku"), and the sequence of dharma propagation ("kyōhō rufu no zengo"). From these five interrelated perspectives Nichiren declared his interpretation of the Lotus Sutra as the supreme teaching.

Throughout his career Nichiren harshly denounced Buddhist practices other than his own as well as the existing social and political system. The tactic he adopted was "shakubuku," conversion, in which he shocked his adversaries with his denunciations while attracting followers through his outward display of supreme confidence. Modern detractors criticize his exclusivist single-truth perspective as intolerant. Apologists argue his arguments should be understood in the context of his samurai society and not through post-modern lenses such as tolerance. Both of them may be regarded as having seized an aspect of the truth, namely that Nichiren, rather like Dogen, was not less brilliantly original for being a rigid dogmatist in doctrine. 

As his career advanced, Nichiren's vehement polemics against Pure Land teachings came to include sharp criticisms of the Shingon, Zen, and Ritsu schools of Buddhism. Collectively his criticisms have become known as "the Four Denunciations." Later in his career he critiqued the Japanese Tendai school for its appropriation of Shingon elements. Reliance on Shingon rituals, he claimed, was magic and would decay the nation. He held that Zen was devilish in its belief that attaining enlightenment was possible without relying on the Buddha's words; Ritsu was thievery because it hid behind token deeds such as public works. In modern parlance the Four Denunciations rebuked thinking that demoralized and disengaged people by encouraging resignation and escapism.

Nichiren deemed the world to be in a degenerative age and believed that people required a simple and effective means to rediscover the core of Buddhism and thereby restore their spirits and times. He described his Three Great Secret Laws ("Sandai hiho") as this very means.

In a writing entitled "Sandai Hiho Sho", or "On the Transmission of the Three Great Secret Laws", Nichiren delineated three teachings in the heart of the 16th chapter of the Lotus Sutra which are secret because he claimed he received them as the leader of the Bodhisattvas of the Earth through a silent transmission from Shakyamuni. They are the invocation ("daimoku"), the object of worship ("honzon"), and the platform of ordination or place of worship ("kaidan").

The "daimoku", the rhythmic chanting of Nam(u)-myōhō-renge-kyō is the means to discover that one's own life, the lives of others, and the environment is the essence of the Buddha of absolute freedom. The chanting is to be done while contemplating the "honzon". At the age of 51, Nichiren inscribed his own Mandala Gohonzon, the object of veneration or worship in his Buddhism, "never before known," as he described it. The Gohonzon is a calligraphic representation of the cosmos and chanting "daimoku" to it is Nichiren's method of meditation to experience the truth of Buddhism. He believed this practice was efficacious, simple to perform, and suited to the capacity of the people and the time.

Nichiren describes the first two secret laws in numerous other writings but the reference to the platform of ordination appears only in the "Sandai Hiho Sho", a work whose authenticity has been questioned by some scholars. Nichiren apparently left the fulfillment of this secret Dharma to his successors and its interpretation has been a matter of heated debate. Some state that it refers to the construction of a physical national ordination platform sanctioned by the emperor; others contend that the ordination platform is the community of believers ("sangha") or, simply, the place where practitioners of the Lotus Sutra live and make collective efforts to realize the ideal of establishing the true Dharma in order to establish peace to the land ("rissho ankoku"). The latter conception entails a robust interplay between religion and secular life and an egalitarian structure in which people are dedicated to perfecting an ideal society.

According to Nichiren, practicing the Three Secret Laws results in the "Three Proofs" which verify their validity. The first proof is "documentary," whether the religion's fundamental texts, here the writings of Nichiren, make a lucid case for the eminence of the religion. "Theoretical proof" is an intellectual standard of whether a religion's teachings reasonably clarify the mysteries of life and death. "Actual proof," deemed the most important by Nichiren, demonstrates the validity of the teaching through the actual improvements achieved by practitioners in their daily lives.

Nichiren was deeply aware of the karmic struggles his followers faced in their day-to-day existence and assured them that they could "cross the sea of suffering" ("Shiji Shiro-dono gosho"). Through prevailing over such challenges, he taught, they would establish a sense of inner freedom, peace of mind, and understanding of the Dharma that persisted independent of the ups and downs of sentient existence. He accepted prevailing Buddhist notions about karma that taught that a person's current conditions were the cumulative effect of past thoughts, words, and actions. He showed little concern, however, for attributing current circumstances to supposed past deeds. Rather, he viewed karma through the lens of the teachings of the Lotus Sutra which could enable all people to become Buddhas, even the ignorant and evil people of the Latter Day of the Law.

When confronting karmic situations, the act of chanting Nam(u)-myoho-renge-kyo would open the wisdom of the Buddha, transforming karma into mission and a creative and joy-filled way of life. Beyond the sphere of a single individual's life, the process would awaken a person's concern for the broader society and sense of social responsibility.

Nichiren introduced the term "votary of the Lotus Sutra" ("Hokekyō no gyōja") to describe himself. The Lotus Sutra itself speaks of the great trials that will be faced by individuals who base themselves on its teachings and attempt to spread it. Nichiren claims he read the sutra "bodily" ("shikidoku"), voluntarily inviting the entailing hardships it predicts rather than just reciting or meditating on its words.

Through challenging these persecutions Nichiren claimed to have discovered his personal mission and felt great joy even when experiencing the harshness of exile. His sufferings became, in his thinking, redemptive opportunities to change his karma and give his life transcendent meaning.

In enduring severe persecutions Nichiren claimed that the negative karma he had accumulated from the past could be eradicated quickly in his current life. He was an active agent in this process, not a victim. He even expressed appreciation to his tormentors for giving him the opportunity to serve as an envoy of the Buddha.
In letters to some of his followers Nichiren extended the concept of meeting persecution for the sake of propagating the Dharma to experiencing tribulations in life such as problems with family discord or illness. He encouraged these followers to take ownership of such life events, view them as opportunities to repay karmic debts and mitigate them in shorter periods of time than would otherwise be the case. Naturally, he did not use language redolent of twentieth century concepts within, e.g., psychotherapy, hyperliberalism or the Human Potential Movement, but his insistence on personal responsibility can be reimagined in such terms. 

Nichiren reached a state of conviction that offered a new perspective on karma. He express that his resolve to carry out his mission was paramount in importance and that the Lotus Sutra's promise of a peaceful and secure existence meant finding joy and validation in the process of overcoming karma. According to Stone, in confronting karma Nichiren "demonstrated an attitude that wastes little energy in railing against it but unflinchingly embraces it, interpreting it in whatever way appears meaningful at the moment so as to use that suffering for one's own development and to offer it on behalf of others."

Nichiren's teachings are replete with vows he makes for himself and asks his followers to share as well. Some are personal in nature such as frequent admonitions for people to transform their inner lives. "You must quickly reform the tenets you hold in your heart," he stated in his treatise "Rissho Ankoku Ron". He urged his followers to attain "treasures of the heart" and to reflect on their behavior as human beings. These vows are "this-worldly" rather than theoretical and are matched with an easily accessible practice.

Nichiren also made a "great vow" of a political dimension. He and his followers to come would create the conditions that lead to a just nation and world which the Lotus Sutra describes as "Kosen-rufu". In earlier Japanese Buddhism the concept of "nation" was equated with Tennō (天皇), or imperial rule and "peace of the land" was associated with the stability of the regime. Nichiren's teachings, however, fully embraced a newly emerging viewpoint in medieval Japan that "nation" referred to the land and the people. Nichiren was unique among his contemporaries in charging the actual government in power, in this case the "bakufu" rather than the throne, with the peace of the land as well as the thriving of the Dharma. In his teachings based on the Lotus Sutra, all human beings are equal, whether the nation's sovereign or an unknown commoner. Enlightenment is not restricted to an individual'

s inner life but is actualized by efforts toward the transformation of the land and the realization of an ideal society.

This entails an urgent mandate. Nichiren links the great vow of personages in the Lotus Sutra to raise all people to the consciousness of the Buddha, to his own single-minded struggles to teach the Law despite the great persecutions he, Nichiren himself, encountered, to his injunction to future disciples to create the Buddha land in the "saha" world over the course of the myriad years to follow.

Nichiren was a charismatic leader who attracted many followers during both his missionary trips and his exiles. Most of these followers were warriors and feudal lords. He maintained to his women followers that they were equally able to attain enlightenment. He set a high standard of leadership and, in his writings, shared his rationale and strategies with them, openly urging them to share his conviction and struggles.

He left the fulfillment of the "kaidan", the third of his Three Secret Dharmas, to his disciples. His many extant letters demonstrate the scope and breadth of his relationship with them and his expectations for them. They recognized and trusted his charismatic leadership and his understanding of Buddhism. Many sought his guidance to overcome personal problems. Many were actively involved with supporting him financially and protecting his community of followers. Several of disciples were praised by him for sharing in his privations and a few lost their lives in these situations. Although over the centuries the movement he established was fraught with divisions, his followers sustained his teachings and example and various times gained considerable influence. Today his followers are found in influential lay movements as well as traditional Nichiren schools.

The relationship between Nichiren and his disciples has been called "shitei funi", the oneness of mentor and disciple. Although the functions of the mentor and disciple may vary, they share the same goals and the same responsibility. Nichiren claimed the precedent for "shitei funi" is a core theme of the Lotus Sutra, especially in chapters 21 and 22 where the Buddha entrusts the future propagation of the sutra to the gathered bodhisattvas.

After Nichiren's death, his teachings were interpreted in different ways. As a result, Nichiren Buddhism encompasses several major branches and schools, each with its own doctrine and set of interpretations of Nichiren's teachings.

Many of Nichiren's writings still exist in his original handwriting, some as complete works and some as fragments. Other documents survive as copies made by his immediate disciples. Nichiren's existing works number over 700 manuscripts in total, including transcriptions of orally delivered lectures, letters of remonstration and illustrations.

Scholars have divided the writings attributed to Nichiren into three categories: those whose authenticity are universally accepted, those generally designated as written by someone else after his death, and a third category in which the veracity of works is still being debated.

In addition to treatises written in formal Classical Chinese ("kanbun" 漢文), Nichiren also wrote expositories and letters to followers in mixed kanji-kana vernacular as well as letters in simplified kana for believers such as children who could not read the more formal styles. Some of Nichiren's "kanbun" works, especially the "Risshō Ankoku Ron", are considered exemplary of the "kanbun" style, while many of his letters show unusual empathy and understanding for the downtrodden of his day.

Among his "kanbun" treatises, five are generally accepted by Nichiren schools as his major works:


Nichiren Shōshū adds an additional five writings to comprise a set of ten major writings. Other Nichiren sects dispute these selections as being either of secondary importance or as apocryphal:


Among the collection of his extant writings are numerous letters to his follows in the form of thank you notes, messages of condolence, responses to questions, and spiritual counseling for trying moments in his followers' lives. Collectively these letters demonstrate that Nichiren was a master of providing both comfort and challenge befitting the unique personalities and situations of each individual.

Many of these letters use tales drawn from Indian, Chinese, and Japanese traditions as well as historical anecdotes and stories from the Buddhist canon. Nichiren incorporated several hundred of these anecdotes and took liberty to freely embellish some of them; a few of the stories he provided do not appear in other collections and could be original.

Another category of his letters follow the genres of Japanese "zuihitsu", lyrical and loosely organized essays that combine personal reflection and poetic language, or personal diaries ("nikki") Nichiren was a master of this genre and these colloquial works reveal his highly personal and charismatic method of proselytization as well as his deep caring for his followers.

Nichiren used his letters as a means to inspire key supporters. About one hundred followers are identified as recipients and several received between 5 and 20 of them. The recipients tended to be of the warrior class and only scattered references appear about his lower status followers, many of whom were illiterate. The series of letters he wrote his followers during the "Atsuhara affair" of 1279 provide a case study of how he used personal written communications to direct a response to the government's actions and to keep his followers steadfast during the ordeal.

Against a backdrop of earlier Buddhist teachings that deny the possibility of enlightenment to women or reserve that possibility for life after death, Nichiren is highly sympathetic to women. Based on various passages from the Lotus Sutra, Nichiren asserts that "Other sutras are written for men only. This sutra is for everyone."

Ninety of his extant letters, nearly a fifth of the total, were addressed to female correspondents. Nichiren Shu published separate volumes of those writings.

In these letters Nichiren plays particular attention to the instantaneous attainment of enlightenment of the Dragon King's daughter in the "Devadatta" (Twelfth) chapter of the Lotus Sutra and displays deep concern for the fears and worries of his female disciples.

In many of his letters to female believers he often expressed compliments for their in-depth questions about Buddhism while encouraging them in their efforts to attain enlightenment in this lifetime.





</doc>
<doc id="22137" url="https://en.wikipedia.org/wiki?curid=22137" title="Nichiren Buddhism">
Nichiren Buddhism

Nichiren Buddhism () is a branch of Mahayana Buddhism based on the teachings of the 13th-century Japanese Buddhist priest Nichiren (1222–1282) and is one of the Kamakura Buddhism schools. Its teachings derive from some 300–400 extant letters and treatises attributed to Nichiren.

Nichiren Buddhism focuses on the Lotus Sutra doctrine that all people have an innate Buddha-nature and are therefore inherently capable of attaining enlightenment in their current form and present lifetime. There are three essential aspects to Nichiren Buddhism, the undertaking of faith, the practice of chanting "Nam Myoho Renge Kyo" accompanied by selected recitations of the Lotus Sutra, and the study of Nichiren's scriptural writings, called "Gosho".

The Nichiren "Gohonzon" is a calligraphic image which is prominently displayed in the home or temple buildings of its believers. The "Gohonzon" used in Nichiren Buddhism is composed of the names of key bodhisattvas and Buddhas in the Lotus Sutra as well as "Namu-Myoho-Renge-Kyo" written in large characters down the center.

After his death, Nichiren left to his followers the mandate to widely propagate the "Gohonzon" and "Daimoku" in order to secure the peace and prosperity of society.

Traditional Nichiren Buddhist temple groups are commonly associated with Nichiren Shōshū and various Nichiren-shū schools. There are also lay groups not affiliated with temples such as Soka Gakkai and Soka Gakkai International, Kenshokai, Shoshinkai, Risshō Kōsei Kai, and Honmon Butsuryū-shū. Several Japanese new religions are Nichiren-inspired lay groups. With the advent, and proselytizing efforts, of the Soka Gakkai International, called "the most prominent Japanese 'export' religion to draw significant numbers of non-Japanese converts", Nichiren Buddhism has spread throughout the world.

Nichiren proposed a classification system that ranks the quality of religions and various Nichiren schools can be either accommodating or vigorously opposed to any other forms of Buddhism or religious beliefs. Within Nichiren Buddhism there are two major divisions which fundamentally differ over whether Nichiren should be regarded as a bodhisattva of the earth, a saint, great teacher—or the actual Buddha of the third age of Buddhism. It is practiced worldwide, with practitioners throughout the United States, Brazil and Europe, as well as in South Korea and southeast Asia. The largest groups are Soka Gakkai International, Nichiren Shu, and Nichiren Shōshū.

Nichiren's teachings encompass a significant number of concepts. Briefly, the basic practice of Nichiren Buddhism is chanting the invocation "Nam-myoho-renge-kyo" to a mandala inscribed by Nichiren, called the "Gohonzon". Embracing "Nam-myoho-renge-kyo" entails both chanting and having the mind of faith ("shinjin"). Both the invocation and the Gohonzon, as taught by Nichiren, embody the title and essence of the Lotus Sutra, which he taught as the only valid scripture for the Latter Day of the Law, as well as the life state of Buddhahood inherent in all life.

Nichiren considered that in the Latter Day of the Law – a time of human strife and confusion, when Buddhism would be in decline – Buddhism had to be more than the theoretical or meditative practice it had become, but was meant to be practiced "with the body", that is, in one's actions and the consequent results that are manifested. More important than the formality of ritual, he claimed, was the substance of the practitioner's life in which the spiritual and material aspects are interrelated. He considered conditions in the world to be a reflection of the conditions of the inner lives of people; the premise of his first major remonstrance, Rissho Ankoku Ron (Establishing The Correct Teaching for the Peace of The Land), is that if a nation abandons heretical forms of Buddhism and adopts faith in the Lotus Sutra, the nation will know peace and security. He considered his disciples the "Bodhisattvas of the Earth" who appeared in the Lotus Sutra with the vow to spread the correct teaching and thereby establish a peaceful and just society. For Nichiren, enlightenment is not limited to one's inner life, but is "something that called for actualization in endeavors toward the transformation of the land, toward the realization of an ideal society."

The specific task to be pursued by Nichiren's disciples was the widespread propagation of his teachings (the invocation and the "Gohonzon") in a way that would effect actual change in the world's societies so that the sanctuary, or seat, of Buddhism could be built. Nichiren saw this sanctuary as a specific seat of his Buddhism, but there is thought that he also meant it in a more general sense, that is, wherever his Buddhism would be practiced. This sanctuary, along with the invocation and "Gohonzon", comprise "the three great secret laws (or dharmas)" found in the Lotus Sutra.

Nichiren Buddhism originated in 13th-century feudal Japan. It is one of six new forms of "Shin Bukkyo" (English: "New Buddhism") of "Kamakura Buddhism." The arrival of these new schools was a response to the social and political upheaval in Japan during this time as power passed from the nobility to a shogunate military dictatorship led by the Minamoto clan and later to the Hōjō clan. A prevailing pessimism existed associated with the perceived arrival of the Age of the Latter Day of the Law. The era was marked by an intertwining relationship between Buddhist schools and the state which included clerical corruption.

By Nichiren's time the Lotus Sūtra was firmly established in Japan. From the ninth century, Japanese rulers decreed that the Lotus Sūtra be recited in temples for its "nation-saving" qualities. It was the most frequently read and recited sutra by the literate lay class and its message was disseminated widely through art, folk tales, music, and theater. It was commonly held that it had powers to bestow spiritual and worldly benefits to individuals. However, even Mount Hiei, the seat of Tiantai Lotus Sutra devotion, had come to adopt an eclectic assortment of esoteric rituals and Pure Land practices as "expedient means" to understand the sutra itself.

Nichiren developed his thinking in this midst of confusing Lotus Sutra practices and a competing array of other "Old Buddhism" and "New Buddhism" schools. The biographical development of his thinking is sourced almost entirely from his extant writings as there is no documentation about him in the public records of his times. Modern scholarship on Nichiren's life tries to provide sophisticated textual and sociohistorical analyses to cull longstanding myths about Nichiren that accrued over time from what is actually concretized.

It is clear that from an early point in his studies Nichiren came to focus on the Lotus Sutra as the culmination and central message of Shakyamuni. As his life unfolded he engaged in a "circular hermeneutic" in which the interplay of the Lotus Sutra text and his personal experiences verified and enriched each other in his mind. As a result, there are significant turning points as his teachings reach full maturity. Scholar Yoshirō Tamura categorizes the development of Nichiren's thinking into three periods:

For more than 20 years Nichiren examined Buddhist texts and commentaries at Mount Hiei's Enryaku-ji temple and other major centers of Buddhist study in Japan. In later writings he claimed he was motivated by four primary questions: (1) What were the essentials of the competing Buddhist sects so they could be ranked according to their merits and flaws? (2) Which of the many Buddhist scriptures that had reached Japan represented the essence of Shakyamuni's teaching? (3) How could he be assured of the certainty of his own enlightenment? (4) Why was the Imperial house defeated by the Kamakura regime in 1221 despite the prayers and rituals of Tendai and Shingon priests? He eventually concluded that the highest teachings of Shakyamuni Buddha ( – ) were to be found in the Lotus Sutra. Throughout his career Nichiren carried his personal copy of the Lotus Sutra which he continually annotated. The mantra he expounded on 28 April 1253, known as the "Daimoku" or "Odaimoku", Namu Myōhō Renge Kyō, expresses his devotion to the Lotus Sutra.

From this early stage of his career, Nichiren started to engage in fierce polemics criticizing the teachings of Buddhism taught by the other sects of his day, a practice that continued and expanded throughout his life. Although Nichiren accepted the Tendai theoretical constructs of "original enlightenment" ("hongaku shisō") and "attaining Buddhahood in one's present form" ("sokushin jobutsu") he drew a distinction, insisting both concepts should be seen as practical and realizable amidst the concrete realities of daily life. He took issue with other Buddhist schools of his time that stressed transcendence over immanence. Nichiren's emphasis on "self-power" (Jpn. "ji-riki") led him to harshly criticize Honen and his Pure Land Buddhism school because of its exclusive reliance on Amida Buddha for salvation which resulted in "other-dependence." (Jpn. "ta-riki") In addition to his critique of Pure Land Buddhism, he later expanded his polemics to criticisms of the Zen, Shingon, and Ritsu sects. These four critiques were later collectively referred to as his "four dictums." Later in his writings, Nichiren referred to his early exegeses of the Pure Land teachings as just the starting point for his polemics against the esoteric teachings, which he had deemed as a far more significant matter of concern. Adding to his criticisms of esoteric Shingon, Nichiren wrote detailed condemnations about the Tendai school which had abandoned its Lotus Sutra-exclusiveness and incorporated esoteric doctrines and rituals as well as faith in the soteriological power of Amida Buddha.

The target of his tactics expanded during the early part of his career. Between 1253 and 1259 he proselytized and converted individuals, mainly attracting mid- to lower-ranking samurai and local landholders and debated resident priests in Pure Land temples. In 1260, however, he attempted to directly reform society as a whole by submitting a treatise entitled ""Risshō Ankoku Ron"" (""Establishment of the Legitimate Teaching for the Protection of the Country"") to Hōjō Tokiyori, the "de facto" leader of the nation.

In it he cites passages from the Ninnō, Yakushi, Daijuku, and Konkōmyō sutras. Drawing on Tendai thinking about the non duality of person and land, Nichiren argued that the truth and efficacy of the people's religious practice will be expressed in the outer conditions of their land and society. He thereby associated the natural disasters of his age with the nation's attachment to inferior teachings, predicted foreign invasion and internal rebellion, and called for the return to legitimate dharma to protect the country. Although the role of Buddhism in "nation-protection" ("chingo kokka") was well-established in Japan at this time, in this thesis Nichiren explicitly held the leadership of the country directly responsible for the safety of the land.

During the middle stage of his career, in refuting other religious schools publicly and vociferously, Nichiren provoked the ire of the country's rulers and of the priests of the sects he criticized. As a result, he was subjected to persecution which included two assassination attempts, an attempted beheading and two exiles. His first exile, to Izu Peninsula (1261–1263), convinced Nichiren that he was "bodily reading the Lotus Sutra ("Jpn. Hokke shikidoku")," fulfilling the predictions on the 13th chapter ("Fortitude") that votaries would be persecuted by ignorant lay people, influential priests, and their friends in high places.

Nichiren began to argue that through "bodily reading the Lotus Sutra," rather than just studying its text for literal meaning, a country and its people could be protected. According to Habito, Nichiren argued that bodily reading the Lotus Sutra entails four aspects:

His three-year exile to Sado Island proved to be another key turning point in Nichiren's thinking. Here he began inscribing the "Gohonzon" and wrote several major theses in which he claimed that he was functioning, at first, in the role of Bodhisattva Never Disparaging of the 20th chapter of the Lotus Sutra and, later, as Bodhisattva Superior Practices, the leader of the Bodhisattvas of the Earth. In his work "The True Object of Worship", he identified himself as functioning as the primordial Buddha, one and the same as the eternal Law represented by the mantra "Namu Myōhō Renge Kyō" which he physically embodied as the "Gohonzon" mandala. This has been described as embodying the same condition or state he attained in a physical object of devotion worship so that others could attain that equivalent condition of enlightenment. During this time the "daimoku" becomes the means to directly access the Buddha's enlightenment.

He concludes his work "The Opening of the Eyes" with the declaration "I will be the pillar of Japan; I will be the eyes of Japan; I will be the vessel of Japan. Inviolable shall remain these vows!" His thinking now went beyond theories of karmic retribution or guarantees of the Lotus Sutra as a protective force. Rather, he expressed a resolve to fulfill his mission despite the consequences. All of his disciples, he asserted, should emulate his spirit and work just like him in helping all people open their innate Buddha lives even though this means entails encountering enormous challenges.

Nichiren's teachings reached their full maturity between the years 1274 and 1282 while he resided in primitive settings at Mount Minobu located in today's Yamanashi Prefecture. During this time he devoted himself to training disciples, produced most of the "Gohonzon" which he sent to followers, and authored works constituting half of his extant writings including six treatises that were categorized by his follower Nikkō as among his ten most important.

In 1278 the “Atsuhara Affair” (“Atsuhara Persecution”) occurred, culminating three years later. In the prior stage of his career, between 1261 and 1273, Nichiren endured and overcame numerous trials that were directed at him personally including assassination attempts, an attempted execution, and two exiles, thereby “bodily reading the Lotus Sutra” ("shikidoku" 色読). In so doing, according to him, he validated the 13th ("Fortitude") chapter of the Lotus Sutra in which a host of bodhisattvas promise to face numerous trials that follow in the wake of upholding and spreading the sutra in the evil age following the death of the Buddha: slander and abuse; attack by swords and staves; enmity from kings, ministers, and respected monks; and repeated banishment.

On two occasions, however, the persecution was aimed at his followers. First, in 1271, in conjunction with the arrest and attempted execution of Nichiren and his subsequent exile to Sado, many of his disciples were arrested, banished, or had lands confiscated by the government. At that time, Nichiren stated, most recanted their faith in order to escape the government's actions. In contrast, during the Atsuhara episode twenty lay peasant-farmer followers were arrested on questionable charges and tortured; three were ultimately executed. This time none recanted their faith. Some of his prominent followers in other parts of the country were also being persecuted but maintained their faith as well.

Although Nichiren was situated in Minobu, far from the scene of the persecution, the Fuji district of present-day Shizuoka Prefecture, Nichiren held his community together in the face of significant oppression through a sophisticated display of legal and rhetorical responses. He also drew on a wide array of support from the network of leading monks and lay disciples he had raised, some of whom were also experiencing persecution at the hands of the government.

Throughout the events he wrote many letters to his disciples in which he gave context to the unfolding events by asserting that severe trials have deep significance. According to Stone, “By standing firm under interrogation, the Atsuhara peasants had proved their faith in Nichiren’s eyes, graduating in his estimation from ‘ignorant people’ to devotees meriting equally with himself the name of ‘practitioners of the Lotus Sutra.’” During this time Nichiren inscribed 114 mandalas that are extant today, 49 of which have been identified as being inscribed for individual lay followers and which may have served to deepen the bond between teacher and disciple. In addition, a few very large mandalas were inscribed, apparently intended for use at gathering places, suggesting the existence of some type of conventicle structure.

The Atsuhara Affair also gave Nichiren the opportunity to better define what was to become Nichiren Buddhism. He stressed that meeting great trials was a part of the practice of the Lotus Sutra; the great persecutions of Atsuhara were not results of karmic retribution but were the historical unfolding of the Buddhist Dharma. The vague “single good of the true vehicle” which he advocated in the "Risshō ankoku ron" now took final form as chanting the Lotus Sutra's "daimoku" or title which he described as the heart of the “origin teaching” ("honmon" 本門) of the Lotus Sutra. This, he now claimed, lay hidden in the depths of the 16th (“The Life Span of the Tathāgata”) chapter, never before being revealed, but intended by the Buddha solely for the beginning of the Final Dharma Age.

A prolific writer, Nichiren's personal communiques among his followers as well as numerous treatises detail his view of the correct form of practice for the "Latter Day of the Law" ("mappō"); lay out his views on other Buddhist schools, particularly those of influence during his lifetime; and elucidate his interpretations of Buddhist teachings that preceded his. These writings are collectively known as "Gosho" (御書) or "Nichiren ibun" (日蓮遺文).

Out of 162 historically identified followers of Nichiren, 47 were women. Many of his writings were to women followers in which he displays strong empathy for their struggles, and continually stressed the Lotus Sutra's teaching that all people, men and women equally, can become enlightened just as they are. His voice is sensitive and kind which differs from the strident picture painted about him by critics.

Which of these writings, including the "Ongi Kuden" (orally transmitted teachings), are deemed authentic or apocryphal is a matter of debate within the various schools of today's Nichiren Buddhism. His "Rissho Ankoku Ron", preserved at Shochuzan Hokekyo-ji, is one of the National Treasures of Japan.

After Nichiren's death in 1282 the Kamakura shogunate weakened largely due to financial and political stresses resulting from defending the country from the Mongols. It was replaced by the Ashikaga shogunate (1336–1573), which in turn was succeeded by the Azuchi–Momoyama period (1573–1600), and then the Tokugawa shogunate (1600–1868). During these time periods, collectively comprising Japan's medieval history, Nichiren Buddhism experienced considerable fracturing, growth, turbulence and decline. A prevailing characteristic of the movement in medieval Japan was its lack of understanding of Nichiren's own spiritual realization. Serious commentaries about Nichiren's theology did not appear for almost two hundred years. This contributed to divisive doctrinal confrontations that were often superficial and dogmatic.

This long history of foundings, divisions, and mergers have led to today's 37 legally incorporated Nichiren Buddhist groups. In the modern period, Nichiren Buddhism experienced a revival, largely initiated by lay people and lay movements.

Several denominations comprise the umbrella term "Nichiren Buddhism" which was known at the time as the "Hokkeshū" (Lotus School) or "Nichirenshū" (Nichiren School). The splintering of Nichiren's teachings into different schools began several years after Nichiren's passing. Despite their differences, however, the Nichiren groups shared commonalities: asserting the primacy of the Lotus Sutra, tracing Nichiren as their founder, centering religious practice on chanting "Namu-myoho-renge-kyo", using the "Gohonzon" in meditative practice, insisting on the need for propagation, and participating in remonstrations with the authorities.

The movement was supported financially by local warlords or stewards ("jitõ") who often founded tightly-organized clan temples ("ujidera") that were frequently led by sons who became priests. Most Nichiren schools point to the founding date of their respective head or main temple (for example, Nichiren Shū the year 1281, Nichiren Shōshū the year 1288, and Kempon Hokke Shu the year 1384) although they did not legally incorporate as religious bodies until the late 19th and early 20th century. A last wave of temple mergers took place in the 1950s.

The roots of this splintering can be traced to the organization of the Nichiren community during his life. In 1282, one year before his death, Nichiren named "six senior priests" ("rokurōsō") disciple to lead his community: Nikkō Shonin (日興), Nisshō (日昭), Nichirō (日朗), Nikō (日向), Nitchō (日頂), and Nichiji (日持). Each had led communities of followers in different parts of the Kanto region of Japan and these groups, after Nichiren's death, ultimately morphed into lineages of schools.

Nikkō Shonin, Nichirō, and Nisshō were the core of the Minobu (also known as the Nikō or Kuon-ji) "monryu" or school. Nikō became the second chief abbot of Minobu (Nichiren is considered by this school to be the first). Nichirō's direct lineage was called the Nichirō or Hikigayatsu "monryu". Nisshō's lineage became the Nisshō or Hama "monryu". Nitchō formed the Nakayama lineage but later returned to become a follower of Nikkō. Nichiji, originally another follower of Nikkō, eventually traveled to the Asian continent (ca. 1295) on a missionary journey and some scholarship suggests he reached northern China, Manchuria, and possibly Mongolia. Kuon-ji Temple in Mount Minobu eventually became the head temple of today's Nichiren Shū, the largest branch among traditional schools, encompassing the schools and temples tracing their origins to Nikō, Nichirō, Nisshō, Nitchō, and Nichiji. The lay and/or new religious movements Reiyūkai, Risshō Kōsei Kai, and Nipponzan-Myōhōji-Daisanga stem from this lineage.

Nikkō left Kuon-ji in 1289 and became the founder of what was to be called the Nikkō "monryu" or lineage. He founded a center at the foot of Mount Fuji which would later be known as the Taisekiji temple of Nichiren Shōshū. Soka Gakkai is the largest independent lay organization that shares roots with this lineage.

Fault lines between the various Nichiren groups crystallized over several issues:

The cleavage between Nichiren groups has also been classified by the so-called "Itchi" (meaning unity or harmony) and "Shoretsu" (a contraction of two words meaning superior/inferior) lineages.


Although there were rivalries and unique interpretations among the early Hokkeshũ lineages, none were as deep and distinct as the divide between the Nikkō or Fuji school and the rest of the tradition. Animosity and discord among the six senior disciples started after the second death anniversary of Nichiren's 100th Day Memorial ceremony (23 January 1283) when the rotation system as agreed upon the ""Shuso Gosenge Kiroku"" (English: Record document of founder's demise) and "Rimbo Cho" (English: Rotation Wheel System) to clean and maintain Nichiren's grave. By the third anniversary of Nichiren's passing (13 October 1284), these arrangements seemed to have broken down. Nikkō claimed that the other five senior priests no longer returned to Nichiren's tomb in Mount Minobu, citing signs of neglect at the gravesite. He took up residency and overall responsibility for Kuonji temple while Nikō served as its doctrinal instructor. Before long tensions grew between the two concerning the behavior of Hakii Nanbu Rokurō Sanenaga, the steward of the Minobu district and the temple's patron.

Nikkō accused Sanenaga of unorthodox practices deemed to be heretical such as crafting a standing statue of Shakyamuni Buddha as an object of worship, providing funding for the construction of a Pure Land "stupa" in Fuji, and visiting and worshiping at the Mishima Taisha Shinto shrine which was an honorary shrine of the Hōjō clan shogunate. Nikkō regarded the latter as a violation of Nichiren's "Rissho ankoku ron".

In addition, Nikkō made accusatory charges that after Nichiren's death, other disciples slowly began to gradually deviate from what Nikkō viewed as Nichiren's orthodox teachings. Chief among these complaints was the syncretic practices of some of the disciples to worship images of Shakyamuni Buddha. Nikkō admonished other disciple priests for signing their names "Tendai Shamon" (of the Tendai Buddhist school) in documents they sent to the Kamakura government. Furthermore, Nikkō alleged that the other disciples disregarded some of Nichiren's writings written in Katakana rather than in Classical Chinese syllabary.

Sanenaga defended his actions, claiming that it was customary for his political family to provide monetary donations and make homage to the Shinto shrine of the Kamakura shogunate. Nikō tolerated Sanenaga's acts, claiming that similar incidents occurred previously with the knowledge of Nichiren. Sanenaga sided with Nikō and Nikkō departed in 1289 from Minobu. He returned to his home in Suruga Province and established two temples: Taiseki-ji in the Fuji district and Honmonji in Omosu district. He spent most of his life at the latter, where he trained his followers.

According to Stone, it is not absolutely clear that Nikkō intended to completely break from the other senior disciples and start his own school. However, his followers claimed that he was the only one of the six senior disciples who maintained the purity of Nichiren's legacy. Two documents appeared, first mentioned and discovered by Taiseki-ji High Priest Nikkyo Shonin in 1488, claiming Nichiren transferred his teaching exclusively to Nikkō but their authenticity has been questioned. Taiseki-ji does not dispute that the original documents are missing but holds that certified copies are preserved in their repositories. In contrast, other Nichiren sects vehemently claim them as forgeries since they are not in the original handwriting of Nichiren or Nikkō, holding they were copied down by Nikkō's disciples after his death."

In addition to using the letters to defend its claim to othodoxy, the documents may have served to justify Taiseki-ji's claimed superiority over other Nikkō temples, especially Ikegami Honmon-ji, the site of Nichiren's tomb. Even though there had been efforts by temples of the Nikkō lineage in the late 19th century to unify into one single separate Nichiren school the "Kommon-ha", today's Nichiren Shōshū comprises only the Taiseki-ji temple and its dependent temples. It is not identical to the historical Nikkō or Fuji lineage. Parts of the "Kommon-ha", the "Honmon-Shu", eventually became part of Nichiren Shu in the 1950s. New religious movements like Sōka Gakkai, Shōshinkai, and Kenshōkai trace their origins to the Nichiren Shōshū school.

In the early 14th century Hokkeshū followers spread the teachings westward and established congregations (Jpn. "shū") into the imperial capital of Kyoto and as far as Bizen and Bitchu. During this time there is documentation of face-to-face public debates between Hokkeshū and Nembutsu adherents. By the end of the century Hokkeshū temples had been founded all over Kyoto, only being outnumbered by Zen temples. The demographic base of support in Kyoto were members of the merchant class (Jpn. "machishū"), some of whom had acquired great wealth. Tanabe hypothesizes they were drawn to this faith because of Nichiren's emphasis on the "third realm" (Jpn. "daisan hōmon") of the Lotus Sutra, staked out in chapters 10-22, which emphasize practice in the mundane world.

In the 15th century, the political and social order began to collapse and Hokkeshū followers armed themselves. The "Hokke-ikki" was an uprising in 1532 of Hokke followers against the followers of the Pure Land school in 1532. Initially successful it became the most powerful religious group in Kyoto but its fortunes were reversed in 1536 when Mt. Hiei armed forces destroyed twenty-one Hokkeshū temples and killed some 58,000 of its followers. In 1542 permission was granted by the government to rebuild the destroyed temples and the Hokke "machishū" played a crucial role in rebuilding the commerce, industry, and arts in Kyoto. Their influence in the arts and literature continued through the Momoyama (1568–1615) and Edo (1615–1868) periods and many of the most famous artists and literati were drawn from their ranks.

Although the various sects of Nichiren Buddhism were administratively independent, there is evidence of cooperation between them. For example, in 1466 the major Hokke temples in Kyoto signed the Kanshō-era accord (Kanshō "meiyaku") to protect themselves against threats from Mt. Hiei. Despite strong sectarian differences, there is also evidence of interactions between Hokkeshū and Tendai scholar-monks.

During the Edo period, with the consolidation of power by the Tokugawa shogunate, increased pressure was placed major Buddhist schools and Nichiren temples to conform to governmental policies. Some Hokkeshū adherents, the followers of the so-called Fuju-fuse lineage, adamantly bucked this policy based on their readings of Nichiren's teachings to neither take ("fuju") nor give ("fuse") offerings from non-believers. Suppressed, adherents often held their meetings clandestinely which led to the Fuju-fuse persecution and numerous executions of believers in 1668. During this time of persecution, most likely to prevent young priests from adopting a passion for propagation, Nichiren seminaries emphasized Tendai studies with only a few top-ranking students permitted to study some of Nichiren's writings.

During the Edo period the majority of Hokkeshū temples were subsumed into the shogunate's Danka system, an imposed nationwide parish system designed to ensure religious peace and root out Christianity. In this system Buddhist temples, in addition to their ceremonial duties, were forced to carry out state administrative functions. Thereby they became agents of the government and were prohibited to engage in any missionary activities. Hokkeshū temples were now obligated, just like those of other Buddhist schools, to focus on funeral and memorial services ("Sōshiki bukkyō") as their main activity. Stagnation was often the price for the protected status.

Nichiren Buddhism was deeply influenced by the transition from the Tokugawa (1600–1868) to Meiji (1868–1912) periods in nineteenth-century Japan. The changeover from early modern ("kinsei") to modern ("kindai") was marked by the transformation of late-feudal institutions into modern ones as well as the political transition from shogunal to imperial rule and the economic shift from national isolation to integration in the world economy. This entailed creating a centralized state, stitching together some 260 feudal domains ruled by hereditary leaders ("daimyō"), and moving from a caste social system to a meritocracy based on educational achievement. Although commonly perceived as a singular event called the Meiji Restoration, the transition was full of twists and turns that began in the later Tokugawa years and continued decades after the 1867–1868 demise of the shogunate and launch of imperial rule.

By this time Japanese Buddhism was often characterized by syncretism in which local nativistic worship was incorporated into Buddhist practice. For example, Tendai, Shingon, Jodō, and Nichiren temples often had chapels within them dedicated to Inari Shinto worship. Within Nichiren Buddhism there was a phenomenon of "Hokke Shintō" (Lotus Shinto), closely influenced by Yoshida Shintō.

Anti-Buddhist sentiment had been building throughout the latter part of the Tokugawa period (1603–1868). Scholars such as Tominaga Nakamoto and Hirata Atsutane attacked the theoretical roots of Buddhism. Critics included promoters of Confucianism, nativism, Shinto-inspired Restorationists, and modernizers. Buddhism was critiqued as a needless drain on public resources and also as an insidious foreign influence that had obscured the indigenous Japanese spirit.

Under attack by two policies of the day, "shinbutsu bunri" (Separation of Shinto Deities and Buddhas) and "haibutsu kishaku" (Eradication of Buddhism), Japanese Buddhism during the Tokugawa-to-Meiji transition proved to be a crisis of survival. The new government promoted policies that reduced the material resources available to Buddhist temples and downgraded their role in the religious, political, and social life of the nation.

The policies of "shibutsu bunri" were implemented at the local level throughout Japan but were particularly intense in three domains that were the most active in the Restoration: Satsuma, Choshii, and Tosa. In Satsuma, for example, by 1872 all of its 1000+ Buddhist temples had been abolished, their monks laicized, and their landholdings confiscated. Throughout the country thousands of Buddhist temples and, at a minimum, tens of thousands of Buddhist sutras, paintings, statues, temple bells and other ritual objects were destroyed, stolen, lost, or sold during the early years of the restoration.

Starting in the second decade of the restoration, pushback against these policies came from Western powers interested in providing a safe harbor for Christianity and Buddhist leaders who proposed an alliance of Shinto and Buddhism to resist Christianity. As part of this accommodation, Buddhist priests were forced to promote key teachings of Shinto and provide support for national policies.

Nichiren Buddhism, like the other Buddhist schools, struggled between accommodation and confrontation. The Nichiren scholar Udana-in Nichiki (1800–1859) argued for a policy of co-existence with other schools of Buddhism, Confucianism, Nativism, and European religions. His disciple Arai Nissatsu (1830–1888) forged an alliance of several Nichiren branches and became the first superintendent of the present Nichiren Shū which was incorporated in 1876. Nissatsu was active in Buddhist intersect cooperation to resist the government's hostile policies, adopted the government's "Great Teaching" policy that was Shinto-derived, and promoted intersectarian understanding. In the process, however, he reinterpreted some of Nichiren's important teachings. Among those arguing against accommodation were Nichiren scholar and lay believer Ogawa Taidō (1814–1878) and the cleric Honda Nisshō (1867–1931) of the Kempon Hokke denomination.

After the above events and centuries of splintering based on dogma and institutional histories, the following major Nichiren temple schools, according to Matsunaga, were officially recognized in the Meiji era:

Nichiren Buddhism went through many reforms in the Meiji Period during a time of persecution, Haibutsu kishaku (廃仏毀釈), when the government attempted to eradicate mainstream Japanese Buddhism. As a part of the Meiji Restoration, the interdependent Danka system between the state and Buddhist temples was dismantled which left the latter without its funding. Buddhist institutions had to align themselves to the new nationalistic agenda or perish. Many of these reform efforts were led by lay people.

The trend toward lay centrality was prominent in Nichiren Buddhism as well, predating the Meiji period. Some Nichiren reformers in the Meiji period attempted to inject a nationalistic interpretation of Nichiren's teachings; others called for globalist perspectives. According to Japanese researcher "Yoshiro Tamura", the term "Nichirenism" applies broadly to the following three categories:

Both Nichiren and his followers have been associated with fervent Japanese nationalism specifically identified as Nichirenism between the Meiji period and the conclusion of World War II. The nationalistic interpretation of Nichiren's teachings were inspired by lay Buddhist movements like Kokuchūkai and resulted in violent historical events such as the May 15 Incident and the League of Blood Incident. Among the key proponents of this interpretation are Chigaku Tanaka who founded the Kokuchūkai (English: Nation's Pillar Society). Tanaka was charismatic and through his writings and lecturers attracted many followers such as Kanji Ishiwara. Nisshō Honda advocated the unification of Japanese Buddhists to support the imperial state. Other ultra-nationalist activists who based their ideas on Nichiren were Ikki Kita and Nisshō Inoue.

Nichirenism also includes several intellectuals and activists who reacted against the prewar ultranationalistic interpretations and argued for an egalitarian and socialist vision of society based on Nichiren's teachings and the Lotus Sutra. These figures ran against the growing tide of Japanese militarism and were subjected to political harassment and persecution. A leading figure in this group was Girō Seno who formed the New Buddhist Youth League ("Shinkō Bukkyō Seinen Dōmei").

Originally influenced by the ideals of Tanaka and Honda, Giro Seno came to reject ultra-nationalism and argued for humanism, socialism, pacifism, and democracy as a new interpretation of Nichiren's beliefs. He was imprisoned for two years under the National Security Act. The same fate was also endured by Tsunesaburo Makiguchi, who refused the religious dictum of Shinto display accepted by Nichiren Shoshu for the "Soka Kyoiku Gakkai", his lay organization composed of primarily secretaries and teachers until it grew to become Soka Gakkai after World War II.

Several Nichiren-inspired religious movements arose and appealed primarily to this segment of society with a message of alleviating suffering salvation for many poor urban workers. Honmon Butsuryū-shū, an early example of lay-based religious movements of the modern period inspired by Nichiren, was founded several years before the Meiji Restoration. Reiyukai, Rissho Koseikai stemming from Nichiren Shu while Kenshokai and Soka Gakkai, once affiliated with Nichiren Shoshu, are more recent examples of lay-inspired movements drawing from Nichiren's teachings and life.

Nichiren Buddhism has had a major impact on Japan's literary and cultural life. Japanese literary figure Takayama Chogyū and children's author Kenji Miyazawa praised Nichiren's teachings. A prominent researcher, Masaharu Anesaki, was encouraged to study Nichiren which led to the work "Nichiren: The Buddhist Prophet" which introduced Nichiren to the West. Non-Buddhist Japanese individuals such as Uchimura Kanzō listed Nichiren as one of five historical figures who best represented Japan, while Tadao Yanaihara described Nichiren as one of the four historical figures he most admired.

While various sects and organizations have had a presence in nations outside Japan for over a century, the ongoing expansion of Nichiren Buddhism overseas started in 1960 when Soka Gakkai president Daisaku Ikeda initiated his group's worldwide propagation efforts growing from a few hundred transplanted Japanese to over 3500 families just by 1962.

Nichiren Buddhism is now practiced in many countries outside of Japan. In the United States, religious studies scholar Charles S. Prebish coined the typology of "two Buddhisms" to delineate the divide between forms of Buddhism that appealed either primarily to people of the Asian diaspora or to Euro-American converts. Nattier, on the other hand, proposes a three-way typology. "Import" or "elite" Buddhism refers to a class of people who have the time and means to seek Buddhist teachers to appropriate certain Buddhist techniques such as meditation. "Export or evangelical" Buddhism refers to groups that actively proselytize for new members in their local organizations. "Baggage" or "ethnic" Buddhism refers to diaspora Buddhists, usually of a single ethnic group, who have relocated more for social and economic advancement than for evangelical purposes. Another taxonomy divides Western Buddhist groups into three different categories: evangelical, church-like, and meditational.

Nichiren Shu has been classified into the church-like category. One of several Japanese Buddhist schools that followed in the wake of Japanese military conquest and colonization, Nichiren Shu opened a temple in Pusan, Korea in 1881. Its fortunes rose and diminished with the political tides but eventually failed. It also established missions in Sakhalin, Manchuria, and Taiwan. A Nichiren Shu mission was established in Hawaii in 1900. By 1920 it established temples at Pahala, Honolulu, Wailuku and Maui. In 1955 it officially started a mission in Brazil. In 1991 it established the Nichiren Buddhist International Center in 1991 and in 2002 built a center in Hayward, California, to help overseas missions. However, Nichiren Shu does not widely propagate in the West.

Some have characterized the Soka Gakkai as evangelical but others claim that it broke out of the "Two Buddhisms" paradigm. It is quite multi-ethnic and it has taken hold among native populations in locations including Korea, Malaysia, Brazil, Europe, parts of Africa, India, and North America. The growth of the Soka Gakkai was sparked by repeated missionary trips beginning in the early 1960s by Daisaku Ikeda, its third president. In 1975 the Soka Gakkai International was launched in Guam. In the United States it has attracted a diverse membership including a significant demographic of African Americans. Since the 1970s it has created institutions, publications and exhibitions to support its overall theme of "peace, culture, and education." There is academic research on various national organizations affiliated with this movement: the United States, the United Kingdom, Italy, Canada, Brazil, Scotland, Southeast Asia, Germany, and Thailand.

The Rissho Kosei Kai focuses on using its teachings to promote a culture of religiosity through inter-religious dialogue. In 1967, it launched the "Faith to All Men Movement" to awaken a globalized religiosity. It has over 2 million members and 300 Dharma centers in 20 countries throughout the world including Frankfurt and Moorslede. It is active in interfaith organizations, including the International Association for Religious Freedom (IARF) and Religions for Peace (WCRP). It has consultative states with the United Nations and since 1983 issues an annual Peace Prize to individuals or organizations worldwide that work for peace and development and promote interreligious cooperation.

The Reiyukai conducts more typical missionary activities in the West. It has a membership of between five hundred and one thousand members in Europe, concentrated in Italy, Spain, England and France. The approximately 1,500 members of the Nihonzan Myohoji have built peace pagodas, conducted parades beating the drum while chanting the daimoku, and encouraged themselves and others to create world peace.

Nichiren Shoshu has six temples in the United States led by Japanese priests and supported by lay Asians and non-Asians. There is one temple in Brazil and the residing priest serves as a "circuit rider" to attend to other locations.

The following lists are based on English-language Wikipedia articles and the Japanese Wikipedia article on .

In alphabetical order (Japanese characters preceded by "ja:" link to articles in the Japanese Wikipedia). 
In alphabetical order (Japanese characters preceded by "ja:" link to articles in the Japanese Wikipedia):









</doc>
<doc id="22141" url="https://en.wikipedia.org/wiki?curid=22141" title="Newport News Shipbuilding">
Newport News Shipbuilding

Newport News Shipbuilding (NNS), a division of Huntington Ingalls Industries, is the largest industrial employer in Virginia, and sole designer, builder and refueler of United States Navy aircraft carriers and one of two providers of U.S. Navy submarines. Founded as the Chesapeake Dry Dock and Construction Co. in 1886, Newport News Shipbuilding has built more than 800 ships, including both naval and commercial ships. Located in the city of Newport News, its facilities span more than , strategically positioned in one of the great harbors of the East Coast.

The shipyard is a major employer, not only for the lower Virginia Peninsula, but also portions of Hampton Roads south of the James River and the harbor, portions of the Middle Peninsula region, and even some northeastern counties of North Carolina.

The shipyard is building the aircraft carriers and .

In 2013, Newport News Shipbuilding began the deactivation of the first nuclear-powered aircraft carrier, , which it also built.

Newport News Shipbuilding also performs refueling and complex overhaul (RCOH) work on s. This is a four-year vessel renewal program that not only involves refueling of the vessel's nuclear reactors but also includes modernization work. The yard has completed RCOH for four "Nimitz"-class carriers (, , and ). As of May 2016 this work was underway for the fifth "Nimitz"-class vessel, . As of November 2017 this work was underway for the sixth "Nimitz"-class vessel, .

Industrialist Collis P. Huntington (1821–1900) provided crucial funding to complete the Chesapeake and Ohio Railroad (C&O) from Richmond, Virginia to the Ohio River in the early 1870s. Although originally built for general commerce, this C&O rail link to the midwest was soon also being used to transport bituminous coal from the previously isolated coalfields, adjacent to the New River and the Kanawha River in West Virginia. In 1881, the Peninsula Extension of the C&O was built from Richmond down the Virginia Peninsula to reach a new coal pier on Hampton Roads in Warwick County near the small unincorporated community of Newport News Point. However, building the railroad and coal pier was only the first part of Huntington's dreams for Newport News.

In 1886, Huntington built a shipyard to repair ships servicing this transportation hub. In 1891 Newport News Shipbuilding and Drydock Company delivered its first ship, the tugboat "Dorothy". By 1897 NNS had built three warships for the US Navy: , and .

When Collis died in 1900, his nephew Henry E. Huntington inherited much of his uncle's fortune. He also married Collis' widow Arabella Huntington, and assumed Collis' leadership role with Newport News Shipbuilding and Drydock Company. Under Henry Huntington's leadership, growth continued.

In 1906 the revolutionary launched a great naval race worldwide. Between 1907 and 1923, Newport News built six of the US Navy's total of 22 dreadnoughts – , , , , and . All but the first were in active service in World War II. In 1907 President Theodore Roosevelt sent the Great White Fleet on its round-the-world voyage. NNS had built seven of its 16 battleships.

In 1914 NNS built SS "Medina" for the Mallory Steamship Company; as she was until 2009 the world's oldest active ocean-faring passenger ship.

In the early years, leaders of the Newport News community and those of the shipyard were virtually interchangeable. Shipyard president Walter A. Post served from March 9, 1911 to February 12, 1912, when he died. Earlier, he had come to the area as one of the builders of the C&O Railway's terminals, and had served as the first mayor of Newport News after it became an independent city in 1896. It was on March 14, 1914 that Albert Lloyd Hopkins, a young New Yorker trained in engineering, succeeded Post as president of the company. In May 1915 while traveling to England on shipyard business aboard , Albert L. Hopkins tenure and life ended prematurely when that ship was torpedoed and sunk by a German U-boat off Queenstown on the Irish coast. His assistant, Frederic Gauntlett, was also on board, but was able to swim to safety. Homer Lenoir Ferguson was company vice president when Hopkins died, and assumed the presidency the following August. He saw the company through both world wars, became a noted community leader, and was a co-founder of the Mariners' Museum with Archer Huntington. He served until July 31, 1946, after World War II had ended on both the European and Pacific fronts.
Just northwest of the shipyard, Hilton Village, one of the first planned communities in the country, was built by the federal government to house shipyard workers in 1918. The planners met with the wives of shipyard workers. Based on their input 14 house plans were designed for the projected 500 English-village-style homes. After the war, in 1922, Henry Huntington acquired it from the government, and helped facilitate the sale of the homes to shipyard employees and other local residents. Three streets there were named after Post, Hopkins, and Ferguson.

The "Lusitania" incident was among the events that brought the United States into World War I. Between 1918 and 1920 NNS delivered 25 destroyers, and after the war it began building aircraft carriers. was delivered in 1934, and NNS went on to build and .

After World War I NNS completed a major reconditioning and refurbishment of the ocean liner . Before the war she had been the German liner "Vaterland", but the start of hostilities found her laid up in New York Harbor and she had been seized by the US Government in 1917 and converted into a troopship. War duty and age meant that all wiring, plumbing, and interior layouts were stripped and redesigned while her hull was strengthened and her boilers converted from coal to oil while being refurbished. Virtually a new ship emerged from NNS in 1923, and SS "Leviathan" became the flagship of United States Lines.

In 1927 NNS launched the world's first significant turbo-electric ocean liner: Panama Pacific Line's . At the time she was also the largest merchant ship yet built in the United States, although she was a modest size compared with the biggest European liners of her era. NNS launched "California"s sister ships "Virginia" in 1928 and "Pennsylvania" in 1929. NNS followed them by launching two even larger turbo-electric liners for Dollar Steamship Company: the in 1930, followed by her sister in 1931. was launched in 1939 and entered service with United States lines shortly before World War II but soon returned to the shipyard for conversion to a troopship, USS "West Point".

By 1940 the Navy had ordered a battleship, seven more aircraft carriers and four cruisers. During World War II, NNS built ships as part of the U.S. Government's Emergency Shipbuilding Program, and swiftly filled requests for "Liberty ships" that were needed during the war. It founded the North Carolina Shipbuilding Company, an emergency yard on the banks of the Cape Fear River and launched its first Liberty ship before the end of 1941, building 243 ships in all, including 186 Libertys. For its contributions during the war, the Navy awarded the company its "E" pennant for excellence in shipbuilding. NNS ranked 23rd among United States corporations in the value of wartime production contracts.

In the post-war years NNS built the famous passenger liner , which set a transatlantic speed record that still stands today. In 1954 NNS, Westinghouse and the Navy developed and built a prototype nuclear reactor for a carrier propulsion system. NNS designed in 1960. In 1959 NNS launched its first nuclear-powered submarine, .

In the 1970s, NNS launched two of the largest tankers ever built in the western hemisphere and also constructed three liquefied natural gas carriers – at over 390,000 deadweight tons, the largest ever built in the United States. NNS and Westinghouse Electric Company jointly form Offshore Power Systems to build floating nuclear power plants for Public Service Electric and Gas Company. 
In the 1980s, NNS produced a variety of Navy products, including nuclear aircraft carriers and nuclear attack submarines. Since 1999 the shipyard has produced only warships for the Navy.

In 2007, the US Navy found that workers had used incorrect metal to fuse together pipes and joints on submarines under construction and this could have led to cracking and leaks. In 2009 it was found that bolts and fasteners in weapons-handling systems on four Navy submarines, , , , and , were installed incorrectly, delaying the launching of the boats while the problems were corrected.

In 1968, Newport News merged with Tenneco Corporation. In 1996, Tenneco initiated a spinoff of Newport News into an independent company (Newport News Shipbuilding). The company was purchased by Northrop Grumman in 2001 for $2.6 billion and renamed "Northrop Grumman Newport News". This division was merged with Northrop Grumman Ship Systems in 2008 and given the name "Northrop Grumman Shipbuilding". Three years later, the company was spun off as Huntington Ingalls Industries, Inc., which trades under the symbol HII on the New York Stock Exchange.

Other ships built at the Newport News yard include:


 


</doc>
<doc id="22145" url="https://en.wikipedia.org/wiki?curid=22145" title="Newton's method">
Newton's method

In numerical analysis, Newton's method, also known as the Newton–Raphson method, named after Isaac Newton and Joseph Raphson, is a root-finding algorithm which produces successively better approximations to the roots (or zeroes) of a real-valued function. The most basic version starts with a single-variable function defined for a real variable , the function's derivative , and an initial guess for a root of . If the function satisfies sufficient assumptions and the initial guess is close, then

is a better approximation of the root than . Geometrically, is the intersection of the -axis and the tangent of the graph of at : that is, the improved guess is the unique root of the linear approximation at the initial point. The process is repeated as

until a sufficiently precise value is reached. This algorithm is first in the class of Householder's methods, succeeded by Halley's method. The method can also be extended to complex functions and to systems of equations.

The idea is to start with an initial guess which is reasonably close to the true root, then to approximate the function by its tangent line using calculus, and finally to compute the -intercept of this tangent line by elementary algebra. This -intercept will typically be a better approximation to the original function's root than the first guess, and the method can be iterated.

More formally, suppose is a differentiable function defined on the interval with values in the real numbers , and we have some current approximation . Then we can derive the formula for a better approximation, by referring to the diagram on the right. The equation of the tangent line to the curve at is

where denotes the derivative. The -intercept of this line (the value of which makes ) is taken as the next approximation, , to the root, so that the equation of the tangent line is satisfied when formula_4: 

Solving for gives

We start the process with some arbitrary initial value . (The closer to the zero, the better. But, in the absence of any intuition about where the zero might lie, a "guess and check" method might narrow the possibilities to a reasonably small interval by appealing to the intermediate value theorem.) The method will usually converge, provided this initial guess is close enough to the unknown zero, and that . Furthermore, for a zero of multiplicity 1, the convergence is at least quadratic (see rate of convergence) in a neighbourhood of the zero, which intuitively means that the number of correct digits roughly doubles in every step. More details can be found in the analysis section below.

Householder's methods are similar but have higher order for even faster convergence. However, the extra computations required for each step can slow down the overall performance relative to Newton's method, particularly if or its derivatives are computationally expensive to evaluate.

The name "Newton's method" is derived from Isaac Newton's description of a special case of the method in "De analysi per aequationes numero terminorum infinitas" (written in 1669, published in 1711 by William Jones) and in "De metodis fluxionum et serierum infinitarum" (written in 1671, translated and published as "Method of Fluxions" in 1736 by John Colson). However, his method differs substantially from the modern method given above. Newton applied the method only to polynomials, starting with an initial root estimate and extracting a sequence of error corrections. He used each correction to rewrite the polynomial in terms of the remaining error, and then solved for a new correction by neglecting higher-degree terms. He did not explicitly connect the method with derivatives or present a general formula. Newton applied this method to both numerical and algebraic problems, producing Taylor series in the latter case.

Newton may have derived his method from a similar but less precise method by Vieta. The essence of Vieta's method can be found in the work of the Persian mathematician Sharaf al-Din al-Tusi, while his successor Jamshīd al-Kāshī used a form of Newton's method to solve to find roots of (Ypma 1995). A special case of Newton's method for calculating square roots was known since ancient times and is often called the Babylonian method.

Newton's method was used by 17th-century Japanese mathematician Seki Kōwa to solve single-variable equations, though the connection with calculus was missing.

Newton's method was first published in 1685 in "A Treatise of Algebra both Historical and Practical" by John Wallis. In 1690, Joseph Raphson published a simplified description in "Analysis aequationum universalis". Raphson also applied the method only to polynomials, but he avoided Newton's tedious rewriting process by extracting each successive correction from the original polynomial. This allowed him to derive a reusable iterative expression for each problem. Finally, in 1740, Thomas Simpson described Newton's method as an iterative method for solving general nonlinear equations using calculus, essentially giving the description above. In the same publication, Simpson also gives the generalization to systems of two equations and notes that Newton's method can be used for solving optimization problems by setting the gradient to zero.

Arthur Cayley in 1879 in "The Newton–Fourier imaginary problem" was the first to notice the difficulties in generalizing Newton's method to complex roots of polynomials with degree greater than 2 and complex initial values. This opened the way to the study of the theory of iterations of rational functions.

Newton's method is an extremely powerful technique—in general the convergence is quadratic: as the method converges on the root, the difference between the root and the approximation is squared (the number of accurate digits roughly doubles) at each step. However, there are some difficulties with the method.

Newton's method requires that the derivative can be calculated directly. An analytical expression for the derivative may not be easily obtainable or could be expensive to evaluate. In these situations, it may be appropriate to approximate the derivative by using the slope of a line through two nearby points on the function. Using this approximation would result in something like the secant method whose convergence is slower than that of Newton's method.

It is important to review the proof of quadratic convergence of Newton's method before implementing it. Specifically, one should review the assumptions made in the proof. For situations where the method fails to converge, it is because the assumptions made in this proof are not met.

If the first derivative is not well behaved in the neighborhood of a particular root, the method may overshoot, and diverge from that root. An example of a function with one root, for which the derivative is not well behaved in the neighborhood of the root, is

for which the root will be overshot and the sequence of will diverge. For , the root will still be overshot, but the sequence will oscillate between two values. For , the root will still be overshot but the sequence will converge, and for the root will not be overshot at all.

In some cases, Newton's method can be stabilized by using successive over-relaxation, or the speed of convergence can be increased by using the same method.

If a stationary point of the function is encountered, the derivative is zero and the method will terminate due to division by zero.

A large error in the initial estimate can contribute to non-convergence of the algorithm. To overcome this problem one can often linearise the function that is being optimized using calculus, logs, differentials, or even using evolutionary algorithms, such as the stochastic tunneling. Good initial estimates lie close to the final globally optimal parameter estimate. In nonlinear regression, the sum of squared errors (SSE) is only "close to" parabolic in the region of the final parameter estimates. Initial estimates found here will allow the Newton–Raphson method to quickly converge. It is only here that the Hessian matrix of the SSE is positive and the first derivative of the SSE is close to zero.

In a robust implementation of Newton's method, it is common to place limits on the number of iterations, bound the solution to an interval known to contain the root, and combine the method with a more robust root finding method.

If the root being sought has multiplicity greater than one, the convergence rate is merely linear (errors reduced by a constant factor at each step) unless special steps are taken. When there are two or more roots that are close together then it may take many iterations before the iterates get close enough to one of them for the quadratic convergence to be apparent. However, if the multiplicity formula_8 of the root is known, the following modified algorithm preserves the quadratic convergence rate:

This is equivalent to using successive over-relaxation. On the other hand, if the multiplicity of the root is not known, it is possible to estimate formula_8 after carrying out one or two iterations, and then use that value to increase the rate of convergence.

Suppose that the function has a zero at , i.e., , and is differentiable in a neighborhood of .

If is continuously differentiable and its derivative is nonzero at , then there exists a neighborhood of such that for all starting values in that neighborhood, the sequence will converge to .

If the function is continuously differentiable and its derivative is not 0 at and it has a second derivative at then the convergence is quadratic or faster. If the second derivative is not 0 at then the convergence is merely quadratic. If the third derivative exists and is bounded in a neighborhood of , then:

where

If the derivative is 0 at , then the convergence is usually only linear. Specifically, if is twice continuously differentiable, and , then there exists a neighborhood of such that, for all starting values in that neighborhood, the sequence of iterates converges linearly, with rate 1/2 Alternatively, if and for ,  in a neighborhood of , being a zero of multiplicity , and if , then there exists a neighborhood of such that, for all starting values in that neighborhood, the sequence of iterates converges linearly.

However, even linear convergence is not guaranteed in pathological situations.

In practice, these results are local, and the neighborhood of convergence is not known in advance. But there are also some results on global convergence: for instance, given a right neighborhood of , if is twice differentiable in and if , in , then, for each in the sequence is monotonically decreasing to .

According to Taylor's theorem, any function which has a continuous second derivative can be represented by an expansion about a point that is close to a root of . Suppose this root is . Then the expansion of about is:
where the Lagrange form of the Taylor series expansion remainder is

where is in between and .

Since is the root, () becomes:
Dividing equation () by and rearranging gives
Remembering that is defined by
one finds that

That is,
Taking absolute value of both sides gives

Equation () shows that the rate of convergence is at least quadratic if the following conditions are satisfied:


The term "sufficiently" close in this context means the following:
\right |<C\left |{\frac {f"(\alpha)}{f'(\alpha)}}\right |,</math> for some ;

Finally, () can be expressed in the following way:
where is the supremum of the variable coefficient of on the interval defined in condition 1, that is:

The initial point has to be chosen such that conditions 1 to 3 are satisfied, where the third condition requires that .

The disjoint subsets of the basins of attraction—the regions of the real number line such that within each region iteration from any point leads to one particular root—can be infinite in number and arbitrarily small. For example, for the function , the following initial conditions are in successive basins of attraction:

Newton's method is only guaranteed to converge if certain conditions are satisfied. If the assumptions made in the proof of quadratic convergence are met, the method will converge. For the following subsections, failure of the method to converge indicates that the assumptions made in the proof were not met.

In some cases the conditions on the function that are necessary for convergence are satisfied, but the point chosen as the initial point is not in the interval where the method converges. This can happen, for example, if the function whose root is sought approaches zero asymptotically as goes to or . In such cases a different method, such as bisection, should be used to obtain a better estimate for the zero to use as an initial point.

Consider the function:

It has a maximum at and solutions of at . If we start iterating from the stationary point (where the derivative is zero), will be undefined, since the tangent at (0,1) is parallel to the -axis:

The same issue occurs if, instead of the starting point, any iteration point is stationary. Even if the derivative is small but not zero, the next iteration will be a far worse approximation.

For some functions, some starting points may enter an infinite cycle, preventing convergence. Let

and take 0 as the starting point. The first iteration produces 1 and the second iteration returns to 0 so the sequence will alternate between the two without converging to a root. In fact, this 2-cycle is stable: there are neighborhoods around 0 and around 1 from which all points iterate asymptotically to the 2-cycle (and hence not to the root of the function). In general, the behavior of the sequence can be very complex (see Newton fractal). The real solution of this equation is ….

If the function is not continuously differentiable in a neighborhood of the root then it is possible that Newton's method will always diverge and fail, unless the solution is guessed on the first try.

A simple example of a function where Newton's method diverges is trying to find the cube root of zero. The cube root is continuous and infinitely differentiable, except for , where its derivative is undefined:

For any iteration point , the next iteration point will be:

The algorithm overshoots the solution and lands on the other side of the -axis, farther away than it initially was; applying Newton's method actually doubles the distances from the solution at each iteration.

In fact, the iterations diverge to infinity for every , where . In the limiting case of (square root), the iterations will alternate indefinitely between points and , so they do not converge in this case either.

If the derivative is not continuous at the root, then convergence may fail to occur in any neighborhood of the root. Consider the function

Its derivative is:

Within any neighborhood of the root, this derivative keeps changing sign as approaches 0 from the right (or from the left) while for .

So is unbounded near the root, and Newton's method will diverge almost everywhere in any neighborhood of it, even though:

In some cases the iterates converge but do not converge as quickly as promised. In these cases simpler methods converge just as quickly as Newton's method.

If the first derivative is zero at the root, then convergence will not be quadratic. Let

then and consequently

So convergence is not quadratic, even though the function is infinitely differentiable everywhere.

Similar problems occur even when the root is only "nearly" double. For example, let

Then the first few iterations starting at are
it takes six iterations to reach a point where the convergence appears to be quadratic.

If there is no second derivative at the root, then convergence may fail to be quadratic. Let
Then
And
except when where it is undefined. Given ,

which has approximately times as many bits of precision as has. This is less than the 2 times as many which would be required for quadratic convergence. So the convergence of Newton's method (in this case) is not quadratic, even though: the function is continuously differentiable everywhere; the derivative is not zero at the root; and is infinitely differentiable except at the desired root.

When dealing with complex functions, Newton's method can be directly applied to find their zeroes. Each zero has a basin of attraction in the complex plane, the set of all starting values that cause the method to converge to that particular zero. These sets can be mapped as in the image shown. For many complex functions, the boundaries of the basins of attraction are fractals.

In some cases there are regions in the complex plane which are not in any of these basins of attraction, meaning the iterates do not converge. For example, if one uses a real initial condition to seek a root of , all subsequent iterates will be real numbers and so the iterations cannot converge to either root, since both roots are non-real. In this case almost all real initial conditions lead to chaotic behavior, while some initial conditions iterate either to infinity or to repeating cycles of any finite length.

Curt McMullen has shown that for any possible purely iterative algorithm similar to Newton's method, the algorithm will diverge on some open regions of the complex plane when applied to some polynomial of degree 4 or higher. However, McMullen gave a generally convergent algorithm for polynomials of degree 3.

One may also use Newton's method to solve systems of (nonlinear) equations, which amounts to finding the zeroes of continuously differentiable functions . In the formulation given above, one then has to left multiply with the inverse of the Jacobian matrix instead of dividing by :

Rather than actually computing the inverse of the Jacobian matrix, one can save time by solving the system of linear equations

for the unknown .

The -dimensional variant of Newton's method can be used to solve systems of greater than (nonlinear) equations as well if the algorithm uses the generalized inverse of the non-square Jacobian matrix instead of the inverse of . If the nonlinear system has no solution, the method attempts to find a solution in the non-linear least squares sense. See Gauss–Newton algorithm for more information.

Another generalization is Newton's method to find a root of a functional defined in a Banach space. In this case the formulation is

where is the Fréchet derivative computed at . One needs the Fréchet derivative to be boundedly invertible at each in order for the method to be applicable. A condition for existence of and convergence to a root is given by the Newton–Kantorovich theorem.

In -adic analysis, the standard method to show a polynomial equation in one variable has a -adic root is Hensel's lemma, which uses the recursion from Newton's method on the -adic numbers. Because of the more stable behavior of addition and multiplication in the -adic numbers compared to the real numbers (specifically, the unit ball in the -adics is a ring), convergence in Hensel's lemma can be guaranteed under much simpler hypotheses than in the classical Newton's method on the real line.

The Newton–Fourier method is Joseph Fourier's extension of Newton's method to provide bounds on the absolute error of the root approximation, while still providing quadratic convergence.

Assume that is twice continuously differentiable on and that contains a root in this interval. Assume that on this interval (this is the case for instance if , , and , and on this interval). This guarantees that there is a unique root on this interval, call it . If it is concave down instead of concave up then replace by since they have the same roots.

Let be the right endpoint of the interval and let be the left endpoint of the interval. Given , define

which is just Newton's method as before. Then define

where the denominator is and not . The iterations will be strictly decreasing to the root while the iterations will be strictly increasing to the root. Also,

so that distance between and decreases quadratically.

When the Jacobian is unavailable or too expensive to compute at every iteration, a quasi-Newton method can be used.

Newton's method can be generalized with the q-analog of the usual derivative.

A nonlinear equation has multiple solutions in general. But if the initial value is not appropriate, Newton's method may not converge to the desired solution or may converge to the same solution found earlier. When we have already found N solutions of formula_38, then the next root can be found by applying Newton's method to the next equation:

This method is applied to obtain zeros of the Bessel function of the second kind.

Hirano's modified Newton method is a modification conserving the convergence of Newton method and avoiding unstableness. It is developed to solve complex polynomials.

Combining Newton's method with interval arithmetic is very useful in some contexts. This provides a stopping criterion that is more reliable than the usual ones (which are a small value of the function or a small variation of the variable between consecutive iterations). Also, this may detect cases where Newton's method converges theoretically but diverges numerically because of an insufficient floating-point precision (this is typically the case for polynomials of large degree, where a very small change of the variable may change dramatically the value of the function; see Wilkinson's polynomial).

Consider formula_40, where formula_41 is a real interval, and suppose that we have an interval extension formula_42 of formula_43, meaning that formula_42 takes as input an interval formula_45 and outputs an interval formula_46 such that:
We also assume that formula_48, so in particular formula_49 has at most one root in formula_41.
We then define the interval Newton operator by:

where formula_52. Note that the hypothesis on formula_42 implies that formula_54 is well defined and is an interval (see interval arithmetic for further details on interval operations). This naturally leads to the following sequence:
The mean value theorem ensures that if there is a root of formula_49 in formula_57, then it is also in formula_58. Moreover, the hypothesis on formula_42 ensures that formula_58 is at most half the size of formula_57 when formula_8 is the midpoint of formula_63, so this sequence converges towards formula_64, where formula_65 is the root of formula_49 in formula_41.

If formula_68 strictly contains formula_69, the use of extended interval division produces a union of two intervals for formula_70 ; multiple roots are therefore automatically separated and bounded.

Newton's method can be used to find a minimum or maximum of a function formula_71. The derivative is zero at a minimum or maximum, so local minima and maxima can be found by applying Newton's method to the derivative. The iteration becomes:

An important application is Newton–Raphson division, which can be used to quickly find the reciprocal of a number , using only multiplication and subtraction, that is to say the number such that . We can rephrase that as finding the zero of . We have .

Newton's iteration is
Therefore, Newton's iteration needs only two multiplications and one subtraction.

This method is also very efficient to compute the multiplicative inverse of a power series.

Many transcendental equations can be solved using Newton's method. Given the equation
with and/or a transcendental function, one writes
The values of that solve the original equation are then the roots of , which may be found via Newton's method.

Newton's method is applied to the ratio of Bessel functions in order to obtain its root.

A numerical verification for solutions of nonlinear equations has been established by using Newton's method multiple times and forming a set of solution candidates.

An iterative Newton-Raphson procedure was employed in order to impose a stable Dirichlet boundary condition in CFD, as a quite general strategy to model current and potential distribution for electrochemical cell stacks.

Consider the problem of finding the square root of a number "a", that is to say the positive number such that . Newton's method is one of many methods of computing square roots. We can rephrase that as finding the zero of . We have .

For example, for finding the square root of 612 with an initial guess , the sequence given by Newton's method is:

where the correct digits are underlined. With only a few iterations one can obtain a solution accurate to many decimal places.

Rearranging the formula as follows yields the Babylonian method of finding square roots:

i.e. the arithmetic mean of the guess, and .

Consider the problem of finding the positive number with . We can rephrase that as finding the zero of . We have . Since for all and for , we know that our solution lies between 0 and 1.

For example, with an initial guess , the sequence given by Newton's method is (note that a starting value of 0 will lead to an undefined result, showing the importance of using a starting point that is close to the solution):

The correct digits are underlined in the above example. In particular, is correct to 12 decimal places. We see that the number of correct digits after the decimal point increases from 2 (for ) to 5 and 10, illustrating the quadratic convergence.

The following is an implementation example of the Newton's method in the Julia programming language for finding a root of a function codice_1 which has derivative codice_2.

The initial guess will be and the function will be so that .

Each new iteration of Newton's method will be denoted by codice_3. We will check during the computation whether the denominator (codice_4) becomes too small (smaller than codice_5), which would be the case if , since otherwise a large amount of error could be introduced.
x0 = 1 # The initial guess
f(x) = x^2 - 2 # The function whose root we are trying to find
fprime(x) = 2x # The derivative of the function
tolerance = 1e-7 # 7 digit accuracy is desired
epsilon = 1e-14 # Do not divide by a number smaller than this
maxIterations = 20 # Do not allow the iterations to continue indefinitely
solutionFound = false # Have not converged to a solution yet

for i = 1:maxIterations

end

if solutionFound
else
end





</doc>
<doc id="22146" url="https://en.wikipedia.org/wiki?curid=22146" title="New Order (band)">
New Order (band)

New Order are an English rock band formed in 1980 by vocalist and guitarist Bernard Sumner, bassist Peter Hook, and drummer Stephen Morris. The band formed after the demise of Joy Division, following the suicide of lead singer Ian Curtis; they were joined by Gillian Gilbert on keyboards later that year. New Order's integration of post-punk with electronic and dance music made them one of the most acclaimed and influential bands of the 1980s. They were the flagship band for Manchester-based independent record label Factory Records and its nightclub The Haçienda, and worked in long-term collaboration with graphic designer Peter Saville.

While the band's early years were overshadowed by the legacy of Joy Division, their experience of the early 1980s New York club scene saw them increasingly incorporate dance rhythms and electronic instrumentation into their work. Their 1983 hit "Blue Monday" became the best-selling 12-inch single of all time and a popular club track. In the 1980s, they released successful albums such as "Power, Corruption & Lies" (1983), "Technique" (1989), and the singles compilation "Substance" (1987). They disbanded in 1993 to work on individual projects before reuniting in 1998. In the years since, New Order has gone through various hiatuses and personnel changes, most prominently the departure of Hook in 2007. They released their tenth studio album, "Music Complete", in 2015.

Between 1977 and 1980, Ian Curtis, Peter Hook, Stephen Morris, and Bernard Sumner were members of the post-punk band Joy Division, often featuring heavy production input from producer Martin Hannett. Curtis took his own life on 18 May 1980, the day before Joy Division were scheduled to depart for their first American tour, and prior to the release of the band's second album, "Closer". The rest of the band decided soon after Curtis's death that they would carry on. Prior to his death, the members of Joy Division had agreed not to continue under the Joy Division name should any one member leave. On 29 July 1980, the still unnamed trio debuted live at Manchester's Beach Club. Rob Gretton, the band's manager for over twenty years, is credited for having found the name "New Order" in an article in "The Guardian" entitled "The People's New Order of Kampuchea". The band adopted this name, despite its previous use for former Stooge Ron Asheton's band The New Order. The group states that the name New Order (as was also the case with "Joy Division") does not draw a direct line to National Socialism or Fascism.

The band rehearsed with each member taking turns on vocals. Sumner ultimately took the role, as he could sing when he wasn't playing his guitar. They wanted to complete the line-up with someone they knew well and whose musical skill and style was compatible with their own. Gretton suggested Morris's girlfriend Gillian Gilbert, and she was invited to join the band in early October 1980, as keyboardist and guitarist. Her first live performance with the band occurred at The Squat in Manchester on 25 October 1980.

The initial release as New Order was the single "Ceremony", backed with "In a Lonely Place". These two songs were written in the weeks before Curtis took his own life. With the release of "Movement" in November 1981, New Order initially started on a similar route as their previous incarnation, performing dark, melodic songs, albeit with an increased use of synthesisers. The band viewed the period as a low point, as they were still reeling from Curtis' death. Hook commented that the only positive thing to come out of the "Movement" sessions was that producer Martin Hannett had showed the band how to use a mixing board, which allowed them to produce records by themselves from then on. More recently, Hook indicated a change of heart: "I think "Movement" gets a raw deal in general really – for me, when you consider the circumstances in which it was written, it is a fantastic record."

New Order visited New York City again in 1981, where the band were introduced to post-disco, freestyle and electro. The band had taken to listening to Italian disco to cheer themselves up, while Morris taught himself drum programming. The singles that followed, "Everything's Gone Green" and "Temptation", saw a change in direction toward dance music.

The Haçienda, Factory Records' own nightclub (largely funded by New Order) opened in May 1982 in Manchester and was even issued a Factory catalogue number: FAC51. The opening of UK's first ever superclub was marked by a nearly 23-minute instrumental piece originally entitled "Prime 5 8 6", but released 15 years later as "Video 5 8 6". Composed primarily by Sumner and Morris, "Prime 5 8 6"/"Video 5 8 6" was an early version of "5 8 6" that contained rhythm elements that would later surface on "Blue Monday" and "Ultraviolence".

New Order played Glastonbury in 1981, June 19-21

"Power, Corruption & Lies", released in May 1983, was a synthesiser-based outing and a dramatic change in sound from Joy Division and the preceding album, although the band had been hinting at the increased use of technology during the music-making process for a number of years then, including their work as Joy Division. Starting from what earlier singles had hinted, this was where the band had found their footing, mixing early techno music with their earlier guitar-based sound and showing the strong influence of acts like Kraftwerk and Giorgio Moroder. Even further in this direction was the electronically sequenced, four-on-the-floor single "Blue Monday". Inspired by Klein + M.B.O.'s "Dirty Talk" and Sylvester's disco classic, "You Make Me Feel (Mighty Real)", "Blue Monday" became the best-selling independent 12" single of all time in the UK; however, (much to the chagrin of the buying public) it was not on the track list of "Power, Corruption & Lies". This resulted in a sticker being applied to unsold copies of "Power, Corruption & Lies" album saying, "DOES NOT CONTAIN BLUE MONDAY". The song was included however on the cassette format in some countries, such as Australia and New Zealand, and on the original North American CD release of the album, alongside its B-side, "The Beach". "Blue Monday" was also included on the 2008 collector's edition of "Power, Corruption & Lies".

The 1983 single "Confusion" firmly established the group as a dance music force, inspiring many musicians in subsequent years. In 1984 they followed the largely synthesised single "Thieves Like Us" with the heavy guitar-drum-bass rumble of "Murder", a not-too-distant cousin of "Ecstasy" from the "Power, Corruption & Lies" album. KROQ Los Angeles DJ Jed The Fish claims New Order had more to do with the emergence of house music than the Warehouse music of Chicago and “Frankie Knuckles and the whole so-called House music scene. Unless you were actually from regional Chicago, had you ever heard of House music until New Order? Be real, now.”

1985's "Low-Life" refined and sometimes mixed the two styles, guitar-based and electronic, and included "The Perfect Kiss"—the video for which was filmed by Jonathan Demme—and "Sub-culture". In February 1986, the soundtrack album to "Pretty in Pink" featuring "Shellshock" was released on A&M Records. An instrumental version of "Thieves Like Us" and the instrumental "Elegia" appeared in the film but were not on the soundtrack album. Later that summer, New Order headlined a line-up that included the Smiths, the Fall, and A Certain Ratio during the Festival of the Tenth Summer at Manchester's G-Mex.

"Brotherhood" (1986) divided the two approaches onto separate album sides. The album notably featured "Bizarre Love Triangle" (a Top 20 hit in Australia and New Zealand) and "Angel Dust" (of which a remixed instrumental version is available on the UK "True Faith" CD video single, under the title "Evil Dust"), a track which marries a synth break beat with "Low-Life"-era guitar effects. While New Order toured North America with friends Echo & the Bunnymen, the summer of 1987 saw the release of the compilation "Substance", which featured the new single "True Faith". "Substance" was an important album in collecting the group's 12-inch singles onto CD for the first time and featured new versions of "Temptation" and "Confusion"—referred to as "Temptation '87" and "Confusion '87". A second disc featured several of the B-sides from the singles on the first disc, as well as additional A-sides "Procession" and "Murder". The single, "True Faith", with its surreal video, became a hit on MTV and the band's first American top 40 hit. The single's B-side, "1963"—originally planned on being the A-side until the group's label convinced them to release "True Faith" instead—would later be released as a single in its own right several years later, with two new versions.

In December 1987, the band released a further single, "Touched by the Hand of God", with a Kathryn Bigelow-directed video parodying glam-metal. The song was one of four new tracks recorded for the American comedy film "Salvatation!", and reached number 20 on the UK Singles Chart and number 1 in the UK Independent Singles chart. However, it would not appear on an album until the 1994 compilation "The Best of New Order".

By this time, the group was heavily influenced by the Balearic sounds of Ibiza, which were making their way into the Haçienda. Partly recorded at Mediterranean Sound studios on Ibiza, "Technique" was released in February 1989. The album entered the charts at number one in the UK and contained a mix of acid house influence (as on opening track "Fine Time") and a more traditional rock sound (as on the single "Run 2"). The album is a blend of upbeat, accessible music coupled with blunt, poignant lyrics. During the summer of 1989, New Order supported "Technique" by touring with Public Image Ltd, Throwing Muses and The Sugarcubes across the United States and Canada in what the press dubbed the "Monsters of Alternative Rock" tour. Around this time, band members also began side projects including Electronic (Sumner with Johnny Marr) and Revenge (Hook with Davyth Hicks). Morris and Gilbert began to work together on outside TV theme production work. In 1991, the band were sued by the publishing company of American singer John Denver, who alleged that the guitar break in "Run 2" was similar to his song "Leaving on a Jet Plane". The case was settled out of court and the song has since been credited to both New Order and John Denver.

In 1990, New Order recorded the official song of the England national football team's 1990 World Cup campaign, "World in Motion", under the ad hoc band name EnglandNewOrder. The song, co-written with comedian Keith Allen, was the band's sole number one UK hit. The song was originally planned to be titled "E for England", however the Football Association vetoed the title upon realising that this was a reference to ecstasy; a drug heavily associated with the Haçienda. (Allen claimed that his original draft lyrics included "E is for England, England starts with E / We'll all be smiling when we're in Italy.") The song also featured chanting from members of the England team and Allen, and a guest rap from left winger John Barnes. It was again produced by Stephen Hague, who the band chose to produce their next album.

The band's next album "Republic" was shadowed by the collapse of their longtime label Factory Records. The label had been ailing due to financial difficulties, and was forced to declare bankruptcy in 1992. New Order never had a formal contract with Factory. Although unusual for a major group, this was Factory's standard practice until the mid-1980s. Because of this, the band, rather than Factory Records, legally owned all of their recordings. This has been cited by Wilson himself as the main reason London Records' 1992 offer to buy the ailing label fell through. Following Factory's collapse, New Order signed with London, as did Morris and Gilbert separately for their side project The Other Two, whose debut album was originally intended for release on Factory. "Republic", released around the world in 1993, spawned the singles "Regret"—New Order's highest-charting single in the US—"Ruined in a Day", "World", and "Spooky".

Following the release and promotion of "Republic", the band put New Order on hold while focusing on side projects; with The Other Two's debut album released in 1993. In 1994, a second singles collection was released, entitled "The Best of New Order". It featured all of the band's singles since "Substance" as well as a few extra tracks: "Vanishing Point" (from 1989's "Technique"), "The Perfect Kiss", "Thieves Like Us", "Shellshock", and new recordings of "True Faith", "Bizarre Love Triangle", "1963", and "Round & Round". The new versions of "True Faith" and "1963" (the latter as a more guitar-oriented version produced by Arthur Baker) were released as singles to promote the album. In the US, the track listing was altered to set it apart from "Substance" as well as the UK release of "The Best of New Order" which had been available months prior. This collection was followed by a remix album, "The Rest of New Order", featuring a selection of existing and newly commissioned mixes of classic New Order tracks. Some versions contained an extra disc or cassette composed entirely of remixes of "Blue Monday". "Blue Monday" was released as a single for a third time to promote the collection.

The group reconvened in 1998 at the suggestion of Rob Gretton. Nearly five years had passed since they had last seen each other. Sumner said, "We decided before we agreed to doing any gig, to have a meeting, and if anyone had any grudges to bear, to iron them out." By the second meeting everyone agreed to continue playing, scheduling their reunion gig for the Phoenix Festival that same year. In addition to rarer songs, New Order also decided to begin playing Joy Division songs again. When the Phoenix Festival was cancelled due to low ticket sales, New Order instead played the last night of that year's Reading Festival.

Their 2001 release "Get Ready" largely departed from their more electronic style and focused on more guitar oriented music. According to Sumner, ""Get Ready" was guitar-heavy simply because we felt that we'd left that instrument alone for a long time." Longtime fan Billy Corgan of The Smashing Pumpkins played guitar and sang back-up on the track "Turn My Way," and in 2001 toured with the band on dates in the UK, US, and Japan for a short period of time. Phil Cunningham (formerly of Marion) joined the band in a live capacity, deputising for Gilbert who declined to tour in favour of caring for her and Morris' children. Primal Scream's Bobby Gillespie provided vocals on the track "Rock the Shack". Singles from the album included "Crystal," "60 Miles an Hour" and Someone Like You."

In 2002, "Q" featured New Order on their list of the "50 Bands to See Before You Die", although this was as part of a sub-list of "5 Bands That Could Go Either Way". Both New Order and Joy Division were portrayed in the Michael Winterbottom film "24 Hour Party People", depicting the rise and fall of Factory Records as seen through the eyes of label founder Tony Wilson. Cameos by Wilson himself, along with Mark E. Smith of The Fall and former members of Happy Mondays and Inspiral Carpets, lent a degree of legitimacy to the proceedings. The film touched on some of Factory's other artists, including Happy Mondays and The Durutti Column. The soundtrack featured the new track "Here to Stay," produced by the Chemical Brothers, which was released as a single. The single's music video highlighted scenes taken from the film.

The band released a new album on 27 March 2005, titled "Waiting for the Sirens' Call", their first with new member Phil Cunningham. Cunningham replaced Gilbert (now married to Morris) so she could look after their children. Singles from this album were "Krafty", "Jetstream" (which features guest vocals by Ana Matronic from Scissor Sisters), and the title track. At the 2005 NME Awards, New Order and Joy Division received the award for "Godlike Geniuses" (for lifetime achievement). Previous winners include Ozzy Osbourne, The Clash, and Happy Mondays. In 2006 the album track "Guilt Is a Useless Emotion" was nominated for a Grammy Award in the category of Best Dance Recording.

In the autumn of 2005, the group released another greatest hits compilation, in the form of "Singles". The two-disc release was an updated version of the "Substance" collection and contained every single released from their 1981 debut all the way through to "Waiting for the Sirens' Call". However, unlike "Substance", which focused almost exclusively on the 12" versions of the group's singles, "Singles" collected the 7" versions, many of which (like "Ceremony", "Temptation" and "Confusion") had never been released on CD. The album was accompanied by a two-disc DVD set, titled "Item", that collected the extended UK version of "NewOrderStory" with a DVD of all New Order music videos as well as two newly commissioned videos for "Temptation '87" and "Ceremony".

The "New Order: Live in Glasgow" DVD was recorded at the Glasgow Academy in 2006 and features 18 tracks, including 4 Joy Division songs. Next to that, the release also contains a bonus disc of footage from the band's personal archive including 1980s footage from Glastonbury (June 1981), Rome, Cork, Rotterdam and Toronto.

In 2006, the band played several one-off live dates as well as short tours in the UK, Brazil and Argentina. After their Buenos Aires show in November 2006, Peter Hook suggested that the band should stop touring. In early May 2007, Hook was interviewed by British radio station XFM – originally to talk about his contribution to the debut album of Jane's Addiction singer Perry Farrell's new band Satellite Party – and stated that "Me and Bernard aren't working together." Further complicating the news, NewOrderOnline, a website with support from New Order management, reported that according to "a source close to the band", "The news about the split is false... New Order still exists despite what [Hook] said … Peter Hook can leave the band, but this doesn't mean the end of New Order." However, Sumner revealed in 2009 that he no longer wished to make music as New Order.

In September 2011, the band announced that they would perform for the first time since 2006, at the Ancienne Belgique, Brussels on 17 October and at the Bataclan, Paris on 18 October. The band's line-up included keyboardist Gillian Gilbert, who returned to the band after a ten-year break, and Bad Lieutenant bassist Tom Chapman in place of Peter Hook. They played subsequent shows in London and South America in December.

In December 2011, New Order released "Live at the London Troxy", a live album from their performance of 10 December 2011 at The Troxy in London. This release featured the new lineup and their first show in London in over five years.
They continued to tour throughout 2012, including a short tour of New Zealand and Australia in February/March. They played at the 'T in the Park' festival in Scotland on 3 and 4 July 2012 and at the EXIT Festival in Novi Sad Serbia on 13 July 2012. New Order performed at Hyde Park with Blur and The Specials to celebrate the 2012 Summer Olympics closing ceremony.

"Lost Sirens" was released in the United Kingdom on 14 January 2013. "Lost Sirens" is an eight-track album of tracks left out of "Waiting for the Sirens' Call". The album was discussed by Gillian Gilbert in a Brazilian interview to promote the band's appearance in São Paulo. She acknowledged issues with former member Peter Hook, and stated there was "a lot going on behind the scenes on the copyright" delaying the release.

The band debuted their first newly written song since the "Waiting for the Sirens' Call" sessions, titled "Singularity", during Lollapalooza Chile in March 2014. In July, the group toured North America, where they debuted the song "Plastic". On 2 September it was announced that the band decided to release their new album through Mute Records. The New Order catalogue remains with Warner Music.

On 22 September 2015, the band released a new album, "Music Complete", their first without Peter Hook. The album was produced mostly by the band themselves, except "Singularity" and "Unlearn This Hatred", both produced by Tom Rowlands, while "Superheated" features additional production by Stuart Price.

In November 2015, Peter Hook sued Bernard Sumner, Stephen Morris and Gillian Gilbert. In an objection, he claimed that they set up a new company behind his back and it has generated an income of £7.8 million in four years while he received only a fraction of that. The three members insisted they had treated Hook fairly and that his stake in the band's royalties was reasonable. The judge ruled that there was "at least a reasonable prospect" of Hook proving that he was not getting a fair share of royalties and other income. He was willing to hear the case but urged the parties to come to an agreement rather than suffer legal costs of around £900,000.

On 13 July 2017, New Order played a concert at Manchester International Festival with Liam Gillick. The performance was then released as a live album titled "∑(No,12k,Lg,17Mif) New Order + Liam Gillick: So it goes.. (Live at MIF)" on July 12, 2019.

On 20 September 2017, a posting on New Order's official website announced that a full and final settlement had been reached in the long running disputes with their former bassist Peter Hook.

On 23 August 2018, the band played the first date of a North American tour at the Palace Theatre in St. Paul Minnesota, US. According to the band's official website, other stops on the tour included Cleveland, Ohio; Washington, DC; Toronto, Ontario; Long Beach, California; Kahului, Hawaii; and Honolulu, Hawaii. As of 24 August 2018, a single show in Santiago, Chile had been announced for 21 November 2018.

In January 2020, the band played a four night residency in Florida, and in February 2020, they announced a co-headlining tour in North America with the Pet Shop Boys, and that the only concert in the UK in 2020 would be at The O2 on 10 October.

In 1988, Bernard Sumner teamed up with former Smiths guitarist Johnny Marr to form the group Electronic, also enlisting the help of Neil Tennant and Chris Lowe of the Pet Shop Boys. Electronic regrouped in 1996 for "Raise the Pressure", which also featured Karl Bartos (formerly of Kraftwerk). The project's third album "Twisted Tenderness" was released in 1999 after which the band dissolved.

In June 2009, Bernard Sumner formed a new band called Bad Lieutenant with Phil Cunningham (guitar) and Jake Evans (guitar and vocals). Their album "Never Cry Another Tear" was released on 5 October 2009. In addition to Cunningham and Evans the album also features appearances by Stephen Morris (drums), Jack Mitchell (drums), Tom Chapman (bass) and Alex James (bass). The live band included Morris on drums and Tom Chapman on bass.

Hook has been involved with several other projects. In the 1990s, Hook recorded with Killing Joke with a view to joining the band. However, original bassist Martin 'Youth' Glover instead returned to the band. In 1995 he toured with The Durutti Column. He has recorded one album with the band Revenge with Davyth Hicks and Chris Jones and two with Monaco (both as bassist, keyboardist and lead vocalist) with David Potts. Monaco scored a club and alternative radio hit with "What Do You Want From Me?" in 1997. Hook also formed a band called Freebass with fellow bass players Mani (The Stone Roses) and Andy Rourke (The Smiths) and vocalist Gary Briggs, which was active from 2007 to 2010. He also contributed to Perry Farrell's Satellite Party. Hook's current band Peter Hook and The Light is touring Joy Division and New Order albums in their entirety.

In 1990 Gilbert and Morris formed their own band, The Other Two. The Other Two released its first single "Tasty Fish" in 1991 and released two albums, "The Other Two & You" in 1993 and "Super Highways" in 1999. They have also been involved in scoring television soundtracks. In 2007, Gilbert and Morris remixed two tracks for the Nine Inch Nails remixes album "Year Zero Remixed".

"BeMusic" was a name the band used for their publishing company (the LP label for "Movement" says "B Music" in large letters, though using an italic ß for the letter B). All four members of the band used the name for production work for other artists' recordings between 1982 and 1985.

The first BeMusic credit was for Peter Hook producing Stockholm Monsters in 1982. Other artists with producer or musician credit for "BeMusic" were 52nd Street, Section 25, Marcel King, Quando Quango, Paul Haig, Thick Pigeon, Nyam Nyam and Life.

Their production work as BeMusic was collected on two LTM Recordings compilation CDs, "Cool As Ice: The BeMusic Productions" and "Twice As Nice" (which also included production work by Donald Johnson, of A Certain Ratio, and Arthur Baker).

New Order's music mixes rock with dance music, as can be seen on signature tracks such as 1982's "Temptation", 1983's "Blue Monday" and 1987's "True Faith". Founding member Hook stated that the band's shift from playing cold dark tracks from 1981 to producing electro/rock tracks from 1982 was inspired by the music of German electronic group Kraftwerk, US rock band Sparks who had produced disco/electro-rock music with producer Giorgio Moroder on their "No. 1 in Heaven" album, and also the Moroder/Donna Summer collaboration on "I Feel Love". New Order's collaboration with New York DJ Arthur Baker was inspired by the records' sounds of Grandmaster Flash and the Furious Five and Afrika Bambaataa & the Soulsonic Force.

The group's album art earned them the status of icons in the alternative community, and has shown considerable longevity. According to an unsigned "Allmusic" text, the band are also regarded as "the first alternative dance" music group with their fusion of "used icy, gloomy post-punk with Kraftwerk-style synth-pop" and were also labeled as synth-pop, post-punk, new wave, dance-rock and electronica.

They have heavily influenced techno, rock, and pop musicians including the Pet Shop Boys, 808 State, Arcade Fire, and Moby, and were themselves influenced by the likes of David Bowie, Neu!, Kraftwerk, Cabaret Voltaire and Giorgio Moroder. They have also significantly influenced electro, freestyle and house. New Order's Kraftwerk influence was acknowledged by their single "Krafty", which had cover art referencing "Autobahn".

Bassist Peter Hook contributed to New Order's sound by developing an idiosyncratic bass guitar technique. He often used the bass as a lead instrument, playing melodies on the high strings with a signature heavy chorus effect, leaving the actual basslines to keyboards or sequencers. This has often been cited as a defining characteristic of the New Order sound.

Drummer Stephen Morris plays a mixture of acoustic and electronic drums, and in many cases plays along seamlessly with sequenced parts. All the band members could and did switch instruments throughout gigs, as evidenced on Jonathan Demme's video for "The Perfect Kiss" and the concert videos "Taras Shevchenko" (recorded in New York, November 1981) and "Pumped Full of Drugs" (Tokyo, May 1985). During such live gigs, Sumner alternated between guitar, keyboards, melodica and (on the track "Confusion") bass; Gilbert switched between keyboards and guitar, Morris between drums and keyboards, and Hook played both bass and electronic drums. "Taras Shevchenko" is also notable for the fact all four members of the group have left the stage before the final song, "Temptation", comes to a complete end.

Both New Order and Joy Division were among the most successful artists on the Factory Records label, run by Granada television personality Tony Wilson, and partnered with Factory in the financing of the Manchester club The Haçienda. The band rarely gave interviews in the 1980s, later ascribing this to not wanting to discuss Ian Curtis. The band became more open in the 1990s; for example, the aforementioned "NewOrderStory" (and in particular the longer UK version) featured extensive personal interviews. Speaking in 2009, fellow synthpop musician Phil Oakey described New Order's slow-burn career as cult musicians as being unusually prolonged and effective: "If you want to make a lot of money out of pop, be number 3 a lot. Like New Order did." Despite this, the band have commented on the unplanned nature of their career and the considerable expense lost in supporting the Haçienda.

Almost all New Order recordings bear minimalist packaging, art directed by Peter Saville. The group's record sleeves bucked the 1980s trend by rarely showing the band members (with the exception of the "Low-Life" album) or even providing basic information such as the band name or title of the release. Song names were often hidden within the shrink wrapped package, either on the disc itself (such as the "Blue Monday" single), on an inconspicuous part of an inner sleeve ("The Perfect Kiss" single), or written in a cryptic colour code invented by Saville ("Power, Corruption & Lies"). Saville said his intention was to sell the band as a "mass-produced secret" of sorts, and that the minimalist style was enough to allow fans to identify the band's products without explicit labelling. Saville frequently sent the artwork straight to the printer, unreviewed by either the band or the label.

! Year !! Awards !! Work !! Category !! Result


Former members





</doc>
<doc id="22148" url="https://en.wikipedia.org/wiki?curid=22148" title="Niccolò Fontana Tartaglia">
Niccolò Fontana Tartaglia

Niccolò Fontana Tartaglia (; 1499/1500 – 13 December 1557) was an Italian mathematician, engineer (designing fortifications), a surveyor (of topography, seeking the best means of defense or offense) and a bookkeeper from the then-Republic of Venice (now part of Italy). He published many books, including the first Italian translations of Archimedes and Euclid, and an acclaimed compilation of mathematics. Tartaglia was the first to apply mathematics to the investigation of the paths of cannonballs, known as ballistics, in his "Nova Scientia" ("A New Science", 1537); his work was later partially validated and partially superseded by Galileo's studies on falling bodies. He also published a treatise on retrieving sunken ships.

Niccolò Fontana was born in Brescia, the son of Michele Fontana, a dispatch rider who travelled to neighboring towns to deliver mail. In 1506, Michele was murdered by robbers, and Niccolò, his two siblings, and his mother were left impoverished. Niccolò experienced further tragedy in 1512 when the King Louis XII's troops invaded Brescia during the War of the League of Cambrai against Venice. The militia of Brescia defended their city for seven days. When the French finally broke through, they took their revenge by massacring the inhabitants of Brescia. By the end of battle, over 45,000 residents were killed. During the massacre, Niccolò and his family sought sanctuary in the local cathedral. But the French entered and a soldier sliced Niccolò's jaw and palate with a saber and left him for dead. His mother nursed him back to health but the young boy was left with a speech impediment, prompting the nickname "Tartaglia" ("stammerer"). After this he would never shave, and grew a beard to camouflage his scars.

Tartaglia's biographer Arnoldo Masotti writes that:

Tartaglia moved to Verona around 1517, then to Venice in 1534, a major European commercial hub and one of the great centers of the Italian renaissance at this time. Also relevant is Venice's place at the forefront of European printing culture in the sixteenth century, making early printed texts available even to poor scholars if sufficiently motivated or well-connected — Tartaglia knew of Archimedes' work on the quadrature of the parabola, for example, from Guarico's Latin edition of 1503, which he had found "in the hands of a sausage-seller in Verona in 1531" ("in mano di un salzizaro in Verona, l'anno 1531" in his words).

Tartaglia eked out a living teaching practical mathematics in abacus schools and earned a penny where he could:

He died in Venice.

"Nova Scientia" (1537) was Tartaglia's first published work, described by Matteo Valleriani as:

Then dominant Aristotelian physics preferred categories like "heavy" and "natural" and "violent" to describe motion, generally eschewing mathematical explanations. Tartaglia brought mathematical models to the fore, "eviscerat[ing] Aristotelian terms of projectile movement" in the words Mary J. Henninger-Voss. One of his findings was that the maximum range of a projectile was achieved by directing the cannon at a 45° angle to the horizon.

Tartaglia's model for a cannonball's flight was that it proceeded from the cannon in a straight line, then after a while started to arc towards the earth along a circular path, then finally dropped in another straight line directly towards the earth. At the end of Book 2 of "Nova Scientia", Tartaglia proposes to find the length of that initial rectilinear path for a projectile fired at an elevation of 45°, engaging in a Euclidean-style argument, but one with numbers attached to line segments and areas, and eventually proceeds algebraically to find the desired quantity ("procederemo per algebra" in his words).

Mary J. Henninger-Voss notes that "Tartaglia's work on military science had an enormous circulation throughout Europe", being a reference for common gunners into the eighteenth century, sometimes through unattributed translations. He influenced Galileo as well, who owned "richly annotated" copies of his works on ballistics as he set about solving the projectile problem once and for all.

Archimedes' works began to be studied outside the universities in Tartaglia's day as exemplary of the notion that mathematics is the key to understanding physics, Federigo Commandino reflecting this notion when saying in 1558 that "with respect to geometry no one of sound mind could deny that Archimedes was some god". Tartaglia published a 71-page Latin edition of Archimedes in 1543, "Opera Archimedis Syracusani philosophi et mathematici ingeniosissimi", containing Archimedes' works on the parabola, the circle, centers of gravity, and floating bodies. Guarico had published Latin editions of the first two in 1503, but the works on centers of gravity and floating bodies had not been published before. Tartaglia published Italian versions of some Archimedean texts later in life, his executor continuing to publish his translations after his death. Galileo probably learned of Archimedes' work through these widely disseminated editions.

Tartaglia's Italian edition of Euclid in 1543, "Euclide Megarense philosopho", was especially significant as the first translation of the "Elements" into any modern European language. For two centuries Euclid had been taught from two Latin translations taken from an Arabic source; these contained errors in Book V, the Eudoxian theory of proportion, which rendered it unusable. Tartaglia's edition was based on Zamberti's Latin translation of an uncorrupted Greek text, and rendered Book V correctly. He also wrote the first modern and useful commentary on the theory. This work went through many editions in the sixteenth century and helped diffuse knowledge of mathematics to a non-academic but increasingly well-informed literate and numerate public in Italy. The theory became an essential tool for Galileo, as it had been for Archimedes.

Tartaglia exemplified and eventually transcended the abacco tradition that had flourished in Italy since the twelfth century, a tradition of concrete commercial mathematics taught at abacus schools maintained by communities of merchants. "Maestros d'abaco" like Tartaglia taught not with the abacus but with paper-and-pen, inculcating algorithms of the type found in grade schools today.

Tartaglia's masterpiece was the "General Trattato di Numeri et Misure" ("General Treatise on Number and Measure"), a 1500-page encyclopedia in six parts written in the Venetian dialect, the first three coming out in 1556 about the time of Tartaglia's death and the last three published posthumously by his literary executor and publisher Curtio Troiano in 1560. David Eugene Smith wrote of the "General Trattato" that it was:

Part I is 554 pages long and constitutes essentially a commercial arithmetic, taking up such topics as basic operations with the complex currencies of the day (ducats, soldi, pizolli, and so on), exchanging currencies, calculating interest, and dividing profits in joint companies. The book is replete with worked examples with much emphasis on methods and rules (that is, algorithms), all ready to use virtually as is.

Part II takes up more general arithmetic problems, including progressions, powers, binomial expansions, Tartaglia's triangle (also known as "Pascal's triangle"), calculations with roots, and proportions / fractions.

Part IV concerns triangles, regular polygons, the Platonic solids, and Archimedean topics like the quadrature of the circle and circumscribing a cylinder around a sphere.

Tartaglia was proficient with binomial expansions and included many worked examples in Part II of the "General Trattato", one a detailed explanation of how to calculate the summands of formula_1, including the appropriate binomial coefficients.

Tartaglia knew of Pascal's triangle one hundred years before Pascal, as shown in this image from the "General Trattato". His examples are numeric, but he thinks about it geometrically, the horizontal line formula_2 at the top of the triangle being broken into two segments formula_3 and formula_4, where point formula_5 is the apex of the triangle. Binomial expansions amount to taking formula_6 for exponents formula_7 as you go down the triangle. The symbols along the outside represent powers at this early stage of algebraic notation: formula_8, and so on. He writes explicitly about the additive formation rule, that (for example) the adjacent 15 and 20 in the fifth row add up to 35, which appears beneath them in the sixth row.

Tartaglia is perhaps best known today for his conflicts with Gerolamo Cardano. In 1539 Cardano cajoled Tartaglia into revealing his solution to the cubic equations by promising not to publish them. Tartaglia divulged the secrets of the solutions of three different forms of the cubic equation in verse. Several years later, Cardano happened to see unpublished work by Scipione del Ferro who independently came up with the same solution as Tartaglia. As the unpublished work was dated before Tartaglia's, Cardano decided his promise could be broken and included Tartaglia's solution in his next publication. Even though Cardano credited his discovery, Tartaglia was extremely upset and a famous public challenge match resulted between himself and Cardano's student, Ludovico Ferrari. Widespread stories that Tartaglia devoted the rest of his life to ruining Cardano, however, appear to be completely fabricated. Mathematical historians now credit both Cardano and Tartaglia with the formula to solve cubic equations, referring to it as the "Cardano–Tartaglia formula".

Tartaglia was a prodigious calculator and master of solid geometry. In Part IV of the "General Trattato" he shows by example how to calculate the height of a pyramid on a triangular base, that is, an irregular tetrahedron.

The base of the pyramid is a formula_9 triangle formula_10, with edges of length formula_11, and formula_12 rising up to the apex formula_13 from points formula_14, formula_5, and formula_16 respectively. Base triangle formula_10 partitions into formula_18 and formula_19 triangles by dropping the perpendicular from point formula_16 to side formula_21. He proceeds to erect a triangle in the plane perpendicular to line formula_21 through the pyramid's apex, point formula_13, calculating all three sides of this triangle and noting that its height is the height of the pyramid. At the last step, he applies what amounts to this formula for the height formula_24 of a triangle in terms of its sides formula_25 (the height from side formula_26 to its opposite vertex):

a formula deriving from the Law of Cosines (not that he cites any justification in this section of the "General Trattato").

Tartaglia drops a digit early in the calculation, taking formula_28 as formula_29, but his method is sound. The final (correct) answer is:

The volume of the pyramid is easily gotten after that (not that Tartaglia gives it):

Simon Stevin invented decimal fractions later in the sixteenth century, so the last figure would have been foreign to Tartaglia, who always used fractions. All the same, his approach is in some ways a modern one, suggesting by example an algorithm for calculating the height of most or all irregular tetrahedra, but (as usual for him) he gives no explicit formula.




</doc>
<doc id="22149" url="https://en.wikipedia.org/wiki?curid=22149" title="Nagarjuna">
Nagarjuna

Nāgārjuna (c. 150 – c. 250 CE), (Tibetan: mGon-po kLu-grub) is widely considered one of the most important Buddhist philosophers. Along with his disciple Āryadeva, he is considered the founder of the Madhyamaka school of Mahāyāna Buddhism. Nāgārjuna is also credited with developing the philosophy of the Prajñāpāramitā sūtras and, by some sources, with having revealed these scriptures to the world after recovering them from the nāgas. He is traditionally thought to have written many treatises on rasayana, as well as serving a term as the head of Nālandā.

Very little is reliably known of the life of Nāgārjuna, since the surviving accounts were written in Chinese and Tibetan centuries after his death. According to some accounts, Nāgārjuna was originally from South India. Some scholars believe that Nāgārjuna was an advisor to a king of the Satavahana dynasty. Archaeological evidence at Amarāvatī indicates that if this is true, the king may have been Yajña Śrī Śātakarṇi, who ruled between 167 and 196 CE. On the basis of this association, Nāgārjuna is conventionally placed at around 150–250 CE.

According to a 4th/5th-century biography translated by Kumārajīva, Nāgārjuna was born into a Brahmin family in Vidarbha (a region of Maharashtra) and later became a Buddhist.

Some sources claim that in his later years, Nāgārjuna lived on the mountain of Śrīparvata near the city that would later be called Nāgārjunakoṇḍa ("Hill of Nāgārjuna"). The ruins of Nāgārjunakoṇḍa are located in Guntur district, Andhra Pradesh. The Caitika and Bahuśrutīya nikāyas are known to have had monasteries in Nāgārjunakoṇḍa. The archaeological finds at Nagarjunakonda have not resulted in any evidence that the site was associated with Nagarjuna. The name "Nagarjunakonda" dates from the medieval period, and the 3rd-4th century inscriptions found at the site make it clear that it was known as "Vijayapuri" in the ancient period.

There exist a number of influential texts attributed to Nāgārjuna though, as there are many pseudepigrapha attributed to him, lively controversy exists over which are his authentic works.

The "Mūlamadhyamakakārikā" is Nāgārjuna's best-known work. It is "not only a grand commentary on the Buddha's discourse to Kaccayana, the only discourse cited by name, but also a detailed and careful analysis of most of the important discourses included in the Nikayas and the agamas, especially those of the "Atthakavagga" of the "Sutta-nipata".

In the "Mūlamadhyamakakārikā", "[A]ll experienced phenomena are empty ("sunya"). This did not mean that they are not experienced and, therefore, non-existent; only that they are devoid of a permanent and eternal substance ("svabhava") because, like a dream, they are mere projections of human consciousness. Since these imaginary fictions are experienced, they are not mere names ("prajnapti")."

According to David Seyfort Ruegg, the "Madhyamakasastrastuti" attributed to Candrakirti (c. 600 – c. 650) refers to eight texts by Nagarjuna:the "(Madhyamaka)karikas", the "Yuktisastika", the "Sunyatasaptati", the "Vigrahavyavartani", the "Vidala" (i.e. "Vaidalyasutra/Vaidalyaprakarana"), the "Ratnavali", the "Sutrasamuccaya", and "Samstutis ("Hymns")". This list covers not only much less than the grand total of works ascribed to Nagarjuna in the Chinese and Tibetan collections, but it does not even include all such works that Candrakirti has himself cited in his writings.According to one view, that of Christian Lindtner, the works definitely written by Nāgārjuna are:


The Tibetan historian Buston considers the first six to be the main treatises of Nāgārjuna (this is called the "yukti corpus", "rigs chogs"), while according to Tāranātha only the first five are the works of Nāgārjuna. TRV Murti considers Ratnaavali, Pratitya Samutpaada Hridaya and Sutra Samuccaya to be works of Nāgārjuna as the first two are quoted profusely by Chandrakirti and the third by Shantideva.

In addition to works mentioned above, several others are attributed to Nāgārjuna. There is an ongoing, lively controversy over which of those works are authentic. Contemporary research suggest that some these works belong to a significantly later period, either to late 8th or early 9th century CE, and hence can not be authentic works of Nāgārjuna. Several works considered important in esoteric Buddhism are attributed to Nāgārjuna and his disciples by traditional historians like Tāranātha from 17th century Tibet. These historians try to account for chronological difficulties with various theories. For example, apropagation of later writings via mystical revelation. For a useful summary of this tradition, see Wedemeyer 2007.

According to Ruegg, "three collections of stanzas on the virtues of intelligence and moral conduct ascribed to Nagarjuna are extant in Tibetan translation": "Prajñasatakaprakarana", "Nitisastra-Jantuposanabindu" and "Niti-sastra-Prajñadanda."

Other works are extant only in Chinese, one of these is the "Shih-erh-men-lun" or 'Twelve-topic treatise' (*"Dvadasanikaya" or *"Dvadasamukha-sastra"); one of the three basic treatises of the Sanlun school (East Asian Madhyamaka).

Lindtner considers that the "Mahāprajñāpāramitāupadeśa" ("Ta-chih-tu-lun", Taisho 1509, "Commentary on the great prajñaparamita") which has been influential in Chinese Buddhism, is not a genuine work of Nāgārjuna. This work is also only attested in a Chinese translation by Kumārajīva and is unknown in the Tibetan and Indian traditions. There is much discussion as to whether this is a work of Nāgārjuna, or someone else. Étienne Lamotte, who translated one third of the work into French, felt that it was the work of a North Indian bhikṣu of the Sarvāstivāda school who later became a convert to the Mahayana. The Chinese scholar-monk Yin Shun felt that it was the work of a South Indian and that Nāgārjuna was quite possibly the author. These two views are not necessarily in opposition and a South Indian Nāgārjuna could well have studied the northern Sarvāstivāda. Neither of the two felt that it was composed by Kumārajīva, which others have suggested.

Other attributed works include:


From studying his writings, it is clear that Nāgārjuna was conversant with many of the Śrāvaka philosophies and with the Mahāyāna tradition. However, determining Nāgārjuna's affiliation with a specific nikāya is difficult, considering much of this material has been lost. If the most commonly accepted attribution of texts (that of Christian Lindtner) holds, then he was clearly a Māhayānist, but his philosophy holds assiduously to the Śrāvaka "Tripiṭaka", and while he does make explicit references to Mahāyāna texts, he is always careful to stay within the parameters set out by the Śrāvaka canon.

Nāgārjuna may have arrived at his positions from a desire to achieve a consistent exegesis of the Buddha's doctrine as recorded in the āgamas. In the eyes of Nāgārjuna, the Buddha was not merely a forerunner, but the very founder of the Madhyamaka system. David Kalupahana sees Nāgārjuna as a successor to Moggaliputta-Tissa in being a champion of the middle-way and a reviver of the original philosophical ideals of the Buddha.

Nāgārjuna assumes a knowledge of the definitions of the sixteen categories as given in the Nyaya Sutras, the chief text of the Hindu Nyaya school, and wrote a treatise on the pramanas where he reduced the syllogism of five members into one of three. In the Vigrahavyavartani Karika, Nāgārjuna criticises the Nyaya theory of pramanas (means of knowledge) 

Nāgārjuna was fully acquainted with the classical Hindu philosophies of Samkhya and even the Vaiseshika.

Because of the high degree of similarity between Nāgārjuna's philosophy and Pyrrhonism, particularly the surviving works of Sextus Empiricus, Thomas McEvilley suspects that Nāgārjuna was influenced by Greek Pyrrhonists texts imported into India. But according to others, Pyrrho of Elis (c. 360-c. 270 BCE), usually credited with founding this school of sceptical philosophy, was himself influenced by Indian philosophy, when he travelled to India with Alexander the Great's army and studied with the gymnosophists. According to Christopher I. Beckwith, Pyrrho's teachings are based on Buddhism, because "adiaphora", "astathmēta" and "anepikrita" in the "Aristocles Passage" resemble the Buddhist three marks of existence. According to him, the key innovative tenets of Pyrrho's scepticism were only found in Indian philosophy at the time and not in Greece.

Nāgārjuna's major thematic focus is the concept of śūnyatā (translated into English as "emptiness") which brings together other key Buddhist doctrines, particularly anātman "not-self" and pratītyasamutpāda "dependent origination", to refute the metaphysics of some of his contemporaries. For Nāgārjuna, as for the Buddha in the early texts, it is not merely sentient beings that are "selfless" or non-substantial; all phenomena (dhammas) are without any svabhāva, literally "own-being", "self-nature", or "inherent existence" and thus without any underlying essence. They are "empty" of being independently existent; thus the heterodox theories of svabhāva circulating at the time were refuted on the basis of the doctrines of early Buddhism. This is so because all things arise always dependently: not by their own power, but by depending on conditions leading to their coming into existence, as opposed to being.

Nāgārjuna means by real any entity which has a nature of its own (svabhāva), which is not produced by causes (akrtaka), which is not dependent on anything else (paratra nirapeksha).

Chapter 24 verse 14 of the Mūlamadhyamakakārikā provides one of Nāgārjuna's most famous quotations on emptiness and co-arising:

As part of his analysis of the emptiness of phenomena in the Mūlamadhyamakakārikā, Nāgārjuna critiques svabhāva in several different concepts. He discusses the problems of positing any sort of inherent essence to causation, movement, change and personal identity. Nāgārjuna makes use of the Indian logical tool of the tetralemma to attack any essentialist conceptions. Nāgārjuna's logical analysis is based on four basic propositions:

To say that all things are 'empty' is to deny any kind of ontological foundation; therefore Nāgārjuna's view is often seen as a kind of ontological anti-foundationalism or a metaphysical anti-realism.

Understanding the nature of the emptiness of phenomena is simply a means to an end, which is nirvana. Thus Nāgārjuna's philosophical project is ultimately a soteriological one meant to correct our everyday cognitive processes which mistakenly posits svabhāva on the flow of experience.

Some scholars such as Fyodor Shcherbatskoy and T.R.V. Murti held that Nāgārjuna was the inventor of the Shunyata doctrine; however, more recent work by scholars such as Choong Mun-keat, Yin Shun and Dhammajothi Thero has argued that Nāgārjuna was not an innovator by putting forth this theory, but that, in the words of Shi Huifeng, "the connection between emptiness and dependent origination is not an innovation or creation of Nāgārjuna".

Nāgārjuna was also instrumental in the development of the two truths doctrine, which claims that there are two levels of truth in Buddhist teaching, the ultimate truth ("paramārtha satya") and the conventional or superficial truth ("saṃvṛtisatya"). The ultimate truth to Nāgārjuna is the truth that everything is empty of essence, this includes emptiness itself ('the emptiness of emptiness'). While some (Murti, 1955) have interpreted this by positing Nāgārjuna as a neo-Kantian and thus making ultimate truth a metaphysical noumenon or an "ineffable ultimate that transcends the capacities of discursive reason", others such as Mark Siderits and Jay L. Garfield have argued that Nāgārjuna's view is that "the ultimate truth is that there is no ultimate truth" (Siderits) and that Nāgārjuna is a "semantic anti-dualist" who posits that there are only conventional truths. Hence according to Garfield:

Suppose that we take a conventional entity, such as a table. We analyze it to demonstrate its emptiness, finding that there is no table apart from its parts […]. So we conclude that it is empty. But now let us analyze that emptiness […]. What do we find? Nothing at all but the table’s lack of inherent existence. […]. To see the table as empty […] is to see the table as conventional, as dependent.

In articulating this notion in the "Mūlamadhyamakakārikā", Nāgārjuna drew on an early source in the "Kaccānagotta Sutta", which distinguishes definitive meaning ("nītārtha") from interpretable meaning ("neyārtha"):

The version linked to is the one found in the nikayas, and is slightly different from the one found in the "Samyuktagama". Both contain the concept of teaching via the middle between the extremes of existence and non-existence. Nagarjuna does not make reference to "everything" when he quotes the agamic text in his "Mūlamadhyamakakārikā".

Jay L. Garfield describes that Nāgārjuna approached causality from the four noble truths and dependent origination. Nāgārjuna distinguished two dependent origination views in a causal process, that which causes effects and that which causes conditions. This is predicated in the two truth doctrine, as conventional truth and ultimate truth held together, in which both are empty in existence. The distinction between effects and conditions is controversial. In Nāgārjuna's approach, cause means an event or state that has power to bring an effect. Conditions, refer to proliferating causes that bring a further event, state or process; without a metaphysical commitment to an occult connection between explaining and explanans. He argues nonexistent causes and various existing conditions. The argument draws from unreal causal power. Things conventional exist and are ultimately nonexistent to rest in the middle way in both causal existence and nonexistence as casual emptiness within the Mūlamadhyamakakārikā doctrine. Although seeming strange to Westerners, this is seen as an attack on a reified view of causality.

Nāgārjuna also taught the idea of relativity; in the Ratnāvalī, he gives the example that shortness exists only in relation to the idea of length. The determination of a thing or object is only possible in relation to other things or objects, especially by way of contrast. He held that the relationship between the ideas of "short" and "long" is not due to intrinsic nature (svabhāva). This idea is also found in the Pali Nikāyas and Chinese Āgamas, in which the idea of relativity is expressed similarly: "That which is the element of light ... is seen to exist on account of [in relation to] darkness; that which is the element of good is seen to exist on account of bad; that which is the element of space is seen to exist on account of form."

Nāgārjuna is often depicted in composite form comprising human and nāga characteristics. Often the nāga-aspect forms a canopy crowning and shielding his human head. The notion of the nāga is found throughout Indian religious culture, and typically signifies an intelligent serpent or dragon, who is responsible for the rains, lakes and other bodies of water. In Buddhism, it is a synonym for a realised arhat, or wise person in general.



</doc>
<doc id="22151" url="https://en.wikipedia.org/wiki?curid=22151" title="Nuclear reactor">
Nuclear reactor

A nuclear reactor, formerly known as an atomic pile, is a device used to initiate and control a self-sustained nuclear chain reaction. Nuclear reactors are used at nuclear power plants for electricity generation and in nuclear marine propulsion. Heat from nuclear fission is passed to a working fluid (water or gas), which in turn runs through steam turbines. These either drive a ship's propellers or turn electrical generators' shafts. Nuclear generated steam in principle can be used for industrial process heat or for district heating. Some reactors are used to produce isotopes for medical and industrial use, or for production of weapons-grade plutonium. As of early 2019, the IAEA reports there are 454 nuclear power reactors and 226 nuclear research reactors in operation around the world.

Just as conventional thermal power stations generate electricity by harnessing the thermal energy released from burning fossil fuels, nuclear reactors convert the energy released by controlled nuclear fission into thermal energy for further conversion to mechanical or electrical forms.

When a large fissile atomic nucleus such as uranium-235 or plutonium-239 absorbs a neutron, it may undergo nuclear fission. The heavy nucleus splits into two or more lighter nuclei, (the fission products), releasing kinetic energy, gamma radiation, and free neutrons. A portion of these neutrons may be absorbed by other fissile atoms and trigger further fission events, which release more neutrons, and so on. This is known as a nuclear chain reaction.

To control such a nuclear chain reaction, Control rods containing neutron poisons and neutron moderators can change the portion of neutrons that will go on to cause more fission. Nuclear reactors generally have automatic and manual systems to shut the fission reaction down if monitoring detects unsafe conditions.

The reactor core generates heat in a number of ways:

A kilogram of uranium-235 (U-235) converted via nuclear processes releases approximately three million times more energy than a kilogram of coal burned conventionally (7.2 × 10 joules per kilogram of uranium-235 versus 2.4 × 10 joules per kilogram of coal).

A nuclear reactor coolant — usually water but sometimes a gas or a liquid metal (like liquid sodium or lead) or molten salt — is circulated past the reactor core to absorb the heat that it generates. The heat is carried away from the reactor and is then used to generate steam. Most reactor systems employ a cooling system that is physically separated from the water that will be boiled to produce pressurized steam for the turbines, like the pressurized water reactor. However, in some reactors the water for the steam turbines is boiled directly by the reactor core; for example the boiling water reactor.

The rate of fission reactions within a reactor core can be adjusted by controlling the quantity of neutrons that are able to induce further fission events. Nuclear reactors typically employ several methods of neutron control to adjust the reactor's power output. Some of these methods arise naturally from the physics of radioactive decay and are simply accounted for during the reactor's operation, while others are mechanisms engineered into the reactor design for a distinct purpose.

The fastest method for adjusting levels of fission-inducing neutrons in a reactor is via movement of the control rods. Control rods are made of neutron poisons and therefore absorb neutrons. When a control rod is inserted deeper into the reactor, it absorbs more neutrons than the material it displaces—often the moderator. This action results in fewer neutrons available to cause fission and reduces the reactor's power output. Conversely, extracting the control rod will result in an increase in the rate of fission events and an increase in power.

The physics of radioactive decay also affects neutron populations in a reactor. One such process is delayed neutron emission by a number of neutron-rich fission isotopes. These delayed neutrons account for about 0.65% of the total neutrons produced in fission, with the remainder (termed "prompt neutrons") released immediately upon fission. The fission products which produce delayed neutrons have half-lives for their decay by neutron emission that range from milliseconds to as long as several minutes, and so considerable time is required to determine exactly when a reactor reaches the critical point. Keeping the reactor in the zone of chain reactivity where delayed neutrons are "necessary" to achieve a critical mass state allows mechanical devices or human operators to control a chain reaction in "real time"; otherwise the time between achievement of criticality and nuclear meltdown as a result of an exponential power surge from the normal nuclear chain reaction, would be too short to allow for intervention. This last stage, where delayed neutrons are no longer required to maintain criticality, is known as the prompt critical point. There is a scale for describing criticality in numerical form, in which bare criticality is known as "zero dollars" and the prompt critical point is "one dollar", and other points in the process interpolated in cents.

In some reactors, the coolant also acts as a neutron moderator. A moderator increases the power of the reactor by causing the fast neutrons that are released from fission to lose energy and become thermal neutrons. Thermal neutrons are more likely than fast neutrons to cause fission. If the coolant is a moderator, then temperature changes can affect the density of the coolant/moderator and therefore change power output. A higher temperature coolant would be less dense, and therefore a less effective moderator.

In other reactors the coolant acts as a poison by absorbing neutrons in the same way that the control rods do. In these reactors power output can be increased by heating the coolant, which makes it a less dense poison. Nuclear reactors generally have automatic and manual systems to scram the reactor in an emergency shut down. These systems insert large amounts of poison (often boron in the form of boric acid) into the reactor to shut the fission reaction down if unsafe conditions are detected or anticipated.

Most types of reactors are sensitive to a process variously known as xenon poisoning, or the iodine pit. The common fission product Xenon-135 produced in the fission process acts as a neutron poison that absorbs neutrons and therefore tends to shut the reactor down. Xenon-135 accumulation can be controlled by keeping power levels high enough to destroy it by neutron absorption as fast as it is produced. Fission also produces iodine-135, which in turn decays (with a half-life of 6.57 hours) to new xenon-135. When the reactor is shut down, iodine-135 continues to decay to xenon-135, making restarting the reactor more difficult for a day or two, as the xenon-135 decays into cesium-135, which is not nearly as poisonous as xenon-135, with a half-life of 9.2 hours. This temporary state is the "iodine pit." If the reactor has sufficient extra reactivity capacity, it can be restarted. As the extra xenon-135 is transmuted to xenon-136, which is much less a neutron poison, within a few hours the reactor experiences a "xenon burnoff (power) transient". Control rods must be further inserted to replace the neutron absorption of the lost xenon-135. Failure to properly follow such a procedure was a key step in the Chernobyl disaster.

Reactors used in nuclear marine propulsion (especially nuclear submarines) often cannot be run at continuous power around the clock in the same way that land-based power reactors are normally run, and in addition often need to have a very long core life without refueling. For this reason many designs use highly enriched uranium but incorporate burnable neutron poison in the fuel rods. This allows the reactor to be constructed with an excess of fissionable material, which is nevertheless made relatively safe early in the reactor's fuel burn cycle by the presence of the neutron-absorbing material which is later replaced by normally produced long-lived neutron poisons (far longer-lived than xenon-135) which gradually accumulate over the fuel load's operating life.

The energy released in the fission process generates heat, some of which can be converted into usable energy. A common method of harnessing this thermal energy is to use it to boil water to produce pressurized steam which will then drive a steam turbine that turns an alternator and generates electricity.

The neutron was discovered in 1932 by British physicist James Chadwick. The concept of a nuclear chain reaction brought about by nuclear reactions mediated by neutrons was first realized shortly thereafter, by Hungarian scientist Leó Szilárd, in 1933. He filed a patent for his idea of a simple reactor the following year while working at the Admiralty in London. However, Szilárd's idea did not incorporate the idea of nuclear fission as a neutron source, since that process was not yet discovered. Szilárd's ideas for nuclear reactors using neutron-mediated nuclear chain reactions in light elements proved unworkable.

Inspiration for a new type of reactor using uranium came from the discovery by Lise Meitner, Fritz Strassmann and Otto Hahn in 1938 that bombardment of uranium with neutrons (provided by an alpha-on-beryllium fusion reaction, a "neutron howitzer") produced a barium residue, which they reasoned was created by the fissioning of the uranium nuclei. Subsequent studies in early 1939 (one of them by Szilárd and Fermi) revealed that several neutrons were also released during the fissioning, making available the opportunity for the nuclear chain reaction that Szilárd had envisioned six years previously.

On 2 August 1939 Albert Einstein signed a letter to President Franklin D. Roosevelt (written by Szilárd) suggesting that the discovery of uranium's fission could lead to the development of "extremely powerful bombs of a new type", giving impetus to the study of reactors and fission. Szilárd and Einstein knew each other well and had worked together years previously, but Einstein had never thought about this possibility for nuclear energy until Szilard reported it to him, at the beginning of his quest to produce the Einstein-Szilárd letter to alert the U.S. government.

Shortly after, Hitler's Germany invaded Poland in 1939, starting World War II in Europe. The U.S. was not yet officially at war, but in October, when the Einstein-Szilárd letter was delivered to him, Roosevelt commented that the purpose of doing the research was to make sure "the Nazis don't blow us up." The U.S. nuclear project followed, although with some delay as there remained skepticism (some of it from Fermi) and also little action from the small number of officials in the government who were initially charged with moving the project forward.

The following year the U.S. Government received the Frisch–Peierls memorandum from the UK, which stated that the amount of uranium needed for a chain reaction was far lower than had previously been thought. The memorandum was a product of the MAUD Committee, which was working on the UK atomic bomb project, known as Tube Alloys, later to be subsumed within the Manhattan Project.

Eventually, the first artificial nuclear reactor, Chicago Pile-1, was constructed at the University of Chicago, by a team led by Italian physicist Enrico Fermi, in late 1942. By this time, the program had been pressured for a year by U.S. entry into the war. The Chicago Pile achieved criticality on 2 December 1942 at 3:25 PM. The reactor support structure was made of wood, which supported a pile (hence the name) of graphite blocks, embedded in which was natural uranium oxide 'pseudospheres' or 'briquettes'.

Soon after the Chicago Pile, the U.S. military developed a number of nuclear reactors for the Manhattan Project starting in 1943. The primary purpose for the largest reactors (located at the Hanford Site in Washington), was the mass production of plutonium for nuclear weapons. Fermi and Szilard applied for a patent on reactors on 19 December 1944. Its issuance was delayed for 10 years because of wartime secrecy.

"World's first nuclear power plant" is the claim made by signs at the site of the EBR-I, which is now a museum near Arco, Idaho. Originally called "Chicago Pile-4", it was carried out under the direction of Walter Zinn for Argonne National Laboratory. This experimental LMFBR operated by the U.S. Atomic Energy Commission produced 0.8 kW in a test on 20 December 1951 and 100 kW (electrical) the following day, having a design output of 200 kW (electrical).

Besides the military uses of nuclear reactors, there were political reasons to pursue civilian use of atomic energy. U.S. President Dwight Eisenhower made his famous Atoms for Peace speech to the UN General Assembly on 8 December 1953. This diplomacy led to the dissemination of reactor technology to U.S. institutions and worldwide.

The first nuclear power plant built for civil purposes was the AM-1 Obninsk Nuclear Power Plant, launched on 27 June 1954 in the Soviet Union. It produced around 5 MW (electrical).

After World War II, the U.S. military sought other uses for nuclear reactor technology. Research by the Army and the Air Force never came to fruition; however, the U.S. Navy succeeded when they steamed the USS "Nautilus" (SSN-571) on nuclear power 17 January 1955.

The first commercial nuclear power station, Calder Hall in Sellafield, England was opened in 1956 with an initial capacity of 50 MW (later 200 MW).

The first portable nuclear reactor "Alco PM-2A" was used to generate electrical power (2 MW) for Camp Century from 1960 to 1963.

All commercial power reactors are based on nuclear fission. They generally use uranium and its product plutonium as nuclear fuel, though a thorium fuel cycle is also possible. Fission reactors can be divided roughly into two classes, depending on the energy of the neutrons that sustain the fission chain reaction:

In principle, fusion power could be produced by nuclear fusion of elements such as the deuterium isotope of hydrogen. While an ongoing rich research topic since at least the 1940s, no self-sustaining fusion reactor for power generation has ever been built.

Used by thermal reactors:



In 2003, the French Commissariat à l'Énergie Atomique (CEA) was the first to refer to "Gen II" types in Nucleonics Week.

The first mentioning of "Gen III" was in 2000, in conjunction with the launch of the Generation IV International Forum (GIF) plans.

"Gen IV" was named in 2000, by the United States Department of Energy (DOE) for developing new plant types.










More than a dozen advanced reactor designs are in various stages of development. Some are evolutionary from the PWR, BWR and PHWR designs above, some are more radical departures. The former include the advanced boiling water reactor (ABWR), two of which are now operating with others under construction, and the planned passively safe Economic Simplified Boiling Water Reactor (ESBWR) and AP1000 units (see Nuclear Power 2010 Program).

Rolls-Royce aims to sell nuclear reactors for the production of synfuel for aircraft.

Generation IV reactors are a set of theoretical nuclear reactor designs currently being researched. These designs are generally not expected to be available for commercial construction before 2030. Current reactors in operation around the world are generally considered second- or third-generation systems, with the first-generation systems having been retired some time ago. Research into these reactor types was officially started by the Generation IV International Forum (GIF) based on eight technology goals. The primary goals being to improve nuclear safety, improve proliferation resistance, minimize waste and natural resource utilization, and to decrease the cost to build and run such plants.

Generation V reactors are designs which are theoretically possible, but which are not being actively considered or researched at present. Though some generation V reactors could potentially be built with current or near term technology, they trigger little interest for reasons of economics, practicality, or safety.

Controlled nuclear fusion could in principle be used in fusion power plants to produce power without the complexities of handling actinides, but significant scientific and technical obstacles remain. Several fusion reactors have been built, but only recently reactors have been able to release more energy than the amount of energy used in the process. Despite research having started in the 1950s, no commercial fusion reactor is expected before 2050. The ITER project is currently leading the effort to harness fusion power.

Thermal reactors generally depend on refined and enriched uranium. Some nuclear reactors can operate with a mixture of plutonium and uranium (see MOX). The process by which uranium ore is mined, processed, enriched, used, possibly reprocessed and disposed of is known as the nuclear fuel cycle.

Under 1% of the uranium found in nature is the easily fissionable U-235 isotope and as a result most reactor designs require enriched fuel.
Enrichment involves increasing the percentage of U-235 and is usually done by means of gaseous diffusion or gas centrifuge. The enriched result is then converted into uranium dioxide powder, which is pressed and fired into pellet form. These pellets are stacked into tubes which are then sealed and called fuel rods. Many of these fuel rods are used in each nuclear reactor.

Most BWR and PWR commercial reactors use uranium enriched to about 4% U-235, and some commercial reactors with a high neutron economy do not require the fuel to be enriched at all (that is, they can use natural uranium). According to the International Atomic Energy Agency there are at least 100 research reactors in the world fueled by highly enriched (weapons-grade/90% enrichment) uranium. Theft risk of this fuel (potentially used in the production of a nuclear weapon) has led to campaigns advocating conversion of this type of reactor to low-enrichment uranium (which poses less threat of proliferation).

Fissile U-235 and non-fissile but fissionable and fertile U-238 are both used in the fission process. U-235 is fissionable by thermal (i.e. slow-moving) neutrons. A thermal neutron is one which is moving about the same speed as the atoms around it. Since all atoms vibrate proportionally to their absolute temperature, a thermal neutron has the best opportunity to fission U-235 when it is moving at this same vibrational speed. On the other hand, U-238 is more likely to capture a neutron when the neutron is moving very fast. This U-239 atom will soon decay into plutonium-239, which is another fuel. Pu-239 is a viable fuel and must be accounted for even when a highly enriched uranium fuel is used. Plutonium fissions will dominate the U-235 fissions in some reactors, especially after the initial loading of U-235 is spent. Plutonium is fissionable with both fast and thermal neutrons, which make it ideal for either nuclear reactors or nuclear bombs.

Most reactor designs in existence are thermal reactors and typically use water as a neutron moderator (moderator means that it slows down the neutron to a thermal speed) and as a coolant. But in a fast breeder reactor, some other kind of coolant is used which will not moderate or slow the neutrons down much. This enables fast neutrons to dominate, which can effectively be used to constantly replenish the fuel supply. By merely placing cheap unenriched uranium into such a core, the non-fissionable U-238 will be turned into Pu-239, "breeding" fuel.

In thorium fuel cycle thorium-232 absorbs a neutron in either a fast or thermal reactor. The thorium-233 beta decays to protactinium-233 and then to uranium-233, which in turn is used as fuel. Hence, like uranium-238, thorium-232 is a fertile material.

The amount of energy in the reservoir of nuclear fuel is frequently expressed in terms of "full-power days," which is the number of 24-hour periods (days) a reactor is scheduled for operation at full power output for the generation of heat energy. The number of full-power days in a reactor's operating cycle (between refueling outage times) is related to the amount of fissile uranium-235 (U-235) contained in the fuel assemblies at the beginning of the cycle. A higher percentage of U-235 in the core at the beginning of a cycle will permit the reactor to be run for a greater number of full-power days.

At the end of the operating cycle, the fuel in some of the assemblies is "spent", having spent 4 to 6 years in the reactor producing power. This spent fuel is discharged and replaced with new (fresh) fuel assemblies. Though considered "spent," these fuel assemblies contain a large quantity of fuel. In practice it is economics that determines the lifetime of nuclear fuel in a reactor. Long before all possible fission has taken place, the reactor is unable to maintain 100%, full output power, and therefore, income for the utility lowers as plant output power lowers. Most nuclear plants operate at a very low profit margin due to operating overhead, mainly regulatory costs, so operating below 100% power is not economically viable for very long. The fraction of the reactor's fuel core replaced during refueling is typically one-third, but depends on how long the plant operates between refueling. Plants typically operate on 18 month refueling cycles, or 24 month refueling cycles. This means that 1 refueling, replacing only one-third of the fuel, can keep a nuclear reactor at full power for nearly 2 years. The disposition and storage of this spent fuel is one of the most challenging aspects of the operation of a commercial nuclear power plant. This nuclear waste is highly radioactive and its toxicity presents a danger for thousands of years. After being discharged from the reactor, spent nuclear fuel is transferred to the on-site spent fuel pool. The spent fuel pool is a large pool of water that provides cooling and shielding of the spent nuclear fuel. Once the energy has decayed somewhat (approximately 5 years), the fuel can be transferred from the fuel pool to dry shielded casks, that can be safely stored for thousands of years. After loading into dry shielded casks, the casks are stored on-site in a specially guarded facility in impervious concrete bunkers. On-site fuel storage facilities are designed to withstand the impact of commercial airliners, with little to no damage to the spent fuel. An average on-site fuel storage facility can hold 30 years of spent fuel in a space smaller that a football field.

Not all reactors need to be shut down for refueling; for example, pebble bed reactors, RBMK reactors, molten salt reactors, Magnox, AGR and CANDU reactors allow fuel to be shifted through the reactor while it is running. In a CANDU reactor, this also allows individual fuel elements to be situated within the reactor core that are best suited to the amount of U-235 in the fuel element.

The amount of energy extracted from nuclear fuel is called its burnup, which is expressed in terms of the heat energy produced per initial unit of fuel weight. Burn up is commonly expressed as megawatt days thermal per metric ton of initial heavy metal.

Nuclear safety covers the actions taken to prevent nuclear and radiation accidents and incidents or to limit their consequences. The nuclear power industry has improved the safety and performance of reactors, and has proposed new safer (but generally untested) reactor designs but there is no guarantee that the reactors will be designed, built and operated correctly. Mistakes do occur and the designers of reactors at Fukushima in Japan did not anticipate that a tsunami generated by an earthquake would disable the backup systems that were supposed to stabilize the reactor after the earthquake, despite multiple warnings by the NRG and the Japanese nuclear safety administration. According to UBS AG, the Fukushima I nuclear accidents have cast doubt on whether even an advanced economy like Japan can master nuclear safety. Catastrophic scenarios involving terrorist attacks are also conceivable. An interdisciplinary team from MIT has estimated that given the expected growth of nuclear power from 2005–2055, at least four serious nuclear accidents would be expected in that period.

Serious, though rare, nuclear and radiation accidents have occurred. These include the SL-1 accident (1961), the Three Mile Island accident (1979), Chernobyl disaster (1986), and the Fukushima Daiichi nuclear disaster (2011). Nuclear-powered submarine mishaps include the K-19 reactor accident (1961), the K-27 reactor accident (1968), and the K-431 reactor accident (1985).

Nuclear reactors have been launched into Earth orbit at least 34 times. A number of incidents connected with the unmanned nuclear-reactor-powered Soviet RORSAT radar satellite program resulted in spent nuclear fuel reentering the Earth's atmosphere from orbit.

Almost two billion years ago a series of self-sustaining nuclear fission "reactors" self-assembled in the area now known as Oklo in Gabon, West Africa. The conditions at that place and time allowed a natural nuclear fission to occur with circumstances that are similar to the conditions in a constructed nuclear reactor.

Such reactors can no longer form on Earth in its present geologic period. Radioactive decay of formerly more abundant uranium-235 over the time span of hundreds of millions of years has reduced the proportion of this naturally occurring fissile isotope to below the amount required to sustain a chain reaction with only plain water as a moderator.

The natural nuclear reactors formed when a uranium-rich mineral deposit became inundated with groundwater that acted as a neutron moderator, and a strong chain reaction took place. The water moderator would boil away as the reaction increased, slowing it back down again and preventing a meltdown. The fission reaction was sustained for hundreds of thousands of years, cycling on the order of hours to a few days.

These natural reactors are extensively studied by scientists interested in geologic radioactive waste disposal. They offer a case study of how radioactive isotopes migrate through the Earth's crust. This is a significant area of controversy as opponents of geologic waste disposal fear that isotopes from stored waste could end up in water supplies or be carried into the environment.

Nuclear reactors produce tritium as part of normal operations, which is eventually released into the environment in trace quantities.

As an isotope of hydrogen, tritium (T) frequently binds to oxygen and forms TO. This molecule is chemically identical to HO and so is both colorless and odorless, however the additional neutrons in the hydrogen nuclei cause the tritium to undergo beta decay with a half-life of 12.3 years. Despite being measurable, the tritium released by nuclear power plants is minimal. The United States NRC estimates that a person drinking water for one year out of a well contaminated by what they would consider to be a significant tritiated water spill would receive a radiation dose of 0.3 millirem. For comparison, this is an order of magnitude less than the 4 millirem a person receives on a round trip flight from Washington, D.C. to Los Angeles, a consequence of less atmospheric protection against highly energetic cosmic rays at high altitudes.

The amounts of strontium-90 released from nuclear power plants under normal operations is so low as to be undetectable above natural background radiation. Detectable strontium-90 in ground water and the general environment can be traced to weapons testing that occurred during the mid-20th century (accounting for 99% of the Strontium-90 in the environment) and the Chernobyl accident (accounting for the remaining 1%).



</doc>
<doc id="22153" url="https://en.wikipedia.org/wiki?curid=22153" title="Nuclear power">
Nuclear power

Nuclear power is the use of nuclear reactions that release nuclear energy to generate heat, which most frequently is then used in steam turbines to produce electricity in a nuclear power plant. Nuclear power can be obtained from nuclear fission, nuclear decay and nuclear fusion reactions. Presently, the vast majority of electricity from nuclear power is produced by nuclear fission of uranium and plutonium. Nuclear decay processes are used in niche applications such as radioisotope thermoelectric generators. Generating electricity from fusion power remains at the focus of international research. This article mostly deals with nuclear fission power for electricity generation.

Civilian nuclear power supplied 2,563 terawatt hours (TWh) of electricity in 2018, equivalent to about 10% of global electricity generation, and was the second largest low-carbon power source after hydroelectricity. there are 443 civilian fission reactors in the world, with a combined electrical capacity of 395 gigawatt (GW). There are also 56 nuclear power reactors under construction and 109 reactors planned, with a combined capacity of 60 GW and 120 GW, respectively. The United States has the largest fleet of nuclear reactors, generating over 800 TWh zero-emissions electricity per year with an average capacity factor of 92%. Most reactors under construction are generation III reactors in Asia.

Nuclear power has one of the lowest levels of fatalities per unit of energy generated compared to other energy sources. Coal, petroleum, natural gas and hydroelectricity each have caused more fatalities per unit of energy due to air pollution and accidents. Since its commercialization in the 1970s, nuclear power has prevented about 1.84 million air pollution-related deaths and the emission of about 64 billion tonnes of carbon dioxide equivalent that would have otherwise resulted from the burning of fossil fuels. 

Accidents in nuclear power plants include the Chernobyl disaster in the Soviet Union in 1986, the Fukushima Daiichi nuclear disaster in Japan in 2011, and the more contained Three Mile Island accident in the United States in 1979.

There is a debate about nuclear power. Proponents, such as the World Nuclear Association and Environmentalists for Nuclear Energy, contend that nuclear power is a safe, sustainable energy source (see also Nuclear power proposed as renewable energy) that reduces carbon emissions. Nuclear power opponents, such as Greenpeace and NIRS, contend that nuclear power poses many threats to people and the environment.

In 1932 physicist Ernest Rutherford discovered that when lithium atoms were "split" by protons from a proton accelerator, immense amounts of energy were released in accordance with the principle of mass–energy equivalence. However, he and other nuclear physics pioneers Niels Bohr and Albert Einstein believed harnessing the power of the atom for practical purposes anytime in the near future was unlikely.

The same year, his doctoral student James Chadwick discovered the neutron, which was immediately recognized as a potential tool for nuclear experimentation because of its lack of an electric charge. Experiments bombarding materials with neutrons led Frédéric and Irène Joliot-Curie to discover induced radioactivity in 1934, which allowed the creation of radium-like elements. Further work by Enrico Fermi in the 1930s focused on using slow neutrons to increase the effectiveness of induced radioactivity. Experiments bombarding uranium with neutrons led Fermi to believe he had created a new transuranic element, which was dubbed hesperium.

In 1938, German chemists Otto Hahn and Fritz Strassmann, along with Austrian physicist Lise Meitner and Meitner's nephew, Otto Robert Frisch, conducted experiments with the products of neutron-bombarded uranium, as a means of further investigating Fermi's claims.
They determined that the relatively tiny neutron split the nucleus of the massive uranium atoms into two roughly equal pieces, contradicting Fermi.
This was an extremely surprising result: all other forms of nuclear decay involved only small changes to the mass of the nucleus, whereas this process—dubbed "fission" as a reference to biology—involved a complete rupture of the nucleus.
Numerous scientists, including Leó Szilárd, who was one of the first, recognized that if fission reactions released additional neutrons, a self-sustaining nuclear chain reaction could result. Once this was experimentally confirmed and announced by Frédéric Joliot-Curie in 1939, scientists in many countries (including the United States, the United Kingdom, France, Germany, and the Soviet Union) petitioned their governments for support of nuclear fission research, just on the cusp of World War II, for the development of a nuclear weapon.

In the United States, where Fermi and Szilárd had both emigrated, the discovery of the nuclear chain reaction led to the creation of the first man-made reactor, the research reactor known as Chicago Pile-1, which achieved criticality on December 2, 1942. The reactor's development was part of the Manhattan Project, the Allied effort to create atomic bombs during World War II. It led to the building of larger single-purpose production reactors, such as the X-10 Pile, for the production of weapons-grade plutonium for use in the first nuclear weapons. The United States tested the first nuclear weapon in July 1945, the Trinity test, with the atomic bombings of Hiroshima and Nagasaki taking place one month later.

In August 1945, the first widely distributed account of nuclear energy, the pocketbook "The Atomic Age", was released. It discussed the peaceful future uses of nuclear energy and depicted a future where fossil fuels would go unused. Nobel laureate Glenn Seaborg, who later chaired the United States Atomic Energy Commission, is quoted as saying "there will be nuclear powered earth-to-moon shuttles, nuclear powered artificial hearts, plutonium heated swimming pools for SCUBA divers, and much more".

In the same month, with the end of the war, Seaborg and others would file hundreds of initially classified patents, most notably Eugene Wigner and Alvin Weinberg's Patent #2,736,696, on a conceptual light water reactor (LWR) that would later become the United States' primary reactor for naval propulsion and later take up the greatest share of the commercial fission-electric landscape.

The United Kingdom, Canada, and the USSR proceeded to research and develop nuclear energy over the course of the late 1940s and early 1950s.

Electricity was generated for the first time by a nuclear reactor on December 20, 1951, at the EBR-I experimental station near Arco, Idaho, which initially produced about 100 kW.
In 1953, American President Dwight Eisenhower gave his "Atoms for Peace" speech at the United Nations, emphasizing the need to develop "peaceful" uses of nuclear power quickly. This was followed by the Atomic Energy Act of 1954 which allowed rapid declassification of U.S. reactor technology and encouraged development by the private sector.

The first organization to develop nuclear power was the U.S. Navy, with the S1W reactor for the purpose of propelling submarines and aircraft carriers. The first nuclear-powered submarine, , was put to sea in January 1954. The trajectory of civil reactor design was heavily influenced by Admiral Hyman G. Rickover, who with Weinberg as a close advisor, selected the PWR/Pressurized Water Reactor design, in the form of a 10 MW reactor for the Nautilus, a decision that would result in the PWR receiving a government commitment to develop, an engineering lead that would result in a lasting impact on the civilian electricity market in the years to come. The United States Navy Nuclear Propulsion design and operation community, under Rickover's style of attentive management retains a continuing record of zero reactor accidents (defined as the uncontrolled release of fission products to the environment resulting from damage to a reactor core). with the U.S. Navy fleet of nuclear-powered ships, standing at some 80 vessels as of 2018.

On June 27, 1954, the USSR's Obninsk Nuclear Power Plant, based on what would become the prototype of the RBMK reactor design, became the world's first nuclear power plant to generate electricity for a power grid, producing around 5 megawatts of electric power.

On July 17, 1955 the BORAX III reactor, the prototype to later Boiling Water Reactors, became the first to generate electricity for an entire community, the town of Arco, Idaho. A motion picture record of the demonstration, of supplying some 2 megawatts (2 MW) of electricity, was presented to the United Nations, Where at the "First Geneva Conference", the world's largest gathering of scientists and engineers, met to explore the technology in that year. In 1957 EURATOM was launched alongside the European Economic Community (the latter is now the European Union). The same year also saw the launch of the International Atomic Energy Agency (IAEA).

The world's first "commercial nuclear power station", Calder Hall at Windscale, England, was opened in 1956 with an initial capacity of 50 MW per reactor (200 MW total), it was the first of a fleet of dual-purpose MAGNOX reactors, though officially code-named PIPPA (Pressurized Pile Producing Power and Plutonium) by the UKAEA to denote the plant's dual commercial and military role.

The U.S. Army Nuclear Power Program formally commenced in 1954. Under its management, the 2 megawatt SM-1, at Fort Belvoir, Virginia, was the first in the United States to supply electricity in an industrial capacity to the commercial grid (VEPCO), in April 1957.

The first commercial nuclear station to become operational in the United States was the 60 MW Shippingport Reactor (Pennsylvania), in December 1957.

The 3 MW SL-1 was a U.S. Army experimental nuclear power reactor at the National Reactor Testing Station, Idaho National Laboratory. It was derived from the Borax Boiling water reactor (BWR) design and it first achieved operational criticality and connection to the grid in 1958. 
For reasons unknown, in 1961 a technician removed a control rod about 22 inches farther than the prescribed 4 inches. This resulted in a steam explosion which killed the three crew members and caused a meltdown. The event was eventually rated at 4 on the seven-level INES scale.

In service from 1963 and operated as the experimental testbed for the later Alfa-class submarine fleet, one of the two liquid-metal-cooled reactors on board the , underwent a fuel element failure accident in 1968, with the emission of gaseous fission products into the surrounding air, producing 9 crew fatalities and 83 injuries.

The total global installed nuclear capacity initially rose relatively quickly, rising from less than 1 gigawatt (GW) in 1960 to 100 GW in the late 1970s, and 300 GW in the late 1980s. Since the late 1980s worldwide capacity has risen much more slowly, reaching 366 GW in 2005. Between around 1970 and 1990, more than 50 GW of capacity was under construction (peaking at over 150 GW in the late 1970s and early 1980s)—in 2005, around 25 GW of new capacity was planned. More than two-thirds of all nuclear plants ordered after January 1970 were eventually cancelled. A total of 63 nuclear units were canceled in the United States between 1975 and 1980.

In 1972 Alvin Weinberg, co-inventor of the light water reactor design (the most common nuclear reactors today) was fired from his job at Oak Ridge National Laboratory by the Nixon administration, "at least in part" over his raising of concerns about the safety and wisdom of ever larger scaling-up of his design, especially above a power rating of ~500 MW, as in a loss of coolant accident scenario, the decay heat generated from such large compact solid-fuel cores was thought to be beyond the capabilities of passive/natural convection cooling to prevent a rapid fuel rod melt-down and resulting in then, potential far reaching fission product pluming. While considering the LWR, well suited at sea for the submarine and naval fleet, Weinberg did not show complete support for its use by utilities on land at the power output that they were interested in for supply scale reasons, and would request for a greater share of AEC research funding to evolve his team's demonstrated, Molten-Salt Reactor Experiment, a design with greater inherent safety in this scenario and with that an envisioned greater economic growth potential in the market of large-scale civilian electricity generation.

Similar to the earlier BORAX reactor safety experiments, conducted by Argonne National Laboratory, in 1976 Idaho National Laboratory began a test program focused on LWR reactors under various accident scenarios, with the aim of understanding the event progression and mitigating steps necessary to respond to a failure of one or more of the disparate systems, with much of the redundant back-up safety equipment and nuclear regulations drawing from these series of destructive testing investigations.

During the 1970s and 1980s rising economic costs (related to extended construction times largely due to regulatory changes and pressure-group litigation) and falling fossil fuel prices made nuclear power plants then under construction less attractive. In the 1980s in the U.S. and 1990s in Europe, the flat electric grid growth and electricity liberalization also made the addition of large new baseload energy generators economically unattractive.

The 1973 oil crisis had a significant effect on countries, such as France and Japan, which had relied more heavily on oil for electric generation (39% and 73% respectively) to invest in nuclear power.
The French plan, known as the Messmer plan, was for the complete independence from oil, with an envisaged construction of 80 reactors by 1985 and 170 by 2000.
France would construct 25 fission-electric stations, installing 56 mostly PWR design reactors over the next 15 years, though foregoing the 100 reactors initially charted in 1973, for the 1990s. In 2018, 72% of French electricity was generated by 58 reactors, the highest percentage by any nation in the world.

Some local opposition to nuclear power emerged in the U.S. in the early 1960s, beginning with the proposed Bodega Bay station in California, in 1958, which produced conflict with local citizens and by 1964 the concept was ultimately abandoned. In the late 1960s some members of the scientific community began to express pointed concerns. These anti-nuclear concerns related to nuclear accidents, nuclear proliferation, nuclear terrorism and radioactive waste disposal. In the early 1970s, there were large protests about a proposed nuclear power plant in Wyhl, Germany. The project was cancelled in 1975 the anti-nuclear success at Wyhl inspired opposition to nuclear power in other parts of Europe and North America. By the mid-1970s anti-nuclear activism gained a wider appeal and influence, and nuclear power began to become an issue of major public protest. In some countries, the nuclear power conflict "reached an intensity unprecedented in the history of technology controversies". In May 1979, an estimated 70,000 people, including then governor of California Jerry Brown, attended a march against nuclear power in Washington, D.C. Anti-nuclear power groups emerged in every country that had a nuclear power programme.

Globally during the 1980s one new nuclear reactor started up every 17 days on average.

In the early 1970s, the increased public hostility to nuclear power in the United States lead the United States Atomic Energy Commission and later the Nuclear Regulatory Commission to lengthen the license procurement process, tighten engineering regulations and increase the requirements for safety equipment. Together with relatively minor percentage increases in the total quantity of steel, piping, cabling and concrete per unit of installed nameplate capacity, the more notable changes to the regulatory open public hearing-response cycle for the granting of construction licenses, had the effect of what was once an initial 16 months for project initiation to the pouring of first concrete in 1967, escalating to 32 months in 1972 and finally 54 months in 1980, which ultimately, quadrupled the price of power reactors.

Utility proposals in the U.S for nuclear generating stations, peaked at 52 in 1974, fell to 12 in 1976 and have never recovered, in large part due to the pressure-group litigation strategy, of launching lawsuits against each proposed U.S construction proposal, keeping private utilities tied up in court for years, one of which having reached the supreme court in 1978. With permission to build a nuclear station in the U.S. eventually taking longer than in any other industrial country, the spectre facing utilities of having to pay interest on large construction loans while the anti-nuclear movement used the legal system to produce delays, increasingly made the viability of financing construction, less certain. By the close of the 1970s it became clear that nuclear power would not grow nearly as dramatically as once believed.

Over 120 reactor proposals in the United States were ultimately cancelled and the construction of new reactors ground to a halt. A cover story in the February 11, 1985, issue of "Forbes" magazine commented on the overall failure of the U.S. nuclear power program, saying it "ranks as the largest managerial disaster in business history".

According to some commentators, the 1979 accident at Three Mile Island (TMI) played a major part in the reduction in the number of new plant constructions in many other countries. According to the NRC, TMI was the most serious accident in "U.S. commercial nuclear power plant operating history, even though it led to no deaths or injuries to plant workers or members of the nearby community." The regulatory uncertainty and delays eventually resulted in an escalation of construction related debt that led to the bankruptcy of Seabrook's major utility owner, Public Service Company of New Hampshire. At the time, the fourth largest bankruptcy in United States corporate history.

Among American engineers, the cost increases from implementing the regulatory changes that resulted from the TMI accident were, when eventually finalized, only a few percent of total construction costs for new reactors, primarily relating to the prevention of safety systems from being turned off. With the most significant engineering result of the TMI accident, the recognition that better operator training was needed and that the existing emergency core cooling system of PWRs worked better in a real-world emergency than members of the anti-nuclear movement had routinely claimed.

The already slowing rate of new construction along with the shutdown in the 1980s of two existing demonstration nuclear power stations in the Tennessee Valley, United States, when they couldn't economically meet the NRC's new tightened standards, shifted electricity generation to coal-fired power plants. In 1977, following the first oil shock, U.S. President Jimmy Carter made a speech calling the energy crisis the "moral equivalent of war" and prominently supporting nuclear power. However, nuclear power could not compete with cheap oil and gas, particularly after public opposition and regulatory hurdles made new nuclear prohibitively expensive.

In 2006 The Brookings Institution, a public policy organization, stated that new nuclear units had not been built in the United States because of soft demand for electricity, the potential cost overruns on nuclear reactors due to regulatory issues and resulting construction delays.

In 1982, amongst a backdrop of ongoing protests directed at the construction of the first commercial scale breeder reactor in France, a later member of the Swiss Green Party fired five RPG-7 rocket-propelled grenades at the still under construction containment building of the Superphenix reactor. Two grenades hit and caused minor damage to the reinforced concrete outer shell. It was the first time protests reached such heights. After examination of the superficial damage, the prototype fast breeder reactor started and operated for over a decade.

According to some commentators, the 1986 Chernobyl disaster played a major part in the reduction in the number of new plant constructions in many other countries:
Unlike the Three Mile Island accident the much more serious Chernobyl accident did not increase regulations or engineering changes affecting Western reactors; because the RBMK design, which lacks safety features such as "robust" containment buildings, was only used in the Soviet Union. Over 10 RBMK reactors are still in use today. However, changes were made in both the RBMK reactors themselves (use of a safer enrichment of uranium) and in the control system (preventing safety systems being disabled), amongst other things, to reduce the possibility of a similar accident. Russia now largely relies upon, builds and exports a variant of the PWR, the VVER, with over 20 in use today.

An international organization to promote safety awareness and the professional development of operators in nuclear facilities, the World Association of Nuclear Operators (WANO), was created as a direct outcome of the 1986 Chernobyl accident. The organization was created with the intent to share and grow the adoption of nuclear safety culture, technology and community, where before there was an atmosphere of cold war secrecy.

Numerous countries, including Austria (1978), Sweden (1980) and Italy (1987) (influenced by Chernobyl) have voted in referendums to oppose or phase out nuclear power.

In the early 2000s, the nuclear industry was expecting a nuclear renaissance, an increase in the construction of new reactors, due to concerns about carbon dioxide emissions. However, in 2009, Petteri Tiippana, the director of STUK's nuclear power plant division, told the BBC that it was difficult to deliver a Generation III reactor project on schedule because builders were not used to working to the exacting standards required on nuclear construction sites, since so few new reactors had been built in recent years.

In 2018 the MIT Energy Initiative study on the future of nuclear energy concluded that, together with the strong suggestion that government should financially support development and demonstration of new Generation IV nuclear technologies, for a worldwide renaissance to commence, a global standardization of regulations needs to take place, with a move towards serial manufacturing of standardized units akin to the other complex engineering field of aircraft and aviation. At present it is common for each country to demand bespoke changes to the design to satisfy varying national regulatory bodies, often to the benefit of domestic engineering supply firms. The report goes on to note that the most cost-effective projects have been built with multiple (up to six) reactors per site using a standardized design, with the same component suppliers and construction crews working on each unit, in a continuous work flow.

Following the Tōhoku earthquake on 11 March 2011, one of the largest earthquakes ever recorded, and a subsequent tsunami off the coast of Japan, the Fukushima Daiichi Nuclear Power Plant suffered three core meltdowns due to failure of the emergency cooling system for lack of electricity supply. This resulted in the most serious nuclear accident since the Chernobyl disaster.

The Fukushima Daiichi nuclear accident prompted a re-examination of nuclear safety and nuclear energy policy in many countries and raised questions among some commentators over the future of the renaissance.
Germany approved plans to close all its reactors by 2022. Italian nuclear energy plans ended when Italy banned the generation, but not consumption, of nuclear electricity in a June 2011 referendum.
China, Switzerland, Israel, Malaysia, Thailand, United Kingdom, and the Philippines reviewed their nuclear power programs.

In 2011 the International Energy Agency halved its prior estimate of new generating capacity to be built by 2035.
Nuclear power generation had the biggest ever fall year-on-year in 2012, with nuclear power plants globally producing 2,346 TWh of electricity, a drop of 7% from 2011.
This was caused primarily by the majority of Japanese reactors remaining offline that year and the permanent closure of eight reactors in Germany.

The Fukushima Daiichi nuclear accident sparked controversy about the importance of the accident and its effect on nuclear's future.
The crisis prompted countries with nuclear power to review the safety of their reactor fleet and reconsider the speed and scale of planned nuclear expansions.
In 2011, "The Economist" opined that nuclear power "looks dangerous, unpopular, expensive and risky", and suggested a nuclear phase-out.
Jeffrey Sachs, Earth Institute Director, disagreed claiming combating climate change would require an expansion of nuclear power.
Investment banks were also critical of nuclear soon after the accident.

In 2011 German engineering giant Siemens said it would withdraw entirely from the nuclear industry in response to the Fukushima accident. In 2017, Siemens set the "milestone" of supplying the first additive manufacturing part to a nuclear power station, at the Krško Nuclear Power Plant in Slovenia, which it regards as an "industry breakthrough".

The "Associated Press" and Reuters reported in 2011 the suggestion that the safety and survival of the younger Onagawa Nuclear Power Plant, the closest reactor facility to the epicenter and on the coast, demonstrate that it is possible for nuclear facilities to withstand the greatest natural disasters. The Onagawa plant was also said to show that nuclear power can retain public trust, with the surviving residents of the town of Onagawa taking refuge in the gymnasium of the nuclear facility following the destruction of their town.
Following an IAEA inspection in 2012, the agency stated that "The structural elements of the [Onagawa] NPS (nuclear power station) were remarkably undamaged given the magnitude of ground motion experienced and the duration and size of this great earthquake,”.

In February 2012, the U.S. NRC approved the construction of 2 reactors at the Vogtle Electric Generating Plant, the first approval in 30 years. 

Kharecha and Hansen estimated that "global nuclear power has prevented an average of 1.84 million air pollution-related deaths and 64 gigatonnes of CO-equivalent (GtCO-eq) greenhouse gas (GHG) emissions that would have resulted from fossil fuel burning" and, if continued, it could prevent up to 7 million deaths and 240 GtCO-eq emissions by 2050.

In August 2015, following 4 years of near zero fission-electricity generation, Japan began restarting its nuclear reactors, after safety upgrades were completed, beginning with Sendai Nuclear Power Plant.

By 2015, the IAEA's outlook for nuclear energy had become more promising.
"Nuclear power is a critical element in limiting greenhouse gas emissions," the agency noted, and "the prospects for nuclear energy remain positive in the medium to long term despite a negative impact in some countries in the aftermath of the [Fukushima-Daiichi] accident...it is still the second-largest source worldwide of low-carbon electricity.
And the 72 reactors under construction at the start of last year were the most in 25 years."
As of 2015 the global trend was for new nuclear power stations coming online to be balanced by the number of old plants being retired. Eight new grid connections were completed by China in 2015.

In 2016 the BN-800 sodium cooled fast reactor in Russia, began commercial electricity generation, while plans for a BN-1200 were initially conceived the future of the fast reactor program in Russia awaits the results from MBIR, an under construction multi-loop Generation research facility for testing the chemically more inert lead, lead-bismuth and gas coolants, it will similarly run on recycled MOX (mixed uranium and plutonium oxide) fuel. An on-site pyrochemical processing, closed fuel-cycle facility, is planned, to recycle the spent fuel/"waste" and reduce the necessity for a growth in uranium mining and exploration. In 2017 the manufacture program for the reactor commenced with the facility open to collaboration under the "International Project on Innovative Nuclear Reactors and Fuel Cycle", it has a construction schedule, that includes an operational start in 2020. As planned, it will be the world's most-powerful research reactor.

In 2015 the Japanese government committed to the aim of restarting its fleet of 40 reactors by 2030 after safety upgrades, and to finish the construction of the Generation III Ōma Nuclear Power Plant.
This would mean that approximately 20% of electricity would come from nuclear power by 2030. As of 2018, some reactors have restarted commercial operation following inspections and upgrades with new regulations. While South Korea has a large nuclear power industry, the new government in 2017, influenced by a vocal anti-nuclear movement, committed to halting nuclear development after the completion of the facilities presently under construction.
The bankruptcy of Westinghouse in March 2017 due to US$9 billion of losses from the halting of construction at Virgil C. Summer Nuclear Generating Station, in the U.S. is considered an advantage for eastern companies, for the future export and design of nuclear fuel and reactors.

In 2016, the U.S. Energy Information Administration projected for its “base case” that world nuclear power generation would increase from 2,344 terawatt hours (TWh) in 2012 to 4,500 TWh in 2040. Most of the predicted increase was expected to be in Asia. As of 2018, there are over 150 nuclear reactors planned including 50 under construction. In January 2019, China had 45 reactors in operation, 13 under construction, and plans to build 43 more, which would make it the world's largest generator of nuclear electricity.

Zero-emission nuclear power is an important part of the climate change mitigation effort. Under IEA Sustainable Development Scenario by 2030 nuclear power and CCUS would have generated 3900 TWh globally while wind and solar 8100 TWh with the ambition to achieve net-zero emissions by 2070. In order to achieve this goal on average 15 GWe of nuclear power should have been added annually on average. As of 2019 over 60 GW in new nuclear power plants was in construction, mostly in China, Russia, Korea, India and UAE. Many countries in the world are considering Small Modular Reactors with one in Russia connected to the grid in 2020.

Countries with nuclear power plant in planning phase include Argentina, Brazil, Bulgaria, the Czech Republic, Egypt, Finland, Hungary, India, Kazakhstan, Poland, Saudi Arabia and Uzbekistan.

The future of nuclear power varies greatly between countries, depending on government policies. Some countries, most notably, Germany, have adopted policies of nuclear power phase-out. At the same time, some Asian countries, such as China and India, have committed to rapid expansion of nuclear power. In other countries, such as the United Kingdom and the United States, nuclear power is planned to be part of the energy mix together with renewable energy.

 the cost of extending plant lifetimes is competitive with other electricity generation technologies, including new solar and wind projects. In the United States, licenses of almost half of the operating nuclear reactors have been extended to 60 years.
The U.S. NRC and the U.S. Department of Energy have initiated research into Light water reactor sustainability which is hoped will lead to allowing extensions of reactor licenses beyond 60 years, provided that safety can be maintained, to increase energy security and preserve low-carbon generation sources. Research into nuclear reactors that can last 100 years, known as Centurion Reactors, is being conducted.

As of 2020 a number of US nuclear power plants were cleared by Nuclear Regulatory Commission for operations up to 80 years.

Just as many conventional thermal power stations generate electricity by harnessing the thermal energy released from burning fossil fuels, nuclear power plants convert the energy released from the nucleus of an atom via nuclear fission that takes place in a nuclear reactor. When a neutron hits the nucleus of a uranium-235 or plutonium atom, it can split the nucleus into two smaller nuclei. The reaction is called nuclear fission. The fission reaction releases energy and neutrons. The released neutrons can hit other uranium or plutonium nuclei, causing new fission reactions, which release more energy and more neutrons. This is called a chain reaction. The reaction rate is controlled by control rods that absorb excess neutrons. The controllability of nuclear reactors depends on the fact that a small fraction of neutrons resulting from fission are delayed. The time delay between the fission and the release of the neutrons slows down changes in reaction rates and gives time for moving the control rods to adjust the reaction rate.

A fission nuclear power plant is generally composed of a nuclear reactor, in which the nuclear reactions generating heat take place; a cooling system, which removes the heat from inside the reactor; a steam turbine, which transforms the heat in mechanical energy; an electric generator, which transform the mechanical energy into electrical energy.

The life cycle of nuclear fuel starts with Uranium mining, which can be underground, open-pit, or in-situ leach mining, an increasing number of the highest output mines are remote underground operations, such as McArthur River uranium mine, in Canada, which by itself accounts for 13% of global production. The uranium ore, now independent from the ore body is then, as is shared in common with other metal mining, converted into a compact ore concentrate form, known in the case of uranium as "yellowcake"(UO) to facilitate transport.

In reactors that can sustain the neutron economy with the use of graphite or heavy water moderators, the reactor fuel can be this natural uranium on reducing to the much denser black ceramic oxide (UO) form. For light water reactors, the fuel for which requires a further isotopic refining, the yellowcake is converted to the only suitable monoatomic uranium molecule, that is a gas just above room temperature, uranium hexafluoride, which is then sent through gaseous enrichment. In civilian light water reactors, Uranium is typically enriched to 3-5% uranium-235, and then generally converted back into a black powdered ceramic uranium oxide(UO) form, that is then compressively sintered into fuel pellets, a stack of which forms fuel rods of the proper composition and geometry for the particular reactor that the fuel is needed in.

In modern light-water reactors the fuel rods will typically spend 3 operational cycles (about 6 years) inside the reactor, generally until about 3% of the uranium has been fissioned. Afterwards, they will be moved to a spent fuel pool which provides cooling for the thermal heat and shielding for ionizing radiation. Depending largely upon burnup efficiency, after about 5 years in a spent fuel pool the spent fuel is radioactively and thermally cool enough to handle, and can be moved to dry storage casks or reprocessed.

Uranium is a fairly common element in the Earth's crust: it is approximately as common as tin or germanium, and is about 40 times more common than silver.
Uranium is present in trace concentrations in most rocks, dirt, and ocean water, but is generally economically extracted only where it is present in high concentrations.
As of 2011 the world's known resources of uranium, economically recoverable at the arbitrary price ceiling of US$130/kg, were enough to last for between 70 and 100 years.

The OECD's red book of 2011 said that conventional uranium resources had grown by 12.5% since 2008 due to increased exploration, with this increase translating into greater than a century of uranium available if the rate of use were to continue at the 2011 level. In 2007, the OECD estimated 670 years of economically recoverable uranium in total conventional resources and phosphate ores assuming the then-current use rate.

Light water reactors make relatively inefficient use of nuclear fuel, mostly fissioning only the very rare uranium-235 isotope. Nuclear reprocessing can make this waste reusable. Newer generation III reactors also achieve a more efficient use of the available resources than the generation II reactors which make up the vast majority of reactors worldwide. With a pure fast reactor fuel cycle with a burn up of all the Uranium and actinides (which presently make up the most hazardous substances in nuclear waste), there is an estimated 160,000 years worth of Uranium in total conventional resources and phosphate ore at the price of 60–100 US$/kg.

Unconventional uranium resources also exist.
Uranium is naturally present in seawater at a concentration of about 3 micrograms per liter, with 4.5 billion tons of uranium considered present in seawater at any time.
In 2012 it was estimated that this fuel source could be extracted at 10 times the current price of uranium.

In 2014, with the advances made in the efficiency of seawater uranium extraction, it was suggested that it would be economically competitive to produce fuel for light water reactors from seawater if the process was implemented at large scale.
Uranium extracted on an industrial scale from seawater would constantly be replenished by both river erosion of rocks and the natural process of uranium dissolved from the surface area of the ocean floor, both of which maintain the solubility equilibria of seawater concentration at a stable level.
Some commentators have argued that this strengthens the case for Nuclear power to be considered a renewable energy

As opposed to light water reactors which use uranium-235 (0.7% of all natural uranium), fast breeder reactors use uranium-238 (99.3% of all natural uranium) or thorium. A number of fuel cycles and breeder reactor combinations are considered to be sustainable and/or renewable sources of energy. In 2006 it was estimated that with seawater extraction, there was likely some five billion years' worth of uranium-238 for use in breeder reactors.

Breeder technology has been used in several reactors, but the high cost of reprocessing fuel safely, at 2006 technological levels, requires uranium prices of more than US$200/kg before becoming justified economically. Breeder reactors are however being pursued as they have the potential to burn up all of the actinides in the present inventory of nuclear waste while also producing power and creating additional quantities of fuel for more reactors via the breeding process.

As of 2017, there are two breeders producing commercial power, BN-600 reactor and the BN-800 reactor, both in Russia.
The BN-600, with a capacity of 600 MW, was built in 1980 in Beloyarsk and is planned to produce power until 2025. The BN-800 is an updated version of the BN-600, and started operation in 2014. The Phénix breeder reactor in France was powered down in 2009 after 36 years of operation.

Both China and India are building breeder reactors.
The Indian 500 MWe Prototype Fast Breeder Reactor is in the commissioning phase, with plans to build more.

Another alternative to fast breeders are thermal breeder reactors that use uranium-233 bred from thorium as fission fuel in the thorium fuel cycle. Thorium is about 3.5 times more common than uranium in the Earth's crust, and has different geographic characteristics. This would extend the total practical fissionable resource base by 450%. India's three-stage nuclear power programme features the use of a thorium fuel cycle in the third stage, as it has abundant thorium reserves but little uranium.

The most important waste stream from nuclear power reactors is spent nuclear fuel. From LWRs, it is typically composed of 95% uranium, 4% fission products from the energy generating nuclear fission reactions, as well as about 1% transuranic actinides (mostly reactor grade plutonium, neptunium and americium) from unavoidable neutron capture events. The plutonium and other transuranics are responsible for the bulk of the long-term radioactivity, whereas the fission products are responsible for the bulk of the short-term radioactivity.

The high-level radioactive waste/spent fuel that is generated from power production, requires treatment, management and isolation from the environment. The technical issues in accomplishing this are considerable, due to the extremely long periods some particularly sublimation prone, mildly radioactive wastes, remain potentially hazardous to living organisms, namely the long-lived fission products, technetium-99 (half-life 220,000 years) and iodine-129 (half-life 15.7 million years), which dominate the waste stream in radioactivity after the more intensely radioactive short-lived fission products(SLFPs) have decayed into stable elements, which takes approximately 300 years. To successfully isolate the LLFP waste from the biosphere, either separation and transmutation, or some variation of a synroc treatment and deep geological storage, is commonly suggested.

While in the US, spent fuel is presently in its entirety, federally classified as a nuclear waste and is treated similarly, in other countries it is largely reprocessed to produce a partially recycled fuel, known as mixed oxide fuel or MOX. For spent fuel that does not undergo reprocessing, the most concerning isotopes are the medium-lived transuranic elements, which are led by reactor grade plutonium (half-life 24,000 years).

Some proposed reactor designs, such as the American Integral Fast Reactor and the Molten salt reactor can more completely use or burnup the spent reactor grade plutonium fuel and other minor actinides, generated from light water reactors, as under the designed fast fission spectrum, these elements are more likely to fission and produce the aforementioned fission products in their place. This offers a potentially more attractive alternative to deep geological disposal.

The thorium fuel cycle results in similar fission products, though creates a much smaller proportion of transuranic elements from neutron capture events within a reactor. Therefore, spent thorium fuel, breeding the true fuel of fissile uranium-233, is somewhat less concerning from a radiotoxic and security standpoint.

The nuclear industry also produces a large volume of low-level radioactive waste in the form of contaminated items like clothing, hand tools, water purifier resins, and (upon decommissioning) the materials of which the reactor itself is built. Low-level waste can be stored on-site until radiation levels are low enough to be disposed as ordinary waste, or it can be sent to a low-level waste disposal site.

In countries with nuclear power, radioactive wastes account for less than 1% of total industrial toxic wastes, much of which remains hazardous for long periods. Overall, nuclear power produces far less waste material by volume than fossil-fuel based power plants. Coal-burning plants are particularly noted for producing large amounts of toxic and mildly radioactive ash due to concentrating naturally occurring metals and mildly radioactive material in coal. A 2008 report from Oak Ridge National Laboratory concluded that coal power actually results in more radioactivity being released into the environment than nuclear power operation, and that the population effective dose equivalent, or dose to the public from radiation from coal plants is 100 times as much as from the operation of nuclear plants.
Although coal ash is much less radioactive than spent nuclear fuel on a weight per weight basis, coal ash is produced in much higher quantities per unit of energy generated, and this is released directly into the environment as fly ash, whereas nuclear plants use shielding to protect the environment from radioactive materials, for example, in dry cask storage vessels.

Disposal of nuclear waste is often considered the most politically divisive aspect in the lifecycle of a nuclear power facility.
Presently, waste is mainly stored at individual reactor sites and there are over 430 locations around the world where radioactive material continues to accumulate.
Some experts suggest that centralized underground repositories which are well-managed, guarded, and monitored, would be a vast improvement.
There is an "international consensus on the advisability of storing nuclear waste in deep geological repositories", with the lack of movement of nuclear waste in the 2 billion year old natural nuclear fission reactors in Oklo, Gabon being cited as "a source of essential information today."

There are no commercial scale purpose built underground high-level waste repositories in operation. However, in Finland the Onkalo spent nuclear fuel repository is under construction as of 2015. The Waste Isolation Pilot Plant (WIPP) in New Mexico has been taking nuclear waste since 1999 from production reactors, but as the name suggests is a research and development facility.
In 2014 a radiation leak caused by violations in the use of chemically reactive packaging brought renewed attention to the need for quality control management, along with some initial calls for more R&D into the alternative methods of disposal for radioactive waste and spent fuel.
In 2017, the facility was formally reopened after three years of investigation and cleanup, with the resumption of new storage taking place later that year.

The U.S Nuclear Waste Policy Act, a fund which previously received $750 million in fee revenues each year from the nation's combined nuclear electric utilities, had an unspent balance of $44.5 billion as of the end of FY2017, when a court ordered the federal government to cease withdrawing the fund, until it provides a destination for the utilities commercial spent fuel.

Horizontal drillhole disposal describes proposals to drill over one kilometer vertically, and two kilometers horizontally in the earth’s crust, for the purpose of disposing of high-level waste forms such as spent nuclear fuel, Caesium-137, or Strontium-90. After the emplacement and the retrievability period, drillholes would be backfilled and sealed.

Most thermal reactors run on a once-through fuel cycle, mainly due to the low price of fresh uranium, though many reactors are also fueled with recycled fissionable materials that remain in spent nuclear fuel. The most common fissionable material that is recycled is the reactor-grade plutonium ("RGPu") that is extracted from spent fuel, it is mixed with uranium oxide and fabricated into mixed-oxide or MOX fuel. The first LWR designs certified to operate on a full core of MOX fuel, the ABWR and the System 80, began to appear in the 1990s. The potential for recycling the spent fuel a second time is limited by undesirable neutron economy issues using second-generation MOX fuel in "thermal"-reactors. These issues do not affect fast reactors, which are therefore preferred in order to achieve the full energy potential of the original uranium. The only commercial demonstration of twice recycled, high burnup fuel to date, occurred in the Phénix "fast" reactor.

Because thermal LWRs remain the most common reactor worldwide, the most typical form of commercial spent fuel recycling is to recycle the plutonium a single time as MOX fuel, as is done in France, where it is considered to increase the sustainability of the nuclear fuel cycle, reduce the attractiveness of spent fuel to theft and lower the volume of high level nuclear waste. Reprocessing of civilian fuel from power reactors is also currently done in the United Kingdom, Russia, Japan, and India.

The main constituent of spent fuel from the most common light water reactor, is uranium that is slightly more enriched than natural uranium, which can be recycled, though there is a lower incentive to do so. Most of this "recovered uranium", or at times referred to as reprocessed uranium, remains in storage. It can however be used in a fast reactor, used directly as fuel in CANDU reactors, or re-enriched for another cycle through an LWR. The direct use of recovered uranium to fuel a CANDU reactor was first demonstrated at Quishan, China. The first re-enriched uranium reload to fuel a commercial LWR, occurred in 1994 at the Cruas unit 4, France. Re-enriching of reprocessed uranium is common in France and Russia. When reprocessed uranium, namely Uranium-236, is part of the fuel of LWRs, it generates a spent fuel and plutonium isotope stream with greater inherent self-protection, than the once-thru fuel cycle.

While reprocessing offers the potential recovery of up to 95% of the remaining uranium and plutonium fuel, in spent nuclear fuel and a reduction in long term radioactivity within the remaining waste. Reprocessing has been politically controversial because of the potential to contribute to nuclear proliferation and varied perceptions of increasing the vulnerability to nuclear terrorism and because of its higher fuel cost, compared to the once-through fuel cycle. Similarly, while reprocessing reduces the volume of high-level waste, it does not reduce the fission products that are the primary residual heat generating and radioactive substances for the first few centuries outside the reactor, thus still requiring an almost identical container-spacing for the initial first few hundred years, within proposed geological waste isolation facilities. However much of the opposition to the Yucca Mountain project and those similar to it, primarily center not around fission products but the "plutonium mine" concern that placed in the underground, un-reprocessed spent fuel, will eventually become.

In the United States, spent nuclear fuel is currently not reprocessed. A major recommendation of the Blue Ribbon Commission on America's Nuclear Future was that "the United States should undertake...one or more permanent deep geological facilities for the safe disposal of spent fuel and high-level nuclear waste".

The French La Hague reprocessing facility has operated commercially since 1976 and is responsible for half the world's reprocessing as of 2010. Having produced MOX fuel from spent fuel derived from France, Japan, Germany, Belgium, Switzerland, Italy, Spain and the Netherlands, with the non-recyclable part of the spent fuel eventually sent back to the user nation. More than 32,000 tonnes of spent fuel had been reprocessed as of 2015, with the majority from France, 17% from Germany, and 9% from Japan. Once a source of criticism from Greenpeace, more recently the organization have ceased attempting to criticize the facility on technical grounds, having succeeded at performing the process without serious incidents that have been frequent at other such facilities around the world. In the past, the antinuclear movement argued that reprocessing would not be technically or economically feasible.
A PUREX related facility, frequently considered to be the proprietary COEX, designed by Areva, is a major long term commitment of the PRC with the intention to supply by 2030, Chinese reactors with economically separated and indigenous recycled fuel.

The financial costs of every nuclear power plant continues for some time after the facility has finished generating its last useful electricity. Once no longer economically viable, nuclear reactors and uranium enrichment facilities are generally decommissioned, returning the facility and its parts to a safe enough level to be entrusted for other uses, such as greenfield status.
After a cooling-off period that may last decades, reactor core materials are dismantled and cut into small pieces to be packed in containers for interim storage or transmutation experiments.

In the United States a Nuclear Waste Policy Act and Nuclear Decommissioning Trust Fund is legally required, with utilities banking 0.1 to 0.2 cents/kWh during operations to fund future decommissioning. They must report regularly to the Nuclear Regulatory Commission (NRC) on the status of their decommissioning funds. About 70% of the total estimated cost of decommissioning all U.S. nuclear power reactors has already been collected (on the basis of the average cost of $320 million per reactor-steam turbine unit).

In the United States in 2011, there are 13 reactors that had permanently shut down and are in some phase of decommissioning. With Connecticut Yankee Nuclear Power Plant and Yankee Rowe Nuclear Power Station having completed the process in 2006–2007, after ceasing commercial electricity production circa 1992.
The majority of the 15 years, was used to allow the station to naturally cool-down on its own, which makes the manual disassembly process both safer and cheaper.
Decommissioning at nuclear sites which have experienced a serious accident are the most expensive and time-consuming.

Nuclear fission power stations, excluding the contribution from naval nuclear fission reactors, provided 11% of the world's electricity in 2012, somewhat less than that generated by hydro-electric stations at 16%.
Since electricity accounts for about 25% of humanity's energy usage with the majority of the rest coming from fossil fuel reliant sectors such as transport, manufacture and home heating, nuclear fission's contribution to the global final energy consumption was about 2.5%.
This is a little more than the combined global electricity production from wind, solar, biomass and geothermal power, which together provided 2% of global final energy consumption in 2014.

In addition, there were approximately 140 naval vessels using nuclear propulsion in operation, powered by about 180 reactors.

Nuclear power's share of global electricity production has fallen from 16.5% in 1997 to about 10% in 2017, in large part because the economics of nuclear power have become more difficult.

Regional differences in the use of nuclear power are large.
The United States produces the most nuclear energy in the world, with nuclear power providing 19% of the electricity it consumes, while France produces the highest percentage of its electrical energy from nuclear reactors – 72% as of 2018.
In the European Union as a whole nuclear power provides 25% of the electricity as of 2017.
Nuclear power is the single largest low-carbon electricity source in the United States, and accounts for two-thirds of the European Union's low-carbon electricity.
Nuclear energy policy differs among European Union countries, and some, such as Austria, Estonia, Ireland and Italy, have no active nuclear power stations.

Many military and some civilian (such as some icebreakers) ships use nuclear marine propulsion.
A few space vehicles have been launched using nuclear reactors: 33 reactors belong to the Soviet RORSAT series and one was the American SNAP-10A.

International research is continuing into additional uses of process heat such as hydrogen production (in support of a hydrogen economy), for desalinating sea water, and for use in district heating systems.

Both fission and fusion appear promising for space propulsion applications, generating higher mission velocities with less reaction mass. This is due to the much higher energy density of nuclear reactions: some 7 orders of magnitude (10,000,000 times) more energetic than the chemical reactions which power the current generation of rockets.

Radioactive decay has been used on a relatively small scale (few kW), mostly to power space missions and experiments by using radioisotope thermoelectric generators such as those developed at Idaho National Laboratory.

The economics of new nuclear power plants is a controversial subject, since there are diverging views on this topic, and multibillion-dollar investments depend on the choice of an energy source.
Nuclear power plants typically have high capital costs for building the plant, but low fuel costs.
Comparison with other power generation methods is strongly dependent on assumptions about construction timescales and capital financing for nuclear plants as well as the future costs of fossil fuels and renewables as well as for energy storage solutions for intermittent power sources.
On the other hand, measures to mitigate global warming, such as a carbon tax or carbon emissions trading, may favor the economics of nuclear power.

Analysis of the economics of nuclear power must also take into account who bears the risks of future uncertainties.
To date all operating nuclear power plants have been developed by state-owned or regulated electric utility monopolies
Many countries have now liberalized the electricity market where these risks, and the risk of cheaper competitors emerging before capital costs are recovered, are borne by plant suppliers and operators rather than consumers, which leads to a significantly different evaluation of the economics of new nuclear power plants.

Nuclear power plants, though capable of some grid-load following, are typically run as much as possible to keep the cost of the generated electrical energy as low as possible, supplying mostly base-load electricity.

Peer reviewed analyses of the available cost trends of nuclear power, since its inception,
show large disparity by nation, design, build rate and the establishment of familiarity in expertise. The two nations of which data were available, which have produced reactors at a lower cost trend than prior facilities in the 2000s were India and S.Korea. In the history of civilian reactor power, certain designs lent considerable early positive economics, over competitors, such as the CANDU which alongside, at one time, much higher realized capacity factor/reliability when compared to Gen II LWRs up to about the 1990s, at a time when LWRs in the U.S began to utilize improved enrichment, permitting longer operation times without stoppages, the CANDU design had allowed Canada to also forego uranium enrichment facilities and due to the on-line refueling reactor design, the larger set of PHWRs of which the CANDU design is a part, continue to hold many world record positions for longest continual electricity generation, without stoppage, routinely close to and over 800 days, before maintenance checks. The specific record as of 2019 is held by a PHWR at Kaiga Atomic Power Station, generating electricity at the nameplate rating continuously for 962 days.

The PHWR fleet of India, in analysis by M.V. Ramana, were constructed, fuelled and continue to operate, close to the price of Indian coal power stations,
at a similar price.

The Fukushima Daiichi nuclear disaster is expected to increase the costs of operating and new LWR power stations, due to increased requirements for on-site spent fuel management and elevated design basis threats.

Nuclear reactors have three unique characteristics that affect their safety, as compared to other power plants.
Firstly, intensely radioactive materials are present in a nuclear reactor. Their release to the environment could be hazardous.
Secondly, the fission products, which make up most of the intensely radioactive substances in the reactor, continue to generate a significant amount of decay heat even after the fission chain reaction has stopped. If the heat cannot be removed from the reactor, the fuel rods may overheat and release radioactive materials.
Thirdly, a criticality accident (a rapid increase of the reactor power) is possible in certain reactor designs if the chain reaction cannot be controlled.
These three characteristics have to be taken into account when designing nuclear reactors.

All modern reactors are designed so that an uncontrolled increase of the reactor power is prevented by natural feedback mechanisms: if the temperature or the amount of steam in the reactor increases, the fission rate inherently decreases by designing in a negative void coefficient of reactivity. The chain reaction can also be manually stopped by inserting control rods into the reactor core. Emergency core cooling systems (ECCS) can remove the decay heat from the reactor if normal cooling systems fail. If the ECCS fails, multiple physical barriers limit the release of radioactive materials to the environment even in the case of an accident. The last physical barrier is the large containment building. Approximately 120 reactors, such as all those in Switzerland prior to and all reactors in Japan after the Fukushima accident, incorporate Filtered Containment Venting Systems, onto the containment structure, which are designed to relieve the containment pressure during an accident by releasing gases to the environment while retaining most of the fission products in the filter structures.

Nuclear power with death rate of 0.07 per TWh remains the safest energy source per unit of energy compared to other energy sources.

Some serious nuclear and radiation accidents have occurred.
The severity of nuclear accidents is generally classified using the International Nuclear Event Scale (INES) introduced by the International Atomic Energy Agency (IAEA).
The scale ranks anomalous events or accidents on a scale from 0 (a deviation from normal operation that poses no safety risk) to 7 (a major accident with widespread effects).
There have been 3 accidents of level 5 or higher in the civilian nuclear power industry, two of which, the Chernobyl accident and the Fukushima accident, are ranked at level 7.

The Chernobyl accident in 1986 caused approximately 50 deaths from direct and indirect effects, and some temporary serious injuries.
The future predicted mortality from cancer increases, is usually estimated at some 4000 in the decades to come. A higher number of the routinely treatable Thyroid cancer, set to be the only type of causal cancer, will likely be seen in future large studies.

The Fukushima Daiichi nuclear accident was caused by the 2011 Tohoku earthquake and tsunami.
The accident has not caused any radiation-related deaths, but resulted in radioactive contamination of surrounding areas.
The difficult Fukushima disaster cleanup will take 40 or more years, and is expected to cost tens of billions of dollars.
The Three Mile Island accident in 1979 was a smaller scale accident, rated at INES level 5.
There were no direct or indirect deaths caused by the accident.

According to Benjamin K. Sovacool, fission energy accidents ranked first among energy sources in terms of their total economic cost, accounting for 41 percent of all property damage attributed to energy accidents.
Another analysis presented in the international journal "Human and Ecological Risk Assessment" found that coal, oil, Liquid petroleum gas and hydroelectric accidents (primarily due to the Banqiao dam burst) have resulted in greater economic impacts than nuclear power accidents. Comparing Nuclear's "latent" cancer deaths, such as cancer with other energy sources "immediate" deaths per unit of energy generated(GWeyr). This study does not include Fossil fuel related cancer and other indirect deaths created by the use of fossil fuel consumption in its "severe accident", an accident with more than 5 fatalities, classification.</ref>

Nuclear power works under an insurance framework that limits or structures accident liabilities in accordance with the Paris convention on nuclear third-party liability, the Brussels supplementary convention, the Vienna convention on civil liability for nuclear damage and the Price-Anderson Act in the United States.
It is often argued that this potential shortfall in liability represents an external cost not included in the cost of nuclear electricity; but the cost is small, amounting to about 0.1% of the levelized cost of electricity, according to a CBO study.
These beyond-regular-insurance costs for worst-case scenarios are not unique to nuclear power, as hydroelectric power plants are similarly not fully insured against a catastrophic event such as the Banqiao Dam disaster, where 11 million people lost their homes and from 30,000 to 200,000 people died, or large dam failures in general. As private insurers base dam insurance premiums on limited scenarios, major disaster insurance in this sector is likewise provided by the state.

In terms of lives lost per unit of energy generated, nuclear power has caused fewer accidental deaths per unit of energy generated than all other major sources of energy generation.
Energy produced by coal, petroleum, natural gas and hydropower has caused more deaths per unit of energy generated due to air pollution and energy accidents.
This is found when comparing the immediate deaths from other energy sources to both the immediate nuclear related deaths from accidents and also including the latent, or predicted, indirect cancer deaths from nuclear energy accidents.
When the combined immediate and indirect fatalities from nuclear power and all fossil fuels are compared, including fatalities resulting from the mining of the necessary natural resources to power generation and to air pollution, the use of nuclear power has been calculated to have prevented about 1.8 million deaths between 1971 and 2009, by reducing the proportion of energy that would otherwise have been generated by fossil fuels, and is projected to continue to do so.
Following the 2011 Fukushima nuclear disaster, it has been estimated that if Japan had never adopted nuclear power, accidents and pollution from coal or gas plants would have caused more lost years of life.

Forced evacuation from a nuclear accident may lead to social isolation, anxiety, depression, psychosomatic medical problems, reckless behavior, even suicide.
Such was the outcome of the 1986 Chernobyl nuclear disaster in Ukraine.
A comprehensive 2005 study concluded that "the mental health impact of Chernobyl is the largest public health problem unleashed by the accident to date".
Frank N. von Hippel, an American scientist, commented on the 2011 Fukushima nuclear disaster, saying that a disproportionate radiophobia, or "fear of ionizing radiation could have long-term psychological effects on a large portion of the population in the contaminated areas".
A 2015 report in "Lancet" explained that serious impacts of nuclear accidents were often not directly attributable to radiation exposure, but rather social and psychological effects.
Evacuation and long-term displacement of affected populations created problems for many people, especially the elderly and hospital patients.
In January 2015, the number of Fukushima evacuees was around 119,000, compared with a peak of around 164,000 in June 2012.

Terrorists could target nuclear power plants in an attempt to release radioactive contamination into the community. The United States 9/11 Commission has said that nuclear power plants were potential targets originally considered for the September 11, 2001 attacks. An attack on a reactor's spent fuel pool could also be serious, as these pools are less protected than the reactor core. The release of radioactivity could lead to thousands of near-term deaths and greater numbers of long-term fatalities.

In the United States, the NRC carries out "Force on Force" (FOF) exercises at all nuclear power plant sites at least once every three years.
In the United States, plants are surrounded by a double row of tall fences which are electronically monitored.
The plant grounds are patrolled by a sizeable force of armed guards.

Insider sabotage is also a threat because insiders can observe and work around security measures.
Successful insider crimes depended on the perpetrators' observation and knowledge of security vulnerabilities.
A fire caused 5–10 million dollars worth of damage to New York's Indian Point Energy Center in 1971.
The arsonist turned out to be a plant maintenance worker. Some reactors overseas have also reported varying levels of sabotage by workers.

Many technologies and materials associated with the creation of a nuclear power program have a dual-use capability, in that they can be used to make nuclear weapons if a country chooses to do so. When this happens a nuclear power program can become a route leading to a nuclear weapon or a public annex to a "secret" weapons program. The concern over Iran's nuclear activities is a case in point.

As of April 2012 there were thirty one countries that have civil nuclear power plants, of which nine have nuclear weapons, with the vast majority of these nuclear weapons states having first produced weapons, before commercial fission electricity stations.
Moreover, the re-purposing of civilian nuclear industries for military purposes would be a breach of the Non-proliferation treaty, to which 190 countries adhere.

A fundamental goal for global security is to minimize the nuclear proliferation risks associated with the expansion of nuclear power.
The Global Nuclear Energy Partnership was an international effort to create a distribution network in which developing countries in need of energy would receive nuclear fuel at a discounted rate, in exchange for that nation agreeing to forgo their own indigenous develop of a uranium enrichment program.
The France-based Eurodif/"European Gaseous Diffusion Uranium Enrichment Consortium" is a program that successfully implemented this concept, with Spain and other countries without enrichment facilities buying a share of the fuel produced at the French controlled enrichment facility, but without a transfer of technology.
Iran was an early participant from 1974, and remains a shareholder of Eurodif via Sofidif.

A 2009 United Nations report said that:
the revival of interest in nuclear power could result in the worldwide dissemination of uranium enrichment and spent fuel reprocessing technologies, which present obvious risks of proliferation as these technologies can produce fissile materials that are directly usable in nuclear weapons.

On the other hand, power reactors can also reduce nuclear weapons arsenals when military grade nuclear materials are reprocessed to be used as fuel in nuclear power plants.
The Megatons to Megawatts Program, the brainchild of Thomas Neff of MIT, is the single most successful non-proliferation program to date.
Up to 2005, the Megatons to Megawatts Program had processed $8 billion of high enriched, weapons grade uranium into low enriched uranium suitable as nuclear fuel for commercial fission reactors by diluting it with natural uranium.
This corresponds to the elimination of 10,000 nuclear weapons.
For approximately two decades, this material generated nearly 10 percent of all the electricity consumed in the United States (about half of all U.S. nuclear electricity generated) with a total of around 7 trillion kilowatt-hours of electricity produced. Enough energy to energize the entire United States electric grid for about two years. In total it is estimated to have cost $17 billion, a "bargain for US ratepayers", with Russia profiting $12 billion from the deal. Much needed profit for the Russian nuclear oversight industry, which after the collapse of the Soviet economy, had difficulties paying for the maintenance and security of the Russian Federations highly enriched uranium and warheads.

The Megatons to Megawatts Program was hailed as a major success by anti-nuclear weapon advocates as it has largely been the driving force behind the sharp reduction in the quantity of nuclear weapons worldwide since the cold war ended.
However without an increase in nuclear reactors and greater demand for fissile fuel, the cost of dismantling and down blending has dissuaded Russia from continuing their disarmament.
As of 2013 Russia appears to not be interested in extending the program.

Nuclear power is one of the leading low carbon power generation methods of producing electricity, and in terms of total life-cycle greenhouse gas emissions per unit of energy generated, has emission values comparable to or lower than renewable energy.
A 2014 analysis of the carbon footprint literature by the Intergovernmental Panel on Climate Change (IPCC) reported that the embodied total life-cycle emission intensity of fission electricity has a median value of 12 g eq/kWh, which is the lowest out of all commercial baseload energy sources.
This is contrasted with coal and natural gas at 820 and 490 g eq/kWh.
From the beginning of its commercialization in the 1970s, nuclear power has prevented the emission of about 64 billion tonnes of carbon dioxide equivalent that would have otherwise resulted from the burning of fossil fuels in thermal power stations.

The variation in a person's absorbed natural background radiation, averages 2.4 mSv/a globally but frequently varies between 1 mSv/a and 13 mSv/a depending in most part on the geology a person resides upon. According to the United Nations (UNSCEAR), regular NPP/nuclear power plant operations including the nuclear fuel cycle, increases this amount to 0.0002 millisieverts (mSv) per year of public exposure as a global average.
The average dose from operating NPPs to the local populations around them is "less than" 0.0001 mSv/a. The average dose to those living within 50 miles of a coal power plant is over three times this dose, 0.0003 mSv/a.

As of a 2008 report, Chernobyl resulted in the most affected surrounding populations and male recovery personnel receiving an average initial 50 to 100 mSv over a few hours to weeks, while the remaining global legacy of the worst nuclear power plant accident in average exposure is 0.002 mSv/a and is continually dropping at the decaying rate, from the initial high of 0.04 mSv per person averaged over the entire populace of the Northern Hemisphere in the year of the accident in 1986.

Slowing global warming requires a transition to a low-carbon economy, mainly by burning far less fossil fuel. Limiting global warming to 1.5 degrees C is technically possible if no new fossil fuel power plants are built from 2019. This has generated considerable interest and dispute in determining the best path forward to rapidly replace fossil-based fuels in the global energy mix, with intense academic debate. Sometimes the IEA says that countries without nuclear should develop it as well as their renewable power.
In developed nations the economically feasible geography for new hydropower is lacking, with every geographically suitable area largely already exploited. Proponents of wind and solar energy claim these resources alone could eliminate the need for nuclear power.

Some analysts argue that conventional renewable energy sources, wind and solar do not offer the scalability necessary for a large scale decarbonization of the electric grid, mainly due to intermittency-related considerations. Along with other commentators who have questioned the links between the anti-nuclear movement and the fossil fuel industry. These commentators point, in support of the assessment, to the expansion of the coal burning Lippendorf Power Station in Germany and in 2015 the opening of a large, 1730 MW coal burning power station in Moorburg, the only such coal burning facility of its kind to commence operations, in Western Europe in the 2010s. Germany is likely to miss its 2020 emission reduction target.

Several studies suggest that it might be theoretically possible to cover a majority of world energy generation with new renewable sources.
The Intergovernmental Panel on Climate Change (IPCC) has said that if governments were supportive, renewable energy supply could account for close to 80% of the world's energy use by 2050.

Analysis in 2015 by professor and chair of Environmental Sustainability Barry W. Brook and his colleagues on the topic of replacing fossil fuels entirely, from the electric grid of the world, has determined that at the historically modest and proven-rate at which nuclear energy was added to and replaced fossil fuels in France and Sweden during each nation's building programs in the 1980s, nuclear energy could displace or remove fossil fuels from the electric grid completely within 10 years, "allow[ing] the world to meet the most stringent greenhouse-gas mitigation targets".

In a similar analysis, Brook had earlier determined that 50% of all global energy, that is not solely electricity, but transportation synthetic fuels etc. could be generated within approximately 30 years, if the global nuclear fission build rate was identical to each of these nation's already proven installation rates in units of installed nameplate capacity, GW per year, per unit of global GDP (GW/year/$).
This is in contrast to the conceptual studies for a "100% renewable energy" world, which would require an orders of magnitude more costly global investment per year, which has no historical precedent, along with far greater land that would have to be devoted to the wind, wave and solar projects, and the inherent assumption that humanity will use less, and not more, energy in the future. As Brook notes, the "principal limitations on nuclear fission are not technical, economic or fuel-related, but are instead linked to complex issues of societal acceptance, fiscal and political inertia, and inadequate critical evaluation of the real-world constraints facing [the other] low-carbon alternatives."

In some places which aim to phase out fossil fuels in favor of low carbon power, such as Britain, seasonal energy storage is difficult to provide, so having renewables supply over 60% of electricity might be expensive. whether interconnectors or new nuclear would be more expensive than taking renewables over 60% is still being researched and debated. Britain's older gas-cooled nuclear reactors are not flexible to balance demand, wind and solar, but the island's newer water-cooled reactors should have similar flexibility to fossil fueled power plants. According to the operator from 2025 the British electricity grid may spend periods zero-carbon, with only renewables and nuclear. However actually supplying the electricity grid only from nuclear and renewables may be done together with interconnected countries, such as France in the case of Britain.

Nuclear power is comparable to, and in some cases lower, than many renewable energy sources in terms of lives lost per unit of electricity delivered.
However, as opposed to renewable energy, conventional designs for nuclear reactors produce a smaller volume of manufacture and operations related waste, most notably, the intensely radioactive spent fuel that needs to be stored or reprocessed.
A nuclear plant also needs to be disassembled and removed and much of the disassembled nuclear plant needs to be stored as low level nuclear waste for a few decades.

In an EU wide 2018 assessment of progress in reducing greenhouse gas emissions per capita, France and Sweden were the only two large industrialized nations within the EU to receive a positive rating, as every other country received a "poor" to "very poor" grade.

A 2018 analysis by MIT argued that, to be much more cost-effective as they approach deep decarbonization, electricity systems should integrate baseload low carbon resources, such as nuclear, with renewables, storage and demand response.

Nuclear power stations require approximately one square kilometer of land per typical reactor. Environmentalists and conservationists have begun to question the global renewable energy expansion proposals, as they are opposed to the frequently controversial use of once forested land to situate renewable energy systems. Seventy five academic conservationists signed a letter, suggesting a more effective policy to mitigate climate change involving the reforestation of this land proposed for renewable energy production, to its prior natural landscape, by means of the native trees that previously inhabited it, in tandem with the lower land use footprint of nuclear energy, as the path to assure both the commitment to carbon emission reductions and to succeed with landscape rewilding programs that are part of the global native species protection and re-introduction initiatives.

These scientists argue that government commitments to increase renewable energy usage while simultaneously making commitments to expand areas of biological conservation, are two competing land use outcomes, in opposition to one another, that are increasingly coming into conflict. With the existing protected areas for conservation at present regarded as insufficient to safeguard biodiversity "the conflict for space between energy production and habitat will remain one of the key future conservation issues to resolve."

The nuclear power debate concerns the controversy which has surrounded the deployment and use of nuclear fission reactors to generate electricity from nuclear fuel for civilian purposes. The debate about nuclear power peaked during the 1970s and 1980s, when it "reached an intensity unprecedented in the history of technology controversies", in some countries.

Proponents of nuclear energy regard it as a sustainable energy source that reduces carbon emissions and increases energy security by decreasing dependence on imported energy sources. M. King Hubbert, who popularized the concept of peak oil, saw oil as a resource that would run out and considered nuclear energy its replacement.
Proponents also claim that the present quantity of nuclear waste is small and can be reduced through the latest technology of newer reactors, and that the operational safety record of fission-electricity is unparalleled.

Opponents believe that nuclear power poses many threats to people and the environment such as the risk of nuclear weapons proliferation and terrorism. They also contend that reactors are complex machines where many things can and have gone wrong. In years past, they also argued that when all the energy-intensive stages of the nuclear fuel chain are considered, from uranium mining to nuclear decommissioning, nuclear power is neither a low-carbon nor an economical electricity source.

Arguments of economics and safety are used by both sides of the debate.

Current fission reactors in operation around the world are second or third generation systems, with most of the first-generation systems having been already retired.
Research into advanced generation IV reactor types was officially started by the Generation IV International Forum (GIF) based on eight technology goals, including to improve economics, safety, proliferation resistance, natural resource utilization and the ability to consume existing nuclear waste in the production of electricity.
Most of these reactors differ significantly from current operating light water reactors, and are expected to be available for commercial construction after 2030.

Hybrid nuclear power is a proposed means of generating power by use of a combination of nuclear fusion and fission processes. The concept dates to the 1950s, and was briefly advocated by Hans Bethe during the 1970s, but largely remained unexplored until a revival of interest in 2009, due to delays in the realization of pure fusion. When a sustained nuclear fusion power plant is built, it has the potential to be capable of extracting all the fission energy that remains in spent fission fuel, reducing the volume of nuclear waste by orders of magnitude, and more importantly, eliminating all actinides present in the spent fuel, substances which cause security concerns.

Nuclear fusion reactions have the potential to be safer and generate less radioactive waste than fission.
These reactions appear potentially viable, though technically quite difficult and have yet to be created on a scale that could be used in a functional power plant.
Fusion power has been under theoretical and experimental investigation since the 1950s.

Several experimental nuclear fusion reactors and facilities exist.
The largest and most ambitious international nuclear fusion project currently in progress is ITER, a large tokamak under construction in France.
ITER is planned to pave the way for commercial fusion power by demonstrating self-sustained nuclear fusion reactions with positive energy gain.
Construction of the ITER facility began in 2007, but the project has run into many delays and budget overruns.
The facility is now not expected to begin operations until the year 2027–11 years after initially anticipated. A follow on commercial nuclear fusion power station, DEMO, has been proposed. There are also suggestions for a power plant based upon a different fusion approach, that of an inertial fusion power plant.

Fusion powered electricity generation was initially believed to be readily achievable, as fission-electric power had been. However, the extreme requirements for continuous reactions and plasma containment led to projections being extended by several decades. In 2010, more than 60 years after the first attempts, commercial power production was still believed to be unlikely before 2050.





</doc>
<doc id="22156" url="https://en.wikipedia.org/wiki?curid=22156" title="BI Norwegian Business School">
BI Norwegian Business School

BI Norwegian Business School () is the largest business school in Norway and the second largest in all of Europe. BI has in total four campuses with the main one located in Oslo. The university has 845 employees consisting of an academic staff of 404 people and 441 administrative staff. In 2015, BI Norwegian Business School had 18,728 students. BI is the largest supplier of economic and administrative competence and skills in Norway with more than 200 000 graduates since 1983. BI Norwegian Business School is a private foundation and is accredited by NOKUT as a specialised university institution. BI organised its academic activities in nine separate research departments covering all of the disciplines that can be expected at a modern European business school.

BI Norwegian Business School was founded in 1943 by Finn Øien as "Bedriftøkonomisk Institutt" (), hence the abbreviation "BI".

BI offers a full set of programs for bachelor, master, and doctoral degrees, as well as executive education and tailor-made programs for businesses. The teaching languages are English (BBA and graduate programs) and Norwegian (majority of undergraduate programs and custom programs for local businesses). The school currently participates in exchange programs with 200 foreign institutions in 45 countries.

The internationally award-winning main campus in Nydalen (Oslo) was designed by Niels Torp, who also designed Gardermoen Airport.

Norsk Kundebarometer (NKB) () is a research program run by BI, with a focus on relations between customers and businesses. Based on an annual survey of Norwegian households, it collects data that may be used for comparison between businesses, comparisons between various industries, and comparisons over time.

BI has educated roughly 1700 students in China through its close relationship with Fudan University in Shanghai, and is also the majority shareholder of the ISM University of Management and Economics (previously known as International School of Management) with around 1800 students located in Vilnius and Kaunas in Lithuania.
Undergraduate (All taught in Norwegian except Business Administration and Business Analytics)

Graduate (All taught in English, except MSc in Accounting & Auditing and MSc in Law & Business)


Executive MBA (EMBA general management in cooperation with Nanyang Business School (Nanyang Technological University), Singapore and Instituto de Empresa in Madrid, Spain and Haas School of Business (University of California at Berkeley), USA)

The school has two student organizations, one for the main campus in Oslo and one for the other campuses. The Oslo student organization is called "" (SBIO) (). This union was formed in 2005 after the relocation of the three locations in Oslo into one—Nydalen Campus. The three previous unions were called Bedriftøkonomisk Studentersamfund (BS), BISON and MØSS. BS was the oldest union, formed in 1964. The union for the other campuses is "BI Studentsamfunn" (BIS) (). This union was founded on 7 February 1987 and is today the largest student union of a private school in Norway. As of June 2019, the two student organizations have decided to merge into one student body, the name and other details of which will be decided over the summer of 2019.

The student newspaper is named "INSIDE", and its circulation is 11,000.

The all-male student choir is named UFDA The Choir Boys and was established in 1986.

BI is currently ranked 37th in the Financial Times ranking of European Business Schools.

In 2009, BI was ranked by Eduniversal as the 35th most influential business school in the world.

BI is accredited as a specialised university institution by the Norwegian Agency for Quality Assurance in Education (NOKUT).

BI has also received the following recognitions from private institutions:





 

</doc>
<doc id="22158" url="https://en.wikipedia.org/wiki?curid=22158" title="Nuclear proliferation">
Nuclear proliferation

Nuclear proliferation is the spread of nuclear weapons, fissionable material, and weapons-applicable nuclear technology and information to nations not recognized as "Nuclear Weapon States" by the Treaty on the Non-Proliferation of Nuclear Weapons, commonly known as the "Non-Proliferation Treaty" or "NPT". Proliferation has been opposed by many nations with and without nuclear weapons, as governments fear that more countries with nuclear weapons will increase the possibility of nuclear warfare (up to and including the so-called countervalue targeting of civilians with nuclear weapons), de-stabilize international or regional relations, or infringe upon the national sovereignty of nation states.

Four countries besides the five recognized Nuclear Weapons States have acquired, or are presumed to have acquired, nuclear weapons: India, Pakistan, North Korea, and Israel. None of these four is a party to the NPT, although North Korea acceded to the NPT in 1985, then withdrew in 2003 and conducted announced nuclear tests in 2006, 2009, 2013, 2016, and 2017. One critique of the NPT is that the treaty is discriminatory in the sense that only those countries that tested nuclear weapons before 1968 are recognized as nuclear weapon states while all other states are treated as non-nuclear-weapon states who can only join the treaty if they forswear nuclear weapons.

Research into the development of nuclear weapons was initially undertaken during World War II by the United States (in cooperation with the United Kingdom and Canada), Germany, Japan, and the USSR. The United States was the first and is the only country to have used a nuclear weapon in war, when it used two bombs against Japan in August 1945. After surrendering to end the war, Germany and Japan ceased to be involved in any nuclear weapon research. In August 1949, the USSR tested a nuclear weapon, becoming the second country to detonate a nuclear bomb. The United Kingdom first tested a nuclear weapon in October 1952. France first tested a nuclear weapon in 1960. The People's Republic of China detonated a nuclear weapon in 1964. India conducted its first nuclear test in 1974, which prompted Pakistan to develop its own nuclear program and, when India conducted a second series of nuclear tests in 1998, Pakistan followed with a series of tests of its own. In 2006, North Korea conducted its first nuclear test.

Early efforts to prevent nuclear proliferation involved intense government secrecy, the wartime acquisition of known uranium stores (the Combined Development Trust), and at times even outright sabotage—such as the bombing of a heavy-water facility in Norway thought to be used for a German nuclear program. These efforts began immediately after the discovery of nuclear fission and its military potential. None of these efforts were explicitly public, because the weapon developments themselves were kept secret until the bombing of Hiroshima.

Earnest international efforts to promote nuclear non-proliferation began soon after World War II, when the Truman Administration proposed the Baruch Plan of 1946, named after Bernard Baruch, America's first representative to the United Nations Atomic Energy Commission. The Baruch Plan, which drew heavily from the Acheson–Lilienthal Report of 1946, proposed the verifiable dismantlement and destruction of the U.S. nuclear arsenal (which, at that time, was the only nuclear arsenal in the world) after all governments had cooperated successfully to accomplish two things: (1) the establishment of an "international atomic development authority," which would actually own and control all military-applicable nuclear materials and activities, and (2) the creation of a system of automatic sanctions, which not even the U.N. Security Council could veto, and which would proportionately punish states attempting to acquire the capability to make nuclear weapons or fissile material.

Baruch's plea for the destruction of nuclear weapons invoked basic moral and religious intuitions. In one part of his address to the UN, Baruch said, "Behind the black portent of the new atomic age lies a hope which, seized upon with faith, can work out our salvation. If we fail, then we have damned every man to be the slave of Fear. Let us not deceive ourselves. We must elect World Peace or World Destruction... We must answer the world's longing for peace and security." With this remark, Baruch helped launch the field of nuclear ethics, to which many policy experts and scholars have contributed.

Although the Baruch Plan enjoyed wide international support, it failed to emerge from the UNAEC because the Soviet Union planned to veto it in the Security Council. Still, it remained official American policy until 1953, when President Eisenhower made his "Atoms for Peace" proposal before the U.N. General Assembly. Eisenhower's proposal led eventually to the creation of the International Atomic Energy Agency (IAEA) in 1957. Under the "Atoms for Peace" program thousands of scientists from around the world were educated in nuclear science and then dispatched home, where many later pursued secret weapons programs in their home country.

Efforts to conclude an international agreement to limit the spread of nuclear weapons did not begin until the early 1960s, after four nations (the United States, the Soviet Union, the United Kingdom and France) had acquired nuclear weapons (see List of states with nuclear weapons for more information). Although these efforts stalled in the early 1960s, they renewed once again in 1964, after China detonated a nuclear weapon. In 1968, governments represented at the Eighteen Nation Disarmament Committee (ENDC) finished negotiations on the text of the NPT. In June 1968, the U.N. General Assembly endorsed the NPT with General Assembly Resolution 2373 (XXII), and in July 1968, the NPT opened for signature in Washington, DC, London and Moscow. The NPT entered into force in March 1970.

Since the mid-1970s, the primary focus of non-proliferation efforts has been to maintain, and even increase, international control over the fissile material and specialized technologies necessary to build such devices because these are the most difficult and expensive parts of a nuclear weapons program. The main materials whose generation and distribution is controlled are highly enriched uranium and plutonium. Other than the acquisition of these special materials, the scientific and technical means for weapons construction to develop rudimentary, but working, nuclear explosive devices are considered to be within the reach of industrialized nations.

Since its founding by the United Nations in 1957, the International Atomic Energy Agency (IAEA) has promoted two, sometimes contradictory, missions: on the one hand, the Agency seeks to promote and spread internationally the use of civilian nuclear energy; on the other hand, it seeks to prevent, or at least detect, the diversion of civilian nuclear energy to nuclear weapons, nuclear explosive devices or purposes unknown. The IAEA now operates a safeguards system as specified under Article III of the Nuclear Non-Proliferation Treaty (NPT) of 1968, which aims to ensure that civil stocks of uranium and plutonium, as well as facilities and technologies associated with these nuclear materials, are used only for peaceful purposes and do not contribute in any way to proliferation or nuclear weapons programs. It is often argued that proliferation of nuclear weapons to many other states has been prevented by the extension of assurances and mutual defence treaties to these states by nuclear powers, but other factors, such as national prestige, or specific historical experiences, also play a part in hastening or stopping nuclear proliferation.

Dual-use technology refers to the possibility of military use of civilian nuclear power technology. Many technologies and materials associated with the creation of a nuclear power program have a dual-use capability, in that several stages of the nuclear fuel cycle allow diversion of nuclear materials for nuclear weapons. When this happens a nuclear power program can become a route leading to the atomic bomb or a public annex to a secret bomb program. The crisis over Iran’s nuclear activities is a case in point.

Many UN and US agencies warn that building more nuclear reactors unavoidably increases nuclear proliferation risks. A fundamental goal for American and global security is to minimize the proliferation risks associated with the
expansion of nuclear power. If this development is "poorly managed or efforts to contain risks are unsuccessful, the nuclear future will be dangerous". For nuclear power programs to be developed and managed safely and securely, it is important that countries have domestic “good governance” characteristics that will encourage proper nuclear operations and management:

These characteristics include low degrees of corruption (to avoid officials selling materials and technology for their own personal gain as occurred with the A.Q. Khan smuggling network in Pakistan), high degrees of political stability (defined by the World Bank as “likelihood that the government will be destabilized or overthrown by unconstitutional or violent means, including motivated violence and terrorism”), high governmental effectiveness scores (a World Bank aggregate measure of “the quality of the civil service and the degree of its independence from political pressures [and] the quality of policy formulation and implementation”), and a strong degree of regulatory competence.

At present, 189 countries are States Parties to the "Treaty on the Nonproliferation of Nuclear Weapons", more commonly known as the Nuclear Non-Proliferation Treaty or NPT. These include the five Nuclear Weapons States (NWS) recognized by the NPT: the People's Republic of China, France, Russian Federation, the UK, and the United States.

Notable non-signatories to the NPT are Israel, Pakistan, and India (the latter two have since tested nuclear weapons, while Israel is considered by most to be an unacknowledged nuclear weapons state). North Korea was once a signatory but withdrew in January 2003. The legality of North Korea's withdrawal is debatable but as of 9 October 2006, North Korea clearly possesses the capability to make a nuclear explosive device.

The IAEA was established on 29 July 1957 to help nations develop nuclear energy for peaceful purposes. Allied to this role is the administration of safeguards arrangements to provide assurance to the international community that individual countries are honoring their commitments under the treaty. Though established under its own international treaty, the IAEA reports to both the United Nations General Assembly and the Security Council.

The IAEA regularly inspects civil nuclear facilities to verify the accuracy of documentation supplied to it. The agency checks inventories, and samples and analyzes materials. Safeguards are designed to deter diversion of nuclear material by increasing the risk of early detection. They are complemented by controls on the export of sensitive technology from countries such as UK and United States through voluntary bodies such as the Nuclear Suppliers Group. The main concern of the IAEA is that uranium not be enriched beyond what is necessary for commercial civil plants, and that plutonium which is produced by nuclear reactors not be refined into a form that would be suitable for bomb production.

Traditional safeguards are arrangements to account for and control the use of nuclear materials. This verification is a key element in the international system which ensures that uranium in particular is used only for peaceful purposes.

Parties to the NPT agree to accept technical safeguard measures applied by the IAEA. These require that operators of nuclear facilities maintain and declare detailed accounting records of all movements and transactions involving nuclear material. Over 550 facilities and several hundred other locations are subject to regular inspection, and their records and the nuclear material being audited. Inspections by the IAEA are complemented by other measures such as surveillance cameras and instrumentation.

The inspections act as an alert system providing a warning of the possible diversion of nuclear material from peaceful activities. The system relies on;

All NPT non-weapons states must accept these full-scope safeguards. In the five weapons states plus the non-NPT states (India, Pakistan and Israel), facility-specific safeguards apply. IAEA inspectors regularly visit these facilities to verify completeness and accuracy of records.

The terms of the NPT cannot be enforced by the IAEA itself, nor can nations be forced to sign the treaty. In reality, as shown in Iraq and North Korea, safeguards can be backed up by diplomatic, political and economic measures.

While traditional safeguards easily verified the correctness of formal declarations by suspect states, in the 1990s attention turned to what might not have been declared. While accepting safeguards at declared facilities, Iraq had set up elaborate equipment elsewhere in an attempt to enrich uranium to weapons-grade. North Korea attempted to use research reactors (not commercial electricity-generating reactors) and a nuclear reprocessing plant to produce some weapons-grade plutonium.

The weakness of the NPT regime lay in the fact that no obvious diversion of material was involved. The uranium used as fuel probably came from indigenous sources, and the nuclear facilities were built by the countries themselves without being declared or placed under safeguards. Iraq, as an NPT party, was obliged to declare all facilities but did not do so. Nevertheless, the activities were detected and brought under control using international diplomacy. In Iraq, a military defeat assisted this process.

In North Korea, the activities concerned took place before the conclusion of its NPT safeguards agreement. With North Korea, the promised provision of commercial power reactors appeared to resolve the situation for a time, but it later withdrew from the NPT and declared it had nuclear weapons.

In 1993 a program was initiated to strengthen and extend the classical safeguards system, and a model protocol was agreed by the IAEA Board of Governors 1997. The measures boosted the IAEA's ability to detect undeclared nuclear activities, including those with no connection to the civil fuel cycle.

Innovations were of two kinds. Some could be implemented on the basis of IAEA's existing legal authority through safeguards agreements and inspections. Others required further legal authority to be conferred through an Additional Protocol. This must be agreed by each non-weapons state with IAEA, as a supplement to any existing comprehensive safeguards agreement. Weapons states have agreed to accept the principles of the model additional protocol.

Key elements of the model Additional Protocol:

As of 3 July 2015, 146 countries have signed the Additional Protocols and 126 have brought them into force. The IAEA is also applying the measures of the Additional Protocol in Taiwan. Under the Joint Comprehensive Plan of Action, Iran has agreed to implement its protocol provisionally. Among the leading countries that have not signed the Additional Protocol are Egypt, which says it will not sign until Israel accepts comprehensive IAEA safeguards, and Brazil, which opposes making the protocol a requirement for international cooperation on enrichment and reprocessing, but has not ruled out signing.

The greatest risk from nuclear weapons proliferation comes from countries which have not joined the NPT and which have significant unsafeguarded nuclear activities; India, Pakistan, and Israel fall within this category. While safeguards apply to some of their activities, others remain beyond scrutiny.

A further concern is that countries may develop various sensitive nuclear fuel cycle facilities and research reactors under full safeguards and then subsequently opt out of the NPT. Bilateral agreements, such as insisted upon by Australia and Canada for sale of uranium, address this by including fallback provisions, but many countries are outside the scope of these agreements. If a nuclear-capable country does leave the NPT, it is likely to be reported by the IAEA to the UN Security Council, just as if it were in breach of its safeguards agreement. Trade sanctions would then be likely.

IAEA safeguards can help ensure that uranium supplied as nuclear fuel and other nuclear supplies do not contribute to nuclear weapons proliferation. In fact, the worldwide application of those safeguards and the substantial world trade in uranium for nuclear electricity make the proliferation of nuclear weapons much less likely.

The Additional Protocol, once it is widely in force, will provide credible assurance that there are no undeclared nuclear materials or activities in the states concerned. This will be a major step forward in preventing nuclear proliferation.

The Nuclear Suppliers Group communicated its guidelines, essentially a set of export rules, to the IAEA in 1978. These were to ensure that transfers of nuclear material or equipment would not be diverted to unsafeguarded nuclear fuel cycle or nuclear explosive activities, and formal government assurances to this effect were required from recipients. The Guidelines also recognised the need for physical protection measures in the transfer of sensitive facilities, technology and weapons-usable materials, and strengthened retransfer provisions. The group began with seven members—the United States, the former USSR, the United Kingdom, France, Germany, Canada and Japan—but now includes 46 countries including all five nuclear weapons states.

The International Framework for Nuclear Energy Cooperation is an international project involving 25 partner countries, 28 observer and candidate partner countries, and the International Atomic Energy Agency, the Generation IV International Forum, and the European Commission. Its goal is to "[..] provide competitive, commercially-based services as an alternative to a state’s development of costly, proliferation-sensitive facilities, and address other issues associated with the safe and secure management of used fuel and radioactive waste."

According to Kenneth D. Bergeron's "Tritium on Ice: The Dangerous New Alliance of Nuclear Weapons and Nuclear Power", tritium is not classified as a "special nuclear material" but rather as a by-product. It is seen as an important litmus test on the seriousness of the United States' intention to nuclear disarm. This radioactive, super-heavy, hydrogen isotope is used to boost the efficiency of fissile materials in nuclear weapons. The United States resumed tritium production in 2003 for the first time in 15 years. This could indicate that there is a potential nuclear arm stockpile replacement since the isotope naturally decays.

In May 1995, NPT parties reaffirmed their commitment to a Fissile Materials Cut-off Treaty to prohibit the production of any further fissile material for weapons. This aims to complement the Comprehensive Nuclear-Test-Ban Treaty of 1996 (not entered into force as of June 2020) and to codify commitments made by the United States, the UK, France and Russia to cease production of weapons material, as well as putting a similar ban on China. This treaty will also put more pressure on Israel, India and Pakistan to agree to international verification.

On 9 August 2005, Ayatollah Ali Khamenei issued a fatwa forbidding the production, stockpiling and use of nuclear weapons. Khamenei's official statement was made at the meeting of the International Atomic Energy Agency (IAEA) in Vienna. As of February 2006 Iran formally announced that uranium enrichment within their borders has continued. Iran claims it is for peaceful purposes but the United Kingdom, France, Germany, and the United States claim the purpose is for nuclear weapon research and construction.

India, Pakistan and Israel have been "threshold" countries in terms of the international non-proliferation regime. They possess or are quickly capable of assembling one or more nuclear weapons. They have remained outside the 1970 NPT. They are thus largely excluded from trade in nuclear plant or materials, except for safety-related devices for a few safeguarded facilities.

In May 1998 India and Pakistan each exploded several nuclear devices underground. This heightened concerns regarding an arms race between them, with Pakistan involving the People's Republic of China, an acknowledged nuclear weapons state. Both countries are opposed to the NPT as it stands, and India has consistently attacked the Treaty since its inception in 1970 labeling it as a lopsided treaty in favor of the nuclear powers.

Relations between the two countries are tense and hostile, and the risks of nuclear conflict between them have long been considered quite high. Kashmir is a prime cause of bilateral tension, its sovereignty being in dispute since 1948. There is persistent low level bilateral military conflict due to alleged backing of insurgency by Pakistan in India, and infiltration of Pakistani state backed militants into the Indian state of Jammu and Kashmir, along with the disputed status of Kashmir.

Both engaged in a conventional arms race in the 1980s, including sophisticated technology and equipment capable of delivering nuclear weapons. In the 1990s the arms race quickened. In 1994 India reversed a four-year trend of reduced allocations for defence, and despite its much smaller economy, Pakistan was expected to push its own expenditures yet higher. Both have lost their patrons: India, the former USSR, and Pakistan, the United States.

But it is the growth and modernization of China's nuclear arsenal and its assistance with Pakistan's nuclear power programme and, reportedly, with missile technology, which exacerbate Indian concerns. In particular, as viewed by Indian strategists, Pakistan is aided by China's People's Liberation Army.

Nuclear power for civil use is well established in India. Its civil nuclear strategy has been directed towards complete independence in the nuclear fuel cycle, necessary because of its outspoken rejection of the NPT. Due to economic and technological isolation of India after the nuclear tests in 1974, India has largely diverted focus on developing and perfecting the fast breeder technology by intensive materials and fuel cycle research at the dedicated center established for research into fast reactor technology, Indira Gandhi Center for Atomic Research (IGCAR) at Kalpakkam, in the southern part of the country. At the moment, India has a small fast breeder reactor and is planning a much larger one (Prototype Fast Breeder Reactor). This self-sufficiency extends from uranium exploration and mining through fuel fabrication, heavy water production, reactor design and construction, to reprocessing and waste management. It is also developing technology to utilise its abundant resources of thorium as a nuclear fuel.

India has 14 small nuclear power reactors in commercial operation, two larger ones under construction, and ten more planned. The 14 operating ones (2548 MWe total) comprise:

The two under construction and two of the planned ones are 450 MWe versions of these 200 MWe domestic products. Construction has been seriously delayed by financial and technical problems. In 2001 a final agreement was signed with Russia for the country's first large nuclear power plant, comprising two VVER-1000 reactors, under a Russian-financed US$3 billion contract. The first unit is due to be commissioned in 2007. A further two Russian units are under consideration for the site. Nuclear power supplied 3.1% of India's electricity in 2000.

Its weapons material appears to come from a Canadian-designed 40 MW "research" reactor which started up in 1960, well before the NPT, and a 100 MW indigenous unit in operation since 1985. Both use local uranium, as India does not import any nuclear fuel. It is estimated that India may have built up enough weapons-grade plutonium for a hundred nuclear warheads.

It is widely believed that the nuclear programs of India and Pakistan used Canadian CANDU reactors to produce fissionable materials for their weapons; however, this is not accurate. Both Canada (by supplying the 40 MW research reactor) and the United States (by supplying 21 tons of heavy water) supplied India with the technology necessary to create a nuclear weapons program, dubbed CIRUS (Canada-India Reactor, United States). Canada sold India the reactor on the condition that the reactor and any by-products would be "employed for peaceful purposes only.". Similarly, the United States sold India heavy water for use in the reactor "only... in connection with research into and the use of atomic energy for peaceful purposes". India, in violation of these agreements, used the Canadian-supplied reactor and American-supplied heavy water to produce plutonium for their first nuclear explosion, Smiling Buddha. The Indian government controversially justified this, however, by claiming that Smiling Buddha was a "peaceful nuclear explosion."

The country has at least three other research reactors including the tiny one which is exploring the use of thorium as a nuclear fuel, by breeding fissile U-233. In addition, an advanced heavy-water thorium cycle is under development.

India exploded a nuclear device in 1974, the so-called Smiling Buddha test, which it has consistently claimed was for peaceful purposes. Others saw it as a response to China's nuclear weapons capability. It was then universally perceived, notwithstanding official denials, to possess, or to be able to quickly assemble, nuclear weapons. In 1999 it deployed its own medium-range missile and has developed an intermediate-range missile capable of reaching targets in China's industrial heartland.

In 1995 the United States quietly intervened to head off a proposed nuclear test. However, in 1998 there were five more tests in Operation Shakti. These were unambiguously military, including one claimed to be of a sophisticated thermonuclear device, and their declared purpose was "to help in the design of nuclear weapons of different yields and different delivery systems".

Indian security policies are driven by:

It perceives nuclear weapons as a cost-effective political counter to China's nuclear and conventional weaponry, and the effects of its nuclear weapons policy in provoking Pakistan is, by some accounts, considered incidental.
India has had an unhappy relationship with China. After an uneasy ceasefire ended the 1962 war, relations between the two nations were frozen until 1998. Since then a degree of high-level contact has been established and a few elementary confidence-building measures put in place. China still occupies some territory which it captured during the aforementioned war, claimed by India, and India still occupies some territory claimed by China. Its nuclear weapon and missile support for Pakistan is a major bone of contention.

American President George W. Bush met with India Prime Minister Manmohan Singh to discuss India's involvement with nuclear weapons. The two countries agreed that the United States would give nuclear power assistance to India.

Over the years in Pakistan their nuclear power infrastructure has been well established. It is dedicated to the industrial and economic development of the country. Its current nuclear policy is aimed to promote the socio-economic development of its people as a "foremost priority"; and to fulfill energy, economic, and industrial needs from nuclear sources. , there were three operational mega-commercial nuclear power plants while three larger ones were under construction. The nuclear power plants supplied 787 megawatts (MW) (roughly ≈3.6%) of electricity, and the country has projected production of 8800 MW by 2030. Infrastructure established by the IAEA and the U.S. in the 1950s–1960s was based on peaceful research and development and the economic prosperity of the country.

Although the civil-sector nuclear power was established in the 1950s, the country has an active nuclear weapons program which was started in the 1970s. The bomb program has its roots after East Pakistan gained its independence through the Bangladesh Liberation War, as the new nation of Bangladesh, after India's successful intervention led to a decisive victory over Pakistan in 1971. This large-scale but clandestine atomic bomb project was directed towards the indigenous development of reactor and military-grade plutonium. In 1974, when India surprised the world with the successful detonation of its own bomb, codename "Smiling Buddha", it became "imperative for Pakistan" to pursue weapons research. According to a leading scientist in the program, it became clear that once India detonated their bomb, "Newton's Third Law" came into "operation", from then on it was a classic case of "action and reaction". Earlier efforts were directed towards mastering the plutonium technology from France, but that route was slowed when the plan failed after U.S. intervention to cancel the project. Contrary to popular perception, Pakistan did not forego the "plutonium" route and covertly continued its indigenous research under Munir Ahmad Khan and it succeeded with that route in the early 1980s. Reacting to India's first nuclear weapon test, Prime Minister Zulfikar Ali Bhutto and the country's political and military science circles sensed this test as final and dangerous anticipation to Pakistan's "moral and physical existence." With diplomat Aziz Ahmed on his side, Prime Minister Bhutto launched a serious diplomatic offense and aggressively maintained at the session of the United Nations Security Council:

After 1974, Bhutto's government redoubled its effort, this time equally focused on uranium and plutonium. Pakistan had established science directorates in almost all of her embassies in the important countries of the world, with theoretical physicist S.A. Butt being the director. Abdul Qadeer Khan then established a network through Dubai to smuggle URENCO technology to the Engineering Research Laboratories. Earlier, he worked with the "Physics Dynamics Research Laboratories" (FDO), a subsidiary of the Dutch firm VMF-Stork based in Amsterdam. Later after joining, Urenco, he had access through photographs and documents to the technology. Against popular perception, the technology that Khan had brought from Urenco was based on first generation civil reactor technology, filled with many serious technical errors, though it was an authentic and vital link for the country's gas centrifuge project. After the British Government stopped the British subsidiary of the American Emerson Electric Co. from shipping components to Pakistan, he describes his frustration with a supplier from Germany as: "That man from the German team was unethical. When he did not get the order from us, he wrote a letter to a Labour Party member and questions were asked in [British] Parliament." By 1978, his efforts paid off and made him into a national hero.

In early 1996 the next Prime Minister of Pakistan Benazir Bhutto made it clear that "if India conducts a nuclear test, Pakistan could be forced to "follow suit". In 1997, her statement was echoed by Prime Minister Nawaz Sharif who maintained that "since 1972, [P]akistan had progressed significantly, and we have left that stage (developmental) far behind. Pakistan will not be made a "hostage" to India by signing the CTBT, before (India).!" In May 1998, within weeks of India's nuclear tests, Pakistan announced that it had conducted six underground tests in the Chagai Hills, five on 28 May and one on 30 May. Seismic events consistent with these claims were recorded.

In 2004, the revelation of Khan's efforts led to the exposure of many defunct European consortiums which had defied export restrictions in the 1970s, and of many defunct Dutch companies that exported thousands of centrifuges to Pakistan as early as 1976. Many centrifuge components were apparently manufactured by the Malaysian Scomi Precision Engineering with the assistance of South Asian and German companies, and used a UAE-based computer company as a false front.

It was widely believed to have had direct involvement by the Government of Pakistan. This claim could not be verified due to the refusal of that Government to allow the IAEA to interview the alleged head of the nuclear black market, who happened to be no other than Abdul Qadeer Khan. Confessing his crimes a month later on national television, Khan bailed out the Government by taking full responsibility. Independent investigation conducted by International Institute for Strategic Studies (IISS) confirmed that he had control over the import-export deals, and his acquisition activities were largely unsupervised by Pakistan governmental authorities. All of his activities went undetected for several years. He duly confessed to running the atomic proliferation ring from Pakistan to Iran and North Korea. He was immediately given presidential immunity. The exact nature of involvement at the governmental level is still unclear, but the manner in which the government acted cast doubt on the sincerity of Pakistan.

The Democratic People's Republic of Korea (or better known as North Korea), joined the NPT in 1985 and had subsequently signed a safeguards agreement with the IAEA. However, it was believed that North Korea was diverting plutonium extracted from the fuel of its reactor at Yongbyon, for use in nuclear weapons. The subsequent confrontation with IAEA on the issue of inspections and suspected violations, resulted in North Korea threatening to withdraw from the NPT in 1993. This eventually led to negotiations with the United States resulting in the Agreed Framework of 1994, which provided for IAEA safeguards being applied to its reactors and spent fuel rods. These spent fuel rods were sealed in canisters by the United States to prevent North Korea from extracting plutonium from them. North Korea had to therefore freeze its plutonium programme.

During this period, Pakistan-North Korea cooperation in missile technology transfer was being established. A high level delegation of Pakistan military visited North Korea in August–September 1992, reportedly to discuss the supply of missile technology to Pakistan. In 1993, PM Benazir Bhutto repeatedly traveled to China, and the paid state visit to North Korea. The visits are believed to be related to the subsequent acquisition technology to developed its Ghauri system by Pakistan. During the period 1992–1994, A.Q. Khan was reported to have visited North Korea thirteen times. The missile cooperation program with North Korea was under Dr. A. Q. Khan Research Laboratories. At this time China was under U.S. pressure not to supply the M Dongfeng series of missiles to Pakistan. It is believed by experts that possibly with Chinese connivance and facilitation, the latter was forced to approach North Korea for missile transfers. Reports indicate that North Korea was willing to supply missile sub-systems including rocket motors, inertial guidance systems, control and testing equipment for US$50 million.

It is not clear what North Korea got in return. Joseph S. Bermudez Jr. in "Jane's Defence Weekly" (27 November 2002) reports that Western analysts had begun to question what North Korea received in payment for the missiles; many suspected it was the nuclear technology. The KRL was in charge of both uranium program and also of the missile program with North Korea. It is therefore likely during this period that cooperation in nuclear technology between Pakistan and North Korea was initiated. Western intelligence agencies began to notice exchange of personnel, technology and components between KRL and entities of the North Korean 2nd Economic Committee (responsible for weapons production).

A "New York Times" report on 18 October 2002 quoted U.S. intelligence officials having stated that Pakistan was a major supplier of critical equipment to North Korea. The report added that equipment such as gas centrifuges appeared to have been "part of a barter deal" in which North Korea supplied Pakistan with missiles. Separate reports indicate ("The Washington Times", 22 November 2002) that U.S. intelligence had as early as 1999 picked up signs that North Korea was continuing to develop nuclear arms. Other reports also indicate that North Korea had been working covertly to develop an enrichment capability for nuclear weapons for at least five years and had used technology obtained from Pakistan ("The Washington Times", 18 October 2002).

Israel is also thought to possess an arsenal of potentially up to several hundred nuclear warheads based on estimates of the amount of fissile material produced by Israel. This has never been openly confirmed or denied however, due to Israel's policy of deliberate ambiguity.

An Israeli nuclear installation is located about ten kilometers to the south of Dimona, the Negev Nuclear Research Center. Its construction commenced in 1958, with French assistance. The official reason given by the Israeli and French governments was to build a nuclear reactor to power a "desalination plant", in order to "green the Negev". The purpose of the Dimona plant is widely assumed to be the manufacturing of nuclear weapons, and the majority of defense experts have concluded that it does in fact do that. However, the Israeli government refuses to confirm or deny this publicly, a policy it refers to as "ambiguity".

Norway sold 20 tonnes of heavy water needed for the reactor to Israel in 1959 and 1960 in a secret deal. There were no "safeguards" required in this deal to prevent usage of the heavy water for non-peaceful purposes. The British newspaper "Daily Express" accused Israel of working on a bomb in 1960.
When the United States intelligence community discovered the purpose of the Dimona plant in the early 1960s, it demanded that Israel agree to international inspections. Israel agreed, but on a condition that U.S., rather than IAEA, inspectors were used, and that Israel would receive advanced notice of all inspections.
Some claim that because Israel knew the schedule of the inspectors' visits, it was able to hide the alleged purpose of the site from the inspectors by installing temporary false walls and other devices before each inspection. The inspectors eventually informed the U.S. government that their inspections were useless due to Israeli restrictions on what areas of the facility they could inspect. In 1969, the United States terminated the inspections.

In 1986, Mordechai Vanunu, a former technician at the Dimona plant, revealed to the media some evidence of Israel's nuclear program. Israeli agents arrested him in Italy, drugged him and transported him to Israel. An Israeli court then tried him in secret on charges of treason and espionage, and sentenced him to eighteen years imprisonment. He was freed on 21 April 2004, but was severely limited by the Israeli government. He was arrested again on 11 November 2004, though formal charges were not immediately filed.

Comments on photographs taken by Vanunu inside the Negev Nuclear Research Center have been made by prominent scientists. British nuclear weapons scientist Frank Barnaby, who questioned Vanunu over several days, estimated Israel had enough plutonium for about 150 weapons.

According to Lieutenant Colonel Warner D. Farr in a report to the USAF Counterproliferation Center, while France was previously a leader in nuclear research "Israel and France were at a similar level of expertise after WWII, and Israeli scientists could make significant contributions to the French effort." In 1986 Francis Perrin, French high-commissioner for atomic energy from 1951 to 1970 stated that in 1949 Israeli scientists were invited to the Saclay nuclear research facility, this cooperation leading to a joint effort including sharing of knowledge between French and Israeli scientists especially those with knowledge from the Manhattan Project.

The public stance of India and Pakistan on non-proliferation differs markedly. Pakistan has initiated a series of regional security proposals. It has repeatedly proposed a nuclear free zone in South Asia, and has proclaimed its willingness to engage in nuclear disarmament and to sign the Non-Proliferation Treaty if India would do so. It has endorsed a United States proposal for a regional five power conference to consider non-proliferation in South Asia.

India has taken the view that solutions to regional security issues should be found at the international rather than the regional level, since its chief concern is with China. It therefore rejects Pakistan's proposals.

Instead, the 'Gandhi Plan', put forward in 1988, proposed the revision of the Non-Proliferation Treaty, which it regards as inherently discriminatory in favor of the nuclear-weapon States, and a timetable for complete nuclear weapons disarmament. It endorsed early proposals for a Comprehensive Test Ban Treaty and for an international convention to ban the production of highly-enriched uranium and plutonium for weapons purposes, known as the 'cut-off' convention.

The United States for some years, especially under the Clinton administration, pursued a variety of initiatives to persuade India and Pakistan to abandon their nuclear weapons programs and to accept comprehensive international safeguards on all their nuclear activities. To this end, the Clinton administration proposed a conference of the five nuclear-weapon states, Japan, Germany, India and Pakistan.

India refused this and similar previous proposals, and countered with demands that other potential weapons states, such as Iran and North Korea, should be invited, and that regional limitations would only be acceptable if they were accepted equally by China. The United States would not accept the participation of Iran and North Korea and these initiatives have lapsed.

Another, more recent approach, centers on 'capping' the production of fissile material for weapons purposes, which would hopefully be followed by 'roll back'. To this end, India and the United States jointly sponsored a UN General Assembly resolution in 1993 calling for negotiations for a 'cut-off' convention. Should India and Pakistan join such a convention, they would have to agree to halt the production of fissile materials for weapons and to accept international verification on their relevant nuclear facilities (enrichment and reprocessing plants). It appears that India is now prepared to join negotiations regarding such a Cut-off Treaty, under the UN Conference on Disarmament.

Bilateral confidence-building measures between India and Pakistan to reduce the prospects of confrontation have been limited. In 1990 each side ratified a treaty not to attack the other's nuclear installations, and at the end of 1991 they provided one another with a list showing the location of all their nuclear plants, even though the respective lists were regarded as not being wholly accurate. Early in 1994 India proposed a bilateral agreement for a 'no first use' of nuclear weapons and an extension of the 'no attack' treaty to cover civilian and industrial targets as well as nuclear installations.

Having promoted the Comprehensive Test Ban Treaty since 1954, India dropped its support in 1995 and in 1996 attempted to block the Treaty. Following the 1998 tests the question has been reopened and both Pakistan and India have indicated their intention to sign the CTBT. Indian ratification may be conditional upon the five weapons states agreeing to specific reductions in nuclear arsenals. The UN Conference on Disarmament has also called upon both countries "to accede without delay to the Non-Proliferation Treaty", presumably as non-weapons states.

In 2004 and 2005, Egypt disclosed past undeclared nuclear activities and material to the IAEA. In 2007 and 2008, high-enriched and low-enriched uranium particles were found in environmental samples taken in Egypt. In 2008, the IAEA states Egypt's statements were consistent with its own findings. In May 2009, "Reuters" reported that the IAEA was conducting further investigation in Egypt.

In 2003, the IAEA reported that Iran had been in breach of its obligations to comply with provisions of its safeguard agreement. In 2005, the IAEA Board of Governors voted in a rare non-consensus decision to find Iran in non-compliance with its NPT Safeguards Agreement and to report that non-compliance to the UN Security Council. In response, the UN Security Council passed a series of resolutions citing concerns about the program. Iran's representative to the UN argues sanctions compel Iran to abandon its rights under the Nuclear Nonproliferation Treaty to peaceful nuclear technology. Iran says its uranium enrichment program is exclusively for peaceful purposes and has enriched uranium to "less than 5 percent," consistent with fuel for a nuclear power plant and significantly below the purity of WEU (around 90%) typically used in a weapons program. The director general of the International Atomic Energy Agency, Yukiya Amano, said in 2009 he had not seen any evidence in IAEA official documents that Iran was developing nuclear weapons.

Up to the late 1980s it was generally assumed that any undeclared nuclear activities would have to be based on the diversion of nuclear material from safeguards. States acknowledged the possibility of nuclear activities entirely separate from those covered by safeguards, but it was assumed they would be detected by national intelligence activities. There was no particular effort by IAEA to attempt to detect them.

Iraq had been making efforts to secure a nuclear potential since the 1960s. In the late 1970s a specialised plant, Osiraq, was constructed near Baghdad. The plant was attacked during the Iran–Iraq War and was destroyed by Israeli bombers in June 1981.

Not until the 1990 NPT Review Conference did some states raise the possibility of making more use of (for example) provisions for "special inspections" in existing NPT Safeguards Agreements. Special inspections can be undertaken at locations other than those where safeguards routinely apply, if there is reason to believe there may be undeclared material or activities.

After inspections in Iraq following the UN Gulf War cease-fire resolution showed the extent of Iraq's clandestine nuclear weapons program, it became clear that the IAEA would have to broaden the scope of its activities. Iraq was an NPT Party, and had thus agreed to place all its nuclear material under IAEA safeguards. But the inspections revealed that it had been pursuing an extensive clandestine uranium enrichment programme, as well as a nuclear weapons design programme.

The main thrust of Iraq's uranium enrichment program was the development of technology for electromagnetic isotope separation (EMIS) of indigenous uranium. This uses the same principles as a mass spectrometer (albeit on a much larger scale). Ions of uranium-238 and uranium-235 are separated because they describe arcs of different radii when they move through a magnetic field. This process was used in the Manhattan Project to make the highly-enriched uranium used in the Hiroshima bomb, but was abandoned soon afterwards.

The Iraqis did the basic research work at their nuclear research establishment at Tuwaitha, near Baghdad, and were building two full-scale facilities at Tarmiya and Ash Sharqat, north of Baghdad. However, when the war broke out, only a few separators had been installed at Tarmiya, and none at Ash Sharqat.

The Iraqis were also very interested in centrifuge enrichment, and had been able to acquire some components including some carbon-fibre rotors, which they were at an early stage of testing. In May 1998, "Newsweek" reported that Abdul Qadeer Khan had sent Iraq centrifuge designs, which were apparently confiscated by the UNMOVIC officials. Iraqi officials said "the documents were authentic but that they had not agreed to work with A. Q. Khan, fearing an ISI sting operation, due to strained relations between two countries. The Government of Pakistan and A. Q. Khan strongly denied this allegation whilst the government declared the evidence to be "fraudulent".

They were clearly in violation of their NPT and safeguards obligations, and the IAEA Board of Governors ruled to that effect. The UN Security Council then ordered the IAEA to remove, destroy or render harmless Iraq's nuclear weapons capability. This was done by mid-1998, but Iraq then ceased all cooperation with the UN, so the IAEA withdrew from this work.

The revelations from Iraq provided the impetus for a very far-reaching reconsideration of what safeguards are intended to achieve.

Libya possesses ballistic missiles and previously pursued nuclear weapons under the leadership of Muammar Gaddafi. On 19 December 2003, Gaddafi announced that Libya would voluntarily eliminate all materials, equipment and programs that could lead to internationally proscribed weapons, including weapons of mass destruction and long-range ballistic missiles. Libya signed the Nuclear Non-Proliferation Treaty (NPT) in 1968 and ratified it in 1975, and concluded a safeguards agreement with the International Atomic Energy Agency (IAEA) in 1980. In March 2004, the IAEA Board of Governors welcomed Libya's decision to eliminate its formerly undeclared nuclear program, which it found had violated Libya's safeguards agreement, and approved Libya's Additional Protocol. The United States and the United Kingdom assisted Libya in removing equipment and material from its nuclear weapons program, with independent verification by the IAEA.

A report in the "Sydney Morning Herald" and "Searchina", a Japanese newspaper, report that two Myanma defectors saying that the Myanmar junta was secretly building a nuclear reactor and plutonium extraction facility with North Korea's help, with the aim of acquiring its first nuclear bomb in five years. According to the report, "The secret complex, much of it in caves tunnelled into a mountain at Naung Laing in northern Burma, runs parallel to a civilian reactor being built at another site by Russia that both the Russians and Burmese say will be put under international safeguards." In 2002, Myanmar had notified IAEA of its intention to pursue a civilian nuclear programme. Later, Russia announced that it would build a nuclear reactor in Myanmar. There have also been reports that two Pakistani scientists, from the AQ Khan stable, had been dispatched to Myanmar where they had settled down, to help Myanmar's project. Recently, the David Albright-led Institute for Science and International Security (ISIS) rang alarm bells about Myanmar attempting a nuclear project with North Korean help. If true, the full weight of international pressure will be brought against Myanmar, said officials familiar with developments. But equally, the information that has been peddled by the defectors is also "preliminary" and could be used by the west to turn the screws on Myanmar—on democracy and human rights issues—in the run-up to the elections in the country in 2010. During an ASEAN meeting in Thailand in July 2009, US secretary of state Hillary Clinton highlighted concerns of the North Korean link. "We know there are also growing concerns about military cooperation between North Korea and Burma which we take very seriously," Clinton said. However, in 2012, after contact with the American president, Barack Obama, the Burmese leader, Thein Sein, renounced military ties with DPRK (North Korea).

The Democratic People's Republic of Korea (DPRK) acceded to the NPT in 1985 as a condition for the supply of a nuclear power station by the USSR. However, it delayed concluding its NPT Safeguards Agreement with the IAEA, a process which should take only 18 months, until April 1992.

During that period, it brought into operation a small gas-cooled, graphite-moderated, natural-uranium (metal) fuelled "Experimental Power Reactor" of about 25 MWt (5 MWe), based on the UK Magnox design. While this was a well-suited design to start a wholly indigenous nuclear reactor development, it also exhibited all the features of a small plutonium production reactor for weapons purposes. North Korea also made substantial progress in the construction of two larger reactors designed on the same principles, a prototype of about 200 MWt (50 MWe), and a full-scale version of about 800 MWt (200 MWe). They made only slow progress; construction halted on both in 1994 and has not resumed. Both reactors have degraded considerably since that time and would take significant efforts to refurbish.

In addition it completed and commissioned a reprocessing plant that makes the Magnox spent nuclear fuel safe, recovering uranium and plutonium. That plutonium, if the fuel was only irradiated to a very low burn-up, would have been in a form very suitable for weapons. Although all these facilities at the Yongbyon Nuclear Scientific Research Center were to be under safeguards, there was always the risk that at some stage, the DPRK would withdraw from the NPT and use the plutonium for weapons.

One of the first steps in applying NPT safeguards is for the IAEA to verify the initial stocks of uranium and plutonium to ensure that all the nuclear materials in the country have been declared for safeguards purposes. While undertaking this work in 1992, IAEA inspectors found discrepancies which indicated that the reprocessing plant had been used more often than the DPRK had declared, which suggested that the DPRK could have weapons-grade plutonium which it had not declared to the IAEA. Information passed to the IAEA by a Member State (as required by the IAEA) supported that suggestion by indicating that the DPRK had two undeclared waste or other storage sites.

In February 1993 the IAEA called on the DPRK to allow special inspections of the two sites so that the initial stocks of nuclear material could be verified. The DPRK refused, and on 12 March announced its intention to withdraw from the NPT (three months' notice is required). In April 1993 the IAEA Board concluded that the DPRK was in non-compliance with its safeguards obligations and reported the matter to the UN Security Council. In June 1993 the DPRK announced that it had "suspended" its withdrawal from the NPT, but subsequently claimed a "special status" with respect to its safeguards obligations. This was rejected by IAEA.

Once the DPRK's non-compliance had been reported to the UN Security Council, the essential part of the IAEA's mission had been completed. Inspections in the DPRK continued, although inspectors were increasingly hampered in what they were permitted to do by the DPRK's claim of a "special status". However, some 8,000 corroding fuel rods associated with the experimental reactor have remained under close surveillance.

Following bilateral negotiations between the United States and the DPRK, and the conclusion of the Agreed Framework in October 1994, the IAEA has been given additional responsibilities. The agreement requires a freeze on the operation and construction of the DPRK's plutonium production reactors and their related facilities, and the IAEA is responsible for monitoring the freeze until the facilities are eventually dismantled. The DPRK remains uncooperative with the IAEA verification work and has yet to comply with its safeguards agreement.

While Iraq was defeated in a war, allowing the UN the opportunity to seek out and destroy its nuclear weapons programme as part of the cease-fire conditions, the DPRK was not defeated, nor was it vulnerable to other measures, such as trade sanctions. It can scarcely afford to import anything, and sanctions on vital commodities, such as oil, would either be ineffective or risk provoking war.

Ultimately, the DPRK was persuaded to stop what appeared to be its nuclear weapons programme in exchange, under the agreed framework, for about US$5 billion in energy-related assistance. This included two 1000 MWe light water nuclear power reactors based on an advanced U.S. System-80 design.

In January 2003 the DPRK withdrew from the NPT. In response, a series of discussions among the DPRK, the United States, and China, a series of six-party talks (the parties being the DPRK, the ROK, China, Japan, the United States and Russia) were held in Beijing; the first beginning in April 2004 concerning North Korea's weapons program.

On 10 January 2005, North Korea declared that it was in the possession of nuclear weapons. On 19 September 2005, the fourth round of the Six-Party Talks ended with a joint statement in which North Korea agreed to end its nuclear programs and return to the NPT in exchange for diplomatic, energy and economic assistance. However, by the end of 2005 the DPRK had halted all six-party talks because the United States froze certain DPRK international financial assets such as those in a bank in Macau.

On 9 October 2006, North Korea announced that it has performed its first-ever nuclear weapon test. On 18 December 2006, the six-party talks finally resumed. On 13 February 2007, the parties announced "Initial Actions" to implement the 2005 joint statement including shutdown and disablement of North Korean nuclear facilities in exchange for energy assistance. Reacting to UN sanctions imposed after missile tests in April 2009, North Korea withdrew from the six-party talks, restarted its nuclear facilities and conducted a second nuclear test on 25 May 2009.

On 12 February 2013, North Korea conducted an underground nuclear explosion with an estimated yield of 6 to 7 kilotonnes. The detonation registered a magnitude 4.9 disturbance in the area around the epicenter.

Security of nuclear weapons in Russia remains a matter of concern. According to high-ranking Russian SVR defector Tretyakov, he had a meeting with two Russian businessman representing a state-created "C-W" corporation in 1991. They came up with a project of destroying large quantities of chemical wastes collected from Western countries at the island of Novaya Zemlya (a test place for Soviet nuclear weapons) using an underground nuclear blast. The project was rejected by Canadian representatives, but one of the businessmen told Tretyakov that he keeps his own nuclear bomb at his dacha outside Moscow. Tretyakov thought that man was insane, but the "businessmen" (Vladimir K. Dmitriev) replied: "Do not be so naive. With economic conditions the way they are in Russia today, anyone with enough money can buy a nuclear bomb. It's no big deal really".

In 1991, South Africa acceded to the NPT, concluded a comprehensive safeguards agreement with the IAEA, and submitted a report on its nuclear material subject to safeguards. At the time, the state had a nuclear power programme producing nearly 10% of the country's electricity, whereas Iraq and North Korea only had research reactors.

The IAEA's initial verification task was complicated by South Africa's announcement that between 1979 and 1989 it built and then dismantled a number of nuclear weapons. South Africa asked the IAEA to verify the conclusion of its weapons programme. In 1995 the IAEA declared that it was satisfied all materials were accounted for and the weapons programme had been terminated and dismantled.

South Africa has signed the NPT, and now holds the distinction of being the only known state to have indigenously produced nuclear weapons, and then verifiably dismantled them.

On 6 September 2007, Israel bombed an officially unidentified site in Syria which it later asserted was a nuclear reactor under construction ("see Operation Outside the Box"). The alleged reactor was not asserted to be operational and it was not asserted that nuclear material had been introduced into it. Syria said the site was a military site and was not involved in any nuclear activities. The IAEA requested Syria to provide further access to the site and any other locations where the debris and equipment from the building had been stored. Syria denounced what it called the Western "fabrication and forging of facts" in regards to the incident. IAEA Director General Mohamed ElBaradei criticized the strikes and deplored that information regarding the matter had not been shared with his agency earlier.

For a state that does not possess nuclear weapons, the capability to produce one or more weapons quickly and with little warning is called a breakout capability.


There has been much debate in the academic study of international ecurity as to the advisability of proliferation. In the late 1950s and early 1960s, Gen. Pierre Marie Gallois of France, an adviser to Charles DeGaulle, argued in books like "The Balance of Terror: Strategy for the Nuclear Age" (1961) that mere possession of a nuclear arsenal, what the French called the "Force de frappe", was enough to ensure deterrence, and thus concluded that the spread of nuclear weapons could increase international stability.

Some very prominent neo-realist scholars, such as Kenneth Waltz, Emeritus Professor of Political Science at the University of California, Berkeley and Adjunct Senior Research Scholar at Columbia University, and John Mearsheimer, R. Wendell Harrison Distinguished Service Professor of Political Science at the University of Chicago, continue to argue along the lines of Gallois in a separate development. Specifically, these scholars advocate some forms of nuclear proliferation, arguing that it will decrease the likelihood of war, especially in troubled regions of the world. Aside from the majority opinion which opposes proliferation in any form, there are two schools of thought on the matter: those, like Mearsheimer, who favor selective proliferation, and those such as Waltz, who advocate a laissez-faire attitude to programs like North Korea's.

In embryo, Waltz argues that the logic of mutually assured destruction (MAD) should work in all security environments, regardless of historical tensions or recent hostility. He sees the Cold War as the ultimate proof of MAD logic—the only occasion when enmity between two Great Powers did not result in military conflict. This was, he argues, because nuclear weapons promote caution in decision-makers. Neither Washington nor Moscow would risk a nuclear apocalypse to advance territorial or power goals, hence a peaceful stalemate ensued (Waltz and Sagan (2003), p. 24). Waltz believes there to be no reason why this effect would not occur in all circumstances.

John Mearsheimer would not support Waltz's optimism in the majority of potential instances; however, he has argued for nuclear proliferation as policy in certain places, such as post–Cold War Europe. In two famous articles, Mearsheimer opines that Europe is bound to return to its pre–Cold War environment of regular conflagration and suspicion at some point in the future. He advocates arming both Germany and Ukraine with nuclear weaponry in order to achieve a balance of power between these states in the east and France/UK in the west. If this does not occur, he is certain that war will eventually break out on the European continent.

Another separate argument against Waltz's open proliferation and in favor of Mearsheimer's selective distribution is the possibility of nuclear terrorism. Some countries included in the aforementioned laissez-faire distribution could predispose the transfer of nuclear materials or a bomb falling into the hands of groups not affiliated with any governments. Such countries would not have the political will or ability to safeguard attempts at devices being transferred to a third party. Not being deterred by self-annihilation, terrorism groups could push forth their own nuclear agendas or be used as shadow fronts to carry out the attack plans by mentioned unstable governments.

There are numerous arguments presented against both selective and total proliferation, generally targeting the very neorealist assumptions (such as the primacy of military security in state agendas, the weakness of international institutions, and the long-run unimportance of economic integration and globalization to state strategy) its proponents tend to make. With respect to Mearsheimer's specific example of Europe, many economists and neoliberals argue that the economic integration of Europe through the development of the European Union has made war in most of the European continent so disastrous economically so as to serve as an effective deterrent. Constructivists take this one step further, frequently arguing that the development of EU political institutions has led or will lead to the development of a nascent European identity, which most states on the European continent wish to partake in to some degree or another, and which makes all states within or aspiring to be within the EU regard war between them as unthinkable.

As for Waltz, the general opinion is that most states are not in a position to safely guard against nuclear use, that he underestimates the long-standing antipathy in many regions, and that weak states will be unable to prevent—or will actively provide for—the disastrous possibility of nuclear terrorism. Waltz has dealt with all of these objections at some point in his work; though to many, he has not adequately responded (Betts (2000)).

The Learning Channel documentary Doomsday: "On The Brink" illustrated 40 years of U.S. and Soviet nuclear weapons accidents. Even the 1995 Norwegian rocket incident demonstrated a potential scenario in which Russian democratization and military downsizing at the end of the Cold War did not eliminate the danger of accidental nuclear war through command and control errors. After asking: might a future Russian ruler or renegade Russian general be tempted to use nuclear weapons to make foreign policy? The documentary writers revealed a greater danger of Russian security over its nuclear stocks, but especially the ultimate danger of human nature to want the ultimate weapon of mass destruction to exercise political and military power. Future world leaders might not understand how close the Soviets, Russians, and Americans were to doomsday, how easy it all seemed because apocalypse was avoided for a mere 40 years between rivals, politicians not terrorists, who loved their children and did not want to die, against 30,000 years of human prehistory. History and military experts agree that proliferation can be slowed, but never stopped (technology cannot be uninvented).

'Proliferation begets proliferation' is a concept described by professor of political science Scott Sagan in his article, "Why Do States Build Nuclear Weapons?". This concept can be described as a strategic chain reaction. If one state produces a nuclear weapon it creates almost a domino effect within the region. States in the region will seek to acquire nuclear weapons to balance or eliminate the security threat. Sagan describes this reaction in his article where he states, “Every time one state develops nuclear weapons to balance against its main rival, it also creates a nuclear threat to another region, which then has to initiate its own nuclear weapons program to maintain its national security”. Going back through history we can see how this has taken place. When the United States demonstrated that it had nuclear power capabilities after the bombing of Hiroshima and Nagasaki, the Russians started to develop their program in preparation for the Cold War. With the Russian military buildup, France and the United Kingdom perceived this as a security threat and therefore they pursued nuclear weapons (Sagan, p. 71). Even though proliferation causes proliferation, this does not guarantee that other states will successfully develop nuclear weapons because the economic stability of a state plays an important role on whether the state will successfully be able to acquire nuclear weapons. The article written by Dong-Jong Joo and Erik Gartzke discusses how the economy of a country determines whether they will successfully acquire nuclear weapons.

Former Iranian President Mahmoud Ahmadinejad has been a frequent critic of the concept of "nuclear " as it has been put into practice by several countries, particularly the United States. In an interview with CNN's Christiane Amanpour, Ahmadinejad said that Iran was "against 'nuclear apartheid,' which means some have the right to possess it, use the fuel, and then sell it to another country for 10 times its value. We're against that. We say clean energy is the right of all countries. But also it is the duty and the responsibility of all countries, including ours, to set up frameworks to stop the proliferation of it." Hours after that interview, he spoke passionately in favor of Iran's right to develop nuclear technology, claiming the nation should have the same liberties.

Iran is a signatory of the Nuclear Non-Proliferation Treaty and claims that any work done in regards to nuclear technology is related only to civilian uses, which is acceptable under the treaty. Iran violated its safeguards obligations under the treaty by performing uranium-enrichment in secret, after which the United Nations Security Council ordered Iran to suspend all uranium-enrichment until July 2015.

India has also been discussed in the context of "nuclear apartheid". India has consistently attempted to pass measures that would call for full international disarmament, however they have not succeeded due to protests from those states that already have nuclear weapons. In light of this, India viewed nuclear weapons as a necessary right for all nations as long as certain states were still in possession of nuclear weapons. India stated that nuclear issues were directly related to national security.

Years before India's first underground nuclear test in 1998, the Comprehensive Nuclear-Test-Ban Treaty was passed. Some have argued that coercive language was used in an attempt to persuade India to sign the treaty, which was pushed for heavily by neighboring China. India viewed the treaty as a means for countries that already had nuclear weapons, primarily the five nations of the United Nations Security Council, to keep their weapons while ensuring that no other nations could develop them.

In their article, "The Correlates of Nuclear Proliferation," Sonali Singh and Christopher R. Way argue that states protected by a security guarantee from a great power, particularly if backed by the "nuclear umbrella" of extended deterrence, have less of an incentive to acquire their own nuclear weapons. States that lack such guarantees are more likely to feel their security threatened and so have greater incentives to bolster or assemble nuclear arsenals. As a result, it is then argued that bipolarity may prevent proliferation where as multipolarity may actually influence proliferation.




</doc>
<doc id="22159" url="https://en.wikipedia.org/wiki?curid=22159" title="NPT">
NPT

NPT may refer to:








</doc>
<doc id="22161" url="https://en.wikipedia.org/wiki?curid=22161" title="Nuclear energy">
Nuclear energy

Nuclear energy may refer to:


</doc>
<doc id="22164" url="https://en.wikipedia.org/wiki?curid=22164" title="Netlist">
Netlist

In electronic design, a netlist is a description of the connectivity of an electronic circuit. In its simplest form, a netlist consists of a list of the electronic components in a circuit and a list of the nodes they are connected to. A network (net) is a collection of two or more interconnected components.

The structure, complexity and representation of netlists can vary considerably, but the fundamental purpose of every netlist is to convey connectivity information. Netlists usually provide nothing more than instances, nodes, and perhaps some attributes of the components involved. If they express much more than this, they are usually considered to be a hardware description language such as Verilog or VHDL, or one of several languages specifically designed for input to simulators.

Netlists can be "physical" or "logical", "instance-based" or "net-based", and "flat" or "hierarchical". The latter can be either "folded" or "unfolded".

Most netlists either contain or refer to descriptions of the parts or devices used. Each time a part is used in a netlist, this is called an "instance".

These descriptions will usually list the connections that are made to that kind of device, and some basic properties of that device. These connection points are called "terminals" or "pins", among several other names.

An "instance" could be anything from a MOSFET transistor or a bipolar junction transistor, to a resistor, a capacitor, or an integrated circuit chip.

Instances have "terminals". In the case of a vacuum cleaner, these terminals would be the three metal prongs in the plug. Each terminal has a name, and in continuing the vacuum cleaner example, they might be "Neutral", "Live" and "Ground". Usually, each instance will have a unique name, so that if you have two instances of vacuum cleaners, one might be "vac1" and the other "vac2". Besides their names, they might otherwise be identical.

Networks (nets) are the "wires" that connect things together in the circuit. There may or may not be any special attributes associated with the nets in a design, depending on the particular language the netlist is written in, and that language's features.

Instance based netlists usually provide a list of the instances used in a design.
Along with each instance, either an ordered list of net names is provided, or a list of pairs provided, of an instance port name, along with the net name to which that port is connected. In this kind of description, the list of nets can be gathered from the connection lists, and there is no place to associate particular attributes with the nets themselves. SPICE is an example of instance-based netlists.

Net-based netlists usually describe all the instances and their attributes, then describe each net, and say which port they are connected on each instance. This allows for attributes to be associated with nets.
EDIF is probably the most famous of the net-based netlists.

In large designs, it is a common practice to split the design into pieces, each piece becoming a "definition" which can be used as instances in the design. In the vacuum cleaner analogy, one might have a vacuum cleaner definition with its ports, but now this definition would also include a full description of the machine's internal components and how they connect (motors, switches, etc.), like a wiring diagram does.

A definition which includes no instances is called a "primitive" (or a "leaf", or other names); whereas a definition which includes instances is "hierarchical".

A "folded" hierarchy allows a single definition to be represented several times by instances. An "unfolded" hierarchy does not allow a definition to be used more than once in the hierarchy.

Folded hierarchies can be extremely compact. A small netlist of just a few instances can describe designs with a very large number of instances. For example, suppose definition A is a simple primitive, like a memory cell. Then suppose definition B contains 32 instances of A; C contains 32 instances of B; D contains 32 instances of C; and E contains 32 instances of D. The design now contains 5 definitions (A through E) and 128 instances. Yet, E describes a circuit that contains over a million memory cells.

In a "flat" design, only primitives are instanced. Hierarchical designs can be recursively "exploded" ("flattened") by creating a new copy (with a new name) of each definition each time it is used. If the design is highly folded, expanding it like this will result in a much larger netlist database, but preserves the hierarchy dependencies. Given a hierarchical netlist, the list of instance names in a path from the root definition to a primitive instance specifies the single unique path to that primitive. The paths to every primitive, taken together, comprise a large but flat netlist that is exactly equivalent to the compact hierarchical version.

Backannotation is data that could be added to a hierarchical netlist. Usually they are kept separate from the netlist, because several such alternate sets of data could be applied to a single netlist. These data may have been extracted from a physical design, and might provide extra information for more accurate simulations. Usually the data are composed of a hierarchical path and a piece of data for that primitive or finding the values of RC delay due to interconnection.

Another concept often used in netlists is that of inheritance. Suppose a definition of a capacitor has an associated attribute called "Capacitance", corresponding to the physical property of the same name, with a default value of "100 pF" (100 picofarads). Each instance of this capacitor might also have such an attribute, only with a different value of capacitance. And other instances might not associate any capacitance at all. In the case where no capacitance is specified for an instance, the instance will "inherit" the 100 pF value from its definition. A value specified will "override" the value on the definition. If a great number of attributes end up being the same as on the definition, a great amount of information can be "inherited", and not have to be redundantly specified in the netlist, saving space, and making the design easier to read by both machines and people.


</doc>
<doc id="22165" url="https://en.wikipedia.org/wiki?curid=22165" title="Nuclear disarmament">
Nuclear disarmament

Nuclear disarmament is the act of reducing or eliminating nuclear weapons. It can also be the end state of a nuclear-weapons-free world, in which nuclear weapons are completely eliminated. The term denuclearization is also used to describe the process leading to complete nuclear disarmament.

Nuclear disarmament groups include the Campaign for Nuclear Disarmament, Peace Action, Pugwash Conferences on Science and World Affairs, Greenpeace, Soka Gakkai International, International Physicians for the Prevention of Nuclear War, Mayors for Peace, Global Zero, the International Campaign to Abolish Nuclear Weapons, and the Nuclear Age Peace Foundation. There have been many large anti-nuclear demonstrations and protests. On June 12, 1982, one million people demonstrated in New York City's Central Park against nuclear weapons and for an end to the cold war arms race. It was the largest anti-nuclear protest and the largest political demonstration in American history.

In recent years, some U.S. elder statesmen have also advocated nuclear disarmament. Sam Nunn, William Perry, Henry Kissinger, and George Shultz have called upon governments to embrace the vision of a world free of nuclear weapons, and in various op-ed columns have proposed an ambitious program of urgent steps to that end. The four have created the Nuclear Security Project to advance this agenda. Organisations such as Global Zero, an international non-partisan group of 300 world leaders dedicated to achieving nuclear disarmament, have also been established.

Proponents of nuclear disarmament say that it would lessen the probability of nuclear war occurring, especially accidentally. Critics of nuclear disarmament say that it would undermine deterrence.

In 1945 in the New Mexico desert, American scientists conducted "Trinity," the first nuclear weapons test, marking the beginning of the atomic age. Even before the Trinity test, national leaders debated the impact of nuclear weapons on domestic and foreign policy. Also involved in the debate about nuclear weapons policy was the scientific community, through professional associations such as the Federation of Atomic Scientists and the Pugwash Conference on Science and World Affairs.

On August 6, 1945, towards the end of World War II, the "Little Boy" device was detonated over the Japanese city of Hiroshima. Exploding with a yield equivalent to 12,500 tonnes of TNT, the blast and thermal wave of the bomb destroyed nearly 50,000 buildings (including the headquarters of the 2nd General Army and Fifth Division) and killed 70,000–80,000 people outright, with total deaths being around 90,000–146,000. Detonation of the "Fat Man" device exploded over the Japanese city of Nagasaki three days later on 9 August 1945, destroying 60% of the city and killing 35,000–40,000 people outright, though up to 40,000 additional deaths may have occurred over some time after that. Subsequently, the world’s nuclear weapons stockpiles grew.

Operation Crossroads was a series of nuclear weapon tests conducted by the United States at Bikini Atoll in the Pacific Ocean in the summer of 1946. Its purpose was to test the effect of nuclear weapons on naval ships. Pressure to cancel Operation Crossroads came from scientists and diplomats. Manhattan Project scientists argued that further nuclear testing was unnecessary and environmentally dangerous. A Los Alamos study warned "the water near a recent surface explosion will be a 'witch's brew' of radioactivity". To prepare the atoll for the nuclear tests, Bikini's native residents were evicted from their homes and resettled on smaller, uninhabited islands where they were unable to sustain themselves.

Radioactive fallout from nuclear weapons testing was first drawn to public attention in 1954 when a hydrogen bomb test in the Pacific contaminated the crew of the Japanese fishing boat "Lucky Dragon". One of the fishermen died in Japan seven months later. The incident caused widespread concern around the world and "provided a decisive impetus for the emergence of the anti-nuclear weapons movement in many countries". The anti-nuclear weapons movement grew rapidly because for many people the atomic bomb "encapsulated the very worst direction in which society was moving".

Peace movements emerged in Japan and in 1954 they converged to form a unified "Japanese Council Against Atomic and Hydrogen Bombs". Japanese opposition to the Pacific nuclear weapons tests was widespread, and "an estimated 35 million signatures were collected on petitions calling for bans on nuclear weapons". In the United Kingdom, the first Aldermaston March organised by the Direct Action Committee and supported by the Campaign for Nuclear Disarmament took place on Easter 1958, when several thousand people marched for four days from Trafalgar Square, London, to the Atomic Weapons Research Establishment close to Aldermaston in Berkshire, England, to demonstrate their opposition to nuclear weapons. CND organised Aldermaston marches into the late 1960s when tens of thousands of people took part in the four-day events.

On November 1, 1961, at the height of the Cold War, about 50,000 women brought together by Women Strike for Peace marched in 60 cities in the United States to demonstrate against nuclear weapons. It was the largest national women's peace protest of the 20th century.

In 1958, Linus Pauling and his wife presented the United Nations with the petition signed by more than 11,000 scientists calling for an end to nuclear-weapon testing. The "Baby Tooth Survey," headed by Dr Louise Reiss, demonstrated conclusively in 1961 that above-ground nuclear testing posed significant public health risks in the form of radioactive fallout spread primarily via milk from cows that had ingested contaminated grass. Public pressure and the research results subsequently led to a moratorium on above-ground nuclear weapons testing, followed by the Partial Test Ban Treaty, signed in 1963 by John F. Kennedy and Nikita Khrushchev. On the day that the treaty went into force, the Nobel Prize Committee awarded Pauling the Nobel Peace Prize, describing him as "Linus Carl Pauling, who ever since 1946 has campaigned ceaselessly, not only against nuclear weapons tests, not only against the spread of these armaments, not only against their very use, but against all warfare as a means of solving international conflicts." Pauling started the International League of Humanists in 1974. He was president of the scientific advisory board of the World Union for Protection of Life and also one of the signatories of the Dubrovnik-Philadelphia Statement.

In the 1980s, a movement for nuclear disarmament again gained strength in the light of the weapons build-up and statements of US President Ronald Reagan. Reagan had "a world free of nuclear weapons" as his personal mission, and was largely scorned for this in Europe. Reagan was able to start discussions on nuclear disarmament with Soviet Union. He changed the name "SALT" (Strategic Arms Limitation Talks) to "START" (Strategic Arms Reduction Talks).

On June 3, 1981, William Thomas launched the White House Peace Vigil in Washington, D.C.. He was later joined on the vigil by anti-nuclear activists Concepcion Picciotto and Ellen Benjamin.

On June 12, 1982, one million people demonstrated in New York City's Central Park against nuclear weapons and for an end to the cold war arms race. It was the largest anti-nuclear protest and the largest political demonstration in American history. International Day of Nuclear Disarmament protests were held on June 20, 1983 at 50 sites across the United States. In 1986, hundreds of people walked from Los Angeles to Washington, D.C. in the Great Peace March for Global Nuclear Disarmament. There were many Nevada Desert Experience protests and peace camps at the Nevada Test Site during the 1980s and 1990s.

On May 1, 2005, 40,000 anti-nuclear/anti-war protesters marched past the United Nations in New York, 60 years after the atomic bombings of Hiroshima and Nagasaki. In 2008, 2009, and 2010, there have been protests about, and campaigns against, several new nuclear reactor proposals in the United States.

There is an annual protest against U.S. nuclear weapons research at Lawrence Livermore National Laboratory in California and in the 2007 protest, 64 people were arrested. There have been a series of protests at the Nevada Test Site and in the April 2007 Nevada Desert Experience protest, 39 people were cited by police. There have been anti-nuclear protests at Naval Base Kitsap for many years, and several in 2008.

In 2017, the International Campaign to Abolish Nuclear Weapons was awarded the Nobel Peace Prize "for its work to draw attention to the catastrophic humanitarian consequences of any use of nuclear weapons and for its ground-breaking efforts to achieve a treaty-based prohibition of such weapons".

One of the earliest peace organisations to emerge after the Second World War was the World Peace Council, which was directed by the Communist Party of the Soviet Union through the Soviet Peace Committee. Its origins lay in the Communist Information Bureau's (Cominform) doctrine, put forward 1947, that the world was divided between peace-loving progressive forces led by the Soviet Union and warmongering capitalist countries led by the United States. In 1949, Cominform directed that peace "should now become the pivot of the entire activity of the Communist Parties", and most western Communist parties followed this policy. Lawrence Wittner, a historian of the post-war peace movement, argues that the Soviet Union devoted great efforts to the promotion of the WPC in the early post-war years because it feared an American attack and American superiority of arms at a time when the USA possessed the atom bomb but the Soviet Union had not yet developed it.

In 1950, the WPC launched its Stockholm Appeal calling for the absolute prohibition of nuclear weapons. The campaign won support, collecting, it is said, 560 million signatures in Europe, most from socialist countries, including 10 million in France (including that of the young Jacques Chirac), and 155 million signatures in the Soviet Union – the entire adult population. Several non-aligned peace groups who had distanced themselves from the WPC advised their supporters not to sign the Appeal.

The WPC had uneasy relations with the non-aligned peace movement and has been described as being caught in contradictions as "it sought to become a broad world movement while being instrumentalized increasingly to serve foreign policy in the Soviet Union and nominally socialist countries." From the 1950s until the late 1980s it tried to use non-aligned peace organizations to spread the Soviet point of view. At first there was limited co-operation between such groups and the WPC, but western delegates who tried to criticize the Soviet Union or the WPC's silence about Russian armaments were often shouted down at WPC conferences and by the early 1960s they had dissociated themselves from the WPC.

After the 1986 Reykjavik Summit between U.S. President Ronald Reagan and the new Soviet General Secretary Mikhail Gorbachev, the United States and the Soviet Union concluded two important nuclear arms reduction treaties: the INF Treaty (1987) and START I (1991). After the end of the Cold War, the United States and the Russian Federation concluded the Strategic Offensive Reductions Treaty (2003) and the New START Treaty (2010).

When the extreme danger intrinsic to nuclear war and the possession of nuclear weapons became apparent to all sides during the Cold War, a series of disarmament and nonproliferation treaties were agreed upon between the United States, the Soviet Union, and several other states throughout the world. Many of these treaties involved years of negotiations, and seemed to result in important steps in arms reductions and reducing the risk of nuclear war.

Only one country (South Africa) has been known to ever dismantle an indigenously-developed nuclear arsenal completely. The apartheid government of South Africa produced half a dozen crude fission weapons during the 1980s, but they were dismantled in the early 1990s.

In its landmark resolution 1653 of 1961, "Declaration on the prohibition of the use of nuclear and thermo-nuclear weapons," the UN General Assembly stated that use of nuclear weaponry “would exceed even the scope of war and cause indiscriminate suffering and destruction to mankind and civilization and, as such, is contrary to the rules of international law and to the laws of humanity”.

The UN Office for Disarmament Affairs (UNODA) is a department of the United Nations Secretariat established in January 1998 as part of the United Nations Secretary-General Kofi Annan's plan to reform the UN as presented in his report to the General Assembly in July 1997.

Its goal is to promote nuclear disarmament and non-proliferation and the strengthening of the disarmament regimes in respect to other weapons of mass destruction, chemical and biological weapons. It also promotes disarmament efforts in the area of conventional weapons, especially land mines and small arms, which are often the weapons of choice in contemporary conflicts.

Following the retirement of Sergio Duarte in February 2012, Angela Kane was appointed as the new High Representative for Disarmament Affairs.

On 7 July 2017, a UN conference adopted the Treaty on the Prohibition of Nuclear Weapons with the backing of 122 states. It opened for signature on 20 September 2017.

Despite a general trend toward disarmament in the early 2000s, the George W. Bush administration repeatedly pushed to fund policies that would allegedly make nuclear weapons more usable in the post–Cold War environment. To date the U.S. Congress has refused to fund many of these policies. However, some feel that even considering such programs harms the credibility of the United States as a proponent of nonproliferation.


Former U.S. officials Henry Kissinger, George Shultz, Bill Perry, and Sam Nunn (aka 'The Gang of Four' on nuclear deterrence) proposed in January 2007 that the United States rededicate itself to the goal of eliminating nuclear weapons, concluding: "We endorse setting the goal of a world free of nuclear weapons and working energetically on the actions required to achieve that goal." Arguing a year later that "with nuclear weapons more widely available, deterrence is decreasingly effective and increasingly hazardous," the authors concluded that although "it is tempting and easy to say we can't get there from here, [...] we must chart a course toward that goal." During his presidential campaign, U.S. President-Elect Barack Obama pledged to "set a goal of a world without nuclear weapons, and pursue it."

The United States has taken the lead in ensuring that nuclear materials globally are properly safeguarded. A popular program that has received bipartisan domestic support for over a decade is the Cooperative Threat Reduction Program (CTR). While this program has been deemed a success, many believe that its funding levels need to be increased so as to ensure that all dangerous nuclear materials are secured in the most expeditious manner possible. The CTR program has led to several other innovative and important nonproliferation programs that need to continue to be a budget priority in order to ensure that nuclear weapons do not spread to actors hostile to the United States.

Key programs:

While the vast majority of states have adhered to the stipulations of the Nuclear Nonproliferation Treaty, a few states have either refused to sign the treaty or have pursued nuclear weapons programs while not being members of the treaty. Many view the pursuit of nuclear weapons by these states as a threat to nonproliferation and world peace.

Eliminating nuclear weapons has long been an aim of the pacifist left. But now many mainstream politicians, academic analysts, and retired military leaders also advocate nuclear disarmament. Sam Nunn, William Perry, Henry Kissinger, and George Shultz have called upon governments to embrace the vision of a world free of nuclear weapons, and in three "Wall Street Journal" opeds proposed an ambitious program of urgent steps to that end. The four have created the Nuclear Security Project to advance this agenda. Nunn reinforced that agenda during a speech at the Harvard Kennedy School on October 21, 2008, saying, "I’m much more concerned about a terrorist without a return address that cannot be deterred than I am about deliberate war between nuclear powers. You can’t deter a group who is willing to commit suicide. We are in a different era. You have to understand the world has changed." In 2010, the four were featured in a documentary film entitled "Nuclear Tipping Point". The film is a visual and historical depiction of the ideas laid forth in the Wall Street Journal op-eds and reinforces their commitment to a world without nuclear weapons and the steps that can be taken to reach that goal.

Global Zero is an international non-partisan group of 300 world leaders dedicated to achieving nuclear disarmament. The initiative, launched in December 2008, promotes a phased withdrawal and verification for the destruction of all devices held by official and unofficial members of the nuclear club. The Global Zero campaign works toward building an international consensus and a sustained global movement of leaders and citizens for the elimination of nuclear weapons. Goals include the initiation of United States-Russia bilateral negotiations for reductions to 1,000 total warheads each and commitments from the other key nuclear weapons countries to participate in multilateral negotiations for phased reductions of nuclear arsenals. Global Zero works to expand the diplomatic dialogue with key governments and continue to develop policy proposals on the critical issues related to the elimination of nuclear weapons.

The International Conference on Nuclear Disarmament took place in Oslo in February, 2008, and was organized by The Government of Norway, the Nuclear Threat Initiative and the Hoover Institute. The Conference was entitled "Achieving the Vision of a World Free of Nuclear Weapons" and had the purpose of building consensus between nuclear weapon states and non-nuclear weapon states in relation to the Nuclear Non-proliferation Treaty.
The Tehran International Conference on Disarmament and Non-Proliferation took place in Tehran in April 2010. The conference was held shortly after the signing of the New START, and resulted in a call of action toward eliminating all nuclear weapons. Representatives from 60 countries were invited to the conference. Non-governmental organizations were also present.

Among the prominent figures who have called for the abolition of nuclear weapons are "the philosopher Bertrand Russell, the entertainer Steve Allen, CNN’s Ted Turner, former Senator Claiborne Pell, Notre Dame president Theodore Hesburgh, South African Bishop Desmond Tutu and the Dalai Lama".

Others have argued that nuclear weapons have made the world relatively safer, with peace through deterrence and through the stability–instability paradox, including in south Asia. Kenneth Waltz has argued that nuclear weapons have created a nuclear peace, and further nuclear weapon proliferation might even help avoid the large scale conventional wars that were so common prior to their invention at the end of World War II. In the July 2012 issue of Foreign Affairs Waltz took issue with the view of most U.S., European, and Israeli, commentators and policymakers that a nuclear-armed Iran would be unacceptable. Instead Waltz argues that it would probably be the best possible outcome, as it would restore stability to the Middle East by balancing Israel's regional monopoly on nuclear weapons. Professor John Mueller of Ohio State University, the author of "Atomic Obsession", has also dismissed the need to interfere with Iran's nuclear program and expressed that arms control measures are counterproductive. During a 2010 lecture at the University of Missouri, which was broadcast by C-SPAN, Dr. Mueller has also argued that the threat from nuclear weapons, especially nuclear terrorism, has been exaggerated, both in the popular media and by officials.
Former Secretary Kissinger says there is a new danger, which cannot be addressed by deterrence: "The classical notion of deterrence was that there was some consequences before which aggressors and evildoers would recoil. In a world of suicide bombers, that calculation doesn’t operate in any comparable way". George Shultz has said, "If you think of the people who are doing suicide attacks, and people like that get a nuclear weapon, they are almost by definition not deterrable".

Andrew Bacevich wrote that there is no feasible scenario under which the US could sensibly use nuclear weapons. "For the United States, they are becoming unnecessary, even as a deterrent. Certainly, they are unlikely to dissuade the adversaries most likely to employ such weapons against us -- Islamic extremists intent on acquiring their own nuclear capability. If anything, the opposite is true. By retaining a strategic arsenal in readiness (and by insisting without qualification that the dropping of atomic bombs on two Japanese cities in 1945 was justified), the United States continues tacitly to sustain the view that nuclear weapons play a legitimate role in international politics ... ."

In "The Limits of Safety", Scott Sagan documented numerous incidents in US military history that could have produced a nuclear war by accident. He concluded, "while the military organizations controlling U.S. nuclear forces during the Cold War performed this task with less success than we know, they performed with more success than we "should" have reasonably predicted. The problems identified in this book were not the product of incompetent organizations. They reflect the inherent limits of organizational safety. Recognizing that simple truth is the first and most important step toward a safer future."



</doc>
<doc id="22170" url="https://en.wikipedia.org/wiki?curid=22170" title="Net (mathematics)">
Net (mathematics)

In mathematics, more specifically in general topology and related branches, a net or Moore–Smith sequence is a generalization of the notion of a sequence. In essence, a sequence is a function with domain the natural numbers, and in the context of topology, the codomain of this function is usually any topological space. However, in the context of topology, sequences do not fully encode all information about a function between topological spaces. In particular, the following two conditions are not equivalent in general for a map "f" between topological spaces "X" and "Y":


It is true, however, that condition 1 implies condition 2. The difficulty encountered when attempting to prove that condition 2 implies condition 1 lies in the fact that topological spaces are, in general, not first-countable.
If the first-countability axiom were imposed on the topological spaces in question, the two above conditions would be equivalent. In particular, the two conditions are equivalent for metric spaces.

The purpose of the concept of a net, first introduced by E. H. Moore and Herman L. Smith in 1922, is to generalize the notion of a sequence so as to confirm the equivalence of the conditions (with "sequence" being replaced by "net" in condition 2). In particular, rather than being defined on a countable linearly ordered set, a net is defined on an arbitrary directed set. In particular, this allows theorems similar to that asserting the equivalence of condition 1 and condition 2, to hold in the context of topological spaces that do not necessarily have a countable or linearly ordered neighbourhood basis around a point. Therefore, while sequences do not encode sufficient information about functions between topological spaces, nets do, because collections of open sets in topological spaces are much like directed sets in behaviour. The term "net" was coined by John L. Kelley.

Nets are one of the many tools used in topology to generalize certain concepts that may only be general enough in the context of metric spaces. A related notion, that of the filter, was developed in 1937 by Henri Cartan.

Let A be a directed set with preorder relation "≥" and "X" be a topological space with topology "T". A function "f: A → X" is said to be a "net".

If "A" is a directed set, we often write a net from "A" to "X" in the form ("x"), which expresses the fact that the element α in "A" is mapped to the element "x" in "X".

A subnet is not merely the restriction of a net "f" to a directed subset of "A"; see the linked page for a definition.

Every non-empty totally ordered set is directed. Therefore, every function on such a set is a net. In particular, the natural numbers with the usual order form such a set, and a sequence is a function on the natural numbers, so every sequence is a net.

Another important example is as follows. Given a point "x" in a topological space, let "N" denote the set of all neighbourhoods containing "x". Then "N" is a directed set, where the direction is given by reverse inclusion, so that "S" ≥ "T" if and only if "S" is contained in "T". For "S" in "N", let "x" be a point in "S". Then ("x") is a net. As "S" increases with respect to ≥, the points "x" in the net are constrained to lie in decreasing neighbourhoods of "x", so intuitively speaking, we are led to the idea that "x" must tend towards "x" in some sense. We can make this limiting concept precise.

If ("x") is a net from a directed set "A" into "X", and if "Y" is a subset of "X", then we say that ("x") is eventually in "Y (or residually in "Y) if there exists an α in "A" so that for every β in "A" with β ≥ α, the point "x" lies in "Y".

If ("x") is a net in the topological space "X", and "x" is an element of "X", we say that the net converges towards "x or has limit "x and write
if and only if
Intuitively, this means that the values "x" come and stay as close as we want to "x" for large enough α.

The example net given above on the neighborhood system of a point "x" does indeed converge to "x" according to this definition.

Given a base for the topology, in order to prove convergence of a net it is necessary and sufficient to prove that there exists some point "x", such that ("x") is eventually in all members of the base containing this putative limit.


Let φ be a net on "X" based on the directed set "D" and let "A" be a subset of "X", then φ is said to be frequently in (or cofinally in) "A" if for every α in "D" there exists some β ≥ α, β in "D", so that φ(β) is in "A".

A point "x" in "X" is said to be an accumulation point or cluster point of a net if (and only if) for every neighborhood "U" of "x", the net is frequently in "U".

A net φ on set "X" is called universal, or an ultranet if for every subset "A" of "X", either φ is eventually in "A" or φ is eventually in "X" − "A".

Sequence in a topological space:

A sequence ("a", "a", ...) in a topological space "V" can be considered a net in "V" defined on N.

The net is eventually in a subset "Y" of "V" if there exists an N in N such that for every "n" ≥ "N", the point "a" is in "Y".

We have lim "a" = "L" if and only if for every neighborhood "Y" of "L", the net is eventually in "Y".

The net is frequently in a subset "Y" of "V" if and only if for every "N" in N there exists some "n" ≥ "N" such that "a" is in "Y", that is, if and only if infinitely many elements of the sequence are in "Y". Thus a point "y" in "V" is a cluster point of the net if and only if every neighborhood "Y" of "y" contains infinitely many elements of the sequence.

Function from a metric space to a topological space:

Consider a function from a metric space "M" to a topological space "V", and a point "c" of "M". We direct the set "M"\{"c"} reversely according to distance from "c", that is, the relation is "has at least the same distance to "c" as", so that "large enough" with respect to the relation means "close enough to "c"". The function "f" is a net in "V" defined on "M"\{"c"}.

The net "f" is eventually in a subset "Y" of "V" if there exists an "a" in "M" \ {"c"} such that for every "x" in "M" \ {"c"} with d("x","c") ≤ d("a","c"), the point f("x") is in "Y".

We have lim "f"("x") = "L" if and only if for every neighborhood "Y" of "L", "f" is eventually in "Y".

The net "f" is frequently in a subset "Y" of "V" if and only if for every "a" in "M" \ {"c"} there exists some "x" in "M" \ {"c"} with "d"("x","c") ≤ d("a","c") such that "f(x)" is in "Y".

A point "y" in "V" is a cluster point of the net "f" if and only if for every neighborhood "Y" of "y", the net is frequently in "Y".

Function from a well-ordered set to a topological space:

Consider a well-ordered set [0, "c"] with limit point "c", and a function "f" from [0, "c") to a topological space "V". This function is a net on [0, "c").

It is eventually in a subset "Y" of "V" if there exists an "a" in [0, "c") such that for every "x" ≥ "a", the point "f"("x") is in "Y".

We have lim "f"("x") = "L" if and only if for every neighborhood "Y" of "L", "f" is eventually in "Y".

The net "f" is frequently in a subset "Y" of "V" if and only if for every "a" in [0, "c") there exists some "x" in ["a", "c") such that "f"("x") is in "Y".

A point "y" in "V" is a cluster point of the net "f" if and only if for every neighborhood "Y" of "y", the net is frequently in "Y".

The first example is a special case of this with "c" = ω.

See also ordinal-indexed sequence.

Virtually all concepts of topology can be rephrased in the language of nets and limits. This may be useful to guide the intuition since the notion of limit of a net is very similar to that of limit of a sequence. The following set of theorems and lemmas help cement that similarity:




A Cauchy net generalizes the notion of Cauchy sequence to nets defined on uniform spaces.

A net ("x") is a Cauchy net if for every entourage "V" there exists γ such that for all α, β ≥ γ, ("x", "x") is a member of "V". More generally, in a Cauchy space, a net ("x") is Cauchy if the filter generated by the net is a Cauchy filter.

A filter is another idea in topology that allows for a general definition for convergence in general topological spaces. The two ideas are equivalent in the sense that they give the same concept of convergence. More specifically, for every filter base an "associated net" can be constructed, and convergence of the filter base implies convergence of the associated net—and the other way around (for every net there is a filter base, and convergence of the net implies convergence of the filter base). For instance, any net formula_2 in formula_3 induces a filter base of tails formula_4 where the filter in formula_3 generated by this filter base is called the net's "eventuality filter." This correspondence allows for any theorem that can be proven with one concept to be proven with the other. For instance, continuity of a function from one topological space to the other can be characterized either by the convergence of a net in the domain implying the convergence of the corresponding net in the codomain, or by the same statement with filter bases.

Robert G. Bartle argues that despite their equivalence, it is useful to have both concepts. He argues that nets are enough like sequences to make natural proofs and definitions in analogy to sequences, especially ones using sequential elements, such as is common in analysis, while filters are most useful in algebraic topology. In any case, he shows how the two can be used in combination to prove various theorems in general topology.

Limit superior and limit inferior of a net of real numbers can be defined in a similar manner as for sequences. Some authors work even with more general structures than the real line, like complete lattices.

For a net formula_6 we put

Limit superior of a net of real numbers has many properties analogous to the case of sequences, e.g.
where equality holds whenever one of the nets is convergent.



</doc>
<doc id="22171" url="https://en.wikipedia.org/wiki?curid=22171" title="Nuclear winter">
Nuclear winter

Nuclear winter is a severe and prolonged global climatic cooling effect hypothesized to occur after widespread firestorms following a nuclear war. The hypothesis is based on the fact that such fires can inject soot into the stratosphere, where it can block some direct sunlight from reaching the surface of the Earth. It is speculated that the resulting cooling would lead to widespread crop failure and famine. When developing computer models of nuclear-winter scenarios, researchers use the conventional bombing of Hamburg, and the Hiroshima firestorm in World War II as example cases where soot might have been injected into the stratosphere, alongside modern observations of natural, large-area wildfire-firestorms.

"Nuclear winter," or as it was initially termed, "nuclear twilight," began to be considered as a scientific concept in the 1980s, after it became clear that an earlier hypothesis, that fireball generated NOx emissions would devastate the ozone layer, was losing credibility. It was within this context that the climatic effects of soot from fires became the new focus of the climatic effects of nuclear war. In these model scenarios, various soot clouds containing uncertain quantities of soot were assumed to form over cities, oil refineries, and more rural missile silos. Once the quantity of soot is decided upon by the researchers, the climate effects of these soot clouds are then modeled. The term "nuclear winter" was a neologism coined in 1983 by Richard P. Turco in reference to a 1-dimensional computer model created to examine the "nuclear twilight" idea, this 1-D model output the finding that massive quantities of soot and smoke would remain aloft in the air for on the order of years, causing a severe planet-wide drop in temperature. Turco would later distance himself from these extreme 1-D conclusions.

After the failure of the predictions on the effects of the 1991 Kuwait oil fires, that were made by the primary team of climatologists that advocate the hypothesis, over a decade passed without any new published papers on the topic. More recently, the same team of prominent modellers from the 1980s have begun again to publish the outputs of computer models, these newer models produce the same general findings as their old ones, that the ignition of 100 firestorms, each comparable in intensity to that observed in Hiroshima in 1945, could produce a "small" nuclear winter. These firestorms would result in the injection of soot (specifically black carbon) into the Earth's stratosphere, producing an anti-greenhouse effect that would lower the Earth's surface temperature. The severity of this cooling in Alan Robock's model suggests that the cumulative products of 100 of these firestorms could cool the global climate by approximately 1 °C (1.8 °F), largely eliminating the magnitude of anthropogenic global warming for the next roughly two or three years. Robock has not modeled this, but has speculated that it would have global agricultural losses as a consequence.

As nuclear devices need not be detonated to ignite a firestorm, the term "nuclear winter" is something of a misnomer. The majority of papers published on the subject state that without qualitative justification, nuclear explosions are the cause of the modeled firestorm effects. The only phenomenon that is modeled by computer in the nuclear winter papers is the climate forcing agent of firestorm-soot, a product which can be ignited and formed by a myriad of means. Although rarely discussed, the proponents of the hypothesis state that the same "nuclear winter" effect would occur if 100 conventional firestorms were ignited.

A much larger number of firestorms, in the thousands, was the initial assumption of the computer modelers who coined the term in the 1980s. These were speculated to be a possible result of any large scale employment of counter-value airbursting nuclear weapon use during an American-Soviet total war. This larger number of firestorms, which are not in themselves modeled, are presented as causing nuclear winter conditions as a result of the smoke inputted into various climate models, with the depths of severe cooling lasting for as long as a decade. During this period, summer drops in average temperature could be up to 20 °C (36 °F) in core agricultural regions of the US, Europe, and China, and as much as 35 °C (63 °F) in Russia. This cooling would be produced due to a 99% reduction in the natural solar radiation reaching the surface of the planet in the first few years, gradually clearing over the course of several decades.

On the fundamental level, since the advent of photographic evidence of tall clouds were captured, it was known that firestorms could inject soot smoke/aerosols into the stratosphere but the longevity of this slew of aerosols was a major unknown. Independent of the team that continue to publish theoretical models on nuclear winter, in 2006, Mike Fromm of the Naval Research Laboratory, experimentally found that each natural occurrence of a massive wildfire firestorm, much larger than that observed at Hiroshima, can produce minor "nuclear winter" effects, with short-lived, approximately one month of a nearly immeasurable drop in surface temperatures, confined to the hemisphere that they burned in. This is somewhat analogous to the frequent volcanic eruptions that inject sulfates into the stratosphere and thereby produce minor, even negligible, volcanic winter effects.

A suite of satellite and aircraft-based firestorm-soot-monitoring instruments are at the forefront of attempts to accurately determine the lifespan, quantity, injection height, and optical properties of this smoke. Information regarding all of these properties is necessary to truly ascertain the length and severity of the cooling effect of firestorms, independent of the nuclear winter computer model projections.

Presently, from satellite tracking data, stratospheric smoke aerosols dissipate in a time span under approximately two months. The existence of any hint of a tipping point into a new stratospheric condition where the aerosols would not be removed within this time frame remains to be determined.

The nuclear winter scenario assumes that 100 or more city firestorms are ignited by nuclear explosions, and that the firestorms lift large amounts of sooty smoke into the upper troposphere and lower stratosphere by the movement offered by the pyrocumulonimbus clouds that form during a firestorm. At above the Earth's surface, the absorption of sunlight could further heat the soot in the smoke, lifting some or all of it into the stratosphere, where the smoke could persist for years if there is no rain to wash it out. This aerosol of particles could heat the stratosphere and prevent a portion of the sun's light from reaching the surface, causing surface temperatures to drop drastically. In this scenario it is predicted that surface air temperatures would be the same as, or colder than, a given region's winter for months to years on end.

The modeled stable inversion layer of hot soot between the troposphere and high stratosphere that produces the anti-greenhouse effect was dubbed the "Smokeosphere" by Stephen Schneider et al. in their 1988 paper.

Although it is common in the climate models to consider city firestorms, these need not be ignited by nuclear devices; more conventional ignition sources can instead be the spark of the firestorms. Prior to the previously mentioned solar heating effect, the soot's injection height is controlled by the rate of energy release from the firestorm's fuel, not the size of an initial nuclear explosion. For example, the mushroom cloud from the bomb dropped on Hiroshima reached a height of six kilometers (middle troposphere) within a few minutes and then dissipated due to winds, while the individual fires within the city took almost three hours to form into a firestorm and produce a pyrocumulus cloud, a cloud that is assumed to have reached upper tropospheric heights, as over its multiple hours of burning, the firestorm released an estimated 1000 times the energy of the bomb.

As the incendiary effects of a nuclear explosion do not present any especially characteristic features, it is estimated by those with Strategic bombing experience that as the city was a firestorm hazard, the same fire ferocity and building damage produced at Hiroshima by one 16-kiloton nuclear bomb from a single B-29 bomber could have been produced instead by the conventional use of about 1.2 kilotons of incendiary bombs from 220 B-29s distributed over the city.

While the firestorms of Dresden and Hiroshima and the mass fires of Tokyo and Nagasaki occurred within mere months in 1945, the more intense and conventionally lit Hamburg firestorm occurred in 1943. Despite the separation in time, ferocity and area burned, leading modelers of the hypothesis state that these five fires potentially placed five percent as much smoke into the stratosphere as the hypothetical 100 nuclear-ignited fires discussed in modern models. While it is believed that the modeled climate-cooling-effects from the mass of soot injected into the stratosphere by 100 firestorms (one to five teragrams) would have been detectable with technical instruments in WWII, five percent of that would not have been possible to observe at that time.

The exact timescale for how long this smoke remains, and thus how severely this smoke affects the climate once it reaches the stratosphere, is dependent on both chemical and physical removal processes.

The most important physical removal mechanism is "rainout", both during the "fire-driven convective column" phase, which produces "black rain" near the fire site, and rainout after the convective plume's dispersal, where the smoke is no longer concentrated and thus "wet removal" is believed to be very efficient. However, these efficient removal mechanisms in the troposphere are avoided in the Robock 2007 study, where solar heating is modeled to quickly loft the soot into the stratosphere, "detraining" or separating the darker soot particles from the fire clouds' whiter water condensation.

Once in the stratosphere, the physical removal mechanisms affecting the timescale of the soot particles' residence are how quickly the aerosol of soot collides and coagulates with other particles via Brownian motion, and falls out of the atmosphere via gravity-driven dry deposition, and the time it takes for the "phoretic effect" to move coagulated particles to a lower level in the atmosphere. Whether by coagulation or the phoretic effect, once the aerosol of smoke particles are at this lower atmospheric level, cloud seeding can begin, permitting precipitation to wash the smoke aerosol out of the atmosphere by the wet deposition mechanism.

The chemical processes that affect the removal are dependent on the ability of atmospheric chemistry to oxidize the carbonaceous component of the smoke, via reactions with oxidative species such as ozone and nitrogen oxides, both of which are found at all levels of the atmosphere, and which also occur at greater concentrations when air is heated to high temperatures.

Historical data on residence times of aerosols, albeit a different mixture of aerosols, in this case stratospheric sulfur aerosols and volcanic ash from megavolcano eruptions, appear to be in the one-to-two-year time scale, however aerosol–atmosphere interactions are still poorly understood.

Sooty aerosols can have a wide range of properties, as well as complex shapes, making it difficult to determine their evolving atmospheric optical depth value. The conditions present during the creation of the soot are believed to be considerably important as to their final properties, with soot generated on the more efficient spectrum of burning efficiency considered almost "elemental carbon black," while on the more inefficient end of the burning spectrum, greater quantities of partially burnt/oxidized fuel are present. These partially burnt "organics" as they are known, often form tar balls and brown carbon during common lower-intensity wildfires, and can also coat the purer black carbon particles. However, as the soot of greatest importance is that which is injected to the highest altitudes by the pyroconvection of the firestorm – a fire being fed with storm-force winds of air – it is estimated that the majority of the soot under these conditions is the more oxidized black carbon.

A study presented at the annual meeting of the American Geophysical Union in December 2006 found that even a small-scale, regional nuclear war could disrupt the global climate for a decade or more. In a regional nuclear conflict scenario where two opposing nations in the subtropics would each use 50 Hiroshima-sized nuclear weapons (about 15 kiloton each) on major population centers, the researchers estimated as much as five million tons of soot would be released, which would produce a cooling of several degrees over large areas of North America and Eurasia, including most of the grain-growing regions. The cooling would last for years, and, according to the research, could be "catastrophic".

Nuclear detonations produce large amounts of nitrogen oxides by breaking down the air around them. These are then lifted upwards by thermal convection. As they reach the stratosphere, these nitrogen oxides are capable of catalytically breaking down the ozone present in this part of the atmosphere. Ozone depletion would allow a much greater intensity of harmful ultraviolet radiation from the sun to reach the ground.
A 2008 study by Michael J. Mills et al., published in the Proceedings of the National Academy of Sciences, found that a nuclear weapons exchange between Pakistan and India using their current arsenals could create a near-global ozone hole, triggering human health problems and causing environmental damage for at least a decade. The computer-modeled study looked at a nuclear war between the two countries involving 50 Hiroshima-sized nuclear devices on each side, producing massive urban fires and lofting as much as five million metric tons of soot about into the stratosphere. The soot would absorb enough solar radiation to heat surrounding gases, increasing the break down of the stratospheric ozone layer protecting Earth from harmful ultraviolet radiation, with up to 70% ozone loss at northern high latitudes.

A "nuclear summer" is a hypothesized scenario in which, after a nuclear winter caused by aerosols inserted into the atmosphere that would prevent sunlight from reaching lower levels or the surface, has abated, a greenhouse effect then occurs due to carbon dioxide released by combustion and methane released from the decay of the organic matter and methane from dead organic matter and corpses that froze during the nuclear winter.

Another more sequential hypothetical scenario, following the settling out of most of the aerosols in 1–3 years, the cooling effect would be overcome by a heating effect from greenhouse warming, which would raise surface temperatures rapidly by many degrees, enough to cause the death of much if not most of the life that had survived the cooling, much of which is more vulnerable to higher-than-normal temperatures than to lower-than-normal temperatures. The nuclear detonations would release CO and other greenhouse gases from burning, followed by more released from decay of dead organic matter. The detonations would also insert nitrogen oxides into the stratosphere that would then deplete the ozone layer around the Earth. This layer screens out UV-C radiation from the Sun, which causes genetic damage to life forms on the surface. As the temperature rises, the amount of water in the atmosphere would increase, causing further greenhouse warming of the surface, and if it rose enough, it could cause the sublimation of methane clathrate deposits on the sea floor, releasing huge amounts of methane, a greenhouse gas, into the atmosphere, perhaps enough to trigger runaway climate change.

Other more straightforward hypothetical versions exist of the hypothesis that nuclear winter might give way to a nuclear summer. The high temperatures of the nuclear fireballs could destroy the ozone gas of the middle stratosphere.

In 1952, a few weeks prior to the Ivy Mike (10.4 megaton) bomb test on Elugelab Island, there were concerns that the aerosols lifted by the explosion might cool the Earth. Major Norair Lulejian, USAF, and astronomer Natarajan Visvanathan studied this possibility, reporting their findings in "Effects of Superweapons Upon the Climate of the World", whose distribution was tightly controlled. This report is described in a 2013 report by the Defense Threat Reduction Agency as the initial study of the "nuclear winter" concept. It indicated no appreciable chance of explosion-induced climate change.

The implications for civil defense of numerous surface bursts of high yield hydrogen bomb explosions on Pacific Proving Ground islands such as those of Ivy Mike in 1952 and Castle Bravo (15 Mt) in 1954 were described in a 1957 report on "The Effects of Nuclear Weapons", edited by Samuel Glasstone. A section in that book entitled "Nuclear Bombs and the Weather" states: "The dust raised in severe volcanic eruptions, such as that at Krakatoa in 1883, is known to cause a noticeable reduction in the sunlight reaching the earth ... The amount of [soil or other surface] debris remaining in the atmosphere after the explosion of even the largest nuclear weapons is probably not more than about one percent or so of that raised by the Krakatoa eruption. Further, solar radiation records reveal that none of the nuclear explosions to date has resulted in any detectable change in the direct sunlight recorded on the ground." The US Weather Bureau in 1956 regarded it as conceivable that a large enough nuclear war with megaton-range surface detonations could lift enough soil to cause a new ice age.

In the 1966 RAND corporation memorandum "The Effects of Nuclear War on the Weather and Climate" by E. S. Batten, while primarily analysing potential dust effects from surface bursts, it notes that "in addition to the effects of the debris, extensive fires ignited by nuclear detonations might change the surface characteristics of the area and modify local weather patterns ... however, a more thorough knowledge of the atmosphere is necessary to determine their exact nature, extent, and magnitude."

In the United States National Research Council (NRC) book "Long-Term Worldwide Effects of Multiple Nuclear-Weapons Detonations" published in 1975, it states that a nuclear war involving 4,000 Mt from "present arsenals" would probably deposit much less dust in the stratosphere than the Krakatoa eruption, judging that the effect of dust and oxides of nitrogen would probably be slight climatic cooling which "would probably lie within normal global climatic variability, but the possibility of climatic changes of a more dramatic nature cannot be ruled out".

In the 1985 report "The Effects on the Atmosphere of a Major Nuclear Exchange", the Committee on the Atmospheric Effects of Nuclear Explosions argues that a "plausible" estimate on the amount of stratospheric dust injected following a surface burst of 1 Mt is 0.3 teragrams, of which 8 percent would be in the micrometer range. The potential cooling from soil dust was again looked at in 1992, in a US National Academy of Sciences (NAS) report on geoengineering, which estimated that about 10 kg (10 teragrams) of stratospheric injected soil dust with particulate grain dimensions of 0.1 to 1 micrometer would be required to mitigate the warming from a doubling of atmospheric carbon dioxide, that is, to produce ~2 °C of cooling.

In 1969, Paul Crutzen discovered that oxides of nitrogen (NOx) could be an efficient catalyst for the destruction of the ozone layer/stratospheric ozone. Following studies on the potential effects of NOx generated by engine heat in stratosphere flying Supersonic Transport (SST) airplanes in the 1970s, in 1974, John Hampson suggested in the journal "Nature" that due to the creation of atmospheric NOx by nuclear fireballs, a full-scale nuclear exchange could result in depletion of the ozone shield, possibly subjecting the earth to ultraviolet radiation for a year or more. In 1975, Hampson's hypothesis "led directly" to the United States National Research Council (NRC) reporting on the models of ozone depletion following nuclear war in the book "Long-Term Worldwide Effects of Multiple Nuclear-Weapons Detonations".

In the section of this 1975 NRC book pertaining to the issue of fireball generated NOx and ozone layer loss therefrom, the NRC present model calculations from the early-to-mid 1970s on the effects of a nuclear war with the use of large numbers of multi-megaton yield detonations, which returned conclusions that this could reduce ozone levels by 50 percent or more in the northern hemisphere.

However independent of the computer models presented in the 1975 NRC works, a paper in 1973 in the journal "Nature" depicts the stratospheric ozone levels worldwide overlaid upon the number of nuclear detonations during the era of atmospheric testing. The authors conclude that neither the data nor their models show any correlation between the approximate 500 Mt in historical atmospheric testing and an increase or decrease of ozone concentration. In 1976, a study on the experimental measurements of an earlier atmospheric nuclear test as it affected the ozone layer also found that nuclear detonations are exonerated of depleting ozone, after the at first alarming model calculations of the time. Similarly, a 1981 paper found that the models on ozone destruction from one test and the physical measurements taken were in disagreement, as no destruction was observed.

In total, about 500 Mt were atmospherically detonated between 1945 and 1971, peaking in 1961–62, when 340 Mt were detonated in the atmosphere by the United States and Soviet Union. During this peak, with the multi-megaton range detonations of the two nations nuclear test series, in exclusive examination, a total yield estimated at 300 Mt of energy was released. Due to this, 3 × 10 additional molecules of nitric oxide (about 5,000 tons per Mt, 5 × 10 grams per megaton) are believed to have entered the stratosphere, and while ozone depletion of 2.2 percent was noted in 1963, the decline had started prior to 1961 and is believed to have been caused by other meteorological effects.

In 1982 journalist Jonathan Schell in his popular and influential book "The Fate of the Earth", introduced the public to the belief that fireball generated NOx would destroy the ozone layer to such an extent that crops would fail from solar UV radiation and then similarly painted the fate of the Earth, as plant and aquatic life going extinct. In the same year, 1982, Australian physicist Brian Martin, who frequently corresponded with John Hampson who had been greatly responsible for much of the examination of NOx generation, penned a short historical synopsis on the history of interest in the effects of the direct NOx generated by nuclear fireballs, and in doing so, also outlined Hampson's other non-mainstream viewpoints, particularly those relating to greater ozone destruction from upper-atmospheric detonations as a result of any widely used anti-ballistic missile (ABM-1 Galosh) system. However, Martin ultimately concludes that it is "unlikely that in the context of a major nuclear war" ozone degradation would be of serious concern. Martin describes views about potential ozone loss and therefore increases in ultraviolet light leading to the widespread destruction of crops, as advocated by Jonathan Schell in "The Fate of the Earth", as highly unlikely.

More recent accounts on the specific ozone layer destruction potential of NOx species are much less than earlier assumed from simplistic calculations, as "about 1.2 million tons" of natural and anthropogenic generated stratospheric NOx is believed to be formed each year according to Robert P. Parson in the 1990s.

The first published suggestion that a cooling of climate could be an effect of a nuclear war, appears to have been originally put forth by Poul Anderson and F.N. Waldrop in their post-war story "Tomorrow's Children", in the March 1947 issue of the "Astounding Science Fiction" magazine. The story, primarily about a team of scientists hunting down mutants, warns of a "Fimbulwinter" caused by dust that blocked sunlight after a recent nuclear war and speculated that it may even trigger a new Ice Age. Anderson went on to publish a novel based partly on this story in 1961, titling it "Twilight World". Similarly in 1985 it was noted by T. G. Parsons that the story "Torch" by C. Anvil, which also appeared in "Astounding Science Fiction" magazine, but in the April 1957 edition, contains the essence of the "Twilight at Noon"/"nuclear winter" hypothesis. In the story a nuclear warhead ignites an oil field, and the soot produced "screens out part of the sun's radiation", resulting in Arctic temperatures for much of the population of North America and the Soviet Union.

The 1988 Air Force Geophysics Laboratory publication, "An assessment of global atmospheric effects of a major nuclear war" by H. S. Muench, et al., contains a chronology and review of the major reports on the nuclear winter hypothesis from 1983–1986. In general these reports arrive at similar conclusions as they are based on "the same assumptions, the same basic data", with only minor model-code differences. They skip the modeling steps of assessing the possibility of fire and the initial fire plumes and instead start the modeling process with a "spatially uniform soot cloud" which has found its way into the atmosphere.

Although never openly acknowledged by the multi-disciplinary team who authored the most popular 1980s TTAPS model, in 2011 the American Institute of Physics states that the TTAPS team (named for its participants, who had all previously worked on the phenomenon of dust storms on Mars, or in the area of asteroid impact events: Richard P. Turco, Owen Toon, Thomas P. Ackerman, James B. Pollack and Carl Sagan) announcement of their results in 1983 "was with the explicit aim of promoting international arms control". However, "the computer models were so simplified, and the data on smoke and other aerosols were still so poor, that the scientists could say nothing for certain."

In 1981, William J. Moran began discussions and research in the National Research Council (NRC) on the airborne soil/dust effects of a large exchange of nuclear warheads, having seen a possible parallel in the dust effects of a war with that of the asteroid-created K-T boundary and its popular analysis a year earlier by Luis Alvarez in 1980. An NRC study panel on the topic met in December 1981 and April 1982 in preparation for the release of the NRC's "The Effects on the Atmosphere of a Major Nuclear Exchange", published in 1985.

As part of a study on the creation of oxidizing species such as NOx and ozone in the troposphere after a nuclear war, launched in 1980 by "AMBIO", a journal of the Royal Swedish Academy of Sciences, Paul J. Crutzen and John Birks began preparing for the 1982 publication of a calculation on the effects of nuclear war on stratospheric ozone, using the latest models of the time. However they found that in part as a result of the trend towards more numerous but less energetic, sub-megaton range nuclear warheads (made possible by the ceaseless march to increase ICBM warhead accuracy/Circular Error Probable), the ozone layer danger was "not very significant".

It was after being confronted with these results that they "chanced" upon the notion, as "an afterthought" of nuclear detonations igniting massive fires everywhere and, crucially, the smoke from these conventional fires then going on to absorb sunlight, causing surface temperatures to plummet. In early-1982, the two circulated a draft paper with the first suggestions of alterations in short-term climate from fires presumed to occur following a nuclear war. Later in the same year, the special issue of "Ambio" devoted to the possible environmental consequences of nuclear war by Crutzen and Birks was titled "Twilight at Noon", and largely anticipated the nuclear winter hypothesis. The paper looked into fires and their climatic effect and discussed particulate matter from large fires, nitrogen oxide, ozone depletion and the effect of nuclear twilight on agriculture. Crutzen and Birks' calculations suggested that smoke particulates injected into the atmosphere by fires in cities, forests and petroleum reserves could prevent up to 99 percent of sunlight from reaching the Earth's surface. This darkness, they said, could exist "for as long as the fires burned", which was assumed to be many weeks, with effects such as: "The normal dynamic and temperature structure of the atmosphere would ... change considerably over a large fraction of the Northern Hemisphere, which will probably lead to important changes in land surface temperatures and wind systems." An implication of their work was that a successful nuclear decapitation strike could have severe climatic consequences for the perpetrator.

After reading a paper by N. P. Bochkov and E. I. Chazov, published in the same edition of "Ambio" that carried Crutzen and Birks's paper "Twilight at Noon", Soviet atmospheric scientist Georgy Golitsyn applied his research on Mars dust storms to soot in the Earth's atmosphere. The use of these influential Martian dust storm models in nuclear winter research began in 1971, when the Soviet spacecraft Mars 2 arrived at the red planet and observed a global dust cloud. The orbiting instruments together with the 1971 Mars 3 lander determined that temperatures on the surface of the red-planet were considerably colder than temperatures at the top of the dust cloud. Following these observations, Golitsyn received two telegrams from astronomer Carl Sagan, in which Sagan asked Golitsyn to "explore the understanding and assessment of this phenomenon." Golitsyn recounts that it was around this time that he had "proposed a theory to explain how Martian dust may be formed and how it may reach global proportions."

In the same year Alexander Ginzburg, an employee in Golitsyn's institute, developed a model of dust storms to describe the cooling phenomenon on Mars. Golitsyn felt that his model would be applicable to soot after he read a 1982 Swedish magazine dedicated to the effects of a hypothetical nuclear war between the USSR and the US. Golitsyn would use Ginzburg's largely unmodified dust-cloud model with soot assumed as the aerosol in the model instead of soil dust and in an identical fashion to the results returned, when computing dust-cloud cooling in the Martian atmosphere, the cloud high above the planet would be heated while the planet below would cool drastically. Golitsyn presented his intent to publish this Martian derived Earth-analog model to the Andropov instigated "Committee of Soviet Scientists in Defence of Peace Against the Nuclear Threat" in May 1983, an organization that Golitsyn would later be appointed a position of vice-chairman of. The establishment of this committee was done with the expressed approval of the Soviet leadership with the intent "to expand controlled contacts with Western "nuclear freeze" activists". Having gained this committees approval, in September 1983, Golitsyn published the first computer model on the nascent "nuclear winter" effect in the widely read "Herald of the Russian Academy of Sciences".

On 31 October 1982, Golitsyn and Ginsburg's model and results were presented at the conference on "The World after Nuclear War", hosted in Washington, D.C.

Both Golitsyn and Sagan had been interested in the cooling on the dust storms on the planet Mars in the years preceding their focus on "nuclear winter". Sagan had also worked on Project A119 in the 1950s–1960s, in which he attempted to model the movement and longevity of a plume of lunar soil.

After the publication of "Twilight at Noon" in 1982, the TTAPS team have said that they began the process of doing a 1-dimensional computational modeling study of the atmospheric consequences of nuclear war/soot in the stratosphere, though they would not publish a paper in "Science" magazine until late-December 1983. The phrase "nuclear winter" had been coined by Turco just prior to publication. In this early paper, TTAPS used assumption-based estimates on the total smoke and dust emissions that would result from a major nuclear exchange, and with that, began analyzing the subsequent effects on the atmospheric radiation balance and temperature structure as a result of this quantity of assumed smoke. To compute dust and smoke effects, they employed a one-dimensional microphysics/radiative-transfer model of the Earth's lower atmosphere (up to the mesopause), which defined only the vertical characteristics of the global climate perturbation.

Interest in the environmental effects of nuclear war, however, had continued in the Soviet Union after Golitsyn's September paper, with Vladimir Alexandrov and G. I. Stenchikov also publishing a paper in December 1983 on the climatic consequences, although in contrast to the contemporary TTAPS paper, this paper was based on simulations with a three-dimensional global circulation model. (Two years later Alexandrov disappeared under mysterious circumstances). Richard Turco and Starley L. Thompson were both critical of the Soviet research. Turco called it "primitive" and Thompson said it used obsolete US computer models. Later they were to rescind these criticisms and instead applauded Alexandrov's pioneering work, saying that the Soviet model shared the weaknesses of all the others.

In 1984, the World Meteorological Organization (WMO) commissioned Golitsyn and N. A. Phillips to review the state of the science. They found that studies generally assumed a scenario where half of the world's nuclear weapons would be used, ~5000 Mt, destroying approximately 1,000 cities, and creating large quantities of carbonaceous smoke – 1– being most likely, with a range of 0.2– (NAS; TTAPS assumed ). The smoke resulting would be largely opaque to solar radiation but transparent to infrared, thus cooling the Earth by blocking sunlight, but not creating warming by enhancing the greenhouse effect. The optical depth of the smoke can be much greater than unity. Forest fires resulting from non-urban targets could increase aerosol production further. Dust from near-surface explosions against hardened targets also contributes; each megaton-equivalent explosion could release up to five million tons of dust, but most would quickly fall out; high altitude dust is estimated at 0.1–1 million tons per megaton-equivalent of explosion. Burning of crude oil could also contribute substantially.

The 1-D radiative-convective models used in these studies produced a range of results, with coolings up to 15–42 °C between 14 to 35 days after the war, with a "baseline" of about 20 °C. Somewhat more sophisticated calculations using 3-D GCMs produced similar results: temperature drops of about 20 °C, though with regional variations.

All calculations show large heating (up to 80 °C) at the top of the smoke layer at about ; this implies a substantial modification of the circulation there and the possibility of advection of the cloud into low latitudes and the southern hemisphere.

In a 1990 paper entitled "Climate and Smoke: An Appraisal of Nuclear Winter", TTAPS gave a more detailed description of the short- and long-term atmospheric effects of a nuclear war using a three-dimensional model:

First one to three months:

Following one to three years:

One of the major results of TTAPS' 1990 paper was the re-iteration of the team's 1983 model that 100 oil refinery fires would be sufficient to bring about a small scale, but still globally deleterious nuclear winter.

Following Iraq's invasion of Kuwait and Iraqi threats of igniting the country's approximately 800 oil wells, speculation on the cumulative climatic effect of this, presented at the World Climate Conference in Geneva that November in 1990, ranged from a nuclear winter type scenario, to heavy acid rain and even short term immediate global warming.

In articles printed in the "Wilmington Morning Star" and the "Baltimore Sun" newspapers in January 1991, prominent authors of nuclear winter papers – Richard P. Turco, John W. Birks, Carl Sagan, Alan Robock and Paul Crutzen – collectively stated that they expected catastrophic nuclear winter like effects with continental-sized effects of sub-freezing temperatures as a result of the Iraqis going through with their threats of igniting 300 to 500 pressurized oil wells that could subsequently burn for several months.

As threatened, the wells were set on fire by the retreating Iraqis in March 1991, and the 600 or so burning oil wells were not fully extinguished until November 6, 1991, eight months after the end of the war, and they consumed an estimated six million barrels of oil per day at their peak intensity.

When Operation Desert Storm began in January 1991, coinciding with the first few oil fires being lit, Dr. S. Fred Singer and Carl Sagan discussed the possible environmental effects of the Kuwaiti petroleum fires on the ABC News program "Nightline". Sagan again argued that some of the effects of the smoke could be similar to the effects of a nuclear winter, with smoke lofting into the stratosphere, beginning around above sea level in Kuwait, resulting in global effects. He also argued that he believed the net effects would be very similar to the explosion of the Indonesian volcano Tambora in 1815, which resulted in the year 1816 being known as the "Year Without a Summer".

Sagan listed modeling outcomes that forecast effects extending to South Asia, and perhaps to the Northern Hemisphere as well. Sagan stressed this outcome was so likely that "It should affect the war plans." Singer, on the other hand, anticipated that the smoke would go to an altitude of about and then be rained out after about three to five days, thus limiting the lifetime of the smoke. Both height estimates made by Singer and Sagan turned out to be wrong, albeit with Singer's narrative being closer to what transpired, with the comparatively minimal atmospheric effects remaining limited to the Persian Gulf region, with smoke plumes, in general, lofting to about and a few as high as .

Sagan and his colleagues expected that a "self-lofting" of the sooty smoke would occur when it absorbed the sun's heat radiation, with little to no scavenging occurring, whereby the black particles of soot would be heated by the sun and lifted/lofted higher and higher into the air, thereby injecting the soot into the stratosphere, a position where they argued it would take years for the sun blocking effect of this aerosol of soot to fall out of the air, and with that, catastrophic ground level cooling and agricultural effects in Asia and possibly the Northern Hemisphere as a whole. In a 1992 follow-up, Peter Hobbs and others had observed no appreciable evidence for the nuclear winter team's predicted massive "self-lofting" effect and the oil-fire smoke clouds contained less soot than the nuclear winter modelling team had assumed.

The atmospheric scientist tasked with studying the atmospheric effect of the Kuwaiti fires by the National Science Foundation, Peter Hobbs, stated that the fires' modest impact suggested that "some numbers [used to support the Nuclear Winter hypothesis]... were probably a little overblown."

Hobbs found that at the peak of the fires, the smoke absorbed 75 to 80% of the sun's radiation. The particles rose to a maximum of , and when combined with scavenging by clouds the smoke had a short residency time of a maximum of a few days in the atmosphere.

Pre-war claims of wide scale, long-lasting, and significant global environmental effects were thus not borne out, and found to be significantly exaggerated by the media and speculators, with climate models by those not supporting the nuclear winter hypothesis at the time of the fires predicting only more localized effects such as a daytime temperature drop of ~10 °C within 200 km of the source.

Sagan later conceded in his book "The Demon-Haunted World" that his predictions obviously did not turn out to be correct: "it "was" pitch black at noon and temperatures dropped 4–6° C over the Persian Gulf, but not much smoke reached stratospheric altitudes and Asia was spared."

The idea of oil well and oil reserve smoke pluming into the stratosphere serving as a main contributor to the soot of a nuclear winter was a central idea of the early climatology papers on the hypothesis; they were considered more of a possible contributor than smoke from cities, as the smoke from oil has a higher ratio of black soot, thus absorbing more sunlight. Hobbs compared the papers' assumed "emission factor" or soot generating efficiency from ignited oil pools and found, upon comparing to measured values from oil pools at Kuwait, which were the greatest soot producers, the emissions of soot assumed in the nuclear winter calculations were still "too high". Following the results of the Kuwaiti oil fires being in disagreement with the core nuclear winter promoting scientists, 1990s nuclear winter papers generally attempted to distance themselves from suggesting oil well and reserve smoke will reach the stratosphere.

In 2007, a nuclear winter study, noted that modern computer models have been applied to the Kuwait oil fires, finding that individual smoke plumes are not able to loft smoke into the stratosphere, but that smoke from fires covering a large area like some forest fires can lift smoke into the stratosphere, and recent evidence suggests that this occurs far more often than previously thought. The study also suggested that the burning of the comparably smaller cities, which would be expected to follow a nuclear strike, would also loft significant amounts of smoke into the stratosphere:

However the above simulation notably contained the assumption that no dry or wet deposition would occur.

Between 1990 and 2003, commentators noted that no peer-reviewed papers on "nuclear winter" were published.

Based on new work published in 2007 and 2008 by some of the authors of the original studies, several new hypotheses have been put forth, primarily the assessment that as few as 100 firestorms would result in a nuclear winter. However far from the hypothesis being "new", it drew the same conclusion as earlier 1980s models, which similarly regarded 100 or so city firestorms as a threat.

Compared to climate change for the past millennium, even the smallest exchange modeled would plunge the planet into temperatures colder than the Little Ice Age (the period of history between approximately 1600 and 1850 AD). This would take effect instantly, and agriculture would be severely threatened. Larger amounts of smoke would produce larger climate changes, making agriculture impossible for years. In both cases, new climate model simulations show that the effects would last for more than a decade.

A study published in the "Journal of Geophysical Research" in July 2007, titled "Nuclear winter revisited with a modern climate model and current nuclear arsenals: Still catastrophic consequences", used current climate models to look at the consequences of a global nuclear war involving most or all of the world's current nuclear arsenals (which the authors judged to be one similar to the size of the world's arsenals twenty years earlier). The authors used a global circulation model, ModelE from the NASA Goddard Institute for Space Studies, which they noted "has been tested extensively in global warming experiments and to examine the effects of volcanic eruptions on climate." The model was used to investigate the effects of a war involving the entire current global nuclear arsenal, projected to release about 150 Tg of smoke into the atmosphere, as well as a war involving about one third of the current nuclear arsenal, projected to release about 50 Tg of smoke. In the 150 Tg case they found that:

In addition, they found that this cooling caused a weakening of the global hydrological cycle, reducing global precipitation by about 45%. As for the 50 Tg case involving one third of current nuclear arsenals, they said that the simulation "produced climate responses very similar to those for the 150 Tg case, but with about half the amplitude," but that "the time scale of response is about the same." They did not discuss the implications for agriculture in depth, but noted that a 1986 study which assumed no food production for a year projected that "most of the people on the planet would run out of food and starve to death by then" and commented that their own results show that, "This period of no food production needs to be extended by many years, making the impacts of nuclear winter even worse than previously thought."

In 2014, Michael J. Mills (at the US National Center for Atmospheric Research, NCAR), et al., published "Multi-decadal global cooling and unprecedented ozone loss following a regional nuclear conflict" in the journal "Earth's Future". The authors used computational models developed by NCAR to simulate the climatic effects of a soot cloud that they suggest would be a result, of a regional nuclear war in which 100 "small" (15 Kt) weapons are detonated over cities. The model had outputs, due to the interaction of the soot cloud:

global ozone losses of 20–50% over populated areas, levels unprecedented in human history, would accompany the coldest average surface temperatures in the last 1000 years. We calculate summer enhancements in UV indices of 30–80% over Mid-Latitudes, suggesting widespread damage to human health, agriculture, and terrestrial and aquatic ecosystems. Killing frosts would reduce growing seasons by 10–40 days per year for 5 years. Surface temperatures would be reduced for more than 25 years, due to thermal inertia and albedo effects in the ocean and expanded sea ice. The combined cooling and enhanced UV would put significant pressures on global food supplies and could trigger a global nuclear famine.

Research published in the peer-reviewed journal "Safety" suggested that no nation should possess more than 100 nuclear warheads because of the blowback effect on the aggressor nation's own population because of "nuclear autumn".

The four major, largely independent underpinnings that the nuclear winter concept has and continues to receive criticism over, are regarded as: firstly, would cities readily firestorm, and if so how much soot would be generated? Secondly, "atmospheric" longevity: would the quantities of soot assumed in the models remain in the atmosphere for as long as projected or would far more soot precipitate as black rain much sooner? Third, "timing" of events: how reasonable is it for the modeling of firestorms or war to commence in late spring or summer; this is done in almost all US-Soviet nuclear winter papers, thereby giving rise to the largest possible degree of modeled cooling? Lastly, the issue of "darkness or opacity": how much light-blocking effect the assumed quality of the soot reaching the atmosphere would have.

While the highly popularized initial 1983 TTAPS 1-dimensional model forecasts were widely reported and criticized in the media, in part because every later model predicts far less of its "apocalyptic" level of cooling, most models continue to suggest that some deleterious global cooling would still result, under the assumption that a large number of fires occurred in the spring or summer. Starley L. Thompson's less primitive mid-1980s 3-Dimensional model, which notably contained the very same general assumptions, led him to coin the term "nuclear autumn" to more accurately describe the climate results of the soot in this model, in an on camera interview in which he dismisses the earlier "apocalyptic" models.

A major criticism of the assumptions that continue to make these model results possible appeared in the 1987 book "Nuclear War Survival Skills" ("NWSS"), a civil defense manual by Cresson Kearny for the Oak Ridge National Laboratory. According to the 1988 publication "An assessment of global atmospheric effects of a major nuclear war", Kearny's criticisms were directed at the excessive amount of soot that the modelers assumed would reach the stratosphere. Kearny cited a Soviet study that modern cities would not burn as firestorms, as most flammable city items would be buried under non-combustible rubble and that the TTAPS study included a massive overestimate on the size and extent of non-urban wildfires that would result from a nuclear war. The TTAPS authors responded that, amongst other things, they did not believe target planners would intentionally blast cities into rubble, but instead argued fires would begin in relatively undamaged suburbs when nearby sites were hit, and partially conceded his point about non-urban wildfires. Dr. Richard D. Small, director of thermal sciences at the Pacific-Sierra Research Corporation similarly disagreed strongly with the model assumptions, in particular the 1990 update by TTAPS that argues that some 5,075 Tg of material would burn in a total US-Soviet nuclear war, as analysis by Small of blueprints and real buildings returned a maximum of 1,475 Tg of material that could be burned, "assuming that all the available combustible material was actually ignited".

Although Kearny was of the opinion that future more accurate models would "indicate there will be even smaller reductions in temperature", including future potential models that did not so readily accept that firestorms would occur as dependably as nuclear winter modellers assume, in "NWSS" Kearny did summarize the comparatively moderate cooling estimate of no more than a few days, from the 1986 "Nuclear Winter Reappraised" model by Starley Thompson and Stephen Schneider. This was done in an effort to convey to his readers that contrary to the popular opinion at the time, in the conclusion of these two climate scientists, "on scientific grounds the global apocalyptic conclusions of the initial nuclear winter hypothesis can now be relegated to a vanishing low level of probability."

However while a 1988 article by Brian Martin in "Science and Public Policy" states that although "Nuclear Winter Reappraised" concluded the US-Soviet "nuclear winter" would be much less severe than originally thought, with the authors describing the effects more as a "nuclear autumn", other statements by Thompson and Schneider show that they "resisted the interpretation that this means a rejection of the basic points made about nuclear winter". In the Alan Robock et al. 2007 paper they write that "because of the use of the term 'nuclear autumn' by Thompson and Schneider [1986], even though the authors made clear that the climatic consequences would be large, in policy circles the theory of nuclear winter is considered by some to have been exaggerated and disproved [e.g., Martin, 1988]." In 2007 Schneider expressed his tentative support for the cooling results of the limited nuclear war (Pakistan and India) analyzed in the 2006 model, saying "The sun is much stronger in the tropics than it is in mid-latitudes. Therefore, a much more limited war [there] could have a much larger effect, because you are putting the smoke in the worst possible place", and "anything that you can do to discourage people from thinking that there is any way to win anything with a nuclear exchange is a good idea."

The contribution of smoke from the ignition of live non-desert vegetation, living forests, grasses and so on, nearby to many missile silos is a source of smoke originally assumed to be very large in the initial "Twilight at Noon" paper, and also found in the popular TTAPS publication. However, this assumption was examined by Bush and Small in 1987 and they found that the burning of live vegetation could only conceivably contribute very slightly to the estimated total "nonurban smoke production". With the vegetation's potential to sustain burning only probable if it is within a radius or two from the surface of the nuclear fireball, which is at a distance that would also experience extreme blast winds that would influence any such fires. This reduction in the estimate of the non-urban smoke hazard is supported by the earlier preliminary "Estimating Nuclear Forest Fires" publication of 1984, and by the 1950–60s in-field examination of surface-scorched, mangled but never burnt-down tropical forests on the surrounding islands from the shot points in the Operation Castle, and Operation Redwing test series.

A paper by the United States Department of Homeland Security, finalized in 2010, states that after a nuclear detonation targeting a city "If fires are able to grow and coalesce, a firestorm could develop that would be beyond the abilities of firefighters to control. However experts suggest in the nature of modern US city design and construction may make a raging firestorm unlikely". The nuclear bombing of Nagasaki for example, did not produce a firestorm. This was similarly noted as early as 1986–88, when the assumed quantity of fuel "mass loading" (the amount of fuel per square meter) in cities underpinning the winter models was found to be too high and intentionally creates heat fluxes that loft smoke into the lower stratosphere, yet assessments "more characteristic of conditions" to be found in real-world modern cities, had found that the fuel loading, and hence the heat flux that would result from efficient burning, would rarely loft smoke much higher than 4 km.

Russell Seitz, Associate of the Harvard University Center for International Affairs, argues that the winter models' assumptions give results which the researchers want to achieve and is a case of "worst-case analysis run amok". In September 1986 Seitz published "Siberian fire as 'nuclear winter' guide" in the journal "Nature" in which he investigated the 1915 Siberian fire which started in the early summer months and was caused by the worst drought in the region's recorded history. The fire ultimately devastated the region burning the world's largest boreal forest, the size of Germany. While approximately 8 ˚C of daytime summer cooling occurred under the smoke clouds during the weeks of burning, no increase in potentially devastating agricultural night frosts occurred. Following his investigation into the Siberian fire of 1915, Seitz criticized the "nuclear winter" model results for being based on successive worst-case events: "The improbability of a string of 40 such coin tosses coming up heads approaches that of a pat royal flush. Yet it was represented as a "sophisticated one-dimensional model" – a usage that is oxymoronic, unless applied to [the British model Lesley Lawson] Twiggy."

Seitz cited Carl Sagan, adding an emphasis: ""In almost any realistic case" involving nuclear exchanges between the superpowers, global environmental changes sufficient to cause an extinction event equal to or more severe than that of the close of the Cretaceous when the dinosaurs and many other species died out are likely." Seitz comments: "The ominous rhetoric italicized in this passage puts even the 100 megaton [the original 100 city firestorm] scenario ... on a par with the 100 million megaton blast of an asteroid striking the Earth. This [is] astronomical mega-hype ..." Seitz concludes:
Seitz's opposition caused the proponents of nuclear winter to issue responses in the media. The proponents believed it was simply necessary to show only the possibility of climatic catastrophe, often a worst-case scenario, while opponents insisted that to be taken seriously, nuclear winter should be shown as likely under "reasonable" scenarios. One of these areas of contention, as elucidated by Lynn R. Anspaugh, is upon the question of which season should be used as the backdrop for the US-USSR war models, as most models choose the summer in the Northern Hemisphere as the start point to produce the maximum soot lofting and therefore eventual winter effect, whereas it has been pointed out that if the firestorms occurred in the autumn or winter months, when there is much less intense sunlight to loft soot into a stable region of the stratosphere, the magnitude of the cooling effect from the same number of firestorms as ignited in the summer models, would be negligible according to a January model run by Covey et al. Schneider conceded the issue in 1990, saying "a war in late fall or winter would have no appreciable [cooling] effect".

Anspaugh also expressed frustration that although a managed forest fire in Canada on 3 August 1985 is said to have been lit by proponents of nuclear winter, with the fire potentially serving as an opportunity to do some basic measurements of the optical properties of the smoke and smoke-to-fuel ratio, which would have helped refine the estimates of these critical model inputs, the proponents did not indicate that any such measurements were made. Peter V. Hobbs, who would later successfully attain funding to fly into and sample the smoke clouds from the Kuwait oil fires in 1991, also expressed frustration that he was denied funding to sample the Canadian, and other forest fires in this way. Turco wrote a 10-page memorandum with information derived from his notes and some satellite images, claiming that the smoke plume reached 6 km in altitude.

In 1986, atmospheric scientist Joyce Penner from the Lawrence Livermore National Laboratory published an article in "Nature" in which she focused on the specific variables of the smoke's optical properties and the quantity of smoke remaining airborne after the city fires and found that the published estimates of these variables varied so widely that depending on which estimates were chosen the climate effect could be negligible, minor or massive.
The assumed optical properties for black carbon in more recent nuclear winter papers in 2006 are still "based on those assumed in earlier nuclear winter simulations".

John Maddox, editor of the journal "Nature", issued a series of skeptical comments about nuclear winter studies during his tenure. Similarly S. Fred Singer was a long term vocal critic of the hypothesis in the journal and in televised debates with Carl Sagan.

In a 2011 response to the more modern papers on the hypothesis, Russell Seitz published a comment in "Nature" challenging Alan Robock's claim that there has been no real scientific debate about the 'nuclear winter' concept. In 1986 Seitz also contends that many others are reluctant to speak out for fear of being stigmatized as "closet Dr. Strangeloves", physicist Freeman Dyson of Princeton for example stated "It's an absolutely atrocious piece of science, but I quite despair of setting the public record straight." According to the Rocky Mountain News, Stephen Schneider had been called a fascist by some disarmament supporters for having written his 1986 article "Nuclear Winter Reappraised." As MIT meteorologist Kerry Emanuel similarly wrote a review in "Nature" that the winter concept is "notorious for its lack of scientific integrity" due to the unrealistic estimates selected for the quantity of fuel likely to burn, the imprecise global circulation models used, and ends by stating that the evidence of other models, point to substantial scavenging of the smoke by rain. Emanuel also made an "interesting point" about questioning proponent's objectivity when it came to strong emotional or political issues that they hold.

William R. Cotton, Professor of Atmospheric Science at Colorado State University, specialist in cloud physics modeling and co-creator of the highly influential, and previously mentioned RAMS atmosphere model, had in the 1980s worked on soot rain-out models and supported the predictions made by his own and other nuclear winter models, but has since reversed this position according to a book co-authored by him in 2007, stating that, amongst other systematically examined assumptions, far more rain out/wet deposition of soot will occur than is assumed in modern papers on the subject: "We must wait for a new generation of GCMs to be implemented to examine potential consequences quantitatively" and revealing that in his view, "nuclear winter was largely politically motivated from the beginning".

During the Cuban Missile Crisis, Fidel Castro and Che Guevara called on the USSR to launch a nuclear first strike against the US in the event of a US invasion of Cuba. In the 1980s Castro was pressuring the Kremlin to adopt a harder line against the US under President Ronald Reagan, even arguing for the potential use of nuclear weapons. As a direct result of this a Soviet official was dispatched to Cuba in 1985 with an entourage of "experts", who detailed the ecological effect on Cuba in the event of nuclear strikes on the United States. Soon after, the Soviet official recounts, Castro lost his prior "nuclear fever". In 2010 Alan Robock was summoned to Cuba to help Castro promote his new view that nuclear war would bring about Armageddon. Robock's 90 minute lecture was later aired on the nationwide state-controlled television station in the country.

However, according to Robock, insofar as getting US government attention and affecting nuclear policy, he has failed. In 2009, together with Owen Toon, he gave a talk to the United States Congress but nothing transpired from it and the then presidential science adviser, John Holdren, did not respond to their requests in 2009 or at the time of writing in 2011.
In a 2012 "Bulletin of the Atomic Scientists" feature, Robock and Toon, who had routinely mixed their disarmament advocacy into the conclusions of their "nuclear winter" papers, argue in the political realm that the hypothetical effects of nuclear winter necessitates that the doctrine they assume is active in Russia and US, "mutually assured destruction" (MAD) should instead be replaced with their own "self-assured destruction" (SAD) concept, because, regardless of whose cities burned, the effects of the resultant nuclear winter that they advocate, would be, in their view, catastrophic. In a similar vein, in 1989 Carl Sagan and Richard Turco wrote a policy implications paper that appeared in "AMBIO" that suggested that as nuclear winter is a "well-established prospect", both superpowers should jointly reduce their nuclear arsenals to "Canonical Deterrent Force" levels of 100–300 individual warheads each, such that in "the event of nuclear war [this] would minimize the likelihood of [extreme] nuclear winter."

An originally classified 1984 US interagency intelligence assessment states that in both the preceding 1970s and 80s, the Soviet and US military were already following the ""existing trends"" in warhead miniaturization, of higher accuracy and lower yield nuclear warheads, this is seen when assessing the most numerous physics packages in the US arsenal, which in the 1960s were the B28 and W31, however both quickly became less prominent with the 1970s mass production runs of the 50 Kt W68, the 100 Kt W76 and in the 1980s, with the B61. This trend towards miniaturization, enabled by advances in inertial guidance and accurate GPS navigation etc., was motivated by a multitude of factors, namely the desire to leverage the physics of equivalent megatonnage that miniaturization offered; of freeing up space to fit more MIRV warheads and decoys on each missile. Alongside the desire to still destroy hardened targets but while reducing the severity of fallout collateral damage depositing on neighboring, and potentially friendly, countries. As it relates to the likelihood of nuclear winter, the range of potential thermal radiation ignited fires was already reduced with miniaturization. For example, the most popular nuclear winter paper, the 1983 TTAPS paper, had described a 3000 Mt counterforce attack on ICBM sites with each individual warhead having approximately one Mt of energy; however not long after publication, Michael Altfeld of Michigan State University and political scientist Stephen Cimbala of Pennsylvania State University argued that the then already developed and deployed smaller, more accurate warheads (e.g. W76), together with lower detonation heights, could produce the same counterforce strike with a total of only 3 Mt of energy being expended. They continue that, "if" the nuclear winter models prove to be representative of reality, then far less climatic-cooling would occur, even if firestorm prone areas existed in the target list, as lower fusing heights such as surface bursts, would also limit the range of the burning thermal rays due to terrain masking and shadows cast by buildings, while also temporarily lofting far more localized fallout when compared to airburst fuzing – the standard mode of employment against un-hardened targets. This logic is similarly reflected in the originally classified 1984 "Interagency Intelligence assessment", which suggests that targeting planners would simply have to consider target combustibility along with yield, height of burst, timing and other factors to reduce the amount of smoke to safeguard against the potentiality of a nuclear winter. Therefore, as a consequence of attempting to limit the target fire hazard by reducing the range of thermal radiation with fuzing for surface and sub-surface bursts, this will result in a scenario where the far more concentrated, and therefore deadlier, "local" fallout that is generated following a surface burst forms, as opposed to the comparatively dilute "global" fallout created when nuclear weapons are fuzed in air burst mode.

Altfeld and Cimbala also argued that belief in the possibility of nuclear winter would actually make nuclear war more likely, contrary to the views of Sagan and others, because it would serve yet further motivation to follow the "existing trends", towards the development of more accurate, and even lower explosive yield, nuclear weapons. As the winter hypothesis suggests that the replacement of the then Cold War viewed strategic nuclear weapons in the multi-megaton yield range, with weapons of explosive yields closer to tactical nuclear weapons, such as the Robust Nuclear Earth Penetrator (RNEP), would safeguard against the nuclear winter potential. With the latter capabilities of the then, largely still conceptual RNEP, specifically cited by the influential nuclear warfare analyst Albert Wohlstetter. Tactical nuclear weapons, on the low end of the scale have yields that overlap with large conventional weapons, and are therefore often viewed "as blurring the distinction between conventional and nuclear weapons", making the prospect of using them "easier" in a conflict.

In an interview in 2000 with Mikhail Gorbachev (the leader of the Soviet Union from 1985–91), the following statement was posed to him: "In the 1980s, you warned about the unprecedented dangers of nuclear weapons and took very daring steps to reverse the arms race", with Gorbachev replying "Models made by Russian and American scientists showed that a nuclear war would result in a nuclear winter that would be extremely destructive to all life on Earth; the knowledge of that was a great stimulus to us, to people of honor and morality, to act in that situation."

However, a 1984 US Interagency Intelligence Assessment expresses a far more skeptical and cautious approach, stating that the hypothesis is not scientifically convincing. The report predicted that Soviet nuclear policy would be to maintain their strategic nuclear posture, such as their fielding of the high throw-weight SS-18 missile and they would merely attempt to exploit the hypothesis for propaganda purposes, such as directing scrutiny on the US portion of the nuclear arms race. Moreover, it goes on to express the belief that if Soviet officials did begin to take nuclear winter seriously, it would probably make them demand exceptionally high standards of scientific proof for the hypothesis, as the implications of it would undermine their military doctrine – a level of scientific proof which perhaps could not be met without field experimentation. The un-redacted portion of the document ends with the suggestion that substantial increases in Soviet Civil defense food stockpiles might be an early indicator that Nuclear Winter was beginning to influence Soviet upper echelon thinking.

In 1985 "Time" magazine noted "the suspicions of some Western scientists that the nuclear winter hypothesis was promoted by Moscow to give anti-nuclear groups in the U.S. and Europe some fresh ammunition against America's arms buildup."
In 1985, the United States Senate met to discuss the science and politics of nuclear winter. During the congressional hearing, the influential analyst Leon Gouré presented evidence that perhaps the Soviets have simply echoed Western reports rather than producing unique findings. Gouré hypothesized that Soviet research and discussions of nuclear war may serve only Soviet political agendas, rather than to reflect actual opinions of Soviet leadership.

In 1986, the Defense Nuclear Agency document "An update of Soviet research on and exploitation of Nuclear winter 1984–1986" charted the minimal [public domain] research contribution on, and Soviet propaganda usage of, the nuclear winter phenomenon.

There is some doubt as to when the Soviet Union began modelling fires and the atmospheric effects of nuclear war. Former Soviet intelligence officer Sergei Tretyakov claimed that, under the directions of Yuri Andropov, the KGB invented the concept of "nuclear winter" in order to stop the deployment of NATO Pershing II missiles. They are said to have distributed to peace groups, the environmental movement and the journal "Ambio" disinformation based on a faked "doomsday report" by the Soviet Academy of Sciences by Georgii Golitsyn, Nikita Moiseyev and Vladimir Alexandrov concerning the climatic effects of nuclear war. Although it is accepted that the Soviet Union exploited the nuclear winter hypothesis for propaganda purposes, Tretyakov's inherent claim that the KGB funnelled disinformation to "AMBIO", the journal in which Paul Crutzen and John Birks published the 1982 paper "Twilight at Noon", has not been corroborated . In an interview in 2009, conducted by the National Security Archive, Vitalii Nikolaevich Tsygichko; a Senior Analyst at the Soviet Academy of Sciences and military mathematical modeler, stated that Soviet military analysts were discussing the idea of "nuclear winter" years before U.S. scientists, although they did not use that exact term.

A number of solutions have been proposed to mitigate the potential harm of a nuclear winter if one appears inevitable; with the problem being attacked at both ends, from those focusing on preventing the growth of fires and therefore limiting the amount of smoke that reaches the stratosphere in the first place, and those focusing on food production with reduced sunlight, with the assumption that the very worst-case analysis results of the nuclear winter models prove accurate and no other mitigation strategies are fielded.

In a report from 1967, techniques included various methods of applying liquid nitrogen, dry ice, and water to nuclear-caused fires. The report considered attempting to stop the spread of fires by creating firebreaks by blasting combustible material out of an area, possibly even using nuclear weapons, along with the use of preventative Hazard Reduction Burns. According to the report, one of the most promising techniques investigated was initiation of rain from seeding of mass-fire thunderheads and other clouds passing over the developing, and then stable, firestorm.

In Feeding Everyone No Matter What, under the worst-case scenario predictions of nuclear winter, the authors present various unconventional food possibilities including; natural-gas-digesting bacteria the most well known being Methylococcus capsulatus, that is presently used as a feed in Fish farming, Bark bread a long-standing famine food utilizing the edible inner bark of trees and part of Scandinavian history during the Little Ice Age, mention is similarly given to increased fungiculture or mushrooms such as the honey fungi that grow directly on moist wood without sunlight, and variations of wood or cellulosic biofuel production, which typically already creates edible sugars/xylitol from inedible cellulose, as an intermediate product before the final step of alcohol generation. One author, mechanical engineer David Denkenberger, states that mushrooms could theoretically feed everyone for three years. Seaweed, like mushrooms, can also grow in low-light conditions. Dandelions and tree needles could provide Vitamin C, and bacteria could provide Vitamin E. More conventional cold-weather crops such as potatoes might get sufficient sunlight at the equator to remain feasible.

The minimum annual global wheat storage is approximately 2 months. To feed everyone despite nuclear winter, years of food storage prior to the event has been proposed. While the suggested masses of preserved food would likely never get used as a nuclear winter is comparatively unlikely to occur, the stockpiling of food would have the positive result of ameliorating the effect of the far more frequent disruptions to regional food supplies caused by lower-level conflicts and droughts. There is however the danger that if a sudden rush to food stockpiling occurs without the buffering effect offered by Victory gardens etc., it may exacerbate current food security problems by elevating present food prices.

Despite the name "nuclear winter", nuclear events are not necessary to produce the modeled climatic effect. In an effort to find a quick and cheap solution to the global warming projection of at least 2 ˚C of surface warming as a result of the doubling in CO levels within the atmosphere, through solar radiation management (a form of climate engineering) the underlying nuclear winter effect has been looked at as perhaps holding potential. Besides the more common suggestion to inject sulfur compounds into the stratosphere to approximate the effects of a volcanic winter, the injection of other chemical species such as the release of a particular type of soot particle to create minor "nuclear winter" conditions, has been proposed by Paul Crutzen and others. According to the threshold "nuclear winter" computer models, if one to five teragrams of firestorm-generated soot is injected into the low stratosphere, it is modeled, through the anti-greenhouse effect, to heat the stratosphere but cool the lower troposphere and produce 1.25 °C cooling for two to three years; and after 10 years, average global temperatures would still be 0.5 °C lower than before the soot injection.

Similar climatic effects to "nuclear winter" followed historical supervolcano eruptions, which plumed sulfate aerosols high into the stratosphere, with this being known as a volcanic winter. The effects of smoke in the atmosphere (short wave absorption) are sometimes termed an 'antigreenhouse' effect, and a strong analog is the hazy atmosphere of Titan. Pollack, Toon and others were involved in developing models of Titan's climate in the late 1980s, at the same time as their early nuclear winter studies.

Similarly, extinction-level comet and asteroid impacts are also believed to have generated impact winters by the pulverization of massive amounts of fine rock dust. This pulverized rock can also produce "volcanic winter" effects, if sulfate-bearing rock is hit in the impact and lofted high into the air, and "nuclear winter" effects, with the heat of the heavier rock ejecta igniting regional and possibly even global forest firestorms.

This global "impact firestorms" hypothesis, initially supported by Wolbach, H. Jay Melosh and Owen Toon, suggests that as a result of massive impact events, the small sand-grain-sized ejecta fragments created can meteorically re-enter the atmosphere forming a hot blanket of global debris high in the air, potentially turning the entire sky red-hot for minutes to hours, and with that, burning the complete global inventory of above-ground carbonaceous material, including rain forests. This hypothesis is suggested as a means to explain the severity of the Cretaceous–Paleogene extinction event, as the earth impact of an asteroid about 10 km wide which precipitated the extinction is not regarded as sufficiently energetic to have caused the level of extinction from the initial impact's energy release alone.

The global firestorm winter, however, has been questioned in more recent years (2003–2013) by Claire Belcher, Tamara Goldin and Melosh, who had initially supported the hypothesis, with this re-evaluation being dubbed the "Cretaceous-Palaeogene firestorm debate" by Belcher. The issues raised by these scientists in the debate are the perceived low quantity of soot in the sediment beside the fine-grained iridium-rich asteroid dust layer, if the quantity of re-entering ejecta was perfectly global in blanketing the atmosphere, and if so, the duration and profile of the re-entry heating, whether it was a high thermal pulse of heat or the more prolonged and therefore more incendiary "oven" heating, and finally, how much the "self-shielding effect" from the first wave of now-cooled meteors in dark flight contributed to diminishing the total heat experienced on the ground from later waves of meteors.

In part due to the Cretaceous period being a high-atmospheric-oxygen era, with concentrations above that of the present day. Owen Toon et al. in 2013 were critical of the re-evaluations the hypothesis is undergoing.

It is difficult to successfully ascertain the percentage contribution of the soot in this period's geological sediment record from living plants and fossil fuels present at the time, in much the same manner that the fraction of the material ignited directly by the meteor impact is difficult to determine.






</doc>
<doc id="22172" url="https://en.wikipedia.org/wiki?curid=22172" title="Ode">
Ode

An ode (from ) is a type of lyrical stanza. It is an elaborately structured poem praising or glorifying an event or individual, describing nature intellectually as well as emotionally. A classic ode is structured in three major parts: the "strophe", the "antistrophe", and the "epode". Different forms such as the "homostrophic ode" and the "irregular ode" also enter.

Greek odes were originally poetic pieces performed with musical accompaniment. As time passed on, they gradually became known as personal lyrical compositions whether sung (with or without musical instruments) or merely recited (always with accompaniment). The primary instruments used were the aulos and the lyre (the latter was the most revered instrument to the ancient Greeks).

There are three typical forms of odes: the Pindaric, Horatian, and irregular. Pindaric odes follow the form and style of Pindar. Horatian odes follow conventions of Horace; the odes of Horace deliberately imitated the Greek lyricists such as Alcaeus and Anacreon. Irregular odes use rhyme, but not the three-part form of the Pindaric ode, nor the two- or four-line stanza of the Horatian ode. The ode is a lyric poem. It conveys exalted and inspired emotions. It is a lyric in an elaborate form, expressed in a language that is imaginative, dignified and sincere. Like the lyric, an ode is of Greek origin.

The lyrics can be on various themes. The earliest odes in the English language, using the word in its strict form, were the "Epithalamium" and "Prothalamium" of Edmund Spenser.

In the 17th century, the most important original odes in English were by Abraham Cowley. These were iambic, but had irregular line length patterns and rhyme schemes. Cowley based the principle of his Pindariques on an apparent misunderstanding of Pindar's metrical practice but, nonetheless, others widely imitated his style, with notable success by John Dryden.

With Pindar's metre being better understood in the 18th century, the fashion for Pindaric odes faded, though there are notable actual Pindaric odes by Thomas Gray, "The Progress of Poesy" and "The Bard".

<poem>
There was a time when meadow, grove, and stream,
The earth, and every common sight,
To me did seem
Apparelled in celestial light,
The glory and the freshness of a dream.
It is not now as it hath been of yore;—
Turn wheresoe'er I may,
By night or day,
The things which I have seen I now can see no more...
Our birth is but a sleep and a forgetting:
The Soul that rises with us, our life's Star,
Hath had elsewhere its setting,
And cometh from afar:
Not in entire forgetfulness,
And not in utter nakedness,
But trailing clouds of glory do we come
From God, who is our home...
</poem>

Around 1800, William Wordsworth revived Cowley's Pindarick for one of his finest poems, the "" ode. Others also wrote odes: Samuel Taylor Coleridge, John Keats, and Percy Bysshe Shelley who wrote odes with regular stanza patterns. Shelley's "Ode to the West Wind", written in fourteen line terza rima stanzas, is a major poem in the form. Perhaps the greatest odes of the 19th century, however, were Keats's "Five Great Odes of 1819", which included "Ode to a Nightingale", "Ode on Melancholy", "Ode on a Grecian Urn", "Ode to Psyche", and "To Autumn". After Keats, there have been comparatively few major odes in English. One major exception is the fourth verse of the poem "For the Fallen" by Laurence Binyon, which is often known as "The Ode to the Fallen", or simply as "The Ode".

W.H. Auden also wrote "Ode", one of the most popular poems from his earlier career when he lived in London, in opposition to people's ignorance over the reality of war. In an interview, Auden once stated that he had intended to title the poem "My Silver Age" in mockery of England's supposed imperial golden age, however chose "Ode" as it seemed to provide a more sensitive exploration of warfare.

"Ode on a Grecian Urn", while an ekphrasis, also functions as an ode to the artistic beauty the narrator observes. The English ode's most common rhyme scheme is ABABCDECDE.
As with the Ancient Greek odes, English odes of the 17th and 18th centuries were occasionally set to music. Composers such as Purcell, Händel and Boyce all set English odes to music.



</doc>
<doc id="22189" url="https://en.wikipedia.org/wiki?curid=22189" title="Temple of Olympian Zeus, Athens">
Temple of Olympian Zeus, Athens

The Temple of Olympian Zeus (, ), also known as the Olympieion or Columns of the Olympian Zeus, is a former colossal temple at the center of the Greek capital Athens. It was dedicated to "Olympian" Zeus, a name originating from his position as head of the Olympian gods. Construction began in the 6th century BC during the rule of the Athenian tyrants, who envisaged building the greatest temple in the ancient world, but it was not completed until the reign of the Roman Emperor Hadrian in the 2nd century AD, some 638 years after the project had begun. During the Roman period the temple, which included 104 colossal columns, was renowned as the largest temple in Greece and housed one of the largest cult statues in the ancient world.

The temple's glory was short-lived, as it fell into disuse after being pillaged during a barbarian invasion in 267 AD, just about a century after its completion. It was probably never repaired and was reduced to ruins thereafter. In the centuries after the fall of the Roman Empire, it was extensively quarried for building materials to supply building projects elsewhere in the city. Despite that, a substantial part of the temple remains today, notably sixteen of the original gigantic columns, and it continues to be part of a very important archaeological site of Greece.

The temple is located approximately south-east of the Acropolis, and about south of the center of Athens, Syntagma Square. Its foundations were laid on the site of an ancient outdoor sanctuary dedicated to Zeus. An earlier temple had stood there, constructed by the tyrant Peisistratus around 550 BC. The building was demolished after the death of Peisistratos and the construction of a colossal new Temple of Olympian Zeus was begun around 520 BC by his sons, Hippias and Hipparchos. 
They sought to surpass two famous contemporary temples, the Heraion of Samos and the second Temple of Artemis at Ephesus. Designed by the architects Antistates, Callaeschrus, Antimachides and Phormos, the Temple of Olympian Zeus was intended to be built of local limestone in the Doric style on a colossal platform measuring by . It was to be flanked by a double colonnade of eight columns across the front and back and twenty-one on the flanks, surrounding the cella. 

The work was abandoned when the tyranny was overthrown and Hippias was expelled in 510 BC. Only the platform and some elements of the columns had been completed by that point, and the temple remained in that state for 336 years. The temple was left unfinished during the years of Athenian democracy, apparently, because the Greeks thought it was hubris to build on such a scale. In his treatise "Politics", Aristotle cited the temple as an example of how tyrannies engaged the populace in great works for the state (like a white elephant) and left them no time, energy or means to rebel.
It was not until 174 BC that the Seleucid king Antiochus IV Epiphanes, who presented himself as the earthly embodiment of Zeus, revived the project and placed the Roman architect Decimus Cossutius in charge. The design was changed to have three rows of eight columns across the front and back of the temple and a double row of twenty on the flanks, for a total of 104 columns. The columns would stand high and in diameter. The building material was changed to the expensive but high-quality Pentelic marble and the order was changed from Doric to Corinthian, marking the first time that this order had been used on the exterior of a major temple. However, the project ground to a halt again in 164 BC with the death of Antiochus. The temple was still only half-finished by that stage.
Serious damage was inflicted on the partly built temple by Lucius Cornelius Sulla's sack of Athens in 86 BC. While looting the city, Sulla seized some of the incomplete columns and transported them back to Rome, where they were re-used in the Temple of Jupiter on the Capitoline Hill. A half-hearted attempt was made to complete the temple during Augustus' reign as the first Roman emperor, but it was not until the accession of Hadrian in the 2nd century AD that the project was finally completed around 638 years after it had begun.

In 124–125 AD, when the strongly Philhellene Hadrian visited Athens, a massive building programme was begun that included the completion of the Temple of Olympian Zeus. A walled marble-paved precinct was constructed around the temple, making it a central focus of the ancient city. Cossutius' design was used with few changes and the temple was formally dedicated by Hadrian in 132, who took the title of "Panhellenios" in commemoration of the occasion. The temple and the surrounding precinct were adorned with numerous statues depicting Hadrian, the gods, and personifications of the Roman provinces. A colossal statue of Hadrian was raised behind the building by the people of Athens in honor of the emperor's generosity. An equally colossal chryselephantine statue of Zeus occupied the cella of the temple. The statue's form of construction was unusual, as the use of chryselephantine was by this time regarded as archaic. It has been suggested that Hadrian was deliberately imitating Phidias' famous statue of Athena Parthenos in the Parthenon, seeking to draw attention to the temple and himself by doing so.

Pausanias describes the temple as it was in the 2nd century: 

The Temple of Olympian Zeus was badly damaged during the sack of Athens by the Heruli in 267 AD. It is unlikely to have been repaired, given the extent of the damage to the rest of the city. Assuming that it was not abandoned it would certainly have been closed down in 425 by the Christian Emperor Theodosius II, when he prohibited the worship of the old Roman and Greek gods during the persecution of pagans in the late Roman Empire. Material from the (presumably now ruined) building was incorporated into a basilica constructed nearby during the 5th or 6th century.

Over the following centuries, the temple was systematically quarried to provide building materials and material for the houses and churches of medieval Athens. By the end of the Byzantine period, it had been almost totally destroyed; when Ciriaco de' Pizzicolli (Cyriacus of Ancona) visited Athens in 1436 he found only 21 of the original 104 columns still standing. 
The fate of one of the columns is recorded by a Greek inscription on one of the surviving columns, which states that "on 27 April 1759 he pulled down the column". This refers to the Turkish governor of Athens, Mustapha Agha Tzistarakis, who is recorded by a chronicler as having "destroyed one of Hadrian's columns with gunpowder" in order to re-use the marble to make plaster for the Tzistarakis Mosque that he was building in the Monastiraki district of the city. During the Ottoman period the temple was known to the Greeks as the Palace of Hadrian, while the Turks called it the Palace of Belkis, from a Turkish legend that the temple had been the residence of Solomon's wife.
Fifteen columns remain standing today and a sixteenth column lies on the ground where it fell during a storm in 1852. Nothing remains of the cella or the great statue that it once housed.

The temple was excavated in 1889–1896 by Francis Penrose of the British School in Athens (who also played a leading role in the restoration of the Parthenon), in 1922 by the German archaeologist Gabriel Welter and in the 1960s by Greek archaeologists led by Ioannes Travlos. The temple, along with the surrounding ruins of other ancient structures, is a historical precinct administered by Ephorate of Antiquities of the Greek Interior Ministry.

Today, the temple is an open-air museum, part of the unification of the archaeological sites of Athens. As a historical site it is protected and supervised by the Ephorate of Antiquities.

On 21 January 2007, a group of Greek pagans held a ceremony honoring Zeus on the grounds of the temple. The event was organized by Ellinais, an organization which won a court battle to obtain recognition for Ancient Greek religious practices in the fall of 2006.

On June 28, 2001, Vangelis organized the Mythodea Chorus at the Temple of Olympian Zeus in the context of NASA's Mars mission. Soprano Jessie Norman and Kathleen Battle participated in the concert. The concert was covered by 20 television networks from America, Australia, Canada, Japan and European countries, under the direction of Irish filmmaker Declan Looney. The chorus arrangement brought thousands of people inside the Olympic venues, and outside the temple, into the empty streets of Athens. Joined by Jessie Norman were soprano Kathleen Battle, the London Metropolitan Orchestra and the Greek National Opera, as well as over a hundred people dressed in ancient Greek clothing. The screen mounted at the Olympia connected visual images of ancient Greek performances - vases, frescoes and statues - that invested music with images of the planet Mars.





</doc>
<doc id="22190" url="https://en.wikipedia.org/wiki?curid=22190" title="Organic electronics">
Organic electronics

Organic electronics is a field of materials science concerning the design, synthesis, characterization, and application of organic molecules or polymers that show desirable electronic properties such as conductivity. Unlike conventional inorganic conductors and semiconductors, organic electronic materials are constructed from organic (carbon-based) molecules or polymers using synthetic strategies developed in the context of organic chemistry and polymer chemistry. 

One of the promised benefits of organic electronics is their potential low cost compared to traditional electronics. Attractive properties of polymeric conductors include their electrical conductivity (which can be varied by the concentrations of dopants) and comparatively high mechanical flexibility. Some have high thermal stability.

One class of materials of interest in organic electronics are electrical conductive, i.e. substances that can transmit electrical charges with low resistivity. Traditionally, conductive materials are inorganic. Classical (and still technologically dominant) conductive materials are metals such as copper and aluminum as well as many alloys.

The earliest reported organic conductive material, polyaniline, was described by Henry Letheby in 1862. Work on other polymeric organic materials began in earnest in the 1960s, A high conductivity of 1 S/cm (S = Siemens) was reported in 1963 for a derivative of tetraiodopyrrole. In 1977, it was discovered that polyacetylene can be oxidized with halogens to produce conducting materials from either insulating or semiconducting materials. The 2000 Nobel Prize in Chemistry was awarded to Alan J. Heeger, Alan G. MacDiarmid, and Hideki Shirakawa jointly for their work on conductive polymers. These and many other workers identified large families of electrically conducting polymers including polythiophene, polyphenylene sulfide, and others.

In the 1950s, a second class of electric conductors were discovered based on charge-transfer salts. Early examples were derivatives of polycyclic aromatic compounds. For example, pyrene was shown to form semiconducting charge-transfer complex salts with halogens. In 1972, researchers found metallic conductivity (conductivity comparable to a metal) in the charge-transfer complex TTF-TCNQ.

Conductive plastics have undergone development for applications in industry. In 1987, the first organic diode was produced at Eastman Kodak by Ching W. Tang and Steven Van Slyke.

The initial characterization of the basic properties of polymer light emitting diodes, demonstrating that the light emission phenomenon was injection electroluminescence and that the frequency response was sufficiently fast to permit video display applications, was reported by Bradley, Burroughes, Friend, et al. in a 1990 Nature paper. Moving from molecular to macromolecular materials solved the problems previously encountered with the long-term stability of the organic films and enabled high-quality films to be easily made. Subsequent research developed multilayer polymers and the new field of plastic electronics and organic light-emitting diodes (OLED) research and device production grew rapidly.

Organic conductive materials can be grouped into two main classes: conductive polymers and conductive molecular solids and salts.

Semiconducting small molecules include polycyclic aromatic compounds such as pentacene and rubrene.

Conductive polymers are often typically intrinsically conductive or at least semiconductors. They sometimes show mechanical properties comparable to those of conventional organic polymers. Both organic synthesis and advanced dispersion techniques can be used to tune the electrical properties of conductive polymers, unlike typical inorganic conductors. The most well-studied class of conductive polymers include polyacetylene, polypyrrole, polyaniline, and their copolymers. Poly(p-phenylene vinylene) and its derivatives are used for electroluminescent semiconducting polymers. Poly(3-alkythiophenes) are also a typical material for use in solar cells and transistors.

An OLED (organic light-emitting diode) consists of a thin film of organic material that emits light under stimulation by an electric current. A typical OLED consists of an anode, a cathode, OLED organic material and a conductive layer.

André Bernanose was the first person to observe electroluminescence in organic materials, and Ching W. Tang, reported fabrication of an OLED device in 1987. The OLED device incorporated a double-layer structure motif consisting of separate hole transporting and electron-transporting layers, with light emission taking place in between the two layers. Their discovery opened a new era of current OLED research and device design.

OLED organic materials can be divided into two major families: small-molecule-based and polymer-based. Small molecule OLEDs (SM-OLEDs) include organometallic chelates(Alq3), fluorescent and phosphorescent dyes, and conjugated dendrimers. Fluorescent dyes can be selected according to the desired range of emission wavelengths; compounds like perylene and rubrene are often used. Very recently, Dr. Kim J. et al. at University of Michigan reported a pure organic light emitting crystal, Br6A, by modifying its halogen bonding, they succeeded in tuning the phosphorescence to different wavelengths including green, blue and red. By modifying the structure of Br6A, scientists are attempting to achieve a next generation organic light emitting diode. Devices based on small molecules are usually fabricated by thermal evaporation under vacuum. While this method enables the formation of well-controlled homogeneous film; is hampered by high cost and limited scalability.
Polymer light-emitting diodes (PLEDs), similar to SM-OLED, emit light under an applied electric current. Polymer-based OLEDs are generally more efficient than SM-OLEDs requiring a comparatively lower amount of energy to produce the same luminescence. Common polymers used in PLEDs include derivatives of poly(p-phenylene vinylene) and polyfluorene. The emitted color can be tuned by substitution of different side chains onto the polymer backbone or modifying the stability of the polymer. In contrast to SM-OLEDs, polymer-based OLEDs cannot be fabricated through vacuum evaporation, and must instead be processed using solution-based techniques. Compared to thermal evaporation, solution based methods are more suited to creating films with large dimensions. Zhenan Bao. et al. at Stanford University reported a novel way to construct large-area organic semiconductor thin films using aligned single crystalline domains.

An Organic field-effect transistor is a field-effect transistor utilizing organic molecules or polymers as the active semiconducting layer. A field-effect transistor (FET) is any semiconductor material that utilizes electric field to control the shape of a channel of one type of charge carrier, thereby changing its conductivity. Two major classes of FET are n-type and p-type semiconductor, classified according to the charge type carried. In the case of organic FETs (OFETs), p-type OFET compounds are generally more stable than n-type due to the susceptibility of the latter to oxidative damage.

J.E. Lilienfeld first proposed the field-effect transistor in 1930, but the first OFET was not reported until 1987, when Koezuka et al. constructed one using Polythiophene which shows extremely high conductivity. Other conductive polymers have been shown to act as semiconductors, and newly synthesized and characterized compounds are reported weekly in prominent research journals. Many review articles exist documenting the development of these materials.

Like OLEDs, OFETs can be classified into small-molecule and polymer-based system. Charge transport in OFETs can be quantified using a measure called carrier mobility; currently, rubrene-based OFETs show the highest carrier mobility of 20–40 cm/(V·s). Another popular OFET material is Pentacene. Due to its low solubility in most organic solvents, it's difficult to fabricate thin film transistors (TFTs) from pentacene itself using conventional spin-cast or, dip coating methods, but this obstacle can be overcome by using the derivative TIPS-pentacene. Current research focuses more on thin-film transistor (TFT) model, which eliminates the usage of conductive materials. Very recently, two studies conducted by Dr. Bao Z. et al. and Dr. Kim J. et al. demonstrated control over the formation of designed thin-film transistors. By controlling the formation of crystalline TFT, it is possible to create an aligned (as opposed to randomly ordered) charge transport pathway, resulting in enhanced charge mobility.

Organic solar cells could cut the cost of solar power by making use of inexpensive organic polymers rather than the expensive crystalline silicon used in most solar cells. What's more, the polymers can be processed using low-cost equipment such as ink-jet printers or coating equipment employed to make photographic film, which reduces both capital and operating costs compared with conventional solar-cell manufacturing.

Silicon thin-film solar cells on flexible substrates allow a significant cost reduction of large-area photovoltaics for several reasons:


Inexpensive polymeric substrates like polyethylene terephthalate (PET) or polycarbonate (PC) have the potential for further cost reduction in photovoltaics. Protomorphous solar cells prove to be a promising concept for efficient and low-cost photovoltaics on cheap and flexible substrates for large-area production as well as small and mobile applications.

One advantage of printed electronics is that different electrical and electronic components can be printed on top of each other, saving space and increasing reliability and sometimes they are all transparent. One ink must not damage another, and low temperature annealing is vital if low-cost flexible materials such as paper and plastic film are to be used. There is much sophisticated engineering and chemistry involved here, with iTi, Pixdro, Asahi Kasei, Merck & Co.|Merck, BASF, HC Starck, Hitachi Chemical and Frontier Carbon Corporation among the leaders.
Electronic devices based on organic compounds are now widely used, with many new products under development. Sony reported the first full-color, video-rate, flexible, plastic display made purely of organic materials; television screen based on OLED materials; biodegradable electronics based on organic compound and low-cost organic solar cell are also available.

There are important differences between the processing of small molecule organic semiconductors and semiconducting polymers. Small molecule semiconductors are quite often insoluble and typically require deposition via vacuum sublimation. While usually thin films of soluble conjugated polymers. Devices based on conductive polymers can be prepared by solution processing methods. Both solution processing and vacuum based methods produce amorphous and polycrystalline films with variable degree of disorder. "Wet" coating techniques require polymers to be dissolved in a volatile solvent, filtered and deposited onto a substrate. Common examples of solvent-based coating techniques include drop casting, spin-coating, doctor-blading, inkjet printing and screen printing. Spin-coating is a widely used technique for small area thin film production. It may result in a high degree of material loss. The doctor-blade technique results in a minimal material loss and was primarily developed for large area thin film production. Vacuum based thermal deposition of small molecules requires evaporation of molecules from a hot source. The molecules are then transported through vacuum onto a substrate. The process of condensing these molecules on the substrate surface results in thin film formation. Wet coating techniques can in some cases be applied to small molecules depending on their solubility.

Compared to conventional inorganic solar cell, organic solar cells have the advantage of lower fabrication cost. An organic solar cell is a device that uses organic electronics to convert light into electricity. Organic solar cells utilize organic photovoltaic materials, organic semiconductor diodes that convert light into electricity. Figure to the right shows five commonly used organic photovoltaic materials. Electrons in these organic molecules can be delocalized in a delocalized π orbital with a corresponding π* antibonding orbital. The difference in energy between the π orbital, or highest occupied molecular orbital(HOMO), and π* orbital, or lowest unoccupied molecular orbital(LUMO) is called the band gap of organic photovoltaic materials. Typically, the band gap lies in the range of 1-4eV.

The difference in the band gap of organic photovoltaic materials leads to different chemical structures and forms of organic solar cells. Different forms of solar cells includes single-layer organic photovoltaic cells, bilayer organic photovoltaic cells and heterojunction photovoltaic cells. However, all three of these types of solar cells share the approach of sandwiching the organic electronic layer between two metallic conductors, typically indium tin oxide.
An organic field-effect transistor device consists of three major components: the source, the drain and the gate. Generally, a field-effect transistor has two plates, source in contact with drain and the gate respectively, working as conducting channel. The electrons move from source to the drain, and the gate serves to control the electrons' movement from source to drain. Different types of FETs are designed based on carrier properties. Thin film transistor (TFT), among them, is an easy fabricating one. In a thin film transistor, the source and drain are made by directly depositing a thin layer of semiconductor followed by a thin film of insulator between semiconductor and the metal gate contact. Such a thin film is made by either thermal evaporation, or simply spin coating. In a TFT device, there is no carrier movement between the source and drain. After applying a positive charge, accumulation of electrons on the interface cause bending of the semiconductor and ultimately lowers the conduction band with regards to the Fermi-level of the semiconductor. Finally, a highly conductive channel is formed at the interface.

Conductive polymers are lighter, more flexible, and less expensive than inorganic conductors. This makes them a desirable alternative in many applications. It also creates the possibility of new applications that would be impossible using copper or silicon.

Organic electronics not only includes organic semiconductors, but also organic dielectrics, conductors and light emitters.

New applications include smart windows and electronic paper. Conductive polymers are expected to play an important role in the emerging science of molecular computers.




</doc>
<doc id="22194" url="https://en.wikipedia.org/wiki?curid=22194" title="Operating system">
Operating system

An operating system (OS) is system software that manages computer hardware, software resources, and provides common services for computer programs.

Time-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, printing, and other resources.

For hardware functions such as input and output and memory allocation, the operating system acts as an intermediary between programs and the computer hardware, although the application code is usually executed directly by the hardware and frequently makes system calls to an OS function or is interrupted by it. Operating systems are found on many devices that contain a computer from cellular phones and video game consoles to web servers and supercomputers.

The dominant desktop operating system is Microsoft Windows with a market share of around 82.74%. macOS by Apple Inc. is in second place (13.23%), and the varieties of Linux are collectively in third place (1.57%). In the mobile sector (including smartphones and tablets), Android's share is up to 70% in the year 2017. According to third quarter 2016 data, Android's share on smartphones is dominant with 87.5 percent with also a growth rate of 10.3 percent per year, followed by Apple's iOS with 12.1 percent with per year decrease in market share of 5.2 percent, while other operating systems amount to just 0.3 percent. Linux distributions are dominant in the server and supercomputing sectors. Other specialized classes of operating systems, such as embedded and real-time systems, exist for many applications.

A single-tasking system can only run one program at a time, while a multi-tasking operating system allows more than one program to be running in concurrency. This is achieved by time-sharing, where the available processor time is divided between multiple processes. These processes are each interrupted repeatedly in time slices by a task-scheduling subsystem of the operating system. Multi-tasking may be characterized in preemptive and co-operative types. In preemptive multitasking, the operating system slices the CPU time and dedicates a slot to each of the programs. Unix-like operating systems, such as Solaris and Linux—as well as non-Unix-like, such as AmigaOS—support preemptive multitasking. Cooperative multitasking is achieved by relying on each process to provide time to the other processes in a defined manner. 16-bit versions of Microsoft Windows used cooperative multi-tasking; 32-bit versions of both Windows NT and Win9x used preemptive multi-tasking.

Single-user operating systems have no facilities to distinguish users, but may allow multiple programs to run in tandem. A multi-user operating system extends the basic concept of multi-tasking with facilities that identify processes and resources, such as disk space, belonging to multiple users, and the system permits multiple users to interact with the system at the same time. Time-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, printing, and other resources to multiple users.

A distributed operating system manages a group of distinct, networked computers and makes them appear to be a single computer, as all computations are distributed (divided amongst the constituent computers).

In the distributed and cloud computing context of an OS, "templating" refers to creating a single virtual machine image as a guest operating system, then saving it as a tool for multiple running virtual machines. The technique is used both in virtualization and cloud computing management, and is common in large server warehouses.

Embedded operating systems are designed to be used in embedded computer systems. They are designed to operate on small machines with less autonomy (e.g. PDAs). They are very compact and extremely efficient by design, and are able to operate with a limited amount of resources. Windows CE and Minix 3 are some examples of embedded operating systems.

A real-time operating system is an operating system that guarantees to process events or data by a specific moment in time. A real-time operating system may be single- or multi-tasking, but when multitasking, it uses specialized scheduling algorithms so that a deterministic nature of behavior is achieved. Such an event-driven system switches between tasks based on their priorities or external events, whereas time-sharing operating systems switch tasks based on clock interrupts.

A library operating system is one in which the services that a typical operating system provides, such as networking, are provided in the form of libraries and composed with the application and configuration code to construct a unikernel: a specialized, single address space, machine image that can be deployed to cloud or embedded environments.

Early computers were built to perform a series of single tasks, like a calculator. Basic operating system features were developed in the 1950s, such as resident monitor functions that could automatically run different programs in succession to speed up processing. Operating systems did not exist in their modern and more complex forms until the early 1960s. Hardware features were added, that enabled use of runtime libraries, interrupts, and parallel processing. When personal computers became popular in the 1980s, operating systems were made for them similar in concept to those used on larger computers.

In the 1940s, the earliest electronic digital systems had no operating systems. Electronic systems of this time were programmed on rows of mechanical switches or by jumper wires on plugboards. These were special-purpose systems that, for example, generated ballistics tables for the military or controlled the printing of payroll checks from data on punched paper cards. After programmable general purpose computers were invented, machine languages(consisting of strings of the binary digits 0 and 1 on punched paper tape) were introduced that sped up the programming process (Stern, 1981).
In the early 1950s, a computer could execute only one program at a time. Each user had sole use of the computer for a limited period and would arrive at a scheduled time with their program and data on punched paper cards or punched tape. The program would be loaded into the machine, and the machine would be set to work until the program completed or crashed. Programs could generally be debugged via a front panel using toggle switches and panel lights. It is said that Alan Turing was a master of this on the early Manchester Mark 1 machine, and he was already deriving the primitive conception of an operating system from the principles of the universal Turing machine.

Later machines came with libraries of programs, which would be linked to a user's program to assist in operations such as input and output and compiling (generating machine code from human-readable symbolic code). This was the genesis of the modern-day operating system. However, machines still ran a single job at a time. At Cambridge University in England, the job queue was at one time a washing line (clothes line) from which tapes were hung with different colored clothes-pegs to indicate job priority.

An improvement was the Atlas Supervisor. Introduced with the Manchester Atlas in 1962, it is considered by many to be the first recognisable modern operating system. Brinch Hansen described it as "the most significant breakthrough in the history of operating systems."

Through the 1950s, many major features were pioneered in the field of operating systems on mainframe computers, including batch processing, input/output interrupting, buffering, multitasking, spooling, runtime libraries, link-loading, and programs for sorting records in files. These features were included or not included in application software at the option of application programmers, rather than in a separate operating system used by all applications. In 1959, the SHARE Operating System was released as an integrated utility for the IBM 704, and later in the 709 and 7090 mainframes, although it was quickly supplanted by IBSYS/IBJOB on the 709, 7090 and 7094.

During the 1960s, IBM's OS/360 introduced the concept of a single OS spanning an entire product line, which was crucial for the success of the System/360 machines. IBM's current mainframe operating systems are distant descendants of this original system and modern machines are backwards-compatible with applications written for OS/360.

OS/360 also pioneered the concept that the operating system keeps track of all of the system resources that are used, including program and data space allocation in main memory and file space in secondary storage, and file locking during updates. When a process is terminated for any reason, all of these resources are re-claimed by the operating system.

The alternative CP-67 system for the S/360-67 started a whole line of IBM operating systems focused on the concept of virtual machines. Other operating systems used on IBM S/360 series mainframes included systems developed by IBM: COS/360 (Compatibility Operating System), DOS/360 (Disk Operating System), TSS/360 (Time Sharing System), TOS/360 (Tape Operating System), BOS/360 (Basic Operating System), and ACP (Airline Control Program), as well as a few non-IBM systems: MTS (Michigan Terminal System), MUSIC (Multi-User System for Interactive Computing), and ORVYL (Stanford Timesharing System).

Control Data Corporation developed the SCOPE operating system in the 1960s, for batch processing. In cooperation with the University of Minnesota, the Kronos and later the NOS operating systems were developed during the 1970s, which supported simultaneous batch and timesharing use. Like many commercial timesharing systems, its interface was an extension of the Dartmouth BASIC operating systems, one of the pioneering efforts in timesharing and programming languages. In the late 1970s, Control Data and the University of Illinois developed the PLATO operating system, which used plasma panel displays and long-distance time sharing networks. Plato was remarkably innovative for its time, featuring real-time chat, and multi-user graphical games.

In 1961, Burroughs Corporation introduced the B5000 with the MCP (Master Control Program) operating system. The B5000 was a stack machine designed to exclusively support high-level languages with no machine language or assembler; indeed, the MCP was the first OS to be written exclusively in a high-level language (ESPOL, a dialect of ALGOL). MCP also introduced many other ground-breaking innovations, such as being the first commercial implementation of virtual memory. During development of the AS/400, IBM made an approach to Burroughs to license MCP to run on the AS/400 hardware. This proposal was declined by Burroughs management to protect its existing hardware production. MCP is still in use today in the Unisys company's ClearPath/MCP line of computers.

UNIVAC, the first commercial computer manufacturer, produced a series of EXEC operating systems. Like all early main-frame systems, this batch-oriented system managed magnetic drums, disks, card readers and line printers. In the 1970s, UNIVAC produced the Real-Time Basic (RTB) system to support large-scale time sharing, also patterned after the Dartmouth BC system.

General Electric and MIT developed General Electric Comprehensive Operating Supervisor (GECOS), which introduced the concept of ringed security privilege levels. After acquisition by Honeywell it was renamed General Comprehensive Operating System (GCOS).

Digital Equipment Corporation developed many operating systems for its various computer lines, including TOPS-10 and TOPS-20 time sharing systems for the 36-bit PDP-10 class systems. Before the widespread use of UNIX, TOPS-10 was a particularly popular system in universities, and in the early ARPANET community. RT-11 was a single-user real-time OS for the PDP-11 class minicomputer, and RSX-11 was the corresponding multi-user OS.

From the late 1960s through the late 1970s, several hardware capabilities evolved that allowed similar or ported software to run on more than one system. Early systems had utilized microprogramming to implement features on their systems in order to permit different underlying computer architectures to appear to be the same as others in a series. In fact, most 360s after the 360/40 (except the 360/165 and 360/168) were microprogrammed implementations.

The enormous investment in software for these systems made since the 1960s caused most of the original computer manufacturers to continue to develop compatible operating systems along with the hardware. Notable supported mainframe operating systems include:


The first microcomputers did not have the capacity or need for the elaborate operating systems that had been developed for mainframes and minis; minimalistic operating systems were developed, often loaded from ROM and known as "monitors". One notable early disk operating system was CP/M, which was supported on many early microcomputers and was closely imitated by Microsoft's MS-DOS, which became widely popular as the operating system chosen for the IBM PC (IBM's version of it was called IBM DOS or PC DOS). In the 1980s, Apple Computer Inc. (now Apple Inc.) abandoned its popular Apple II series of microcomputers to introduce the Apple Macintosh computer with an innovative graphical user interface (GUI) to the Mac OS.

The introduction of the Intel 80386 CPU chip in October 1985, with 32-bit architecture and paging capabilities, provided personal computers with the ability to run multitasking operating systems like those of earlier minicomputers and mainframes. Microsoft responded to this progress by hiring Dave Cutler, who had developed the VMS operating system for Digital Equipment Corporation. He would lead the development of the Windows NT operating system, which continues to serve as the basis for Microsoft's operating systems line. Steve Jobs, a co-founder of Apple Inc., started NeXT Computer Inc., which developed the NEXTSTEP operating system. NEXTSTEP would later be acquired by Apple Inc. and used, along with code from FreeBSD as the core of Mac OS X (macOS after latest name change).

The GNU Project was started by activist and programmer Richard Stallman with the goal of creating a complete free software replacement to the proprietary UNIX operating system. While the project was highly successful in duplicating the functionality of various parts of UNIX, development of the GNU Hurd kernel proved to be unproductive. In 1991, Finnish computer science student Linus Torvalds, with cooperation from volunteers collaborating over the Internet, released the first version of the Linux kernel. It was soon merged with the GNU user space components and system software to form a complete operating system. Since then, the combination of the two major components has usually been referred to as simply "Linux" by the software industry, a naming convention that Stallman and the Free Software Foundation remain opposed to, preferring the name GNU/Linux. The Berkeley Software Distribution, known as BSD, is the UNIX derivative distributed by the University of California, Berkeley, starting in the 1970s. Freely distributed and ported to many minicomputers, it eventually also gained a following for use on PCs, mainly as FreeBSD, NetBSD and OpenBSD.

Unix was originally written in assembly language. Ken Thompson wrote B, mainly based on BCPL, based on his experience in the MULTICS project. B was replaced by C, and Unix, rewritten in C, developed into a large, complex family of inter-related operating systems which have been influential in every modern operating system (see History).

The "Unix-like" family is a diverse group of operating systems, with several major sub-categories including System V, BSD, and Linux. The name "UNIX" is a trademark of The Open Group which licenses it for use with any operating system that has been shown to conform to their definitions. "UNIX-like" is commonly used to refer to the large set of operating systems which resemble the original UNIX.

Unix-like systems run on a wide variety of computer architectures. They are used heavily for servers in business, as well as workstations in academic and engineering environments. Free UNIX variants, such as Linux and BSD, are popular in these areas.

Four operating systems are certified by The Open Group (holder of the Unix trademark) as Unix. HP's HP-UX and IBM's AIX are both descendants of the original System V Unix and are designed to run only on their respective vendor's hardware. In contrast, Sun Microsystems's Solaris can run on multiple types of hardware, including x86 and Sparc servers, and PCs. Apple's macOS, a replacement for Apple's earlier (non-Unix) Mac OS, is a hybrid kernel-based BSD variant derived from NeXTSTEP, Mach, and FreeBSD.

Unix interoperability was sought by establishing the POSIX standard. The POSIX standard can be applied to any operating system, although it was originally created for various Unix variants.

A subgroup of the Unix family is the Berkeley Software Distribution family, which includes FreeBSD, NetBSD, and OpenBSD. These operating systems are most commonly found on webservers, although they can also function as a personal computer OS. The Internet owes much of its existence to BSD, as many of the protocols now commonly used by computers to connect, send and receive data over a network were widely implemented and refined in BSD. The World Wide Web was also first demonstrated on a number of computers running an OS based on BSD called NeXTSTEP.

In 1974, University of California, Berkeley installed its first Unix system. Over time, students and staff in the computer science department there began adding new programs to make things easier, such as text editors. When Berkeley received new VAX computers in 1978 with Unix installed, the school's undergraduates modified Unix even more in order to take advantage of the computer's hardware possibilities. The Defense Advanced Research Projects Agency of the US Department of Defense took interest, and decided to fund the project. Many schools, corporations, and government organizations took notice and started to use Berkeley's version of Unix instead of the official one distributed by AT&T.

Steve Jobs, upon leaving Apple Inc. in 1985, formed NeXT Inc., a company that manufactured high-end computers running on a variation of BSD called NeXTSTEP. One of these computers was used by Tim Berners-Lee as the first webserver to create the World Wide Web.

Developers like Keith Bostic encouraged the project to replace any non-free code that originated with Bell Labs. Once this was done, however, AT&T sued. After two years of legal disputes, the BSD project spawned a number of free derivatives, such as NetBSD and FreeBSD (both in 1993), and OpenBSD (from NetBSD in 1995).

macOS (formerly "Mac OS X" and later "OS X") is a line of open core graphical operating systems developed, marketed, and sold by Apple Inc., the latest of which is pre-loaded on all currently shipping Macintosh computers. macOS is the successor to the original classic Mac OS, which had been Apple's primary operating system since 1984. Unlike its predecessor, macOS is a UNIX operating system built on technology that had been developed at NeXT through the second half of the 1980s and up until Apple purchased the company in early 1997.
The operating system was first released in 1999 as Mac OS X Server 1.0, followed in March 2001 by a client version (Mac OS X v10.0 "Cheetah"). Since then, six more distinct "client" and "server" editions of macOS have been released, until the two were merged in OS X 10.7 "Lion".

Prior to its merging with macOS, the server edition macOS Server was architecturally identical to its desktop counterpart and usually ran on Apple's line of Macintosh server hardware. macOS Server included work group management and administration software tools that provide simplified access to key network services, including a mail transfer agent, a Samba server, an LDAP server, a domain name server, and others. With Mac OS X v10.7 Lion, all server aspects of Mac OS X Server have been integrated into the client version and the product re-branded as "OS X" (dropping "Mac" from the name). The server tools are now offered as an application.

The Linux kernel originated in 1991, as a project of Linus Torvalds, while a university student in Finland. He posted information about his project on a newsgroup for computer students and programmers, and received support and assistance from volunteers who succeeded in creating a complete and functional kernel.

Linux is Unix-like, but was developed without any Unix code, unlike BSD and its variants. Because of its open license model, the Linux kernel code is available for study and modification, which resulted in its use on a wide range of computing machinery from supercomputers to smart-watches. Although estimates suggest that Linux is used on only 1.82% of all "desktop" (or laptop) PCs, it has been widely adopted for use in servers and embedded systems such as cell phones. Linux has superseded Unix on many platforms and is used on most supercomputers including the top 385. Many of the same computers are also on Green500 (but in different order), and Linux runs on the top 10. Linux is also commonly used on other small energy-efficient computers, such as smartphones and smartwatches. The Linux kernel is used in some popular distributions, such as Red Hat, Debian, Ubuntu, Linux Mint and Google's Android, Chrome OS, and Chromium OS.

Microsoft Windows is a family of proprietary operating systems designed by Microsoft Corporation and primarily targeted to Intel architecture based computers, with an estimated 88.9 percent total usage share on Web connected computers. The latest version is Windows 10.

In 2011, Windows 7 overtook Windows XP as most common version in use.

Microsoft Windows was first released in 1985, as an operating environment running on top of MS-DOS, which was the standard operating system shipped on most Intel architecture personal computers at the time. In 1995, Windows 95 was released which only used MS-DOS as a bootstrap. For backwards compatibility, Win9x could run real-mode MS-DOS and 16-bit Windows 3.x drivers. Windows ME, released in 2000, was the last version in the Win9x family. Later versions have all been based on the Windows NT kernel. Current client versions of Windows run on IA-32, x86-64 and 32-bit ARM microprocessors. In addition Itanium is still supported in older server version Windows Server 2008 R2. In the past, Windows NT supported additional architectures.

Server editions of Windows are widely used. In recent years, Microsoft has expended significant capital in an effort to promote the use of Windows as a server operating system. However, Windows' usage on servers is not as widespread as on personal computers as Windows competes against Linux and BSD for server market share.

ReactOS is a Windows-alternative operating system, which is being developed on the principles of Windows without using any of Microsoft's code.

There have been many operating systems that were significant in their day but are no longer so, such as AmigaOS; OS/2 from IBM and Microsoft; classic Mac OS, the non-Unix precursor to Apple's macOS; BeOS; XTS-300; RISC OS; MorphOS; Haiku; BareMetal and FreeMint. Some are still used in niche markets and continue to be developed as minority platforms for enthusiast communities and specialist applications. OpenVMS, formerly from DEC, is still under active development by VMS Software Inc. Yet other operating systems are used almost exclusively in academia, for operating systems education or to do research on operating system concepts. A typical example of a system that fulfills both roles is MINIX, while for example Singularity is used purely for research. Another example is the Oberon System designed at ETH Zürich by Niklaus Wirth, Jürg Gutknecht and a group of students at the former Computer Systems Institute in the 1980s. It was used mainly for research, teaching, and daily work in Wirth's group.

Other operating systems have failed to win significant market share, but have introduced innovations that have influenced mainstream operating systems, not least Bell Labs' Plan 9.

The components of an operating system all exist in order to make the different parts of a computer work together. All user software needs to go through the operating system in order to use any of the hardware, whether it be as simple as a mouse or keyboard or as complex as an Internet component.

With the aid of the firmware and device drivers, the kernel provides the most basic level of control over all of the computer's hardware devices. It manages memory access for programs in the RAM, it determines which programs get access to which hardware resources, it sets up or resets the CPU's operating states for optimal operation at all times, and it organizes the data for long-term non-volatile storage with file systems on such media as disks, tapes, flash memory, etc.

The operating system provides an interface between an application program and the computer hardware, so that an application program can interact with the hardware only by obeying rules and procedures programmed into the operating system. The operating system is also a set of services which simplify development and execution of application programs. Executing an application program involves the creation of a process by the operating system kernel which assigns memory space and other resources, establishes a priority for the process in multi-tasking systems, loads program binary code into memory, and initiates execution of the application program which then interacts with the user and with hardware devices.

Interrupts are central to operating systems, as they provide an efficient way for the operating system to interact with and react to its environment. The alternative having the operating system "watch" the various sources of input for events (polling) that require action can be found in older systems with very small stacks (50 or 60 bytes) but is unusual in modern systems with large stacks. Interrupt-based programming is directly supported by most modern CPUs. Interrupts provide a computer with a way of automatically saving local register contexts, and running specific code in response to events. Even very basic computers support hardware interrupts, and allow the programmer to specify code which may be run when that event takes place.

When an interrupt is received, the computer's hardware automatically suspends whatever program is currently running, saves its status, and runs computer code previously associated with the interrupt; this is analogous to placing a bookmark in a book in response to a phone call. In modern operating systems, interrupts are handled by the operating system's kernel. Interrupts may come from either the computer's hardware or the running program.

When a hardware device triggers an interrupt, the operating system's kernel decides how to deal with this event, generally by running some processing code. The amount of code being run depends on the priority of the interrupt (for example: a person usually responds to a smoke detector alarm before answering the phone). The processing of hardware interrupts is a task that is usually delegated to software called a device driver, which may be part of the operating system's kernel, part of another program, or both. Device drivers may then relay information to a running program by various means.

A program may also trigger an interrupt to the operating system. If a program wishes to access hardware, for example, it may interrupt the operating system's kernel, which causes control to be passed back to the kernel. The kernel then processes the request. If a program wishes additional resources (or wishes to shed resources) such as memory, it triggers an interrupt to get the kernel's attention.

Modern microprocessors (CPU or MPU) support multiple modes of operation. CPUs with this capability offer at least two modes: user mode and supervisor mode. In general terms, supervisor mode operation allows unrestricted access to all machine resources, including all MPU instructions. User mode operation sets limits on instruction use and typically disallows direct access to machine resources. CPUs might have other modes similar to user mode as well, such as the virtual modes in order to emulate older processor types, such as 16-bit processors on a 32-bit one, or 32-bit processors on a 64-bit one.

At power-on or reset, the system begins in supervisor mode. Once an operating system kernel has been loaded and started, the boundary between user mode and supervisor mode (also known as kernel mode) can be established.

Supervisor mode is used by the kernel for low level tasks that need unrestricted access to hardware, such as controlling how memory is accessed, and communicating with devices such as disk drives and video display devices. User mode, in contrast, is used for almost everything else. Application programs, such as word processors and database managers, operate within user mode, and can only access machine resources by turning control over to the kernel, a process which causes a switch to supervisor mode. Typically, the transfer of control to the kernel is achieved by executing a software interrupt instruction, such as the Motorola 68000 codice_1 instruction. The software interrupt causes the microprocessor to switch from user mode to supervisor mode and begin executing code that allows the kernel to take control.

In user mode, programs usually have access to a restricted set of microprocessor instructions, and generally cannot execute any instructions that could potentially cause disruption to the system's operation. In supervisor mode, instruction execution restrictions are typically removed, allowing the kernel unrestricted access to all machine resources.

The term "user mode resource" generally refers to one or more CPU registers, which contain information that the running program isn't allowed to alter. Attempts to alter these resources generally causes a switch to supervisor mode, where the operating system can deal with the illegal operation the program was attempting, for example, by forcibly terminating ("killing") the program).

Among other things, a multiprogramming operating system kernel must be responsible for managing all system memory which is currently in use by programs. This ensures that a program does not interfere with memory already in use by another program. Since programs time share, each program must have independent access to memory.

Cooperative memory management, used by many early operating systems, assumes that all programs make voluntary use of the kernel's memory manager, and do not exceed their allocated memory. This system of memory management is almost never seen any more, since programs often contain bugs which can cause them to exceed their allocated memory. If a program fails, it may cause memory used by one or more other programs to be affected or overwritten. Malicious programs or viruses may purposefully alter another program's memory, or may affect the operation of the operating system itself. With cooperative memory management, it takes only one misbehaved program to crash the system.

Memory protection enables the kernel to limit a process' access to the computer's memory. Various methods of memory protection exist, including memory segmentation and paging. All methods require some level of hardware support (such as the 80286 MMU), which doesn't exist in all computers.

In both segmentation and paging, certain protected mode registers specify to the CPU what memory address it should allow a running program to access. Attempts to access other addresses trigger an interrupt which cause the CPU to re-enter supervisor mode, placing the kernel in charge. This is called a segmentation violation or Seg-V for short, and since it is both difficult to assign a meaningful result to such an operation, and because it is usually a sign of a misbehaving program, the kernel generally resorts to terminating the offending program, and reports the error.

Windows versions 3.1 through ME had some level of memory protection, but programs could easily circumvent the need to use it. A general protection fault would be produced, indicating a segmentation violation had occurred; however, the system would often crash anyway.

The use of virtual memory addressing (such as paging or segmentation) means that the kernel can choose what memory each program may use at any given time, allowing the operating system to use the same memory locations for multiple tasks.

If a program tries to access memory that isn't in its current range of accessible memory, but nonetheless has been allocated to it, the kernel is interrupted in the same way as it would if the program were to exceed its allocated memory. (See section on memory management.) Under UNIX this kind of interrupt is referred to as a page fault.

When the kernel detects a page fault it generally adjusts the virtual memory range of the program which triggered it, granting it access to the memory requested. This gives the kernel discretionary power over where a particular application's memory is stored, or even whether or not it has actually been allocated yet.

In modern operating systems, memory which is accessed less frequently can be temporarily stored on disk or other media to make that space available for use by other programs. This is called swapping, as an area of memory can be used by multiple programs, and what that memory area contains can be swapped or exchanged on demand.

"Virtual memory" provides the programmer or the user with the perception that there is a much larger amount of RAM in the computer than is really there.

Multitasking refers to the running of multiple independent computer programs on the same computer; giving the appearance that it is performing the tasks at the same time. Since most computers can do at most one or two things at one time, this is generally done via time-sharing, which means that each program uses a share of the computer's time to execute.

An operating system kernel contains a scheduling program which determines how much time each process spends executing, and in which order execution control should be passed to programs. Control is passed to a process by the kernel, which allows the program access to the CPU and memory. Later, control is returned to the kernel through some mechanism, so that another program may be allowed to use the CPU. This so-called passing of control between the kernel and applications is called a context switch.

An early model which governed the allocation of time to programs was called cooperative multitasking. In this model, when control is passed to a program by the kernel, it may execute for as long as it wants before explicitly returning control to the kernel. This means that a malicious or malfunctioning program may not only prevent any other programs from using the CPU, but it can hang the entire system if it enters an infinite loop.

Modern operating systems extend the concepts of application preemption to device drivers and kernel code, so that the operating system has preemptive control over internal run-times as well.

The philosophy governing preemptive multitasking is that of ensuring that all programs are given regular time on the CPU. This implies that all programs must be limited in how much time they are allowed to spend on the CPU without being interrupted. To accomplish this, modern operating system kernels make use of a timed interrupt. A protected mode timer is set by the kernel which triggers a return to supervisor mode after the specified time has elapsed. (See above sections on Interrupts and Dual Mode Operation.)

On many single user operating systems cooperative multitasking is perfectly adequate, as home computers generally run a small number of well tested programs. The AmigaOS is an exception, having preemptive multitasking from its very first version. Windows NT was the first version of Microsoft Windows which enforced preemptive multitasking, but it didn't reach the home user market until Windows XP (since Windows NT was targeted at professionals).

Access to data stored on disks is a central feature of all operating systems. Computers store data on disks using files, which are structured in specific ways in order to allow for faster access, higher reliability, and to make better use of the drive's available space. The specific way in which files are stored on a disk is called a file system, and enables files to have names and attributes. It also allows them to be stored in a hierarchy of directories or folders arranged in a directory tree.

Early operating systems generally supported a single type of disk drive and only one kind of file system. Early file systems were limited in their capacity, speed, and in the kinds of file names and directory structures they could use. These limitations often reflected limitations in the operating systems they were designed for, making it very difficult for an operating system to support more than one file system.

While many simpler operating systems support a limited range of options for accessing storage systems, operating systems like UNIX and Linux support a technology known as a virtual file system or VFS. An operating system such as UNIX supports a wide array of storage devices, regardless of their design or file systems, allowing them to be accessed through a common application programming interface (API). This makes it unnecessary for programs to have any knowledge about the device they are accessing. A VFS allows the operating system to provide programs with access to an unlimited number of devices with an infinite variety of file systems installed on them, through the use of specific device drivers and file system drivers.

A connected storage device, such as a hard drive, is accessed through a device driver. The device driver understands the specific language of the drive and is able to translate that language into a standard language used by the operating system to access all disk drives. On UNIX, this is the language of block devices.

When the kernel has an appropriate device driver in place, it can then access the contents of the disk drive in raw format, which may contain one or more file systems. A file system driver is used to translate the commands used to access each specific file system into a standard set of commands that the operating system can use to talk to all file systems. Programs can then deal with these file systems on the basis of filenames, and directories/folders, contained within a hierarchical structure. They can create, delete, open, and close files, as well as gather various information about them, including access permissions, size, free space, and creation and modification dates.

Various differences between file systems make supporting all file systems difficult. Allowed characters in file names, case sensitivity, and the presence of various kinds of file attributes makes the implementation of a single interface for every file system a daunting task. Operating systems tend to recommend using (and so support natively) file systems specifically designed for them; for example, NTFS in Windows and ext3 and ReiserFS in Linux. However, in practice, third party drivers are usually available to give support for the most widely used file systems in most general-purpose operating systems (for example, NTFS is available in Linux through NTFS-3g, and ext2/3 and ReiserFS are available in Windows through third-party software).

Support for file systems is highly varied among modern operating systems, although there are several common file systems which almost all operating systems include support and drivers for. Operating systems vary on file system support and on the disk formats they may be installed on. Under Windows, each file system is usually limited in application to certain media; for example, CDs must use ISO 9660 or UDF, and as of Windows Vista, NTFS is the only file system which the operating system can be installed on. It is possible to install Linux onto many types of file systems. Unlike other operating systems, Linux and UNIX allow any file system to be used regardless of the media it is stored in, whether it is a hard drive, a disc (CD, DVD...), a USB flash drive, or even contained within a file located on another file system.

A device driver is a specific type of computer software developed to allow interaction with hardware devices. Typically this constitutes an interface for communicating with the device, through the specific computer bus or communications subsystem that the hardware is connected to, providing commands to and/or receiving data from the device, and on the other end, the requisite interfaces to the operating system and software applications. It is a specialized hardware-dependent computer program which is also operating system specific that enables another program, typically an operating system or applications software package or computer program running under the operating system kernel, to interact transparently with a hardware device, and usually provides the requisite interrupt handling necessary for any necessary asynchronous time-dependent hardware interfacing needs.

The key design goal of device drivers is abstraction. Every model of hardware (even within the same class of device) is different. Newer models also are released by manufacturers that provide more reliable or better performance and these newer models are often controlled differently. Computers and their operating systems cannot be expected to know how to control every device, both now and in the future. To solve this problem, operating systems essentially dictate how every type of device should be controlled. The function of the device driver is then to translate these operating system mandated function calls into device specific calls. In theory a new device, which is controlled in a new manner, should function correctly if a suitable driver is available. This new driver ensures that the device appears to operate as usual from the operating system's point of view.

Under versions of Windows before Vista and versions of Linux before 2.6, all driver execution was co-operative, meaning that if a driver entered an infinite loop it would freeze the system. More recent revisions of these operating systems incorporate kernel preemption, where the kernel interrupts the driver to give it tasks, and then separates itself from the process until it receives a response from the device driver, or gives it more tasks to do.

Currently most operating systems support a variety of networking protocols, hardware, and applications for using them. This means that computers running dissimilar operating systems can participate in a common network for sharing resources such as computing, files, printers, and scanners using either wired or wireless connections. Networks can essentially allow a computer's operating system to access the resources of a remote computer to support the same functions as it could if those resources were connected directly to the local computer. This includes everything from simple communication, to using networked file systems or even sharing another computer's graphics or sound hardware. Some network services allow the resources of a computer to be accessed transparently, such as SSH which allows networked users direct access to a computer's command line interface.

Client/server networking allows a program on a computer, called a client, to connect via a network to another computer, called a server. Servers offer (or host) various services to other network computers and users. These services are usually provided through ports or numbered access points beyond the server's IP address. Each port number is usually associated with a maximum of one running program, which is responsible for handling requests to that port. A daemon, being a user program, can in turn access the local hardware resources of that computer by passing requests to the operating system kernel.

Many operating systems support one or more vendor-specific or open networking protocols as well, for example, SNA on IBM systems, DECnet on systems from Digital Equipment Corporation, and Microsoft-specific protocols (SMB) on Windows. Specific protocols for specific tasks may also be supported such as NFS for file access. Protocols like ESound, or esd can be easily extended over the network to provide sound from local applications, on a remote system's sound hardware.

A computer being secure depends on a number of technologies working properly. A modern operating system provides access to a number of resources, which are available to software running on the system, and to external devices like networks via the kernel.

The operating system must be capable of distinguishing between requests which should be allowed to be processed, and others which should not be processed. While some systems may simply distinguish between "privileged" and "non-privileged", systems commonly have a form of requester "identity", such as a user name. To establish identity there may be a process of "authentication". Often a username must be quoted, and each username may have a password. Other methods of authentication, such as magnetic cards or biometric data, might be used instead. In some cases, especially connections from the network, resources may be accessed with no authentication at all (such as reading files over a network share). Also covered by the concept of requester identity is "authorization"; the particular services and resources accessible by the requester once logged into a system are tied to either the requester's user account or to the variously configured groups of users to which the requester belongs.

In addition to the allow or disallow model of security, a system with a high level of security also offers auditing options. These would allow tracking of requests for access to resources (such as, "who has been reading this file?"). Internal security, or security from an already running program is only possible if all possibly harmful requests must be carried out through interrupts to the operating system kernel. If programs can directly access hardware and resources, they cannot be secured.

External security involves a request from outside the computer, such as a login at a connected console or some kind of network connection. External requests are often passed through device drivers to the operating system's kernel, where they can be passed onto applications, or carried out directly. Security of operating systems has long been a concern because of highly sensitive data held on computers, both of a commercial and military nature. The United States Government Department of Defense (DoD) created the "Trusted Computer System Evaluation Criteria" (TCSEC) which is a standard that sets basic requirements for assessing the effectiveness of security. This became of vital importance to operating system makers, because the TCSEC was used to evaluate, classify and select trusted operating systems being considered for the processing, storage and retrieval of sensitive or classified information.

Network services include offerings such as file sharing, print services, email, web sites, and file transfer protocols (FTP), most of which can have compromised security. At the front line of security are hardware devices known as firewalls or intrusion detection/prevention systems. At the operating system level, there are a number of software firewalls available, as well as intrusion detection/prevention systems. Most modern operating systems include a software firewall, which is enabled by default. A software firewall can be configured to allow or deny network traffic to or from a service or application running on the operating system. Therefore, one can install and be running an insecure service, such as Telnet or FTP, and not have to be threatened by a security breach because the firewall would deny all traffic trying to connect to the service on that port.

An alternative strategy, and the only sandbox strategy available in systems that do not meet the Popek and Goldberg virtualization requirements, is where the operating system is not running user programs as native code, but instead either emulates a processor or provides a host for a p-code based system such as Java.

Internal security is especially relevant for multi-user systems; it allows each user of the system to have private files that the other users cannot tamper with or read. Internal security is also vital if auditing is to be of any use, since a program can potentially bypass the operating system, inclusive of bypassing auditing.

Every computer that is to be operated by an individual requires a user interface. The user interface is usually referred to as a shell and is essential if human interaction is to be supported. The user interface views the directory structure and requests services from the operating system that will acquire data from input hardware devices, such as a keyboard, mouse or credit card reader, and requests operating system services to display prompts, status messages and such on output hardware devices, such as a video monitor or printer. The two most common forms of a user interface have historically been the command-line interface, where computer commands are typed out line-by-line, and the graphical user interface, where a visual environment (most commonly a WIMP) is present.

Most of the modern computer systems support graphical user interfaces (GUI), and often include them. In some computer systems, such as the original implementation of the classic Mac OS, the GUI is integrated into the kernel.

While technically a graphical user interface is not an operating system service, incorporating support for one into the operating system kernel can allow the GUI to be more responsive by reducing the number of context switches required for the GUI to perform its output functions. Other operating systems are modular, separating the graphics subsystem from the kernel and the Operating System. In the 1980s UNIX, VMS and many others had operating systems that were built this way. Linux and macOS are also built this way. Modern releases of Microsoft Windows such as Windows Vista implement a graphics subsystem that is mostly in user-space; however the graphics drawing routines of versions between Windows NT 4.0 and Windows Server 2003 exist mostly in kernel space. Windows 9x had very little distinction between the interface and the kernel.

Many computer operating systems allow the user to install or create any user interface they desire. The X Window System in conjunction with GNOME or KDE Plasma 5 is a commonly found setup on most Unix and Unix-like (BSD, Linux, Solaris) systems. A number of Windows shell replacements have been released for Microsoft Windows, which offer alternatives to the included Windows shell, but the shell itself cannot be separated from Windows.

Numerous Unix-based GUIs have existed over time, most derived from X11. Competition among the various vendors of Unix (HP, IBM, Sun) led to much fragmentation, though an effort to standardize in the 1990s to COSE and CDE failed for various reasons, and were eventually eclipsed by the widespread adoption of GNOME and K Desktop Environment. Prior to free software-based toolkits and desktop environments, Motif was the prevalent toolkit/desktop combination (and was the basis upon which CDE was developed).

Graphical user interfaces evolve over time. For example, Windows has modified its user interface almost every time a new major version of Windows is released, and the Mac OS GUI changed dramatically with the introduction of Mac OS X in 1999.

A real-time operating system (RTOS) is an operating system intended for applications with fixed deadlines (real-time computing). Such applications include some small embedded systems, automobile engine controllers, industrial robots, spacecraft, industrial control, and some large-scale computing systems.

An early example of a large-scale real-time operating system was Transaction Processing Facility developed by American Airlines and IBM for the Sabre Airline Reservations System.

Embedded systems that have fixed deadlines use a real-time operating system such as VxWorks, PikeOS, eCos, QNX, MontaVista Linux and RTLinux. Windows CE is a real-time operating system that shares similar APIs to desktop Windows but shares none of desktop Windows' codebase. Symbian OS also has an RTOS kernel (EKA2) starting with version 8.0b.

Some embedded systems use operating systems such as Palm OS, BSD, and Linux, although such operating systems do not support real-time computing.

Operating system development is one of the most complicated activities in which a computing hobbyist may engage. A hobby operating system may be classified as one whose code has not been directly derived from an existing operating system, and has few users and active developers.

In some cases, hobby development is in support of a "homebrew" computing device, for example, a simple single-board computer powered by a 6502 microprocessor. Or, development may be for an architecture already in widespread use. Operating system development may come from entirely new concepts, or may commence by modeling an existing operating system. In either case, the hobbyist is his/her own developer, or may interact with a small and sometimes unstructured group of individuals who have like interests.

Examples of a hobby operating system include Syllable and TempleOS.

Application software is generally written for use on a specific operating system, and sometimes even for specific hardware. When porting the application to run on another OS, the functionality required by that application may be implemented differently by that OS (the names of functions, meaning of arguments, etc.) requiring the application to be adapted, changed, or otherwise maintained.

Unix was the first operating system not written in assembly language, making it very portable to systems different from its native PDP-11.

This cost in supporting operating systems diversity can be avoided by instead writing applications against software platforms such as Java or Qt. These abstractions have already borne the cost of adaptation to specific operating systems and their system libraries.

Another approach is for operating system vendors to adopt standards. For example, POSIX and OS abstraction layers provide commonalities that reduce porting costs.



</doc>
<doc id="22196" url="https://en.wikipedia.org/wiki?curid=22196" title="Orson Welles">
Orson Welles

George Orson Welles (May 6, 1915 – October 10, 1985) was an American actor, director, writer and producer who is remembered for his innovative work in radio, theatre and film. He is considered one of the greatest filmmakers of all time.

While in his twenties Welles directed a number of high-profile stage productions for the Federal Theatre Project, including an adaptation of "Macbeth" with an entirely African American cast and the political musical "The Cradle Will Rock". In 1937 he and John Houseman founded the Mercury Theatre, an independent repertory theatre company that presented a series of productions on Broadway through 1941, including "Caesar" (1937), a Broadway adaptation of William Shakespeare's "Julius Caesar".

In 1938, his radio anthology series "The Mercury Theatre on the Air" gave Welles the platform to find international fame as the director and narrator of a radio adaptation of H. G. Wells' novel "The War of the Worlds", which caused widespread panic because many listeners thought that an invasion by extraterrestrial beings was actually occurring. Although some contemporary sources say these reports of panic were mostly false and overstated, they rocketed Welles to notoriety.

His first film was "Citizen Kane" (1941), which is consistently ranked as the greatest film ever made, and which he co-wrote, produced, directed and starred in as Charles Foster Kane. Welles released twelve other features, the most acclaimed of which include "The Magnificent Ambersons" (1942), "The Lady from Shanghai" (1947), "Touch of Evil" (1958), "The Trial" (1962), "Chimes at Midnight" (1965) and "F for Fake" (1973). His distinctive directorial style featured layered and nonlinear narrative forms, uses of lighting such as chiaroscuro, unusual camera angles, sound techniques borrowed from radio, deep focus shots and long takes. He has been praised as "the ultimate auteur".

Welles was an outsider to the studio system, and struggled for creative control on his projects early on with the major film studios in Hollywood and later in life with a variety of independent financiers across Europe, where he spent most of his career. Many of his films were either heavily edited or remained unreleased. Some, like "Touch of Evil", have been painstakingly re-edited from his notes. With a development spanning almost 50 years, Welles's final film, "The Other Side of the Wind", was released in 2018.

Welles had three marriages, including one with Rita Hayworth, and three children. Known for his baritone voice, Welles performed extensively across theatre, radio and film. He was a lifelong magician noted for presenting troop variety shows in the war years. In 2002 he was voted the greatest film director of all time in two British Film Institute polls among directors and critics. In 2018 he was included in the list of the 50 greatest Hollywood actors of all time by "The Daily Telegraph".

George Orson Welles was born May 6, 1915, in Kenosha, Wisconsin, a son of Richard Head Welles (1872–1930) and Beatrice Ives Welles ("née" Beatrice Lucy Ives; 1883–1924). He was named after one of his great-grandfathers, influential Kenosha attorney Orson S. Head, and his brother George Head. An alternative story of the source of his first and middle names was told by George Ade, who met Welles's parents on a West Indies cruise toward the end of 1914. Ade was traveling with a friend, Orson Wells (no relation), and the two of them sat at the same table as Mr. and Mrs. Richard Welles. Mrs. Welles was pregnant at the time, and when they said goodbye, she told them that she had enjoyed their company so much that if the child were a boy, she intended to name it for them: George Orson.

Despite his family's affluence, Welles encountered hardship in childhood. His parents separated and moved to Chicago in 1919. His father, who made a fortune as the inventor of a popular bicycle lamp, became an alcoholic and stopped working. Welles's mother, a pianist, played during lectures by Dudley Crafts Watson at the Art Institute of Chicago to support her son and herself; the oldest Welles boy, "Dickie", was institutionalized at an early age because he had learning difficulties. Beatrice died of hepatitis in a Chicago hospital on May 10, 1924, just after Welles's ninth birthday. The Gordon String Quartet, which had made its first appearance at her home in 1921, played at Beatrice's funeral.

After his mother's death, Welles ceased pursuing music. It was decided that he would spend the summer with the Watson family at a private art colony in the village of Wyoming in the finger lakes region of New York State, established by Lydia Avery Coonley Ward. There he played and became friends with the children of the Aga Khan, including the 12-year-old Prince Aly Khan. Then, in what Welles later described as "a hectic period" in his life, he lived in a Chicago apartment with both his father and Dr. Maurice Bernstein, a Chicago physician who had been a close friend of both his parents. Welles briefly attended public school before his alcoholic father left business altogether and took him along on his travels to Jamaica and the Far East. When they returned they settled in a hotel in Grand Detour, Illinois, that was owned by his father. When the hotel burned down, Welles and his father took to the road again.

"During the three years that Orson lived with his father, some observers wondered who took care of whom", wrote biographer Frank Brady.

"In some ways, he was never really a young boy, you know," said Roger Hill, who became Welles's teacher and lifelong friend.

Welles briefly attended public school in Madison, Wisconsin, enrolled in the fourth grade. On September 15, 1926, he entered the Todd Seminary for Boys, an expensive independent school in Woodstock, Illinois, that his older brother, Richard Ives Welles, had attended ten years before until he was expelled for misbehavior. At Todd School, Welles came under the influence of Roger Hill, a teacher who was later Todd's headmaster. Hill provided Welles with an "ad hoc" educational environment that proved invaluable to his creative experience, allowing Welles to concentrate on subjects that interested him. Welles performed and staged theatrical experiments and productions there.

"Todd provided Welles with many valuable experiences", wrote critic Richard France. "He was able to explore and experiment in an atmosphere of acceptance and encouragement. In addition to a theatre the school's own radio station was at his disposal." Welles's first radio experience was on the Todd station, where he performed an adaptation of "Sherlock Holmes" that was written by him.

On December 28, 1930, when Welles was 15, his father died of heart and kidney failure at the age of 58, alone in a hotel in Chicago. Shortly before this, Welles had announced to his father that he would stop seeing him, believing it would prompt his father to refrain from drinking. As a result, Orson felt guilty because he believed his father had drunk himself to death because of him. His father's will left it to Orson to name his guardian. When Roger Hill declined, Welles chose Maurice Bernstein.

Following graduation from Todd in May 1931, Welles was awarded a scholarship to Harvard University, while his mentor Roger Hill advocated he attend Cornell College in Iowa. Rather than enrolling, he chose travel. He studied for a few weeks at the Art Institute of Chicago with Boris Anisfeld, who encouraged him to pursue painting.

Welles occasionally returned to Woodstock, the place he eventually named when he was asked in a 1960 interview, "Where is home?" Welles replied, "I suppose it's Woodstock, Illinois, if it's anywhere. I went to school there for four years. If I try to think of a home, it's that."

After his father's death, Welles traveled to Europe using a small portion of his inheritance. Welles said that while on a walking and painting trip through Ireland, he strode into the Gate Theatre in Dublin and claimed he was a Broadway star. The manager of the Gate, Hilton Edwards, later said he had not believed him but was impressed by his brashness and an impassioned audition he gave. Welles made his stage debut at the Gate Theatre on October 13, 1931, appearing in Ashley Dukes's adaptation of "Jew Suss" as Duke Karl Alexander of Württemberg. He performed small supporting roles in subsequent Gate productions, and he produced and designed productions of his own in Dublin. In March 1932 Welles performed in W. Somerset Maugham's "The Circle" at Dublin's Abbey Theatre and traveled to London to find additional work in the theatre. Unable to obtain a work permit, he returned to the U.S.

Welles found his fame ephemeral and turned to a writing project at Todd School that became immensely successful, first entitled "Everybody's Shakespeare" and subsequently, "The Mercury Shakespeare". Welles traveled to North Africa while working on thousands of illustrations for the "Everybody's Shakespeare" series of educational books, a series that remained in print for decades.

In 1933, Roger and Hortense Hill invited Welles to a party in Chicago, where Welles met Thornton Wilder. Wilder arranged for Welles to meet Alexander Woollcott in New York, in order that he be introduced to Katharine Cornell, who was assembling a repertory theatre company. Cornell's husband, director Guthrie McClintic, immediately put Welles under contract and cast him in three plays. "Romeo and Juliet", "The Barretts of Wimpole Street" and "Candida" toured in repertory for 36 weeks beginning in November 1933, with the first of more than 200 performances taking place in Buffalo, New York.

In 1934, Welles got his first job on radio—on "The American School of the Air"—through actor-director Paul Stewart, who introduced him to director Knowles Entrikin. That summer Welles staged a drama festival with the Todd School at the Opera House in Woodstock, Illinois, inviting Micheál Mac Liammóir and Hilton Edwards from Dublin's Gate Theatre to appear along with New York stage luminaries in productions including "Trilby", "Hamlet", "The Drunkard" and "Tsar Paul". At the old firehouse in Woodstock he also shot his first film, an eight-minute short titled "The Hearts of Age".

On November 14, 1934, Welles married Chicago socialite and actress Virginia Nicolson (often misspelled "Nicholson") in a civil ceremony in New York. To appease the Nicolsons, who were furious at the couple's elopement, a formal ceremony took place December 23, 1934, at the New Jersey mansion of the bride's godmother. Welles wore a cutaway borrowed from his friend George Macready.

A revised production of Katharine Cornell's "Romeo and Juliet" opened December 20, 1934, at the Martin Beck Theatre in New York. The Broadway production brought the 19-year-old Welles (now playing Tybalt) to the notice of John Houseman, a theatrical producer who was casting the lead role in the debut production of Archibald MacLeish's verse play, "Panic". On March 22, 1935, Welles made his debut on the CBS Radio series "The March of Time", performing a scene from "Panic" for a news report on the stage production

By 1935 Welles was supplementing his earnings in the theatre as a radio actor in Manhattan, working with many actors who later formed the core of his Mercury Theatre on programs including "America's Hour", "Cavalcade of America", "Columbia Workshop" and "The March of Time". "Within a year of his debut Welles could claim membership in that elite band of radio actors who commanded salaries second only to the highest paid movie stars," wrote critic Richard France.

Part of the Works Progress Administration, the Federal Theatre Project (1935–39) was a New Deal program to fund theatre and other live artistic performances and entertainment programs in the United States during the Great Depression. It was created as a relief measure to employ artists, writers, directors and theatre workers. Under national director Hallie Flanagan it was shaped into a true national theatre that created relevant art, encouraged experimentation and innovation, and made it possible for millions of Americans to see live theatre for the first time.
John Houseman, director of the Negro Theatre Unit in New York, invited Welles to join the Federal Theatre Project in 1935. Far from unemployed — "I was so employed I forgot how to sleep" — Welles put a large share of his $1,500-a-week radio earnings into his stage productions, bypassing administrative red tape and mounting the projects more quickly and professionally. "Roosevelt once said that I was the only operator in history who ever illegally siphoned money "into" a Washington project," Welles said.

The Federal Theatre Project was the ideal environment in which Welles could develop his art. Its purpose was employment, so he was able to hire any number of artists, craftsmen and technicians, and he filled the stage with performers. The company for the first production, an adaptation of William Shakespeare's "Macbeth" with an entirely African-American cast, numbered 150. The production became known as the "Voodoo Macbeth" because Welles changed the setting to a mythical island suggesting the Haitian court of King Henri Christophe, with Haitian "vodou" fulfilling the rôle of Scottish witchcraft. The play opened April 14, 1936, at the Lafayette Theatre in Harlem and was received rapturously. At 20, Welles was hailed as a prodigy. The production then made a 4,000-mile national tour that included two weeks at the Texas Centennial Exposition in Dallas.

Next mounted was the farce "Horse Eats Hat", an adaptation by Welles and Edwin Denby of "The Italian Straw Hat", an 1851 five-act farce by Eugène Marin Labiche and Marc-Michel. The play was presented September 26 – December 5, 1936, at Maxine Elliott's Theatre, New York, and featured Joseph Cotten in his first starring role. It was followed by an adaptation of "Dr. Faustus" that used light as a prime unifying scenic element in a nearly black stage, presented January 8 – May 9, 1937, at Maxine Elliott's Theatre.

Outside the scope of the Federal Theatre Project, American composer Aaron Copland chose Welles to direct "The Second Hurricane" (1937), an operetta with a libretto by Edwin Denby. Presented at the Henry Street Settlement Music School in New York for the benefit of high school students, the production opened April 21, 1937, and ran its scheduled three performances.

In 1937, Welles rehearsed Marc Blitzstein's political operetta, "The Cradle Will Rock". It was originally scheduled to open June 16, 1937, in its first public preview. Because of severe federal cutbacks in the Works Progress projects, the show's premiere at the Maxine Elliott Theatre was canceled. The theater was locked and guarded to prevent any government-purchased materials from being used for a commercial production of the work. In a last-minute move, Welles announced to waiting ticket-holders that the show was being transferred to the Venice, 20 blocks away. Some cast, and some crew and audience, walked the distance on foot. The union musicians refused to perform in a commercial theater for lower non-union government wages. The actors' union stated that the production belonged to the Federal Theater Project and could not be performed outside that context without permission. Lacking the participation of the union members, "The Cradle Will Rock" began with Blitzstein introducing the show and playing the piano accompaniment on stage with some cast members performing from the audience. This impromptu performance was well received by its audience.

Breaking with the Federal Theatre Project in 1937, Welles and Houseman founded their own repertory company, which they called the Mercury Theatre. The name was inspired by the title of the iconoclastic magazine, "The American Mercury". Welles was executive producer, and the original company included such actors as Joseph Cotten, George Coulouris, Geraldine Fitzgerald, Arlene Francis, Martin Gabel, John Hoyt, Norman Lloyd, Vincent Price, Stefan Schnabel and Hiram Sherman.

"I think he was the greatest directorial talent we've ever had in the [American] theater," Lloyd said of Welles in a 2014 interview. "When you saw a Welles production, you saw the text had been affected, the staging was remarkable, the sets were unusual, music, sound, lighting, a totality of everything. We had not had such a man in our theater. He was the first and remains the greatest."

The Mercury Theatre opened November 11, 1937, with "Caesar", Welles's modern-dress adaptation of Shakespeare's tragedy "Julius Caesar"—streamlined into an anti-fascist tour de force that Joseph Cotten later described as "so vigorous, so contemporary that it set Broadway on its ear." The set was completely open with no curtain, and the brick stage wall was painted dark red. Scene changes were achieved by lighting alone. On the stage was a series of risers; squares were cut into one at intervals and lights were set beneath it, pointing straight up to evoke the "cathedral of light" at the Nuremberg Rallies. "He staged it like a political melodrama that happened the night before," said Lloyd.

Beginning January 1, 1938, "Caesar" was performed in repertory with "The Shoemaker's Holiday"; both productions moved to the larger National Theatre. They were followed by "Heartbreak House" (April 29, 1938) and "Danton's Death" (November 5, 1938). As well as being presented in a pared-down oratorio version at the Mercury Theatre on Sunday nights in December 1937, "The Cradle Will Rock" was at the Windsor Theatre for 13 weeks (January 4 – April 2, 1938). Such was the success of the Mercury Theatre that Welles appeared on the cover of "Time" magazine, in full makeup as Captain Shotover in "Heartbreak House", in the issue dated May 9, 1938—three days after his 23rd birthday.

Simultaneously with his work in the theatre, Welles worked extensively in radio as an actor, writer, director and producer, often without credit. Between 1935 and 1937 he was earning as much as $2,000 a week, shuttling between radio studios at such a pace that he would arrive barely in time for a quick scan of his lines before he was on the air. While he was directing the "Voodoo Macbeth" Welles was dashing between Harlem and midtown Manhattan three times a day to meet his radio commitments.

In addition to continuing as a repertory player on "The March of Time", in the fall of 1936 Welles adapted and performed "Hamlet" in an early two-part episode of CBS Radio's "Columbia Workshop". His performance as the announcer in the series' April 1937 presentation of Archibald MacLeish's verse drama "The Fall of the City" was an important development in his radio career and made the 21-year-old Welles an overnight star.

In July 1937, the Mutual Network gave Welles a seven-week series to adapt "Les Misérables". It was his first job as a writer-director for radio, the radio debut of the Mercury Theatre, and one of Welles's earliest and finest achievements. He invented the use of narration in radio.

"By making himself the center of the storytelling process, Welles fostered the impression of self-adulation that was to haunt his career to his dying day", wrote critic Andrew Sarris. "For the most part, however, Welles was singularly generous to the other members of his cast and inspired loyalty from them above and beyond the call of professionalism."

That September, Mutual chose Welles to play Lamont Cranston, also known as "The Shadow". He performed the role anonymously through mid-September 1938.

After the theatrical successes of the Mercury Theatre, CBS Radio invited Orson Welles to create a summer show for 13 weeks. The series began July 11, 1938, initially titled "First Person Singular", with the formula that Welles would play the lead in each show. Some months later the show was called "The Mercury Theatre on the Air". The weekly hour-long show presented radio plays based on classic literary works, with original music composed and conducted by Bernard Herrmann.

The Mercury Theatre's radio adaptation of "The War of the Worlds" by H. G. Wells October 30, 1938, brought Welles instant fame. The combination of the news bulletin form of the performance with the between-breaks dial spinning habits of listeners was later reported to have created widespread confusion among listeners who failed to hear the introduction, although the extent of this confusion has come into question. Panic was reportedly spread among listeners who believed the fictional news reports of a Martian invasion. The myth of the result created by the combination was reported as fact around the world and disparagingly mentioned by Adolf Hitler in a public speech.

Welles's growing fame drew Hollywood offers, lures that the independent-minded Welles resisted at first. "The Mercury Theatre on the Air," which had been a sustaining show (without sponsorship) was picked up by Campbell Soup and renamed "The Campbell Playhouse." "The Mercury Theatre on the Air" made its last broadcast on December 4, 1938, and "The Campbell Playhouse" began five days later.

Welles began commuting from California to New York for the two Sunday broadcasts of "The Campbell Playhouse" after signing a film contract with RKO Pictures in August 1939. In November 1939, production of the show moved from New York to Los Angeles.

After 20 shows, Campbell began to exercise more creative control and had complete control over story selection. As his contract with Campbell came to an end, Welles chose not to sign on for another season. After the broadcast of March 31, 1940, Welles and Campbell parted amicably.

RKO Radio Pictures president George Schaefer eventually offered Welles what generally is considered the greatest contract offered to a filmmaker, much less to one who was untried. Engaging him to write, produce, direct and perform in two motion pictures, the contract subordinated the studio's financial interests to Welles's creative control, and broke all precedent by granting Welles the right of final cut. After signing a summary agreement with RKO on July 22, Welles signed a full-length 63-page contract August 21, 1939. The agreement was bitterly resented by the Hollywood studios and persistently mocked in the trade press.

RKO rejected Welles's first two movie proposals, but agreed on the third offer – "Citizen Kane". Welles co-wrote, produced and directed the film, and performed the lead role. Welles conceived the project with screenwriter Herman J. Mankiewicz, who was writing radio plays for "The Campbell Playhouse". Mankiewicz based the original outline of the film script on the life of William Randolph Hearst, whom he knew socially and came to hate after being exiled from Hearst's circle.

After agreeing on the storyline and character, Welles supplied Mankiewicz with 300 pages of notes and put him under contract to write the first draft screenplay under the supervision of John Houseman. Welles wrote his own draft, then drastically condensed and rearranged both versions and added scenes of his own. The industry accused Welles of underplaying Mankiewicz's contribution to the script, but Welles countered the attacks by saying, "At the end, naturally, I was the one making the picture, after all—who had to make the decisions. I used what I wanted of Mank's and, rightly or wrongly, kept what I liked of my own."

Welles's project attracted some of Hollywood's best technicians, including cinematographer Gregg Toland. For the cast, Welles primarily used actors from his Mercury Theatre. Filming "Citizen Kane" took ten weeks.

Hearst's newspapers barred all reference to "Citizen Kane" and exerted enormous pressure on the Hollywood film community to force RKO to shelve the film. RKO chief George Schaefer received a cash offer from MGM's Louis B. Mayer and other major studio executives if he would destroy the negative and existing prints of the film.

While waiting for "Citizen Kane" to be released, Welles produced and directed the original Broadway production of "Native Son", a drama written by Paul Green and Richard Wright based on Wright's novel. Starring Canada Lee, the show ran March 24 – June 28, 1941, at the St. James Theatre. The Mercury Production was the last time Welles and Houseman worked together.

"Citizen Kane" was given a limited release and the film received overwhelming critical praise. It was voted the best picture of 1941 by the National Board of Review and the New York Film Critics Circle. The film garnered nine Academy Award nominations but won only for Best Original Screenplay, shared by Mankiewicz and Welles. "Variety" reported that block voting by screen extras deprived "Citizen Kane" of Oscars for Best Picture and Best Actor (Welles), and similar prejudices were likely to have been responsible for the film receiving no technical awards.

The delay in the film's release and uneven distribution contributed to mediocre results at the box office. After it ran its course theatrically, "Citizen Kane" was retired to the vault in 1942. In postwar France, however, the film's reputation grew after it was seen for the first time in 1946. In the United States, it began to be re-evaluated after it began to appear on television in 1956. That year it was also re-released theatrically, and film critic Andrew Sarris described it as "the great American film" and "the work that influenced the cinema more profoundly than any American film since "Birth of a Nation"." "Citizen Kane" is now hailed as the greatest film ever made.

Welles's second film for RKO was "The Magnificent Ambersons", adapted by Welles from the Pulitzer Prize-winning novel by Booth Tarkington. Toland was not available, so Stanley Cortez was named cinematographer. The meticulous Cortez worked slowly and the film lagged behind schedule and over budget. Prior to production, Welles's contract was renegotiated, revoking his right to control the final cut. "The Magnificent Ambersons" was in production October 28, 1941 – January 22, 1942.

Throughout the shooting of the film Welles was also producing a weekly half-hour radio series, "The Orson Welles Show". Many of the "Ambersons" cast participated in the CBS Radio series, which ran September 15, 1941 – February 2, 1942.

At RKO's request, Welles worked on an adaptation of Eric Ambler's spy thriller, "Journey into Fear", co-written with Joseph Cotten. In addition to acting in the film, Welles was the producer. Direction was credited to Norman Foster. Welles later said that they were in such a rush that the director of each scene was determined by whoever was closest to the camera.

"Journey into Fear" was in production January 6 – March 12, 1942.

In late November 1941, Welles was appointed as a goodwill ambassador to Latin America by Nelson Rockefeller, U.S. Coordinator of Inter-American Affairs and a principal stockholder in RKO Radio Pictures. The mission of the OCIAA was cultural diplomacy, promoting hemispheric solidarity and countering the growing influence of the Axis powers in Latin America. John Hay Whitney, head of the agency's Motion Picture Division, was asked by the Brazilian government to produce a documentary of the annual Rio Carnival celebration taking place in early February 1942. In a telegram December 20, 1941, Whitney wrote Welles, "Personally believe you would make great contribution to hemisphere solidarity with this project."

The OCIAA sponsored cultural tours to Latin America and appointed goodwill ambassadors including George Balanchine and the American Ballet, Bing Crosby, Aaron Copland, Walt Disney, John Ford and Rita Hayworth. Welles was thoroughly briefed in Washington, D.C., immediately before his departure for Brazil, and film scholar Catherine L. Benamou, a specialist in Latin American affairs, finds it "not unlikely" that he was among the goodwill ambassadors who were asked to gather intelligence for the U.S. government in addition to their cultural duties. She concludes that Welles's acceptance of Whitney's request was "a logical and patently patriotic choice".

In addition to working on his ill-fated film project, "It's All True", Welles was responsible for radio programs, lectures, interviews and informal talks as part of his OCIAA-sponsored cultural mission, which was regarded as a success. He spoke on topics ranging from Shakespeare to visual art at gatherings of Brazil's elite, and his two intercontinental radio broadcasts in April 1942 were particularly intended to tell U.S. audiences that President Vargas was a partner with the Allies. Welles's ambassadorial mission was extended to permit his travel to other nations including Argentina, Bolivia, Chile, Colombia, Ecuador, Guatemala, Mexico, Peru and Uruguay. Welles worked for more than half a year with no compensation.

Welles's own expectations for the film were modest. ""It's All True" was not going to make any cinematic history, nor was it intended to," he later said. "It was intended to be a perfectly honorable execution of my job as a goodwill ambassador, bringing entertainment to the Northern Hemisphere that showed them something about the Southern one."

In July 1941, Welles conceived "It's All True" as an omnibus film mixing documentary and docufiction in a project that emphasized the dignity of labor and celebrated the cultural and ethnic diversity of North America. It was to have been his third film for RKO, following "Citizen Kane" (1941) and "The Magnificent Ambersons" (1942). Duke Ellington was put under contract to score a segment with the working title, "The Story of Jazz", drawn from Louis Armstrong's 1936 autobiography, "Swing That Music". Armstrong was cast to play himself in the brief dramatization of the history of jazz performance, from its roots to its place in American culture in the 1940s. "The Story of Jazz" was to go into production in December 1941.

Mercury Productions purchased the stories for two other segments—"My Friend Bonito" and "The Captain's Chair"—from documentary filmmaker Robert J. Flaherty. Adapted by Norman Foster and John Fante, "My Friend Bonito" was the only segment of the original "It's All True" to go into production. Filming took place in Mexico September–December 1941, with Norman Foster directing under Welles's supervision.

In December 1941, the Office of the Coordinator of Inter-American Affairs asked Welles to make a film in Brazil that would showcase the Carnaval in Rio de Janeiro. With filming of "My Friend Bonito" about two-thirds complete, Welles decided he could shift the geography of "It's All True" and incorporate Flaherty's story into an omnibus film about Latin America—supporting the Roosevelt administration's Good Neighbor policy, which Welles strongly advocated. In this revised concept, "The Story of Jazz" was replaced by the story of samba, a musical form with a comparable history and one that came to fascinate Welles. He also decided to do a ripped-from-the-headlines episode about the epic voyage of four poor Brazilian fishermen, the jangadeiros, who had become national heroes. Welles later said this was the most valuable story.

Required to film the Carnaval in Rio de Janeiro in early February 1942, Welles rushed to edit "The Magnificent Ambersons" and finish his acting scenes in "Journey into Fear". He ended his lucrative CBS radio show February 2, flew to Washington, D.C., for a briefing, and then lashed together a rough cut of "Ambersons" in Miami with editor Robert Wise. Welles recorded the film's narration the night before he left for South America: "I went to the projection room at about four in the morning, did the whole thing, and then got on the plane and off to Rio—and the end of civilization as we know it."

Welles left for Brazil on February 4 and began filming in Rio February 8, 1942. At the time it did not seem that Welles's other film projects would be disrupted, but as film historian Catherine L. Benamou wrote, "the ambassadorial appointment would be the first in a series of turning points leading—in 'zigs' and 'zags,' rather than in a straight line—to Welles's loss of complete directorial control over both "The Magnificent Ambersons" and "It's All True", the cancellation of his contract at RKO Radio Studio, the expulsion of his company Mercury Productions from the RKO lot, and, ultimately, the total suspension of "It's All True".

In 1942 RKO Pictures underwent major changes under new management. Nelson Rockefeller, the primary backer of the Brazil project, left its board of directors, and Welles's principal sponsor at RKO, studio president George Schaefer, resigned. RKO took control of "Ambersons" and edited the film into what the studio considered a commercial format. Welles's attempts to protect his version ultimately failed. In South America, Welles requested resources to finish "It's All True". Given a limited amount of black-and-white film stock and a silent camera, he was able to finish shooting the episode about the jangadeiros, but RKO refused to support further production on the film.

"So I was fired from RKO," Welles later recalled. "And they made a great publicity point of the fact that I had gone to South America without a script and thrown all this money away. I never recovered from that attack." Later in 1942, when RKO Pictures began promoting its new corporate motto, "Showmanship In Place of Genius: A New Deal at RKO", Welles understood it as a reference to him.

Welles returned to the United States August 22, 1942, after more than six months in South America. A week after his return he produced and emceed the first two hours of a seven-hour coast-to-coast War Bond drive broadcast titled "I Pledge America". Airing August 29, 1942, on the Blue Network, the program was presented in cooperation with the United States Department of the Treasury, Western Union (which wired bond subscriptions free of charge) and the American Women's Voluntary Services. Featuring 21 dance bands and a score of stage and screen and radio stars, the broadcast raised more than $10 million—more than $146 million today—for the war effort.

On October 12, 1942, "Cavalcade of America" presented Welles's radio play, "Admiral of the Ocean Sea", an entertaining and factual look at the legend of Christopher Columbus.

"It belongs to a period when hemispheric unity was a crucial matter and many programs were being devoted to the common heritage of the Americas," wrote broadcasting historian Erik Barnouw. "Many such programs were being translated into Spanish and Portuguese and broadcast to Latin America, to counteract many years of successful Axis propaganda to that area. The Axis, trying to stir Latin America against Anglo-America, had constantly emphasized the differences between the two. It became the job of American radio to emphasize their common experience and essential unity."

"Admiral of the Ocean Sea", also known as "Columbus Day", begins with the words, "Hello Americans"—the title Welles would choose for his own series five weeks later.

"Hello Americans", a CBS Radio series broadcast November 15, 1942 – January 31, 1943, was produced, directed and hosted by Welles under the auspices of the Office of the Coordinator for Inter-American Affairs. The 30-minute weekly program promoted inter-American understanding and friendship, drawing upon the research amassed for the ill-fated film, "It's All True". The series was produced concurrently with Welles's other CBS series, "Ceiling Unlimited" (November 9, 1942 – February 1, 1943), sponsored by the Lockheed-Vega Corporation. The program was conceived to glorify the aviation industry and dramatize its role in World War II. Welles's shows were regarded as significant contributions to the war effort.

Throughout the war Welles worked on patriotic radio programs including "Command Performance", "G.I. Journal", "Mail Call", "Nazi Eyes on Canada", "Stage Door Canteen" and "Treasury Star Parade".

In early 1943, the two concurrent radio series ("Ceiling Unlimited", "Hello Americans") that Orson Welles created for CBS to support the war effort had ended. Filming also had wrapped on the 1943 film adaptation of "Jane Eyre" and that fee, in addition to the income from his regular guest-star roles in radio, made it possible for Welles to fulfill a lifelong dream. He approached the War Assistance League of Southern California and proposed a show that evolved into a big-top spectacle, part circus and part magic show. He offered his services as magician and director, and invested some $40,000 of his own money in an extravaganza he co-produced with his friend Joseph Cotten: "The Mercury Wonder Show for Service Men". Members of the U.S. armed forces were admitted free of charge, while the general public had to pay. The show entertained more than 1,000 service members each night, and proceeds went to the War Assistance League, a charity for military service personnel.

The development of the show coincided with the resolution of Welles's oft-changing draft status in May 1943, when he was finally declared 4-F—unfit for military service—for a variety of medical reasons. "I felt guilty about the war," Welles told biographer Barbara Leaming. "I was guilt-ridden about my civilian status." He had been publicly hounded about his patriotism since "Citizen Kane", when the Hearst press began persistent inquiries about why Welles had not been drafted.

"The Mercury Wonder Show" ran August 3 – September 9, 1943, in an 80-by-120-foot tent located at 9000 Cahuenga Boulevard, in the heart of Hollywood.

At intermission September 7, 1943, KMPC radio interviewed audience and cast members of "The Mercury Wonder Show"—including Welles and Rita Hayworth, who were married earlier that day. Welles remarked that "The Mercury Wonder Show" had been performed for approximately 48,000 members of the U.S. armed forces.

The idea of doing a radio variety show occurred to Welles after his success as substitute host of four consecutive episodes (March 14 – April 4, 1943) of "The Jack Benny Program", radio's most popular show, when Benny contracted pneumonia on a performance tour of military bases. A half-hour variety show broadcast January 26 – July 19, 1944, on the Columbia Pacific Network, "The Orson Welles Almanac" presented sketch comedy, magic, mindreading, music and readings from classic works. Many of the shows originated on U.S. military camps, where Welles and his repertory company and guests entertained the troops with a reduced version of "The Mercury Wonder Show". The performances of the all-star jazz group Welles brought together for the show were so popular that the band became a regular feature and was an important force in reviving interest in traditional New Orleans jazz.
Welles was placed on the U.S. Treasury payroll on May 15, 1944, as an expert consultant for the duration of the war, with a retainer of $1 a year. On the recommendation of President Franklin D. Roosevelt, Secretary of the Treasury Henry Morgenthau asked Welles to lead the Fifth War Loan Drive, which opened June 12 with a one-hour radio show on all four networks, broadcast from Texarkana, Texas. Including a statement by the President, the program defined the causes of the war and encouraged Americans to buy $16 billion in bonds to finance the Normandy landings and the most violent phase of World War II. Welles produced additional war loan drive broadcasts on June 14 from the Hollywood Bowl, and June 16 from Soldier Field, Chicago. Americans purchased $20.6 billion in War Bonds during the Fifth War Loan Drive, which ended on July 8, 1944.

Welles campaigned ardently for Roosevelt in 1944. A longtime supporter and campaign speaker for FDR, he occasionally sent the president ideas and phrases that were sometimes incorporated into what Welles characterized as "less important speeches". One of these ideas was the joke in what came to be called the Fala speech, Roosevelt's nationally broadcast September 23 address to the International Teamsters Union which opened the 1944 presidential campaign.

Welles campaigned for the Roosevelt–Truman ticket almost full-time in the fall of 1944, traveling to nearly every state to the detriment of his own health and at his own expense. In addition to his radio addresses he filled in for Roosevelt, opposite Republican presidential nominee Thomas E. Dewey, at "The New York Herald Tribune Forum" broadcast October 18 on the Blue Network. Welles accompanied FDR to his last campaign rally, speaking at an event November 4 at Boston's Fenway Park before 40,000 people, and took part in a historic election-eve campaign broadcast November 6 on all four radio networks.

On November 21, 1944, Welles began his association with "This Is My Best", a CBS radio series he would briefly produce, direct, write and host (March 13 – April 24, 1945). He wrote a political column called "Orson Welles' Almanac" (later titled "Orson Welles Today") for "The New York Post" January–November 1945, and advocated the continuation of FDR's New Deal policies and his international vision, particularly the establishment of the United Nations and the cause of world peace.

On April 12, 1945, the day Franklin D. Roosevelt died, the Blue-ABC network marshalled its entire executive staff and national leaders to pay homage to the late president. "Among the outstanding programs which attracted wide attention was a special tribute delivered by Orson Welles", reported "Broadcasting" magazine. Welles spoke at 10:10 p.m Eastern War Time, from Hollywood, and stressed the importance of continuing FDR's work: "He has no need for homage and we who loved him have no time for tears … Our fighting sons and brothers cannot pause tonight to mark the death of him whose name will be given to the age we live in."

Welles presented another special broadcast on the death of Roosevelt the following evening: "We must move on beyond mere death to that free world which was the hope and labor of his life."

He dedicated the April 17 episode of "This Is My Best" to Roosevelt and the future of America on the eve of the United Nations Conference on International Organization. Welles was an advisor and correspondent for the Blue-ABC radio network's coverage of the San Francisco conference that formed the UN, taking place April 24 – June 23, 1945. He presented a half-hour dramatic program written by Ben Hecht on the opening day of the conference, and on Sunday afternoons (April 29 – June 10) he led a weekly discussion from the San Francisco Civic Auditorium.

In the fall of 1945 Welles began work on "The Stranger" (1946), a film noir drama about a war crimes investigator who tracks a high-ranking Nazi fugitive to an idyllic New England town. Edward G. Robinson, Loretta Young and Welles star.

Producer Sam Spiegel initially planned to hire director John Huston, who had rewritten the screenplay by Anthony Veiller. When Huston entered the military, Welles was given the chance to direct and prove himself able to make a film on schedule and under budget—something he was so eager to do that he accepted a disadvantageous contract. One of its concessions was that he would defer to the studio in any creative dispute.

"The Stranger" was Welles's first job as a film director in four years. He was told that if the film was successful he could sign a four-picture deal with International Pictures, making films of his own choosing. Welles was given some degree of creative control, and he endeavored to personalize the film and develop a nightmarish tone. He worked on the general rewrite of the script and wrote scenes at the beginning of the picture that were shot but subsequently cut by the producers. He filmed in long takes that largely thwarted the control given to editor Ernest J. Nims under the terms of the contract.

"The Stranger" was the first commercial film to use documentary footage from the Nazi concentration camps. Welles had seen the footage in early May 1945 in San Francisco, as a correspondent and discussion moderator at the UN Conference on International Organization. He wrote of the Holocaust footage in his syndicated "New York Post" column May 7, 1945.

Completed a day ahead of schedule and under budget, "The Stranger" was the only film made by Welles to have been a "bona fide" box office success upon its release. Its cost was $1.034 million; 15 months after its release it had grossed $3.216 million. Within weeks of the completion of the film, International Pictures backed out of its promised four-picture deal with Welles. No reason was given, but the impression was left that "The Stranger" would not make money.

In the summer of 1946, Welles moved to New York to direct the Broadway musical "Around the World", a stage adaptation of the Jules Verne novel "Around the World in Eighty Days" with a book by Welles and music by Cole Porter. Producer Mike Todd, who would later produce the successful 1956 film adaptation, pulled out from the lavish and expensive production, leaving Welles to support the finances. When Welles ran out of money he convinced Columbia Pictures president Harry Cohn to send enough money to continue the show, and in exchange Welles promised to write, produce, direct and star in a film for Cohn for no further fee. The stage show soon failed due to poor box-office, with Welles unable to claim the losses on his taxes.

In 1946, Welles began two new radio series—"The Mercury Summer Theatre of the Air" for CBS, and "Orson Welles Commentaries" for ABC. While "Mercury Summer Theatre" featured half-hour adaptations of some classic Mercury radio shows from the 1930s, the first episode was a condensation of his "Around the World" stage play, and is the only record of Cole Porter's music for the project. Several original Mercury actors returned for the series, as well as Bernard Herrmann. Welles invested his earnings into his failing stage play. "Commentaries" was a political vehicle for him, continuing the themes from his "New York Post" column. Again, Welles lacked a clear focus, until the NAACP brought to his attention the case of Isaac Woodard. Welles brought significant attention to Woodard's cause.

The last broadcast of "Orson Welles Commentaries" on October 6, 1946, marked the end of Welles's own radio shows.

The film that Welles was obliged to make in exchange for Harry Cohn's help in financing the stage production "Around the World" was "The Lady from Shanghai", filmed in 1947 for Columbia Pictures. Intended as a modest thriller, the budget skyrocketed after Cohn suggested that Welles's then-estranged second wife Rita Hayworth co-star.

Cohn disliked Welles's rough cut, particularly the confusing plot and lack of close-ups, and was not in sympathy with Welles's Brechtian use of irony and black comedy, especially in a farcical courtroom scene. Cohn ordered extensive editing and re-shoots. After heavy editing by the studio, approximately one hour of Welles's first cut was removed, including much of a climactic confrontation scene in an amusement park funhouse. While expressing displeasure at the cuts, Welles was appalled particularly with the musical score. The film was considered a disaster in America at the time of release, though the closing shootout in a hall of mirrors has since become a touchstone of film noir. Not long after release, Welles and Hayworth finalized their divorce.

Although "The Lady From Shanghai" was acclaimed in Europe, it was not embraced in the U.S. until decades later, where it is now often regarded as a classic of film noir. A similar difference in reception on opposite sides of the Atlantic, followed by greater American acceptance, befell the Welles-inspired Chaplin film "Monsieur Verdoux", originally to be directed by Welles starring Chaplin, then directed by Chaplin with the idea credited to Welles.

Prior to 1948, Welles convinced Republic Pictures to let him direct a low-budget version of "Macbeth", which featured highly stylized sets and costumes, and a cast of actors lip-syncing to a pre-recorded soundtrack, one of many innovative cost-cutting techniques Welles deployed in an attempt to make an epic film from B-movie resources. The script, adapted by Welles, is a violent reworking of Shakespeare's original, freely cutting and pasting lines into new contexts via a collage technique and recasting "Macbeth" as a clash of pagan and proto-Christian ideologies. Some voodoo trappings of the famous Welles/Houseman Negro Theatre stage adaptation are visible, especially in the film's characterization of the Weird Sisters, who create an effigy of Macbeth as a charm to enchant him. Of all Welles's post-"Kane" Hollywood productions, "Macbeth" is stylistically closest to "Citizen Kane" in its long takes and deep focus photography.

Republic initially trumpeted the film as an important work but decided it did not care for the Scottish accents and held up general release for almost a year after early negative press reaction, including "Life"s comment that Welles's film "doth foully slaughter Shakespeare." Welles left for Europe, while co-producer and lifelong supporter Richard Wilson reworked the soundtrack. Welles returned and cut 20 minutes from the film at Republic's request and recorded narration to cover some gaps. The film was decried as a disaster. "Macbeth" had influential fans in Europe, especially the French poet and filmmaker Jean Cocteau, who hailed the film's "crude, irreverent power" and careful shot design, and described the characters as haunting "the corridors of some dreamlike subway, an abandoned coal mine, and ruined cellars oozing with water."

In Italy he starred as Cagliostro in the 1948 film "Black Magic". His co-star, Akim Tamiroff, impressed Welles so much that Tamiroff would appear in four of Welles's productions during the 1950s and 1960s.

The following year, Welles starred as Harry Lime in Carol Reed's "The Third Man", alongside Joseph Cotten, his friend and co-star from "Citizen Kane", with a script by Graham Greene and a memorable score by Anton Karas.

A few years later, British radio producer Harry Alan Towers would resurrect the Lime character in the radio series "The Adventures of Harry Lime".

Welles appeared as Cesare Borgia in the 1949 Italian film "Prince of Foxes", with Tyrone Power and Mercury Theatre alumnus Everett Sloane, and as the Mongol warrior Bayan in the 1950 film version of the novel "The Black Rose" (again with Tyrone Power).

During this time, Welles was channeling his money from acting jobs into a self-financed film version of Shakespeare's play "Othello". From 1949 to 1951, Welles worked on "Othello", filming on location in Italy and Morocco. The film featured Welles's friends, Micheál Mac Liammóir as Iago and Hilton Edwards as Desdemona's father Brabantio. Suzanne Cloutier starred as Desdemona and Campbell Playhouse alumnus Robert Coote appeared as Iago's associate Roderigo.

Filming was suspended several times as Welles ran out of funds and left for acting jobs, accounted in detail in MacLiammóir's published memoir "Put Money in Thy Purse". The American release prints had a technically flawed soundtrack, suffering from a dropout of sound at every quiet moment. Welles's daughter, Beatrice Welles-Smith, restored "Othello" in 1992 for a wide re-release. The restoration included reconstructing Angelo Francesco Lavagnino's original musical score, which was originally inaudible, and adding ambient stereo sound effects, which were not in the original film. The restoration went on to a successful theatrical run in America.

In 1952, Welles continued finding work in England after the success of the "Harry Lime" radio show. Harry Alan Towers offered Welles another series, "The Black Museum", which ran for 52 weeks with Welles as host and narrator. Director Herbert Wilcox offered Welles the part of the murdered victim in "Trent's Last Case", based on the novel by E. C. Bentley. In 1953, the BBC hired Welles to read an hour of selections from Walt Whitman's epic poem "Song of Myself". Towers hired Welles again, to play Professor Moriarty in the radio series, "The Adventures of Sherlock Holmes", starring John Gielgud and Ralph Richardson.

Welles briefly returned to America to make his first appearance on television, starring in the "Omnibus" presentation of "King Lear", broadcast live on CBS October 18, 1953. Directed by Peter Brook, the production costarred Natasha Parry, Beatrice Straight and Arnold Moss.

In 1954, director George More O'Ferrall offered Welles the title role in the 'Lord Mountdrago' segment of "Three Cases of Murder", co-starring Alan Badel. Herbert Wilcox cast Welles as the antagonist in "Trouble in the Glen" opposite Margaret Lockwood, Forrest Tucker and Victor McLaglen. Old friend John Huston cast him as Father Mapple in his 1956 film adaptation of Herman Melville's "Moby-Dick", starring Gregory Peck.

Welles's next turn as director was the film "Mr. Arkadin" (1955), which was produced by his political mentor from the 1940s, Louis Dolivet. It was filmed in France, Germany, Spain and Italy on a very limited budget. Based loosely on several episodes of the Harry Lime radio show, it stars Welles as a billionaire who hires a man to delve into the secrets of his past. The film stars Robert Arden, who had worked on the Harry Lime series; Welles's third wife, Paola Mori, whose voice was dubbed by actress Billie Whitelaw; and guest stars Akim Tamiroff, Michael Redgrave, Katina Paxinou and Mischa Auer. Frustrated by his slow progress in the editing room, producer Dolivet removed Welles from the project and finished the film without him. Eventually five different versions of the film would be released, two in Spanish and three in English. The version that Dolivet completed was retitled "Confidential Report". In 2005 Stefan Droessler of the Munich Film Museum oversaw a reconstruction of the surviving film elements.

In 1955, Welles also directed two television series for the BBC. The first was "Orson Welles' Sketch Book", a series of six 15-minute shows featuring Welles drawing in a sketchbook to illustrate his reminiscences for the camera (including such topics as the filming of "It's All True" and the Isaac Woodard case), and the second was "Around the World with Orson Welles", a series of six travelogues set in different locations around Europe (such as Vienna, the Basque Country between France and Spain, and England). Welles served as host and interviewer, his commentary including documentary facts and his own personal observations (a technique he would continue to explore in later works).

During Episode 3 of Sketchbook Welles makes a deliberate attack on the abuse of police powers around the world. The episode starts with him telling the story of Isaac Woodard, an African-American Veteran of the South Pacific during World War II being falsely accused by a bus driver of being drunk and disorderly, who then has a policeman remove the man from the bus. Woodard is not arrested right away, but rather he is beaten into unconsciousness nearly to the point of death and when he finally regains consciousness he is permanently blinded. By the time doctors from the US Army located him three weeks later there was nothing that could be done. Welles assures the audience that he personally saw to it that justice was served to this policeman although he doesn't mention what type of justice was delivered. Welles then goes on to give other examples of police being given more power and authority than is necessary. The title of this episode is: The Police.

In 1956, Welles completed "Portrait of Gina". The film cans would remain in a lost-and-found locker at the hotel for several decades, where they were discovered after Welles's death.

In 1956, Welles returned to Hollywood.

He began filming a projected pilot for Desilu, owned by Lucille Ball and her husband Desi Arnaz, who had recently purchased the former RKO studios. The film was "The Fountain of Youth", based on a story by John Collier. Originally deemed not viable as a pilot, the film was not aired until 1958—and won the Peabody Award for excellence.

Welles guest starred on television shows including "I Love Lucy". On radio, he was narrator of "Tomorrow" (October 17, 1956), a nuclear holocaust drama produced and syndicated by ABC and the Federal Civil Defense Administration.

Welles's next feature film role was in "Man in the Shadow" for Universal Pictures in 1957, starring Jeff Chandler.

Welles stayed on at Universal to direct (and co-star with) Charlton Heston in the 1958 film "Touch of Evil", based on Whit Masterson's novel "Badge of Evil". Originally only hired as an actor, Welles was promoted to director by Universal Studios at the insistence of Charlton Heston. The film reunited many actors and technicians with whom Welles had worked in Hollywood in the 1940s, including cameraman Russell Metty ("The Stranger"), makeup artist Maurice Seiderman ("Citizen Kane"), and actors Joseph Cotten, Marlene Dietrich and Akim Tamiroff. Filming proceeded smoothly, with Welles finishing on schedule and on budget, and the studio bosses praising the daily rushes. Nevertheless, after the end of production, the studio re-edited the film, re-shot scenes, and shot new exposition scenes to clarify the plot. Welles wrote a 58-page memo outlining suggestions and objections, stating that the film was no longer his version—it was the studio's, but as such, he was still prepared to help with it.

In 1978, a longer preview version of the film was discovered and released.

As Universal reworked "Touch of Evil", Welles began filming his adaptation of Miguel de Cervantes's novel "Don Quixote" in Mexico, starring Mischa Auer as Quixote and Akim Tamiroff as Sancho Panza.

He continued shooting "Don Quixote" in Spain and Italy, but replaced Mischa Auer with Francisco Reiguera, and resumed acting jobs.
In Italy in 1959, Welles directed his own scenes as King Saul in Richard Pottier's film "David and Goliath". In Hong Kong he co-starred with Curt Jürgens in Lewis Gilbert's film "Ferry to Hong Kong". In 1960, in Paris he co-starred in Richard Fleischer's film "Crack in the Mirror". In Yugoslavia he starred in Richard Thorpe's film "The Tartars" and Veljko Bulajić's "Battle of Neretva".

Throughout the 1960s, filming continued on "Quixote" on-and-off until the end of the decade, as Welles evolved the concept, tone and ending several times. Although he had a complete version of the film shot and edited at least once, he would continue toying with the editing well into the 1980s, he never completed a version of the film he was fully satisfied with, and would junk existing footage and shoot new footage. (In one case, he had a complete cut ready in which Quixote and Sancho Panza end up going to the moon, but he felt the ending was rendered obsolete by the 1969 moon landings, and burned 10 reels of this version.) As the process went on, Welles gradually voiced all of the characters himself and provided narration. In 1992, the director Jesús Franco constructed a film out of the portions of "Quixote" left behind by Welles. Some of the film stock had decayed badly. While the Welles footage was greeted with interest, the post-production by Franco was met with harsh criticism.

In 1961, Welles directed "In the Land of Don Quixote", a series of eight half-hour episodes for the Italian television network RAI. Similar to the "Around the World with Orson Welles" series, they presented travelogues of Spain and included Welles's wife, Paola, and their daughter, Beatrice. Though Welles was fluent in Italian, the network was not interested in him providing Italian narration because of his accent, and the series sat unreleased until 1964, by which time the network had added Italian narration of its own. Ultimately, versions of the episodes were released with the original musical score Welles had approved, but without the narration.

In 1962, Welles directed his adaptation of "The Trial", based on the novel by Franz Kafka and produced by Michael and Alexander Salkind. The cast included Anthony Perkins as Josef K, Jeanne Moreau, Romy Schneider, Paola Mori and Akim Tamiroff. While filming exteriors in Zagreb, Welles was informed that the Salkinds had run out of money, meaning that there could be no set construction. No stranger to shooting on found locations, Welles soon filmed the interiors in the Gare d'Orsay, at that time an abandoned railway station in Paris. Welles thought the location possessed a "Jules Verne modernism" and a melancholy sense of "waiting", both suitable for Kafka. To remain in the spirit of Kafka Welles set up the cutting room together with the Film Editor, Frederick Muller (as Fritz Muller), in the old un-used, cold, depressing, station master office. The film failed at the box-office. Peter Bogdanovich would later observe that Welles found the film riotously funny. Welles also told a BBC interviewer that it was his best film. While filming "The Trial" Welles met Oja Kodar, who later became his mistress and collaborator for the last 20 years of his life.

Welles played a film director in "La Ricotta" (1963), Pier Paolo Pasolini's segment of the "Ro.Go.Pa.G." movie, although his renowned voice was dubbed by Italian writer Giorgio Bassani. He continued taking what work he could find acting, narrating or hosting other people's work, and began filming "Chimes at Midnight", which was completed in 1965.

Filmed in Spain, "Chimes at Midnight" was based on Welles's play, "Five Kings", in which he drew material from six Shakespeare plays to tell the story of Sir John Falstaff (Welles) and his relationship with Prince Hal (Keith Baxter). The cast includes John Gielgud, Jeanne Moreau, Fernando Rey and Margaret Rutherford; the film's narration, spoken by Ralph Richardson, is taken from the chronicler Raphael Holinshed. Welles held the film in high regard: "It's my favorite picture, yes. If I wanted to get into heaven on the basis of one movie, that's the one I would offer up."

In 1966, Welles directed a film for French television, an adaptation of "The Immortal Story", by Karen Blixen. Released in 1968, it stars Jeanne Moreau, Roger Coggio and Norman Eshley. The film had a successful run in French theaters. At this time Welles met Oja Kodar again, and gave her a letter he had written to her and had been keeping for four years; they would not be parted again. They immediately began a collaboration both personal and professional. The first of these was an adaptation of Blixen's "The Heroine", meant to be a companion piece to "The Immortal Story" and starring Kodar. Unfortunately, funding disappeared after one day's shooting. After completing this film, he appeared in a brief cameo as Cardinal Wolsey in Fred Zinnemann's adaptation of "A Man for All Seasons"—a role for which he won considerable acclaim.
In 1967, Welles began directing "The Deep", based on the novel "Dead Calm" by Charles Williams and filmed off the shore of Yugoslavia. The cast included Jeanne Moreau, Laurence Harvey and Kodar. Personally financed by Welles and Kodar, they could not obtain the funds to complete the project, and it was abandoned a few years later after the death of Harvey. The surviving footage was eventually edited and released by the Filmmuseum München. In 1968 Welles began filming a TV special for CBS under the title "Orson's Bag", combining travelogue, comedy skits and a condensation of Shakespeare's play "The Merchant of Venice" with Welles as Shylock. In 1969 Welles called again the Film Editor Frederick Muller to work with him re-editing the material and they set up cutting rooms at the Safa Palatino Studios in Rome. Funding for the show sent by CBS to Welles in Switzerland was seized by the IRS. Without funding, the show was not completed. The surviving film clips portions were eventually released by the Filmmuseum München.

In 1969, Welles authorized the use of his name for a cinema in Cambridge, Massachusetts. The Orson Welles Cinema remained in operation until 1986, with Welles making a personal appearance there in 1977. Also in 1969 he played a supporting role in John Huston's "The Kremlin Letter". Drawn by the numerous offers he received to work in television and films, and upset by a tabloid scandal reporting his affair with Kodar, Welles abandoned the editing of "Don Quixote" and moved back to America in 1970.

Welles returned to Hollywood, where he continued to self-finance his film and television projects. While offers to act, narrate and host continued, Welles also found himself in great demand on television talk shows. He made frequent appearances for Dick Cavett, Johnny Carson, Dean Martin and Merv Griffin.

Welles's primary focus during his final years was "The Other Side of the Wind", a project that was filmed intermittently between 1970 and 1976. Co-written by Welles and Oja Kodar, it is the story of an aging film director (John Huston) looking for funds to complete his final film. The cast includes Peter Bogdanovich, Susan Strasberg, Norman Foster, Edmond O'Brien, Cameron Mitchell and Dennis Hopper. Financed by Iranian backers, ownership of the film fell into a legal quagmire after the Shah of Iran was deposed. The legal disputes kept the film in its unfinished state until early 2017, and was finally released in November 2018.
Welles portrayed Louis XVIII of France in the 1970 film "Waterloo", and narrated the beginning and ending scenes of the historical comedy "Start the Revolution Without Me" (1970).

In 1971, Welles directed a short adaptation of "Moby-Dick", a one-man performance on a bare stage, reminiscent of his 1955 stage production "Moby Dick—Rehearsed". Never completed, it was eventually released by the Filmmuseum München. He also appeared in "Ten Days' Wonder", co-starring with Anthony Perkins and directed by Claude Chabrol (who reciprocated with a bit part as himself in "Other Wind"), based on a detective novel by Ellery Queen. That same year, the Academy of Motion Picture Arts and Sciences gave him an Academy Honorary Award "for superlative artistry and versatility in the creation of motion pictures." Welles pretended to be out of town and sent John Huston to claim the award, thanking the Academy on film. In his speech, Huston criticized the Academy for presenting the award while refusing to support Welles' projects.

In 1972, Welles acted as on-screen narrator for the film documentary version of Alvin Toffler's 1970 book "Future Shock". Working again for a British producer, Welles played Long John Silver in director John Hough's "Treasure Island" (1972), an adaptation of the Robert Louis Stevenson novel, which had been the second story broadcast by "The Mercury Theatre on the Air" in 1938. This was the last time he played the lead role in a major film. Welles also contributed to the script, his writing credit was attributed to the pseudonym 'O. W. Jeeves'. In some versions of the film Welles's original recorded dialog was redubbed by Robert Rietty.

In 1973, Welles completed "F for Fake", a personal essay film about art forger Elmyr de Hory and the biographer Clifford Irving. Based on an existing documentary by François Reichenbach, it included new material with Oja Kodar, Joseph Cotten, Paul Stewart and William Alland. An excerpt of Welles's 1930s "War of the Worlds" broadcast was recreated for this film; however, none of the dialogue heard in the film actually matches what was originally broadcast. Welles filmed a five-minute trailer, rejected in the U.S., that featured several shots of a topless Kodar.

Welles hosted a British syndicated anthology series, "Orson Welles's Great Mysteries", during the 1973–74 television season. His brief introductions to the 26 half-hour episodes were shot in July 1973 by Gary Graver. The year 1974 also saw Welles lending his voice for that year's remake of Agatha Christie's classic thriller "Ten Little Indians" produced by his former associate, Harry Alan Towers and starring an international cast that included Oliver Reed, Elke Sommer and Herbert Lom.

In 1975, Welles narrated the documentary "", focusing on Warner Bros. cartoons from the 1940s. Also in 1975, the American Film Institute presented Welles with its third Lifetime Achievement Award (the first two going to director John Ford and actor James Cagney). At the ceremony, Welles screened two scenes from the nearly finished "The Other Side of the Wind".

In 1976, Paramount Television purchased the rights for the entire set of Rex Stout's Nero Wolfe stories for Orson Welles. Welles had once wanted to make a series of Nero Wolfe movies, but Rex Stout—who was leery of Hollywood adaptations during his lifetime after two disappointing 1930s films—turned him down. Paramount planned to begin with an ABC-TV movie and hoped to persuade Welles to continue the role in a mini-series. Frank D. Gilroy was signed to write the television script and direct the TV movie on the assurance that Welles would star, but by April 1977 Welles had bowed out. In 1980 the Associated Press reported "the distinct possibility" that Welles would star in a Nero Wolfe TV series for NBC television. Again, Welles bowed out of the project due to creative differences and William Conrad was cast in the role.

In 1979, Welles completed his documentary "Filming Othello", which featured Michael MacLiammoir and Hilton Edwards. Made for West German television, it was also released in theaters. That same year, Welles completed his self-produced pilot for "The Orson Welles Show" television series, featuring interviews with Burt Reynolds, Jim Henson and Frank Oz and guest-starring the Muppets and Angie Dickinson. Unable to find network interest, the pilot was never broadcast. Also in 1979, Welles appeared in the biopic "The Secret of Nikola Tesla", and a cameo in "The Muppet Movie" as Lew Lord.

Beginning in the late 1970s, Welles participated in a series of famous television commercial advertisements. For two years he was on-camera spokesman for the Paul Masson Vineyards, and sales grew by one third during the time Welles intoned what became a popular catchphrase: "We will sell no wine before its time." He was also the voice behind the long-running Carlsberg "Probably the best lager in the world" campaign, promoted Domecq sherry on British television and provided narration on adverts for Findus, though the actual adverts have been overshadowed by a famous blooper reel of voice recordings, known as the Frozen Peas reel. He also did commercials for the Preview Subscription Television Service seen on stations around the country including WCLQ/Cleveland, KNDL/St. Louis and WSMW/Boston. As money ran short, he began directing commercials to make ends meet, including the famous British "Follow the Bear" commercials for Hofmeister lager.

In 1981, Welles hosted the documentary "The Man Who Saw Tomorrow", about Renaissance-era prophet Nostradamus. In 1982, the BBC broadcast "The Orson Welles Story" in the "Arena" series. Interviewed by Leslie Megahey, Welles examined his past in great detail, and several people from his professional past were interviewed as well. It was reissued in 1990 as "With Orson Welles: Stories of a Life in Film". Welles provided narration for the tracks "Defender" from Manowar's 1987 album "Fighting the World" and "Dark Avenger" on their 1982 album, "Battle Hymns". He also recorded the concert introduction for the live performances of Manowar that says, "Ladies and gentlemen, from the United States of America, all hail Manowar." Manowar have been using this introduction for all of their concerts since then.

During the 1980s, Welles worked on such film projects as "The Dreamers", based on two stories by Isak Dinesen and starring Oja Kodar, and "Orson Welles' Magic Show", which reused material from his failed TV pilot. Another project he worked on was "Filming The Trial", the second in a proposed series of documentaries examining his feature films. While much was shot for these projects, none of them was completed. All of them were eventually released by the Filmmuseum München.

In 1984, Welles narrated the short-lived television series "Scene of the Crime". During the early years of "Magnum, P.I.", Welles was the voice of the unseen character Robin Masters, a famous writer and playboy. Welles's death forced this minor character to largely be written out of the series. In an oblique homage to Welles, the "Magnum, P.I." producers ambiguously concluded that story arc by having one character accuse another of having hired an actor to portray Robin Masters. He also, in this penultimate year released a music single, titled "I Know What It Is To Be Young (But You Don't Know What It Is To Be Old)", which he recorded under Italian label Compagnia Generale del Disco. The song was performed with the Nick Perito Orchestra and the Ray Charles Singers and produced by Jerry Abbott (father of guitarist "Dimebag Darrell" Abbott).

The last film roles before Welles's death included voice work in the animated films "Enchanted Journey" (1984) and "" (1986), in which he played the planet-eating robot Unicron. His last film appearance was in Henry Jaglom's 1987 independent film "Someone to Love", released two years after his death but produced before his voice-over in "Transformers: The Movie". His last television appearance was on the television show "Moonlighting". He recorded an introduction to an episode entitled "The Dream Sequence Always Rings Twice", which was partially filmed in black and white. The episode aired five days after his death and was dedicated to his memory.

In the mid-1980s, Henry Jaglom taped lunch conversations with Welles at Los Angeles's Ma Maison as well as in New York. Edited transcripts of these sessions appear in Peter Biskind's 2013 book "My Lunches With Orson: Conversations Between Henry Jaglom and Orson Welles".

Orson Welles and Chicago-born actress and socialite Virginia Nicolson (1916–1996) were married on November 14, 1934. The couple separated in December 1939 and were divorced on February 1, 1940. After bearing with Welles's romances in New York, Virginia had learned that Welles had fallen in love with Mexican actress Dolores del Río.

Infatuated with her since adolescence, Welles met del Río at Darryl Zanuck's ranch soon after he moved to Hollywood in 1939. Their relationship was kept secret until 1941, when del Río filed for divorce from her second husband. They openly appeared together in New York while Welles was directing the Mercury stage production "Native Son". They acted together in the movie "Journey into Fear" (1943). Their relationship came to an end due, among other things, to Welles's infidelities. Del Río returned to Mexico in 1943, shortly before Welles married Rita Hayworth.

Welles married Rita Hayworth on September 7, 1943. They were divorced on November 10, 1947. During his last interview, recorded for "The Merv Griffin Show" on the evening before his death, Welles called Hayworth "one of the dearest and sweetest women that ever lived … and we were a long time together—I was lucky enough to have been with her longer than any of the other men in her life."

In 1955, Welles married actress Paola Mori (née Countess Paola di Gerfalco), an Italian aristocrat who starred as Raina Arkadin in his 1955 film, "Mr. Arkadin". The couple began a passionate affair, and they were married at her parents' insistence. They were wed in London May 8, 1955, and never divorced.

Croatian-born artist and actress Oja Kodar became Welles's longtime companion both personally and professionally from 1966 onward, and they lived together for some of the last 20 years of his life.

Welles had three daughters from his marriages: Christopher Welles Feder (born March 27, 1938, with Virginia Nicolson); Rebecca Welles Manning (December 17, 1944 – October 17, 2004, with Rita Hayworth); and Beatrice Welles (born November 13, 1955, with Paola Mori).

Welles is thought to have had a son, British director Michael Lindsay-Hogg (born May 5, 1940), with Irish actress Geraldine Fitzgerald, then the wife of Sir Edward Lindsay-Hogg, 4th baronet. When Lindsay-Hogg was 16, his mother reluctantly divulged pervasive rumors that his father was Welles, and she denied them—but in such detail that he doubted her veracity. Fitzgerald evaded the subject for the rest of her life. Lindsay-Hogg knew Welles, worked with him in the theatre and met him at intervals throughout Welles's life. After learning that Welles's oldest daughter, Chris, his childhood playmate, had long suspected that he was her brother, Lindsay-Hogg initiated a DNA test that proved inconclusive. In his 2011 autobiography, Lindsay-Hogg reported that his questions were resolved by his mother's close friend Gloria Vanderbilt, who wrote that Fitzgerald had told her that Welles was his father. A 2015 Welles biography by Patrick McGilligan, however, reports the impossibility of Welles's paternity: Fitzgerald left the U.S. for Ireland in May 1939, and her son was conceived before her return in late October, whereas Welles did not travel overseas during that period.

After the death of Rebecca Welles Manning, a man named Marc McKerrow was revealed to be her son—and therefore a direct descendant of Orson Welles and Rita Hayworth. McKerrow's reactions to the revelation and his meeting with Oja Kodar are documented in the 2008 film "Prodigal Sons". McKerrow died on June 18, 2010.

Despite an urban legend promoted by Welles, he was not related to Abraham Lincoln's wartime Secretary of the Navy, Gideon Welles. The myth dates back to the first newspaper feature ever written about Welles—"Cartoonist, Actor, Poet and only 10"—in the February 19, 1926, issue of "The Capital Times". The article falsely states that he was descended from "Gideon Welles, who was a member of President Lincoln's cabinet". As presented by Charles Higham in a genealogical chart that introduces his 1985 biography of Welles, Orson Welles's father was Richard Head Welles (born Wells), son of Richard Jones Wells, son of Henry Hill Wells (who had an uncle named Gideon "Wells"), son of William Hill Wells, son of Richard Wells (1734–1801).

Peter Noble's 1956 biography describes Welles as "a magnificent figure of a man, over six feet tall, handsome, with flashing eyes and a gloriously resonant speaking-voice". Welles said that a voice specialist once told him he was born to be a heldentenor, a heroic tenor, but that when he was young and working at the Gate Theatre in Dublin, he forced his voice down into a bass-baritone.

Even as a baby, Welles was prone to illness, including diphtheria, measles, whooping cough, and malaria. From infancy he suffered from asthma, sinus headaches, and backache that was later found to be caused by congenital anomalies of the spine. Foot and ankle trouble throughout his life was the result of flat feet. "As he grew older", Brady wrote, "his ill health was exacerbated by the late hours he was allowed to keep [and] an early penchant for alcohol and tobacco".

In 1928, at age 13, Welles was already more than six feet tall (1.83 meters) and weighed over 180 pounds (81.6 kg). His passport recorded his height as six feet three inches (192 cm), with brown hair and green eyes.

"Crash diets, drugs, and corsets had slimmed him for his early film roles", wrote biographer Barton Whaley. "Then always back to gargantuan consumption of high-caloric food and booze. By summer 1949, when he was 34, his weight had crept up to a stout 230 pounds (104 kg). In 1953, he ballooned from 250 to 275 pounds (113 to 125 kg). After 1960, he remained permanently obese."

When Peter Bogdanovich once asked him about his religion, Welles gruffly replied that it was none of his business, then misinformed him that he was raised Catholic.

Although the Welles family was no longer devout, it was fourth-generation Protestant Episcopalian and, before that, Quaker and Puritan.

The funeral of Welles's father, Richard H. Welles, was Episcopalian.

In April 1982, when interviewer Merv Griffin asked him about his religious beliefs, Welles replied, "I try to be a Christian. I don't pray really, because I don't want to bore God." Near the end of his life, Welles was dining at Ma Maison, his favorite restaurant in Los Angeles, when proprietor Patrick Terrail conveyed an invitation from the head of the Greek Orthodox Church, who asked Welles to be his guest of honor at divine liturgy at Saint Sophia Cathedral. Welles replied, "Please tell him I really appreciate that offer, but I am an atheist."

"Orson never joked or teased about the religious beliefs of others", wrote biographer Barton Whaley. "He accepted it as a cultural artifact, suitable for the births, deaths, and marriages of strangers and even some friends—but without emotional or intellectual meaning for himself."

Welles was politically active from the beginning of his career. He remained aligned with the left throughout his life, and always defined his political orientation as "progressive". He was an outspoken critic of racism in the United States and the practice of segregation. He was a strong supporter of Franklin D. Roosevelt and the New Deal and often spoke out on radio in support of progressive politics. He campaigned heavily for Roosevelt in the 1944 election. Welles did not support the 1948 presidential bid of Roosevelt's second vice president Henry A. Wallace for the Progressive Party, however, later describing Wallace as "a prisoner of the Communist Party."

"During a White House dinner," Welles recalled in a 1983 conversation with his friend Roger Hill, "when I was campaigning for Roosevelt, in a toast, with considerable tongue in cheek, he said, 'Orson, you and I are the two greatest actors alive today.' In private that evening, and on several other occasions, he urged me to run for a Senate seat in either California or Wisconsin. He wasn't alone." In the 1980s, Welles still expressed admiration for Roosevelt but also described his presidency as "a semidictatorship."

During a 1970 appearance on "The Dick Cavett Show", Welles claimed to have met Hitler while hiking in Austria with a teacher who was a "budding Nazi". He said that Hitler made no impression on him at all and does not remember him. He said that he had no personality at all: "He was invisible. There was nothing there until there were 5,000 people yelling sieg heil."

For several years, he wrote a newspaper column on political issues and considered running for the U.S. Senate in 1946, representing his home state of Wisconsin—a seat that was ultimately won by Joseph McCarthy.

Welles's political activities were reported on pages 155–157 of "Red Channels", the anti-Communist publication that, in part, fueled the already flourishing Hollywood Blacklist. He was in Europe during the height of the Red Scare, thereby adding one more reason for the Hollywood establishment to ostracize him.

In 1970, Welles narrated (but did not write) a satirical political record on the rise of President Richard Nixon titled "The Begatting of the President".

He was a lifelong member of the International Brotherhood of Magicians and the Society of American Magicians.

On the evening of October 9, 1985, Welles recorded his final interview on syndicated TV program "The Merv Griffin Show", appearing with biographer Barbara Leaming. "Both Welles and Leaming talked of Welles's life, and the segment was a nostalgic interlude," wrote biographer Frank Brady. Welles returned to his house in Hollywood and worked into the early hours typing stage directions for the project he and Gary Graver were planning to shoot at UCLA the following day. Welles died sometime on the morning of October 10, following a heart attack. He was found by his chauffeur at around 10 a.m.; the first of Welles's friends to arrive was Paul Stewart. Welles was 70 years old at his death.

Welles was cremated by prior agreement with the executor of his estate, Greg Garrison, whose advice about making lucrative TV appearances in the 1970s made it possible for Welles to pay off a portion of the taxes he owed the IRS. A brief private funeral was attended by Paola Mori and Welles's three daughters—the first time they had ever been together. Only a few close friends were invited: Garrison, Graver, Roger Hill and Prince Alessandro Tasca di Cuto. Chris Welles Feder later described the funeral as an awful experience.

A public memorial tribute took place November 2, 1985, at the Directors Guild of America Theater in Los Angeles. Host Peter Bogdanovich introduced speakers including Charles Champlin, Geraldine Fitzgerald, Greg Garrison, Charlton Heston, Roger Hill, Henry Jaglom, Arthur Knight, Oja Kodar, Barbara Leaming, Janet Leigh, Norman Lloyd, Dan O'Herlihy, Patrick Terrail and Robert Wise.

"I know what his feelings were regarding his death", Joseph Cotten later wrote. "He did not want a funeral; he wanted to be buried quietly in a little place in Spain. He wanted no memorial services ..." Cotten declined to attend the memorial program; instead he sent a short message, ending with the last two lines of a Shakespeare sonnet that Welles had sent him on his most recent birthday:

But if the while I think on thee, dear friend,All losses are restored and sorrows end.

In 1987 the ashes of Welles and Mori (killed in a 1986 car crash) were taken to Ronda, Spain, and buried in an old well covered by flowers on the rural estate of a longtime friend, bullfighter Antonio Ordóñez.

Welles's reliance on self-production meant that many of his later projects were filmed piecemeal or were not completed. Welles financed his later projects through his own fundraising activities. He often also took on other work to obtain money to fund his own films.

In the mid-1950s, Welles began work on "Don Quixote", initially a commission from CBS television. Welles expanded the film to feature length, developing the screenplay to take Quixote and Sancho Panza into the modern age. Filming stopped with the death of Francisco Reiguera, the actor playing Quixote, in 1969. Orson Welles continued editing the film into the early 1970s. At the time of his death, the film remained largely a collection of footage in various states of editing. The project and, more important, Welles's conception of the project changed radically over time.

A version Oja Kodar supervised, with help from Jess Franco, assistant director during production, was released in 1992 to poor reviews.

Frederick Muller, the film editor for The "Trial", "Chimes at Midnight," and the CBS Special "Orson Bag," worked on editing three reels of the original, unadulterated version. When asked in 2013 by a journalist of "Time Out" for his opinion, he said that he felt that if released without image re-editing but with the addition of "ad hoc" sound and music, it probably would have been rather successful.

In 1969, Welles was given a TV commission to film a condensed adaptation of "The Merchant of Venice". Welles completed the film by 1970, but the finished negative was later mysteriously stolen from his Rome production office. A restored and reconstructed version of the film, made by using the original script and composer's notes, premiered at pre-opening ceremonies of the 72nd Venice International Film Festival, alongside "Othello", in 2015.

In 1970, Welles began shooting "The Other Side of the Wind". The film relates the efforts of a film director (played by John Huston) to complete his last Hollywood picture and is largely set at a lavish party. By 1972 the filming was reported by Welles as being "96% complete", though by 1979 Welles had only edited about 40 minutes of the film. In that year, legal complications over the ownership of the film put the negative into a Paris vault. In 2004 director Peter Bogdanovich, who acted in the film, announced his intention to complete the production.

On October 28, 2014, Los Angeles-based production company Royal Road Entertainment announced it had negotiated an agreement, with the assistance of producer Frank Marshall, and would purchase the rights to complete and release "The Other Side of the Wind". Bogdanovich and Marshall planned to complete Welles's nearly finished film in Los Angeles, aiming to have it ready for screening May 6, 2015, the 100th anniversary of Welles's birth. Royal Road Entertainment and German producer Jens Koethner Kaul acquired the rights held by Les Films de l'Astrophore and the late Mehdi Boushehri. They reached an agreement with Oja Kodar, who inherited Welles's ownership of the film, and Beatrice Welles, manager of the Welles estate; but at the end of 2015, efforts to complete the film were at an impasse.

In March 2017, Netflix acquired distribution rights to the film. That month, the original negative, dailies and other footage arrived in Los Angeles for post-production; the film was completed in 2018. The film premiered at the 75th Venice International Film Festival on August 31, 2018.

On November 2, 2018, the film debuted in select theaters and on Netflix, forty-eight years after principal photography began.

Some footage is included in the documentaries "Working with Orson Welles" (1993), "Orson Welles: One Man Band" (1995), and most extensively "They'll Love Me When I'm Dead" (2018).

"Too Much Johnson" is a 1938 comedy film written and directed by Welles. Designed as the cinematic aspect of Welles's Mercury Theatre stage presentation of William Gillette's 1894 comedy, the film was not completely edited or publicly screened. "Too Much Johnson" was considered a lost film until August 2013, with news reports that a pristine print had been discovered in Italy in 2008. A copy restored by the George Eastman House museum was scheduled to premiere October 9, 2013, at the Pordenone Silent Film Festival, with a U.S. premiere to follow. A single performance of "Too Much Johnson", on February 2, 2015, at the Film Forum in New York City, was a great success. Produced by Bruce Goldstein and adapted and directed by Allen Lewis Rickman, it featured the Film Forum Players with live piano.

"Heart of Darkness" was Welles's projected first film, in 1940. It was planned in extreme detail and some test shots were filmed; the footage is now lost. It was planned to be entirely shot in long takes from the point of view of the narrator, Marlow, who would be played by Welles; his reflection would occasionally be seen in the window as his boat sailed down river. The project was abandoned because it could not be delivered on budget, and "Citizen Kane" was made instead.

In 1941, Welles planned a film with his then partner, the Mexican actress Dolores del Río. "Santa" was adapted from the novel by Mexican writer Federico Gamboa. The film would have marked the debut of Dolores del Río in the Mexican cinema. Welles made a correction of the script in 13 extraordinary sequences. The high salary demanded by del Río stopped the project. In 1943, the film was finally completed with the settings of Welles, led by Norman Foster and starring Mexican actress Esther Fernández.

In 1941 Welles also planned a Mexican drama with Dolores del Río, which he gave to RKO to be budgeted. The film was a movie version of the novel by the same name by Calder Marshall. In the story, del Río would play Elena Medina, "the most beautiful girl in the world", with Welles playing an American who becomes entangled in a mission to disrupt a Nazi plot to overthrow the Mexican government. Welles planned to shoot in Mexico, but the Mexican government had to approve the story, and this never occurred.

In 1941, Welles received the support of Bishop Fulton Sheen for a retelling of the life of Christ, to be set in the American West in the 1890s. After filming of "Citizen Kane" was complete, Welles, Perry Ferguson, and Gregg Toland scouted locations in Baja California and Mexico. Welles wrote a screenplay with dialogue from the Gospels of Mark, Matthew, and Luke. "Every word in the film was to be from the Bible — no original dialogue, but done as a sort of American primitive," Welles said, "set in the frontier country in the last century." The unrealized project was revisited by Welles in the 1950s, when he wrote a second unfilmed screenplay, to be shot in Egypt.

Welles did not originally want to direct "It's All True", a 1942 documentary about South America, but after its abandonment by RKO, he spent much of the 1940s attempting to buy the negative of his material from RKO, so that he could edit and release it in some form. The footage remained unseen in vaults for decades, and was assumed lost. Over 50 years later, some (but not all) of the surviving material saw release in the 1993 documentary "It's All True: Based on an Unfinished Film by Orson Welles".

In 1944, Welles wrote the first-draft script of "Monsieur Verdoux", a film that he also intended to direct. Charlie Chaplin initially agreed to star in it, but later changed his mind, citing never having been directed by someone else in a feature before. Chaplin bought the film rights and made the film himself in 1947, with some changes. The final film credits Chaplin with the script, "based on an idea by Orson Welles".

Welles spent around nine months around 1947–48 co-writing the screenplay for "Cyrano de Bergerac" along with Ben Hecht, a project Welles was assigned to direct for Alexander Korda. He began scouting for locations in Europe whilst filming "Black Magic", but Korda was short of money, so sold the rights to Columbia pictures, who eventually dismissed Welles from the project, and then sold the rights to United Artists, who in turn made a film version in 1950, which was not based on Welles's script.

After Welles's elaborate musical stage version of this Jules Verne novel, encompassing 38 different sets, went live in 1946, Welles shot some test footage in Morocco in 1947 for a film version. The footage was never edited, funding never came through, and Welles abandoned the project. Nine years later, the stage show's producer Mike Todd made his own award-winning film version of the book.

"Moby Dick—Rehearsed" was a film version of Welles's 1955 London meta-play, starring Gordon Jackson, Christopher Lee, Patrick McGoohan, and with Welles as Ahab. Using bare, minimalist sets, Welles alternated between a cast of nineteenth-century actors rehearsing a production of "Moby Dick", with scenes from "Moby Dick" itself. Kenneth Williams, a cast member who was apprehensive about the entire project, recorded in his autobiography that Welles's dim, atmospheric stage lighting made some of the footage so dark as to be unwatchable. The entire play was filmed, but is now presumed lost. This was made during one weekend at the Hackney Empire theater.

The producers of "Histoires extraordinaires", a 1968 anthology film based on short stories by Edgar Allan Poe, announced in June 1967 that Welles would direct one segment based on both "Masque of the Red Death" and "The Cask of Amontillado" for the omnibus film. Welles withdrew in September 1967 and was replaced. The script, written in English by Welles and Oja Kodar, is in the Filmmuseum Munchen collection.

This Monty Python-esque spoof in which Welles plays all but one of the characters (including two characters in drag), was made around 1968-9. Welles intended this completed sketch to be one of several items in a television special on London. Other items filmed for this special – all included in the "One Man Band" documentary by his partner Oja Kodar — comprised a sketch on Winston Churchill (played in silhouette by Welles), a sketch on peers in a stately home, a feature on London gentlemen's clubs, and a sketch featuring Welles being mocked by his snide Savile Row tailor (played by Charles Gray).

Welles wrote two screenplays for "Treasure Island" in the 1960s, and was eager to seek financial backing to direct it. His plan was to film it in Spain in concert with "Chimes at Midnight". Welles intended to play the part of Long John Silver. He wanted Keith Baxter to play Doctor Livesey and John Gielgud to take on the role of Squire Trelawney. Australian-born child actor Fraser MacIntosh ("The Boy Cried Murder"), then 11-years old, was cast as Jim Hawkins and flown to Spain for the shoot, which would have been directed by Jess Franco. About 70 percent of the "Chimes at Midnight" cast would have had roles in "Treasure Island". However, funding for the project fell through. Eventually, Welles's own screenplay (under the pseudonym of O.W. Jeeves) was further rewritten, and formed the basis of the 1972 film version directed by John Hough, in which Welles played Long John Silver.

"The Deep", an adaptation of Charles Williams's "Dead Calm", was entirely set on two boats and shot mostly in close-ups. It was filmed off the coasts of Yugoslavia and the Bahamas between 1966 and 1969, with all but one scene completed. It was originally planned as a commercially viable thriller, to show that Welles could make a popular, successful film. It was put on hold in 1970 when Welles worried that critics would not respond favorably to this film as his theatrical follow-up to the much-lauded "Chimes at Midnight", and Welles focused instead on "F for Fake". It was abandoned altogether in 1973, perhaps due to the death of its star Laurence Harvey. In a 2015 interview, Oja Kodar blamed Welles's failure to complete the film on Jeanne Moreau's refusal to participate in its dubbing.

"Dune", an early attempt at adapting Frank Herbert's sci-fi novel by Chilean film director Alejandro Jodorowsky, was to star Welles as the evil Baron Vladimir Harkonnen. Jodorowsky had personally chosen Welles for the role, but the planned film never advanced past pre-production.

In 1978 Welles was lined up by his long-time protégé Peter Bogdanovich (who was then acting as Welles's "de facto" agent) to direct "Saint Jack", an adaptation of the 1973 Paul Theroux novel about an American pimp in Singapore. Hugh Hefner and Bogdanovich's then-partner Cybill Shepherd were both attached to the project as producers, with Hefner providing finance through his Playboy productions. However, both Hefner and Shepherd became convinced that Bogdanovich himself would be a more commercially viable director than Welles, and insisted that Bogdanovich take over. Since Bogdanovich was also in need of work after a series of box office flops, he agreed. When the film was finally made in 1979 by Bogdanovich and Hefner (but without Welles or Shepherd's participation), Welles felt betrayed and according to Bogdanovich the two "drifted apart a bit".

After the success of his 1978 film "Filming Othello" made for West German television, and mostly consisting of a monolog to the camera, Welles began shooting scenes for this follow-up film, but never completed it. What Welles did film was an 80-minute question-and-answer session in 1981 with film students asking about the film. The footage was kept by Welles's cinematographer Gary Graver, who donated it to the Munich Film Museum, which then pieced it together with Welles's trailer for the film, into an 83-minute film which is occasionally screened at film festivals.

Written by Welles with Oja Kodar, "The Big Brass Ring" was adapted and filmed by director George Hickenlooper in partnership with writer F.X. Feeney. Both the Welles script and the 1999 film center on a U.S. Presidential hopeful in his 40s, his elderly mentor—a former candidate for the Presidency, brought low by homosexual scandal—and the Italian journalist probing for the truth of the relationship between these men. During the last years of his life, Welles struggled to get financing for the planned film; however, his efforts at casting Jack Nicholson, Robert Redford, Warren Beatty, Clint Eastwood, Burt Reynolds and Paul Newman as the main character were unsuccessful. All of the actors turned down the role for various reasons.

In 1984, Welles wrote the screenplay for a film he planned to direct, an autobiographical drama about the 1937 staging of "The Cradle Will Rock". Rupert Everett was slated to play the young Welles. However, Welles was unable to acquire funding. Tim Robbins later directed a similar film, but it was not based on Welles's script.

At the time of his death, Welles was in talks with a French production company to direct a film version of the Shakespeare play "King Lear", in which he would also play the title role.

"" was an adaptation of Vladimir Nabokov's novel. Welles flew to Paris to discuss the project personally with the Russian author.













</doc>
<doc id="22197" url="https://en.wikipedia.org/wiki?curid=22197" title="Open content">
Open content

Open content describes any work that others can copy or modify freely by attributing to the original creator, but without needing to ask for permission. This has been applied to a range of formats, including textbooks, academic journals, films and music. The term was an expansion of the related concept of open-source software. Such content is said to be under an open licence.

The concept of applying free software licenses to content was introduced by Michael Stutz, who in 1994 wrote the paper "Applying Copyleft to Non-Software Information" for the GNU Project. The term "open content" was coined by David A. Wiley in 1998 and evangelized via the "Open Content Project", describing works licensed under the Open Content License (a non-free share-alike license, see 'Free content' below) and other works licensed under similar terms.

It has since come to describe a broader class of content without conventional copyright restrictions. The openness of content can be assessed under the '5Rs Framework' based on the extent to which it can be reused, revised, remixed and redistributed by members of the public without violating copyright law. Unlike free content and content under open-source licenses, there is no clear threshold that a work must reach to qualify as 'open content'.

Although open content has been described as a counterbalance to copyright, open content licenses rely on a copyright holder's power to license their work, similarly as copyleft which also utilizes copyright for such a purpose.

In 2003 Wiley announced that the Open Content Project has been succeeded by Creative Commons and their licenses, where he joined as "Director of Educational Licenses".

In 2005, the Open Icecat project was launched, in which product information for e-commerce applications was created and published under the Open Content License. It was embraced by the tech sector, which was already quite open source minded.

In 2006 the Creative Commons' successor project was the "Definition of Free Cultural Works" for free content, put forth by Erik Möller, Richard Stallman, Lawrence Lessig, Benjamin Mako Hill, Angela Beesley, and others. The "Definition of Free Cultural Works" is used by the Wikimedia Foundation. In 2008, the Attribution and Attribution-ShareAlike Creative Commons licenses were marked as "Approved for Free Cultural Works" among other licenses.
Another successor project is the "Open Knowledge Foundation" ("OKF"), founded by Rufus Pollock in Cambridge, UK in 2004 as a global non-profit network to promote and share open content and data. In 2007 the Open Knowledge Foundation gave an "Open Knowledge Definition" for ""Content such as music, films, books; Data be it scientific, historical, geographic or otherwise; Government and other administrative information"". In October 2014 with version 2.0 "Open Works" and "Open Licenses" were defined and "open" is described as synonymous to the definitions of open/free in the Open Source Definition, the Free Software Definition and the Definition of Free Cultural Works. A distinct difference is the focus given to the public domain and that it focuses also on the accessibility ("open access") and the readability ("open formats"). Among several conformant licenses, six are recommended, three own (Open Data Commons Public Domain Dedication and Licence (PDDL), Open Data Commons Attribution License (ODC-BY), Open Data Commons Open Database License (ODbL)) and the CC BY, CC BY-SA, and CC0 creative commons licenses.

The OpenContent website once defined OpenContent as 'freely available for modification, use and redistribution under a license similar to those used by the open-source / free software community'. However, such a definition would exclude the Open Content License (OPL) because that license forbade charging 'a fee for the [OpenContent] itself', a right required by free and open-source software licenses.

The term since shifted in meaning. OpenContent ""is licensed in a manner that provides users with free and perpetual permission to engage in the 5R activities.""

The 5Rs are put forward on the OpenContent website as a framework for assessing the extent to which content is open:

This broader definition distinguishes open content from open-source software, since the latter must be available for commercial use by the public. However, it is similar to several definitions for open educational resources, which include resources under noncommercial and verbatim licenses.

The later "Open Definition" by the Open Knowledge Foundation (now known as Open Knowledge International) define open knowledge with open content and open data as sub-elements and draws heavily on the Open Source Definition; it preserves the limited sense of open content as free content, unifying both.

"Open access" refers to toll-free or gratis access to content, mainly published originally peer-reviewed scholarly journals. Some open access works are also licensed for reuse and redistribution ("libre open access"), which would qualify them as open content.

Over the past decade, open content has been used to develop alternative routes towards higher education. Traditional universities are expensive, and their tuition rates are increasing. Open content allows a free way of obtaining higher education that is "focused on collective knowledge and the sharing and reuse of learning and scholarly content."
There are multiple projects and organizations that promote learning through open content, including OpenCourseWare Initiative, The Saylor Foundation and Khan Academy. Some universities, like MIT, Yale, and Tufts are making their courses freely available on the internet.

The textbook industry is one of the educational industries in which open content can make the biggest impact. Traditional textbooks, aside from being expensive, can also be inconvenient and out of date, because of publishers' tendency to constantly print new editions. Open textbooks help to eliminate this problem, because they are online and thus easily updatable. Being openly licensed and online can be helpful to teachers, because it allows the textbook to be modified according to the teacher's unique curriculum. There are multiple organizations promoting the creation of openly licensed textbooks. Some of these organizations and projects include The University of Minnesota's Open Textbook Library, Connexions, OpenStax College, The Saylor Foundation Open Textbook Challenge and Wikibooks

According to the current definition of open content on the OpenContent website, any general, royalty-free copyright license would qualify as an open license because it 'provides users with the right to make more kinds of uses than those normally permitted under the law. These permissions are granted to users free of charge.'

However, the narrower definition used in the Open Definition effectively limits open content to libre content, any free content license, defined by the Definition of Free Cultural Works, would qualify as an open content license. According to this narrower criteria, the following still-maintained licenses qualify:

(For more licenses see Open Knowledge, Free content and Free Cultural Works licenses)



</doc>
<doc id="22199" url="https://en.wikipedia.org/wiki?curid=22199" title="Ohio">
Ohio

Ohio is a state in the East North Central region of the Midwestern United States. Of the fifty states, it is the 34th largest by area, the seventh most populous, and the tenth most densely populated. The state's capital and largest city is Columbus. Ohio is bordered by Lake Erie to the north, Pennsylvania to the east, West Virginia to the southeast, Kentucky to the southwest, Indiana to the west, and Michigan to the northwest.

The state takes its name from the Ohio River, whose name in turn originated from the Seneca word " ohiːyo", meaning "good river", "great river" or "large creek". Partitioned from the Northwest Territory, Ohio was the 17th state admitted to the Union on March 1, 1803, and the first under the Northwest Ordinance. Ohio is historically known as the "Buckeye State" after its Ohio buckeye trees, and Ohioans are also known as "Buckeyes".

Ohio rose from the land west of Appalachia in colonial times through the Northwest Indian Wars as part of the Northwest Territory in the early frontier, to become the first non-colonial "free" state admitted to the union, to an industrial powerhouse in the 20th century before transitioning to a more information and service based economy in the 21st.

The government of Ohio is composed of the executive branch, led by the governor; the legislative branch, which comprises the bicameral Ohio General Assembly; and the judicial branch, led by the state Supreme Court. Ohio occupies 16 seats in the United States House of Representatives. Ohio is known for its status as both a swing state and a bellwether in national elections. Seven presidents of the United States have come from Ohio.

Ohio is an industrial state, ranking 8th out of 50 states in GDP (2015), is the third largest US state for manufacturing, and is the second largest producer of automobiles behind Michigan.

Ohio's geographic location has proven to be an asset for economic growth and expansion. Because Ohio links the Northeast to the Midwest, much cargo and business traffic passes through its borders along its well-developed highways. Ohio has the nation's 10th largest highway network and is within a one-day drive of 50% of North America's population and 70% of North America's manufacturing capacity. To the north, Lake Erie gives Ohio of coastline, which allows for numerous cargo ports. Ohio's southern border is defined by the Ohio River (with the border being at the 1792 low-water mark on the north side of the river), and much of the northern border is defined by Lake Erie. Ohio's neighbors are Pennsylvania to the east, Michigan to the northwest, Lake Erie to the north, Indiana to the west, Kentucky on the south, and West Virginia on the southeast. Ohio's borders were defined by metes and bounds in the Enabling Act of 1802 as follows:

Ohio is bounded by the Ohio River, but nearly all of the river itself belongs to Kentucky and West Virginia. In 1980, the U.S. Supreme Court held that, based on the wording of the cessation of territory by Virginia (which at the time included what is now Kentucky and West Virginia), the boundary between Ohio and Kentucky (and, by implication, West Virginia) is the northern low-water mark of the river as it existed in 1792. Ohio has only that portion of the river between the river's 1792 low-water mark and the present high-water mark.

The border with Michigan has also changed, as a result of the Toledo War, to angle slightly northeast to the north shore of the mouth of the Maumee River.

Much of Ohio features glaciated till plains, with an exceptionally flat area in the northwest being known as the Great Black Swamp. This glaciated region in the northwest and central state is bordered to the east and southeast first by a belt known as the glaciated Allegheny Plateau, and then by another belt known as the unglaciated Allegheny Plateau. Most of Ohio is of low relief, but the unglaciated Allegheny Plateau features rugged hills and forests.
The rugged southeastern quadrant of Ohio, stretching in an outward bow-like arc along the Ohio River from the West Virginia Panhandle to the outskirts of Cincinnati, forms a distinct socio-economic unit. Geologically similar to parts of West Virginia and southwestern Pennsylvania, this area's coal mining legacy, dependence on small pockets of old manufacturing establishments, and distinctive regional dialect set this section off from the rest of the state. In 1965 the United States Congress passed the Appalachian Regional Development Act, an attempt to "address the persistent poverty and growing economic despair of the Appalachian Region". This act defines 29 Ohio counties as part of Appalachia. While 1/3 of Ohio's land mass is part of the federally defined Appalachian region, only 12.8% of Ohioans live there (1.476 million people.)
Significant rivers within the state include the Cuyahoga River, Great Miami River, Maumee River, Muskingum River, and Scioto River. The rivers in the northern part of the state drain into the northern Atlantic Ocean via Lake Erie and the St. Lawrence River, and the rivers in the southern part of the state drain into the Gulf of Mexico via the Ohio River and then the Mississippi.

The worst weather disaster in Ohio history occurred along the Great Miami River in 1913. Known as the Great Dayton Flood, the entire Miami River watershed flooded, including the downtown business district of Dayton. As a result, the Miami Conservancy District was created as the first major flood plain engineering project in Ohio and the United States.

Grand Lake St. Marys in the west-central part of the state was constructed as a supply of water for canals in the canal-building era of 1820–1850. For many years this body of water, over , was the largest artificial lake in the world. were not the economic fiasco that similar efforts were in other states. Some cities, such as Dayton, owe their industrial emergence to location on canals, and as late as 1910 interior canals carried much of the bulk freight of the state.

The climate of Ohio is a humid continental climate (Köppen climate classification "Dfa/Dfb") throughout most of the state, except in the extreme southern counties of Ohio's Bluegrass region section, which are located on the northern periphery of the humid subtropical climate ("Cfa") and Upland South region of the United States. Summers are typically hot and humid throughout the state, while winters generally range from cool to cold. Precipitation in Ohio is moderate year-round. Severe weather is not uncommon in the state, although there are typically fewer tornado reports in Ohio than in states located in what is known as the Tornado Alley. Severe lake effect snowstorms are also not uncommon on the southeast shore of Lake Erie, which is located in an area designated as the Snowbelt.

Although predominantly not in a subtropical climate, some warmer-climate flora and fauna do reach well into Ohio. For instance, some trees with more southern ranges, such as the blackjack oak, "Quercus marilandica", are found at their northernmost in Ohio just north of the Ohio River. Also evidencing this climatic transition from a subtropical to continental climate, several plants such as the Southern magnolia "(Magnolia grandiflora)", Albizia julibrissin (mimosa), Crape Myrtle, and even the occasional Needle Palm are hardy landscape materials regularly used as street, yard, and garden plantings in the Bluegrass region of Ohio; but these same plants will simply not thrive in much of the rest of the state. This interesting change may be observed while traveling through Ohio on Interstate 75 from Cincinnati to Toledo; the observant traveler of this diverse state may even catch a glimpse of Cincinnati's common wall lizard, one of the few examples of permanent "subtropical" fauna in Ohio.

Due to flooding resulting in severely damaged highways, Governor Mike DeWine declared a state of emergency in 37 Ohio counties in 2019.

The highest recorded temperature was , near Gallipolis on July 21, 1934.
The lowest recorded temperature was , at Milligan on February 10, 1899, during the Great Blizzard of 1899.

Although few have registered as noticeable to the average resident, more than 200 earthquakes with a magnitude of 2.0 or higher have occurred in Ohio since 1776. The Western Ohio Seismic Zone and a portion of the Southern Great Lakes Seismic Zone are located in the state, and numerous faults lie under the surface.

The most substantial known earthquake in Ohio history was the Anna (Shelby County) earthquake, which occurred on March 9, 1937. It was centered in western Ohio, and had a magnitude of 5.4, and was of intensity VIII.

Other significant earthquakes in Ohio include: one of magnitude 4.8 near Lima on September 19, 1884; one of magnitude 4.2 near Portsmouth on May 17, 1901; and one of 5.0 in LeRoy Township in Lake County on January 31, 1986, which continued to trigger 13 aftershocks of magnitude 0.5 to 2.4 for two months.

Notable Ohio earthquakes in the 21st century include one occurring on December 31, 2011, approximately northwest of Youngstown, and one occurring on June 10, 2019, approximately north-northwest of Eastlake under Lake Erie; both registered a 4.0 magnitude.

Columbus is both the capital of Ohio and its largest city, located near the geographic center of the state and well known for The Ohio State University. However, other Ohio cities function as economic and cultural centers of metropolitan areas. Akron, Canton, Cleveland, Mansfield, and Youngstown are in the Northeast, known for major industrial companies Goodyear Tire and Rubber and Timken, top ranked colleges Case Western Reserve University and Kent State University, the Cleveland Clinic, and cultural attractions including the Cleveland Museum of Art, Big Five group Cleveland Orchestra, Playhouse Square, the Pro Football Hall of Fame, and the Rock and Roll Hall of Fame. Lima and Toledo are the major cities in Northwest Ohio. Northwest Ohio is known for its glass making industry, and is home to Owens Corning and Owens-Illinois, two Fortune 500 corporations. Dayton and Springfield are located in the Miami Valley, which is home to the University of Dayton, the Dayton Ballet, and the extensive Wright-Patterson Air Force Base. Cincinnati anchors Southwest Ohio, home of Miami University and the University of Cincinnati, Cincinnati Union Terminal, Cincinnati Symphony Orchestra, and various Fortune 500 companies including Procter & Gamble, Kroger, Macy's, Inc., and Fifth Third Bank. Steubenville is the only metropolitan city in Appalachian Ohio, which is home to Hocking Hills State Park.

The Cincinnati metropolitan area extends into Kentucky and Indiana, the Steubenville metropolitan area extends into West Virginia, the Toledo metropolitan area extends into Michigan, and the Youngstown metropolitan area extends into Pennsylvania.

Ohio cities that function as centers of United States micropolitan areas include:

Archeological evidence of spear points of both the Folsom and Clovis types indicate that the Ohio Valley was inhabited by nomadic people as early as 13,000 BC. These early nomads disappeared from Ohio by 1,000 BC. Between 1,000 and 800 BC, the sedentary Adena culture emerged. The Adena were able to establish "semi-permanent" villages because they domesticated plants, including, sunflowers, and "grew squash and possibly corn"; with hunting and gathering, this cultivation supported more settled, complex villages. The most notable remnant of the Adena culture is the Great Serpent Mound, located in Adams County, Ohio.
Around 100 BC, the Adena evolved into the Hopewell people who were also mound builders. Their complex, large and technologically sophisticated earthworks can be found in modern-day Marietta, Newark, and Circleville. They were also a prolific trading society, their trading network spanning a third of the continent. The Hopewell disappeared from the Ohio Valley about 600 AD. The Mississippian Culture rose as the Hopewell Culture declined. Many Siouan-speaking peoples from the plains and east coast claim them as ancestors and say they lived throughout the Ohio region until approximately the 13th century.

There were three other cultures contemporaneous with the Mississippians: the Fort Ancient people, the Whittlesey Focus people and the Monongahela Culture. All three cultures disappeared in the 17th century. Their origins are unknown. The Shawnees may have absorbed the Fort Ancient people. It is also possible that the Monongahela held no land in Ohio during the Colonial Era. The Mississippian Culture were close to and traded extensively with the Fort Ancient people.

Indians in the Ohio Valley were greatly affected by the aggressive tactics of the Iroquois Confederation, based in central and western New York. After the Beaver Wars in the mid-17th century, the Iroquois claimed much of the Ohio country as hunting and, more importantly, beaver-trapping ground. After the devastation of epidemics and war in the mid-17th century, which largely emptied the Ohio country of indigenous people by the mid-to-late 17th century, the land gradually became repopulated by the mostly Algonquian. Many of these Ohio-country nations were multi-ethnic (sometimes multi-linguistic) societies born out of the earlier devastation brought about by disease, war, and subsequent social instability. They subsisted on agriculture (corn, sunflowers, beans, etc.) supplemented by seasonal hunts. By the 18th century, they were part of a larger global economy brought about by European entry into the fur trade.

The indigenous nations to inhabit Ohio in the historical period included the Iroquoian, the Algonquian & the Siouan. Ohio country was also the site of Indian massacres, such as the Yellow Creek Massacre, Gnadenhutten and Pontiac's Rebellion school massacre. Most Native Peoples who remained in Ohio were slowly bought out and convinced to leave, or ordered to do so by law, in the early 19th century with the Indian Removal Act of 1830.

During the 18th century, the French set up a system of trading posts to control the fur trade in the region. Beginning in 1754, France and Great Britain fought the French and Indian War. As a result of the Treaty of Paris, the French ceded control of Ohio and the remainder of the Old Northwest to Great Britain.

Pontiac's Rebellion in the 1760s, however, posed a challenge to British military control. This came to an end with the colonists' victory in the American Revolution. In the Treaty of Paris in 1783, Britain ceded all claims to Ohio country to the United States.

The United States created the Northwest Territory under the Northwest Ordinance of 1787. Slavery was not permitted in the new territory. Settlement began with the founding of Marietta by the Ohio Company of Associates, which had been formed by a group of American Revolutionary War veterans. Following the Ohio Company, the Miami Company (also referred to as the "Symmes Purchase") claimed the southwestern section, and the Connecticut Land Company surveyed and settled the Connecticut Western Reserve in present-day Northeast Ohio. Territorial surveyors from Fort Steuben began surveying an area of eastern Ohio called the Seven Ranges at about the same time.
The old Northwest Territory originally included areas previously known as Ohio Country and Illinois Country. As Ohio prepared for statehood, the Indiana Territory was created, reducing the Northwest Territory to approximately the size of present-day Ohio plus the eastern half of the Lower Peninsula of Michigan and the eastern tip of the Upper Peninsula and a sliver of southeastern Indiana called "The Gore".

Under the Northwest Ordinance, areas could be defined and admitted as states once their population reached 60,000. Although Ohio's population was only 45,000 in December 1801, Congress determined that it was growing rapidly and had already begun the path to statehood. In regards to the Leni Lenape natives, Congress decided that 10,000 acres on the Muskingum River in the present state of Ohio would "be set apart and the property thereof be vested in the Moravian Brethren ... or a society of the said Brethren for civilizing the Indians and promoting Christianity".

On February 19, 1803, U.S. president Thomas Jefferson signed an act of Congress that approved Ohio's boundaries and constitution. However, Congress had never passed a resolution formally admitting Ohio as the 17th state. The current custom of Congress declaring an official date of statehood did not begin until 1812, with Louisiana's admission as the 18th state. Although no formal resolution of admission was required, when the oversight was discovered in 1953, as Ohio began preparations for celebrating its sesquicentennial, Ohio congressman George H. Bender introduced a bill in Congress to admit Ohio to the Union retroactive to March 1, 1803, the date on which the Ohio General Assembly first convened. At a special session at the old state capital in Chillicothe, the Ohio state legislature approved a new petition for statehood which was delivered to Washington, D.C., on horseback. On August 7, 1953 (the year of Ohio's 150th anniversary), President Eisenhower signed a congressional joint resolution that officially declared March 1, 1803, the date of Ohio's admittance into the Union.

Ohio has had three capital cities: Chillicothe, Zanesville, and Columbus. Chillicothe was the capital from 1803 to 1810. The capital was then moved to Zanesville for two years, as part of a state legislative compromise to get a bill passed. The capital was then moved back to Chillicothe, which was the capital from 1812 to 1816. Finally, the capital was moved to Columbus, to have it near the geographic center of the state.

Although many Native Americans had migrated west to evade American encroachment, others remained settled in the state, sometimes assimilating in part. In 1830 under President Andrew Jackson, the US government forced Indian Removal of most tribes to the Indian Territory west of the Mississippi River.

In 1835, Ohio fought with Michigan in the Toledo War, a mostly bloodless boundary war over the Toledo Strip. Only one person was injured in the conflict. Congress intervened, making Michigan's admittance as a state conditional on ending the conflict. In exchange for giving up its claim to the Toledo Strip, Michigan was given the western two-thirds of the Upper Peninsula, in addition to the eastern third which was already considered part of the state.

Ohio's central position and its population gave it an important place during the Civil War. The Ohio River was a vital artery for troop and supply movements, as were Ohio's railroads. The industry of Ohio made the state one of the most important states in the Union during the Civil war. Ohio contributed more soldiers per-capita than any other state in the Union. In 1862, the state's morale was badly shaken in the aftermath of the Battle of Shiloh, a costly victory in which Ohio forces suffered 2,000 casualties. Later that year, when Confederate troops under the leadership of Stonewall Jackson threatened Washington, D.C., Ohio governor David Tod still could recruit 5,000 volunteers to provide three months of service. From July 12 to July 23, 1863, Southern Ohio and Indiana were attacked in Morgan's Raid. While this raid was insignificant and small, it aroused fear among people in Ohio and Indiana. Almost 35,000 Ohioans died in the conflict, and 30,000 were physically wounded. By the end of the Civil War, the Union's top three generals–Ulysses S. Grant, William Tecumseh Sherman, and Philip Sheridan–were all from Ohio.

In 1912 a Constitutional Convention was held with Charles Burleigh Galbreath as secretary. The result reflected the concerns of the Progressive Era. It introduced the initiative and the referendum. Also, it allowed the General Assembly to put questions on the ballot for the people to ratify laws and constitutional amendments originating in the Legislature. Under the Jeffersonian principle that laws should be reviewed once a generation, the constitution provided for a recurring question to appear on Ohio's general election ballots every 20 years. The question asks whether a new convention is required. Although the question has appeared in 1932, 1952, 1972, and 1992, it has never been approved. Instead, constitutional amendments have been proposed by petition to the legislature hundreds of times and adopted in a majority of cases.

From just over 45,000 residents in 1800, Ohio's population grew faster than 10% per decade (except for the 1940 census) until the 1970 census, which recorded just over 10.65 million Ohioans. Growth then slowed for the next four decades. The United States Census Bureau estimates that the population of Ohio was 11,689,100 on July 1, 2019, a 1.32% increase since the 2010 United States Census. Ohio's population growth lags that of the entire United States, and Caucasians are found in a greater density than the United States average. , Ohio's center of population is located in Morrow County, in the county seat of Mount Gilead. This is approximately south and west of Ohio's population center in 1990.
As of 2011, 27.6% of Ohio's children under the age of 1 belonged to minority groups.

6.2% of Ohio's population is under five years of age, 23.7 percent under 18 years of age, and 14.1 percent were 65 or older. Females made up approximately 51.2 percent of the population.

"Note: Births in table don't add up, because Hispanics are counted both by their ethnicity and by their race, giving a higher overall number."


According to the 2010 United States Census, the racial composition of Ohio was the following:

In 2010, there were 469,700 foreign-born residents in Ohio, corresponding to 4.1% of the total population. Of these, 229,049 (2.0%) were naturalized US citizens and 240,699 (2.1%) were not. The largest groups were: Mexico (54,166), India (50,256), China (34,901), Germany (19,219), Philippines (16,410), United Kingdom (15,917), Canada (14,223), Russia (11,763), South Korea (11,307), and Ukraine (10,681). Though predominantly white, Ohio has large black populations in all major metropolitan areas throughout the state, Ohio has a significant Hispanic population made up of Mexicans in Toledo and Columbus, and Puerto Ricans in Cleveland and Columbus, and also has a significant and diverse Asian population in Columbus.

The largest ancestry groups (which the Census defines as not including racial terms) in the state are:

Ancestries claimed by less than 1% of the population include Sub-Saharan African, Puerto Rican, Swiss, Swedish, Arab, Greek, Norwegian, Romanian, Austrian, Lithuanian, Finnish, West Indian, Portuguese and Slovene.

About 6.7% of the population age 5 years and older reported speaking a language other than English, with 2.2% of the population speaking Spanish, 2.6% speaking other Indo-European languages, 1.1% speaking Asian and Austronesian languages, and 0.8% speaking other languages. Numerically: 10,100,586 spoke English, 239,229 Spanish, 55,970 German, 38,990 Chinese, 33,125 Arabic, and 32,019 French. In addition 59,881 spoke a Slavic language and 42,673 spoke another West Germanic language according to the 2010 Census. Ohio also had the nation's largest population of Slovene speakers, second largest of Slovak speakers, second largest of Pennsylvania Dutch (German) speakers, and the third largest of Serbian speakers.

According to a Pew Forum poll, as of 2008, 76% of Ohioans identified as Christian. Specifically, 26% of Ohio's population identified as Evangelical Protestant, 22% as Mainline Protestant, and 21% as Catholic. 17% of the population is unaffiliated with any religious body. 1.3% (148,380) were Jewish. There are also small minorities of Jehovah's Witnesses (1%), Muslims (1%), Hindus (<0.5%), Buddhists (<0.5%), Mormons (<0.5%), and other faiths (1-1.5%).

According to the Association of Religion Data Archives (ARDA), in 2010 the largest denominations by adherents were the Catholic Church with 1,992,567; the United Methodist Church with 496,232; the Evangelical Lutheran Church in America with 223,253, the Southern Baptist Convention with 171,000, the Christian Churches and Churches of Christ with 141,311, the United Church of Christ with 118,000, and the Presbyterian Church (USA) with 110,000. With about 70,000 people in 2015 Ohio had the second largest Amish population of all states of the US.

According to the same data, a majority of Ohioans, 55%, feel religion is "very important", 30% that it is "somewhat important", and 15% that religion is "not too important/not important at all". 36% of Ohioans indicate that they attend religious services at least once weekly, 35% occasionally, and 27% seldom or never.

According to the U.S. Census Bureau, the total number for employment in 2016 was 4,790,178. The total number of unique employer establishments was 252,201, while the total number of nonemployer establishments was 785,833. In 2010, Ohio was ranked second in the country for best business climate by Site Selection magazine, based on a business-activity database. The state has also won three consecutive Governor's Cup awards from the magazine, based on business growth and developments. , Ohio's gross domestic product (GDP) was $626 billion. This ranks Ohio's economy as the seventh-largest of all fifty states and the District of Columbia.

The Small Business & Entrepreneurship Council ranked the state No. 10 for best business-friendly tax systems in their Business Tax Index 2009, including a top corporate tax and capital gains rate that were both ranked No.6 at 1.9%. Ohio was ranked No. 11 by the council for best friendly-policy states according to their Small Business Survival Index 2009. The Directorship's Boardroom Guide ranked the state No. 13 overall for best business climate, including No.7 for best litigation climate. Forbes ranked the state No.8 for best regulatory environment in 2009. Ohio has five of the top 115 colleges in the nation, according to U.S. News and World Report's 2010 rankings, and was ranked No.8 by the same magazine in 2008 for best high schools.

Ohio's unemployment rate stands at 4.5% as of February 2018, down from 10.7% in May 2010. The state still lacks 45,000 jobs compared to the pre-recession numbers of 2007. The labor force participation as of April 2015 is 63%, slightly above the national average. Ohio's per capita income stands at $34,874. , Ohio's median household income is $52,334, and 14.6% of the population is below the poverty line

The manufacturing and financial activities sectors each compose 18.3% of Ohio's GDP, making them Ohio's largest industries by percentage of GDP. Ohio has the third largest manufacturing workforce behind California and Texas. Ohio has the largest bioscience sector in the Midwest, and is a national leader in the "green" economy. Ohio is the largest producer in the country of plastics, rubber, fabricated metals, electrical equipment, and appliances. 5,212,000 Ohioans are currently employed by wage or salary.

By employment, Ohio's largest sector is trade/transportation/utilities, which employs 1,010,000 Ohioans, or 19.4% of Ohio's workforce, while the health care and education sector employs 825,000 Ohioans (15.8%). Government employs 787,000 Ohioans (15.1%), manufacturing employs 669,000 Ohioans (12.9%), and professional and technical services employs 638,000 Ohioans (12.2%). Ohio's manufacturing sector is the third-largest of all fifty United States states in terms of gross domestic product. Fifty-nine of the United States' top 1,000 publicly traded companies (by revenue in 2008) are headquartered in Ohio, including Procter & Gamble, Goodyear Tire & Rubber, AK Steel, Timken, Abercrombie & Fitch, and Wendy's.

Ohio is also one of 41 states with its own lottery, the Ohio Lottery. The Ohio Lottery has contributed over $15.5 billion to public education in its 34-year history.

Many major east–west transportation corridors go through Ohio. One of those pioneer routes, known in the early 20th century as "Main Market Route 3", was chosen in 1913 to become part of the historic Lincoln Highway which was the first road across America, connecting New York City to San Francisco. In Ohio, the Lincoln Highway linked many towns and cities together, including Canton, Mansfield, Wooster, Lima, and Van Wert. The arrival of the Lincoln Highway to Ohio was a major influence on the development of the state. Upon the advent of the federal numbered highway system in 1926, the Lincoln Highway through Ohio became U.S. Route 30.

Ohio also is home to of the Historic National Road, now U.S. Route 40.

Ohio has a highly developed network of roads and interstate highways. Major east-west through routes include the Ohio Turnpike (I-80/I-90) in the north, I-76 through Akron to Pennsylvania, I-70 through Columbus and Dayton, and the Appalachian Highway (State Route 32) running from West Virginia to Cincinnati. Major north–south routes include I-75 in the west through Toledo, Dayton, and Cincinnati, I-71 through the middle of the state from Cleveland through Columbus and Cincinnati into Kentucky, and I-77 in the eastern part of the state from Cleveland through Akron, Canton, New Philadelphia and Marietta south into West Virginia. Interstate 75 between Cincinnati and Dayton is one of the heaviest traveled sections of interstate in Ohio.

Ohio also has a highly developed network of signed state bicycle routes. Many of them follow rail trails, with conversion ongoing. The Ohio to Erie Trail (route 1) connects Cincinnati, Columbus, and Cleveland. U.S. Bicycle Route 50 traverses Ohio from Steubenville to the Indiana state line outside Richmond.

Ohio has several long-distance hiking trails, the most prominent of which is the Buckeye Trail which extends in a loop around the state of Ohio. Part of it is on roads and part is on wooded trail. Additionally, the North Country Trail (the longest of the eleven National Scenic Trails authorized by Congress) and the American Discovery Trail (a system of recreational trails and roads that collectively form a coast-to-coast route across the mid-tier of the United States) pass through Ohio. Much of these two trails coincide with the Buckeye Trail.

Ohio has five international airports, four commercial, and two military. The five international include Cleveland Hopkins International Airport, John Glenn Columbus International Airport, and Dayton International Airport, Ohio's third largest airport. Akron Fulton International Airport handles cargo and for private use. Rickenbacker International Airport is one of two military airfields which is also home to the 7th largest FedEx building in America. The other military airfield is Wright Patterson Air Force Base which is one of the largest Air Force bases in the United States. Other major airports are located in Toledo and Akron.

Cincinnati/Northern Kentucky International Airport is in Hebron, Kentucky, and therefore is not listed above.


The state government of Ohio consists of the executive, judicial, and legislative branches.

The executive branch is headed by the governor of Ohio. The current governor is Mike DeWine since 2019, a member of the Republican Party. A lieutenant governor succeeds the governor in the event of any removal from office, and performs any duties assigned by the governor. The current lieutenant governor is Jon A. Husted. The other elected constitutional offices in the executive branch are the secretary of state (Frank LaRose), auditor (Keith Faber), treasurer (Robert Sprague), and attorney general (Dave Yost).

There are three levels of the Ohio state judiciary. The lowest level is the court of common pleas: each county maintains its own constitutionally mandated court of common pleas, which maintain jurisdiction over "all justiciable matters". The intermediate-level court system is the district court system. Twelve courts of appeals exist, each retaining jurisdiction over appeals from common pleas, municipal, and county courts in a set geographical area. A case heard in this system is decided by a three-judge panel, and each judge is elected.

The highest-ranking court, the Ohio Supreme Court, is Ohio's "court of last resort". A seven-justice panel composes the court, which, by its own discretion, hears appeals from the courts of appeals, and retains original jurisdiction over limited matters.

The Ohio General Assembly is a bicameral legislature consisting of the Senate and House of Representatives. The Senate is composed of 33 districts, each of which is represented by one senator. Each senator represents approximately 330,000 constituents. The House of Representatives is composed of 99 members.

Eight US presidents hailed from Ohio at the time of their elections, giving rise to its nickname "mother of presidents", a sobriquet it shares with Virginia. It is also termed "modern mother of presidents", in contrast to Virginia's status as the origin of presidents earlier in American history. Seven presidents were born in Ohio, making it second to Virginia's eight. Virginia-born William Henry Harrison lived most of his life in Ohio and is also buried there. Harrison conducted his political career while living on the family compound, founded by his father-in-law, John Cleves Symmes, in North Bend, Ohio. The seven presidents born in Ohio were Ulysses S. Grant, Rutherford B. Hayes, James A. Garfield, Benjamin Harrison (grandson of William Henry Harrison), William McKinley, William Howard Taft and Warren G. Harding. All seven were Republicans.

Ohio is considered a swing state, being won by either the Democratic or Republican candidates reasonably each election. As a swing state, Ohio is usually targeted by both major-party campaigns, especially in competitive elections. Pivotal in the election of 1888, Ohio has been a regular swing state since 1980.

Additionally, Ohio is considered a bellwether. Historian R. Douglas Hurt asserts that not since Virginia "had a state made such a mark on national political affairs". "The Economist" notes that "This slice of the mid-west contains a bit of everything American—part north-eastern and part southern, part urban and part rural, part hardscrabble poverty and part booming
suburb", Since 1896, Ohio has had only two misses in the general election (Thomas E. Dewey in 1944 and Richard Nixon in 1960) and has the longest perfect streak of any state, voting for the winning presidential candidate in each election since 1964, and in 33 of the 37 held since the Civil War. No Republican has ever won the presidency without winning Ohio.

As of 2019, there are more than 7.8 million registered Ohioan voters, with 1.3 million Democrats and 1.9 million Republicans. They are disproportionate in age, with a million more over 65 than there are 18- to 24-year-olds. Since the 2010 midterm elections, Ohio's voter demographic has leaned towards the Republican Party. The governor, Mike DeWine, is Republican, as well as all other non-judicial statewide elected officials, including Lieutenant Governor Jon A. Husted, Attorney General Dave Yost, State Auditor Keith Faber, Secretary of State Frank LaRose and State Treasurer Robert Sprague. In the Ohio State Senate the Republicans are the majority, 24–9, and in the Ohio House of Representatives the Republicans control the delegation 61–38.

Losing two seats in the U.S. House of Representatives following the 2010 Census, Ohio has had 16 seats for the three presidential elections of the decade in 2012, 2016 and 2020. As of the 2018 midterms, twelve federal representatives are Republicans while four are Democrats. Marcy Kaptur (D-09) is the most senior member of the Ohio delegation to the U.S. House of Representatives. The senior U.S. senator, Sherrod Brown, is a Democrat, while the junior, Rob Portman, is a Republican.

Since 1994, the state has had a policy of purging infrequent voters from its rolls. In April 2016, a lawsuit was filed, challenging this policy on the grounds that it violated the National Voter Registration Act (NVRA) of 1993 and the Help America Vote Act of 2002. In June, the federal district court ruled for the plaintiffs and entered a preliminary injunction applicable only to the November 2016 election. The preliminary injunction was upheld in September by the Court of Appeals for the Sixth Circuit. Had it not been upheld, thousands of voters would have been purged from the rolls just a few weeks before the election.

Still, it has been estimated that the state has removed up to two million voters since 2011.

Ohio's system of public education is outlined in Article VI of the state constitution, and in Title XXXIII of the Ohio Revised Code. Ohio University, the first university in the Northwest Territory, was also the first public institution in Ohio. Substantively, Ohio's system is similar to those found in other states. At the State level, the Ohio Department of Education, which is overseen by the Ohio State Board of Education, governs primary and secondary educational institutions. At the municipal level, there are approximately 700 school districts statewide. The Ohio Board of Regents coordinates and assists with Ohio's institutions of higher education which have recently been reorganized into the University System of Ohio under Governor Strickland. The system averages an annual enrollment of more than 400,000 students, making it one of the five largest state university systems in the U.S.

Ohio schools consistently ranking in the top 50 nationally of the U.S. News & World Report of liberal arts colleges are Kenyon College, Oberlin College, and Denison University. Ranking in the top 100 nationally of the U.S. News & World Report of national research universities are Case Western Reserve University, Ohio State University and Miami University.


Ohio is home to some of the nation's highest-ranked public libraries. The 2008 study by Thomas J. Hennen Jr. ranked Ohio as number one in a state-by-state comparison. For 2008, 31 of Ohio's library systems were all ranked in the top ten for American cities of their population category.

The Ohio Public Library Information Network (OPLIN) is an organization that provides Ohio residents with internet access to their 251 public libraries. OPLIN also provides Ohioans with free home access to high-quality, subscription research databases.

Ohio also offers the OhioLINK program, allowing Ohio's libraries (particularly those from colleges and universities) access to materials for the other libraries. The program is largely successful in allowing researchers for access to books and other media that might not be otherwise available.

Ohio is home to nine professional sports teams in each of the five different major leagues in the United States. Current teams include the Cincinnati Reds and Cleveland Indians of Major League Baseball, the Columbus Crew SC and FC Cincinnati of Major League Soccer, the Cleveland Cavaliers of the National Basketball Association, the Cincinnati Bengals and Cleveland Browns of the National Football League, and the Columbus Blue Jackets of the National Hockey League.

Ohio has brought home seven World Series titles (Reds 1919, 1940, 1975, 1976, 1990; Indians 1920, 1948), one MLS Cup (Crew 2008), one NBA Championship (Cavaliers 2016), and nine NFL Championships (Pros 1920; Bulldogs 1922, 1923, 1924; Rams 1945; Browns 1950, 1954, 1955, 1964). Despite this success in the NFL in the first half of the 20th century, no Ohio team has won the Super Bowl since its inception in 1967 or made an appearance since 1989. No Ohio team has made an appearance in the Stanley Cup Finals.

Ohio played a central role in the development of both Major League Baseball and the National Football League. Baseball's first fully professional team, the Cincinnati Red Stockings of 1869, were organized in Ohio. An informal early-20th-century American football association, the Ohio League, was the direct predecessor of the NFL, although neither of Ohio's modern NFL franchises trace their roots to an Ohio League club. The Pro Football Hall of Fame is located in Canton.

On a smaller scale, Ohio hosts minor league baseball, arena football, indoor football, mid-level hockey, and lower division soccer. 

Winter Guard International has hosted national championships in the UD Arena at the University of Dayton in Dayton, Ohio from 1983 - 1989, 1991 - 1996, 1998 - 2000, 2002 - 2003, and 2005 - 2020.

The Mid-Ohio Sports Car Course has hosted several auto racing championships, including CART World Series, IndyCar Series, NASCAR Nationwide Series, Can-Am, Formula 5000, IMSA GT Championship, American Le Mans Series and Rolex Sports Car Series.
The Grand Prix of Cleveland also hosted CART races from 1982 to 2007. The Eldora Speedway is a major dirt oval that hosts NASCAR Camping World Truck Series, World of Outlaws Sprint Cars and USAC Silver Crown Series races.

Ohio hosts two PGA Tour events, the WGC-Bridgestone Invitational and Memorial Tournament.
The Cincinnati Masters is an ATP World Tour Masters 1000 and WTA Premier 5 tennis tournament.

Ohio has eight NCAA Division I Football Bowl Subdivision college football teams, divided among three different conferences. It has also experienced considerable success in the secondary and tertiary tiers of college football divisions.

There is only one program in the Power Five conferences, the Ohio State Buckeyes, who play in the Big Ten Conference. The football team is fifth in all-time winning percentage, with a 922–326–53 overall record and a 24–26 bowl record as of 2019. The program has produced seven Heisman Trophy winners, forty conference titles, and eight undisputed national championships. The men's basketball program has appeared in the NCAA Division I Men's Basketball Tournament 27 times.

In the Group of Five conferences, the Cincinnati Bearcats play as a member of the American Athletic Conference. Their men's basketball team has over 1,800 wins, 33 March Madness appearances, and is currently on a nine-year streak of appearances as of 2019. Six teams are represented in the Mid-American Conference: the Akron Zips, Bowling Green Falcons, Kent State Golden Flashes, Miami RedHawks, Ohio Bobcats and the Toledo Rockets. The MAC headquarters are in Cleveland. The Cincinnati–Miami rivalry game has been played in southwest Ohio every year since 1888, and is the oldest current non-conference NCAA football rivalry.

Other Division I schools, either part of the NCAA Division I Football Championship Subdivision or not fielding in football include the Cleveland State Vikings, Xavier Musketeers, Wright State Raiders, and Youngstown State Penguins. Xavier's men's basketball has performed particularly well, with 27 March Madness appearances. Youngstown State's football has the third most NCAA Division I Football Championship wins, with 3.

There are 12 NCAA Division II universities and 22 NCAA Division III universities in Ohio.





</doc>
<doc id="22201" url="https://en.wikipedia.org/wiki?curid=22201" title="Orbital">
Orbital

Orbital may refer to:






</doc>
<doc id="22203" url="https://en.wikipedia.org/wiki?curid=22203" title="Organic compound">
Organic compound

In chemistry, organic compounds are generally any chemical compounds that contain carbon-hydrogen bonds. Due to carbon's ability to catenate (form chains with other carbon atoms), millions of organic compounds are known. The study of the properties, reactions, and syntheses of organic compounds comprises the discipline known as organic chemistry. For historical reasons, a few classes of carbon-containing compounds (e.g., carbonate anion salts and cyanide salts), along with a handful of other exceptions (e.g., carbon dioxide), are not classified as organic compounds and are considered inorganic. Other than those just named, little consensus exists among chemists on precisely which carbon-containing compounds are excluded, making any rigorous definition of an organic compound elusive. 

Although organic compounds make up only a small percentage of the Earth's crust, they are of central importance because all known life is based on organic compounds. Living things incorporate inorganic carbon compounds into organic compounds through a network of processes (the carbon cycle) that begins with the conversion of carbon dioxide and a hydrogen source like water into simple sugars and other organic molecules by autotrophic organisms using light (photosynthesis) or other sources of energy. Most synthetically produced organic compounds are ultimately derived from petrochemicals consisting mainly of hydrocarbons, which are themselves formed from the high pressure and temperature degradation of organic matter underground over geological timescales. This ultimate derivation notwithstanding, organic compounds are no longer defined as compounds originating in living things, as they were historically.

In chemical nomenclature, an "organyl group", frequently represented by the letter R, refers to any monovalent substituent whose open valence is on a carbon atom.

For historical reasons discussed below, a few types of carbon-containing compounds, such as carbides, carbonates, simple oxides of carbon (for example, CO and CO), and cyanides are considered inorganic. Different forms (allotropes) of pure carbon, such as diamond, graphite, fullerenes, and carbon nanotubes are also excluded because they are simple substances composed of only a single element and therefore are not generally considered to be chemical "compounds".

Vitalism was a widespread conception that substances found in organic nature are created from the chemical elements by the action of a "vital force" or "life-force" ("vis vitalis") that only living organisms possess. Vitalism taught that these "organic" compounds were fundamentally different from the "inorganic" compounds that could be obtained from the elements by chemical manipulations.

Vitalism survived for a while even after the rise of modern ideas about the atomic theory and chemical elements. It first came under question in 1824, when Friedrich Wöhler synthesized oxalic acid, a compound known to occur only in living organisms, from cyanogen. A further experiment was Wöhler's 1828 synthesis of urea from the inorganic salts potassium cyanate and ammonium sulfate. Urea had long been considered an "organic" compound, as it was known to occur only in the urine of living organisms. Wöhler's experiments were followed by many others, in which increasingly complex "organic" substances were produced from "inorganic" ones without the involvement of any living organism.

Although vitalism has been discredited, scientific nomenclature retains the distinction between "organic" and "inorganic" compounds. The modern meaning of "organic compound" is any compound that contains a significant amount of carbon—even though many of the organic compounds known today have no connection to any substance found in living organisms. The term "carbogenic" has been proposed by E. J. Corey as a modern alternative to "organic", but this neologism remains relatively obscure.

The organic compound -isoleucine molecule presents some features typical of organic compounds: carbon–carbon bonds, carbon–hydrogen bonds, as well as covalent bonds from carbon to oxygen and to nitrogen.

As described in detail below, any definition of organic compound that uses simple, broadly applicable criteria turns out to be unsatisfactory, to varying degrees. The modern, commonly accepted definition of organic compound essentially amounts to any carbon containing compound, excluding several classes of substances traditionally considered as 'inorganic'. However, the list of substances so excluded varies from author to author. Still, it is generally agreed upon that there are (at least) a few carbon containing compounds that should not be considered organic. For instance, almost all authorities would require the exclusion of alloys that contain carbon, including steel (which contains cementite, FeC), as well as other metal and semimetal carbides (including "ionic" carbides, e.g, AlC and CaC and "covalent" carbides, e.g. BC and SiC, and graphite intercalation compounds, e.g. KC). Other compounds and materials that are considered 'inorganic' by most authorities include: metal carbonates, simple oxides (CO, CO, and arguably, CO), the allotropes of carbon, cyanide derivatives not containing an organic residue (e.g., KCN, (CN), BrCN, CNO, etc.), and heavier analogs thereof (e.g., CP 'cyaphide anion', CSe, COS; although CS 'carbon disulfide' is often classed as an "organic" solvent). Halides of carbon without hydrogen (e.g., CF and CClF), phosgene (COCl), carboranes, metal carbonyls (e.g., nickel carbonyl), mellitic anhydride (CO), and other exotic oxocarbons are also considered inorganic by some authorities.

Nickel carbonyl (Ni(CO)) and other metal carbonyls present an interesting case. They are often volatile liquids, like many organic compounds, yet they contain only carbon bonded to a transition metal and to oxygen and are often prepared directly from metal and carbon monoxide. Nickel carbonyl is frequently considered to be "organometallic". Although many organometallic chemists employ a broad definition, in which any compound containing a carbon-metal covalent bond is considered organometallic, it is debatable whether organometallic compounds form a subset of organic compounds. 

Metal complexes with organic ligands but no carbon-metal bonds (e.g., Cu(OAc)) are not considered organometallic; instead they are classed as "metalorganic". Likewise, it is also unclear whether metalorganic compounds should automatically be considered organic.

The relatively narrow definition of organic compounds as those containing C-H bonds excludes compounds that are (historically and practically) considered organic. Neither urea nor oxalic acid is organic by this definition, yet they were two key compounds in the vitalism debate. The IUPAC Blue Book on organic nomenclature specifically mentions urea and oxalic acid. Other compounds lacking C-H bonds but traditionally considered organic include benzenehexol, mesoxalic acid, and carbon tetrachloride. Mellitic acid, which contains no C-H bonds, is considered a possible organic substance in Martian soil. Terrestrially, it, and its anhydride, mellitic anhydride, are associated with the mineral mellite (AlC(COO)·16HO).

A slightly broader definition of organic compound includes all compounds bearing C-H or C-C bonds. This would still exclude urea. Moreover, this definition still leads to somewhat arbitrary divisions in sets of carbon-halogen compounds. For example, CF and CCl would be considered by this rule to be "inorganic", whereas CFH, CHCl, and CCl would be organic, though these compounds share many physical and chemical properties.

Organic compounds may be classified in a variety of ways. One major distinction is between natural and synthetic compounds. Organic compounds can also be classified or subdivided by the presence of heteroatoms, e.g., organometallic compounds, which feature bonds between carbon and a metal, and organophosphorus compounds, which feature bonds between carbon and a phosphorus.
Another distinction, based on the size of organic compounds, distinguishes between small molecules and polymers.
Natural compounds refer to those that are produced by plants or animals. Many of these are still extracted from natural sources because they would be more expensive to produce artificially. Examples include most sugars, some alkaloids and terpenoids, certain nutrients such as vitamin B, and, in general, those natural products with large or stereoisometrically complicated molecules present in reasonable concentrations in living organisms.
Further compounds of prime importance in biochemistry are antigens, carbohydrates, enzymes, hormones, lipids and fatty acids, neurotransmitters, nucleic acids, proteins, peptides and amino acids, lectins, vitamins, and fats and oils.

Compounds that are prepared by reaction of other compounds are known as "synthetic". They may be either compounds that already are found in plants or animals or those that do not occur naturally.

Most polymers (a category that includes all plastics and rubbers) are organic synthetic or semi-synthetic compounds.

Many organic compounds—two examples are ethanol and insulin—are manufactured industrially using organisms such as bacteria and yeast. Typically, the DNA of an organism is altered to express compounds not ordinarily produced by the organism. Many such biotechnology-engineered compounds did not previously exist in nature. 


A great number of more specialized databases exist for diverse branches of organic chemistry.

The main tools are proton and carbon-13 NMR spectroscopy, IR Spectroscopy, Mass spectrometry, UV/Vis Spectroscopy and X-ray crystallography.




</doc>
<doc id="22204" url="https://en.wikipedia.org/wiki?curid=22204" title="Oligopoly">
Oligopoly

An oligopoly (ολιγοπώλιο) (Greek: ὀλίγοι πωλητές ""few sellers"") is a market form wherein a market or industry is dominated by a small group of large sellers (oligopolists). Oligopolies can result from various forms of collusion that reduce market competition which then typically leads to higher prices for consumers. Oligopolies have their own market structure. 

With few sellers, each oligopolist is likely to be aware of the actions of the others. According to game theory, the decisions of one firm therefore influence and are influenced by decisions of other firms. Strategic planning by oligopolists needs to take into account the likely responses of the other market participants. Entry barriers include high investment requirements, strong consumer loyalty for existing brands and economies of scale. In developed economies oligopolies dominate the economy as the perfectly competitive model is of negligible importance for consumers. Oligopolies differ from price takers in that they do not have a supply curve. Instead, they search for the best price-output combination.

Oligopoly is a common market form where only a limited number of firms are in competition. As a quantitative description of oligopoly, the four-firm concentration ratio is often utilized. This measure expresses, as a percentage, the market share of the four largest firms in any particular industry. For example, as of fourth quarter 2008, if we combine total market share of Verizon Wireless, AT&T, Sprint, and T-Mobile, we see that these firms, together, control 97% of the U.S. cellular telephone market.

Oligopolistic competition can give rise to both wide-ranging and diverse outcomes. In some situations, particular companies may employ restrictive trade practices (collusion, market sharing etc.) in order to inflate prices and restrict production in much the same way that a monopoly does. Whenever there is a formal agreement for such collusion, between companies that usually compete with one another, this practice is known as a cartel. A prime example of such a cartel is OPEC, which has a profound influence on the international price of oil.

Firms often collude in an attempt to stabilize unstable markets, so as to reduce the risks inherent in these markets for investment and product development. There are legal restrictions on such collusion in most countries. There does not have to be a formal agreement for collusion to take place (although for the act to be illegal there must be actual communication between companies)–for example, in some industries there may be an acknowledged market leader which informally sets prices to which other producers respond, known as price leadership.

In other situations, competition between sellers in an oligopoly can be fierce, with relatively low prices and high production. This could lead to an efficient outcome approaching perfect competition. The competition in an oligopoly can be greater when there are more firms in an industry than if, for example, the firms were only regionally based and did not compete directly with each other.

Thus the welfare analysis of oligopolies is sensitive to the parameter values used to define the market's structure. In particular, the level of dead weight loss is hard to measure. The study of product differentiation indicates that oligopolies might also create excessive levels of differentiation in order to stifle competition.
Oligopoly theory makes heavy use of game theory to model the behavior of oligopolies:


Oligopolies become "mature" when competing entities realize they can maximize profits through joint efforts designed to maximize price control by minimizing the influence of competition. As a result of operating in countries with enforced antitrust laws, oligopolists will operate under tacit collusion, which is collusion through an understanding among the competitors of a market that by collectively raising prices, each participating competitor can achieve economic profits comparable to those achieved by a monopolist while avoiding the explicit breach of market regulations. Hence, the kinked demand curve for a joint profit-maximizing oligopoly industry can model the behaviors of oligopolists' pricing decisions other than that of the price leader (the price leader being the entity that all other entities follow in terms of pricing decisions). This is because if an entity unilaterally raises the prices of their good/service and competing entities do not follow, the entity that raised their price will lose a significant market as they face the elastic upper segment of the demand curve. As the joint profit-maximizing efforts achieve greater economic profits for all participating entities, there becomes an incentive for an individual entity to "cheat" by expanding output to gain greater market share and profit. In the case of oligopolist cheating, when the incumbent entity discovers this breach in collusion, competitors in the market will retaliate by matching or dropping prices lower than the original drop. Hence, the market share originally gained by having dropped the price will be minimised or eliminated. This is why on the kinked demand curve model the lower segment of the demand curve is inelastic. As a result, in such markets price rigidity prevails.

There is no single model describing the operation of an oligopolistic market. The variety and complexity of the models exist because you can have two to 10 firms competing on the basis of price, quantity, technological innovations, marketing, and reputation. However, there are a series of simplified models that attempt to describe market behavior by considering certain circumstances. Some of the better-known models are the dominant firm model, the Cournot–Nash model, the Bertrand model and the kinked demand model.

The Cournot–Nash model is the simplest oligopoly model. The model assumes that there are two "equally positioned firms"; the firms compete on the basis of quantity rather than price and each firm makes an "output of decision assuming that the other firm's behavior is fixed." The market demand curve is assumed to be linear and marginal costs are constant. To find the Cournot–Nash equilibrium one determines how each firm reacts to a change in the output of the other firm. The path to equilibrium is a series of actions and reactions. The pattern continues until a point is reached where neither firm desires "to change what it is doing, given how it believes the other firm will react to any change." The equilibrium is the intersection of the two firm's reaction functions. The reaction function shows how one firm reacts to the quantity choice of the other firm. For example, assume that the firm 1's demand function is "P" = ("M" − "Q") − "Q" where "Q" is the quantity produced by the other firm and Q is the amount produced by firm 1, and M=60 is the market. Assume that marginal cost is C=12. Firm 1 wants to know its maximizing quantity and price. Firm 1 begins the process by following the profit maximization rule of equating marginal revenue to marginal costs. Firm 1's total revenue function is "R" = "Q" "P" = "Q"("M" − "Q" − "Q") = "MQ" − "Q" "Q" − "Q". The marginal revenue function is formula_1.

Equation 1.1 is the reaction function for firm 1. Equation 1.2 is the reaction function for firm 2.

To determine the Cournot–Nash equilibrium you can solve the equations simultaneously. The equilibrium quantities can also be determined graphically. The equilibrium solution would be at the intersection of the two reaction functions. Note that if you graph the functions the axes represent quantities. The reaction functions are not necessarily symmetric. The firms may face differing cost functions in which case the reaction functions would not be identical nor would the equilibrium quantities.

The Bertrand model is essentially the Cournot–Nash model except the strategic variable is price rather than quantity.

The model assumptions are:

The only Nash equilibrium is P = P = MC.

Neither firm has any reason to change strategy. If the firm raises prices it will lose all its customers. If the firm lowers price P < MC then it will be losing money on every unit sold.

The Bertrand equilibrium is the same as the competitive result. Each firm will produce where P = marginal costs and there will be zero profits. A generalization of the Bertrand model is the Bertrand–Edgeworth model that allows for capacity constraints and more general cost functions.

According to this model, each firm faces a demand curve kinked at the existing price. The conjectural assumptions of the model are; if the firm raises its price above the current existing price, competitors will not follow and the acting firm will lose market share and second if a firm lowers prices below the existing price then their competitors will follow to retain their market share and the firm's output will increase only marginally.

If the assumptions hold then:

The gap in the marginal revenue curve means that marginal costs can fluctuate without changing equilibrium price and quantity. Thus prices tend to be rigid.

Many industries have been cited as oligopolistic, including civil aviation, agricultural pesticides, electricity, and platinum group metal mining. In most countries, the telecommunications sector is characterized by an oligopolistic market structure. Rail freight markets in the European Union have an oligopolistic structure. In the United States, industries that have identified as oligopolistic include food processing, funeral services, sugar refining, beer, and pulp and paper.

Market power and market concentration can be estimated or quantified using several different tools and measurements, including the Lerner index, stochastic frontier analysis, and New Empirical Industrial Organization (NEIO) modeling, as well as the Herfindahl-Hirschman index.

In an oligopoly, firms operate under imperfect competition. With the fierce price competitiveness created by this sticky-upward demand curve, firms use non-price competition in order to accrue greater revenue and market share.

"Kinked" demand curves are similar to traditional demand curves, as they are downward-sloping. They are distinguished by a hypothesized convex bend with a discontinuity at the bend–"kink". Thus the first derivative at that point is undefined and leads to a jump discontinuity in the marginal revenue curve.

Classical economic theory assumes that a profit-maximizing producer with some market power (either due to oligopoly or monopolistic competition) will set marginal costs equal to marginal revenue. This idea can be envisioned graphically by the intersection of an upward-sloping marginal cost curve and a downward-sloping marginal revenue curve (because the more one sells, the lower the price must be, so the less a producer earns per unit). In classical theory, any change in the marginal cost structure (how much it costs to make each additional unit) or the marginal revenue structure (how much people will pay for each additional unit) will be immediately reflected in a new price and/or quantity sold of the item. This result does not occur if a "kink" exists. Because of this jump discontinuity in the marginal revenue curve, marginal costs could change without necessarily changing the price or quantity.

The motivation behind this kink is the idea that in an oligopolistic or monopolistically competitive market, firms will not raise their prices because even a small price increase will lose many customers. This is because competitors will generally ignore price increases, with the hope of gaining a larger market share as a result of now having comparatively lower prices. However, even a large price decrease will gain only a few customers because such an action will begin a price war with other firms. The curve is therefore more price-elastic for price increases and less so for price decreases. Theory predicts that firms will enter the industry in the long run.



</doc>
<doc id="22205" url="https://en.wikipedia.org/wiki?curid=22205" title="Oasis">
Oasis

In geography, an oasis (, plural oases, ) is a fertile area (often having a date palm grove) in a desert or semi-desert environment. Oases also provide habitats for animals and plants.

The word "oasis" came into English from , from , , which in turn is a direct borrowing from Demotic Egyptian. The word for "oasis" in the later attested Coptic language (the descendant of Demotic Egyptian) is "wahe" or "ouahe" which means a "dwelling place".

Oases are made fertile when sources of freshwater, such as underground rivers or aquifers, irrigate the surface naturally or via man-made wells. 
The presence of water on the surface or underground is necessary and the local or regional management of this essential resource is strategic, but not sufficient to create such areas: continuous human work and know-how (a technical and social culture) are essential to maintain such ecosystems.

Rain showers provide subterranean water to sustain natural oases, such as the Tuat. Substrata of impermeable rock and stone can trap water and retain it in pockets, or on long faulting subsurface ridges or volcanic dikes water can collect and percolate to the surface. Any incidence of water is then used by migrating birds, which also pass seeds with their droppings which will grow at the water's edge forming an oasis. It can also be used to plant crops.

The location of oases has been of critical importance for trade and transportation routes in desert areas; caravans must travel via oases so that supplies of water and food can be replenished. Thus, political or military control of an oasis has in many cases meant control of trade on a particular route. For example, the oases of Awjila, Ghadames and Kufra, situated in modern-day Libya, have at various times been vital to both north–south and east–west trade in the Sahara Desert. The Silk Road across Central Asia also incorporated several oases.

In North American history, oases have been less prominent since the desert regions are smaller, however several areas in the deep southwestern United States have oases regions that served as important links through the hot deserts and vast rural areas. While present day desert cities like Las Vegas, Phoenix, Palm Springs, and Tucson are large modern cities, many of these locations were once small, isolated farming areas that travelers through the western desert stopped for food and supplies. Even today, there are several roads that go through western deserts like U.S. Route 50 through southern Nevada, and the Mojave Desert that feature small green fields, citrus groves and small isolated supply towns.

People who live in an oasis must manage land and water use carefully; fields must be irrigated to grow plants like apricots, dates, figs, and olives. The most important plant in an oasis is the date palm, which forms the upper layer. These palm trees provide shade for smaller trees like peach trees, which form the middle layer. By growing plants in different layers, the farmers make best use of the soil and water. Many vegetables are also grown and some cereals, such as barley, millet, and wheat, are grown where there is more moisture.
In summary, an oasis palm grove is a highly anthropized and irrigated area that supports a traditionally intensive and polyculture-based agriculture. The oasis is integrated into its desert environment through an often close association with nomadic transhumant livestock farming (very often pastoral and sedentary populations are clearly distinguished). However, the oasis is emancipated from the desert by a very particular social and ecosystem structure. Responding to environmental constraints, it is an integrated agriculture that is conducted with the superposition (in its typical form) of two or three strata creating what is called the "oasis effect":



</doc>
<doc id="22206" url="https://en.wikipedia.org/wiki?curid=22206" title="Oboe">
Oboe

The oboe ( ) is a type of double reed woodwind instrument. Oboes are usually made of wood, but may also be made of synthetic materials, such as plastic, resin or hybrid composites. The most common oboe plays in the treble or soprano range. A soprano oboe measures roughly long, with metal keys, a conical bore and a flared bell. Sound is produced by blowing into the reed at a sufficient air pressure, causing it to vibrate with the air column. The distinctive tone is versatile and has been described as "bright". When the word "oboe" is used alone, it is generally taken to mean the treble instrument rather than other instruments of the family, such as the "bass oboe", the "cor anglais" (English horn), or oboe "d'amore".

A musician who plays the oboe is called an oboist.

Today, the oboe is commonly used as orchestral or solo instrument in symphony orchestras, concert bands and chamber ensembles. The oboe is especially used in classical music, chamber music, film music, some genres of folk music, and is occasionally heard in jazz, rock, pop, and popular music. The oboe is widely recognized as the instrument that tunes the orchestra with its distinctive 'A'.

In comparison to other modern woodwind instruments, the treble oboe is sometimes referred to as having a clear and penetrating voice. "The Sprightly Companion", an instruction book published by Henry Playford in 1695, describes the oboe as "Majestical and Stately, and not much Inferior to the Trumpet". In the play "Angels in America" the sound is described as like "that of a duck if the duck were a songbird". The rich timbre is derived from its conical bore (as opposed to the generally cylindrical bore of flutes and clarinets). As a result, oboes are easier to hear over other instruments in large ensembles due to its penetrating sound. The highest note is a semitone lower than the nominally highest note of the B clarinet. Since the clarinet has a wider range, the lowest note of the B clarinet is significantly deeper (a minor sixth) than the lowest note of the oboe.

Music for the standard oboe is written in concert pitch (i.e., it is not a transposing instrument), and the instrument has a soprano range, usually from B to G. Orchestras tune to a concert A played by the first oboe. According to the League of American Orchestras, this is done because the pitch is secure and its penetrating sound makes it ideal for tuning. The pitch of the oboe is affected by the way in which the reed is made. The reed has a significant effect on the sound. Variations in cane and other construction materials, the age of the reed, and differences in scrape and length all affect the pitch. German and French reeds, for instance, differ in many ways, causing the sound to vary accordingly. Weather conditions such as temperature and humidity also affect the pitch. Skilled oboists adjust their embouchure to compensate for these factors. Subtle manipulation of embouchure and air pressure allows the oboist to express timbre and dynamics.

Most professional oboists make their reeds to suit their individual needs. By making their reeds, oboists can precisely control factors such as tone color, intonation, and responsiveness. They can also account for individual embouchure, oral cavity, oboe angle, and air support.

Novice oboists rarely make their own reeds, as the process is difficult and time consuming, and frequently purchase reeds from a music store instead. Commercially available cane reeds are available in several degrees of hardness; a medium reed is very popular, and most beginners use medium-soft reeds. These reeds, like clarinet, saxophone, and bassoon reeds, are made from "Arundo donax". As oboists gain more experience, they may start making their own reeds after the model of their teacher or buying handmade reeds (usually from a professional oboist) and using special tools including gougers, pre-gougers, guillotines, knives, and other tools to make and adjusts reeds to their liking. The reed is considered the part of oboe that makes the instrument so difficult because the individual nature of each reed means that it is hard to achieve a consistent sound. Slight variations in temperature, altitude, weather, and climate can also have an effect on the sound of the reed, as well as minute changes in the physique of the reed.

Plastic oboe reeds are rarely used, and are less readily available than plastic reeds for other instruments, such as the clarinet. However they do exist, and are produced by brands such as Legere.

In English, prior to 1770, the standard instrument was called a "hautbois", "hoboy", or "French hoboy" ( ). This was borrowed from the French name, ""hautbois"" (), which is a compound word made up of "haut" ("high", "loud") and "bois" ("wood", "woodwind"). The spelling of "oboe" was adopted into English c. 1770 from the Italian "oboè", a transliteration of the 17th-century pronunciation of the French name.

The regular oboe first appeared in the mid-17th century, when it was called a "hautbois". This name was also used for its predecessor, the shawm, from which the basic form of the "hautbois" was derived. Major differences between the two instruments include the division of the "hautbois" into three sections, or joints (which allowed for more precise manufacture), and the elimination of the "pirouette", the wooden ledge below the reed which allowed players to rest their lips.

The exact date and place of origin of the "hautbois" are obscure, as are the individuals who were responsible. Circumstantial evidence, such as the statement by the flautist composer Michel de la Barre in his "Memoire", points to members of the Philidor (Filidor) and Hotteterre families. The instrument may in fact have had multiple inventors.}}sfn|Burgess|Haynes|2004|loc=28 ff}} The "hautbois" quickly spread throughout Europe, including Great Britain, where it was called "hautboy", "hoboy", "hautboit", "howboye", and similar variants of the French name. It was the main melody instrument in early military bands, until it was succeeded by the clarinet.

The standard Baroque oboe is generally made of boxwood and has three keys: a "great" key and two side keys (the side key is often doubled to facilitate use of either the right or left hand on the bottom holes). In order to produce higher pitches, the player has to "overblow", or increase the air stream to reach the next harmonic. Notable oboe-makers of the period are the Germans Jacob Denner and J.H. Eichentopf, and the English Thomas Stanesby (died 1734) and his son Thomas Jr (died 1754). The range for the Baroque oboe comfortably extends from C to D. With the resurgence of interest in early music in the mid 20th century, a few makers began producing copies to specifications taken from surviving historical instruments.

The Classical period brought a regular oboe whose bore was gradually narrowed, and the instrument became outfitted with several keys, among them those for the notes D, F, and G. A key similar to the modern octave key was also added called the "slur key", though it was at first used more like the "flick" keys on the modern German bassoon. Only later did French instrument makers redesign the octave key to be used in the manner of the modern key (i.e. held open for the upper register, closed for the lower). The narrower bore allows the higher notes to be more easily played, and composers began to more often utilize the oboe's upper register in their works. Because of this, the oboe's tessitura in the Classical era was somewhat broader than that found in Baroque works. The range for the Classical oboe extends from C to F (using the scientific pitch notation system), though some German and Austrian oboes are capable of playing one half-step lower. Classical-era composers who wrote concertos for oboe include Mozart (both the solo concerto in C major K. 314/285d and the lost original of Sinfonia Concertante in E major K. 297b, as well as a fragment of F major concerto K. 417f), Haydn (both the Sinfonia Concertante in B Hob. I:105 and the spurious concerto in C major Hob. VIIg:C1), Beethoven (the F major concerto, Hess 12, of which only sketches survive, though the second movement was reconstructed in the late 20th century), and numerous other composers including Johann Christian Bach, Johann Christian Fischer, Jan Antonín Koželuh, and Ludwig August Lebrun. Many solos exist for the regular oboe in chamber, symphonic, and operatic compositions from the Classical era.

The Wiener oboe (Viennese oboe) is a type of modern oboe that retains the essential bore and tonal characteristics of the historical oboe. The Akademiemodel Wiener Oboe, first developed in the late 19th century by Josef Hajek from earlier instruments by C. T. Golde of Dresden (1803–73), is now made by several makers such as André Constantinides, Karl Rado, Guntram Wolf, Christian Rauch and Yamaha. It has a wider internal bore, a shorter and broader reed and the fingering-system is very different than the conservatoire oboe. In "The Oboe", Geoffrey Burgess and Bruce Haynes write "The differences are most clearly marked in the middle register, which is reedier and more pungent, and the upper register, which is richer in harmonics on the Viennese oboe". Guntram Wolf describes them: "From the concept of the bore, the Viennese oboe is the last representative of the historical oboes, adapted for the louder, larger orchestra, and fitted with an extensive mechanism. Its great advantage is the ease of speaking, even in the lowest register. It can be played very expressively and blends well with other instruments." The Viennese oboe is, along with the Vienna horn, perhaps the most distinctive member of the Wiener Philharmoniker instrumentarium.

This oboe was developed further in the 19th century by the Triébert family of Paris. Using the Boehm flute as a source of ideas for key work, Guillaume Triébert and his sons, Charles and Frederic, devised a series of increasingly complex yet functional key systems. A variant form using large tone holes, the Boehm system oboe, was never in common use, though it was used in some military bands in Europe into the 20th century. F. Lorée of Paris made further developments to the modern instrument. Minor improvements to the bore and key work have continued through the 20th century, but there has been no fundamental change to the general characteristics of the instrument for several decades.

The modern standard oboe is most commonly made from grenadilla, also known as African blackwood, though some manufacturers also make oboes out of other members of the genus "Dalbergia", which includes cocobolo, rosewood, and violetwood (also known as kingwood). Ebony (genus Diospyros) has also been used. Student model oboes are often made from plastic resin, to avoid instrument cracking to which wood instruments are prone, but also to make the instrument more economical. The oboe has an extremely narrow conical bore. It is played with a double reed consisting of two thin blades of cane tied together on a small-diameter metal tube (staple) which is inserted into the reed socket at the top of the instrument. The commonly accepted range for the oboe extends from B to about G, over two and a half octaves, though its common tessitura lies from C to E. Some student oboes only extend down to B (the key for B is not present). 

A modern oboe with the "full conservatoire" ("conservatory" in the US) or Gillet key system has 45 pieces of keywork, with the possible additions of a third-octave key and alternate (left little finger) F- or C-key. The keys are usually made of nickel silver, and are silver- or occasionally gold-plated. Besides the full conservatoire system, oboes are also made using the British thumbplate system. Most have "semi-automatic" octave keys, in which the second-octave action closes the first, and some have a fully automatic octave key system, as used on saxophones. Some full-conservatory oboes have finger holes covered with rings rather than plates ("open-holed"), and most of the professional models have at least the right-hand third key open-holed. Professional oboes used in the UK and Iceland frequently feature conservatoire system combined with a thumb plate. Releasing the thumb plate has the same effect as pressing down the right-hand index-finger key. This produces alternate options which eliminate the necessity for most of the common cross-intervals (intervals where two or more keys need to be released and pressed down simultaneously), but cross intervals are much more difficult to execute in such a way that the sound remains clear and continuous throughout the frequency change (a quality also called legato and often called-for in the oboe repertoire).

The standard oboe has several siblings of various sizes and playing ranges. The most widely known and used today is the cor anglais (English horn) the tenor (or alto) member of the family. A transposing instrument; it is pitched in F, a perfect fifth lower than the oboe. The oboe d'amore, the alto (or mezzo-soprano) member of the family, is pitched in A, a minor third lower than the oboe. J.S. Bach made extensive use of both the oboe d'amore as well as the "taille" and oboe da caccia, Baroque antecedents of the cor anglais. Even less common is the bass oboe (also called baritone oboe), which sounds one octave lower than the oboe. Delius and Holst both scored for the instrument. Similar to the bass oboe is the more powerful heckelphone, which has a wider bore and larger tone than the baritone oboe. Only 165 heckelphones have ever been made. Not surprisingly, competent heckelphone players are difficult to find due to the extreme rarity of this particular instrument. The least common of all are the musette (also called oboe musette or piccolo oboe), the sopranino member of the family (it is usually pitched in E or F above the oboe), and the contrabass oboe (typically pitched in C, two octaves deeper than the standard oboe).

Folk versions of the oboe, sometimes equipped with extensive keywork, are found throughout Europe. These include the musette (France) and the piston oboe and bombarde (Brittany), the piffero and ciaramella (Italy), and the xirimia (also spelled chirimia) (Spain). Many of these are played in tandem with local forms of bagpipe, particularly with the Italian müsa and zampogna or Breton biniou.



The oboe remains uncommon in jazz music, but there have been notable uses of the instrument. Some early bands in the 1920s and '30s, most notably that of Paul Whiteman, included it for coloristic purposes. The multi-instrumentalist Garvin Bushell (1902–1991) played the oboe in jazz bands as early as 1924 and used the instrument throughout his career, eventually recording with John Coltrane in 1961. Gil Evans featured oboe in sections of his famous "Sketches of Spain" collaboration with trumpeter Miles Davis. Though primarily a tenor saxophone and flute player, Yusef Lateef was among the first (in 1961) to use the oboe as a solo instrument in modern jazz performances and recordings. Composer and double bassist Charles Mingus gave the oboe a brief but prominent role (played by Dick Hafer) in his composition "I.X. Love" on the 1963 album "Mingus Mingus Mingus Mingus Mingus".

With the birth of jazz fusion in the late 1960s, and its continuous development through the following decade, the oboe became somewhat more prominent, replacing on some occasions the saxophone as the focal point. The oboe was used with great success by the Welsh multi-instrumentalist Karl Jenkins in his work with the groups Nucleus and Soft Machine, and by the American woodwind player Paul McCandless, co-founder of the Paul Winter Consort and later Oregon.

The 1980s saw an increasing number of oboists try their hand at non-classical work, and many players of note have recorded and performed alternative music on oboe. Some present-day jazz groups influenced by classical music, such as the Maria Schneider Orchestra, feature the oboe.

Indie singer-songwriter and composer Sufjan Stevens, having studied the instrument in school, often includes the instrument in his arrangements and compositions, most frequently in his geographic tone-poems "Illinois", "Michigan".

The oboe is frequently featured in film music, often to underscore a particularly poignant or sad scene, for example in the motion picture "Born on the Fourth of July". One of the most prominent uses of the oboe in a film score is Ennio Morricone's "Gabriel's Oboe" theme from the 1986 film "The Mission".

It is featured as a solo instrument in the theme "Across the Stars" from the John Williams score to "".





</doc>
<doc id="22208" url="https://en.wikipedia.org/wiki?curid=22208" title="Organic chemistry">
Organic chemistry

Organic chemistry is a branch of chemistry that studies the structure, properties and reactions of organic compounds, which contain carbon in covalent bonding. Study of structure determines their chemical composition and formula. Study of properties includes physical and chemical properties, and evaluation of chemical reactivity to understand their behavior. The study of organic reactions includes the chemical synthesis of natural products, drugs, and polymers, and study of individual organic molecules in the laboratory and via theoretical (in silico) study.

The range of chemicals studied in organic chemistry includes hydrocarbons (compounds containing only carbon and hydrogen) as well as compounds based on carbon, but also containing other elements, especially oxygen, nitrogen, sulfur, phosphorus (included in many biochemicals) and the halogens. Organometallic chemistry is the study of compounds containing carbon–metal bonds.

In addition, contemporary research focuses on organic chemistry involving other organometallics including the lanthanides, but especially the transition metals zinc, copper, palladium, nickel, cobalt, titanium and chromium.
Organic compounds form the basis of all earthly life and constitute the majority of known chemicals. The bonding patterns of carbon, with its valence of four—formal single, double, and triple bonds, plus structures with delocalized electrons—make the array of organic compounds structurally diverse, and their range of applications enormous. They form the basis of, or are constituents of, many commercial products including pharmaceuticals; petrochemicals and agrichemicals, and products made from them including lubricants, solvents; plastics; fuels and explosives. The study of organic chemistry overlaps organometallic chemistry and biochemistry, but also with medicinal chemistry, polymer chemistry, and materials science.

Before the nineteenth century, chemists generally believed that compounds obtained from living organisms were endowed with a vital force that distinguished them from inorganic compounds. According to the concept of vitalism (vital force theory), organic matter was endowed with a "vital force". During the first half of the nineteenth century, some of the first systematic studies of organic compounds were reported. Around 1816 Michel Chevreul started a study of soaps made from various fats and alkalis. He separated the acids that, in combination with the alkali, produced the soap. Since these were all individual compounds, he demonstrated that it was possible to make a chemical change in various fats (which traditionally come from organic sources), producing new compounds, without "vital force". In 1828 Friedrich Wöhler produced the "organic" chemical urea (carbamide), a constituent of urine, from "inorganic" starting materials (the salts potassium cyanate and ammonium sulfate), in what is now called the Wöhler synthesis. Although Wöhler himself was cautious about claiming he had disproved vitalism, this was the first time a substance thought to be organic was synthesized in the laboratory without biological (organic) starting materials. The event is now generally accepted as indeed disproving the doctrine of vitalism.

In 1856 William Henry Perkin, while trying to manufacture quinine accidentally produced the organic dye now known as Perkin's mauve. His discovery, made widely known through its financial success, greatly increased interest in organic chemistry.

A crucial breakthrough for organic chemistry was the concept of chemical structure, developed independently in 1858 by both Friedrich August Kekulé and Archibald Scott Couper. Both researchers suggested that tetravalent carbon atoms could link to each other to form a carbon lattice, and that the detailed patterns of atomic bonding could be discerned by skillful interpretations of appropriate chemical reactions.

The era of the pharmaceutical industry began in the last decade of the 19th century when the manufacturing of acetylsalicylic acidmore commonly referred to as aspirinin Germany was started by Bayer. By 1910 Paul Ehrlich and his laboratory group began developing arsenic-based arsphenamine, (Salvarsan), as the first effective medicinal treatment of syphilis, and thereby initiated the medical practice of chemotherapy. Ehrlich popularized the concepts of "magic bullet" drugs and of systematically improving drug therapies. His laboratory made decisive contributions to developing antiserum for diphtheria and standardizing therapeutic serums.

Early examples of organic reactions and applications were often found because of a combination of luck and preparation for unexpected observations. The latter half of the 19th century however witnessed systematic studies of organic compounds. The development of synthetic indigo is illustrative. The production of indigo from plant sources dropped from 19,000 tons in 1897 to 1,000 tons by 1914 thanks to the synthetic methods developed by Adolf von Baeyer. In 2002, 17,000 tons of synthetic indigo were produced from petrochemicals.

In the early part of the 20th century, polymers and enzymes were shown to be large organic molecules, and petroleum was shown to be of biological origin.

The multiple-step synthesis of complex organic compounds is called total synthesis. Total synthesis of complex natural compounds increased in complexity to glucose and terpineol. For example, cholesterol-related compounds have opened ways to synthesize complex human hormones and their modified derivatives. Since the start of the 20th century, complexity of total syntheses has been increased to include molecules of high complexity such as lysergic acid and vitamin B.
The discovery of petroleum and the development of the petrochemical industry spurred the development of organic chemistry. Converting individual petroleum compounds into "types" of compounds by various chemical processes led to organic reactions enabling a broad range of industrial and commercial products including, among (many) others: plastics, synthetic rubber, organic adhesives, and various property-modifying petroleum additives and catalysts.

The majority of chemical compounds occurring in biological organisms are carbon compounds, so the association between organic chemistry and biochemistry is so close that biochemistry might be regarded as in essence a branch of organic chemistry. Although the history of biochemistry might be taken to span some four centuries, fundamental understanding of the field only began to develop in the late 19th century and the actual term "biochemistry" was coined around the start of 20th century. Research in the field increased throughout the twentieth century, without any indication of slackening in the rate of increase, as may be verified by inspection of abstraction and indexing services such as BIOSIS Previews and Biological Abstracts, which began in the 1920s as a single annual volume, but has grown so drastically that by the end of the 20th century it was only available to the everyday user as an online electronic database.

Since organic compounds often exist as mixtures, a variety of techniques have also been developed to assess purity, especially important being chromatography techniques such as HPLC and gas chromatography. Traditional methods of separation include distillation, crystallization, and solvent extraction.

Organic compounds were traditionally characterized by a variety of chemical tests, called "wet methods", but such tests have been largely displaced by spectroscopic or other computer-intensive methods of analysis. Listed in approximate order of utility, the chief analytical methods are:

Traditional spectroscopic methods such as infrared spectroscopy, optical rotation, and UV/VIS spectroscopy provide relatively nonspecific structural information but remain in use for specific classes of compounds. Refractive index and density were also important for substance identification.

The physical properties of organic compounds typically of interest include both quantitative and qualitative features. Quantitative information includes a melting point, boiling point, and index of refraction. Qualitative properties include odor, consistency, solubility, and color.

Organic compounds typically melt and many boil. In contrast, while inorganic materials generally can be melted, many do not boil, tending instead to degrade. In earlier times, the melting point (m.p.) and boiling point (b.p.) provided crucial information on the purity and identity of organic compounds. The melting and boiling points correlate with the polarity of the molecules and their molecular weight. Some organic compounds, especially symmetrical ones, sublime, that is they evaporate without melting. A well-known example of a sublimable organic compound is para-dichlorobenzene, the odiferous constituent of modern mothballs. Organic compounds are usually not very stable at temperatures above 300 °C, although some exceptions exist.

Neutral organic compounds tend to be hydrophobic; that is, they are less soluble in water than in organic solvents. Exceptions include organic compounds that contain ionizable (which can be converted in ions) groups as well as low molecular weight alcohols, amines, and carboxylic acids where hydrogen bonding occurs. Otherwise organic compounds tend to dissolve in organic solvents. Solubility varies widely with the organic solute and with the organic solvent.

Various specialized properties of molecular crystals and organic polymers with conjugated systems are of interest depending on applications, e.g. thermo-mechanical and electro-mechanical such as piezoelectricity, electrical conductivity (see conductive polymers and organic semiconductors), and electro-optical (e.g. non-linear optics) properties. For historical reasons, such properties are mainly the subjects of the areas of polymer science and materials science.

The names of organic compounds are either systematic, following logically from a set of rules, or nonsystematic, following various traditions. Systematic nomenclature is stipulated by specifications from IUPAC. Systematic nomenclature starts with the name for a parent structure within the molecule of interest. This parent name is then modified by prefixes, suffixes, and numbers to unambiguously convey the structure. Given that millions of organic compounds are known, rigorous use of systematic names can be cumbersome. Thus, IUPAC recommendations are more closely followed for simple compounds, but not complex molecules. To use the systematic naming, one must know the structures and names of the parent structures. Parent structures include unsubstituted hydrocarbons, heterocycles, and mono functionalized derivatives thereof.

Nonsystematic nomenclature is simpler and unambiguous, at least to organic chemists. Nonsystematic names do not indicate the structure of the compound. They are common for complex molecules, which include most natural products. Thus, the informally named lysergic acid diethylamide is systematically named
(6a"R",9"R")-"N","N"-diethyl-7-methyl-4,6,6a,7,8,9-hexahydroindolo-[4,3-"fg"] quinoline-9-carboxamide.

With the increased use of computing, other naming methods have evolved that are intended to be interpreted by machines. Two popular formats are SMILES and InChI.

Organic molecules are described more commonly by drawings or structural formulas, combinations of drawings and chemical symbols. The line-angle formula is simple and unambiguous. In this system, the endpoints and intersections of each line represent one carbon, and hydrogen atoms can either be notated explicitly or assumed to be present as implied by tetravalent carbon.
By 1880 an explosion in the number of chemical compounds being discovered occurred assisted by new synthetic and analytical techniques. Grignard described the situation as "chaos le plus complet" as due to the lack of convention it was possible to have multiple names for the same compound. This led to the creation of the Geneva rules in 1892.

The concept of functional groups is central in organic chemistry, both as a means to classify structures and for predicting properties. A functional group is a molecular module, and the reactivity of that functional group is assumed, within limits, to be the same in a variety of molecules. Functional groups can have a decisive influence on the chemical and physical properties of organic compounds. Molecules are classified based on their functional groups. Alcohols, for example, all have the subunit C-O-H. All alcohols tend to be somewhat hydrophilic, usually form esters, and usually can be converted to the corresponding halides. Most functional groups feature heteroatoms (atoms other than C and H). Organic compounds are classified according to functional groups, alcohols, carboxylic acids, amines, etc.

The aliphatic hydrocarbons are subdivided into three groups of homologous series according to their state of saturation:
The rest of the group is classed according to the functional groups present. Such compounds can be "straight-chain", branched-chain or cyclic. The degree of branching affects characteristics, such as the octane number or cetane number in petroleum chemistry.

Both saturated (alicyclic) compounds and unsaturated compounds exist as cyclic derivatives. The most stable rings contain five or six carbon atoms, but large rings (macrocycles) and smaller rings are common. The smallest cycloalkane family is the three-membered cyclopropane ((CH)). Saturated cyclic compounds contain single bonds only, whereas aromatic rings have an alternating (or conjugated) double bond. Cycloalkanes do not contain multiple bonds, whereas the cycloalkenes and the cycloalkynes do.

Aromatic hydrocarbons contain conjugated double bonds. This means that every carbon atom in the ring is sp2 hybridized, allowing for added stability. The most important example is benzene, the structure of which was formulated by Kekulé who first proposed the delocalization or resonance principle for explaining its structure. For "conventional" cyclic compounds, aromaticity is conferred by the presence of 4n + 2 delocalized pi electrons, where n is an integer. Particular instability (antiaromaticity) is conferred by the presence of 4n conjugated pi electrons.

The characteristics of the cyclic hydrocarbons are again altered if heteroatoms are present, which can exist as either substituents attached externally to the ring (exocyclic) or as a member of the ring itself (endocyclic). In the case of the latter, the ring is termed a heterocycle. Pyridine and furan are examples of aromatic heterocycles while piperidine and tetrahydrofuran are the corresponding alicyclic heterocycles. The heteroatom of heterocyclic molecules is generally oxygen, sulfur, or nitrogen, with the latter being particularly common in biochemical systems.

Heterocycles are commonly found in a wide range of products including aniline dyes and medicines. Additionally, they are prevalent in a wide range of biochemical compounds such as alkaloids, vitamins, steroids, and nucleic acids (e.g. DNA, RNA).

Rings can fuse with other rings on an edge to give polycyclic compounds. The purine nucleoside bases are notable polycyclic aromatic heterocycles. Rings can also fuse on a "corner" such that one atom (almost always carbon) has two bonds going to one ring and two to another. Such compounds are termed spiro and are important in several natural products.

One important property of carbon is that it readily forms chains, or networks, that are linked by carbon-carbon (carbon-to-carbon) bonds. The linking process is called polymerization, while the chains, or networks, are called polymers. The source compound is called a monomer.

Two main groups of polymers exist synthetic polymers and biopolymers. Synthetic polymers are artificially manufactured, and are commonly referred to as industrial polymers. Biopolymers occur within a respectfully natural environment, or without human intervention.

Biomolecular chemistry is a major category within organic chemistry which is frequently studied by biochemists. Many complex multi-functional group molecules are important in living organisms. Some are long-chain biopolymers, and these include peptides, DNA, RNA and the polysaccharides such as starches in animals and celluloses in plants. The other main classes are amino acids (monomer building blocks of peptides and proteins), carbohydrates (which includes the polysaccharides), the nucleic acids (which include DNA and RNA as polymers), and the lipids. Besides, animal biochemistry contains many small molecule intermediates which assist in energy production through the Krebs cycle, and produces isoprene, the most common hydrocarbon in animals. Isoprenes in animals form the important steroid structural (cholesterol) and steroid hormone compounds; and in plants form terpenes, terpenoids, some alkaloids, and a class of hydrocarbons called biopolymer polyisoprenoids present in the latex of various species of plants, which is the basis for making rubber.

See also: peptide synthesis, oligonucleotide synthesis and carbohydrate synthesis.

In pharmacology, an important group of organic compounds is small molecules, also referred to as 'small organic compounds'. In this context, a small molecule is a small organic compound that is biologically active but is not a polymer. In practice, small molecules have a molar mass less than approximately 1000 g/mol.

Fullerenes and carbon nanotubes, carbon compounds with spheroidal and tubular structures, have stimulated much research into the related field of materials science. The first fullerene was discovered in 1985 by Sir Harold W. Kroto of the United Kingdom and by Richard E. Smalley and Robert F. Curl, Jr., of the United States. Using a laser to vaporize graphite rods in an atmosphere of helium gas, these chemists and their assistants obtained cagelike molecules composed of 60 carbon atoms (C60) joined together by single and double bonds to form a hollow sphere with 12 pentagonal and 20 hexagonal faces—a design that resembles a football, or soccer ball. In 1996 the trio was awarded the Nobel Prize for their pioneering efforts. The C60 molecule was named buckminsterfullerene (or, more simply, the buckyball) after the American architect R. Buckminster Fuller, whose geodesic dome is constructed on the same structural principles.

Organic compounds containing bonds of carbon to nitrogen, oxygen and the halogens are not normally grouped separately. Others are sometimes put into major groups within organic chemistry and discussed under titles such as organosulfur chemistry, organometallic chemistry, organophosphorus chemistry and organosilicon chemistry.

Organic reactions are chemical reactions involving organic compounds. Many of these reactions are associated with functional groups. The general theory of these reactions involves careful analysis of such properties as the electron affinity of key atoms, bond strengths and steric hindrance. These factors can determine the relative stability of short-lived reactive intermediates, which usually directly determine the path of the reaction.

The basic reaction types are: addition reactions, elimination reactions, substitution reactions, pericyclic reactions, rearrangement reactions and redox reactions. An example of a common reaction is a substitution reaction written as:

where X is some functional group and Nu is a nucleophile.

The number of possible organic reactions is infinite. However, certain general patterns are observed that can be used to describe many common or useful reactions. Each reaction has a stepwise reaction mechanism that explains how it happens in sequence—although the detailed description of steps is not always clear from a list of reactants alone.

The stepwise course of any given reaction mechanism can be represented using arrow pushing techniques in which curved arrows are used to track the movement of electrons as starting materials transition through intermediates to final products.

Synthetic organic chemistry is an applied science as it borders engineering, the "design, analysis, and/or construction of works for practical purposes". Organic synthesis of a novel compound is a problem-solving task, where a synthesis is designed for a target molecule by selecting optimal reactions from optimal starting materials. Complex compounds can have tens of reaction steps that sequentially build the desired molecule. The synthesis proceeds by utilizing the reactivity of the functional groups in the molecule. For example, a carbonyl compound can be used as a nucleophile by converting it into an enolate, or as an electrophile; the combination of the two is called the aldol reaction. Designing practically useful syntheses always requires conducting the actual synthesis in the laboratory. The scientific practice of creating novel synthetic routes for complex molecules is called total synthesis.

Strategies to design a synthesis include retrosynthesis, popularized by E.J. Corey, which starts with the target molecule and splices it to pieces according to known reactions. The pieces, or the proposed precursors, receive the same treatment, until available and ideally inexpensive starting materials are reached. Then, the retrosynthesis is written in the opposite direction to give the synthesis. A "synthetic tree" can be constructed because each compound and also each precursor has multiple syntheses.




</doc>
<doc id="22209" url="https://en.wikipedia.org/wiki?curid=22209" title="Orthography">
Orthography

An orthography is a set of conventions for writing a language. It includes norms of spelling, hyphenation, capitalization, word breaks, emphasis, and punctuation.

Most transnational languages in the modern period have a system of writing, and for most such languages a standard orthography has been developed, often based on a standard variety of the language, and thus exhibiting less dialect variation than the spoken language. Sometimes there may be variation in a language's orthography, as between American and British spelling in the case of English orthography. In some languages orthography is regulated by language academies, although for many languages (including English) there are no such authorities, and orthography develops in a more natural way. Even in the latter languages, a significant amount of consensus arises naturally, although a maximum of consistency or standardization occurs only when prescriptively imposed according to style guides.

The English word "orthography" dates from the 15th century. It comes from the French "orthographie", from Latin "orthographia", which derives from Greek ὀρθός "orthós", "correct", and γράφειν "gráphein", "to write".

Orthography is largely concerned with matters of spelling, and in particular the relationship between phonemes and graphemes in a language. Other elements that may be considered part of orthography include hyphenation, capitalization, word breaks, emphasis, and punctuation. Orthography thus describes or defines the set of symbols used in writing a language, and the rules regarding how to use those symbols.

Most natural languages developed as oral languages, and writing systems have usually been crafted or adapted as ways of representing the spoken language. The rules for doing this tend to become standardized for a given language, leading to the development of an orthography that is generally considered "correct". In linguistics the term "orthography" is often used to refer to any method of writing a language, without judgment as to right and wrong, with a scientific understanding that orthographic standardization exists on a spectrum of strength of convention. The original sense of the word, though, implies a dichotomy of correct and incorrect, and the word is still most often used to refer specifically to a thoroughly standardized, prescriptively correct, way of writing a language. A distinction may be made here between "etic" and "emic" viewpoints: the purely descriptive (etic) approach, which simply considers any system that is actually used—and the emic view, which takes account of language users' perceptions of correctness.

Orthographic units, such as letters of an alphabet, are technically called graphemes. These are a type of abstraction, analogous to the phonemes of spoken languages; different physical forms of written symbols are considered to represent the same grapheme if the differences between them are not significant for meaning. For example, different forms of the letter "b" are all considered to represent a single grapheme in the orthography of, say, English.
Graphemes or sequences of them are sometimes placed between angle brackets, as in or . This distinguishes them from phonemic transcription, which is placed between slashes (, ), and from phonetic transcription, which is placed between square brackets (, ).

The writing systems on which orthographies are based can be divided into a number of types, depending on what type of unit each symbol serves to represent. The principal types are "logographic" (with symbols representing words or morphemes), "syllabic" (with symbols representing syllables), and "alphabetic" (with symbols roughly representing phonemes). Many writing systems combine features of more than one of these types, and a number of detailed classifications have been proposed. Japanese is an example of a writing system that can be written using a combination of logographic kanji characters and syllabic hiragana and katakana characters; as with many non-alphabetic languages, alphabetic romaji characters may also be used as needed.

Orthographies that use alphabets and syllabaries are based on the principle that the written symbols (graphemes) correspond to units of sound of the spoken language: phonemes in the former case, and syllables in the latter. However, in virtually all cases, this correspondence is not exact. Different languages' orthographies offer different degrees of correspondence between spelling and pronunciation. English orthography, French orthography and Danish orthography, for example, are highly irregular, whereas the orthographies of languages such as Russian, German and Spanish represent pronunciation much more faithfully, although the correspondence between letters and phonemes is still not exact. Finnish, Turkish and Serbo-Croatian orthographies are remarkably consistent: approximation of the principle "one letter per sound".

An orthography in which the correspondences between spelling and pronunciation are highly complex or inconsistent is called a "deep orthography" (or less formally, the language is said to have "irregular spelling"). An orthography with relatively simple and consistent correspondences is called "shallow" (and the language has "regular spelling").

One of the main reasons for which spelling and pronunciation deviate is that sound changes taking place in the spoken language are not always reflected in the orthography, and hence spellings correspond to historical rather than present-day pronunciation. One consequence of this is that many spellings come to reflect a word's morphophonemic structure rather than its purely phonemic structure (for example, the English regular past tense morpheme is consistently spelled "-ed" in spite of its different pronunciations in various words). This is discussed further at .

The syllabary systems of Japanese (hiragana and katakana) are examples of almost perfectly shallow orthographies—the kana correspond with almost perfect consistency to the spoken syllables, although with a few exceptions where symbols reflect historical or morphophonemic features: notably the use of ぢ "ji" and づ "zu" (rather than じ "ji" and ず "zu", their pronunciation in standard Tokyo dialect) when the character is a voicing of an underlying ち or つ (see rendaku), and the use of は, を, and へ to represent the sounds わ, お, and え, as relics of historical kana usage.

The Korean "hangul" system was also originally an extremely shallow orthography, but as a representation of the modern language it frequently also reflects morphophonemic features.

For full discussion of degrees of correspondence between spelling and pronunciation in alphabetic orthographies, including reasons why such correspondence may break down, see Phonemic orthography.

An orthography based on the principle that symbols correspond to phonemes may, in some cases, lack characters to represent all the phonemes or all the phonemic distinctions in the language. This is called a defective orthography. An example in English is the lack of any indication of stress. Another is the digraph "th", which represents two different phonemes (as in "then" and "thin"). A more systematic example is that of abjads like the Arabic and Hebrew alphabets, in which the short vowels are normally left unwritten and must be inferred by the reader.

When an alphabet is borrowed from its original language for use with a new language—as has been done with the Latin alphabet for many languages, or Japanese Katakana for non-Japanese words—it often proves defective in representing the new language's phonemes. Sometimes this problem is addressed by the use of such devices as digraphs (such as "sh" and "ch" in English, where pairs of letters represent single sounds), diacritics (like the caron on the letters "š" and "č", which represent those same sounds in Czech), or the addition of completely new symbols (as some languages have introduced the letter "w" to the Latin alphabet) or of symbols from another alphabet, such as the rune "þ" in Icelandic.

After the classical period, Greek developed a lowercase letter system that introduced diacritic marks to enable foreigners to learn pronunciation and in some cases, grammatical features. However, as pronunciation of letters changed over time, the diacritic marks were reduced to representing the stressed syllable. In Modern Greek typesetting, this system has been simplified to only have a single accent to indicate which syllable is stressed.




</doc>
<doc id="22210" url="https://en.wikipedia.org/wiki?curid=22210" title="One-time pad">
One-time pad

In cryptography, the one-time pad (OTP) is an encryption technique that cannot be cracked, but requires the use of a one-time pre-shared key the same size as, or longer than, the message being sent. In this technique, a plaintext is paired with a random secret key (also referred to as "a one-time pad"). Then, each bit or character of the plaintext is encrypted by combining it with the corresponding bit or character from the pad using modular addition.

The resulting ciphertext will be impossible to decrypt or break if the following four conditions are met:


It has also been proven that any cipher with the property of perfect secrecy must use keys with effectively the same requirements as OTP keys. Digital versions of one-time pad ciphers have been used by nations for critical diplomatic and military communication, but the problems of secure key distribution have made them impractical for most applications.

First described by Frank Miller in 1882, the one-time pad was re-invented in 1917. On July 22, 1919, U.S. Patent 1,310,719 was issued to Gilbert Vernam for the XOR operation used for the encryption of a one-time pad. Derived from his "Vernam cipher", the system was a cipher that combined a message with a key read from a punched tape. In its original form, Vernam's system was vulnerable because the key tape was a loop, which was reused whenever the loop made a full cycle. One-time use came later, when Joseph Mauborgne recognized that if the key tape were totally random, then cryptanalysis would be impossible.

The "pad" part of the name comes from early implementations where the key material was distributed as a pad of paper, allowing the current top sheet to be torn off and destroyed after use. For concealment the pad was sometimes so small that a powerful magnifying glass was required to use it. The KGB used pads of such size that they could fit in the palm of a hand, or in a walnut shell. To increase security, one-time pads were sometimes printed onto sheets of highly flammable nitrocellulose, so that they could easily be burned after use.

There is some ambiguity to the term "Vernam cipher" because some sources use "Vernam cipher" and "one-time pad" synonymously, while others refer to any additive stream cipher as a "Vernam cipher", including those based on a cryptographically secure pseudorandom number generator (CSPRNG).

Frank Miller in 1882 was the first to describe the one-time pad system for securing telegraphy.

The next one-time pad system was electrical. In 1917, Gilbert Vernam (of AT&T Corporation) invented and later patented in 1919 () a cipher based on teleprinter technology. Each character in a message was electrically combined with a character on a punched paper tape key. Joseph Mauborgne (then a captain in the U.S. Army and later chief of the Signal Corps) recognized that the character sequence on the key tape could be completely random and that, if so, cryptanalysis would be more difficult. Together they invented the first one-time tape system.

The next development was the paper pad system. Diplomats had long used codes and ciphers for confidentiality and to minimize telegraph costs. For the codes, words and phrases were converted to groups of numbers (typically 4 or 5 digits) using a dictionary-like codebook. For added security, secret numbers could be combined with (usually modular addition) each code group before transmission, with the secret numbers being changed periodically (this was called superencryption). In the early 1920s, three German cryptographers (Werner Kunze, Rudolf Schauffler and Erich Langlotz), who were involved in breaking such systems, realized that they could never be broken if a separate randomly chosen additive number was used for every code group. They had duplicate paper pads printed with lines of random number groups. Each page had a serial number and eight lines. Each line had six 5-digit numbers. A page would be used as a work sheet to encode a message and then destroyed. The serial number of the page would be sent with the encoded message. The recipient would reverse the procedure and then destroy his copy of the page. The German foreign office put this system into operation by 1923.

A separate notion was the use of a one-time pad of letters to encode plaintext directly as in the example below. Leo Marks describes inventing such a system for the British Special Operations Executive during World War II, though he suspected at the time that it was already known in the highly compartmentalized world of cryptography, as for instance at Bletchley Park.

The final discovery was made by information theorist Claude Shannon in the 1940s who recognized and proved the theoretical significance of the one-time pad system. Shannon delivered his results in a classified report in 1945, and published them openly in 1949. At the same time, Soviet information theorist Vladimir Kotelnikov had independently proved absolute security of the one-time pad; his results were delivered in 1941 in a report that apparently remains classified.

Suppose Alice wishes to send the message "HELLO" to Bob. Assume two pads of paper containing identical random sequences of letters were somehow previously produced and securely issued to both. Alice chooses the appropriate unused page from the pad. The way to do this is normally arranged for in advance, as for instance "use the 12th sheet on 1 May", or "use the next available sheet for the next message".

The material on the selected sheet is the "key" for this message. Each letter from the pad will be combined in a predetermined way with one letter of the message. (It is common, but not required, to assign each letter a numerical value, e.g., "A" is 0, "B" is 1, and so on.)

In this example, the technique is to combine the key and the message using modular addition. The numerical values of corresponding message and key letters are added together, modulo 26. So, if key material begins with "XMCKL" and the message is "HELLO", then the coding would be done as follows:

If a number is larger than 25, then the remainder after subtraction of 26 is taken in modular arithmetic fashion. This simply means that if the computations "go past" Z, the sequence starts again at A.

The ciphertext to be sent to Bob is thus "EQNVZ". Bob uses the matching key page and the same process, but in reverse, to obtain the plaintext. Here the key is "subtracted" from the ciphertext, again using modular arithmetic:

Similar to the above, if a number is negative, then 26 is added to make the number zero or higher.

Thus Bob recovers Alice's plaintext, the message "HELLO". Both Alice and Bob destroy the key sheet immediately after use, thus preventing reuse and an attack against the cipher. The KGB often issued its agents one-time pads printed on tiny sheets of flash paper, paper chemically converted to nitrocellulose, which burns almost instantly and leaves no ash.

The classical one-time pad of espionage used actual pads of minuscule, easily concealed paper, a sharp pencil, and some mental arithmetic. The method can be implemented now as a software program, using data files as input (plaintext), output (ciphertext) and key material (the required random sequence). The XOR operation is often used to combine the plaintext and the key elements, and is especially attractive on computers since it is usually a native machine instruction and is therefore very fast. It is, however, difficult to ensure that the key material is actually random, is used only once, never becomes known to the opposition, and is completely destroyed after use. The auxiliary parts of a software one-time pad implementation present real challenges: secure handling/transmission of plaintext, truly random keys, and one-time-only use of the key.

To continue the example from above, suppose Eve intercepts Alice's ciphertext: "EQNVZ". If Eve had infinite time, she would find that the key "XMCKL" would produce the plaintext "HELLO", but she would also find that the key "TQURI" would produce the plaintext "LATER", an equally plausible message:
In fact, it is possible to "decrypt" out of the ciphertext any message whatsoever with the same number of characters, simply by using a different key, and there is no information in the ciphertext that will allow Eve to choose among the various possible readings of the ciphertext.

One-time pads are "information-theoretically secure" in that the encrypted message (i.e., the ciphertext) provides no information about the original message to a cryptanalyst (except the maximum possible length of the message). This is a very strong notion of security first developed during WWII by Claude Shannon and proved, mathematically, to be true for the one-time pad by Shannon about the same time. His result was published in the "Bell System Technical Journal" in 1949. Properly used, one-time pads are secure in this sense even against adversaries with infinite computational power.

Claude Shannon proved, using information theory considerations, that the one-time pad has a property he termed "perfect secrecy"; that is, the ciphertext "C" gives absolutely no additional information about the plaintext. This is because, given a truly random key that is used only once, a ciphertext can be translated into "any" plaintext of the same length, and all are equally likely. Thus, the "a priori" probability of a plaintext message "M" is the same as the "a posteriori" probability of a plaintext message "M" given the corresponding ciphertext.

Mathematically, this is expressed as formula_1, where formula_2 is the information entropy of the plaintext and formula_3 is the conditional entropy of the plaintext given the ciphertext "C". (Here, Η is the capital Greek letter eta.) This implies that for every message "M" and corresponding ciphertext "C", there must be at least one key "K" that binds them as a one-time pad. Mathematically speaking, this means formula_4, where formula_5 denotes the distinct quantity of keys, ciphers and messages. In other words, if you need to be able to go from any plaintext in message space "M" to any cipher in cipher-space "C" (encryption) and from any cipher in cipher-space "C" to a plain text in message space "M" (decryption), you need at least formula_6 keys (all keys used with equal probability of formula_7 to ensure perfect secrecy).

Another way of stating perfect secrecy is based on the idea that for all messages formula_8 in message space "M", and for all ciphers "c" in cipher space "C", we have formula_9, where formula_10 represents the probabilities, taken over a choice of formula_11 in key space formula_12 over the coin tosses of a probabilistic algorithm, formula_13. Perfect secrecy is a strong notion of cryptanalytic difficulty.

Conventional symmetric encryption algorithms use complex patterns of substitution and transpositions. For the best of these currently in use, it is not known whether there can be a cryptanalytic procedure that can reverse (or, usefully, partially reverse) these transformations without knowing the key used during encryption. Asymmetric encryption algorithms depend on mathematical problems that are thought to be difficult to solve, such as integer factorization and discrete logarithms. However, there is no proof that these problems are hard, and a mathematical breakthrough could make existing systems vulnerable to attack.

Given perfect secrecy, in contrast to conventional symmetric encryption, OTP is immune even to brute-force attacks. Trying all keys simply yields all plaintexts, all equally likely to be the actual plaintext. Even with known plaintext, like part of the message being known, brute-force attacks cannot be used, since an attacker is unable to gain any information about the parts of the key needed to decrypt the rest of the message. The parts that are known will reveal "only" the parts of the key corresponding to them, and they correspond on a strictly one-to-one basis; no part of the key is dependent on any other part.

Quantum computers have been shown by Peter Shor and others to be much faster at solving some of the difficult problems that grant some asymmetric encryption its security. If quantum computers are built with enough qubits, and overcoming some limitations to error-correction, some public key cryptography algorithms will become obsolete. One-time pads, however, will remain secure. See quantum cryptography and post-quantum cryptography for further discussion of the ramifications of quantum computers to information security.

Despite Shannon's proof of its security, the one-time pad has serious drawbacks in practice because it requires:


One-time pads solve few current practical problems in cryptography. High quality ciphers are widely available and their security is not considered a major worry at present. Such ciphers are almost always easier to employ than one-time pads; the amount of key material that must be properly and securely generated, securely distributed and securely stored is far smaller, and public key cryptography overcomes this problem.

High-quality random numbers are difficult to generate. The random number generation functions in most programming language libraries are not suitable for cryptographic use. Even those generators that are suitable for normal cryptographic use, including /dev/random and many hardware random number generators, may make some use of cryptographic functions whose security has not been proven. An example of how true randomness can be achieved is by measuring radioactive emissions.

In particular, one-time use is absolutely necessary. If a one-time pad is used just twice, simple mathematical operations can reduce it to a running key cipher. If both plaintexts are in a natural language (e.g., English or Russian) then, even though both are secret, each stands a very high chance of being recovered by heuristic cryptanalysis, with possibly a few ambiguities. Of course, a longer message can only be broken for the portion that overlaps a shorter message, plus perhaps a little more by completing a word or phrase. The most famous exploit of this vulnerability occurred with the Venona project.

Because the pad, like all shared secrets, must be passed and kept secure, and the pad has to be at least as long as the message, there is often no point in using one-time padding, as one can simply send the plain text instead of the pad (as both can be the same size and have to be sent securely). However, once a very long pad has been securely sent (e.g., a computer disk full of random data), it can be used for numerous future messages, until the sum of their sizes equals the size of the pad. Quantum key distribution also proposes a solution to this problem, assuming fault-tolerant quantum computers.

Distributing very long one-time pad keys is inconvenient and usually poses a significant security risk. The pad is essentially the encryption key, but unlike keys for modern ciphers, it must be extremely long and is much too difficult for humans to remember. Storage media such as thumb drives, DVD-Rs or personal digital audio players can be used to carry a very large one-time-pad from place to place in a non-suspicious way, but even so the need to transport the pad physically is a burden compared to the key negotiation protocols of a modern public-key cryptosystem, and such media cannot reliably be erased securely by any means short of physical destruction (e.g., incineration). A 4.7 GB DVD-R full of one-time-pad data, if shredded into particles in size, leaves over 4 megabits of (admittedly hard to recover, but not impossibly so) data on each particle. In addition, the risk of compromise during transit (for example, a pickpocket swiping, copying and replacing the pad) is likely to be much greater in practice than the likelihood of compromise for a cipher such as AES. Finally, the effort needed to manage one-time pad key material scales very badly for large networks of communicants—the number of pads required goes up as the square of the number of users freely exchanging messages. For communication between only two persons, or a star network topology, this is less of a problem.

The key material must be securely disposed of after use, to ensure the key material is never reused and to protect the messages sent. Because the key material must be transported from one endpoint to another, and persist until the message is sent or received, it can be more vulnerable to forensic recovery than the transient plaintext it protects (see data remanence).

As traditionally used, one-time pads provide no message authentication, the lack of which can pose a security threat in real-world systems. For example, an attacker who knows that the message contains "meet jane and me tomorrow at three thirty pm" can derive the corresponding codes of the pad directly from the two known elements (the encrypted text and the known plaintext). The attacker can then replace that text by any other text of exactly the same length, such as "three thirty meeting is canceled, stay home". The attacker's knowledge of the one-time pad is limited to this byte length, which must be maintained for any other content of the message to remain valid. This is a little different from malleability where it is not taken necessarily that the plaintext is known. "See also" stream cipher attack.

Standard techniques to prevent this, such as the use of a message authentication code can be used along with a one-time pad system to prevent such attacks, as can classical methods such as variable length padding and Russian copulation, but they all lack the perfect security the OTP itself has. Universal hashing provides a way to authenticate messages up to an arbitrary security bound (i.e., for any , a large enough hash ensures that even a computationally unbounded attacker's likelihood of successful forgery is less than "p"), but this uses additional random data from the pad, and removes the possibility of implementing the system without a computer.

Despite its problems, the one-time-pad retains some practical interest. In some hypothetical espionage situations, the one-time pad might be useful because it can be computed by hand with only pencil and paper. Indeed, nearly all other high quality ciphers are entirely impractical without computers. In the modern world, however, computers (such as those embedded in personal electronic devices such as mobile phones) are so ubiquitous that possessing a computer suitable for performing conventional encryption (for example, a phone that can run concealed cryptographic software) will usually not attract suspicion.


One-time pads have been used in special circumstances since the early 1900s. In 1923, it was employed for diplomatic communications by the German diplomatic establishment. The Weimar Republic Diplomatic Service began using the method in about 1920. The breaking of poor Soviet cryptography by the British, with messages made public for political reasons in two instances in the 1920s (ARCOS case), appear to have induced the Soviet Union to adopt one-time pads for some purposes by around 1930. KGB spies are also known to have used pencil and paper one-time pads more recently. Examples include Colonel Rudolf Abel, who was arrested and convicted in New York City in the 1950s, and the 'Krogers' (i.e., Morris and Lona Cohen), who were arrested and convicted of espionage in the United Kingdom in the early 1960s. Both were found with physical one-time pads in their possession.

A number of nations have used one-time pad systems for their sensitive traffic. Leo Marks reports that the British Special Operations Executive used one-time pads in World War II to encode traffic between its offices. One-time pads for use with its overseas agents were introduced late in the war. A few British one-time tape cipher machines include the Rockex and Noreen. The German Stasi Sprach Machine was also capable of using one time tape that East Germany, Russia, and even Cuba used to send encrypted messages to their agents.

The World War II voice scrambler SIGSALY was also a form of one-time system. It added noise to the signal at one end and removed it at the other end. The noise was distributed to the channel ends in the form of large shellac records that were manufactured in unique pairs. There were both starting synchronization and longer-term phase drift problems that arose and were solved before the system could be used.

The hotline between Moscow and Washington D.C., established in 1963 after the 1962 Cuban Missile Crisis, used teleprinters protected by a commercial one-time tape system. Each country prepared the keying tapes used to encode its messages and delivered them via their embassy in the other country. A unique advantage of the OTP in this case was that neither country had to reveal more sensitive encryption methods to the other.

U.S. Army Special Forces used one-time pads in Vietnam. By using Morse code with one-time pads and continuous wave radio transmission (the carrier for Morse code), they achieved both secrecy and reliable communications.

During the 1983 Invasion of Grenada, U.S. forces found a supply of pairs of one-time pad books in a Cuban warehouse.

Starting in 1988, the African National Congress (ANC) used disk-based one-time pads as part of a secure communication system between ANC leaders outside South Africa and in-country operatives as part of Operation Vula, a successful effort to build a resistance network inside South Africa. Random numbers on the disk were erased after use. A Belgian airline stewardess acted as courier to bring in the pad disks. A regular resupply of new disks was needed as they were used up fairly quickly. One problem with the system was that it could not be used for secure data storage. Later Vula added a stream cipher keyed by book codes to solve this problem.

A related notion is the one-time code—a signal, used only once; e.g., "Alpha" for "mission completed", "Bravo" for "mission failed" or even "Torch" for "Allied invasion of French Northern Africa" cannot be "decrypted" in any reasonable sense of the word. Understanding the message will require additional information, often 'depth' of repetition, or some traffic analysis. However, such strategies (though often used by real operatives, and baseball coaches) are not a cryptographic one-time pad in any significant sense.

At least into the 1970s, the U.S. National Security Agency (NSA) produced a variety of manual one-time pads, both general purpose and specialized, with 86,000 one-time pads produced in fiscal year 1972. Special purpose pads were produced for what NSA called "pro forma" systems, where “the basic framework, form or format of every message text is identical or nearly so; the same kind of information, message after message, is to be presented in the same order, and only specific values, like numbers, change with each message.” Examples included nuclear launch messages and radio direction finding reports (COMUS).

General purpose pads were produced in several formats, a simple list of random letters (DIANA) or just numbers (CALYPSO), tiny pads for covert agents (MICKEY MOUSE), and pads designed for more rapid encoding of short messages, at the cost of lower density. One example, ORION, had 50 rows of plaintext alphabets on one side and the corresponding random cipher text letters on the other side. By placing a sheet on top of a piece of carbon paper with the carbon face up, one could circle one letter in each row on one side and the corresponding letter one the other side would be circled by the carbon paper. Thus one ORION sheet could quickly encode or decode a message up to 50 characters long. Production of ORION pads required printing both sides in exact registration, a difficult process, so NSA switched to another pad format, MEDEA, with 25 rows of paired alphabets and random characters. ("See" for illustrations.)
The NSA also built automated systems for the "centralized headquarters of CIA and Special Forces units so that they can efficiently process the many separate one-time pad messages to and from individual pad holders in the field".

During World War II and into the 1950s, the U.S. made extensive use of one-time tape systems. In addition to providing confidentiality, circuits secured by one-time tape ran continually, even when there was no traffic, thus protecting against traffic analysis. In 1955, NSA produced some 1,660,000 rolls of one time tape. Each roll was 8 inches in diameter, contained 100,000 characters, lasted 166 minutes and cost $4.55 to produce. By 1972, only 55,000 rolls were produced, as one-time tapes were replaced by rotor machines such as SIGTOT, and later by electronic devices based on shift registers. The NSA describes one-time tape systems like 5-UCO and SIGTOT as being used for intelligence traffic until the introduction of the electronic cipher based KW-26 in 1957.

While one-time pads provide perfect secrecy if generated and used properly, small mistakes can lead to successful cryptanalysis:



</doc>
<doc id="22211" url="https://en.wikipedia.org/wiki?curid=22211" title="Oelde">
Oelde

Oelde () is a town in the district of Warendorf, in North Rhine-Westphalia, Germany. It is located near Beckum.

Oelde consists of 5 districts:

The neighboring municipalities and cities are clockwise, starting in the north:

Oelde is twinned with:

The name Oelde was first mentioned in a document around 890 as "Ulithi im Dreingau" in the Urbar of the Werden monastery.

In 1457 a conflagration destroyed the city. In 1498, after the reconstruction, Oelde had 750 citizens. Another fire raged in 1605 and destroyed a total of 18 houses, barns and the town hall.

In 1939, Oelde was given its own exit when the motorway A 2 was built. 

In the 1950s and 1960s, a high number of visitors came to Oelde when diplomats accepted the invitation of the Federal Presidents Heuss and Lübke to hunt small game in the state forest "Geisterholz". These events were commonly known as "diplomatic hunts."

In 2001 Oelde hosted one of the most important flower shows ever organized in Westphalia with more than 2.2 million visitors. Since then, the city garden, included in the exhibition grounds and embellished for the occasion, has been commercially exploited under the name "Park of the four seasons" (Vier-Jahreszeiten-Park).

Oelde is a centre of metal and lumber production, publishing, and also higher education through its nursing college.
It is also home to the headquarters of GEA (Westfalia Separator), a manufacturer of centrifuges and dairy machines and the headquarters of Haver & Boecker, a manufacturer of wire weaving.

Oelde is connected to the Bundesautobahn 2.

The Hamm–Minden railway connects Oelde station to the German rail network. The line is served by the Rhein-Weser-Express and the Ems-Börde-Bahn every hour.



</doc>
<doc id="22213" url="https://en.wikipedia.org/wiki?curid=22213" title="Operator (mathematics)">
Operator (mathematics)

In mathematics, an operator is generally a mapping or function that acts on elements of a space to produce elements of another space (possibly the same space, sometimes required to be the same space). There is no general definition of an "operator", but the term is often used in place of "function" when the domain is a set of functions or other structured objects. Also, the domain of an operator is often difficult to be explicitly characterized (for example in the case of an integral operator), and may be extended to related objects (an operator that acts on functions may act also on differential equations whose functions are solutions). See Operator (physics) for other examples.

The most basic operators (in some sense) are linear maps, which act on vector spaces. However, when using "linear operator" instead of "linear map", mathematicians often mean actions on vector spaces of functions, which also preserve other properties, such as continuity. For example, differentiation and indefinite integration are linear operators; operators that are built from them are called differential operators, integral operators or integro-differential operators.

Operator is also used for denoting the symbol of a mathematical operation. This is related with the meaning of "operator" in computer programming, see operator (computer programming).

The most common kind of operator encountered are "linear operators". Let "U" and "V" be vector spaces over a field "K". A mapping "A": "U" → "V" is linear if
for all x, y in "U" and for all "α, β" in "K". 
This means that a linear operator preserves vector space operations, in the sense that it does not matter whether you apply the linear operator before or after the operations of addition and scalar multiplication. In more technical words, linear operators are morphisms between vector spaces.

In the finite-dimensional case linear operators can be represented by matrices in the following way. Let formula_2 be a field, and formula_3 and formula_4 be finite-dimensional vector spaces over formula_2. Let us select a basis formula_6 in formula_3 and formula_8 in formula_4. Then let formula_10 be an arbitrary vector in formula_3 (assuming Einstein convention), and formula_12 be a linear operator. Then
Then formula_14 is the matrix of the operator formula_15 in fixed bases. formula_16 does not depend on the choice of formula_17, and formula_18 if formula_19. Thus in fixed bases n-by-m matrices are in bijective correspondence to linear operators from formula_3 to formula_4.

The important concepts directly related to operators between finite-dimensional vector spaces are the ones of rank, determinant, inverse operator, and eigenspace.

Linear operators also play a great role in the infinite-dimensional case. The concepts of rank and determinant cannot be extended to infinite-dimensional matrices. This is why very different techniques are employed when studying linear operators (and operators in general) in the infinite-dimensional case. The study of linear operators in the infinite-dimensional case is known as functional analysis (so called because various classes of functions form interesting examples of infinite-dimensional vector spaces).

The space of sequences of real numbers, or more generally sequences of vectors in any vector space, themselves form an infinite-dimensional vector space. The most important cases are sequences of real or complex numbers, and these spaces, together with linear subspaces, are known as sequence spaces. Operators on these spaces are known as sequence transformations.

Bounded linear operators over Banach space form a Banach algebra in respect to the standard operator norm. The theory of Banach algebras develops a very general concept of spectra that elegantly generalizes the theory of eigenspaces.

Let "U" and "V" be two vector spaces over the same ordered field (for example, formula_22), and they are equipped with norms. Then a linear operator from "U" to "V" is called bounded if there exists "C > 0" such that
for all x in "U".

Bounded operators form a vector space. On this vector space we can introduce a norm that is compatible with the norms of "U" and "V":

In case of operators from "U" to itself it can be shown that

Any unital normed algebra with this property is called a Banach algebra. It is possible to generalize spectral theory to such algebras. C*-algebras, which are Banach algebras with some additional structure, play an important role in quantum mechanics.

In geometry, additional structures on vector spaces are sometimes studied. Operators that map such vector spaces to themselves bijectively are very useful in these studies, they naturally form groups by composition.

For example, bijective operators preserving the structure of a vector space are precisely the invertible linear operators. They form the general linear group under composition. They "do not" form a vector space under the addition of operators, e.g. both "id" and "-id" are invertible (bijective), but their sum, 0, is not.

Operators preserving the Euclidean metric on such a space form the isometry group, and those that fix the origin form a subgroup known as the orthogonal group. Operators in the orthogonal group that also preserve the orientation of vector tuples form the special orthogonal group, or the group of rotations.

Operators are also involved in probability theory, such as expectation, variance, and covariance. Indeed, every covariance is basically a dot product; every variance is a dot product of a vector with itself, and thus is a quadratic norm; every standard deviation is a norm (square root of the quadratic norm); the corresponding cosine to this dot product is the Pearson correlation coefficient; expected value is basically an integral operator (used to measure weighted shapes in the space).

From the point of view of functional analysis, calculus is the study of two linear operators: the differential operator formula_26, and the Volterra operator formula_27.

The Fourier transform is useful in applied mathematics, particularly physics and signal processing. It is another integral operator; it is useful mainly because it converts a function on one (temporal) domain to a function on another (frequency) domain, in a way effectively invertible. No information is lost, as there is an inverse transform operator. In the simple case of periodic functions, this result is based on the theorem that any continuous periodic function can be represented as the sum of a series of sine waves and cosine waves:
The tuple "(a, a, b, a, b, ...)" is in fact an element of an infinite-dimensional vector space ℓ, and thus Fourier series is a linear operator.

When dealing with general function R → C, the transform takes on an integral form:

The "Laplace transform" is another integral operator and is involved in simplifying the process of solving differential equations.

Given "f" = "f"("s"), it is defined by:

Three operators are key to vector calculus:

As an extension of vector calculus operators to physics, engineering and tensor spaces, Grad, Div and Curl operators also are often associated with Tensor calculus as well as vector calculus.



</doc>
<doc id="22216" url="https://en.wikipedia.org/wiki?curid=22216" title="O Brother, Where Art Thou?">
O Brother, Where Art Thou?

O Brother, Where Art Thou? is a 2000 crime comedy-drama film written, produced, co-edited and directed by Joel and Ethan Coen, and starring George Clooney, John Turturro, and Tim Blake Nelson, with Chris Thomas King, John Goodman, Holly Hunter, and Charles Durning in supporting roles.

The film is set in 1930 or 1940 rural Mississippi after the Great Depression. Its story is a modern satire loosely based on Homer's epic Greek poem "The Odyssey" that incorporates mythology from the American South. The title of the film is a reference to the Preston Sturges 1941 film "Sullivan's Travels", in which the protagonist is a director who wants to film "O Brother, Where Art Thou?", a fictional book about the Great Depression.

Much of the music used in the film is period folk music, including that of Virginia bluegrass singer Ralph Stanley. The movie was one of the first to extensively use digital color correction to give the film an autumnal, sepia-tinted look. The film received positive reviews, and the soundtrack won a Grammy Award for Album of the Year in 2002 using American folk music. The country and folk musicians who were dubbed into the film included John Hartford, Alison Krauss, Dan Tyminski, Emmylou Harris, Gillian Welch, Chris Sharp, Patty Loveless, and others. They joined together to perform the music from the film in a "Down from the Mountain" concert tour which was filmed for TV and DVD.

Three convicts, Ulysses Everett McGill, Pete Hogwallop, and Delmar O'Donnell, escape from a chain gang and set out to retrieve a supposed treasure Everett buried before the area is flooded to make a lake. The three get a lift from a blind man driving a handcar on a railway. He tells them, among other prophecies, that they will find a fortune but not the one they seek. The trio make their way to the house of Wash, Pete's cousin. They sleep in the barn, but Wash reports them to Sheriff Cooley, who, along with his men, torches the barn. Wash's son helps them escape.

They pick up Tommy Johnson, a young black man, who claims he sold his soul to the devil in exchange for the ability to play guitar. In need of money, the four stop at a radio broadcast tower where they record a song as The Soggy Bottom Boys. That night, the trio part ways with Tommy after their car is discovered by the police. Unbeknownst to them, the recording becomes a major hit.

Near a river, the group hears singing. They see three women washing clothes and singing. The women drug them with corn whiskey and they lose consciousness. Upon waking, Delmar finds Pete's clothes lying next to him, empty except for a toad. Delmar is convinced the women were Sirens and transformed Pete into the toad. Later, one-eyed Bible salesman Big Dan Teague invites them for a picnic lunch, then mugs them and kills the toad.

Everett and Delmar arrive in Everett's home town. Everett confronts his wife Penny, who changed her last name and told his daughters he was dead. He gets into a fight with Vernon T. Waldrip, her new "suitor." They later see Pete working on a chain gang. Later that night, they sneak into Pete's holding cell and free him. As it turns out, the women had dragged Pete away and turned him in to the authorities. Under torture, Pete gave away the treasure's location to the police. Everett then confesses that there is no treasure. He made it up to convince the guys he was chained with to escape with him in order to stop his wife from getting married. Pete is enraged at Everett, because he had two weeks left on his original sentence, and must serve fifty more years for the escape.

The trio stumble upon a rally of the Ku Klux Klan, who are planning to hang Tommy. The trio disguise themselves as Klansmen and attempt to rescue Tommy. However, Big Dan, a Klan member, reveals their identities. Chaos ensues, and the Grand Wizard reveals himself as Homer Stokes, a candidate in the upcoming gubernatorial election. The trio rush Tommy away and cut the supports of a large burning cross, leaving it to fall on Big Dan.

Everett convinces Pete, Delmar and Tommy to help him win his wife back. They sneak into a Stokes campaign gala dinner she is attending, disguised as musicians. The group begins a performance of their radio hit. The crowd recognizes the song and goes wild. Homer recognizes them as the group who humiliated his mob. When he demands the group be arrested and reveals his white supremacist views, the crowd runs him out of town on a rail. Pappy O'Daniel, the incumbent candidate, seizes the opportunity, endorses the Soggy Bottom Boys and grants them full pardons. Penny agrees to marry Everett with the condition that he find her original ring.

The next morning, the group sets out to retrieve the ring, which is at a cabin in the valley which Everett had earlier claimed was the location of his treasure. The police, having learned of the place from Pete, arrest the group. Dismissing their claims of having received pardons, Sheriff Cooley orders them hanged. Just as Everett prays to God, the valley is flooded and they are saved. Tommy finds the ring in a desk that floats by, and they return to town. However, when Everett presents the ring to Penny, it turns out it was not her ring, she doesn't want that one, and she can't remember where she put the real ring.


Gillian Welch, who contributed to the soundtrack, appears as a record store customer asking for a copy of the Soggy Bottom Boys' record.

The idea of "O Brother, Where Art Thou?" arose spontaneously. Work on the script began in December 1997, long before the start of production, and was at least half-written by May 1998. Despite the fact that Ethan Coen described the "Odyssey" as "one of my favorite storyline schemes", neither of the brothers had read the epic, and they were only familiar with its content through adaptations and numerous references to the "Odyssey" in popular culture. According to the brothers, Nelson (who has a degree in classics from Brown University) was the only person on the set who had read the "Odyssey".

The title of the film is a reference to the 1941 Preston Sturges film "Sullivan's Travels", in which the protagonist (a director) wants to direct a film about the Great Depression called "O Brother, Where Art Thou?" that will be a "commentary on modern conditions, stark realism, and the problems that confront the average man". Lacking any experience in this area, the director sets out on a journey to experience the human suffering of the average man but is sabotaged by his anxious studio. The film has some similarity in tone to Sturges's film, including scenes with prison gangs and a black church choir. The prisoners at the picture show scene is also a direct homage to a nearly identical scene in Sturges's film.

Joel Coen revealed in a 2000 interview that he traveled to Phoenix to offer the lead role to Clooney. Clooney agreed to do the role immediately, without reading the script. He stated that he liked even the Coens' least successful films. Clooney did not immediately understand his character and sent the script to his uncle Jack, who lived in Kentucky, asking him to read the entire script into a tape recorder. Unknown to Clooney, in his recording, Jack, a devout Baptist, omitted all instances of the words "damn" and "hell" from the Coens' script, which only became known to Clooney after the directors pointed this out to him during shooting.

This was the fourth film of the brothers in which John Turturro has starred. Other actors in "O Brother, Where Art Thou?" who had worked previously with the Coens include John Goodman (three films), Holly Hunter (two), Charles Durning (two) and Michael Badalucco (one).

The Coens used digital color correction to give the film a sepia-tinted look. Joel stated this was because the actual set was "greener than Ireland". Cinematographer Roger Deakins stated, "Ethan and Joel favored a dry, dusty Delta look with golden sunsets. They wanted it to look like an old hand-tinted picture, with the intensity of colors dictated by the scene and natural skin tones that were all shades of the rainbow." Initially the crew tried to perform the color correction using a physical process, however after several tries with various chemical processes proved unsatisfactory, it became necessary to perform the process digitally.

This was the fifth film collaboration between the Coen Brothers and Deakins, and it was slated to be shot in Mississippi at a time of year when the foliage, grass, trees, and bushes would be a lush green. It was filmed near locations in Canton, Mississippi, and Florence, South Carolina, in the summer of 1999. After shooting tests, including film bipack and bleach bypass techniques, Deakins suggested digital mastering be used. Deakins spent 11 weeks fine-tuning the look, mainly targeting the greens, making them a burnt yellow and desaturating the overall image in the digital files. This made it the first feature film to be entirely color corrected by digital means, narrowly beating Nick Park's "Chicken Run".

"O Brother, Where Art Thou?" was the first time a digital intermediate was used on the entirety of a first-run Hollywood film that otherwise had very few visual effects. The work was done in Los Angeles by Cinesite using a Spirit DataCine for scanning at 2K resolution, a Pandora MegaDef to adjust the color, and a Kodak Lightning II recorder to put out to film.

A major theme of the film is the connection between old-time music and political campaigning in the Southern U.S. It makes reference to the traditions, institutions, and campaign practices of bossism and political reform that defined Southern politics in the first half of the 20th century.

The Ku Klux Klan, at the time a political force of white populism, is depicted burning crosses and engaging in ceremonial dance. The character Menelaus "Pappy" O'Daniel, the governor of Mississippi and host of the radio show "The Flour Hour", is similar in name and demeanor to W. Lee "Pappy" O'Daniel, one-time Governor of Texas and later U.S. Senator from that state. W. Lee O'Daniel was in the flour business, and used a backing band called the Light Crust Doughboys on his radio show. In one campaign, W. Lee O'Daniel carried a broom, an oft-used campaign device in the reform era, promising to sweep away patronage and corruption. His theme song had the hook, "Please pass the biscuits, Pappy", emphasizing his connection with flour.
While the film borrows from historical politics, differences are obvious between the characters in the film and historical political figures. The O'Daniel of the movie used "You Are My Sunshine" as his theme song (which was originally recorded by singer and Governor of Louisiana James Houston "Jimmie" Davis), and Homer Stokes, as the challenger to the incumbent O'Daniel, portrays himself as the "reform candidate", using a broom as a prop.

Music was originally conceived as a major component of the film, not merely as a background or a support. Producer and musician T Bone Burnett worked with the Coens while the script was still in its working phases and the soundtrack was recorded before filming commenced.

Much of the music used in the film is period-specific folk music, including that of Virginia bluegrass singer Ralph Stanley. The musical selection also includes religious music, including Primitive Baptist and traditional African American gospel, most notably the Fairfield Four, an "a cappella" quartet with a career extending back to 1921 who appear in the soundtrack and as gravediggers towards the film's end. Selected songs in the film reflect the possible spectrum of musical styles typical of the old culture of the American South: gospel, delta blues, country, swing and bluegrass.

The use of dirges and other macabre songs is a theme that often recurs in Appalachian music ("O Death", "Lonesome Valley", "Angel Band", "I Am Weary") in contrast to bright, cheerful songs ("Keep On the Sunny Side", "In the Highways") in other parts of the film.

The voices of the Soggy Bottom Boys were provided by Dan Tyminski (lead vocal on "Man of Constant Sorrow"), Nashville songwriter Harley Allen, and the Nashville Bluegrass Band's Pat Enright. The three won a CMA Award for Single of the Year and a Grammy Award for Best Country Collaboration with Vocals, both for the song "Man of Constant Sorrow". Tim Blake Nelson sang the lead vocal on "In the Jailhouse Now".

"Man of Constant Sorrow" has five variations: two are used in the film, one in the music video, and two in the soundtrack album. Two of the variations feature the verses being sung back-to-back, and the other three variations feature additional music between each verse. Though the song received little significant radio airplay, it reached #35 on the U.S. "Billboard" Hot Country Singles & Tracks chart in 2002. The version of "I'll Fly Away" heard in the film is performed not by Krauss and Welch (as it is on the CD and concert tour), but by the Kossoy Sisters with Erik Darling accompanying on long-neck five-string banjo, recorded in 1956 for the album "Bowling Green" on Tradition Records.

The film premiered at the AFI Film Festival on October 19, 2000. It grossed $71,868,327 worldwide off its $26 million budget.

Review aggregation website Rotten Tomatoes gives it a score of 77% based on 151 reviews and an average score of 7.12/10. The consensus reads: "Though not as good as Coen brothers' classics such as "Blood Simple", the delightfully loopy "O Brother, Where Art Thou?" is still a lot of fun." The film holds an average score of 69/100 on Metacritic based on 30 reviews.

Roger Ebert gave two and a half out of four stars to the film, saying all the scenes in the film were "wonderful in their different ways, and yet I left the movie uncertain and unsatisfied".

The film was selected into the main competition of the 2000 Cannes Film Festival.

The film also received two Academy Award nominations at the 73rd Academy Awards: Best Adapted Screenplay and Best Cinematography. Cinematographer Roger Deakins was recognized with both Academy Award and ASC Outstanding Achievement Award nominations for his work on the film.

For his portrayal of Ulysses Everett McGill, George Clooney received the Golden Globe Award for Best Actor – Motion Picture Musical or Comedy. The film was also nominated for the Golden Globe Award for Best Motion Picture – Musical or Comedy.

The Soggy Bottom Boys are the (fictional) musical group that the main characters form to serve as accompaniment for the film. The name is in homage to the Foggy Mountain Boys, a bluegrass band led by Lester Flatt and Earl Scruggs. In the film, the songs credited to the band are lip-synched by the actors, except that Tim Blake Nelson does sing his own vocals on "In the Jailhouse Now".

The band's hit single is Dick Burnett's "Man of Constant Sorrow", a song that had enjoyed much success prior to the movie's release. After the film's release, the fictitious band became so popular that the country and folk musicians who were dubbed into the film got together and performed the music from the film in a Down from the Mountain concert tour, which was filmed for TV and DVD. This included Ralph Stanley, John Hartford, Alison Krauss, Emmylou Harris, Gillian Welch, Chris Sharp, and others.



</doc>
<doc id="22217" url="https://en.wikipedia.org/wiki?curid=22217" title="Ohio State University">
Ohio State University

The Ohio State University (commonly Ohio State or OSU) is a public research university in Columbus, Ohio. Founded in 1870 as a land-grant university and the ninth university in Ohio with the Morrill Act of 1862, the university was originally known as the Ohio Agricultural and Mechanical College. The college originally focused on various agricultural and mechanical disciplines but it developed into a comprehensive university under the direction of then-Governor (later, U.S. president) Rutherford B. Hayes, and in 1878 the Ohio General Assembly passed a law changing the name to "The Ohio State University". The main campus in Columbus, Ohio, has since grown into the third-largest university campus in the United States. The university also operates regional campuses in Lima, Mansfield, Marion, Newark, and Wooster.

With nearly 50,000 undergraduate students and nearly 15,000 graduate students, Ohio State is one of the largest American universities. It has an extensive student life program, with over 1,000 student organizations; intercollegiate, club and recreational sports programs; student media organizations and publications, fraternities and sororities; and three student governments. Ohio State athletic teams compete in Division I of the NCAA and are known as the Ohio State Buckeyes. As of the 2016 Summer Olympics, athletes from Ohio State have won 104 Olympic medals (46 gold, 35 silver, and 23 bronze). The university is a member of the Big Ten Conference for the majority of sports.

The proposal of a manufacturing and agriculture university in central Ohio was initially met in the 1870s with hostility from the state's agricultural interests and competition for resources from Ohio University, which was chartered by the Northwest Ordinance, and Miami University. Championed by the Republican governor Rutherford B. Hayes, The Ohio State University was founded in 1870 as a land-grant university under the Morrill Act of 1862 as the Ohio Agricultural and Mechanical College. The school was originally within a farming community on the northern edge of Columbus. While some interests in the state had hoped the new university would focus on matriculating students of various agricultural and mechanical disciplines, Hayes manipulated both the university's location and its initial board of trustees towards a more comprehensive educational mission. The university opened its doors to 24 students on September 17, 1873. In 1878 the first class of six men graduated. The first woman graduated the following year.

Also in 1878, the Ohio legislature recognized an expanded scope for the university by changing its name to "The Ohio State University". The definite article "the" is part of Ohio State's legal name; since at least the 1990s, Ohio State alumni, especially NFL players, have emphasized the "The" when referring to their school (""The" Ohio State University"). In 2019 Ohio State filed for trademark protection of "the" when it is used to refer to Ohio State; the application was denied.

Ohio State began accepting graduate students in the 1880s, and in 1891, the school saw the founding of its law school, Moritz College of Law. It would later acquire colleges of medicine, dentistry, optometry, veterinary medicine, commerce, and journalism in subsequent years. In 1916 Ohio State was elected into membership in the Association of American Universities.

Michael V. Drake, former chancellor of the University of California, Irvine, became the 15th president of The Ohio State University on June 30, 2014. He announced on November 21, 2019 that he would be retiring at the end of the 2019–2020 academic year.

On June 3, 2020, the Ohio State Board of Trustees appointed Kristina M. Johnson, former chancellor of the State University of New York as the 16th president of The Ohio State University.

Ohio State's main campus is about north of the city's downtown. The historical center of campus is the Oval, a quad of about . Four buildings are listed on the National Register of Historic Places: Hale Hall (originally Enarson Hall), Hayes Hall, Ohio Stadium, and Orton Hall.
Unlike earlier public universities such as Ohio University and Miami University, whose campuses have a consistent architectural style, the Ohio State campus is a mix of traditional, modern and post-modern styles.
The William Oxley Thompson Memorial Library, anchoring the Oval's western end, is Ohio State library's main branch and largest repository. The Thompson Library was designed in 1913 by the Boston firm of Allen and Collens in the Italianate Renaissance Revival style, and its placement on the Oval was suggested by the Olmsted Brothers who had designed New York City's Central Park. In 2006 the Thompson Library began a $100-million renovation to maintain the building's classical Italian Renaissance architecture.

Ohio State operates the North America's 18th-largest university research library with a combined collection of over 5.8 million volumes. Additionally, the libraries regularly receive about 35,000 serial titles. Its recent acquisitions were 16th among university research libraries in North America. Along with 21 libraries on its Columbus campus, the university has eight branches at off-campus research facilities and regional campuses, and a book storage depository near campus. In all, the Ohio State library system encompasses 55 branches and specialty collections. Some more significant collections include the Byrd Polar Research Center Archival Program, which has the archives of Admiral Richard E. Byrd and other polar research materials; the Hilandar Research Library, which has the world's largest collection of medieval Slavic manuscripts on microform; the Ohio State Cartoon Library & Museum, the world's largest repository of original cartoons; the Lawrence and Lee Theatre Research Institute; and the archives of Senator John Glenn.

Anchoring the traditional campus gateway at the eastern end of the Oval is the 1989 Wexner Center for the Arts. Designed by architects Peter Eisenman of New York and Richard Trott of Columbus, the center was funded in large part by Ohio State alumnus Leslie Wexner's gift of $25 million in the 1980s. The center was founded to encompass all aspects of visual and performing arts with a focus on new commissions and artist residencies. Part of its design was to pay tribute to the armory that formerly had the same location. Its groundbreaking deconstructivist architecture has resulted in it being lauded as one of the most important buildings of its generation. Its design has also been criticized as proving less than ideal for many of the art installations it has attempted to display. The centerpiece of the Wexner Center's permanent collection is Picasso's "Nude on a Black Armchair", which was purchased by alumnus Leslie Wexner at auction for $45 million.

To the south of the Oval is another, somewhat smaller, expanse of green space commonly referred to as the South Oval. At its eastern end, it is anchored by the Ohio Union. To the west are Hale Hall, the Kuhn Honors House, Browning Amphitheatre (a traditional stone Greek theatre) and Mirror Lake.

Knowlton Hall, dedicated in October 2004, is at the corner of West Woodruff Avenue and Tuttle Park Place, next to Ohio Stadium. Knowlton Hall along with the Fisher College of Business and Hitchcock Hall form an academic nucleus in the Northwestern corner of North campus. Knowlton Hall was designed by Mac Scogin Merril Elam from Atlanta along with WSA Studio from Columbus, Ohio, and is home to the KSA Café, the disciplines of Architecture, Landscape Architecture, City and Regional Planning, and about 550 undergraduate and graduate students. Knowlton Hall stands out from the general reddish-brown brick of Ohio State's campus with distinctive white marble tiles that cover the building's exterior. This unique wall cladding was requested by Austin E. Knowlton, the namesake of and main patron to the creation of Knowlton Hall. Knowlton also requested 5 white marble columns be erected on the site, each column representing one of the classical orders of Architecture.

The Ohio State College of Medicine is on the southern edge of the central campus. It is home to the James Cancer Hospital, a cancer research institute and one of the National Cancer Institute's forty-one comprehensive cancer centers, along with the Richard M. Ross Heart Hospital, a research institute for cardiovascular disease.

In 1916 Ohio State became the first university in Ohio to be extended membership into the Association of American Universities, and remains the only public university in Ohio among the organization's 60 members. "The Public Ivies: America's Flagship Public Universities" (2000) by Howard and Matthew Greene listed Ohio State as one of a select number of public universities offering the highest educational quality.
In its 2019 edition, "U.S. News & World Report" ranked Ohio State as tied for the 17th-best public university in the United States, and tied for 56th among all national universities.

The "Academic Ranking of World Universities" placed Ohio State 42nd nationally and 79th globally for 2016. In its 2015-16 rankings, "Times Higher Education World University Rankings" ranked it tied for 90th in the world. In 2016 "QS World University Rankings" ranked the university 88th in the world.

The "Washington Monthly" college rankings, which seek to evaluate colleges' contributions to American society based on factors of social mobility, research, and service to the country by their graduates, in 2018 placed Ohio State 105th among national universities.

Ohio State is also the only public university in Ohio to be classified among "R1: Doctoral Universities – Highest Research Activity" and have its undergraduate admissions classified as "more selective".

"Bloomberg Businessweek" ranked the undergraduate business program at Ohio State's Fisher College of Business as the 14th best in the nation in its 2016 rankings. "U.S. News & World Report" ranks the MBA program tied for 30th in America. Fisher's Executive MBA program was ranked 3rd nationally for return on investment by The Wall Street Journal in 2008 citing a 170 percent return on an average of $66,900 invested in tuition and expenses during the 18-month program.

The Ohio State linguistics department was recently ranked among the top 10 programs nationally, and top 20 internationally by "QS World University Rankings".

The Ohio State University is among the top 12 U.S. public research universities and 3rd among all universities in industry-sponsored research (National Science Foundation).

Research facilities include Aeronautical/Astronautical Research Laboratory, Byrd Polar Research Center, Center for Automotive Research (OSU CAR), Chadwick Arboretum, Biomedical Research Tower, Biological Sciences Building, CDME, Comprehensive Cancer Center, David Heart and Lung Research Institute, Electroscience Laboratory, Large Binocular Telescope ("LBT", originally named the Columbus Project), Mershon Center for International Security Studies, Museum of Biological Diversity, National Center for the Middle Market, Stone Laboratory on Gibraltar Island, OH, Center for Urban and Regional Analysis and Ohio Agricultural Research and Development Center.

Undergraduate admissions to Ohio State are classified as "more selective" by "U.S. News & World Report" and "The Princeton Review" and according to the data are the most selective for any public university in Ohio. 67% of incoming freshmen in autumn 2017 were ranked in the top 10% of their high school class. The average GPA at Ohio State is 3.81, the middle 50% range of ACT scores is 27-31 (average 29), while the middle 50% SAT scores (critical reading and math only) is 1260–1450 (average 1344) Ohio State's freshman class has included at least 100 National Merit Scholars for nine of the last ten years.

Tuition and fees for full-time, Ohio residents enrolled at the Columbus campus for the 2014–2015 academic year were $10,037. For the 2006–2007 academic year, tuition at Ohio State for Ohio residents placed it as the fifth-most expensive public university and slightly beneath the weighted average tuition of $8,553 among Ohio's thirteen public four-year universities.

Ohio State was among the first group of four public universities to raise a $1 billion endowment when it passed the $1 billion mark in 1999. At the end of 2005, Ohio State's endowment stood at $1.73 billion, ranking it seventh among public universities and 27th among all American universities. In June 2006, the endowment passed the $2 billion mark.

In recent decades, and in response to continually shrinking state funding, Ohio State has conducted two significant multi-year fundraising campaigns. The first concluded in 1987 and raised $460 million—a record at the time for a public university. The "Affirm Thy Friendship Campaign" took place between 1995 and 2000. With an initial goal of raising $850 million, the campaign's final tally was $1.23 billion, placing Ohio State among the small group of public universities to have successfully conducted a $1 billion campaign. At his welcoming ceremony, returning President E. Gordon Gee announced, in the Fall of 2007, Ohio State would launch a $2.5 billion fund-raising campaign. In 2019, celebrating the university's 150th year, President Michael V. Drake announced the "Time and Change Campaign" with a goal of raising $4.5 billion from 1 million individual donors.

The Office of Student Life has partnership affiliations with the Schottenstein Center, the Blackwell Inn, and the Drake Events Center. Services supporting student wellness include the Wilce Student Health Center, named for university physician John Wilce, the Mary A. Daniels Student Wellness Center and the Counseling and Consultation Service.

The RPAC is the main recreational facility on campus. The Wellness Center within the RPAC offers services such as nutrition counseling, financial coaching, HIV and STI testing, sexual assault services, and alcohol and other drug education.

Ohio State's "Buckeye Bullet" electric car broke the world record for the fastest speed by an electric vehicle on October 3, 2004, with a speed of 271.737 mph (437.3 km/h) at the Bonneville Salt Flats in Utah. The vehicle also holds the U.S. record for fastest electric vehicle with a speed of 314.958 mph (506.9 km/h), and peak timed mile speed of 321.834 mph (517.9 km/h). A team of engineering students from the university's "Center for Automotive Research-Intelligent Transportation" (CAR-IT) designed, built and managed the vehicle. In 2007 Buckeye Bullet 2 was launched. This follow-up effort was a collaboration between Ohio State engineering students and engineers from the Ford Motor Company and will seek to break the land speed record for hydrogen cell powered vehicles.

In June 2018, Ohio State dissolved its Sexual Civility and Empowerment unit and eliminated four positions in the unit due to concerns about mismanagement and a lack of support for survivors of sexual assault. This occurred after the unit was suspended in February 2018 and following an external review. "The Columbus Dispatch" and the school newspaper, "The Lantern" reported that "[SCE] failed to properly report students' sexual-assault complaints" and that some victims were told that they were lying', 'delusional', 'suffering from mental illness', 'have an active imagination', that they 'didn't understand their own experience' and also 'fabricated their story'." With help from the Philadelphia law firm Cozen O'Connor, the university will be creating a new framework to handle sexual assault cases and reevaluating its Title IX program.

On July 20, 2018, "BBC News" reported that over 100 male students, including athletes from 14 sports, had reported sexual misconduct by a deceased university team physician, Richard Strauss. The reports dated back to 1978 and included claims that he groped and took nude photographs of his patients. Four former wrestlers filed a lawsuit against Ohio State for ignoring complaints of "rampant sexual misconduct" by Strauss. U.S. representative Jim Jordan was named in the lawsuit and has since denied the former wrestlers' claims that he knew about the abuse while he was an assistant coach for eight years at the university. In May 2020, the university entered into a settlement and agreed to pay $40.9 million to the sexual abuse survivors.

"The Advocate College Guide for LGBT Students" lists Ohio State as one of the 20 best campuses in America for LGBT students.

The Morrill Scholarship Program (MSP) is Ohio State's premier diversity/merit scholarship program, rewarding academically talented students who are actively engaged in diversity-based leadership, service and social justice activities. MSP seeks academically talented high school seniors who will contribute to campus diversity actively engage as advocates, and champions of diversity, inclusion, social justice and academic excellence on campus. There are three scholarship levels: prominence, excellence, and distinction.

The graduation rate of black males at The Ohio State University is higher than that of other Big Ten Schools. For the men who participate in the early arrival programs, like the Bell National Resource Center's Early Arrival Program, the freshman to sophomore retention rate is higher than that of the entire university with 95% matriculating to their second year.

Ohio State operates 41 on-campus residence halls divided into three geographic clusters: South Campus (site of the university's original dormitories), North Campus (largely constructed during the post-war enrollment boom), and West Campus ("The Towers"). The residence hall system has 40 smaller living and learning environments defined by social or academic considerations.

Separate housing for graduate and professional students is maintained on the Southern tier of campus within the Gateway Residential Complex and the William H. Hall Student Residential Complex. Family housing is maintained at Buckeye Village at the far northern edge of campus beyond the athletic complex.

Student Life University Housing also administers student residential housing on the OSU Newark, OSU Mansfield, and OSU Agricultural Technical Institute (ATI) campuses.

The Residence Hall Advisory Council (RHAC), which is a representative body of all students living in the University's residence halls, helps evaluate and improve the living conditions of the residence halls.

Ohio State offers two distinct honors programs for high ability undergraduates: Honors and Scholars. The Honors program is open to students in all majors. The Scholars program is centered on thirteen specific programs such as "Architecture Scholars", "Media, Marketing, and Communications Scholars", "Biological Sciences Scholars", "International Affairs Scholars", "Business Scholars" and "Politics, Society and Law Scholars." Students in the Scholars program are expected to live and take select classes with other members of the program. Additionally, Ohio State offers the Honors Collegium with membership extended to ten incoming freshmen and following the Spring of a student's first or second year to the university's top undergraduates. Collegium students try to compete for internships, graduate schools and nationally competitive awards, such as the Marshall, Rhodes, or Truman Scholarships.

Ohio State also administers two large-scale scholarship programs to ensure access to the university to high-ability students from low-income or traditionally underrepresented groups. The first, the Young Scholars Program, was initiated in 1988. 120 promising minority students from Ohio's nine largest urban public school districts are selected prior to entering high school. The program offers a series of academic camps each summer and counseling throughout the students' high school careers. Upon completion of the program, which also mandates a college preparatory curriculum and minimum grade point average, the students are guaranteed admission to Ohio State as well as any need-based financial aid. The Land Grant Scholarship was initiated in 2005. This program seeks to ensure access to Ohio State to high-ability students from low-income backgrounds. Ohio State has committed to offering a full-ride scholarship each academic year to at least one student from each of Ohio's 88 counties.

Ohio State maintains an honors center in the Kuhn Honors & Scholars House, which served as the university president's residence until 1972. Three residence halls are designated all or in part as honors residences: Bradley Hall, Lincoln Tower, and Taylor Tower.

Ohio State is rated at the #3 most amazing student union (Best College Reviews). The Ohio Union was the first student union built by an American public university. The Ohio Union is dedicated to the enrichment of the student experience, on and off the university campus. The first Ohio Union, on the south edge of the South Oval, was constructed in 1909 and was later renamed Enarson Hall. The second Ohio Union was completed in 1950 and was prominently along High Street, southeast of the Oval. It was a center of student life for more than 50 years, providing facilities for student activities, organizations and events and serving as an important meeting place for campus and community interaction. The union also housed many student services and programs, along with dining and recreational facilities. The second Ohio Union was demolished in February 2007 to make way for the new Ohio Union, which was finished in 2010. During this time, student activities were relocated to Ohio Stadium and other academic buildings.

Student organizations at Ohio State provide students with opportunities to get involved in a wide variety of interest areas including academic, social, religious, artistic, service-based, diversity and many more.
There are over 1,000 registered student organizations that involve many thousands of students. The university's forensics team has won the state National Forensics Association tournament several times.

Block "O" is currently the largest student-run organization on the campus of Ohio State. With over 2,400 annual members, Block "O" serves as the official student cheering section at athletic events for the University. According to the Student Organization Office in the Ohio Union, Agricultural Education Society is the oldest student organization on campus. The Men's Glee Club often disputes the claim, but after consultation with Ohio Union Staff, Agricultural Education Society was named as the university's oldest organization.

Each year, students may sign-up to participate in BuckeyeThon, Ohio State's student-led philanthropy. The organization hosts events throughout the year to support the hematology/oncology/bone marrow transplant unit at Nationwide Children's Hospital in Columbus, Ohio. Although BuckeyeThon is operated entirely by student volunteers, it is embedded within Student Life and The Ohio State University Foundation. The organization receives support, advising, and specialized leadership training from the university. Each February, thousands of students and community members attend BuckeyeThon's signature event, a Dance Marathon consisting of two separate 12-hour shifts. In the past 15 years, students have raised over $5 million to support treatment, research, and various therapies at the hospital. Unique to BuckeyeThon is the use of an operational fund separate from the main philanthropic cancer fund. As a registered non-profit, BuckeyeThon is subject to university audit and issues gift receipts through the Foundation. An annual operational fund relies on university grants, outside sponsors, and event registration fees. This allows the entirety of donations made to the cancer fund to solely support patients without hindrance from outside costs.

Ohio State has several student-managed publications and media outlets. "The Makio" is the official yearbook. "The Makio's" sales plummeted by 60% during the early 1970s; the organization went bankrupt and stopped publication during the late 1970s. The book was revived from 1985 to 1994 and revived again in 2000 thanks to several student organizations. "The Lantern" is the school's daily newspaper and has operated as a laboratory newspaper in the School of Communication (formerly the School of Journalism) since 1881. "Mosaic" is a literary magazine published by Ohio State, which features undergraduate fiction, poetry, and art. "The Sundial" is a student-written and published humor magazine. Founded in 1911, it is one of the oldest humor magazines in the country. After a 17-year hiatus in which no magazine was published it has recently been revived, first in print form, and now in an online humor blog, as well as multiple social media outlets. Ohio State has two improvisational comedy groups, "The 8th Floor Improv" and "Fishbowl Improv", who regularly perform long and short-form improv around campus and across the U.S. There are two student-run radio stations on campus. AROUSE, the music station, is home to over 100 student DJs, streaming music and independent content. Scarlet and Gray Sports Radio broadcasts eleven different Ohio State sports. Both stations broadcast on an Internet audio stream (no broadcast signals are available in Columbus). Students also operate a local cable TV channel known as Buckeye TV, which airs primarily on the campus closed cable system operated by the Office of the Chief Information Officer (OCIO).

At The Ohio State University, three recognized student governments represent their constituents.

Ohio State's intercollegiate sports teams are called the "Buckeyes" (derived from the colloquial term for people from the state of Ohio and after the state tree, the Ohio Buckeye, "Aesculus glabra"), and participate in the NCAA's Division I in all sports (Division I FBS in football) and the Big Ten Conference in most sports. (The women's hockey program competes in the Western Collegiate Hockey Association). The school colors are scarlet and gray. Brutus Buckeye is the mascot. Ohio State currently has 36 varsity teams.

Ohio State is one of six universities (the University of Michigan, the University of Florida, Stanford University, UCLA, and the University of California at Berkeley being the others) to have won national championships in all three major men's sports (baseball, men's basketball, and football). Ohio State is also one of only two universities to appear in the national championship games in both football and men's basketball in the same calendar year (the other university is the University of Florida.) Ohio State has also won national championships in wrestling, men's volleyball, men's swimming and diving, men's outdoor track & field, men's golf, men's gymnastics, men's fencing, women's rowing, co-ed fencing, and multiple synchronized swimming championships. The Ohio State equestrian team has won eight Intercollegiate Horse Show Association national championships. Since the inception of the Athletic Director's Cup, Ohio State has finished in the top 25 each year, including top-six finishes in three of the last five years. During the 2005–2006 school year Ohio State became the first Big Ten team to win conference championships in football, men's basketball, and women's basketball. Ohio State repeated the feat during the 2006–2007 school year, winning solo championships in all three sports. In 2007 "Sports Illustrated" nicknamed Ohio State's athletic program as being "The Program" due to the unsurpassed facilities, an unparalleled number of men's and women's sports teams, their success, and the financial support of an impressive fan base.

Outstanding sports figures that were student athletes at Ohio State include 1936 Olympics gold medalist Jesse Owens "the Buckeye Bullet" (track and field), John Havlicek, Jerry Lucas, Bobby Knight, and Larry Siegfried (basketball), 2010 Olympics silver medalist Ryan Kesler (ice hockey), Katie Smith and the first three-time player of the year in Big Ten Basketball history Jessica Davenport (women's basketball), Frank Howard (basketball and baseball), Jack Nicklaus (golf); and Chic Harley (three-time All-American football running back). Ohio State football players have combined for seven Heisman Awards including the only two-time winner Archie Griffin in 1974 and 1975, Eddie George in 1995, and most recently Troy Smith in 2006. Hall of Fame coaches at Ohio State have included Paul Brown, Woody Hayes, and Jim Tressel in football, Fred Taylor in basketball, Larry Snyder in track and field, and Mike Peppe in swimming and diving. Hall of fame players, in pro-football, include Sid Gillman, Lou Groza, Dante Lavelli, Jim Parker, Paul Warfield, Dick LeBeau, and Bill Willis.

The marching band has also a longstanding tradition at Ohio State. The band is famous for "Script Ohio", during which the band marches single-file through the curves of the word "Ohio", much like a pen writes the word, all while playing the French march "Le Regiment de Sambre et Meuse".

"Across the Field", Ohio State's fight song, and "Buckeye Battle Cry" are commonly played and sung at athletic events, as well as commencement and convocation exercises.

Ohio State operates a public television station, WOSU-TV (virtual channel 34/DT 16, a local PBS TV station), as well as two public radio stations, WOSU-FM 89.7(NPR/BBC news/talk) and WOSA-FM 101.1 (classical, "Classical 101") in Columbus.

Ohio State's faculty currently includes 21 members of the National Academy of Sciences or National Academy of Engineering, four members of the Institute of Medicine, and 177 elected fellows of the American Association for the Advancement of Science. In 2009, 17 Ohio State faculty were elected as AAAS Fellows. Each year since 2002, Ohio State has either led or been second among all American universities in the number of their faculty elected as fellows to the AAAS.

In surveys conducted in 2005 and 2006 by the Collaborative on Academic Careers in Higher Education (COACHE), Ohio State was rated as "exemplary" in four of the seven measured aspects of workplace satisfaction for junior faculty at 31 universities: overall tenure practices, policy effectiveness, compensation, and work-family balance.

In the last quarter century, 32 Ohio State faculty members have received the Guggenheim Fellowship, more than all other public and private Ohio universities combined. In 2008 three Ohio State faculty were awarded Guggenheim Fellowships, placing Ohio State among the top 15 universities in the United States. Since the 2000–2001 award year, 55 Ohio State faculty members have been named as Fulbright Fellows, the most of any Ohio university.

Ohio State has over 475,000 living alumni around the world. Ohio State alumni include Nobel Prize recipients, Pulitzer Prize recipients, Olympic Games gold medalists, UFC champions, and Medal of Honor recipients, ambassadors, as well as Fortune 500 CEOs and members of the Forbes 400 list of the world's wealthiest individuals. Numerous graduates have gone on to become U.S. governors, senators and members of Congress. Ohio State alumni have appeared on the cover of "Time" magazine twelve times, with the artwork of alumnus Roy Lichtenstein featured on an additional two "Time" covers. George Steinbrenner, former owner of the New York Yankees who won seven World Series with the team, earned his master's degree from Ohio State. Larry Sanger, one of the founders of Wikipedia, and Steve May, chief technology officer at Pixar, both graduated from Ohio State. Roboticist James S. Albus was named a "Hero of US Manufacturing" by "Fortune Magazine" in 1997.

Ohio State alumni have been inducted into the Baseball Hall of Fame in Cooperstown, New York, the NFL Hall of Fame and the Basketball Hall of Fame. Its athletes have won a combined eighty-three Olympic medals and three times have received the Sullivan Award as the nation's top amateur athlete.



</doc>
<doc id="22218" url="https://en.wikipedia.org/wiki?curid=22218" title="Ontario">
Ontario

Ontario is one of the thirteen provinces and territories of Canada. Located in Central Canada, it is Canada's most populous province, with 38.3 percent of the country's population, and is the second-largest province in total area. Ontario is the fourth-largest jurisdiction in total area when the territories of the Northwest Territories and Nunavut are included. It is home to the nation's capital city, Ottawa, and the nation's most populous city, Toronto, which is also Ontario's provincial capital.

Ontario is bordered by the province of Manitoba to the west, Hudson Bay and James Bay to the north, and Quebec to the east and northeast, and to the south by the U.S. states of (from west to east) Minnesota, Michigan, Ohio, Pennsylvania, and New York. Almost all of Ontario's border with the United States follows inland waterways: from the westerly Lake of the Woods, eastward along the major rivers and lakes of the Great Lakes/Saint Lawrence River drainage system. These include Rainy River, Pigeon River, Lake Superior, St. Marys River, Lake Huron, St. Clair River, Lake St. Clair, Detroit River, Lake Erie, Niagara River, Lake Ontario and the St. Lawrence River from Kingston, to the Quebec boundary just east of Cornwall. There is only about of land border, made up of portages including Height of Land Portage on the Minnesota border.

Ontario is sometimes conceptually divided into two regions, Northern Ontario and Southern Ontario. The great majority of Ontario's population and arable land is in the south. In contrast, the larger, northern part of Ontario is sparsely populated with cold winters and heavy forestation.

The province is named after Lake Ontario, a term thought to be derived from ', a Huron (Wyandot) word meaning "great lake", or possibly ', which means "beautiful water" in the Iroquoian languages. Ontario has about 250,000 freshwater lakes.

The province consists of three main geographical regions:

Despite the absence of any mountainous terrain in the province, there are large areas of uplands, particularly within the Canadian Shield which traverses the province from northwest to southeast and also above the Niagara Escarpment which crosses the south. The highest point is Ishpatina Ridge at above sea level in Temagami, Northeastern Ontario. In the south, elevations of over are surpassed near Collingwood, above the Blue Mountains in the Dundalk Highlands and in hilltops near the Madawaska River in Renfrew County.

The Carolinian forest zone covers most of the southwestern region of the province. The temperate and fertile Great Lakes-Saint Lawrence Valley in the south is part of the Eastern Great Lakes lowland forests ecoregion where the forest has now been largely replaced by agriculture, industrial and urban development. A well-known geographic feature is Niagara Falls, part of the Niagara Escarpment. The Saint Lawrence Seaway allows navigation to and from the Atlantic Ocean as far inland as Thunder Bay in Northwestern Ontario. Northern Ontario covers approximately 87% of the province's surface area; conversely Southern Ontario contains 94% of the population.

Point Pelee is a peninsula of Lake Erie in southwestern Ontario (near Windsor and Detroit, Michigan) that is the southernmost extent of Canada's mainland. Pelee Island and Middle Island in Lake Erie extend slightly farther. All are south of 42°N – slightly farther south than the northern border of California.

Ontario's climate varies by season and location. Three air sources affect it: cold, dry, arctic air from the north (dominant factor during the winter months, and for a longer part of the year in far northern Ontario); Pacific polar air crossing in from the western Canadian Prairies/US Northern Plains; and warm, moist air from the Gulf of Mexico and the Atlantic Ocean. The effects of these major air masses on temperature and precipitation depend mainly on latitude, proximity to major bodies of water and to a small extent, terrain relief. In general, most of Ontario's climate is classified as humid continental.

Ontario has three main climatic regions:


In the northeastern parts of Ontario, extending south as far as Kirkland Lake, the cold waters of Hudson Bay depress summer temperatures, making it cooler than other locations at similar latitudes. The same is true on the northern shore of Lake Superior, which cools hot humid air from the south, leading to cooler summer temperatures. Along the eastern shores of Lake Superior and Lake Huron winter temperatures are slightly moderated but come with frequent heavy lake-effect snow squalls that increase seasonal snowfall totals to upwards of in some places. These regions have higher annual precipitation, in some places over .


Severe thunderstorms peak in summer. Windsor, in Southern (Southwestern) Ontario, has the most lightning strikes per year in Canada, averaging 33 days of thunderstorm activity per year. In a typical year, Ontario averages 11 confirmed tornado touchdowns. However, over the last 4 years, it has had upwards of 20 tornado touchdowns per year, with the highest frequency in the Windsor-Essex – Chatham Kent area, though few are very destructive (the majority between F0 to F2 on the Fujita scale). Ontario had a record 29 tornadoes in both 2006 and 2009. Tropical depression remnants occasionally bring heavy rains and winds in the south, but are rarely deadly. A notable exception was Hurricane Hazel which struck Southern Ontario centred on Toronto, in October 1954.

Prior to the arrival of the Europeans, the region was inhabited by Algonquian (Ojibwe, Cree and Algonquin) in the northern/western portions, and Iroquois and Wyandot (Huron) people more in the south/east. During the 17th century, the Algonquians and Hurons fought the Beaver Wars against the Iroquois.

The French explorer Étienne Brûlé explored part of the area in 1610–12. The English explorer Henry Hudson sailed into Hudson Bay in 1611 and claimed the area for England.

Samuel de Champlain reached Lake Huron in 1615, and French missionaries began to establish posts along the Great Lakes. French settlement was hampered by their hostilities with the Iroquois, who allied themselves with the British. From 1634 to 1640, Hurons were devastated by European infectious diseases, such as measles and smallpox, to which they had no immunity. By 1700, the Iroquois had seceded from Ontario and the Mississaugas of the Ojibwa had settled the north shore of Lake Ontario. The remaining Huron settled north of Quebec.

The British established trading posts on Hudson Bay in the late 17th century and began a struggle for domination of Ontario with the French. After the French of New France were defeated during the Seven Years' War, the two powers awarded nearly all of France's North American possessions (New France) to Britain in the 1763 Treaty of Paris, including those lands of Ontario not already claimed by Britain. The British annexed the Ontario region to Quebec in 1774. 

The first European settlements were in 1782–1784 when 5,000 American loyalists entered what is now Ontario following the American Revolution. The Kingdom of Great Britain granted them land and other items with which to rebuild their lives. The British also set up reserves in Ontario for the Mohawks who had fought for the British and had lost their land in New York state. Other Iroquois, also displaced from New York were resettled in 1784 at the Six Nations reserve at the west end of Lake Ontario. The Mississaugas, displaced by European settlements, would later move to Six Nations also.

The population of Canada west of the St. Lawrence-Ottawa River confluence substantially increased during this period, a fact recognized by the "Constitutional Act" of 1791, which split Quebec into the Canadas: Upper Canada southwest of the St. Lawrence-Ottawa River confluence, and Lower Canada east of it. John Graves Simcoe was appointed Upper Canada's first Lieutenant governor in 1793.

American troops in the War of 1812 invaded Upper Canada across the Niagara River and the Detroit River, but were defeated and pushed back by the British, Canadian fencibles and militias, and First Nations warriors. However, the Americans eventually gained control of Lake Erie and Lake Ontario. The 1813 Battle of York saw American troops defeat the garrison at the Upper Canada capital of York. The Americans looted the town and burned the Upper Canada Parliament Buildings during their brief occupation. The British would burn the American capital of Washington, D.C. in 1814.

After the War of 1812, relative stability allowed for increasing numbers of immigrants to arrive from Europe rather than from the United States. As was the case in the previous decades, this immigration shift was encouraged by the colonial leaders. Despite affordable and often free land, many arriving newcomers, mostly from Britain and Ireland, found frontier life with the harsh climate difficult, and some of those with the means eventually returned home or went south. However, population growth far exceeded emigration in the following decades. It was a mostly agrarian-based society, but canal projects and a new network of plank roads spurred greater trade within the colony and with the United States, thereby improving previously damaged relations over time.

Meanwhile, Ontario's numerous waterways aided travel and transportation into the interior and supplied water power for development. As the population increased, so did the industries and transportation networks, which in turn led to further development. By the end of the century, Ontario vied with Quebec as the nation's leader in terms of growth in population, industry, arts and communications.

Unrest in the colony began to chafe against the aristocratic Family Compact who governed while benefiting economically from the region's resources, and who did not allow elected bodies power. This resentment spurred republican ideals and sowed the seeds for early Canadian nationalism. Accordingly, rebellion in favour of responsible government rose in both regions; Louis-Joseph Papineau led the Lower Canada Rebellion and William Lyon Mackenzie, first Toronto mayor, led the Upper Canada Rebellion. In Upper Canada, the rebellion was quickly a failure. William Lyon Mackenzie escaped to the United States, where he declared the Republic of Canada on Navy Island on the Niagara River.

Although both rebellions were put down in short order, the British government sent Lord Durham to investigate the causes. He recommended self-government be granted and Lower and Upper Canada be re-joined in an attempt to assimilate the French Canadians. Accordingly, the two colonies were merged into the Province of Canada by the "Act of Union 1840", with the capital at Kingston, and Upper Canada becoming known as Canada West. Parliamentary self-government was granted in 1848. There were heavy waves of immigration in the 1840s, and the population of Canada West more than doubled by 1851 over the previous decade. As a result, for the first time, the English-speaking population of Canada West surpassed the French-speaking population of Canada East, tilting the representative balance of power.

An economic boom in the 1850s coincided with railway expansion across the province, further increasing the economic strength of Central Canada. With the repeal of the Corn Laws and a reciprocity agreement in place with the United States, various industries such as timber, mining, farming and alcohol distilling benefited tremendously.

A political stalemate between the French- and English-speaking legislators, as well as fear of aggression from the United States during and immediately after the American Civil War, led the political elite to hold a series of conferences in the 1860s to effect a broader federal union of all British North American colonies. The "British North America Act" took effect on July 1, 1867, establishing the Dominion of Canada, initially with four provinces: Nova Scotia, New Brunswick, Quebec and Ontario. The Province of Canada was divided into Ontario and Quebec so that each linguistic group would have its own province. Both Quebec and Ontario were required by section 93 of the "British North America Act" to safeguard existing educational rights and privileges of Protestant and the Catholic minority. Thus, separate Catholic schools and school boards were permitted in Ontario. However, neither province had a constitutional requirement to protect its French- or English-speaking minority. Toronto was formally established as Ontario's provincial capital.

Once constituted as a province, Ontario proceeded to assert its economic and legislative power. In 1872, the lawyer Oliver Mowat became Premier of Ontario and remained as premier until 1896. He fought for provincial rights, weakening the power of the federal government in provincial matters, usually through well-argued appeals to the Judicial Committee of the Privy Council. His battles with the federal government greatly decentralized Canada, giving the provinces far more power than John A. Macdonald had intended. He consolidated and expanded Ontario's educational and provincial institutions, created districts in Northern Ontario, and fought to ensure that those parts of Northwestern Ontario not historically part of Upper Canada (the vast areas north and west of the Lake Superior-Hudson Bay watershed, known as the District of Keewatin) would become part of Ontario, a victory embodied in the "Canada (Ontario Boundary) Act, 1889". He also presided over the emergence of the province into the economic powerhouse of Canada. Mowat was the creator of what is often called "Empire Ontario".

Beginning with Sir John A. Macdonald's National Policy (1879) and the construction of the Canadian Pacific Railway (1875–1885) through Northern Ontario and the Canadian Prairies to British Columbia, Ontario manufacturing and industry flourished. However, population increase slowed after a large recession hit the province in 1893, thus slowing growth drastically but for only a few years. Many newly arrived immigrants and others moved west along the railway to the Prairie Provinces and British Columbia, sparsely settling Northern Ontario.

Mineral exploitation accelerated in the late 19th century, leading to the rise of important mining centres in the northeast, such as Sudbury, Cobalt and Timmins. The province harnessed its water power to generate hydro-electric power and created the state-controlled Hydro-Electric Power Commission of Ontario, later Ontario Hydro. The availability of cheap electric power further facilitated the development of industry. The Ford Motor Company of Canada was established in 1904 and the McLaughlin Motor Car Company (later General Motors Canada) was founded in 1907. The motor vehicle industry became the most lucrative industry for the Ontario economy during the 20th century.

In July 1912, the Conservative government of Sir James Whitney issued Regulation 17 which severely limited the availability of French-language schooling to the province's French-speaking minority. French Canadians reacted with outrage, journalist Henri Bourassa denouncing the "Prussians of Ontario". The regulation was eventually repealed in 1927.

Influenced by events in the United States, the government of Sir William Hearst introduced prohibition of alcoholic drinks in 1916 with the passing of the "Ontario Temperance Act". However, residents could distil and retain their own personal supply, and liquor producers could continue distillation and export for sale, allowing this already sizeable industry to strengthen further. Ontario became a hotbed for the illegal smuggling of liquor and the biggest supplier into the United States, which was under complete prohibition. Prohibition in Ontario came to an end in 1927 with the establishment of the Liquor Control Board of Ontario under the government of Howard Ferguson. The sale and consumption of liquor, wine, and beer are still controlled by some of the most extreme laws in North America to ensure strict community standards and revenue generation from the alcohol retail monopoly are upheld.

The post-World War II period was one of exceptional prosperity and growth. Ontario has been the recipients of most immigration to Canada, largely immigrants from war-torn Europe in the 1950s and 1960s and following changes in federal immigration law, a massive influx of non-Europeans since the 1970s. From a largely ethnically British province, Ontario has rapidly become culturally very diverse.

The nationalist movement in Quebec, particularly after the election of the "Parti Québécois" in 1976, contributed to driving many businesses and English-speaking people out of Quebec to Ontario, and as a result, Toronto surpassed Montreal as the largest city and economic centre of Canada. Depressed economic conditions in the Maritime Provinces have also resulted in de-population of those provinces in the 20th century, with heavy migration into Ontario.

Ontario's official language is English, although there exists a number of French-speaking communities across Ontario. French-language services are made available for communities with a sizeable French-speaking population; a service that is ensured under the "French Language Services Act" of 1989.

Until 1763, most of Ontario was considered part of New France by French claim. Rupert's Land, defined as the drainage basin of Hudson Bay, was claimed by Britain, and included much of today's Northern Ontario. The British defeated the armies of the French colony and its indigenous allies in the French and Indian War, part of the Seven Years' War global conflict. Concluding the war, the peace treaty between the European powers, known as the Treaty of Paris 1763, assigned almost all of France's possessions in North America to Britain, including parts that would later become Ontario not already part of Rupert's Land. Britain established the first Province of Quebec, encompassing contemporary Quebec and southern Ontario.

After the American War of Independence, the first reserves for First Nations were established. These are situated at Six Nations (1784), Tyendinaga (1793) and Akwesasne (1795). Six Nations and Tyendinaga were established by the British for those indigenous groups who had fought on the side of the British, and were expelled from the new United States. Akwesasne was a pre-existing Mohawk community and its borders were formalized under the 1795 Jay Treaty.

In 1788, while part of the Province of Quebec, southern Ontario was divided into four districts: Hesse, Lunenburg, Mecklenburg, and Nassau. In 1792, the four districts were renamed: Hesse became the Western District, Lunenburg became the Eastern District, Mecklenburg became the Midland District, and Nassau became the Home District. Counties were created within the districts.

By 1798, there were eight districts: Eastern, Home, Johnstown, London, Midland, Newcastle, Niagara, and Western. By 1826, there were eleven districts: Bathurst, Eastern, Gore, Home, Johnstown, London, Midland, Newcastle, Niagara, Ottawa, and Western. By 1838, there were twenty districts: Bathurst, Brock, Colbourne, Dalhousie, Eastern, Gore, Home, Huron, Johnstown, London, Midland, Newcastle, Niagara, Ottawa, Prince Edward, Simcoe, Talbot, Victoria, Wellington, and Western.

In 1849, the districts of southern Ontario were abolished by the Province of Canada, and county governments took over certain municipal responsibilities. The Province of Canada also began creating "districts" in sparsely populated Northern Ontario with the establishment of Algoma District and Nipissing District in 1858.

The borders of Ontario, its new name in 1867, were provisionally expanded north and west. When the Province of Canada was formed, its borders were not entirely clear, and Ontario claimed eventually to reach all the way to the Rocky Mountains and Arctic Ocean. With Canada's acquisition of Rupert's Land, Ontario was interested in clearly defining its borders, especially since some of the new areas in which it was interested were rapidly growing. After the federal government asked Ontario to pay for construction in the new disputed area, the province asked for an elaboration on its limits, and its boundary was moved north to the 51st parallel north.

The northern and western boundaries of Ontario were in dispute after Canadian Confederation. Ontario's right to Northwestern Ontario was determined by the Judicial Committee of the Privy Council in 1884 and confirmed by the "Canada (Ontario Boundary) Act, 1889" of the Parliament of the United Kingdom. By 1899, there were seven northern districts: Algoma, Manitoulin, Muskoka, Nipissing, Parry Sound, Rainy River, and Thunder Bay. Four more northern districts were created between 1907 and 1912: Cochrane, Kenora, Sudbury and Timiskaming.

In the 2016 census, Ontario had a population of 13,448,494 living in 5,169,174 of its 5,598,391 total dwellings, a 4.6 percent change from its 2011 population of 12,851,821. With a land area of , it had a population density of in 2016. The largest population centres in Ontario are Toronto, Ottawa, Hamilton, Kitchener, London and Oshawa which all have more than 300,000 inhabitants.

The percentages given below add to more than 100 per cent because of dual responses (e.g., "French and Canadian" response generates an entry both in the category "French Canadian" and in the category "Canadian").

The majority of Ontarians are of English or other European descent including large Scottish, Irish and Italian communities. Slightly less than 5 per cent of the population of Ontario is Franco-Ontarian, that is those whose native tongue is French, although those with French ancestry account for 11 per cent of the population. In relation to natural increase or inter-provincial migration, immigration is a huge population growth force in Ontario, as it has been over the last two centuries. More recent sources of immigrants with large or growing communities in Ontario include South Asians, Caribbeans, Latin Americans, Europeans, Asians, and Africans. Most populations have settled in the larger urban centres.

In 2011, 25.9 per cent of the population consisted of visible minorities and 2.4 per cent of the population was Indigenous, mostly of First Nations and Métis descent. There was also a small number of Inuit people in the province. The number of Aboriginal people and visible minorities has been increasing at a faster rate than the general population of Ontario.

In 2011, the largest religious denominations in Ontario were the Roman Catholic Church (with 31.4% of the population), the United Church of Canada (7.5%), and the Anglican Church (6.1%). 23.1% of Ontarians had no religious affiliation, making it the second-largest religious grouping in the province after Roman Catholics.

The major religious groups in Ontario in 2011 were:
In Ontario, Catholics are represented by the Assembly of Catholic Bishops of Ontario and the Anglican Protestants by the Ecclesiastical Province of Ontario. The Ecclesiastical Province covers most of the geographical province of Ontario

The principal language of Ontario is English, the province's "de facto" official language, with approximately 97.2 per cent of Ontarians having proficiency in the language, although only 69.5 per cent of Ontarians reported English as their mother tongue in the 2016 Census. English is one of two official languages of Canada, with the other being French. English and French are the official languages of the courts in Ontario. Approximately 4.6 per cent of the population were identified as francophones, with 11.5 per cent of Ontarians having proficiency in French. Approximately 11.2 per cent of the Ontarians reported being bilingual in both official languages of Canada. Approximately 2.5 per cent of Ontarians have no proficiency in either English or French. 

Franco-Ontarians are concentrated in the northeastern, eastern, and extreme Southern parts of the province, where under the "French Language Services Act", provincial government services are required to be available in French if at least 10 per cent of a designated area's population report French as their native language or if an urban centre has at least 5,000 francophones.

Other languages spoken by residents include Arabic, Bengali, Cantonese, Dutch, German, Greek, Gujarati, Hindi, Hebrew, Italian, Korean, Malayalam, Mandarin, Persian, Polish, Portuguese, Punjabi, Russian, Sinhalese, Somali, Spanish, Tagalog, Telugu, Tamil, Tibetan, Ukrainian, Urdu, and Vietnamese.

Ontario is Canada's leading manufacturing province, accounting for 52% of the total national manufacturing shipments in 2004. Ontario's largest trading partner is the American state of Michigan. , Moody's bond-rating agency rated Ontario debt at AA2/stable, while S&P rated it AA-. Dominion Bond Rating Service rated it AA(low) in January 2013. Long known as a bastion of Canadian manufacturing and financial solvency, Ontario's public debt-to-GDP ratio is projected to be 38.4% in fiscal year 2023–2024.

Mining and the forest products industry, notably pulp and paper, are vital to the economy of Northern Ontario. As of 2011, roughly 200,000 ha are clearcut each year; herbicides for hardwood suppression are applied to a third of the total. There has been controversy over the Ring of Fire mineral deposit, and whether the province can afford to spend CAD$2.25 billion on a road from the Trans-Canada Highway near Kenora to the deposit, currently valued at CAD$60 billion.

An abundance of natural resources, excellent transportation links to the North American heartland and the inland Great Lakes making ocean access possible via container ships, have all contributed to making manufacturing the principal industry of the province, found mainly in the Golden Horseshoe region, which is the largest industrialized area in Canada, the southern end of the region being part of the North American Rust Belt. Important products include motor vehicles, iron, steel, food, electrical appliances, machinery, chemicals, and paper.

Hamilton is the largest steel manufacturing city in Canada followed closely by Sault Ste. Marie, and Sarnia is the centre for petrochemical production. Construction employed more than 6.5% of the province's work force in June 2011. Ontario's steel industry was once centred in Hamilton. Hamilton harbour, which can be seen from the QEW Skyway bridge, is an industrial wasteland; U.S. Steel-owned Stelco announced in the autumn of 2013 that it would close in 2014, with the loss of 875 jobs. The move flummoxed a union representative, who seemed puzzled why a plant with capacity of 2 million tons per annum would be shut while Canada imported 8 million tons of steel the previous year. Algoma Steel maintains a plant in Sault Ste Marie.

Ontario surpassed Michigan in car production, assembling 2.696 million vehicles in 2004. Ontario has Chrysler plants in Windsor and Bramalea, two GM plants in Oshawa and one in Ingersoll, a Honda assembly plant in Alliston, Ford plants in Oakville and St. Thomas and Toyota assembly plants in Cambridge and Woodstock. However, as a result of steeply declining sales, in 2005, General Motors announced massive layoffs at production facilities across North America, including two large GM plants in Oshawa and a drive train facility in St. Catharines, that resulted in 8,000 job losses in Ontario alone. In 2006, Ford Motor Company announced between 25,000 and 30,000 layoffs phased until 2012; Ontario was spared the worst, but job losses were announced for the St Thomas facility and the Windsor Casting plant. However, these losses will be offset by Ford's recent announcement of a hybrid vehicle facility slated to begin production in 2007 at its Oakville plant and GM's re-introduction of the Camaro which will be produced in Oshawa. On December 4, 2008 Toyota announced the grand opening of the RAV4 plant in Woodstock, and Honda also plans to add an engine plant at its facility in Alliston. Despite these new plants coming online, Ontario has not yet fully recovered following massive layoffs caused by the global recession; its unemployment rate was 7.3% in May 2013, compared to 8.7 percent in January 2010 and approximately 6% in 2007. In September 2013, the Ontario government committed CAD$70.9 million to the Ford plant in Oakville, while the federal government committed CAD$71.1mn, to secure 2,800 jobs. The province has lost 300,000 manufacturing jobs in the decade from 2003, and the Bank of Canada noted that "while the energy and mining industries have benefitted from these movements, the pressure on the manufacturing sector has intensified, since many firms in this sector were already dealing with growing competition from low-cost economies such as China."

Toronto, the capital of Ontario, is the centre of Canada's financial services and banking industry. Neighbouring cities are home to product distribution, IT centres, and manufacturing industries. Canada's Federal Government is the largest single employer in the National Capital Region, which centres on the border cities of Ontario's Ottawa and Quebec's Gatineau.

The information technology sector is important, particularly in the "Silicon Valley North" section of Ottawa, home to Canada's largest technology park. IT is also important in the Waterloo Region, where the headquarters of BlackBerry is located.

Tourism contributes heavily to the economy of Central Ontario, peaking during the summer months owing to the abundance of fresh water recreation and wilderness found there in reasonable proximity to the major urban centres. At other times of the year, hunting, skiing and snowmobiling are popular. This region has some of the most vibrant fall colour displays anywhere on the continent, and tours directed at overseas visitors are organized to see them. Tourism also plays a key role in border cities with large casinos, among them Windsor, Cornwall, Sarnia and Niagara Falls, the latter of which attracts millions of US and other international visitors.

Once the dominant industry, agriculture occupies a small percentage of the population. However, much of the land in southern Ontario is given over to agriculture. As the following table shows, while the number of individual farms has steadily decreased and their overall size has shrunk at a lower rate, greater mechanization has supported increased supply to satisfy the ever-increasing demands of a growing population base; this has also meant a gradual increase in the total amount of land used for growing crops.
Common types of farms reported in the 2001 census include those for cattle, small grains and dairy. The fruit- and wine industry is primarily on the Niagara Peninsula, Prince Edward County, and along the northern shore of Lake Erie, where tobacco farms are also situated. Market vegetables grow in the rich soils of the Holland Marsh near Newmarket. The area near Windsor is also very fertile. The Heinz plant in Leamington was taken over in these autumn of 2013 by Warren Buffett and a Brazilian partner, following which it put 740 people out of work. Government subsidies followed shortly; Premier Kathleen Wynne offered CAD$200,000 to cushion the blow, and promised that another processed-food operator would soon be found. On December 10, 2013, Kellogg's announced layoffs for more than 509 workers at a cereal manufacture plant in London.

The area defined as the Corn Belt covers much of the southwestern area of the province, extending as far north as close to Goderich, but corn and soy are grown throughout the southern portion of the province. Apple orchards are a common sight along the southern shore of Nottawasaga Bay (part of Georgian Bay) near Collingwood and along the northern shore of Lake Ontario near Cobourg. Tobacco production, centred in Norfolk County, has decreased, allowing an increase in alternative crops such as hazelnuts and ginseng. The Ontario origins of Massey Ferguson, once one of the largest farm-implement manufacturers in the world, indicate the importance agriculture once had to the Canadian economy.

Southern Ontario's limited supply of agricultural land is going out of production at an increasing rate. Urban sprawl and farmland severances contribute to the loss of thousands of acres of productive agricultural land in Ontario each year. Over 2,000 farms and of farmland in the GTA alone were lost to production in the two decades between 1976 and 1996. This loss represented approximately 18%". of Ontario's Class 1 farmland being converted to urban purposes. In addition, increasing rural severances provide ever-greater interference with agricultural production. In an effort to protect the farmland and green spaces of the National Capital Region, and Greater Toronto Area, the Federal and Provincial Governments introduced greenbelts around Ottawa and the Golden Horseshoe, limiting urban development in these areas.

Ontario's rivers make it rich in hydroelectric energy. In 2009, Ontario Power Generation generated 70 percent of the province's electricity, of which 51 percent is nuclear, 39% is hydroelectric and 10% is fossil-fuel derived. By 2025, nuclear power is projected to supply 42%, while fossil-fuel-derived generation is projected to decrease slightly over the next 20 years. Much of the newer power generation coming online in the last few years is natural gas or combined-cycle natural gas plants. OPG is not, however, responsible for the transmission of power, which is under the control of Hydro One. 
Despite its diverse range of power options, problems related to increasing consumption, lack of energy efficiency and aging nuclear reactors, Ontario has been forced in recent years to purchase power from its neighbours Quebec and Michigan to supplement its power needs during peak consumption periods. Ontario's basic domestic rate in 2010 was 11.17 cents per kWh; by contrast. Quebec's was 6.81. In December 2013, the government projected a 42 percent hike by 2018, and 68 percent by 2033. Industrial rates are projected to rise by 33% by 2018, and 55% in 2033.

The "Green Energy and Green Economy Act", 2009 (GEA), takes a two-pronged approach to commercializing renewable energy; first, it aims to bring more renewable energy sources to the province; and secondly, it aims to adopt more energy-efficiency measures to help conserve energy. The bill envisaged appointing a Renewable Energy Facilitator to provide "one-window" assistance and support to project developers to facilitate project approvals.

The approvals process for transmission projects would also be streamlined and (for the first time in Ontario) the bill would enact standards for renewable energy projects. Homeowners would have access to incentives to develop small-scale renewables such as low- or no-interest loans to finance the capital cost of renewable energy generating facilities like solar panels.

Ontario is home to Niagara Falls, which supplies a large amount of electricity to the province. The Bruce Nuclear Generating Station, the largest operational nuclear power plant in the world, is also in Ontario and uses 8 CANDU reactors to generate electricity for the province.

Ontario had the most wind energy capacity of the country with 4,900 MW of power (41% of Canada capacity).

The "British North America Act 1867" section 69 stipulated "There shall be a Legislature for Ontario consisting of the Lieutenant Governor and of One House, styled the Legislative Assembly of Ontario." The assembly currently has 124 seats (increased from 107 as of the 42nd Ontario general election) representing ridings elected in a first-past-the-post system across the province.

The legislative buildings at Queen's Park are the seat of government. Following the Westminster system, the leader of the party holding the most seats in the assembly is known as the "Premier and President of the Council" (Executive Council Act R.S.O. 1990). The Premier chooses the cabinet or Executive Council whose members are deemed ministers of the Crown.

Although the "Legislative Assembly Act (R.S.O. 1990)" refers to "members of the assembly", the legislators are now commonly called MPPs (Members of the Provincial Parliament) in English and "députés de l'Assemblée législative" in French, but they have also been called MLAs (Members of the Legislative Assembly), and both are acceptable. The title of Prime Minister of Ontario, correct in French ("le Premier ministre"), is permissible in English but now generally avoided in favour of the title "Premier" to avoid confusion with the Prime Minister of Canada.

Ontario has grown, from its roots in Upper Canada, into a modern jurisdiction. The old titles of the chief law officers, the Attorney-General and the Solicitor-General, remain in use. They both are responsible to the Legislature. The Attorney-General drafts the laws and is responsible for criminal prosecutions and the administration of justice, while the Solicitor-General is responsible for law enforcement and the police services of the province. 
The Municipal Act, 2001 (Ontario) is the main statute governing the creation, administration and government of municipalities in the Canadian province of Ontario, other than the City of Toronto. After being passed in 2001, it came into force on January 1, 2003, replacing the previous "Municipal Act". Effective January 1, 2007, the Municipal Act, 2001 (the Act) was significantly amended by the Municipal Statute Law Amendment Act, 2006 (Bill 130).

Ontario has numerous political parties which run for election. The three main parties are the centre-right Progressive Conservative Party of Ontario, the social democratic Ontario New Democratic Party (NDP), the centre-left Ontario Liberal Party. The Progressive Conservatives, Liberals and New Democrats have each governed the province, while the Greens elected their first-ever member to the Legislative Assembly in 2018.

The 2018 provincial election resulted in a Progressive Conservative majority under Doug Ford, who was sworn in to office on June 29.

Statistics Canada's measure of a "metro area", the Census Metropolitan Area (CMA), roughly bundles together population figures from the core municipality with those from "commuter" municipalities.

<nowiki>*</nowiki>Parts of Quebec (including Gatineau) are included in the Ottawa CMA. The population of the Ottawa CMA, in both provinces, is shown.

In Canada, education falls under provincial jurisdiction. Publicly funded elementary and secondary schools are administered by the Ontario Ministry of Education, while colleges and universities are administered by the Ontario Ministry of Training, Colleges and Universities. The Minister of Education is Stephen Lecce, and the Minister of Training, Colleges and Universities is Ross Romano.

Higher education in Ontario includes postsecondary education and skills training regulated by the Ministry of Training, Colleges, and Universities and provided by universities, colleges of applied arts and technology, and private career colleges. The minister is Merrilee Fullerton. The ministry administers laws covering 22 public universities, 24 public colleges (21 Colleges of Applied Arts and Technology (CAATs) and three Institutes of Technology and Advanced Learning (ITALs)), 17 privately funded religious universities, and over 500 private career colleges. The Canadian constitution provides each province with the responsibility for higher education and there is no corresponding national federal ministry of higher education. Within Canadian federalism the division of responsibilities and taxing powers between the Ontario and Canadian governments creates the need for co-operation to fund and deliver higher education to students. Each higher education system aims to improve participation, access, and mobility for students. There are two central organizations that assist with the process of applying to Ontario universities and colleges: the Ontario Universities' Application Centre and Ontario College Application Service. While application services are centralized, admission and selection processes vary and are the purview of each institution. Admission to many Ontario postsecondary institutions can be highly competitive. Upon admission, students may get involved with regional student representation with the Canadian Federation of Students, the Canadian Alliance of Student Associations, the Ontario Undergraduate Student Alliance, or through the College Student Alliance in Ontario.

In 2019, the government of Ontario passed legislation that established the Poet Laureate of Ontario.

In 1973, the first slogan to appear on licence plates in Ontario was "Keep It Beautiful". This was replaced by "Yours to Discover" in 1982, apparently inspired by a tourism slogan, "Discover Ontario", dating back to 1927. Plates with the French equivalent, , were made available to the public beginning in May 2008. (From 1988 to 1990, "Ontario Incredible" gave "Yours to Discover" a brief respite.)

In 2007, a new song replaced "A Place to Stand" after four decades. "There's No Place Like This" is featured in television advertising, performed by Ontario artists including Molly Johnson, Brian Byrne, Keshia Chanté, as well as Tomi Swick and Arkells.

The province has professional sports teams in baseball, basketball, Canadian football, ice hockey, lacrosse, rugby league, rugby union and soccer.

Transportation routes in Ontario evolved from early waterway travel and First Nations paths followed by European explorers. Ontario has two major east–west routes, both starting from Montreal in the neighbouring province of Quebec. The northerly route, which was a major fur trade route, travels west from Montreal along the Ottawa River, then continues northwestward towards Manitoba. Major cities on or near the route include Ottawa, North Bay, Sudbury, Sault Ste. Marie, and Thunder Bay. The southerly route, which was driven by growth in settlements originated by the United Empire Loyalists and later other European immigrants, travels southwest from Montreal along the St. Lawrence River, Lake Ontario, and Lake Erie before entering the United States in Michigan. Major cities on or near the route include Kingston, Belleville, Peterborough, Oshawa, Toronto, Mississauga, Kitchener-Waterloo, Hamilton, London, Sarnia, and Windsor. This route was also heavily used by immigrants to the Midwestern US particularly in the late 19th century.

Important airports in the province include Toronto Pearson International Airport, which is the busiest airport in Canada, handling nearly 50 million passengers in 2018. Ottawa Macdonald–Cartier International Airport is Ontario's second largest airport. Toronto/Pearson and Ottawa/Macdonald-Cartier form two of the three points in Canada's busiest set of air routes (the third point being Montréal–Pierre Elliott Trudeau International Airport). In addition to airports in Ottawa, and Toronto, the province also operates three other international airports, the John C. Munro Hamilton International Airport in Hamilton, the Thunder Bay International Airport in Thunder Bay and the London International Airport in London. John C. Munro Hamilton International Airport serves as cargo hub, reliever for Pearson, and a hub for ULCC Swoop.

Most Ontario cities have regional airports, many of which have scheduled commuter flights from Air Canada Jazz or smaller airlines and charter companies – flights from the mid-size cities such as Thunder Bay, Sault Ste. Marie, Sudbury, North Bay, Timmins, Windsor, London, and Kingston feed directly into larger airports in Toronto and Ottawa. Bearskin Airlines also runs flights along the northerly east–west route, connecting Ottawa, North Bay, Sudbury, Sault Ste. Marie, Kitchener and Thunder Bay directly.

Isolated towns and settlements in the northern areas of the province rely partly or entirely on air service for travel, goods, and even ambulance services (MEDIVAC), since much of the far northern area of the province cannot be reached by road or rail.

Via Rail operates the inter-regional passenger train service on the Quebec City–Windsor Corridor, along with "The Canadian", a transcontinental rail service from Southern Ontario to Vancouver, and the Sudbury–White River train. Additionally, Amtrak rail connects Ontario with key New York cities including Buffalo, Albany, and New York City. Ontario Northland provides rail service to destinations as far north as Moosonee near James Bay, connecting them with the south.

Freight rail is dominated by the founding cross-country Canadian National Railway and CP Rail companies, which during the 1990s sold many short rail lines from their vast network to private companies operating mostly in the south.

Regional commuter rail is limited to the provincially owned GO Transit, and serves a train-bus network spanning the Golden Horseshoe region, with Union Station in Toronto serving as the transport hub.

There are several city rail-transit systems in the Province. The Toronto Transit Commission operates subways, as well as streetcars (being one of the busiest streetcar systems in North America). OC Transpo operates a light rail metro system in Ottawa. In addition, Waterloo region operates a surface light rail system. Plans to build a light rail line is also underway in the Regional Municipality of Peel.
400-series highways make up the primary vehicular network in the south of province, and they connect at a number of points to border crossings to the United States, and Quebec, the busiest being the Detroit–Windsor Tunnel and Ambassador Bridge and the Blue Water Bridge (via Highway 402). Some of the primary highways along the southern route are Highway 401, Highway 417, and Highway 400, Highway 401 being the busiest highway in North America. Other provincial highways and regional roads inter-connect the remainder of the province.

The Saint Lawrence Seaway, which extends across most of the southern portion of the province and connects to the Atlantic Ocean, is the primary water transportation route for cargo, particularly iron ore and grain. In the past, the Great Lakes and St. Lawrence River were also a major passenger transportation route, but over the past half century passenger travel has been reduced to ferry services and sightseeing cruises. Ontario's three largest ports are the Port of Hamilton, Port of Thunder Bay and the Port of Windsor. Ontario's only saltwater port is located in the town of Moosonee on James Bay.



</doc>
<doc id="22219" url="https://en.wikipedia.org/wiki?curid=22219" title="Ottawa">
Ottawa

Ottawa (, ; Canadian ) is the capital city of Canada. It stands on the south bank of the Ottawa River in the eastern portion of southern Ontario. Ottawa borders Gatineau, Quebec, and forms the core of the Ottawa–Gatineau census metropolitan area (CMA) and the National Capital Region (NCR). As of 2016, Ottawa had a city population of 934,243 and a metropolitan population of 1,323,783 making it the fourth-largest city and the fifth-largest CMA in Canada. In June 2019, the City of Ottawa estimated it had surpassed a population of a million.

Founded in 1826 as Bytown, and incorporated as Ottawa in 1855, the city has evolved into the political centre of Canada. Its original boundaries were expanded through numerous annexations and were ultimately replaced by a new city incorporation and amalgamation in 2001 which significantly increased its land area. The city name "Ottawa" was chosen in reference to the Ottawa River, the name of which is derived from the Algonquin "Odawa", meaning "to trade".

Ottawa has the most educated population among Canadian cities and is home to a number of post-secondary, research, and cultural institutions, including the National Arts Centre, the National Gallery, and numerous national museums.

With the draining of the Champlain Sea around ten thousand years ago, the Ottawa Valley became habitable. Local populations used the area for wild edible harvesting, hunting, fishing, trade, travel, and camps for over 6500 years. The Ottawa river valley has archeological sites with arrow heads, pottery, and stone tools. Three major rivers meet within Ottawa, making it an important trade and travel area for thousands of years. The Algonquins called the Ottawa River "Kichi Sibi" or "Kichissippi" meaning "Great River" or "Grand River".

Étienne Brûlé, widely regarded as the first European to travel up the Ottawa River, passed by Ottawa in 1610 on his way to the Great Lakes. Three years later, Samuel de Champlain wrote about the waterfalls in the area and about his encounters with the Algonquins, who had been using the Ottawa River for centuries. Many missionaries would follow the early explorers and traders. The first maps of the area used the word Ottawa, derived from the Algonquin word "adawe" ("to trade", used in reference to the area's importance to First Nations traders), to name the river. Philemon Wright, a New Englander, created the first European settlement in the area on 7 March 1800 on the north side of the river, across from the present-day city of Ottawa in Hull. He, with five other families and twenty-five labourers, set about to create an agricultural community called Wrightsville. Wright pioneered the Ottawa Valley timber trade (soon to be the area's most significant economic activity) by transporting timber by river from the Ottawa Valley to Quebec City. Bytown, Ottawa's original name, was founded as a community in 1826 when hundreds of land speculators were attracted to the south side of the river when news spread that British authorities were immediately constructing the northerly end of the Rideau Canal military project at that location. The following year, the town was named after British military engineer Colonel John By who was responsible for the entire Rideau Waterway construction project.

The canal's military purpose was to provide a secure route between Montreal and Kingston on Lake Ontario, bypassing a particularly vulnerable stretch of the St. Lawrence River bordering the state of New York that had left re-supply ships bound for southwestern Ontario easily exposed to enemy fire during the War of 1812. Colonel By set up military barracks on the site of today's Parliament Hill. He also laid out the streets of the town and created two distinct neighbourhoods named "Upper Town" west of the canal and "Lower Town" east of the canal. Similar to its Upper Canada and Lower Canada namesakes, historically "Upper Town" was predominantly English speaking and Protestant whereas "Lower Town" was predominantly French, Irish and Catholic. Bytown's population grew to 1,000 as the Rideau Canal was being completed in 1832. Bytown encountered some impassioned and violent times in her early pioneer period that included Irish labour unrest that attributed to the Shiners' War from 1835 to 1845 and political dissension evident from the 1849 Stony Monday Riot. In 1855 Bytown was renamed "Ottawa" and incorporated as a city. William Pittman Lett was installed as the first city clerk guiding it through 36 years of development.
On New Year's Eve 1857, Queen Victoria, as a symbolic and political gesture, was presented with the responsibility of selecting a location for the permanent capital of the Province of Canada. In reality, Prime Minister John A. Macdonald had assigned this selection process to the Executive Branch of the Government, as previous attempts to arrive at a consensus had ended in deadlock. The "Queen's choice" turned out to be the small frontier town of Ottawa for two main reasons: Firstly, Ottawa's isolated location in a backcountry surrounded by dense forest far from the Canada–US border and situated on a cliff face would make it more defensible from attack. Secondly, Ottawa was approximately midway between Toronto and Kingston (in Canada West) and Montreal and Quebec City (in Canada East). Additionally, despite Ottawa's regional isolation, it had seasonal water transportation access to Montreal over the Ottawa River and to Kingston via the Rideau Waterway. By 1854 it also had a modern all-season Bytown and Prescott Railway that carried passengers, lumber and supplies the 82-kilometres to Prescott on the Saint Lawrence River and beyond. Ottawa's small size, it was thought, would make it less prone to rampaging politically motivated mobs, as had happened in the previous Canadian capitals. The government already owned the land that would eventually become Parliament Hill which they thought would be an ideal location for the Parliament Buildings. Ottawa was the only settlement of any substantial size that was already directly on the border of French populated former Lower Canada and English populated former Upper Canada thus additionally making the selection an important political compromise. Queen Victoria made her "Queen's choice" very quickly just before welcoming in the New Year.

Starting in the 1850s, entrepreneurs known as lumber barons began to build large sawmills, which became some of the largest mills in the world. Rail lines built in 1854 connected Ottawa to areas south and to the transcontinental rail network via Hull and Lachute, Quebec in 1886. The original Parliament buildings which included the Centre, East and West Blocks were constructed between 1859 and 1866 in the Gothic Revival style. At the time, this was the largest North American construction project ever attempted and Public Works Canada and its architects were not initially well prepared. The Library of Parliament and Parliament Hill landscaping would not be completed until 1876. By 1885 Ottawa was the only city in Canada whose downtown street lights were powered entirely by electricity. In 1889 the Government developed and distributed 60 "water leases" (still in use) to mainly local industrialists which gave them permission to generate electricity and operate hydroelectric generators at Chaudière Falls. Public transportation began in 1870 with a horsecar system, overtaken in the 1890s by a vast electric streetcar system that lasted until 1959.

The Hull–Ottawa fire of 1900 destroyed two-thirds of Hull, including 40 percent of its residential buildings and most of its largest employers along the waterfront. It also spread across the Ottawa River and destroyed about one fifth of Ottawa from the Lebreton Flats south to Booth Street and down to Dow's Lake. On 1 June 1912 the Grand Trunk Railway opened both the Château Laurier hotel and its neighbouring downtown Union Station. On 3 February 1916 the Centre Block of the Parliament buildings was destroyed by a fire. The House of Commons and Senate was temporarily relocated to the then recently constructed Victoria Memorial Museum, now the Canadian Museum of Nature until the completion of the new Centre Block in 1922, the centrepiece of which is a dominant Gothic revival styled structure known as the Peace Tower. The location of what is now Confederation Square was a former commercial district centrally located in a triangular area downtown surrounded by historically significant heritage buildings which includes the Parliament buildings. It was redeveloped as a ceremonial centre in 1938 as part of the City Beautiful Movement and became the site of the National War Memorial in 1939 and designated a National Historic Site in 1984. A new Central Post Office (now the Privy Council of Canada) was constructed in 1939 beside the War Memorial because the original post office building on the proposed Confederation Square grounds had to be demolished.

Ottawa's former industrial appearance was vastly altered by the 1950 Greber Plan. Prime Minister Mackenzie King hired French architect-planner Jacques Greber to design an urban plan for managing development in the National Capital Region, to make it more esthetically pleasing and more befitting a location for Canada's political centre. Greber's plan included the creation of the National Capital Greenbelt, the Parkway, the Queensway highway system, the relocation of downtown Union Station (now the Senate of Canada Building) to the suburbs, the removal of the street car system, the decentralization of selected government offices, the relocation of industries and removal of substandard housing from the downtown and the creation of the Rideau Canal and Ottawa River pathways to name just a few of its recommendations. In 1958 the National Capital Commission was established as a Crown Corporation from the passing of the National Capital Act to implement the Greber Plan recommendations-which it accomplished during the 1960s and 1970s.

In the previous 50 years, other commissions, plans and projects had failed to implement plans to improve the capital such as the 1899 Ottawa Improvement Commission (OIC), The Todd Plan in 1903, The Holt Report in 1915 and The Federal District Commission (FDC) established in 1927. In 1958 a new City Hall opened on Green Island near Rideau falls where urban renewal had recently transformed this former industrial location into green space. Until then, City Hall had temporarily been for 27 years (1931–1958) at the Transportation Building adjacent to Union Station and now part of the Rideau Centre. In 2001, Ottawa City Hall returned downtown to a relatively new building (1990) on 110 Laurier Avenue West, the prior home of the now defunct Regional Municipality of Ottawa-Carleton. This new location was close to Ottawa's first (1849–1877) and second (1877–1931) City Halls. This new city hall complex also contained an adjacent 19th century restored heritage building formerly known as the Ottawa Normal School.

From the 1960s until the 1980s, the National Capital Region experienced a building boom, which was followed by large growth in the high-tech industry during the 1990s and 2000s. Ottawa became one of Canada's largest high tech cities and was nicknamed Silicon Valley North. By the 1980s, Bell Northern Research (later Nortel) employed thousands, and large federally assisted research facilities such as the National Research Council contributed to an eventual technology boom. The early adopters led to offshoot companies such as Newbridge Networks, Mitel and Corel.

Ottawa's city limits had been increasing over the years, but it acquired the most territory on 1 January 2001, when it amalgamated all the municipalities of the Regional Municipality of Ottawa–Carleton into one single city. Regional Chair Bob Chiarelli was elected as the new city's first mayor in the 2000 municipal election, defeating Gloucester mayor Claudette Cain. The city's growth led to strains on the public transit system and on road bridges. On 15 October 2001, a diesel-powered light rail transit (LRT) line was introduced on an experimental basis. Known today as the Trillium Line, it was dubbed the O-Train and connected downtown Ottawa to the southern suburbs via Carleton University. The decision to extend the O-Train, and to replace it with an electric light rail system was a major issue in the 2006 municipal elections where Chiarelli was defeated by businessman Larry O'Brien. After O'Brien's election transit plans were changed to establish a series of light rail stations from the east side of the city into downtown, and for using a tunnel through the downtown core. Jim Watson, the last mayor of Ottawa prior to amalgamation, was re-elected in the 2010 election.

In October 2012, City Council approved the final Lansdowne Park plan, an agreement with the Ottawa Sports and Entertainment Group that saw a new stadium, increased green space, and housing and retail added to the site. In December 2012, City Council voted unanimously to move forward with the Confederation Line, a light rail transit line, which was opened on 14 September 2019.

Ottawa is on the south bank of the Ottawa River and contains the mouths of the Rideau River and Rideau Canal. The older part of the city (including what remains of Bytown) is known as "Lower Town", and occupies an area between the canal and the rivers. Across the canal to the west lies "Centretown" and "Downtown Ottawa", which is the city's financial and commercial hub and home to the Parliament of Canada and numerous federal government department headquarters, notably the Privy Council Office. On 29 June 2007, the Rideau Canal, which stretches to Kingston, Fort Henry and four Martello towers in the Kingston area, was recognized as a UNESCO World Heritage Site.

Located within the major, yet mostly dormant Western Quebec Seismic Zone, Ottawa is occasionally struck by earthquakes. Examples include the 2000 Kipawa earthquake, a magnitude-4.5 earthquake on 24 February 2006, the 2010 Central Canada earthquake, and a magnitude-5.2 earthquake on 17 May 2013.

Ottawa sits at the confluence of three major rivers: the Ottawa River, the Gatineau River and the Rideau River. The Ottawa and Gatineau rivers were historically important in the logging and lumber industries and the Rideau as part of the Rideau Canal system for military, commercial and, subsequently, recreational purposes. The Rideau Canal (Rideau Waterway) first opened in 1832 and is long. It connects the Saint Lawrence River on Lake Ontario at Kingston to the Ottawa River near Parliament Hill. It was able to bypass the unnavigable sections of the Cataraqui and Rideau rivers and various small lakes along the waterway due to flooding techniques and the construction of 47 water transport locks.The Rideau River got its name from early French explorers who thought the waterfalls at the point where the Rideau River empties into the Ottawa River resembled a "curtain". Hence they began naming the falls and river "rideau" which is the French equivalent of the English word for curtain. During part of the winter season the Ottawa section of the canal forms the world's largest skating rink, thereby providing both a recreational venue and a transportation path to downtown for ice skaters (from Carleton University and Dow's Lake to the Rideau Centre and National Arts Centre).

Across the Ottawa River, which forms the border between Ontario and Quebec, lies the city of Gatineau, itself the result of amalgamation of the former Quebec cities of Hull and Aylmer together with Gatineau. Although formally and administratively separate cities in two separate provinces, Ottawa and Gatineau (along with a number of nearby municipalities) collectively constitute the National Capital Region, which is considered a single metropolitan area. One federal crown corporation, the National Capital Commission, or NCC, has significant land holdings in both cities, including sites of historical and touristic importance. The NCC, through its responsibility for planning and development of these lands, is an important contributor to both cities. Around the main urban area is an extensive greenbelt, administered by the NCC for conservation and leisure, and comprising mostly forest, farmland and marshland.

Ottawa has a humid continental climate (Köppen "Dfb") with four distinct seasons and is between Zones 5a and 5b on the Canadian Plant Hardiness Scale. The average July maximum temperature is . The average January minimum temperature is 

Summers are warm and humid in Ottawa. On average 11 days of the three summer months have temperatures exceeding , or 37 days if the humidex is considered. Average relative humidity averages 54% in the afternoon and 84% by morning.

Snow and ice are dominant during the winter season. On average Ottawa receives of snowfall annually but maintains an average of snowpack throughout the three winter months. An average 16 days of the three winter months experience temperatures below , or 41 days if the wind chill is considered.

Spring and fall are variable, prone to extremes in temperature and unpredictable swings in conditions. Hot days above have occurred as early as April or as late as October. Annual precipitation averages around .

Ottawa experiences about 2,130 hours of average sunshine annually (46% of possible). Winds in Ottawa are generally Westerlies averaging but tend to be slightly more dominant during the winter.

The highest temperature ever recorded in Ottawa was on 4 July 1913, 1 August 1917 and 11 August 1944. The coldest temperature ever recorded was on 29 December 1933.

Ottawa is bounded on the east by the United Counties of Prescott and Russell; by Renfrew County and Lanark County in the west; on the south by the United Counties of Leeds and Grenville and the United Counties of Stormont, Dundas and Glengarry; and on the north by the Regional County Municipality of Les Collines-de-l'Outaouais and the City of Gatineau. Modern Ottawa is made up of eleven historic townships, ten of which are from Carleton County and one from Russell.

The city has a main urban area but many other urban, suburban and rural areas exist within the modern city's limits. The main suburban area extends a considerable distance to the east, west and south of the centre, and it includes the former cities of Gloucester, Nepean and Vanier, the former village of Rockcliffe Park (a high-income neighbourhood which is adjacent to the Prime Minister's official residence at 24 Sussex and the Governor General's residence), and the communities of Blackburn Hamlet and Orléans. The Kanata suburban area includes the former village of Stittsville to the southwest. Nepean is another major suburb which also includes Barrhaven. The communities of Manotick and Riverside South are on the other side of the Rideau River, and Greely, southeast of Riverside South.
A number of rural communities (villages and hamlets) lie beyond the greenbelt but are administratively part of the Ottawa municipality. Some of these communities are Burritts Rapids; Ashton; Fallowfield; Kars; Fitzroy Harbour; Munster; Carp; North Gower; Metcalfe; Constance Bay and Osgoode and Richmond. Several towns are within the federally defined National Capital Region but outside the city of Ottawa municipal boundaries; including the urban communities of Almonte, Carleton Place, Embrun, Kemptville, Rockland, and Russell.
In 2016, the populations of the City of Ottawa and the Ottawa–Gatineau census metropolitan area (CMA) were 934,243 and 1,323,783 respectively. The city had a population density of in 2016, while the CMA had a population density of . It is the second-largest city in Ontario, fourth-largest city in the country, and the fourth-largest CMA in the country.

Ottawa's median age of 40.1 is both below the provincial and national averages as of 2016. Youths under 15 years constituted 16.7% of the total population in 2016, while those of retirement age (65 years and older) made up 15.4%.

Over 20 percent of the city's population is foreign-born, with the most common non-Canadian countries of origin being the United Kingdom (8.8% of those foreign-born), China (8.0%), and Lebanon (4.8%). About 6.1% of residents are not Canadian citizens.

Around 65% of Ottawa residents describe themselves as Christian , with Catholics accounting for 38.5% of the population and members of Protestant churches 25%. Non-Christian religions are also very well established in Ottawa, the largest being Islam (6.7%), Hinduism (1.4%), Buddhism (1.3%), and Judaism (1.2%). Those with no religious affiliation represent 22.8%.

As of 2016, approximately 69.1% of Ottawa's population was white, while 4.6% were aboriginal and 26.3% were visible minorities (higher than the national percentage of 22.3%). Below is a breakdown of the demographics.

Bilingualism became official policy for the conduct of municipal business in 2002, and 37.6% of the population can speak both languages as of 2016, making it the largest city in Canada with both English and French as co-official languages. Those who identify their mother tongue as English constitute 62.4 percent, while those with French as their mother tongue make up 14.2 percent of the population. In terms of respondents' knowledge of one or both official languages, 59.9 percent and 1.5 percent of the population have knowledge of English only and French only, respectively; while 37.2 percent have a knowledge of both official languages. The overall Ottawa–Gatineau census metropolitan area (CMA) has a larger proportion of French speakers than Ottawa itself, since Gatineau is overwhelmingly French speaking. An additional 20.4 percent of the population list languages other than English and French as their mother tongue. These include Arabic (3.2%), Chinese (3.0%), Spanish (1.2%), Italian (1.1%), and many others.

As of 2015, the region of Ottawa-Gatineau has the sixth highest total household income of all Canadian metropolitan areas ($82,052). The median household income after taxes is $73,745 which is higher than the national median of $61,348. The unemployment rate in Ottawa in 2016 was 7.2%, lower than the national rate of 7.7%. In 2019 Mercer ranks Ottawa with the third highest quality of living of any Canadian city, and 19th highest in the world. It is also rated the second cleanest city in Canada, and third cleanest city in the world.

Ottawa's primary employers are the Public Service of Canada and the high-tech industry, although tourism and healthcare also represent increasingly sizeable economic activities. The Federal government is the city's largest employer, employing over 110,000 individuals from the National Capital region. The national headquarters for many federal departments are in Ottawa, particularly throughout Centretown and in the Terrasses de la Chaudière and Place du Portage complexes in Hull. The National Defence Headquarters in Ottawa is the main command centre for the Canadian Armed Forces and hosts the Department of National Defence. The Ottawa area includes CFS Leitrim and the former CFB Rockcliffe. During the summer, the city hosts the Ceremonial Guard, which performs functions such as the Changing the Guard. As the national capital of Canada, tourism is an important part of Ottawa's economy, particularly after the 150th anniversary of Canada which was centred in Ottawa. The lead-up to the festivities saw much investment in civic infrastructure, upgrades to tourist infrastructure and increases in national cultural attractions. The National Capital Region annually attracts an estimated 7.3 million tourists, who spend about 1.18 billion dollars.

In addition to the economic activities that come with being the national capital, Ottawa is an important technology centre; in 2015, its 1800 companies employed approximately 63,400 people. The concentration of companies in this industry earned the city the nickname of "Silicon Valley North". Most of these companies specialize in telecommunications, software development and environmental technology. Large technology companies such as Nortel, Corel, Mitel, Cognos, Halogen Software, Shopify and JDS Uniphase were founded in the city. Ottawa also has regional locations for Nokia, 3M, Adobe Systems, Bell Canada, IBM and Hewlett-Packard. Many of the telecommunications and new technology are in the western part of the city (formerly Kanata). The "tech sector" was doing particularly well in 2015/2016. 

Another major employer is the health sector, which employs over 18,000 people. Four active general hospitals are in the Ottawa area: Queensway Carleton Hospital, The Ottawa Hospital, Montfort Hospital, and Children's Hospital of Eastern Ontario. Several specialized hospital facilities are also present, such as the University of Ottawa Heart Institute and the Royal Ottawa Mental Health Centre. Nordion, i-Stat and the National Research Council of Canada and OHRI are part of the growing life science sector. Business, finance, administration, and sales and service rank high among types of occupations. Approximately ten percent of Ottawa's GDP is derived from finance, insurance and real estate whereas employment in goods-producing industries is only half the national average. The City of Ottawa is the second largest employer with over 15,000 employees.

In 2006, Ottawa experienced an increase of 40,000 jobs over 2001 with a five-year average growth that was relatively slower than in the late 1990s. While the number of employees in the federal government stagnated, the high-technology industry grew by 2.4%. The overall growth of jobs in Ottawa-Gatineau was 1.3% compared to the previous year, down to sixth place among Canada's largest cities. In 2016, the unemployment rate in Ottawa was 7.2%, which was below the national unemployment rate of 7.7%. The economic downturn resulted in an increase in the unemployment rate between April 2008 and April 2009 from 4.7 to 6.3%. In the province, however, this rate increased over the same period from 6.4 to 9.1%.

Traditionally the ByWard Market (in Lower Town), Parliament Hill and the Golden Triangle (both in Centretown – Downtown) have been the focal points of the cultural scenes in Ottawa. Modern thoroughfares such as Wellington Street, Rideau Street, Sussex Drive, Elgin Street, Bank Street, Somerset Street, Preston Street, Richmond Road in Westboro, and Sparks Street are home to many boutiques, museums, theatres, galleries, landmarks and memorials in addition to eating establishments, cafes, bars and nightclubs.

Ottawa hosts a variety of annual seasonal activities—such as Winterlude, the largest festival in Canada, and Canada Day celebrations on Parliament Hill and surrounding downtown area, as well as Bluesfest, Canadian Tulip Festival, Ottawa Dragon Boat Festival, Ottawa International Jazz Festival, Fringe Festival and Folk Music Festival, that have grown to become some of the largest festivals of their kind in the world. In 2010, Ottawa's Festival industry received the IFEA "World Festival and Event City Award" for the category of North American cities with a population between 500,000 and 1,000,000.

As Canada's capital, Ottawa has played host to a number of significant cultural events in Canadian history, including the first visit of the reigning Canadian sovereign—King George VI, with his consort, Queen Elizabeth—to his parliament, on 19 May 1939. VE Day was marked with a large celebration on 8 May 1945, the first raising of the country's new national flag took place on 15 February 1965, and the centennial of Confederation was celebrated on 1 July 1967. Elizabeth II was in Ottawa on 17 April 1982, to issue a royal proclamation of the enactment of the Constitution Act. In 1983, Prince Charles and Diana Princess of Wales came to Ottawa for a state dinner hosted by then Prime Minister Pierre Trudeau. In 2011, Ottawa was selected as the first city to receive Prince William, Duke of Cambridge, and Catherine, Duchess of Cambridge during their tour of Canada.

Influenced by government structures, much of the city's architecture tends to be formalistic and functional; however, the city is also marked by Romantic and Picturesque styles of architecture such as the Parliament Buildings' gothic revival architecture. Ottawa's domestic architecture is dominated by single family homes, but also includes smaller numbers of semi-detached houses, rowhouses, and apartment buildings. Many domestic buildings are clad in brick, with small numbers covered in wood, stone, or siding of different materials; variations are common, depending on neighbourhoods and the age of dwellings within them.

The skyline has been controlled by building height restrictions originally implemented to keep Parliament Hill and the Peace Tower at visible from most parts of the city. Today, several buildings are slightly taller than the Peace Tower, with the tallest on Albert Street being the 29-storey Place de Ville (Tower C) at . Federal buildings in the National Capital Region are managed by Public Works Canada, while most of the federal land in the region is managed by the National Capital Commission; its control of much undeveloped land gives the NCC a great deal of influence over the city's development.

Amongst the city's national museums and galleries is the National Gallery of Canada; designed by famous architect Moshe Safdie, it is a permanent home to the Maman sculpture. The Canadian War Museum houses over 3.75 million artifacts and was moved to an expanded facility in 2005. The Canadian Museum of Nature was built in 1905, and underwent a major renovation between 2004 and 2010. Across the Ottawa river in Gatineau is the most visited museum in Canada, the Canadian Museum of History. Designed by Canadian Aboriginal architect Douglas Cardinal, the curving-shaped complex, built at a cost of US$340 million, also houses the Canadian Children's Museum, the Canadian Postal Museum and a 3D IMAX theatre.

The city is also home to the Canada Agriculture Museum, the Canada Aviation and Space Museum, the Canada Science and Technology Museum, Billings Estate Museum, Bytown Museum, Canadian Museum of Contemporary Photography, the Bank of Canada Museum, and the Portrait Gallery of Canada.

The Ottawa Little Theatre, originally called the Ottawa Drama League at its inception in 1913, is the longest-running community theatre company in Ottawa. Since 1969, Ottawa has been the home of the National Arts Centre, a major performing arts venue that houses four stages and is home to the National Arts Centre Orchestra, the Ottawa Symphony Orchestra and Opera Lyra Ottawa. Established in 1975, the Great Canadian Theatre Company specializes in the production of Canadian plays at a local level.

The Rideau Canal is the oldest continuously operated canal system in North America, and in 2007, it was registered as a UNESCO World Heritage Site. In addition, 24 other National Historic Sites of Canada are in Ottawa, including: the Central Chambers, the Central Experimental Farm, the Château Laurier, Confederation Square, the former Ottawa Teachers' College, Office of the Prime Minister and Privy Council, Laurier House and the Parliament Buildings. Many other properties of cultural value have been designated as having "heritage elements" by the City of Ottawa under Part IV of the "Ontario Heritage Act".

Sport in Ottawa has a history dating back to the 19th century. Ottawa is home to six professional sports teams. The Ottawa Senators are a professional ice hockey team playing in the National Hockey League. The Senators play their home games at the Canadian Tire Centre. The Ottawa Redblacks are a professional Canadian Football team playing in the Canadian Football League. A professional soccer club, Atlético Ottawa, will play in the Canadian Premier League, following the dissolution of Ottawa Fury FC. A new rugby league team called the Ottawa Aces will play in the 2021 RFL League 1 competition. The Redblacks, Atlético, and the Aces all play their home games at TD Place Stadium. The city is once again home to a professional basketball team, with the Ottawa Blackjacks beginning to play in the Canadian Elite Basketball League, out of the TD Place Arena. Previously, Ottawa was home to the Ottawa SkyHawks basketball team, of the National Basketball League of Canada. The Ottawa Champions play professional baseball at Raymond Chabot Grant Thornton Park, most recently in the Can-Am League. They are league-less, however, following the merger of the Can-Am League and the Frontier League.

Several non-professional teams also play in Ottawa, including the Ottawa 67's junior ice hockey team.

Collegiate teams in various sports compete in Canadian Interuniversity Sport. The Carleton Ravens are nationally ranked in basketball, and the Ottawa Gee-Gees are nationally ranked in football and basketball. Algonquin College has also won numerous national championships. The city is home to an assortment of amateur organized team sports such as soccer, basketball, baseball, curling, rowing, hurling and horse racing. Casual recreational activities, such as skating, cycling, hiking, sailing, golfing, skiing, and fishing/ice fishing are also popular.

The City of Ottawa is a single-tier municipality, meaning it is in itself a census division and has no county or regional municipality government above it. As a single-tier municipality, Ottawa has responsibility for all municipal services, including fire, emergency medical services, police, parks, roads, sidewalks, public transit, drinking water, storm water, sanitary sewage and solid waste. Ottawa is governed by the 24-member Ottawa City Council consisting of 23 councillors each representing one ward and the mayor Jim Watson, elected in a citywide vote.

Along with being the capital of Canada, Ottawa is politically diverse in local politics. Most of the city has traditionally supported the Liberal Party. Perhaps the safest areas for the Liberals are the ones dominated by Francophones, especially in Vanier and central Gloucester. Central Ottawa is usually more left-leaning, and the New Democratic Party have won ridings there. Some of Ottawa's suburbs are swing areas, notably central Nepean and, despite its francophone population, Orléans. The southern and western parts of the old city of Ottawa are generally moderate and swing to the Conservative Party. The farther one goes outside the city centre like to Kanata and Barrhaven and rural areas, the voters tend to be increasingly conservative, both fiscally and socially. This is especially true in the former Townships of West Carleton, Goulbourn, Rideau and Osgoode, which are more in line with the conservative areas in the surrounding counties. However, not all rural areas support the Conservative Party. Rural parts of the former township of Cumberland, with a large number of Francophones, traditionally support the Liberal Party, though their support has recently weakened.

At present, Ottawa is host to 130 embassies. A further 49 countries accredit their embassies and missions in the United States to Canada.

Ottawa is served by a number of airlines that fly into the Ottawa Macdonald–Cartier International Airport , as well as two main regional airports Gatineau-Ottawa Executive Airport, and the Ottawa/Carp Airport.

Ottawa station (IATA: XDS), is the main inter-city train station operated by Via Rail. It is located 4 km to the east of downtown in Eastway Gardens and serves Via Rail's Corridor Route. The city is also served by inter-city passenger rail service at Fallowfield station in Barrhaven.

Inter-city bus services operate out of Ottawa Central Station, 1.5 km south of downtown in Centretown and just north of Highway 417.

OC Transpo, a department of the city, operates the public transit system. OC Transpo operates an integrated, multi-modal Rapid Transit system which includes:


The Rapid bus service network operates all day, 7 days a week, reaching Kanata to the West, Barrhaven to the South-West, Orléans to the East, and South Keys to the South. There are also several night bus routes that cover Line 1's downtown stations while it is shut off for the night, and backup service to downtown while the train is delayed.

Both OC Transpo and the Quebec-based Société de transport de l'Outaouais (STO) operate bus services between Ottawa and Gatineau.

OC Transpo also operates a door-to-door bus service for the differently-abled known as ParaTranspo.

Construction was recently completed on the Confederation Line, a light-rail transit line (LRT), which includes a tunnel through the downtown area featuring three underground stations. The project broke ground in 2013, and opened in September 2019. A further and 19 stations will be built by 2023, referred to as the Stage 2 plan. There is a proposed LRT system that would link Ottawa with Gatineau.
The city is served by two freeway corridors. The primary corridor is east-west and consists of provincial Highway 417 (designated as the Queensway) and Ottawa-Carleton Regional Road 174 (formerly Provincial Highway 17); a north-south corridor, Highway 416 (designated as Veterans' Memorial Highway), connects Ottawa to the rest of the 400-Series Highway network in Ontario at the 401. Highway 417 is also the Ottawa portion of the Trans-Canada Highway.

The city also has several scenic parkways (promenades), such as Colonel By Drive, Queen Elizabeth Driveway, the Sir John A. MacDonald Parkway, the Rockcliffe Parkway and the Aviation Parkway and has a freeway connection to Autoroute 5 and Autoroute 50, in Gatineau. In 2006, the National Capital Commission completed aesthetic enhancements to Confederation Boulevard, a ceremonial route of existing roads linking key attractions on both sides of the Ottawa River.

Numerous paved multi-use trails, mostly operated by the National Capital Commission, wind their way through much of the city, including along the Ottawa River, Rideau River, and Rideau Canal. These pathways are used for transportation, tourism, and recreation. Because many streets either have wide curb lanes or bicycle lanes, cycling is a popular mode of transportation throughout the year. As of 31 December 2015, of cycling facilities are found in Ottawa, including of multi use pathways, of cycle tracks, of on-road bicycle lanes, and of paved shoulders. of new cycling facilities were added between 2011 and 2014. A downtown street that is restricted to pedestrians only, Sparks Street was turned into a pedestrian mall in 1966. On Sundays (since 1960) and selected holidays and events additional avenues and streets are reserved for pedestrian and/or bicycle uses only. In May 2011, The NCC introduced the Capital Bixi bicycle-sharing system.

Ottawa is known as one of the most educated cities in Canada, with over half the population having graduated from college and/or university. Ottawa has the highest per capita concentration of engineers, scientists, and residents with PhDs in Canada.

The city has two main public universities:


Ottawa also has two main public colleges – Algonquin College and La Cité collégiale. It also has two Catholic universities – Dominican University College and Saint Paul University. Other colleges and universities in nearby areas (namely, the neighbouring city of Gatineau) include the University of Quebec en Outaouais, Cégep de l'Outaouais, and Heritage College.

Four main public school boards exist in Ottawa: English, English-Catholic, French, and French-Catholic. The English-language Ottawa-Carleton District School Board (OCDSB) is the largest board with 147 schools, followed by the English-Catholic Ottawa Catholic School Board with 85 schools. The two French-language boards are the French-Catholic "Conseil des écoles catholiques du Centre-Est" with 49 schools, and the French "Conseil des écoles publiques de l'Est de l'Ontario" with 37 schools. Ottawa also has numerous private schools which are not part of a board.

The Ottawa Public Library was created in 1906 as part of the famed Carnegie library system. The library system had 2.3 million items .

Three main daily local newspapers are printed in Ottawa: two English newspapers, the "Ottawa Citizen" established as "the Bytown Packet" in 1845 and the "Ottawa Sun", and one French newspaper, "Le Droit". Multiple Canadian television broadcast networks and systems, and an extensive number of radio stations, broadcast in both English and French.

In addition to the market's local media services, Ottawa is home to several national media operations, including CPAC (Canada's national legislature broadcaster) and the parliamentary bureau staff of virtually all of Canada's major newsgathering organizations in television, radio and print. The city is also home to the head office of the Canadian Broadcasting Corporation, although it is not the primary production location of most CBC radio or television programming.

Ottawa is twinned with:




</doc>
<doc id="22256" url="https://en.wikipedia.org/wiki?curid=22256" title="Objectivism">
Objectivism

Objectivism is a philosophical system developed by Russian-American writer Ayn Rand. Rand first expressed Objectivism in her fiction, most notably "The Fountainhead" (1943) and "Atlas Shrugged" (1957), and later in non-fiction essays and books. Leonard Peikoff, a professional philosopher and Rand's designated intellectual heir, later gave it a more formal structure. Rand described Objectivism as "the concept of man as a heroic being, with his own happiness as the moral purpose of his life, with productive achievement as his noblest activity, and reason as his only absolute". Peikoff characterizes Objectivism as a "closed system" insofar as its "fundamental principles" were set out by Rand and are not subject to change. However, he stated that "new implications, applications and integrations can always be discovered".

Objectivism's main tenets are that reality exists independently of consciousness, that human beings have direct contact with reality through sense perception (see direct and indirect realism), that one can attain objective knowledge from perception through the process of concept formation and inductive logic, that the proper moral purpose of one's life is the pursuit of one's own happiness (see rational egoism), that the only social system consistent with this morality is one that displays full respect for individual rights embodied in "laissez-faire" capitalism, and that the role of art in human life is to transform humans' metaphysical ideas by selective reproduction of reality into a physical form—a work of art—that one can comprehend and to which one can respond emotionally.

Academic philosophers have mostly ignored or rejected Rand's philosophy. Nonetheless, Objectivism has been a significant influence among libertarians and American conservatives. The Objectivist movement, which Rand founded, attempts to spread her ideas to the public and in academic settings.

Rand originally expressed her philosophical ideas in her novels - most notably, in both "The Fountainhead" and "Atlas Shrugged". She further elaborated on them in her periodicals "The Objectivist Newsletter", "The Objectivist", and "The Ayn Rand Letter", and in non-fiction books such as "Introduction to Objectivist Epistemology" and "The Virtue of Selfishness".

The name "Objectivism" derives from the idea that human knowledge and values are objective: they exist and are determined by the nature of reality, to be discovered by one's mind, and are not created by the thoughts one has. Rand stated that she chose the name because her preferred term for a philosophy based on the primacy of existence—"existentialism"—had already been taken.

Rand characterized Objectivism as "a philosophy for living on earth", based on reality, and intended as a method of defining human nature and the nature of the world in which we live.
Rand's philosophy begins with three axioms: existence, consciousness, and identity. Rand defined an axiom as "a statement that identifies the base of knowledge and of any further statement pertaining to that knowledge, a statement necessarily contained in all others whether any particular speaker chooses to identify it or not. An axiom is a proposition that defeats its opponents by the fact that they have to accept it and use it in the process of any attempt to deny it." As Objectivist philosopher Leonard Peikoff argued, Rand's argument for axioms "is not a proof that the axioms of existence, consciousness, and identity are true. It is proof that they are "axioms", that they are at the base of knowledge and thus inescapable."

Rand said that "existence" is the perceptually self-evident fact at the base of all other knowledge, i.e., that "existence exists". She further said that to be is to be "something", that "existence "is" identity". That is, to be is to be "an entity of a specific nature made of specific attributes". That which has no nature or attributes does not and cannot exist. The axiom of existence is conceptualized as differentiating something from nothing, while the law of identity is conceptualized as differentiating one thing from another, i.e., one's first awareness of the law of non-contradiction, another crucial base for the rest of knowledge. As Rand wrote, "A leaf ... cannot be all red and green at the same time, it cannot freeze and burn at the same time... A is A." Objectivism rejects belief in anything alleged to transcend existence.

Rand argued that consciousness is "the faculty of perceiving that which exists". As she put it, "to be conscious is to be conscious of "something"", that is consciousness itself cannot be distinguished or conceptualized except in relation to an independent reality. "It cannot be aware only of itself—there is no 'itself' until it is aware of something." Thus, Objectivism posits that the mind does not create reality, but rather, it is a means of discovering reality. Expressed differently, existence has "primacy" over consciousness, which must conform to it. Any other type of argument Rand termed "the primacy of consciousness", including any variant of metaphysical subjectivism or theism.

Objectivist philosophy derives its explanations of action and causation from the axiom of identity, referring to causation as "the law of identity applied to action". According to Rand, it is entities that act, and every action is the action of an entity. The way entities act is caused by the specific nature (or "identity") of those entities; if they were different they would act differently. As with the other axioms, an implicit understanding of causation is derived from one's primary observations of causal connections among entities even before it is verbally identified, and serves as the basis of further knowledge.

According to Rand, attaining knowledge beyond what is given by perception requires both volition (or the exercise of free will) and performing a specific method of validation by observation, concept-formation, and the application of inductive and deductive reasoning. For example, a belief in dragons, however sincere, does not mean that reality includes dragons. A process of proof identifying the basis in reality of a claimed item of knowledge is necessary to establish its truth.

Objectivist epistemology begins with the principle that "consciousness is identification". This is understood to be a direct consequence of the metaphysical principle that "existence is identity". Rand defined "reason" as "the faculty that identifies and integrates the material provided by man's senses". Rand wrote "The fundamental concept of method, the one on which all the others depend, is logic. The distinguishing characteristic of logic (the art of non-contradictory identification) indicates the nature of the actions (actions of consciousness required to achieve a correct identification) and their goal (knowledge)—while omitting the length, complexity or specific steps of the process of logical inference, as well as the nature of the particular cognitive problem involved in any given instance of using logic."

According to Rand, consciousness possesses a specific and finite identity, just like everything else that exists; therefore, it must operate by a specific method of validation. An item of knowledge cannot be "disqualified" by being arrived at by a specific process in a particular form. Thus, for Rand, the fact that consciousness must itself possess identity implies the rejection of both universal skepticism based on the "limits" of consciousness, as well as any claim to revelation, emotion or faith based belief.

Objectivist epistemology maintains that all knowledge is ultimately based on perception. "Percepts, not sensations, are the given, the self-evident." Rand considered the validity of the senses to be axiomatic, and said that purported arguments to the contrary all commit the fallacy of the "stolen concept" by presupposing the validity of concepts that, in turn, presuppose the validity of the senses. She said that perception, being determined physiologically, is incapable of error. For example, optical illusions are errors in the conceptual identification of what is seen, not errors of sight itself. The validity of sense perception, therefore, is not susceptible to proof (because it is presupposed by all proof as proof is only a matter of adducing sensory evidence) nor should its validity be denied (since the conceptual tools one would have to use to do this are derived from sensory data). Perceptual error, therefore, is not possible. Rand consequently rejected epistemological skepticism, as she said that the skeptics' claim to knowledge "distorted" by the form or the means of perception is impossible.

The Objectivist theory of perception distinguishes between the "form" and "object." The form in which an organism perceives is determined by the physiology of its sensory systems. Whatever form the organism perceives it in, what it perceives—the object of perception—is reality. Rand consequently rejected the Kantian dichotomy between "things as we perceive them" and "things as they are in themselves". Rand wrote

The aspect of epistemology given the most elaboration by Rand is the theory of concept-formation, which she presented in "Introduction to Objectivist Epistemology". She argued that concepts are formed by a process of measurement omission. Peikoff described this as follows:
According to Rand, "the term 'measurements omitted' does not mean, in this context, that measurements are regarded as non-existent; it means that "measurements exist, but are not specified". That measurements "must" exist is an essential part of the process. The principle is: the relevant measurements must exist in "some" quantity, but may exist in "any" quantity."

Rand argued that concepts are organized hierarchically. Concepts such as 'dog,' which bring together "concretes" available in perception, can be differentiated (into the concepts of 'dachshund,' 'poodle,' etc.) or integrated (along with 'cat,' etc., into the concept of 'animal'). Abstract concepts such as 'animal' can be further integrated, via "abstraction from abstractions", into such concepts as 'living thing.' Concepts are formed in the context of knowledge available. A young child differentiates dogs from cats and chickens, but need not explicitly differentiate them from deep-sea tube worms, or from other types of animals not yet known to him, to form a concept 'dog'.

Because of its characterization of concepts as "open-ended" classifications that go well beyond the characteristics included in their past or current definitions, Objectivist epistemology rejects the analytic-synthetic distinction as a false dichotomy and denies the possibility of "a priori" knowledge.

Rand rejected "feeling" as sources of knowledge. Rand acknowledged the importance of emotion for human beings, but she maintained that emotions are a consequence of the conscious or subconscious ideas that a person already accepts, not a means of achieving awareness of reality. "Emotions are not tools of cognition." Rand also rejected all forms of faith or mysticism, terms that she used synonymously. She defined faith as "the acceptance of allegations without evidence or proof, either apart from or "against" the evidence of one's senses and reason... Mysticism is the claim to some non-sensory, non-rational, non-definable, non-identifiable means of knowledge, such as 'instinct,' 'intuition,' 'revelation,' or any form of 'just knowing.'" Reliance on revelation is like reliance on a Ouija board; it bypasses the need to show how it connects its results to reality. Faith, for Rand, is not a "short-cut" to knowledge, but a "short-circuit" destroying it.

Objectivism acknowledges the facts that human beings have limited knowledge, are vulnerable to error, and do not instantly understand all of the implications of their knowledge. According to Peikoff, one can be certain of a proposition if all of the available evidence verifies it, i.e., it can be logically integrated with the rest of one's knowledge; one is then certain within the context of the evidence.

Rand rejected the traditional rationalist/empiricist dichotomy, arguing that it embodies a false alternative: conceptually-based knowledge independent of perception (rationalism) versus perceptually-based knowledge independent of concepts (empiricism). Rand argued that neither is possible because the senses provide the material of knowledge while conceptual processing is also needed to establish knowable propositions.

The philosopher John Hospers, who was influenced by Rand and shared her moral and political opinions, disagreed with her concerning issues of epistemology. Some philosophers, such as Tibor Machan, have argued that the Objectivist epistemology is incomplete.

Psychology professor Robert L. Campbell writes that the relationship between Objectivist epistemology and cognitive science remains unclear because Rand made claims about human cognition and its development which belong to psychology, yet Rand also argued that philosophy is logically prior to psychology and in no way dependent on it.

The philosophers Randall Dipert and Roderick T. Long have argued that Objectivist epistemology conflates the perceptual process by which judgments are formed with the way in which they are to be justified, thereby leaving it unclear how sensory data can validate judgments structured propositionally.

Objectivism includes an extensive treatment of ethical concerns. Rand wrote on morality in her works "We the Living" (1936), "Atlas Shrugged" (1957) and "The Virtue of Selfishness" (1964). Rand defines morality as "a code of values to guide man's choices and actions—the choices and actions that determine the purpose and the course of his life". Rand maintained that the first question is not what should the code of values be, the first question is "Does man need values at all—and why?" According to Rand, "it is only the concept of 'Life' that makes the concept of 'Value' possible", and "the fact that a living entity "is", determines what it "ought" to do". Rand writes: "there is only one fundamental alternative in the universe: existence or non-existence—and it pertains to a single class of entities: to living organisms. The existence of inanimate matter is unconditional, the existence of life is not: it depends on a specific course of action. [...] It is only a living organism that faces a constant alternative: the issue of life or death".

Rand argued that the primary emphasis of man's free will is the choice: 'to think or not to think'. "Thinking is not an automatic function. In any hour and issue of his life, man is free to think or to evade that effort. Thinking requires a state of full, focused awareness. The act of focusing one's consciousness is volitional. Man can focus his mind to a full, active, purposefully directed awareness of reality—or he can unfocus it and let himself drift in a semiconscious daze, merely reacting to any chance stimulus of the immediate moment, at the mercy of his undirected sensory-perceptual mechanism and of any random, associational connections it might happen to make." According to Rand, therefore, possessing free will, human beings must "choose" their values: one does not "automatically" have one's own life as his ultimate value. Whether in fact a person's actions promote and fulfill his own life or not is a question of fact, as it is with all other organisms, but whether a person will act to promote his well-being is up to him, not hard-wired into his physiology. "Man has the power to act as his own destroyer—and that is the way he has acted through most of his history."

In "Atlas Shrugged", Rand wrote "Man's mind is his basic tool of survival. Life is given to him, survival is not. His body is given to him, its sustenance is not. His mind is given to him, its content is not. To remain alive he must act and before he can act he must know the nature and purpose of his action. He cannot obtain his food without knowledge of food and of the way to obtain it. He cannot dig a ditch—or build a cyclotron—without a knowledge of his aim and the means to achieve it. To remain alive, he must think." In her novels, "The Fountainhead" and "Atlas Shrugged", she also emphasizes the importance of productive work, romantic love and art to human happiness, and dramatizes the ethical character of their pursuit. The primary virtue in Objectivist ethics is rationality, as Rand meant it "the recognition and acceptance of reason as one's only source of knowledge, one's only judge of values and one's only guide to action".

The purpose of a moral code, Rand said, is to provide the principles by reference to which man can achieve the values his survival requires. Rand summarizes:
Rand's explanation of values presents the proposition that an individual's primary moral obligation is to achieve his own well-being—it is for his life and his self-interest that an individual ought to obey a moral code. Ethical egoism is a corollary of setting man's life as the moral standard. Rand believed that rational egoism is the logical consequence of humans following evidence to its logical conclusion. The only alternative would be that they live without orientation to reality.

A corollary to Rand's endorsement of self-interest is her rejection of the ethical doctrine of altruism—which she defined in the sense of Auguste Comte's altruism (he invented the term), as a moral obligation to live for the sake of others. Rand also rejected subjectivism. A "whim-worshiper" or "hedonist", according to Rand, is not motivated by a desire to live his own human life, but by a wish to live on a sub-human level. Instead of using "that which promotes my (human) life" as his standard of value, he mistakes "that which I (mindlessly happen to) value" for a standard of value, in contradiction of the fact that, existentially, he is a human and therefore rational organism. The "I value" in whim-worship or hedonism can be replaced with "we value", "he values", "they value", or "God values", and still it would remain dissociated from reality. Rand repudiated the equation of rational selfishness with hedonistic or whim-worshiping "selfishness-without-a-self". She said that the former is good, and the latter bad, and that there is a fundamental difference between them.

For Rand, all of the principal virtues are applications of the role of reason as man's basic tool of survival: rationality, honesty, justice, independence, integrity, productiveness, and pride—each of which she explains in some detail in "The Objectivist Ethics". The essence of Objectivist ethics is summarized by the oath her "Atlas Shrugged" character John Galt adhered to: "I swear—by my life and my love of it—that I will never live for the sake of another man, nor ask another man to live for mine."

Some philosophers have criticized Objectivist ethics. The philosopher Robert Nozick argues that Rand's foundational argument in ethics is unsound because it does not explain why someone could not rationally prefer dying and having no values, in order to further some particular value. He argues that her attempt to defend the morality of selfishness is, therefore, an instance of begging the question. Nozick also argues that Rand's solution to David Hume's famous is-ought problem is unsatisfactory. In response, the philosophers Douglas B. Rasmussen and Douglas Den Uyl have argued that Nozick misstated Rand's case.

Charles King criticized Rand's example of an indestructible robot to demonstrate the value of life as incorrect and confusing. In response, Paul St. F. Blair defended Rand's ethical conclusions, while maintaining that his arguments might not have been approved by Rand.

Rand's defense of individual liberty integrates elements from her entire philosophy. Since reason is the means of human knowledge, it is therefore each person's most fundamental means of survival and is necessary to the achievement of values. The use or threat of force neutralizes the practical effect of an individual's reason, whether the force originates from the state or from a criminal. According to Rand, "man's mind will not function at the point of a gun". Therefore, the only type of organized human behavior consistent with the operation of reason is that of voluntary cooperation. Persuasion is the method of reason. By its nature, the overtly irrational cannot rely on the use of persuasion and must ultimately resort to force to prevail. Thus, Rand argued that reason and freedom are correlates, just as she argued that mysticism and force are corollaries. Based on this understanding of the role of reason, Objectivists claim that the initiation of physical force against the will of another is immoral, as are indirect initiations of force through threats, fraud, or breach of contract. The use of defensive or retaliatory force, on the other hand, is appropriate.

Objectivism claims that because the opportunity to use reason without the initiation of force is necessary to achieve moral values, each individual has an inalienable moral right to act as his own judgment directs and to keep the product of his effort. Peikoff, explaining the basis of rights, stated, "In content, as the founding fathers recognized, there is one fundamental right, which has several major derivatives. The fundamental right is the right to life. Its major derivatives are the right to liberty, property, and the pursuit of happiness." "A 'right' is a moral principle defining and sanctioning a man's freedom of action in a social context." These rights are specifically understood to be rights to action, not to specific results or objects, and the obligations created by rights are negative in nature: each individual must refrain from violating the rights of others. Objectivists reject alternative notions of rights, such as positive rights, collective rights, or animal rights. Objectivism claims that the only social system which fully recognizes individual rights is capitalism, specifically what Rand described as "full, pure, uncontrolled, unregulated laissez-faire capitalism". Objectivism regards capitalism as the social system which is most beneficial to the poor, but does not consider this its primary justification. Rather, it is the only moral social system. Objectivism maintains that only societies seeking to establish freedom (or free nations) have a right to self-determination.

Objectivism describes government as "the means of placing the retaliatory use of physical force under objective control—i.e., under objectively defined laws"; thus, government is both legitimate and critically important in order to protect individual rights. Rand opposed anarchism because she considered that putting police and courts on the market is an inherent miscarriage of justice. Objectivism claims that the proper functions of a government are ""the police", to protect men from criminals—"the armed services", to protect men from foreign invaders—"the law courts", to settle disputes among men according to objective laws", the executive, and legislatures. Furthermore, in protecting individual rights, the government is acting as an agent of its citizens and "has no rights except the rights "delegated" to it by the citizens" and it must act in an impartial manner according to specific, objectively defined laws. Prominent Objectivists Peikoff and Yaron Brook have since expressed endorsement of other government functions.

Rand argued that limited intellectual property monopolies being granted to certain inventors and artists on a first-to-file basis are moral because she considered all property as fundamentally intellectual. Furthermore, the value of a commercial product derives in part from the necessary work of its inventors. However, Rand considered limits on patents and copyrights as important and said that if they were granted in perpetuity, it would necessarily result in "de facto" collectivism.

Rand opposed racism and any legal application of racism. She considered affirmative action to be an example of legal racism. Rand advocated the right to legal abortion. Rand believed capital punishment is morally justified as retribution against a murderer, but dangerous due to the risk of mistakenly executing innocent people and facilitating state murder. She therefore said she opposed capital punishment "on epistemological, not moral, grounds". She opposed involuntary military conscription. She opposed any form of censorship, including legal restrictions on pornography, opinion or worship, famously quipping; "In the transition to statism, every infringement of human rights has begun with a given right's least attractive practitioners".

Objectivists have also opposed a number of government activities commonly endorsed by both liberals and conservatives, including antitrust laws, the minimum wage, public education, and existing child labor laws. Objectivists have argued against faith-based initiatives, displaying religious symbols in government facilities, and the teaching of "intelligent design" in public schools. Rand opposed involuntary taxation and believed government could be financed voluntarily, although she thought this could only happen after other reforms of government were implemented.

Some critics, including economists and political philosophers such as Murray Rothbard, David D. Friedman, Roy Childs, Norman P. Barry, and Chandran Kukathas, have argued that Objectivist ethics are consistent with anarcho-capitalism instead of minarchism.

The Objectivist theory of art derives from its epistemology, by way of "psycho-epistemology" (Rand's term for an individual's characteristic mode of functioning in acquiring knowledge). Art, according to Objectivism, serves a human cognitive need: it allows human beings to understand concepts as though they were percepts. Objectivism defines "art" as a "selective re-creation of reality according to an artist's metaphysical value-judgments"—that is, according to what the artist believes to be ultimately true and important about the nature of reality and humanity. In this respect Objectivism regards art as a way of presenting abstractions concretely, in perceptual form.

The human need for art, according to this idea, derives from the need for cognitive economy. A concept is already a sort of mental shorthand standing for a large number of concretes, allowing a human being to think indirectly or implicitly of many more such concretes than can be kept explicitly in mind. But a human being cannot keep indefinitely many concepts explicitly in mind either—and yet, according to Objectivism, he or she needs a comprehensive conceptual framework to provide guidance in life. Art offers a way out of this dilemma by providing a perceptual, easily grasped means of communicating and thinking about a wide range of abstractions, including one's metaphysical value-judgments. Objectivism regards art as an effective way to communicate a moral or ethical ideal. Objectivism does not, however, regard art as propagandistic: even though art involves moral values and ideals, its purpose is not to educate, only to show or project. Moreover, art need not be, and usually is not, the outcome of a full-blown, explicit philosophy. Usually it stems from an artist's "sense of life" (which is preconceptual and largely emotional).

The end goal of Rand's own artistic endeavors was to portray the ideal man. "The Fountainhead" is the best example of this effort. Rand uses the character of Roark to embody the concept of the higher man which she believes is what great art should do – embody the characteristics of the best of humanity. This symbolism should be represented in all art; artistic expression should be an extension of the greatness in humanity.

Rand said that Romanticism was the highest school of literary art, noting that Romanticism was "based on the recognition of the principle that man possesses the faculty of volition", absent which, Rand believed, literature is robbed of dramatic power, adding:
The term "romanticism", however, is often affiliated with emotionalism, to which Objectivism is completely opposed. Historically, many romantic artists were philosophically subjectivist. Most Objectivists who are also artists subscribe to what they term romantic realism, which is how Rand described her own work.

Several authors have developed and applied Rand's ideas in their own work. Rand described Peikoff's "The Ominous Parallels" (1982), as "the first book by an Objectivist philosopher other than myself". During 1991, Peikoff published "", a comprehensive exposition of Rand's philosophy. Chris Matthew Sciabarra discusses Rand's ideas and theorizes about their intellectual origins in "" (1995). Surveys such as "On Ayn Rand" by Allan Gotthelf (1999), "Ayn Rand" by Tibor R. Machan (2000), and "Objectivism in One Lesson" by Andrew Bernstein (2009) provide briefer introductions to Rand's ideas.

Some scholars have emphasized applying Objectivism to more specific areas. Machan has developed Rand's contextual conception of human knowledge (while also drawing on the insights of J. L. Austin and Gilbert Harman) in works such as "Objectivity" (2004), and David Kelley has explicated Rand's epistemological ideas in works such as "The Evidence of the Senses" (1986) and "A Theory of Abstraction" (2001). Regarding the topic of ethics, Kelley has argued in works such as "Unrugged Individualism" (1996) and "The Contested Legacy of Ayn Rand" (2000) that Objectivists should pay more attention to the virtue of benevolence and place less emphasis on issues of moral sanction. Kelley's claims have been controversial, and critics Peikoff and Peter Schwartz have argued that he contradicts important principles of Objectivism. Kelley has used the term "Open Objectivism" for a version of Objectivism that involves "a commitment to reasoned, non-dogmatic discussion and debate", "the recognition that Objectivism is open to expansion, refinement, and revision", and "a policy of benevolence toward others, including fellow-travelers and critics". Arguing against Kelley, Peikoff characterized Objectivism as a "closed system" that is not subject to change.

An author who emphasizes Rand's ethics, Tara Smith, retains more of Rand's original ideas in such works as "Moral Rights and Political Freedom" (1995), "Viable Values" (2000), and "Ayn Rand's Normative Ethics" (2006). In collaboration with Peikoff, David Harriman has developed a theory of scientific induction based upon Rand's theory of concepts in "The Logical Leap: Induction in Physics" (2010).

The political aspects of Rand's philosophy are discussed by Bernstein in "The Capitalist Manifesto" (2005). In "Capitalism: A Treatise on Economics" (1996), George Reisman attempts to integrate Objectivist methodology and insights with both Classical and Austrian economics. In psychology, Professor Edwin A. Locke and Ellen Kenner have explored Rand's ideas in the publication "The Selfish Path to Romance: How to Love with Passion & Reason". Other writers have explored the application of Objectivism to fields ranging from art, as in "What Art Is" (2000) by Louis Torres and Michelle Marder Kamhi, to teleology, as in "The Biological Basis of Teleological Concepts" (1990) by Harry Binswanger.

According to one Rand biographer, most people first read Rand's works in their "formative years". Rand's former protégé Nathaniel Branden referred to Rand's "especially powerful appeal to the young", while Onkar Ghate of the Ayn Rand Institute said Rand "appeals to the idealism of youth". This appeal has alarmed a number of critics of the philosophy. Many of these young people later abandon their positive opinion of Rand and are often said to have "outgrown" her ideas. Endorsers of Rand's work recognize the phenomenon, but attribute it to the loss of youthful idealism and inability to resist social pressures for intellectual conformity. In contrast, historian Jennifer Burns, writing in "Goddess of the Market" (2009), writes some critics "dismiss Rand as a shallow thinker appealing only to adolescents", although she thinks the critics "miss her significance" as a "gateway drug" to right-wing politics.

Academic philosophers have generally dismissed Objectivism since Rand first presented it. Objectivism has been termed "fiercely anti-academic" because of Rand's criticism of contemporary intellectuals. David Sidorsky, a professor of moral and political philosophy at Columbia University, writes that Rand's work is "outside the mainstream" and is more of an ideology than a comprehensive philosophy. British philosopher Ted Honderich notes that he deliberately excluded an article on Rand from "The Oxford Companion to Philosophy" (Rand is, however, mentioned in the article on popular philosophy by Anthony Quinton). Rand is the subject of entries in the "Stanford Encyclopedia of Philosophy", "The Dictionary of Modern American Philosophers", the "Internet Encyclopedia of Philosophy", "The Routledge Dictionary of Twentieth-Century Political Thinkers", and "The Penguin Dictionary of Philosophy". Chandran Kukathas writes in an entry about Rand in the "Routledge Encyclopedia of Philosophy", "The influence of Rand's ideas was strongest among college students in the USA but attracted little attention from academic philosophers." Kukathas also writes that her defenses of capitalism and selfishness "kept her out of the intellectual mainstream".

During recent decades, Rand's works are more likely to be encountered in classrooms. The Ayn Rand Society, dedicated to fostering the scholarly study of Objectivism, is affiliated with the American Philosophical Association's Eastern Division. Aristotle scholar and Objectivist Allan Gotthelf, late chairman of the Society, and his colleagues argued for more academic study of Objectivism, considering the philosophy as a unique and intellectually interesting defense of classical liberalism that is worth debating. In 1999, a refereed "Journal of Ayn Rand Studies" began. Programs and fellowships for the study of Objectivism have been supported at the University of Pittsburgh, University of Texas at Austin and University of North Carolina at Chapel Hill.





</doc>
