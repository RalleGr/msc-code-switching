<doc id="13971" url="https://en.wikipedia.org/wiki?curid=13971" title="History of painting">
History of painting

The history of painting reaches back in time to artifacts from pre-historic humans, and spans all cultures. It represents a continuous, though periodically disrupted, tradition from Antiquity. Across cultures, and spanning continents and millennia, the history of painting is an ongoing river of creativity, that continues into the 21st century. Until the early 20th century it relied primarily on representational, religious and classical motifs, after which time more purely abstract and conceptual approaches gained favor.

Developments in Eastern painting historically parallel those in Western painting, in general, a few centuries earlier. African art, Jewish art, Islamic art, Indian art, Chinese art, and Japanese art each had significant influence on Western art, and vice versa.

Initially serving utilitarian purpose, followed by imperial, private, civic, and religious patronage, Eastern and Western painting later found audiences in the aristocracy and the middle class. From the Modern era, the Middle Ages through the Renaissance painters worked for the church and a wealthy aristocracy. Beginning with the Baroque era artists received private commissions from a more educated and prosperous middle class. Finally in the West the idea of "art for art's sake" began to find expression in the work of the Romantic painters like Francisco de Goya, John Constable, and J. M. W. Turner. The 19thcentury saw the rise of the commercial art gallery, which provided patronage in the 20th century.

The oldest known paintings are approximately 40,000 years old. José Luis Sanchidrián at the University of Cordoba, Spain, believes the paintings are more likely to have been painted by Neanderthals than early modern humans. Images at the Chauvet cave in France are thought to be about 32,000 years old. They are engraved and painted using red ochre and black pigment and show horses, rhinoceros, lions, buffalo, mammoth or humans often hunting. There are examples of cave paintings all over the world—in France, India, Spain, Southern Africa, China, Australia etc.

Various conjectures have been made as to the meaning these paintings had to the people that made them. Prehistoric artists may have painted animals to "catch" their soul or spirit in order to hunt them more easily or the paintings may represent an animistic vision and homage to surrounding nature. They may be the result of a basic need of expression that is innate to human beings, or they could have been for the transmission of practical information.
In Paleolithic times, the representation of humans in cave paintings was rare. Mostly, animals were painted, not only animals that were used as food but also animals that represented strength like the rhinoceros or large Felidae, as in the Chauvet Cave. Signs like dots were sometimes drawn. Rare human representations include handprints and stencils, and figures depicting human / animal hybrids. The Chauvet Cave in the Ardèche Departments of France contains the most important preserved cave paintings of the Paleolithic era, painted around 31,000 BC. The Altamira cave paintings in Spain were done 14,000 to 12,000 BC and show, among others, bisons. The hall of bulls in Lascaux, Dordogne, France, is one of the best known cave paintings and dates to about 15,000 to 10,000 BC.

If there is meaning to the paintings, it remains unknown. The caves were not in an inhabited area, so they may have been used for seasonal rituals. The animals are accompanied by signs which suggest a possible magic use. Arrow-like symbols in Lascaux are sometimes interpreted as being used as calendars or almanacs, but the evidence remains inconclusive. The most important work of the Mesolithic era were the "marching warriors", a rock painting at Cingle de la Mola, Castellón, Spain dated to about 7000 to 4000 BC. The technique used was probably spitting or blowing the pigments onto the rock. The paintings are quite naturalistic, though stylized. The figures are not three-dimensional, even though they overlap.

The earliest known Indian paintings were the rock paintings of prehistoric times, the petroglyphs as found in places like the Rock Shelters of Bhimbetka, and some of them are older than 5500 BC. Such works continued and after several millennia, in the 7th century, carved pillars of Ajanta, Maharashtra state present a fine example of Indian paintings. The colors, mostly various shades of red and orange, were derived from minerals.

The history of Eastern painting includes a vast range of influences from various cultures and religions. Developments in Eastern painting historically parallel those in Western painting, in general a few centuries earlier. African art, Jewish art, Islamic art, Indian art, Chinese art, Korean Art, and Japanese art each had significant influence on Western art, and, vice versa.

Chinese painting is one of the oldest continuous artistic traditions in the world. The earliest paintings were not representational but ornamental; they consisted of patterns or designs rather than pictures. Early pottery was painted with spirals, zigzags, dots, or animals. It was only during the Warring States period (403–221 B.C.) that artists began to represent the world around them. Japanese painting is one of the oldest and most highly refined of the Japanese arts, encompassing a wide variety of genre and styles. The history of Japanese painting is a long history of synthesis and competition between native Japanese aesthetics and adaptation of imported ideas. Korean painting, as an independent form, began around 108 B.C., around the fall of Gojoseon, making it one of the oldest in the world. The artwork of that time period evolved into the various styles that characterized the Three Kingdoms of Korea period, most notably the paintings and frescoes that adorn the tombs of Goguryeo's royalty. During the Three Kingdoms period and through the Goryeo dynasty, Korean painting was characterized primarily by a combination of Korean-style landscapes, facial features, Buddhist-centered themes, and an emphasis on celestial observation that was facilitated by the rapid development of Korean astronomy.

"See also Chinese painting, Japanese painting, Korean painting."

China, Japan and Korea have a strong tradition in painting which is also highly attached to the art of calligraphy and printmaking (so much that it is commonly seen as painting). Far east traditional painting is characterized by water based techniques, less realism, "elegant" and stylized subjects, graphical approach to depiction, the importance of white space (or negative space) and a preference for landscape (instead of the human figure) as a subject. Beyond ink and color on silk or paper scrolls, gold on lacquer was also a common medium in painted East Asian artwork. Although silk was a somewhat expensive medium to paint upon in the past, the invention of paper during the 1st century AD by the Han court eunuch Cai Lun provided not only a cheap and widespread medium for writing, but also a cheap and widespread medium for painting (making it more accessible to the public).

The ideologies of Confucianism, Daoism, and Buddhism played important roles in East Asian art. Medieval Song dynasty painters such as Lin Tinggui and his "Luohan Laundering" (housed in the Smithsonian Freer Gallery of Art) of the 12th century are excellent examples of Buddhist ideas fused into classical Chinese artwork. In the latter painting on silk (image and description provided in the link), bald-headed Buddhist Luohan are depicted in a practical setting of washing clothes by a river. However, the painting itself is visually stunning, with the Luohan portrayed in rich detail and bright, opaque colors in contrast to a hazy, brown, and bland wooded environment. Also, the tree tops are shrouded in swirling fog, providing the common "negative space" mentioned above in East Asian Art.

In Japonisme, late 19th-century Post-Impressionists like Van Gogh and Henri de Toulouse-Lautrec, and tonalists such as James McNeill Whistler, admired early 19th-century Japanese Ukiyo-e artists like Hokusai (1760–1849) and Hiroshige (1797–1858) and were influenced by them.

The earliest surviving examples of Chinese painted artwork date to the Warring States Period (481 – 221 BC), with paintings on silk or tomb murals on rock, brick, or stone. They were often in simplistic stylized format and in more-or-less rudimentary geometric patterns. They often depicted mythological creatures, domestic scenes, labor scenes, or palatial scenes filled with officials at court. Artwork during this period and the subsequent Qin Dynasty (221 – 207 BC) and Han Dynasty (202 BC – 220 AD) was made not as a means in and of itself or for higher personal expression; rather artwork was created to symbolize and honor funerary rites, representations of mythological deities or spirits of ancestors, etc. Paintings on silk of court officials and domestic scenes could be found during the Han Dynasty, along with scenes of men hunting on horseback or partaking in military parade. There was also painting on three dimensional works of art like figurines and statues, such as the original-painted colors covering the soldier and horse statues of the Terracotta Army. During the social and cultural climate of the ancient Eastern Jin Dynasty (316 – 420 AD) based at Nanjing in the south, painting became one of the official pastimes of Confucian-taught bureaucratic officials and aristocrats (along with music played by the guqin zither, writing fanciful calligraphy, and writing and reciting of poetry). Painting became a common form of artistic self-expression, and during this period painters at court or amongst elite social circuits were judged and ranked by their peers.
The establishment of classical Chinese landscape painting is accredited largely to the Eastern Jin Dynasty artist Gu Kaizhi (344 – 406 AD), one of the most famous artists of Chinese history. Like the elongated scroll scenes of Kaizhi, Tang dynasty (618 – 907 AD) Chinese artists like Wu Daozi painted vivid and highly detailed artwork on long horizontal handscrolls (which were very popular during the Tang), such as his "Eighty Seven Celestial People". Painted artwork during the Tang period pertained the effects of an idealized landscape environment, with sparse numbers of objects, persons, or amount of activity, as well as monochromatic in nature (example: the murals of Price Yide's tomb in the Qianling Mausoleum). There were also figures such as early Tang-era painter Zhan Ziqian, who painted superb landscape paintings that were well ahead of his day in portrayal of realism. However, landscape art did not reach greater level of maturity and realism in general until the Five Dynasties and Ten Kingdoms period (907 – 960 AD). During this time, there were exceptional landscape painters like Dong Yuan (refer to this article for an example of his artwork), and those who painted more vivid and realistic depictions of domestic scenes, like Gu Hongzhong and his "Night Revels of Han Xizai".
During the Chinese Song dynasty (960 – 1279 AD), not only landscape art was improved upon, but portrait painting became more standardized and sophisticated than before (for example, refer to Emperor Huizong of Song), and reached its classical age maturity during the Ming Dynasty (1368–1644 AD). During the late 13th century and first half of the 14th century, Chinese under the Mongol-controlled Yuan Dynasty were not allowed to enter higher posts of government (reserved for Mongols or other ethnic groups from Central Asia), and the Imperial examination was ceased for the time being. Many Confucian-educated Chinese who now lacked profession turned to the arts of painting and theatre instead, as the Yuan period became one of the most vibrant and abundant eras for Chinese artwork. An example of such would be Qian Xuan (1235–1305 AD), who was an official of the Song dynasty, but out of patriotism, refused to serve the Yuan court and dedicated himself to painting. Examples of superb art from this period include the rich and detailed painted murals of the Yongle Palace, or "Dachunyang Longevity Palace", of 1262 AD, a UNESCO World Heritage site. Within the palace, paintings cover an area of more than 1000 square meters, and hold mostly Daoist themes. It was during the Song dynasty that painters would also gather in social clubs or meetings to discuss their art or others' artwork, the praising of which often led to persuasions to trade and sell precious works of art. However, there were also many harsh critics of others art as well, showing the difference in style and taste amongst different painters. In 1088 AD, the polymath scientist and statesman Shen Kuo once wrote of the artwork of one Li Cheng, who he criticized as follows:

Although high level of stylization, mystical appeal, and surreal elegance were often preferred over realism (such as in shan shui style), beginning with the medieval Song dynasty there were many Chinese painters then and afterwards who depicted scenes of nature that were vividly real. Later Ming Dynasty artists would take after this Song dynasty emphasis for intricate detail and realism on objects in nature, especially in depictions of animals (such as ducks, swans, sparrows, tigers, etc.) amongst patches of brightly colored flowers and thickets of brush and wood (a good example would be the anonymous Ming Dynasty painting "Birds and Plum Blossoms", housed in the Freer Gallery of the Smithsonian Museum in Washington, D.C.). There were many renowned Ming Dynasty artists; Qiu Ying is an excellent example of a paramount Ming era painter (famous even in his own day), utilizing in his artwork domestic scenes, bustling palatial scenes, and nature scenes of river valleys and steeped mountains shrouded in mist and swirling clouds. During the Ming Dynasty there were also different and rivaling schools of art associated with painting, such as the Wu School and the Zhe School.

Classical Chinese painting continued on into the early modern Qing Dynasty, with highly realistic portrait paintings like seen in the late Ming Dynasty of the early 17th century. The portraits of Kangxi Emperor, Yongzheng Emperor, and Qianlong Emperor are excellent examples of realistic Chinese portrait painting. During the Qianlong reign period and the continuing 19th century, European Baroque styles of painting had noticeable influence on Chinese portrait paintings, especially with painted visual effects of lighting and shading. Likewise, East Asian paintings and other works of art (such as porcelain and lacquerware) were highly prized in Europe since initial contact in the 16th century.

Western techniques of oil paintings began entering China in the 19th century, becoming prevalent among Chinese artists and art students in the early 20th century, coinciding with China's growing engagement with the West. Artists such as Li Tiefu, Hong Yi, Xu Beihong, Yan Wenliang, Lin Fengmian, Fang Ganmin, Pang Yuliang went abroad, predominantly to Paris and Tokyo, to learn Western art. Through them, artistic movements such as Impressionism, Cubism, Fauvism, Post-impressionism grew and thrived in China, only halted by the Second World War and the birth of the People's Republic of China, when modernistic artistic styles were seen as being inconsistent with the prevailing political ideals and realism was the only acceptable artistic form. Nonetheless, the legacy of the close engagement with Western art in the early 20th century endured. Oil paintings survived as a important medium in Chinese artistic scenes; traditional Chinese ink paintings were also changed as a result. 
Japanese painting (絵画) is one of the oldest and most highly refined of the Japanese arts, encompassing a wide variety of genres and styles. As with Japanese arts in general, Japanese painting developed through a long history of synthesis and competition between native Japanese aesthetics and adaptation of imported ideas. Ukiyo-e, or "pictures of the floating world," is a genre of Japanese woodblock prints (or "woodcuts") and paintings produced between the 17th and 20th centuries, featuring motifs of landscapes, theater, and courtesan districts. It is the main artistic genre of Japanese woodblock printing. Japanese printmaking, especially from the Edo period, exerted enormous influence on French painting over the 19th century.

Korean painting, as an independent form, began around 108 B.C., around the fall of Gojoseon, making it one of the oldest in the world. The artwork of that time period evolved into the various styles that characterized the Three Kingdoms of Korea period, most notably the paintings and frescoes that adorn the tombs of Goguryeo's royalty. During the Three Kingdoms period and through the Goryeo dynasty, Korean painting was characterized primarily by a combination of Korean-style landscapes, facial features, Buddhist-centered themes, and an emphasis on celestial observation that was facilitated by the rapid development of Korean astronomy. It wasn't until the Joseon dynasty that Confucian themes began to take root in Korean paintings, used in harmony with indigenous aspects.

The history of Korean painting has been characterized by the use monochromatic works of black brushwork, often on mulberry paper or silk. This style is evident in "Min-Hwa", or colorful folk art, tomb paintings, and ritual and festival arts, both of which incorporated an extensive use of colour.

Indian paintings historically revolved around the religious deities and kings. Indian art is a collective term for several different schools of art that existed in the Indian subcontinent. The paintings varied from large frescoes of Ajanta to the intricate Mughal miniature paintings to the metal embellished works from the Tanjore school. The paintings from the Gandhar–Taxila are influenced by the Persian works in the west. The eastern style of painting was mostly developed around the Nalanda school of art. The works are mostly inspired by various scenes from Indian mythology.

The earliest Indian paintings were the rock paintings of prehistoric times, the petroglyphs as found in places like the Rock Shelters of Bhimbetka, and some of them are older than 5500 BC. Such works continued and after several millennia, in the 7th century, carved pillars of Ajanta, Maharashtra state present a fine example of Indian paintings, and the colors, mostly various shades of red and orange, were derived from minerals.

Ajanta Caves in Maharashtra, India are rock-cut cave monuments dating back to the 2nd century BCE and containing paintings and sculpture considered to be masterpieces of both Buddhist religious art and universal pictorial art.

Madhubani painting is a style of Indian painting, practiced in the Mithila region of Bihar state, India. The origins of Madhubani painting are shrouded in antiquity.

Mughal painting is a particular style of Indian painting, generally confined to illustrations on the book and done in miniatures, and which emerged, developed and took shape during the period of the Mughal Empire 16th −19th centuries.

Rajput painting evolved and flourished during the 18th century, in the royal courts of Rajputana, India. Each Rajput kingdom evolved a distinct style, but with certain common features. Rajput paintings depict a number of themes, events of epics like the Ramayana and the Mahabharata, Krishna's life, beautiful landscapes, and humans. Miniatures were the preferred medium of Rajput painting, but several manuscripts also contain Rajput paintings, and paintings were even done on the walls of palaces, inner chambers of the forts, havelies, particularly, the havelis of Shekhawait.

The colors extracted from certain minerals, plant sources, conch shells, and were even derived by processing precious stones, gold and silver were used. The preparation of desired colors was a lengthy process, sometimes taking weeks. Brushes used were very fine.

Tanjore painting is an important form of classical South Indian painting native to the town of Tanjore in Tamil Nadu. The art form dates back to the early 9th century, a period dominated by the Chola rulers, who encouraged art and literature. These paintings are known for their elegance, rich colors, and attention to detail. The themes for most of these paintings are Hindu Gods and Goddesses and scenes from Hindu mythology. In modern times, these paintings have become a much sought after souvenir during festive occasions in South India.

The process of making a Tanjore painting involves many stages. The first stage involves the making of the preliminary sketch of the image on the base. The base consists of a cloth pasted over a wooden base. Then chalk powder or zinc oxide is mixed with water-soluble adhesive and applied on the base. To make the base smoother, a mild abrasive is sometimes used. After the drawing is made, decoration of the jewellery and the apparels in the image is done with semi-precious stones. Laces or threads are also used to decorate the jewellery. On top of this, the gold foils are pasted. Finally, dyes are used to add colors to the figures in the paintings.

During British rule in India, the crown found that Madras had some of the most talented and intellectual artistic minds in the world. As the British had also established a huge settlement in and around Madras, Georgetown was chosen to establish an institute that would cater to the artistic expectations of the royal family in London. This has come to be known as the Madras School. At first traditional artists were employed to produce exquisite varieties of furniture, metal work, and curios and their work was sent to the royal palaces of the Queen.

Unlike the Bengal School where 'copying' is the norm of teaching, the Madras School flourishes on 'creating' new styles, arguments and trends.

The Bengal school of art was an influential style of art that flourished in India during the British Raj in the early 20th century. It was associated with Indian nationalism, but was also promoted and supported by many British arts administrators.

The Bengal School arose as an avant garde and nationalist movement reacting against the academic art styles previously promoted in India, both by Indian artists such as Raja Ravi Varma and in British art schools. Following the widespread influence of Indian spiritual ideas in the West, the British art teacher Ernest Binfield Havel attempted to reform the teaching methods at the Calcutta School of Art by encouraging students to imitate Mughal miniatures. This caused immense controversy, leading to a strike by students and complaints from the local press, including from nationalists who considered it to be a retrogressive move. Havel was supported by the artist Abanindranath Tagore, a nephew of the poet Rabindranath Tagore. Tagore painted a number of works influenced by Mughal art, a style that he and Havel believed to be expressive of India's distinct spiritual qualities, as opposed to the "materialism" of the West. Tagore's best-known painting, "Bharat Mata" (Mother India), depicted a young woman, portrayed with four arms in the manner of Hindu deities, holding objects symbolic of India's national aspirations. Tagore later attempted to develop links with Japanese artists as part of an aspiration to construct a pan-Asianist model of art.

The Bengal School's influence in India declined with the spread of modernist ideas in the 1920s. In the post-independence period, Indian artists showed more adaptability as they borrowed freely from European styles and amalgamated them freely with the Indian motifs to new forms of art. While artists like Francis Newton Souza and Tyeb Mehta were more western in their approach, there were others like Ganesh Pyne and Maqbool Fida Husain who developed thoroughly indigenous styles of work. Today after the process of liberalization of market in India, the artists are experiencing more exposure to the international art-scene which is helping them in emerging with newer forms of art which were hitherto not seen in India. Jitish Kallat had shot to fame in the late 1990s with his paintings which were both modern and beyond the scope of generic definition. However, while artists in India in the new century are trying out new styles, themes and metaphors, it would not have been possible to get such quick recognition without the aid of the business houses which are now entering the art field like they had never before.

Amrita Sher-Gil was an Indian painter, sometimes known as India's Frida Kahlo, and today considered an important woman painter of 20th-century India, whose legacy stands at par with that of the Masters of Bengal Renaissance; she is also the 'most expensive' woman painter of India.

Today, she is amongst "Nine Masters", whose work was declared as "art treasures" by The Archaeological Survey of India, in 1976 and 1979, and over 100 of her paintings are now displayed at National Gallery of Modern Art, New Delhi.

During the colonial era, Western influences started to make an impact on Indian art. Some artists developed a style that used Western ideas of composition, perspective and realism to illustrate Indian themes. Others, like Jamini Roy, consciously drew inspiration from folk art.

By the time of Independence in 1947, several schools of art in India provided access to modern techniques and ideas. Galleries were established to showcase these artists. Modern Indian art typically shows the influence of Western styles, but is often inspired by Indian themes and images. Major artists are beginning to gain international recognition, initially among the Indian diaspora, but also among non-Indian audiences.

The Progressive Artists' Group, established shortly after India became independent in 1947, was intended to establish new ways of expressing India in the post-colonial era. The founders were six eminent artists – K. H. Ara, S. K. Bakre, H. A. Gade, M.F. Husain, S.H. Raza and F. N. Souza, though the group was dissolved in 1956, it was profoundly influential in changing the idiom of Indian art. Almost all India's major artists in the 1950s were associated with the group. Some of those who are well-known today are Bal Chabda, Manishi Dey, Mukul Dey, V. S. Gaitonde, Ram Kumar, Tyeb Mehta, and Akbar Padamsee. Other famous painters like Jahar Dasgupta, Prokash Karmakar, John Wilkins, Narayanan Ramachandran, and Bijon Choudhuri enriched the art culture of India. They have become the icons of modern Indian art. Art historians like Prof. Rai Anand Krishna have also referred to those works of modern artistes that reflect Indian ethos. Geeta Vadhera has had acclaim in translating complex, Indian spiritual themes onto canvas like Sufi thought, the Upanishads and the Bhagwad Geeta.

Indian art got a boost with the economic liberalization of the country since the early 1990s. Artists from various fields now started bringing in varied styles of work. In post-liberalization India, many artists have established themselves in the international art market like the abstract painter Natvar Bhavsar, figurative artist Devajyoti Ray and sculptor Anish Kapoor whose mammoth postminimalist artworks have acquired attention for their sheer size. Many art houses and galleries have also opened in USA and Europe to showcase Indian artworks.

Filipino painting as a whole can be seen as an amalgamation of many cultural influences, though it tends to be more Western in its current form with Eastern roots.

Early Filipino painting can be found in red slip (clay mixed with water) designs embellished on the ritual pottery of the Philippines such as the acclaimed Manunggul Jar. Evidence of Philippine pottery-making dated as early as 6000BC has been found in Sanga-sanga Cave, Sulu and Laurente Cave, Cagayan. It has been proven that by 5000BC, the making of pottery was practiced throughout the country. Early Filipinos started making pottery before their Cambodian neighbors and at about the same time as the Thais as part of what appears to be a widespread Ice Age development of pottery technology. Further evidences of painting are manifested in the tattoo tradition of early Filipinos, whom the Portuguese explorer referred to as "Pintados" or the 'Painted People' of the Visayas. Various designs referencing flora and fauna with heavenly bodies decorate their bodies in various colored pigmentation. Perhaps, some of the most elaborate painting done by early Filipinos that survive to the present day can be manifested among the arts and architecture of the Maranao who are well known for the Nāga Dragons and the Sarimanok carved and painted in the beautiful Panolong of their Torogan or King's House.

Filipinos began creating paintings in the European tradition during the 17th-century Spanish period. The earliest of these paintings were Church frescoes, religious imagery from Biblical sources, as well as engravings, sculptures and lithographs featuring Christian icons and European nobility. Most of the paintings and sculptures between the 19th, and 20th century produced a mixture of religious, political, and landscape art works, with qualities of sweetness, dark, and light. Early modernist painters such as Damián Domingo was associated with religious and secular paintings. The art of Juan Luna and Félix Hidalgo showed a trend for political statement. Artist such as Fernando Amorsolo used post-modernism to produce paintings that illustrated Philippine culture, nature, and harmony. While other artists such as Fernando Zóbel used realities and abstract on his work.
Ancient Egypt, a civilization with very strong traditions of architecture and sculpture (both originally painted in bright colours) also had many mural paintings in temples and buildings, and painted illustrations on papyrus manuscripts. Egyptian wall painting and decorative painting is often graphic, sometimes more symbolic than realistic. Egyptian painting depicts figures in bold outline and flat silhouette, in which symmetry is a constant characteristic. Egyptian painting has close connection with its written language – called Egyptian hieroglyphs. Painted symbols are found amongst the first forms of written language. The Egyptians also painted on linen, remnants of which survive today. Ancient Egyptian paintings survived due to the extremely dry climate. The ancient Egyptians created paintings to make the afterlife of the deceased a pleasant place. The themes included journey through the afterworld or their protective deities introducing the deceased to the gods of the underworld. Some examples of such paintings are paintings of the gods and goddesses Ra, Horus, Anubis, Nut, Osiris and Isis. Some tomb paintings show activities that the deceased were involved in when they were alive and wished to carry on doing for eternity. In the New Kingdom and later, the "Book of the Dead" was buried with the entombed person. It was considered important for an introduction to the afterlife.
To the north of Egypt was the Minoan civilization centered on the island of Crete. The wall paintings found in the palace of Knossos are similar to that of the Egyptians but much more free in style. Mycenaean Greece, beginning around 1600 BC, produced similar art to that of Minoan Crete. Ancient Greek art during the Greek Dark Age became far less complex, but the renewal of Greek civilization throughout the Mediterranean during Archaic Greece brought about new forms of Greek art with the Orientalizing style.
Ancient Greece had skilled painters, sculptors (though both endeavours were regarded as mere manual labour at the time), and architects. The Parthenon is an example of their architecture that has lasted to modern days. Greek marble sculpture is often described as the highest form of Classical art. Painting on pottery of Ancient Greece and ceramics gives a particularly informative glimpse into the way society in Ancient Greece functioned. Black-figure vase painting and Red-figure vase painting gives many surviving examples of what Greek painting was. Some famous Greek painters on wooden panels who are mentioned in texts are Apelles, Zeuxis and Parrhasius, however no examples of Ancient Greek panel painting survive, only written descriptions by their contemporaries or later Romans. Zeuxis lived in 5–6BC and was said to be the first to use sfumato. According to Pliny the Elder, the realism of his paintings was such that birds tried to eat the painted grapes. Apelles is described as the greatest painter of Antiquity for perfect technique in drawing, brilliant color and modeling.

Roman art was influenced by Greece and can in part be taken as a descendant of ancient Greek painting. However, Roman painting does have important unique characteristics. Surviving Roman paintings include wall paintings and frescoes, many from villas in Campania, in Southern Italy at sites such as Pompeii and Herculaneum. Such painting can be grouped into four main "styles" or periods and may contain the first examples of "trompe-l'œil", pseudo-perspective, and pure landscape. Almost the only painted portraits surviving from the Ancient world are a large number of coffin-portraits of bust form found in the Late Antique cemetery of Al-Fayum. Although these were neither of the best period nor the highest quality, they are impressive in themselves, and give an idea of the quality that the finest ancient work must have had. A very small number of miniatures from Late Antique illustrated books also survive, and a rather larger number of copies of them from the Early Medieval period.

The rise of Christianity imparted a different spirit and aim to painting styles. Byzantine art, once its style was established by the 6th century, placed great emphasis on retaining traditional iconography and style, and gradually evolved during the thousand years of the Byzantine Empire and the living traditions of Greek and Russian Orthodox icon-painting. Byzantine painting has a hieratic feeling and icons were and still are seen as a representation of divine revelation. There were many frescos, but fewer of these have survived than mosaics.
Byzantine art has been compared to contemporary abstraction, in its flatness and highly stylised depictions of figures and landscape. Some periods of Byzantine art, especially the so-called Macedonian art of around the 10th century, are more flexible in approach. Frescos of the Palaeologian Renaissance of the early 14th century survive in the Chora Church in Istanbul.

In post-Antique Catholic Europe the first distinctive artistic style to emerge that included painting was the Insular art of the British Isles, where the only surviving examples are miniatures in Illuminated manuscripts such as the Book of Kells. These are most famous for their abstract decoration, although figures, and sometimes scenes, were also depicted, especially in Evangelist portraits. Carolingian and Ottonian art also survives mostly in manuscripts, although some wall-painting remain, and more are documented. The art of this period combines Insular and "barbarian" influences with a strong Byzantine influence and an aspiration to recover classical monumentality and poise.

Walls of Romanesque and Gothic churches were decorated with frescoes as well as sculpture and many of the few remaining murals have great intensity, and combine the decorative energy of Insular art with a new monumentality in the treatment of figures. Far more miniatures in Illuminated manuscripts survive from the period, showing the same characteristics, which continue into the Gothic period.

Panel painting becomes more common during the Romanesque period, under the heavy influence of Byzantine icons. Towards the middle of the 13th century, Medieval art and Gothic painting became more realistic, with the beginnings of interest in the depiction of volume and perspective in Italy with Cimabue and then his pupil Giotto. From Giotto on, the treatment of composition by the best painters also became much more free and innovative. They are considered to be the two great medieval masters of painting in western culture. Cimabue, within the Byzantine tradition, used a more realistic and dramatic approach to his art. His pupil, Giotto, took these innovations to a higher level which in turn set the foundations for the western painting tradition. Both artists were pioneers in the move towards naturalism.

Churches were built with more and more windows and the use of colorful stained glass become a staple in decoration. One of the most famous examples of this is found in the cathedral of Notre Dame de Paris. By the 14th century Western societies were both richer and more cultivated and painters found new patrons in the nobility and even the bourgeoisie. Illuminated manuscripts took on a new character and slim, fashionably dressed court women were shown in their landscapes. This style soon became known as International style and tempera panel paintings and altarpieces gained importance.

The Renaissance (French for 'rebirth'), a cultural movement roughly spanning the 14th through the mid-17th century, heralded the study of classical sources, as well as advances in science which profoundly influenced European intellectual and artistic life. In the Low Countries, especially in modern day Flanders, a new way of painting was established in the beginning of the 15th century. In the footsteps of the developments made in the illumination of manuscripts, especially by the Limbourg Brothers, artists became fascinated by the tangible in the visible world and began representing objects in an extremely naturalistic way. The adoption of oil painting whose invention was traditionally, but erroneously, credited to Jan van Eyck, made possible a new verisimilitude in depicting this naturalism. The medium of oil paint was already present in the work of Melchior Broederlam, but painters like Jan van Eyck and Robert Campin brought its use to new heights and employed it to represent the naturalism they were aiming for. With this new medium the painters of this period were capable of creating richer colors with a deep intense tonality. The illusion of glowing light with a porcelain-like finish characterized Early Netherlandish painting and was a major difference to the matte surface of tempera paint used in Italy. Unlike the Italians, whose work drew heavily from the art of Ancient Greece and Rome, the northerners retained a stylistic residue of the sculpture and illuminated manuscripts of the Middle Ages (especially its naturalism). The most important artist of this time was Jan van Eyck, whose work ranks among the finest made by artists who are now known as Early Netherlandish painters or Flemish Primitives (since most artists were active in cities in modern day Flanders). The first painter of this period was the Master of Flémalle, nowadays identified as Robert Campin, whose work follows the art of the International Gothic. Another important painter of this period was Rogier van der Weyden, whose compositions stressed human emotion and drama, demonstrated for instance in his Descent from the Cross, which ranks among the most famous works of the 15th century and was the most influential Netherlandish painting of Christ's crucifixion. Other important artists from this period are Hugo van der Goes (whose work was highly influential in Italy), Dieric Bouts (who was among the first northern painters to demonstrate the use of a single vanishing point), Petrus Christus, Hans Memling and Gerard David.

In Italy, the art of Classical antiquity inspired a style of painting that emphasized the ideal. Artists such as Paolo Uccello, Masaccio, Fra Angelico, Piero della Francesca, Andrea Mantegna, Filippo Lippi, Sandro Botticelli, Leonardo da Vinci, Michelangelo Buonarroti, and Raphael took painting to a higher level through the use of perspective, the study of human anatomy and proportion, and through their development of an unprecedented refinement in drawing and painting techniques. A somewhat more naturalistic style emerged in Venice. Painters of the Venetian school, such as Giovanni Bellini, Giorgione, Titian, Tintoretto, and Veronese, were less concerned with precision in their drawing than with the richness of color and unity of effect that could be achieved by a more spontaneous approach to painting.

Flemish, Dutch and German painters of the Renaissance such as Hans Holbein the Younger, Albrecht Dürer, Lucas Cranach, Matthias Grünewald, Hieronymous Bosch, and Pieter Bruegel represent a different approach from their Italian colleagues, one that is more realistic and less idealized. Genre painting became a popular idiom amongst the Northern painters like Pieter Bruegel.

Renaissance painting reflects the revolution of ideas and science (astronomy, geography) that occurred in this period, the Reformation, and the invention of the printing press. Dürer, considered one of the greatest of printmakers, states that painters are not mere artisans but thinkers as well. With the development of easel painting in the Renaissance, painting gained independence from architecture. Easel paintings—movable pictures which could be hung easily on walls—became a popular alternative to paintings fixed to furniture, walls or other structures. Following centuries dominated by religious imagery, secular subject matter slowly returned to Western painting. Artists included visions of the world around them, or the products of their own imaginations in their paintings. Those who could afford the expense could become patrons and commission portraits of themselves or their family.

The High Renaissance gave rise to a stylized art known as Mannerism. In place of the balanced compositions and rational approach to perspective that characterized art at the dawn of the 16th century, the Mannerists sought instability, artifice, and doubt. The unperturbed faces and gestures of Piero della Francesca and the calm Virgins of Raphael are replaced by the troubled expressions of Pontormo and the emotional intensity of El Greco. Restless and unstable compositions, often extreme or disjunctive effects of perspective, and stylized poses are characteristic of Italian Mannerists such as Tintoretto, Pontormo, and Bronzino, and appeared later in the work of Northern Mannerists such as Hendrick Goltzius, Bartholomeus Spranger, and Joachim Wtewael.

Baroque painting is associated with the Baroque cultural movement, a movement often identified with Absolutism and the Counter Reformation or Catholic Revival; the existence of important Baroque painting in non-absolutist and Protestant states also, however, underscores its popularity, as the style spread throughout Western Europe.

Baroque painting is characterized by great drama, rich, deep color, and intense light and dark shadows. Baroque art was meant to evoke emotion and passion instead of the calm rationality that had been prized during the Renaissance. During the period beginning around 1600 and continuing throughout the 17th century, painting is characterized as Baroque. Among the greatest painters of the Baroque are Caravaggio, Rembrandt, Frans Hals, Rubens, Velázquez, Poussin, and Johannes Vermeer. Caravaggio is an heir of the humanist painting of the High Renaissance. His realistic approach to the human figure, painted directly from life and dramatically spotlit against a dark background, shocked his contemporaries and opened a new chapter in the history of painting.
Baroque painting often dramatizes scenes using light effects; this can be seen in works by Rembrandt, Vermeer, Le Nain, La Tour, and Jusepe de Ribera.
In Italy, the Baroque style is epitomized by religious and mythological paintings in the Grand Manner by artists such as the Carracci, Guido Reni, and Luca Giordano. Illusionistic church ceiling frescoes by Pietro da Cortona seemed to open to the sky. A much quieter type of Baroque emerged in the Dutch Republic, where easel paintings of everyday subjects were popular with middle-class collectors, and many painters became specialists in genre, others in landscape or seascape or still life. Vermeer, Gerard ter Borch, and Pieter de Hooch brought great technical refinement to the painting of domestic scenes, as did Willem Claesz. Heda to still life. In contrast, Rembrandt excelled in painting every type of subject, and developed an individual painterly style in which the chiaroscuro and dark backgrounds derived from Caravaggio and the Utrecht Caravaggists lose their theatrical quality.

During the 18th century, Rococo followed as a lighter extension of Baroque, often frivolous and erotic. Rococo developed first in the decorative arts and interior design in France. Louis XV's succession brought a change in the court artists and general artistic fashion. The 1730s represented the height of Rococo development in France exemplified by the works of Antoine Watteau and François Boucher. Rococo still maintained the Baroque taste for complex forms and intricate patterns, but by this point, it had begun to integrate a variety of diverse characteristics, including a taste for Oriental designs and asymmetric compositions.

The Rococo style spread with French artists and engraved publications. It was readily received in the Catholic parts of Germany, Bohemia, and Austria, where it was merged with the lively German Baroque traditions. German Rococo was applied with enthusiasm to churches and palaces, particularly in the south, while Frederician Rococo developed in the Kingdom of Prussia.

The French masters Watteau, Boucher and Fragonard represent the style, as do Giovanni Battista Tiepolo and Jean-Baptiste-Siméon Chardin who was considered by some as the best French painter of the 18th century – the "Anti-Rococo". Portraiture was an important component of painting in all countries, but especially in England, where the leaders were William Hogarth, in a blunt realist style, and Francis Hayman, Angelica Kauffman (who was Swiss), Thomas Gainsborough and Joshua Reynolds in more flattering styles influenced by Anthony van Dyck. In France during the Rococo era Jean-Baptiste Greuze (the favorite painter of Denis Diderot), excelled in portraits and history paintings, and Maurice Quentin de La Tour and Élisabeth Vigée-Lebrun were highly accomplished portrait painters. La Tour specialized in pastel painting, which became a popular medium during this period.

William Hogarth helped develop a theoretical foundation for Rococo beauty. Though not intentionally referencing the movement, he argued in his "Analysis of Beauty" (1753) that the undulating lines and S-curves prominent in Rococo were the basis for grace and beauty in art or nature (unlike the straight line or the circle in Classicism). The beginning of the end for Rococo came in the early 1760s as figures like Voltaire and Jacques-François Blondel began to voice their criticism of the superficiality and degeneracy of the art. Blondel decried the "ridiculous jumble of shells, dragons, reeds, palm-trees and plants" in contemporary interiors.

By 1785, Rococo had passed out of fashion in France, replaced by the order and seriousness of Neoclassical artists like Jacques-Louis David.

After Rococo there arose in the late 18th century, in architecture, and then in painting severe neo-classicism, best represented by such artists as David and his heir Ingres. Ingres' work already contains much of the sensuality, but none of the spontaneity, that was to characterize Romanticism.
This movement turned its attention toward landscape and nature as well as the human figure and the supremacy of natural order above mankind's will. There is a pantheist philosophy (see Spinoza and Hegel) within this conception that opposes Enlightenment ideals by seeing mankind's destiny in a more tragic or pessimistic light. The idea that human beings are not above the forces of Nature is in contradiction to Ancient Greek and Renaissance ideals where mankind was above all things and owned his fate. This thinking led romantic artists to depict the sublime, ruined churches, shipwrecks, massacres and madness.

By the mid-19th-century painters became liberated from the demands of their patronage to only depict scenes from religion, mythology, portraiture or history. The idea "art for art's sake" began to find expression in the work of painters like Francisco de Goya, John Constable, and J.M.W. Turner. Romantic painters saw landscape painting as an important genre to express the vanity of mankind in opposition to the grandeur of nature. Until then, landscape painting wasn't considered the most important genre for painters (like portraiture or history painting). But painters like J.M.W. Turner and Caspar David Friedrich managed to elevate landscape painting to an eminence rivalling history painting.
Some of the major painters of this period are Eugène Delacroix, Théodore Géricault, J. M. W. Turner, Caspar David Friedrich and John Constable. Francisco de Goya's late work demonstrates the Romantic interest in the irrational, while the work of Arnold Böcklin evokes mystery and the paintings of Aesthetic movement artist James McNeill Whistler evoke both sophistication and decadence. In the United States the Romantic tradition of landscape painting was known as the Hudson River School: exponents include Thomas Cole, Frederic Edwin Church, Albert Bierstadt, Thomas Moran, and John Frederick Kensett. Luminism was a movement in American landscape painting related to the Hudson River School.

The leading Barbizon School painter Camille Corot painted in both a romantic and a realistic vein; his work prefigures Impressionism, as does the paintings of Eugène Boudin who was one of the first French landscape painters to paint outdoors. Boudin was also an important influence on the young Claude Monet, whom in 1857 he introduced to Plein air painting. A major force in the turn towards Realism at mid-century was Gustave Courbet. In the latter third of the century Impressionists like Édouard Manet, Claude Monet, Pierre-Auguste Renoir, Camille Pissarro, Alfred Sisley, Berthe Morisot, Mary Cassatt, and Edgar Degas worked in a more direct approach than had previously been exhibited publicly. They eschewed allegory and narrative in favor of individualized responses to the modern world, sometimes painted with little or no preparatory study, relying on deftness of drawing and a highly chromatic pallette. Manet, Degas, Renoir, Morisot, and Cassatt concentrated primarily on the human subject. Both Manet and Degas reinterpreted classical figurative canons within contemporary situations; in Manet's case the re-imaginings met with hostile public reception. Renoir, Morisot, and Cassatt turned to domestic life for inspiration, with Renoir focusing on the female nude. Monet, Pissarro, and Sisley used the landscape as their primary motif, the transience of light and weather playing a major role in their work. While Sisley most closely adhered to the original principals of the Impressionist perception of the landscape, Monet sought challenges in increasingly chromatic and changeable conditions, culminating in his series of monumental works of Water Lilies painted in Giverny.

Pissarro adopted some of the experiments of Post-Impressionism. Slightly younger Post-Impressionists like Vincent van Gogh, Paul Gauguin, and Georges Seurat, along with Paul Cézanne led art to the edge of modernism; for Gauguin Impressionism gave way to a personal symbolism; Seurat transformed Impressionism's broken color into a scientific optical study, structured on frieze-like
compositions; Van Gogh's turbulent method of paint application, coupled with a sonorous use of color, predicted Expressionism and Fauvism, and Cézanne, desiring to unite classical composition with a revolutionary abstraction of natural forms, would come to be seen as a precursor of 20th-century art.
The spell of Impressionism was felt throughout the world, including in the United States, where it became integral to the painting of American Impressionists such as Childe Hassam, John Twachtman, and Theodore Robinson; and in Australia where painters of the Heidelberg School such as Arthur Streeton, Frederick McCubbin and Charles Conder painted "en plein air" and were particularly interested in the Australian landscape and light. It also exerted influence on painters who were not primarily Impressionistic in theory, like the portrait and landscape painter John Singer Sargent. At the same time in America at the turn of the 20th century there existed a native and nearly insular realism, as richly embodied in the figurative work of Thomas Eakins, the Ashcan School, and the landscapes and seascapes of Winslow Homer, all of whose paintings were deeply invested in the solidity of natural forms. The visionary landscape, a motive largely dependent on the ambiguity of the nocturne, found its advocates in Albert Pinkham Ryder and Ralph Albert Blakelock.

In the late 19th century there also were several, rather dissimilar, groups of Symbolist painters whose works resonated with younger artists of the 20th century, especially with the Fauvists and the Surrealists. Among them were Gustave Moreau, Odilon Redon, Pierre Puvis de Chavannes, Henri Fantin-Latour, Arnold Böcklin, Edvard Munch, Félicien Rops, and Jan Toorop, and Gustave Klimt amongst others including the Russian Symbolists like Mikhail Vrubel.

Symbolist painters mined mythology and dream imagery for a visual language of the soul, seeking evocative paintings that brought to mind a static world of silence. The symbols used in Symbolism are not the familiar emblems of mainstream iconography but intensely personal, private, obscure and ambiguous references. More a philosophy than an actual style of art, the Symbolist painters influenced the contemporary Art Nouveau movement and Les Nabis. In their exploration of dreamlike subjects, symbolist painters are found across centuries and cultures, as they are still today; Bernard Delvaille has described René Magritte's surrealism as "Symbolism plus Freud".

The heritage of painters like Van Gogh, Cézanne, Gauguin, and Seurat was essential for the development of modern art. At the beginning of the 20th century Henri Matisse and several other young artists revolutionized the Paris art world with "wild", multi-colored, expressive, landscapes and figure paintings that the critics called Fauvism. Pablo Picasso made his first cubist paintings based on Cézanne's idea that all depiction of nature can be reduced to three solids: cube, sphere and cone.

The heritage of painters like Van Gogh, Cézanne, Gauguin, and Seurat was essential for the development of modern art. At the beginning of the 20th century Henri Matisse and several other young artists including the pre-cubist Georges Braque, André Derain, Raoul Dufy and Maurice de Vlaminck revolutionized the Paris art world with "wild", multi-colored, expressive, landscapes and figure paintings that the critics called Fauvism. Henri Matisse's second version of "The Dance" signifies a key point in his career and in the development of modern painting. It reflects Matisse's incipient fascination with primitive art: the intense warm colors against the cool blue-green background and the rhythmical succession of dancing nudes convey the feelings of emotional liberation and hedonism. Pablo Picasso made his first cubist paintings based on Cézanne's idea that all depiction of nature can be reduced to three solids: cube, sphere and cone. With the painting Les Demoiselles d'Avignon 1907, Picasso dramatically created a new and radical picture depicting a raw and primitive brothel scene with five prostitutes, violently painted women, reminiscent of African tribal masks and his own new Cubist inventions. analytic Cubism was jointly developed by Pablo Picasso and Georges Braque, exemplified by "Violin and Candlestick, Paris", from about 1908 through 1912. Analytic cubism, the first clear manifestation of cubism, was followed by synthetic cubism, practised by Braque, Picasso, Fernand Léger, Juan Gris, Albert Gleizes, Marcel Duchamp and countless other artists into the 1920s. Synthetic cubism is characterized by the introduction of different textures, surfaces, collage elements, papier collé and a large variety of merged subject matter.

Les Fauves (French for "The Wild Beasts") were early-20th-century painters, experimenting with freedom of expression through color. The name was given, humorously and not as a compliment, to the group by art critic Louis Vauxcelles. Fauvism was a short-lived and loose grouping of early-20th-century artists whose works emphasized painterly qualities, and the imaginative use of deep color over the representational values. Fauvists made the subject of the painting easy to read, exaggerated perspectives and an interesting prescient prediction of the Fauves was expressed in 1888 by Paul Gauguin to Paul Sérusier,

""How do you see these trees? They are yellow. So, put in yellow; this shadow, rather blue, paint it with pure ultramarine; these red leaves? Put in vermilion.""

The leaders of the movement were Henri Matisse and André Derain – friendly rivals of a sort, each with his own followers. Ultimately Matisse became the "yang" to Picasso's "yin" in the 20th century. Fauvist painters included Albert Marquet, Charles Camoin, Maurice de Vlaminck, Raoul Dufy, Othon Friesz, the Dutch painter Kees van Dongen, and Picasso's partner in Cubism, Georges Braque amongst others.
Fauvism, as a movement, had no concrete theories, and was short lived, beginning in 1905 and ending in 1907, they only had three exhibitions. Matisse was seen as the leader of the movement, due to his seniority in age and prior self-establishment in the academic art world. His 1905 portrait of Mme. Matisse "The Green Line", (above), caused a sensation in Paris when it was first exhibited. He said he wanted to create art to delight; art as a decoration was his purpose and it can be said that his use of bright colors tries to maintain serenity of composition. In 1906 at the suggestion of his dealer Ambroise Vollard, André Derain went to London and produced a series of paintings like "Charing Cross Bridge, London" (above) in the Fauvist style, paraphrasing the famous series by the Impressionist painter Claude Monet. Masters like Henri Matisse and Pierre Bonnard continued developing their narrative styles independent of any movement throughout the 20th century.

By 1907 Fauvism no longer was a shocking new movement, soon it was replaced by Cubism on the critics' radar screen as the latest new development in Contemporary Art of the time.
In 1907 Appolinaire, commenting about Matisse in an article published in La Falange, said, "We are not here in the presence of an extravagant or an extremist undertaking: Matisse's art is eminently reasonable."
Analytic cubism was jointly developed by Pablo Picasso and Georges Braque from about 1908 through 1912. Analytic cubism, the first clear manifestation of cubism, was followed by Synthetic cubism, practised by Braque, Picasso, Fernand Léger, Juan Gris, Albert Gleizes, Marcel Duchamp and countless other artists into the 1920s. Synthetic cubism is characterized by the introduction of different textures, surfaces, collage elements, papier collé and a large variety of merged subject matter.

During the years between 1910 and the end of World War I and after the heyday of cubism, several movements emerged in Paris. Giorgio De Chirico moved to Paris in July 1911, where he joined his brother Andrea (the poet and painter known as Alberto Savinio). Through his brother he met Pierre Laprade a member of the jury at the Salon d'Automne, where he exhibited three of his dreamlike works: "Enigma of the Oracle", "Enigma of an Afternoon" and "Self-Portrait". During 1913 he exhibited his work at the Salon des Indépendants and Salon d'Automne, his work was noticed by Pablo Picasso and Guillaume Apollinaire and several others. His compelling and mysterious paintings are considered instrumental to the early beginnings of Surrealism. During the first half of the 20th century in Europe masters like Georges Braque, André Derain, and Giorgio De Chirico continued painting independent of any movement.

In the first two decades of the 20th century and after Cubism, several other important movements emerged; futurism (Balla), abstract art (Kandinsky), Der Blaue Reiter), Bauhaus, (Kandinsky) and (Klee), Orphism, (Robert Delaunay and František Kupka), Synchromism (Morgan Russell), De Stijl (Mondrian), Suprematism (Malevich), Constructivism (Tatlin), Dadaism (Duchamp, Picabia, Arp) and Surrealism (De Chirico, André Breton, Miró, Magritte, Dalí, Ernst). Modern painting influenced all the visual arts, from Modernist architecture and design, to avant-garde film, theatre and modern dance and became an experimental laboratory for the expression of visual experience, from photography and concrete poetry to advertising art and fashion. Van Gogh's painting exerted great influence upon 20th-century Expressionism, as can be seen in the work of the Fauves, Die Brücke (a group led by German painter Ernst Kirchner), and the Expressionism of Edvard Munch, Egon Schiele, Marc Chagall, Amedeo Modigliani, Chaim Soutine and others..

Wassily Kandinsky a Russian painter, printmaker and art theorist, one of the most famous 20th-century artists is generally considered the first important painter of modern abstract art. As an early Modernist, in search of new modes of visual expression, and spiritual expression, he theorized as did contemporary occultists and theosophists, that pure visual abstraction had corollary vibrations with sound and music. They posited that pure abstraction could express pure spirituality. His earliest abstractions were generally titled as the example in the (above gallery) "Composition VII", making connection to the work of the composers of music. Kandinsky included many of his theories about abstract art in his book "Concerning the Spiritual in Art." Robert Delaunay was a French artist who is associated with Orphism, (reminiscent of a link between pure abstraction and cubism). His later works were more abstract, reminiscent of Paul Klee. His key contributions to abstract painting refer to his bold use of color, and a clear love of experimentation of both depth and tone. At the invitation of Wassily Kandinsky, Delaunay and his wife the artist Sonia Delaunay, joined The Blue Rider (Der Blaue Reiter), a Munich-based group of abstract artists, in 1911, and his art took a turn to the abstract.

Other major pioneers of early abstraction include Russian painter Kasimir Malevich, who after the Russian Revolution in 1917, and after pressure from the Stalinist regime in 1924 returned to painting imagery and "Peasants and Workers in the field", and Swiss painter Paul Klee whose masterful color experiments made him an important pioneer of abstract painting at the Bauhaus. Still other important pioneers of abstract painting include the Swedish artist Hilma af Klint, Czech painter František Kupka as well as American artists Stanton MacDonald-Wright and Morgan Russell who, in 1912, founded Synchromism, an art movement that closely resembles Orphism.

"Expressionism" and "Symbolism" are broad rubrics that involve several important and related movements in 20th-century painting that dominated much of the avant-garde art being made in Western, Eastern and Northern Europe. Expressionist works were painted largely between World War I and World War II, mostly in France, Germany, Norway, Russia, Belgium, and Austria. Expressionist artists are related to both Surrealism and Symbolism and are each uniquely and somewhat eccentrically personal. Fauvism, Die Brücke, and Der Blaue Reiter are three of the best known groups of Expressionist and Symbolist painters.

Artists as interesting and diverse as Marc Chagall, whose painting "I and the Village", (above) tells an autobiographical story that examines the relationship between the artist and his origins, with a lexicon of artistic Symbolism. Gustav Klimt, Egon Schiele, Edvard Munch, Emil Nolde, Chaim Soutine, James Ensor, Oskar Kokoschka, Ernst Ludwig Kirchner, Max Beckmann, Franz Marc, Käthe Schmidt Kollwitz, Georges Rouault, Amedeo Modigliani and some of the Americans abroad like Marsden Hartley, and Stuart Davis, were considered influential expressionist painters. Although Alberto Giacometti is primarily thought of as an intense Surrealist sculptor, he made intense expressionist paintings as well.

Piet Mondrian's art was also related to his spiritual and philosophical studies. In 1908 he became interested in the theosophical movement launched by Helena Petrovna Blavatsky in the late 19th century. Blavatsky believed that it was possible to attain a knowledge of nature more profound than that provided by empirical means, and much of Mondrian's work for the rest of his life was inspired by his search for that spiritual knowledge.

De Stijl also known as neoplasticism, was a Dutch artistic movement founded in 1917. The term "De Stijl" is used to refer to a body of work from 1917 to 1931 founded in the Netherlands.

"De Stijl" is also the name of a journal that was published by the Dutch painter, designer, writer, and critic Theo van Doesburg propagating the group's theories. Next to van Doesburg, the group's principal members were the painters Piet Mondrian, Vilmos Huszár, and Bart van der Leck, and the architects Gerrit Rietveld, Robert van 't Hoff, and J. J. P. Oud. The artistic philosophy that formed a basis for the group's work is known as "neoplasticism" – the new plastic art (or "Nieuwe Beelding" in Dutch).

Proponents of De Stijl sought to express a new utopian ideal of spiritual harmony and order. They advocated pure abstraction and universality by a reduction to the essentials of form and colour; they simplified visual compositions to the vertical and horizontal directions, and used only primary colors along with black and white. Indeed, according to the Tate Gallery's online article on neoplasticism, Mondrian himself sets forth these delimitations in his essay "Neo-Plasticism in Pictorial Art". He writes, "... this new plastic idea will ignore the particulars of appearance, that is to say, natural form and colour. On the contrary, it should find its expression in the abstraction of form and colour, that is to say, in the straight line and the clearly defined primary colour." The Tate article further summarizes that this art allows "only primary colours and non-colours, only squares and rectangles, only straight and horizontal or vertical line." The Guggenheim Museum's online article on De Stijl summarizes these traits in similar terms: "It [De Stijl] was posited on the fundamental principle of the geometry of the straight line, the square, and the rectangle, combined with a strong asymmetricality; the predominant use of pure primary colors with black and white; and the relationship between positive and negative elements in an arrangement of non-objective forms and lines."

De Stijl movement was influenced by Cubist painting as well as by the mysticism and the ideas about "ideal" geometric forms (such as the "perfect straight line") in the neoplatonic philosophy of mathematician M. H. J. Schoenmaekers. The works of De Stijl would influence the Bauhaus style and the international style of architecture as well as clothing and interior design. However, it did not follow the general guidelines of an "ism" (Cubism, Futurism, Surrealism), nor did it adhere to the principles of art schools like Bauhaus; it was a collective project, a joint enterprise.

Marcel Duchamp, came to international prominence in the wake of his notorious success at the New York City Armory Show in 1913, (soon after he denounced artmaking for chess). After Duchamp's Nude Descending a Staircase became the international cause celebre at the 1913 Armory show in New York he created "The Bride Stripped Bare by Her Bachelors, Even, Large Glass". The "Large Glass" pushed the art of painting to radical new limits being part painting, part collage, part construction. Duchamp became closely associated with the Dada movement that began in neutral Zurich, Switzerland, during World War I and peaked from 1916 to 1920. The movement primarily involved visual arts, literature (poetry, art manifestoes, art theory), theatre, and graphic design, and concentrated its anti war politic through a rejection of the prevailing standards in art through anti-art cultural works. Francis Picabia, Man Ray, Kurt Schwitters, Tristan Tzara, Hans Richter, Jean Arp, Sophie Taeuber-Arp, along with Duchamp and many others are associated with the Dadaist movement. Duchamp and several Dadaists are also associated with Surrealism, the movement that dominated European painting in the 1920s and 1930s.

In 1924 André Breton published the "Surrealist Manifesto." The Surrealist movement in painting became synonymous with the avant-garde and which featured artists whose works varied from the abstract to the super-realist. With works on paper like "Machine Turn Quickly", (above) Francis Picabia continued his involvement in the Dada movement through 1919 in Zurich and Paris, before breaking away from it after developing an interest in Surrealist art. Yves Tanguy, René Magritte and Salvador Dalí are particularly known for their realistic depictions of dream imagery and fantastic manifestations of the imagination. Joan Miró's "The Tilled Field" of 1923–1924 verges on abstraction, this early painting of a complex of objects and figures, and arrangements of sexually active characters; was Miró's first Surrealist masterpiece. Miró's "The Tilled Field" also contains several parallels to Bosch's "Garden of Earthly Delights": similar flocks of birds; pools from which living creatures emerge; and oversize disembodied ears all echo the Dutch master's work that Miró saw as a young painter in The Prado. The more abstract Joan Miró, Jean Arp, André Masson, and Max Ernst were very influential, especially in the United States during the 1940s.
Throughout the 1930s, Surrealism continued to become more visible to the public at large. A Surrealist group developed in Britain and, according to Breton, their 1936 London International Surrealist Exhibition was a high water mark of the period and became the model for international exhibitions. Surrealist groups in Japan, and especially in Latin America, the Caribbean and in Mexico produced innovative and original works.

Dalí and Magritte created some of the most widely recognized images of the movement. The 1928/1929 painting "This Is Not A Pipe", by Magritte is the subject of a Michel Foucault 1973 book, "This is not a Pipe" (English edition, 1991), that discusses the painting and its paradox. Dalí joined the group in 1929, and participated in the rapid establishment of the visual style between 1930 and 1935.

Surrealism as a visual movement had found a method: to expose psychological truth by stripping ordinary objects of their normal significance, in order to create a compelling image that was beyond ordinary formal organization, and perception, sometimes evoking empathy from the viewer, sometimes laughter and sometimes outrage and bewilderment.

1931 marked a year when several Surrealist painters produced works which marked turning points in their stylistic evolution: in one example, liquid shapes become the trademark of Dalí, particularly in his "The Persistence of Memory", which features the image of watches that sag as if they are melting. Evocations of time and its compelling mystery and absurdity.

The characteristics of this style – a combination of the depictive, the abstract, and the psychological – came to stand for the alienation which many people felt in the modernist period, combined with the sense of reaching more deeply into the psyche, to be "made whole with one's individuality."

Max Ernst whose 1920 painting "Murdering Airplane", studied philosophy and psychology in Bonn and was interested in the alternative realities experienced by the insane. His paintings may have been inspired by the psychoanalyst Sigmund Freud's study of the delusions of a paranoiac, Daniel Paul Schreber. Freud identified Schreber's fantasy of becoming a woman as a "castration complex." The central image of two pairs of legs refers to Schreber's hermaphroditic desires. Ernst's inscription on the back of the painting reads: "The picture is curious because of its symmetry. The two sexes balance one another."

During the 1920s André Masson's work was enormously influential in helping the newly arrived in Paris and young artist Joan Miró find his roots in the new Surrealist painting. Miró acknowledged in letters to his dealer Pierre Matisse the importance of Masson as an example to him in his early years in Paris.

Long after personal, political and professional tensions have fragmented the Surrealist group into thin air and ether, Magritte, Miró, Dalí and the other Surrealists continue to define a visual program in the arts. Other prominent surrealist artists include Giorgio de Chirico, Méret Oppenheim, Toyen, Grégoire Michonze, Roberto Matta, Kay Sage, Leonora Carrington, Dorothea Tanning, and Leonor Fini among others.

Der Blaue Reiter was a German movement lasting from 1911 to 1914, fundamental to Expressionism, along with Die Brücke which was founded the previous decade in 1905 and was a group of German expressionist artists formed in Dresden in 1905. Founding members of Die Brücke were Fritz Bleyl, Erich Heckel, Ernst Ludwig Kirchner and Karl Schmidt-Rottluff. Later members included Max Pechstein, Otto Mueller and others. The group was one of the seminal ones, which in due course had a major impact on the evolution of modern art in the 20th century and created the style of Expressionism.

Wassily Kandinsky, Franz Marc, August Macke, Alexej von Jawlensky, whose psychically expressive painting of the Russian dancer "Portrait of Alexander Sakharoff", 1909 is in the gallery above, Marianne von Werefkin, Lyonel Feininger and others founded the Der Blaue Reiter group in response to the rejection of Kandinsky's painting "Last Judgement" from an exhibition. Der Blaue Reiter lacked a central artistic manifesto, but was centered around Kandinsky and Marc. Artists Gabriele Münter and Paul Klee were also involved.
The name of the movement comes from a painting by Kandinsky created in 1903. It is also claimed that the name could have derived from Marc's enthusiasm for horses and Kandinsky's love of the colour blue. For Kandinsky, "blue" is the colour of spirituality: the darker the blue, the more it awakens human desire for the eternal.

In the USA during the period between World War I and World War II painters tended to go to Europe for recognition. Artists like Marsden Hartley, Patrick Henry Bruce, Gerald Murphy and Stuart Davis, created reputations abroad. In New York City, Albert Pinkham Ryder and Ralph Blakelock were influential and important figures in advanced American painting between 1900 and 1920. During the 1920s photographer Alfred Stieglitz exhibited Georgia O'Keeffe, Arthur Dove, Alfred Henry Maurer, Charles Demuth, John Marin and other artists including European Masters Henri Matisse, Auguste Rodin, Henri Rousseau, Paul Cézanne, and Pablo Picasso, at his gallery "the 291."

During the 1920s and the 1930s and the Great Depression, Surrealism, late Cubism, the Bauhaus, De Stijl, Dada, German Expressionism, Expressionism, and modernist and masterful color painters like Henri Matisse and Pierre Bonnard characterized the European art scene. In Germany Max Beckmann, Otto Dix, George Grosz and others politicized their paintings, foreshadowing the coming of World War II. While in America American Scene painting and the social realism and regionalism movements that contained both political and social commentary dominated the art world. Artists like Ben Shahn, Thomas Hart Benton, Grant Wood, George Tooker, John Steuart Curry, Reginald Marsh, and others became prominent. In Latin America besides the Uruguayan painter Joaquín Torres García and Rufino Tamayo from Mexico, the muralist movement with Diego Rivera, David Siqueiros, José Orozco, Pedro Nel Gómez and Santiago Martinez Delgado and the Symbolist paintings by Frida Kahlo began a renaissance of the arts for the region, with a use of color and historic, and political messages. Frida Kahlo's Symbolist works also relate strongly to Surrealism and to the Magic Realism movement in literature. The psychological drama in many of Kahlo's self portraits (above) underscore the vitality and relevance of her paintings to artists in the 21st century.

"American Gothic" is a painting by Grant Wood from 1930. Portraying a pitchfork-holding farmer and a younger woman in front of a house of Carpenter Gothic style, it is one of the most familiar images in 20th-century American art. Art critics had favorable opinions about the painting, like Gertrude Stein and Christopher Morley, they assumed the painting was meant to be a satire of rural small-town life. It was thus seen as part of the trend towards increasingly critical depictions of rural America, along the lines of Sherwood Anderson's "1919 Winesburg, Ohio", Sinclair Lewis' 1920 "Main Street", and Carl Van Vechten's "The Tattooed Countess" in literature. However, with the onset of the Great Depression, the painting came to be seen as a depiction of steadfast American pioneer spirit.

Diego Rivera is perhaps best known by the public world for his 1933 mural, "Man at the Crossroads", in the lobby of the RCA Building at Rockefeller Center. When his patron Nelson Rockefeller discovered that the mural included a portrait of Vladimir Lenin and other communist imagery, he fired Rivera, and the unfinished work was eventually destroyed by Rockefeller's staff. The film "Cradle Will Rock" includes a dramatization of the controversy. Frida Kahlo (Rivera's wife's) works are often characterized by their stark portrayals of pain. Of her 143 paintings 55 are self-portraits, which frequently incorporate symbolic portrayals of her physical and psychological wounds. Kahlo was deeply influenced by indigenous Mexican culture, which is apparent in her paintings' bright colors and dramatic symbolism. Christian and Jewish themes are often depicted in her work as well; she combined elements of the classic religious Mexican tradition—which were often bloody and violent—with surrealist renderings. While her paintings are not overtly Christian they certainly contain elements of the macabre Mexican Christian style of religious paintings.

Political activism was an important piece of David Siqueiros' life, and frequently inspired him to set aside his artistic career. His art was deeply rooted in the Mexican Revolution, a violent and chaotic period in Mexican history in which various social and political factions fought for recognition and power. The period from the 1920s to the 1950s is known as the Mexican Renaissance, and Siqueiros was active in the attempt to create an art that was at once Mexican and universal. He briefly gave up painting to focus on organizing miners in Jalisco.

During the 1930s radical leftist politics characterized many of the artists connected to Surrealism, including Pablo Picasso. On 26 April 1937, during the Spanish Civil War, the Basque town of Gernika was the scene of the "Bombing of Gernika" by the Condor Legion of Nazi Germany's Luftwaffe. The Germans were attacking to support the efforts of Francisco Franco to overthrow the Basque Government and the Spanish Republican government. The town was devastated, though the Biscayan assembly and the Oak of Gernika survived. Pablo Picasso painted his mural sized "Guernica" to commemorate the horrors of the bombing.

In its final form, "Guernica" is an immense black and white, tall and wide mural painted in oil. The mural presents a scene of death, violence, brutality, suffering, and helplessness without portraying their immediate causes. The choice to paint in black and white contrasts with the intensity of the scene depicted and invokes the immediacy of a newspaper photograph.
Picasso painted the mural sized painting called "Guernica" in protest of the bombing. The painting was first exhibited in Paris in 1937, then Scandinavia, then London in 1938 and finally in 1939 at Picasso's request the painting was sent to the United States in an extended loan (for safekeeping) at MoMA. The painting went on a tour of museums throughout the USA until its final return to the Museum of Modern Art in New York City where it was exhibited for nearly thirty years. Finally in accord with Pablo Picasso's wish to give the painting to the people of Spain as a gift, it was sent to Spain in 1981.

During the Great Depression of the 1930s, through the years of World War II American art was characterized by Social Realism and American Scene Painting in the work of Grant Wood, Edward Hopper, Ben Shahn, Thomas Hart Benton, and several others. "Nighthawks" (1942) is a painting by Edward Hopper that portrays people sitting in a downtown diner late at night. It is not only Hopper's most famous painting, but one of the most recognizable in American art. It is currently in the collection of the Art Institute of Chicago. The scene was inspired by a diner (since demolished) in Greenwich Village, Hopper's home neighborhood in Manhattan. Hopper began painting it immediately after the attack on Pearl Harbor. After this event there was a large feeling of gloominess over the country, a feeling that is portrayed in the painting. The urban street is empty outside the diner, and inside none of the three patrons is apparently looking or talking to the others but instead is lost in their own thoughts. This portrayal of modern urban life as empty or lonely is a common theme throughout Hopper's work.

The Dynamic for artists in Europe during the 1930s deteriorated rapidly as the Nazi's power in Germany and across Eastern Europe increased. The climate became so hostile for artists and art associated with Modernism and abstraction that many left for the Americas. "Degenerate art" was a term adopted by the Nazi regime in Germany for virtually all modern art. Such art was banned on the grounds that it was un-German or Jewish Bolshevist in nature, and those identified as degenerate artists were subjected to sanctions. These included being dismissed from teaching positions, being forbidden to exhibit or to sell their art, and in some cases being forbidden to produce art entirely.

"Degenerate Art" was also the title of an exhibition, mounted by the Nazis in Munich in 1937, consisting of modernist artworks chaotically hung and accompanied by text labels deriding the art. Designed to inflame public opinion against modernism, the exhibition subsequently traveled to several other cities in Germany and Austria. German artist Max Beckmann and scores of others fled Europe for New York. In New York City a new generation of young and exciting Modernist painters led by Arshile Gorky, Willem de Kooning, and others were just beginning to come of age.

Arshile Gorky's portrait of someone who might be Willem de Kooning (above) is an example of the evolution of abstract expressionism from the context of figure painting, cubism and surrealism. Along with his friends de Kooning and John D. Graham Gorky created bio-morphically shaped and abstracted figurative compositions that by the 1940s evolved into totally abstract paintings. Gorky's work seems to be a careful analysis of memory, emotion and shape, using line and color to express feeling and nature.

The 1940s in New York City heralded the triumph of American abstract expressionism, a modernist movement that combined lessons learned from Henri Matisse, Pablo Picasso, Surrealism, Joan Miró, Cubism, Fauvism, and early Modernism via great teachers in America like Hans Hofmann and John D. Graham. American artists benefited from the presence of Piet Mondrian, Fernand Léger, Max Ernst and the André Breton group, Pierre Matisse's gallery, and Peggy Guggenheim's gallery "The Art of This Century", as well as other factors. The figurative work of Francis Bacon, Frida Kahlo, Edward Hopper, Lucian Freud, Andrew Wyeth and others served as a kind of alternative to abstract expressionism.

Post-Second World War American painting called Abstract expressionism included artists like Jackson Pollock, Willem de Kooning, Arshile Gorky, Mark Rothko, Hans Hofmann, Clyfford Still, Franz Kline, Adolph Gottlieb, Mark Tobey, Barnett Newman, James Brooks, Philip Guston, Robert Motherwell, Conrad Marca-Relli, Jack Tworkov, William Baziotes, Richard Pousette-Dart, Ad Reinhardt, Hedda Sterne, Jimmy Ernst, Esteban Vicente, Bradley Walker Tomlin, and Theodoros Stamos, among others. American Abstract expressionism got its name in 1946 from the art critic Robert Coates. It is seen as combining the emotional intensity and self-denial of the German Expressionists with the anti-figurative aesthetic of the European abstract schools such as futurism, the Bauhaus and synthetic cubism. Abstract expressionism, action painting, and Color Field painting are synonymous with the New York School.

Technically Surrealism was an important predecessor for abstract expressionism with its emphasis on spontaneous, automatic or subconscious creation. Jackson Pollock's dripping paint onto a canvas laid on the floor is a technique that has its roots in the work of André Masson. Another important ear<nowiki>ly m</nowiki>anifestation of what came to be abstract expressionism is the work of American Northwest artist Mark Tobey, especially his "white writing" canvases, which, though generally not large in scale, anticipate the "all over" look of Pollock's drip paintings.

Additionally, Abstract expressionism has an image of being rebellious, anarchic, highly idiosyncratic and, some feel, rather nihilistic. In practice, the term is applied to any number of artists working (mostly) in New York who had quite different styles, and even applied to work which is not especially abstract nor expressionist. Pollock's energetic "action paintings", with their "busy" feel, are different both technically and aesthetically, to the violent and grotesque "Women" series of Willem de Kooning. As seen above in the gallery "Woman V" is one of a series of six paintings made by de Kooning between 1950 and 1953 that depict a three-quarter-length female figure. He began the first of these paintings, "Woman I" collection: The Museum of Modern Art, New York City, in June 1950, repeatedly changing and painting out the image until January or February 1952, when the painting was abandoned unfinished. The art historian Meyer Schapiro saw the painting in de Kooning's studio soon afterwards and encouraged the artist to persist. De Kooning's response was to begin three other paintings on the same theme; "Woman II" collection: The Museum of Modern Art, New York City, "Woman III", Tehran Museum of Contemporary Art, "Woman IV", Nelson-Atkins Museum of Art, Kansas City, Missouri. During the summer of 1952, spent at East Hampton, de Kooning further explored the theme through drawings and pastels. He may have finished work on "Woman I" by the end of June, or possibly as late as November 1952, and probably the other three women pictures were concluded at much the same time. The "Woman series" are decidedly figurative paintings. Another important artist is Franz Kline, as demonstrated by his painting "High Street", 1950 as with Jackson Pollock and other Abstract Expressionists, was labelled an "action painter" because of his seemingly spontaneous and intense style, focusing less, or not at all, on figures or imagery, but on the actual brush strokes and use of canvas.

Clyfford Still, Barnett Newman, Adolph Gottlieb, and the serenely shimmering blocks of color in Mark Rothko's work (which is not what would usually be called expressionist and which Rothko denied was abstract), are classified as abstract expressionists, albeit from what Clement Greenberg termed the Color Field direction of abstract expressionism. Both Hans Hofmann and Robert Motherwell (gallery) can be comfortably described as practitioners of action painting and Color Field painting.

Abstract expressionism has many stylistic similarities to the Russian artists of the early 20th century such as Wassily Kandinsky. Although it is true that spontaneity or of the impression of spontaneity characterized many of the abstract expressionists works, most of these paintings involved careful planning, especially since their large size demanded it. An exception might be the drip paintings of Pollock.

Why this style gained mainstream acceptance in the 1950s is a matter of debate. American Social realism had been the mainstream in the 1930s. It had been influenced not only by the Great Depression but also by the Social Realists of Mexico such as David Alfaro Siqueiros and Diego Rivera. The political climate after World War II did not long tolerate the social protests of those painters. Abstract expressionism arose during World War II and began to be showcased during the early 1940s at galleries in New York like "The Art of This Century Gallery". The late 1940s through the mid-1950s ushered in the McCarthy era. It was after World War II and a time of political conservatism and extreme artistic censorship in the United States. Some people have conjectured that since the subject matter was often totally abstract, Abstract expressionism became a safe strategy for artists to pursue this style. Abstract art could be seen as apolitical. Or if the art was political, the message was largely for the insiders. However, those theorists are in the minority. As the first truly original school of painting in America, Abstract expressionism demonstrated the vitality and creativity of the country in the post-war years, as well as its ability (or need) to develop an aesthetic sense that was not constrained by the European standards of beauty.

Although Abstract expressionism spread quickly throughout the United States, the major centers of this style were New York City and California, especially in the New York School, and the San Francisco Bay area. Abstract expressionist paintings share certain characteristics, including the use of large canvases, an "all-over" approach, in which the whole canvas is treated with equal importance (as opposed to the center being of more interest than the edges). The canvas as the "arena" became a credo of action painting, while the "integrity of the picture plane" became a credo of the Color Field painters. Many other artists began exhibiting their abstract expressionist related paintings during the 1950s including Alfred Leslie, Sam Francis, Joan Mitchell, Helen Frankenthaler, Cy Twombly, Milton Resnick, Michael Goldberg, Norman Bluhm, Ray Parker, Nicolas Carone, Grace Hartigan, Friedel Dzubas, and Robert Goodnough among others.

During the 1950s Color Field painting initially referred to a particular type of abstract expressionism, especially the work of Mark Rothko, Clyfford Still, Barnett Newman, Robert Motherwell and Adolph Gottlieb. It essentially involved abstract paintings with large, flat expanses of color that expressed the sensual, and visual feelings and properties of large areas of nuanced surface. Art critic Clement Greenberg perceived Color Field painting as related to but different from Action painting. The overall expanse and gestalt of the work of the early color field painters speaks of an almost religious experience, awestruck in the face of an expanding universe of sensuality, color and surface. During the early-to-mid-1960s, "Color Field painting" came to refer to the styles of artists like Jules Olitski, Kenneth Noland, and Helen Frankenthaler, whose works were related to second-generation abstract expressionism, and to younger artists like Larry Zox, and Frank Stella, – all moving in a new direction. Artists like Clyfford Still, Mark Rothko, Hans Hofmann, Morris Louis, Jules Olitski, Kenneth Noland, Helen Frankenthaler, Larry Zox, and others often used greatly reduced references to nature, and they painted with a highly articulated and psychological use of color. In general these artists eliminated recognizable imagery. In "Mountains and Sea", from 1952, a seminal work of Color Field painting by Helen Frankenthaler the artist used the stain technique for the first time.

In Europe there was the continuation of Surrealism, Cubism, Dada and the works of Matisse. Also in Europe, Tachisme (the European equivalent to Abstract expressionism) took hold of the newest generation. Serge Poliakoff, Nicolas de Staël, Georges Mathieu, Vieira da Silva, Jean Dubuffet, Yves Klein and Pierre Soulages among others are considered important figures in post-war European painting.

Eventually abstract painting in America evolved into movements such as Neo-Dada, Color Field painting, Post painterly abstraction, Op art, hard-edge painting, Minimal art, shaped canvas painting, Lyrical Abstraction, Neo-expressionism and the continuation of Abstract expressionism. As a response to the tendency toward abstraction imagery emerged through various new movements, notably Pop art.

Earlier in England in 1956 the term "Pop Art" was used by Lawrence Alloway for paintings that celebrated consumerism of the post World War II era. This movement rejected abstract expressionism and its focus on the hermeneutic and psychological interior, in favor of art which depicted, and often celebrated material consumer culture, advertising, and iconography of the mass production age. The early works of David Hockney and the works of Richard Hamilton Peter Blake and Eduardo Paolozzi were considered seminal examples in the movement.

Pop art in America was to a large degree initially inspired by the works of Jasper Johns, Larry Rivers, and Robert Rauschenberg. Although the paintings of Gerald Murphy, Stuart Davis and Charles Demuth during the 1920s and 1930s set the table for pop art in America. In New York City during the mid-1950s Robert Rauschenberg and Jasper Johns created works of art that at first seemed to be continuations of Abstract expressionist painting. Actually their works and the work of Larry Rivers, were radical departures from abstract expressionism especially in the use of banal and literal imagery and the inclusion and the combining of mundane materials into their work. The innovations of Johns' specific use of various images and objects like chairs, numbers, targets, beer cans and the American flag; Rivers paintings of subjects drawn from popular culture such as George Washington crossing the Delaware, and his inclusions of images from advertisements like the camel from Camel cigarettes, and Rauschenberg's surprising constructions using inclusions of objects and pictures taken from popular culture, hardware stores, junkyards, the city streets, and taxidermy gave rise to a radical new movement in American art. Eventually by 1963 the movement came to be known worldwide as pop art.

American pop art is exemplified by artists: Andy Warhol, Claes Oldenburg, Wayne Thiebaud, James Rosenquist, Jim Dine, Tom Wesselmann and Roy Lichtenstein among others. Lichtenstein's most important work is arguably "Whaam!" (1963, Tate Modern, London), one of the earliest known examples of pop art, adapted a comic-book panel from a 1962 issue of DC Comics' "All-American Men of War". The painting depicts a fighter aircraft firing a rocket into an enemy plane, with a red-and-yellow explosion. The cartoon style is heightened by the use of the onomatopoeic lettering ""Whaam!"" and the boxed caption ""I pressed the fire control... and ahead of me rockets blazed through the sky..."" Pop art merges popular and mass culture with fine art, while injecting humor, irony, and recognizable imagery and content into the mix. In October 1962 the Sidney Janis Gallery mounted "The New Realists" the first major pop art group exhibition in an uptown art gallery in New York City. Sidney Janis mounted the exhibition in a 57th Street storefront near his gallery at 15 E. 57th Street. The show sent shockwaves through the New York School and reverberated worldwide. Earlier in the fall of 1962 an historically important and ground-breaking "New Painting of Common Objects" exhibition of pop art, curated by Walter Hopps at the Pasadena Art Museum sent shock waves across the Western United States.

While in the downtown scene in New York City's East Village 10th Street galleries artists were formulating an American version of Pop Art. Claes Oldenburg had his storefront and made painted objects, and the Green Gallery on 57th Street began to show Tom Wesselmann and James Rosenquist. Later Leo Castelli exhibited other American artists including the bulk of the careers of Andy Warhol and Roy Lichtenstein and his use of Benday dots, a technique used in commercial reproduction. There is a connection between the radical works of Duchamp, and Man Ray, the rebellious Dadaists – with a sense of humor; and pop artists like Alex Katz (who became known for his parodies of portrait photography and suburban life), Claes Oldenburg, Andy Warhol, Roy Lichtenstein and the others.

While throughout the 20th century many painters continued to practice landscape and figurative painting with contemporary subjects and solid technique, like Milton Avery, John D. Graham, Fairfield Porter, Edward Hopper, Balthus, Francis Bacon, Nicolas de Staël, Andrew Wyeth, Lucian Freud, Frank Auerbach, Philip Pearlstein, David Park, Nathan Oliveira, David Hockney, Malcolm Morley, Richard Estes, Ralph Goings, Audrey Flack, Chuck Close, Susan Rothenberg, Eric Fischl, Vija Celmins and Richard Diebenkorn.

During the 1930s through the 1960s abstract painting in America and Europe evolved into movements such as abstract expressionism, Color Field painting, Post painterly abstraction, Op art, hard-edge painting, Minimal art, shaped canvas painting, and Lyrical Abstraction. Other artists reacted as a response to the tendency toward abstraction, allowing figurative imagery to continue through various new contexts like the Bay Area Figurative Movement in the 1950s and new forms of expressionism from the 1940s through the 1960s. In Italy during this time, Giorgio Morandi was the foremost still life painter, exploring a wide variety of approaches to depicting everyday bottles and kitchen implements. Throughout the 20th century many painters practiced Realism and used expressive imagery; practicing landscape and figurative painting with contemporary subjects and solid technique, and unique expressivity like still-life painter Giorgio Morandi, Milton Avery, John D. Graham, Fairfield Porter, Edward Hopper, Andrew Wyeth, Balthus, Francis Bacon, Leon Kossoff, Frank Auerbach, Lucian Freud, Philip Pearlstein, Willem de Kooning, Arshile Gorky, Grace Hartigan, Robert De Niro, Sr., Elaine de Kooning and others. Along with Henri Matisse, Pablo Picasso, Pierre Bonnard, Georges Braque, and other 20th-century masters. In particular Milton Avery through his use of color and his interest in seascape and landscape paintings connected with the Color field aspect of Abstract expressionism as manifested by Adolph Gottlieb and Mark Rothko as well as the lessons American painters took from the work of Henri Matisse.

"Head VI", 1949 is a painting by the Irish born artist Francis Bacon and is an example of Post World War II European Expressionism. The work shows a distorted version of the Portrait of Innocent X painted by the Spanish artist Diego Velázquez in 1650. The work is one of a series of variants of the Velázquez painting which Bacon executed throughout the 1950s and early 1960s, over a total of forty-five works. When asked why he was compelled to revisit the subject so often, Bacon replied that he had nothing against the Popes, that he merely "wanted an excuse to use these colours, and you can't give ordinary clothes that purple colour without getting into a sort of false fauve manner." The Pope in this version seethes with anger and aggression, and the dark colors give the image a grotesque and nightmarish appearance. The pleated curtains of the backdrop are rendered transparent, and seem to fall through the Pope's face.
Italian painter Giorgio Morandi was an important 20th-century early pioneer of Minimalism. Born in Bologna, Italy, in 1890, throughout his career, Morandi concentrated almost exclusively on still lifes and landscapes, except for a few self-portraits. With great sensitivity to tone, color, and compositional balance, he would depict the same familiar bottles and vases again and again in paintings notable for their simplicity of execution. Morandi executed 133 etchings, a significant body of work in its own right, and his drawings and watercolors often approach abstraction in their economy of means. Through his simple and repetitive motifs and economical use of color, value and surface, Morandi became a prescient and important forerunner of Minimalism. He died in Bologna in 1964.

After World War II the term School of Paris often referred to Tachisme, the European equivalent of American Abstract expressionism and those artists are also related to Cobra. Important proponents being Jean Dubuffet, Pierre Soulages, Nicholas de Staël, Hans Hartung, Serge Poliakoff, and Georges Mathieu, among several others. During the early 1950s Dubuffet (who was always a figurative artist), and de Staël, abandoned abstraction, and returned to imagery via figuration and landscape. De Staël 's work was quickly recognised within the post-war art world, and he became one of the most influential artists of the 1950s. His return to representation (seascapes, footballers, jazz musicians, seagulls) during the early 1950s can be seen as an influential precedent for the American Bay Area Figurative Movement, as many of those abstract painters like Richard Diebenkorn, David Park, Elmer Bischoff, Wayne Thiebaud, Nathan Oliveira, Joan Brown and others made a similar move; returning to imagery during the mid-1950s. Much of de Staël 's late work – in particular his thinned, and diluted oil on canvas abstract landscapes of the mid-1950s predicts Color Field painting and Lyrical Abstraction of the 1960s and 1970s. Nicolas de Staël's bold and intensely vivid color in his last paintings predict the direction of much of contemporary painting that came after him including Pop art of the 1960s.

During the 1950s and 1960s as abstract painting in America and Europe evolved into movements such as Color Field painting, post-painterly abstraction, op art, hard-edge painting, minimal art, shaped canvas painting, Lyrical Abstraction, and the continuation of Abstract expressionism. Other artists reacted as a response to the tendency toward abstraction with art brut, as seen in "Court les rues," 1962, by Jean Dubuffet, fluxus, neo-Dada, New Realism, allowing imagery to re-emerge through various new contexts like pop art, the Bay Area Figurative Movement (a prime example is Diebenkorn's "Cityscape I, (Landscape No. 1)," 1963, Oil on canvas, 60 1/4 x 50 1/2 inches, collection: San Francisco Museum of Modern Art) and later in the 1970s Neo-expressionism. The Bay Area Figurative Movement of whom David Park, Elmer Bischoff, Nathan Oliveira and Richard Diebenkorn whose painting "Cityscape 1", 1963 is a typical example were influential members flourished during the 1950s and 1960s in California. Although throughout the 20th century painters continued to practice Realism and use imagery, practicing landscape and figurative painting with contemporary subjects and solid technique, and unique expressivity like Milton Avery, Edward Hopper, Jean Dubuffet, Francis Bacon, Frank Auerbach, Lucian Freud, Philip Pearlstein, and others. Younger painters practiced the use of imagery in new and radical ways. Yves Klein, Martial Raysse, Niki de Saint Phalle, Wolf Vostell, David Hockney, Alex Katz, Malcolm Morley, Ralph Goings, Audrey Flack, Richard Estes, Chuck Close, Susan Rothenberg, Eric Fischl, John Baeder and Vija Celmins were a few who became prominent between the 1960s and the 1980s. Fairfield Porter was largely self-taught, and produced representational work in the midst of the Abstract Expressionist movement. His subjects were primarily landscapes, domestic interiors and portraits of family, friends and fellow artists, many of them affiliated with the New York School of writers, including John Ashbery, Frank O'Hara, and James Schuyler. Many of his paintings were set in or around the family summer house on Great Spruce Head Island, Maine.

Also during the 1960s and 1970s, there was a reaction against painting. Critics like Douglas Crimp viewed the work of artists like Ad Reinhardt, and declared the "death of painting". Artists began to practice new ways of making art. New movements gained prominence some of which are: Fluxus, Happening, Video art, Installation art Mail art, the situationists, Conceptual art, Postminimalism, Earth art, arte povera, performance art and body art among others.

Neo-Dada is also a movement that started 1n the 1950s and 1960s and was related to Abstract expressionism only with imagery. Featuring the emergence of combined manufactured items, with artist materials, moving away from previous conventions of painting. This trend in art is exemplified by the work of Jasper Johns and Robert Rauschenberg, whose "combines" in the 1950s were forerunners of Pop Art and Installation art, and made use of the assemblage of large physical objects, including stuffed animals, birds and commercial photography. Robert Rauschenberg, Jasper Johns, Larry Rivers, John Chamberlain, Claes Oldenburg, George Segal, Jim Dine, and Edward Kienholz among others were important pioneers of both abstraction and Pop Art; creating new conventions of art-making; they made acceptable in serious contemporary art circles the radical inclusion of unlikely materials as parts of their works of art.

Color Field painting clearly pointed toward a new direction in American painting, away from abstract expressionism. Color Field painting is related to post-painterly abstraction, suprematism, abstract expressionism, hard-edge painting and Lyrical Abstraction.

During the 1960s and 1970s abstract painting continued to develop in America through varied styles. Geometric abstraction, Op art, hard-edge painting, Color Field painting and minimal painting, were some interrelated directions for advanced abstract painting as well as some other new movements. Morris Louis was an important pioneer in advanced Color Field painting, his work can serve as a bridge between abstract expressionism, Color Field painting, and minimal art. Two influential teachers Josef Albers and Hans Hofmann introduced a new generation of American artists to their advanced theories of color and space. Josef Albers is best remembered for his work as a Geometric abstractionist painter and theorist. Most famous of all are the hundreds of paintings and prints that make up the series "Homage to the Square". In this rigorous series, begun in 1949, Albers explored chromatic interactions with flat colored squares arranged concentrically on the canvas. Albers' theories on art and education were formative for the next generation of artists. His own paintings form the foundation of both hard-edge painting and Op art.

Josef Albers, Hans Hofmann, Ilya Bolotowsky, Burgoyne Diller, Victor Vasarely, Bridget Riley, Richard Anuszkiewicz, Frank Stella, Morris Louis, Kenneth Noland, Ellsworth Kelly, Barnett Newman, Larry Poons, Ronald Davis, Larry Zox, Al Held and some others like Mino Argento, are artists closely associated with Geometric abstraction, Op art, Color Field painting, and in the case of Hofmann and Newman Abstract expressionism as well.

In 1965, an exhibition called "The Responsive Eye", curated by William C. Seitz, was held at the Museum of Modern Art, in New York City. The works shown were wide-ranging, encompassing the Minimalism of Frank Stella, the Op art of Larry Poons, the work of Alexander Liberman, alongside the masters of the Op Art movement: Victor Vasarely, Richard Anuszkiewicz, Bridget Riley and others. The exhibition focused on the perceptual aspects of art, which result both from the illusion of movement and the interaction of color relationships. Op art, also known as optical art, is a style present in some paintings and other works of art that use optical illusions. Op art is also closely akin to geometric abstraction and hard-edge painting. Although sometimes the term used for it is perceptual abstraction.

Op art is a method of painting concerning the interaction between illusion and picture plane, between understanding and seeing. Op art works are abstract, with many of the better known pieces made in only black and white. When the viewer looks at them, the impression is given of movement, hidden images, flashing and vibration, patterns, or alternatively, of swelling or warping.

Color Field painting sought to rid art of superfluous rhetoric. Artists like Clyfford Still, Mark Rothko, Hans Hofmann, Morris Louis, Jules Olitski, Kenneth Noland, Helen Frankenthaler, John Hoyland, Larry Zox, and others often used greatly reduced references to nature, and they painted with a highly articulated and psychological use of color. In general these artists eliminated recognizable imagery. Certain artists quoted references to past or present art, but in general color field painting presents abstraction as an end in itself. In pursuing this direction of modern art, artists wanted to present each painting as one unified, cohesive, monolithic image.

Frank Stella, Kenneth Noland, Ellsworth Kelly, Barnett Newman, Ronald Davis, Neil Williams, Robert Mangold, Charles Hinman, Richard Tuttle, David Novros, and Al Loving are examples of artists associated with the use of the shaped canvas during the period beginning in the early 1960s. Many Geometric abstract artists, minimalists, and Hard-edge painters elected to use the edges of the image to define the shape of the painting rather than accepting the rectangular format. In fact, the use of the shaped canvas is primarily associated with paintings of the 1960s and 1970s that are coolly abstract, formalistic, geometrical, objective, rationalistic, clean-lined, brashly sharp-edged, or minimalist in character. The Andre Emmerich Gallery, the Leo Castelli Gallery, the Richard Feigen Gallery, and the Park Place Gallery were important showcases for Color Field painting, shaped canvas painting and Lyrical Abstraction in New York City during the 1960s. There is a connection with post-painterly abstraction, which reacted against abstract expressionisms' mysticism, hyper-subjectivity, and emphasis on making the act of painting itself dramatically visible – as well as the solemn acceptance of the flat rectangle as an almost ritual prerequisite for serious painting. During the 1960s Color Field painting and Minimal art were often closely associated with each other. In actuality by the early 1970s both movements became decidedly diverse.

Another related movement of the late 1960s, Lyrical Abstraction (the term being coined by Larry Aldrich, the founder of the Aldrich Contemporary Art Museum, Ridgefield Connecticut), encompassed what Aldrich said he saw in the studios of many artists at that time. It is also the name of an exhibition that originated in the Aldrich Museum and traveled to the Whitney Museum of American Art and other museums throughout the United States between 1969 and 1971.

Lyrical Abstraction in the late 1960s is characterized by the paintings of Dan Christensen, Ronnie Landfield, Peter Young and others, and along with the fluxus movement and postminimalism (a term first coined by Robert Pincus-Witten in the pages of "Artforum" in 1969) sought to expand the boundaries of abstract painting and minimalism by focusing on process, new materials and new ways of expression. Postminimalism often incorporating industrial materials, raw materials, fabrications, found objects, installation, serial repetition, and often with references to Dada and Surrealism is best exemplified in the sculptures of Eva Hesse. Lyrical Abstraction, conceptual art, postminimalism, Earth art, video, performance art, installation art, along with the continuation of fluxus, abstract expressionism, Color Field painting, hard-edge painting, minimal art, op art, pop art, photorealism and New Realism extended the boundaries of contemporary art in the mid-1960s through the 1970s. Lyrical Abstraction is a type of freewheeling abstract painting that emerged in the mid-1960s when abstract painters returned to various forms of painterly, pictorial, expressionism with a predominate focus on process, gestalt and repetitive compositional strategies in general.

Lyrical Abstraction shares similarities with color field painting and abstract expressionism, Lyrical Abstraction as exemplified by the 1968 Ronnie Landfield painting "For William Blake", (above) especially in the freewheeling usage of paint – texture and surface. Direct drawing, calligraphic use of line, the effects of brushed, splattered, stained, squeegeed, poured, and splashed paint superficially resemble the effects seen in abstract expressionism and color field painting. However, the styles are markedly different. Setting it apart from abstract expressionism and action painting of the 1940s and 1950s is the approach to composition and drama. As seen in action painting there is an emphasis on brushstrokes, high compositional drama, dynamic compositional tension. While in Lyrical Abstraction there is a sense of compositional randomness, all over composition, low key and relaxed compositional drama and an emphasis on process, repetition, and an all over sensibility.,

Agnes Martin, Robert Mangold, Brice Marden, Jo Baer, Robert Ryman, Richard Tuttle, Neil Williams, David Novros, Paul Mogenson, Charles Hinman are examples of artists associated with Minimalism and (exceptions of Martin, Baer and Marden) the use of the shaped canvas also during the period beginning in the early 1960s. Many Geometric abstract artists, minimalists, and hard-edge painters elected to use the edges of the image to define the shape of the painting rather than accepting the rectangular format. In fact, the use of the shaped canvas is primarily associated with paintings of the 1960s and 1970s that are coolly abstract, formalistic, geometrical, objective, rationalistic, clean-lined, brashly sharp-edged, or minimalist in character. The Bykert Gallery, and the Park Place Gallery were important showcases for Minimalism and shaped canvas painting in New York City during the 1960s.

During the 1960s and 1970s artists such as Robert Motherwell, Adolph Gottlieb, Phillip Guston, Lee Krasner, Cy Twombly, Robert Rauschenberg, Jasper Johns, Richard Diebenkorn, Josef Albers, Elmer Bischoff, Agnes Martin, Al Held, Sam Francis, Ellsworth Kelly, Morris Louis, Helen Frankenthaler, Gene Davis, Frank Stella, Kenneth Noland, Joan Mitchell, Friedel Dzubas, and younger artists like Brice Marden, Robert Mangold, Sam Gilliam, John Hoyland, Sean Scully, Pat Steir, Elizabeth Murray, Larry Poons, Walter Darby Bannard, Larry Zox, Ronnie Landfield, Ronald Davis, Dan Christensen, Joan Snyder, Ross Bleckner, Archie Rand, Susan Crile, and dozens of others produced a wide variety of paintings.

During the 1960s and 1970s, there was a reaction against abstract painting. Some critics viewed the work of artists like Ad Reinhardt, and declared the 'death of painting'. Artists began to practice new ways of making art. New movements gained prominence some of which are: postminimalism, Earth art, video art, installation art, arte povera, performance art, body art, fluxus, happening, mail art, the situationists and conceptual art among others.

However still other important innovations in abstract painting took place during the 1960s and the 1970s characterized by monochrome painting and hard-edge painting inspired by Ad Reinhardt, Barnett Newman, Milton Resnick, and Ellsworth Kelly. Artists as diverse as Agnes Martin, Al Held, Larry Zox, Frank Stella, Larry Poons, Brice Marden and others explored the power of simplification. The convergence of Color Field painting, minimal art, hard-edge painting, Lyrical Abstraction, and postminimalism blurred the distinction between movements that became more apparent in the 1980s and 1990s. The neo-expressionism movement is related to earlier developments in abstract expressionism, neo-Dada, Lyrical Abstraction and postminimal painting.

In the late 1960s the abstract expressionist painter Philip Guston helped to lead a transition from abstract expressionism to Neo-expressionism in painting, abandoning the so-called "pure abstraction" of abstract expressionism in favor of more cartoonish renderings of various personal symbols and objects. These works were inspirational to a new generation of painters interested in a revival of expressive imagery. His painting "Painting, Smoking, Eating" 1973, seen above in the gallery is an example of Guston's final and conclusive return to representation.

In the late 1970s and early 1980s, there was also a return to painting that occurred almost simultaneously in Italy, Germany, France and Britain. These movements were called Transavantguardia, Neue Wilde, Figuration Libre, Neo-expressionism, the school of London, and in the late 1980s the Stuckists respectively. These painting were characterized by large formats, free expressive mark making, figuration, myth and imagination. All work in this genre came to be labeled neo-expressionism. Critical reaction was divided. Some critics regarded it as driven by profit motivations by large commercial galleries. This type of art continues in popularity into the 21st century, even after the art crash of the late 1980s. Anselm Kiefer is a leading figure in European Neo-expressionism by the 1980s, Kiefer's themes widened from a focus on Germany's role in civilization to the fate of art and culture in general. His work became more sculptural and involves not only national identity and collective memory, but also occult symbolism, theology and mysticism. The theme of all the work is the trauma experienced by entire societies, and the continual rebirth and renewal in life.

During the late 1970s in the United States painters who began working with invigorated surfaces and who returned to imagery like Susan Rothenberg gained in popularity, especially as seen above in paintings like "Horse 2", 1979. During the 1980s American artists like Eric Fischl, David Salle, Jean-Michel Basquiat (who began as a graffiti artist), Julian Schnabel, and Keith Haring, and Italian painters like Mimmo Paladino, Sandro Chia, and Enzo Cucchi, among others defined the idea of Neo-expressionism in America.

Neo-expressionism was a style of modern painting that became popular in the late 1970s and dominated the art market until the mid-1980s. It developed in Europe as a reaction against the conceptual and minimalistic art of the 1960s and 1970s. Neo-expressionists returned to portraying recognizable objects, such as the human body (although sometimes in a virtually abstract manner), in a rough and violently emotional way using vivid colours and banal colour harmonies. The veteran painters Philip Guston, Frank Auerbach, Leon Kossoff, Gerhard Richter, A. R. Penck and Georg Baselitz, along with slightly younger artists like Anselm Kiefer, Eric Fischl, Susan Rothenberg, Francesco Clemente, Jean-Michel Basquiat, Julian Schnabel, Keith Haring, and many others became known for working in this intense expressionist vein of painting.

Painting still holds a respected position in contemporary art. Art is an open field no longer divided by the objective versus non-objective dichotomy. Artists can achieve critical success whether their images are representational or abstract. What has currency is content, exploring the boundaries of the medium, and a refusal to recapitulate the works of the past as an end goal.

At the beginning of the 21st century Contemporary painting and Contemporary art in general continues in several contiguous modes, characterized by the idea of pluralism. The "crisis" in painting and current art and current art criticism today is brought about by pluralism. There is no consensus, nor need there be, as to a representative style of the age. There is an "anything goes" attitude that prevails; an "everything going on", and consequently "nothing going on" syndrome; this creates an aesthetic traffic jam with no firm and clear direction and with every lane on the artistic superhighway filled to capacity. Consequently magnificent and important works of art continue to be made albeit in a wide variety of styles and aesthetic temperaments, the marketplace being left to judge merit.

Hard-edge painting, geometric abstraction, appropriation, hyperrealism, photorealism, expressionism, minimalism, Lyrical Abstraction, pop art, op art, abstract expressionism, Color Field painting, monochrome painting, neo-expressionism, collage, intermedia painting, assemblage painting, digital painting, postmodern painting, neo-Dada painting, shaped canvas painting, environmental mural painting, traditional figure painting, landscape painting, portrait painting, are a few continuing and current directions in painting at the beginning of the 21st century.

During the period before and after European exploration and settlement of the Americas, including North America, Central America, South America and the Islands of the Caribbean, the Antilles, the Lesser Antilles and other island groups, indigenous native cultures produced creative works including architecture, pottery, ceramics, weaving, , sculpture, painting and murals as well as other religious and utilitarian objects. Each continent of the Americas hosted societies that were unique and individually developed cultures; that produced totems, works of religious symbolism, and decorative and expressive painted works. African influence was especially strong in the art of the Caribbean and South America. The arts of the indigenous people of the Americas had an enormous impact and influence on European art and vice versa during and after the Age of Exploration. Spain, Portugal, France, The Netherlands, and England were all powerful and influential colonial powers in the Americas during and after the 15th century. By the 19th century cultural influence began to flow both ways across the Atlantic

The depiction of humans, animals or any other figurative subjects is forbidden within Islam to prevent believers from idolatry so there is no religiously motivated painting (or sculpture) tradition within Muslim culture. Pictorial activity was reduced to Arabesque, mainly abstract, with geometrical configuration or floral and plant-like patterns. Strongly connected to architecture and calligraphy, it can be widely seen as used for the painting of tiles in mosques or in illuminations around the text of the Koran and other books. In fact, abstract art is not an invention of modern art but it is present in pre-classical, barbarian and non-western cultures many centuries before it and is essentially a decorative or applied art. Notable illustrator M. C. Escher was influenced by this geometrical and pattern-based art. Art Nouveau (Aubrey Beardsley and the architect Antonio Gaudí) re-introduced abstract floral patterns into western art.

Note that despite the taboo of figurative visualization, some Muslim countries did cultivate a rich tradition in painting, though not in its own right, but as a companion to the written word. Iranian or Persian art, widely known as Persian miniature, concentrates on the illustration of epic or romantic works of literature. Persian illustrators deliberately avoided the use of shading and perspective, though familiar with it in their pre-Islamic history, in order to abide by the rule of not creating any lifelike illusion of the real world. Their aim was not to depict the world as it is, but to create images of an ideal world of timeless beauty and perfect order.

In present days, painting by art students or professional artists in Arab and non-Arab Muslim countries follows the same tendencies of Western culture art.

Oriental historian Basil Gray believes "Iran has offered a particularly unique art to the world which is excellent in its kind". Caves in Iran's Lorestan province exhibit painted imagery of animals and hunting scenes. Some such as those in Fars Province and Sialk are at least 5,000 years old. Painting in Iran is thought to have reached a climax during the Tamerlane era, when outstanding masters such as Kamaleddin Behzad gave birth to a new style of painting.

Paintings of the Qajar period are a combination of European influences and Safavid miniature schools of painting such as those introduced by Reza Abbasi and classical works by Mihr 'Ali. Masters such as Kamal-ol-molk further pushed forward the European influence in Iran. It was during the Qajar era when "Coffee House painting" emerged. Subjects of this style were often religious in nature depicting scenes from Shia epics and the like.

African traditional culture and tribes do not seem to have great interest in two-dimensional representations in favour of sculpture and relief. However, decorative painting in African culture is often abstract and geometrical. Another pictorial manifestation is body painting, and face painting present for example in Maasai and Kĩkũyũ culture in their ceremony rituals. Ceremonial cave painting in certain villages can be found to be still in use. Note that Pablo Picasso and other modern artists were influenced by African sculpture and masks in their varied styles.
Contemporary African artists follow western art movements and their paintings have little difference from occidental art works.

The Kingdom of Kush in ancient Nubia (i.e. modern Sudan), bordering Ancient Egypt, produced a wide variety of arts, including wall paintings and painted objects. At the Sudanese site of Kerma, center of the Kerma culture that predated the Kingdom of Kush, a circa 1700 BC fragmentary painting from a royal tomb depicts a sailing ship and houses with ladders that are similar to scenes in reliefs from the reign of Egyptian queen Hatshepsut (c. 1479–1458 BC). The ancient tradition of wall paintings, first described by Abu Salih during the 12th century AD, continued into the period of medieval Nubia.

The Christian tradition of painting in Ethiopia dates back to the 4th century AD, during the ancient Kingdom of Aksum. During their exile to Axum, the 7th-century followers of Muhammad described paintings decorating the Church of Our Lady Mary of Zion. However, the earliest surviving examples of church paintings in Ethiopia come from the church of Debre Selam Mikael in the Tigray Region, dated to the 11th century AD. Ethiopian paintings in illuminated manuscripts predate the earliest surviving church paintings. For instance, the Ethiopian Garima Gospels of the 4th-6th centuries AD contain illuminated scenes imitating the contemporary Byzantine illuminated style.

At the start of the 20th century, artists like Picasso, Matisse, Paul Gauguin and Modigliani became aware of, and were inspired by, African art. In a situation where the established avant garde was straining against the constraints imposed by serving the world of appearances, African Art demonstrated the power of supremely well organised forms; produced not only by responding to the faculty of sight, but also and often primarily, the faculty of imagination, emotion and mystical and religious experience. These artists saw in African art a formal perfection and sophistication unified with phenomenal expressive power.





</doc>
<doc id="13972" url="https://en.wikipedia.org/wiki?curid=13972" title="Hungarian language">
Hungarian language

Hungarian () is a Uralic language spoken in Hungary and parts of several neighbouring countries. It is the official language of Hungary and one of the 24 official languages of the European Union. Outside Hungary it is also spoken by communities of Hungarians in the countries that today make up Slovakia, western Ukraine (Subcarpathia), central and western Romania (Transylvania), northern Serbia (Vojvodina), northern Croatia and northeastern Slovenia (Mur region).

It is also spoken by Hungarian diaspora communities worldwide, especially in North America (particularly the United States and Canada) and Israel. With 13 million speakers, it is the Uralic family's largest member by number of speakers.

Hungarian is a member of the Uralic language family. Linguistic connections between Hungarian and other Uralic languages were noticed in the 1670s, and the family itself (then called Finno-Ugric) was established in 1717. Hungarian has traditionally been assigned to the Ugric branch within the Finno-Ugric group, along with the Mansi and Khanty languages of western Siberia (Khanty–Mansia region), but it is no longer clear that it is a valid group. When the Samoyed languages were determined to be part of the family, it was thought at first that Finnic and Ugric (Finno-Ugric) were closer to each other than to the Samoyed branch of the family, but that is now frequently questioned.

The name of Hungary could be a result of regular sound changes of "Ungrian/Ugrian", and the fact that the Eastern Slavs referred to Hungarians as "Ǫgry/Ǫgrove" (sg. "Ǫgrinŭ") seemed to confirm that. Current literature favors the hypothesis that it comes from the name of the Turkic tribe Onoğur (which means "ten arrows" or "ten tribes").

There are numerous regular sound correspondences between Hungarian and the other Ugric languages. For example, Hungarian corresponds to Khanty in certain positions, and Hungarian corresponds to Khanty , while Hungarian final corresponds to Khanty final . For example, Hungarian "ház" "house" vs. Khanty "xot" "house", and Hungarian "száz" "hundred" vs. Khanty "sot" "hundred". The distance between the Ugric and Finnic languages is greater, but the correspondences are also regular.

The traditional view holds that the Hungarian language diverged from its Ugric relatives in the first half of the 1st millennium BC, in western Siberia east of the southern Urals. The Hungarians gradually changed their lifestyle from being settled hunters to being nomadic pastoralists, probably as a result of early contacts with Iranian (Scythians and Sarmatians) or Turkic nomads. In Hungarian, Iranian loanwords date back to the time immediately following the breakup of Ugric and probably span well over a millennium. Among these include "tehén" ‘cow’ (cf. Avestan "daénu"); "tíz" ‘ten’ (cf. Avestan "dasa"); "tej" ‘milk’ (cf. Persian "dáje" ‘wet nurse’); and "nád" ‘reed’ (from late Middle Iranian; cf. Middle Persian "nāy").

Archaeological evidence from present day southern Bashkortostan confirms the existence of Hungarian settlements between the Volga River and the Ural Mountains. The Onoğurs (and Bulgars) later had a great influence on the language, especially between the 5th and 9th centuries. This layer of Turkic loans is large and varied (e.g. "szó" "word", from Turkic; and "daru" "crane", from the related Permic languages), and includes words borrowed from Oghur Turkic; e.g. "borjú" "calf" (cf. Chuvash "păru", "părăv" vs. Turkish "buzağı"); "dél" ‘noon; south’ (cf. Chuvash "tĕl" vs. Turkish dial. "düš"). Many words related to agriculture, state administration and even family relationships show evidence of such backgrounds. Hungarian syntax and grammar were not influenced in a similarly dramatic way over these three centuries.

After the arrival of the Hungarians in the Carpathian Basin, the language came into contact with a variety of speech communities, among them Slavic, Turkic, and German. Turkic loans from this period come mainly from the Pechenegs and Cumanians, who settled in Hungary during the 12th and 13th centuries: e.g. "koboz" "cobza" (cf. Turkish "kopuz" ‘lute’); "komondor" "mop dog" (< *"kumandur" < "Cuman"). Hungarian borrowed many words from neighbouring Slavic languages: e.g. "tégla" ‘brick’; "mák" ‘poppy seed’; "karácsony" ‘Christmas’). These languages in turn borrowed words from Hungarian: e.g. Serbo-Croatian "ašov" from Hungarian "ásó" ‘spade’. About 1.6 percent of the Romanian lexicon is of Hungarian origin.

Recent studies support an origin of the Uralic languages, including early Hungarian, in eastern or central Siberia, somewhere between the Ob and Yenisei river or near the Sayan mountains in the Russian–Mongolian borderregion. A 2019 study based on genetics, archaeology and linguistics, found that early Uralic speakers arrived in Europe from the east, specifically from eastern Siberia.

Hungarian historian and archaeologist Gyula László claims that geological data from pollen analysis seems to contradict the placing of the ancient Hungarian homeland near the Urals.

There have been attempts to show that Hungarian is related to other languages, such as Hebrew, Hunnic, Sumerian, Egyptian, Etruscan, Basque, Persian, Pelasgian, Greek, Chinese, Sanskrit, English, Tibetan, Magar, Quechua, Armenian, Japanese, and at least 40 other languages. Mainstream linguists dismiss these attempts as pseudoscientific comparisons with no merit.

Today the consensus among linguists is that Hungarian is a member of the Uralic family of languages.

The classification of Hungarian as a Uralic/Finno-Ugric rather than a Turkic language continued to be a matter of impassioned political controversy throughout the 18th and into the 19th centuries. During the latter half of the 19th century, a competing hypothesis proposed a Turkic affinity of Hungarian, or, alternatively, that both the Uralic and the Turkic families formed part of a superfamily of Ural–Altaic languages. Following an academic debate known as "Az ugor-török háború" ("the Ugric-Turkic war"), the Finno-Ugric hypothesis was concluded the sounder of the two, mainly based on work by the German linguist .

Hungarians did in fact absorb some Turkic influences during several centuries of cohabitation. For example, the Hungarians appear to have learned animal husbandry techniques from the Turkic Chuvash people, as a high proportion of words specific to agriculture and livestock are of Chuvash origin. A strong Chuvash influence was also apparent in Hungarian burial customs.

The first written accounts of Hungarian date to the 10th century, such as mostly Hungarian personal names and place names in "De Administrando Imperio", written in Greek by Eastern Roman Emperor Constantine VII. No significant texts written in Old Hungarian script have survived, as wood, the medium of writing in use at the time, was perishable.

The Kingdom of Hungary was founded in 1000 by Stephen I. The country became a Western-styled Christian (Roman Catholic) state, with Latin script replacing Hungarian runes. The earliest remaining fragments of the language are found in the establishing charter of the abbey of Tihany from 1055, intermingled with Latin text. The first extant text fully written in Hungarian is the Funeral Sermon and Prayer, which dates to the 1190s. Although the orthography of these early texts differed considerably from that used today, contemporary Hungarians can still understand a great deal of the reconstructed spoken language, despite changes in grammar and vocabulary.

A more extensive body of Hungarian literature arose after 1300. The earliest known example of Hungarian religious poetry is the 14th-century "Lamentations of Mary". The first Bible translation was the Hussite Bible in the 1430s.

The standard language lost its diphthongs, and several postpositions transformed into suffixes, including "reá" "onto" (the phrase "utu rea "onto the way" found in the 1055 text would later become "útra). There were also changes in the system of vowel harmony. At one time, Hungarian used six verb tenses, while today only two or three are used.

In 1533, Kraków printer Benedek Komjáti published (modern orthography: ), the first Hungarian-language book set in movable type.

By the 17th century, the language already closely resembled its present-day form, although two of the past tenses remained in use. German, Italian and French loans also began to appear. Further Turkish words were borrowed during the period of Ottoman rule (1541 to 1699).

In the 19th century a group of writers, most notably Ferenc Kazinczy, spearheaded a process of "nyelvújítás" (language revitalization). Some words were shortened ("győzedelem" > "győzelem", 'triumph' or 'victory'); a number of dialectal words spread nationally ("e.g.", "cselleng" 'dawdle'); extinct words were reintroduced ("dísz", 'décor'); a wide range of expressions were coined using the various derivative suffixes; and some other, less frequently used methods of expanding the language were utilized. This movement produced more than ten thousand words, most of which are used actively today.

The 19th and 20th centuries saw further standardization of the language, and differences between mutually comprehensible dialects gradually diminished.

In 1920, Hungary signed the Treaty of Trianon, losing 71 percent of its territory and one-third of the ethnic Hungarian population along with it.

Today the language holds official status nationally in Hungary and regionally in Romania, Slovakia, Serbia, Austria and Slovenia.

Hungarian has about 13 million native speakers, of whom more than 9.8 million live in Hungary. According to the 2011 Hungarian census, 9,896,333 people (99.6% of the total population) speak Hungarian, of whom 9,827,875 people (98.9%) speak it as a first language, while 68,458 people (0.7%) speak it as a second language. About 2.2 million speakers live in other areas that were part of the Kingdom of Hungary before the Treaty of Trianon (1920). Of these, the largest group lives in Transylvania, the western half of present-day Romania, where there are approximately 1.25 million Hungarians. There are large Hungarian communities also in Slovakia, Serbia and Ukraine, and Hungarians can also be found in Austria, Croatia, and Slovenia, as well as about a million additional people scattered in other parts of the world. For example, there are more than one hundred thousand Hungarian speakers in the Hungarian American community and 1.5 million with Hungarian ancestry in the United States.

Hungarian is the official language of Hungary, and thus an official language of the European Union. Hungarian is also one of the official languages of Vojvodina and an official language of three municipalities in Slovenia: Hodoš, Dobrovnik and Lendava, along with Slovene. Hungarian is officially recognized as a minority or regional language in Austria, Croatia, Romania, Zakarpattia in Ukraine, and Slovakia. In Romania it is a recognized minority language used at local level in communes, towns and municipalities with an ethnic Hungarian population of over 20%.

The dialects of Hungarian identified by Ethnologue are: Alföld, West Danube, Danube-Tisza, King's Pass Hungarian, Northeast Hungarian, Northwest Hungarian, Székely and West Hungarian. These dialects are, for the most part, mutually intelligible. The Hungarian Csángó dialect, which is mentioned but not listed separately by Ethnologue, is spoken primarily in Bacău County in eastern Romania. The Csángó Hungarian group has been largely isolated from other Hungarian people, and they therefore preserved features that closely resemble earlier forms of Hungarian.

Hungarian has 14 vowel phonemes and 25 consonant phonemes. The vowel phonemes can be grouped as pairs of short and long vowels such as "o" and "ó". Most of the pairs have a similar pronunciation and vary significantly only in their duration. However, pairs "a"/"á" and "e"/"é" differ both in closedness and length.

Consonant length is also distinctive in Hungarian. Most consonant phonemes can occur as geminates.

The sound voiced palatal plosive , written , sounds similar to 'd' in British English 'duty'. It occurs in the name of the country, "Magyarország" (Hungary), pronounced . It is one of three palatalised consonants, the others being and . Historically a fourth palatalized consonant existed, still written .

A single 'r' is pronounced as an alveolar tap ("akkora" 'of that size'), but a double 'r' is pronounced as an alveolar trill ("akkorra" 'by that time'), like in Spanish.

Primary stress is always on the first syllable of a word, as in Finnish and the neighbouring Slovak and Czech. There is a secondary stress on other syllables in compounds: "viszontlátásra" ("goodbye") is pronounced . Elongated vowels in non-initial syllables may seem to be stressed to an English-speaker, as length and stress correlate in English.

Hungarian is an agglutinative language. It uses various affixes, mainly suffixes but also some prefixes and a circumfix, to change a word's meaning and its grammatical function.

Hungarian uses vowel harmony to attach suffixes to words. That means that most suffixes have two or three different forms, and the choice between them depends on the vowels of the head word. There are some minor and unpredictable exceptions to the rule.

Nouns have 18 cases, which are formed regularly with suffixes. The nominative case is unmarked ("az alma" 'the apple') and, for example, the accusative is marked with the suffix "–t" ("az almát" '[I eat] the apple'). Half of the cases express a combination of the source-location-target and surface-inside-proximity ternary distinctions (three times three cases); there is a separate case ending –"ból"/"–ből" meaning a combination of source and insideness: 'from inside of'.

Possession is expressed by a possessive suffix on the possessed object, rather than the possessor as in English (Peter's apple becomes "Péter almája", literally 'Peter apple-his'). Noun plurals are formed with"–k" ("az almák" ‘the apples’), but after a numeral, the singular is used ("két alma" ‘two apples’, literally ‘two apple’; not "*két almák").

Unlike English, Hungarian uses case suffixes and nearly always postpositions instead of prepositions.

There are two types of articles in Hungarian, definite and indefinite, which roughly correspond to the equivalents in English.

Adjectives precede nouns ("a piros alma" 'the red apple') and have three degrees: positive ("piros" 'red'), comparative ("pirosabb" 'redder') and superlative ("a legpirosabb" 'the reddest').

If the noun takes the plural or a case, an attributive adjective is invariable: "a piros almák" 'the red apples'. However, a predicative adjective agrees with the noun: "az almák pirosak" 'the apples are red'. Adjectives by themselves can behave as nouns (and so can take case suffixes): "Melyik almát kéred? – A pirosat." 'Which apple would you like? – The red one'.

The neutral word order is subject–verb–object (SVO). However, Hungarian is a topic-prominent language, and so has a word order that depends not only on syntax but also on the topic–comment structure of the sentence (for example, what aspect is assumed to be known and what is emphasized).

A Hungarian sentence generally has the following order: topic, comment (or focus), verb and the rest.

The topic shows that the proposition is only for that particular thing or aspect, and it implies that the proposition is not true for some others. For example, in ""Az almát János látja"." ('It is John who sees the apple'. Literally 'The apple John sees.'), the apple is in the topic, implying that other objects may be seen by not him but other people (the pear may be seen by Peter). The topic part may be empty.

The focus shows the new information for the listeners that may not have been known or that their knowledge must be corrected. For example, "Én vagyok az apád". ('I am your father'. Literally, 'It is I who am your father'.), from the movie "The Empire Strikes Back", the pronoun I ("én") is in the focus and implies that it is new information, and the listener thought that someone else is his father.

Although Hungarian is sometimes described as having free word order, different word orders are generally not interchangeable, and the neutral order is not always correct to use. Also, the intonation is also different with different topic-comment structures. The topic usually has a rising intonation, the focus having a falling intonation. In the following examples, the topic is marked with italics, and the focus (comment) is marked with boldface.

Hungarian has a four-tiered system for expressing levels of politeness. From highest to lowest:


The four-tiered system has somewhat been eroded due to the recent expansion of ""tegeződés"".

Some anomalies emerged with the arrival of multinational companies who have addressed their customers in the "te" (least polite) form right from the beginning of their presence in Hungary. A typical example is the Swedish furniture shop IKEA, whose web site and other publications address the customers in "te" form. When a news site asked IKEA—using the "te" form—why they address their customers this way, IKEA's PR Manager explained in his answer—using the "ön" form—that their way of communication reflects IKEA's open-mindedness and the Swedish culture. However IKEA in France uses the polite ("vous") form. Another example is the communication of Telenor (a mobile network operator) towards its customers. Telenor chose to communicate towards business customers in the polite "ön" form while all other customers are addressed in the less polite "te" form.

During the first early phase of Hungarian language reforms (late 18th and early 19th centuries) more than ten thousand words were coined, several thousand of which are still actively used today (see also Ferenc Kazinczy, the leading figure of the Hungarian language reforms.) Kazinczy's chief goal was to replace existing words of German and Latin origins with newly-created Hungarian words. As a result, Kazinczy and his later followers (the reformers) significantly reduced the formerly high ratio of words of Latin and German origins in the Hungarian language, which were related to social sciences, natural sciences, politics and economics, institutional names, fashion etc.
Giving an accurate estimate for the total word count is difficult, since it is hard to define "a word" in agglutinating languages, due to the existence of affixed words and compound words. To obtain a meaningful definition of compound words, we have to exclude such compounds whose meaning is the mere sum of its elements. The largest dictionaries giving translations from Hungarian to another language contain 120,000 words and phrases (but this may include redundant phrases as well, because of translation issues). The new desk lexicon of the Hungarian language contains 75,000 words and the Comprehensive Dictionary of Hungarian Language (to be published in 18 volumes in the next twenty years) is planned to contain 110,000 words. The default Hungarian lexicon is usually estimated to comprise 60,000 to 100,000 words. (Independently of specific languages, speakers actively use at most 10,000 to 20,000 words, with an average intellectual using 25,000 to 30,000 words.) However, all the Hungarian lexemes collected from technical texts, dialects etc. would total up to 1,000,000 words.

Parts of the lexicon can be organized using word-bushes. (See an example on the right.) The words in these bushes share a common root, are related through inflection, derivation and compounding, and are usually broadly related in meaning.

The basic vocabulary shares several hundred word roots with other Uralic languages like Finnish, Estonian, Mansi and Khanty. Examples are the verb "él" "live" (Finnish "elää"), the numbers "kettő" (2), "három" (3), "négy" (4) (cf. Mansi китыг "kitig", хурум "khurum", нила "nila", Finnish "kaksi, kolme, neljä", Estonian "kaks, kolm, neli", ), as well as "víz" 'water', "kéz" 'hand', "vér" 'blood', "fej" 'head' (cf. Finnish and Estonian "vesi, käsi, veri", Finnish "pää", Estonian "pea" or "pää").

Words for elementary kinship and nature are more Ugric, less r-Turkic and less Slavic. Agricultural words are about 50% r-Turkic and 50% Slavic; pastoral terms are more r-Turkic, less Ugric and less Slavic. Finally, Christian and state terminology is more Slavic and less r-Turkic. The Slavic is most probably proto-Slovakian and/or -Slovenian. This is easily understood in the Uralic paradigm, proto-Magyars were first similar to Ob-Ugors who were mainly hunters, fishers and gatherers, but with some horses, too. Then they accultured to Bulgarian r-Turks, so the older layer of agriculture words (wine, beer, wheat, barley &c.) are purely r-Turkic, and many terms of statesmanship and religion were, too.

Except for a few Latin and Greek loan-words, these differences are unnoticed even by native speakers; the words have been entirely adopted into the Hungarian lexicon. There are an increasing number of English loan-words, especially in technical fields.

Another source differs in that loanwords in Hungarian are held to constitute about 45% of bases in the language. Although the lexical percentage of native words in Hungarian is 55%, their use accounts for 88.4% of all words used (the percentage of loanwords used being just 11.6%). Therefore, the history of Hungarian has come, especially since the 19th century, to favor neologisms from original bases, whilst still having developed as many terms from neighboring languages in the lexicon.

Words can be compounds or derived. Most derivation is with suffixes, but there is a small set of derivational prefixes as well.

Compounds have been present in the language since the Proto-Uralic era. Numerous ancient compounds transformed to base words during the centuries. Today, compounds play an important role in vocabulary.

A good example is the word "arc":

Compounds are made up of two base words: the first is the prefix, the latter is the suffix. A compound can be "subordinative": the prefix is in logical connection with the suffix. If the prefix is the subject of the suffix, the compound is generally classified as a subjective one. There are objective, determinative, and adjunctive compounds as well. Some examples are given below:

According to current orthographic rules, a subordinative compound word has to be written as a single word, without spaces; however, if the length of a compound of three or more words (not counting one-syllable verbal prefixes) is seven or more syllables long (not counting case suffixes), a hyphen must be inserted at the appropriate boundary to ease the determination of word boundaries for the reader.

Other compound words are "coordinatives": there is no concrete relation between the prefix and the suffix. Subcategories include reduplication (to emphasise the meaning; "olykor-olykor"
'really occasionally'), twin words (where a base word and a distorted form of it makes up a compound: "gizgaz", where the suffix 'gaz' means 'weed' and the prefix "giz" is the distorted form; the compound itself means 'inconsiderable weed'), and such compounds which have meanings, but neither their prefixes, nor their suffixes make sense (for example, "hercehurca" 'complex, obsolete procedures').

A compound also can be made up by multiple (i.e., more than two) base words: in this case, at least one word element, or even both the prefix and the suffix is a compound. Some examples:

Hungarian words for the points of the compass are directly derived from the position of the Sun during the day in the Northern Hemisphere.


There are two basic words for "red" in Hungarian: "piros" and "vörös" (variant: "veres"; compare with Estonian "verev" or Finnish "punainen"). (They are basic in the sense that one is not a sub-type of the other, as the English "scarlet" is of "red".) The word "vörös" is related to "vér", meaning "blood" (Finnish and Estonian "veri"). When they refer to an actual difference in colour (as on a colour chart), "vörös" usually refers to the deeper (darker and/or more red and less orange) hue of red. In English similar differences exist between "scarlet" and "red". While many languages have multiple names for this colour, often Hungarian scholars assume this is unique in recognizing two shades of red as separate and distinct "folk colours".

However, the two words are also used independently of the above in collocations. "Piros" is learned by children first, as it is generally used to describe inanimate, artificial things, or things seen as cheerful or neutral, while "vörös" typically refers to animate or natural things (biological, geological, physical and astronomical objects), as well as serious or emotionally charged subjects.

When the rules outlined above are in contradiction, typical collocations usually prevail. In some cases where a typical collocation does not exist, the use of either of the two words may be equally adequate.

Examples:

The Hungarian words for brothers and sisters are differentiated based upon relative age. There is also a general word for "sibling": "testvér", from "test" "body" and "vér" "blood"; "i.e.", originating from the same body and blood.

In addition, there are separate prefixes for several ancestors and descendants:

The words for "boy" and "girl" are applied with possessive suffixes. Nevertheless, the terms are differentiated with different declension or lexemes:

"Fia" is only used in this, irregular possessive form; it has no nominative on its own (see inalienable possession). However, the word "fiú" can also take the regular suffix, in which case the resulting word "(fiúja)" will refer to a lover or partner (boyfriend), rather than a male offspring.

The word "fiú" (boy) is also often noted as an extreme example of the ability of the language to add suffixes to a word, by forming "fiaiéi", adding vowel-form suffixes only, where the result is quite a frequently used word:


The above word is often considered to be the longest word in Hungarian, although there are longer words like:


Words of such length are not used in practice, and are difficult to understand even for natives. They were invented to show, in a somewhat facetious way, the ability of the language to form long words (see agglutinative language). They are not compound words—they are formed by adding a series of one and two-syllable suffixes (and a few prefixes) to a simple root ("szent", saint or holy).
There is virtually no limit for the length of words, but when too many suffixes are added, the meaning of the word becomes less clear, and the word becomes hard to understand, and will work like a riddle even for native speakers.

The English word best known as being of Hungarian origin is probably "paprika", from Serbo-Croatian "papar" "pepper" and the Hungarian diminutive "-ka". The most common however is "coach", from "kocsi", originally "kocsi szekér" "car from/in the style of Kocs". Others are:


The Hungarian language was originally written in right-to-left Old Hungarian runes, superficially similar in appearance to the better-known futhark runes but unrelated. After Stephen I of Hungary established the Kingdom of Hungary in the year 1000, the old system was gradually discarded in favour of the Latin alphabet and left-to-right order. Although now not used at all in everyday life, the old script is still known and practised by some enthusiasts.

Modern Hungarian is written using an expanded Latin alphabet, and has a phonemic orthography, i.e. pronunciation can generally be predicted from the written language. In addition to the standard letters of the Latin alphabet, Hungarian uses several modified Latin characters to represent the additional vowel sounds of the language. These include letters with acute accents "(á, é, í, ó, ú)" to represent long vowels, and umlauts ("ö" and "ü") and their long counterparts "ő" and "ű" to represent front vowels. Sometimes (usually as a result of a technical glitch on a computer) or is used for , and for . This is often due to the limitations of the Latin-1 / ISO-8859-1 code page. These letters are not part of the Hungarian language, and are considered misprints. Hungarian can be properly represented with the Latin-2 / ISO-8859-2 code page, but this code page is not always available. (Hungarian is the only language using both and .) Unicode includes them, and so they can be used on the Internet.

Additionally, the letter pairs , , and represent the palatal consonants , , and (roughly analogous to the "d+y" sounds in British ""du"ke" or American "woul"d y"ou")—produced using a similar mechanism as the letter "d" when pronounced with the tongue pointing to the palate.

Hungarian uses for and for , which is the reverse of Polish usage. The letter is and is . These digraphs are considered single letters in the alphabet. The letter is also a "single letter digraph", but is pronounced like (English ), and appears mostly in old words. The letters and are exotic remnants and are hard to find even in longer texts. Some examples still in common use are "madzag" ("string"), "edzeni" ("to train (athletically)") and "dzsungel" ("jungle").

Sometimes additional information is required for partitioning words with digraphs: házszám ("street number") = "ház" ("house") + "szám" ("number"), not an unintelligible "házs" + "zám".

Hungarian distinguishes between long and short vowels, with long vowels written with acutes. It also distinguishes between long and short consonants, with long consonants being doubled. For example, "lenni" ("to be"), "hozzászólás" ("comment"). The digraphs, when doubled, become trigraphs: + = , e.g. "művésszel" ("with an artist"). But when the digraph occurs at the end of a line, all of the letters are written out. For example, ("with a bus"):

When the first lexeme of a compound ends in a digraph and the second lexeme starts with the same digraph, both digraphs are written out: "jegy" + "gyűrű" = "jegygyűrű" ("engagement/wedding ring", "jegy" means "sign", "mark". The term "jegyben lenni/járni" means "to be engaged"; "gyűrű" means "ring").

Usually a trigraph is a double digraph, but there are a few exceptions: "tizennyolc" ("eighteen") is a concatenation of "tizen" + "nyolc". There are doubling minimal pairs: "tol" ("push") vs. "toll" ("feather" or "pen").

While to English speakers they may seem unusual at first, once the new orthography and pronunciation are learned, written Hungarian is almost completely phonemic (except for etymological spellings and "ly, j" representing ).

The word order is basically from general to specific. This is a typical analytical approach and is used generally in Hungarian.

The Hungarian language uses the so-called eastern name order, in which the surname (general, deriving from the family) comes first and the given name comes last. If a second given name is used, this follows the first given name.

For clarity, in foreign languages Hungarian names are usually represented in the western name order. Sometimes, however, especially in the neighbouring countries of Hungary – where there is a significant Hungarian population – the Hungarian name order is retained, as it causes less confusion there.

For an example of foreign use, the birth name of the Hungarian-born physicist called the "father of the hydrogen bomb" was Teller Ede, but he immigrated to the United States in the 1930s and thus became known as Edward Teller. Prior to the mid-20th century, given names were usually translated along with the name order; this is no longer as common. For example, the pianist uses "András Schiff" when abroad, not "Andrew Schiff" (in Hungarian "Schiff András"). If a second given name is present, it becomes a middle name and is usually written out in full, rather than truncated to an initial.

In modern usage, foreign names retain their order when used in Hungarian. Therefore:


Before the 20th century, not only was it common to reverse the order of foreign personalities, they were also "Hungarianised": "Goethe János Farkas" (originally Johann Wolfgang Goethe). This usage sounds odd today, when only a few well-known personalities are referred to using their Hungarianised names, including "Verne Gyula" (Jules Verne), "Marx Károly" (Karl Marx), "Kolumbusz Kristóf" (Christopher Columbus; note that the last of these is also translated in English from the original Italian or possibly Ligurian).

Some native speakers disapprove of this usage; the names of certain historical religious personalities (including popes), however, are always Hungarianised by practically all speakers, such as "Luther Márton" (Martin Luther), "Husz János" (Jan Hus), "Kálvin János" (John Calvin); just like the names of monarchs, for example the king of Spain, Juan Carlos I is referred to as "I. János Károly" or the queen of the UK, Elizabeth II is referred to as "II. Erzsébet".

Japanese names, which are usually written in western order in the rest of Europe, retain their original order in Hungarian, e. g. "Kuroszava Akira" instead of Akira Kurosawa.

The Hungarian convention for date and time is to go from the generic to the specific: 1. year, 2. month, 3. day, 4. hour, 5. minute, (6. second)

The year and day are always written in Arabic numerals, followed by a full stop. The month can be written by its full name or can be abbreviated, or even denoted by Roman or Arabic numerals. Except for the first case (month written by its full name), the month is followed by a full stop. Usually, when the month is written in letters, there is no leading zero before the day. On the other hand, when the month is written in Arabic numerals, a leading zero is common, but not obligatory. Except at the beginning of a sentence, the name of the month always begins with a lower-case letter.

Hours, minutes, and seconds are separated by a colon (H:m:s). Fractions of a second are separated by a full stop from the rest of the time. Hungary generally uses the 24-hour clock format, but in verbal (and written) communication 12-hour clock format can also be used. See below for usage examples.

Date and time may be separated by a comma or simply written one after the other.


Date separated by hyphen is also spreading, especially on datestamps. Here – just like the version separated by full stops – leading zeros are in use.


When only hours and minutes are written in a sentence (so not only "displaying" time), these parts can be separated by a full stop (e.g. "Találkozzunk 10.35-kor." – "Let's meet at 10.35."), or it is also regular to write hours in normal size, and minutes put in superscript (and not necessarily) underlined (e.g. "A találkozó 10-kor kezdődik." "or" "A találkozó 10-kor kezdődik." – "The meeting begins at 10.35.").

Also, in verbal and written communication it is common to use "délelőtt" (literally "before noon") and "délután" (lit. "after noon") abbreviated as "de." and "du." respectively. Délelőtt and délután is said or written before the time, e.g. "Délután 4 óra van." – "It's 4 p.m.". However e.g. "délelőtt 5 óra" (should mean "5 a.m.") or "délután 10 óra" (should mean "10 p.m.") are never used, because at these times the sun is not up, instead "hajnal" ("dawn"), "reggel" ("morning"), "este" ("evening") and "éjjel" ("night") is used, however there are no exact rules for the use of these, as everybody uses them according to their habits (e.g. somebody may have woken up at 5 a.m. so he/she says "Reggel 6-kor ettem." – "I had food at "*morning" 6.", and somebody woke up at 11 a.m. so he/she says "Hajnali 6-kor még aludtam." – "I was still sleeping at "*dawn" 6."). Roughly, these expressions mean these times:


Although address formatting is increasingly being influenced by standard European conventions, the traditional Hungarian style is:

Budapest, Deák Ferenc tér 1. 1052

So the order is: 1) settlement (most general), 2) street/square/etc. (more specific), 3) house number (most specific) 4)(HU-)postcode. The house number may be followed by the storey and door numbers. The HU- part before the postcode is only for incoming postal traffic from foreign countries. Addresses on envelopes and postal parcels should be formatted and placed on the right side as follows:

Name of the recipient
Settlement
Street address (up to door number if necessary)
(HU-)postcode

"Note: The stress is always placed on the first syllable of each word. The remaining syllables all receive an equal, lesser stress. All syllables are pronounced clearly and evenly, even at the end of a sentence, unlike in English."












</doc>
<doc id="13974" url="https://en.wikipedia.org/wiki?curid=13974" title="Hymenoptera">
Hymenoptera

Females typically have a special ovipositor for inserting eggs into hosts or places that are otherwise inaccessible. The ovipositor is often modified into a stinger. The young develop through holometabolism (complete metamorphosis)—that is, they have a worm-like larval stage and an inactive pupal stage before they mature.

The name Hymenoptera refers to the wings of the insects, but the original derivation is ambiguous. All references agree that the derivation involves the Ancient Greek πτερόν ("pteron") for wing. The Ancient Greek ὑμήν ("hymen") for membrane provides a plausible etymology for the term because species in this order have membranous wings. However, a key characteristic of this order is that the hind wings are connected to the fore wings by a series of hooks. Thus, another plausible etymology involves Hymen, the Ancient Greek god of marriage, as these insects have "married wings" in flight.

The cladogram of external relationships, based on a 2008 DNA and protein analysis, shows the order as a clade, most closely related to endopterygote orders including the Diptera (true flies) and Lepidoptera (butterflies and moths).
Hymenoptera originated in the Triassic, with the oldest fossils belonging to the family Xyelidae. Social hymenopterans appeared during the Cretaceous. The evolution of this group has been intensively studied by Alex Rasnitsyn, Michael S. Engel, and others.
This clade has been studied by examining the mitochondrial DNA. Although this study was unable to resolve all the ambiguities in this clade, some relationships could be established. The Aculeata, Ichneumonomorpha, and Proctotrupomorpha were monophyletic. The Megalyroidea and Trigonalyoidea are sister clades as are the Chalcidoidea+Diaprioidea. The Cynipoidea was generally recovered as the sister group to Chalcidoidea and Diaprioidea which are each other's closest relations. 
The cladogram is based on Schulmeister 2003.

Hymenopterans range in size from very small to large insects, and usually have two pairs of wings. Their mouthparts are adapted for chewing, with well-developed mandibles (ectognathous mouthparts). Many species have further developed the mouthparts into a lengthy proboscis, with which they can drink liquids, such as nectar. They have large compound eyes, and typically three simple eyes, ocelli.

The forward margin of the hind wing bears a number of hooked bristles, or "hamuli", which lock onto the fore wing, keeping them held together. The smaller species may have only two or three hamuli on each side, but the largest wasps may have a considerable number, keeping the wings gripped together especially tightly. Hymenopteran wings have relatively few veins compared with many other insects, especially in the smaller species.

In the more ancestral hymenopterans, the ovipositor is blade-like, and has evolved for slicing plant tissues. In the majority, however, it is modified for piercing, and, in some cases, is several times the length of the body. In some species, the ovipositor has become modified as a stinger, and the eggs are laid from the base of the structure, rather than from the tip, which is used only to inject venom. The sting is typically used to immobilise prey, but in some wasps and bees may be used in defense.

Hymenopteran larvae typically have a distinct head region, three thoracic segments, and usually nine or 10 abdominal segments. In the suborder Symphyta, the larvae resemble caterpillars in appearance, and like them, typically feed on leaves. They have large chewing mandibles, three pairs of thoracic limbs, and, in most cases, six or eight abdominal prolegs. Unlike caterpillars, however, the prolegs have no grasping spines, and the antennae are reduced to mere stubs. Symphytan larvae that are wood borers or stem borers have no abdominal legs and the thoracic legs are smaller than those of non-borers.

With rare exceptions, larvae of the suborder Apocrita have no legs and are maggotlike in form, and are adapted to life in a protected environment. This may be the body of a host organism, or a cell in a nest, where the adults will care for the larva. In parasitic forms, the head is often greatly reduced and partially withdrawn into the prothorax (anterior part of the thorax). Sense organs appear to be poorly developed, with no ocelli, very small or absent antennae, and toothlike, sicklelike, or spinelike mandibles. They are also unable to defecate until they reach adulthood due to having an incomplete digestive tract (a blind sac), presumably to avoid contaminating their environment. The larvae of stinging forms (Aculeata) generally have 10 pairs of spiracles, or breathing pores, whereas parasitic forms usually have nine pairs present.

Among most or all hymenopterans, sex is determined by the number of chromosomes an individual possesses. Fertilized eggs get two sets of chromosomes (one from each parent's respective gametes) and develop into diploid females, while unfertilized eggs only contain one set (from the mother) and develop into haploid males. The act of fertilization is under the voluntary control of the egg-laying female, giving her control of the sex of her offspring. This phenomenon is called haplodiploidy.

However, the actual genetic mechanisms of haplodiploid sex determination may be more complex than simple chromosome number. In many Hymenoptera, sex is actually determined by a single gene locus with many alleles. In these species, haploids are male and diploids heterozygous at the sex locus are female, but occasionally a diploid will be homozygous at the sex locus and develop as a male, instead. This is especially likely to occur in an individual whose parents were siblings or other close relatives. Diploid males are known to be produced by inbreeding in many ant, bee, and wasp species. Diploid biparental males are usually sterile but a few species that have fertile diploid males are known.

One consequence of haplodiploidy is that females on average actually have more genes in common with their sisters than they do with their own daughters. Because of this, cooperation among kindred females may be unusually advantageous, and has been hypothesized to contribute to the multiple origins of eusociality within this order. In many colonies of bees, ants, and wasps, worker females will remove eggs laid by other workers due to increased relatedness to direct siblings, a phenomenon known as worker policing.

Another consequence is that hymenopterans may be more resistant to the deleterious effects of inbreeding. As males are haploid, any recessive genes will automatically be expressed, exposing them to natural selection. Thus, the genetic load of deleterious genes is purged relatively quickly.

Some hymenopterans take advantage of parthenogenesis, the creation of embryos without fertilization. Thelytoky is a particular form of parthenogenesis in which female embryos are created (without fertilisation). The form of thelytoky in hymenopterans is a kind of automixis in which two haploid products (proto-eggs) from the same meiosis fuse to form a diploid zygote. This process tends to maintain heterozygosity in the passage of the genome from mother to daughter. It is found in several ant species including the desert ant "Cataglyphis cursor", the clonal raider ant "Cerapachys biroi", the predaceous ant "Platythyrea punctata", and the electric ant (little fire ant) "Wasmannia auropunctata". It also occurs in the Cape honey bee "Apis mellifera capensis".

Oocytes that undergo automixis with central fusion often have a reduced rate of crossover recombination, which helps to maintain heterozygosity and avoid inbreeding depression. Species that display central fusion with reduced recombination include the ants "Platythyrea punctata" and " Wasmannia auropunctata" and the honey bee "Apis mellifera capensis". In "A. m. capensis", the recombination rate during meiosis is reduced more than tenfold. In "W. auropunctata" the reduction is 45 fold.

Single queen colonies of the narrow headed ant "Formica exsecta" illustrate the possible deleterious effects of increased homozygosity. Colonies of this species which have more homozygous queens will age more rapidly, resulting in reduced colony survival.

Different species of Hymenoptera show a wide range of feeding habits. The most primitive forms are typically phytophagous, feeding on flowers, pollen, foliage, or stems. Stinging wasps are predators, and will provision their larvae with immobilised prey, while bees feed on nectar and pollen.

A huge number of species are parasitoids as larvae. The adults inject the eggs into a host, which they begin to consume after hatching. For example, the eggs of the endangered "Papilio homerus" are parasitized at a rate of 77%, mainly by Hymenoptera species. Some species are even hyperparasitoid, with the host itself being another parasitoid insect. Habits intermediate between those of the herbivorous and parasitoid forms are shown in some hymenopterans, which inhabit the galls or nests of other insects, stealing their food, and eventually killing and eating the occupant.

The Hymenoptera are divided into two groups; the Symphyta which have no waist, and the Apocrita which have a narrow waist.

The suborder Symphyta includes the sawflies, horntails, and parasitic wood wasps. The group may be paraphyletic, as it has been suggested that the family Orussidae may be the group from which the Apocrita arose. They have an unconstricted junction between the thorax and abdomen. The larvae are herbivorous, free-living, and eruciform, with three pairs of true legs, prolegs (on every segment, unlike Lepidoptera) and ocelli. The prolegs do not have crochet hooks at the ends unlike the larvae of the Lepidoptera.

The wasps, bees, and ants together make up the suborder (and clade) Apocrita, characterized by a constriction between the first and second abdominal segments called a wasp-waist (petiole), also involving the fusion of the first abdominal segment to the thorax. Also, the larvae of all Apocrita lack legs, prolegs, or ocelli. The hindgut of the larvae also remains closed during development, with feces being stored inside the body, with the exception of some bee larvae where the larval anus has reappeared through developmental reversion. In general, the anus only opens at the completion of larval growth.







</doc>
<doc id="13976" url="https://en.wikipedia.org/wiki?curid=13976" title="Hannibal Hamlin">
Hannibal Hamlin

Hannibal Hamlin (August 27, 1809 – July 4, 1891) was an American attorney and politician from the state of Maine. In a public service career that spanned over 50 years, he served as the 15th vice president of the United States. The first Republican to hold the office, Hamlin served from 1861 to 1865. He is considered among the most influential politicians to have come from Maine.

A native of Paris, Maine (part of Massachusetts until 1820), Hamlin managed his father's farm before becoming a newspaper editor. He studied law, was admitted to the bar in 1833, and began to practice in Hampden, Maine. Originally a Democrat, Hamlin began his political career with election to the Maine House of Representatives in 1835 and an appointment to the military staff of the Governor of Maine. As an officer in the militia, he took part in the 1839 negotiations that helped end the Aroostook War. In the 1840s Hamlin was elected to and served in the United States House of Representatives. In 1848 the state house elected him to the United States Senate, where he served until January 1857. He served temporarily as governor for six weeks in the beginning of 1857, after which he returned to the Senate. Hamlin was an active opponent of slavery; he supported the Wilmot Proviso and opposed the Compromise Measures of 1850. In 1854, he strongly opposed passage of the Kansas–Nebraska Act. Hamlin's increasingly anti-slavery views caused him to leave the Democratic Party for the newly formed Republican Party in 1856.

In the 1860 election, Hamlin was the Republican nominee for Vice President. Selected to run with Abraham Lincoln, who was from Illinois, Hamlin was chosen in part to bring geographic balance to the ticket and in part because as a former Democrat, he could work to convince other anti-slavery Democrats that their future lay with the Republican Party. The Lincoln and Hamlin ticket was successful, and Hamlin served as Vice President from 1861 to 1865, which included all but the last month of the American Civil War. The first Republican Vice President, Hamlin held the office in an era when the office was considered more a part of the legislative branch than the executive; he was not personally close to Lincoln and did not play a major role in his administration. Even so, Hamlin supported the administration's legislative program in his role as presiding officer of the Senate, and he looked for other ways to demonstrate his support for the Union, including a term of service in a Maine militia unit during the war.

For the 1864 election, Hamlin was replaced as Vice Presidential nominee by Andrew Johnson, a Southern Democrat chosen for his appeal to Southern Unionists. After leaving the vice presidency, Hamlin served as Collector of the Port of Boston, a lucrative post to which he was appointed by Johnson after the latter succeeded to the presidency following Lincoln's assassination. However, Hamlin later resigned as Collector because of his disagreement with Johnson over Reconstruction of the former Confederacy.

In 1869, Hamlin was elected again to the U.S. Senate, and he served two terms. After leaving the Senate in 1881, he served briefly as United States Ambassador to Spain before returning to Maine in late 1882. In retirement, Hamlin was a resident of Bangor, Maine, where he died in 1891. He was buried at Mount Hope Cemetery in Bangor.

Hamlin was born to Cyrus Hamlin and his wife Anna, née Livermore, in Paris (now in Maine, then a part of Massachusetts). He was a descendant in the sixth generation of English colonist James Hamlin, who had settled in the Massachusetts Bay Colony in 1639. He was a grandnephew of U.S. Senator Samuel Livermore II of New Hampshire.

According to folklore, Hamlin's life was saved when he was an infant by a Native American medicine woman named Molly Ockett. Hamlin was gravely ill and Molly Ockett prescribed that he be given warm cow's milk after which he recovered.

Hamlin attended the district schools and Hebron Academy and later managed his father's farm. From 1827 to 1830 he published the "Oxford Jeffersonian" newspaper in partnership with Horatio King.

He studied law with the firm headed by Samuel Fessenden, was admitted to the bar in 1833, and began practicing in Hampden, Maine, where he lived until 1848.

Hamlin married Sarah Jane Emery of Paris Hill in 1833. Her father was Stephen Emery, who was appointed as Maine's Attorney General in 1839–1840. Hamlin and Sarah had four children together: George, Charles, Cyrus and Sarah.

His wife died in 1855. The next year, Hamlin married Sarah's half-sister, Ellen Vesta Emery in 1856. They had two children together: Hannibal E. and Frank. Ellen Hamlin died in 1925.

Hamlin's political career began in 1835, when he was elected to the Maine House of Representatives. Appointed a Major on the staff of Governor John Fairfield, he served with the militia in the bloodless Aroostook War of 1839. He facilitated negotiations between Fairfield and Lieutenant Governor John Harvey of New Brunswick, which helped reduce tensions and make possible the Webster–Ashburton Treaty, which ended the war.

Hamlin unsuccessfully ran for the United States House of Representatives in 1840 and left the State House in 1841. He later was elected to two terms in the United States House of Representatives, serving from 1843 to 1847. He was elected by the state legislature to fill a U.S. Senate vacancy in 1848, and to a full term in 1851. A Democrat at the beginning of his career, Hamlin supported the candidacy of Franklin Pierce in 1852.

From the very beginning of his service in Congress, Hamlin was prominent as an opponent of the extension of slavery. He was a conspicuous supporter of the Wilmot Proviso and spoke against the Compromise Measures of 1850. In 1854, Hamlin strongly opposed the passage of the Kansas–Nebraska Act, which repealed the Missouri Compromise. After the Democratic Party endorsed that repeal at the 1856 Democratic National Convention, on June 12, 1856, he withdrew from the Democratic Party and joined the newly organized Republican Party, causing a national sensation.

The Republicans nominated Hamlin for Governor of Maine in the same year. He carried the election by a large majority and was inaugurated on January 8, 1857. In the latter part of February 1857, however, he resigned the governorship. He returned to the United States Senate, serving from 1857 to January 1861.

Hamlin was nominated by the Republican Party to serve as Vice President of the United States in the 1860 presidential election on a ticket with former Representative Abraham Lincoln. Given that Lincoln was from Illinois, a vice presidential nominee from Maine made sense in terms of regional balance. As a former Democrat, Hamlin could persuade other anti-slavery Democrats that joining the Republican Party was the only way to ensure slavery's demise.

Hamlin and Lincoln were not close personally but had a good working relationship. At the time, the Vice President was part of the legislative branch in his role as President of the Senate and did not attend cabinet meetings; Hamlin did not regularly visit the White House. Mary Todd Lincoln and Hamlin disliked each other. For his part, Hamlin complained, "I am only a fifth wheel of a coach and can do little for my friends."

He had little influence in the Lincoln Administration, although he urged both the Emancipation Proclamation and the arming of Black Americans. He strongly supported Joseph Hooker's appointment as commander of the Army of the Potomac, which ended in failure at the Battle of Chancellorsville.

Beginning in 1860, Hamlin was a member of Company A of the Maine State Guard, a militia unit. When the company was called up in the summer of 1864, Hamlin was told that because of his position as Vice President, he did not have to take part in the muster. He opted to serve, arguing that he could set an example by doing the duty expected of any citizen, and the only concession made because of his office was that he was quartered with the officers. He reported to Fort McClary in July, initially taking part in routine assignments including guard duty, and later taking over as the company cook. He was promoted to corporal during his service, and mustered out with the rest of his unit in mid-September.

In June 1864, the Republicans and War Democrats joined to form the National Union Party. Although Lincoln was renominated, War Democrat Andrew Johnson of Tennessee was named to replace Hamlin as Lincoln's running mate. Lincoln was seeking to broaden his base of support and was also looking ahead to Southern Reconstruction, at which Johnson had proven himself adept as military governor of occupied Tennessee. Hamlin, by contrast, was an ally of the Northern "Radical Republicans" (who would later impeach Johnson). Lincoln and Johnson were elected in November 1864, and Hamlin's term expired on March 4, 1865.

After leaving the vice presidency Hamlin served briefly as Collector of the Port of Boston. Appointed to the post by Johnson, Hamlin resigned in protest over Johnson's Reconstruction policy and accompanying efforts to build a political following loyal to him after he had been repudiated by the Republicans. Republicans had supported Johnson as part of the National Union ticket during the war, but opposed him after he became President and his position on Reconstruction deviated from theirs.

Although Hamlin narrowly missed becoming President, his vice presidency would usher in a half-century of sustained national influence for the Maine Republican Party. In the period 1861–1911, Maine Republicans occupied the offices of Vice President, Secretary of the Treasury (twice), Secretary of State, President pro tempore of the United States Senate, Speaker of the United States House of Representatives (twice), and would field a presidential nominee in James G. Blaine, a level of influence in national politics unmatched by subsequent Maine political delegations.

Not content with private life, Hamlin returned to the U.S. Senate in 1869 to serve two more 6-year terms before declining to run for re-election in 1880 because of an ailing heart. His last duty as a public servant came in 1881 when Secretary of State James G. Blaine convinced President James A. Garfield to name Hamlin as United States Ambassador to Spain. Hamlin received the appointment on June 30, 1881, and held the post until October 17, 1882.

Upon returning from Spain, Hamlin retired from public life to his home in Bangor, Maine, which he had purchased in 1851. The Hannibal Hamlin House – as it is known today – is located in central Bangor at 15 5th Street; incorporating Victorian, Italianate, and Mansard-style architecture, the mansion was posted to the National Register of Historic Places in 1979.

Hamlin was elected as a Third Class Companion of the Military Order of the Loyal Legion of the United States. Third Class was the MOLLUS division created to recognize civilians who had contributed outstanding service to the Union during the war.

On Independence Day, July 4, 1891, Hamlin collapsed and fell unconscious while playing cards at the Tarratine Club he founded in downtown Bangor. He was then placed on one of the club's couches. He died a few hours later of natural causes. He was 81. The couch is preserved at the Bangor Public Library. Hannibal Hamlin was buried in the Hamlin family plot at Mount Hope Cemetery in Bangor, Maine. Hamlin survived six of his successors in the vice presidency: Andrew Johnson, Schuyler Colfax, Henry Wilson, William A. Wheeler, Chester A. Arthur, and Thomas A. Hendricks. 

Hamlin had four sons who grew to adulthood: Charles Hamlin, Cyrus Hamlin, Hannibal Emery and Frank Hamlin. Charles and Cyrus served in the Union forces during the Civil War, both becoming generals, Charles by brevet. Cyrus was among the first Union officers to argue for the enlistment of black troops, and himself commanded a brigade of freedmen in the Mississippi River campaign. Charles and sister Sarah were present at Ford's Theater the night of Lincoln's assassination. Hannibal Emery Hamlin was Maine Attorney General from 1905 to 1908. Hannibal Hamlin's great-granddaughter Sally Hamlin was a child actor who made many spoken word recordings for the Victor Talking Machine Company in the early years of the 20th century.

Hannibal's older brother, Elijah Livermore Hamlin, was president of the Mutual Fire Insurance Co. of Bangor, and the Bangor Institution for Savings. He was twice an unsuccessful candidate for Governor of Maine in the late 1840s, though he did serve as Mayor of Bangor in 1851–52. The brothers were members of different political parties (Hannibal a Democrat, and Elijah a Whig) before both becoming Republican in the later 1850s.

Hannibal's nephew (Elijah's son) Augustus Choate Hamlin was a physician, artist, mineralogist, author, and historian. He was also Mayor of Bangor in 1877–78, and a founding member of the Bangor Historical Society.

Augustus served as surgeon in the 2nd Maine Volunteer Infantry Regiment during the Civil War, eventually becoming a U.S. Army Medical Inspector, and later the Surgeon General of Maine. He wrote books about Andersonville Prison and the Battle of Chancellorsville. Hannibal's grand-nephew (Elijah's grandson) Isaiah K. Stetson was Speaker of the Maine House of Representatives in 1899–1900, and owned a large company in Bangor which manufactured and shipped lumber and ice and ran a shipyard and marine railway.

Hannibal's first cousin Cyrus Hamlin, who was a graduate of the Bangor Theological Seminary, became a missionary in Turkey, where he founded Robert College. He later became president of Middlebury College in Vermont. His son, A. D. F. Hamlin, Hannibal's first cousin once removed, became a professor of architecture at Columbia University and a noted architectural historian. There are biographies of Hamlin by his grandson Charles E. Hamlin (published 1899, reprinted 1971) and by H. Draper Hunt (published 1969)

Hamlin County, South Dakota is named in his honor, as are Hamlin, Kansas; Hamlin, New York; Hamlin, West Virginia; Hamlin Township; Hamlin Lake in Mason County, Michigan; and, Hamlin, a small Maine village that is a U.S.–Canada border crossing with Grand Falls, New Brunswick. There are statues in Hamlin's likeness in the United States Capitol and in a public park (Norumbega Mall) in Bangor, Maine.

There is also a building on the University of Maine Campus, in Orono, named Hannibal Hamlin Hall. This burned down in 1945, in a fire that killed two students, but was subsequently rebuilt. Hannibal Hamlin Memorial Library is next to his birthplace in Paris, Maine.

The Hampden Maine Historical Society exhibit a restoration of his first law office at their Kinsley House Museum grounds.

Hamlin's house in Bangor subsequently housed the Presidents of the adjacent Bangor Theological Seminary. It is listed on the National Register of Historic Places, as is Hamlin's birthplace in Paris, Maine (as part of the Paris Hill Historic District).

Hamlin Park in Chicago is named in his honor.

Hamlin appears briefly in three alternate history writings by Harry Turtledove: "The Guns of the South", "Must and Shall", and "How Few Remain".

"Fallout 3" features a character named Hannibal Hamlin. He is shown to be an admirer of Abraham Lincoln and was a former slave who now leads an anti-slavery militia of sorts composed of other former slaves.



 


</doc>
<doc id="13978" url="https://en.wikipedia.org/wiki?curid=13978" title="Hopwood Award">
Hopwood Award

The Hopwood Awards are a major scholarship program at the University of Michigan, founded by Avery Hopwood.

Under the terms of the will of Avery Hopwood, a prominent American dramatist and member of the Class of 1905 of The University of Michigan, one-fifth of Mr. Hopwood's estate was given to the Regents for the encouragement of creative work in writing. The first awards were made in 1931, and today the Hopwood Program offers approximately $120,000 in prizes every year to aspiring writers at the University of Michigan. According to Nicholas Delbanco, UM English Professor and former Director of the Hopwood Awards Program, "This is the oldest and best known series of writing prizes in the country and it is a very good indicator of future success."

Awards are offered in the following genres: drama/screenplay, essay, the novel, short fiction, Nonfiction, and poetry. These awards are classified under two categories, Graduate or Undergraduate, except the novel and drama/screenplay, which are combined categories. Award amounts for this contest vary, but usually fall in the range of $1000 to $6000.

The Summer Hopwood Contest was discontinued in 2017, but archives of winning Summer Hopwood manuscripts will continue to be held in the Hopwood Room. When it ran, the contest was open only to students who took writing courses during spring and summer terms. Awards were given in the categories of Drama or Screenplay, Nonfiction, Short Fiction, and Poetry. Novels were not eligible for the Summer Hopwood Contest.

This contest is open only to freshmen and sophomores who are enrolled in writing courses. Awards are given in the categories of Nonfiction, Fiction, and Poetry.

The Hopwood Program administers the Hopwood Award, as well as several other awards in writing. It is located in the Hopwood Room at the University of Michigan and serves the needs and interests of Hopwood contestants. The Room was established by Professor Roy W. Cowden, Director of the Hopwood Awards from 1933 to 1952, who generously contributed a part of his library, which has grown through the addition of many volumes of contemporary literature. In addition to housing the winning manuscripts from the past years of the contests, the Hopwood Room has a lending library of twentieth -century literature, a generous supply of non-circulating current periodicals, some reference 
books on how to get published, information on graduate and summer writing 
programs, and a collection of screen plays donated by former Hopwood winner 
Lawrence Kasdan.

The Hopwood Program also administers the following writing contests: 





</doc>
<doc id="13980" url="https://en.wikipedia.org/wiki?curid=13980" title="Homeostasis">
Homeostasis

In biology, homeostasis is the state of steady internal, physical, and chemical conditions maintained by living systems. This is the condition of optimal functioning for the organism and includes many variables, such as body temperature and fluid balance, being kept within certain pre-set limits (homeostatic range). Other variables include the pH of extracellular fluid, the concentrations of sodium, potassium and calcium ions, as well as that of the blood sugar level, and these need to be regulated despite changes in the environment, diet, or level of activity. Each of these variables is controlled by one or more regulators or homeostatic mechanisms, which together maintain life.

Homeostasis is brought about by a natural resistance to change when already in the optimal conditions, and equilibrium is maintained by many regulatory mechanisms. All homeostatic control mechanisms have at least three interdependent components for the variable being regulated: a receptor, a control centre, and an effector. The receptor is the sensing component that monitors and responds to changes in the environment, either external or internal. Receptors include thermoreceptors, and mechanoreceptors. Control centres include the respiratory centre, and the renin–angiotensin system. An effector is the target acted on, to bring about the change back to the normal state. At the cellular level, receptors include nuclear receptors that bring about changes in gene expression through up-regulation or down-regulation, and act in negative feedback mechanisms. An example of this is in the control of bile acids in the liver.

Some centers, such as the renin–angiotensin system, control more than one variable. When the receptor senses a stimulus, it reacts by sending action potentials to a control center. The control center sets the maintenance range—the acceptable upper and lower limits—for the particular variable, such as temperature. The control center responds to the signal by determining an appropriate response and sending signals to an effector, which can be one or more muscles, an organ, or a gland. When the signal is received and acted on, negative feedback is provided to the receptor that stops the need for further signaling.

The cannabinoid receptor type 1 (CB1), located at the presynaptic neuron, is a receptor that can stop stressful neurotransmitter release to the postsynaptic neuron; it is activated by endocannabinoids (ECs) such as anandamide ("N"-arachidonoylethanolamide; AEA) and 2-arachidonoylglycerol (2-AG) via a retrograde signaling process in which these compounds are synthesized by and released from postsynaptic neurons, and travel back to the presynaptic terminal to bind to the CB1 receptor for modulation of neurotransmitter release to obtain homeostasis.

The polyunsaturated fatty acids (PUFAs) are lipid derivatives of omega-3 (docosahexaenoic acid, DHA, and eicosapentaenoic acid, EPA) or of omega-6 (arachidonic acid, ARA) are synthesized from membrane phospholipids and used as a precursor for endocannabinoids (ECs) mediate significant effects in the fine-tune adjustment of body homeostasis.

The concept of the regulation of the internal environment was described by French physiologist Claude Bernard in 1849, and the word "homeostasis" was coined by Walter Bradford Cannon in 1926. In 1932, Joseph Barcroft a British physiologist, was the first to say that higher brain function required the most stable internal environment. Thus, to Barcroft homeostasis was not only organized by the brain—homeostasis served the brain. Homeostasis is an almost exclusively biological term, referring to the concepts described by Bernard and Cannon, concerning the constancy of the internal environment in which the cells of the body live and survive. The term cybernetics is applied to technological control systems such as thermostats, which function as homeostatic mechanisms, but is often defined much more broadly than the biological term of homeostasis.

The word "homeostasis" () uses combining forms of "homeo-" and "-stasis", New Latin from Greek: ὅμοιος "homoios", "similar" and στάσις "stasis", "standing still", yielding the idea of "staying the same".

The metabolic processes of all organisms can only take place in very specific physical and chemical environments. The conditions vary with each organism, and with whether the chemical processes take place inside the cell or in the interstitial fluid bathing the cells. The best known homeostatic mechanisms in humans and other mammals are regulators that keep the composition of the extracellular fluid (or the "internal environment") constant, especially with regard to the temperature, pH, osmolality, and the concentrations of sodium, potassium, glucose, carbon dioxide, and oxygen. However, a great many other homeostatic mechanisms, encompassing many aspects of human physiology, control other entities in the body. Where the levels of variables are higher or lower than those needed, they are often prefixed with "hyper-" and "hypo-", respectively such as hyperthermia and hypothermia or hypertension and hypotension.
If an entity is homeostatically controlled it does not imply that its value is necessarily absolutely steady in health. Core body temperature is, for instance, regulated by a homeostatic mechanism with temperature sensors in, amongst others, the hypothalamus of the brain. However, the set point of the regulator is regularly reset. For instance, core body temperature in humans varies during the course of the day (i.e. has a circadian rhythm), with the lowest temperatures occurring at night, and the highest in the afternoons. Other normal temperature variations include those related to the menstrual cycle. The temperature regulator's set point is reset during infections to produce a fever. Organisms are capable of adjusting somewhat to varied conditions such as temperature changes or oxygen levels at altitude, by a process of acclimatisation.

Homeostasis does not govern every activity in the body. For instance the signal (be it via neurons or hormones) from the sensor to the effector is, of necessity, highly variable in order to convey information about the direction and magnitude of the error detected by the sensor. Similarly the effector's response needs to be highly adjustable to reverse the error – in fact it should be very nearly in proportion (but in the opposite direction) to the error that is threatening the internal environment. For instance, the arterial blood pressure in mammals is homeostatically controlled, and measured by stretch receptors in the walls of the aortic arch and carotid sinuses at beginnings of the internal carotid arteries. The sensors send messages via sensory nerves to the medulla oblongata of the brain indicating whether the blood pressure has fallen or risen, and by how much. The medulla oblongata then distributes messages along motor or efferent nerves belonging to the autonomic nervous system to a wide variety of effector organs, whose activity is consequently changed to reverse the error in the blood pressure. One of the effector organs is the heart whose rate is stimulated to rise (tachycardia) when the arterial blood pressure falls, or to slow down (bradycardia) when the pressure rises above set point. Thus the heart rate (for which there is no sensor in the body) is not homeostatically controlled, but is one of effector responses to errors in the arterial blood pressure. Another example is the rate of sweating. This is one of the effectors in the homeostatic control of body temperature, and therefore highly variable in rough proportion to the heat load that threatens to destabilize the body's core temperature, for which there is a sensor in the hypothalamus of the brain.

Mammals regulate their core temperature using input from thermoreceptors in the hypothalamus, brain, spinal cord, internal organs, and great veins. Apart from the internal regulation of temperature, a process called allostasis can come into play that adjusts behaviour to adapt to the challenge of very hot or cold extremes (and to other challenges). These adjustments may include seeking shade and reducing activity, or seeking warmer conditions and increasing activity, or huddling.
Behavioural thermoregulation takes precedence over physiological thermoregulation since necessary changes can be affected more quickly and physiological thermoregulation is limited in its capacity to respond to extreme temperatures.

When core temperature falls, the blood supply to the skin is reduced by intense vasoconstriction. The blood flow to the limbs (which have a large surface area) is similarly reduced, and returned to the trunk via the deep veins which lie alongside the arteries (forming venae comitantes). This acts as a counter-current exchange system which short-circuits the warmth from the arterial blood directly into the venous blood returning into the trunk, causing minimal heat loss from the extremities in cold weather. The subcutaneous limb veins are tightly constricted, not only reducing heat loss from this source, but also forcing the venous blood into the counter-current system in the depths of the limbs.

The metabolic rate is increased, initially by non-shivering thermogenesis, followed by shivering thermogenesis if the earlier reactions are insufficient to correct the hypothermia.

When core temperature rises are detected by thermoreceptors, the sweat glands in the skin are stimulated via cholinergic sympathetic nerves to secrete sweat onto the skin, which, when it evaporates, cools the skin and the blood flowing through it. Panting is an alternative effector in many vertebrates, which cools the body also by the evaporation of water, but this time from the mucous membranes of the throat and mouth.

Blood sugar levels are regulated within fairly narrow limits. In mammals the primary sensors for this are the beta cells of the pancreatic islets. The beta cells respond to a rise in the blood sugar level by secreting insulin into the blood, and simultaneously inhibiting their neighboring alpha cells from secreting glucagon into the blood. This combination (high blood insulin levels and low glucagon levels) act on effector tissues, chief of which are the liver, fat cells and muscle cells. The liver is inhibited from producing glucose, taking it up instead, and converting it to glycogen and triglycerides. The glycogen is stored in the liver, but the triglycerides are secreted into the blood as very low-density lipoprotein (VLDL) particles which are taken up by adipose tissue, there to be stored as fats. The fat cells take up glucose through special glucose transporters (GLUT4), whose numbers in the cell wall are increased as a direct effect of insulin acting on these cells. The glucose that enters the fat cells in this manner is converted into triglycerides (via the same metabolic pathways as are used by the liver) and then stored in those fat cells together with the VLDL-derived triglycerides that were made in the liver. Muscle cells also take glucose up through insulin-sensitive GLUT4 glucose channels, and convert it into muscle glycogen.

A fall in blood glucose, causes insulin secretion to be stopped, and glucagon to be secreted from the alpha cells into the blood. This inhibits the uptake of glucose from the blood by the liver, fats cells and muscle. Instead the liver is strongly stimulated to manufacture glucose from glycogen (through glycogenolysis) and from non-carbohydrate sources (such as lactate and de-aminated amino acids) using a process known as gluconeogenesis. The glucose thus produced is discharged into the blood correcting the detected error (hypoglycemia). The glycogen stored in muscles remains in the muscles, and is only broken down, during exercise, to glucose-6-phosphate and thence to pyruvate to be fed into the citric acid cycle or turned into lactate. It is only the lactate and the waste products of the citric acid cycle that are returned to the blood. The liver can take up only the lactate, and by the process of energy consuming gluconeogenesis convert it back to glucose.

Changes in the levels of oxygen, carbon dioxide, and plasma pH are sent to the respiratory center, in the brainstem where they are regulated.
The partial pressure of oxygen and carbon dioxide in the arterial blood is monitored by the peripheral chemoreceptors (PNS) in the carotid artery and aortic arch. A change in the partial pressure of carbon dioxide is detected as altered pH in the cerebrospinal fluid by central chemoreceptors (CNS) in the medulla oblongata of the brainstem. Information from these sets of sensors is sent to the respiratory center which activates the effector organs – the diaphragm and other muscles of respiration. An increased level of carbon dioxide in the blood, or a decreased level of oxygen, will result in a deeper breathing pattern and increased respiratory rate to bring the blood gases back to equilibrium.

Too little carbon dioxide, and, to a lesser extent, too much oxygen in the blood can temporarily halt breathing, a condition known as apnea, which freedivers use to prolong the time they can stay underwater.

The partial pressure of carbon dioxide is more of a deciding factor in the monitoring of pH. However, at high altitude (above 2500 m) the monitoring of the partial pressure of oxygen takes priority, and hyperventilation keeps the oxygen level constant. With the lower level of carbon dioxide, to keep the pH at 7.4 the kidneys secrete hydrogen ions into the blood, and excrete bicarbonate into the urine. This is important in the acclimatization to high altitude.

The kidneys measure the oxygen content rather than the partial pressure of oxygen in the arterial blood. When the oxygen content of the blood is chronically low, oxygen-sensitive cells secrete erythropoietin (EPO) into the blood. The effector tissue is the red bone marrow which produces red blood cells (RBCs)(erythrocytes). The increase in RBCs leads to an increased hematocrit in the blood, and subsequent increase in hemoglobin that increases the oxygen carrying capacity. This is the mechanism whereby high altitude dwellers have higher hematocrits than sea-level residents, and also why persons with pulmonary insufficiency or right-to-left shunts in the heart (through which venous blood by-passes the lungs and goes directly into the systemic circulation) have similarly high hematocrits.

Regardless of the partial pressure of oxygen in the blood, the amount of oxygen that can be carried, depends on the hemoglobin content. The partial pressure of oxygen may be sufficient for example in anemia, but the hemoglobin content will be insufficient and subsequently as will be the oxygen content. Given enough supply of iron, vitamin B12 and folic acid, EPO can stimulate RBC production, and hemoglobin and oxygen content restored to normal.

The brain can regulate blood flow over a range of blood pressure values by vasoconstriction and vasodilation of the arteries.

High pressure receptors called baroreceptors in the walls of the aortic arch and carotid sinus (at the beginning of the internal carotid artery) monitor the arterial blood pressure. Rising pressure is detected when the walls of the arteries stretch due to an increase in blood volume. This causes heart muscle cells to secrete the hormone atrial natriuretic peptide (ANP) into the blood. This acts on the kidneys to inhibit the secretion of renin and aldosterone causing the release of sodium, and accompanying water into the urine, thereby reducing the blood volume.
This information is then conveyed, via afferent nerve fibers, to the solitary nucleus in the medulla oblongata. From here motor nerves belonging to the autonomic nervous system are stimulated to influence the activity of chiefly the heart and the smallest diameter arteries, called arterioles. The arterioles are the main resistance vessels in the arterial tree, and small changes in diameter cause large changes in the resistance to flow through them. When the arterial blood pressure rises the arterioles are stimulated to dilate making it easier for blood to leave the arteries, thus deflating them, and bringing the blood pressure down, back to normal. At the same time the heart is stimulated via cholinergic parasympathetic nerves to beat more slowly (called bradycardia), ensuring that the inflow of blood into the arteries is reduced, thus adding to the reduction in pressure, and correction of the original error.

Low pressure in the arteries, causes the opposite reflex of constriction of the arterioles, and a speeding up of the heart rate (called tachycardia). If the drop in blood pressure is very rapid or excessive, the medulla oblongata stimulates the adrenal medulla, via "preganglionic" sympathetic nerves, to secrete epinephrine (adrenaline) into the blood. This hormone enhances the tachycardia and causes severe vasoconstriction of the arterioles to all but the essential organ in the body (especially the heart, lungs, and brain). These reactions usually correct the low arterial blood pressure (hypotension) very effectively.

The plasma ionized calcium (Ca) concentration is very tightly controlled by a pair of homeostatic mechanisms. The sensor for the first one is situated in the parathyroid glands, where the chief cells sense the Ca level by means of specialized calcium receptors in their membranes. The sensors for the second are the parafollicular cells in the thyroid gland. The parathyroid chief cells secrete parathyroid hormone (PTH) in response to a fall in the plasma ionized calcium level; the parafollicular cells of the thyroid gland secrete calcitonin in response to a rise in the plasma ionized calcium level.

The effector organs of the first homeostatic mechanism are the bones, the kidney, and, via a hormone released into the blood by the kidney in response to high PTH levels in the blood, the duodenum and jejunum. Parathyroid hormone (in high concentrations in the blood) causes bone resorption, releasing calcium into the plasma. This is a very rapid action which can correct a threatening hypocalcemia within minutes. High PTH concentrations cause the excretion of phosphate ions via the urine. Since phosphates combine with calcium ions to form insoluble salts (see also bone mineral), a decrease in the level of phosphates in the blood, releases free calcium ions into the plasma ionized calcium pool. PTH has a second action on the kidneys. It stimulates the manufacture and release, by the kidneys, of calcitriol into the blood. This steroid hormone acts on the epithelial cells of the upper small intestine, increasing their capacity to absorb calcium from the gut contents into the blood.

The second homeostatic mechanism, with its sensors in the thyroid gland, releases calcitonin into the blood when the blood ionized calcium rises. This hormone acts primarily on bone, causing the rapid removal of calcium from the blood and depositing it, in insoluble form, in the bones.

The two homeostatic mechanisms working through PTH on the one hand, and calcitonin on the other can very rapidly correct any impending error in the plasma ionized calcium level by either removing calcium from the blood and depositing it in the skeleton, or by removing calcium from it. The skeleton acts as an extremely large calcium store (about 1 kg) compared with the plasma calcium store (about 180 mg). Longer term regulation occurs through calcium absorption or loss from the gut.

Another example are the most well-characterised endocannabinoids like anandamide ("N"-arachidonoylethanolamide; AEA) and 2-arachidonoylglycerol (2-AG), whose synthesis occurs through the action of a series of intracellular enzymes activated in response to a rise in intracellular calcium levels to introduce homeostasis and prevention of tumor development through putative protective mechanisms that prevent cell growth and migration by activation of CB1 and/or CB2 and adjoining receptors.

The homeostatic mechanism which controls the plasma sodium concentration is rather more complex than most of the other homeostatic mechanisms described on this page.
The sensor is situated in the juxtaglomerular apparatus of kidneys, which senses the plasma sodium concentration in a surprisingly indirect manner. Instead of measuring it directly in the blood flowing past the juxtaglomerular cells, these cells respond to the sodium concentration in the renal tubular fluid after it has already undergone a certain amount of modification in the proximal convoluted tubule and loop of Henle. These cells also respond to rate of blood flow through the juxtaglomerular apparatus, which, under normal circumstances, is directly proportional to the arterial blood pressure, making this tissue an ancillary arterial blood pressure sensor.

In response to a lowering of the plasma sodium concentration, or to a fall in the arterial blood pressure, the juxtaglomerular cells release renin into the blood. Renin is an enzyme which cleaves a decapeptide (a short protein chain, 10 amino acids long) from a plasma α-2-globulin called angiotensinogen. This decapeptide is known as angiotensin I. It has no known biological activity. However, when the blood circulates through the lungs a pulmonary capillary endothelial enzyme called angiotensin-converting enzyme (ACE) cleaves a further two amino acids from angiotensin I to form an octapeptide known as angiotensin II. Angiotensin II is a hormone which acts on the adrenal cortex, causing the release into the blood of the steroid hormone, aldosterone. Angiotensin II also acts on the smooth muscle in the walls of the arterioles causing these small diameter vessels to constrict, thereby restricting the outflow of blood from the arterial tree, causing the arterial blood pressure to rise. This, therefore, reinforces the measures described above (under the heading of "Arterial blood pressure"), which defend the arterial blood pressure against changes, especially hypotension.

The angiotensin II-stimulated aldosterone released from the zona glomerulosa of the adrenal glands has an effect on particularly the epithelial cells of the distal convoluted tubules and collecting ducts of the kidneys. Here it causes the reabsorption of sodium ions from the renal tubular fluid, in exchange for potassium ions which are secreted from the blood plasma into the tubular fluid to exit the body via the urine. The reabsorption of sodium ions from the renal tubular fluid halts further sodium ion losses from the body, and therefore preventing the worsening of hyponatremia. The hyponatremia can only be "corrected" by the consumption of salt in the diet. However, it is not certain whether a "salt hunger" can be initiated by hyponatremia, or by what mechanism this might come about.

When the plasma sodium ion concentration is higher than normal (hypernatremia), the release of renin from the juxtaglomerular apparatus is halted, ceasing the production of angiotensin II, and its consequent aldosterone-release into the blood. The kidneys respond by excreting sodium ions into the urine, thereby normalizing the plasma sodium ion concentration. The low angiotensin II levels in the blood lower the arterial blood pressure as an inevitable concomitant response.

The reabsorption of sodium ions from the tubular fluid as a result of high aldosterone levels in the blood does not, of itself, cause renal tubular water to be returned to the blood from the distal convoluted tubules or collecting ducts. This is because sodium is reabsorbed in exchange for potassium and therefore causes only a modest change in the osmotic gradient between the blood and the tubular fluid. Furthermore, the epithelium of the distal convoluted tubules and collecting ducts is impermeable to water in the absence of antidiuretic hormone (ADH) in the blood. ADH is part of the control of fluid balance. Its levels in the blood vary with the osmolality of the plasma, which is measured in the hypothalamus of the brain. Aldosterone's action on the kidney tubules prevents sodium loss to the extracellular fluid (ECF). So there is no change in the osmolality of the ECF, and therefore no change in the ADH concentration of the plasma. However, low aldosterone levels cause a loss of sodium ions from the ECF, which could potentially cause a change in extracellular osmolality and therefore of ADH levels in the blood.

High potassium concentrations in the plasma cause depolarization of the zona glomerulosa cells' membranes in the outer layer of the adrenal cortex. This causes the release of aldosterone into the blood.

Aldosterone acts primarily on the distal convoluted tubules and collecting ducts of the kidneys, stimulating the excretion of potassium ions into the urine. It does so, however, by activating the basolateral Na/K pumps of the tubular epithelial cells. These sodium/potassium exchangers pump three sodium ions out of the cell, into the interstitial fluid and two potassium ions into the cell from the interstitial fluid. This creates an ionic concentration gradient which results in the reabsorption of sodium (Na) ions from the tubular fluid into the blood, and secreting potassium (K) ions from the blood into the urine (lumen of collecting duct).

The total amount of water in the body needs to be kept in balance. Fluid balance involves keeping the fluid volume stabilized, and also keeping the levels of electrolytes in the extracellular fluid stable. Fluid balance is maintained by the process of osmoregulation and by behavior. Osmotic pressure is detected by osmoreceptors in the median preoptic nucleus in the hypothalamus. Measurement of the plasma osmolality to give an indication of the water content of the body, relies on the fact that water losses from the body, (through unavoidable water loss through the skin which is not entirely waterproof and therefore always slightly moist, water vapor in the exhaled air, sweating, vomiting, normal feces and especially diarrhea) are all hypotonic, meaning that they are less salty than the body fluids (compare, for instance, the taste of saliva with that of tears. The latter has almost the same salt content as the extracellular fluid, whereas the former is hypotonic with respect to the plasma. Saliva does not taste salty, whereas tears are decidedly salty). Nearly all normal and abnormal losses of body water therefore cause the extracellular fluid to become hypertonic. Conversely, excessive fluid intake dilutes the extracellular fluid causing the hypothalamus to register hypotonic hyponatremia conditions.

When the hypothalamus detects a hypertonic extracellular environment, it causes the secretion of an antidiuretic hormone (ADH) called vasopressin which acts on the effector organ, which in this case is the kidney. The effect of vasopressin on the kidney tubules is to reabsorb water from the distal convoluted tubules and collecting ducts, thus preventing aggravation of the water loss via the urine. The hypothalamus simultaneously stimulates the nearby thirst center causing an almost irresistible (if the hypertonicity is severe enough) urge to drink water. The cessation of urine flow prevents the hypovolemia and hypertonicity from getting worse; the drinking of water corrects the defect.

Hypo-osmolality results in very low plasma ADH levels. This results in the inhibition of water reabsorption from the kidney tubules, causing high volumes of very dilute urine to be excreted, thus getting rid of the excess water in the body.

Urinary water loss, when the body water homeostat is intact, is a "compensatory" water loss, "correcting" any water excess in the body. However, since the kidneys cannot generate water, the thirst reflex is the all-important second effector mechanism of the body water homeostat, "correcting" any water deficit in the body.

The plasma pH can be altered by respiratory changes in the partial pressure of carbon dioxide; or altered by metabolic changes in the carbonic acid to bicarbonate ion ratio. The bicarbonate buffer system regulates the ratio of carbonic acid to bicarbonate to be equal to 1:20, at which ratio the blood pH is 7.4 (as explained in the Henderson–Hasselbalch equation). A change in the plasma pH gives an acid–base imbalance.
In acid–base homeostasis there are two mechanisms that can help regulate the pH. Respiratory compensation a mechanism of the respiratory center, adjusts the partial pressure of carbon dioxide by changing the rate and depth of breathing, to bring the pH back to normal. The partial pressure of carbon dioxide also determines the concentration of carbonic acid, and the bicarbonate buffer system can also come into play. Renal compensation can help the bicarbonate buffer system.
The sensor for the plasma bicarbonate concentration is not known for certain. It is very probable that the renal tubular cells of the distal convoluted tubules are themselves sensitive to the pH of the plasma. The metabolism of these cells produces carbon dioxide, which is rapidly converted to hydrogen and bicarbonate through the action of carbonic anhydrase. When the ECF pH falls (becoming more acidic) the renal tubular cells excrete hydrogen ions into the tubular fluid to leave the body via urine. Bicarbonate ions are simultaneously secreted into the blood that decreases the carbonic acid, and consequently raises the plasma pH. The converse happens when the plasma pH rises above normal: bicarbonate ions are excreted into the urine, and hydrogen ions released into the plasma.

When hydrogen ions are excreted into the urine, and bicarbonate into the blood, the latter combines with the excess hydrogen ions in the plasma that stimulated the kidneys to perform this operation. The resulting reaction in the plasma is the formation of carbonic acid which is in equilibrium with the plasma partial pressure of carbon dioxide. This is tightly regulated to ensure that there is no excessive build-up of carbonic acid or bicarbonate. The overall effect is therefore that hydrogen ions are lost in the urine when the pH of the plasma falls. The concomitant rise in the plasma bicarbonate mops up the increased hydrogen ions (caused by the fall in plasma pH) and the resulting excess carbonic acid is disposed of in the lungs as carbon dioxide. This restores the normal ratio between bicarbonate and the partial pressure of carbon dioxide and therefore the plasma pH.
The converse happens when a high plasma pH stimulates the kidneys to secrete hydrogen ions into the blood and to excrete bicarbonate into the urine. The hydrogen ions combine with the excess bicarbonate ions in the plasma, once again forming an excess of carbonic acid which can be exhaled, as carbon dioxide, in the lungs, keeping the plasma bicarbonate ion concentration, the partial pressure of carbon dioxide and, therefore, the plasma pH, constant.

Cerebrospinal fluid (CSF) allows for regulation of the distribution of substances between cells of the brain, and neuroendocrine factors, to which slight changes can cause problems or damage to the nervous system. For example, high glycine concentration disrupts temperature and blood pressure control, and high CSF pH causes dizziness and syncope.

Inhibitory neurons in the central nervous system play a homeostatic role in the balance of neuronal activity between excitation and inhibition. Inhibitory neurons using GABA, make compensating changes in the neuronal networks preventing runaway levels of excitation. An imbalance between excitation and inhibition is seen to be implicated in a number of neuropsychiatric disorders.

The neuroendocrine system is the mechanism by which the hypothalamus maintains homeostasis, regulating metabolism, reproduction, eating and drinking behaviour, energy utilization, osmolarity and blood pressure.

The regulation of metabolism, is carried out by hypothalamic interconnections to other glands. 
Three endocrine glands of the hypothalamic–pituitary–gonadal axis (HPG axis) often work together and have important regulatory functions. Two other regulatory endocrine axes are the hypothalamic–pituitary–adrenal axis (HPA axis) and the hypothalamic–pituitary–thyroid axis (HPT axis).

The liver also has many regulatory functions of the metabolism. An important function is the production and control of bile acids. Too much bile acid can be toxic to cells and its synthesis can be inhibited by activation of FXR a nuclear receptor.

At the cellular level, homeostasis is carried out by several mechanisms including transcriptional regulation that can alter the activity of genes in response to changes.

The amount of energy taken in through nutrition needs to match the amount of energy used. To achieve energy homeostasis appetite is regulated by two hormones, grehlin and leptin. Grehlin stimulates hunger and the intake of food and leptin acts to signal satiety (fullness).

A 2019 review of weight-change interventions, including dieting, exercise and overeating, found that body weight homeostasis could not precisely correct for "energetic errors", the loss or gain of calories, in the short-term.

Many diseases are the result of a homeostatic failure. Almost any homeostatic component can malfunction either as a result of an inherited defect, an inborn error of metabolism, or an acquired disease. Some homeostatic mechanisms have inbuilt redundancies, which ensures that life is not immediately threatened if a component malfunctions; but sometimes a homeostatic malfunction can result in serious disease, which can be fatal if not treated. A well-known example of a homeostatic failure is shown in type 1 diabetes mellitus. Here blood sugar regulation is unable to function because the beta cells of the pancreatic islets are destroyed and cannot produce the necessary insulin. The blood sugar rises in a condition known as hyperglycemia.

The plasma ionized calcium homeostat can be disrupted by the constant, unchanging, over-production of parathyroid hormone by a parathyroid adenoma resulting in the typically features of hyperparathyroidism, namely high plasma ionized Ca levels and the resorption of bone, which can lead to spontaneous fractures. The abnormally high plasma ionized calcium concentrations cause conformational changes in many cell-surface proteins (especially ion channels and hormone or neurotransmitter receptors) giving rise to lethargy, muscle weakness, anorexia, constipation and labile emotions.

The body water homeostat can be compromised by the inability to secrete ADH in response to even the normal daily water losses via the exhaled air, the feces, and insensible sweating. On receiving a zero blood ADH signal, the kidneys produce huge unchanging volumes of very dilute urine, causing dehydration and death if not treated.

As organisms age, the efficiency of their control systems becomes reduced. The inefficiencies gradually result in an unstable internal environment that increases the risk of illness, and leads to the physical changes associated with aging.

Various chronic diseases are kept under control by homeostatic compensation, which masks a problem by compensating for it (making up for it) in another way. However, the compensating mechanisms eventually wear out or are disrupted by a new complicating factor (such as the advent of a concurrent acute viral infection), which sends the body reeling through a new cascade of events. Such decompensation unmasks the underlying disease, worsening its symptoms. Common examples include decompensated heart failure, kidney failure, and liver failure.

In the Gaia hypothesis, James Lovelock stated that the entire mass of living matter on Earth (or any planet with life) functions as a vast homeostatic superorganism that actively modifies its planetary environment to produce the environmental conditions necessary for its own survival. In this view, the entire planet maintains several homeostasis (the primary one being temperature homeostasis). Whether this sort of system is present on Earth is open to debate. However, some relatively simple homeostatic mechanisms are generally accepted. For example, it is sometimes claimed that when atmospheric carbon dioxide levels rise, certain plants may be able to grow better and thus act to remove more carbon dioxide from the atmosphere. However, warming has exacerbated droughts, making water the actual limiting factor on land. When sunlight is plentiful and the atmospheric temperature climbs, it has been claimed that the phytoplankton of the ocean surface waters, acting as global sunshine, and therefore heat sensors, may thrive and produce more dimethyl sulfide (DMS). The DMS molecules act as cloud condensation nuclei, which produce more clouds, and thus increase the atmospheric albedo, and this feeds back to lower the temperature of the atmosphere. However, rising sea temperature has stratified the oceans, separating warm, sunlit waters from cool, nutrient-rich waters. Thus, nutrients have become the limiting factor, and plankton levels have actually fallen over the past 50 years, not risen. As scientists discover more about Earth, vast numbers of positive and negative feedback loops are being discovered, that, together, maintain a metastable condition, sometimes within a very broad range of environmental conditions.

Predictive homeostasis is an anticipatory response to an expected challenge in the future, such as the stimulation of insulin secretion by gut hormones which enter the blood in response to a meal. This insulin secretion occurs before the blood sugar level rises, lowering the blood sugar level in anticipation of a large influx into the blood of glucose resulting from the digestion of carbohydrates in the gut. Such anticipatory reactions are open loop systems which are based, essentially, on "guess work", and are not self-correcting. Anticipatory responses always require a closed loop negative feedback system to correct the 'over-shoots' and 'under-shoots' to which the anticipatory systems are prone.

The term has come to be used in other fields, for example:

An actuary may refer to "risk homeostasis", where (for example) people who have anti-lock brakes have no better safety record than those without anti-lock brakes, because the former unconsciously compensate for the safer vehicle via less-safe driving habits. Previous to the innovation of anti-lock brakes, certain maneuvers involved minor skids, evoking fear and avoidance: Now the anti-lock system moves the boundary for such feedback, and behavior patterns expand into the no-longer punitive area. It has also been suggested that ecological crises are an instance of risk homeostasis in which a particular behavior continues until proven dangerous or dramatic consequences actually occur.

Sociologists and psychologists may refer to "stress homeostasis", the tendency of a population or an individual to stay at a certain level of stress, often generating artificial stresses if the "natural" level of stress is not enough.

Jean-François Lyotard, a postmodern theorist, has applied this term to societal 'power centers' that he describes in "The Postmodern Condition", as being 'governed by a principle of homeostasis,' for example, the scientific hierarchy, which will sometimes ignore a radical new discovery for years because it destabilizes previously accepted norms.

Familiar technological homeostatic mechanisms include:




</doc>
<doc id="13981" url="https://en.wikipedia.org/wiki?curid=13981" title="Hockey">
Hockey

Hockey is a sport in which two teams play against each other by trying to manoeuvre a ball or a puck into the opponent's goal using a hockey stick. There are many types of hockey such as bandy, field hockey, ice hockey and rink hockey.

In most of the world, the term "hockey" by itself refers to field hockey, while in Canada, the United States, Russia and most of Eastern and Northern Europe, the term usually refers to ice hockey.

The first recorded use of the word "hockey" is in the 1773 book "Juvenile Sports and Pastimes, to Which Are Prefixed, Memoirs of the Author: Including a New Mode of Infant Education" by Richard Johnson (Pseud. Master Michel Angelo), whose chapter XI was titled "New Improvements on the Game of Hockey". The belief that hockey was mentioned in a 1363 proclamation by King Edward III of England is based on modern translations of the proclamation, which was originally in Latin and explicitly forbade the games "Pilam Manualem, Pedivam, & Bacularem: & ad Canibucam & Gallorum Pugnam". The English historian and biographer John Strype did not use the word "hockey" when he translated the proclamation in 1720, instead translating "Canibucam" as "Cambuck"; this may have referred to either an early form of hockey or a game more similar to golf or croquet.

The word "hockey" itself is of unknown origin. One supposition is that it is a derivative of "hoquet", a Middle French word for a shepherd's stave. The curved, or "hooked" ends of the sticks used for hockey would indeed have resembled these staves. Another supposition derives from the known use of cork bungs, (stoppers) in place of wooden balls to play the game. The stoppers came from barrels containing "hock" ale, also called "hocky".

Games played with curved sticks and a ball can be found in the histories of many cultures. In Egypt, 4000-year-old carvings feature teams with sticks and a projectile, hurling dates to before 1272 BC in Ireland, and there is a depiction from approximately 600 BC in Ancient Greece, where the game may have been called "kerētízein" or (κερητίζειν) because it was played with a horn or horn-like stick ("kéras", κέρας). In Inner Mongolia, the Daur people have been playing "beikou", a game similar to modern field hockey, for about 1,000 years.

Most evidence of hockey-like games during the Middle Ages is found in legislation concerning sports and games. The Galway Statute enacted in Ireland in 1527 banned certain types of ball games, including games using "hooked" (written "hockie", similar to "hooky") sticks.

By the 19th century, the various forms and divisions of historic games began to differentiate and coalesce into the individual sports defined today. Organizations dedicated to the codification of rules and regulations began to form, and national and international bodies sprang up to manage domestic and international competition.

Bandy is played with a ball on a football pitch-sized ice arena (bandy rink), typically outdoors, and with many rules similar to association football. It is played professionally in Russia and Sweden. The sport is recognized by the IOC; its international governing body is the Federation of International Bandy.

Bandy has its roots in England in the 19th century, was originally called "hockey on the ice", and spread from England to other European countries around 1900; a similar Russian sport can also be seen as a predecessor and in Russia, bandy is sometimes called "Russian hockey". Bandy World Championships have been played since 1957 and Women's Bandy World Championships since 2004. There are national club championships in many countries and the top clubs in the world play in the Bandy World Cup every year.

Field hockey is played on gravel, natural grass, or sand-based or water-based artificial turf, with a small, hard ball approximately 73 mm (2.9 in) in diameter. The game is popular among both males and females in many parts of the world, particularly in Europe, Asia, Australia, New Zealand, South Africa, and Argentina. In most countries, the game is played between single-sex sides, although they can be mixed-sex.

The governing body is the 126-member International Hockey Federation (FIH). Men's field hockey has been played at each Summer Olympic Games since 1908 except for 1912 and 1924, while women's field hockey has been played at the Summer Olympic Games since 1980.

Modern field hockey sticks are constructed of a composite of wood, glass fibre or carbon fibre (sometimes both) and are J-shaped, with a curved hook at the playing end, a flat surface on the playing side and a curved surface on the rear side. All sticks are right-handed – left-handed sticks are not permitted.

While field hockey in its current form appeared in mid-18th century England, primarily in schools, it was not until the first half of the 19th century that it became firmly established. The first club was created in 1849 at Blackheath in south-east London. Field hockey is the national sport of Pakistan. It was the national sport of India until the Ministry of Youth Affairs and Sports declared in August 2012 that India has no national sport.

Ice hockey is played between two teams of skaters on a large flat area of ice, using a three-inch-diameter (76.2 mm) vulcanized rubber disc called a puck. This puck is often frozen before high-level games to decrease the amount of bouncing and friction on the ice. The game is played all over North America, Europe and to varying extents in many other countries around the world. It is the most popular sport in Canada, Finland, Latvia, the Czech Republic, and Slovakia. Ice hockey is the national sport of Latvia and the national winter sport of Canada. Ice hockey is played at a number of levels, by all ages.

The governing body of international play is the 77-member International Ice Hockey Federation (IIHF). Men's ice hockey has been played at the Winter Olympics since 1924, and was in the 1920 Summer Olympics. Women's ice hockey was added to the Winter Olympics in 1998. North America's National Hockey League (NHL) is the strongest professional ice hockey league, drawing top ice hockey players from around the globe. The NHL rules are slightly different from those used in Olympic ice hockey over many categories. International ice hockey rules were adopted from Canadian rules in the early 1900s.

The contemporary sport developed in Canada from European and native influences. These included various stick and ball games similar to field hockey, bandy and other games where two teams push a ball or object back and forth with sticks. These were played outdoors on ice under the name "hockey" in England throughout the 19th century, and even earlier under various other names. In Canada, there are 24 reports of hockey-like games in the 19th century before 1875 (five of them using the name "hockey"). The first organized and recorded game of ice hockey was played indoors in Montreal, Quebec, Canada, on March 3, 1875, and featured several McGill University students.

Ice hockey sticks are long L-shaped sticks made of wood, graphite, or composites with a blade at the bottom that can lie flat on the playing surface when the stick is held upright and can legally curve either way, for left- or right-handed players.

Ice sledge hockey or para ice hockey is a form of ice hockey designed for players with physical disabilities affecting their lower bodies. Players sit on double-bladed sledges and use two sticks; each stick has a blade at one end and small picks at the other. Players use the sticks to pass, stickhandle and shoot the puck, and to propel their sledges. The rules are very similar to IIHF ice hockey rules.

Canada is a recognized international leader in the development of sledge hockey, and much of the equipment for the sport was first developed there, such as sledge hockey sticks laminated with fiberglass, as well as aluminum shafts with hand-carved insert blades and special aluminum sledges with regulation skate blades.

Based on ice sledge hockey, inline sledge hockey is played to the same rules as inline puck hockey (essentially ice hockey played off-ice using inline skates). There is no classification point system dictating who can play inline sledge hockey, unlike the situation with other team sports such as wheelchair basketball and wheelchair rugby. Inline sledge hockey is being developed to allow everyone, regardless of whether they have a disability or not, to complete up to world championship level based solely on talent and ability. The first game of inline sledge hockey was played at Bisley, England, on 19 December 2009 between the Hull Stingrays and the Grimsby Redwings. Matt Lloyd is credited with inventing inline sledge hockey, and Great Britain is seen as the international leader in the game's development.

Inline hockey is a variation of roller hockey very similar to ice hockey, from which it is derived. Inline hockey is played by two teams, consisting of four skaters and one goalie, on a dry rink divided into two halves by a center line, with one net at each end of the rink. The game is played in three 15-minute periods with a variation of the ice hockey off-side rule. Icings are also called, but are usually referred to as illegal clearing. The governing body is the IIHF, as for ice hockey, but some leagues and competitions do not follow the IIHF regulations, in particular USA Inline and Canada Inline.

Roller hockey, also known as quad hockey, international-style ball hockey, rink hockey and Hoquei em Patins, is an overarching name for a roller sport that has existed since long before inline skates were invented. This sport is played in over sixty countries and has a worldwide following. Roller hockey was a demonstration sport at the 1992 Barcelona Summer Olympics.

Also known as road hockey, this is a dry-land variant of ice and roller hockey played year-round on a hard surface (usually asphalt). A ball is usually used instead of a puck, and protective equipment is not usually worn.

Other games derived from hockey or its predecessors include the following:






</doc>
<doc id="13983" url="https://en.wikipedia.org/wiki?curid=13983" title="Hawick">
Hawick

Hawick ( ; , ) is a town in the Scottish Borders council area and historic county of Roxburghshire in the east Southern Uplands of Scotland. It is south-west of Jedburgh and south-southeast of Selkirk. It is one of the farthest towns from the sea in Scotland, in the heart of Teviotdale, and the biggest town in the former county of Roxburghshire. Hawick's architecture is distinctive in that it has many sandstone buildings with slate roofs. The town is at the
confluence of the Slitrig Water with the River Teviot. Hawick is known for its yearly Common Riding, for its rugby team Hawick Rugby Football Club and for its knitwear industry.

At the 2001 census Hawick had a resident population of 14,801. By 2011, this had reduced to 14,294.

The west end of the town contains "the Mote", the remains of a Norman motte-and-bailey. In the centre of the High Street is the Scots baronial style town hall, built in 1886, and the east end has an equestrian statue, known as "the Horse", erected in 1914. Drumlanrig's Tower, now a museum, dates largely from the mid-16th century.
In 2009 another monument the "Turning of the Bull" (artist, Angela Hunter, Innerleithen, Scotland) was unveiled in Hawick. This monument depicts William Rule turning the wild bull as it was charging King Robert the Bruce, thus saving the king's life and beginning the Scottish Clan of Turnbull. A poem written by John Leyden commemorates this historical event. "His arms robust the hardy hunter flung around his bending horns, and upward wrung, with writhing force his neck retorted round, and rolled the panting monster to the ground, crushed, with enormous strength, his bony skull; and courtiers hailed the man who turned the bull."

Companies: Hawick Cashmere, Hawick Knitwear, Johnstons of Elgin, Lyle & Scott, Peter Scott, Pringle of Scotland, and Scott and Charters, have had and in many cases still have manufacturing plants in Hawick, producing luxury cashmere and merino wool knitwear. The first knitting machine was brought to Hawick in 1771 by John Hardie, building on an existing carpet manufacturing trade. Originally based on linen, this quickly moved to wool and factories multiplied, driving the growth of the town. Engineering firm Turnbull and Scott had their headquarters in an Elizabethan-style listed building on Commercial Road before moving to Burnfoot.

In recent times, unemployment has been an issue in Hawick, and the unemployment claimant rate remained ahead of the overall Scottish Borders between 2014 and 2017. The closure of once significant employers including mills like Peter Scott and Pringle have impacted job availability in the town over the last few decades, and the population has declined partly because of this, at 13,730 in 2016, the lowest level since the 1800s. Despite efforts to improve the economic situation, employment and poverty remain relatively important in the context of the Scottish Borders, with the number of children living in poverty in the town 10% higher than the average for the region in 2017. Developments such as a new central business hub, Aldi supermarket, and distillery, all set for opening in 2018/19, are expected to benefit Hawick. Despite this, continued business closures, for example Homebase and the Original Factory Store in 2018, suggest continued economic decline for the town.

Hawick lies in the centre of the valley of the Teviot. The A7 Edinburgh to Carlisle road passes through the town, with main roads also leading to Berwick-upon-Tweed (the A698) and Newcastle upon Tyne (the A6088, which joins the A68 at the Carter Bar, south-east of Hawick).

The town lost its rail service in 1969, when as part of the Beeching Axe the 'Waverley Route' from Carlisle to Edinburgh via Hawick was closed. It was said to be the farthest large town from a railway station in the United Kingdom, but this changed as a result of the opening of the Borders Railway, which in 2015 reopened part of the former Waverley Route to Tweedbank, near Galashiels. Regular buses serve the railway station at Carlisle, away. Reconnecting Hawick to the Borders Railway would require reinstatement of a further approximately 17 miles of the former Waverley Route from Hawick to Tweedbank station via Hassendean, St Boswells, and Melrose, and refurbishment of the four arch Ale Water viaduct near New Belses. Hawick station was on the north bank of the river Teviot, below Wilton Hill Terrace, with a now demolished viaduct (near the Mart Street bridge) carrying the route south towards Carlisle. Waverley Walk in Hawick is footpath along the former railway route, north-eastward from the former station site near Teviotdale Leisure Centre.

The nearest major airports are at Edinburgh, away, and Newcastle, away.

The town hosts the annual Common Riding, which combines the annual riding of the boundaries of the town's common land with the commemoration of a victory of local youths over an English raiding party in 1514. In March 2007, this was described by the "Rough Guide" publication "World Party" as one of the best parties in the world.

People from Hawick call themselves "Teries", after a traditional song which includes the line "Teribus ye teri odin".

Many Hawick residents speak the local dialect of Border Scots which is informally known as "Teri Talk". It is similar (but not identical by any means) to the dialects spoken in surrounding towns, especially Jedburgh, Langholm and Selkirk. The speech of this general area was described in "Dialect of the Southern Counties of Scotland" (1873) by James Murray, considered the first systematic study of any dialect. The Hawick tongue retains many elements of Old English, together with particular vocabulary, grammar and pronunciation. Its distinctiveness arose from the relative isolation of the town.

The town is the home of Hawick Rugby Football Club and a senior football team, Hawick Royal Albert, who currently play in the East of Scotland Football League.

Rivalry between the small Border towns is generally played out on the rugby union field. The historical competition continues to this day, as Hawick's main rival is the similarly-sized town of Galashiels.

The Hawick Baw game was once played here by the 'uppies' and the 'doonies' on the first Monday after the new moon in the month of February. The river of the town formed an important part of the pitch. Although no longer played at Hawick, it is still played at nearby Jedburgh.

"Hawick balls" or "baws", also known as Hills Balls or taffy rock bools, are a peppermint-flavoured boiled sweet that originated in the town. They are particularly associated with rugby commentator Bill McLaren who was known to offer them from a bag that he always carried. They are now produced in Greenock.

The Borders Abbeys Way passes through Hawick. A statue of Bill McLaren the late popular rugby commentator is in Wilton Lodge Park to the west of the town centre.









Hawick's villages:




</doc>
<doc id="13985" url="https://en.wikipedia.org/wiki?curid=13985" title="Hatfield, Hertfordshire">
Hatfield, Hertfordshire

Hatfield is a town and civil parish in Hertfordshire, England, in the borough of Welwyn Hatfield. It had a population of 29,616 in 2001, and 39,201 at the 2011 Census. The settlement is of Saxon origin. Hatfield House, home of the Marquess of Salisbury, forms the nucleus of the old town. From the 1930s when de Havilland opened a factory until the 1990s when British Aerospace closed it, aircraft design and manufacture employed more people there than any other industry. Hatfield was one of the post-war New Towns built around London and has much modernist architecture from the period. The University of Hertfordshire is based there.

Hatfield lies north of London beside the A1(M) motorway and has direct trains to London King's Cross railway station, Finsbury Park and Moorgate. There has been a strong increase in commuters who work in London moving into the area.

In the Saxon period Hatfield was known as Hetfelle, but by the year 970, when King Edgar gave to the monastery of Ely, it had become known as Haethfeld. Hatfield is recorded in the Domesday Book as the property of the Abbey of Ely, and unusually, the original census data which compilers of Domesday used survives, giving us slightly more information than in the final Domesday record. No other records remain until 1226, when Henry III granted the Bishops of Ely rights to an annual four-day fair and a weekly market. The town was then called Bishop's Hatfield.

Hatfield House is the seat of the Cecil family, the Marquesses of Salisbury. Elizabeth Tudor was confined there for three years in what is now known as The Old Palace in Hatfield Park. Legend has it that she learnt here of her accession as queen in 1558, while sitting under an oak tree in the Park. She held her first Council in the Great Hall (The Old Palace) of Hatfield. In 1851, the route of the Great North Road (now the A1000) was altered to avoid cutting through the grounds of Hatfield House.

The town grew up around the gates of Hatfield House. Old Hatfield retains many historic buildings, notably the Old Palace, St Etheldreda's Church and Hatfield House. The Old Palace was built by the Bishop of Ely, Cardinal Morton, in 1497, during the reign of Henry VII, and the only surviving wing is still used today for Elizabethan-style banquets.

St Etheldreda's Church was founded by the monks from Ely, and the first wooden church, built in 1285, was probably sited where the existing building stands overlooking the old town.

The church of St Etheldreda, well situated towards the top of the hill, contains an Early English round arch with the dog-tooth moulding, but for the rest is Decorated and Perpendicular, and largely restored. The chapel north of the chancel is known as the Salisbury chapel, and was erected by Robert Cecil, 1st Earl of Salisbury, who was buried here. It is in a mixture of classic and Gothic styles. In a private portion of the churchyard is buried, among others of the family, Robert Gascoyne-Cecil, 3rd Marquess of Salisbury.

In 1930 the de Havilland airfield and aircraft factory was opened at Hatfield and by 1949 it had become the largest employer in the town, with almost 4,000 staff. It was taken over by Hawker Siddeley in 1960 and merged into British Aerospace in 1978. In the 1930s it produced a range of small biplanes. During the Second World War it produced the Mosquito fighter bomber and developed the Vampire, the second British production jet aircraft after the Gloster Meteor. After the war, facilities were expanded and it developed the Comet airliner (the world's first production jet liner), the Trident airliner, and an early bizjet, the DH125.

British Aerospace closed the Hatfield site in 1993 having moved the BAe 146 production line to Woodford Aerodrome. The land was used as a film set for Steven Spielberg's movie "Saving Private Ryan" and most of the BBC/HBO television drama "Band of Brothers". It was later developed for housing, higher education, commerce and retail. 

Today, Hatfield's aviation history is remembered by the names of certain local streets and pubs (e. g. Comet Way, The Airfield, Dragon Road) as well as "The Comet Hotel" (now owned by Ramada) built in the 1930s. "The Harrier Pub" (formerly "The Hilltop") is actually named after the Harrier bird, not the aircraft, hence the original pub sign showing the bird. The de Havilland Aircraft Heritage Centre, at Salisbury Hall in nearby London Colney, preserves and displays many historic de Havilland aeroplanes and related archives.

The Abercrombie Plan for London in 1944 proposed a New Town in Hatfield. It was designated in the New Towns Act 1946, forming part of the initial Hertfordshire group with nearby Stevenage, Welwyn Garden City and Letchworth. The Government allocated for Hatfield New Town, with a population target of 25,000. (By 2001 the population had reached 27,833.) The Hatfield Development Corporation, tasked with creating the New Town, chose to build a new town centre, rejecting Old Hatfield because it was on the wrong side of the railway, without space for expansion and "with its intimate village character, out of scale with the town it would have to serve." They chose instead St Albans Road on the town's east-west bus route. A road pattern was planned that offered no temptation to through traffic to take short cuts through the town and which enabled local traffic to move rapidly.

Hatfield retains New Town characteristics, including much modernist architecture of the 1950s and the trees and open spaces that were outlined in the original design. As of 2017, a redevelopment of the town centre was planned.

Hatfield Town F.C. plays Non-League football at Gosling Sports Park.

Hatfield Athletic Football Club competes in the Herts Senior County League and plays its games at Lemsford.

The town has a public swimming pool and four sports/leisure centres (two with indoor swimming pools).

Hatfield is part of Welwyn Hatfield borough council in the county of Hertfordshire. It is a civil parish and has a town council. It is twinned with the Dutch port town of Zierikzee. Hatfield is part of the Welwyn Hatfield constituency, which also includes Welwyn Garden City. The MP for Welwyn Hatfield is Grant Shapps, a Conservative.

Hatfield experiences an oceanic climate (Köppen climate classification "Cfb") like most of the United Kingdom.

Hatfield has a nine-screen Odeon cinema, a stately home (Hatfield House), a museum (Mill Green Museum), a contemporary art gallery (Art and Design Gallery), a theatre (The Weston Auditorium) and a music venue (The Forum Hertfordshire). There are shopping centres in the new town: the Galleria (indoor shopping centre), The Stable Yard (Hatfield House), and at two supermarkets (ASDA and Tesco).

Hatfield contains numerous primary and secondary schools, including The Ryde School, St Philip Howard Catholic Primary School, Countess Anne School, Onslow St Audrey's School and Bishops Hatfield Girls School and the independent day and boarding girls' school Queenswood School.

The University of Hertfordshire is based in Hatfield. A large section of the airfield site was purchased by the University and the £120-million de Havilland Campus, incorporating a £15-million Sports Village, was opened in September 2003. The university has closed its sites at Watford and Hertford; faculties situated there have been moved to the de Havilland Campus.

The equine branch of the Royal Veterinary College is based in Hatfield.


Hatfield is to the north of London. It is from London Luton Airport. The A1(M) runs through a tunnel beneath the town, which is also close to the M25.

In the eighteenth and nineteenth centuries it was the northern terminus of the Hatfield and Reading Turnpike that allowed travelers from the north to continue their journey to the west without going through the congestion of London.

The East Coast railway line from London to York runs through the town, separating the old and new parts. A commuter service connects Hatfield railway station to London King's Cross. A new railway station and car park opened in late 2015. The frequent train service runs direct from Hatfield Station to London King's Cross (21 minutes) via Finsbury Park (16 minutes, Victoria Underground Line) on fast trains running two or three times an hour. An additional train service calls at all stations to Moorgate in the City of London.

There was a fatal rail crash at Hatfield in 2000, which brought track-maintenance deficiencies to public attention. A garden beside the East Coast Main Line was built as a memorial to the crash victims.











</doc>
<doc id="13986" url="https://en.wikipedia.org/wiki?curid=13986" title="Hertfordshire">
Hertfordshire

Hertfordshire (; often abbreviated Herts) is one of the home counties in southern England. It is bordered by Bedfordshire and Cambridgeshire to the north, Essex to the east, Greater London to the south, and Buckinghamshire to the west. For government statistical purposes, it is placed in the East of England region.

In 2013, the county had a population of 1,140,700 in an area of . Hemel Hempstead, Stevenage, Watford, and the only city in the county, St Albans have between 50,000 and 100,000 residents. Hertford, once the main market town for the medieval agricultural county, derives its name from a hart (stag) and a ford, used as the components of the county's coat of arms and flag. Elevations are high for the region in the north and west. These reach over in the western projection around Tring which is in the Chilterns. The county's borders are approximately the watersheds of the Colne and Lea; both flowing to the south; each accompanied by a canal. Hertfordshire's undeveloped land is mainly agricultural and much is protected by green belt.

The county's landmarks span many centuries, ranging from the Six Hills in the new town of Stevenage built by local inhabitants during the Roman period, to Leavesden Film Studios. The volume of intact medieval and Tudor buildings surpasses London, in places in well-preserved conservation areas, especially in St Albans which includes some remains of Verulamium, the town where in the 3rd century an early recorded British martyrdom took place. Saint Alban, a Romano-British soldier, took the place of a Christian priest and was beheaded on Holywell Hill. His martyr's cross of a yellow saltire on a blue field is reflected in the flag and coat of arms of Hertfordshire.

Hertfordshire is well-served with motorways and railways, providing good access to London. The largest sector of the economy of the county is in services.

Hertfordshire was the area assigned to a fortress constructed at Hertford under the rule of Edward the Elder in 913. Hertford is derived from the Anglo-Saxon "heort ford," meaning deer crossing (of a watercourse). The name Hertfordshire is first recorded in the "Anglo-Saxon Chronicle" in 1011. Deer feature in many county emblems. Many of the names of the current settlements date back to the Anglo-Saxon period, with many featuring standard placename suffixes attributed to the Anglo-Saxons: "ford", "ton", "den", "bourn", "ley", "stead", "ing", "lett", "wood", and "worth", are represented in this county by Hertford, Royston, Harpenden, Redbourn, Cuffley, Wheathampstead, Tring, Radlett, Borehamwood, and Rickmansworth.

There is evidence of human life in Hertfordshire from the Mesolithic period. It was first farmed during the Neolithic period and permanent habitation appeared at the beginning of the Bronze Age. This was followed by tribes settling in the area during the Iron Age.

Following the Roman conquest of Britain in AD 43, the aboriginal Catuvellauni quickly submitted and adapted to the Roman life; resulting in the development of several new towns, including Verulamium (St Albans) where in c. 293 the first recorded British martyrdom is traditionally believed to have taken place. Saint Alban, a Romano-British soldier, took the place of a Christian priest and was beheaded on Holywell Hill. His martyr's cross of a yellow saltire on a blue field is reflected in the flag and coat of arms of Hertfordshire as the yellow field to the stag or Hart representing the county. He is the Patron Saint of Hertfordshire.

With the departure of the Roman Legions in the early 5th century, the now unprotected territory was invaded and colonised by the Anglo-Saxons. By the 6th century the majority of the modern county was part of the East Saxon kingdom. This relatively short-lived kingdom collapsed in the 9th century, ceding the territory of Hertfordshire to the control of the West Anglians of Mercia. The region finally became an English shire in the 10th century, on the merger of the West Saxon and Mercian kingdoms.
In the midst of the Norse invasions, Hertfordshire was on the front lines of much of the fighting. King Edward the Elder, in his reconquest of Norse-held lands in what was to become England, established a "burh" or fort in Hertford, which was to curb Norse activities in the area. His father, King Alfred the Great, established the River Lea as a boundary between his kingdom and that of the Norse lord Guthrum, with the north and eastern parts of the county being within the Danelaw. There is little evidence however of Norse placenames within this region, and many of the Anglo-Saxon features remained intact to this day. The county however suffered from renewed Norse raids in the late 10th to early 11th centuries, as armies led by Danish kings Swein Forkbeard and Cnut the Great harried the country as part of their attempts to undermine and overthrow English king Athelred the Unready.

A century later, William of Normandy received the surrender of the surviving senior English Lords and Clergy at Berkhamsted, resulting in a new Anglicised title of William the Conqueror, before entering London unopposed and being crowned at Westminster. Hertfordshire was used for some of the new Norman castles at Bishop's Stortford, and at King's Langley, a staging post between London and the royal residence of Berkhamsted.

The Domesday Book recorded the county as having nine hundreds. Tring and Danais became oneDacorumfrom Danis Corum or Danish rule harking back to a Viking not Saxon past. The other seven were Braughing, Broadwater, Cashio, Edwinstree, Hertford, Hitchin and Odsey.

In the later Plantagenet period, St. Albans Abbey was an initial drafting place of what was to become the Magna Carta. And in the later Wars of the Roses, St. Albans was the scene of two major battles between the Lancastrians and the Yorkists.

In Tudor times, Hatfield House was often frequented by Queen Elizabeth I. Stuart King James I used the locale for hunting and facilitated the construction of a waterway, the New River, supplying drinking water to London.

As London grew, Hertfordshire became conveniently close to the English capital; much of the area was owned by the nobility and aristocracy, this patronage helped to boost the local economy. However, the greatest boost to Hertfordshire came during the Industrial Revolution, after which the population rose dramatically. In 1903, Letchworth became the world's first garden city and Stevenage became the first town to redevelop under the New Towns Act 1946.

The first shooting-down of a zeppelin over Great Britain during WW1 happened in Cuffley.

From the 1920s until the late 1980s, the town of Borehamwood was home to one of the major British film studio complexes, including the MGM-British Studios. Many well-known films were made here including the first three "Star Wars" movies (IV, V, & VI). The studios generally used the name of Elstree. American director Stanley Kubrick not only used to shoot in those studios but also lived in the area until his death. "Big Brother UK" and "Who Wants To Be A Millionaire?" have been filmed there. "EastEnders" is filmed at Elstree. Hertfordshire has seen development at Warner Bros. Studios, Leavesden; the "Harry Potter" series was filmed here and the 1995 James Bond film "GoldenEye".

On 17 October 2000, the Hatfield rail crash killed four people with over 70 injured. The crash exposed the shortcomings of Railtrack, which consequently saw speed restrictions and major track replacement. On 10 May 2002, the second of the Potters Bar rail accidents occurred killing seven people; the train was at high speed when it derailed and flipped into the air when one of the carriages slid along the platform where it came to rest.

In early December 2005, the 2005 Hemel Hempstead fuel depot explosions occurred at the Hertfordshire Oil Storage Terminal.

In 2012, the canoe and kayak slalom events of the 2012 Summer Olympics took place in Waltham Cross, Broxbourne.

Hertfordshire is the county immediately north of London and is part of the East of England region, a mainly statistical unit. To the east is Essex, to the west is Buckinghamshire and to the north are Bedfordshire and Cambridgeshire. A significant minority of the population across all districts commute to Central London.

The county's boundaries were roughly fixed by the Counties (Detached Parts) Act 1844 which eliminated exclaves; amended when, in 1965 under the London Government Act 1963, East Barnet Urban District and Barnet Urban District were abolished, their area was transferred to form part of the present-day London Borough of Barnet and the Potters Bar Urban District of Middlesex was transferred to Hertfordshire.

The highest point in the county is at (AOD) on the Ridgeway long distance national path, on the border of Hastoe near Tring with Drayton Beauchamp, Buckinghamshire.

As at the 2011 census of the ten Districts, East Hertfordshire had the minimal, 290 people per km, whereas Watford had the maximal 4210 people per km. Compared to nearby Bedfordshire and Buckinghamshire, Hertfordshire has far less large towns or cities, such as Luton and Milton Keynes respectively, which have roughly 200,000 or more residents apiece. The overall population of Hertfordshire is higher than the two aforementioned counties (approximately 1,000,000), but featuring many small to medium-sized towns. The larger communities in the county, such as Stevenage, Watford, Letchworth and Hemel Hempstead, all have populations ranging from 70,000 to 150,000, and thus not overly large in the grand scheme of British locales.

The River Lea near Harpenden runs through Wheathampstead, Welwyn Garden City, Hertford, Ware, and Broxbourne before reaching Cheshunt and ultimately the River Thames. The far west of the county is the most hilly, with the Chiltern Hills surrounding Tring, Berkhamsted and the Ashridge estate. This Area of Outstanding Natural Beauty runs from near Hitchin in the north to Berkshire and Oxfordshire.

Many of the county's major settlements are in the central, northern and southern areas, such as Watford, Hemel Hempstead, Kings Langley, Rickmansworth, St. Albans, Harpenden, Radlett, Borehamwood, Potters Bar, Stevenage, Hatfield, Welwyn and Welwyn Garden City, Hitchin, Letchworth and Baldock. These are all small to medium-sized locations, featuring a mix of post-WWII new towns and older/more historical locales. The City of St. Albans is an example of a historical settlement, as its cathedral and abbey date to the Norman period, and there are ruins from the Roman settlement of Verulamium nearby the current city centre. Stevenage is a mix of post-WWII new town planning amidst its prior incarnation as a smaller town. The Old Town in Stevenage represents this historic core and has many shops and buildings reflecting its pre-WWII heritage. Hitchin also has a historic centre, with many Tudor and Stuart era buildings interspersed amongst more contemporary structures.

Hertfordshire's eastern regions are predominantly rural and arable, intermixed with villages and small to medium-sized towns. Royston, Buntingford and Bishops Stortford, along with Ware and the county town of Hertford are major settlements in this regard. The physical geography of eastern Hertfordshire is less elevated than the far west, but with lower rising hills and prominent rivers such as the Stort. This river rises in Essex and terminates via a confluence with the Lea near to Ware. 
Apart from the Lea and Stort, the River Colne is the major watercourse in the county's west. This runs near Watford and Radlett, and has a complex system/drainage area running south into both Greater London and Buckinghamshire.

An unofficial status, the purple star-shaped flower with yellow stamens, the Pasqueflower is among endemic county flowers.

The rocks of Hertfordshire belong to the great shallow syncline known as the London Basin. The beds dip in a south-easterly direction towards the syncline's lowest point roughly under the River Thames. The most important formations are the Cretaceous Chalk, exposed as the high ground in the north and west of the county, forming the Chiltern Hills and the younger Palaeocene, Reading Beds and Eocene, London Clay which occupy the remaining southern part. The eastern half of the county was covered by glaciers during the Ice Age and has a superficial layer of glacial boulder clays.

Much of the county is given over to agriculture. One product, now largely defunct, was water-cress, based in Hemel Hempstead and Berkhamsted supported by reliable, clean chalk rivers. 

Some quarrying of sand and gravel occurs in the St Albans area. In the past, clay has supplied local brick-making and still does in Bovingdon, just south-west of Hemel Hempstead. The chalk that is the bedrock of much of the county provides an aquifer that feeds streams and is also exploited to provide water supplies for much of the county and beyond. Chalk has also been used as a building material and, once fired, the resultant lime was spread on agricultural land to improve fertility. The mining of chalk since the early 18th century has left unrecorded underground galleries that occasionally collapse unexpectedly and endanger buildings.

Fresh water is supplied to London from Ware, using the New River built by Hugh Myddleton and opened in 1613. Local rivers, although small, supported developing industries such as paper production at Nash Mills.

Hertfordshire affords habitat for a variety of flora and fauna. One bird previously common in the shire is the Hooded Crow, the old name of which is the eponymous name of the regional newspaper, the "Royston Crow" published in Royston.

In November 2013, the uSwitch Quality of Life Index listed Hertfordshire as the third-best place to live in the UK.

This is a table of trends of regional gross value added of Hertfordshire at current basic prices with figures in millions of British Pounds Sterling.

Hertfordshire has headquarters of many large well-known UK companies. Hemel Hempstead is home to DSG International. Welwyn Garden City hosts Tesco, as well as Roche UK's headquarters (subsidiary of the Swiss pharmaceutical firm Hoffman-La Roche) and Cereal Partners production facilities, Pure the DAB radio maker is based in Kings Langley. JD Wetherspoon is in Watford. Skanska is in Rickmansworth, GlaxoSmithKline has plants in Ware and Stevenage. Hatfield used to be connected with the aircraft industry, as it was where de Havilland developed the world's first commercial jet liner, the Comet. Now the site is a business park and new campus for the University of Hertfordshire. This major new employment site is home to, among others, EE, Computacenter and Ocado. A subsidiary of BAE Systems, Airbus and Finmeccanica in Stevenage, MBDA, develops missiles. In the same town Airbus (Defence & Space Division) produces satellites. The National Pharmacy Association (NPA), the trade association for all of the UK's community pharmacies, is based in St Albans. Warner Bros. also owns and runs Warner Studios in Leavesden.

As of the 2019–20 season, there are three professional football teams in Hertfordshire: Watford F.C., Stevenage F.C., and Arsenal W.F.C..

Since 1922, Watford play their home games at Vicarage Road. The club joined the Football League in 1920 as a founding member of the Third Division and first played in the First Division of English football in 1982, finishing as runners-up to champions Liverpool. Watford have played in the Premier League since their promotion from the EFL Championship following the 2014-15 season.

Stevenage F.C. was formed in 1976 as Stevenage Borough and have played at Broadhall Way since 1980. Stevenage was the first club to win a competitive match at the new Wembley Stadium, beating Kidderminster Harriers 3–2 in the 2007 FA Trophy Final. The club currently play in the EFL League Two and have been managed by former player Dino Maamria since March 2018.

Arsenal F.C., whilst based at the Emirates Stadium in the London Borough of Islington, has long held a training ground in the county. Until 1999, it held the London Colney University of London facility, until it built a new purpose-built compound adjacent to it. Watford FC currently utilises the old Arsenal training area as its training facility.

Arsenal W.F.C. play at Meadow Park in Borehamwood. The club was formed in 1987 and have played in the FA Women's Super League since its inaugural season in 2011.

Hertfordshire has many semi-professional and amateur clubs. The highest placed of these is Boreham Wood who play in the National League, the fifth tier of English football. The next highest placed are Hemel Hempstead Town and St Albans City, who play one division lower in the National League South.

Hemel Stags are a rugby league team based in Hemel Hempstead. Hemel Stags have played at Pennine Way Stadium since the club's founding in 1981. The club plays in league 1, the of the British rugby league system.

The Hertfordshire Rugby Football Union is the governing body for rugby union in Hertfordshire; responsible for any interested parties involved in rugby.

Tring Rugby play matches at Cow Lane, Tring. The first XV currently play in the London & South East Premier, a league.

Below is a list of notable visitor attractions in Hertfordshire:


Hertfordshire is a home county with many towns forming part of the London commuter belt and has some of the principal roads in England including the A1, A1(M), A41, A414, M1, M11, and the M25.

Four principal national railway lines pass through the county:

A number of other local rail routes also cross Hertfordshire:

Three commuter lines operated by Transport for London enter the county:

Stansted Airport and Luton Airport are both within of the county's borders. The commercial airfield at Elstree is for light aircraft.

The Grand Union Canal passes through Rickmansworth, Watford, Hemel Hempstead, Berkhamsted and Tring.

Hertfordshire has 26 independent schools and 73 state secondary schools.
The state secondary schools are entirely comprehensive, although 7 schools in the south and southwest of the county are partially selective (see Education in Watford).
All state schools have sixth forms, and there are no sixth form colleges.
The tertiary colleges, each with multiple campuses, are Hertford Regional College, North Hertfordshire College, Oaklands College and West Herts College.
The University of Hertfordshire is a modern university based largely in Hatfield. It has more than 23,000 students.

Hertfordshire is the location of Jack Worthing's country house in Oscar Wilde's play "The Importance of Being Earnest".

Jane Austen's novel "Pride and Prejudice" is primarily set in Hertfordshire.

The location of Mr Jarndyce's Bleak House in Charles Dickens's "Bleak House" is near St Albans.

The eponymous residence in E. M. Forster's novel "Howards End" was based on Rooks Nest House just outside Stevenage.

George Orwell based "Animal Farm" on Wallington, Hertfordshire, where he lived between 1936 and 1940. Manor Farm and The Great Barn both feature in the novel.




</doc>
<doc id="13987" url="https://en.wikipedia.org/wiki?curid=13987" title="Helene Kröller-Müller">
Helene Kröller-Müller

Helene Kröller-Müller (11 February 1869 – 14 December 1939) was one of the first European women to put together a major art collection. She is credited with being one of the first collectors to recognise the genius of Vincent van Gogh. She donated her entire collection to the Dutch people, along with her and her husband, Anton Kröller's, large forested country estate. Today it is the Kröller-Müller Museum and sculpture garden and Hoge Veluwe National Park, the largest national park in the Netherlands.

She was born Helene Emma Laura Juliane Müller at , Essen, Germany, into a wealthy industrialist family. Her father, Wilhelm Müller, owned Wm. H. Müller & Co., a prosperous supplier of raw materials to the mining and steel industries. She married Dutch shipping and mining tycoon Anton Kröller in 1888 and used both surnames in accordance with Dutch tradition.

She studied under Henk Bremmer in 1906–1907. As she was one of the wealthiest women in the Netherlands at the time, Bremmer recommended that she form an art collection. In 1907, she began her collection with the painting "Train in a Landscape" by Paul Gabriël. Subsequently, Helene Kröller-Müller became an avid art collector, and one of the first people to recognise the genius of Vincent van Gogh. She eventually amassed more than 90 van Gogh paintings and 185 drawings, one of the world's largest collections of the artist's work, second only to the Van Gogh Museum in Amsterdam. She also bought more than 400 works by Dutch artist Bart van der Leck, but his popularity did not take off like van Gogh's.
Kröller-Müller also collected works by modern artists, such as Picasso, Georges Braque, Jean Metzinger, Albert Gleizes, Fernand Léger, Diego Rivera, Juan Gris, Piet Mondrian, Gino Severini, Joseph Csaky, Auguste Herbin, Georges Valmier, María Blanchard, Léopold Survage and Tobeen. However, Bremmer advised her not to buy "A Sunday Afternoon on the Island of La Grande Jatte" by Georges Seurat, which turned out to be an important icon of 20th-century art. She did purchase however "Le Chahut" by Seurat, another icon in the history of modern art. Also, she steered away from artists of her native Germany, whose work she found "insufficiently authoritative."

On a trip to Florence in June 1910, she conceived the idea of creating a museum-house. From 1913 onwards parts of her collection were open to the public; until the mid-1930s her exhibition hall in The Hague was one of the very rare places where one could see more than a few works of modern art. In 1928, Anton and Helene created the Kröller-Müller Foundation to protect the collection and the estates. In 1935, they donated to the Dutch people their entire collection totaling approximately 12,000 objects, on condition that a large museum be built in the gardens of her park. Held in the care of the Dutch government, the Kröller-Müller Museum was opened in 1938.

The Kröller-Müller Museum is nestled in their 75-acre (300,000 m) forested country estate, today the largest national park in the Netherlands, the Hoge Veluwe National Park near the town of Otterlo and Arnhem. A lavish art gallery was planned near their iconic lakeside Jachthuis Sint Hubertus hunting lodge and landscape statue of their close personal friend, the South African Boer General Christian de Wet on the estate. Due to threat of war the plans were never implemented in their lifetime but once the war was over a large forest sculpture garden and understated open exhibition extension was opened, housing statues by Rodin and the second largest collection of van Gogh paintings in the world, including the famous Sunflowers.




</doc>
<doc id="13988" url="https://en.wikipedia.org/wiki?curid=13988" title="Hans-Georg Gadamer">
Hans-Georg Gadamer

Hans-Georg Gadamer (; ; February 11, 1900 – March 13, 2002) was a German philosopher of the continental tradition, best known for his 1960 "magnum opus" "Truth and Method" ("Wahrheit und Methode") on hermeneutics. 

Gadamer was born in Marburg, Germany, the son of Johannes Gadamer (1867–1928), a pharmaceutical chemistry professor who later also served as the rector of the University of Marburg. He was raised a Protestant Christian. Gadamer resisted his father's urging to take up the natural sciences and became more and more interested in the humanities. His mother, Emma Karoline Johanna Geiese (1869–1904) died of diabetes while Hans-Georg was four years old, and he later noted that this may have had an effect on his decision to not pursue scientific studies. Jean Grondin describes Gadamer as finding in his mother "a poetic and almost religious counterpart to the iron fist of his father". Gadamer did not serve during World War I for reasons of ill health and similarly was exempted from serving during World War II due to polio.

He later studied classics and philosophy in the University of Breslau under Richard Hönigswald, but soon moved back to the University of Marburg to study with the Neo-Kantian philosophers Paul Natorp (his doctoral thesis advisor) and Nicolai Hartmann. He defended his dissertation "The Essence of Pleasure in Plato's Dialogues" () in 1922.

Shortly thereafter, Gadamer moved to Freiburg University and began studying with Martin Heidegger, who was then a promising young scholar who had not yet received a professorship. He became close to Heidegger, and when Heidegger received a position at Marburg, Gadamer followed him there, where he became one of a group of students such as Leo Strauss, Karl Löwith, and Hannah Arendt. It was Heidegger's influence that gave Gadamer's thought its distinctive cast and led him away from the earlier neo-Kantian influences of Natorp and Hartmann. Gadamer studied Aristotle both under Edmund Husserl and under Heidegger.

Gadamer habilitated in 1929 and spent most of the early 1930s lecturing in Marburg. Unlike Heidegger, who joined the Nazi Party in May 1933 and continued as a member until the party was dissolved following World War II, Gadamer was silent on Nazism, and he was not politically active during the Third Reich. Gadamer did not join the Nazis, and he did not serve in the army because of the polio he had contracted in 1922. He joined the National Socialist Teachers League in August 1933.

In 1933 Gadamer signed the "Vow of allegiance of the Professors of the German Universities and High-Schools to Adolf Hitler and the National Socialistic State".

In April 1937 he became a temporary professor at Marburg, then in 1938 he received a professorship at Leipzig University. From an SS-point of view Gadamer was classified as neither supportive nor disapproving in the ""SD-Dossiers über Philosophie-Professoren"" (i.e. SD-files concerning philosophy professors) that were set up by the SS-Security-Service (SD). In 1946, he was found by the American occupation forces to be untainted by Nazism and named rector of the university.

The level of Gadamer's involvement with the Nazis has been disputed in the works of Richard Wolin and Teresa Orozco. Orozco alleges, with reference to Gadamer's published works, that Gadamer had supported the Nazis more than scholars had supposed. Gadamer scholars have rejected these assertions: Jean Grondin has said that Orozco is engaged in a "witch-hunt" while Donatella Di Cesare said that "the archival material on which Orozco bases her argument is actually quite negligible". Cesare and Grondin have argued that there is no trace of antisemitism in Gadamer's work, and that Gadamer maintained friendships with Jews and provided shelter for nearly two years for the philosopher Jacob Klein in 1933 and 1934. Gadamer also reduced his contact with Heidegger during the Nazi era.

The communist DDR was no more to Gadamer's liking than the Third Reich, and he left for West Germany, accepting first a position in Goethe University Frankfurt and then the succession of Karl Jaspers in the University of Heidelberg in 1949. He remained in this position, as emeritus, until his death in 2002 at the age of 102. He was also an Editorial Advisor of the journal Dionysius. It was during this time that he completed his "magnum opus", "Truth and Method" (1960), and engaged in his famous debate with Jürgen Habermas over the possibility of transcending history and culture in order to find a truly objective position from which to critique society. The debate was inconclusive, but marked the beginning of warm relations between the two men. It was Gadamer who secured Habermas's first professorship in the University of Heidelberg.

In 1968, Gadamer invited Tomonobu Imamichi for lectures at Heidelberg, but their relationship became very cool after Imamichi alleged that Heidegger had taken his concept of "Dasein" out of Okakura Kakuzo's concept of "das in-der-Welt-sein" (to be in the being in the world) expressed in "The Book of Tea", which Imamichi's teacher had offered to Heidegger in 1919, after having followed lessons with him the year before. Imamichi and Gadamer renewed contact four years later during an international congress.

In 1981, Gadamer attempted to engage with Jacques Derrida at a conference in Paris but it proved less enlightening because the two thinkers had little in common. A last meeting between Gadamer and Derrida was held at the Stift of Heidelberg in July 2001, coordinated by Derrida's students Joseph Cohen and Raphael Zagury-Orly. This meeting marked, in many ways, a turn in their philosophical encounter. After Gadamer's death, Derrida called their failure to find common ground one of the worst debacles of his life and expressed, in the main obituary for Gadamer, his great personal and philosophical respect. Richard J. Bernstein said that "[a] genuine dialogue between Gadamer and Derrida has never taken place. This is a shame because there are crucial and consequential issues that arise between hermeneutics and deconstruction".

Gadamer received honorary doctorates from the University of Bamberg, the University of Wrocław, Boston College, Charles University in Prague, Hamilton College, the University of Leipzig, the University of Marburg (1999) the University of Ottawa, Saint Petersburg State University (2001), the University of Tübingen and University of Washington.

On February 11, 2000, the University of Heidelberg celebrated Gadamer's one hundredth birthday with a ceremony and conference. Gadamer's last academic engagement was in the summer of 2001 at an annual symposium on hermeneutics that two of Gadamer's American students had organised. On March 13, 2002, Gadamer died at Heidelberg's University Clinic at the age of 102. He is buried in the Köpfel cemetery in Ziegelhausen.

Gadamer's philosophical project, as explained in "Truth and Method", was to elaborate on the concept of "philosophical hermeneutics", which Heidegger initiated but never dealt with at length. Gadamer's goal was to uncover the nature of human understanding. In "Truth and Method", Gadamer argued that "truth" and "method" were at odds with one another. For Gadamer, "the experience of art is exemplary in its provision of truths that are inaccessible by scientific methods, and this experience is projected to the whole domain of human sciences." He was critical of two approaches to the human sciences ("Geisteswissenschaften"). On the one hand, he was critical of modern approaches to humanities that modeled themselves on the natural sciences, which simply sought to “objectively” observe and analyze texts and art. On the other hand, he took issue with the traditional German approaches to the humanities, represented for instance by Friedrich Schleiermacher and Wilhelm Dilthey, who believed that meaning, as an object, could be found within a text through a particular process that allowed for a connection with the author's thoughts that led to the creation of a text (Schleiermacher), or the situation that led to an expression of human inner life (Dilthey).

However, Gadamer argued meaning and understanding are not objects to be found through certain methods, but are inevitable phenomena. Hermeneutics is not a process in which an interpreter finds a particular meaning, but “a philosophical effort to account for understanding as an ontological—the ontological—process of man.” Thus, Gadamer is not giving a prescriptive method on how to understand, but rather he is working to examine how understanding, whether of texts, artwork, or experience, is possible at all. Gadamer intended "Truth and Method" to be a description of what we always do when we interpret things (even if we do not know it): "My real concern was and is philosophic: not what we do or what we ought to do, but what happens to us over and above our wanting and doing".

As a result of Martin Heidegger’s temporal analysis of human existence, Gadamer argued that people have a so-called historically-effected consciousness ("wirkungsgeschichtliches Bewußtsein"), and that they are embedded in the particular history and culture that shaped them. However the historical consciousness is not an object over and against our existence, but “a stream in which we move and participate, in every act of understanding.” Therefore, people do not come to any given thing without some form of preunderstanding established by this historical stream. The tradition in which an interpreter stands establishes "prejudices" that affect how he or she will make interpretations. For Gadamer, these prejudices are not something that hinders our ability to make interpretations, but are both integral to the reality of being, and “are the basis of our being able to understand history at all.” Gadamer criticized Enlightenment thinkers for harboring a "prejudice against prejudices".

For Gadamer, interpreting a text involves a fusion of horizons ("Horizontverschmelzung"). Both the text and the interpreter find themselves within a particular historical tradition, or “horizon.” Each horizon is expressed through the medium of language, and both text and interpreter belong to and participate in history and language. This “belongingness” to language is the common ground between interpreter and text that makes understanding possible. As an interpreter seeks to understand a text, a common horizon emerges. This fusion of horizons does not mean the interpreter now fully understands some kind of objective meaning, but is “an event in which a world opens itself to him.” The result is a deeper understanding of the subject matter.

Gadamer further explains the hermeneutical experience as a dialogue. To justify this, he uses Plato's dialogues as a model for how we are to engage with written texts. To be in conversation, one must take seriously “the truth claim of the person with whom one is conversing.” Further, each participant in the conversation relates to one another insofar as they belong to the common goal of understanding one another. Ultimately, for Gadamer, the most important dynamic of conversation as a model for the interpretation of a text is “the give-and-take of question and answer.” In other words, the interpretation of a given text will change depending on the questions the interpreter asks of the
text. The "meaning" emerges not as an object that lies in the text or in the interpreter, but rather an event that results from the interaction of the two.

"Truth and Method" was published twice in English, and the revised edition is now considered authoritative. The German-language edition of Gadamer's Collected Works includes a volume in which Gadamer elaborates his argument and discusses the critical response to the book. Finally, Gadamer's essay on Celan (entitled "Who Am I and Who Are You?") has been considered by many—including Heidegger and Gadamer himself—as a "second volume" or continuation of the argument in "Truth and Method".

Gadamer's "Truth and Method" has become an authoritative work in the communication ethics field, spawning several prominent ethics theories and guidelines. The most profound of these is the formulation of the dialogic coordinates, a standard set of prerequisite communication elements necessary for inciting dialogue. Adhering to Gadamer's theories regarding bias, communicators can better initiate dialogic transaction, allowing biases to merge and promote mutual understanding and learning.

Gadamer also added philosophical substance to the notion of human health. In "The Enigma of Health", Gadamer explored what it means to heal, as a patient and a provider. In this work the practice and art of medicine are thoroughly examined, as is the inevitability of any cure.

In addition to his work in hermeneutics, Gadamer is also well known for a long list of publications on Greek philosophy. Indeed, while "Truth and Method" became central to his later career, much of Gadamer's early life centered on studying Greek thinkers, Plato and Aristotle specifically. In the Italian introduction to "Truth and Method", Gadamer said that his work on Greek philosophy was "the best and most original part" of his career. His book "Plato's Dialectical Ethics" looks at the "Philebus" dialogue through the lens of phenomenology and the philosophy of Martin Heidegger.



Weinsheimer. New Haven: Yale University Press, 2004.





</doc>
<doc id="13991" url="https://en.wikipedia.org/wiki?curid=13991" title="Honeymoon">
Honeymoon

A honeymoon is a holiday taken by newlyweds immediately after their wedding, to celebrate their marriage. Today, honeymoons are often celebrated in destinations considered exotic or romantic.

In Western culture and some westernized countries’ cultures, the custom of a newlywed couple's going on a holiday together originated in early-19th-century Great Britain. Upper-class couples would take a "bridal tour", sometimes accompanied by friends or family, to visit relatives who had not been able to attend the wedding. The practice soon spread to the European continent and was known in France as a "voyage à la façon anglaise" (translation: English-style voyage), from the 1820s onwards.

Honeymoons in the modern sense—a pure holiday voyage undertaken by the couple—became widespread during the "Belle Époque", as one of the first instances of modern mass tourism. This came about despite initial disapproval by contemporary medical opinion (which worried about women's frail health) and by "savoir vivre" guidebooks (which referred to the public attention drawn to what was assumed to be the wife's sexual initiation). The most popular honeymoon destinations at the time were the French Riviera and Italy, particularly its seaside resorts and romantic cities such as Rome, Verona, and Venice. Typically honeymoons would start on the night of the marriage, with the couple leaving midway through the reception to catch a late train or ship. However, in the 21st century, many couples will not leave until 1–3 days after the ceremony and reception. In Jewish traditions, honeymoons are often put off seven days to allow for the seven nights of feasting if the visits to friends and family cannot be incorporated into the trip.

The honeymoon was originally the period following marriage, "characterized by love and happiness", as attested since 1546. The word may allude to "the idea that the first month of marriage is the sweetest".
According to a different version of the Oxford English Dictionary:
Today, "honeymoon" has a positive meaning, but originally it may have referred to the inevitable waning of love like a phase of the moon. In 1552, Richard Huloet wrote:
A fanciful 19th-century theory claimed that the word alludes to "the custom of the higher order of the Teutones... to drink Mead, or Metheglin, a beverage made with "honey", for thirty days after every wedding", but the theory is now rejected.

In many modern languages, the word for a honeymoon is a calque (e.g., ) or near-calque.

One possible source of the word is from Persian "mah-e-asal", which translates to "month of honey". The Persian word "mah" means both "moon" and "month", just as the English word "month" derives from "moon", and the kanji used in Japanese is the same for both "moon" and "month". This is likely a result of most ancient calendars being lunar calendars, where a month is defined as one lunar cycle. 

Another practical source for the term comes from the early days in the life of a honey bee queen. Immediately after her birth within a hive, a queen bee leaves the hive over the course of several days, to meet up with multiple drones in separate drone congregation areas. She is inseminated with a lifetime of sperm, and then returns to the hive to remain there the rest of her life, laying eggs. The queen essentially goes away for a "honey-moon" and returns, ready to live the rest of her life. The centuries-old practice of beekeeping may have led to other folklore related to this "going away" before starting a life "in the hive" (back at home). 

One 2015 scholarly study concluded that going on a honeymoon is associated with a somewhat lower risk of divorce, regardless of how much or little is spent on the honeymoon itself. However, high spending and incurring significant debt on other wedding-related expenses, such as engagement rings and wedding ceremonies, is associated with a high risk of divorce.

An emerging 21st-century travel trend is the "solomoon" or "unimoon", a separate, solo holiday the newlyweds take without their spouse. "The New Zealand Herald" cites a report by "The New York Times" that such alternatives to honeymoons are "particularly suited for couples who just cannot agree on where to go". (This trend contrasts with the use by a jilted bride or groom of the travel reservations intended for the honeymoon, as popularly depicted in such films as "" (2008), wherein Carrie Bradshaw turns her ruined Mexican honeymoon into a girls' trip, and "Like Father" (2018), wherein a bride left at the altar travels with her absentee father on the cruise meant for her honeymoon.)



</doc>
<doc id="13992" url="https://en.wikipedia.org/wiki?curid=13992" title="Harold Kushner">
Harold Kushner

Harold Samuel Kushner is a prominent American rabbi aligned with the progressive wing of Conservative Judaism, and a popular author.

Born in Brooklyn, Kushner graduated from Columbia University in 1955 and later obtained his rabbinical ordination from the Jewish Theological Seminary (JTS) in 1960. The same institution awarded him a doctoral degree in Bible in 1972. Kushner has also studied at the Hebrew University of Jerusalem, taught at Clark University and the Rabbinical School of the JTS, and received six honorary doctorates.

He served as the congregational rabbi of Temple Israel of Natick, in Natick, Massachusetts for 24 years and belongs to the Rabbinical Assembly.

He is the author of a best selling book on the problem of evil, "When Bad Things Happen to Good People." Written following the death of his son, Aaron, from the premature aging disease progeria, the book deals with questions about human suffering, God, omnipotence and theodicy. Aaron was born in 1963 and died in 1977; the book was published in 1981.

Kushner has written a number of other popular theological books, such as "How Good Do We Have to Be?" (Dedicated to his grandson, Carl), "To Life!" and many others. In collaboration with the late Chaim Potok, Kushner co-edited "Etz Hayim: A Torah Commentary", the new official Torah commentary of the Conservative movement, which was jointly published in 2001 by the Rabbinical Assembly and the Jewish Publication Society. His "Living a Life That Matters" became a best seller in the fall of 2001. Kushner's book, "The Lord Is My Shepherd", was a meditation on the Twenty-Third Psalm released in 2003. Kushner also wrote a response to Simon Wiesenthal's question of forgiveness in the book "."





</doc>
<doc id="13994" url="https://en.wikipedia.org/wiki?curid=13994" title="Hotspot">
Hotspot

Hotspot or Hot spot may refer to:










</doc>
<doc id="13995" url="https://en.wikipedia.org/wiki?curid=13995" title="Heapsort">
Heapsort

In computer science, heapsort is a comparison-based sorting algorithm. Heapsort can be thought of as an improved selection sort: like selection sort, heapsort divides its input into a sorted and an unsorted region, and it iteratively shrinks the unsorted region by extracting the largest element from it and inserting it into the sorted region. Unlike selection sort, heapsort does not waste time with a linear-time scan of the unsorted region; rather, heap sort maintains the unsorted region in a heap data structure to more quickly find the largest element in each step.

Although somewhat slower in practice on most machines than a well-implemented quicksort, it has the advantage of a more favorable worst-case runtime. Heapsort is an in-place algorithm, but it is not a stable sort.

Heapsort was invented by J. W. J. Williams in 1964. This was also the birth of the heap, presented already by Williams as a useful data structure in its own right. In the same year, R. W. Floyd published an improved version that could sort an array in-place, continuing his earlier research into the treesort algorithm.

The heapsort algorithm can be divided into two parts.

In the first step, a heap is built out of the data (see ). The heap is often placed in an array with the layout of a complete binary tree. The complete binary tree maps the binary tree structure into the array indices; each array index represents a node; the index of the node's parent, left child branch, or right child branch are simple expressions. For a zero-based array, the root node is stored at index 0; if codice_1 is the index of the current node, then
In the second step, a sorted array is created by repeatedly removing the largest element from the heap (the root of the heap), and inserting it into the array. The heap is updated after each removal to maintain the heap property. Once all objects have been removed from the heap, the result is a sorted array.

Heapsort can be performed in place. The array can be split into two parts, the sorted array and the heap. The storage of heaps as arrays is diagrammed here. The heap's invariant is preserved after each extraction, so the only cost is that of extraction.

The Heapsort algorithm involves preparing the list by first turning it into a max heap. The algorithm then repeatedly swaps the first value of the list with the last value, decreasing the range of values considered in the heap operation by one, and sifting the new first value into its position in the heap. This repeats until the range of considered values is one value in length.

The steps are:
The buildMaxHeap() operation is run once, and is in performance. The siftDown() function is , and is called times. Therefore, the performance of this algorithm is .

The following is a simple way to implement the algorithm in pseudocode. Arrays are zero-based and codice_2 is used to exchange two elements of the array. Movement 'down' means from the root towards the leaves, or from lower indices to higher. Note that during the sort, the largest element is at the root of the heap at codice_3, while at the end of the sort, the largest element is in codice_4.

The sorting routine uses two subroutines, codice_5 and codice_6. The former is the common in-place heap construction routine, while the latter is a common subroutine for implementing codice_5.

The codice_5 procedure can be thought of as building a heap from the bottom up by successively sifting downward to establish the heap property. An alternative version (shown below) that builds the heap top-down and sifts upward may be simpler to understand. This codice_9 version can be visualized as starting with an empty heap and successively inserting elements, whereas the codice_6 version given above treats the entire input array as a full but "broken" heap and "repairs" it starting from the last non-trivial sub-heap (that is, the last parent node).
Also, the codice_6 version of heapify has time complexity, while the codice_9 version given below has time complexity due to its equivalence with inserting each element, one at a time, into an empty heap.
This may seem counter-intuitive since, at a glance, it is apparent that the former only makes half as many calls to its logarithmic-time sifting function as the latter; i.e., they seem to differ only by a constant factor, which never affects asymptotic analysis.

To grasp the intuition behind this difference in complexity, note that the number of swaps that may occur during any one siftUp call "increases" with the depth of the node on which the call is made. The crux is that there are many (exponentially many) more "deep" nodes than there are "shallow" nodes in a heap, so that siftUp may have its full logarithmic running-time on the approximately linear number of calls made on the nodes at or near the "bottom" of the heap. On the other hand, the number of swaps that may occur during any one siftDown call "decreases" as the depth of the node on which the call is made increases. Thus, when the codice_6 codice_5 begins and is calling codice_6 on the bottom and most numerous node-layers, each sifting call will incur, at most, a number of swaps equal to the "height" (from the bottom of the heap) of the node on which the sifting call is made. In other words, about half the calls to siftDown will have at most only one swap, then about a quarter of the calls will have at most two swaps, etc.

The heapsort algorithm itself has time complexity using either version of heapify.

The most important variation to the basic algorithm, which is included in all practical implementations, is a heap-construction algorithm by Floyd which runs in time and uses siftdown rather than siftup, avoiding the need to implement siftup at all.

Rather than starting with a trivial heap and repeatedly adding leaves, Floyd's algorithm starts with the leaves, observing that they are trivial but valid heaps by themselves, and then adds parents. Starting with element and working backwards, each internal node is made the root of a valid heap by sifting down. The last step is sifting down the first element, after which the entire array obeys the heap property.

The worst-case number of comparisons during the Floyd's heap-construction phase of Heapsort is known to be equal to , where is the number of 1 bits in the binary representation of and is number of trailing 0 bits.

The standard implementation of Floyd's heap-construction algorithm causes a large number of cache misses once the size of the data exceeds that of the CPU cache. Much better performance on large data sets can be obtained by merging in depth-first order, combining subheaps as soon as possible, rather than combining all subheaps on one level before proceeding to the one above.

Bottom-up heapsort is a variant which reduces the number of comparisons required by a significant factor. While ordinary heapsort requires comparisons worst-case and on average, the bottom-up variant requires comparisons on average, and in the worst case.

If comparisons are cheap (e.g. integer keys) then the difference is unimportant, as top-down heapsort compares values that have already been loaded from memory. If, however, comparisons require a function call or other complex logic, then bottom-up heapsort is advantageous.

This is accomplished by improving the codice_6 procedure. The change improves the linear-time heap-building phase somewhat, but is more significant in the second phase. Like ordinary heapsort, each iteration of the second phase extracts the top of the heap, , and fills the gap it leaves with , then sifts this latter element down the heap. But this element comes from the lowest level of the heap, meaning it is one of the smallest elements in the heap, so the sift-down will likely take many steps to move it back down. In ordinary heapsort, each step of the sift-down requires two comparisons, to find the minimum of three elements: the new node and its two children.

Bottom-up heapsort instead finds the path of largest children to the leaf level of the tree (as if it were inserting −∞) using only one comparison per level. Put another way, it finds a leaf which has the property that it and all of its ancestors are greater than or equal to their siblings. (In the absence of equal keys, this leaf is unique.) Then, from this leaf, it searches "upward" (using one comparison per level) for the correct position in that path to insert . This is the same location as ordinary heapsort finds, and requires the same number of exchanges to perform the insert, but fewer comparisons are required to find that location.

Because it goes all the way to the bottom and then comes back up, it is called heapsort with bounce by some authors.

The return value of the codice_17 is used in the modified codice_6 routine:

Bottom-up heapsort was announced as beating quicksort (with median-of-three pivot selection) on arrays of size ≥16000.

A 2008 re-evaluation of this algorithm showed it to be no faster than ordinary heapsort for integer keys, presumably because modern branch prediction nullifies the cost of the predictable comparisons which bottom-up heapsort manages to avoid.

A further refinement does a binary search in the path to the selected leaf, and sorts in a worst case of comparisons, approaching the information-theoretic lower bound of comparisons.

A variant which uses two extra bits per internal node ("n"−1 bits total for an "n"-element heap) to cache information about which child is greater (two bits are required to store three cases: left, right, and unknown) uses less than compares.


Heapsort primarily competes with quicksort, another very efficient general purpose nearly-in-place comparison-based sort algorithm.

Quicksort is typically somewhat faster due to some factors, but the worst-case running time for quicksort is , which is unacceptable for large data sets and can be deliberately triggered given enough knowledge of the implementation, creating a security risk. See quicksort for a detailed discussion of this problem and possible solutions.

Thus, because of the upper bound on heapsort's running time and constant upper bound on its auxiliary storage, embedded systems with real-time constraints or systems concerned with security often use heapsort, such as the Linux kernel.

Heapsort also competes with merge sort, which has the same time bounds. Merge sort requires auxiliary space, but heapsort requires only a constant amount. Heapsort typically runs faster in practice on machines with small or slow data caches, and does not require as much external memory. On the other hand, merge sort has several advantages over heapsort:

Introsort is an alternative to heapsort that combines quicksort and heapsort to retain advantages of both: worst case speed of heapsort and average speed of quicksort.

Let { 6, 5, 3, 1, 8, 7, 2, 4 } be the list that we want to sort from the smallest to the largest. (NOTE, for 'Building the Heap' step: Larger nodes don't stay below smaller node parents. They are swapped with parents, and then recursively checked if another swap is needed, to keep larger numbers above smaller numbers on the heap binary tree.)




</doc>
<doc id="13996" url="https://en.wikipedia.org/wiki?curid=13996" title="Heap (data structure)">
Heap (data structure)

In computer science, a heap is a specialized tree-based data structure which is essentially an almost complete tree that satisfies the heap property: in a "max heap", for any given node C, if P is a parent node of C, then the "key" (the "value") of P is greater than or equal to the key of C. In a "min heap", the key of P is less than or equal to the key of C. The node at the "top" of the heap (with no parents) is called the "root" node.

The heap is one maximally efficient implementation of an abstract data type called a priority queue, and in fact, priority queues are often referred to as "heaps", regardless of how they may be implemented. In a heap, the highest (or lowest) priority element is always stored at the root. However, a heap is not a sorted structure; it can be regarded as being partially ordered. A heap is a useful data structure when it is necessary to repeatedly remove the object with the highest (or lowest) priority.

A common implementation of a heap is the binary heap, in which the tree is a binary tree (see figure). The heap data structure, specifically the binary heap, was introduced by J. W. J. Williams in 1964, as a data structure for the heapsort sorting algorithm. Heaps are also crucial in several efficient graph algorithms such as Dijkstra's algorithm. When a heap is a complete binary tree, it has a smallest possible height—a heap with "N" nodes and for each node "a" branches always has log "N" height.

Note that, as shown in the graphic, there is no implied ordering between siblings or cousins and no implied sequence for an in-order traversal (as there would be in, e.g., a binary search tree). The heap relation mentioned above applies only between nodes and their parents, grandparents, etc. The maximum number of children each node can have depends on the type of heap.

The common operations involving heaps are:




Heaps are usually implemented with an implicit heap data structure, which is an implicit data structure consisting of an array (fixed size or dynamic array) where each element represents a tree node whose parent/children relationship is defined implicitly by their index. After an element is inserted into or deleted from a heap, the heap property may be violated and the heap must be balanced by swapping elements within the array.
In an implicit heap data structure, the first (or last) element will contain the root. The next two elements of the array contain its children. The next four contain the four children of the two child nodes, etc. Thus the children of the node at position "n" would be at positions 2n and 2n + 1 in a one-based array, or 2n + 1 and 2n + 2 in a zero-based array. Computing the index of the parent node of n-th element is also straightforward. For one-based arrays the parent of element n is located at position n/2. Similarly, for zero-based arrays, is the parent is located at position (n-1)/2 (floored). This allows moving up or down the tree by doing simple index computations. Balancing a heap is done by sift-up or sift-down operations (swapping elements which are out of order). As we can build a heap from an array without requiring extra memory (for the nodes, for example), heapsort can be used to sort an array in-place.

Different types of heaps implement the operations in different ways, but notably, insertion is often done by adding the new element at the end of the heap in the first available free space. This will generally violate the heap property, and so the elements are then shifted up until the heap property has been reestablished. Similarly, deleting the root is done by removing the root and then putting the last element in the root and sifting down to rebalance. Thus replacing is done by deleting the root and putting the "new" element in the root and sifting down, avoiding a sifting up step compared to pop (sift down of last element) followed by push (sift up of new element).

Construction of a binary (or "d"-ary) heap out of a given array of elements may be performed in linear time using the classic Floyd algorithm, with the worst-case number of comparisons equal to 2"N" − 2"s"("N") − "e"("N") (for a binary heap), where "s"("N") is the sum of all digits of the binary representation of "N" and "e"("N") is the exponent of 2 in the prime factorization of "N". This is faster than a sequence of consecutive insertions into an originally empty heap, which is log-linear.

The heap data structure has many applications.






</doc>
<doc id="13998" url="https://en.wikipedia.org/wiki?curid=13998" title="Hierarchy">
Hierarchy

A hierarchy (from the Greek: , from "hierarkhes", 'president of sacred rites') is an arrangement of items (objects, names, values, categories, etc.) in which the items are represented as being "above", "below", or "at the same level as" one another. Hierarchy is an important concept in a wide variety of fields, such as philosophy, mathematics, computer science, organizational theory, systems theory, and the social sciences (especially political philosophy).

A hierarchy can link entities either directly or indirectly, and either vertically or diagonally. The only direct links in a hierarchy, insofar as they are hierarchical, are to one's immediate superior or to one of one's subordinates, although a system that is largely hierarchical can also incorporate alternative hierarchies. Hierarchical links can extend "vertically" upwards or downwards via multiple links in the same direction, following a path. All parts of the hierarchy that are not linked vertically to one another nevertheless can be "horizontally" linked through a path by traveling up the hierarchy to find a common direct or indirect superior, and then down again. This is akin to two co-workers or colleagues; each reports to a common superior, but they have the same relative amount of authority. Organizational forms exist that are both alternative and complementary to hierarchy. Heterarchy is one such form.

Hierarchies have their own special vocabulary. These terms are easiest to understand when a hierarchy is diagrammed (see below).

In an organizational context, the following terms are often used related to hierarchies:

In a mathematical context (in graph theory), the general terminology used is different.

Most hierarchies use a more specific vocabulary pertaining to their subject, but the idea behind them is the same. For example, with data structures, objects are known as nodes, superiors are called parents and subordinates are called children. In a business setting, a superior is a supervisor/boss and a peer is a colleague.

Degree of branching refers to the number of direct subordinates or children an object has (in graph theory, equivalent to the number of other vertices connected to via outgoing arcs, in a directed graph) a node has. Hierarchies can be categorized based on the "maximum degree", the highest degree present in the system as a whole. Categorization in this way yields two broad classes: "linear" and "branching".

In a linear hierarchy, the maximum degree is 1. In other words, all of the objects can be visualized in a line-up, and each object (excluding the top and bottom ones) has exactly one direct subordinate and one direct superior. Note that this is referring to the "objects" and not the "levels"; every hierarchy has this property with respect to levels, but normally each level can have an infinite number of objects. An example of a linear hierarchy is the hierarchy of life.

In a branching hierarchy, one or more objects has a degree of 2 or more (and therefore the minimum degree is 2 or higher). For many people, the word "hierarchy" automatically evokes an image of a branching hierarchy. Branching hierarchies are present within numerous systems, including organizations and classification schemes. The broad category of branching hierarchies can be further subdivided based on the degree.

A flat hierarchy is a branching hierarchy in which the maximum degree approaches infinity, i.e., that has a wide span. Most often, systems intuitively regarded as hierarchical have at most a moderate span. Therefore, a flat hierarchy is often not viewed as a hierarchy at all. For example, diamonds and graphite are flat hierarchies of numerous carbon atoms that can be further decomposed into subatomic particles.

An overlapping hierarchy is a branching hierarchy in which at least one object has two parent objects. For example, a graduate student can have two co-supervisors to whom the student reports directly and equally, and who have the same level of authority within the university hierarchy (i.e., they have the same position or tenure status).

Possibly the first use of the English word "hierarchy" cited by the "Oxford English Dictionary" was in 1881, when it was used in reference to the three orders of three angels as depicted by Pseudo-Dionysius the Areopagite (5th–6th centuries). Pseudo-Dionysius used the related Greek word (ἱεραρχία, "hierarchia") both in reference to the celestial hierarchy and the ecclesiastical hierarchy. The Greek term "hierarchia" means 'rule of a high priest', from "hierarches" (ἱεράρχης, 'president of sacred rites, high-priest') and that from "hiereus" (ἱερεύς, 'priest') and "arche" (ἀρχή, 'first place or power, rule'). Dionysius is credited with first use of it as an abstract noun.

Since hierarchical churches, such as the Roman Catholic (see Catholic Church hierarchy) and Eastern Orthodox churches, had tables of organization that were "hierarchical" in the modern sense of the word (traditionally with God as the pinnacle or head of the hierarchy), the term came to refer to similar organizational methods in secular settings.

A hierarchy is typically depicted as a pyramid, where the height of a level represents that level's status and width of a level represents the quantity of items at that level relative to the whole. For example, the few Directors of a company could be at the apex, and the base could be thousands of people who have no subordinates.

These pyramids are typically diagrammed with a tree or triangle diagram (but note that not all triangle/pyramid diagrams are hierarchical; for example, the 1992 USDA food guide pyramid), both of which serve to emphasize the size differences between the levels. An example of a triangle diagram appears to the right. An organizational chart is the diagram of a hierarchy within an organization, and is depicted in tree form in , below.

More recently, as computers have allowed the storage and navigation of ever larger data sets, various methods have been developed to represent hierarchies in a manner that makes more efficient use of the available space on a computer's screen. Examples include fractal maps, TreeMaps and Radial Trees.

In the design field, mainly graphic design, successful layouts and formatting of the content on documents are heavily dependent on the rules of visual hierarchy. Visual hierarchy is also important for proper organization of files on computers.

An example of visually representing hierarchy is through the Nested clusters. The Nested clusters represents hierarchical relationships by using layers of information. The child element is within the parent element, such as in a Venn diagram. This structure of representing hierarchy is most effective in representing simple relationships. For example, when directing someone to open a file on a computer desktop, one may first direct them towards the main folder, then the subfolders within the main folder. They will keep opening files within the folders until the designated file is located.

For more complicated hierarchies, the stair structure represents hierarchical relationships through the use of visual stacking. Visually imagine the top of a downward staircase beginning at the left and descending on the right. The child elements are towards the bottom of the stairs and the parent elements are at the top. This structure is effective when representing more complicated hierarchies where steps are not placed in obvious sequences. Further steps are concealed unless all of the steps are revealed in sequence. In the computer desktop example, a file that is being sought after can only be found once another file is opened. The link for the desired file is within another document. All the steps must be completed until the final destination is reached.

In plain English, a hierarchy can be thought of as a set in which:
The first requirement is also interpreted to mean that a hierarchy can have no circular relationships; the association between two objects is always transitive.
The second requirement asserts that a hierarchy must have a leader or root that is common to all of the objects.

Mathematically, in its most general form, a hierarchy is a partially ordered set or "poset". The system in this case is the entire poset, which is constituted of elements. Within this system, each element shares a particular unambiguous property. Objects with the same property value are grouped together, and each of those resulting levels is referred to as a class.

"Hierarchy" is particularly used to refer to a poset in which the classes are organized in terms of increasing complexity. 
Operations such as addition, subtraction, multiplication and division are often performed in a certain sequence or order. Usually, addition and subtraction are performed after multiplication and division has already been applied to a problem. The use of parentheses is also a representation of hierarchy, for they show which operation is to be done prior to the following ones. For example:
(2 + 5) × (7 - 4).
In this problem, typically one would multiply 5 by 7 first, based on the rules of mathematical hierarchy. But when the parentheses are placed, one will know to do the operations within the parentheses first before continuing on with the problem. These rules are largely dominant in algebraic problems, ones that include several steps to solve. The use of hierarchy in mathematics is beneficial to quickly and efficiently solve a problem without having to go through the process of slowly dissecting the problem. Most of these rules are now known as the proper way into solving certain equations.

A nested hierarchy or "inclusion hierarchy" is a hierarchical ordering of nested sets. The concept of nesting is exemplified in Russian matryoshka dolls. Each doll is encompassed by another doll, all the way to the outer doll. The outer doll holds all of the inner dolls, the next outer doll holds all the remaining inner dolls, and so on. Matryoshkas represent a nested hierarchy where each level contains only one object, i.e., there is only one of each size of doll; a generalized nested hierarchy allows for multiple objects within levels but with each object having only one parent at each level. The general concept is both demonstrated and mathematically formulated in the following example:

A square can always also be referred to as a quadrilateral, polygon or shape. In this way, it is a hierarchy. However, consider the set of polygons using this classification. A square can "only" be a quadrilateral; it can never be a triangle, hexagon, etc.

Nested hierarchies are the organizational schemes behind taxonomies and systematic classifications. For example, using the original Linnaean taxonomy (the version he laid out in the 10th edition of "Systema Naturae"), a human can be formulated as:

Taxonomies may change frequently (as seen in biological taxonomy), but the underlying concept of nested hierarchies is always the same.

In many programming taxonomies and syntax models (as well as fractals in mathematics), nested hierarchies, including Russian dolls, are also used to illustrate the properties of self-similarity and recursion. Recursion itself is included as a subset of hierarchical programming, and recursive thinking can be synonymous with a form of hierarchical thinking and logic.

A containment hierarchy is a direct extrapolation of the nested hierarchy concept. All of the ordered sets are still nested, but every set must be "strict"—no two sets can be identical. The shapes example above can be modified to demonstrate this:

The notation formula_4 means "x" is a subset of "y" but is not equal to "y".

A general example of a containment hierarchy is demonstrated in class inheritance in object-oriented programming.

Two types of containment hierarchies are the "subsumptive" containment hierarchy and the "compositional" containment hierarchy. A subsumptive hierarchy "subsumes" its children, and a compositional hierarchy is "composed" of its children. A hierarchy can also be both subsumptive "and" compositional.

A "subsumptive" containment hierarchy is a classification of object classes from the general to the specific. Other names for this type of hierarchy are "taxonomic hierarchy" and "IS-A hierarchy". The last term describes the relationship between each level—a lower-level object "is a" member of the higher class. The taxonomical structure outlined above is a subsumptive containment hierarchy. Using again the example of Linnaean taxonomy, it can be seen that an object that is part of the level "Mammalia" "is a" member of the level "Animalia"; more specifically, a human "is a" primate, a primate "is a" mammal, and so on. A subsumptive hierarchy can also be defined abstractly as a hierarchy of "concepts". For example, with the Linnaean hierarchy outlined above, an entity name like "Animalia" is a way to group all the species that fit the conceptualization of an animal.

A "compositional" containment hierarchy is an ordering of the parts that make up a system—the system is "composed" of these parts. Most engineered structures, whether natural or artificial, can be broken down in this manner.

The compositional hierarchy that every person encounters at every moment is the hierarchy of life. Every person can be reduced to organ systems, which are composed of organs, which are composed of tissues, which are composed of cells, which are composed of molecules, which are composed of atoms. In fact, the last two levels apply to all matter, at least at the macroscopic scale. Moreover, each of these levels inherit all the properties of their children.

In this particular example, there are also "emergent properties"—functions that are not seen at the lower level (e.g., cognition is not a property of neurons but is of the brain)—and a scalar quality (molecules are bigger than atoms, cells are bigger than molecules, etc.). Both of these concepts commonly exist in compositional hierarchies, but they are not a required general property. These "level hierarchies" are characterized by bi-directional causation. "Upward causation" involves lower-level entities causing some property of a higher level entity; children entities may interact to yield parent entities, and parents are composed at least partly by their children. "Downward causation" refers to the effect that the incorporation of entity "x" into a higher-level entity can have on "x"'s properties and interactions. Furthermore, the entities found at each level are "autonomous".

According to Kulish (2002), almost every system of organization applied to the world is arranged hierarchically. By their common definitions, every nation has a government and every government is hierarchical. Socioeconomic systems are stratified into a social hierarchy (the social stratification of societies), and all systematic classification schemes (taxonomies) are hierarchical. Most organized religions, regardless of their internal governance structures, operate as a hierarchy under God. Many Christian denominations have an autocephalous ecclesiastical hierarchy of leadership. Families are viewed as a hierarchical structure in terms of cousinship (e.g., first cousin once removed, second cousin, etc.), ancestry (as depicted in a family tree) and inheritance (succession and heirship). All the requisites of a well-rounded life and lifestyle can be organized using Maslow's hierarchy of human needs. Learning must often follow a hierarchical scheme—to learn differential equations one must first learn calculus; to learn calculus one must first learn elementary algebra; and so on. Even nature itself has its own hierarchies, as numerous schemes such as Linnaean taxonomy, the organization of life, and biomass pyramids attempt to document. Hierarchies are so infused into daily life that they are viewed as trivial.

While the above examples are often clearly depicted in a hierarchical form and are classic examples, hierarchies exist in numerous systems where this branching structure is not immediately apparent. For example, most postal code systems are hierarchical. Using the Canadian postal code system as an example, the top level's binding concept is the "postal district", and consists of 18 objects (letters). The next level down is the "zone", where the objects are the digits 0–9. This is an example of an overlapping hierarchy, because each of these 10 objects has 18 parents. The hierarchy continues downward to generate, in theory, 7,200,000 unique codes of the format "A0A 0A0" (the second and third letter position allow 20 objects each). Most library classification systems are also hierarchical. The Dewey Decimal System is regarded as infinitely hierarchical because there is no finite bound on the number of digits can be used after the decimal point.

Organizations can be structured as a dominance hierarchy. In an organizational hierarchy, there is a single person or group with the most power and authority, and each subsequent level represents a lesser authority. Most organizations are structured in this manner, including governments, companies, militia and organized religions. The units or persons within an organization are depicted hierarchically in an organizational chart.

In a reverse hierarchy, the conceptual pyramid of authority is turned upside-down, so that the apex is at the bottom and the base is at the top. This mode represents the idea that members of the higher rankings are responsible for the members of the lower rankings.

Empirically, we observe in nature a large proportion of the (complex) biological systems, they exhibit hierarchic structure. On theoretical grounds we could expect complex systems to be hierarchies in a world in which complexity had to evolve from simplicity. System hierarchies analysis performed in the 1950s, laid the empirical foundations for a field that would be, from the 1980s, hierarchical ecology.

The theoretical foundations are summarized by Thermodynamics.
When biological systems are modeled as physical systems, in its most general abstraction, they are thermodynamic open systems that exhibit self-organised behavior, and the set/subset relations between dissipative structures can be characterized in a hierarchy.

CGI and computer animation programs mostly use hierarchies for models. On a 3D model of a human for example, the chest is a parent of the upper left arm, which is a parent of the lower left arm, which is a parent of the hand. This is used in modeling and animation for almost everything built as a 3D digital model.

Many grammatical theories, such as phrase-structure grammar, involve hierarchy.

Direct–inverse languages such as Cree and Mapudungun distinguish subject and object on verbs not by different subject and object markers, but via a hierarchy of persons.

In this system, the three (or four with Algonquian languages) persons are placed in a hierarchy of salience. To distinguish which is subject and which object, "inverse markers" are used if the object outranks the subject.

On the other hand, languages include a variety of phenomena that are not hierarchical. For example, the relationship between a pronoun and a prior noun phrase to which it refers, commonly crosses grammatical boundaries in non-hierarchical ways.

The structure of a musical composition is often understood hierarchically (for example by Heinrich Schenker (1768–1835, see Schenkerian analysis), and in the (1985) Generative Theory of Tonal Music, by composer Fred Lerdahl and linguist Ray Jackendoff). The sum of all notes in a piece is understood to be an all-inclusive surface, which can be reduced to successively more sparse and more fundamental types of motion. The levels of structure that operate in Schenker's theory are the foreground, which is seen in all the details of the musical score; the middle ground, which is roughly a summary of an essential contrapuntal progression and voice-leading; and the background or Ursatz, which is one of only a few basic "long-range counterpoint" structures that are shared in the gamut of tonal music literature.

The pitches and form of tonal music are organized hierarchically, all pitches deriving their importance from their relationship to a tonic key, and secondary themes in other keys are brought back to the tonic in a recapitulation of the primary theme. Susan McClary connects this specifically in the sonata-allegro form to the feminist hierarchy of gender (see above) in her book "Feminine Endings", even pointing out that primary themes were often previously called "masculine" and secondary themes "feminine."









In the work of diverse theorists such as William James (1842–1910), Michel Foucault (1926–1984) and Hayden White, important critiques of hierarchical epistemology are advanced. James famously asserts in his work "Radical Empiricism" that clear distinctions of type and category are a constant but unwritten goal of scientific reasoning, so that when they are discovered, success is declared. But if aspects of the world are organized differently, involving inherent and intractable ambiguities, then scientific questions are often considered unresolved.

Hierarchy in ethics emerged in Western Europe, West Asia and North Africa around the 1600s. In this aspect, the term hierarchy refers to how distinguishable they are from real to unreal. Feminists, Marxists, anarchists, communists, critical theorists and others, all of whom have multiple interpretations, criticize the hierarchies commonly found within human society, especially in social relationships. Hierarchies are present in all parts of society: in businesses, schools, families, etc. These relationships are often viewed as necessary. Entities that stand in hierarchical arrangements are animals, humans, plants, etc.

In ethics, various virtues are enumerated and sometimes organized hierarchically according to certain brands of virtue theory.

In some of these random examples, there is an asymmetry of 'compositional' significance between levels of structure, so that small parts of the whole hierarchical array depend, for their meaning, on their membership in larger parts. There is a hierarchy of activities in human life: productive activity serves or is guided by the moral life; the moral life is guided by practical reason; practical reason (used in moral and political life) serves contemplative reason (whereby we contemplate God). Practical reason sets aside time and resources for contemplative reason.

"(For example, in )"




</doc>
<doc id="14002" url="https://en.wikipedia.org/wiki?curid=14002" title="Outline of health sciences">
Outline of health sciences

The following outline is provided as an overview of and topical guide to health sciences:

Health sciences – are those sciences which focus on health, or health care, as core parts of their subject matter. Because these two subject matter relates to multiple academic disciplines, both STEM disciplines as well as emerging patient safety disciplines (such as social care research) are relevant to current health science knowledge.

Health sciences knowledge bases are currently diverse, with intellectual foundations that are sometimes mutually-inconsistent. There is currently an existing bias in the field, towards high valuation of knowledge deriving from controlling views on the human agency (as epitomized by the epistemological basis of Randomized Control Trial designs); compare this against the more naturalistic views on human agency taken by research based on Ethnography for example).

Mental health

Social health

Physical health

Medicine – applied science or practice of the diagnosis, treatment, and prevention of disease. It encompasses a variety of health care practices evolved to maintain and restore health by the prevention and treatment of illness. Some of its branches are:







</doc>
<doc id="14004" url="https://en.wikipedia.org/wiki?curid=14004" title="Hour">
Hour

An hour (symbol: h; also abbreviated hr) is a unit of time conventionally reckoned as of a day and scientifically reckoned as 3,599–3,601 seconds, depending on conditions. There are 60 minutes in an hour, and 24 hours in a day.

The hour was initially established in the ancient Near East as a variable measure of of the night or daytime. Such seasonal, temporal, or unequal hours varied by season and latitude. 

Equal or equinoctial hours were taken as of the day as measured from noon to noon; the minor seasonal variations of this unit were eventually smoothed by making it of the mean solar day. Since this unit was not constant due to long term variations in the Earth's rotation, the hour was finally separated from the Earth's rotation and defined in terms of the atomic or physical second.

In the modern metric system, hours are an accepted unit of time defined as 3,600 atomic seconds. However, on rare occasions an hour may incorporate a positive or negative leap second, making it last 3,599 or 3,601 seconds, in order to keep it within 0.9 seconds of UT1, which is based on measurements of the mean solar day.

"Hour" is a development of the Anglo-Norman ' and Middle English ', first attested in the 13th century. 

It displaced tide tīd, "time" and stound stund, "span of time". The Anglo-Norman term was a borrowing of Old French ', a variant of ', which derived from Latin "" and Greek "hṓrā" ().

Like Old English ' and ', "hṓrā" was originally a vaguer word for any span of time, including seasons and years. Its Proto-Indo-European root has been reconstructed as "" ("year, summer"), making "hour" distantly cognate with "year".

The time of day is typically expressed in English in terms of hours. Whole hours on a 12-hour clock are expressed using the contracted phrase "o'clock", from the older "of clock". (10 am and 10 pm are both read as "ten o'clock".) 

Hours on a 24-hour clock ("military time") are expressed as "hundred" or "hundred hours". (1000 is read "ten hundred" or "ten hundred hours"; 10 pm would be "twenty-two hundred".) 

Fifteen and thirty minutes past the hour is expressed as "a quarter past" or "after" and "half past", respectively, from their fraction of the hour. Fifteen minutes before the hour may be expressed as "a quarter to", "of", "till", or "before" the hour. (9:45 may be read "nine forty-five" or "a quarter till ten".)

The ancient Greeks and Romans originally divided the day into 12 hours and the night into 3 or 4 night watches.
The Greek astronomer Andronicus of Cyrrhus oversaw the construction of a horologion called the Tower of the Winds in Athens during the first century. This structure tracked a 24-hour day using both sundials and mechanical hour indicators. The night was eventually also divided into 12 hours.

The canonical hours were introduced to early Christianity from Second Temple Judaism.
By AD 60, the Didache, recommends disciples to pray the Lord's Prayer three times a day; this practice found its way into the canonical hours as well. By the second and third centuries, such Church Fathers as Clement of Alexandria, Origen, and Tertullian wrote of the practice of Morning and Evening Prayer, and of the prayers at the third, sixth and ninth hours.
In the early church, during the night before every feast, a vigil was kept. The word "Vigils", at first applied to the Night Office, comes from a Latin source, namely the "Vigiliae" or nocturnal watches or guards of the soldiers. The night from six o'clock in the evening to six o'clock in the morning was divided into four watches or vigils of three hours each, the first, the second, the third, and the fourth vigil. 

The "Horae" were originally personifications of seasonal aspects of nature, not of the time of day.
The list of twelve "Horae" representing the twelve hours of the day is recorded only in Late Antiquity, by Nonnus. The first and twelfth of the "Horae" were added to the original set of ten:

Medieval astronomers such as al-Biruni and Sacrobosco, divided the hour into 60 minutes, each of 60 seconds; this derives from Babylonian astronomy, where the corresponding terms denoted the time required for the Sun's apparent motion through the ecliptic to describe one minute or second of arc, respectively. 
In present terms, the Babylonian degree of time was thus four minutes long, the "minute" of time was thus four seconds long and the "second" 1/15 of a second.) 

In medieval Europe, the Roman hours continued to be marked on sundials but the more important units of time were the canonical hours of the Orthodox and Catholic Church. During daylight, these followed the pattern set by the three-hour bells of the Roman markets, which were succeeded by the bells of local churches. They rang prime at about 6am, terce at about 9am, sext at noon, nones at about 3pm, and vespers at either 6pm or sunset. Matins and lauds precede these irregularly in the morning hours; compline follows them irregularly before sleep; and the midnight office follows that. Vatican II ordered their reformation for the Catholic Church in 1963, though they continue to be observed in the Orthodox churches.

When mechanical clocks began to be used to show hours of daylight or nighttime, their period needed to be changed every morning and evening (for example, by changing the length of their pendula). The use of 24 hours for the entire day meant hours varied much less and the clocks needed to be adjusted only a few times a month.

The minor irregularities of the apparent solar day were smoothed by measuring time using the mean solar day, using the Sun's movement along the celestial equator rather than along the ecliptic. The irregularities of this time system were so minor that most clocks reckoning such hours did not need adjustment. However, scientific measurements eventually became precise enough to note the effect of tidal deceleration of the Earth by the Moon, which gradually lengthens the Earth's days. 

During the French Revolution, a general decimalization of measures was enacted, including decimal time between 1793 and 1795. Under its provisions, the French hour () was of the day and divided formally into 100 decimal minutes (') and informally into 10 tenths ('). This hour was only briefly in official use, being repealed by the same 1795 legislation that first established the metric system.

The metric system bases its measurements of time upon the second, defined since 1952 in terms of the Earth's rotation in 1900. Its hours are a secondary unit computed as precisely 3,600 seconds. However, an hour of Coordinated Universal Time (UTC), used as the basis of most civil time, has lasted 3,601 seconds 27 times since 1972 in order to keep it within 0.9 seconds of universal time, which is based on measurements of the mean solar day at 0° longitude. The addition of these seconds accommodates the very gradual slowing of the rotation of the Earth.

In modern life, the ubiquity of clocks and other timekeeping devices means that segmentation of days according to their hours is commonplace. Most forms of employment, whether wage or salaried labour, involve compensation based upon measured or expected hours worked. The fight for an eight-hour day was a part of labour movements around the world. Informal rush hours and happy hours cover the times of day when commuting slows down due to congestion or alcoholic drinks being available at discounted prices. The hour record for the greatest distance travelled by a cyclist within the span of an hour is one of cycling's greatest honours.

Many different ways of counting the hours have been used. Because sunrise, sunset, and, to a lesser extent, noon, are the conspicuous points in the day, starting to count at these times was, for most people in most early societies, much easier than starting at midnight. However, with accurate clocks and modern astronomical equipment (and the telegraph or similar means to transfer a time signal in a split-second), this issue is much less relevant.

Astrolabes, sundials, and astronomical clocks sometimes show the hour length and count using some of these older definitions and counting methods.

In ancient and medieval cultures, the counting of hours generally started with sunrise. Before the widespread use of artificial light, societies were more concerned with the division between night and day, and daily routines often began when light was sufficient.

"Babylonian hours" divide the day and night into 24 equal hours, reckoned from the time of sunrise. They are so named from the false belief of ancient authors that the Babylonians divided the day into 24 parts, beginning at sunrise. In fact, they divided the day into 12 parts (called "kaspu" or "double hours") or into 60 equal parts.

Sunrise marked the beginning of the first hour, the middle of the day was at the end of the sixth hour and sunset at the end of the twelfth hour. This meant that the duration of hours varied with the season. In the Northern hemisphere, particularly in the more northerly latitudes, summer daytime hours were longer than winter daytime hours, each being one twelfth of the time between sunrise and sunset. These variable-length hours were variously known as temporal, unequal, or seasonal hours and were in use until the appearance of the mechanical clock, which furthered the adoption of equal length hours.

This is also the system used in Jewish law and frequently called "Talmudic hour" ("Sha'a Zemanit") in a variety of texts. The Talmudic hour is one twelfth of time elapsed from sunrise to sunset, day hours therefore being longer than night hours in the summer; in winter they reverse.

The Indic day began at sunrise. The term "hora" was used to indicate an hour. The time was measured based on the length of the shadow at day time. A "hora" translated to 2.5 "pe". There are 60 "pe" per day, 60 minutes per "pe" and 60 "kshana" (snap of a finger or instant) per minute. "Pe" was measured with a bowl with a hole placed in still water. Time taken for this graduated bowl was one "pe". Kings usually had an officer in charge of this clock.

In so-called "Italian time", "Italian hours", or "old Czech time", the first hour started with the sunset Angelus bell (or at the end of dusk, i.e., half an hour after sunset, depending on local custom and geographical latitude). The hours were numbered from 1 to 24. For example, in Lugano, the sun rose in December during the 14th hour and noon was during the 19th hour; in June the sun rose during the 7th hour and noon was in the 15th hour. Sunset was always at the end of the 24th hour. The clocks in church towers struck only from 1 to 12, thus only during night or early morning hours.

This manner of counting hours had the advantage that everyone could easily know how much time they had to finish their day's work without artificial light. It was already widely used in Italy by the 14th century and lasted until the mid-18th century; it was officially abolished in 1755, or in some regions customary until the mid-19th century.

The system of Italian hours can be seen on a number of clocks in Europe, where the dial is numbered from 1 to 24 in either Roman or Arabic numerals. The St Mark's Clock in Venice, and the Orloj in Prague are famous examples. It was also used in Poland and Bohemia until the 17th century.

The Islamic day begins at sunset. The first prayer of the day (maghrib) is to be performed between just after sunset and the end of twilight. Until 1968 Saudi Arabia used the system of counting 24 equal hours with the first hour starting at sunset.

For many centuries, up to 1925, astronomers counted the hours and days from noon, because it was the easiest solar event to measure accurately. An advantage of this method (used in the Julian Date system, in which a new Julian Day begins at noon) is that the date doesn't change during a single night's observing.

In the modern 12-hour clock, counting the hours starts at midnight and restarts at noon. Hours are numbered 12, 1, 2, ..., 11. Solar noon is always close to 12 noon (ignoring artificial adjustments due to time zones and daylight saving time), differing according to the equation of time by as much as fifteen minutes either way. At the equinoxes sunrise is around 6 a.m. (, before noon), and sunset around 6 p.m. (, after noon).

In the modern 24-hour clock, counting the hours starts at midnight, and hours are numbered from 0 to 23. Solar noon is always close to 12:00, again differing according to the equation of time. At the equinoxes sunrise is around 06:00, and sunset around 18:00.

The ancient Egyptians began dividing the night into "" at some time before the compilation of the Dynasty V Pyramid Texts in the 24thcentury. By 2150 (Dynasty IX), diagrams of stars inside Egyptian coffin lids—variously known as "diagonal calendars" or "star clocks"—attest that there were exactly 12 of these. Clagett writes that it is "certain" this duodecimal division of the night followed the adoption of the Egyptian civil calendar, usually placed on the basis of analyses of the Sothic cycle, but a lunar calendar presumably long predated this and also would have had twelve months in each of its years. The coffin diagrams show that the Egyptians took note of the heliacal risings of 36 stars or constellations (now known as "decans"), one for each of the ten-day "weeks" of their civil calendar. (12 sets of alternate "triangle decans" were used for the 5 epagomenal days between years.) Each night, the rising of eleven of these decans were noted, separating the night into twelve divisions whose middle terms would have lasted about 40minutes each. (Another seven stars were noted by the Egyptians during the twilight and predawn periods, although they were not important for the hour divisions.) The original decans used by the Egyptians would have fallen noticeably out of their proper places over a span of several centuries. By the time of (), the priests at Karnak were using water clocks to determine the hours. These were filled to the brim at sunset and the hour determined by comparing the water level against one of its twelve gauges, one for each month of the year. During the New Kingdom, another system of decans was used, made up of 24 stars over the course of the year and 12 within any one night.

The later division of the day into 12 hours was accomplished by sundials marked with ten equal divisions. The morning and evening periods when the sundials failed to note time were observed as the first and last hours.

The Egyptian hours were closely connected both with the priesthood of the gods and with their divine services. By the New Kingdom, each hour was conceived as a specific region of the sky or underworld through which Ra's solar barge travelled. Protective deities were assigned to each and were used as the names of the hours. As the protectors and resurrectors of the sun, the goddesses of the night hours were considered to hold power over all lifespans and thus became part of Egyptian funerary rituals. Two fire-spitting cobras were said to guard the gates of each hour of the underworld, and Wadjet and the rearing cobra (uraeus) were also sometimes referenced as ' from their role protecting the dead through these gates. The Egyptian word for astronomer, used as a synonym for priest, was ', "one of the "wnwt"", as it were "one of the hours". The earliest forms of "" include one or three stars, with the later solar hours including the determinative hieroglyph for "sun".

Ancient China divided its day into 100 "marks" running from midnight to midnight. The system is said to have been used since remote antiquity, credited to the legendary Yellow Emperor, but is first attested in Han-era water clocks and in the 2nd-century history of that dynasty. It was measured with sundials and water clocks. Into the Eastern Han, the Chinese measured their day schematically, adding the 20-"ke" difference between the solstices evenly throughout the year, one every nine days. During the night, time was more commonly reckoned during the night by the "watches" of the guard, which were reckoned as a fifth of the time from sunset to sunrise.

Imperial China continued to use "ke" and "geng" but also began to divide the day into 12 "double hours" named after the earthly branches and sometimes also known by the name of the corresponding animal of the Chinese zodiac. The first "shi" originally ran from 11pm to 1am but was reckoned as starting at midnight by the time of the History of Song, compiled during the early Yuan. These apparently began to be used during the Eastern Han that preceded the Three Kingdoms era, but the sections that would have covered them are missing from their official histories; they first appear in official use in the Tang-era Book of Sui. Variations of all these units were subsequently adopted by Japan and the other countries of the Sinosphere.

The 12 "shi" supposedly began to be divided into 24 hours under the Tang, although they are first attested in the Ming-era Book of Yuan. In that work, the hours were known by the same earthly branches as the "shi", with the first half noted as its "starting" and the second as "completed" or "proper" "shi". In modern China, these are instead simply numbered and described as "little "shi"". The modern "ke" is now used to count quarter-hours, rather than a separate unit.

As with the Egyptian night and daytime hours, the division of the day into twelve "shi" has been credited to the example set by the rough number of lunar cycles in a solar year, although the 12-year Jovian orbital cycle was more important to traditional Chinese and Babylonian reckoning of the zodiac.

In Thailand, Laos, and Cambodia, the traditional system of noting hours is the six-hour clock. This reckons each of a day's 24 hours apart from noon as part of a fourth of the day. 7 am was the first hour of the first half of daytime; 1 pm the first hour of the latter half of daytime; 7 pm the first hour of the first half of nighttime; and 1 am the first hour of the latter half of nighttime. This system existed in the Ayutthaya Kingdom, deriving its current phrasing from the practice of publicly announcing the daytime hours with a gong and the nighttime hours with a drum. It was abolished in Laos and Cambodia during their French occupation and is uncommon there now. The Thai system remains in informal use in the form codified in 1901 by King Chulalongkorn.

The Vedas and Puranas employed units of time based on the sidereal day ("nakṣatra ahorātram"). This was variously divided into 30 "muhūtras" of 48 minutes each or 60 "dandas" or "nadís" of 24 minutes each. The solar day was later similarly divided into 60 "ghaṭikás" of about the same duration, each divided in turn into 60 "vinadis". The Sinhalese followed a similar system but called their sixtieth of a day a "peya".







</doc>
<doc id="14005" url="https://en.wikipedia.org/wiki?curid=14005" title="Hezekiah">
Hezekiah

Hezekiah (; ), or Ezekias, was, according to the Hebrew Bible, the son of Ahaz and the 13th king of Judah. He is considered a very righteous king in both the Second Book of Kings and the Second Book of Chronicles. He is also one of the more prominent kings of Judah mentioned in the Bible and is one of the kings mentioned in the genealogy of Jesus in the Gospel of Matthew. "No king of Judah, among either his predecessors or his successors, could ... be compared to him", according to 2 Kings 18:5.

Edwin Thiele concluded that his reign was between c. 715 and 686 BC.

According to the biblical narrative, Hezekiah witnessed the destruction of the northern Kingdom of Israel by Sargon's Assyrians in c. 722 BC and was king of Judah during the siege of Jerusalem by Sennacherib in 701 BC. Hezekiah enacted sweeping religious reforms, including a strict mandate for the sole worship of Yahweh and a prohibition on venerating other deities within the Temple of Jerusalem. Isaiah and Micah prophesied during his reign.

The name Hezekiah means "Yahweh strengthens" in Hebrew. Alternately it may be translated as "Yahweh is my strength".

The main accounts of Hezekiah's reign are found in , , and of the Hebrew Bible. mentions that it is a collection of King Solomon's proverbs that were "copied by the officials of King Hezekiah of Judah". His reign is also referred to in the books of the prophets Isaiah, Jeremiah, Hosea, and Micah. The books of Hosea and Micah record that their prophecies were made during Hezekiah’s reign.

Hezekiah was the son of King Ahaz and Abijah. His mother, Abijah (also called Abi), was a daughter of the high priest Zechariah. Based on Thiele's dating, Hezekiah was born in c. 741 BCE. He was married to Hephzi-bah. () He died from natural causes at the age of 54 in c. 687 BCE, and was succeeded by his son Manasseh ().

According to the biblical narrative, Hezekiah assumed the throne of Judah at the age of 25 and reigned for 29 years (, ). Some writers have proposed that Hezekiah served as coregent with his father Ahaz for about 14 years. His sole reign is dated by William F. Albright as 715–687 BCE, and by Edwin R. Thiele as 716–687 BCE (the last ten years being a co-regency with his son Manasseh).

Hezekiah purified and repaired the Temple, purged its idols, and reformed the priesthood. In an effort to abolish idolatry from his kingdom, he destroyed the high places (or "bamot") and the "bronze serpent" (or "Nehushtan"), recorded as being made by Moses, which had become objects of idolatrous worship. In place of this, he centralized the worship of God at the Temple in Jerusalem. Hezekiah also defeated the Philistines, "as far as Gaza and its territory", () and resumed the Passover pilgrimage and the tradition of inviting the scattered tribes of Israel to take part in a Passover festival. 
2 Chronicles 30 (but not the parallel account in 2 Kings) records that Hezekiah sent messengers to Ephraim and Manasseh inviting them to Jerusalem for the celebration of the Passover. The messengers, however, were not only not listened to, but were even laughed at, although a few men of the tribes of Asher, Manasseh and Zebulun "were humble enough to come" to the city. Nevertheless, the Passover was celebrated with great solemnity and such rejoicing as had not been seen in Jerusalem since the days of Solomon. The celebration took place during the second month, Iyar, because not enough priests had consecrated themselves in the first month.

Biblical writer H. P. Mathys suggests that Hezekiah, being unable to restore the union of Judah and Israel by political means, used the invitation to the northern tribes as a final religious "attempt to restore the unity of the cult". He also notes that this account "is often considered to contain historically reliable elements, especially since negative aspects are also reported on", although he questions the full extent to which it may be considered historically reliable.

After the death of Assyrian king Sargon II in 705 BCE, Sargon's son Sennacherib became king of Assyria. In 703 BCE, Sennacherib began a series of major campaigns to quash opposition to Assyrian rule, starting with cities in the eastern part of the realm. In 701 BCE, Sennacherib turned toward cities in the west. Hezekiah then had to face the invasion of Judah. According to the Bible, Hezekiah did not rely on Egypt for support, but relied on God and prayed to Him for deliverance of his capital city Jerusalem. (; ; ; ; )

The Assyrians recorded that Sennacherib lifted his siege of Jerusalem after Hezekiah paid Sennacherib tribute. The Bible records that Hezekiah paid him three hundred talents of silver and thirty of gold as tribute, even sending the doors of the Temple to produce the promised amount, but, even after the payment was made, Sennacherib renewed his assault on Jerusalem. Sennacherib surrounded the city and sent his Rabshakeh to the walls as a messenger. The Rabshakeh addressed the soldiers manning the city wall in Hebrew ("Yĕhuwdiyth"), asking them to distrust Yahweh and Hezekiah, claiming that Hezekiah's righteous reforms (destroying the idols and High Places) were a sign that the people should not trust their god to be favorably disposed (). records that Hezekiah went to the Temple and there he prayed to God.

Knowing that Jerusalem would eventually be subject to siege, Hezekiah had been preparing for some time by fortifying the walls of the capital, building towers, and constructing a tunnel to bring fresh water to the city from a spring outside its walls. He made at least two major preparations that would help Jerusalem to resist conquest: the construction of the Siloam Tunnel, and construction of the Broad Wall.

"When Sennacherib had come, intent on making war against Jerusalem, Hezekiah consulted with his officers about stopping the flow of the springs outside the city … for otherwise, they thought, the King of Assyria would come and find water in abundance" (). 

The narratives of the Bible state that Sennacherib's army besieged Jerusalem. (; ; ; )

According to the biblical record, Sennacherib sent threatening letters warning Hezekiah that he had not desisted from his determination to take the Judean capital. () Although they besieged Jerusalem, the biblical accounts state that the Assyrians did not so much as "shoot an arrow there, ... nor cast up a siege rampart against it", and that God sent out an angel who, in one night, struck down "a hundred and eighty-five thousand in the camp of the Assyrians," sending Sennacherib back "with shame of face to his own land".

Sennacherib's inscriptions make no mention of the disaster suffered by his forces. But, as Professor Jack Finegan comments: "In view of the general note of boasting which pervades the inscriptions of the Assyrian kings, ... it is hardly to be expected that Sennacherib would record such a defeat." The Cambridge Bible for Schools and Colleges refers to an "Egyptian tradition, according to which Sennacherib had already reached Pelusium in Egypt, when in a single night his army was rendered helpless by a plague of field-mice which gnawed the bows of the soldiers and the thongs of their shields". The version of the matter that Sennacherib presents, as found inscribed on what is known as the Sennacherib Prism preserved in the University of Chicago Oriental Institute, in part says: "As to Hezekiah, the Jew, he did not submit to my yoke ... Hezekiah himself ... did send me, later, to Nineveh, my lordly city, together with 30 talents of gold, 800 talents of silver, ..." This version inflates the number of silver talents sent from 300 to 800; but in other regards it confirms the biblical record and shows that Sennacherib made no claim that he captured Jerusalem. However, Sennacherib presents the matter of Hezekiah's paying tribute as having come after the Assyrian threat of a siege against Jerusalem, whereas the Bible states it was paid before.

Of Sennacherib's death, records:

"It came about as he was worshiping in the house of Nisroch his god, that Adrammelech and Sharezer killed him [Sennacherib] with the sword; and they escaped into the land of Ararat. And Esarhaddon his son became king in his place."

According to Assyrian records, Sennacherib was assassinated in 681 BCE, twenty years after the 701 BCE invasion of Judah. A Neo-Babylonian letter corroborates with the biblical account a sentiment from Sennacherib’s sons to assassinate him, an event Assyriologists have reconstructed as historical. The son Ardi-Mulishi, who is mentioned in the letter as killing anyone who would reveal his conspiracy, successfully murders his father in c. 681 BCE, and was most likely the Adrammelech in 2 Kings, though Sharezer is not known elsewhere. Assyriologists posit the murder was motivated because Esarhaddon was chosen as heir to the throne instead of Ardi-Mulishi, the next eldest son. Assyrian and Hebrew biblical history corroborate that Esarhaddon ultimately did succeed the throne. Other Assyriologists assert that Sennacherib was murdered in revenge for his destruction of Babylon, a city sacred to all Mesopotamians, including the Assyrians.

Later in his life, Hezekiah was ill with a boil or an inflammation which Isaiah initially thought would be fatal. The narrative of his sickness and miraculous recovery is found in , and . Various ambassadors came to congratulate him on his recovery, among them from Merodach-baladan, son of the king of Babylon, "for he had heard that Hezekiah had been sick". Hezekiah, his vanity flattered by the visit, showed the Babylonian embassy all the wealth, arms and stores of Jerusalem, revealing too much information to Baladan, king of Babylon (or perhaps boasting about his wealth): he was then confronted by Isaiah, who foretold that a future generation of the people of Judah would be taken as captives to Babylon. Hezekiah was reassured that his own lifetime would see peace and security.

According to , Hezekiah lived another 15 years after praying to God. His son and successor, Manasseh, was born during this time: he was 12 years of age when he succeeded Hezekiah.

According to the Talmud, the disease came about because of a dispute between him and Isaiah over who should pay whom a visit and over Hezekiah's refusal to marry and have children, although in the end he married Isaiah's daughter. Some Talmudists also considered that it might have come about as a way for Hezekiah to purge his sins or due to his arrogance in assuming his righteousness.

Extra-biblical sources do much more for us than give us a pan-Mid Eastern picture into which we contextualize Hezekiah: there are extra-biblical sources that specify Hezekiah by name, along with his reign and influence. "Historiographically, his reign is noteworthy for the convergence of a variety of biblical sources and diverse extrabiblical evidence often bearing on the same events. Significant data concerning Hezekiah appear in the Deuteronomistic History, the Chronicler, Isaiah, Assyrian annals and reliefs, Israelite epigraphy, and, increasingly, stratigraphy". Archaeologist Amihai Mazar calls the tensions between Assyria and Judah "one of the best-documented events of the Iron Age" (172). Hezekiah's story is one of the best to cross-reference with the rest of the Mid Eastern world's historical documents.

A seal impression dating back to 727–698 BCE, reading "לחזקיהו [בן] אחז מלך יהדה" "Belonging to Hezekiah [son of] Ahaz king of Judah" was uncovered in a dig at the Ophel in Jerusalem. The impression on this inscription was set in ancient Hebrew script.

A lintel inscription, found over the doorway of a tomb, has been ascribed to his secretary, Shebnah ().

LMLK stored jars along the border with Assyria "demonstrate careful preparations to counter Sennacherib's likely route of invasion" and show "a notable degree of royal control of towns and cities which would facilitate Hezekiah's destruction of rural sacrificial sites and his centralization of worship in Jerusalem". Evidence suggests they were used throughout his 29-year reign. There are some Bullae from sealed documents that may have belonged to Hezekiah himself. There are also some that name his servants ("ah-vah-deem" in Hebrew, ayin-bet-dalet-yod-mem).

In 2015 Eilat Mazar discovered a bulla that bears an inscription in ancient Hebrew script that translates as: "Belonging to Hezekiah [son of] Ahaz king of Judah." This is the first seal impression of an Israelite or Judean king to come to light in a scientific archaeological excavation. While another, unprovenanced bulla of King Hezekiah was known, this was the first time a seal impression of Hezekiah had been discovered in situ in the course of actual excavations. Archaeological findings like the Hezekiah seal led scholars to surmise that the ancient Judahite kingdom had a highly developed administrative system. In 2018 Mazar published a report discussing the discovery of a bulla (a type of seal) which she says may have to have belonged to Isaiah. She believes the fragment to have been part of a seal whose complete text might have read "Belonging to Isaiah the prophet." Several other biblical archaeologists, including George Washington University's Christopher Rollston have pointed to the bulla being incomplete, and the present inscription not enough to necessarily refer to the biblical figure.

According to the work of archaeologists and philologists, the reign of Hezekiah saw a notable increase in the power of the Judean state. At this time Judah was the strongest nation on the Assyrian–Egyptian frontier. There were increases in literacy and in the production of literary works. The massive construction of the Broad Wall was made during his reign, the city was enlarged to accommodate a large influx, and population increased in Jerusalem up to 25,000, "five times the population under Solomon." Archaeologist Amihai Mazar explains, "Jerusalem was a virtual city-state where the majority of the state's population was concentrated," in comparison to the rest of Judah's cities (167). Archaeologist Israel Finkelstein says, "The key phenomenon—which cannot be explained solely against the background of economic prosperity—was the sudden growth of the population of Jerusalem in particular, and of Judah in general" (153). He says the cause of this growth must be a large influx of Israelites fleeing from the Assyrian destruction of the northern state. It is "[t]he only reasonable way to explain this unprecedented demographic development" (154). This, according to Finkelstein, set the stage for motivations to compile and reconcile Hebrew history into a text at that time (157). Mazar questions this explanation, since, he argues, it is "no more than an educated guess" (167).

The Siloam Tunnel was chiseled through 533 meters (1,750 feet) of solid rock in order to provide Jerusalem underground access to the waters of the Gihon Spring or Siloam Pool, which lay outside the city.

The Siloam Inscription from the Siloam Tunnel is now in the Istanbul Archaeology Museum. It "commemorates the dramatic moment when the two original teams of tunnelers, digging with picks from opposite ends of the tunnel, met each other" (564). It is "[o]ne of the most important ancient Hebrew inscriptions ever discovered." Finkelstein and Mazar cite this tunnel as an example of Jerusalem's impressive state-level power at the time.

Archaeologists like William G. Dever have pointed at archaeological evidence for the iconoclasm during the period of Hezekiah's reign. The central cult room of the temple at Arad (a royal Judean fortress) was deliberately and carefully dismantled, "with the altars and massebot" concealed "beneath a Str. 8 plaster floor". This stratum correlates with the late 8th century; Dever concludes that "the deliberate dismantling of the temple and its replacement by another structure in the days of Hezekiah is an archeological fact. I see no reason for skepticism here."

Under Rehoboam, Lachish became the second-most important city of the kingdom of Judah. During the revolt of king Hezekiah against Assyria, it was captured by Sennacherib despite determined resistance (see Siege of Lachish).

As the Lachish relief attests, Sennacherib began his siege of the city of Lachish in 701 BCE. The Lachish Relief graphically depicts the battle, and the defeat of the city, including Assyrian archers marching up a ramp and Judahites pierced through on mounted stakes. "The reliefs on these slabs" discovered in the Assyrian palace at Nineveh "originally formed a single, continuous work, measuring 8 feet ... tall by 80 feet ... long, which wrapped around the room" (559). Visitors "would have been impressed not only by the magnitude of the artwork itself but also by the magnificent strength of the Assyrian war machine."

Sennacherib's Prism was found buried in the foundations of the Nineveh palace. It was written in cuneiform, the Mesopotamian form of writing of the day. The prism records the conquest of 46 strong towns and "uncountable smaller places," along with the siege of Jerusalem where Sennacherib says he just "shut him up ... like a bird in a cage," subsequently enforcing a larger tribute upon him.

The Hebrew Bible states that during the night, the angel of Jehovah (YHWH Hebrew) brought death to 185,000 Assyrians troops (), forcing the army to abandon the siege, yet it also records a tribute paid to Sennacherib of 300 silver talents following the siege. There is no account of the supernatural event in the prism. Sennacherib's account records his levying of a tribute from Hezekiah, the king of Judea, who was within Jerusalem, leaving the city as the only one intact following the exile of the northern ten-tribe kingdom of Israel due to idolatry. (2 Kings 17:22, 23; 2 Kings 18:1–8) Sennacherib recorded a payment of 800 silver talents, which suggests a capitulation to end the siege. However, Inscriptions have been discovered describing Sennacherib's defeat of the Ethiopian forces. These say: "As to Hezekiah, the Jew, he did not submit to my yoke, I laid siege to 46 of his strong cities ... and conquered (them). ... Himself I made a prisoner in Jerusalem, his royal residence, like a bird in a cage." He does not claim to have captured the city. This is consistent with the Bible account of Hezekiah's revolt against Assyria in the sense that neither account seems to indicate that Sennacherib ever entered or formally captured the city. Sennacherib in this inscription claims that Hezekiah paid for tribute 800 talents of silver, in contrast with the Bible's 300, however this could be due to boastful exaggeration which was not uncommon amongst kings of the period. Furthermore, the annals record a list of booty sent from Jerusalem to Nineveh. In the inscription, Sennacherib claims that Hezekiah accepted servitude, and some theorize that Hezekiah remained on his throne as a vassal ruler. The campaign is recorded with differences in the Assyrian records and in the biblical Books of Kings; there is agreement that the Assyrian have a propensity for exaggeration.

One theory that takes the biblical view posits that a defeat was caused by "possibly an outbreak of the bubonic plague". Another that this is a composite text which makes use of a 'legendary motif' analogous to that of the Exodus story.


The Talmud (Bava Batra 15a) credits Hezekiah with overseeing the compilation of the biblical books of Isaiah, Proverbs, Song of Songs and Ecclesiastes.

According to Jewish tradition, the victory over the Assyrians and Hezekiah's return to health happened at the same time, the first night of Passover.

The Greek historian Herodotus (c. 484 BCE – c. 425 BCE) wrote of the invasion and acknowledges many Assyrian deaths, which he claims were the result of a plague of mice. The Jewish historian Josephus followed the writings of Herodotus. These historians record Sennacherib's failure to take Jerusalem is "uncontested".
Abi saved the life of her son Hezekiah, whom her godless husband, Ahaz, had designed as an offering to Moloch. By anointing him with the blood of the salamander, she enabled him to pass through the fire of Moloch unscathed (Sanh. 63b).

Hezekiah is considered as the model of those who put their trust in the Lord. Only during his sickness did he waver in his hitherto unshaken trust and require a sign, for which he was blamed by Isaiah (Lam. R. i.). The Hebrew name "Ḥizḳiyyah" is considered by the Talmudists to be a surname, meaning either "strengthened by Yhwh" or "he who made a firm alliance between the Israelites and Yhwh"; his eight other names are enumerated in Isa. ix. 5 (Sanh. 94a). He is called the restorer of the study of the Law in the schools, and is said to have planted a sword at the door of the bet ha-midrash, declaring that he who would not study the Law should be struck with the weapon (ib. 94b).

Hezekiah's piety, which, according to the Talmudists, alone occasioned the destruction of the Assyrian army and the signal deliverance of the Israelites when Jerusalem was attacked by Sennacherib, caused him to be considered by some as the Messiah (ib. 99a). According to Bar Ḳappara, Hezekiah was destined to be the Messiah, but the attribute of justice("middat ha-din") protested against this, saying that as David, who sang so much the glory of God, had not been made the Messiah, still less should Hezekiah, for whom so many miracles had been performed, yet who did not sing the praise of God (ib. 94a).

Hezekiah's dangerous illness was caused by the discord between him and Isaiah, each of whom desired that the other should pay him the first visit. In order to reconcile them God struck Hezekiah with a malady and ordered Isaiah to visit the sick king. Isaiah told the latter that he would die, and that his soul also would perish because he had not married and had thus neglected the commandment to perpetuate the human species. Hezekiah did not despair, however, holding to the principle that one must always have recourse to prayer. He finally married Isaiah's daughter, who bore him Manasseh (Ber. 10a). However, in Gen. R. lxv. 4, as quoted in Yalḳ., II Kings, 243, it is said that Hezekiah prayed for illness and for recovery in order that he might be warned and be able to repent of his sins. He was thus the first who recovered from illness. But in his prayer he was rather arrogant, praising himself; and this resulted in the banishment of his descendants (Sanh. 104a). R. Levi said that Hezekiah's words, "and I have done what is good in thy eyes" (II Kings xx. 3), refer to his concealing a book of healing. According to the Talmudists, Hezekiah did six things, of which three agreed with the dicta of the Rabbis and three disagreed therewith (Pes. iv., end). The first three were these: (1) he concealed the book of healing because people, instead of praying to God, relied on medical prescriptions; (2) he broke in pieces the brazen serpent (see Biblical Data, above); and (3) he dragged his father's remains on a pallet, instead of giving them kingly burial. The second three were: (1) stopping the water of Gihon; (2) cutting the gold from the doors of the Temple; and (3) celebrating the Passover in the second month (Ber. 10b; comp. Ab. R. N. ii., ed. Schechter, p. 11).

The question that puzzled Heinrich Ewald ("Gesch. des Volkes Israel," iii. 669, note 5) and others, "Where was the brazen serpent till the time of Hezekiah?" occupied the Talmudists also. They answered it in a very simple way: Asa and Joshaphat, when clearing away the idols, purposely left the brazen serpent behind, in order that Hezekiah might also be able to do a praiseworthy deed in breaking it (Ḥul. 6b).

The Midrash reconciles the two different narratives (II Kings xviii. 13-16 and II Chron. xxxii. 1-8) of Hezekiah's conduct at the time of Sennacherib's invasion (see Biblical Data, above). It says that Hezekiah prepared three means of defense: prayer, presents, and war (Eccl. R. ix. 27), so that the two Biblical statements complement each other. The reason why Hezekiah's display of his treasures to the Babylonian ambassadors aroused the anger of God (II Chron. xxxii. 25) was that Hezekiah opened before them the Ark, showing them the tablets of the covenant, and saying, "It is with this that we are victorious" (Yalḳ., l.c. 245).

Notwithstanding Hezekiah's immense riches, his meal consisted only of a pound of vegetables (Sanh. 94b). The honor accorded to him after death consisted, according to R. Judah, in his bier being preceded by 36,000 men whose shoulders were bare in sign of mourning. According to R. Nehemiah, a scroll of the Law was placed on Hezekiah's bier. Another statement is that a yeshibah was established on his grave—for three days, according to some: for seven, according to others; or for thirty, according to a third authority (Yalḳ., II Chron. 1085). The Talmudists attribute to Hezekiah the redaction of the books of Isaiah, Proverbs, Song of Solomon, and Ecclesiastes (B. B. 15a).

Understanding the biblically recorded sequence of events in Hezekiah's life as chronological or not is critical to the contextual interpretation of his reign. According to scholar Stephen L. Harris, chapter 20 of 2 Kings does not follow the events of chapters 18 and 19 (161). Rather, the Babylonian envoys precede the Assyrian invasion and siege. Chapter 20 would have been added during the exile, and Harris says it "evidently took place before Sennacherib's invasion' when Hezekiah was "trying to recruit Babylon as an ally against Assyria.' Consequently, "Hezekiah ends his long reign impoverished and ruling over only a tiny scrap of his former domain.' Likewise, "The Archaeological Study Bible" says, "The presence of these riches' that Hezekiah shows to the Babylonians "indicates that this event took place before Hezekiah's payment of tribute to Sennacherib in 701 BC" (564). Again, "Though the king's illness and the subsequent Babylonian mission are described at the end of the accounts of his reign, they must have occurred before the war with Assyria. Thus, Isaiah's chastening of Hezekiah is due to his alliances made with other countries during the Assyrian conflict for insurance. To a reader who interprets the chapters chronologically, it would appear that Hezekiah ended his reign at a climax, but with a scholarly analysis, his end would contrarily be interpreted as a long fall from where he began.”

There has been considerable academic debate about the actual dates of reigns of the Israelite kings. Scholars have endeavored to synchronize the chronology of events referred to in the Hebrew Bible with those derived from other external sources. In the case of Hezekiah, scholars have noted that the apparent inconsistencies are resolved by accepting the evidence that Hezekiah, like his predecessors for four generations in the kings of Judah, had a coregency with his father, and this coregency began in 729 BCE.

As an example of the reasoning that finds inconsistencies in calculations when coregencies are "a priori" ruled out, dates the fall of Samaria (the Northern Kingdom) to the 6th year of Hezekiah's reign. William F. Albright has dated the fall of the Kingdom of Israel to 721 BCE, while E. R. Thiele calculates the date as 723 BCE. If Abright's or Thiele's dating are correct, then Hezekiah's reign would begin in either 729 or 727 BCE. On the other hand, states that Sennacherib invaded Judah in the 14th year of Hezekiah's reign. Dating based on Assyrian records date this invasion to 701 BCE, and Hezekiah's reign would therefore begin in 716/715 BCE. This dating would be confirmed by the account of Hezekiah's illness in chapter 20, which immediately follows Sennacherib's departure (). This would date his illness to Hezekiah's 14th year, which is confirmed by Isaiah's statement () that he will live fifteen more years (29 − 15 = 14). As shown below, these problems are all addressed by scholars who make reference to the ancient Near Eastern practice of coregency.

Following the approach of Wellhausen, another set of calculations shows it is probable that Hezekiah did not ascend the throne before 722 BCE. By Albright's calculations, Jehu's initial year is 842 BCE; and between it and Samaria's destruction the "Books of Kings" give the total number of the years the kings of Israel ruled as 143 7/12, while for the kings of Judah the number is 165. This discrepancy, amounting in the case of Judah to 45 years (165–120), has been accounted for in various ways; but every one of those theories must allow that Hezekiah's first six years fell before 722 BCE. (That Hezekiah began to reign before 722 BCE, however, is entirely consistent with the principle that the Ahaz/Hezekiah coregency began in 729 BCE.) Nor is it clearly known how old Hezekiah was when called to the throne, although states he was twenty-five years of age. His father died at the age of thirty-six (); it is not likely that Ahaz at the age of eleven should have had a son. Hezekiah's own son Manasseh ascended the throne twenty-nine years later, at the age of twelve. This places his birth in the seventeenth year of his father's reign, or gives Hezekiah's age as forty-two, if he was twenty-five at his ascension. It is more probable that Ahaz was twenty-one or twenty-five when Hezekiah was born (and suggesting an error in the text), and that the latter was thirty-two at the birth of his son and successor, Manasseh.
Since Albright and Friedman, several scholars have explained these dating problems on the basis of a coregency between Hezekiah and his father Ahaz between 729 and 716/715 BCE. Assyriologists and Egyptologists recognize that coregency was a practice both in Assyria and Egypt. After noting that coregencies were only used sporadically in the northern kingdom (Israel), Nadav Na'aman writes,
In the kingdom of Judah, on the other hand, the nomination of a co-regent was the common procedure, beginning from David who, before his death, elevated his son Solomon to the throne. When taking into account the permanent nature of the co-regency in Judah from the time of Joash, one may dare to conclude that dating the co-regencies accurately is indeed the key for solving the problems of biblical chronology in the eighth century BC."

Among the numerous scholars who have recognized the coregency between Ahaz and Hezekiah are Kenneth Kitchen in his various writings, Leslie McFall, and Jack Finegan. McFall, in his 1991 article, argues that if 729 BCE (that is, the Judean regnal year beginning in Tishri of 729) is taken as the start of the Ahaz/Hezekiah coregency, and 716/715 BCE as the date of the death of Ahaz, then all the extensive chronological data for Hezekiah and his contemporaries in the late eighth century BCE are in harmony. Further, McFall found that no textual emendations are required among the numerous dates, reign lengths, and synchronisms given in the Hebrew Testament for this period. In contrast, those who do not accept the Ancient Near Eastern principle of coregencies require multiple emendations of the Scriptural text, and there is no general agreement on which texts should be emended, nor is there any consensus among these scholars on the resultant chronology for the eighth century BCE. This is in contrast with the general consensus among those who accept the biblical and near Eastern practice of coregencies that Hezekiah was installed as coregent with his father Ahaz in 729 BCE, and the synchronisms of 2 Kings 18 must be measured from that date, whereas the synchronisms to Sennacherib are measured from the sole reign starting in 716/715 BCE. The two synchronisms to Hoshea of Israel in 2 Kings 18 are then in exact agreement with the dates of Hoshea's reign that can be determined from Assyrian sources, as is the date of Samaria's fall as stated in 2 Kings 18:10. An analogous situation of two ways of measurement, both equally valid, is encountered in the dates given for Jehoram of Israel, whose first year is synchronized to the 18th year of the sole reign of Jehoshaphat of Judah in 2 Kings 3:1 (853/852 BCE), but his reign is also reckoned according to another method as starting in the second year of the coregency of Jehoshaphat and his son Jehoram of Judah (2 Kings 1:17); both methods refer to the same calendrical year.

Scholars who accept the principle of coregencies note that abundant evidence for their use is found in the biblical material itself. The agreement of scholarship built on these principles with both biblical and secular texts was such that the Thiele/McFall chronology was accepted as the best chronology for the kingdom period in Jack Finegan's encyclopedic "Handbook of Biblical Chronology".





</doc>
<doc id="14006" url="https://en.wikipedia.org/wiki?curid=14006" title="Haemophilia">
Haemophilia

Haemophilia is a mostly inherited genetic disorder that impairs the body's ability to make blood clots, a process needed to stop bleeding. This results in people bleeding for a longer time after an injury, easy bruising, and an increased risk of bleeding inside joints or the brain. Those with a mild case of the disease may have symptoms only after an accident or during surgery. Bleeding into a joint can result in permanent damage while bleeding in the brain can result in long term headaches, seizures, or a decreased level of consciousness.
There are two main types of haemophilia: haemophilia A, which occurs due to low amounts of clotting factor VIII, and haemophilia B, which occurs due to low levels of clotting factor IX. They are typically inherited from one's parents through an X chromosome carrying a nonfunctional gene. Rarely a new mutation may occur during early development or haemophilia may develop later in life due to antibodies forming against a clotting factor. Other types include haemophilia C, which occurs due to low levels of factor XI, and parahaemophilia, which occurs due to low levels of factor V. Acquired haemophilia is associated with cancers, autoimmune disorders, and pregnancy. Diagnosis is by testing the blood for its ability to clot and its levels of clotting factors.
Prevention may occur by removing an egg, fertilizing it, and testing the embryo before transferring it to the uterus. Treatment is by replacing the missing blood clotting factors. This may be done on a regular basis or during bleeding episodes. Replacement may take place at home or in hospital. The clotting factors are made either from human blood or by recombinant methods. Up to 20% of people develop antibodies to the clotting factors which makes treatment more difficult. The medication desmopressin may be used in those with mild haemophilia A. Studies of gene therapy are in early human trials.
Haemophilia A affects about 1 in 5,000–10,000, while haemophilia B affects about 1 in 40,000, males at birth. As haemophilia A and B are both X-linked recessive disorders, females are rarely severely affected. Some females with a nonfunctional gene on one of the X chromosomes may be mildly symptomatic. Haemophilia C occurs equally in both sexes and is mostly found in Ashkenazi Jews. In the 1800s haemophilia B was common within the royal families of Europe. The difference between haemophilia A and B was determined in 1952. The word is from the Greek "haima" αἷμα meaning blood and "philia" φιλία meaning love.
Characteristic symptoms vary with severity. In general symptoms are internal or external bleeding episodes, which are called "bleeds". People with more severe haemophilia suffer more severe and more frequent bleeds, while people with mild haemophilia usually suffer more minor symptoms except after surgery or serious trauma. In cases of moderate haemophilia symptoms are variable which manifest along a spectrum between severe and mild forms.

In both haemophilia A and B, there is spontaneous bleeding but a normal bleeding time, normal prothrombin time, normal thrombin time, but prolonged partial thromboplastin time. Internal bleeding is common in people with severe haemophilia and some individuals with moderate haemophilia. The most characteristic type of internal bleed is a joint bleed where blood enters into the joint spaces. This is most common with severe haemophiliacs and can occur spontaneously (without evident trauma). If not treated promptly, joint bleeds can lead to permanent joint damage and disfigurement. Bleeding into soft tissues such as muscles and subcutaneous tissues is less severe but can lead to damage and requires treatment.

Children with mild to moderate haemophilia may not have any signs or symptoms at birth, especially if they do not undergo circumcision. Their first symptoms are often frequent and large bruises and haematomas from frequent bumps and falls as they learn to walk. Swelling and bruising from bleeding in the joints, soft tissue, and muscles may also occur. Children with mild haemophilia may not have noticeable symptoms for many years. Often, the first sign in very mild haemophiliacs is heavy bleeding from a dental procedure, an accident, or surgery. Females who are carriers usually have enough clotting factors from their one normal gene to prevent serious bleeding problems, though some may present as mild haemophiliacs.

Severe complications are much more common in cases of severe and moderate haemophilia. Complications may arise from the disease itself or from its treatment:
Haemophilic arthropathy is characterized by chronic proliferative synovitis and cartilage destruction. If an intra-articular bleed is not drained early, it may cause apoptosis of chondrocytes and affect the synthesis of proteoglycans. The hypertrophied and fragile synovial lining while attempting to eliminate excessive blood may be more likely to easily rebleed, leading to a vicious cycle of hemarthrosis-synovitis-hemarthrosis. In addition, iron deposition in the synovium may induce an inflammatory response activating the immune system and stimulating angiogenesis, resulting in cartilage and bone destruction.

Typically, females possess two X-chromosomes, and males have one X and one Y-chromosome. Since the mutations causing the disease are X-linked recessive, a female carrying the defect on one of her X-chromosomes may not be affected by it, as the equivalent dominant allele on her other chromosome should express itself to produce the necessary clotting factors, due to X inactivation. Therefore, heterozygous females are just carriers of this genetic disposition. However, the Y-chromosome in the male has no gene for factors VIII or IX. If the genes responsible for production of factor VIII or factor IX present on a male's X-chromosome are deficient there is no equivalent on the Y-chromosome to cancel it out, so the deficient gene is not masked and the disorder will develop.

Since a male receives his single X-chromosome from his mother, the son of a healthy female silently carrying the deficient gene will have a 50% chance of inheriting that gene from her and with it the disease; and if his mother is affected with haemophilia, he will have a 100% chance of being a haemophiliac. In contrast, for a female to inherit the disease, she must receive two deficient X-chromosomes, one from her mother and the other from her father (who must therefore be a haemophiliac himself). Hence, haemophilia is expressed far more commonly among males than females, while double-X females are far more likely to be silent carriers, survive childhood and to submit each of her genetic children to an at least 50% risk of receiving the deficient gene. However, it is possible for female carriers to become mild haemophiliacs due to lyonisation (inactivation) of the X-chromosomes. Haemophiliac daughters are more common than they once were, as improved treatments for the disease have allowed more haemophiliac males to survive to adulthood and become parents. Adult females may experience menorrhagia (heavy periods) due to the bleeding tendency. The pattern of inheritance is criss-cross type. This type of pattern is also seen in colour blindness.

A mother who is a carrier has a 50% chance of passing the faulty X-chromosome to her daughter, while an affected father will always pass on the affected gene to his daughters. A son cannot inherit the defective gene from his father. This is a recessive trait and can be passed on if cases are more severe with carrier. Genetic testing and genetic counselling is recommended for families with haemophilia. Prenatal testing, such as amniocentesis, is available to pregnant women who may be carriers of the condition.

As with all genetic disorders, it is also possible for a human to acquire it spontaneously through mutation, rather than inheriting it, because of a new mutation in one of their parents' gametes. Spontaneous mutations account for about 33% of all cases of haemophilia A. About 30% of cases of haemophilia B are the result of a spontaneous gene mutation.

If a female gives birth to a haemophiliac son, either the female is a carrier for the blood disorder or the haemophilia was the result of a spontaneous mutation. Until modern direct DNA testing, however, it was impossible to determine if a female with only healthy children was a carrier or not. Generally, the more healthy sons she bore, the higher the probability that she was not a carrier.

If a male is afflicted with the disease and has children with a female who is not a carrier, his daughters will be carriers of haemophilia. His sons, however, will not be affected with the disease. The disease is X-linked and the father cannot pass haemophilia through the Y-chromosome. Males with the disorder are then no more likely to pass on the gene to their children than carrier females, though all daughters they sire will be carriers and all sons they father will not have haemophilia (unless the mother is a carrier).

There are numerous different mutations which cause each type of haemophilia. Due to differences in changes to the genes involved, people with haemophilia often have some level of active clotting factor. Individuals with less than 1% active factor are classified as having severe haemophilia, those with 1–5% active factor have moderate haemophilia, and those with mild haemophilia have between 5% and 40% of normal levels of active clotting factor.

Haemophilia can be diagnosed before, during or after birth if there is a family history of the condition. Several options are available to parents. If there is no family history of haemophilia, it is usually only diagnosed when a child begins to walk or crawl. They may experience joint bleeds or easy bruising.

Mild haemophilia may only be discovered later, usually after an injury or a dental or surgical procedure.

Genetic testing and counselling are available to help determine the risk of passing the condition onto a child. This may involve testing a sample of tissue or blood to look for signs of the genetic mutation that causes haemophilia.

A pregnant woman with a history of haemophilia in her family can test for the haemophilia gene. Such tests include:


There is a small risk of these procedures causing problems such as miscarriage or premature labour, so the woman may discuss this with the doctor in charge of her care.

If haemophilia is suspected after a child has been born, a blood test can usually confirm the diagnosis. Blood from the umbilical cord can be tested at birth if there's a family history of haemophilia. A blood test will also be able to identify whether a child has haemophilia A or B, and how severe it is.

There are several types of haemophilia: haemophilia A, haemophilia B, haemophilia C, "parahaemophilia", "acquired haemophilia A", and "acquired haemophilia B".

Haemophilia A, is a recessive X-linked genetic disorder resulting in a deficiency of functional clotting Factor VIII. Haemophilia B, is also a recessive X-linked genetic disorder involving a lack of functional clotting Factor IX. Haemophilia C, is an autosomal genetic disorder involving a lack of functional clotting Factor XI. Haemophilia C is not completely recessive, as heterozygous individuals also show increased bleeding.

The type of haemophilia known as "parahaemophilia" is a mild and rare form and is due to a deficiency in factor V. This type can be inherited or acquired.

A non-genetic form of haemophilia is caused by autoantibodies against factor VIII and so is known as "acquired haemophilia A". Acquired haemophilia can be associated with cancers, autoimmune disorders and following childbirth.

There is no long-term cure. Treatment and prevention of bleeding episodes is done primarily by replacing the missing blood clotting factors.

Clotting factors are usually not needed in mild haemophilia. In moderate haemophilia clotting factors are typically only needed when bleeding occurs or to prevent bleeding with certain events. In severe haemophilia preventive use is often recommended two or three times a week and may continue for life. Rapid treatment of bleeding episodes decreases damage to the body.

Factor VIII is used in haemophilia A and factor IX in haemophilia B. Factor replacement can be either isolated from human blood serum, recombinant, or a combination of the two. Some people develop antibodies (inhibitors) against the replacement factors given to them, so the amount of the factor has to be increased or non-human replacement products must be given, such as porcine factor VIII.

If a person becomes refractory to replacement coagulation factor as a result of high levels of circulating inhibitors, this may be partially overcome with recombinant human factor VIII.

In early 2008, the US Food and Drug Administration (FDA) approved anti-haemophilic factor genetically engineered from the genes of Chinese hamster ovary cells. Since 1993 recombinant factor products (which are typically cultured in Chinese hamster ovary (CHO) tissue culture cells and involve little, if any human plasma products) have been available and have been widely used in wealthier western countries. While recombinant clotting factor products offer higher purity and safety, they are, like concentrate, extremely expensive, and not generally available in the developing world. In many cases, factor products of any sort are difficult to obtain in developing countries.

Clotting factors are either given preventively or on-demand. Preventive use involves the infusion of clotting factor on a regular schedule in order to keep clotting levels sufficiently high to prevent spontaneous bleeding episodes. On-demand (or episodic) treatment involves treating bleeding episodes once they arise. In 2007, a trial comparing on-demand treatment of boys (< 30 months) with haemophilia A with prophylactic treatment (infusions of 25 IU/kg body weight of Factor VIII every other day) in respect to its effect on the prevention of joint-diseases. When the boys reached 6 years of age, 93% of those in the prophylaxis group and 55% of those in the episodic-therapy group had a normal index joint-structure on MRI. Preventative treatment, however, resulted in average costs of $300,000 per year. The author of an editorial published in the same issue of the "NEJM" supports the idea that prophylactic treatment not only is more effective than on demand treatment but also suggests that starting after the first serious joint-related haemorrhage may be more cost effective than waiting until the fixed age to begin. Most haemophiliacs in third world countries have limited or no access to commercial blood clotting factor products.

Desmopressin (DDAVP) may be used in those with mild haemophilia A. Tranexamic acid or epsilon aminocaproic acid may be given along with clotting factors to prevent breakdown of clots.

Pain medicines, steroids, and physical therapy may be used to reduce pain and swelling in an affected joint. In those with severe hemophilia A already receiving FVIII, emicizumab may provide some benefit. Different treatments are used to help those with an acquired form of hemophilia in addition to the normal clotting factors. Often the most effective treatment is corticosteroids which remove the auto-antibodies in half of people. As a secondary route of treatment, cyclophosphamide and cyclosporine are used and are proven effective for those who did not respond to the steroid treatments. In rare cases a third route or treatment is used, high doses of intravenous immunoglobulin or immunosorbent that works to help control bleeding instead of battling the auto-antibodies. 

Anticoagulants such as heparin and warfarin are contraindicated for people with haemophilia as these can aggravate clotting difficulties. Also contraindicated are those drugs which have "blood thinning" side effects. For instance, medicines which contain aspirin, ibuprofen, or naproxen sodium should not be taken because they are well known to have the side effect of prolonged bleeding.

Also contraindicated are activities with a high likelihood of trauma, such as motorcycling and skateboarding. Popular sports with very high rates of physical contact and injuries such as American football, hockey, boxing, wrestling, and rugby should be avoided by people with haemophilia. Other active sports like soccer, baseball, and basketball also have a high rate of injuries, but have overall less contact and should be undertaken cautiously and only in consultation with a doctor.

Like most aspects of the disorder, life expectancy varies with severity and adequate treatment. People with severe haemophilia who don't receive adequate, modern treatment have greatly shortened lifespans and often do not reach maturity. Prior to the 1960s when effective treatment became available, average life expectancy was only 11 years. By the 1980s the life span of the average haemophiliac receiving appropriate treatment was 50–60 years. Today with appropriate treatment, males with haemophilia typically have a near normal quality of life with an average lifespan approximately 10 years shorter than an unaffected male.

Since the 1980s the primary leading cause of death of people with severe haemophilia has shifted from haemorrhage to HIV/AIDS acquired through treatment with contaminated blood products. The second leading cause of death related to severe haemophilia complications is intracranial haemorrhage which today accounts for one third of all deaths of people with haemophilia. Two other major causes of death include hepatitis infections causing cirrhosis and obstruction of air or blood flow due to soft tissue haemorrhage.

Haemophilia is rare, with only about 1 instance in every 10,000 births (or 1 in 5,000 male births) for haemophilia A and 1 in 50,000 births for haemophilia B. About 18,000 people in the United States have haemophilia. Each year in the US, about 400 babies are born with the disorder. Haemophilia usually occurs in males and less often in females. It is estimated that about 2,500 Canadians have haemophilia A, and about 500 Canadians have haemophilia B.

The excessive bleeding was known to ancient people. The Talmud instructs that a boy must not be circumcised if he had two brothers who died due to complications arising from their circumcisions, and Maimonides says that this excluded paternal half-brothers. This may have been due to a concern about hemophilia. The first medical professional to describe the disease was Arab surgeon Al-Zahrawi, also known as Abulcasis. In the tenth century he described families whose males died of bleeding after only minor traumas. While many other such descriptive and practical references to the disease appear throughout historical writings, scientific analysis did not begin until the start of the nineteenth century.

In 1803, John Conrad Otto, a Philadelphian physician, wrote an account about "a hemorrhagic disposition existing in certain families" in which he called the affected males "bleeders". He recognised that the disorder was hereditary and that it affected mostly males and was passed down by healthy females. His paper was the second paper to describe important characteristics of an X-linked genetic disorder (the first paper being a description of colour blindness by John Dalton who studied his own family). Otto was able to trace the disease back to a woman who settled near Plymouth, NH in 1720. The idea that affected males could pass the trait onto their unaffected daughters was not described until 1813 when John F. Hay, published an account in The New England Journal of Medicine.

In 1924, a Finnish doctor discovered a hereditary bleeding disorder similar to haemophilia localised in the Åland Islands, southwest of Finland. This bleeding disorder is called "Von Willebrand Disease".

The term "haemophilia" is derived from the term "haemorrhaphilia" which was used in a description of the condition written by Friedrich Hopff in 1828, while he was a student at the University of Zurich. In 1937, Patek and Taylor, two doctors from Harvard, discovered anti-haemophilic globulin. In 1947, Pavlosky, a doctor from Buenos Aires, found haemophilia A and haemophilia B to be separate diseases by doing a lab test. This test was done by transferring the blood of one haemophiliac to another haemophiliac. The fact that this corrected the clotting problem showed that there was more than one form of haemophilia.

Haemophilia has featured prominently in European royalty and thus is sometimes known as 'the royal disease'. Queen Victoria passed the mutation for haemophilia B to her son Leopold and, through two of her daughters, Alice and Beatrice, to various royals across the continent, including the royal families of Spain, Germany, and Russia. In Russia, Tsarevich Alexei, the son and heir of Tsar Nicholas II, famously suffered from haemophilia, which he had inherited from his mother, Empress Alexandra, one of Queen Victoria's granddaughters. The haemophilia of Alexei would result in the rise to prominence of the Russian mystic Grigori Rasputin, at the imperial court.

It was claimed that Rasputin was successful at treating Tsarevich Alexei's haemophilia. At the time, a common treatment administered by professional doctors was to use aspirin, which worsened rather than lessened the problem. It is believed that, by simply advising against the medical treatment, Rasputin could bring visible and significant improvement to the condition of Tsarevich Alexei.

In Spain, Queen Victoria's youngest daughter, Princess Beatrice, had a daughter Victoria Eugenie of Battenberg, who later became Queen of Spain. Two of her sons were haemophiliacs and both died from minor car accidents. Her eldest son, Prince Alfonso of Spain, Prince of Asturias, died at the age of 31 from internal bleeding after his car hit a telephone booth. Her youngest son, Infante Gonzalo, died at age 19 from abdominal bleeding following a minor car accident in which he and his sister hit a wall while avoiding a cyclist. Neither appeared injured or sought immediate medical care and Gonzalo died two days later from internal bleeding.

The method for the production of an antihaemophilic factor was discovered by Judith Graham Pool from Stanford University in 1964, and approved for commercial use in 1971 in the United States under the name "Cryoprecipitated AHF". Together with the development of a system for transportation and storage of human plasma in 1965, this was the first time an efficient treatment for haemophilia became available.

Up until late-1985 many people with haemophilia received clotting factor products that posed a risk of HIV and hepatitis C infection. The plasma used to create the products was not screened or tested, neither had most of the products been subject to any form of viral inactivation.

Tens of thousands worldwide were infected as a result of contaminated factor products including more than 10,000 people in the United States, 3,500 British, 1,400 Japanese, 700 Canadians, 250 Irish, and 115 Iraqis.

Infection via the tainted factor products had mostly stopped by 1986 by which time viral inactivation methods had largely been put into place, although some products were shown to still be dangerous in 1987.

In those with severe haemophilia, gene therapy may reduce symptoms to those that a mild or moderate person with haemophilia might have. The best results have been found in haemophilia B. In 2016 early stage human research was ongoing with a few sites recruiting participants. In 2017 a gene therapy trial on nine people with haemophilia A reported that high doses did better than low doses. It is not currently an accepted treatment for haemophilia.



</doc>
<doc id="14008" url="https://en.wikipedia.org/wiki?curid=14008" title="Hickory (disambiguation)">
Hickory (disambiguation)

Hickory is a type of tree ("Carya" species) found in North America and East Asia.

Hickory may also refer to:





</doc>
<doc id="14009" url="https://en.wikipedia.org/wiki?curid=14009" title="Hemicellulose">
Hemicellulose

A hemicellulose (also known as polyose) is one of a number of heteropolymer (matrix polysaccharides), such as arabinoxylans, present along with cellulose in almost all terrestrial plant cell walls. While cellulose is crystalline, strong, and resistant to hydrolysis, hemicelluloses have random, amorphous structure with little strength. They are easily hydrolyzed by dilute acid or base as well as a myriad of hemicellulase enzymes.

Diverse kinds of hemicelluloses are known. Important examples include xylan, glucuronoxylan, arabinoxylan, glucomannan, and xyloglucan.

Hemicelluloses are polysaccharides often associated with cellulose, but cellulose and hemicellulose have distinct compositions and structures. Diverse sugars comprise hemicellulose, whereas cellulose is derived exclusively from glucose. For instance, besides glucose, sugar monomers in hemicelluloses can include the five-carbon sugars xylose and arabinose, the six-carbon sugars mannose and galactose, and the six-carbon deoxy sugar rhamnose. Hemicelluloses contain most of the D-pentose sugars, and occasionally small amounts of L-sugars as well. Xylose is in most cases the sugar monomer present in the largest amount, although in softwoods mannose can be the most abundant sugar. Not only regular sugars can be found in hemicellulose, but also their acidified form, for instance glucuronic acid and galacturonic acid can be present.

Unlike cellulose, hemicelluloses consist of shorter chains – 500–3,000 sugar units. In contrast, 7,000–15,000 glucose molecules comprise each polymer of cellulose. In addition, hemicellulose may be branched polymers, while cellulose is unbranched. Hemicelluloses are embedded in the cell walls of plants, sometimes in chains that form a 'ground' – they bind with pectin to cellulose to form a network of cross-linked fibres. 

Based on the structural difference, like backbone linkages and side groups, as well as other factors, like abundance and distributions in plants, hemicellulose could be characterized into four groups as following: 1) Xylans, 2) Mannans; 3) Mixed linkage β-glucans; 4) Xyloglucans

Xylans

Xylans usually consist of backbone of β-(1→4)-linked xylose residues. And it could be further divided into homoxylans and heteroxylans. Homoxylans has a backbone of D-xylopyranose residues linked by β(1→3) or mixed ,β(1→3, 1→4)-glycosidic linkages. Homoxylans mainly carry structural functions. Heteroxylans such as glucuronoxylans, glucuronoarabinoxylans, and complex heteroxylans, have a backbone of D-xylopyranose and short carbohydrate branches. For examples, glucuronoxylan has substitution with α-(1→2)-linked glucuronosyl and 4-O-methyl glucuronosyl residues. And arabinoxylans and glucuronoarabinoxylans contain arabinose residues attached to the backbone

Mannans

The mannan-type hemicellulose can be classified into two types based on their main chain difference, galactomannans and glucomannans. Galactomannans have only β-(1→4) linked D-mannopyranose residues in linear chains. Glucomannans consist of both β-(1→4) linked D-mannopyranose and β-(1→4) linked D-glucopyranose residues in the main chains. As for the side chains, D-galactopyranose residues tend to be 6-linked to both types as the single side chains with various amount.

Mixed linkage β-glucans

The conformation of the mixed linkage glucan chains usually contains blocks of β-(1→4) D-Glucopyranose separated by single β-(1→3) D-Glucopyranose. The population of β-(1→4) and β-(1→3) are about 70% and 30%. These glucans primarily consist of cellotriosly (CHO) and cellotraosyl (CHO)segments in random order. There are some study show the molar ratio of cellotriosly/cellotraosyl for oat (2.1-2.4), barley (2.8-3.3), and wheat (4.2-4.5).

Xyloglucans

Xyloglucans have a backbone similar to cellulose with α-D-Xylopyranose residues at position 6. To better describe different side chains, a single letter code notation is used for each side chain type. G -- unbranched Glc residue; X -- α-d-Xyl-(1→6)-Glc. L -- β-Gal , S -- α-l-Araf, F-- α-l-Fuc. These are the most common side chains.

The two most common types of xyloglucans in plant cell walls are identified as XXXG and XXGG.

Hemicelluloses are synthesised from sugar nucleotides in the cell's Golgi apparatus. Two models explain their synthesis: 1) a '2 component model' where modification occurs at two transmembrane proteins, and 2) a '1 component model' where modification occurs only at one transmembrane protein. After synthesis, hemicelluloses are transported to the plasma membrane via Golgi vesicles.

Each kind of hemicellulose is biosynthesized by specialized enzymes.

Mannan chain backbones are synthesized by cellulose synthase-like protein family A (CSLA) and possibly enzymes in cellulose synthase-like protein family D (CSLD). Mannan synthase, a particular enzyme in CSLA, is responsible for the addition of mannose units to the backbone. The galactose side-chains of some mannans are added by galactomannan galactosyltransferase. Acetylation of mannans is mediated by a mannan O-acetyltransferase, however, this enzyme has not been definitively identified.

Xyloglucan backbone synthesis is mediated by cellulose synthase-like protein family C (CSLC), particularly glucan synthase, which adds glucose units to the chain. Backbone synthesis of xyloglucan is also mediated in some way by xylosyltransferase, but this mechanism is separate to its transferase function and remains unclear. Xylosyltransferase in its transferase function is, however, utilized for the addition of xylose to the side-chain. Other enzymes utilized for side-chain synthesis of xyloglucan include galactosyltransferase (which is responsible for the addition of galactose and of which two different forms are utilized), fucosyltransferase (which is responsible for the addition of fucose), and acetyltransferase (which is responsible for acetylation).

Xylan backbone synthesis, unlike that of the other hemicelluloses, is not mediated by any cellulose synthase-like proteins. Instead, xylan synthase is responsible for backbone synthesis, facilitating the addition of xylose. Several genes for xylan synthases have been identified. Several other enzymes are utilized for the addition and modification of the side-chain units of xylan, including glucuronosyltransferase (which adds glucuronic acid units), xylosyltransferase (which adds additional xylose units), arabinosyltransferase (which adds arabinose), methyltransferase (responsible for methylation), and acetyltransferase (responsible for acetylation).Given that mixed-linkage glucan is a non-branched homopolymer of glucose, there is no side-chain synthesis, only the addition of glucose to the backbone in two linkages, β1-3 and β1-4. Backbone synthesis is mediated by enzymes in cellulose synthase-like protein families F and H (CSLF and CSLH), specifically glucan synthase. Several forms of glucan synthase from CSLF and CSLH have been identified. All of them are responsible for addition of glucose to the backbone and all are capable of producing both β1-3 and β1-4 linkages, however, it is unknown how much each specific enzyme contributes to the distribution of β1-3 and β1-4 linkages.

In the sulphite pulp process the hemicellulose is largely hydrolysed by the acid pulping liquor ending up in the brown liquor where the fermentable hexose sugars (around 2%) can be used for producing ethanol. This process was primarily applied to calcium sulfite brown liquors.


Arabinogalactans can be used as emulsifiers, stabilizers and binders according to the Federal Food, Drug and Cosmetic Act. Arabinogalactans can also be used as bonding agent for a bunch of things like sweeteners.

The films based on xylan show low oxygen permeability and thus are of potential interest as packaging for oxygen-sensitive products.

Agar is used in making jellies and puddings. It is also growth medium with other nutrients for microorganisms.

Curdlan can be used in fat replacement to produce diet food while having a taste and a mouth feel of real fat containing products.


b-glucans have an important role in food supplement while b-glucans are also promising in health-related issues, especially in immune reactions and the treatment of cancer.


Xanthan, with other polysaccharides can form gels that have high solution viscosity which can be used in the oil industry to thicken drilling mud. In the food industry, xanthan is used in products such as dressings and sauces.


Alginate is an important role in the development of antimicrobial textiles due to its characteristics of environmental friendliness, and high industrialization level as a sustainable biopolymer. 

Hemicellulose in Plant Cells


There are many ways to obtain hemicellulose; all of these rely on extraction methods through hardwood or softwood trees milled into smaller samples. In hardwoods the main hemicellulose extract is glucuronoxlyan (acetylated xylans), while galactoglucomannan is found in softwoods. Prior to extraction the wood typically must be milled into wood chips of various sizes depending on the reactor used. Following this, a hot water extraction process, also known as autohydrolysis or hydrothermal treatment, is utilized with the addition of acids and bases to vastly change the yield size and properties. The main advantage to hot water extraction is that it offers a method where the only chemical that is needed is water, making this environmentally friendly and cheap.

The hot water treatment goal is achieve as much removal of hemilleculose from the wood as possible. This is done through the hydrolysis of the hemicellulose to achieve smaller oligomers and monosacccharie xylose. Xylose when dehydrated becomes furfural. When xylose and fufural are the goal, acid catalysts, such as formic acid, are added to increase the transition of polysaccharide to monosaccharide. This catalyst also has been show to also utilize a solvent effect to be aid the reaction.

One method of pretreatment is to soak the wood with diluted acids (with concentrations around 4%). This converts the hydroloze hemicellulose into monosaccharaides. When pretreatment is done with bases (for instance sodium or potassium hydroxide) this destroys the structure of the inherent lignin. This changes the structure from crystalline to amorphous. Another pretreatment method is to pretreat hydrothermally. This offers advantages such as no toxic or corrosive solvents are needed, nor are special reactors, and no extra costs to dispose of hazardous chemicals.

The hot water extraction process is done in batch reactors, semi-continuous reactors, or slurry continuous reactors. For batch and semi-continuous reactors wood samples can be used in conditions such as chips or pellets while a slurry reactor must have particles as small as 200 to 300 micrometers. While the particle size decreases the yield production decreases as well. This is due to the increase of cellulose.

The hot water process is operated at a temperature range of 160 to 240 degrees Celsius in order to maintain the liquid phrase. This is done above the normal boiling point of water to increase the solubilization of the hemicellulose and the depolymerization of polysaccharides. This process can take several minutes to several hours depending on the temperature and pH of the system. Higher temperatures paired with higher extraction times lead to higher yields. A maximum yield is obtained at a pH of 3.5. If below, the extraction yield exponentially decreases. In order to control pH sodium bicarbonates are generally added. The sodium biocarbonates inhibits the autodyolysis of acetyl groups as well as inhibiting glycosic bonds. Depending on the temperature and time the hemicellulose can be further converted into oligomers, monomers, and lignin.




</doc>
<doc id="14011" url="https://en.wikipedia.org/wiki?curid=14011" title="Hillbilly">
Hillbilly

"Hillbilly" is a term (often derogatory) for people who dwell in rural, mountainous areas in the United States, primarily in southern Appalachia and the Ozarks. The term was later used to refer to people from other rural and mountainous areas west of the Mississippi river too, particularly those of the Rocky Mountains and near the Rio Grande.

The first known instances of "hillbilly" in print were in "The Railroad Trainmen's Journal" (vol. ix, July 1892), an 1899 photograph of men and women in West Virginia labeled "Camp Hillbilly", and a 1900 "New York Journal" article containing the definition: "a Hill-Billie is a free and untrammeled white citizen of Alabama, who lives in the hills, has no means to speak of, dresses as he can, talks as he pleases, drinks whiskey when he gets it, and fires off his revolver as the fancy takes him". The stereotype is twofold in that it incorporates both positive and negative traits: "Hillbillies" are often considered independent and self-reliant individuals who resist the modernization of society, but at the same time they are also defined as backward and violent. Scholars argue this duality is reflective of the split ethnic identities in white America. The term's later usage extended beyond solely white communities, exemplified with the "Hispanic hillbillies of northern New Mexico," in reference to the Hispanos of New Mexico.

The Appalachian Mountains were settled in the 18th century by settlers primarily from England, lowland Scotland, and the province of Ulster in Ireland. The settlers from Ulster were mainly Protestants who migrated to Ireland, during the Plantation of Ulster in the 17th century, from Scotland and Northern England. Many further migrated to the American colonies beginning in the 1730s, and in America became known as the Scots-Irish.

Scholars argue that the term "hillbilly" originated from Scottish dialect. The term "hill-folk" referred to people who preferred isolation from the greater society, and "billy" meant "comrade" or "companion". It is suggested that "hill-folk" and "billie" were combined when the Cameronians fled to the hills of southern Scotland. There is also the belief that most of the settlers from Scotland and northern Ireland were followers of king William of Orange. 'Billy' is a diminutive of 'William' common across the British isles. For the people who settle in America in the hills and who were Williamites, the term hillbilly connects both people who live in the hills and who are supporters of king William of Orange's ideologies. In 17th century Ireland, during the Williamite War, Protestant supporters of King William III ("King Billy") were often referred to as "Billy's Boys". However, some scholars disagree with this theory. Michael Montgomery's "From Ulster to America: The Scotch-Irish Heritage of American English" states, "In Ulster in recent years it has sometimes been supposed that it was coined to refer to followers of King William III and brought to America by early Ulster emigrants, but this derivation is almost certainly incorrect. ... In America "hillbilly" was first attested only in 1898, which suggests a later, independent development."

The term "hillbilly" spread in the years following the American Civil War. At this time, the country was developing both technologically and socially, but the Appalachian region was falling behind. Before the war, Appalachia was not distinctively different from other rural areas of the country. Post-war, although the frontier pushed farther west, the region maintained frontier characteristics. Appalachians themselves were perceived as backward, quick to violence and inbred in their isolation. Fueled by news stories of mountain feuds such as that in the 1880s between the Hatfields and McCoys, the hillbilly stereotype developed in the late 19th to early 20th century.

The "classic" hillbilly stereotype reached its current characterization during the years of the Great Depression. The period of Appalachian out-migration, roughly from the 1930s through the 1950s, saw many mountain residents moving north to the Midwestern industrial cities of Chicago, Cleveland, Akron, and Detroit.

This movement to Northern society, which became known as the "Hillbilly Highway", brought these previously isolated communities into mainstream United States culture. In response, poor white mountaineers became central characters in newspapers, pamphlets, and eventually, motion pictures. Authors at the time were inspired by historical figures such as Davy Crockett and Daniel Boone. The mountaineer image transferred over to the 20th century where the "hillbilly" stereotype emerged.

Pop culture has perpetuated the "hillbilly" stereotype. Scholarly works suggest that the media has exploited both the Appalachian region and people by classifying them as "hillbillies". These generalizations do not match the cultural experiences of Appalachians. Appalachians, like many other groups, do not subscribe to a single identity. One of the issues associated with stereotyping is that it is profitable. When "hillbilly" became a widely used term, entrepreneurs saw a window for potential revenue. They "recycled" the image and brought it to life through various forms of media.

The comics portrayed hillbilly stereotypes, notably in two strips, "Li'l Abner" and "Snuffy Smith". Both characters were introduced in 1934. Television and film have portrayed "hillbillies" in both derogatory and sympathetic terms. Films such as "Sergeant York" or the Ma and Pa Kettle series portrayed the "hillbilly" as wild but good-natured. Television programs of the 1960s such as "The Real McCoys", "The Andy Griffith Show", and especially "The Beverly Hillbillies", portrayed the "hillbilly" as backwards but with enough wisdom to outwit more sophisticated city folk. "Gunsmoke" Festus Haggen was portrayed as intelligent and quick-witted (but lacking "education"). The popular 1970s television variety show "Hee Haw" regularly lampooned the stereotypical "hillbilly" lifestyle. A darker image of the hillbilly was introduced to another generation in the film "Deliverance" (1972), based on a novel of the same name by James Dickey, which depicted some "hillbillies" as genetically deficient, inbred, and murderous. Similar "evil hillbilly people"-type have also been seen in a more comical light in the 1988 horror film "The Moonlight Sonata", but the 2010 horror comedy film "Tucker & Dale vs. Evil" even parodies hillbilly steteotyping.

"Hillbillies" were at the center of reality television in the 21st century. Network television shows such as "New Beverly Hillbillies", "High Life", and "The Simple Life" displayed the "hillbilly" lifestyle for viewers in the United States. This sparked protests across the country with rural-minded individuals gathering to fight the stereotype. The Center for Rural Strategies started a nationwide campaign stating the stereotype was "politically incorrect". The Kentucky-based organization engaged political figures in the movement such as Robert Byrd and Mike Huckabee. Both protestors argued that the discrimination of any other group in United States would not be tolerated, so neither should the discrimination against rural U.S. citizens. A 2003 piece published by "The Cincinnati Enquirer" read, "In this day of hypersensitivity to diversity and political correctness, Appalachians have been a group that it is still socially acceptable to demean and joke about. ... But rural folks have spoken up and said 'enough' to the Hollywood mockers."

"" (2016) is a memoir by J. D. Vance about the Appalachian values of his upbringing and their relationship to the social problems of his hometown, Middletown, Ohio. The book topped "The New York Times" Best Seller list in August 2016.

A family of "Hill People", who are employed as migrant workers on a farm in 1952 Arkansas, have a major role in John Grisham's book "A Painted House", with Grisham trying to avoid stereotypes.

"Hillbilly music" was at one time considered an acceptable label for what is now known as country music. The label, coined in 1925 by country pianist Al Hopkins, persisted until the 1950s.

The "hillbilly music" categorization covers a wide variety of musical genres including bluegrass, country, western, and gospel. Appalachian folk song existed long before the "hillbilly" label. When the commercial industry was combined with "traditional Appalachian folksong", "hillbilly music" was formed. Some argue this is a "High Culture" issue where sophisticated individuals may see something considered "unsophisticated" as "trash".

In the early-20th century, artists began to utilize the "hillbilly" label. The term gained momentum due to Ralph Peer, the recording director of OKeh Records, who heard it being used among Southerners when he went down to Virginia to record the music and labeled all Southern country music as so from then on. The York Brothers entitled one of their songs "Hillbilly Rose" and the Delmore Brothers followed with their song "Hillbilly Boogie". In 1927, the Gennett studios in Richmond, Indiana, made a recording of black fiddler Jim Booker. The recordings were labeled "made for Hillbilly" in the Gennett files and were marketed to a white audience. Columbia Records had much success with the "Hill Billies" featuring Al Hopkins and Fiddlin' Charlie Bowman.

By the late-1940s, radio stations started to use the "hillbilly music" label. Originally, "hillbilly" was used to describe fiddlers and string bands, but now it was used to describe traditional Appalachian music. Appalachians had never used this term to describe their own music. Popular songs whose style bore characteristics of both hillbilly and African American music were referred to as "hillbilly boogie" and "rockabilly". Elvis Presley was a prominent player of rockabilly and was known early in his career as the "Hillbilly Cat".

When the Country Music Association was founded in 1958, the term "hillbilly music" gradually fell out of use. The music industry merged hillbilly music, Western swing, and Cowboy music, to form the current category C&W, Country and Western.

Some artists (notably Hank Williams) and fans were offended by the "hillbilly music" label. While the term is not used as frequently today, it is still used on occasion to refer to old-time music or bluegrass. For example, WHRB broadcasts a popular weekly radio show entitled "Hillbilly at Harvard". The show is devoted to playing a mix of old-time music, bluegrass, and traditional country and western.

The hillbilly stereotype is considered to have had a traumatizing effect on some in the Appalachian region. Feelings of shame, self-hatred, and detachment are cited as a result of "culturally transmitted traumatic stress syndrome". Appalachian scholars say that the large-scale stereotyping has rewritten Appalachian history, making Appalachians feel particularly vulnerable. "Hillbilly" has now become part of Appalachian identity and some Appalachians feel they are constantly defending themselves against this image.

The stereotyping also has political implications for the region. There is a sense of "perceived history" that prevents many political issues from receiving adequate attention. Appalachians are often blamed for economic struggles. "Moonshiners, welfare cheats, and coal miners" are stereotypes stemming from the greater hillbilly stereotype in the region. This prejudice has been said to serve as a barrier for addressing some serious issues such as the economy and the environment.

Despite the political and social difficulties associated with stereotyping, Appalachians have organized to enact change. The War on Poverty is sometimes considered to be an example of one effort that allowed for Appalachian community organization. Grassroots movements, protests, and strikes are common in the area, though not always successful.

The Springfield, Missouri Chamber of Commerce once presented dignitaries visiting the city with an "Ozark Hillbilly Medallion" and a certificate proclaiming the honoree a "hillbilly of the Ozarks". On June 7, 1952, President Harry S. Truman received the medallion after a breakfast speech at the Shrine Mosque for the 35th Division Association. Other recipients included US Army generals Omar Bradley and Matthew Ridgway, J. C. Penney, Johnny Olson, and Ralph Story.

Hillbilly Days is an annual festival held in mid-April in Pikeville, Kentucky celebrating the best of Appalachian culture. The event began by local Shriners as a fundraiser to support the Shriners Children's Hospital. It has grown since its beginning in 1976 and now is the second largest festival held in the state of Kentucky. Artists and craftspeople showcase their talents and sell their works on display. Nationally renowned musicians as well as the best of the regional mountain musicians share six different stages located throughout the downtown area of Pikeville. Aspiring hillbillies from across the nation compete to come up with the wildest Hillbilly outfit. The event has earned its name as the Mardi Gras of the Mountains. Fans of "mountain music" come from around the United States to hear this annual concentrated gathering of talent. Some refer to this event as the equivalent of a "Woodstock" for mountain music.

The term "Hillbilly" is used with pride by a number of people within the region as well as famous persons, such as singer Dolly Parton, chef Sean Brock, and actress Minnie Pearl. Positive self-identification with the term generally includes identification with a set of "hillbilly values" including love and respect for nature, strong work ethic, generosity toward neighbors and those in need, family ties, self-reliance, resiliency, and a simple lifestyle.


African Banjo Echoes in Appalachia: A Study of Folk Tradition (1995), by Cecelia Conway


</doc>
<doc id="14012" url="https://en.wikipedia.org/wiki?curid=14012" title="Host">
Host

A host is a person responsible for guests at an event or for providing hospitality during it.

Host may also refer to:













</doc>
<doc id="14013" url="https://en.wikipedia.org/wiki?curid=14013" title="Hernán Cortés">
Hernán Cortés

Hernán Cortés de Monroy y Pizarro Altamirano, 1st Marquess of the Valley of Oaxaca (; ; 1485 – December 2, 1547) was a Spanish "Conquistador" who led an expedition that caused the fall of the Aztec Empire and brought large portions of what is now mainland Mexico under the rule of the King of Castile in the early 16th century. Cortés was part of the generation of Spanish explorers and conquistadors who began the first phase of the Spanish colonization of the Americas.

Born in Medellín, Spain, to a family of lesser nobility, Cortés chose to pursue adventure and riches in the New World. He went to Hispaniola and later to Cuba, where he received an "encomienda" (the right to the labor of certain subjects). For a short time, he served as "alcalde" (magistrate) of the second Spanish town founded on the island. In 1519, he was elected captain of the third expedition to the mainland, which he partly funded. His enmity with the Governor of Cuba, Diego Velázquez de Cuéllar, resulted in the recall of the expedition at the last moment, an order which Cortés ignored.

Arriving on the continent, Cortés executed a successful strategy of allying with some indigenous people against others. He also used a native woman, Doña Marina, as an interpreter. She later bore his first son. When the Governor of Cuba sent emissaries to arrest Cortés, he fought them and won, using the extra troops as reinforcements. Cortés wrote letters directly to the king asking to be acknowledged for his successes instead of being punished for mutiny. After he overthrew the Aztec Empire, Cortés was awarded the title of "Marqués del Valle de Oaxaca", while the more prestigious title of Viceroy was given to a high-ranking nobleman, Antonio de Mendoza. In 1541 Cortés returned to Spain, where he died six years later of natural causes.

Because of the controversial undertakings of Cortés and the scarcity of reliable sources of information about him, it is difficult to describe his personality or motivations. Early lionizing of the conquistadores did not encourage deep examination of Cortés. Modern reconsideration has done little to enlarge understanding regarding him. As a result of these historical trends, descriptions of Cortés tend to be simplistic, and either damning or idealizing.

Cortés himself used the form "Hernando" or "Fernando" for his first name, as seen in his signature and the title of an early portrait. William Hickling Prescott's "Conquest of Mexico" (1843) also refers to him as Hernando Cortés. At some point writers began using the shortened form of "Hernán" more generally.

Cortés was born in 1485 in the town of Medellín, then a village in the Kingdom of Castile, now a municipality of the modern-day province of Badajoz in Extremadura, Spain. His father, Martín Cortés de Monroy, born in 1449 to Rodrigo or Ruy Fernández de Monroy and his wife María Cortés, was an infantry captain of distinguished ancestry but slender means. Hernán's mother was Catalína Pizarro Altamirano.

Through his mother, Hernán was second cousin once removed of Francisco Pizarro, who later conquered the Inca Empire of modern-day Peru, and not to be confused with another Francisco Pizarro, who joined Cortés to conquer the Aztecs. (His maternal grandmother, Leonor Sánchez Pizarro Altamirano, was first cousin of Pizarro's father Gonzalo Pizarro y Rodriguez.) Through his father, Hernán was related to Nicolás de Ovando, the third Governor of Hispaniola. His paternal great-grandfather was Rodrigo de Monroy y Almaraz, 5th Lord of Monroy.

According to his biographer, chaplain, and friend Francisco López de Gómara, Cortés was pale and sickly as a child. At the age of 14, he was sent to study Latin under an uncle in Salamanca. Modern historians have misconstrued this personal tutoring as time enrolled at the University of Salamanca.

After two years, Cortés returned home to Medellín, much to the irritation of his parents, who had hoped to see him equipped for a profitable legal career. However, those two years in Salamanca, plus his long period of training and experience as a notary, first in Valladolid and later in Hispaniola, gave him knowledge of the legal codes of Castile that he applied to help justify his unauthorized conquest of Mexico.

At this point in his life, Cortés was described by Gómara as ruthless, haughty, and mischievous. The 16-year-old youth had returned home to feel constrained life in his small provincial town. By this time, news of the exciting discoveries of Christopher Columbus in the New World was streaming back to Spain.

Plans were made for Cortés to sail to the Americas with a family acquaintance and distant relative, Nicolás de Ovando, the newly appointed Governor of Hispaniola. (This island is now divided between Haiti and the Dominican Republic). Cortés suffered an injury and was prevented from traveling. He spent the next year wandering the country, probably spending most of his time in Spain's southern ports of Cadiz, Palos, Sanlucar, and Seville. He finally left for Hispaniola in 1504 and became a colonist.

Cortés reached Hispaniola in a ship commanded by Alonso Quintero, who tried to deceive his superiors and reach the New World before them in order to secure personal advantages. Quintero's mutinous conduct may have served as a model for Cortés in his subsequent career. The history of the conquistadores is rife with accounts of rivalry, jockeying for positions, mutiny, and betrayal.

Upon his arrival in 1504 in Santo Domingo, the capital of Hispaniola, the 18-year-old Cortés registered as a citizen; this entitled him to a building plot and land to farm. Soon afterward, Governor Nicolás de Ovando granted him an "encomienda" and appointed him as a notary of the town of Azua de Compostela. His next five years seemed to help establish him in the colony; in 1506, Cortés took part in the conquest of Hispaniola and Cuba. The expedition leader awarded him a large estate of land and Indian slaves for his efforts.

In 1511, Cortés accompanied Diego Velázquez de Cuéllar, an aide of the Governor of Hispaniola, in his expedition to conquer Cuba. Velázquez was appointed Governor of New Spain. At the age of 26, Cortés was made clerk to the treasurer with the responsibility of ensuring that the Crown received the "quinto", or customary one fifth of the profits from the expedition.

Velázquez was so impressed with Cortés that he secured a high political position for him in the colony. He became secretary for Governor Velázquez. Cortés was twice appointed municipal magistrate ("alcalde") of Santiago. In Cuba, Cortés became a man of substance with an "encomienda" to provide Indian labor for his mines and cattle. This new position of power also made him the new source of leadership, which opposing forces in the colony could then turn to. In 1514, Cortés led a group which demanded that more Indians be assigned to the settlers.

As time went on, relations between Cortés and Governor Velázquez became strained. This began once news reached Velázquez that Juan de Grijalva had established a colony on the mainland where there was a bonanza of silver and gold, and Velázquez decided to send him help. Cortés was appointed Captain-General of this new expedition in October 1518, but was advised to move fast before Velázquez changed his mind.

With Cortés' experience as an administrator, knowledge gained from many failed expeditions, and his impeccable rhetoric he was able to gather six ships and 300 men, within a month. Velázquez's jealousy exploded and he decided to put the expedition in other hands. However, Cortés quickly gathered more men and ships in other Cuban ports.

Cortés also found time to become romantically involved with Catalina Xuárez (or Juárez), the sister-in-law of Governor Velázquez. Part of Velázquez's displeasure seems to have been based on a belief that Cortés was trifling with Catalina's affections. Cortés was temporarily distracted by one of Catalina's sisters but finally married Catalina, reluctantly, under pressure from Governor Velázquez. However, by doing so, he hoped to secure the good will of both her family and that of Velázquez.

It was not until he had been almost 15 years in the Indies that Cortés began to look beyond his substantial status as mayor of the capital of Cuba and as a man of affairs in the thriving colony. He missed the first two expeditions, under the orders of Francisco Hernández de Córdoba and then Juan de Grijalva, sent by Diego Velázquez to Mexico in 1518.

In 1518, Velázquez put Cortés in command of an expedition to explore and secure the interior of Mexico for colonization. At the last minute, due to the old argument between the two, Velázquez changed his mind and revoked Cortés's charter. He ignored the orders and, in an act of open mutiny, went anyway in February 1519. He stopped in Trinidad, Cuba, to hire more soldiers and obtain more horses. Accompanied by about 11 ships, 500 men (including seasoned slaves), 13 horses, and a small number of cannons, Cortés landed on the Yucatán Peninsula in Mayan territory. There he encountered Geronimo de Aguilar, a Spanish Franciscan priest who had survived a shipwreck followed by a period in captivity with the Maya, before escaping. Aguilar had learned the Chontal Maya language and was able to translate for Cortés.

In March 1519, Cortés formally claimed the land for the Spanish crown. Then he proceeded to Tabasco, where he met with resistance and won a battle against the natives. He received twenty young indigenous women from the vanquished natives, and he converted them all to Christianity.

Among these women was La Malinche, his future mistress and mother of his son Martín. Malinche knew both the Nahuatl language and Chontal Maya, thus enabling Cortés to communicate with the Aztecs through Aguilar. At San Juan de Ulúa on Easter Sunday 1519, Cortés met with Moctezuma II's Aztec Empire governors Tendile and Pitalpitoque.
In July 1519, his men took over Veracruz. By this act, Cortés dismissed the authority of the Governor of Cuba to place himself directly under the orders of King Charles. In order to eliminate any ideas of retreat, Cortés scuttled his ships.

In Veracruz, he met some of the tributaries of the Aztecs and asked them to arrange a meeting with Moctezuma II, the "tlatoani" (ruler) of the Aztec Empire. Moctezuma repeatedly turned down the meeting, but Cortés was determined. Leaving a hundred men in Veracruz, Cortés marched on Tenochtitlán in mid-August 1519, along with 600 soldiers, 15 horsemen, 15 cannons, and hundreds of indigenous carriers and warriors.

On the way to Tenochtitlán, Cortés made alliances with indigenous peoples such as the Totonacs of Cempoala and the Nahuas of Tlaxcala. The Otomis initially, and then the Tlaxcalans fought with the Spanish in a series of three battles from 2 to 5 September 1519, and at one point, Diaz remarked, "they surrounded us on every side". After Cortés continued to release prisoners with messages of peace, and realizing the Spanish were enemies of Moctezuma, Xicotencatl the Elder and Maxixcatzin persuaded the Tlaxcalan warleader, Xicotencatl the Younger, that it would be better to ally with the newcomers than to kill them.

In October 1519, Cortés and his men, accompanied by about 1,000 Tlaxcalteca, marched to Cholula, the second largest city in central Mexico. Cortés, either in a pre-meditated effort to instill fear upon the Aztecs waiting for him at Tenochtitlan or (as he later claimed, when he was being investigated) wishing to make an example when he feared native treachery, massacred thousands of unarmed members of the nobility gathered at the central plaza, then partially burned the city.
By the time he arrived in Tenochtitlán the Spaniards had a large army. On November 8, 1519, they were peacefully received by Moctezuma II. Moctezuma deliberately let Cortés enter the Aztec capital, the island city of Tenochtitlán, hoping to get to know their weaknesses better and to crush them later.

Moctezuma gave lavish gifts of gold to the Spaniards which, rather than placating them, excited their ambitions for plunder. In his letters to King Charles, Cortés claimed to have learned at this point that he was considered by the Aztecs to be either an emissary of the feathered serpent god Quetzalcoatl or Quetzalcoatl himself – a belief which has been contested by a few modern historians. But quickly Cortés learned that several Spaniards on the coast had been killed by Aztecs while supporting the Totonacs, and decided to take Moctezuma as a hostage in his own palace, indirectly ruling Tenochtitlán through him.
Meanwhile, Velázquez sent another expedition, led by Pánfilo de Narváez, to oppose Cortés, arriving in Mexico in April 1520 with 1,100 men. Cortés left 200 men in Tenochtitlán and took the rest to confront Narváez. He overcame Narváez, despite his numerical inferiority, and convinced the rest of Narváez's men to join him. In Mexico, one of Cortés's lieutenants Pedro de Alvarado, committed the "massacre in the Great Temple", triggering a local rebellion.

Cortés speedily returned to Tenochtitlán. On July 1, 1520 Moctezuma was killed (the Spaniards claimed he was stoned to death by his own people; others claim he was murdered by the Spanish once they realized his inability to placate the locals). Faced with a hostile population, Cortés decided to flee for Tlaxcala. During the "Noche Triste" (June 30 – July 1, 1520), the Spaniards managed a narrow escape from Tenochtitlán across the Tlacopan causeway, while their rearguard was being massacred. Much of the treasure looted by Cortés was lost (as well as his artillery) during this panicked escape from Tenochtitlán.

After a battle in Otumba, they managed to reach Tlaxcala, having lost 870 men. With the assistance of their allies, Cortés's men finally prevailed with reinforcements arriving from Cuba. Cortés began a policy of attrition towards Tenochtitlán, cutting off supplies and subduing the Aztecs' allied cities. The siege of Tenochtitlán ended with Spanish victory and the destruction of the city.

In January 1521, Cortés countered a conspiracy against him, headed by Antonio de Villafana, who was hanged for the offense. Finally, with the capture of Cuauhtémoc, the "tlatoani" (ruler) of Tenochtitlán, on August 13, 1521, the Aztec Empire was captured, and Cortés was able to claim it for Spain, thus renaming the city Mexico City. From 1521 to 1524, Cortés personally governed Mexico.

Many historical sources have conveyed an impression that Cortés was unjustly treated by the Spanish Crown, and that he received nothing but ingratitude for his role in establishing New Spain. This picture is the one Cortés presents in his letters and in the later biography written by Francisco López de Gómara. However, there may be more to the picture than this. Cortés's own sense of accomplishment, entitlement, and vanity may have played a part in his deteriorating position with the king:

King Charles appointed Cortés as governor, captain general and chief justice of the newly conquered territory, dubbed "New Spain of the Ocean Sea". But also, much to the dismay of Cortés, four royal officials were appointed at the same time to assist him in his governing – in effect, submitting him to close observation and administration. Cortés initiated the construction of Mexico City, destroying Aztec temples and buildings and then rebuilding on the Aztec ruins what soon became the most important European city in the Americas.

Cortés managed the founding of new cities and appointed men to extend Spanish rule to all of New Spain, imposing the "encomienda" system in 1524. He reserved many encomiendas for himself and for his retinue, which they considered just rewards for their accomplishment in conquering central Mexico. However, later arrivals and members of factions antipathetic to Cortés complained of the favoritism that excluded them.

In 1523, the Crown (possibly influenced by Cortés's enemy, Bishop Fonseca), sent a military force under the command of Francisco de Garay to conquer and settle the northern part of Mexico, the region of Pánuco. This was another setback for Cortés who mentioned this in his fourth letter to the King in which he describes himself as the victim of a conspiracy by his archenemies Diego Velázquez de Cuéllar, Diego Columbus and Bishop Fonseca as well as Francisco Garay. The influence of Garay was effectively stopped by this appeal to the King who sent out a decree forbidding Garay to interfere in the politics of New Spain, causing him to give up without a fight.

Although Cortés had flouted the authority of Diego Velázquez in sailing to the mainland and then leading an expedition of conquest, Cortés's spectacular success was rewarded by the crown with a coat of arms, a mark of high honor, following the conqueror's request. The document granting the coat of arms summarizes Cortés's accomplishments in the conquest of Mexico. The proclamation of the king says in part:

We, respecting the many labors, dangers, and adventures which you underwent as stated above, and so that there might remain a perpetual memorial of you and your services and that you and your descendants might be more fully honored ... it is our will that besides your coat of arms of your lineage, which you have, you may have and bear as your coat of arms, known and recognized, a shield ...

The grant specifies the iconography of the coat of arms, the central portion divided into quadrants. In the upper portion, there is a "black eagle with two heads on a white field, which are the arms of the empire". Below that is a "golden lion on a red field, in memory of the fact that you, the said Hernando Cortés, by your industry and effort brought matters to the state described above" (i.e., the conquest). The specificity of the other two quadrants is linked directly to Mexico, with one quadrant showing three crowns representing the three Aztec emperors of the conquest era, Moctezuma, Cuitlahuac, and Cuauhtemoc and the other showing the Aztec capital of Tenochtitlan. Encircling the central shield are symbols of the seven city-states around the lake and their lords that Cortés defeated, with the lords "to be shown as prisoners bound with a chain which shall be closed with a lock beneath the shield".

Cortés's wife Catalina Súarez arrived in New Spain around summer 1522, along with her sister and brother. His marriage to Catalina was at this point extremely awkward, since she was a kinswoman of the governor of Cuba, Diego Velázquez, whose authority Cortés had thrown off and who was therefore now his enemy. Catalina lacked the noble title of "doña," so at this point his marriage with her no longer raised his status. Their marriage had been childless. Since Cortés had sired children with a variety of indigenous women, including a son around 1522 by his cultural translator, Doña Marina, Cortés knew he was capable of fathering children. Cortés's only male heir at this point was illegitimate, but nonetheless named after Cortés's father, Martín Cortés. This son Martín Cortés was sometimes called "El Mestizo".

Catalina Suárez died under mysterious circumstances the night of November 1–2, 1522. There were accusations at the time that Cortés had murdered his wife. There was an investigation into her death, interviewing a variety of household residents and others. The documentation of the investigation was published in the nineteenth century in Mexico and these archival documents were uncovered in the twentieth century. The death of Catalina Suárez produced a scandal and investigation, but Cortés was now free to marry someone of high status more appropriate to his wealth and power. In 1526, he built an imposing residence for himself, the Palace of Cortés in Cuernavaca, in a region close to the capital where he had extensive encomienda holdings. In 1529 he had been accorded the noble designation of "don", but more importantly was given the noble title of Marquess of the Valley of Oaxaca and married the Spanish noblewoman Doña Juana de Zúñiga. The marriage produced three children, including another son, who was also named Martín. As the first-born legitimate son, Don Martín Cortés y Zúñiga was now Cortés's heir and succeeded him as holder of the title and estate of the Marquessate of the Valley of Oaxaca. Cortés's legitimate daughters were Doña Maria, Doña Catalina, and Doña Juana.

Since the conversion to Christianity of indigenous peoples was an essential and integral part of the extension of Spanish power, making formal provisions for that conversion once the military conquest was completed was an important task for Cortés. During the Age of Discovery, the Catholic Church had seen early attempts at conversion in the Caribbean islands by Spanish friars, particularly the mendicant orders. Cortés made a request to the Spanish monarch to send Franciscan and Dominican friars to Mexico to convert the vast indigenous populations to Christianity. In his fourth letter to the king, Cortés pleaded for friars rather than diocesan or secular priests because those clerics were in his view a serious danger to the Indians' conversion.

If these people [Indians] were now to see the affairs of the Church and the service of God in the hands of canons or other dignitaries, and saw them indulge in the vices and profanities now common in Spain, knowing that such men were the ministers of God, it would bring our Faith into much harm that I believe any further preaching would be of no avail.

He wished the mendicants to be the main evangelists. Mendicant friars did not usually have full priestly powers to perform all the sacraments needed for conversion of the Indians and growth of the neophytes in the Christian faith, so Cortés laid out a solution to this to the king.

Your Majesty should likewise beseech His Holiness [the pope] to grant these powers to the two principal persons in the religious orders that are to come here, and that they should be his delegates, one from the Order of St. Francis and the other from the Order of St. Dominic. They should bring the most extensive powers Your Majesty is able to obtain, for, because these lands are so far from the Church of Rome, and we, the Christians who now reside here and shall do so in the future, are so far from the proper remedies of our consciences and, as we are human, so subject to sin, it is essential that His Holiness should be generous with us and grant to these persons most extensive powers, to be handed down to persons actually in residence here whether it be given to the general of each order or to his provincials.

The Franciscans arrived in May 1524, a symbolically powerful group of twelve known as the Twelve Apostles of Mexico, led by Fray Martín de Valencia. Franciscan Geronimo de Mendieta claimed that Cortés's most important deed was the way he met this first group of Franciscans. The conqueror himself was said to have met the friars as they approached the capital, kneeling at the feet of the friars who had walked from the coast. This story was told by Franciscans to demonstrate Cortés piety and humility and was a powerful message to all, including the Indians, that Cortés's earthly power was subordinate to the spiritual power of the friars. However, one of the first twelve Franciscans, Fray Toribio de Benavente Motolinia does not mention it in his history. Cortés and the Franciscans had a particularly strong alliance in Mexico, with Franciscans seeing him as "the new Moses" for conquering Mexico and opening it to Christian evangelization. In Motolinia's 1555 response to Dominican Bartolomé de Las Casas, he praises Cortés.

And as to those who murmur against the Marqués del Valle [Cortés], God rest him, and who try to blacken and obscure his deeds, I believe that before God their deeds are not as acceptable as those of the Marqués. Although as a human he was a sinner, he had faith and works of a good Christian, and a great desire to employ his life and property in widening and augmenting the fair of Jesus Christ, and dying for the conversion of these gentiles ... Who has loved and defended the Indians of this new world like Cortés? ... Through this captain, God opened the door for us to preach his holy gospel and it was he who caused the Indians to revere the holy sacraments and respect the ministers of the church.

In Fray Bernardino de Sahagún's 1585 revision of the conquest narrative first codified as Book XII of the Florentine Codex, there are laudatory references to Cortés that do not appear in the earlier text from the indigenous perspective. Whereas Book XII of the Florentine Codex concludes with an account of Spaniards' search for gold, in Sahagún's 1585 revised account, he ends with praise of Cortés for requesting the Franciscans be sent to Mexico to convert the Indians.

From 1524 to 1526, Cortés headed an expedition to Honduras where he defeated Cristóbal de Olid, who had claimed Honduras as his own under the influence of the Governor of Cuba Diego Velázquez. Fearing that Cuauhtémoc might head an insurrection in Mexico, he brought him with him to Honduras. In a controversial move, Cuauhtémoc was executed during the journey. Raging over Olid's treason, Cortés issued a decree to arrest Velázquez, whom he was sure was behind Olid's treason. This, however, only served to further estrange the Crown of Castile and the Council of Indies, both of which were already beginning to feel anxious about Cortés's rising power.
Cortés's fifth letter to King Charles attempts to justify his conduct, concludes with a bitter attack on "various and powerful rivals and enemies" who have "obscured the eyes of your Majesty". Charles, who was also Holy Roman Emperor, had little time for distant colonies (much of Charles's reign was taken up with wars with France, the German Protestants and the expanding Ottoman Empire), except insofar as they contributed to finance his wars. In 1521, year of the Conquest, Charles was attending to matters in his German domains and Bishop Adrian of Utrecht functioned as regent in Spain.

Velázquez and Fonseca persuaded the regent to appoint a commissioner (a "Juez de residencia", Luis Ponce de León) with powers to investigate Cortés's conduct and even arrest him. Cortés was once quoted as saying that it was "more difficult to contend against [his] own countrymen than against the Aztecs." Governor Diego Velázquez continued to be a thorn in his side, teaming up with Bishop Juan Rodríguez de Fonseca, chief of the Spanish colonial department, to undermine him in the Council of the Indies.

A few days after Cortés's return from his expedition, Ponce de León suspended Cortés from his office of governor of New Spain. The Licentiate then fell ill and died shortly after his arrival, appointing Marcos de Aguilar as "alcalde mayor". The aged Aguilar also became sick and appointed Alonso de Estrada governor, who was confirmed in his functions by a royal decree in August 1527. Cortés, suspected of poisoning them, refrained from taking over the government.

Estrada sent Diego de Figueroa to the south. De Figueroa raided graveyards and extorted contributions, meeting his end when the ship carrying these treasures sank. Albornoz persuaded Alonso de Estrada to release Gonzalo de Salazar and Chirinos. When Cortés complained angrily after one of his adherents' hands was cut off, Estrada ordered him exiled. Cortés sailed for Spain in 1528 to appeal to King Charles.

In 1528, Cortés returned to Spain to appeal to the justice of his master, Charles V. Juan Altamirano and Alonso Valiente stayed in Mexico and acted as Cortés' representatives during his absence. Cortés presented himself with great splendor before Charles V's court. By this time Charles had returned and Cortés forthrightly responded to his enemy's charges. Denying he had held back on gold due the crown, he showed that he had contributed more than the quinto (one-fifth) required. Indeed, he had spent lavishly to build the new capital of Mexico City on the ruins of the Aztec capital of Tenochtitlán, leveled during the siege that brought down the Aztec empire.

He was received by Charles with every distinction, and decorated with the order of Santiago. In return for his efforts in expanding the still young Spanish Empire, Cortés was rewarded in 1529 by being accorded the noble title of "don" but more importantly named the ""Marqués del Valle de Oaxaca"" (Marquess of the Valley of Oaxaca and married the Spanish noblewoman Doña Juana Zúñiga, after the 1522 death of his much less distinguished first wife, Catalina Suárez. The noble title and senorial estate of the Marquesado was passed down to his descendants until 1811. The Oaxaca Valley was one of the wealthiest regions of New Spain, and Cortés had 23,000 vassals in 23 named encomiendas in perpetuity.

Although confirmed in his land holdings and vassals, he was not reinstated as governor and was never again given any important office in the administration of New Spain. During his travel to Spain, his property was mismanaged by abusive colonial administrators. He sided with local natives in a lawsuit. The natives documented the abuses in the Huexotzinco Codex.

The entailed estate and title passed to his legitimate son Don Martín Cortés upon Cortés's death in 1547, who became the Second Marquess. Don Martín's association with the so-called Encomenderos' Conspiracy endangered the entailed holdings, but they were restored and remained the continuing reward for Hernán Cortés's family through the generations.

Cortés returned to Mexico in 1530 with new titles and honors, but with diminished power. Although Cortés still retained military authority and permission to continue his conquests, viceroy Don Antonio de Mendoza was appointed in 1535 to administer New Spain's civil affairs. This division of power led to continual dissension, and caused the failure of several enterprises in which Cortés was engaged. On returning to Mexico, Cortés found the country in a state of anarchy. There was a strong suspicion in court circles of an intended rebellion by Cortés.

After reasserting his position and reestablishing some sort of order, Cortés retired to his estates at Cuernavaca, about 30 miles (48 km) south of Mexico City. There he concentrated on the building of his palace and on Pacific exploration. Remaining in Mexico between 1530 and 1541, Cortés quarreled with Nuño Beltrán de Guzmán and disputed the right to explore the territory that is today California with Antonio de Mendoza, the first viceroy.

Cortés acquired several silver mines in Zumpango del Rio in 1534. By the early 1540s, he owned 20 silver mines in Sultepec, 12 in Taxco, and 3 in Zacualpan. Earlier, Cortés had claimed the silver in the Tamazula area.

In 1536, Cortés explored the northwestern part of Mexico and discovered the Baja California Peninsula. Cortés also spent time exploring the Pacific coast of Mexico. The Gulf of California was originally named the "Sea of Cortés" by its discoverer Francisco de Ulloa in 1539. This was the last major expedition by Cortés.

After his exploration of Baja California, Cortés returned to Spain in 1541, hoping to confound his angry civilians, who had brought many lawsuits against him (for debts, abuse of power, etc.).

On his return he went through a crowd to speak to the emperor, who demanded of him who he was. "I am a man," replied Cortés, "who has given you more provinces than your ancestors left you cities."

The emperor finally permitted Cortés to join him and his fleet commanded by Andrea Doria at the great expedition against Algiers in the Barbary Coast in 1541, which was then part of the Ottoman Empire and was used as a base by Hayreddin Barbarossa, a famous Turkish corsair and Admiral-in-Chief of the Ottoman Fleet. During this campaign, Cortés was almost drowned in a storm that hit his fleet while he was pursuing Barbarossa.

Having spent a great deal of his own money to finance expeditions, he was now heavily in debt. In February 1544 he made a claim on the royal treasury, but was ignored for the next three years. Disgusted, he decided to return to Mexico in 1547. When he reached Seville, he was stricken with dysentery. He died in Castilleja de la Cuesta, Seville province, on December 2, 1547, from a case of pleurisy at the age of 62.

He left his many mestizo and white children well cared for in his will, along with every one of their mothers. He requested in his will that his remains eventually be buried in Mexico. Before he died he had the Pope remove the "natural" status of four of his children (legitimizing them in the eyes of the church), including Martin, the son he had with Doña Marina (also known as La Malinche), said to be his favourite. His daughter, Doña Catalina, however, died shortly after her father's death.

After his death, his body was moved more than eight times for several reasons. On December 4, 1547 he was buried in the mausoleum of the Duke of Medina in the church of San Isidoro del Campo, Sevilla. Three years later (1550) due to the space being required by the duke, his body was moved to the altar of Santa Catarina in the same church. In his testament, Cortés asked for his body to be buried in the monastery he had ordered to be built in Coyoacan in México, ten years after his death, but the monastery was never built. So in 1566, his body was sent to New Spain and buried in the church of San Francisco de Texcoco, where his mother and one of his sisters were buried.

In 1629, "Don Pedro Cortés fourth "Marquez del Valle", his last male descendant, died, so the viceroy decided to move the bones of Cortés along with those of his descendant to the Franciscan church in México. This was delayed for nine years, while his body stayed in the main room of the palace of the viceroy. Eventually it was moved to the Sagrario of Franciscan church, where it stayed for 87 years. In 1716, it was moved to another place in the same church. In 1794, his bones were moved to the "Hospital de Jesus" (founded by Cortés), where a statue by Tolsá and a mausoleum were made. There was a public ceremony and all the churches in the city rang their bells.

In 1823, after the independence of México, it seemed imminent that his body would be desecrated, so the mausoleum was removed, the statue and the coat of arms were sent to Palermo, Sicily, to be protected by the Duke of Terranova. The bones were hidden, and everyone thought that they had been sent out of México. In 1836, his bones were moved to another place in the same building.

It was not until November 24, 1946 that they were rediscovered, thanks to the discovery of a secret document by Lucas Alamán. His bones were put in the charge of the Instituto Nacional de Antropología e Historia (INAH). The remains were authenticated by INAH. They were then restored to the same place, this time with a bronze inscription and his coat of arms. When the bones were first rediscovered, the supporters of the Hispanic tradition in Mexico were excited, but one supporter of an indigenist vision of Mexico "proposed that the remains be publicly burned in front of the statue of Cuauhtemoc, and the ashes flung into the air". Following the discovery and authentication of Cortés's remains, there was a discovery of what were described as the bones of Cuauhtémoc, resulting in a "battle of the bones".

Cortés is commemorated in the scientific name of a subspecies of Mexican lizard, "Phrynosoma orbiculare cortezii".

There are relatively few sources to the early life of Cortés; his fame arose from his participation in the conquest of Mexico and it was only after this that people became interested in reading and writing about him.

Probably the best source is his letters to the king which he wrote during the campaign in Mexico, but they are written with the specific purpose of putting his efforts in a favourable light and so must be read critically. Another main source is the biography written by Cortés's private chaplain Lopez de Gómara, which was written in Spain several years after the conquest. Gómara never set foot in the Americas and knew only what Cortés had told him, and he had an affinity for knightly romantic stories which he incorporated richly in the biography. The third major source is written as a reaction to what its author calls "the lies of Gomara", the eyewitness account written by the Conquistador Bernal Díaz del Castillo does not paint Cortés as a romantic hero but rather tries to emphasize that Cortés's men should also be remembered as important participants in the undertakings in Mexico.

In the years following the conquest more critical accounts of the Spanish arrival in Mexico were written. The Dominican friar Bartolomé de Las Casas wrote his "A Short Account of the Destruction of the Indies" which raises strong accusations of brutality and heinous violence towards the Indians; accusations against both the conquistadors in general and Cortés in particular. The accounts of the conquest given in the Florentine Codex by the Franciscan Bernardino de Sahagún and his native informants are also less than flattering towards Cortés. The scarcity of these sources has led to a sharp division in the description of Cortés's personality and a tendency to describe him as either a vicious and ruthless person or a noble and honorable cavalier.

In México there are few representations of Cortés. However, many landmarks still bear his name, from the castle Palacio de Cortés in the city of Cuernavaca to some street names throughout the republic.

The pass between the volcanoes Iztaccíhuatl and Popocatépetl where Cortés took his soldiers on their march to Mexico City. It is known as the Paso de Cortés.

The muralist Diego Rivera painted several representation of him but the most famous, depicts him as a powerful and ominous figure along with Malinche in a mural in the National Palace in Mexico City.
In 1981, President Lopez Portillo tried to bring Cortés to public recognition. First, he made public a copy of the bust of Cortés made by Manuel Tolsá in the Hospital de Jesús Nazareno with an official ceremony, but soon a nationalist group tried to destroy it, so it had to be taken out of the public. Today the copy of the bust is in the "Hospital de Jesús Nazareno" while the original is in Naples, Italy, in the Villa Pignatelli.

Later, another monument, known as "Monumento al Mestizaje" by Julián Martínez y M. Maldonado (1982) was commissioned by Mexican president José López Portillo to be put in the "Zócalo" (Main square) of Coyoacan, near the place of his country house, but it had to be removed to a little known park, the Jardín Xicoténcatl, Barrio de San Diego Churubusco, to quell protests. The statue depicts Cortés, Malinche and their son Martín.

There is another statue by Sebastián Aparicio, in Cuernavaca, was in a hotel "El casino de la selva". Cortés is barely recognizable, so it sparked little interest. The hotel was closed to make a commercial center, and the statue was put out of public display by Costco the builder of the commercial center.

Hernán Cortés is a character in the opera "La Conquista" (2005) by Italian composer Lorenzo Ferrero, which depicts the major episodes of the Spanish conquest of the Aztec Empire in 1521.

Cortés' personal account of the conquest of Mexico is narrated in his five letters addressed to Charles V. These five letters, the "cartas de relación", are Cortés' only surviving writings. See "Letters and Dispatches of Cortés", translated by George Folsom (New York, 1843); Prescott's "Conquest of Mexico" (Boston, 1843); and Sir Arthur Helps's "Life of Hernando Cortes" (London, 1871).

His first letter was considered lost, and the one from the municipality of Veracruz has to take its place. It was published for the first time in volume IV of "Documentos para la Historia de España", and subsequently reprinted. 

The "Segunda Carta de Relacion", bearing the date of October 30, 1520, appeared in print at Seville in 1522. The third letter, dated May 15, 1522, appeared at Seville in 1523. The fourth, October 20, 1524, was printed at Toledo in 1525. The fifth, on the Honduras expedition, is contained in volume IV of the "Documentos para la Historia de España".

Natural children of Don Hernán Cortés

He married twice: firstly in Cuba to Catalina Suárez Marcaida, who died at Coyoacán in 1522 without issue, and secondly in 1529 to "doña" Juana Ramírez de Arellano de Zúñiga, daughter of "don" Carlos Ramírez de Arellano, 2nd Count of Aguilar and wife the Countess "doña" Juana de Zúñiga, and had:





</doc>
<doc id="14015" url="https://en.wikipedia.org/wiki?curid=14015" title="Herstory">
Herstory

Herstory is a term for history written from a feminist perspective, emphasizing the role of women, or told from a woman's point of view. It originated as an alteration of the word "history", as part of a feminist critique of conventional historiography, which in their opinion is traditionally written as "his story," i.e., from the male point of view. (The word "history"—from the Ancient Greek ἱστορία, or "historia", meaning "knowledge obtained by inquiry"—is etymologically unrelated to the possessive pronoun "his".)

The "Oxford English Dictionary" credits Robin Morgan with first using the term "herstory" in print in her 1970 anthology "Sisterhood is Powerful". Concerning the feminist organization W.I.T.C.H., Morgan wrote:

During the 1970s and 1980s, second-wave feminists saw the study of history as a male-dominated intellectual enterprise and presented "herstory" as a means of compensation. The term, intended to be both serious and comic, became a rallying cry used on T-shirts and buttons as well as in academia.

In 2017, Hridith Sudev, an inventor, environmentalist and social activist associated with various youth movements, launched 'The Herstory Movement,' an online platform to "celebrate lesser known great persons; female, queer or otherwise marginalized, who helped shape the modern World History." It is intended as an academic platform to feature stories of female historic persons and thus help facilitate more widespread knowledge about 'Great Women' History.

Non-profit organizations Global G.L.O.W and LitWorld created a joint initiative called the "HerStory Campaign." This campaign works with 25 other countries to share girl's lives and stories. They encourage others to join the campaign and to 'raise our voices on behalf of all world's girls.'

The herstory movement has spawned women-centered presses, such as Virago Press in 1973, which publishes fiction and non-fiction by noted women authors like Janet Frame and Sarah Dunant.

This movement has led to an increase in activity in other female-centric disciplines such as "femistry" and "galgebra".

it's hi-story, not his-story. It's spelled history, not hisstory... 

Christina Hoff Sommers has been a vocal critic of the concept of herstory, and presented her argument against the movement in her 1994 book "Who Stole Feminism?" Sommers defined herstory as an attempt to infuse education with ideology at the expense of knowledge. The "gender feminists," as she called them, were the group of feminists responsible for the movement, which she felt amounted to negationism. She regarded most attempts to make historical studies more female-inclusive as being artificial in nature and an impediment to progress.

Professor and author Devoney Looser has criticized the concept of herstory for overlooking the contributions that some women made as historians before the twentieth century.

The Global Language Monitor, a nonprofit group that analyzes and tracks trends in language, named "herstory" the third most "politically incorrect" word of 2006—rivaled only by ""macaca"" and ""Global Warming Denier.""

Books published on the topic include:



</doc>
<doc id="14017" url="https://en.wikipedia.org/wiki?curid=14017" title="House of Cards (British TV series)">
House of Cards (British TV series)

House of Cards is a 1990 British political thriller television serial in four episodes, set after the end of Margaret Thatcher's tenure as Prime Minister of the United Kingdom. It was televised by the BBC from 18 November to 9 December 1990, to critical and popular acclaim.

Andrew Davies adapted the story from the 1989 novel of the same name by Michael Dobbs, a former Chief of Staff at Conservative Party headquarters. Neville Teller also dramatised Dobbs's novel for BBC World Service in 1996, and it had two television sequels ("To Play the King" and "The Final Cut"). The opening and closing theme music for this TV series is entitled "Francis Urquhart's March".

"House of Cards" was ranked 84th in the British Film Institute list of the 100 Greatest British Television Programmes in 2000. In 2013, the serial and the Dobbs novel were the basis for a US adaptation set in Washington, D.C., commissioned and released by Netflix.

The antihero of "House of Cards" is Francis Urquhart, a fictional Chief Whip of the Conservative Party, played by Ian Richardson. The plot follows his amoral and manipulative scheme to become leader of the governing party and, thus, Prime Minister of the United Kingdom.

Michael Dobbs did not envision writing the second and third books, as Urquhart dies at the end of the first novel. The screenplay of the BBC's dramatisation of "House of Cards" differs from the book, and hence allows future series. Dobbs wrote two following books, "To Play the King" and "The Final Cut", which were televised in 1993 and 1995, respectively.

"House of Cards" was said to draw from Shakespeare's plays "Macbeth" and "Richard III", both of which feature main characters who are corrupted by power and ambition. Richardson has a Shakespearean background and said he based his characterisation of Urquhart on Shakespeare's portrayal of Richard III.

Urquhart frequently talks through the camera to the audience, breaking the fourth wall.

After Margaret Thatcher's resignation, the ruling Conservative Party is about to elect a new leader. Francis Urquhart (Ian Richardson), an MP and the Government Chief Whip in the House of Commons, introduces viewers to the contestants, from which Henry "Hal" Collingridge (David Lyon) emerges victorious. Urquhart is secretly contemptuous of the well-meaning but weak Collingridge, but expects a promotion to a senior position in the Cabinet. After the general election, which the party wins by a reduced majority, Urquhart submits his suggestions for a reshuffle that includes his desired promotion. However, Collingridge – citing Harold Macmillan's political demise after the 1962 Night of the Long Knives – effects no changes at all. Urquhart resolves to oust Collingridge, with encouragement from his wife, Elizabeth (Diane Fletcher).

At the same time, with Elizabeth's blessing, Urquhart begins an affair with Mattie Storin (Susannah Harker), a junior political reporter at a Conservative-leaning tabloid newspaper called "The Chronicle". The affair allows Urquhart to manipulate Mattie and indirectly skew her coverage of the Conservative leadership contest in his favour. Mattie has an apparent Electra complex; she finds appeal in Urquhart's much older age and later refers to him as "Daddy". Another unwitting pawn is Roger O'Neill (Miles Anderson), the party's cocaine-addicted public relations consultant.

Urquhart blackmails O'Neill into leaking information on budget cuts that humiliates Collingridge during the Prime Minister's Questions. Later, he blames party chairman Lord "Teddy" Billsborough (Nicholas Selby) for leaking an internal poll showing a drop in Tory numbers, leading Collingridge to sack him. As Collingridge's image suffers, Urquhart encourages ultraconservative Foreign Secretary Patrick Woolton (Malcolm Tierney) and "Chronicle" owner Benjamin Landless (Kenny Ireland) to support his removal. Urquhart also poses as Collingridge's alcoholic brother Charles (James Villiers), to trade shares in a chemical company about to benefit from advance information confidential to the government. Consequently, Collingridge becomes falsely accused of insider trading and is forced to resign.

In the ensuing leadership race, Urquhart initially feigns unwillingness to stand before announcing his candidacy. With the help of his underling, Tim Stamper (Colin Jeavons), Urquhart goes about making sure his competitors drop out of the race: Health Secretary Peter MacKenzie (Christopher Owen) accidentally runs his car over a disabled protester at a demonstration staged by Urquhart and is forced by the public outcry to withdraw, while Education Secretary Harold Earle (Kenneth Gilbert) is blackmailed into withdrawing when Urquhart anonymously sends pictures of him in the company of a rent boy whom Earle had paid for sex.

The first ballot leaves Urquhart to face Woolton and Michael Samuels, the moderate Environment Secretary supported by Billsborough. Urquhart eliminates Woolton by a prolonged scheme: at the party conference, he pressures O'Neill into persuading his personal assistant and lover, Penny Guy (Alphonsia Emmanuel), to have a one-night stand with Woolton in his suite, which Urquhart records via a bugged ministerial red box. When the tape is sent to Woolton, he is led to assume that Samuels is behind the scheme and backs Urquhart in the contest. Urquhart also receives support from Collingridge, who is unaware of Urquhart's role in his own downfall. Samuels is forced out of the running when the tabloids reveal that he backed leftist causes as a student at University of Cambridge.

Stumbling across contradictions in the allegations against Collingridge and his brother, Mattie begins to dig deeper. On Urquhart's orders, O'Neill arranges for her car and flat to be vandalised in a show of intimidation. However, O'Neill becomes increasingly uneasy with what he is being asked to do, and his cocaine addiction adds to his instability. Urquhart mixes O'Neill's cocaine with rat poison, causing him to kill himself when taking the cocaine in a motorway lavatory. Though initially blind to the truth of matters thanks to her relations with Urquhart, Mattie eventually deduces that Urquhart is responsible for O'Neill's death and is behind the unfortunate downfalls of Collingridge and all of Urquhart's rivals.

Mattie looks for Urquhart at the point when it seems his victory is certain. She eventually finds him on the roof garden of the Houses of Parliament, where she confronts him. He admits to O'Neill's murder and everything else he has done. He then asks whether he can trust Mattie, and, though she answers in the affirmative, he does not believe her and throws her off the roof onto a van parked below. An unseen person picks up Mattie's tape recorder, which she had been using to secretly record her conversations with Urquhart. The series ends with Urquhart defeating Samuels in the second leadership ballot and being driven to Buckingham Palace to be invited to form a government by Elizabeth II.

In the first novel, but not in the television series:

Before the series was reissued in 2013 to coincide with the release of the US version of "House of Cards", Dobbs rewrote portions of the novel to bring the series in line with the television mini-series and restore continuity among the three novels. In the 2013 version:

The first installment of the TV series coincidentally aired two days before the Conservative Party leadership election. During a time of "disillusionment with politics", the series "caught the nation's mood".

Ian Richardson won a Best Actor BAFTA in 1991 for his role as Urquhart, and Andrew Davies won an Emmy for outstanding writing in a miniseries.

The series ranked 84th in the British Film Institute list of the 100 Greatest British Television Programmes.

The Urquhart trilogy has been adapted in the United States as "House of Cards". The show stars Kevin Spacey as Francis "Frank" Underwood, the Majority Whip of the Democratic Party, who schemes and murders his way to becoming President of the United States. It is produced by David Fincher and Spacey's Trigger Street Productions, with the initial episodes directed by Fincher.

The series, produced and financed by independent studio Media Rights Capital, is one of Netflix's first forays into original programming. Series one was made available online on 1 February 2013. The series is filmed in Baltimore, Maryland. The first series was critically acclaimed and earned four Golden Globe Nominations, including Best Drama, actor, actress and supporting actor, with Robin Wright winning best actress. It also earned nine Primetime Emmy Award nominations, winning three, and was the first show to earn nominations that was broadcast solely via an internet streaming service.

The drama introduced and popularised the phrase: "You might very well think that; I couldn't possibly comment". It was a non-confirmation confirmative statement, used by Urquhart whenever he could not be seen to agree with a leading statement, with the emphasis on either the "I" or the "possibly", depending on the situation. The phrase was even used in the House of Commons, House of Lords and Parliamentary Committees following the series.

A variation on the phrase was written into the TV adaptation of Terry Pratchett's "Hogfather" for the character Death, as an in-joke on the fact that he was voiced by Richardson.

During the first Gulf War, a British reporter speaking from Baghdad, conscious of the possibility of censorship, used the code phrase "You might very well think that; I couldn't possibly comment" to answer a BBC presenter's question.

A further variation was used by Nicola Murray, a fictional government minister, in the third series finale of "The Thick of It".

In the U.S. adaptation, the phrase is used by Frank Underwood in the first episode during his initial meeting with Zoe Barnes, the US counterpart of Mattie Storin.




</doc>
<doc id="14018" url="https://en.wikipedia.org/wiki?curid=14018" title="Helen Gandy">
Helen Gandy

Helen W. Gandy (April 8, 1897 – July 7, 1988) was an American civil servant. For 54 years, she was the secretary to Federal Bureau of Investigation director J. Edgar Hoover, who called her "indispensable". She exercised great behind-the-scenes influence on Hoover and the workings of the Bureau. Following Hoover's death in 1972, she spent weeks destroying his "Personal File", thought to be where the most incriminating material he used to manipulate and control the most powerful figures in Washington was kept.

Helen Gandy was born in Rockville, New Jersey, one of three children (two daughters and a son) born to Franklin Dallas and Annie (née Williams) Gandy. She grew up in New Jersey in Fairton or the Port Norris section of Commercial Township (sources differ) and graduated from Bridgeton High School in Bridgeton, New Jersey. In 1918, aged 21, she moved to Washington, D.C., where she later took classes at Strayer Business College and George Washington University Law School.

Gandy briefly worked in a department store in Washington before finding a job as a file clerk at the Justice Department in 1918. Within weeks, she went to work as a typist for Hoover, effective March 25, 1918, having told Hoover in her interview she had "no immediate plans to marry." She, like Hoover, would never marry; both were completely devoted to the Bureau.

When Hoover went to the Bureau of Investigation (its original title; it became the F.B.I. in 1935) as its assistant director on August 22, 1921, he specifically requested Gandy return from vacation to help him in the new post. Hoover became director of the Bureau in 1924, and Gandy continued in his service. She was promoted to "office assistant" on August 23, 1937 and "executive assistant" on October 1, 1939. Though she would receive promotions in her civil service grade subsequently, she retained her title as executive assistant until her retirement on May 2, 1972, the day Hoover died. Hoover said of her: "if there is anyone in this Bureau whose services are indispensable, I consider Miss Gandy to be that person." Despite this, Curt Gentry wrote:

Theirs was a rigidly formal relationship. He'd always called her 'Miss Gandy' (when angry, barking it out as one word). In all those fifty-four years he had never once called her by her first name.

Hoover biographers Theoharis and Cox would say "her stern face recalled Cerberus at the gate," a view echoed by Anthony Summers in his life of Hoover, who also pictured Gandy as Hoover's first line of defense against the outside world. When Attorney General Robert F. Kennedy, Hoover's superior, had a direct telephone line installed between their offices, Hoover refused to answer the phone. "Put that damn thing on Miss Gandy's desk where it belongs," Hoover would declare.

Gentry described Gandy's influence:

Her genteel manner and pleasant voice contrasted sharply with this domineering presence. Yet behind the politeness was a resolute firmness not unlike his, and no small amount of influence. Many a career in the Bureau had been quietly manipulated by her. Even those who disliked him, praised her, most often commenting on her remarkable ability to get along with all kinds of people. That she had held her position for fifty-four years was the best evidence of this, for it was a Bureau tradition that the closer you were to him, the more demanding he was.

William C. Sullivan, an agent with the Bureau for three decades, reported in his memoir when he worked in the public relations section answering mail from the public, he gave a correspondent the wrong measurements for Hoover's personal popover recipe, relying on memory rather than the files. Gandy, ever protective of her boss, caught the error and brought it to Hoover's attention. The director then placed an official letter of reprimand in Sullivan's file for the lapse. Mark Felt, deputy associate director of the Bureau, wrote in his memoir that Gandy "was bright and alert and quick-tempered—and completely dedicated to her boss."

Hoover died during the night of May 1–2, 1972. According to Curt Gentry, who wrote the 1991 book "J Edgar Hoover: The Man and the Secrets", Hoover's body was not discovered by his live-in cook and general housekeeper, Annie Fields; rather, it was discovered by James Crawford, who had been Hoover's chauffeur for 37 years. Crawford then yelled out to Fields and Tom Moton (Hoover's new chauffeur after Crawford had retired in January 1972). Ms. Fields first called Hoover's personal physician, Dr. Robert Choisser, then used another phone to call Clyde Tolson's private number. Tolson then called Helen Gandy's private number with the news of Hoover's death along with orders to begin destroying the files. Within an hour, the "D List" ("d" standing for destruction) was being distributed, and the destruction of files began. However, "The New York Times" quoted an anonymous F.B.I. source in spring 1975, who said: "Gandy had begun almost a year before Mr. Hoover's death and was instructed to purge the files that were then in his office."
Anthony Summers reported that G. Gordon Liddy had said of his sources in the F.B.I.: "by the time Gray went in to get the files, Miss Gandy had already got rid of them." The day after Hoover died, Gray, who had been named acting director by President Richard Nixon upon Tolson's resignation from that position, went to Hoover's office. Gandy paused from her work to give Gray a tour. He found file cabinets open and packing boxes being filled with papers. She informed him the boxes contained personal papers of Hoover's. Gandy stated Gray flipped through a few files and approved her work, but Gray was to deny he looked at any papers. Gandy also told Gray it would be a week before she could clear Hoover's effects out so Gray could move into the suite.

Gray reported to Nixon that he had secured Hoover's office and its contents. However, he had sealed only Hoover's personal inner office, where no files were stored, not the entire suite of offices. Since 1957, Hoover's "Official/Confidential" files, containing material too sensitive to include in the Bureau's central files, had been kept in the outer office, where Gandy sat. Gentry reported that Gray would not have known where to look in Gandy's office for the files, as her office was lined floor to ceiling with filing cabinets; moreover, without her index to the files, he would not have been able to locate incriminating material, for files were deliberately mislabeled, e.g., President Nixon's file was labeled "Obscene Matters".

On May 4, Gandy turned over 12 boxes labelled "Official/Confidential", containing 167 files and 17,750 pages, to Mark Felt. Many of them contained derogatory information. Gray told the press that afternoon that "there are no dossiers or secret files. There are just general files and I took steps to preserve their integrity." Gandy retained the "Personal File".

Gandy worked on going through Hoover's "Personal File" in the office until May 12. She then transferred at least 32 file drawers of material to the basement rec room of Hoover's Washington home at 4936 Thirtieth Place, NW, where she continued her work from May 13 to July 17. Gandy later testified nothing official had been removed from the Bureau's offices, "not even his badge." At Hoover's residence the destruction was overseen by John P. Mohr, the number three man in the Bureau after Hoover and Tolson. They were aided by James Jesus Angleton, the Central Intelligence Agency's counterintelligence chief, whom Hoover's neighbors saw removing boxes from Hoover's home. Mohr would claim the boxes Angleton removed were cases of spoiled wine.

When the House Committee on Government Oversight investigated the F.B.I.'s spying on and harassment of Martin Luther King, Jr. and others in 1975, Gandy was called to testify. "I tore them up, put them in boxes, and they were taken away to be shredded," she told the congressmen about the papers. The Bureau's Washington field office had F.B.I. drivers transport the material to Hoover's home, then once Gandy had gone through the material, the drivers transported it back to the field office in the Old Post Office Building on Pennsylvania Avenue, where it was shredded and burned.

Gandy stated that Hoover had left standing instructions to destroy his personal papers upon his death, and that this instruction was confirmed by Tolson and Gray. Gandy stated that she destroyed no official papers, that everything was personal papers of Hoover's. The staff of the subcommittee did not believe her, but she told the committee: "I have no reason to lie." Representative Andrew Maguire (D-New Jersey), a freshman member of the 94th Congress, said "I find your testimony very difficult to believe." Gandy held her ground: "That is your privilege."

"I can give you my word. I know what there was—letters to and from friends, personal friends, a lot of letters," she testified. Gandy also said the files she took to his home also included his financial papers, such as tax returns and investment statements, the deed to his home, and papers relating to his dogs' pedigrees.

Curt Gentry wrote:

In "J. Edgar Hoover: The Man and His Secrets", Gentry describes the nature of the files: "... their contents included blackmail material on the patriarch of an American political dynasty, his sons, their wives, and other women; allegations of two homosexual arrests which Hoover leaked to help defeat a witty, urbane Democratic presidential candidate; the surveillance reports on one of America's best-known first ladies and her alleged lovers, both male and female, white and black; the child molestation documentation the director used to control and manipulate one of the Red-baiting proteges; a list of the Bureau's spies in the White House during the eight administrations when Hoover was FBI director; the forbidden fruit of hundreds of illegal wiretaps and bugs, containing, for example, evidence that an attorney general, Tom C. Clark, who later became Supreme Court justice, had received payoffs from the Chicago syndicate; as well as celebrity files, with all the unsavory gossip Hoover could amass on some of the biggest names in show business."

While Gandy officially retired the day Hoover died, she spent the next few weeks destroying his papers (as described and referenced above). Hoover left her $5,000 in his will.

In 1961, Gandy and her sister, Lucy G. Rodman, donated a portrait of their mother by Thomas Eakins to the Smithsonian American Art Museum. Gandy lived in Washington until 1986, when she moved to DeLand, Florida, in Volusia County, where a niece lived. Gandy was an avid trout fisherman.

Gandy died of a heart attack on July 7, 1988, either in DeLand (as indicated by her "New York Times" obituary) or in nearby Orange City, Florida (as stated in her "Post" obituary).

Gandy was portrayed by actresses Lee Kessler in the television film "J. Edgar Hoover" (1987) and Naomi Watts in the cinematic release "J. Edgar" (2011).




</doc>
<doc id="14019" url="https://en.wikipedia.org/wiki?curid=14019" title="Horsepower">
Horsepower

Horsepower (hp) is a unit of measurement of power, or the rate at which work is done, usually in reference to the output of engines or motors. There are many different standards and types of horsepower. Two common definitions used today are the mechanical horsepower (or imperial horsepower), which is about 745.7 watts, and the metric horsepower, which is approximately 735.5 watts.

The term was adopted in the late 18th century by Scottish engineer James Watt to compare the output of steam engines with the power of draft horses. It was later expanded to include the output power of other types of piston engines, as well as turbines, electric motors and other machinery. The definition of the unit varied among geographical regions. Most countries now use the SI unit watt for measurement of power. With the implementation of the EU Directive 80/181/EEC on 1 January 2010, the use of horsepower in the EU is permitted only as a supplementary unit.

The development of the steam engine provided a reason to compare the output of horses with that of the engines that could replace them. In 1702, Thomas Savery wrote in "The Miner's Friend":

So that an engine which will raise as much water as two horses, working together at one time in such a work, can do, and for which there must be constantly kept ten or twelve horses for doing the same. Then I say, such an engine may be made large enough to do the work required in employing eight, ten, fifteen, or twenty horses to be constantly maintained and kept for doing such a work…
The idea was later used by James Watt to help market his improved steam engine. He had previously agreed to take royalties of one third of the savings in coal from the older Newcomen steam engines. This royalty scheme did not work with customers who did not have existing steam engines but used horses instead.

Watt determined that a horse could turn a mill wheel 144 times in an hour (or 2.4 times a minute). The wheel was in radius; therefore, the horse travelled feet in one minute. Watt judged that the horse could pull with a force of . So:

Watt defined and calculated the horsepower as 32,572 ft⋅lbf/min, which was rounded to an even 33,000 ft⋅lbf/min.

Watt determined that a pony could lift an average per minute over a four-hour working shift. Watt then judged a horse was 50% more powerful than a pony and thus arrived at the 33,000 ft⋅lbf/min figure. "Engineering in History" recounts that John Smeaton initially estimated that a horse could produce per minute. John Desaguliers had previously suggested per minute, and Tredgold suggested per minute. "Watt found by experiment in 1782 that a 'brewery horse' could produce per minute." James Watt and Matthew Boulton standardized that figure at per minute the next year.

A common legend states that the unit was created when one of Watt's first customers, a brewer, specifically demanded an engine that would match a horse, and chose the strongest horse he had and driving it to the limit. Watt, while aware of the trick, accepted the challenge and built a machine that was actually even stronger than the figure achieved by the brewer, and it was the output of that machine which became the horsepower.

In 1993, R. D. Stevenson and R. J. Wassersug published correspondence in "Nature" summarizing measurements and calculations of peak and sustained work rates of a horse. Citing measurements made at the 1926 Iowa State Fair, they reported that the peak power over a few seconds has been measured to be as high as and also observed that for sustained activity, a work rate of about per horse is consistent with agricultural advice from both the 19th and 20th centuries and also consistent with a work rate of about 4 times the basal rate expended by other vertebrates for sustained activity.

When considering human-powered equipment, a healthy human can produce about briefly (see orders of magnitude) and sustain about indefinitely; trained athletes can manage up to about briefly
and for a period of several hours. The Jamaican sprinter Usain Bolt produced a maximum of 0.89 seconds into his 9.58 second dash world record in 2009.

If torque and rotational speed are expressed in coherent SI units, the power is calculated as

where formula_3 is power in watts when formula_4 is torque in newton-metres, and formula_5 is angular speed in radians per second. When using other units or if the speed is in revolutions per unit time rather than radians, a conversion factor has to be included.

When torque formula_6 is in pound-foot units, rotational speed formula_7 is in rpm, the resulting power in horsepower is

The constant 5252 is the rounded value of (33,000 ft⋅lbf/min)/(2π rad/rev).

When torque formula_6 is in inch-pounds,

The constant 63,025 is the approximation of

The following definitions have been or are widely used:

In certain situations it is necessary to distinguish between the various definitions of horsepower and thus a suffix is added: hp(I) for mechanical (or imperial) horsepower, hp(M) for metric horsepower, hp(S) for boiler (or steam) horsepower and hp(E) for electrical horsepower.

Assuming the third CGPM (1901, CR 70) definition of standard gravity, , is used to define the pound-force as well as the kilogram force, and the international avoirdupois pound (1959), one mechanical horsepower is:

Or given that 1 hp = 550 ft⋅lbf/s, 1 ft = 0.3048 m, 1 lbf ≈ 4.448 N, 1 J = 1 N⋅m, 1 W = 1 J/s: 1 hp ≈ 746 W

The various units used to indicate this definition ("PS", "cv", "hk", "pk", "ks" and "ch") all translate to "horse power" in English. British manufacturers often intermix metric horsepower and mechanical horsepower depending on the origin of the engine in question. Sometimes the metric horsepower rating of an engine is conservative enough so that the same figure can be used for both 80/1269/EEC with metric hp and SAE J1349 with imperial hp.

DIN 66036 defines one metric horsepower as the power to raise a mass of 75 kilograms against the Earth's gravitational force over a distance of one metre in one second: = 75 ⋅m/s = 1 PS. This is equivalent to 735.499 W, or 98.6% of an imperial mechanical horsepower.

In 1972, the PS was rendered obsolete by EEC directives, when it was replaced by the kilowatt as the official power-measuring unit. It is still in use for commercial and advertising purposes, in addition to the kilowatt rating, as many customers are still not familiar with the use of kilowatts for engines.

Other names for the metric horsepower are the Italian , Dutch , the French , the Spanish and Portuguese , the Russian , the Swedish , the Finnish , the Estonian , the Norwegian and Danish , the Hungarian , the Czech and Slovak or ), the Bosnian/Croatian/Serbian , the Bulgarian , the Macedonian , the Polish , Slovenian , the Ukrainian and the Romanian , which all equal the German .

In the 19th century, the French had their own unit, which they used instead of the CV or horsepower. It was called the poncelet and was abbreviated "p".

Tax horsepower is a non-linear rating of a motor vehicle for tax purposes. The fiscal power is formula_12, where "P" is the maximum power in kilowatts and "U" is the amount of carbon dioxide (CO) emitted in grams per kilometre. The term for CO measurements has been included in the definition only since 1998, so older ratings in CV are not directly comparable. The fiscal power has found its way into naming of automobile models, such as the popular Citroën deux-chevaux. The (ch) unit should not be confused with the French (CV).

Nameplates on electrical motors show their power output, not the power input (the power delivered at the shaft, not the power consumed to drive the motor). This power output is ordinarily stated in watts or kilowatts. In the United States, the power output is stated in horsepower, which for this purpose is defined as exactly 746 W.

Hydraulic horsepower can represent the power available within hydraulic machinery, power through the down-hole nozzle of a drilling rig, or can be used to estimate the mechanical power needed to generate a known hydraulic flow rate.

It may be calculated as
where pressure is in psi, and flow rate is in US gallons per minute.

Drilling rigs are powered mechanically by rotating the drill pipe from above. Hydraulic power is still needed though, as between 2 and 7 hp are required to push mud through the drill bit to clear waste rock. Additional hydraulic power may also be used to drive a down-hole mud motor to power directional drilling.

Boiler horsepower is a boiler's capacity to deliver steam to a steam engine and is not the same unit of power as the 550 ft-lb/s definition. One boiler horsepower is equal to the thermal energy rate required to evaporate 34.5 lb of fresh water at 212 °F in one hour. In the early days of steam use, the boiler horsepower was roughly comparable to the horsepower of engines fed by the boiler.

The term "boiler horsepower" was originally developed at the Philadelphia Centennial Exhibition in 1876, where the best steam engines of that period were tested. The average steam consumption of those engines (per output horsepower) was determined to be the evaporation of 30 pounds of water per hour, based on feed water at 100 °F, and saturated steam generated at 70 psi. This original definition is equivalent to a boiler heat output of 33,485 Btu/h. Years later in 1884, the ASME re-defined the boiler horsepower as the thermal output equal to the evaporation of 34.5 pounds per hour of water "from and at" 212 °F. This considerably simplified boiler testing, and provided more accurate comparisons of the boilers at that time. This revised definition is equivalent to a boiler heat output of 33,469 Btu/h. Present industrial practice is to define "boiler horsepower" as a boiler thermal output equal to 33,475 Btu/h, which is very close to the original and revised definitions.

Boiler horsepower is still used to measure boiler output in industrial boiler engineering in Australia, the US, and New Zealand. Boiler horsepower is abbreviated BHP, not to be confused with brake horsepower, below, which is also abbreviated BHP.

Drawbar horsepower (dbhp) is the power a railway locomotive has available to haul a train or an agricultural tractor to pull an implement. This is a measured figure rather than a calculated one. A special railway car called a dynamometer car coupled behind the locomotive keeps a continuous record of the drawbar pull exerted, and the speed. From these, the power generated can be calculated. To determine the maximum power available, a controllable load is required; it is normally a second locomotive with its brakes applied, in addition to a static load.

If the drawbar force (formula_14) is measured in pounds-force (lbf) and speed (formula_15) is measured in miles per hour (mph), then the drawbar power (formula_3) in horsepower (hp) is

Example: How much power is needed to pull a drawbar load of 2,025 pounds-force at 5 miles per hour?

The constant 375 is because 1 hp = 375 lbf⋅mph. If other units are used, the constant is different. When using coherent SI units (watts, newtons, and metres per second), no constant is needed, and the formula becomes formula_19.

This formula may also be used to calculate the horsepower of a jet engine, using the speed of the jet and the thrust required to maintain that speed.

Example: How much power is generated with a thrust of 4,000 pounds at 400 miles per hour?

This measure was instituted by the Royal Automobile Club in Britain and was used to denote the power of early 20th-century British cars. (An identical measure, known as ALAM horsepower or NACC horsepower, was used for early U.S. automobiles.) Many cars took their names from this figure (hence the Austin Seven and Riley Nine), while others had names such as "40/50 hp", which indicated the RAC figure followed by the true measured power.

Taxable horsepower does not reflect developed horsepower; rather, it is a calculated figure based on the engine's bore size, number of cylinders, and a (now archaic) presumption of engine efficiency. As new engines were designed with ever-increasing efficiency, it was no longer a useful measure, but was kept in use by UK regulations which used the rating for tax purposes.

where

This is equal to the engine displacement in cubic inches divided by 0.625π, then divided again by the stroke in inches.

Since taxable horsepower was computed based on bore and number of cylinders, not based on actual displacement, it gave rise to engines with "undersquare" dimensions (bore smaller than stroke), which tended to impose an artificially low limit on rotational speed, hampering the potential power output and efficiency of the engine.

The situation persisted for several generations of four- and six-cylinder British engines: for example, Jaguar's 3.4-litre XK engine of the 1950s had six cylinders with a bore of and a stroke of , where most American automakers had long since moved to oversquare (large bore, short stroke) V8 engines (see, for example, the early Chrysler Hemi).

The power of an engine may be measured or estimated at several points in the transmission of the power from its generation to its application. A number of names are used for the power developed at various stages in this process, but none is a clear indicator of either the measurement system or definition used.

In the case of an engine dynamometer, power is measured at the engine's flywheel. 

In general:

All the above assumes that no power inflation factors have been applied to any of the readings.

Engine designers use expressions other than horsepower to denote objective targets or performance, such as brake mean effective pressure (BMEP). This is a coefficient of theoretical brake horsepower and cylinder pressures during combustion.

Nominal horsepower (nhp) is an early 19th-century rule of thumb used to estimate the power of steam engines. It assumed a steam pressure of .

nhp = 7 × area of piston in square inches × equivalent piston speed in feet per minute/33,000

For paddle ships, the Admiralty rule was that the piston speed in feet per minute was taken as 129.7 × (stroke). For screw steamers, the intended piston speed was used.

The stroke (or length of stroke) was the distance moved by the piston measured in feet.

For the nominal horsepower to equal the actual power it would be necessary for the mean steam pressure in the cylinder during the stroke to be and for the piston speed to be that generated by the assumed relationship for paddle ships.

The French Navy used the same definition of nominal horse power as the Royal Navy.

Indicated horsepower (ihp) is the theoretical power of a reciprocating engine if it is completely frictionless in converting the expanding gas energy (piston pressure × displacement) in the cylinders. It is calculated from the pressures developed in the cylinders, measured by a device called an "engine indicator" – hence indicated horsepower. As the piston advances throughout its stroke, the pressure against the piston generally decreases, and the indicator device usually generates a graph of pressure vs stroke within the working cylinder. From this graph the amount of work performed during the piston stroke may be calculated.

Indicated horsepower was a better measure of engine power than nominal horsepower (nhp) because it took account of steam pressure. But unlike later measures such as shaft horsepower (shp) and brake horsepower (bhp), it did not take into account power losses due to the machinery internal frictional losses, such as a piston sliding within the cylinder, plus bearing friction, transmission and gear box friction, etc.

Brake horsepower (bhp) is the power measured using a brake type (load) dynamometer at a specified location, such as the crankshaft, output shaft of the transmission, rear axle or rear wheels. Bhp is Brake dyno derived and is often incorrectly confused with upfactored power figures as produced using an inertia type (not a load dyno).

In Europe, the DIN 70020 standard tests the engine fitted with all ancillaries and exhaust system as used in the car. The older American standard (SAE gross horsepower, referred to as bhp) used an engine without alternator, water pump, and other auxiliary components such as power steering pump, muffled exhaust system, etc., so the figures were higher than the European figures for the same engine. The newer American standard (referred to as SAE net horsepower) tests an engine with all the auxiliary components (see "Engine power test standards" below).

Brake refers to the device which is used to provide an equal braking force / load to balance / equal an engine's output force and hold it at a desired rotational speed. During testing, the output torque and rotational speed were measured to determine the brake horsepower. Horsepower was originally measured and calculated by use of the "indicator diagram" (a James Watt invention of the late 18th century), and later by means of a Prony brake connected to the engine's output shaft. Modern dynamometers use any of several braking methods to measure the engine's brake horsepower, the actual output of the engine itself, before losses to the drivetrain.

Shaft horsepower (shp) is the power delivered to a propeller shaft, a turbine shaft, or to an output shaft of an automotive transmission. Shaft horsepower is a common rating for turboshaft and turboprop engines, industrial turbines, and some marine applications. 

Equivalent shaft horsepower (eshp) is sometimes used to rate turboprop engines. It includes the equivalent power derived from residual jet thrust from the turbine exhaust.

There exist a number of different standard determining how the power and torque of an automobile engine is measured and corrected. Correction factors are used to adjust power and torque measurements to standard atmospheric conditions, to provide a more accurate comparison between engines as they are affected by the pressure, humidity, and temperature of ambient air. Some standards are described below.

In the early twentieth century, a so-called "SAE horsepower" was sometimes quoted for U.S. automobiles. This long predates the Society of Automotive Engineers (SAE) horsepower measurement standards and was really just another term for the widely used ALAM or NACC horsepower figure, which was the same as the British RAC horsepower, used for tax purposes.

Prior to the 1972 model year, American automakers rated and advertised their engines in brake horsepower, "bhp", which was a version of brake horsepower called SAE gross horsepower because it was measured according to Society of Automotive Engineers (SAE) standards (J245 and J1995) that call for a stock test engine without accessories (such as dynamo/alternator, radiator fan, water pump), and sometimes fitted with long tube test headers in lieu of the OEM exhaust manifolds. This contrasts with both SAE net power and DIN 70020 standards, which account for engine accessories (but not transmission losses). The atmospheric correction standards for barometric pressure, humidity and temperature for SAE gross power testing were relatively idealistic.

In the United States, the term "bhp" fell into disuse in 1971–1972, as automakers began to quote power in terms of SAE net horsepower in accord with SAE standard J1349. Like SAE gross and other brake horsepower protocols, SAE net hp is measured at the engine's crankshaft, and so does not account for transmission losses. However, similar to the DIN 70020 standard, SAE net power testing protocol calls for standard production-type belt-driven accessories, air cleaner, emission controls, exhaust system, and other power-consuming accessories. This produces ratings in closer alignment with the power produced by the engine as it is actually configured and sold.

In 2005, the SAE introduced "SAE Certified Power" with SAE J2723. To attain certification the test must follow the SAE standard in question, take place in an ISO 9000/9002 certified facility and be witnessed by an SAE approved third party.

A few manufacturers such as Honda and Toyota switched to the new ratings immediately. The rating for Toyota's Camry 3.0 L "1MZ-FE" V6 fell from . The company's Lexus ES 330 and Camry SE V6 (3.3 L V6) were previously rated at but the ES 330 dropped to while the Camry declined to . The first engine certified under the new program was the 7.0 L LS7 used in the 2006 Chevrolet Corvette Z06. Certified power rose slightly from .

While Toyota and Honda are retesting their entire vehicle lineups, other automakers generally are retesting only those with updated powertrains. For example, the 2006 Ford Five Hundred is rated at 203 horsepower, the same as that of 2005 model. However, the 2006 rating does not reflect the new SAE testing procedure, as Ford is not going to incur the extra expense of retesting its existing engines. Over time, most automakers are expected to comply with the new guidelines.

SAE tightened its horsepower rules to eliminate the opportunity for engine manufacturers to manipulate factors affecting performance such as how much oil was in the crankcase, engine control system calibration, and whether an engine was tested with high octane fuel. In some cases, such can add up to a change in horsepower ratings.

DIN 70020 is a German DIN standard for measuring road vehicle horsepower. DIN hp is measured at the engine's output shaft as a form of metric horsepower rather than mechanical horsepower. Similar to SAE net power rating, and unlike SAE gross power, DIN testing measures the engine as installed in the vehicle, with cooling system, charging system and stock exhaust system all connected. DIN 70020 is often seen abbreviated as "PS", derived from the German word for horsepower Pferdestärke.

A test standard by Italian CUNA ("Commissione Tecnica per l'Unificazione nell'Automobile", Technical Commission for Automobile Unification), a federated entity of standards organisation UNI, was formerly used in Italy.
CUNA prescribed that the engine be tested with all accessories necessary to its running fitted (such as the water pump), while all others—such as alternator/dynamo, radiator fan, and exhaust manifold—could be omitted. All calibration and accessories had to be as on production engines.

ECE R24 is a UN standard for the approval of compression ignition engine emissions, installation and measurement of engine power. It is similar to DIN 70020 standard, but with different requirements for connecting an engine's fan during testing causing it to absorb less power from the engine.

ECE R85 is a UN standard for the approval of internal combustion engines with regard to the measurement of the net power.

80/1269/EEC of 16 December 1980 is a European Union standard for road vehicle engine power.

The International Organization for Standardization (ISO) publishes several standards for measuring engine horsepower.

JIS D 1001 is a Japanese net, and gross, engine power test code for automobiles or trucks having a spark ignition, diesel engine, or fuel injection engine.




</doc>
<doc id="14020" url="https://en.wikipedia.org/wiki?curid=14020" title="History of London">
History of London

The history of London, the capital city of England and the United Kingdom, extends over 2000 years. In that time, it has become one of the world's most significant financial and cultural capital cities. It has withstood plague, devastating fire, civil war, aerial bombardment, terrorist attacks, and riots.

The City of London is the historic core of the Greater London metropolis, and is today its primary financial district, though it represents only a small part of the wider metropolis.

According to "Historia Regum Britanniae", by Geoffrey of Monmouth, London was founded by Brutus of Troy about 1000–1100 B.C.E. after he defeated the native giant Gogmagog; the settlement was known as ', ' (Latin for New Troy), which, according to a pseudo-etymology, was corrupted to "Trinovantum". Trinovantes were the Iron Age tribe who inhabited the area prior to the Romans. Geoffrey provides prehistoric London with a rich array of legendary kings, such as Lud (see also Lludd, from Welsh mythology) who, he claims, renamed the town "Caer Ludein", from which London was derived, and was buried at Ludgate.

Some recent discoveries indicate probable very early settlements near the Thames in the London area. In 1993, the remains of a Bronze Age bridge were found on the Thames's south foreshore, upstream of Vauxhall Bridge. This bridge either crossed the Thames, or went to a now lost island in the river. Dendrology dated the timbers to between 1750 B.C.E and 1285 B.C.E. In 2001, a further dig found that the timbers were driven vertically into the ground on the south bank of the Thames west of Vauxhall Bridge. In 2010, the foundations of a large timber structure, dated to between 4,800 B.C.E. and 4,500 B.C.E. were found, again on the foreshore south of Vauxhall Bridge. The function of the mesolithic structure is not known. All these structures are on the south bank at a natural crossing point where the River Effra flows into the Thames.

Archaeologist Leslie Wallace notes that "Because no LPRIA [Late pre-Roman Iron Age] settlements or significant domestic refuse have been found in London, despite extensive archaeological excavation, arguments for a purely Roman foundation of London are now common and uncontroversial."

"Londinium" was established as a civilian town by the Romans about four years after the invasion of AD 43. London, like Rome, was founded on the point of the river where it was narrow enough to bridge and the strategic location of the city provided easy access to much of Europe. Early Roman London occupied a relatively small area, roughly equivalent to the size of Hyde Park. In around AD 60, it was destroyed by the Iceni led by their queen Boudica. The city was quickly rebuilt as a planned Roman town and recovered after perhaps 10 years; the city grew rapidly over the following decades.

During the 2nd century "Londinium" was at its height and replaced Colchester as the capital of Roman Britain (Britannia). Its population was around 60,000 inhabitants. It boasted major public buildings, including the largest basilica north of the Alps, temples, bath houses, an amphitheatre and a large fort for the city garrison. Political instability and recession from the 3rd century onwards led to a slow decline.

At some time between AD 180 and AD 225, the Romans built the defensive London Wall around the landward side of the city. The wall was about long, high, and thick. The wall would survive for another 1,600 years and define the City of London's perimeters for centuries to come. The perimeters of the present City are roughly defined by the line of the ancient wall.

Londinium was an ethnically diverse city with inhabitants from across the Roman Empire, including natives of Britannia, continental Europe, the Middle East, and North Africa.

In the late 3rd century, Londinium was raided on several occasions by Saxon pirates. This led, from around 255 onwards, to the construction of an additional riverside wall. Six of the traditional seven city gates of London are of Roman origin, namely: Ludgate, Newgate, Aldersgate, Cripplegate, Bishopsgate and Aldgate (Moorgate is the exception, being of medieval origin).

By the 5th century, the Roman Empire was in rapid decline and in AD 410, the Roman occupation of Britannia came to an end. Following this, the Roman city also went into rapid decline and by the end of the 5th century was practically abandoned.

Until recently it was believed that Anglo-Saxon settlement initially avoided the area immediately around Londinium. However, the discovery in 2008 of an Anglo-Saxon cemetery at Covent Garden indicates that the incomers had begun to settle there at least as early as the 6th century and possibly in the 5th. The main focus of this settlement was outside the Roman walls, clustering a short distance to the west along what is now the Strand, between the Aldwych and Trafalgar Square. It was known as "Lundenwic", the "-wic" suffix here denoting a trading settlement. Recent excavations have also highlighted the population density and relatively sophisticated urban organisation of this earlier Anglo-Saxon London, which was laid out on a grid pattern and grew to house a likely population of 10–12,000.

Early Anglo-Saxon London belonged to a people known as the Middle Saxons, from whom the name of the county of Middlesex is derived, but who probably also occupied the approximate area of modern Hertfordshire and Surrey. However, by the early 7th century the London area had been incorporated into the kingdom of the East Saxons. In 604 King Saeberht of Essex converted to Christianity and London received Mellitus, its first post-Roman bishop.

At this time Essex was under the overlordship of King Æthelberht of Kent, and it was under Æthelberht's patronage that Mellitus founded the first St. Paul's Cathedral, traditionally said to be on the site of an old Roman Temple of Diana (although Christopher Wren found no evidence of this). It would have only been a modest church at first and may well have been destroyed after he was expelled from the city by Saeberht's pagan successors.

The permanent establishment of Christianity in the East Saxon kingdom took place in the reign of King Sigeberht II in the 650s. During the 8th century, the kingdom of Mercia extended its dominance over south-eastern England, initially through overlordship which at times developed into outright annexation. London seems to have come under direct Mercian control in the 730s.

Viking attacks dominated most of the 9th century, becoming increasingly common from around 830 onwards. London was sacked in 842 and again in 851. The Danish "Great Heathen Army", which had rampaged across England since 865, wintered in London in 871. The city remained in Danish hands until 886, when it was captured by the forces of King Alfred the Great of Wessex and reincorporated into Mercia, then governed under Alfred's sovereignty by his son-in-law Ealdorman Æthelred.

Around this time the focus of settlement moved within the old Roman walls for the sake of defence, and the city became known as "Lundenburh". The Roman walls were repaired and the defensive ditch re-cut, while the bridge was probably rebuilt at this time. A second fortified Borough was established on the south bank at Southwark, the "Suthringa Geworc" (defensive work of the men of Surrey). The old settlement of "Lundenwic" became known as the "ealdwic" or "old settlement", a name which survives today as Aldwich.

From this point, the City of London began to develop its own unique local government. Following Ethelred's death in 911 it was transferred to Wessex, preceding the absorption of the rest of Mercia in 918. Although it faced competition for political pre-eminence in the united Kingdom of England from the traditional West Saxon centre of Winchester, London's size and commercial wealth brought it a steadily increasing importance as a focus of governmental activity. King Athelstan held many meetings of the "witan" in London and issued laws from there, while King Æthelred the Unready issued the Laws of London there in 978.

Following the resumption of Viking attacks in the reign of Ethelred, London was unsuccessfully attacked in 994 by an army under King Sweyn Forkbeard of Denmark. As English resistance to the sustained and escalating Danish onslaught finally collapsed in 1013, London repulsed an attack by the Danes and was the last place to hold out while the rest of the country submitted to Sweyn, but by the end of the year it too capitulated and Æthelred fled abroad. Sweyn died just five weeks after having been proclaimed king and Æthelred was restored to the throne, but Sweyn's son Cnut returned to the attack in 1015.

After Æthelred's death at London in 1016 his son Edmund Ironside was proclaimed king there by the "witangemot" and left to gather forces in Wessex. London was then subjected to a systematic siege by Cnut but was relieved by King Edmund's army; when Edmund again left to recruit reinforcements in Wessex the Danes resumed the siege but were again unsuccessful. However, following his defeat at the Battle of Assandun Edmund ceded to Cnut all of England north of the Thames, including London, and his death a few weeks later left Cnut in control of the whole country.

A Norse saga tells of a battle when King Æthelred returned to attack Danish-occupied London. According to the saga, the Danes lined London Bridge and showered the attackers with spears. Undaunted, the attackers pulled the roofs off nearby houses and held them over their heads in the boats. Thus protected, they were able to get close enough to the bridge to attach ropes to the piers and pull the bridge down, thus ending the Viking occupation of London. This story presumably relates to Æthelred's return to power after Sweyn's death in 1014, but there is no strong evidence of any such struggle for control of London on that occasion.

Following the extinction of Cnut's dynasty in 1042 English rule was restored under Edward the Confessor. He was responsible for the foundation of Westminster Abbey and spent much of his time at Westminster, which from this time steadily supplanted the City itself as the centre of government. Edward's death at Westminster in 1066 without a clear heir led to a succession dispute and the Norman conquest of England. Earl Harold Godwinson was elected king by the "witangemot" and crowned in Westminster Abbey but was defeated and killed by William the Bastard, Duke of Normandy at the Battle of Hastings. The surviving members of the "witan" met in London and elected King Edward's young nephew Edgar the Ætheling as king.

The Normans advanced to the south bank of the Thames opposite London, where they defeated an English attack and burned Southwark but were unable to storm the bridge. They moved upstream and crossed the river at Wallingford before advancing on London from the north-west. The resolve of the English leadership to resist collapsed and the chief citizens of London went out together with the leading members of the Church and aristocracy to submit to William at Berkhamstead, although according to some accounts there was a subsequent violent clash when the Normans reached the city. Having occupied London, William was crowned king in Westminster Abbey.

The new Norman regime established new fortresses within the city to dominate the native population. By far the most important of these was the Tower of London at the eastern end of the city, where the initial timber fortification was rapidly replaced by the construction of the first stone castle in England. The smaller forts of Baynard's Castle and Montfichet's Castle were also established along the waterfront. King William also granted a charter in 1067 confirming the city's existing rights, privileges and laws. London was a centre of England's nascent Jewish population, the first of whom arrived in about 1070. Its growing self-government was consolidated by the election rights granted by King John in 1199 and 1215.

In 1097, William Rufus, the son of William the Conqueror began the construction of 'Westminster Hall', which became the focus of the Palace of Westminster.

In 1176, construction began of the most famous incarnation of London Bridge (completed in 1209) which was built on the site of several earlier timber bridges. This bridge would last for 600 years, and remained the only bridge across the River Thames until 1739.

Violence against Jews took place in 1190, after it was rumoured that the new King had ordered their massacre after they had presented themselves at his coronation.

In 1216, during the First Barons' War London was occupied by Prince Louis of France, who had been called in by the baronial rebels against King John and was acclaimed as King of England in St Paul's Cathedral. However, following John's death in 1217 Louis's supporters reverted to their Plantagenet allegiance, rallying round John's son Henry III, and Louis was forced to withdraw from England.

In 1224, after an accusation of ritual murder, the Jewish community was subjected to a steep punitive levy. Then in 1232, Henry III confiscated the principal synagogue of the London Jewish community because he claimed their chanting was audible in a neighboring church. In 1264, during the Second Barons' War, Simon de Montfort's rebels occupied London and killed 500 Jews while attempting to seize records of debts.

London's Jewish community was forced to leave England by the expulsion by Edward I in 1290. They left for France, Holland and further afield; their property was seized, and many suffered robbery and murder as they departed.

Over the following centuries, London would shake off the heavy French cultural and linguistic influence which had been there since the times of the Norman conquest. The city would figure heavily in the development of Early Modern English.
During the Peasants' Revolt of 1381, London was invaded by rebels led by Wat Tyler. A group of peasants stormed the Tower of London and executed the Lord Chancellor, Archbishop Simon Sudbury, and the Lord Treasurer. The peasants looted the city and set fire to numerous buildings. Tyler was stabbed to death by the Lord Mayor William Walworth in a confrontation at Smithfield and the revolt collapsed.

Trade increased steadily during the Middle Ages, and London grew rapidly as a result. In 1100, London's population was somewhat more than 15,000. By 1300, it had grown to roughly 80,000. London lost at least half of its population during the Black Death in the mid-14th century, but its economic and political importance stimulated a rapid recovery despite further epidemics. Trade in London was organised into various guilds, which effectively controlled the city, and elected the Lord Mayor of the City of London.

Medieval London was made up of narrow and twisting streets, and most of the buildings were made from combustible materials such as timber and straw, which made fire a constant threat, while sanitation in cities was of low-quality.

In 1475, the Hanseatic League set up its main English trading base ("kontor") in London, called "Stalhof" or "Steelyard". It existed until 1853, when the Hanseatic cities of Lübeck, Bremen and Hamburg sold the property to South Eastern Railway. Woollen cloth was shipped undyed and undressed from 14th/15th century London to the nearby shores of the Low Countries, where it was considered indispensable.

During the Reformation, London was the principal early centre of Protestantism in England. Its close commercial connections with the Protestant heartlands in northern continental Europe, large foreign mercantile communities, disproportionately large number of literate inhabitants and role as the centre of the English print trade all contributed to the spread of the new ideas of religious reform. Before the Reformation, more than half of the area of London was the property of monasteries, nunneries and other religious houses.

Henry VIII's "Dissolution of the Monasteries" had a profound effect on the city as nearly all of this property changed hands. The process started in the mid 1530s, and by 1538 most of the larger monastic houses had been abolished. Holy Trinity Aldgate went to Lord Audley, and the Marquess of Winchester built himself a house in part of its precincts. The Charterhouse went to Lord North, Blackfriars to , the leper hospital of St Giles to Lord Dudley, while the king took for himself the leper hospital of St James, which was rebuilt as St James's Palace.

The period saw London rapidly rising in importance among Europe's commercial centres. Trade expanded beyond Western Europe to Russia, the Levant, and the Americas. This was the period of mercantilism and monopoly trading companies such as the Muscovy Company (1555) and the British East India Company (1600) were established in London by Royal Charter. The latter, which ultimately came to rule India, was one of the key institutions in London, and in Britain as a whole, for two and a half centuries. Immigrants arrived in London not just from all over England and Wales, but from abroad as well, for example Huguenots from France; the population rose from an estimated 50,000 in 1530 to about 225,000 in 1605. The growth of the population and wealth of London was fuelled by a vast expansion in the use of coastal shipping.

The late 16th and early 17th century saw the great flourishing of drama in London whose preeminent figure was William Shakespeare. During the mostly calm later years of Elizabeth's reign, some of her courtiers and some of the wealthier citizens of London built themselves country residences in Middlesex, Essex and Surrey. This was an early stirring of the villa movement, the taste for residences which were neither of the city nor on an agricultural estate, but at the time of Elizabeth's death in 1603, London was still very compact.

Xenophobia was rampant in London, and increased after the 1580s. Many immigrants became disillusioned by routine threats of violence and molestation, attempts at expulsion of foreigners, and the great difficulty in acquiring English citizenship. Dutch cities proved more hospitable, and many left London permanently. Foreigners are estimated to have made up 4,000 of the 100,000 residents of London by 1600, many being Dutch and German workers and traders.

London's expansion beyond the boundaries of the City was decisively established in the 17th century. In the opening years of that century the immediate environs of the City, with the principal exception of the aristocratic residences in the direction of Westminster, were still considered not conducive to health. Immediately to the north was Moorfields, which had recently been drained and laid out in walks, but it was frequented by beggars and travellers, who crossed it in order to get into London. Adjoining Moorfields were Finsbury Fields, a favourite practising ground for the archers, Mile End, then a common on the Great Eastern Road and famous as a rendezvous for the troops.

The preparations for King James I becoming king were interrupted by a severe plague epidemic, which may have killed over thirty thousand people. The Lord Mayor's Show, which had been discontinued for some years, was revived by order of the king in 1609. The dissolved monastery of the Charterhouse, which had been bought and sold by the courtiers several times, was purchased by Thomas Sutton for £13,000. The new hospital, chapel, and schoolhouse were begun in 1611. Charterhouse School was to be one of the principal public schools in London until it moved to Surrey in Victorian times, and the site is still used as a medical school.

The general meeting-place of Londoners in the day-time was the nave of Old St. Paul's Cathedral. Merchants conducted business in the aisles, and used the font as a counter upon which to make their payments; lawyers received clients at their particular pillars; and the unemployed looked for work. St Paul's Churchyard was the centre of the book trade and Fleet Street was a centre of public entertainment. Under James I the theatre, which established itself so firmly in the latter years of Elizabeth, grew further in popularity. The performances at the public theatres were complemented by elaborate masques at the royal court and at the inns of court.

Charles I acceded to the throne in 1625. During his reign, aristocrats began to inhabit the West End in large numbers. In addition to those who had specific business at court, increasing numbers of country landowners and their families lived in London for part of the year simply for the social life. This was the beginning of the "London season". Lincoln's Inn Fields was built about 1629. The piazza of Covent Garden, designed by England's first classically trained architect Inigo Jones followed in about 1632. The neighbouring streets were built shortly afterwards, and the names of Henrietta, Charles, James, King and York Streets were given after members of the royal family.
In January 1642 five members of parliament whom the King wished to arrest were granted refuge in the City. In August of the same year the King raised his banner at Nottingham, and during the English Civil War London took the side of the parliament. Initially the king had the upper hand in military terms and in November he won the Battle of Brentford a few miles to the west of London. The City organised a new makeshift army and Charles hesitated and retreated. Subsequently, an extensive system of fortifications was built to protect London from a renewed attack by the Royalists. This comprised a strong earthen rampart, enhanced with bastions and redoubts. It was well beyond the City walls and encompassed the whole urban area, including Westminster and Southwark. London was not seriously threatened by the royalists again, and the financial resources of the City made an important contribution to the parliamentarians' victory in the war.

The unsanitary and overcrowded City of London has suffered from the numerous outbreaks of the plague many times over the centuries, but in Britain it is the last major outbreak which is remembered as the "Great Plague" It occurred in 1665 and 1666 and killed around 60,000 people, which was one fifth of the population. Samuel Pepys chronicled the epidemic in his diary. On 4 September 1665 he wrote "I have stayed in the city till above 7400 died in one week, and of them about 6000 of the plague, and little noise heard day or night but tolling of bells."

The Great Plague was immediately followed by another catastrophe, albeit one which helped to put an end to the plague. On the Sunday, 2 September 1666 the Great Fire of London broke out at one o'clock in the morning at a bakery in Pudding Lane in the southern part of the City. Fanned by an eastern wind the fire spread, and efforts to arrest it by pulling down houses to make firebreaks were disorganised to begin with. On Tuesday night the wind fell somewhat, and on Wednesday the fire slackened. On Thursday it was extinguished, but on the evening of that day the flames again burst forth at the Temple. Some houses were at once blown up by gunpowder, and thus the fire was finally mastered. The Monument was built to commemorate the fire: for over a century and a half it bore an inscription attributing the conflagration to a ""popish frenzy"".
The fire destroyed about 60% of the City, including Old St Paul's Cathedral, 87 parish churches, 44 livery company halls and the Royal Exchange. However, the number of lives lost was surprisingly small; it is believed to have been 16 at most. Within a few days of the fire, three plans were presented to the king for the rebuilding of the city, by Christopher Wren, John Evelyn and Robert Hooke.

Wren proposed to build main thoroughfares north and south, and east and west, to insulate all the churches in conspicuous positions, to form the most public places into large piazzas, to unite the halls of the 12 chief livery companies into one regular square annexed to the Guildhall, and to make a fine quay on the bank of the river from Blackfriars to the Tower of London. Wren wished to build the new streets straight and in three standard widths of thirty, sixty and ninety feet. Evelyn's plan differed from Wren's chiefly in proposing a street from the church of St Dunstan's in the East to the St Paul's, and in having no quay or terrace along the river. These plans were not implemented, and the rebuilt city generally followed the streetplan of the old one, and most of it has survived into the 21st century.

Nonetheless, the new City was different from the old one. Many aristocratic residents never returned, preferring to take new houses in the West End, where fashionable new districts such as St. James's were built close to the main royal residence, which was Whitehall Palace until it was destroyed by fire in the 1690s, and thereafter St. James's Palace. The rural lane of Piccadilly sprouted courtiers mansions such as Burlington House. Thus the separation between the middle class mercantile City of London, and the aristocratic world of the court in Westminster became complete.

In the City itself there was a move from wooden buildings to stone and brick construction to reduce the risk of fire. Parliament's Rebuilding of London Act 1666 stated ""building with brick [is] not only more comely and durable, but also more safe against future perils of fire"". From then on only doorcases, window-frames and shop fronts were allowed to be made of wood.

Christopher Wren's plan for a new model London came to nothing, but he was appointed to rebuild the ruined parish churches and to replace St Paul's Cathedral. His domed baroque cathedral was the primary symbol of London for at least a century and a half. As city surveyor, Robert Hooke oversaw the reconstruction of the City's houses. The East End, that is the area immediately to the east of the city walls, also became heavily populated in the decades after the Great Fire. London's docks began to extend downstream, attracting many working people who worked on the docks themselves and in the processing and distributive trades. These people lived in Whitechapel, Wapping, Stepney and Limehouse, generally in slum conditions.

In the winter of 1683–1684, a frost fair was held on the Thames. The frost, which began about seven weeks before Christmas and continued for six weeks after, was the greatest on record. The Revocation of the Edict of Nantes in 1685 led to a large migration on Huguenots to London. They established a silk industry at Spitalfields.

At this time the Bank of England was founded, and the British East India Company was expanding its influence. Lloyd's of London also began to operate in the late 17th century. In 1700, London handled 80% of England's imports, 69% of its exports and 86% of its re-exports. Many of the goods were luxuries from the Americas and Asia such as silk, sugar, tea and tobacco. The last figure emphasises London's role as an entrepot: while it had many craftsmen in the 17th century, and would later acquire some large factories, its economic prominence was never based primarily on industry. Instead it was a great trading and redistribution centre. Goods were brought to London by England's increasingly dominant merchant navy, not only to satisfy domestic demand, but also for re-export throughout Europe and beyond.

William III, a Dutchman, cared little for London, the smoke of which gave him asthma, and after the first fire at Whitehall Palace (1691) he purchased Nottingham House and transformed it into Kensington Palace. Kensington was then an insignificant village, but the arrival of the court soon caused it to grow in importance. The palace was rarely favoured by future monarchs, but its construction was another step in the expansion of the bounds of London. During the same reign Greenwich Hospital, then well outside the boundary of London, but now comfortably inside it, was begun; it was the naval complement to the Chelsea Hospital for former soldiers, which had been founded in 1681. During the reign of Queen Anne an act was passed authorising the building of 50 new churches to serve the greatly increased population living outside the boundaries of the City of London.

The 18th century was a period of rapid growth for London, reflecting an increasing national population, the early stirrings of the Industrial Revolution, and London's role at the centre of the evolving British Empire.

In 1707, an Act of Union was passed merging the Scottish and the English Parliaments, thus establishing the Kingdom of Great Britain. A year later, in 1708 Christopher Wren's masterpiece, St Paul's Cathedral was completed on his birthday. However, the first service had been held on 2 December 1697; more than 10 years earlier. This Cathedral replaced the original St. Paul's which had been completely destroyed in the Great Fire of London. This building is considered one of the finest in Britain and a fine example of Baroque architecture.

Many tradesmen from different countries came to London to trade goods and merchandise. Also, more immigrants moved to London making the population greater. More people also moved to London for work and for business making London an altogether bigger and busier city. Britain's victory in the Seven Years' War increased the country's international standing and opened large new markets to British trade, further boosting London's prosperity.

During the Georgian period London spread beyond its traditional limits at an accelerating pace. This is shown in a series of detailed maps, particularly John Rocque's 1741–45 map "(see below)" and his 1746 Map of London. New districts such as Mayfair were built for the rich in the West End, new bridges over the Thames encouraged an acceleration of development in South London and in the East End, the Port of London expanded downstream from the City. During this period was also the uprising of the American colonies. In 1780, the Tower of London held its only American prisoner, former President of the Continental Congress, Henry Laurens. In 1779, he was the Congress's representative of Holland, and got the country's support for the Revolution. On his return voyage back to America, the Royal Navy captured him and charged him with treason after finding evidence of a reason of war between Great Britain and the Netherlands. He was released from the Tower on 21 December 1781 in exchange for General Lord Cornwallis.

In 1762, George III acquired Buckingham Palace (then called Buckingham House) from the Duke of Buckingham. It was enlarged over the next 75 years by architects such as John Nash.
A phenomenon of the era was the coffeehouse, which became a popular place to debate ideas. Growing literacy and the development of the printing press meant that news became widely available. Fleet Street became the centre of the embryonic national press during the century.

18th-century London was dogged by crime. The Bow Street Runners were established in 1750 as a professional police force. Penalties for crime were harsh, with the death penalty being applied for fairly minor crimes. Public hangings were common in London, and were popular public events.

In 1780, London was rocked by the Gordon Riots, an uprising by Protestants against Roman Catholic emancipation led by Lord George Gordon. Severe damage was caused to Catholic churches and homes, and 285 rioters were killed.

In the year 1787, freed slaves from London, America, and many of Britain's colonies founded Freetown in modern-day Sierra Leone.

Up until 1750, London Bridge was the only crossing over the Thames, but in that year Westminster Bridge was opened and, for the first time in history, London Bridge, in a sense, had a rival. In 1798, Frankfurt banker Nathan Mayer Rothschild arrived in London and set up a banking house in the city, with a large sum of money given to him by his father, Amschel Mayer Rothschild. The Rothschilds also had banks in Paris and Vienna. The bank financed numerous large-scale projects, especially regarding railways around the world and the Suez Canal.

The 18th century saw the breakaway of the American colonies and many other unfortunate events in London, but also great change and Enlightenment. This all led into the beginning of modern times, the 19th century.

During the 19th century, London was transformed into the world's largest city and capital of the British Empire. Its population expanded from 1 million in 1800 to 6.7 million a century later. During this period, London became a global political, financial, and trading capital. In this position, it was largely unrivalled until the latter part of the century, when Paris and New York began to threaten its dominance.

While the city grew wealthy as Britain's holdings expanded, 19th-century London was also a city of poverty, where millions lived in overcrowded and unsanitary slums. Life for the poor was immortalised by Charles Dickens in such novels as Oliver Twist In 1810, after the death of Sir Francis Baring and Abraham Goldsmid, Rothschild emerges as the major banker in London.

In 1829, the then Home Secretary (and future prime minister) Robert Peel established the Metropolitan Police as a police force covering the entire urban area. The force gained the nickname of "bobbies" or "peelers" named after Robert Peel.

19th-century London was transformed by the coming of the railways. A new network of metropolitan railways allowed for the development of suburbs in neighbouring counties from which middle-class and wealthy people could commute to the centre. While this spurred the massive outward growth of the city, the growth of greater London also exacerbated the class divide, as the wealthier classes emigrated to the suburbs, leaving the poor to inhabit the inner city areas.

The first railway to be built in London was a line from London Bridge to Greenwich, which opened in 1836. This was soon followed by the opening of great rail termini which eventually linked London to every corner of Great Britain, including Euston station (1837), Paddington station (1838), Fenchurch Street station (1841), Waterloo station (1848), King's Cross station (1850), and St Pancras station (1863). From 1863, the first lines of the London Underground were constructed.

The urbanised area continued to grow rapidly, spreading into Islington, Paddington, Belgravia, Holborn, Finsbury, Shoreditch, Southwark and Lambeth. Towards the middle of the century, London's antiquated local government system, consisting of ancient parishes and vestries, struggled to cope with the rapid growth in population. In 1855, the Metropolitan Board of Works (MBW) was created to provide London with adequate infrastructure to cope with its growth. One of its first tasks was addressing London's sanitation problems. At the time, raw sewage was pumped straight into the River Thames. This culminated in The Great Stink of 1858. Parliament finally gave consent for the MBW to construct a large system of sewers. The engineer put in charge of building the new system was Joseph Bazalgette. In what was one of the largest civil engineering projects of the 19th century, he oversaw construction of over 2100 km of tunnels and pipes under London to take away sewage and provide clean drinking water. When the London sewerage system was completed, the death toll in London dropped dramatically, and epidemics of cholera and other diseases were curtailed. Bazalgette's system is still in use today.

One of the most famous events of 19th-century London was the Great Exhibition of 1851. Held at The Crystal Palace, the fair attracted 6 million visitors from across the world and displayed Britain at the height of its Imperial dominance.

As the capital of a massive empire, London became a magnet for immigrants from the colonies and poorer parts of Europe. A large Irish population settled in the city during the Victorian period, with many of the newcomers refugees from the Great Famine (1845–1849). At one point, Catholic Irish made up about 20% of London's population; they typically lived in overcrowded slums. London also became home to a sizable Jewish community, which was notable for its entrepreneurship in the clothing trade and merchandising.

In 1888, the new County of London was established, administered by the London County Council. This was the first elected London-wide administrative body, replacing the earlier Metropolitan Board of Works, which had been made up of appointees. The County of London covered broadly what was then the full extent of the London conurbation, although the conurbation later outgrew the boundaries of the county. In 1900, the county was sub-divided into 28 metropolitan boroughs, which formed a more local tier of administration than the county council.

Many famous buildings and landmarks of London were constructed during the 19th century including:

London entered the 20th century at the height of its influence as the capital of one of the largest empires in history, but the new century was to bring many challenges.

London's population continued to grow rapidly in the early decades of the century, and public transport was greatly expanded. A large tram network was constructed by the London County Council, through the LCC Tramways; the first motorbus service began in the 1900s. Improvements to London's overground and underground rail network, including large scale electrification were progressively carried out.

During World War I, London experienced its first bombing raids carried out by German zeppelin airships; these killed around 700 people and caused great terror, but were merely a foretaste of what was to come. The city of London would experience many more terrors as a result of both World Wars. The largest explosion in London occurred during World War I: the Silvertown explosion, when a munitions factory containing 50 tons of TNT exploded, killing 73 and injuring 400.

The period between the two World Wars saw London's geographical extent growing more quickly than ever before or since. A preference for lower density suburban housing, typically semi-detached, by Londoners seeking a more "rural" lifestyle, superseded Londoners' old predilection for terraced houses. This was facilitated not only by a continuing expansion of the rail network, including trams and the Underground, but also by slowly widening car ownership. London's suburbs expanded outside the boundaries of the County of London, into the neighbouring counties of Essex, Hertfordshire, Kent, Middlesex and Surrey.

Like the rest of the country, London suffered severe unemployment during the Great Depression of the 1930s. In the East End during the 1930s, politically extreme parties of both right and left flourished. The Communist Party of Great Britain and the British Union of Fascists both gained serious support. Clashes between right and left culminated in the Battle of Cable Street in 1936. The population of London reached an all-time peak of 8.6 million in 1939.

Large numbers of Jewish immigrants fleeing from Nazi Germany settled in London during the 1930s, mostly in the East End.

Labour Party politician Herbert Morrison was a dominant figure in local government in the 1920s and 1930s. He became mayor of Hackney and a member of the London County Council in 1922, and for a while was Minister of Transport in Ramsay MacDonald's cabinet. When Labour gained power in London in 1934, Morrison unified the bus, tram and trolleybus services with the Underground, by the creation of the London Passenger Transport Board (known as London Transport) in 1933., He led the effort to finance and build the new Waterloo Bridge. He designed the Metropolitan Green Belt around the suburbs and worked to clear slums, build schools, and reform public assistance.

During World War II, London, as many other British cities, suffered severe damage, being bombed extensively by the "Luftwaffe" as a part of The Blitz. Prior to the bombing, hundreds of thousands of children in London were evacuated to the countryside to avoid the bombing. Civilians took shelter from the air raids in underground stations.

The heaviest bombing took place during The Blitz between 7 September 1940 and 10 May 1941. During this period, London was subjected to 71 separate raids receiving over 18,000 tonnes of high explosive. One raid in December 1940, which became known as the Second Great Fire of London, saw a firestorm engulf much of the City of London and destroy many historic buildings. St Paul's Cathedral, however, remained unscathed; a photograph showing the Cathedral shrouded in smoke became a famous image of the war.

Having failed to defeat Britain, Hitler turned his attention to the Eastern front and regular bombing raids ceased. They began again, but on a smaller scale with the "Little Blitz" in early 1944. Towards the end of the war, during 1944/45 London again came under heavy attack by pilotless V-1 flying bombs and V-2 rockets, which were fired from Nazi occupied Europe. These attacks only came to an end when their launch sites were captured by advancing Allied forces.

London suffered severe damage and heavy casualties, the worst hit part being the Docklands area. By the war's end, just under 30,000 Londoners had been killed by the bombing, and over 50,000 seriously injured, tens of thousands of buildings were destroyed, and hundreds of thousands of people were made homeless.

Three years after the war, the 1948 Summer Olympics were held at the original Wembley Stadium, at a time when the city had barely recovered from the war. London's rebuilding was slow to begin. However, in 1951 the Festival of Britain was held, which marked an increasing mood of optimism and forward looking.

In the immediate postwar years housing was a major issue in London, due to the large amount of housing which had been destroyed in the war. The authorities decided upon high-rise blocks of flats as the answer to housing shortages. During the 1950s and 1960s the skyline of London altered dramatically as tower blocks were erected, although these later proved unpopular. In a bid to reduce the number of people living in overcrowded housing, a policy was introduced of encouraging people to move into newly built new towns surrounding London.

Through the 19th and in the early half of the 20th century, Londoners used coal for heating their homes, which produced large amounts of smoke. In combination with climatic conditions this often caused a characteristic smog, and London became known for its typical "London Fog", also known as "Pea Soupers". London was sometimes referred to as "The Smoke" because of this. In 1952, this culminated in the disastrous Great Smog of 1952 which lasted for five days and killed over 4,000 people. In response to this, the Clean Air Act 1956 was passed, mandating the creating of "smokeless zones" where the use of "smokeless" fuels was required (this was at a time when most households still used open fires); the Act was effective.
Starting in the mid-1960s, and partly as a result of the success of such UK musicians as the Beatles and The Rolling Stones, London became a centre for the worldwide youth culture, exemplified by the Swinging London subculture which made Carnaby Street a household name of youth fashion around the world. London's role as a trendsetter for youth fashion continued strongly in the 1980s during the new wave and punk eras and into the mid-1990s with the emergence of the Britpop era.

From the 1950s onwards London became home to a large number of immigrants, largely from Commonwealth countries such as Jamaica, India, Bangladesh, Pakistan, which dramatically changed the face of London, turning it into one of the most diverse cities in Europe. However, the integration of the new immigrants was not always easy. Racial tensions emerged in events such as the Brixton Riots in the early 1980s.

From the beginning of "The Troubles" in Northern Ireland in the early 1970s until the mid-1990s, London was subjected to repeated terrorist attacks by the Provisional IRA.

The outward expansion of London was slowed by the war, and the introduction of the Metropolitan Green Belt. Due to this outward expansion, in 1965 the old County of London (which by now only covered part of the London conurbation) and the London County Council were abolished, and the much larger area of Greater London was established with a new Greater London Council (GLC) to administer it, along with 32 new London boroughs.

Greater London's population declined steadily in the decades after World War II, from an estimated peak of 8.6 million in 1939 to around 6.8 million in the 1980s. However, it then began to increase again in the late 1980s, encouraged by strong economic performance and an increasingly positive image.

London's traditional status as a major port declined dramatically in the post-war decades as the old Docklands could not accommodate large modern container ships. The principal ports for London moved downstream to the ports of Felixstowe and Tilbury. The docklands area had become largely derelict by the 1980s, but was redeveloped into flats and offices from the mid-1980s onwards. The Thames Barrier was completed in the 1980s to protect London against tidal surges from the North Sea.

In the early 1980s political disputes between the GLC run by Ken Livingstone and the Conservative government of Margaret Thatcher led to the GLC's abolition in 1986, with most of its powers relegated to the London boroughs. This left London as the only large metropolis in the world without a central administration.

In 2000, London-wide government was restored, with the creation of the Greater London Authority (GLA) by Tony Blair's government, covering the same area of Greater London. The new authority had similar powers to the old GLC, but was made up of a directly elected Mayor and a London Assembly. The first election took place on 4 May, with Ken Livingstone comfortably regaining his previous post. London was recognised as one of the nine regions of England. In global perspective, it was emerging as a World city widely compared to New York and Tokyo.

Around the start of the 21st century, London hosted the much derided Millennium Dome at Greenwich, to mark the new century. Other Millennium projects were more successful. One was the largest observation wheel in the world, the "Millennium Wheel", or the London Eye, which was erected as a temporary structure, but soon became a fixture, and draws four million visitors a year. The National Lottery also released a flood of funds for major enhancements to existing attractions, for example the roofing of the Great Court at the British Museum.

The London Plan, published by the Mayor of London in 2004, estimated that the population would reach 8.1 million by 2016, and continue to rise thereafter. This was reflected in a move towards denser, more urban styles of building, including a greatly increased number of tall buildings, and proposals for major enhancements to the public transport network. However, funding for projects such as Crossrail remained a struggle.

On 6 July 2005 London won the right to host the 2012 Olympics and Paralympics making it the first city to host the modern games three times. However, celebrations were cut short the following day when the city was rocked by a series of terrorist attacks. More than 50 were killed and 750 injured in three bombings on London Underground trains and a fourth on a double decker bus near King's Cross.

London was the starting point for countrywide riots which occurred in August 2011, when thousands of people rioted in several city boroughs and in towns across England. In 2011, the population grew over 8 million people for the first time in decades. White British formed less than half of the population for the first time.

In the public there was ambivalence leading-up to the Olympics, though public sentiment changed strongly in their favour following a successful opening ceremony and when the anticipated organisational and transport problems never occurred.









</doc>
<doc id="14021" url="https://en.wikipedia.org/wiki?curid=14021" title="History of astronomy">
History of astronomy

Astronomy is the oldest of the natural sciences, dating back to antiquity, with its origins in the religious, mythological, cosmological, calendrical, and astrological beliefs and practices of prehistory: vestiges of these are still found in astrology, a discipline long interwoven with public and governmental astronomy. It was not completely separated in Europe (see astrology and astronomy) during the Copernican Revolution starting in 1543. In some cultures, astronomical data was used for astrological prognostication. The study of astronomy has received financial and social support from many institutions, especially the Church, which was its largest source of support between the 12th century to the Enlightenment.

Ancient astronomers were able to differentiate between stars and planets, as stars remain relatively fixed over the centuries while planets will move an appreciable amount during a comparatively short time.

Early cultures identified celestial objects with gods and spirits. They related these objects (and their movements) to phenomena such as rain, drought, seasons, and tides. It is generally believed that the first astronomers were priests, and that they understood celestial objects and events to be manifestations of the divine, hence early astronomy's connection to what is now called astrology. A 32,500 year old carved ivory Mammoth tusk could contain the oldest known star chart (resembling the constellation Orion). It has also been suggested that drawing on the wall of the Lascaux caves in France dating from 33,000 to 10,000 years ago could be a graphical representation of the Pleiades, the Summer Triangle, and the Northern Crown. Ancient structures with possibly astronomical alignments (such as Stonehenge) probably fulfilled astronomical, religious, and social functions.

Calendars of the world have often been set by observations of the Sun and Moon (marking the day, month and year), and were important to agricultural societies, in which the harvest depended on planting at the correct time of year, and for which the nearly full moon was the only lighting for night-time travel into city markets.
The common modern calendar is based on the Roman calendar. Although originally a lunar calendar, it broke the traditional link of the month to the phases of the Moon and divided the year into twelve almost-equal months, that mostly alternated between thirty and thirty-one days. Julius Caesar instigated calendar reform in 46 BCE and introduced what is now called the Julian calendar, based upon the 365  day year length originally proposed by the 4th century BCE Greek astronomer Callippus.

The origins of Western astronomy can be found in Mesopotamia, the "land between the rivers" Tigris and Euphrates, where the ancient kingdoms of Sumer, Assyria, and Babylonia were located. A form of writing known as cuneiform emerged among the Sumerians around 3500–3000 BC. Our knowledge of Sumerian astronomy is indirect, via the earliest Babylonian star catalogues dating from about 1200 BC. The fact that many star names appear in Sumerian suggests a continuity reaching into the Early Bronze Age. Astral theology, which gave planetary gods an important role in Mesopotamian mythology and religion, began with the Sumerians. They also used a sexagesimal (base 60) place-value number system, which simplified the task of recording very large and very small numbers. The modern practice of dividing a circle into 360 degrees, or an hour into 60 minutes, began with the Sumerians. For more information, see the articles on Babylonian numerals and mathematics.

Classical sources frequently use the term Chaldeans for the astronomers of Mesopotamia, who were, in reality, priest-scribes specializing in astrology and other forms of divination.

The first evidence of recognition that astronomical phenomena are periodic and of the application of mathematics to their prediction is Babylonian. Tablets dating back to the Old Babylonian period document the application of mathematics to the variation in the length of daylight over a solar year. Centuries of Babylonian observations of celestial phenomena are recorded in the series of cuneiform tablets known as the "Enūma Anu Enlil". The oldest significant astronomical text that we possess is Tablet 63 of the "Enūma Anu Enlil", the Venus tablet of Ammi-saduqa, which lists the first and last visible risings of Venus over a period of about 21 years and is the earliest evidence that the phenomena of a planet were recognized as periodic. The MUL.APIN, contains catalogues of stars and constellations as well as schemes for predicting heliacal risings and the settings of the planets, lengths of daylight measured by a water clock, gnomon, shadows, and intercalations. The Babylonian GU text arranges stars in 'strings' that lie along declination circles and thus measure right-ascensions or time-intervals, and also employs the stars of the zenith, which are also separated by given right-ascensional differences.

A significant increase in the quality and frequency of Babylonian observations appeared during the reign of Nabonassar (747–733 BC). The systematic records of ominous phenomena in Babylonian astronomical diaries that began at this time allowed for the discovery of a repeating 18-year cycle of lunar eclipses, for example. The Greek astronomer Ptolemy later used Nabonassar's reign to fix the beginning of an era, since he felt that the earliest usable observations began at this time.

The last stages in the development of Babylonian astronomy took place during the time of the Seleucid Empire (323–60 BC). In the 3rd century BC, astronomers began to use "goal-year texts" to predict the motions of the planets. These texts compiled records of past observations to find repeating occurrences of ominous phenomena for each planet. About the same time, or shortly afterwards, astronomers created mathematical models that allowed them to predict these phenomena directly, without consulting past records. A notable Babylonian astronomer from this time was Seleucus of Seleucia, who was a supporter of the heliocentric model.

Babylonian astronomy was the basis for much of what was done in Greek and Hellenistic astronomy, in classical Indian astronomy, in Sassanian Iran, in Byzantium, in Syria, in Islamic astronomy, in Central Asia, and in Western Europe.

Astronomy in the Indian subcontinent dates back to the period of Indus Valley Civilization during 3rd millennium BCE, when it was used to create calendars. As the Indus Valley civilization did not leave behind written documents, the oldest extant Indian astronomical text is the Vedanga Jyotisha, dating from the Vedic period. Vedanga Jyotisha describes rules for tracking the motions of the Sun and the Moon for the purposes of ritual. During the 6th century, astronomy was influenced by the Greek and Byzantine astronomical traditions.

Aryabhata (476–550), in his magnum opus "Aryabhatiya" (499), propounded a computational system based on a planetary model in which the Earth was taken to be spinning on its axis and the periods of the planets were given with respect to the Sun. He accurately calculated many astronomical constants, such as the periods of the planets, times of the solar and lunar eclipses, and the instantaneous motion of the Moon. Early followers of Aryabhata's model included Varahamihira, Brahmagupta, and Bhaskara II.

Astronomy was advanced during the Shunga Empire and many star catalogues were produced during this time. The Shunga period is known as the "Golden age of astronomy in India".
It saw the development of calculations for the motions and places of various planets, their rising and setting, conjunctions, and the calculation of eclipses.

Indian astronomers by the 6th century believed that comets were celestial bodies that re-appeared periodically. This was the view expressed in the 6th century by the astronomers Varahamihira and Bhadrabahu, and the 10th-century astronomer Bhattotpala listed the names and estimated periods of certain comets, but it is unfortunately not known how these figures were calculated or how accurate they were.

Bhāskara II (1114–1185) was the head of the astronomical observatory at Ujjain, continuing the mathematical tradition of Brahmagupta. He wrote the "Siddhantasiromani" which consists of two parts: "Goladhyaya" (sphere) and "Grahaganita" (mathematics of the planets). He also calculated the time taken for the Earth to orbit the Sun to 9 decimal places. The Buddhist University of Nalanda at the time offered formal courses in astronomical studies.

Other important astronomers from India include Madhava of Sangamagrama, Nilakantha Somayaji and Jyeshtadeva, who were members of the Kerala school of astronomy and mathematics from the 14th century to the 16th century. Nilakantha Somayaji, in his "Aryabhatiyabhasya", a commentary on Aryabhata's "Aryabhatiya", developed his own computational system for a partially heliocentric planetary model, in which Mercury, Venus, Mars, Jupiter and Saturn orbit the Sun, which in turn orbits the Earth, similar to the Tychonic system later proposed by Tycho Brahe in the late 16th century. Nilakantha's system, however, was mathematically more efficient than the Tychonic system, due to correctly taking into account the equation of the centre and latitudinal motion of Mercury and Venus. Most astronomers of the Kerala school of astronomy and mathematics who followed him accepted his planetary model.

The Ancient Greeks developed astronomy, which they treated as a branch of mathematics, to a highly sophisticated level. The first geometrical, three-dimensional models to explain the apparent motion of the planets were developed in the 4th century BC by Eudoxus of Cnidus and Callippus of Cyzicus. Their models were based on nested homocentric spheres centered upon the Earth. Their younger contemporary Heraclides Ponticus proposed that the Earth rotates around its axis.

A different approach to celestial phenomena was taken by natural philosophers such as Plato and Aristotle. They were less concerned with developing mathematical predictive models than with developing an explanation of the reasons for the motions of the Cosmos. In his "Timaeus", Plato described the universe as a spherical body divided into circles carrying the planets and governed according to harmonic intervals by a world soul. Aristotle, drawing on the mathematical model of Eudoxus, proposed that the universe was made of a complex system of concentric spheres, whose circular motions combined to carry the planets around the earth. This basic cosmological model prevailed, in various forms, until the 16th century.

In the 3rd century BC Aristarchus of Samos was the first to suggest a heliocentric system, although only fragmentary descriptions of his idea survive. Eratosthenes estimated the circumference of the Earth with great accuracy.

Greek geometrical astronomy developed away from the model of concentric spheres to employ more complex models in which an eccentric circle would carry around a smaller circle, called an epicycle which in turn carried around a planet. The first such model is attributed to Apollonius of Perga and further developments in it were carried out in the 2nd century BC by Hipparchus of Nicea. Hipparchus made a number of other contributions, including the first measurement of precession and the compilation of the first star catalog in which he proposed our modern system of apparent magnitudes.

The Antikythera mechanism, an ancient Greek astronomical observational device for calculating the movements of the Sun and the Moon, possibly the planets, dates from about 150–100 BC, and was the first ancestor of an astronomical computer. It was discovered in an ancient shipwreck off the Greek island of Antikythera, between Kythera and Crete. The device became famous for its use of a differential gear, previously believed to have been invented in the 16th century, and the miniaturization and complexity of its parts, comparable to a clock made in the 18th century. The original mechanism is displayed in the Bronze collection of the National Archaeological Museum of Athens, accompanied by a replica.

Depending on the historian's viewpoint, the acme or corruption of physical Greek astronomy is seen with Ptolemy of Alexandria, who wrote the classic comprehensive presentation of geocentric astronomy, the "Megale Syntaxis" (Great Synthesis), better known by its Arabic title "Almagest", which had a lasting effect on astronomy up to the Renaissance. In his "Planetary Hypotheses", Ptolemy ventured into the realm of cosmology, developing a physical model of his geometric system, in a universe many times smaller than the more realistic conception of Aristarchus of Samos four centuries earlier.

The precise orientation of the Egyptian pyramids affords a lasting demonstration of the high degree of technical skill in watching the heavens attained in the 3rd millennium BC. It has been shown the Pyramids were aligned towards the pole star, which, because of the precession of the equinoxes, was at that time Thuban, a faint star in the constellation of Draco. Evaluation of the site of the temple of Amun-Re at Karnak, taking into account the change over time of the obliquity of the ecliptic, has shown that the Great Temple was aligned on the rising of the midwinter Sun. The length of the corridor down which sunlight would travel would have limited illumination at other times of the year. The Egyptians also found the position of Sirius (the dog star) who they believed was Anubis their Jackal headed god moving through the heavens. Its position was critical to their civilisation as when it rose heliacal in the east before sunrise it foretold the flooding of the Nile. It is also where we get the phrase 'dog days of summer' from.

Astronomy played a considerable part in religious matters for fixing the dates of festivals and determining the hours of the night. The titles of several temple books are preserved recording the movements and phases of the sun, moon and stars. The rising of Sirius (Egyptian: Sopdet, Greek: Sothis) at the beginning of the inundation was a particularly important point to fix in the yearly calendar.

Writing in the Roman era, Clement of Alexandria gives some idea of the importance of astronomical observations to the sacred rites:
And after the Singer advances the Astrologer (ὡροσκόπος), with a "horologium" (ὡρολόγιον) in his hand, and a "palm" (φοίνιξ), the symbols of astrology. He must know by heart the Hermetic astrological books, which are four in number. Of these, one is about the arrangement of the fixed stars that are visible; one on the positions of the Sun and Moon and five planets; one on the conjunctions and phases of the Sun and Moon; and one concerns their risings.

The Astrologer's instruments ("horologium" and "palm") are a plumb line and sighting instrument. They have been identified with two inscribed objects in the Berlin Museum; a short handle from which a plumb line was hung, and a palm branch with a sight-slit in the broader end. The latter was held close to the eye, the former in the other hand, perhaps at arm's length. The "Hermetic" books which Clement refers to are the Egyptian theological texts, which probably have nothing to do with Hellenistic Hermetism.

From the tables of stars on the ceiling of the tombs of Rameses VI and Rameses IX it seems that for fixing the hours of the night a man seated on the ground faced the Astrologer in such a position that the line of observation of the pole star passed over the middle of his head. On the different days of the year each hour was determined by a fixed star culminating or nearly culminating in it, and the position of these stars at the time is given in the tables as in the centre, on the left eye, on the right shoulder, etc. According to the texts, in founding or rebuilding temples the north axis was determined by the same apparatus, and we may conclude that it was the usual one for astronomical observations. In careful hands it might give results of a high degree of accuracy.

The astronomy of East Asia began in China. Solar term was completed in Warring States period. The knowledge of Chinese astronomy was introduced into East Asia.

Astronomy in China has a long history. Detailed records of astronomical observations were kept from about the 6th century BC, until the introduction of Western astronomy and the telescope in the 17th century. Chinese astronomers were able to precisely predict eclipses.

Much of early Chinese astronomy was for the purpose of timekeeping. The Chinese used a lunisolar calendar, but because the cycles of the Sun and the Moon are different, astronomers often prepared new calendars and made observations for that purpose.

Astrological divination was also an important part of astronomy. Astronomers took careful note of "guest stars" which suddenly appeared among the fixed stars. They were the first to record a supernova, in the Astrological Annals of the Houhanshu in 185 AD. Also, the supernova that created the Crab Nebula in 1054 is an example of a "guest star" observed by Chinese astronomers, although it was not recorded by their European contemporaries. Ancient astronomical records of phenomena like supernovae and comets are sometimes used in modern astronomical studies.

The world's first star catalogue was made by Gan De, a , in the 4th century BC.

Maya astronomical codices include detailed tables for calculating phases of the Moon, the recurrence of eclipses, and the appearance and disappearance of Venus as morning and evening star. The Maya based their calendrics in the carefully calculated cycles of the Pleiades, the Sun, the Moon, Venus, Jupiter, Saturn, Mars, and also they had a precise description of the eclipses as depicted in the Dresden Codex, as well as the ecliptic or zodiac, and the Milky Way was crucial in their Cosmology. A number of important Maya structures are believed to have been oriented toward the extreme risings and settings of Venus. To the ancient Maya, Venus was the patron of war and many recorded battles are believed to have been timed to the motions of this planet. Mars is also mentioned in preserved astronomical codices and early mythology.

Although the Maya calendar was not tied to the Sun, John Teeple has proposed that the Maya calculated the solar year to somewhat greater accuracy than the Gregorian calendar. Both astronomy and an intricate numerological scheme for the measurement of time were vitally important components of Maya religion.

Since 1990 our understanding of prehistoric Europeans has been radically changed by discoveries of ancient astronomical artifacts throughout Europe. The artifacts demonstrate that Neolithic and Bronze Age Europeans had a sophisticated knowledge of mathematics and astronomy.

Among the discoveries are:


The Arabic and the Persian world under Islam had become highly cultured, and many important works of knowledge from Greek astronomy and Indian astronomy and Persian astronomy were translated into Arabic, used and stored in libraries throughout the area. An important contribution by Islamic astronomers was their emphasis on observational astronomy. This led to the emergence of the first astronomical observatories in the Muslim world by the early 9th century. Zij star catalogues were produced at these observatories.

In the 10th century, Abd al-Rahman al-Sufi (Azophi) carried out observations on the stars and described their positions, magnitudes, brightness, and colour and drawings for each constellation in his "Book of Fixed Stars". He also gave the first descriptions and pictures of "A Little Cloud" now known as the Andromeda Galaxy. He mentions it as lying before the mouth of a Big Fish, an Arabic constellation. This "cloud" was apparently commonly known to the Isfahan astronomers, very probably before 905 AD. The first recorded mention of the Large Magellanic Cloud was also given by al-Sufi. In 1006, Ali ibn Ridwan observed SN 1006, the brightest supernova in recorded history, and left a detailed description of the temporary star.

In the late 10th century, a huge observatory was built near Tehran, Iran, by the astronomer Abu-Mahmud al-Khujandi who observed a series of meridian transits of the Sun, which allowed him to calculate the tilt of the Earth's axis relative to the Sun. He noted that measurements by earlier (Indian, then Greek) astronomers had found higher values for this angle, possible evidence that the axial tilt is not constant but was in fact decreasing. In 11th-century Persia, Omar Khayyám compiled many tables and performed a reformation of the calendar that was more accurate than the Julian and came close to the Gregorian.

Other Muslim advances in astronomy included the collection and correction of previous astronomical data, resolving significant problems in the Ptolemaic model, the development of the universal latitude-independent astrolabe by Arzachel, the invention of numerous other astronomical instruments, Ja'far Muhammad ibn Mūsā ibn Shākir's belief that the heavenly bodies and celestial spheres were subject to the same physical laws as Earth, the first elaborate experiments related to astronomical phenomena, the introduction of exacting empirical observations and experimental techniques, and the introduction of empirical testing by Ibn al-Shatir, who produced the first model of lunar motion which matched physical observations.

Natural philosophy (particularly Aristotelian physics) was separated from astronomy by Ibn al-Haytham (Alhazen) in the 11th century, by Ibn al-Shatir in the 14th century, and Qushji in the 15th century, leading to the development of an astronomical physics.

After the significant contributions of Greek scholars to the development of astronomy, it entered a relatively static era in Western Europe from the Roman era through the 12th century. This lack of progress has led some astronomers to assert that nothing happened in Western European astronomy during the Middle Ages. Recent investigations, however, have revealed a more complex picture of the study and teaching of astronomy in the period from the 4th to the 16th centuries.

Western Europe entered the Middle Ages with great difficulties that affected the continent's intellectual production. The advanced astronomical treatises of classical antiquity were written in Greek, and with the decline of knowledge of that language, only simplified summaries and practical texts were available for study. The most influential writers to pass on this ancient tradition in Latin were Macrobius, Pliny, Martianus Capella, and Calcidius. In the 6th century Bishop Gregory of Tours noted that he had learned his astronomy from reading Martianus Capella, and went on to employ this rudimentary astronomy to describe a method by which monks could determine the time of prayer at night by watching the stars.

In the 7th century the English monk Bede of Jarrow published an influential text, "On the Reckoning of Time", providing churchmen with the practical astronomical knowledge needed to compute the proper date of Easter using a procedure called the "computus". This text remained an important element of the education of clergy from the 7th century until well after the rise of the Universities in the 12th century.

The range of surviving ancient Roman writings on astronomy and the teachings of Bede and his followers began to be studied in earnest during the revival of learning sponsored by the emperor Charlemagne. By the 9th century rudimentary techniques for calculating the position of the planets were circulating in Western Europe; medieval scholars recognized their flaws, but texts describing these techniques continued to be copied, reflecting an interest in the motions of the planets and in their astrological significance.

Building on this astronomical background, in the 10th century European scholars such as Gerbert of Aurillac began to travel to Spain and Sicily to seek out learning which they had heard existed in the Arabic-speaking world. There they first encountered various practical astronomical techniques concerning the calendar and timekeeping, most notably those dealing with the astrolabe. Soon scholars such as Hermann of Reichenau were writing texts in Latin on the uses and construction of the astrolabe and others, such as Walcher of Malvern, were using the astrolabe to observe the time of eclipses in order to test the validity of computistical tables.

By the 12th century, scholars were traveling to Spain and Sicily to seek out more advanced astronomical and astrological texts, which they translated into Latin from Arabic and Greek to further enrich the astronomical knowledge of Western Europe. The arrival of these new texts coincided with the rise of the universities in medieval Europe, in which they soon found a home. Reflecting the introduction of astronomy into the universities, John of Sacrobosco wrote a series of influential introductory astronomy textbooks: the Sphere, a Computus, a text on the Quadrant, and another on Calculation.

In the 14th century, Nicole Oresme, later bishop of Liseux, showed that neither the scriptural texts nor the physical arguments advanced against the movement of the Earth were demonstrative and adduced the argument of simplicity for the theory that the Earth moves, and "not" the heavens. However, he concluded "everyone maintains, and I think myself, that the heavens do move and not the earth: For God hath established the world which shall not be moved." In the 15th century, Cardinal Nicholas of Cusa suggested in some of his scientific writings that the Earth revolved around the Sun, and that each star is itself a distant sun.

During the renaissance period, astronomy began to undergo a revolution in thought known as the Copernican revolution, which gets the name from the astronomer Nicolaus Copernicus, who proposed a heliocentric system, in which the planets revolved around the Sun and not the Earth. His "De Revolutionibus Orbium Coelestium" was published in 1543. While in the long term this was a very controversial claim, in the very beginning it only brought minor controversy. The theory became the dominant view because many figures, most notably Galileo Galilei, Johannes Kepler and Isaac Newton championed and improved upon the work. Other figures also aided this new model despite not believing the overall theory, like Tycho Brahe, with his well-known observations.

Brahe, a Danish noble, was an essential astronomer in this period. He came on the astronomical scene with the publication of "De Nova Stella" in which he disproved conventional wisdom on the supernova SN 1572. He also created the Tychonic System in which he blended the mathematical benefits of the Copernican system and the “physical benefits” of the Ptolemaic system. This was one of the systems people believed in when they did not accept heliocentrism, but could no longer accept the Ptolemaic system. He is most known for his highly accurate observations of the stars and the solar system. Later he moved to Prague and continued his work. In Prague he was at work on the Rudolphine Tables, that were not finished until after his death. The Rudolphine Tables was a star map designed to be more accurate than either the Alphonsine Tables, made in the 1300s and the Prutenic Tables which were inaccurate. He was assisted at this time by his assistant Johannes Kepler, who would later use his observations to finish Brahe's works and for his theories as well.

After the death of Brahe, Kepler was deemed his successor and was given the job of completing Brahe's uncompleted works, like the Rudolphine Tables. He completed the Rudolphine Tables in 1624, although it was not published for several years. Like many other figures of this era, he was subject to religious and political troubles, like the Thirty Years War, which led to chaos that almost destroyed some of his works. Kepler was, however, the first to attempt to derive mathematical predictions of celestial motions from assumed physical causes. He discovered the three Kepler's Laws of Planetary Motion that now carry his name, those laws being as follows:


With these laws, he managed to improve upon the existing Heliocentric model. The first two were published in 1609. Kepler's contributions improved upon the overall system, giving it more credibility because it adequately explained events and could cause more reliable predictions. Before this the Copernican model was just as unreliable as the Ptolemaic model. This improvement came because Kepler realized the orbits were not perfect circles, but ellipses.Galileo Galilei was among the first to use a telescope to observe the sky, and after constructing a 20x refractor telescope. He discovered the four largest moons of Jupiter in 1610, which are now collectively known as the Galilean moons, in his honor. This discovery was the first known observation of satellites orbiting another planet. He also found that our Moon had craters and observed, and correctly explained, sunspots, and that Venus exhibited a full set of phases resembling lunar phases. Galileo argued that these facts demonstrated incompatibility with the Ptolemaic model, which could not explain the phenomenon and would even contradict it. With the moons it demonstrated that the Earth does not have to have everything orbiting it and that other parts of the Solar System could orbit another object, such as the Earth orbiting the Sun. In the Ptolemaic system the celestial bodies were supposed to be perfect so such objects should not have craters or sunspots. The phases of Venus could only happen in the event that Venus's orbit is insides Earth's orbit, which could not happen if the Earth was the center. He, as the most famous example, had to face challenges from church officials, more specifically the Roman Inquisition. They accused him of heresy because these beliefs went against the teachings of the Roman Catholic Church and were challenging the Catholic church's authority when it was at its weakest. While he was able to avoid punishment for a little while he was eventually tried and pled guilty to heresy in 1633. Although this came at some expense, his book was banned, and he was put under house arrest until he died in 1642.Sir Isaac Newton developed further ties between physics and astronomy through his law of universal gravitation. Realizing that the same force that attracts objects to the surface of the Earth held the Moon in orbit around the Earth, Newton was able to explain – in one theoretical framework – all known gravitational phenomena. In his "Philosophiae Naturalis Principia Mathematica", he derived Kepler's laws from first principles. Those first principles are as follows:


Thus while Kepler explained how the planets moved, Newton accurately managed to explain why the planets moved the way they do. Newton's theoretical developments laid many of the foundations of modern physics.

Outside of England, Newton's theory took some time to become established. Descartes' theory of vortices held sway in France, and Huygens, Leibniz and Cassini accepted only parts of Newton's system, preferring their own philosophies. Voltaire published a popular account in 1738. In 1748, the French Academy of Sciences offered a reward for solving the perturbations of Jupiter and Saturn which was eventually solved by Euler and Lagrange. Laplace completed the theory of the planets, publishing from 1798 to 1825.

Edmund Halley succeeded Flamsteed as Astronomer Royal in England and succeeded in predicting the return in 1758 of the comet that bears his name. Sir William Herschel found the first new planet, Uranus, to be observed in modern times in 1781. The gap between the planets Mars and Jupiter disclosed by the Titius–Bode law was filled by the discovery of the asteroids Ceres and Pallas in 1801 and 1802 with many more following.

At first, astronomical thought in America was based on Aristotelian philosophy, but interest in the new astronomy began to appear in Almanacs as early as 1659.

In the 19th century, Joseph von Fraunhofer discovered that when sunlight was dispersed, a multitude of spectral lines were observed (regions where there was less or no light). Experiments with hot gases showed that the same lines could be observed in the spectra of gases, with specific lines corresponding to unique elements. It was proved that the chemical elements found in the Sun (chiefly hydrogen and helium) were also found on Earth.
During the 20th century spectroscopy (the study of these lines) advanced, especially because of the advent of quantum physics, which was necessary to understand the observations.

Although in previous centuries noted astronomers were exclusively male, at the turn of the 20th century women began to play a role in the great discoveries. In this period prior to modern computers, women at the United States Naval Observatory (USNO), Harvard University, and other astronomy research institutions began to be hired as human "computers", who performed the tedious calculations while scientists performed research requiring more background knowledge. A number of discoveries in this period were originally noted by the women "computers" and reported to their supervisors. For example, at the Harvard Observatory Henrietta Swan Leavitt discovered the cepheid variable star period-luminosity relation which she further developed into a method of measuring distance outside of the Solar System.

Annie Jump Cannon, also at Harvard, organized the stellar spectral types according to stellar temperature. In 1847, Maria Mitchell discovered a comet using a telescope. According to Lewis D. Eigen, Cannon alone, "in only 4 years discovered and catalogued more stars than all the men in history put together."
Most of these women received little or no recognition during their lives due to their lower professional standing in the field of astronomy. Although their discoveries and methods are taught in classrooms around the world, few students of astronomy can attribute the works to their authors or have any idea that there were active female astronomers at the end of the 19th century. 

Most of our current knowledge was gained during the 20th century. With the help of the use of photography, fainter objects were observed. The Sun was found to be part of a galaxy made up of more than 10 stars (10 billion stars). The existence of other galaxies, one of the matters of "the great debate", was settled by Edwin Hubble, who identified the Andromeda nebula as a different galaxy, and many others at large distances and receding, moving away from our galaxy.

Physical cosmology, a discipline that has a large intersection with astronomy, made huge advances during the 20th century, with the model of the hot Big Bang heavily supported by the evidence provided by astronomy and physics, such as the redshifts of very distant galaxies and radio sources, the cosmic microwave background radiation, Hubble's law and cosmological abundances of elements.

In the 19th century, scientists began discovering forms of light which were invisible to the naked eye: X-Rays, gamma rays, radio waves, microwaves, ultraviolet radiation, and infrared radiation. This had a major impact on astronomy, spawning the fields of infrared astronomy, radio astronomy, x-ray astronomy and finally gamma-ray astronomy. With the advent of spectroscopy it was proven that other stars were similar to the Sun, but with a range of temperatures, masses and sizes. The existence of our galaxy, the Milky Way, as a separate group of stars was only proven in the 20th century, along with the existence of "external" galaxies, and soon after, the expansion of the universe seen in the recession of most galaxies from us.







</doc>
<doc id="14022" url="https://en.wikipedia.org/wiki?curid=14022" title="Haber process">
Haber process

The Haber process, also called the Haber–Bosch process, is an artificial nitrogen fixation process and is the main industrial procedure for the production of ammonia today. It is named after its inventors, the German chemists Fritz Haber and Carl Bosch, who developed it in the first decade of the 20th century. The process converts atmospheric nitrogen (N) to ammonia (NH) by a reaction with hydrogen (H) using a metal catalyst under high temperatures and pressures:

Before the development of the Haber process, ammonia had been difficult to produce on an industrial scale, with early methods such as the Birkeland–Eyde process and Frank–Caro process all being highly inefficient.

Although the Haber process is mainly used to produce fertilizer today, during World War I it provided Germany with a source of ammonia for the production of explosives, compensating for the Allied Powers' trade blockade on Chilean saltpeter.

Throughout the 19th century the demand for nitrates and ammonia for use as fertilizers and industrial feedstocks had been steadily increasing. The main source was mining niter deposits and guano from tropical islands. At the beginning of the 20th century it was being predicted that these reserves could not satisfy future demands, and research into new potential sources of ammonia became more important. Although atmospheric nitrogen (N) is abundant, comprising nearly 80% of the air, it is exceptionally stable and does not readily react with other chemicals. Converting N into ammonia posed a challenge for chemists globally.

Haber, with his assistant Robert Le Rossignol, developed the high-pressure devices and catalysts needed to demonstrate the Haber process at laboratory scale. They demonstrated their process in the summer of 1909 by producing ammonia from air, drop by drop, at the rate of about per hour. The process was purchased by the German chemical company BASF, which assigned Carl Bosch the task of scaling up Haber's tabletop machine to industrial-level production. He succeeded in 1910. Haber and Bosch were later awarded Nobel prizes, in 1918 and 1931 respectively, for their work in overcoming the chemical and engineering problems of large-scale, continuous-flow, high-pressure technology.

Ammonia was first manufactured using the Haber process on an industrial scale in 1913 in BASF's Oppau plant in Germany, reaching 20 tonnes per day the following year. During World War I, the production of munitions required large amounts of nitrate. The Allies had access to large sodium nitrate deposits in Chile (Chile saltpetre) controlled by British companies. Germany had no such resources, so the Haber process proved essential to the German war effort. Synthetic ammonia from the Haber process was used for the production of nitric acid, a precursor to the nitrates used in explosives.

Today, the most popular catalysts are based on iron promoted with KO, CaO, SiO, and AlO. The original Haber–Bosch reaction chambers used osmium as the catalyst, but it was available in extremely small quantities. Haber noted uranium was almost as effective and easier to obtain than osmium. Under Bosch's direction in 1909, the BASF researcher Alwin Mittasch discovered a much less expensive iron-based catalyst, which is still used today.

During the interwar years, alternative processes were developed, the most notably different being the Casale process and Claude process. Luigi Casale and Georges Claude proposed to increase the pressure of the synthesis loop to , thereby increasing the single-pass ammonia conversion and making nearly complete liquefaction at ambient temperature feasible. Georges Claude even proposed to have three or four converters with liquefaction steps in series, thereby omitting the need for a recycle. Nowadays, most plants resemble the original Haber process ( and ), albeit with improved single-pass conversion and lower energy consumption due to process and catalyst optimization.

A major contributor to the elucidation of this mechanism was Gerhard Ertl.

This conversion is typically conducted at pressures above 10 MPa (100 bar; 1,450 psi) and between , as the gases (nitrogen and hydrogen) are passed over four beds of catalyst, with cooling between each pass for maintaining a reasonable equilibrium constant. On each pass only about 15% conversion occurs, but any unreacted gases are recycled, and eventually an overall conversion of 97% is achieved.

The steam reforming, shift conversion, carbon dioxide removal, and methanation steps each operate at pressures of about , and the ammonia synthesis loop operates at pressures ranging from , depending upon which proprietary process is used.

The major source of hydrogen is methane from natural gas. The conversion, steam reforming, is conducted with steam in a high-temperature and -pressure tube inside a reformer with a nickel catalyst, separating the carbon and hydrogen atoms in the natural gas. Other fossil fuel sources include coal, heavy fuel oil and naphtha, while hydrogen is also produced from biomass and from electrolysis of water.

Nitrogen gas (N) is very unreactive because the atoms are held together by strong triple bonds. The Haber process relies on catalysts that accelerate the scission of this triple bond.

Two opposing considerations are relevant to this synthesis: the position of the equilibrium and the rate of reaction. At room temperature, the equilibrium is strongly in favor of ammonia, but the reaction doesn't proceed at a detectable rate due to its high activation energy. Because the reaction is exothermic, the equilibrium constant becomes 1 around (see Le Châtelier's principle).
Above this temperature, the equilibrium quickly becomes quite unfavorable for the reaction product at atmospheric pressure, according to the van 't Hoff equation. Lowering the temperature is also unhelpful because the catalyst requires a temperature of at least 400 °C to be efficient.

Increased pressure does favor the forward reaction because there are 4 moles of reactant for every 2 moles of product, and the pressure used () alters the equilibrium concentrations to give a substantial ammonia yield. The reason for this is evident in the equilibrium relationship, which is

formula_2

where formula_3 is the fugacity coefficient of species formula_4, formula_5 is the mole fraction of the same species, formula_6 is the pressure in the reactor, and formula_7 is standard pressure, typically .

Economically, pressurization of the reactor is expensive: pipes, valves, and reaction vessels need to be strengthened, and there are safety considerations when working at 20 MPa. In addition, running compressors takes considerable energy, as work must be done on the (very compressible) gas. Thus, the compromise used gives a single-pass yield of around 15%

While removing the product (i.e., ammonia gas) from the system would increase the reaction yield, this step is not used in practice, since the temperature is too high; it is removed from the equilibrium mixture of gases leaving the reaction vessel. The hot gases are cooled enough, whilst maintaining a high pressure, for the ammonia to condense and be removed as liquid. Unreacted hydrogen and nitrogen gases are then returned to the reaction vessel to undergo further reaction. While most ammonia is removed (typically down to 2–5 mol.%), some ammonia remains in the recycle stream to the converter. In academic literature, more complete separation of ammonia has been proposed by absorption in metal halides and by adsorption on zeolites. Such a process is called a "absorbent-enhanced Haber process" or "adsorbent-enhanced Haber process".

The Haber–Bosch process relies on catalysts to accelerate the hydrogenation of N. The catalysts are "heterogeneous", meaning that they are solid that interact on gaseous reagents. 

The catalyst typically consists of finely divided iron bound to an iron oxide carrier containing promoters possibly including aluminium oxide, potassium oxide, calcium oxide, and magnesium oxide.

In industrial practice, the iron catalyst is obtained from finely ground iron powder, which is usually obtained by reduction of high-purity magnetite (FeO). The pulverized iron metal is burnt (oxidized) to give magnetite or wüstite (FeO, ferrous oxide) of a defined particle size. The magnetite (or wüstite) particles are then partially reduced, removing some of the oxygen in the process. The resulting catalyst particles consist of a core of magnetite, encased in a shell of wüstite, which in turn is surrounded by an outer shell of iron metal. The catalyst maintains most of its bulk volume during the reduction, resulting in a highly porous high-surface-area material, which enhances its effectiveness as a catalyst. Other minor components of the catalyst include calcium and aluminium oxides, which support the iron catalyst and help it maintain its surface area. These oxides of Ca, Al, K, and Si are unreactive to reduction by the hydrogen.

The production of the required magnetite catalyst requires a particular melting process in which the used raw materials must be free of catalyst poisons and the promoter aggregates must be evenly distributed in the magnetite melt. Rapid cooling of the magnetite melt, which has an initial temperature of about 3500 °C, produces the precursor desired highly active catalyst. Unfortunately, the rapid cooling ultimately forms a catalyst of reduced abrasion resistance. Despite this disadvantage, the method of rapid cooling is often preferred in practice.

The reduction of the catalyst precursor magnetite to α-iron is carried out directly in the production plant with synthesis gas. The reduction of the magnetite proceeds via the formation of Wüstite (FeO), so that particles with a core of magnetite surrounded by a shell of Wüstite are formed. The further reduction of magnetite and wüstite leads to the formation of α-iron, which forms together with the promoters the outer shell. The involved processes are complex and depend on the reduction temperature: At lower temperatures, wüstite disproportionates into an iron phase and a magnetite phase; at higher temperatures, the reduction of the wüstite and magnetite to iron dominates.

The α-iron forms primary crystallites with a diameter of about 30 nanometers. These form crystallites a bimodal pore system with pore diameters of about 10 nanometers (produced by the reduction of the magnetite phase) and of 25 to 50 nanometers (produced by the reduction of the desertite phase). With the exception of cobalt oxide, the promoters are not reduced.

During the reduction of the iron oxide with synthesis gas, water vapour is formed. This water vapor must be considered for high catalyst quality as contact with the finely divided iron would lead to premature aging of the catalyst through recrystallization, especially in conjunction with high temperatures. The vapour pressure of the water in the gas mixture produced during catalyst formation is thus kept as low as possible, target values are below 3 gm. For this reason, the reduction is carried out at high gas exchange, low pressure and low temperatures. The exothermic nature of the ammonia formation ensures a gradual increase in temperature.

The reduction of fresh, fully oxidized catalyst or precursor to full production capacity takes four to ten days. The Wüstit phase is reduced faster and at lower temperatures than the magnetite phase (FeO). After detailed kinetic, microscopic and X-ray spectroscopic investigations it was shown that Wüstite reacts first to metallic iron. This leads to a gradient of iron(II) ions, whereby these diffuse from the magnetite through the Wüstite to the particle surface and precipitate there as iron nuclei.

In industrial practice, pre-reduced, stabilised catalysts have gained a significant market share. They are delivered showing the fully developed pore structure, but have been oxidized again on the surface after manufacture and are therefore no longer pyrophoric. The reactivation of such pre-reduced catalysts requires only 30 to 40 hours instead of the usual time periods of several days. In addition to the short start-up time, they also have other advantages such as higher water resistance and lower weight. 
Since the industrial launch of the Haber–Bosch process, many efforts have been made to improve it. Many metals were intensively tested in the search for suitable catalysts: The requirement for suitability is the dissociative adsorption of nitrogen (i. e. the nitrogen molecule must be split upon adsorption into nitrogen atoms). At the same time the binding of the nitrogen atoms must not be too strong, otherwise the catalyst would be blocked and the catalytic ability would be reduced (i. e. self-poisoning). The elements in the periodic table at the left of the iron group show such a strong bond to nitrogen. The formation of surface nitrides makes for example chromium catalysts ineffective. Metals to the right of the iron group, in contrast, adsorb nitrogen too weakly to be able to activate it sufficiently for ammonia synthesis. Haber himself initially used catalysts based on osmium and uranium. Uranium, however, reacts to its nitride during catalysis and osmium oxide is rare.

Due to the comparatively low price, high availability, easy processing, lifespan and activity, iron was ultimately chosen as catalyst. The production of for example 1800 tons ammonia per day requires a gas pressure of at least 130 bar, temperatures of 400 to 500 °C and a reactor volume of at least 100 m³. According to theoretical and practical studies, further improvements of the pure iron catalyst are limited. It was only in 1984 that the activity of iron catalysts were increased noticeably by inclusion of cobalt.

Ruthenium forms highly active catalysts. Allowing milder operating pressures and temperatures, Ru-based materials are referred to as second-generation catalysts. Such catalysts are prepared by decomposition of triruthenium dodecacarbonyl on graphite. A drawback of activated-carbon-supported ruthenium-based catalysts is the methanation of the support in the presence of hydrogen. Their activity is strongly dependent on the catalyst carrier and the promoters. A wide range of substances can be used as carriers, including carbon, magnesium oxide, aluminum oxide, zeolites, spinels, and boron nitride.

Ruthenium-activated carbon-based catalysts have been used industrially in the KBR Advanced Ammonia Process (KAAP) since 1992. The carbon carrier is partially degraded to methane; however, this can be mitigated by a special treatment of the carbon at 1500 °C, thus prolonging the catalysts lifetime. In addition, the finely dispersed carbon poses a risk of explosion. For these reasons and due to its low acidity, magnesium oxide has proven to be a good alternative. Carriers with acidic properties extract electrons from ruthenium, make it less reactive, and undesirably bind ammonia to the surface.

Catalyst poisons lower the activity of the catalyst. They are usually impurities in the synthesis gas (a raw material). Sulfur compounds, phosphorus compounds, arsenic compounds, and chlorine compounds are permanent catalyst poisons. Water, carbon monoxide, carbon dioxide and oxygen are temporary catalyst poisons.

Although chemically inert components of the synthesis gas mixture such as noble gases or methane are not catalyst poisons in the strict sense, they accumulate through the recycling of the process gases and thus lower the partial pressure of the reactants, which in turn has a negative effect on the conversion.

The formation of ammonia occurs from nitrogen and hydrogen according to the following equation:

The reaction is an exothermic equilibrium reaction in which the gas volume is reduced. The equilibrium constant K of the reaction (see table) is obtained from the following equation:

Since the reaction is exothermic, the equilibrium of the reaction shifts at lower temperatures to the side of the ammonia. Furthermore, four volumetric parts of the raw materials produce two volumetric parts of ammonia. According to Le Chatelier's principle, a high pressure therefore also favours the formation of ammonia. In addition, a high pressure is necessary to ensure sufficient surface coverage of the catalyst with nitrogen. For this reason, a ratio of nitrogen to hydrogen of 1 to 3, a pressure of 250 to 350 bar, a temperature of 450 to 550 °C and α iron are used as catalysts.

The catalyst ferrite (α-Fe) is produced in the reactor by the reduction of magnetite with hydrogen. The catalyst has its highest efficiency at temperatures of about 400 to 500 °C. Even though the catalyst greatly lowers the activation energy for the cleavage of the triple bond of the nitrogen molecule, high temperatures are still required for an appropriate reaction rate. At the industirally utilized reaction temperature of 450 to 550 °C an optimum between the decomposition of ammonia into the starting materials and the effectiveness of the catalyst is achieved. The formed ammonia is continuously removed from the system. The volume fraction of ammonia in the gas mixture is about 20%.

The inert components, especially the noble gases such as argon, should not exceed a certain content in order not to reduce the partial pressure of the reactants too much. To remove the inert gas components, part of the gas is removed and the argon is separated in a gas separation plant. The extraction of pure argon from the circulating gas is carried out using the Linde process.

Modern ammonia plants produce more than 3000 tons per day in one production line. The following diagram shows the set-up of a Haber–Bosch plant:

Depending on its origin, the synthesis gas must first be freed from impurities such as hydrogen sulphide or organic sulphur compounds, which act as a catalyst poison. High concentrations of hydrogen sulphide, which occur in synthesis gas from carbonization coke, are removed in a wet cleaning stage such as the Sulfosolvan process, while low concentrations are removed by adsorption on activated carbon. Organosulfur compounds are separated by pressure swing adsorption together with carbon dioxide after CO conversion.

To produce hydrogen by steam reforming, methane reacts with water vapor using a nickel oxide-alumina catalyst in the primary reformer to form carbon monoxide and hydrogen. The energy required for this, the enthalpy ΔH, is 206 kJ/mol.

The methane gas reacts in the primary reformer only partially. In order to increase the hydrogen yield and keep the content of inert components (i. e. methane) as low as possible, the remaining methane gas is converted in a second step with oxygen to hydrogen and carbon monoxide in the secondary reformer. The secondary reformer is supplied with air as oxygen source. Also the required nitrogen for the subsequent ammonia synthesis is added to the gas mixture.

In a third step, the carbon monoxide is oxidized to carbon dioxide, which is called CO conversion or water-gas shift reaction.

Carbon monoxide and carbon dioxide would form carbamates with ammonia, which would clog (as solids) pipelines and apparatus within a short time. In the following process step, the carbon dioxide must therefore be removed from the gas mixture. In contrast to carbon monoxide, carbon dioxide can easily be removed from the gas mixture by gas scrubbing with triethanolamine. The gas mixture then still contains methane and noble gases such as argon, which, however, behave inertly.

The gas mixture is then compressed to operating pressure by turbo compressors. The resulting compression heat is dissipated by heat exchangers; it is used to preheat raw gases.

The actual production of ammonia takes place in the ammonia reactor. The first reactors were bursting under the high pressure because the atomic hydrogen in the carbonaceous steel partially recombined to methane and produced cracks in the steel. Bosch therefore developed tube reactors consisting of a pressure-bearing steel tube in which a low-carbon iron lining tube was inserted filled with the catalyst. Hydrogen that diffused through the inner steel pipe escaped to the outside via thin holes in the outer steel jacket, the so-called Bosch holes. A disadvantage of the tubular reactors was the relatively high pressure loss, which had to be applied again by compression. The development of hydrogen-resistant chromium-molybdenum steels made it possible to construct single-walled pipes.

Modern ammonia reactors are designed as multi-storey reactors with low pressure drop, in which the catalysts are distributed as fills over about ten storeys one above the other. The gas mixture flows through them one after the other from top to bottom. Cold gas is injected from the side for cooling. A disadvantage of this reactor type is the incomplete conversion of the cold gas mixture in the last catalyst bed.

Alternatively, the reaction mixture between the catalyst layers is cooled using heat exchangers, whereby the hydrogen-nitrogen mixture is preheated to reaction temperature. Reactors of this type have three catalyst beds. In addition to good temperature control, this reactor type has the advantage of better conversion of the raw material gases compared to reactors with cold gas injection.

The reaction product is continuously removed for maximum yield. The gas mixture is cooled to 450 °C in a heat exchanger using water, freshly supplied gases and other process streams. The ammonia also condenses and is separated in a pressure separator. Unreacted nitrogen and hydrogen are than compressed back to the process by a circulating gas compressor, supplemented with fresh gas and fed to the reactor. In a subsequent distillation, the product ammonia is purified.

The mechanism of ammonia synthesis contains the following seven elementary steps:


Transport and diffusion (the first and last two steps) are fast compared to adsorption, reaction and desorption because of the shell structure of the catalyst. It is known from various investigations that the rate-determining step of the ammonia synthesis is the dissociation of nitrogen. In contrast, exchange reactions between hydrogen and deuterium on the Haber–Bosch catalysts still take place at temperatures of at a measurable rate; the exchange between deuterium and hydrogen on the ammonia molecule also takes place at room temperature. Since the adsorption of both molecules is rapid, it cannot determine the speed of ammonia synthesis.

In addition to the reaction conditions, the adsorption of nitrogen on the catalyst surface depends on the microscopic structure of the catalyst surface. Iron has different crystal surfaces, whose reactivity is very different. The Fe(111) and Fe(211) surfaces have by far the highest activity. The explanation for this is that only these surfaces have so-called C7 sites - these are iron atoms with seven closest neighbours.

The dissociative adsorption of nitrogen on the surface follows the following scheme, where S* symbolizes an iron atom on the surface of the catalyst:

The adsorption of nitrogen is similar to the chemisorption of carbon monoxide. On a Fe(111) surface, the adsorption of nitrogen first leads to an adsorbed γ-species with an adsorption energy of 24 kJmol and an N-N stretch vibration of 2100 cm. Since the nitrogen is isoelectronic to carbon monoxide, it adsorbs in an on-end configuration in which the molecule is bound perpendicular to the metal surface at one nitrogen atom. This has been confirmed by photoelectron spectroscopy.

Ab-initio-MO calculations have shown that, in addition to the σ binding of the free electron pair of nitrogen to the metal, there is a π binding from the d orbitals of the metal to the π* orbitals of nitrogen, which strengthens the iron-nitrogen bond. The nitrogen in the α state is more strongly bound with 31 kJmol. The resulting N-N bond weakening could be experimentally confirmed by a reduction of the wave numbers of the N-N stretching oscillation to 1490 cm.

Further heating of the Fe(111) area covered by α-N leads to both desorption and emergence of a new band at 450 cm. This represents a metal-nitrogen oscillation, the β state. A comparison with vibration spectra of complex compounds allows the conclusion that the N molecule is bound "side-on", with an N atom in contact with a C7 site. This structure is called "surface nitride". The surface nitride is very strongly bound to the surface. Hydrogen atoms (H), which are very mobile on the catalyst surface, quickly combine with it.

Infrared spectroscopically detected surface imides (NH), surface amides (NH) and surface ammoniacates (NH) are formed, the latter decay under NH release (desorption). The individual molecules were identified or assigned by X-ray photoelectron spectroscopy (XPS), high-resolution electron energy loss spectroscopy (HREELS) and IR spectroscopy.

On the basis of these experimental findings, the reaction mechanism is believed to involve the following steps (see also figure):
Reaction 5 occurs in three steps, forming NH, NH, and then NH. Experimental evidence points to reaction 2 as being the slow, rate-determining step. This is not unexpected, since the bond broken, the nitrogen triple bond, is the strongest of the bonds that must be broken. 

As with all Haber–Bosch catalysts, nitrogen dissociation is the rate determining step for ruthenium activated carbon catalysts. The active center for ruthenium is a so-called B5 site, a 5-fold coordinated position on the Ru(0001) surface where two ruthenium atoms form a step edge with three ruthenium atoms on the Ru(0001) surface. The number of B5 sites depends on the size and shape of the ruthenium particles, the ruthenium precursor and the amount of ruthenium used. The reinforcing effect of the basic carrier used in the ruthenium catalyst is similar to the promoter effect of alkali metals used in the iron catalyst.

An energy diagram can be created based on the enthalpy of reaction of the individual steps. The energy diagram can be used to compare homogeneous and heterogeneous reactions: Due to the high activation energy of the dissociation of nitrogen, the homogeneous gas phase reaction is not realizable. The catalyst avoids this problem as the energy gain resulting from the binding of nitrogen atoms to the catalyst surface overcompensates for the necessary dissociation energy so that the reaction is finally exothermic. Nevertheless, the dissociative adsorption of nitrogen remains the rate determining step: not because of the activation energy, but mainly because of the unfavorable pre-exponential factor of the rate constant. Although hydrogenation is endothermic, this energy can easily be applied by the reaction temperature (about 700 K).

When first invented, the Haber process competed against another industrial process, the cyanamide process. However, the cyanamide process consumed large amounts of electrical power and was more labor-intensive than the Haber process.

As of 2018, the Haber process produces 230 million tonnes of anhydrous ammonia per year. The ammonia is used mainly as a nitrogen fertilizer as ammonia itself, in the form of ammonium nitrate, and as urea. The Haber process consumes 3–5% of the world's natural-gas production (around 1–2% of the world's energy supply). In combination with advances in breeding, herbicides and pesticides, these fertilizers have helped to increase the productivity of agricultural land:
The energy-intensivity of the process contributes to climate change and other environmental problems:

Since nitrogen use efficiency is typically less than 50%, farm runoff from heavy use of fixed industrial nitrogen disrupts biological habitats.
Nearly 50% of the nitrogen found in human tissues originated from the Haber–Bosch process. Thus, the Haber process serves as the "detonator of the population explosion", enabling the global population to increase from 1.6 billion in 1900 to 7.7 billion by November 2018.




</doc>
<doc id="14023" url="https://en.wikipedia.org/wiki?curid=14023" title="Hot or Not">
Hot or Not

Hot or Not is a rating site that allows users to rate the attractiveness of photos submitted voluntarily by others. The site offers a matchmaking engine called 'Meet Me' and an extended profile feature called "Hotlists". The domain hotornot.com is currently owned by Hot Or Not Limited, and was previously owned by Avid Life Media. 'Hot or Not' was a significant influence on the people who went on to create the social media sites Facebook and YouTube.

Users would submit photographs of themselves to the site for the purpose of other users to rate said person's attractiveness on a scale of 1 - 10, with the cumulative average acting as the overall score for a given photograph.

The site was founded in October 2000 by James Hong and Jim Young, two friends and Silicon Valley-based engineers. Both graduated from the University of California, Berkeley in electrical engineering, with Young pursuing a Ph.D at the time. It was inspired by some other developers' ideas.

The site was a technical solution to a disagreement the founders had one day over a passing woman's attractiveness. The site was originally called "Am I Hot or Not". Within a week of launching, it had reached almost two million page views per day. Within a few months, the site was immediately behind CNET and NBCi on NetNielsen Rating's Top 25 advertising domains. To keep up with rising costs Hong and Young added a matchmaking component to their website called "Meet Me at Hot or Not", i.e. a system of range voting. The matchmaking service has been especially successful and the site continues to generate most of its revenue through subscriptions. In the December 2006 issue of "Time" magazine, the founders of YouTube stated that they originally set out to make a version of Hot or Not with Video before developing their more inclusive site. Mark Zuckerberg of Facebook similarly got his start by creating a Hot or Not type site called FaceMash, where he posted photos from Harvard's Facebook for the university's community to rate.

Hot or Not was sold for a rumored $20 million on February 8, 2008 to Avid Life Media, owners of Ashley Madison. Annual revenue reached $7.5 million, with net profits of $5.5 million. They initially started off $60,000 in debt due to tuition fees James paid for his MBA. On July 31, 2008, Hot or Not launched Hot or Not Gossip and a Baresi rate box (a "hot meter") – a subdivision to expand their market, run by former radio DJ turned celebrity blogger Zack Taylor.

Hot or Not was preceded by the rating sites, like RateMyFace, which was registered a year earlier in the summer of 1999, and AmIHot.com, which was registered in January 2000 by MIT freshman Daniel Roy. Regardless, despite any head starts of its predecessors, Hot or Not quickly became the most popular. Since AmIHotOrNot.com's launch, the concept has spawned many imitators. The concept always remained the same, but the subject matter varied greatly. The concept has also been integrated with a wide variety of dating and matchmaking systems. In 2007 BecauseImHot.com launched and deleted anyone with a rating below 7 after a voting audit or the first 50 votes (whichever is first).

In 2005, as an example of using image morphing methods to study the effects of averageness, imaging researcher Pierre Tourigny created a composite of about 30 faces to find out the current standard of good looks on the Internet. On the Hot or Not web site, people rate others' attractiveness on a scale of 1 to 10. An average score based on hundreds or even thousands of individual ratings takes only a few days to emerge. To make this hot or not palette of morphed images, photos from the site were sorted by rank and used SquirlzMorph to create multi-morph composites from them. Unlike projects like Face of Tomorrow, where the subjects are posed for the purpose, the portraits are blurry because the source images are of low resolution with differences in variables such as posture, hair styles and glasses, so that in this instance images could use only 36 control points for the morphs. A similar study was done with Miss Universe contestants, as shown in the averageness article, as well as one for age, as shown in youthfulness article.

A 2006 "hot" or "not" style study, involving 264 women and 18 men, at the Washington University School of Medicine, as published online in the journal "Brain Research", indicates that a person's brain determines whether an image is erotically appealing long before the viewer is even aware they are seeing the picture. Moreover, according to these researchers, one of the basic functions of the brain is to classify images into a hot or not type categorization. The study's researchers also discovered that sexy shots induce a uniquely powerful reaction in the brain, equal in effect for both men and women, and that erotic images produced a strong reaction in the hypothalamus.




</doc>
<doc id="14024" url="https://en.wikipedia.org/wiki?curid=14024" title="H.263">
H.263

H.263 is a video compression standard originally designed as a low-bit-rate compressed format for videoconferencing. It was standardized by the ITU-T Video Coding Experts Group (VCEG) in a project ending in 1995/1996. It is a member of the H.26x family of video coding standards in the domain of the ITU-T.

Like previous H.26x standards, H.263 is based on discrete cosine transform (DCT) video compression. H.263 was later extended to add various additional enhanced features in 1998 and 2000. Smaller additions were also made in 1997 and 2001, and a unified edition was produced in 2005.

The H.263 standard was first designed to be utilized in H.324 based systems (PSTN and other circuit-switched network videoconferencing and videotelephony), but it also found use in H.323 (RTP/IP-based videoconferencing), H.320 (ISDN-based videoconferencing, where it was the most widely used video compression standard), RTSP (streaming media) and SIP (IP-based videoconferencing) solutions. 

H.263 is a required video coding format in ETSI 3GPP technical specifications for IP Multimedia Subsystem (IMS), Multimedia Messaging Service (MMS) and Transparent end-to-end Packet-switched Streaming Service (PSS). In 3GPP specifications, H.263 video is usually used in 3GP container format.

H.263 also found many applications on the internet: much Flash Video content (as used on sites such as YouTube, Google Video, and MySpace) used to be encoded in Sorenson Spark format (an incomplete implementation of H.263). The original version of the RealVideo codec was based on H.263 until the release of RealVideo 8.

H.263 was developed as an evolutionary improvement based on experience from H.261 and H.262 (aka MPEG-2 Video), the previous ITU-T standards for video compression, and the MPEG-1 standard developed in ISO/IEC. Its first version was completed in 1995 and provided a suitable replacement for H.261 at all bit rates. It was further enhanced in projects known as H.263v2 (also known as H.263+ or H.263 1998) and H.263v3 (also known as H.263++ or H.263 2000). It was also used as the basis for the development of MPEG-4 Part 2. MPEG-4 Part 2 is H.263 compatible in the sense that basic "baseline" H.263 bitstreams are correctly decoded by an MPEG-4 Video decoder.

The next enhanced format developed by ITU-T VCEG (in partnership with MPEG) after H.263 was the H.264 standard, also known as AVC and MPEG-4 part 10. As H.264 provides a significant improvement in capability beyond H.263, the H.263 standard is now considered a legacy design. Most new videoconferencing products now include H.264 as well as H.263 and H.261 capabilities. An even-newer standard format, HEVC, has also been developed by VCEG and MPEG, and has begun to emerge in some applications.

Since the original ratification of H.263 in March 1996 (approving a document that was produced in November 1995), there have been two subsequent additions which improved on the original standard by additional optional extensions (for example, the H.263v2 project added a deblocking filter in its Annex J).

The original version of H.263 specified the following annexes:

The first version of H.263 supported a limited set of picture sizes:

In March 1997, an informative Appendix I describing Error Tracking – an encoding technique for providing improved robustness to data losses and errors, was approved to provide information for the aid of implementers having an interest in such techniques.

H.263v2 (also known as "H.263+", or as "the 1998 version of H.263") is the informal name of the second edition of the ITU-T H.263 international video coding standard. It retained the entire technical content of the original version of the standard, but enhanced H.263 capabilities by adding several annexes which can substantially improve encoding efficiency and provide other capabilities (such as enhanced robustness against data loss in the transmission channel). The H.263+ project was ratified by the ITU in February 1998. It added the following Annexes:
H.263v2 also added support for flexible customized picture formats and custom picture clock frequencies. As noted above, the only picture formats previously supported in H.263 had been Sub-QCIF, QCIF, CIF, 4CIF, and 16CIF, and the only picture clock frequency had been 30000/1001 (approximately 29.97) clock ticks per second.

H.263v2 specified a set of recommended modes in an informative appendix (Appendix II, since deprecated):
The definition of H.263v3 (also known as H.263++ or as the 2000 version of H.263) added three annexes. These annexes and an additional annex that specified profiles (approved the following year) were originally published as separate documents from the main body of the standard itself. The additional annexes specified are:

The prior informative Appendix II (recommended optional enhancement) was obsoleted by the creation of the normative Annex X.

In June 2001, another informative appendix (Appendix III, Examples for H.263 encoder/decoder implementations) was approved. It describes techniques for encoding and for error/loss concealment by decoders.

In January 2005, a unified H.263 specification document was produced (with the exception of Appendix III, which remains as a separately-published document).

In August 2005, an implementors guide was approved to correct a small error in the seldom-used Annex Q reduced-resolution update mode.

In countries without software patents, H.263 video can be legally encoded and decoded with the free LGPL-licensed libavcodec library (part of the FFmpeg project) which is used by programs such as ffdshow, VLC media player and MPlayer.




</doc>
<doc id="14026" url="https://en.wikipedia.org/wiki?curid=14026" title="House of Orange (disambiguation)">
House of Orange (disambiguation)

The House of Orange is a branch of the House of Nassau active in European politics.

House of Orange may also refer to:



</doc>
<doc id="14029" url="https://en.wikipedia.org/wiki?curid=14029" title="Histone">
Histone

In biology, histones are highly basic proteins found in eukaryotic cell nuclei that pack and order the DNA into structural units called nucleosomes. Histones are abundant in lysine and arginine. Histone are the chief protein components of chromatin, acting as spools around which DNA winds, and playing a role in gene regulation. Without histones, the unwound DNA in chromosomes would be very long (a length to width ratio of more than 10 million to 1 in human DNA). For example, each human diploid cell (containing 23 pairs of chromosomes) has about 1.8 meters of DNA; wound on the histones, the diploid cell has about 90 micrometers (0.09 mm) of chromatin. When the diploid cells are duplicated and condensed during mitosis, the result is about 120 micrometers of chromosomes.

Five major families of histones exist: H1/H5, H2A, H2B, H3, and H4. Histones H2A, H2B, H3 and H4 are known as the core histones, while histones H1/H5 are known as the linker histones.

The core histones all exist as dimers, which are similar in that they all possess the histone fold domain: three alpha helices linked by two loops. It is this helical structure that allows for interaction between distinct dimers, particularly in a head-tail fashion (also called the handshake motif). The resulting four distinct dimers then come together to form one octameric nucleosome core, approximately 63 Angstroms in diameter (a solenoid (DNA)-like particle). Around 146 base pairs (bp) of DNA wrap around this core particle 1.65 times in a left-handed super-helical turn to give a particle of around 100 Angstroms across. The linker histone H1 binds the nucleosome at the entry and exit sites of the DNA, thus locking the DNA into place and allowing the formation of higher order structure. The most basic such formation is the 10 nm fiber or beads on a string conformation. This involves the wrapping of DNA around nucleosomes with approximately 50 base pairs of DNA separating each pair of nucleosomes (also referred to as linker DNA). Higher-order structures include the 30 nm fiber (forming an irregular zigzag) and 100 nm fiber, these being the structures found in normal cells. During mitosis and meiosis, the condensed chromosomes are assembled through interactions between nucleosomes and other regulatory proteins.

Histones are subdivided into canonical replication-dependent histones that are expressed during the S-phase of the cell cycle and replication-independent histone variants, expressed during the whole cell cycle. In animals, genes encoding canonical histones are typically clustered along the chromosome, lack introns and use a stem loop structure at the 3' end instead of a polyA tail. Genes encoding histone variants are usually not clustered, have introns and their mRNAs are regulated with polyA tails. Complex multicellular organisms typically have a higher number of histone variants providing a variety of different functions. Recent data are accumulating about the roles of diverse histone variants highlighting the functional links between variants and the delicate regulation of organism development. Histone variants from different organisms, their classification and variant specific features can be found in "HistoneDB 2.0 - Variants" database.

The following is a list of human histone proteins:

The nucleosome core is formed of two H2A-H2B dimers and a H3-H4 tetramer, forming two nearly symmetrical halves by tertiary structure (C2 symmetry; one macromolecule is the mirror image of the other). The H2A-H2B dimers and H3-H4 tetramer also show pseudodyad symmetry. The 4 'core' histones (H2A, H2B, H3 and H4) are relatively similar in structure and are highly conserved through evolution, all featuring a 'helix turn helix turn helix' motif (DNA-binding protein motif that recognize specific DNA sequence). They also share the feature of long 'tails' on one end of the amino acid structure - this being the location of post-translational modification (see below).

Archaeal histone only contains a H3-H4 like dimeric structure made out of the same protein. Such dimeric structures can stack into a tall superhelix ("supernucleosome") onto which DNA coils in a manner similar to nucleosome spools. Only some archaeal histones have tails.

It has been proposed that histone proteins are evolutionarily related to the helical part of the extended AAA+ ATPase domain, the C-domain, and to the N-terminal substrate recognition domain of Clp/Hsp100 proteins. Despite the differences in their topology, these three folds share a homologous helix-strand-helix (HSH) motif.

Using an electron paramagnetic resonance spin-labeling technique, British researchers measured the distances between the spools around which eukaryotic cells wind their DNA. They determined the spacings range from 59 to 70 Å.

In all, histones make five types of interactions with DNA:

The highly basic nature of histones, aside from facilitating DNA-histone interactions, contributes to their water solubility.

Histones are subject to post translational modification by enzymes primarily on their N-terminal tails, but also in their globular domains. Such modifications include methylation, citrullination, acetylation, phosphorylation, SUMOylation, ubiquitination, and ADP-ribosylation. This affects their function of gene regulation.

In general, genes that are active have less bound histone, while inactive genes are highly associated with histones during interphase. It also appears that the structure of histones has been evolutionarily conserved, as any deleterious mutations would be severely maladaptive. All histones have a highly positively charged N-terminus with many lysine and arginine residues.

Histones were discovered in 1884 by Albrecht Kossel. The word "histone" dates from the late 19th century and is derived from the German word ""Histon"", a word itself of uncertain origin - perhaps from the Greek "histanai" or "histos".

In the early 1960s, before the types of histones were known and before histones were known to be highly conserved across taxonomically diverse organisms, James F. Bonner and his collaborators began a study of these proteins that were known to be tightly associated with the DNA in the nucleus of higher organisms. Bonner and his postdoctoral fellow Ru Chih C. Huang showed that isolated chromatin would not support RNA transcription in the test tube, but if the histones were extracted from the chromatin, RNA could be transcribed from the remaining DNA. Their paper became a citation classic. Paul T'so and James Bonner had called together a World Congress on Histone Chemistry and Biology in 1964, in which it became clear that there was no consensus on the number of kinds of histone and that no one knew how they would compare when isolated from different organisms. Bonner and his collaborators then developed methods to separate each type of histone, purified individual histones, compared amino acid compositions in the same histone from different organisms, and compared amino acid sequences  of the same histone from different organisms in collaboration with Emil Smith from UCLA. For example, they found Histone IV sequence to be highly conserved between peas and calf thymus. However, their work on the biochemical characteristics of individual histones did not reveal how the histones interacted with each other or with DNA to which they were tightly bound.

Also in the 1960s, Vincent Allfrey and Alfred Mirsky had suggested, based on their analyses of histones, that acetylation and methylation of histones could provide a transcriptional control mechanism, but did not have available the kind of detailed analysis that later investigators were able to conduct to show how such regulation could be gene-specific. Until the early 1990s, histones were dismissed by most as inert packing material for eukaryotic nuclear DNA, a view based in part on the models of Mark Ptashne and others, who believed that transcription was activated by protein-DNA and protein-protein interactions on largely naked DNA templates, as is the case in bacteria.

During the 1980s, Yahli Lorch and Roger Kornberg showed that a nucleosome on a core promoter prevents the initiation of transcription in vitro, and Michael Grunstein demonstrated that histones repress transcription in vivo, leading to the idea of the nucleosome as a general gene repressor. Relief from repression is believed to involve both histone modification and the action of chromatin-remodeling complexes. Vincent Allfrey and Alfred Mirsky had earlier proposed a role of histone modification in transcriptional activation, regarded as a molecular manifestation of epigenetics. Michael Grunstein and David Allis found support for this proposal, in the importance of histone acetylation for transcription in yeast and the activity of the transcriptional activator Gcn5 as a histone acetyltransferase.

The discovery of the H5 histone appears to date back to the 1970s, and it is now considered an isoform of Histone H1.

Histones are found in the nuclei of eukaryotic cells, and in certain Archaea, namely Proteoarchaea and Euryarchaea, but not in bacteria. The unicellular algae known as dinoflagellates were previously thought to be the only eukaryotes that completely lack histones, however, later studies showed that their DNA still encodes histone genes. Unlike the core histones, lysine-rich linker histone (H1) proteins are found in bacteria, otherwise known as nucleoprotein HC1/HC2.

Archaeal histones may well resemble the evolutionary precursors to eukaryotic histones. Histone proteins are among the most highly conserved proteins in eukaryotes, emphasizing their important role in the biology of the nucleus. In contrast mature sperm cells largely use protamines to package their genomic DNA, most likely because this allows them to achieve an even higher packaging ratio.

There are some "variant" forms in some of the major classes. They share amino acid sequence homology and core structural similarity to a specific class of major histones but also have their own feature that is distinct from the major histones. These "minor histones" usually carry out specific functions of the chromatin metabolism. For example, histone H3-like CENPA is associated with only the centromere region of the chromosome. Histone H2A variant H2A.Z is associated with the promoters of actively transcribed genes and also involved in the prevention of the spread of silent heterochromatin. Furthermore, H2A.Z has roles in chromatin for genome stability. Another H2A variant H2A.X is phosphorylated at S139 in regions around double-strand breaks and marks the region undergoing DNA repair. Histone H3.3 is associated with the body of actively transcribed genes.

Nucleosome histones may have evolved from ribosomal proteins (RPS6/RPS15) with which they share much in common, both being short and basic proteins.

Histones act as spools around which DNA winds. This enables the compaction necessary to fit the large genomes of eukaryotes inside cell nuclei: the compacted molecule is 40,000 times shorter than an unpacked molecule.

Histones undergo posttranslational modifications that alter their interaction with DNA and nuclear proteins. The H3 and H4 histones have long tails protruding from the nucleosome, which can be covalently modified at several places. Modifications of the tail include methylation, acetylation, phosphorylation, ubiquitination, SUMOylation, citrullination, and ADP-ribosylation. The core of the histones H2A and H2B can also be modified. Combinations of modifications are thought to constitute a code, the so-called "histone code". Histone modifications act in diverse biological processes such as gene regulation, DNA repair, chromosome condensation (mitosis) and spermatogenesis (meiosis).

The common nomenclature of histone modifications is:

So H3K4me1 denotes the monomethylation of the 4th residue (a lysine) from the start (i.e., the N-terminal) of the H3 protein.

A huge catalogue of histone modifications have been described, but a functional understanding of most is still lacking. Collectively, it is thought that histone modifications may underlie a histone code, whereby combinations of histone modifications have specific meanings. However, most functional data concerns individual prominent histone modifications that are biochemically amenable to detailed study.

The addition of one, two, or many methyl groups to lysine has little effect on the chemistry of the histone; methylation leaves the charge of the lysine intact and adds a minimal number of atoms so steric interactions are mostly unaffected. However, proteins containing Tudor, chromo or PHD domains, amongst others, can recognise lysine methylation with exquisite sensitivity and differentiate mono, di and tri-methyl lysine, to the extent that, for some lysines (e.g.: H4K20) mono, di and tri-methylation appear to have different meanings. Because of this, lysine methylation tends to be a very informative mark and dominates the known histone modification functions.
Recently it has been shown, that the addition of a serotonin group to the position 5 glutamine of H3, happens in serotonergic cells such as neurons. This is part of the differentiation of the serotonergic cells. This post-translational modification happens in conjunction with the H3K4me3 modification. The serotonylation potentiates the binding of the general transcription factor TFIID to the TATA box.

What was said above of the chemistry of lysine methylation also applies to arginine methylation, and some protein domains—e.g., Tudor domains—can be specific for methyl arginine instead of methyl lysine. Arginine is known to be mono- or di-methylated, and methylation can be symmetric or asymmetric, potentially with different meanings.

Enzymes called peptidylarginine deiminases (PADs) hydrolyze the imine group of arginines and attach a keto group, so that there is one less positive charge on the amino acid residue. This process has been involved in the activation of gene expression by making the modified histones less tightly bound to DNA and thus making the chromatin more accessible. PADs can also produce the opposite effect by removing or inhibiting mono-methylation of arginine residues on histones and thus antagonizing the positive effect arginine methylation has on transcriptional activity.

Addition of an acetyl group has a major chemical effect on lysine as it neutralises the positive charge. This reduces electrostatic attraction between the histone and the negatively charged DNA backbone, loosening the chromatin structure; highly acetylated histones form more accessible chromatin and tend to be associated with active transcription. Lysine acetylation appears to be less precise in meaning than methylation, in that histone acetyltransferases tend to act on more than one lysine; presumably this reflects the need to alter multiple lysines to have a significant effect on chromatin structure. The modification includes H3K27ac.
Addition of a negatively charged phosphate group can lead to major changes in protein structure, leading to the well-characterised role of phosphorylation in controlling protein function. It is not clear what structural implications histone phosphorylation has, but histone phosphorylation has clear functions as a post-translational modification, and binding domains such as BRCT have been characterised.

Most well-studied histone modifications are involved in control of transcription.

Two histone modifications are particularly associated with active transcription:

Three histone modifications are particularly associated with repressed genes:

Analysis of histone modifications in embryonic stem cells (and other stem cells) revealed many gene promoters carrying both H3K4Me3 and H3K27Me3, in other words these promoters display both activating and repressing marks simultaneously. This peculiar combination of modifications marks genes that are poised for transcription; they are not required in stem cells, but are rapidly required after differentiation into some lineages. Once the cell starts to differentiate, these bivalent promoters are resolved to either active or repressive states depending on the chosen lineage.

Marking sites of DNA damage is an important function for histone modifications. It also protects DNA from getting destroyed by ultraviolet radiation of sun.

H3K36me3 has the ability to recruit the MSH2-MSH6 (hMutSα) complex of the DNA mismatch repair pathway. Consistently, regions of the human genome with high levels of H3K36me3 accumulate less somatic mutations due to mismatch repair activity.



Epigenetic modifications of histone tails in specific regions of the brain are of central importance in addictions. Once particular epigenetic alterations occur, they appear to be long lasting "molecular scars" that may account for the persistence of addictions.

Cigarette smokers (about 15% of the US population) are usually addicted to nicotine. After 7 days of nicotine treatment of mice, acetylation of both histone H3 and histone H4 was increased at the FosB promoter in the nucleus accumbens of the brain, causing 61% increase in FosB expression. This would also increase expression of the splice variant Delta FosB. In the nucleus accumbens of the brain, Delta FosB functions as a "sustained molecular switch" and "master control protein" in the development of an addiction.

About 7% of the US population is addicted to alcohol. In rats exposed to alcohol for up to 5 days, there was an increase in histone 3 lysine 9 acetylation in the pronociceptin promoter in the brain amygdala complex. This acetylation is an activating mark for pronociceptin. The nociceptin/nociceptin opioid receptor system is involved in the reinforcing or conditioning effects of alcohol.

Methamphetamine addiction occurs in about 0.2% of the US population. Chronic methamphetamine use causes methylation of the lysine in position 4 of histone 3 located at the promoters of the "c-fos" and the "C-C chemokine receptor 2 (ccr2)" genes, activating those genes in the nucleus accumbens (NAc). c-fos is well known to be important in addiction. The "ccr2" gene is also important in addiction, since mutational inactivation of this gene impairs addiction.

The first step of chromatin structure duplication is the synthesis of histone proteins: H1, H2A, H2B, H3, H4. These proteins are synthesized during S phase of the cell cycle. There are different mechanisms which contribute to the increase of histone synthesis.

Yeast carry one or two copies of each histone gene, which are not clustered but rather scattered throughout chromosomes. Histone gene transcription is controlled by multiple gene regulatory proteins such as transcription factors which bind to histone promoter regions. In budding yeast, the candidate gene for activation of histone gene expression is SBF. SBF is a transcription factor that is activated in late G1 phase, when it dissociates from its repressor Whi5. This occurs when Whi5 is phosphorylated by Cdc8 which is a G1/S Cdk. Suppression of histone gene expression outside of S phases is dependent on Hir proteins which form inactive chromatin structure at the locus of histone genes, causing transcriptional activators to be blocked.

In metazoans the increase in the rate of histone synthesis is due to the increase in processing of pre-mRNA to its mature form as well as decrease in mRNA degradation; this results in an increase of active mRNA for translation of histone proteins. The mechanism for mRNA activation has been found to be the removal of a segment of the 3' end of the mRNA strand, and is dependent on association with stem-loop binding protein (SLBP). SLBP also stabilizes histone mRNAs during S phase by blocking degradation by the 3'hExo nuclease. SLBP levels are controlled by cell-cycle proteins, causing SLBP to accumulate as cells enter S phase and degrade as cells leave S phase. SLBP are marked for degradation by phosphorylation at two threonine residues by cyclin dependent kinases, possibly cyclin A/ cdk2, at the end of S phase. Metazoans also have multiple copies of histone genes clustered on chromosomes which are localized in structures called Cajal bodies as determined by genome-wide chromosome conformation capture analysis (4C-Seq).

Nuclear protein Ataxia-Telangiectasia (NPAT), also known as nuclear protein coactivator of histone transcription, is a transcription factor which activates histone gene transcription on chromosomes 1 and 6 of human cells. NPAT is also a substrate of cyclin E-Cdk2, which is required for the transition between G1 phase and S phase. NPAT activates histone gene expression only after it has been phosphorylated by the G1/S-Cdk cyclin E-Cdk2 in early S phase. This shows an important regulatory link between cell-cycle control and histone synthesis.




</doc>
<doc id="14031" url="https://en.wikipedia.org/wiki?curid=14031" title="Hierarchical organization">
Hierarchical organization

A hierarchical organization is an organizational structure where every entity in the organization, except one, is subordinate to a single other entity. This arrangement is a form of a hierarchy. In an organization, the hierarchy usually consists of a singular/group of power at the top with subsequent levels of power beneath them. This is the dominant mode of organization among large organizations; most corporations, governments, criminal enterprises, and organized religions are hierarchical organizations with different levels of management, power or authority. For example, the broad, top-level overview of the general organization of the Catholic Church consists of the Pope, then the Cardinals, then the Archbishops, and so on. 

Members of hierarchical organizational structures chiefly communicate with their immediate superior and with their immediate subordinates. Structuring organizations in this way is useful partly because it can reduce the communication overhead by limiting information flow.

A hierarchy is typically visualized as a pyramid, where the height of the ranking or person depicts their power status and the width of that level represents how many people or business divisions are at that level relative to the whole—the highest-ranking people are at the apex, and there are very few of them; the base may include thousands of people who have no subordinates. These hierarchies are typically depicted with a tree or triangle diagram, creating an organizational chart or organigram. Those nearest the top have more power than those nearest the bottom, and there being fewer people at the top than at the bottom. As a result, superiors in a hierarchy generally have higher status and command greater rewards than their subordinates.

All governments and most companies have similar structures. Traditionally, the monarch was the pinnacle of the state. In many countries, feudalism and manorialism provided a formal social structure that established hierarchical links at every level of society, with the monarch at the top. 

In modern post-feudal states the nominal top of the hierarchy still remains the head of state, which may be a president or a constitutional monarch, although in many modern states the powers of the head of state are delegated among different bodies. Below the head, there is commonly a senate, parliament or congress, which in turn often delegate the day-to-day running of the country to a prime minister. In many democracies, the people are considered to be the notional top of the hierarchy, over the head of state; in reality, the people's power is restricted to voting in elections.

In business, the business owner traditionally occupied the pinnacle of the organization. In most modern large companies, there is now no longer a single dominant shareholder, and the collective power of the business owners is for most purposes delegated to a board of directors, which in turn delegates the day-to-day running of the company to a managing director or CEO. Again, although the shareholders of the company are the nominal top of the hierarchy, in reality many companies are run at least in part as personal fiefdoms by their management; corporate governance rules are an attempt to mitigate this tendency.

The organizational development theorist Elliott Jacques identified a special role for hierarchy in his concept of requisite organization. 
The iron law of oligarchy, introduced by Robert Michels, describes the inevitable tendency of hierarchical organizations to become oligarchic in their decision making.

The Peter Principle is a term coined by Laurence J. Peter in which the selection of a candidate for a position in an hierarchical organization is based on the candidate's performance in their current role, rather than on abilities relevant to the intended role. Thus, employees only stop being promoted once they can no longer perform effectively, and managers in an hierarchical organization "rise to the level of their incompetence." 

Hierarchiology is another term coined by Laurence J. Peter, described in his humorous book of the same name, to refer to the study of hierarchical organizations and the behavior of their members.

The IRG Solution – hierarchical incompetence and how to overcome it argued that hierarchies were inherently incompetent, and were only able to function due to large amounts of informal lateral communication fostered by private informal networks.

In the work of diverse theorists such as William James (1842–1910), Michel Foucault (1926–1984) and Hayden White, important critiques of hierarchical epistemology are advanced. James famously asserts in his work "Radical Empiricism" that clear distinctions of type and category are a constant but unwritten goal of scientific reasoning, so that when they are discovered, success is declared. But if aspects of the world are organized differently, involving inherent and intractable ambiguities, then scientific questions are often considered unresolved. A hesitation to declare success upon the discovery of ambiguities leaves heterarchy at an artificial and subjective disadvantage in the scope of human knowledge. This bias is an artifact of an aesthetic or pedagogical preference for hierarchy, and not necessarily an expression of objective observation.

Hierarchies and hierarchical thinking has been criticized by many people, including Susan McClary and one political philosophy which is vehemently opposed to hierarchical organization: anarchism. Heterarchy is the most commonly proposed alternative to hierarchy and this has been combined with responsible autonomy by Gerard Fairtlough in his work on Triarchy theory. The most beneficial aspect of a hierarchical organization is the clear command that is established. However, hierarchy may become dismantled by abuse of power.

Amidst constant innovation in information and communication technologies, hierarchical authority structures are giving way to greater decision-making latitude for individuals and more flexible definitions of job activities and this new style of work presents a challenge to existing organizational forms, with some research studies contrasting traditional organizational forms against groups that operate as online communities that are characterized by personal motivation and the satisfaction of making one's own decisions. With all levels of an organization having access to information and communication via digital means, power structures align more as a wirearchy, enabling the flow of power and authority to be based not on hierarchical levels, but on information, trust, credibility, and a focus on results.


</doc>
<doc id="14033" url="https://en.wikipedia.org/wiki?curid=14033" title="Harry Secombe">
Harry Secombe

Sir Harry Donald Secombe (8 September 1921 – 11 April 2001) was a Welsh comedian, actor and singer. Secombe was a member of the British radio comedy programme "The Goon Show" (1951–1960), playing many characters, but most notably, Neddie Seagoon. An accomplished tenor, he also appeared in musicals and films – notably as Mr Bumble in "Oliver!" (1968) – and, in his later years, was a presenter of television shows incorporating hymns and other devotional songs.

Secombe was born in St Thomas, Swansea, the third of four children of Nellie Jane Gladys (née Davies), a shop manageress, and Frederick Ernest Secombe, a grocer. From the age of 11 he attended Dynevor School, a state grammar school in central Swansea.

His family were regular churchgoers, belonging to the congregation of St Thomas Church. A member of the choir, from the age of 12 Secombe would perform a sketch entitled "The Welsh Courtship" at church socials, acting as "feed" to his sister Carol. His elder brother, Fred Secombe, was the author of several books about his experiences as an Anglican priest and rector.

After leaving school in 1937, Secombe became a pay clerk at Baldwin's store. With war looming, he decided in 1938 that he would join the Territorial Army. Very short sighted, he got a friend to tell him the sight test, and then learnt it by heart. He served as a Lance Bombardier in No.132 Field Regiment of the Royal Artillery. He would refer to the unit in which he served during the Second World War in the North African Campaign, Sicily, and Italy, as "The Five-Mile Snipers". While in North Africa Secombe met Spike Milligan for the first time. In Sicily he joined a concert party and developed his own comedy routines to entertain the troops.

When Secombe visited the Falkland Islands to entertain the troops after the 1982 Falklands War, his old regiment promoted him to the rank of sergeant – 37 years after he had been demobbed.

He made his first radio broadcast in May 1944 on a variety show aimed at the services. Following the end of fighting in the war but prior to demobilisation Secombe joined a pool of entertainers in Naples and formed a comedy duo with Spike Milligan.

Secombe joined the cast of the Windmill Theatre in 1946, using a routine he had developed in Italy about how people shaved. Secombe always claimed that his ability to sing could always be counted on to save him when he bombed.

After a regional touring career, his first break came in radio when he was chosen as resident comedian for the Welsh series "Welsh Rarebit," followed by appearances on "Variety Bandbox" and a regular role in "Educating Archie".

Secombe met Michael Bentine at the Windmill Theatre, and was introduced to Peter Sellers by his agent Jimmy Grafton. Both Milligan and Sellers credited him with keeping the act on the bill when club owners had wanted to sack them. Together with Spike Milligan, the four wrote a comedy radio script, and "Those Crazy People" was commissioned and first broadcast on 28 May 1951. Produced by Dennis Main Wilson, this would soon become "The Goon Show" and the show remained on the air until 1960. Secombe mainly played Neddie Seagoon, around whom the show's absurd plots developed. In 1955, whilst appearing on "The Goon Show", Secombe was approached by the BBC to step in at short notice to take the lead in the radio comedy "Hancock's Half Hour". The star of the show, Tony Hancock, had decided to take an unannounced break abroad the day before the live airing of the second season. Secombe appeared in the lead for the first three episodes and had a guest role in the fourth after Hancock's return. All four episodes are lost, but following the discovery of the original scripts the episodes were rerecorded in 2017, with Andrew Secombe performing the role held by his then late father.

With the success of "The Goon Show", Secombe developed a dual career as both a comedy actor and a singer. At the beginning of his career as an entertainer his act would end with a joke version of the duet "Sweethearts," in which he sang both the baritone and falsetto parts. Trained under Italian maestro Manlio di Veroli, he emerged as a "bel canto" tenor (characteristically, he insisted that in his case this meant "can belto") and had a long list of best-selling record albums to his credit.

In 1958 he appeared in the film "Jet Storm," which starred Dame Sybil Thorndike and Richard Attenborough and in the same year Secombe starred in the title role in "Davy", one of Ealing Studios' last films.

The power of his voice allowed Secombe to appear in many stage musicals. This included 1963's "Pickwick," based on Charles Dickens' "The Pickwick Papers", which gave him the number 18 hit single "If I Ruled the World" – his later signature tune. In 1965 the show was produced on tour in the United States, where on Broadway he garnered a nomination for a Tony Award for Best Actor in a Musical. Secombe scored his biggest hit single in 1967 with his version of "This Is My Song", which peaked at no. 2 on the charts in April 1967 while a recording by Petula Clark, which had hit no. 1 in February, was still in the top ten. He also appeared in the musical "The Four Musketeers" (1967) at Drury Lane, as Mr. Bumble in Carol Reed's film of "Oliver!" (1968), and in the Envy segment of "The Magnificent Seven Deadly Sins" (1971).

He would go on to star in his own television show, "The Harry Secombe Show", which debuted on Christmas Day 1968 on BBC 1 and ran for thirty-one episodes until 1973. A sketch comedy show featuring Julian Orchard as Secombe's regular sidekick, the series also featured guest appearances by fellow Goon Spike Milligan as well as leading performers such as Ronnie Barker and Arthur Lowe. Secombe later starred in similar vehicles such as "Sing a Song of Secombe" and ITV's "Secombe with Music" during the 1970s.

Later in life, Secombe (whose brother Fred Secombe was a priest in the Church in Wales, part of the Anglican Communion) attracted new audiences as a presenter of religious programmes, such as the BBC's "Songs of Praise" and ITV's "Stars on Sunday" and "Highway". He was also a special programming consultant to Harlech Television and hosted a Thames Television programme in 1979 entitled "Cross on the Donkey's Back". In the latter half of the 1980s, Secombe personally sponsored a football team for boys aged 9–11 in the local West Sutton Little League, 'Secombes Knights'.

In 1990, he was one of a few to be honoured by a second appearance on "This Is Your Life", when he was surprised by Michael Aspel at a book signing in a London branch of WH Smith. Secombe had been a subject of the show previously in March 1958 when Eamonn Andrews surprised him at the BBC Television Theatre.

In 1963 he was appointed a Commander of the Order of the British Empire (CBE).

He was knighted in 1981, and jokingly referred to himself as Sir Cumference (in recognition of his rotund figure). The motto he chose for his coat of arms was "GO ON", a reference to goon.

Secombe suffered from peritonitis in 1980. Within two years, taking advice from doctors, he had lost five stone in weight. He had a stroke in 1997, from which he made a slow recovery. He was then diagnosed with prostate cancer in September 1998. After suffering a second stroke in 1999, he was forced to abandon his television career, but made a documentary about his condition in the hope of giving encouragement to other sufferers. Secombe had diabetes in the latter part of his life.

Secombe died on 11 April 2001 at the age of 79, from prostate cancer, in hospital in Guildford, Surrey. His ashes are interred at the parish church of Shamley Green, and a later memorial service to celebrate his life was held at Westminster Abbey on 26 October 2001. As well as family members and friends, the service was also attended by Charles, Prince of Wales and representatives of Prince Philip, Duke of Edinburgh, Anne, Princess Royal, Princess Margaret, Countess of Snowdon and Prince Edward, Duke of Kent. On his tombstone is the inscription: "To know him was to love him."

Upon hearing of his old friend's death, Spike Milligan quipped, "I'm glad he died before me, because I didn't want him to sing at my funeral." But Secombe would have the last laugh: upon Milligan's own death the following year, a recording of Secombe singing was played at Spike's memorial service.

The Secombe Theatre at Sutton, London, bears his name in memory of this former local personality. He is also fondly remembered at the London Welsh Centre, where he opened the bar on St Patrick's Day (17 March) 1971.

Secombe met Myra Joan Atherton at the Mumbles Dance hall in 1946. The couple were married from 1948 until his death, and had four children:








</doc>
<doc id="14034" url="https://en.wikipedia.org/wiki?curid=14034" title="Heroin">
Heroin

Heroin, also known as diamorphine among other names, is an opioid used as a recreational drug for its euphoric effects. Medical grade diamorphine is used as a pure hydrochloride salt which is distinguished from black tar heroin, a variable admixture of morphine derivatives—predominantly 6-MAM (6-monoacetylmorphine), which is the result of crude acetylation during clandestine production of street heroin. Diamorphine is used medically in several countries to relieve pain, such as during childbirth or a heart attack, as well as in opioid replacement therapy. It is typically injected, usually into a vein, but it can also be smoked, snorted, or inhaled. In a clinical context the route of administration is most commonly intravenous injection; it may also be given by intramuscular or subcutaneous injection, as well as orally in the form of tablets The onset of effects is usually rapid and lasts for a few hours.
Common side effects include respiratory depression (decreased breathing), dry mouth, drowsiness, impaired mental function, constipation, and addiction. Side effects of use by injection can include abscesses, infected heart valves, blood-borne infections, and pneumonia. After a history of long-term use, opioid withdrawal symptoms can begin within hours of the last use. When given by injection into a vein, heroin has two to three times the effect of a similar dose of morphine. It typically comes as a white or brown powder.
Treatment of heroin addiction often includes behavioral therapy and medications. Medications can include buprenorphine, methadone, or naltrexone. A heroin overdose may be treated with naloxone. An estimated 17 million people use opiates, of which heroin is the most common, and opioid use resulted in 122,000 deaths. The total number of heroin users worldwide as of 2015 is believed to have increased in Africa, the Americas, and Asia since 2000. In the United States, approximately 1.6 percent of people have used heroin at some point, with 950,000 using it in the last year. When people die from overdosing on a drug, the drug is usually an opioid and often heroin.
Heroin was first made by C. R. Alder Wright in 1874 from morphine, a natural product of the opium poppy. Internationally, heroin is controlled under Schedules I and IV of the Single Convention on Narcotic Drugs, and it is generally illegal to make, possess, or sell without a license. About 448 tons of heroin were made in 2016. In 2015, Afghanistan produced about 66% of the world's opium. Illegal heroin is often mixed with other substances such as sugar, starch, caffeine, quinine, or other opioids like fentanyl.

Bayer's original trade name (see 'History' section) of heroin is typically used in non-medical settings. It is used as a recreational drug for the euphoria it induces. Anthropologist Michael Agar once described heroin as "the perfect whatever drug." Tolerance develops quickly, and increased doses are needed in order to achieve the same effects. Its popularity with recreational drug users, compared to morphine, reportedly stems from its perceived different effects.

Short-term addiction studies by the same researchers demonstrated that tolerance developed at a similar rate to both heroin and morphine. When compared to the opioids hydromorphone, fentanyl, oxycodone, and pethidine (meperidine), former addicts showed a strong preference for heroin and morphine, suggesting that heroin and morphine are particularly susceptible to abuse and addiction. Morphine and heroin were also much more likely to produce euphoria and other "positive" subjective effects when compared to these other opioids.

In the United States, heroin is not accepted as medically useful.

Under the generic name diamorphine, heroin is prescribed as a strong pain medication in the United Kingdom, where it is administered via oral, subcutaneous, intramuscular, intrathecal, intranasal or intravenous routes. It may be prescribed for the treatment of acute pain, such as in severe physical trauma, myocardial infarction, post-surgical pain and chronic pain, including end-stage terminal illnesses. In other countries it is more common to use morphine or other strong opioids in these situations. In 2004 the National Institute for Health and Clinical Excellence produced guidance on the management of caesarean section, which recommended the use of intrathecal or epidural diamorphine for post-operative pain relief. For women who have had intrathecal opioids, there should be a minimum hourly observation of respiratory rate, sedation and pain scores for at least 12 hours for diamorphine and 24 hours for morphine. Women should be offered diamorphine (0.3–0.4 mg intrathecally) for intra- and postoperative analgesia because it reduces the need for supplemental analgesia after a caesarean section. Epidural diamorphine (2.5–5 mg) is a suitable alternative.

Diamorphine continues to be widely used in palliative care in the UK, where it is commonly given by the subcutaneous route, often via a syringe driver, if patients cannot easily swallow morphine solution. The advantage of diamorphine over morphine is that diamorphine is more fat soluble and therefore more potent by injection, so smaller doses of it are needed for the same effect on pain. Both of these factors are advantageous if giving high doses of opioids via the subcutaneous route, which is often necessary in palliative care.

It is also used in the palliative management of bone fractures and other trauma, especially in children. In the trauma context, it is primarily given by nose in hospital; although a prepared nasal spray is available. It has traditionally been made by the attending physician, generally from the same "dry" ampoules as used for injection. In children, Ayendi nasal spray is available at 720 micrograms and 1600 microgramsin per 50 microlitre actuation of the spray, which may be preferable as a non-invasive alternative in pediatric care, avoiding the fear of injection in children.

A number of European countries prescribe heroin for treatment of heroin addiction. The initial Swiss HAT (Heroin-assisted treatment) trial (“PROVE” study) was conducted as a prospective cohort study with some 1,000 participants in 18 treatment centers between 1994 and 1996, at the end of 2004, 1,200 patients were enrolled in HAT in 23 treatment centers across Switzerland.
Diamorphine may be used as a maintenance drug to assist the treatment of opiate addiction, normally in long-term chronic intravenous (IV) heroin users. It is only prescribed following exhaustive efforts at treatment via other means. It is sometimes thought that heroin users can walk into a clinic and walk out with a prescription, but the process takes many weeks before a prescription for diamorphine is issued. Though this is somewhat controversial among proponents of a zero-tolerance drug policy, it has proven superior to methadone in improving the social and health situations of addicts.

The UK Department of Health's Rolleston Committee Report in 1926 established the British approach to diamorphine prescription to users, which was maintained for the next 40 years: dealers were prosecuted, but doctors could prescribe diamorphine to users when withdrawing. In 1964 the Brain Committee recommended that only selected approved doctors working at approved specialised centres be allowed to prescribe diamorphine and cocaine to users. The law was made more restrictive in 1968. Beginning in the 1970s, the emphasis shifted to abstinence and the use of methadone; currently only a small number of users in the UK are prescribed diamorphine.

In 1994, Switzerland began a trial diamorphine maintenance program for users that had failed multiple withdrawal programs. The aim of this program was to maintain the health of the user by avoiding medical problems stemming from the illicit use of diamorphine. The first trial in 1994 involved 340 users, although enrollment was later expanded to 1000, based on the apparent success of the program. The trials proved diamorphine maintenance to be superior to other forms of treatment in improving the social and health situation for this group of patients. It has also been shown to save money, despite high treatment expenses, as it significantly reduces costs incurred by trials, incarceration, health interventions and delinquency. Patients appear twice daily at a treatment center, where they inject their dose of diamorphine under the supervision of medical staff. They are required to contribute about 450 Swiss francs per month to the treatment costs. A national referendum in November 2008 showed 68% of voters supported the plan, introducing diamorphine prescription into federal law. The previous trials were based on time-limited executive ordinances. The success of the Swiss trials led German, Dutch, and Canadian cities to try out their own diamorphine prescription programs. Some Australian cities (such as Sydney) have instituted legal diamorphine supervised injecting centers, in line with other wider harm minimization programs.

Since January 2009, Denmark has prescribed diamorphine to a few addicts that have tried methadone and buprenorphine without success. Beginning in February 2010, addicts in Copenhagen and Odense became eligible to receive free diamorphine. Later in 2010, other cities including Århus and Esbjerg joined the scheme. It was supposed that around 230 addicts would be able to receive free diamorphine.

However, Danish addicts would only be able to inject heroin according to the policy set by Danish National Board of Health. Of the estimated 1500 drug users who did not benefit from the then-current oral substitution treatment, approximately 900 would not be in the target group for treatment with injectable diamorphine, either because of "massive multiple drug abuse of non-opioids" or "not wanting treatment with injectable diamorphine".

In July 2009, the German Bundestag passed a law allowing diamorphine prescription as a standard treatment for addicts; a large-scale trial of diamorphine prescription had been authorized in the country in 2002.

On August 26, 2016 Health Canada issued regulations amending prior regulations it had issued under the Controlled Drugs and Substances Act; the "New Classes of Practitioners Regulations", the "Narcotic Control Regulations", and the "Food and Drug Regulations", to allow doctors to prescribe diamorphine to people who have a severe opioid addiction who have not responded to other treatments. The prescription heroin can be accessed by doctors through Health Canada's Special Access Programme (SAP) for "emergency access to drugs for patients with serious or life-threatening conditions when conventional treatments have failed, are unsuitable, or are unavailable."

The onset of heroin's effects depends upon the route of administration. Studies have shown that the subjective pleasure of drug use (the reinforcing component of addiction) is proportional to the rate at which the blood level of the drug increases. Smoking is the fastest route of drug administration, although intravenous injection results in a quicker rise in blood concentration. These are followed by suppository (anal or vaginal insertion), insufflation (snorting), and ingestion (swallowing).

Ingestion does not produce a rush as forerunner to the high experienced with the use of heroin, which is most pronounced with intravenous use. While the onset of the rush induced by injection can occur in as little as a few seconds, the oral route of administration requires approximately half an hour before the high sets in. Thus, with both higher the dosage of heroin used and faster the route of administration used, the higher potential risk for psychological addiction.

Large doses of heroin can cause fatal respiratory depression, and the drug has been used for suicide or as a murder weapon. The serial killer Harold Shipman used diamorphine on his victims, and the subsequent Shipman Inquiry led to a tightening of the regulations surrounding the storage, prescribing and destruction of controlled drugs in the UK.

Because significant tolerance to respiratory depression develops quickly with continued use and is lost just as quickly during withdrawal, it is often difficult to determine whether a heroin lethal overdose was accidental, suicide or homicide. Examples include the overdose deaths of Sid Vicious, Janis Joplin, Tim Buckley, Hillel Slovak, Layne Staley, Bradley Nowell, Ted Binion, and River Phoenix.

Chronic use of heroin and other opioids has been shown to be a potential cause of hyponatremia, resultant because of excess vasopressin secretion.

Use of heroin by mouth is less common than other methods of administration, mainly because there is little to no "rush", and the effects are less potent. Heroin is entirely converted to morphine by means of first-pass metabolism, resulting in deacetylation when ingested. Heroin's oral bioavailability is both dose-dependent (as is morphine's) and significantly higher than oral use of morphine itself, reaching up to 64.2% for high doses and 45.6% for low doses; opiate-naive users showed far less absorption of the drug at low doses, having bioavailabilities of only up to 22.9%. The maximum plasma concentration of morphine following oral administration of heroin was around twice as much as that of oral morphine.

Injection, also known as "slamming", "banging", "shooting up", "digging" or "mainlining", is a popular method which carries relatively greater risks than other methods of administration. Heroin base (commonly found in Europe), when prepared for injection, will only dissolve in water when mixed with an acid (most commonly citric acid powder or lemon juice) and heated. Heroin in the east-coast United States is most commonly found in the hydrochloride salt form, requiring just water (and no heat) to dissolve. Users tend to initially inject in the easily accessible arm veins, but as these veins collapse over time, users resort to more dangerous areas of the body, such as the femoral vein in the groin. Users who have used this route of administration often develop a deep vein thrombosis. Intravenous users can use a various single dose range using a hypodermic needle. The dose of heroin used for recreational purposes is dependent on the frequency and level of use: thus a first-time user may use between 5 and 20 mg, while an established addict may require several hundred mg per day. As with the injection of any drug, if a group of users share a common needle without sterilization procedures, blood-borne diseases, such as HIV/AIDS or hepatitis, can be transmitted.
The use of a common dispenser for water for the use in the preparation of the injection, as well as the sharing of spoons and filters can also cause the spread of blood-borne diseases. Many countries now supply small sterile spoons and filters for single use in order to prevent the spread of disease.

Smoking heroin refers to vaporizing it to inhale the resulting fumes, rather than burning and inhaling the smoke. It is commonly smoked in glass pipes made from glassblown Pyrex tubes and light bulbs. Heroin may be smoked from aluminium foil, which is heated by an underneath flame, with the resulting smoke inhaled through a tube of rolled up foil, a method also known as "chasing the dragon".

Another popular route to intake heroin is insufflation (snorting), where a user crushes the heroin into a fine powder and then gently inhales it (sometimes with a straw or a rolled-up banknote, as with cocaine) into the nose, where heroin is absorbed through the soft tissue in the mucous membrane of the sinus cavity and straight into the bloodstream. This method of administration redirects first-pass metabolism, with a quicker onset and higher bioavailability than oral administration, though the duration of action is shortened. This method is sometimes preferred by users who do not want to prepare and administer heroin for injection or smoking, but still experience a fast onset. Snorting heroin becomes an often unwanted route, once a user begins to inject the drug. The user may still get high on the drug from snorting, and experience a nod, but will not get a rush. A "rush" is caused by a large amount of heroin entering the body at once. When the drug is taken in through the nose, the user does not get the rush because the drug is absorbed slowly rather than instantly.

Heroin for pain has been mixed with sterile water on site by the attending physician, and administered using a syringe with a nebuliser tip. Heroin may be used for fractures, burns, finger-tip injuries, suturing, and wound re-dressing, but is inappropriate in head injuries.

Little research has been focused on the suppository (anal insertion) or pessary (vaginal insertion) methods of administration, also known as "plugging". These methods of administration are commonly carried out using an oral syringe. Heroin can be dissolved and withdrawn into an oral syringe which may then be lubricated and inserted into the anus or vagina before the plunger is pushed. The rectum or the vaginal canal is where the majority of the drug would likely be taken up, through the membranes lining their walls.

Heroin is classified as a hard drug in terms of drug harmfulness. Like most opioids, unadulterated heroin may lead to adverse effects. The purity of street heroin varies greatly, leading to overdoses when the purity is higher than they expected.

Users report an intense rush, an acute transcendent state of euphoria, which occurs while diamorphine is being metabolized into 6-monoacetylmorphine (6-MAM) and morphine in the brain. Some believe that heroin produces more euphoria than other opioids; one possible explanation is the presence of 6-monoacetylmorphine, a metabolite unique to heroin – although a more likely explanation is the rapidity of onset. While other opioids of recreational use produce only morphine, heroin also leaves 6-MAM, also a psycho-active metabolite. However, this perception is not supported by the results of clinical studies comparing the physiological and subjective effects of injected heroin and morphine in individuals formerly addicted to opioids; these subjects showed no preference for one drug over the other. Equipotent injected doses had comparable action courses, with no difference in subjects' self-rated feelings of euphoria, ambition, nervousness, relaxation, drowsiness, or sleepiness. The rush is usually accompanied by a warm flushing of the skin, dry mouth, and a heavy feeling in the extremities. Nausea, vomiting, and severe itching may also occur. After the initial effects, users usually will be drowsy for several hours; mental function is clouded; heart function slows; and breathing is also severely slowed, sometimes enough to be life-threatening. Slowed breathing can also lead to coma and permanent brain damage.

Repeated heroin use changes the physical structure and physiology of the brain, creating long-term imbalances in neuronal and hormonal systems that are not easily reversed. Studies have shown some deterioration of the brain's white matter due to heroin use, which may affect decision-making abilities, the ability to regulate behavior, and responses to stressful situations. Heroin also produces profound degrees of tolerance and physical dependence. Tolerance occurs when more and more of the drug is required to achieve the same effects. With physical dependence, the body adapts to the presence of the drug, and withdrawal symptoms occur if use is reduced abruptly.

Intravenous use of heroin (and any other substance) with needles and syringes or other related equipment may lead to:


The withdrawal syndrome from heroin may begin within as little as two hours of discontinuation of the drug; however, this time frame can fluctuate with the degree of tolerance as well as the amount of the last consumed dose, and more typically begins within 6–24 hours after cessation. Symptoms may include sweating, malaise, anxiety, depression, akathisia, priapism, extra sensitivity of the genitals in females, general feeling of heaviness, excessive yawning or sneezing, rhinorrhea, insomnia, cold sweats, chills, severe muscle and bone aches, nausea, vomiting, diarrhea, cramps, watery eyes, fever, cramp-like pains, and involuntary spasms in the limbs (thought to be an origin of the term "kicking the habit").

Heroin overdose is usually treated with the opioid antagonist, naloxone. This reverses the effects of heroin and causes an immediate return of consciousness but may result in withdrawal symptoms. The half-life of naloxone is shorter than some opioids, such that it may need to be given multiple times until the opioid has been metabolized by the body.

Between 2012 and 2015 it was the leading cause of drug related deaths in the United States. Since then fentanyl is a more common cause of drug related deaths.

Depending on drug interactions and numerous other factors, death from overdose can take anywhere from several minutes to several hours. Death usually occurs due to lack of oxygen resulting from the lack of breathing caused by the opioid. Heroin overdoses can occur because of an unexpected increase in the dose or purity or because of diminished opioid tolerance. However, many fatalities reported as overdoses are probably caused by interactions with other depressant drugs such as alcohol or benzodiazepines. Since heroin can cause nausea and vomiting, a significant number of deaths attributed to heroin overdose are caused by aspiration of vomit by an unconscious person. Some sources quote the median lethal dose (for an average 75 kg opiate-naive individual) as being between 75 and 600 mg. Illicit heroin is of widely varying and unpredictable purity. This means that the user may prepare what they consider to be a moderate dose while actually taking far more than intended. Also, tolerance typically decreases after a period of abstinence. If this occurs and the user takes a dose comparable to their previous use, the user may experience drug effects that are much greater than expected, potentially resulting in an overdose. It has been speculated that an unknown portion of heroin-related deaths are the result of an overdose or allergic reaction to quinine, which may sometimes be used as a cutting agent.

When taken orally, heroin undergoes extensive first-pass metabolism via deacetylation, making it a prodrug for the systemic delivery of morphine. When the drug is injected, however, it avoids this first-pass effect, very rapidly crossing the blood–brain barrier because of the presence of the acetyl groups, which render it much more fat soluble than morphine itself. Once in the brain, it then is deacetylated variously into the inactive 3-monoacetylmorphine and the active 6-monoacetylmorphine (6-MAM), and then to morphine, which bind to μ-opioid receptors, resulting in the drug's euphoric, analgesic (pain relief), and anxiolytic (anti-anxiety) effects; heroin itself exhibits relatively low affinity for the μ receptor. Analgesia follows from the activation of the μ receptor G-protein coupled receptor, which indirectly hyperpolarizes the neuron, reducing the release of nociceptive neurotransmitters, and hence, causes analgesia and increased pain tolerance.

Unlike hydromorphone and oxymorphone, however, administered intravenously, heroin creates a larger histamine release, similar to morphine, resulting in the feeling of a greater subjective "body high" to some, but also instances of pruritus (itching) when they first start using.

Normally GABA, released from inhibitory neurones, inhibits the release of dopamine. Opiates, like heroin and morphine, decrease the inhibitory activity of such neurones. This causes increased release of dopamine in the brain which is the reason for euphoric and rewarding effects of heroin.

Both morphine and 6-MAM are μ-opioid agonists that bind to receptors present throughout the brain, spinal cord, and gut of all mammals. The μ-opioid receptor also binds endogenous opioid peptides such as β-endorphin, Leu-enkephalin, and Met-enkephalin. Repeated use of heroin results in a number of physiological changes, including an increase in the production of μ-opioid receptors (upregulation). These physiological alterations lead to tolerance and dependence, so that stopping heroin use results in uncomfortable symptoms including pain, anxiety, muscle spasms, and insomnia called the opioid withdrawal syndrome. Depending on usage it has an onset 4–24 hours after the last dose of heroin. Morphine also binds to δ- and κ-opioid receptors.

There is also evidence that 6-MAM binds to a subtype of μ-opioid receptors that are also activated by the morphine metabolite morphine-6β-glucuronide but not morphine itself. The third subtype of third opioid type is the mu-3 receptor, which may be a commonality to other six-position monoesters of morphine. The contribution of these receptors to the overall pharmacology of heroin remains unknown.

A subclass of morphine derivatives, namely the 3,6 esters of morphine, with similar effects and uses, includes the clinically used strong analgesics nicomorphine (Vilan), and dipropanoylmorphine; there is also the latter's dihydromorphine analogue, diacetyldihydromorphine (Paralaudin). Two other 3,6 diesters of morphine invented in 1874–75 along with diamorphine, dibenzoylmorphine and acetylpropionylmorphine, were made as substitutes after it was outlawed in 1925 and, therefore, sold as the first "designer drugs" until they were outlawed by the League of Nations in 1930.

Diamorphine is produced from acetylation of morphine derived from natural opium sources, generally using acetic anhydride.

The major metabolites of diamorphine, 6-MAM, morphine, morphine-3-glucuronide and morphine-6-glucuronide, may be quantitated in blood, plasma or urine to monitor for abuse, confirm a diagnosis of poisoning or assist in a medicolegal death investigation. Most commercial opiate screening tests cross-react appreciably with these metabolites, as well as with other biotransformation products likely to be present following usage of street-grade diamorphine such as 6-acetylcodeine and codeine. However, chromatographic techniques can easily distinguish and measure each of these substances. When interpreting the results of a test, it is important to consider the diamorphine usage history of the individual, since a chronic user can develop tolerance to doses that would incapacitate an opiate-naive individual, and the chronic user often has high baseline values of these metabolites in his system. Furthermore, some testing procedures employ a hydrolysis step before quantitation that converts many of the metabolic products to morphine, yielding a result that may be 2 times larger than with a method that examines each product individually.

The opium poppy was cultivated in lower Mesopotamia as long ago as 3400 BC. The chemical analysis of opium in the 19th century revealed that most of its activity could be ascribed to the alkaloids codeine and morphine.

Diamorphine was first synthesized in 1874 by C. R. Alder Wright, an English chemist working at St. Mary's Hospital Medical School in London who had been experimenting combining morphine with various acids. He boiled anhydrous morphine alkaloid with acetic anhydride for several hours and produced a more potent, acetylated form of morphine which is now called "diacetylmorphine" or "morphine diacetate". He sent the compound to F. M. Pierce of Owens College in Manchester for analysis. Pierce told Wright:

Wright's invention did not lead to any further developments, and diamorphine became popular only after it was independently re-synthesized 23 years later by chemist Felix Hoffmann. Hoffmann was working at Bayer pharmaceutical company in Elberfeld, Germany, and his supervisor Heinrich Dreser instructed him to acetylate morphine with the objective of producing codeine, a constituent of the opium poppy that is pharmacologically similar to morphine but less potent and less addictive. Instead, the experiment produced an acetylated form of morphine one and a half to two times more potent than morphine itself. The head of Bayer's research department reputedly coined the drug's new name of "heroin," based on the German "heroisch" which means "heroic, strong" (from the ancient Greek word "heros, ήρως"). Bayer scientists were not the first to make heroin, but their scientists discovered ways to make it, and Bayer led commercialization of heroin.

In 1895, Bayer marketed diacetylmorphine as an over-the-counter drug under the trademark name Heroin. It was developed chiefly as a morphine substitute for cough suppressants that did not have morphine's addictive side-effects. Morphine at the time was a popular recreational drug, and Bayer wished to find a similar but non-addictive substitute to market. However, contrary to Bayer's advertising as a "non-addictive morphine substitute," heroin would soon have one of the highest rates of addiction among its users.

From 1898 through to 1910, diamorphine was marketed under the trademark name Heroin as a non-addictive morphine substitute and cough suppressant. In the 11th edition of "Encyclopædia Britannica" (1910), the article on morphine states: "In the cough of phthisis minute doses [of morphine] are of service, but in this particular disease morphine is frequently better replaced by codeine or by heroin, which checks irritable coughs without the narcotism following upon the administration of morphine."

In the U.S., the Harrison Narcotics Tax Act was passed in 1914 to control the sale and distribution of diacetylmorphine and other opioids, which allowed the drug to be prescribed and sold for medical purposes. In 1924, the United States Congress banned its sale, importation, or manufacture. It is now a Schedule I substance, which makes it illegal for non-medical use in signatory nations of the Single Convention on Narcotic Drugs treaty, including the United States.

The Health Committee of the League of Nations banned diacetylmorphine in 1925, although it took more than three years for this to be implemented. In the meantime, the first designer drugs, viz. 3,6 diesters and 6 monoesters of morphine and acetylated analogues of closely related drugs like hydromorphone and dihydromorphine, were produced in massive quantities to fill the worldwide demand for diacetylmorphine—this continued until 1930 when the Committee banned diacetylmorphine analogues with no therapeutic advantage over drugs already in use, the first major legislation of this type.

Bayer lost some of its trademark rights to heroin (as well as aspirin) under the 1919 Treaty of Versailles following the German defeat in World War I.

Use of heroin by jazz musicians in particular was prevalent in the mid-twentieth century, including Billie Holiday, saxophonists Charlie Parker and Art Pepper, guitarist Joe Pass and piano player/singer Ray Charles; a "staggering number of jazz musicians were addicts". It was also a problem with many rock musicians, particularly from the late 1960s through the 1990s. Pete Doherty is also a self-confessed user of heroin. Nirvana lead singer Kurt Cobain's heroin addiction was well documented. Pantera frontman, Phil Anselmo, turned to heroin while touring during the 1990s to cope with his back pain. James Taylor, John Lennon, Eric Clapton, Johnny Winter, Keith Richards and Janis Joplin also used heroin. Many musicians have made songs referencing their heroin usage.

"Diamorphine" is the Recommended International Nonproprietary Name and British Approved Name. Other synonyms for heroin include: diacetylmorphine, and morphine diacetate. Heroin is also known by many street names including dope, H, smack, junk, horse, and brown, among others.

In Hong Kong, diamorphine is regulated under Schedule 1 of Hong Kong's Chapter 134 "Dangerous Drugs Ordinance". It is available by prescription. Anyone supplying diamorphine without a valid prescription can be fined $5,000,000 (HKD) and imprisoned for life. The penalty for trafficking or manufacturing diamorphine is a $5,000,000 (HKD) fine and life imprisonment. Possession of diamorphine without a license from the Department of Health is illegal with a $1,000,000 (HKD) fine and 7 years of jail time.

In the Netherlands, diamorphine is a List I drug of the Opium Law. It is available for prescription under tight regulation exclusively to long-term addicts for whom methadone maintenance treatment has failed. It cannot be used to treat severe pain or other illnesses.

In the United Kingdom, diamorphine is available by prescription, though it is a restricted Class A drug. According to the 50th edition of the British National Formulary (BNF), diamorphine hydrochloride may be used in the treatment of acute pain, myocardial infarction, acute pulmonary oedema, and chronic pain. The treatment of chronic non-malignant pain must be supervised by a specialist. The BNF notes that all opioid analgesics cause dependence and tolerance but that this is "no deterrent in the control of pain in terminal illness". When used in the palliative care of cancer patients, diamorphine is often injected using a syringe driver.

In Switzerland, heroin is produced in injectable or tablet form under the name Diaphin by a private company under contract to the Swiss government. Swiss-produced heroin has been imported into Canada with government approval.

In Australia diamorphine is listed as a schedule 9 prohibited substance under the Poisons Standard (October 2015). A schedule 9 drug is outlined in the Poisons Act 1964 as "Substances which may be abused or misused, the manufacture, possession, sale or use of which should be prohibited by law except when required for medical or scientific research, or for analytical, teaching or training purposes with approval of the CEO."

In Canada, diamorphine is a controlled substance under Schedule I of the Controlled Drugs and Substances Act (CDSA). Any person seeking or obtaining diamorphine without disclosing authorization 30 days before obtaining another prescription from a practitioner is guilty of an indictable offense and subject to imprisonment for a term not exceeding seven years. Possession of diamorphine for the purpose of trafficking is an indictable offense and subject to imprisonment for life.

In the United States, diamorphine is a Schedule I drug according to the Controlled Substances Act of 1970, making it illegal to possess without a DEA license. Possession of more than 100 grams of diamorphine or a mixture containing diamorphine is punishable with a minimum mandatory sentence of 5 years of imprisonment in a federal prison.

Turkey maintains strict laws against the use, possession or trafficking of illegal drugs. If convicted under these offences, one could receive a heavy fine or a prison sentence of 4 to 24 years.

Abused prescription medicine such as opioid can lead to heroin addiction. The number of death from illegal opioid overdose follows the increasing number of death caused by prescription opioid overdoses. Prescription opioids are relatively easy to obtain. This may ultimately lead to heroin injection because heroin is cheaper than prescribed pills.

Diamorphine is produced from acetylation of morphine derived from natural opium sources. One such method of heroin production involves isolation of the water-soluble components of raw opium, including morphine, in a strongly basic aqueous solution, followed by recrystallization of the morphine base by addition of ammonium chloride. The solid morphine base is then filtered out. The morphine base is then reacted with acetic anhydride, which forms heroin. This highly impure brown heroin base may then undergo further purification steps, which produces a white-colored product; the final products have a different appearance depending on purity and have different names. Heroin purity has been classified into four grades. No.4 is the purest form – white powder (salt) to be easily dissolved and injected. No.3 is "brown sugar" for smoking (base). No.1 and No.2 are unprocessed raw heroin (salt or base).

Traffic is heavy worldwide, with the biggest producer being Afghanistan. According to a U.N. sponsored survey, in 2004, Afghanistan accounted for production of 87 percent of the world's diamorphine. Afghan opium kills around 100,000 people annually.

In 2003 "The Independent" reported:
Opium production in that country has increased rapidly since, reaching an all-time high in 2006. War in Afghanistan once again appeared as a facilitator of the trade. Some 3.3 million Afghans are involved in producing opium.

At present, opium poppies are mostly grown in Afghanistan (), and in Southeast Asia, especially in the region known as the Golden Triangle straddling Burma (), Thailand, Vietnam, Laos () and Yunnan province in China. There is also cultivation of opium poppies in Pakistan (), Mexico () and in Colombia (). According to the DEA, the majority of the heroin consumed in the United States comes from Mexico (50%) and Colombia (43-45%) via Mexican criminal cartels such as Sinaloa Cartel. However, these statistics may be significantly unreliable, the DEA's 50/50 split between Colombia and Mexico is contradicted by the amount of hectares cultivated in each country and in 2014, the DEA claimed most of the heroin in the US came from Colombia.
, the Sinaloa Cartel is the most active drug cartel involved in smuggling illicit drugs such as heroin into the United States and trafficking them throughout the United States. According to the Royal Canadian Mounted Police, 90% of the heroin seized in Canada (where the origin was known) came from Afghanistan. Pakistan is the destination and transit point for 40 percent of the opiates produced in Afghanistan, other destinations of Afghan opiates are Russia, Europe and Iran.

Conviction for trafficking heroin carries the death penalty in most Southeast Asian, some East Asian and Middle Eastern countries (see Use of death penalty worldwide for details), among which Malaysia, Singapore and Thailand are the most strict. The penalty applies even to citizens of countries where the penalty is not in place, sometimes causing controversy when foreign visitors are arrested for trafficking, for example the arrest of nine Australians in Bali, the death sentence given to Nola Blake in Thailand in 1987, or the hanging of an Australian citizen Van Tuong Nguyen in Singapore.

The origins of the present international illegal heroin trade can be traced back to laws passed in many countries in the early 1900s that closely regulated the production and sale of opium and its derivatives including heroin. At first, heroin flowed from countries where it was still legal into countries where it was no longer legal. By the mid-1920s, heroin production had been made illegal in many parts of the world. An illegal trade developed at that time between heroin labs in China (mostly in Shanghai and Tianjin) and other nations. The weakness of government in China and conditions of civil war enabled heroin production to take root there. Chinese triad gangs eventually came to play a major role in the illicit heroin trade. The French Connection route started in the 1930s.

Heroin trafficking was virtually eliminated in the U.S. during World War II because of temporary trade disruptions caused by the war. Japan's war with China had cut the normal distribution routes for heroin and the war had generally disrupted the movement of opium. After World War II, the Mafia took advantage of the weakness of the postwar Italian government and set up heroin labs in Sicily. The Mafia took advantage of Sicily's location along the historic route opium took westward into Europe and the United States. Large-scale international heroin production effectively ended in China with the victory of the communists in the civil war in the late 1940s. The elimination of Chinese production happened at the same time that Sicily's role in the trade developed.

Although it remained legal in some countries until after World War II, health risks, addiction, and widespread recreational use led most western countries to declare heroin a controlled substance by the latter half of the 20th century. In the late 1960s and early 1970s, the CIA supported anti-Communist Chinese Nationalists settled near the Sino-Burmese border and Hmong tribesmen in Laos. This helped the development of the Golden Triangle opium production region, which supplied about one-third of heroin consumed in US after the 1973 American withdrawal from Vietnam. In 1999, Burma, the heartland of the Golden Triangle, was the second largest producer of heroin, after Afghanistan.

The Soviet-Afghan war led to increased production in the Pakistani-Afghan border regions, as U.S.-backed mujaheddin militants raised money for arms from selling opium, contributing heavily to the modern Golden Crescent creation. By 1980, 60 percent of heroin sold in the U.S. originated in Afghanistan. It increased international production of heroin at lower prices in the 1980s. The trade shifted away from Sicily in the late 1970s as various criminal organizations violently fought with each other over the trade. The fighting also led to a stepped-up government law enforcement presence in Sicily.

Following the discovery at a Jordanian airport of a toner cartridge that had been modified into an improvised explosive device, the resultant increased level of airfreight scrutiny led to a major shortage (drought) of heroin from October 2010 until April 2011. This was reported in most of mainland Europe and the UK which led to a price increase of approximately 30 percent in the cost of street heroin and an increased demand for diverted methadone. The number of addicts seeking treatment also increased significantly during this period. Other heroin droughts (shortages) have been attributed to cartels restricting supply in order to force a price increase and also to a fungus that attacked the opium crop of 2009. Many people thought that the American government had introduced pathogens into the Afghanistan atmosphere in order to destroy the opium crop and thus starve insurgents of income.

On 13 March 2012, Haji Bagcho, with ties to the Taliban, was convicted by a U.S. District Court of conspiracy, distribution of heroin for importation into the United States and narco-terrorism. Based on heroin production statistics compiled by the United Nations Office on Drugs and Crime, in 2006, Bagcho's activities accounted for approximately 20 percent of the world's total production for that year.

The European Monitoring Centre for Drugs and Drug Addiction reports that the retail price of brown heroin varies from €14.5 per gram in Turkey to €110 per gram in Sweden, with most European countries reporting typical prices of €35–40 per gram. The price of white heroin is reported only by a few European countries and ranged between €27 and €110 per gram.

The United Nations Office on Drugs and Crime claims in its 2008 World Drug Report that typical US retail prices are US$172 per gram.

Harm reduction is a public health philosophy that seeks to reduce the harms associated with the use of illicit drugs. One aspect of harm reduction initiatives focuses on the behaviour of individual users. In the case of diamorphine, this includes promoting safer means of taking the drug, such as smoking, nasal use, oral or rectal insertion. This attempts to avoid the higher risks of overdose, infections and blood-borne viruses associated with injecting the drug. Other measures include using a small amount of the drug first to gauge the strength, and minimize the risks of overdose. For the same reason, poly drug use (the use of two or more drugs at the same time) is discouraged. Injecting diamorphine users are encouraged to use new needles, syringes, spoons/steri-cups and filters every time they inject and not share these with other users. Users are also encouraged to not use it on their own, as others can assist in the event of an overdose.

Governments that support a harm reduction approach usually fund needle and syringe exchange programs, which supply new needles and syringes on a confidential basis, as well as education on proper filtering before injection, safer injection techniques, safe disposal of used injecting gear and other equipment used when preparing diamorphine for injection may also be supplied including citric acid sachets/vitamin C sachets, steri-cups, filters, alcohol pre-injection swabs, sterile water ampules and tourniquets (to stop use of shoe laces or belts).

Another harm reduction measure employed for example in Europe, Canada and Australia are safe injection sites where users can inject diamorphine and cocaine under the supervision of medically trained staff. Safe injection sites are low threshold and allow social services to approach problem users that would otherwise be hard to reach.
In the UK the Criminal Justice System has a protocol in place that requires that any individual that is arrested and is suspected of having a substance misuse problem be offered the chance to enter a treatment program. This has had the effect of drastically reducing an area's crime rate as individuals arrested for theft in order to supply the funds for their drugs are no longer in the position of having to steal to purchase heroin because they have been placed onto a methadone program, quite often more quickly than would have been possible had they not been arrested. This aspect of harm reduction is seen as being beneficial to both the individual and the community at large, who are then protected from the possible theft of their goods.

During the late 1980s and early 1990s, Swiss authorities ran the ZIPP-AIDS (Zurich Intervention Pilot Project), handing out free syringes in the officially tolerated drug scene in Platzspitz park. In 1994, Zurich started a pilot project using prescription heroin in heroin-assisted treatment (HAT) which allowed users to obtain heroin and inject it under medical supervision. The HAT program proved to be cost-beneficial to society and improve patients overall health and social stability and has since been introduced in multiple European countries.

Researchers are attempting to reproduce the biosynthetic pathway that produces morphine in genetically engineered yeast. In June 2015 the "S"-reticuline could be produced from sugar and "R"-reticuline could be converted to morphine, but the intermediate reaction could not be performed.




</doc>
<doc id="14035" url="https://en.wikipedia.org/wiki?curid=14035" title="Hellas Verona F.C.">
Hellas Verona F.C.

Hellas Verona Football Club, commonly referred to as Hellas Verona or simply Verona, is an Italian football club based in Verona, Veneto, that currently plays in Serie A. The team won the Serie A Championship in 1984–85.

Founded in 1903 by a group of high school students from Greece, the club was named "Hellas", at the request of a professor of classics. At a time in which football was played seriously only in the larger cities of the northwestern Italy, most of Verona was indifferent to the growing sport. However, when in 1906 two city teams chose the city's Roman amphitheatre as a venue to showcase the game, crowd enthusiasm and media interest began to rise.

During these first few years, Hellas was one of three or four area teams playing mainly at a municipal level while fighting against city rivals Bentegodi to become the city's premier football outfit. By the 1907–08 season, Hellas was playing against regional teams and an intense rivalry with Vicenza that lasts to this day was born.

From 1898 to 1926, Italian football was organised into regional groups. In this period, Hellas was one of the founding teams of the early league and often among its top final contenders. In 1911, the city helped Hellas replace the early, gritty football fields with a proper venue. This allowed the team to take part in its first regional tournament, which until 1926, was the qualifying stage for the national title.

In 1919, following a return to activity after a four-year suspension of all football competition in Italy during World War I, the team merged with city rival Verona and changed its name to Hellas Verona. Between 1926 and 1929, the elite ""Campionato Nazionale"" assimilated the top sides from the various regional groups and Hellas Verona joined the privileged teams, yet struggled to remain competitive.

Serie A, as it is structured today, began in 1929, when the "Campionato Nazionale" turned into a professional league. Still an amateur team, Hellas merged with two city rivals, Bentegodi and Scaligera, to form AC Verona. Hoping to build a first class contender for future years, the new team debuted in Serie B in 1929. It would take the "gialloblu" 28 years to finally achieve their goal. After first being promoted to Serie A for one season in 1957–58, in 1959, the team merged with another city rival (called Hellas) and commemorated its beginnings by changing its name to Hellas Verona AC.

Coached by Nils Liedholm, the team returned to Serie A in 1968 and remained in the elite league almost without interruption until 1990. Along the way, it scored a famous 5–3 win in the 1972–73 season that cost Milan the "scudetto" (the Serie A title). The fact that the result came late during the last matchday of the season makes the sudden and unexpected end to the "rossoneri"'s title ambitions all the more memorable.

In 1973–74, Hellas finished the season in fourth-last, just narrowly avoiding relegation, but were nonetheless sent down to Serie B during the summer months as a result of a scandal involving team president Saverio Garonzi. After a year in Serie B, Hellas returned to Serie A.

In the 1975–76 season, the team had a successful run in the Coppa Italia, eliminating highly rated teams such as Torino, Cagliari and Internazionale from the tournament. However, in their first ever final in the competition, Hellas were trounced 4–0 by Napoli.

Under the leadership of coach Osvaldo Bagnoli, in 1982–83 the team secured a fourth-place in Serie A (its highest finish at the time) and even led the Serie A standings for a few weeks. The same season Hellas again reached the Coppa Italia final. After a 2–0 home victory, Hellas then travelled to Turin to play Juventus but were defeated 3–0 after extra time.

Further disappointment followed in the 1983–84 season when the team again reached the Coppa Italia final, only to lose the Cup in the final minutes of the return match against defending Serie A champions Roma

The team made its first European appearance in the 1983-84 UEFA Cup and were knocked out in the second round of the tournament by Sturm Graz. Hellas were eliminated from the 1985–86 European Cup in the second round by defending champions and fellow Serie A side Juventus after a contested game, the result of a scandalous arbitrage by the French Wurtz, having beaten PAOK of Greece in the first round.

In 1988, the team had their best international result when they reached the UEFA Cup quarterfinals with four victories and three draws. The decisive defeat came from German side Werder Bremen.

Although the 1984–85 season squad was made up of a mix of emerging players and mature stars, at the beginning of the season no one would have regarded the team as having the necessary ingredients to make it to the end. Certainly, the additions of Hans-Peter Briegel in midfield and of Danish striker Preben Elkjær to an attack that already featured the wing play of Pietro Fanna, the creative abilities of Antonio Di Gennaro and the scoring touch of Giuseppe Galderisi were to prove crucial.

To mention a few of the memorable milestones on the road to the "scudetto": a decisive win against Juventus (2–0), with a goal scored by Elkjær after having lost a boot in a tackle just outside the box, set the stage early in the championship; an away win over Udinese (5–3) ended any speculation that the team was losing energy at the midway point; three straight wins (including a hard-fought 1–0 victory against a strong Roma side) served notice that the team had kept its polish and focus intact during their rival's final surge; and a 1–1 draw in Bergamo against Atalanta secured the title with a game in hand.

Hellas finished the year with a 15–13–2 record and 43 points, four points ahead of Torino F.C. with Internazionale and Sampdoria rounding out the top four spots. This unusual final table of the Serie A (with the most successful Italian teams of the time, Juventus and Roma, ending up much lower than expected) has led to many speculations. The 1984–85 season was the only season when referees were assigned to matches by way of a random draw. Before then each referee had always been assigned to a specific match by a special commission of referees ("designatori arbitrali"). After the betting scandal of the early 1980 (the Calcio Scommesse scandal), it was decided to clean up the image of Italian football by assigning referees randomly instead of picking them, to clear up all the suspicions and accusations always accompanying Italy's football life. This resulted in a quieter championship and in a completely unexpected final table.

In the following season, won again by Juventus, the choice of the referees went back in the hands of the "designatori arbitrali". In 2006, a major scandal in Italian football revealed that certain clubs had been illegally influencing the referee selection process in an attempt to ensure that certain referees were assigned to their matches.

These were more than mere modest achievements for a mid-size city with a limited appeal to fans across the nation. But soon enough financial difficulties caught up with team managers. In 1991 the team folded and was reborn as Verona, regularly moving to and fro between Serie A and Serie B for several seasons. In 1995 the name was officially changed back to Hellas Verona.

After a three-year stay, their last stint in Serie A ended in grief in 2002. That season emerging international talents such as Adrian Mutu, Mauro Camoranesi, Alberto Gilardino, Martin Laursen, Massimo Oddo, Marco Cassetti and coach Alberto Malesani failed to capitalise on an excellent start and eventually dropped into fourth-to-last place for the first time all season on the very last matchday, enforcing relegation into Serie B.

Following the 2002 relegation to Serie B, team fortunes continued to slip throughout the decade. In the 2003–04 season Hellas Verona struggled in Serie B and spent most of the season fighting off an unthinkable relegation to Serie C1. Undeterred, the fans supported their team and a string of late season wins eventually warded off the danger. Over 5,000 of them followed Hellas to Como on the final day of the season to celebrate.

In 2004–05, things looked much brighter for the team. After a rocky start, Hellas put together a string of results and climbed to third spot. The "gialloblù" held on to the position until January 2005, when transfers weakened the team, yet they managed to take the battle for Serie A to the last day of the season.

The 2006–07 Serie B seemed to start well, due to the club takeover by Pietro Arvedi D'Emilei, which ended nine years of controversial leadership under chairman Gianbattista Pastorello, heavily contested by the supporters in his later years at Verona. However, Verona was immediately involved in the relegation battle, and Massimo Ficcadenti was replaced in December 2006 by Giampiero Ventura. Despite a recovery in the results, Verona ended in an 18th place, thus being forced to play a two-legged playoff against 19th-placed Spezia to avert relegation. A 2–1 away loss in the first leg at La Spezia was followed by a 0–0 home tie, and Verona were relegated to Serie C1 after 64 years of play in the two highest divisions.

Verona appointed experienced coach Franco Colomba for the new season with the aim to return to Serie B as soon as possible. However, despite being widely considered the division favourite, the "gialloblù" spent almost the entire season in last place. After seven matches, club management sacked Colomba in early October and replaced him with youth team coach (and former Verona player) Davide Pellegrini. A new owner acquired the club in late 2007, appointing Giovanni Galli in December as new director of football and Maurizio Sarri as new head coach. Halfway through the 2007–08 season, the team remained at the bottom of Serie C1, on the brink of relegation to the fourth level (Serie C2). In response, club management sacked Sarri and brought back Pellegrini. Thanks to a late-season surge the "scaligeri" avoided direct relegation by qualifying for the relegation play-off, and narrowly averted dropping to Lega Pro Seconda Divisione in the final game, beating Pro Patria 2–1 on aggregate. However, despite the decline in results, attendance and season ticket sales remained at 15,000 on average.

For the 2008–09 season, Verona appointed former Sassuolo and Piacenza manager Gian Marco Remondina with the aim to win promotion to Serie B. However, the season did not start impressively, with Verona being out of the playoff zone by mid-season, and club chairman Pietro Arvedi D'Emilei entering into a coma after being involved in a car crash on his way back from a league match in December 2008. Arvedi died in March 2009, two months after the club was bought by new chairman Giovanni Martinelli.

The following season looked promising, as new transfer players were brought aboard, and fans enthusiastically embraced the new campaign. Season ticket figures climbed to over 10,000, placing Verona ahead of several Serie A teams and all but Torino in Serie B attendance. The team led the standings for much of the season, accumulating a seven-point lead by early in the spring. However, the advantage was gradually squandered, and the team dropped to second place on the second-last day of the season, with a chance to regain first place in the final regular season match against Portogruaro on home soil. Verona, however, disappointed a crowd of over 25,000 fans and, with the loss, dropped to third place and headed towards the play-offs. A managerial change for the post-season saw the firing of Remondina and the arrival of Giovanni Vavassori. After eliminating Rimini in the semi-finals (1–0; 0–0) Verona lost the final to Pescara (2–2 on home soil and 0–1 in the return match) and were condemned to a fourth-straight year of third division football.

Former 1990 World Cup star Giuseppe Giannini (a famous captain of Roma for many years) signed as manager for the 2010–11 campaign. Once again, the team was almost entirely revamped during the transfer season. The squad struggled in the early months and Giannini was eventually sacked and replaced by former Internazionale defender Andrea Mandorlini, who succeeded in reorganising the team's play and bringing discipline both on and off the pitch. In the second half of the season, Verona climbed back from the bottom of the division to clinch a play-off berth (fifth place) on the last day of the regular season. The team advanced to the play-off final after eliminating Sorrento in the semi-finals 3–1 on aggregate. Following the play-off final, after four years of Lega Pro football, Verona were promoted back to Serie B after a 2–1 aggregate win over Salernitana on 19 June 2011.

On 18 May 2013, Verona finished second in Serie B and were promoted to Serie A after an 11-year absence. Their return to the top flight began against title contenders Milan and Roma, beating the former 2–1 and losing to the latter 3–0. The team continued at a steady pace, finishing the first half of the season with 32 points and sitting in sixth place—11 points behind the closest UEFA Champions League spot—and tied with Internazionale for the final UEFA Europa League spot. Verona, however, ultimately finished the year in tenth.

During the 2015–16 season, Verona had not won a single match since the beginning of the campaign until the club edged Atalanta 2–1 on 3 February 2016 in a win at home; coming twenty-three games into the season. Consequently, Verona were relegated from Serie A.

In the 2016–17 Serie B season, Hellas Verona finished second on the table and were automatically promoted back to Serie A. Hellas went on to only last one season back in the top division after finishing second last during the 2017–18 Serie A season and were relegated back to Serie B. At the end of the 2018–19 Serie B season, Hellas finished in 5th position and achieved promotion back to Serie A after defeating Cittadella 3–0 in the second leg of their promotion playoff to win 3–2 on aggregate.

The team's colours are yellow and blue. As a result the clubs most widely used nickname is "gialloblu" literally "yellow-blue" in Italian. The colours represent the city itself and Verona's emblem (a yellow cross on a blue shield) appears on most team apparel. Two more team nicknames are "Mastini" (the mastiffs) and "Scaligeri", both references to Mastino I della Scala of the Della Scala princes that ruled the city during the 13th and 14th centuries.

The Scala family coat of arms is depicted on the team's jersey and on its trademark logo as a stylised image of two large, powerful mastiffs facing opposite directions, introduced in 1995. In essence, the term ""scaligeri"" is synonymous with Veronese, and therefore can describe anything or anyone from Verona (e.g., Chievo Verona, a different team that also links itself to the Scala family – specifically to Cangrande I della Scala).

Since 1963, the club have played at the Stadio Marc'Antonio Bentegodi, which has a capacity of 39,211. The ground is shared with Hellas' rivals, Chievo Verona. It was used as a venue for the 1990 FIFA World Cup.

The intercity fixtures against Chievo Verona are known as the "Derby della Scala". The name refers to the Scaligeri or della Scala aristocratic family, who were rulers of Verona during the Middle Ages and early Renaissance. In the season 2001–02, both Hellas Verona and the city rivals of Chievo Verona were playing in the Serie A. The first ever derby of Verona in Serie A took place on 18 November 2001, while both teams were ranked among the top four. The match was won by Hellas, 3–2. Chievo got revenge in the return match in spring 2002, winning 2–1. Verona thus became the fifth city in Italy, after Milan, Rome, Turin and Genoa to host a cross-town derby in Serie A.

Serie A

Serie B

Coppa Italia



 



The following players have been selected by their country in the World Cup Finals, while playing for Hellas Verona.


</doc>
<doc id="14036" url="https://en.wikipedia.org/wiki?curid=14036" title="Hinayana">
Hinayana

"Hīnayāna" () is a Sanskrit term literally meaning the "small/deficient vehicle". Classical Chinese and Tibetan teachers translate it as "smaller vehicle". The term was applied to the "Śrāvakayāna", the Buddhist path followed by a śrāvaka who wished to become an arhat. This term appeared around the first or second century. Hīnayāna was often contrasted with "Mahāyāna", which means the "great vehicle".

In 1950 the World Fellowship of Buddhists declared that the term Hīnayāna should not be used when referring to any form of Buddhism existing today.

In the past, the term was widely used by Western scholars to cover "the earliest system of Buddhist doctrine", as the "Monier-Williams Sanskrit-English Dictionary" put it. Modern Buddhist scholarship has deprecated the pejorative term, and uses instead the term "Nikaya Buddhism" to refer to early Buddhist schools.

"Hinayana" has also been used as a synonym for Theravada, which is the main tradition of Buddhism in Sri Lanka and Southeast Asia; this is considered inaccurate and derogatory. Robert Thurman writes, "'Nikaya Buddhism' is a coinage of Professor Masatoshi Nagatomi of Harvard University, who suggested it to me as a usage for the eighteen schools of Indian Buddhism to avoid the term 'Hinayana Buddhism,' which is found offensive by some members of the Theravada tradition."

Within Mahayana Buddhism, there were a variety of interpretations as to whom or to what the term "Hinayana" referred. Kalu Rinpoche stated the "lesser" or "greater" designation "did not refer to economic or social status, but concerned the spiritual capacities of the practitioner".
The word "hīnayāna" is formed of "hīna": "little", "poor", "inferior", "abandoned", "deficient", "defective"; and "yāna" (यान): "vehicle", where "vehicle" means "a way of going to enlightenment". The Pali Text Society's "Pali-English Dictionary" (1921–25) defines "hīna" in even stronger terms, with a semantic field that includes "poor, miserable; vile, base, abject, contemptible", and "despicable".

The term was translated by Kumārajīva and others into Classical Chinese as "small vehicle" (小 meaning "small", 乘 meaning "vehicle"), although earlier and more accurate translations of the term also exist. In Mongolian ("Baga Holgon") the term for hinayana also means "small" or "lesser" vehicle, while in Tibetan there are at least two words to designate the term, "theg chung" meaning "small vehicle" and "theg dman" meaning "inferior vehicle" or "inferior spiritual approach".

Thrangu Rinpoche has emphasized that "hinayana" is in no way implying "inferior". In his translation and commentary of Asanga's "Distinguishing Dharma from Dharmata", he writes, "all three traditions of hinayana, mahayana, and vajrayana were practiced in Tibet and that the hinayana which literally means "lesser vehicle" is in no way inferior to the mahayana."

According to Jan Nattier, it is most likely that the term Hīnayāna postdates the term Mahāyāna and was only added at a later date due to antagonism and conflict between the bodhisattva and śrāvaka ideals. The sequence of terms then began with the term "Bodhisattvayāna" "bodhisattva-vehicle", which was given the epithet Mahāyāna "Great Vehicle". It was only later, after attitudes toward the bodhisattva teachings had become more critical, that the term Hīnayāna was created as a back-formation, contrasting with the already established term Mahāyāna. The earliest Mahāyāna texts often use the term Mahāyāna as an epithet and synonym for Bodhisattvayāna, but the term Hīnayāna is comparatively rare in early texts, and is usually not found at all in the earliest translations. Therefore, the often-perceived symmetry between Mahāyāna and Hīnayāna can be deceptive, as the terms were not actually coined in relation to one another in the same era.

According to Paul Williams, "the deep-rooted misconception concerning an unfailing, ubiquitous fierce criticism of the Lesser Vehicle by the [Mahāyāna] is not supported by our texts." Williams states that while evidence of conflict is present in some cases, there is also substantial evidence demonstrating peaceful coexistence between the two traditions.

Although the 18–20 early Buddhist schools are sometimes loosely classified as Hīnayāna in modern times, this is not necessarily accurate. There is no evidence that Mahāyāna ever referred to a separate formal school of Buddhism but rather as a certain set of ideals, and later doctrines. Paul Williams has also noted that the Mahāyāna never had nor ever attempted to have a separate vinaya or ordination lineage from the early Buddhist schools, and therefore bhikṣus and bhikṣuṇīs adhering to the Mahāyāna formally adheres to the vinaya of an early school. This continues today with the Dharmaguptaka ordination lineage in East Asia and the Mūlasarvāstivāda ordination lineage in Tibetan Buddhism. Mahāyāna was never a separate sect of the early schools. From Chinese monks visiting India, we now know that both Mahāyāna and non-Mahāyāna monks in India often lived in the same monasteries side by side.

The seventh-century Chinese Buddhist monk and pilgrim Yijing wrote about the relationship between the various "vehicles" and the early Buddhist schools in India. He wrote, "There exist in the West numerous subdivisions of the schools which have different origins, but there are only four principal schools of continuous tradition." These schools are the Mahāsāṃghika Nikāya, Sthavira nikāya, Mūlasarvāstivāda Nikāya, and Saṃmitīya Nikāya. Explaining their doctrinal affiliations, he then writes, "Which of the four schools should be grouped with the Mahāyāna or with the Hīnayāna is not determined." That is to say, there was no simple correspondence between a Buddhist school and whether its members learn "Hīnayāna" or "Mahāyāna" teachings.

To identify entire schools as "Hīnayāna" that contained not only śrāvakas and pratyekabuddhas but also Mahāyāna bodhisattvas would be attacking the schools of their fellow Mahāyānists as well as their own. Instead, what is demonstrated in the definition of "Hīnayāna" given by Yijing is that the term referred to individuals based on doctrinal differences.

Scholar Isabelle Onians asserts that although "the Mahāyāna ... very occasionally referred to earlier Buddhism as the Hinayāna, the Inferior Way, [...] the preponderance of this name in the secondary literature is far out of proportion to occurrences in the Indian texts." She notes that the term Śrāvakayāna was "the more politically correct and much more usual" term used by Mahāyānists. Jonathan Silk has argued that the term "Hinayana" was used to refer to whomever one wanted to criticize on any given occasion, and did not refer to any definite grouping of Buddhists.

The Chinese monk Yijing, who visited India in the 7th century, distinguished Mahāyāna from Hīnayāna as follows:

In the 7th century, the Chinese Buddhist monk Xuanzang describes the concurrent existence of the Mahāvihara and the Abhayagiri vihāra in Sri Lanka. He refers to the monks of the Mahāvihara as the "Hīnayāna Sthaviras" and the monks of Abhayagiri vihāra as the "Mahāyāna Sthaviras". Xuanzang further writes, "The Mahāvihāravāsins reject the Mahāyāna and practice the Hīnayāna, while the Abhayagirivihāravāsins study both Hīnayāna and Mahāyāna teachings and propagate the "Tripiṭaka"."

Mahayanists were primarily in philosophical dialectic with the Vaibhāṣika school of Sarvāstivāda, which had by far the most "comprehensive edifice of doctrinal systematics" of the nikāya schools. With this in mind it is sometimes argued that the Theravada would not have been considered a "Hinayana" school by Mahayanists because, unlike the now-extinct Sarvastivada school, the primary object of Mahayana criticism, the Theravada school does not claim the existence of independent dharmas; in this it maintains the attitude of early Buddhism. Additionally, the concept of the bodhisattva as one who puts off enlightenment rather than reaching awakening as soon as possible, has no roots in Theravada textual or cultural contexts, current or historical. Aside from the Theravada schools being geographically distant from the Mahayana, the Hinayana distinction is used in reference to certain views and practices that had become found within the Mahayana tradition itself. Theravada, as well as Mahayana schools stress the urgency of one's own awakening in order to end suffering. Some contemporary Theravadin figures have thus indicated a sympathetic stance toward the Mahayana philosophy found in the "Heart Sutra" and the "Mūlamadhyamakakārikā".

The Mahayanists were bothered by the substantialist thought of the Sarvāstivādins and Sautrāntikins, and in emphasizing the doctrine of śūnyatā, David Kalupahana holds that they endeavored to preserve the early teaching. The Theravadins too refuted the Sarvāstivādins and Sautrāntikins (and followers of other schools) on the grounds that their theories were in conflict with the non-substantialism of the canon. The Theravada arguments are preserved in the "Kathavatthu".

Some western scholars still regard the Theravada school to be one of the Hinayana schools referred to in Mahayana literature, or regard Hinayana as a synonym for Theravada, although there is strong evidence that the Theravada schools were in existence as is, long before Mahayana doctrine was created, and certainly many centuries before the derogatory word Hinayana was created. These scholars understand the term to refer to schools of Buddhism that did not accept the teachings of the Mahāyāna sūtras as authentic teachings of the Buddha. At the same time, scholars have objected to the pejorative connotation of the term Hinayana and some scholars do not use it for any school.




</doc>
<doc id="14045" url="https://en.wikipedia.org/wiki?curid=14045" title="Humphrey Bogart">
Humphrey Bogart

Humphrey DeForest Bogart (; December 25, 1899January 14, 1957) was an American film and stage actor. His performances in Classical Hollywood cinema films made him an American cultural icon. In 1999, the American Film Institute selected Bogart as the greatest male star of classic American cinema.

Bogart began acting in Broadway shows, beginning his career in motion pictures with "Up the River" (1930) for Fox. Bogart appeared in supporting roles for the next decade, sometimes portraying gangsters. Bogart was praised for his work as Duke Mantee in "The Petrified Forest" (1936), but remained secondary to other actors Warner Bros. cast in lead roles.

His breakthrough from supporting roles to stardom came with "High Sierra" (1941, his last gangster role) and "The Maltese Falcon" (1941), considered one of the first great "noir" films. Bogart's private detectives, Sam Spade (in "The Maltese Falcon") and Phillip Marlowe (in 1946's "The Big Sleep"), became the models for detectives in other "noir" films. His most significant romantic lead role was with Ingrid Bergman in "Casablanca" (1942), which earned him his first nomination for the Academy Award for Best Actor. Bogart and 19-year-old Lauren Bacall fell in love when they filmed "To Have and Have Not" (1944); soon after the main filming for "The Big Sleep" (1946, their second film together), he filed for divorce from his third wife and married Bacall. After their marriage, she played his love interest in "Dark Passage" (1947) and "Key Largo" (1948).

Bogart's performances in "The Treasure of the Sierra Madre" (1948) and "In a Lonely Place" (1950) are now considered among his best, although they were not recognized as such when the films were released. He reprised those unsettled, unstable characters as a World War II naval-vessel commander in "The Caine Mutiny" (1954), which was a critical and commercial hit and earned him another Best Actor nomination. As a cantankerous river steam launch skipper with Katharine Hepburn's missionary in the World War I adventure "The African Queen" (1951), Bogart received the Academy Award for Best Actor. In his later years, significant roles included "The Barefoot Contessa" with Ava Gardner and his on-screen competition with William Holden for Audrey Hepburn in "Sabrina" (1954). A heavy smoker and drinker, Bogart died from esophageal cancer in January 1957.

Humphrey DeForest Bogart was born on Christmas Day 1899 in New York City, the eldest child of Belmont DeForest Bogart (1867–1934) and Maud Humphrey (1868–1940). Belmont was the only child of the unhappy marriage of Adam Welty Bogart (a Canandaigua, New York, innkeeper) and Julia Augusta Stiles, a wealthy heiress. The name "Bogart" derives from the Dutch surname, "Bogaert". Belmont and Maud married in June 1898. He was a Presbyterian, of English and Dutch descent, and a descendant of Sarah Rapelje (the first European child born in New Netherland). Maud was an Episcopalian of English heritage, and a descendant of "Mayflower" passenger John Howland. Humphrey was raised Episcopalian, but was non-practicing for most of his adult life.

The date of Bogart's birth has been disputed. Clifford McCarty wrote that Warner Bros. publicity department had altered it to January 23, 1900 "to foster the view that a man born on Christmas Day couldn't really be as villainous as he appeared to be on screen". The "corrected" January birthdate subsequently appeared—and in some cases, remains—in many otherwise-authoritative sources. According to biographers Ann M. Sperber and Eric Lax, Bogart always celebrated his birthday on December 25 and listed it on official records (including his marriage license).

Lauren Bacall wrote in her autobiography that Bogart's birthday was always celebrated on Christmas Day, saying that he joked about being cheated out of a present every year. Sperber and Lax noted that a birth announcement in the "Ontario County Times" of January 10, 1900 rules out the possibility of a January 23 birthdate; state and federal census records from 1900 also report a Christmas 1899 birthdate.
Belmont, Bogart's father, was a cardiopulmonary surgeon. Maud was a commercial illustrator who received her art training in New York and France, including study with James Abbott McNeill Whistler. She later became art director of the fashion magazine "The Delineator" and a militant suffragette. Maud used a drawing of baby Humphrey in an advertising campaign for Mellins Baby Food. She earned over $50,000 a year at the peak of her career, considerably more than her husband's $20,000. The Bogarts lived in an Upper West Side apartment, and had a cottage on a 55-acre estate on Canandaigua Lake in upstate New York. When he was young, Bogart's group of friends at the lake would put on plays.

He had two younger sisters: Frances ("Pat") and Catherine Elizabeth ("Kay"). Bogart's parents were busy in their careers, and frequently fought. Very formal, they showed little emotion towards their children. Maud told her offspring to call her "Maud" instead of "Mother", and showed little (if any) physical affection for them. When she was pleased, she "[c]lapped you on the shoulder, almost the way a man does", Bogart recalled. "I was brought up very unsentimentally but very straightforwardly. A kiss, in our family, was an event. Our mother and father didn't glug over my two sisters and me."

Bogart was teased as a boy for his curls, tidiness, the "cute" pictures his mother had him pose for, the Little Lord Fauntleroy clothes in which she dressed him, and for his first name. He inherited a tendency to needle, a fondness for fishing, a lifelong love of boating, and an attraction to strong-willed women from his father.

Bogart attended the private Delancey School until the fifth grade, and then attended the prestigious Trinity School. He was an indifferent, sullen student who showed no interest in after-school activities. Bogart later attended Phillips Academy, a boarding school to which he was admitted based on family connections. Although his parents hoped that he would go on to Yale University, in 1918 Bogart left Phillips. Several reasons have been given; according to one, he was expelled for throwing the headmaster (or a groundskeeper) into Rabbit Pond on campus. Another cited smoking, drinking, poor academic performance, and (possibly) inappropriate comments made to the staff. In a third scenario, Bogart was withdrawn by his father for failing to improve his grades. His parents were deeply disappointed in their failed plans for his future.

With no viable career options, Bogart followed his passion for the sea and enlisted in the United States Navy in the spring of 1918 (during World War I). He recalled later, "At eighteen, war was great stuff. Paris! Sexy French girls! Hot damn!" Bogart was recorded as a model sailor, who spent most of his sea time after the armistice ferrying troops back from Europe.

He may have received his trademark scar and developed his characteristic lisp during his naval stint. There are several conflicting stories. In one, his lip was cut by shrapnel when his ship (the ) was shelled. The ship was never shelled, however, and it is believed that Bogart was not at sea before the armistice. Another story, held by longtime friend Nathaniel Benchley, was that Bogart was injured while taking a prisoner to Portsmouth Naval Prison in Kittery, Maine. While changing trains in Boston, the handcuffed prisoner reportedly asked Bogart for a cigarette. When Bogart looked for a match, the prisoner smashed him across the mouth with the cuffs (cutting Bogart's lip) and fled before he was recaptured and imprisoned. In an alternative version, Bogart was struck in the mouth by a handcuff loosened while freeing his charge; the other handcuff was still around the prisoner's wrist. By the time Bogart was treated by a doctor, a scar had formed. David Niven said that when he first asked Bogart about his scar, however, he said that it was caused by a childhood accident. "Goddamn doctor", Bogart later told Niven. "Instead of stitching it up, he screwed it up." According to Niven, the stories that Bogart got the scar during wartime were made up by the studios. His post-service physical did not mention the lip scar, although it noted many smaller scars. When actress Louise Brooks met Bogart in 1924, he had scar tissue on his upper lip which Brooks said Bogart may have had partially repaired before entering the film industry in 1930. Brooks said that his "lip wound gave him no speech impediment, either before or after it was mended."

Bogart returned home to find his father in poor health, his medical practice faltering, and much of the family's wealth lost in bad timber investments. His character and values developed separate from his family during his navy days, and he began to rebel. Bogart became a liberal who disliked pretension, phonies and snobs, sometimes defying conventional behavior and authority; he was also well-mannered, articulate, punctual, self-effacing and standoffish. After his naval service he worked as a shipper and a bond salesman, joining the Coast Guard Reserve.
Bogart resumed his friendship with Bill Brady Jr. (whose father had show-business connections), and obtained an office job with William A. Brady's new World Films company. Although he wanted to try his hand at screenwriting, directing, and production, he excelled at none. Bogart was stage manager for Brady's daughter Alice's play "A Ruined Lady". He made his stage debut a few months later as a Japanese butler in Alice's 1921 play "Drifting" (nervously delivering one line of dialogue), and appeared in several of her subsequent plays.

Although Bogart had been raised to believe that acting was a lowly profession, he liked the late hours actors kept and the attention they received: "I was born to be indolent and this was the softest of rackets." He spent much of his free time in speakeasies, drinking heavily. A barroom brawl at this time was also a purported cause of Bogart's lip damage, dovetailing with Louise Brooks' account.

Preferring to learn by doing, he never took acting lessons. Bogart was persistent and worked steadily at his craft, appearing in at least 17 Broadway productions between 1922 and 1935. He played juveniles or romantic supporting roles in drawing-room comedies and is reportedly the first actor to say, "Tennis, anyone?" on stage. According to Alexander Woollcott, Bogart "is what is usually and mercifully described as inadequate."

Other critics were kinder. Heywood Broun, reviewing "Nerves", wrote: "Humphrey Bogart gives the most effective performance ... both dry and fresh, if that be possible". He played a juvenile lead (reporter Gregory Brown) in Lynn Starling's comedy "Meet the Wife", which had a successful 232-performance run at the Klaw Theatre from November 1923 through July 1924. Bogart disliked his trivial, effeminate early-career parts, calling them "White Pants Willie" roles.
While playing a double role in "Drifting" at the Playhouse Theatre in 1922, he met actress Helen Menken; they were married on May 20, 1926, at the Gramercy Park Hotel in New York City. Divorced on November 18, 1927, they remained friends. Menken said in her divorce filing that Bogart valued his career more than marriage, citing neglect and abuse. He married Mary Philips, with whom he had worked in the play "Nerves" during its brief run at the Comedy Theatre in September 1924, on April 3, 1928 at her mother's apartment in Hartford, Connecticut.

Theatrical production dropped off sharply after the Wall Street Crash of 1929, and many of the more-photogenic actors headed for Hollywood. Bogart debuted on film with Helen Hayes in the 1928 two-reeler, "The Dancing Town", a complete copy of which has not been found. He also appeared with Joan Blondell and Ruth Etting in a Vitaphone short, "Broadway's Like That" (1930), which was rediscovered in 1963.

Bogart signed a contract with the Fox Film Corporation for $750 a week. There he met Spencer Tracy, a Broadway actor whom Bogart liked and admired, and they became close friends and drinking companions. In 1930, Tracy first called him "Bogie". He made his film debut in his only film with Bogart, John Ford's early sound film "Up the River" (1930), in which they had major roles as inmates. Tracy received top billing, but Bogart appeared on the film's posters. He was billed fourth behind Tracy, Claire Luce and Warren Hymer.

Bogart then had a supporting role in "Bad Sister" (1931) with Bette Davis. Decades later, Tracy and Bogart planned to make "The Desperate Hours" together. Both wanted top billing, however; Tracy dropped out, and was replaced by Fredric March. Bogart shuttled back and forth between Hollywood and the New York stage from 1930 to 1935, out of work for long periods. His parents had separated; his father died in 1934 in debt, which Bogart eventually paid off. He inherited his father's gold ring, which he wore in many of his films. At his father's deathbed, Bogart finally told him how much he loved him. Bogart's second marriage was rocky; dissatisfied with his acting career, depressed and irritable, he drank heavily.

In 1934, Bogart starred in the Broadway play "Invitation to a Murder" at the Theatre Masque (renamed the John Golden Theatre in 1937). Its producer, Arthur Hopkins, heard the play from offstage; he sent for Bogart and offered him the role of escaped murderer Duke Mantee in Robert E. Sherwood's forthcoming play, "The Petrified Forest". Hopkins later recalled:

The play had 197 performances at the Broadhurst Theatre in New York in 1935. Although Leslie Howard was the star, "The New York Times" critic Brooks Atkinson said that the play was "a peach ... a roaring Western melodrama ... Humphrey Bogart does the best work of his career as an actor." Bogart said that the play "marked my deliverance from the ranks of the sleek, sybaritic, stiff-shirted, swallow-tailed 'smoothies' to which I seemed condemned to life." However, he still felt insecure. Warner Bros. bought the screen rights to "The Petrified Forest" in 1935. The play seemed ideal for the studio, which was known for its socially-realistic pictures for a public entranced by real-life criminals such as John Dillinger and Dutch Schultz. Bette Davis and Leslie Howard were cast. Howard, who held the production rights, made it clear that he wanted Bogart to star with him.

The studio tested several Hollywood veterans for the Duke Mantee role and chose Edward G. Robinson, who had star appeal and was due to make a film to fulfill his contract. Bogart cabled news of this development to Howard in Scotland, who replied: "Att: Jack Warner Insist Bogart Play Mantee No Bogart No Deal L.H.". When Warner Bros. saw that Howard would not budge, they gave in and cast Bogart. Jack Warner wanted Bogart to use a stage name, but Bogart declined having built a reputation with his name in Broadway theater. The film version of "The Petrified Forest" was released in 1936. According to "Variety", "Bogart's menace leaves nothing wanting". Frank S. Nugent wrote for "The New York Times" that the actor "can be a psychopathic gangster more like Dillinger than the outlaw himself." The film was successful at the box office, earning $500,000 in rentals, and made Bogart a star. He never forgot Howard's favor and named his only daughter, Leslie Howard Bogart, after him in 1952.

Despite his success in "The Petrified Forest" (an "A movie"), Bogart signed a tepid 26-week contract at $550 per week and was typecast as a gangster in a series of B movie crime dramas. Although he was proud of his success, the fact that it derived from gangster roles weighed on him: "I can't get in a mild discussion without turning it into an argument. There must be something in my tone of voice, or this arrogant face—something that antagonizes everybody. Nobody likes me on sight. I suppose that's why I'm cast as the heavy."

In spite of his success, Warner Bros. had no interest in raising Bogart's profile. His roles were repetitive and physically demanding; studios were not yet air-conditioned, and his tightly-scheduled job at Warners was anything but the indolent and "peachy" actor's life he hoped for. Although Bogart disliked the roles chosen for him, he worked steadily. "In the first 34 pictures" for Warner's, he told George Frazier, "I was shot in 12, electrocuted or hanged in 8, and was a jailbird in 9". He averaged a film every two months between 1936 and 1940, sometimes working on two films at the same time. Bogart used these years to begin developing his film persona: a wounded, stoical, cynical, charming, vulnerable, self-mocking loner with a code of honor.

Amenities at Warners were few, compared to the prestigious Metro-Goldwyn-Mayer. Bogart thought that the Warners wardrobe department was cheap, and often wore his own suits in his films; he used his dog, Zero, to play Pard (his character's dog) in "High Sierra". His disputes with Warner Bros. over roles and money were similar to those waged by the studio with other, less-malleable stars such as Bette Davis and James Cagney.

Leading men at Warner Bros. included James Cagney and Edward G. Robinson. Most of the studio's better scripts went to them (or others), leaving Bogart with what was left: films like "San Quentin" (1937), "Racket Busters" (1938), and "You Can't Get Away with Murder" (1939). His only substantial role during this period was in "Dead End" (1937, on loan to Samuel Goldwyn), as a gangster modeled after Baby Face Nelson.

Bogart played violent roles so often that in Nevil Shute's 1939 novel, "What Happened to the Corbetts", the protagonist replies "I've seen Humphrey Bogart with one often enough" when asked if he knows how to operate an automatic weapon. Although he played a variety of supporting roles in films such as "Angels with Dirty Faces" (1938), Bogart's roles were either rivals of characters played by Cagney and Robinson or a secondary member of their gang. In "Black Legion" (1937), a movie Graham Greene described as "intelligent and exciting, if rather earnest", he played a good man who was caught up with (and destroyed by) a racist organization,

The studio cast Bogart as a wrestling promoter in "Swing Your Lady" (1938), a "hillbilly musical" which he reportedly considered his worst film performance. He played a rejuvenated, formerly-dead scientist in "The Return of Doctor X" (1939), his only horror film: "If it'd been Jack Warner's blood ... I wouldn't have minded so much. The trouble was they were drinking mine and I was making this stinking movie." His wife, Mary, had a stage hit in "A Touch of Brimstone" and refused to abandon her Broadway career for Hollywood. After the play closed, Mary relented; she insisted on continuing her career, however, and they divorced in 1937.
Bogart entered a turbulent third marriage to actress Mayo Methot, a lively, friendly woman when sober but paranoid and aggressive when drunk, on August 21, 1938. She became convinced that Bogart was unfaithful to her (which he eventually was, with Lauren Bacall, while filming "To Have and Have Not" in 1944). They drifted apart; Methot's drinking increased, and she threw plants, crockery and other objects at Bogart. She set their house afire, stabbed him with a knife, and slashed her wrists several times. Bogart needled her; apparently enjoying confrontation, he was sometimes violent as well. The press called them "the Battling Bogarts".

According to their friend, Julius Epstein, "The Bogart-Methot marriage was the sequel to the Civil War". Bogart bought a motor launch which he named "Sluggy," his nickname for Methot: "I like a jealous wife .. We get on so well together (because) we don't have illusions about each other ... I wouldn't give you two cents for a dame without a temper." Louise Brooks said that "except for Leslie Howard, no one contributed as much to Humphrey's success as his third wife, Mayo Methot." Methot's influence was increasingly destructive, however, and Bogart also continued to drink.

He had a lifelong disdain for pretension and phoniness, and was again irritated by his inferior films. Bogart rarely watched his own films and avoided premieres, issuing fake press releases about his private life to satisfy journalistic and public curiosity. When he thought an actor, director or studio had done something shoddy, he spoke up publicly about it. Bogart advised Robert Mitchum that the only way to stay alive in Hollywood was to be an "againster". He was not the most popular of actors, and some in the Hollywood community shunned him privately to avoid trouble with the studios. Bogart once said,
The Hollywood press, unaccustomed to such candor, was delighted.

"High Sierra" (1941, directed by Raoul Walsh) was written by John Huston, Bogart's friend and drinking partner. The film was adapted from a novel by W. R. Burnett, author of the novel on which "Little Caesar" was based. Paul Muni, George Raft, Cagney and Robinson turned down the lead role, giving Bogart the opportunity to play a character with some depth. Walsh initially opposed Bogart's casting, preferring Raft for the part. It was Bogart's last major film as a gangster; a supporting role followed in "The Big Shot", released in 1942. He worked well with Ida Lupino, sparking jealousy from Mayo Methot.

The film cemented a strong personal and professional connection between Bogart and Huston. Bogart admired (and somewhat envied) Huston for his skill as a writer; a poor student, Bogart was a lifelong reader. He could quote Plato, Pope, Ralph Waldo Emerson and over a thousand lines of Shakespeare, and subscribed to the "Harvard Law Review". Bogart admired writers; some of his best friends were screenwriters, including Louis Bromfield, Nathaniel Benchley, and Nunnally Johnson. He enjoyed intense, provocative conversation (accompanied by stiff drinks), as did Huston. Both were rebellious and enjoyed playing childish pranks. Huston was reportedly easily bored during production, and admired Bogart (also bored easily off-camera) for his acting talent and his intense concentration on-set.

Now regarded as a classic film noir, "The Maltese Falcon" (1941) was John Huston's directorial debut. Based on the Dashiell Hammett novel, it was first serialized in the pulp magazine "Black Mask" in 1929 and was the basis of two earlier film versions; the second was "Satan Met a Lady" (1936), starring Bette Davis. Producer Hal B. Wallis initially offered to cast George Raft as the leading man, but Raft (more established than Bogart) had a contract stipulating he was not required to appear in remakes. Fearing that it would be nothing more than a sanitized version of the pre-Production Code "The Maltese Falcon" (1931), Raft turned down the role to make "Manpower" with director Raoul Walsh. Huston then eagerly accepted Bogart as his Sam Spade.

Complementing Bogart were co-stars Sydney Greenstreet, Peter Lorre, Elisha Cook Jr., and Mary Astor as the treacherous female foil. Bogart's sharp timing and facial expressions were praised by the cast and director as vital to the film's quick action and rapid-fire dialogue. It was a commercial hit, and a major triumph for Huston. Bogart was unusually happy with the film: "It is practically a masterpiece. I don't have many things I'm proud of ... but that's one".

Bogart played his first romantic lead in "Casablanca" (1942): Rick Blaine, an expatriate nightclub owner hiding from a suspicious past and negotiating a fine line among Nazis, the French underground, the Vichy prefect and unresolved feelings for his ex-girlfriend. Bosley Crowther wrote in his November 1942 "New York Times" review that Bogart's character was used "to inject a cold point of tough resistance to evil forces afoot in Europe today". The film, directed by Michael Curtiz and produced by Hal Wallis, featured Ingrid Bergman, Claude Rains, Sydney Greenstreet, Paul Henreid, Conrad Veidt, Peter Lorre and Dooley Wilson.

Bogart and Bergman's on-screen relationship was based on professionalism rather than actual rapport, although Mayo Methot assumed otherwise. Off the set, the co-stars hardly spoke. Bergman (who had a reputation for affairs with her leading men) later said about Bogart, "I kissed him but I never knew him." Because she was taller, Bogart had blocks attached to his shoes in some scenes.

Bogart is reported to have been responsible for the notion that Rick Blaine should be portrayed as a chess player, a metaphor for the relationships he maintained with friends, enemies, and allies. He played tournament-level chess (one division below master) in real life, often enjoying games with crew members and cast but finding his better in Paul Henreid.

"Casablanca" won the Academy Award for Best Picture at the 16th Academy Awards for 1943. Bogart was nominated for Best Actor in a Leading Role, but lost to Paul Lukas for his performance in "Watch on the Rhine". The film vaulted Bogart from fourth place to first in the studio's roster, however, finally overtaking James Cagney. He more than doubled his annual salary to over $460,000 by 1946, making him the world's highest-paid actor.

Bogart went on United Service Organizations and War Bond tours with Methot in 1943 and 1944, making arduous trips to Italy and North Africa (including Casablanca). He was still required to perform in films with weak scripts, leading to conflicts with the front office. He starred in "Conflict" (1945, again with Greenstreet), but turned down "God is My Co-Pilot" that year.

Bogart met Lauren Bacall (1924–2014) while filming "To Have and Have Not" (1944), a loose adaptation of the Ernest Hemingway novel. It has several similarities to "Casablanca": the same enemies, the same kind of hero, and a piano player (played by Hoagy Carmichael). When they met, Bacall was 19 and Bogart 44; he nicknamed her "Baby." A model since age 16, she had appeared in two failed plays. Bogart was attracted by Bacall's high cheekbones, green eyes, tawny blond hair, lean body, maturity, poise and earthy, outspoken honesty; he reportedly said, "I just saw your test. We'll have a lot of fun together".

Their emotional bond was strong from the start, their age and acting-experience differences encouraging a mentor-student dynamic. In contrast to the Hollywood norm, their affair was Bogart's first with a leading lady. His early meetings with Bacall were discreet and brief, their separations bridged by love letters. The relationship made it easier for Bacall to make her first film, and Bogart did his best to put her at ease with jokes and quiet coaching. He encouraged her to steal scenes; Howard Hawks also did his best to highlight her role, and found Bogart easy to direct.

However, Hawks began to disapprove of the relationship. He considered himself Bacall's protector and mentor, and Bogart was usurping that role. Not usually drawn to his starlets, the married director also fell for Bacall; he told her that she meant nothing to Bogart and threatened to send her to the poverty-row Monogram Pictures. Bogart calmed her down, and then went after Hawks; Jack Warner settled the dispute, and filming resumed. Hawks said about Bacall, "Bogie fell in love with the character she played, so she had to keep playing it the rest of her life."

Months after wrapping "To Have and Have Not", Bogart and Bacall were reunited for an encore: the film noir "The Big Sleep" (1946), based on the novel by Raymond Chandler with script help from William Faulkner. Chandler admired the actor's performance: "Bogart can be tough without a gun. Also, he has a sense of humor that contains that grating undertone of contempt." Although the film was completed and scheduled for release in 1945, it was withdrawn and re-edited to add scenes exploiting Bogart and Bacall's box-office chemistry in "To Have and Have Not" and the publicity surrounding their offscreen relationship. At director Howard Hawks' urging, production partner Charles K. Feldman agreed to a rewrite of Bacall's scenes to heighten the "insolent" quality which had intrigued critics such as James Agee and audiences of the earlier film, and a memo was sent to studio head Jack Warner.

The dialogue, especially in the added scenes supplied by Hawks, was full of sexual innuendo, and Bogart is convincing as private detective Philip Marlowe. The film was successful, although some critics found its plot confusing and overly complicated. According to Chandler, Hawks and Bogart argued about who killed the chauffeur; when Chandler received an inquiry by telegram, he could not provide an answer.

Bogart filed for divorce from Methot in February 1945. He and Bacall married in a small ceremony at the country home of Bogart's close friend, Pulitzer Prize-winning author Louis Bromfield, at Malabar Farm (near Lucas, Ohio) on May 21, 1945.

They moved into a $160,000 ($ in ) white brick mansion in an exclusive neighborhood of Los Angeles's Holmby Hills. The marriage was a happy one, with tensions due to their differences. Bogart's drinking was sometimes problematic. He was a homebody, and Bacall liked the nightlife; he loved the sea, which made her seasick.

Bogart bought the "Santana", a sailing yacht, from actor Dick Powell in 1945. He found the sea a sanctuary and spent about thirty weekends a year on the water, with a particular fondness for sailing around Catalina Island: "An actor needs something to stabilize his personality, something to nail down what he really is, not what he is currently pretending to be." Bogart joined the Coast Guard Temporary Reserve, offering the Coast Guard use of the "Santana". He reportedly attempted to enlist, but was turned down due to his age.

The suspenseful "Dark Passage" (1947) was Bogart and Bacall's next collaboration. Vincent Parry (Bogart) is intent on finding the real murderer for a crime of which he was convicted and sentenced to prison. According to Bogart's biographer, Stefan Kanfer, it was "a production line film noir with no particular distinction".

Bogart and Bacall's last pairing in a film was in "Key Largo" (1948). Directed by John Huston, Edward G. Robinson was billed second (behind Bogart) as gangster Johnny Rocco: a seething, older synthesis of many of his early bad-guy roles. The characters are trapped during a hurricane in a hotel owned by Bacall's father-in-law, played by Lionel Barrymore. Claire Trevor won an Academy Award for Best Supporting Actress for her performance as Rocco's physically-abused, alcoholic girlfriend.

Riding high in 1947 with a new contract which provided limited script refusal and the right to form his production company, Bogart rejoined with John Huston for "The Treasure of the Sierra Madre": a stark tale of greed among three gold prospectors in Mexico. Lacking a love interest or a happy ending, it was considered a risky project. Bogart later said about co-star (and John Huston's father) Walter Huston, "He's probably the only performer in Hollywood to whom I'd gladly lose a scene."

The film was shot in the heat of summer for greater realism and atmosphere, and was grueling to make. James Agee wrote, "Bogart does a wonderful job with this character ... miles ahead of the very good work he has done before." Although John Huston won the Academy Award for Best Director and screenplay and his father won the Best Supporting Actor award, the film had mediocre box-office results. Bogart complained, "An intelligent script, beautifully directed—something different—and the public turned a cold shoulder on it."

Bogart, a liberal Democrat, organized the Committee for the First Amendment (a delegation to Washington, D.C.) opposing what he saw as the House Un-American Activities Committee's harassment of Hollywood screenwriters and actors. He wrote an article, "I'm No Communist", for the March 1948 issue of "Photoplay" magazine distancing himself from the Hollywood Ten to counter negative publicity resulting from his appearance. Bogart wrote, "The ten men cited for contempt by the House Un-American Activities Committee were not defended by us."

Bogart created his film company, Santana Productions (named after his yacht and the cabin cruiser in "Key Largo"), in 1948. The right to create his own company had left Jack Warner furious, fearful that other stars would do the same and further erode the major studios' power. In addition to pressure from freelancing actors such as Bogart, James Stewart and Henry Fonda, they were beginning to buckle from the impact of television and the enforcement of antitrust laws which broke up theater chains. Bogart appeared in his final films for Warners, "Chain Lightning" (1950) and "The Enforcer" (1951).
Except for "Beat the Devil" (1953), originally distributed in the United States by United Artists, the company released its films through Columbia Pictures; Columbia re-released "Beat the Devil" a decade later. In quick succession, Bogart starred in "Knock on Any Door" (1949), "Tokyo Joe" (1949), "In a Lonely Place" (1950), and "Sirocco" (1951). Santana also made two films without him: "And Baby Makes Three" (1949) and "The Family Secret" (1951).

Although most lost money at the box office (ultimately forcing Santana's sale), at least two retain a reputation; "In a Lonely Place" is considered a film-noir high point. Bogart plays Dixon Steele, an embittered writer with a violent reputation who is the primary suspect in the murder of a young woman and falls in love with failed actress Laurel Gray (Gloria Grahame). Several Bogart biographers, and actress-writer Louise Brooks, have felt that this role is closest to the real Bogart. According to Brooks, the film "gave him a role that he could play with complexity, because the film character's pride in his art, his selfishness, drunkenness, lack of energy stabbed with lightning strokes of violence were shared by the real Bogart". The character mimics some of Bogart's personal habits, twice ordering the actor's favorite meal (ham and eggs).

A parody of sorts of "The Maltese Falcon", "Beat the Devil" was the final film for Bogart and John Huston. Co-written by Truman Capote, the eccentrically-filmed story follows an amoral group of rogues chasing an unattainable treasure. Bogart sold his interest in Santana to Columbia for over $1 million in 1955.

Outside Santana Productions, Bogart starred with Katharine Hepburn in the John Huston-directed "The African Queen" in 1951. The C. S. Forester novel on which it was based was overlooked and left undeveloped for 15 years, until producer Sam Spiegel and Huston bought the rights. Spiegel sent Katharine Hepburn the book; she suggested Bogart for the male lead, believing that "he was the only man who could have played that part". Huston's love of adventure, his deep, longstanding friendship (and success) with Bogart, and the chance to work with Hepburn convinced the actor to leave Hollywood for a difficult shoot on location in the Belgian Congo. Bogart was to get 30 percent of the profits and Hepburn 10 percent, plus a relatively-small salary for both. The stars met in London, and announced that they would work together.

Bacall came for the over-four-month duration, leaving their young son in Los Angeles. The Bogarts began the trip with a junket through Europe, including a visit with Pope Pius XII. Bacall later made herself useful as a cook, nurse and clothes washer; her husband said: "I don't know what we'd have done without her. She Luxed my undies in darkest Africa." Nearly everyone in the cast developed dysentery except Bogart and Huston, who subsisted on canned food and alcohol; Bogart said, "All I ate was baked beans, canned asparagus and Scotch whisky. Whenever a fly bit Huston or me, it dropped dead." Hepburn (a teetotaler) fared worse in the difficult conditions, losing weight and at one point becoming very ill. Bogart resisted Huston's insistence on using real leeches in a key scene where Charlie has to drag his steam launch through an infested marsh, and reasonable fakes were employed. The crew overcame illness, army-ant infestations, leaky boats, poor food, attacking hippos, poor water filters, extreme heat, isolation, and a boat fire to complete the film. Despite the discomfort of jumping from the boat into swamps, rivers and marshes, "The African Queen" apparently rekindled Bogart's early love of boats; when he returned to California, he bought a classic mahogany Hacker-Craft runabout which he kept until his death.

His performance as cantankerous skipper Charlie Allnutt earned Bogart an Academy Award for Best Actor in 1951 (his only award of three nominations), and he considered it the best of his film career. Promising friends that if he won his speech would break the convention of thanking everyone in sight, Bogart advised Claire Trevor when she was nominated for "Key Largo" to "just say you did it all yourself and don't thank anyone". When Bogart won, however, he said: "It's a long way from the Belgian Congo to the stage of this theatre. It's nicer to be here. Thank you very much ... No one does it alone. As in tennis, you need a good opponent or partner to bring out the best in you. John and Katie helped me to be where I am now." Despite the award and its accompanying recognition, Bogart later said: "The way to survive an Oscar is never to try to win another one ... too many stars ... win it and then figure they have to top themselves ... they become afraid to take chances. The result: A lot of dull performances in dull pictures." "The African Queen" was Bogart's first starring Technicolor role.

Bogart dropped his asking price to obtain the role of Captain Queeg in Edward Dmytryk's drama, "The Caine Mutiny" (1954). Though he retained some of his old bitterness about having to do so, he delivered a strong performance in the lead; he received his final Oscar nomination and was the subject of a June 7, 1954 "Time" magazine cover story.

Despite his success, Bogart was still melancholy; he grumbled to (and feuded with) the studio, while his health began to deteriorate. The character of Queeg was similar to his roles in "The Maltese Falcon", "Casablanca" and "The Big Sleep"–the wary loner who trusts no one—but without their warmth and humor. Like his portrayal of Fred C. Dobbs in "The Treasure of the Sierra Madre", Bogart's Queeg is a paranoid, self-pitying character whose small-mindedness eventually destroys him. Henry Fonda played a different role in the Broadway version of "The Caine Mutiny", generating publicity for the film.

For "Sabrina" (1954), Billy Wilder wanted Cary Grant for the older male lead and chose Bogart to play the conservative brother who competes with his younger, playboy sibling (William Holden) for the affection of the Cinderella-like Sabrina (Audrey Hepburn). Although Bogart was lukewarm about the part, he agreed to it on a handshake with Wilder without a finished script but with the director's assurance that he would take good care of Bogart during filming. The actor, however, got along poorly with his director and co-stars; he complained about the script's last-minute drafting and delivery, and accused Wilder of favoring Hepburn and Holden on and off the set. Wilder was the opposite of Bogart's ideal director (John Huston) in style and personality; Bogart complained to the press that Wilder was "overbearing" and "is [a] kind of Prussian German with a riding crop. He is the type of director I don't like to work with ... the picture is a crock of crap. I got sick and tired of who gets Sabrina." Wilder later said, "We parted as enemies but finally made up." Despite the acrimony, the film was successful; according to a review in "The New York Times", Bogart was "incredibly adroit ... the skill with which this old rock-ribbed actor blends the gags and such duplicities with a manly manner of melting is one of the incalculable joys of the show".
Joseph L. Mankiewicz's "The Barefoot Contessa" (1954) was filmed in Rome. In this Hollywood backstory Bogart is a broken-down man, a cynical director-narrator who saves his career by making a star of a flamenco dancer modeled on Rita Hayworth. He was uneasy with Ava Gardner in the female lead; she had just broken up with his Rat Pack buddy Frank Sinatra, and Bogart was annoyed by her inexperienced performance. The actor was generally praised as the film's strongest part. During filming and while Bacall was home, Bogart resumed his discreet affair with Verita Bouvaire-Thompson (his long-time studio assistant, whom he drank with and took sailing). When Bacall found them together, she extracted an expensive shopping spree from her husband; the three traveled together after the shooting.
Bogart could be generous with actors, particularly those who were blacklisted, down on their luck or having personal problems. During the filming of the Edward Dmytryk-directed "The Left Hand of God" (1955), he noticed his co-star Gene Tierney having a hard time remembering her lines and behaving oddly; he coached her, feeding Tierney her lines. Familiar with mental illness because of his sister's bouts of depression, Bogart encouraged Tierney to seek treatment. He also stood behind Joan Bennett and insisted on her as his co-star in Michael Curtiz's "We're No Angels" (1955) when a scandal made her "persona non grata" with studio head Jack Warner.

Bogart rarely performed on television, but he and Bacall appeared on Edward R. Murrow's "Person to Person" and disagreed on the answer to every question. He also appeared on "The Jack Benny Show", where a surviving kinescope of the live telecast captures him in his only TV sketch-comedy performance. Bogart and Bacall worked on an early color telecast in 1955, an NBC adaptation of "The Petrified Forest" for "Producers' Showcase". Bogart received top billing, and Henry Fonda played Leslie Howard's role; a black and white kinescope of the live telecast has survived. Bogart performed radio adaptations of some of his best-known films, such as "Casablanca" and "The Maltese Falcon", and recorded a radio series entitled "Bold Venture" with Bacall.

Bogart became a father at age 49, when Bacall gave birth to Stephen Humphrey Bogart on January 6, 1949 during the filming of "Tokyo Joe". The name was taken from Steve, Bogart's character's nickname in "To Have and Have Not". Stephen became an author and biographer, and hosted a television special about his father on Turner Classic Movies. The couple's daughter, Leslie Howard Bogart, was born on August 23, 1952. Her first and middle names honor Leslie Howard, Bogart's friend and co-star in "The Petrified Forest".

Bogart was a founding member and the original leader of the Hollywood Rat Pack. In the spring of 1955, after a long party in Las Vegas attended by Frank Sinatra, Judy Garland, her husband Sidney Luft, Michael Romanoff and his wife Gloria, David Niven, Angie Dickinson and others, Bacall surveyed the wreckage and said: "You look like a goddamn rat pack."

The name stuck, and was made official at Romanoff's in Beverly Hills. Sinatra was dubbed Pack Leader; Bacall Den Mother; Bogart Director of Public Relations, and Sid Luft Acting Cage Manager. Asked by columnist Earl Wilson what the group's purpose was, Bacall replied: "To drink a lot of bourbon and stay up late."

After signing a long-term deal with Warner Bros., Bogart predicted with glee that his teeth and hair would fall out before the contract ended. In 1955, however, his health was failing. In the wake of Santana, Bogart had formed a new company and had plans for a film ("Melville Goodwin, U.S.A.") in which he would play a general and Bacall a press magnate. His persistent cough and difficulty eating became too serious to ignore, though, and he dropped the project.

A heavy smoker and drinker, Bogart had developed esophageal cancer. He did not talk about his health, and visited a doctor in January 1956 after considerable persuasion from Bacall. The disease worsened several weeks later, and on March 1 Bogart had surgery to remove his esophagus, two lymph nodes and a rib. The surgery was unsuccessful, and chemotherapy followed. He had additional surgery in November 1956, when the cancer had spread. Although Bogart became too weak to walk up and down stairs, he joked despite the pain: "Put me in the dumbwaiter and I'll ride down to the first floor in style." It was then altered to accommodate his wheelchair. Sinatra, Katharine Hepburn, and Spencer Tracy visited Bogart on January 13, 1957. In an interview, Hepburn said:

Bogart lapsed into a coma and died the following day, 20 days after his 57th birthday; at the time of his death he weighed only . A simple funeral was held at All Saints Episcopal Church, with music by Bogart's favorite composers: Johann Sebastian Bach and Claude Debussy. In attendance were some of Hollywood's biggest stars, including Hepburn, Tracy, Judy Garland, David Niven, Ronald Reagan, James Mason, Bette Davis, Danny Kaye, Joan Fontaine, Marlene Dietrich, James Cagney, Errol Flynn, Edward G. Robinson, Gregory Peck, Gary Cooper, Billy Wilder and studio head Jack L. Warner. Bacall asked Tracy to give the eulogy; he was too upset, however, and John Huston spoke instead:

Bogart was cremated, and his ashes were interred in Forest Lawn Memorial Park's Columbarium of Eternal Light in its Garden of Memory in Glendale, California. He was buried with a small, gold whistle which had been part of a charm bracelet he had given to Bacall before they married. On it was inscribed, "If you want anything, just whistle." This alluded to a scene in "To Have and Have Not" when Bacall's character says to Bogart shortly after their first meeting, "You know how to whistle, don't you, Steve? You just put your lips together and blow."
Bogart's estate had a gross value of $910,146 and a net value of $737,668 ($ million and $ million, respectively, in ).

On August 21, 1946, he recorded his hand- and footprints in cement in a ceremony at Grauman's Chinese Theatre. On February 8, 1960, Bogart was posthumously inducted into the Hollywood Walk of Fame with a motion-picture star at 6322 Hollywood Boulevard.

After his death, a "Bogie cult" formed at the Brattle Theatre in Cambridge, Massachusetts, in Greenwich Village, and in France; this contributed to his increased popularity during the late 1950s and 1960s. In 1997, "Entertainment Weekly" magazine ranked Bogart the number-one movie legend of all time; two years later, the American Film Institute rated him the greatest male screen legend.

Jean-Luc Godard's "Breathless" (1960) was the first film to pay tribute to Bogart. Over a decade later, in Woody Allen's comic paean "Play It Again, Sam" (1972), Bogart's ghost aids Allen's character: a film critic having difficulties with women who says that his "sex life has turned into the 'Petrified Forest.

The United States Postal Service honored Bogart with a stamp in its "Legends of Hollywood" series in 1997, the third figure recognized. At a ceremony attended by Lauren Bacall and the Bogart children, Stephen and Leslie, USPS governing-board chair Tirso del Junco delivered a tribute:

"Today, we mark another chapter in the Bogart legacy. With an image that is small and yet as powerful as the ones he left in celluloid, we will begin today to bring his artistry, his power, his unique star quality, to the messages that travel the world."

On June 24, 2006, 103rd Street between Broadway and West End Avenue in New York City was renamed Humphrey Bogart Place. Lauren Bacall and her son, Stephen Bogart, attended the ceremony. "Bogie would never have believed it", she said to the assembled city officials and onlookers.

Bogart has inspired a number of artists. Two Bugs Bunny cartoons featured the actor: "Slick Hare" (1947) and "8 Ball Bunny" (1950, based on "The Treasure of the Sierra Madre"). "The Man with Bogart's Face" (1981, starring Bogart lookalike Robert Sacchi) was an homage to the actor. The lyrics of Bertie Higgins' 1981 song, "Key Largo", refer to "Key Largo" and "Casablanca".





</doc>
<doc id="14051" url="https://en.wikipedia.org/wiki?curid=14051" title="History painting">
History painting

History painting is a genre in painting defined by its subject matter rather than artistic style. History paintings usually depict a moment in a narrative story, rather than a specific and static subject, as in a portrait. The term is derived from the wider senses of the word "historia" in Latin and Italian, meaning "story" or "narrative", and essentially means "story painting". Most history paintings are not of scenes from history, especially paintings from before about 1850.

In modern English, historical painting is sometimes used to describe the painting of scenes from history in its narrower sense, especially for 19th-century art, excluding religious, mythological and allegorical subjects, which are included in the broader term history painting, and before the 19th century were the most common subjects for history paintings.

History paintings almost always contain a number of figures, often a large number, and normally show some type of action that is a moment in a narrative. The genre includes depictions of moments in religious narratives, above all the "Life of Christ", as well as narrative scenes from mythology, and also allegorical scenes. These groups were for long the most frequently painted; works such as Michelangelo's Sistine Chapel ceiling are therefore history paintings, as are most very large paintings before the 19th century. The term covers large paintings in oil on canvas or fresco produced between the Renaissance and the late 19th century, after which the term is generally not used even for the many works that still meet the basic definition.

History painting may be used interchangeably with historical painting, and was especially so used before the 20th century. Where a distinction is made, "historical painting" is the painting of scenes from secular history, whether specific episodes or generalized scenes. In the 19th century, historical painting in this sense became a distinct genre. In phrases such as "historical painting materials", "historical" means in use before about 1900, or some earlier date.

History paintings were traditionally regarded as the highest form of Western painting, occupying the most prestigious place in the hierarchy of genres, and considered the equivalent to the epic in literature. In his "De Pictura" of 1436, Leon Battista Alberti had argued that multi-figure history painting was the noblest form of art, as being the most difficult, which required mastery of all the others, because it was a visual form of history, and because it had the greatest potential to move the viewer. He placed emphasis on the ability to depict the interactions between the figures by gesture and expression.

This view remained general until the 19th century, when artistic movements began to struggle against the establishment institutions of academic art, which continued to adhere to it. At the same time, there was from the latter part of the 18th century an increased interest in depicting in the form of history painting moments of drama from recent or contemporary history, which had long largely been confined to battle-scenes and scenes of formal surrenders and the like. Scenes from ancient history had been popular in the early Renaissance, and once again became common in the Baroque and Rococo periods, and still more so with the rise of Neoclassicism. In some 19th or 20th century contexts, the term may refer specifically to paintings of scenes from secular history, rather than those from religious narratives, literature or mythology.

The term is generally not used in art history in speaking of medieval painting, although the Western tradition was developing in large altarpieces, fresco cycles, and other works, as well as miniatures in illuminated manuscripts. It comes to the fore in Italian Renaissance painting, where a series of increasingly ambitious works were produced, many still religious, but several, especially in Florence, which did actually feature near-contemporary historical scenes such as the set of three huge canvases on "The Battle of San Romano" by Paolo Uccello, the abortive "Battle of Cascina" by Michelangelo and the "Battle of Anghiari" by Leonardo da Vinci, neither of which were completed. Scenes from ancient history and mythology were also popular. Writers such as Alberti and the following century Giorgio Vasari in his "Lives of the Artists", followed public and artistic opinion in judging the best painters above all on their production of large works of history painting (though in fact the only modern (post-classical) work described in "De Pictura" is Giotto's huge "Navicella" in mosaic). Artists continued for centuries to strive to make their reputation by producing such works, often neglecting genres to which their talents were better suited.
There was some objection to the term, as many writers preferred terms such as "poetic painting" ("poesia"), or wanted to make a distinction between the "true" "istoria", covering history including biblical and religious scenes, and the "fabula", covering pagan myth, allegory, and scenes from fiction, which could not be regarded as true. The large works of Raphael were long considered, with those of Michelangelo, as the finest models for the genre.

In the Raphael Rooms in the Vatican Palace, allegories and historical scenes are mixed together, and the Raphael Cartoons show scenes from the Gospels, all in the Grand Manner that from the High Renaissance became associated with, and often expected in, history painting. In the Late Renaissance and Baroque the painting of actual history tended to degenerate into panoramic battle-scenes with the victorious monarch or general perched on a horse accompanied with his retinue, or formal scenes of ceremonies, although some artists managed to make a masterpiece from such unpromising material, as Velázquez did with his "The Surrender of Breda".

An influential formulation of the hierarchy of genres, confirming the history painting at the top, was made in 1667 by André Félibien, a historiographer, architect and theoretician of French classicism became the classic statement of the theory for the 18th century:Celui qui fait parfaitement des païsages est au-dessus d'un autre qui ne fait que des fruits, des fleurs ou des coquilles. Celui qui peint des animaux vivants est plus estimable que ceux qui ne représentent que des choses mortes & sans mouvement; & comme la figure de l'homme est le plus parfait ouvrage de Dieu sur la Terre, il est certain aussi que celui qui se rend l'imitateur de Dieu en peignant des figures humaines, est beaucoup plus excellent que tous les autres ... un Peintre qui ne fait que des portraits, n'a pas encore cette haute perfection de l'Art, & ne peut prétendre à l'honneur que reçoivent les plus sçavans. Il faut pour cela passer d'une seule figure à la représentation de plusieurs ensemble; il faut traiter l'histoire & la fable; il faut représenter de grandes actions comme les historiens, ou des sujets agréables comme les Poëtes; & montant encore plus haut, il faut par des compositions allégoriques, sçavoir couvrir sous le voile de la fable les vertus des grands hommes, & les mystères les plus relevez.

He who produces perfect landscapes is above another who only produces fruit, flowers or seashells. He who paints living animals is more than those who only represent dead things without movement, and as man is the most perfect work of God on the earth, it is also certain that he who becomes an imitator of God in representing human figures, is much more excellent than all the others ... a painter who only does portraits still does not have the highest perfection of his art, and cannot expect the honour due to the most skilled. For that he must pass from representing a single figure to several together; history and myth must be depicted; great events must be represented as by historians, or like the poets, subjects that will please, and climbing still higher, he must have the skill to cover under the veil of myth the virtues of great men in allegories, and the mysteries they reveal".

By the late 18th century, with both religious and mytholological painting in decline, there was an increased demand for paintings of scenes from history, including contemporary history. This was in part driven by the changing audience for ambitious paintings, which now increasingly made their reputation in public exhibitions rather than by impressing the owners of and visitors to palaces and public buildings. Classical history remained popular, but scenes from national histories were often the best-received. From 1760 onwards, the Society of Artists of Great Britain, the first body to organize regular exhibitions in London, awarded two generous prizes each year to paintings of subjects from British history. 
The unheroic nature of modern dress was regarded as a serious difficulty. When, in 1770, Benjamin West proposed to paint "The Death of General Wolfe" in contemporary dress, he was firmly instructed to use classical costume by many people. He ignored these comments and showed the scene in modern dress. Although George III refused to purchase the work, West succeeded both in overcoming his critics' objections and inaugurating a more historically accurate style in such paintings. Other artists depicted scenes, regardless of when they occurred, in classical dress and for a long time, especially during the French Revolution, history painting often focused on depictions of the heroic male nude.

The large production, using the finest French artists, of propaganda paintings glorifying the exploits of Napoleon, were matched by works, showing both victories and losses, from the anti-Napoleonic alliance by artists such as Goya and J.M.W. Turner. Théodore Géricault's "The Raft of the Medusa" (1818–1819) was a sensation, appearing to update the history painting for the 19th century, and showing anonymous figures famous only for being victims of what was then a famous and controversial disaster at sea. Conveniently their clothes had been worn away to classical-seeming rags by the point the painting depicts. At the same time the demand for traditional large religious history paintings very largely fell away.
In the mid-nineteenth century there arose a style known as historicism, which marked a formal imitation of historical styles and/or artists. Another development in the nineteenth century was the treatment of historical subjects, often on a large scale, with the values of genre painting, the depiction of scenes of everyday life, and anecdote. Grand depictions of events of great public importance were supplemented with scenes depicting more personal incidents in the lives of the great, or of scenes centred on unnamed figures involved in historical events, as in the Troubadour style. At the same time scenes of ordinary life with moral, political or satirical content became often the main vehicle for expressive interplay between figures in painting, whether given a modern or historical setting.

By the later 19th century, history painting was often explicitly rejected by avant-garde movements such as the Impressionists (except for Édouard Manet) and the Symbolists, and according to one recent writer "Modernism was to a considerable extent built upon the rejection of History Painting... All other genres are deemed capable of entering, in one form or another, the 'pantheon' of modernity considered, but History Painting is excluded".

Initially, "history painting" and "historical painting" were used interchangeably in English, as when Sir Joshua Reynolds in his fourth "Discourse" uses both indiscriminately to cover "history painting", while saying "...it ought to be called poetical, as in reality it is", reflecting the French term "peinture historique", one equivalent of "history painting". The terms began to separate in the 19th century, with "historical painting" becoming a sub-group of "history painting" restricted to subjects taken from history in its normal sense. In 1853 John Ruskin asked his audience: "What do you at present "mean" by historical painting? Now-a-days it means the endeavour, by the power of imagination, to portray some historical event of past days." So for example Harold Wethey's three-volume catalogue of the paintings of Titian (Phaidon, 1969–75) is divided between "Religious Paintings", "Portraits", and "Mythological and Historical Paintings", though both volumes I and III cover what is included in the term "History Paintings". This distinction is useful but is by no means generally observed, and the terms are still often used in a confusing manner. Because of the potential for confusion modern academic writing tends to avoid the phrase "historical painting", talking instead of "historical subject matter" in history painting, but where the phrase is still used in contemporary scholarship it will normally mean the painting of subjects from history, very often in the 19th century. "Historical painting" may also be used, especially in discussion of painting techniques in conservation studies, to mean "old", as opposed to modern or recent painting.

In 19th-century British writing on art the terms "subject painting" or "anecdotic" painting were often used for works in a line of development going back to William Hogarth of monoscenic depictions of crucial moments in an implied narrative with unidentified characters, such as William Holman Hunt's 1853 painting "The Awakening Conscience" or Augustus Egg's "Past and Present", a set of three paintings, updating sets by Hogarth such as "Marriage à-la-mode".

History painting was the dominant form of academic painting in the various national academies in the 18th century, and for most of the 19th, and increasingly historical subjects dominated. During the Revolutionary and Napoleonic periods the heroic treatment of contemporary history in a frankly propagandistic fashion by Antoine-Jean, Baron Gros, Jacques-Louis David, Carle Vernet and others was supported by the French state, but after the fall of Napoleon in 1815 the French governments were not regarded as suitable for heroic treatment and many artists retreated further into the past to find subjects, though in Britain depicting the victories of the Napoleonic Wars mostly occurred after they were over. Another path was to choose contemporary subjects that were oppositional to government either at home and abroad, and many of what were arguably the last great generation of history paintings were protests at contemporary episodes of repression or outrages at home or abroad: Goya's "The Third of May 1808" (1814), Théodore Géricault's "The Raft of the Medusa" (1818–19), Eugène Delacroix's "The Massacre at Chios" (1824) and "Liberty Leading the People" (1830). These were heroic, but showed heroic suffering by ordinary civilians.
Romantic artists such as Géricault and Delacroix, and those from other movements such as the English Pre-Raphaelite Brotherhood continued to regard history painting as the ideal for their most ambitious works. Others such as Jan Matejko in Poland, Vasily Surikov in Russia, José Moreno Carbonero in Spain and Paul Delaroche in France became specialized painters of large historical subjects. The "style troubadour" ("troubadour style") was a somewhat derisive French term for earlier paintings of medieval and Renaissance scenes, which were often small and depicting moments of anecdote rather than drama; Ingres, Richard Parkes Bonington and Henri Fradelle painted such works. Sir Roy Strong calls this type of work the "Intimate Romantic", and in French it was known as the "peinture de genre historique" or "peinture anecdotique" ("historical genre painting" or "anecdotal painting").

Church commissions for large group scenes from the Bible had greatly reduced, and historical painting became very significant. Especially in the early 19th century, much historical painting depicted specific moments from historical literature, with the novels of Sir Walter Scott a particular favourite, in France and other European countries as much as Great Britain. By the middle of the century medieval scenes were expected to be very carefully researched, using the work of historians of costume, architecture and all elements of decor that were becoming available. And example of this is the extensive research of Byzantine architecture, clothing and decoration made in Parisian museums and libraries by Moreno Carbonero for his masterwork "The Entry of Roger de Flor in Constantinople". The provision of examples and expertise for artists, as well as revivalist industrial designers, was one of the motivations for the establishment of museums like the Victoria and Albert Museum in London.

New techniques of printmaking such as the chromolithograph made good quality monochrome print reproductions both relatively cheap and very widely accessible, and also hugely profitable for artist and publisher, as the sales were so large. Historical painting often had a close relationship with Nationalism, and painters like Matejko in Poland could play an important role in fixing the prevailing historical narrative of national history in the popular mind. In France, "L'art Pompier" ("Fireman art") was a derisory term for official academic historical painting, and in a final phase, "History painting of a debased sort, scenes of brutality and terror, purporting to illustrate episodes from Roman and Moorish history, were Salon sensations. On the overcrowded walls of the exhibition galleries, the paintings that shouted loudest got the attention". Orientalist painting was an alternative genre that offered similar exotic costumes and decor, and at least as much opportunity to depict sex and violence.





</doc>
<doc id="14052" url="https://en.wikipedia.org/wiki?curid=14052" title="Hyperbola">
Hyperbola

In mathematics, a hyperbola (plural "hyperbolas" or "hyperbolae") is a type of smooth curve lying in a plane, defined by its geometric properties or by equations for which it is the solution set. A hyperbola has two pieces, called connected components or branches, that are mirror images of each other and resemble two infinite bows. The hyperbola is one of the three kinds of conic section, formed by the intersection of a plane and a double cone. (The other conic sections are the parabola and the ellipse. A circle is a special case of an ellipse.) If the plane intersects both halves of the double cone but does not pass through the apex of the cones, then the conic is a hyperbola.

Hyperbolas arise in many ways: 
and so on.

Each branch of the hyperbola has two arms which become straighter (lower curvature) further out from the center of the hyperbola. Diagonally opposite arms, one from each branch, tend in the limit to a common line, called the asymptote of those two arms. So there are two asymptotes, whose intersection is at the center of symmetry of the hyperbola, which can be thought of as the mirror point about which each branch reflects to form the other branch. In the case of the curve formula_1 the asymptotes are the two coordinate axes.

Hyperbolas share many of the ellipses' analytical properties such as eccentricity, focus, and directrix. Typically the correspondence can be made with nothing more than a change of sign in some term. Many other mathematical objects have their origin in the hyperbola, such as hyperbolic paraboloids (saddle surfaces), hyperboloids ("wastebaskets"), hyperbolic geometry (Lobachevsky's celebrated non-Euclidean geometry), hyperbolic functions (sinh, cosh, tanh, etc.), and gyrovector spaces (a geometry proposed for use in both relativity and quantum mechanics which is not Euclidean).

The word "hyperbola" derives from the Greek , meaning "over-thrown" or "excessive", from which the English term hyperbole also derives. Hyperbolae were discovered by Menaechmus in his investigations of the problem of doubling the cube, but were then called sections of obtuse cones. The term hyperbola is believed to have been coined by Apollonius of Perga (c. 262–c. 190 BC) in his definitive work on the conic sections, the "Conics". 
The names of the other two general conic sections, the ellipse and the parabola, derive from the corresponding Greek words for "deficient" and "applied"; all three names are borrowed from earlier Pythagorean terminology which referred to a comparison of the side of rectangles of fixed area with a given line segment. The rectangle could be "applied" to the segment (meaning, have an equal length), be shorter than the segment or exceed the segment.

A hyperbola can be defined geometrically as a set of points (locus of points) in the Euclidean plane:

The midpoint formula_8 of the line segment joining the foci is called the "center" of the hyperbola. The line through the foci is called the "major axis". It contains the "vertices" formula_9, which have distance formula_10 to the center. The distance formula_11 of the foci to the center is called the "focal distance" or "linear eccentricity". The quotient formula_12 is the "eccentricity" formula_13.

The equation formula_14 can be viewed in a different way (see diagram):
If formula_15 is the circle with midpoint formula_16 and radius formula_17, then the distance of a point formula_3 of the right branch to the circle formula_15 equals the distance to the focus formula_20:
formula_15 is called the "circular directrix" (related to focus formula_16) of the hyperbola. In order to get the left branch of the hyperbola, one has to use the circular directrix related to formula_20. This property should not be confused with the definition of a hyperbola with help of a directrix (line) below.

If Cartesian coordinates are introduced such that the origin is the center of the hyperbola and the "x"-axis is the major axis, then the hyperbola is called "east-west-opening" and 
For an arbitrary point formula_27 the distance to the focus formula_28 is 
formula_29 and to the second focus formula_30. Hence the point formula_27 is on the hyperbola if the following condition is fulfilled 
Remove the square roots by suitable squarings and use the relation formula_33 to obtain the equation of the hyperbola:

This equation is called the canonical form of a hyperbola, because any hyperbola, regardless of its orientation relative to the Cartesian axes and regardless of the location of its center, can be transformed to this form by a change of variables, giving a hyperbola that is congruent to the original (see below).

The axes of symmetry or "principal axes" are the "transverse axis" (containing the segment of length 2"a" with endpoints at the vertices) and the "conjugate axis" (containing the segment of length 2"b" perpendicular to the transverse axis and with midpoint at the hyperbola's center). As opposed to an ellipse, a hyperbola has only two vertices: formula_35. The two points formula_36 on the conjugate axes are "not" on the hyperbola.

It follows from the equation that the hyperbola is "symmetric" with respect to both of the coordinate axes and hence symmetric with respect to the origin.

For a hyperbola in the above canonical form, the eccentricity is given by

Two hyperbolas are geometrically similar to each other – meaning that they have the same shape, so that one can be transformed into the other by rigid left and right movements, rotation, taking a mirror image, and scaling (magnification) – if and only if they have the same eccentricity.

Solving the equation (above) of the hyperbola for formula_38 yields
It follows from this that the hyperbola approaches the two lines 
for large values of formula_41. These two lines intersect at the center (origin) and are called "asymptotes" of the hyperbola formula_42

With the help of the second figure one can see that

From the Hesse normal form formula_45 of the asymptotes and the equation of the hyperbola one gets:

From the equation formula_49 of the hyperbola (above) one can derive:

In addition, from (2) above it can be shown that

The length of the chord through one of the foci, perpendicular to the major axis of the hyperbola, is called the "latus rectum". One half of it is the "semi-latus rectum" formula_54. A calculation shows
The semi-latus rectum formula_54 may also be viewed as the "radius of curvature " at the vertices.

The simplest way to determine the equation of the tangent at a point formula_57 is to implicitly differentiate the equation formula_58 of the hyperbola. Denoting "dy/dx" as "y′", this produces
With respect to formula_60, the equation of the tangent at point formula_57 is

A particular tangent line distinguishes the hyperbola from the other conic sections. Let "f" be the distance from the vertex "V" (on both the hyperbola and its axis through the two foci) to the nearer focus. Then the distance, along a line perpendicular to that axis, from that focus to a point P on the hyperbola is greater than 2"f". The tangent to the hyperbola at P intersects that axis at point Q at an angle ∠PQV of greater than 45°.

In the case formula_63 the hyperbola is called "rectangular" (or "equilateral"), because its asymptotes intersect rectangularly (that is, are perpendicular). For this case, the linear eccentricity is formula_64, the eccentricity formula_65 and the semi-latus rectum formula_66.

Using the hyperbolic sine and cosine functions formula_67, a parametric representation of the hyperbola formula_58 can be obtained, which is similar to the parametric representation of an ellipse:
which satisfies the Cartesian equation because formula_70

Further parametric representations are given in the section Parametric equations below.

Exchange formula_71 and formula_38 to obtain the equation of the conjugate hyperbola (see diagram):

Just as the trigonometric functions are defined in terms of the unit circle, so also the hyperbolic functions are defined in terms of the unit hyperbola, as shown in this diagram. In a unit circle, the angle (in radians) is equal to twice the area of the circular sector which that angle subtends. The analogous hyperbolic angle is likewise defined as twice the area of a hyperbolic sector.

Let formula_10 be twice the area between the formula_71 axis and a ray through the origin intersecting the unit hyperbola, and define formula_77 as the coordinates of the intersection point.
Then the area of the hyperbolic sector is the area of the triangle minus the curved region past the vertex at formula_78:
which simplifies to the area hyperbolic cosine
Solving for formula_71 yields the exponential form of the hyperbolic cosine:
From formula_83 one gets
and its inverse the area hyperbolic sine:
Other hyperbolic functions are defined according to the hyperbolic cosine and hyperbolic sine, so for example

If the "xy"-coordinate system is rotated about the origin by the angle formula_87 and new coordinates formula_88 are assigned, then formula_89. 
The rectangular hyperbola formula_90 (whose semi-axes are equal) has the new equation formula_91.
Solving for formula_92 yields formula_93

Thus, in an "xy"-coordinate system the graph of a function formula_94 with equation

A rotation of the original hyperbola by formula_105 results in a rectangular hyperbola entirely in the second and fourth quadrants, with the same asymptotes, center, semi-latus rectum, radius of curvature at the vertices, linear eccentricity, and eccentricity as for the case of formula_87 rotation, with equation 

Shifting the hyperbola with equation formula_111 so that the new center is formula_112, yields the new equation 
and the new asymptotes are formula_114 and formula_115. 
The shape parameters formula_116 remain unchanged.

The two lines at distance formula_117 and parallel to the minor axis are called directrices of the hyperbola (see diagram).

For an arbitrary point formula_3 of the hyperbola the quotient of the distance to one focus and to the corresponding directrix (see diagram) is equal to the eccentricity:
The proof for the pair formula_120 follows from the fact that formula_121 and formula_122 satisfy the equation
The second case is proven analogously.

The "inverse statement" is also true and can be used to define a hyperbola (in a manner similar to the definition of a parabola):

For any point formula_124 (focus), any line formula_125 (directrix) not through formula_124 and any real number formula_13 with formula_128 the set of points (locus of points), for which the quotient of the distances to the point and to the line is formula_13

Let formula_133 and assume formula_97 is a point on the curve. 
The directrix formula_125 has equation formula_136. With formula_137, the relation formula_138 produces the equations
The substitution formula_141 yields
This is the equation of an "ellipse" (formula_143) or a "parabola" (formula_144) or a "hyperbola" (formula_145). All of these non-degenerate conics have, in common, the origin as a vertex (see diagram).

If formula_145, introduce new parameters formula_147 so that
formula_148, and then the equation above becomes 
which is the equation of a hyperbola with center formula_150, the "x"-axis as major axis and
the major/minor semi axis formula_147.

The intersection of an upright double cone by a plane not through the vertex with slope greater than the slope of the lines on the cone is a hyperbola (see diagram: red curve). In order to prove the defining property of a hyperbola (see above) one uses two Dandelin spheres formula_152, which are spheres that touch the cone along circles formula_153 , formula_154 and the intersecting (hyperbola) plane at points formula_20 and formula_16. It turns out: formula_157 are the "foci" of the hyperbola.

The definition of a hyperbola by its foci and its circular directrices (see above) can be used for drawing an arc of it with help of pins, a string and a ruler :

(0) Choose the "foci" formula_5, the vertices formula_9 and one of the "circular directrices" , for example formula_15 (circle with radius formula_17) <br>
(1) A "ruler" is fixed at point formula_16 free to rotate around formula_16. Point formula_163 is marked at distance formula_17.<br>
(2) A "string" with length formula_187 is prepared.<br>
(3) One end of the string is pinned at point formula_161 on the ruler, the other end is pinned to point formula_20.<br>
(4) Take a "pen" and hold the string tight to the edge of the ruler. <br>
(5) "Rotating" the ruler around formula_16 prompts the pen to draw an arc of the right branch of the hyperbola, because of formula_191 (see the definition of a hyperbola by "circular directrices").

The tangent at a point formula_3 bisects the angle between the lines formula_193.
Let formula_194 be the point on the line formula_167 with the distance formula_17 to the focus formula_16 (see diagram, formula_10 is the semi major axis of the hyperbola). Line formula_199 is the bisector of the angle between the lines formula_193. In order to prove that formula_199 is the tangent line at point formula_3, one checks that any point formula_203 on line formula_199 which is different from formula_3 cannot be on the hyperbola. Hence formula_199 has only point formula_3 in common with the hyperbola and is, therefore, the tangent at point formula_3. 
From the diagram and the triangle inequality one recognizes that formula_209 holds, which means: formula_210. But if formula_203 is a point of the hyperbola, the difference should be formula_17.

The midpoints of parallel chords of a hyperbola lie on a line through the center (see diagram).

The points of any chord may lie on different branches of the hyperbola.

The proof of the property on midpoints is best done for the hyperbola formula_213. Because any hyperbola is an affine image of the hyperbola formula_213 (see section below) and an affine transformation preserves parallelism and midpoints of line segments, the property is true for all hyperbolas:
For two points formula_215 of the hyperbola formula_213

For parallel chords the slope is constant and the midpoints of the parallel chords lie on the line formula_219

Consequence: for any pair of points formula_220 of a chord there exists a "skew reflection" with an axis (set of fixed points) passing through the center of the hyperbola, which exchanges the points formula_220 and leaves the hyperbola (as a whole) fixed. A skew reflection is a generalization of an ordinary reflection across a line formula_222, where all point-image pairs are on a line perpendicular to formula_222.

Because a skew reflection leaves the hyperbola fixed, the pair of asymptotes is fixed, too. Hence the midpoint formula_8 of a chord formula_225 divides the related line segment formula_226 between the asymptotes into halves, too. This means that formula_227. This property can be used for the construction of further points formula_203 of the hyperbola if a point formula_3 and the asymptotes are given.

If the chord degenerates into a "tangent", then the touching point divides the line segment between the asymptotes in two halves.

The following method to construct single points of a hyperbola relies on the Steiner generation of a non degenerate conic section:

For the generation of points of the hyperbola formula_237 one uses the pencils at the vertices formula_9. Let formula_239 be a point of the hyperbola and formula_240. The line segment formula_241 is divided into n equally-spaced segments and this division is projected parallel with the diagonal formula_176 as direction onto the line segment formula_243 (see diagram). The parallel projection is part of the projective mapping between the pencils at formula_244 and formula_245 needed. The intersection points of any two related lines formula_246 and formula_247 are points of the uniquely defined hyperbola.

"Remark:" The subdivision could be extended beyond the points formula_161 and formula_163 in order to get more points, but the determination of the intersection points would become more inaccurate. A better idea is extending the points already constructed by symmetry (see animation).

"Remark:"

A hyperbola with equation formula_250 is uniquely determined by three points formula_251 with different "x"- and "y"-coordinates. A simple way to determine the shape parameters formula_252 uses the "inscribed angle theorem" for hyperbolas:

Analogous to the inscribed angle theorem for circles one gets the

Inscribed angle theorem for hyperbolas:,:

A consequence of the inscribed angle theorem for hyperbolas is the

3-point-form of a hyperbola's equation:

For a hyperbola formula_264 the intersection points of "orthogonal" tangents lie on the circle formula_265. 
This circle is called the "orthoptic" of the given hyperbola.

The tangents may belong to points on different branches of the hyperbola.

In case of formula_266 there are no pairs of orthogonal tangents.

Any hyperbola can be described in a suitable coordinate system by an equation formula_58. The equation of the tangent at a point formula_268 of the hyperbola is formula_269 If one allows point formula_268 to be an arbitrary point different from the origin, then

This relation between points and lines is a bijection.

The inverse function maps

Such a relation between points and lines generated by a conic is called pole-polar relation or just "polarity". The pole is the point, the polar the line. See Pole and polar.

By calculation one checks the following properties of the pole-polar relation of the hyperbola:

"Remarks:"
Pole-polar relations exist for ellipses and parabolas, too.

Another definition of a hyperbola uses affine transformations:

An affine transformation of the Euclidean plane has the form formula_289, where formula_161 is a regular matrix (its determinant is not 0) and formula_291 is an arbitrary vector. If formula_292 are the column vectors of the matrix formula_161, the unit hyperbola formula_294 is mapped onto the hyperbola

formula_291 is the center, formula_297 a point of the hyperbola and formula_298 a tangent vector at this point. 

In general the vectors formula_292 are not perpendicular. That means, in general formula_300 are "not" the vertices of the hyperbola. But formula_301 point into the directions of the asymptotes. The tangent vector at point formula_302 is 
Because at a vertex the tangent is perpendicular to the major axis of the hyperbola one gets the parameter formula_304 of a vertex from the equation 
and hence from
which yields

The two "vertices" of the hyperbola are formula_309

Solving the parametric representation for formula_310 by Cramer's rule and using formula_311, one gets the implicit representation

The definition of a hyperbola in this section gives a parametric representation of an arbitrary hyperbola, even in space, if one allows formula_313 to be vectors in space.

Because the unit hyperbola formula_83 is affinely equivalent to the hyperbola formula_213, an arbitrary hyperbola can be considered as the affine image (see previous section) of the hyperbola formula_316

formula_318 is the center of the hyperbola, the vectors formula_319 have the directions of the asymptotes and formula_320 is a point of the hyperbola. The tangent vector is
At a vertex the tangent is perpendicular to the major axis. Hence 
and the parameter of a vertex is

formula_324 is equivalent to formula_325 and formula_326 are the vertices of the hyperbola.

The following properties of a hyperbola are easily proven using the representation of a hyperbola introduced in this section.

The tangent vector can be rewritten by factorization:
This means that

This property provides a way to construct the tangent at a point on the hyperbola.

This property of a hyperbola is an affine version of the 3-point-degeneration of Pascal's theorem.

The area of the grey parallelogram formula_331 in the above diagram is
and hence independent of point formula_3. The last equation follows from a calculation for the case, where formula_3 is a vertex and the hyperbola in its canonical form formula_335

For a hyperbola with parametric representation formula_336 (for simplicity the center is the origin) the following is true:

The simple proof is a consequence of the equation formula_339.

This property provides a possibility to construct points of a hyperbola if the asymptotes and one point are given.

This property of a hyperbola is an affine version of the 4-point-degeneration of Pascal's theorem.

For simplicity the center of the hyperbola may be the origin and the vectors formula_340 have equal length. If the last assumption is not fulfilled one can first apply a parameter transformation (see above) in order to make the assumption true. Hence formula_341 are the vertices, formula_342 span the minor axis and one gets formula_343 and formula_344.

For the intersection points of the tangent at point formula_345 with the asymptotes one gets the points 
The "area" of the triangle formula_347 can be calculated by a 2x2-determinant: 
(see rules for determinants).
formula_349 is the area of the rhombus generated by formula_340. The area of a rhombus is equal to one half of the product of its diagonals. The diagonals are the semi-axes formula_147 of the hyperbola. Hence:

For pole = focus: 

The polar coordinates used most commonly for the hyperbola are defined relative to the Cartesian coordinate system that has its "origin in a focus" and its x-axis pointing towards the origin of the "canonical coordinate system" as illustrated in the first diagram.
In this case the angle formula_354 is called true anomaly.

Relative to this coordinate system one has that

and

for pole = center:

With polar coordinates relative to the "canonical coordinate system" (see second diagram)
one has that

For the right branch of the hyperbola the range of formula_358 is

A hyperbola with equation formula_360 can be described by several parametric equations:

The reciprocation of a circle "B" in a circle "C" always yields a conic section such as a hyperbola. The process of "reciprocation in a circle "C"" consists of replacing every line and point in a geometrical figure with their corresponding pole and polar, respectively. The "pole" of a line is the inversion of its closest point to the circle "C", whereas the polar of a point is the converse, namely, a line whose closest point to "C" is the inversion of the point.

The eccentricity of the conic section obtained by reciprocation is the ratio of the distances between the two circles' centers to the radius "r" of reciprocation circle "C". If B and C represent the points at the centers of the corresponding circles, then

Since the eccentricity of a hyperbola is always greater than one, the center B must lie outside of the reciprocating circle "C".

This definition implies that the hyperbola is both the locus of the poles of the tangent lines to the circle "B", as well as the envelope of the polar lines of the points on "B". Conversely, the circle "B" is the envelope of polars of points on the hyperbola, and the locus of poles of tangent lines to the hyperbola. Two tangent lines to "B" have no (finite) poles because they pass through the center C of the reciprocation circle "C"; the polars of the corresponding tangent points on "B" are the asymptotes of the hyperbola. The two branches of the hyperbola correspond to the two parts of the circle "B" that are separated by these tangent points.

A hyperbola can also be defined as a second-degree equation in the Cartesian coordinates ("x", "y") in the plane,

provided that the constants "A", "A", "A", "B", "B", and "C" satisfy the determinant condition

This determinant is conventionally called the discriminant of the conic section.

A special case of a hyperbola—the "degenerate hyperbola" consisting of two intersecting lines—occurs when another determinant is zero:

This determinant Δ is sometimes called the discriminant of the conic section.

Given the above general parametrization of the hyperbola in Cartesian coordinates, the eccentricity can be found using the formula in Conic section#Eccentricity in terms of parameters of the quadratic form.

The center ("x", "y") of the hyperbola may be determined from the formulae

In terms of new coordinates, and , the defining equation of the hyperbola can be written

The principal axes of the hyperbola make an angle "φ" with the positive "x"-axis that is given by

Rotating the coordinate axes so that the "x"-axis is aligned with the transverse axis brings the equation into its canonical form

The major and minor semiaxes "a" and "b" are defined by the equations

where λ and λ are the roots of the quadratic equation

For comparison, the corresponding equation for a degenerate hyperbola (consisting of two intersecting lines) is

The tangent line to a given point ("x", "y") on the hyperbola is defined by the equation

where "E", "F" and "G" are defined by

The normal line to the hyperbola at the same point is given by the equation

The normal line is perpendicular to the tangent line, and both pass through the same point ("x", "y").

From the equation
the left focus is formula_392 and the right focus is formula_393 where is the eccentricity. Denote the distances from a point ("x, y") to the left and right foci as formula_394 and formula_395 For a point on the right branch,

and for a point on the left branch,

This can be proved as follows:

If ("x","y") is a point on the hyperbola the distance to the left focal point is

To the right focal point the distance is

If ("x,y") is a point on the right branch of the hyperbola then formula_400 and

Subtracting these equations one gets

If ("x,y") is a point on the left branch of the hyperbola then formula_404 and

Subtracting these equations one gets

Besides providing a uniform description of circles, ellipses, parabolas, and hyperbolas, conic sections can also be understood as a natural model of the geometry of perspective in the case where the scene being viewed consists of circles, or more generally an ellipse. The viewer is typically a camera or the human eye and the image of the scene a central projection onto an image plane, that is, all projection rays pass a fixed point "O", the center. The lens plane is a plane parallel to the image plane at the lens "O".

The image of a circle c is 

These results can be understood if one recognizes that the projection process can be seen in two steps: 1) circle c and point "O" generate a cone which is 2) cut by the image plane, in order to generate the image.

One sees a hyperbola whenever catching sight of a portion of a circle cut by one's lens plane. The inability to see very much of the arms of the visible branch, combined with the complete absence of the second branch, makes it virtually impossible for the human visual system to recognize the connection with hyperbolas.

The arc length of a hyperbola does not have a closed-form expression. The upper half of a hyperbola can be parameterized as

Then the integral giving the arc length formula_409 from formula_410 to formula_411 can be computed numerically:

After using the substitution formula_413, this can also be represented using the elliptic integral of the second kind with parameter formula_414:

Several other curves can be derived from the hyperbola by inversion, the so-called inverse curves of the hyperbola. If the center of inversion is chosen as the hyperbola's own center, the inverse curve is the lemniscate of Bernoulli; the lemniscate is also the envelope of circles centered on a rectangular hyperbola and passing through the origin. If the center of inversion is chosen at a focus or a vertex of the hyperbola, the resulting inverse curves are a limaçon or a strophoid, respectively.

A family of confocal hyperbolas is the basis of the system of elliptic coordinates in two dimensions. These hyperbolas are described by the equation

where the foci are located at a distance "c" from the origin on the "x"-axis, and where θ is the angle of the asymptotes with the "x"-axis. Every hyperbola in this family is orthogonal to every ellipse that shares the same foci. This orthogonality may be shown by a conformal map of the Cartesian coordinate system "w" = "z" + 1/"z", where "z"= "x" + "iy" are the original Cartesian coordinates, and "w"="u" + "iv" are those after the transformation.

Other orthogonal two-dimensional coordinate systems involving hyperbolas may be obtained by other conformal mappings. For example, the mapping "w" = "z" transforms the Cartesian coordinate system into two families of orthogonal hyperbolas.


Hyperbolas may be seen in many sundials. On any given day, the sun revolves in a circle on the celestial sphere, and its rays striking the point on a sundial traces out a cone of light. The intersection of this cone with the horizontal plane of the ground forms a conic section. At most populated latitudes and at most times of the year, this conic section is a hyperbola. In practical terms, the shadow of the tip of a pole traces out a hyperbola on the ground over the course of a day (this path is called the "declination line"). The shape of this hyperbola varies with the geographical latitude and with the time of the year, since those factors affect the cone of the sun's rays relative to the horizon. The collection of such hyperbolas for a whole year at a given location was called a "pelekinon" by the Greeks, since it resembles a double-bladed axe.

A hyperbola is the basis for solving multilateration problems, the task of locating a point from the differences in its distances to given points — or, equivalently, the difference in arrival times of synchronized signals between the point and the given points. Such problems are important in navigation, particularly on water; a ship can locate its position from the difference in arrival times of signals from a LORAN or GPS transmitters. Conversely, a homing beacon or any transmitter can be located by comparing the arrival times of its signals at two separate receiving stations; such techniques may be used to track objects and people. In particular, the set of possible positions of a point that has a distance difference of 2"a" from two given points is a hyperbola of vertex separation 2"a" whose foci are the two given points.

The path followed by any particle in the classical Kepler problem is a conic section. In particular, if the total energy "E" of the particle is greater than zero (that is, if the particle is unbound), the path of such a particle is a hyperbola. This property is useful in studying atomic and sub-atomic forces by scattering high-energy particles; for example, the Rutherford experiment demonstrated the existence of an atomic nucleus by examining the scattering of alpha particles from gold atoms. If the short-range nuclear interactions are ignored, the atomic nucleus and the alpha particle interact only by a repulsive Coulomb force, which satisfies the inverse square law requirement for a Kepler problem.

The hyperbolic trig function formula_417 appears as one solution to the Korteweg–de Vries equation which describes the motion of a soliton wave in a canal.

As shown first by Apollonius of Perga, a hyperbola can be used to trisect any angle, a well studied problem of geometry. Given an angle, first draw a circle centered at its vertex O, which intersects the sides of the angle at points A and B. Next draw the line segment with endpoints A and B and its perpendicular bisector formula_418. Construct a hyperbola of eccentricity "e"=2 with formula_418 as directrix and B as a focus. Let P be the intersection (upper) of the hyperbola with the circle. Angle POB trisects angle AOB.

To prove this, reflect the line segment OP about the line formula_418 obtaining the point P' as the image of P. Segment AP' has the same length as segment BP due to the reflection, while segment PP' has the same length as segment BP due to the eccentricity of the hyperbola. As OA, OP', OP and OB are all radii of the same circle (and so, have the same length), the triangles OAP', OPP' and OPB are all congruent. Therefore, the angle has been trisected, since 3×POB = AOB.

In portfolio theory, the locus of mean-variance efficient portfolios (called the efficient frontier) is the upper half of the east-opening branch of a hyperbola drawn with the portfolio return's standard deviation plotted horizontally and its expected value plotted vertically; according to this theory, all rational investors would choose a portfolio characterized by some point on this locus.

In biochemistry and pharmacology, the Hill equation and Hill-Langmuir equation respectively describe biological responses and the formation of protein–ligand complexes as functions of ligand concentration. They are both rectangular hyperbolae.

Hyperbolas appear as plane sections of the following quadrics:




</doc>
<doc id="14055" url="https://en.wikipedia.org/wiki?curid=14055" title="Humayun">
Humayun

Nasir-ud-Din Muḥammad (; 6 March 1508 – 27 January 1556), better known by his regnal name, Humayun (), was the second emperor of the Mughal Empire, who ruled over territory in what is now Afghanistan, Pakistan, Northern India, and Bangladesh from 1530–1540 and again from 1555–1556. Like his father, Babur, he lost his kingdom early but regained it with the aid of the Safavid dynasty of Persia, with additional territory. At the time of his death in 1556, the Mughal Empire spanned almost one million square kilometres.

In December 1530, Humayun succeeded his father to the throne of Delhi as ruler of the Mughal territories in the Indian subcontinent. Humayun was an inexperienced ruler when he came to power, at the age of 22. His half-brother Kamran Mirza inherited Kabul and Kandahar, the northernmost parts of their father's empire. Kamran was to become a bitter rival of Humayun.

Humayun lost Mughal territories to Sher Shah Suri, but regained them 15 years later with Safavid aid. Humayun's return from Persia was accompanied by a large retinue of Persian noblemen and signalled an important change in Mughal court culture. The Central Asian origins of the dynasty were largely overshadowed by the influences of Persian art, architecture, language, and literature. There are many stone carvings and thousands of Persian manuscripts in India dating from the time of Humayun.

Subsequently, Humayun further expanded the Empire in a very short time, leaving a substantial legacy for his son, Akbar.

The decision of Babur to divide the territories of his empire between two of his sons was unusual in India, although it had been a common Central Asian practice since the time of Genghis Khan. Unlike most monarchies, which practised primogeniture, the Timurids followed the example of Genghis and did not leave an entire kingdom to the eldest son. Although under that system only a Chingissid could claim sovereignty and khanal authority, any male Chinggisid within a given sub-branch had an equal right to the throne (though the Timurids were not Chinggisid in their paternal ancestry). While Genghis Khan's Empire had been peacefully divided between his sons upon his death, almost every Chinggisid succession since had resulted in fratricide.

Timur himself had divided his territories among Pir Muhammad, Miran Shah, Khalil Sultan and Shah Rukh, which resulted in inter-family warfare. Upon Babur's death, Humayun's territories were the least secure. He had ruled only four years, and not all "umarah" (nobles) viewed Humayun as the rightful ruler. Indeed, earlier, when Babur had become ill, some of the nobles had tried to install his Brother-in-law, Mahdi Khwaja, as ruler. Although this attempt failed, it was a sign of problems to come.

When Humayun came to the throne of the Mughal Empire, several of his brothers revolted against him. Another brother Khalil Mirza (1509–1530) supported Humayun but was assassinated. The Emperor commenced construction of a tomb for his brother in 1538, but this was not yet finished when Humayun was forced to flee to Persia. Sher Shah destroyed the structure and no further work was done on it after Humayun's restoration.

Humayun had two major rivals for his lands: Sultan Bahadur of Gujarat to the southwest and Sher Shah Suri (Sher Khan) settled along the river Ganges in Bihar to the east. Humayun's first campaign was to confront Sher Shah Suri. Halfway through this offensive Humayun had to abandon it and concentrate on Gujarat, where a threat from Ahmed Shah had to be met. Humayun was victorious annexing Gujarat, Malwa, Champaner and the great fort of Mandu.

During the first five years of Humayun's reign, Bahadur and Sher Khan extended their rule, although Sultan Bahadur faced pressure in the east from sporadic conflicts with the Portuguese. While the Mughals had obtained firearms via the Ottoman Empire, Bahadur's Gujarat had acquired them through a series of contracts drawn up with the Portuguese, allowing the Portuguese to establish a strategic foothold in north western India.

In 1535 Humayun was made aware that the Sultan of Gujarat was planning an assault on the Mughal territories with Portuguese aid. Humayun gathered an army and marched on Bahadur. Within a month he had captured the forts of Mandu and Champaner. However, instead of pressing his attack, Humayun ceased the campaign and consolidated his newly conquered territory. Sultan Bahadur, meanwhile escaped and took up refuge with the Portuguese.

Shortly after Humayun had marched on Gujarat, Sher Shah Suri saw an opportunity to wrest control of Agra from the Mughals. He began to gather his army together hoping for a rapid and decisive siege of the Mughal capital. Upon hearing this alarming news, Humayun quickly marched his troops back to Agra allowing Bahadur to easily regain control of the territories Humayun had recently taken. In February 1537, however, Bahadur was killed when a botched plan to kidnap the Portuguese viceroy ended in a fire-fight that the Sultan lost.

Whilst Humayun succeeded in protecting Agra from Sher Shah, the second city of the Empire, Gaur the capital of the "vilayat" of Bengal, was sacked. Humayun's troops had been delayed while trying to take Chunar, a fort occupied by Sher Shah's son, in order to protect his troops from an attack from the rear. The stores of grain at Gauri, the largest in the empire, were emptied, and Humayun arrived to see corpses littering the roads. The vast wealth of Bengal was depleted and brought East, giving Sher Shah a substantial war chest.

Sher Shah withdrew to the east, but Humayun did not follow: instead he "shut himself up for a considerable time in his Harem, and indulged himself in every kind of luxury". Hindal, Humayun's 19-year-old brother, had agreed to aid him in this battle and protect the rear from attack, but he abandoned his position and withdrew to Agra, where he decreed himself acting emperor. When Humayun sent the grand "Mufti", Sheikh Buhlul, to reason with him; the Sheikh was killed. Further provoking the rebellion, Hindal ordered that the "Khutba", or sermon, in the main mosque surrounded.

Humayun's other brother, Kamran Mirza, marched from his territories in the Punjab, ostensibly to aid Humayun. However, his return home had treacherous motives as he intended to stake a claim for Humayun's apparently collapsing empire. He brokered a deal with Hindal providing that his brother would cease all acts of disloyalty in return for a share in the new empire, which Kamran would create once Humayun was deposed.

In June 1539 Sher Shah met Humayun in the Battle of Chausa on the banks of the Ganges, near Buxar. This was to become an entrenched battle in which both sides spent a lot of time digging themselves into positions. The major part of the Mughal army, the artillery, was now immobile, and Humayun decided to engage in some diplomacy using Muhammad Aziz as ambassador. Humayun agreed to allow Sher Shah to rule over Bengal and Bihar, but only as provinces granted to him by his Emperor, Humayun, falling short of outright sovereignty. The two rulers also struck a bargain in order to save face: Humayun's troops would charge those of Sher Shah whose forces then retreat in feigned fear. Thus honour would, supposedly, be satisfied.

Once the Army of Humayun had made its charge and Sher Shah's troops made their agreed-upon retreat, the Mughal troops relaxed their defensive preparations and returned to their entrenchments without posting a proper guard. Observing the Mughals' vulnerability, Sher Shah reneged on his earlier agreement. That very night, his army approached the Mughal camp and finding the Mughal troops unprepared with a majority asleep, they advanced and killed most of them. The Emperor survived by swimming across the Ganges using an air-filled "water skin", and quietly returned to Agra. Humayun was assisted across the Ganges by Shams al-Din Muhammad.

When Humayun returned to Agra, he found that all three of his brothers were present. Humayun once again not only pardoned his brothers for plotting against him, but even forgave Hindal for his outright betrayal. With his armies travelling at a leisurely pace, Sher Shah was gradually drawing closer and closer to Agra. This was a serious threat to the entire family, but Humayun and Kamran squabbled over how to proceed. Kamran withdrew after Humayun refused to make a quick attack on the approaching enemy, instead opting to build a larger army under his own name.

When Kamran returned to Lahore, Humayun, with his other brothers Askari and Hindal, marched to meet Sher Shah east of Agra at the battle of Kannauj on 17 May 1540. Humayun was soundly defeated. He retreated to Agra, pursued by Sher Shah, and thence through Delhi to Lahore. Sher Shah's founding of the short-lived Sur Empire, with its capital at Delhi, resulted in Humayun's exile for 15 years in the court of Shah Tahmasp I.

The four brothers were united in Lahore, but every day they were informed that Sher Shah was getting closer and closer. When he reached Sirhind, Humayun sent an ambassador carrying the message "I have left you the whole of Hindustan [i.e. the lands to the East of Punjab, comprising most of the Ganges Valley]. Leave Lahore alone, and let Sirhind be a boundary between you and me." Sher Shah, however, replied "I have left you Kabul. You should go there." Kabul was the capital of the empire of Humayun's brother Kamran, who was far from willing to hand over any of his territories to his brother. Instead, Kamran approached Sher Shah and proposed that he actually revolt against his brother and side with Sher Shah in return for most of the Punjab. Sher Shah dismissed his help, believing it not to be required, though word soon spread to Lahore about the treacherous proposal, and Humayun was urged to make an example of Kamran and kill him. Humayun refused, citing the last words of his father, Babur, "Do nothing against your brothers, even though they may deserve it."

Humayun decided it would be wise to withdraw still further. He and his army rode out through and across the Thar Desert, when the Hindu ruler Rao Maldeo Rathore allied with Sher Shah Suri against the Mughal Empire. In many accounts Humayun mentions how he and his pregnant wife had to trace their steps through the desert at the hottest time of year. Their rations were low, and they had little to eat; even drinking water was a major problem in the desert. When Hamida Bano's horse died, no one would lend the Queen (who was now eight months pregnant) a horse, so Humayun did so himself, resulting in him riding a camel for six kilometres (four miles), although Khaled Beg then offered him his mount. Humayun was later to describe this incident as the lowest point in his life. Humayun asked that his brothers join him as he fell back into Sindh. While the previously rebellious Hindal Mirza remained loyal and was ordered to join his brothers in Kandahar. Kamran Mirza and Askari Mirza instead decided to head to the relative peace of Kabul. This was to be a definitive schism in the family. Humayun headed for Sindh because he expected aid from the Emir of Sindh, Hussein Umrani, whom he had appointed and who owed him his allegiance. Also, his wife Hamida hailed from Sindh; she was the daughter of a prestigious "pir" family (a "pir" is an Islamic religious guide) of Persian heritage long settled in Sindh. En route to the Emir's court, Humayun had to break journey because his pregnant wife Hamida was unable to travel further. Humayun sought refuge with the Hindu ruler of the oasis town of Amarkot (now part of Sindh province).

Rana Prasad Rao of Amarkot duly welcomed Humayun into his home and sheltered the refugees for several months. Here, in the household of a Hindu Rajput nobleman, Humayun's wife Hamida Bano, daughter of a Sindhi family, gave birth to the future Emperor Akbar on 15 October 1542. The date of birth is well established because Humayun consulted his astronomer to utilise the astrolabe and check the location of the planets. The infant was the long-awaited heir-apparent to the 34-year-old Humayun and the answer of many prayers. Shortly after the birth, Humayun and his party left Amarkot for Sindh, leaving Akbar behind, who was not ready for the grueling journey ahead in his infancy. He was later adopted by Askari Mirza.

For a change, Humayun was not deceived in the character of the man on whom he has pinned his hopes. Emir Hussein Umrani, ruler of Sindh, welcomed Humayun's presence and was loyal to Humayun just as he had been loyal to Babur against the renegade Arghuns. While in Sindh, Humayun alongside Emir Hussein Umrani, gathered horses and weapons and formed new alliances that helped regain lost territories. Until finally Humayun had gathered hundreds of Sindhi and Baloch tribesmen alongside his Mughals and then marched towards Kandahar and later Kabul, thousands more gathered by his side as Humayun continually declared himself the rightful Timurid heir of the first Mughal Emperor, Babur.

After Humayun set out from his expedition in Sindh, along with 300 camels (mostly wild) and 2000 loads of grain, he set off to join his brothers in Kandahar after crossing the Indus River on 11 July 1543 along with the ambition to regain the Mughal Empire and overthrow the Suri dynasty. Among the tribes that had sworn allegiance to Humayun were the Leghari, Magsi, Rind and many others.

In Kamran Mirza's territory, Hindal Mirza had been placed under house arrest in Kabul after refusing to have the "Khutba" recited in Kamran Mirza's name. His other brother, Askari Mirza, was now ordered to gather an army and march on Humayun. When Humayun received word of the approaching hostile army he decided against facing them, and instead sought refuge elsewhere. Akbar was left behind in camp close to Kandahar, as it was December, too cold and dangerous to include the 14-month-old toddler in the march through the mountains of the Hindu Kush. Askari Mirza took Akbar in, leaving the wives of Kamran and Askari Mirza to raise him. The Akbarnama specifies Kamran Mirza's wife, Sultan Begam.

Once again Humayun turned toward Kandahar where his brother Kamran Mirza was in power, but he received no help and had to seek refuge with the Shah of Persia.

Humayun fled to the refuge of the Safavid Empire in Persia, marching with 40 men, his wife Bega Begum, and her companion through mountains and valleys. Among other trials the Imperial party were forced to live on horse meat boiled in the soldiers' helmets. These indignities continued during the month it took them to reach Herat, however after their arrival they were reintroduced to the finer things in life. Upon entering the city his army was greeted with an armed escort, and they were treated to lavish food and clothing. They were given fine accommodations and the roads were cleared and cleaned before them. Shah Tahmasp, unlike Humayun's own family, actually welcomed the Mughal, and treated him as a royal visitor. Here Humayun went sightseeing and was amazed at the Persian artwork and architecture he saw: much of this was the work of the Timurid Sultan Husayn Bayqarah and his ancestor, princess Gauhar Shad, thus he was able to admire the work of his relatives and ancestors at first hand.

He was introduced to the work of the Persian miniaturists, and Kamaleddin Behzad had two of his pupils join Humayun in his court. Humayun was amazed at their work and asked if they would work for him if he were to regain the sovereignty of Hindustan: they agreed. With so much going on Humayun did not even meet the Shah until July, some six months after his arrival in Persia. After a lengthy journey from Herat the two met in Qazvin where a large feast and parties were held for the event. The meeting of the two monarchs is depicted in a famous wall-painting in the Chehel Sotoun (Forty Columns) palace in Esfahan.

The Shah urged that Humayun convert from Sunni to Shia Islam, and Humayun eventually accepted, in order to keep himself and several hundred followers alive. Although the Mughals initially disagreed to their conversion they knew that with this outward acceptance of Shi'ism, Shah Tahmasp was eventually prepared to offer Humayun more substantial support. When Humayun's brother, Kamran Mirza, offered to cede Kandahar to the Persians in exchange for Humayun, dead or alive, Shah Tahmasp refused. Instead the Shah staged a celebration for Humayun, with 300 tents, an imperial Persian carpet, 12 musical bands and "meat of all kinds". Here the Shah announced that all this, and 12,000 elite cavalry were his to lead an attack on his brother Kamran. All that Shah Tahmasp asked for was that, if Humayun's forces were victorious, Kandahar would be his.

With this Persian Safavid aid Humayun took Kandahar from Askari Mirza after a two-week siege. He noted how the nobles who had served Askari Mirza quickly flocked to serve him, "in very truth the greater part of the inhabitants of the world are like a flock of sheep, wherever one goes the others immediately follow". Kandahar was, as agreed, given to the Shah of Persia who sent his infant son, Murad, as the Viceroy. However, the baby soon died and Humayun thought himself strong enough to assume power.

Humayun now prepared to take Kabul, ruled by his brother Kamran Mirza. In the end, there was no actual siege. Kamran Mirza was detested as a leader and as Humayun's Persian army approached the city hundreds of Kamran Mirza's troops changed sides, flocking to join Humayun and swelling his ranks. Kamran Mirza absconded and began building an army outside the city. In November 1545, Hamida and Humayun were reunited with their son Akbar, and held a huge feast. They also held another, larger, feast in the child's honour when he was circumcised.

However, while Humayun had a larger army than his brother and had the upper hand, on two occasions his poor military judgement allowed Kamran Mirza to retake Kabul and Kandahar, forcing Humayun to mount further campaigns for their recapture. He may have been aided in this by his reputation for leniency towards the troops who had defended the cities against him, as opposed to Kamran Mirza, whose brief periods of possession were marked by atrocities against the inhabitants who, he supposed, had helped his brother.

His youngest brother, Hindal Mirza, formerly the most disloyal of his siblings, died fighting on his behalf. His brother Askari Mirza was shackled in chains at the behest of his nobles and aides. He was allowed go on Hajj, and died en route in the desert outside Damascus.

Humayun's other brother, Kamran Mirza, had repeatedly sought to have Humayun killed. In 1552 Kamran Mirza attempted to make a pact with Islam Shah, Sher Shah's successor, but was apprehended by a Gakhar. The Gakhars were one of the minority of tribal groups who had consistently remained loyal to their oath to the Mughals. Sultan Adam of the Gakhars handed Kamran Mirza over to Humayun. Humayun was inclined to forgive his brother. However he was warned that allowing Kamran Mirza's repeated acts of treachery to go unpunished could foment rebellion amongst his own supporters. So, instead of killing his brother, Humayun had Kamran Mirza blinded which would end any claim by the latter to the throne. Humayun sent Kamran Mirza on Hajj, as he hoped to see his brother thereby absolved of his offences. However Kamran Mirza died close to Mecca in the Arabian Peninsula in 1557.

Sher Shah Suri had died in 1545; his son and successor Islam Shah died in 1554. These two deaths left the dynasty reeling and disintegrating. Three rivals for the throne all marched on Delhi, while in many cities leaders tried to stake a claim for independence. This was a perfect opportunity for the Mughals to march back to India.

The Mughal Emperor Humayun gathered a vast army, which included the Baloch tribes of Leghari. Magsi and Rind, and attempted the challenging task of retaking the throne in Delhi. Humayun placed the army under the leadership of Bairam Khan, a wise move given Humayun's own record of military ineptitude, and it turned out to be prescient as Bairam proved himself a great tactician. At the Battle of Sirhind on 22 June 1555, the armies of Sikandar Shah Suri were decisively defeated and the Mughal Empire was re-established in India.

The "Gazetteer of Ulwur" states:

Bairam Khan led the army through the Punjab virtually unopposed. The fort of Rohtas, which was built in 1541–1543 by Sher Shah Suri to crush the Gakhars who were loyal to Humayun, was surrendered without a shot by a treacherous commander. The walls of the Rohtas Fort measure up to 12.5 meters in thickness and up to 18.28 meters in height. They extend for 4 km and feature 68 semi-circular bastions. Its sandstone gates, both massive and ornate, are thought to have exerted a profound influence on Mughal military architecture.

The only major battle faced by Humayun's armies was against Sikander Suri in Sirhind, where Bairam Khan employed a tactic whereby he engaged his enemy in open battle, but then retreated quickly in apparent fear. When the enemy followed after them they were surprised by entrenched defensive positions and were easily annihilated.

After Sirhind, most towns and villages chose to welcome the invading army as it made its way to the capital. On 23 July 1555, Humayun once again sat on Babur's throne in Delhi.

With all of Humayun's brothers now dead, there was no fear of another usurping his throne during his military campaigns. He was also now an established leader and could trust his generals. With this new-found strength Humayun embarked on a series of military campaigns aimed at extending his reign over areas in the east and west of the subcontinent. His sojourn in exile seems to have reduced his reliance on astrology, and his military leadership came to imitate the more effective methods that he had observed in Persia.

Edward S. Holden writes; "He was uniformly kind and considerate to his dependents, devotedly attached to his son Akbar, to his friends, and to his turbulent brothers. The misfortunes of his reign arose in great, from his failure to treat them with rigor." He further writes: "The very defects of his character, which render him less admirable as a successful ruler of nations, make us more fond of him as a man. His renown has suffered in that his reign came between the brilliant conquests of Babur and the beneficent statesmanship of Akbar; but he was not unworthy to be the son of the one and the father of the other." Stanley Lane-Poole writes in his book "Medieval India": "His name meant the winner (Lucky/Conqueror), there is no kind in the history to be named as wrong as Humayun", he was of a forgiving nature. He further writes, "He was in fact unfortunate ... Scarcely had he enjoyed his throne for six months in Delhi when he slipped down from the polished steps of his palace and died in his forty-ninth year (Jan. 24, 1556). If there was a possibility of falling, Humayun was not the man to miss it. He tumbled through his life and tumbled out of it."

Humayun ordered the crushing by elephant of an imam he mistakenly believed to be critical of his reign.

On 24 January 1556, Humayun, with his arms full of books, was descending the staircase from his library when the muezzin announced the Azaan (the call to prayer). It was his habit, wherever and whenever he heard the summons, to bow his knee in holy reverence. Trying to kneel, he caught his foot in his robe, tumbled down several steps and hit his temple on a rugged stone edge. He died three days later. His body was laid to rest in Purana Quila initially, but, because of an attack by Hemu on Delhi and the capture of Purana Qila, Humayun's body was exhumed by the fleeing army and transferred to Kalanaur in Punjab where Akbar was crowned. Humayun's Tomb in Delhi is the first very grand garden tomb in Mughal architecture, setting the precedent later followed by the Taj Mahal and many other Indian monuments. It was commissioned by his favourite and devoted chief wife, Bega Begum.

Akbar later asked his aunt, Gulbadan Begum, to write a biography of her brother, the "Humayun nameh" (or "Humayun-nama" etc.), and what she remembered of Babur. The work begins:
There had been an order issued, ‘Write down whatever you know of the doings of Firdous-Makani (Babur) and Jannat-Ashyani (Humayun)’. At this time when his Majesty Firdaus-Makani passed from this perishable world to the everlasting home, I, this lowly one, was eight years old, so it may well be that I do not remember much. However in obedience to the royal command, I set down whatever there is that I have heard and remember.

The full title is "Ahwal Humayun Padshah Jamah Kardom Gulbadan Begum bint Babur Padshah amma Akbar Padshah". She was only eight when Babur died, and was married at 17, but her work, in a simple Persian style, has been found very interesting by its relatively few readers.

Unlike other Mughal royal biographies (the "Zafarnama" of Timur, "Baburnama", and his own "Akbarnama") no richly illustrated copy has survived, and the work is only known from a single battered and slightly incomplete manuscript, now in the British Library, that emerged in the 1860s. Annette Beveridge published an English translation in 1901, and editions in English and Bengali have been published since 2000.

His full title as Emperor of the Mughal Empire was "Al-Sultan al-'Azam wal Khaqan al-Mukarram, Jam-i-Sultanat-i-haqiqi wa Majazi, Sayyid al-Salatin, Abu'l Muzaffar Nasir ud-din Muhammad Humayun Padshah Ghazi, Zillu'llah".





</doc>
<doc id="14056" url="https://en.wikipedia.org/wiki?curid=14056" title="Prince-elector">
Prince-elector

The prince-electors ( pl. "Kurfürsten", , ), or electors for short, were the members of the electoral college that elected the emperor of the Holy Roman Empire.

From the 13th century onwards, the prince-electors had the privilege of electing the monarch who would be crowned by the pope. After 1508, there were no imperial coronations and the election was sufficient. Charles V (elected in 1519) was the last emperor to be crowned (1530); his successors were elected emperors by the electoral college, each being titled "Elected Emperor of the Romans" (; ). 

The dignity of elector carried great prestige and was considered to be second only to that of king or emperor. The electors held exclusive privileges that were not shared with other princes of the Empire, and they continued to hold their original titles alongside that of elector. 

The heir apparent to a secular prince-elector was known as an electoral prince ().

The German element "Kur-" is based on the Middle High German irregular verb "kiesen" and is related etymologically to the English word "choose" (cf. Old English "ceosan" , participle "coren" 'having been chosen' and Gothic "kiusan"). In English, the "s"/"r" mix in the Germanic verb conjugation has been regularized to "s" throughout, while German retains the "r" in "Kur-". There is also a modern German verb "küren" which means 'to choose' in a ceremonial sense. 

"Fürst" is German for 'prince', but while the German language distinguishes between the head of a principality ("der Fürst") and the son of a monarch ("der Prinz"), English uses "prince" for both concepts. "Fürst" itself is related to English "first" and is thus the 'foremost' person in his realm. Note that 'prince' derives from Latin "princeps", which carried the same meaning.

Electors were "reichsstände" (Imperial Estates), enjoying precedence over the other princes. They were, until the 18th century, exclusively entitled to be addressed with the title "Durchlaucht" (Serene Highness). In 1742, the electors became entitled to the superlative "Durchläuchtigste" (Most Serene Highness), while other princes were promoted to "Durchlaucht".

As Imperial Estates, the electors enjoyed all the privileges of the other princes enjoying that status, including the right to enter into alliances, to autonomy in relation to dynastic affairs and to precedence over other subjects. The Golden Bull had granted them the Privilegium de non appellando, which prevented their subjects from lodging an appeal to a higher Imperial court. However, while this privilege, and some others, were automatically granted to Electors, they were not exclusive to them and many of the larger Imperial Estates were also to be individually granted some or all those rights and privileges.

The electors, like the other princes ruling States of the Empire, were members of the Imperial Diet, which was divided into three "collegia": the Council of Electors, the Council of Princes, and the Council of Cities. In addition to being members of the Council of Electors, several lay electors were therefore members of the Council of Princes as well by virtue of other territories they possessed. In many cases, the lay electors ruled numerous States of the Empire, and therefore held several votes in the Council of Princes. In 1792, the King of Bohemia held three votes, the Elector of Bavaria six votes, the Elector of Brandenburg eight votes, and the Elector of Hanover six votes. 

Thus, of the hundred votes in the Council of Princes in 1792, twenty-three belonged to electors. The lay electors therefore exercised considerable influence, being members of the small Council of Electors and holding a significant number of votes in the Council of Princes. The assent of both bodies was required for important decisions affecting the structure of the Empire, such as the creation of new electorates or States of the Empire.

In addition to voting by colleges or councils, the Imperial Diet also voted in religious coalitions, as provided for in the Peace of Westphalia. The Archbishop of Mainz presided over the Catholic body, or "corpus catholicorum", while the Elector of Saxony presided over the Protestant body, or "corpus evangelicorum". The division into religious bodies was on the basis of the official religion of the state, and not of its rulers. Thus, even when the Electors of Saxony were Catholics during the eighteenth century, they continued to preside over the "corpus evangelicorum", since the state of Saxony was officially Protestant.

The electors were originally summoned by the Archbishop of Mainz within one month of an Emperor's death, and met within three months of being summoned. During the "interregnum", imperial power was exercised by two imperial vicars. Each vicar, in the words of the Golden Bull, was "the administrator of the empire itself, with the power of passing judgments, of presenting to ecclesiastical benefices, of collecting returns and revenues and investing with fiefs, of receiving oaths of fealty for and in the name of the holy empire". The Elector of Saxony was vicar in areas operating under Saxon law (Saxony, Westphalia, Hanover, and northern Germany), while the Elector Palatine was vicar in the remainder of the Empire (Franconia, Swabia, the Rhine, and southern Germany). The Elector of Bavaria replaced the Elector Palatine in 1623, but when the latter was granted a new electorate in 1648, there was a dispute between the two as to which was vicar. In 1659, both purported to act as vicar, but the other vicar recognised the Elector of Bavaria. Later, the two electors made a pact to act as joint vicars, but the Imperial Diet rejected the agreement. In 1711, while the Elector of Bavaria was under the ban of the Empire, the Elector Palatine again acted as vicar, but his cousin was restored to his position upon his restoration three years later. 

Finally, in 1745, the two agreed to alternate as vicars, with Bavaria starting first. This arrangement was upheld by the Imperial Diet in 1752. In 1777 the question was settled when the Elector Palatine inherited Bavaria. On many occasions, however, there was no interregnum, as a new king had been elected during the lifetime of the previous Emperor.

Frankfurt regularly served as the site of the election from the fifteenth century on, but elections were also held at Cologne (1531), Regensburg (1575 and 1636), and Augsburg (1653 and 1690). An elector could appear in person or could appoint another elector as his proxy. More often, an electoral suite or embassy was sent to cast the vote; the credentials of such representatives were verified by the Archbishop of Mainz, who presided over the ceremony. The deliberations were held at the city hall, but voting occurred in the cathedral. In Frankfurt, a special electoral chapel, or "Wahlkapelle", was used for elections. Under the Golden Bull, a majority of electors sufficed to elect a king, and each elector could cast only one vote. Electors were free to vote for whomsoever they pleased (including themselves), but dynastic considerations played a great part in the choice. 

Electors drafted a "Wahlkapitulation", or electoral capitulation, which was presented to the king-elect. The capitulation may be described as a contract between the princes and the king, the latter conceding rights and powers to the electors and other princes. Once an individual swore to abide by the electoral capitulation, he assumed the office of King of the Romans.

In the 10th and 11th centuries, princes often acted merely to confirm hereditary succession in the Saxon Ottonian dynasty and Franconian Salian dynasty. But with the actual formation of the prince-elector class, elections became more open, starting with the election of Lothair II in 1125. The Staufen dynasty managed to get its sons formally elected in their fathers' lifetimes almost as a formality. After these lines ended in extinction, the electors began to elect kings from different families so that the throne would not once again settle within a single dynasty. 

For some two centuries, the monarchy was elective both in theory and in practice; the arrangement, however, did not last, since the powerful House of Habsburg managed to secure succession within their dynasty during the fifteenth century. All kings elected from 1438 onwards were from among the Habsburg Archdukes of Austria (and later Kings of Hungary and Bohemia) until 1740, when the archduchy was inherited by a woman, Maria Theresa, sparking the War of the Austrian Succession. 

A representative of the House of Wittelsbach was elected for a short period of time, but in 1745 Maria Theresa's husband, Francis I of the Habsburg-Lorraine dynasty, became King. All of his successors were also from the same family. Hence, for the greater part of the Empire's history, the role of the electors was largely ceremonial.

Each elector held a "High Office of the Empire" ("Reichserzämter") and was a member of the (ceremonial) Imperial Household. The three spiritual electors were all Arch-Chancellors (, ): the Archbishop of Mainz was Arch-Chancellor of Germany, the Archbishop of Cologne was Arch-Chancellor of Italy, and the Archbishop of Trier was Arch-Chancellor of Burgundy. That left between four and six secular electors:

When the Duke of Bavaria replaced the Elector Palatine in 1623, he assumed the latter's office of Arch-Steward. When the Count Palatine was granted a new electorate, he assumed the position of Arch-Treasurer of the Empire. When the Duke of Bavaria was banned in 1706, the Elector Palatine returned to the office of Arch-Steward, and in 1710 the Elector of Hanover was promoted to the post of Arch-Treasurer. Matters were complicated by the Duke of Bavaria's restoration in 1714; the Elector of Bavaria resumed the office of Arch-Steward, while the Elector Palatine returned to the post of Arch-Treasurer, and the Elector of Hanover was given the new office of Archbannerbearer. The Electors of Hanover, however, continued to be styled Arch-Treasurers, though the Elector Palatine was the one who actually exercised the office until 1777, when he inherited Bavaria and the Arch-Stewardship. After 1777, no further changes were made to the Imperial Household; new offices were planned for the Electors admitted in 1803, but the Empire was abolished before they could be created. The Duke of Württemberg, however, started to adopt the trappings of the Arch-Bannerbearer.

Many High Officers were entitled to use augmentations on their coats of arms; these augmentations, which were special marks of honour, appeared in the centre of the electors' shields (as shown in the image above) atop the other charges (in heraldic terms, the augmentations appeared in the form of inescutcheons). The Arch-Steward used "gules an orb Or" (a gold orb on a red field). The Arch-Marshal utilised the more complicated "per fess sable and argent, two swords in saltire gules" (two red swords arranged in the form of a saltire, on a black and white field). The Arch-Chamberlain's augmentation was "azure a sceptre palewise Or" (a gold sceptre on a blue field), while the Arch-Treasurer's was "gules the crown of Charlemagne Or" (a gold crown on a red field). As noted above, the Elector Palatine and the Elector of Hanover styled themselves Arch-Treasurer from 1714 until 1777; during this time, both electors used the corresponding augmentations. The three Arch-Chancellors and the Arch-Cupbearer did not use any augmentations.

The electors discharged the ceremonial duties associated with their offices only during coronations, where they bore the crown and regalia of the Empire. Otherwise, they were represented by holders of corresponding "Hereditary Offices of the Household". The Arch-Butler was represented by the Butler (Cupbearer) (the Count of Althann), the Arch-Seneschal by the Steward (the Count of Waldburg), the Arch-Chamberlain by the Chamberlain (the Count of Hohenzollern), the Arch-Marshal by the Marshal (the Count of Pappenheim), and the Arch-Treasurer by the Treasurer (the Count of Sinzendorf). The Duke of Württemberg assigned the count of Zeppelin-Aschhausen as hereditary Bannerbearer.

Below are the State arms of each Imperial Elector. Emblems of Imperial High Offices are shown on the appropriate arms.
Three Electors Spiritual (Archbishops):

Four Electors Secular:

Electors added in 17th century:

As Napoleon waged war on Europe, between 1803 and 1806, the following changes to the Constitution of the Holy Roman Empire were attempted until the Empire's collapse:

The German practice of electing monarchs began when ancient Germanic tribes formed "ad hoc" coalitions and elected the leaders thereof. Elections were irregularly held by the Franks, whose successor states include France and the Holy Roman Empire. The French monarchy eventually became hereditary, but the Holy Roman Emperors remained elective, at least in theory, although the Habsburgs provided most of the later monarchs. While all free men originally exercised the right to vote in such elections, suffrage eventually came to be limited to the leading men of the realm. In the election of Lothar II in 1125, a small number of eminent nobles chose the monarch and then submitted him to the remaining magnates for their approbation.

Soon, the right to choose the monarch was settled on an exclusive group of princes, and the procedure of seeking the approval of the remaining nobles was abandoned. The college of electors was mentioned in 1152 and again in 1198. The composition of electors at that time is unclear, but appears to have included representatives of the church and the dukes of the four nations of Germany: the Franks (Duchy of Franconia), Swabians (Duchy of Swabia), Saxons (Duchy of Saxony) and Bavarians (Duchy of Bavaria).

The electoral college is known to have existed by 1152, but its composition is unknown. A letter written by Pope Urban IV in 1265 suggests that by "immemorial custom", seven princes had the right to elect the King and future Emperor. The pope wrote that the seven electors were those who had just voted in the election of 1257, which resulted in the election of two kings.


The three Archbishops oversaw the most venerable and powerful sees in Germany, while the other four were supposed to represent the dukes of the four nations. The Count Palatine of the Rhine held most of the former Duchy of Franconia after the last Duke died in 1039. The Margrave of Brandenburg became an Elector when the Duchy of Swabia was dissolved after the last Duke of Swabia was beheaded in 1268. Saxony, even with diminished territory, retained its eminent position.

The Palatinate and Bavaria were originally (since 1214) held by the same individual, but in 1253 they were divided between two members of the House of Wittelsbach. The other electors refused to allow two princes from the same dynasty to have electoral rights, so a heated rivalry arose between the Count Palatine and the Duke of Bavaria over who should hold the Wittelsbach seat.

Meanwhile, the King of Bohemia, who held the ancient imperial office of Arch-Cupbearer, asserted his right to participate in elections. Sometimes he was challenged on the grounds that his kingdom was not German, though usually he was recognized, instead of Bavaria which after all was just a younger line of Wittelsbachs.

The Declaration of Rhense issued in 1338 had the effect that election by the majority of the electors automatically conferred the royal title and rule over the empire, without papal confirmation. The Golden Bull of 1356 finally resolved the disputes among the electors. Under it, the Archbishops of Mainz, Trier, and Cologne, as well as the King of Bohemia, the Count Palatine of the Rhine, the Duke of Saxony, and the Margrave of Brandenburg held the right to elect the King.

The college's composition remained unchanged until the 17th century, although the Electorate of Saxony was transferred from the senior to the junior branch of the Wettin family in 1547, in the aftermath of the Schmalkaldic War.

In 1621, the Elector Palatine, Frederick V, came under the imperial ban after participating in the Bohemian Revolt (a part of the Thirty Years' War). The Elector Palatine's seat was conferred on the Duke of Bavaria, the head of a junior branch of his family. Originally, the Duke held the electorate personally, but it was later made hereditary along with the duchy. When the Thirty Years' War concluded with the Peace of Westphalia in 1648, a new electorate was created for the Count Palatine of the Rhine. Since the Elector of Bavaria retained his seat, the number of electors increased to eight; the two Wittelsbach lines were now sufficiently estranged so as not to pose a combined potential threat.

In 1685, the religious composition of the College of Electors was disrupted when a Catholic branch of the Wittelsbach family inherited the Palatinate. A new Protestant electorate was created in 1692 for the Duke of Brunswick-Lüneburg, who became known as the Elector of Hanover (the Imperial Diet officially confirmed the creation in 1708). The Elector of Saxony converted to Catholicism in 1697 so that he could become King of Poland, but no additional Protestant electors were created. Although the Elector of Saxony was personally Catholic, the Electorate itself remained officially Protestant, and the Elector even remained the leader of the Protestant body in the Reichstag.

In 1706, the Elector of Bavaria and Archbishop of Cologne were banned during the War of the Spanish Succession, but both were restored in 1714 after the Peace of Baden. In 1777, the number of electors was reduced to eight when the Elector Palatine inherited Bavaria.

Many changes to the composition of the college were necessitated by Napoleon's aggression during the early 19th century. The Treaty of Lunéville (1801), which ceded territory on the Rhine's left bank to France, led to the abolition of the archbishoprics of Trier and Cologne, and the transfer of the remaining spiritual Elector from Mainz to Regensburg. In 1803, electorates were created for the Duke of Württemberg, the Margrave of Baden, the Landgrave of Hesse-Kassel, and the Duke of Salzburg, bringing the total number of electors to ten. When Austria annexed Salzburg under the Treaty of Pressburg (1805), the Duke of Salzburg moved to the Grand Duchy of Würzburg and retained his electorate. None of the new electors, however, had an opportunity to cast votes, as the Holy Roman Empire was abolished in 1806, and the new electorates were never confirmed by the Emperor.

After the abolition of the Holy Roman Empire in August 1806, the Electors continued to reign over their territories, many of them taking higher titles. The Electors of Bavaria, Württemberg, and Saxony styled themselves Kings, while the Electors of Baden, Hesse-Darmstadt, Regensburg, and Würzburg became Grand Dukes. The Elector of Hesse-Kassel, however, retained the meaningless title "Elector of Hesse", thus distinguishing himself from other Hessian princes (the Grand Duke of Hesse-Darmstadt and the Landgrave of Hesse-Homburg). Napoleon soon exiled him and Kassel was annexed to the Kingdom of Westphalia, a new creation. The King of Great Britain remained at war with Napoleon and continued to style himself Elector of Hanover, while the Hanoverian government continued to operate in London.

The Congress of Vienna accepted the Electors of Bavaria, Württemberg, and Saxony as Kings, along with the newly created Grand Dukes. The Elector of Hanover finally joined his fellow Electors by declaring himself the King of Hanover. The restored Elector of Hesse, a Napoleonic creation, tried to be recognized as the King of the Chatti. However, the European powers refused to acknowledge this title at the Congress of Aix-la-Chapelle (1818) and instead listed him with the grand dukes as a "Royal Highness". Believing the title of Prince-Elector to be superior in dignity to that of Grand Duke, the Elector of Hesse-Kassel chose to remain an Elector, even though there was no longer a Holy Roman Emperor to elect. Hesse-Kassel remained the only Electorate in Germany until 1866, when the country backed the losing side in the Austro-Prussian War and was absorbed into Prussia.

Religion was a factor in the election of the Holy Roman Emperor, as some Protestant electors would refuse to vote for a Roman Catholic and vice versa. Most of the time, religion played a minor role and was overshadowed by other factors, including dynastic, territorial and other political interests. For example, the Protestant Elector of Saxony voted for Ferdinand II, Archduke of Austria, putting his political interests first even though Ferdinand was a staunch Roman Catholic who would eventually lead the Empire into the Thirty Years' War.

At the height of the Protestant Reformation, there were times when the electoral college had a Protestant majority. However, all of the Holy Roman Emperors were Catholic. Some historians maintain that Ferdinand I had been touched by the Reformed theology and was probably the closest the Holy Roman Empire ever came to a Protestant emperor; he remained nominally Catholic throughout his life, although reportedly he refused last rites on his deathbed. Other historians maintain he was as Catholic as his brother, but tended to see religion as outside the political sphere.









</doc>
<doc id="14059" url="https://en.wikipedia.org/wiki?curid=14059" title="Howard Hughes">
Howard Hughes

Howard Robard Hughes Jr. (December 24, 1905 – April 5, 1976) was an American business magnate, investor, record-setting pilot, engineer, film director, and philanthropist, known during his lifetime as one of the most financially successful individuals in the world. He first became prominent as a film producer, and then as an influential figure in the aviation industry. Later in life, he became known for his eccentric behavior and reclusive lifestyle—oddities that were caused in part by his worsening obsessive-compulsive disorder (OCD), chronic pain from a near-fatal plane crash and increasing deafness.

As a film tycoon, Hughes gained fame in Hollywood beginning in the late 1920s, when he produced big-budget and often controversial films such as "The Racket" (1928), "Hell's Angels" (1930), and "Scarface" (1932). Later he controlled the RKO film studio.

Hughes formed the Hughes Aircraft Company in 1932, hiring numerous engineers and designers. He spent the rest of the 1930s and much of the 1940s setting multiple world air speed records and building the Hughes H-1 Racer and H-4 Hercules (the "Spruce Goose"). He acquired and expanded Trans World Airlines and later acquired Air West, renaming it Hughes Airwest. Hughes was included in "Flying" Magazine's list of the 51 Heroes of Aviation, ranked at 25. Today, his legacy is maintained through the Howard Hughes Medical Institute and the Howard Hughes Corporation.

Records locate the birthplace of Howard Hughes as either Humble or Houston, Texas. The date remains uncertain because of conflicting dates from various sources. He repeatedly claimed Christmas Eve as his birthday. A 1941 affidavit birth certificate of Hughes, signed by his aunt Annette Gano Lummis and by Estelle Boughton Sharp, states that he was born on December 24, 1905, in Harris County, Texas. However, his certificate of baptism, recorded on October 7, 1906, in the parish register of St. John's Episcopal Church in Keokuk, Iowa, listed his date of birth as September 24, 1905, without any reference to the place of birth.

Howard Robard Hughes Jr. was the son of Allene Stone Gano (1883–1922) and of Howard R. Hughes Sr. (1869–1924), a successful inventor and businessman from Missouri. He had English, Welsh and some French Huguenot ancestry, and was a descendant of John Gano (1727–1804), the minister who allegedly baptized George Washington. His father patented (1909) the two-cone roller bit, which allowed rotary drilling for petroleum in previously inaccessible places. The senior Hughes made the shrewd and lucrative decision to commercialize the invention by leasing the bits instead of selling them, obtained several early patents, and founded the Hughes Tool Company in 1909. Hughes' uncle was the famed novelist, screenwriter, and film-director Rupert Hughes.

At a young age, Hughes showed interest in science and technology. In particular, he had great engineering aptitude and built Houston's first "wireless" radio transmitter at age 11. He went on to be one of the first licensed ham-radio operators in Houston, having the assigned callsign W5CY (originally 5CY). At 12, Hughes was photographed in the local newspaper, identified as the first boy in Houston to have a "motorized" bicycle, which he had built from parts from his father's steam engine. He was an indifferent student, with a liking for mathematics, flying, and mechanics. He took his first flying lesson at 14, and attended Fessenden School in Massachusetts in 1921.

After a brief stint at The Thacher School, Hughes attended math and aeronautical engineering courses at Caltech. The red-brick house where Hughes lived as a teenager at 3921 Yoakum Blvd., Houston, still stands, now on the grounds of the University of St. Thomas.

His mother Allene died in March 1922 from complications of an ectopic pregnancy. Howard Hughes Sr. died of a heart attack in 1924. Their deaths apparently inspired Hughes to include the establishment of a medical research laboratory in the will that he signed in 1925 at age 19. Howard Sr.'s will had not been updated since Allene's death, and Hughes inherited 75% of the family fortune. On his 19th birthday, Hughes was declared an emancipated minor, enabling him to take full control of his life.

From a young age, Hughes became a proficient and enthusiastic golfer. He often scored near-par figures, played the game to a two-three handicap during his 20s, and for a time aimed for a professional golf career. He golfed frequently with top players, including Gene Sarazen. Hughes rarely played competitively and gradually gave up his passion for the sport to pursue other interests. Hughes used to play golf every afternoon at LA courses including the Lakeside Golf Club, Wilshire Country Club, or the Bel-Air Country Club. Partners included George Von Elm or Ozzie Carlton. After Hughes hurt himself in the late 1920s, his golfing tapered off, and after his F-11 crash, Hughes was unable to play at all.

Hughes withdrew from Rice University shortly after his father's death. On June 1, 1925, he married Ella Botts Rice, daughter of David Rice and Martha Lawson Botts of Houston, and great-niece of William Marsh Rice, for whom Rice University was named. They moved to Los Angeles, where he hoped to make a name for himself as a filmmaker.

They moved into the Ambassador Hotel, and Hughes proceeded to learn to fly a Waco, while simultaneously producing his first motion picture, "Swell Hogan".

Hughes enjoyed a highly successful business career beyond engineering, aviation, and filmmaking; many of his career endeavors involved varying entrepreneurial roles. The Summa Corporation was the name adopted for the business interests of Howard Hughes after he sold the tool division of Hughes Tool Company in 1972. The company served as the principal holding company for Hughes' business ventures and investments. Though primarily involved in the aerospace and defense, electronics, mass-media, manufacturing, and hospitality industries, it has also maintained a strong presence in a wide variety of industries including real estate, petroleum-drilling and oilfield services, consulting, entertainment, and engineering. Much of Hughes' fortune later went to philanthropic causes, notably supporting health-care and medical research.

Hughes' first film, "Swell Hogan," directed by Ralph Graves, proved a disaster. His next two films, "Everybody's Acting" (1926) and "Two Arabian Knights" (1927), achieved financial success; the latter won the first Academy Award for Best Director of a comedy picture. "The Racket" (1928) and "The Front Page" (1931) were also nominated for Academy Awards.

Hughes spent $3.5 million to make the flying film "Hell's Angels" (1930). "Hell's Angels" received one Academy Award nomination for Best Cinematography.

He produced another hit, "Scarface" (1932), a production delayed by censors' concern over its violence.

"The Outlaw" premiered in 1943, but was not released nationally until 1946. The film featured Jane Russell, who received considerable attention from industry censors, this time owing to her revealing costumes.

From the 1940s to the late 1950s the Hughes Tool Company ventured into the film industry when it obtained partial ownership of the RKO companies, which included RKO Pictures, RKO Studios, a chain of movie theaters known as RKO Theatres and a network of radio stations known as the RKO Radio Network.

In 1948 Hughes gained control of RKO, a struggling major Hollywood studio, by acquiring the 929,000 shares owned by Floyd Odlum's Atlas Corporation, for $8,825,000. Within weeks of acquiring the studio, Hughes dismissed 700 employees. Production dwindled to 9 pictures during the first year of Hughes' control; previously RKO had averaged 30 per year.

Production shut down for six months, during which time investigations were conducted of each employee who remained with RKO as far as their political leanings were concerned. Only after ensuring that the stars under contract to RKO had no suspect affiliations would Hughes approve completed pictures to be sent back for re-shooting. This was especially true of the women under contract to RKO at that time. If Hughes felt that his stars did not properly represent the political views of his liking or if a film's anti-communist politics were not sufficiently clear, he pulled the plug. In 1952 an abortive sale to a Chicago-based group connected to the mafia with no experience in the industry disrupted studio operations at RKO even further.

In 1953 Hughes became involved with a high-profile lawsuit as part of the settlement of the "United States v. Paramount Pictures, Inc." Antitrust Case. As a result of the hearings, the shaky status of RKO became increasingly apparent. A steady stream of lawsuits from RKO's minority shareholders had grown to become extremely annoying to Hughes. They had accused him of financial misconduct and corporate mismanagement. Since Hughes wanted to focus primarily on his aircraft manufacturing and TWA holdings during the years of the Korean War of 1950 to 1953, Hughes offered to buy out all other stockholders in order to dispense with their distractions.

By the end of 1954, Hughes had gained near-total control of RKO at a cost of nearly $24 million, becoming the first sole owner of a major Hollywood studio since the silent-film era. Six months later Hughes sold the studio to the General Tire and Rubber Company for $25 million. Hughes retained the rights to pictures that he had personally produced, including those made at RKO. He also retained Jane Russell's contract. For Howard Hughes, this was the virtual end of his 25-year involvement in the motion-picture industry. However, his reputation as a financial wizard emerged unscathed. During that time-period, RKO became known as the home of classic "film noir" productions - thanks in part to the limited budgets required to make such films during Hughes' tenure. Hughes reportedly walked away from RKO having made $6.5 million in personal profit. According to Noah Dietrich, Hughes made a $10,000,000 profit from the sale of the theaters, and made a profit of $1,000,000 from his 7-year ownership of RKO.

According to Noah Dietrich, "Land became a principal asset for the Hughes empire". Hughes acquired 1200 acres in Culver City for Hughes Aircraft, bought 7 sections [4,480 acres] in Tucson for his Falcon missile-plant, and purchased 25,000 acres near Las Vegas. In 1968, the Hughes Tool Company purchased the North Las Vegas Air Terminal.

Originally known as Summa Corporation, the Howard Hughes Corporation formed in 1972 when the oil-tools business of Hughes Tool Company, then owned by Howard Hughes Jr., floated on the New York Stock Exchange under the "Hughes Tool" name. This forced the remaining businesses of the "original" Hughes Tool to adopt a new corporate name: "Summa". The name "Summa"Latin for "highest"was adopted without the approval of Hughes himself, who preferred to keep his own name on the business, and suggested "HRH Properties" (for Hughes Resorts and Hotels, and also his own initials). In 1988 Summa announced plans for Summerlin, a master-planned community named for the paternal grandmother of Howard Hughes, Jean Amelia Summerlin.

Initially staying in the Desert Inn, Hughes refused to vacate his room, and instead decided to purchase the entire hotel. Hughes extended his financial empire to include Las Vegas real-estate, hotels, and media outlets, spending an estimated $300 million, and using his considerable powers to take-over many of the well-known hotels, especially the venues connected with organized crime. He quickly became one of the most powerful men in Las Vegas. He was instrumental in changing the image of Las Vegas from its Wild West roots into a more refined cosmopolitan city. In addition to the Desert Inn, Hughes would eventually own the Sands, Frontier, Silver Slipper, Castaways and Landmark and Harold's Club in Reno. Hughes would eventually become the largest employer in Nevada.

Another portion of Hughes' commercial interests involved aviation, airlines, and the aerospace and defense industries. A lifelong aircraft enthusiast and pilot, Hughes survived four airplane accidents: one in a Thomas-Morse Scout while filming "Hell's Angels", one while setting the airspeed record in the Hughes Racer, one at Lake Mead in 1943, and the near fatal crash of the Hughes XF-11 in 1946. At Rogers Airport in Los Angeles he learned to fly from pioneer aviators, including Moye Stephens and J.B. Alexander. He set many world records and commissioned the construction of custom aircraft for himself while heading Hughes Aircraft at the airport in Glendale, CA. Operating from there, the most technologically important aircraft he commissioned was the Hughes H-1 Racer. On September 13, 1935, Hughes, flying the H-1, set the landplane airspeed record of over his test course near Santa Ana, California (Giuseppe Motta reached 362 mph in 1929 and George Stainforth reached 407.5 mph in 1931, both in seaplanes). This marked the last time in history that an aircraft built by a private individual set the world airspeed record. A year and a half later, on January 19, 1937, flying the same H-1 Racer fitted with longer wings, Hughes set a new transcontinental airspeed record by flying non-stop from Los Angeles to Newark in seven hours, 28 minutes, and 25 seconds (beating his own previous record of nine hours, 27 minutes). His average ground-speed over the flight was .

The H-1 Racer featured a number of design innovations: it had retractable landing gear (as Boeing Monomail had five years before), and all rivets and joints set flush into the body of the aircraft to reduce drag. The H-1 Racer is thought to have influenced the design of a number of World War II fighters such as the Mitsubishi A6M Zero, Focke-Wulf Fw 190, and F8F Bearcat, although that has never been reliably confirmed. The H-1 Racer was donated to the Smithsonian.

On July 14, 1938, Hughes set another record by completing a flight around the world in just 91 hours (three days, 19 hours, 17 minutes), beating the previous record set in 1933 by Wiley Post in a single-engine Lockheed Vega by almost four days. Hughes returned home ahead of photographs of his flight. Taking off from New York City, Hughes continued to Paris, Moscow, Omsk, Yakutsk,  Fairbanks, and Minneapolis, then returning to New York City. For this flight he flew a  Lockheed 14 Super Electra (NX18973, a twin-engine transport with a four-man crew) fitted with the latest radio- and navigational-equipment. Harry Connor was the co-pilot, Thomas Thurlow the navigator, Richard Stoddart the engineer, and Ed Lund the mechanic. Hughes wanted the flight to be a triumph of American aviation technology, illustrating that safe, long-distance air travel was possible. Albert Lodwick of Mystic, Iowa provided organizational skills as the flight operations manager. While Hughes had previously been relatively obscure despite his wealth, being better known for dating Katharine Hepburn, New York City now gave him a ticker-tape parade in the Canyon of Heroes.. Hughes and his crew were awarded the 1938 Collier Trophy for flying around the world in record time. He was awarded the Harmon Trophy in 1936and 1938 for the record breaking global circumnavigation. 

In 1938 the William P. Hobby Airport in Houston, Texas—known at the time as Houston Municipal Airport—was renamed after Hughes, but the name was changed back after people objected to naming the airport after a living person.
Hughes also had a role in the design and financing of both the Boeing 307 Stratoliner and Lockheed L-049 Constellation.

Other aviator awards include: the Bibesco Cup of the Fédération Aéronautique Internationale in 1938, the Octave Chanute Award in 1940, and a special Congressional Gold Medal in 1939 "in recognition of the achievements of Howard Hughes in advancing the science of aviation and thus bringing great credit to his country throughout the world".

President Harry S. Truman sent the Congressional medal to Hughes after the F-11 crash. After his around-the-world flight, Hughes had declined to go to the White House to collect it.

The Hughes D-2 was conceived in 1939 as a bomber with five crew members, powered by 42-cylinder Wright R-2160 Tornado engines. In the end it appeared as two-seat fighter-reconnaissance aircraft designated the D-2A, powered by two Pratt & Whitney R-2800-49 engines. The aircraft was constructed using the Duramold process. The prototype was brought to Harper's Dry Lake in California in great secrecy in 1943, and first flew on June 20 of that year. Acting on a recommendation of the president's son, Colonel Elliott Roosevelt, who had become friends with Hughes, in September 1943 the USAAF ordered 100 of a reconnaissance development of the D-2, known as the F-11. Hughes then attempted to get the military to pay for the development of the D-2. In November 1944, the hangar containing the D-2A was reportedly hit by lightning and the aircraft was destroyed. The D-2 design was abandoned, but led to the extremely controversial Hughes XF-11. The XF-11 was a large, all-metal, two-seat reconnaissance aircraft, powered by two Pratt & Whitney R-4360-31 engines, each driving a set of contra-rotating propellers. Only two prototypes were completed; the second one with a single propeller per side.

In the spring of 1943 Hughes spent nearly a month in Las Vegas, test-flying his Sikorsky S-43 amphibian aircraft, practising touch-and-go landings on Lake Mead in preparation for flying the H-4 Hercules. The weather conditions at the lake during the day were ideal and he enjoyed Las Vegas at night. On May 17, 1943, Hughes flew the Sikorsky from California, carrying two CAA aviation inspectors, two of his employees, and actress Ava Gardner. Hughes dropped Gardner off in Las Vegas and proceeded to Lake Mead to conduct qualifying tests in the S-43. The test flight did not go well. The Sikorsky crashed into Lake Mead, killing CAA inspector Ceco Cline and Hughes' employee Richard Felt. Hughes suffered a severe gash on the top of his head when he hit the upper control panel and had to be rescued by one of the others on board. Hughes paid divers $100,000 to raise the aircraft and later spent more than $500,000 restoring it. Hughes sent the plane to Houston, where it remained for many years.

Hughes was involved in another near-fatal aircraft accident on July 7, 1946, while performing the first flight of the prototype U.S. Army Air Forces reconnaissance aircraft, the XF-11, near Hughes airfield at Culver City, California. An oil leak caused one of the contra-rotating propellers to reverse pitch, causing the aircraft to yaw sharply and lose altitude rapidly. Hughes attempted to save the aircraft by landing it at the Los Angeles Country Club golf course, but just seconds before reaching the course, the XF-11 started to drop dramatically and crashed in the Beverly Hills neighborhood surrounding the country club.

When the XF-11 finally came to a halt after destroying three houses, the fuel tanks exploded, setting fire to the aircraft and a nearby home at 808 North Whittier Drive owned by Lt Col. Charles E. Meyer. Hughes managed to pull himself out of the flaming wreckage but lay beside the aircraft until rescued by Marine Master Sgt. William L. Durkin, who happened to be in the area visiting friends. Hughes sustained significant injuries in the crash, including a crushed collar bone, multiple cracked ribs, crushed chest with collapsed left lung, shifting his heart to the right side of the chest cavity, and numerous third-degree burns. An oft-told story said that Hughes sent a check to the Marine weekly for the remainder of his life as a sign of gratitude. However, Durkin's daughter denied knowing that he received any money from his rescue of Hughes. Yet Noah Dietrich asserts that Hughes did send Durkin $200 a month.

Despite his physical injuries, Hughes took pride that his mind was still working. As he lay in his hospital bed, he decided that he did not like the bed's design. He called in plant engineers to design a customized bed, equipped with hot and cold running water, built in six sections, and operated by 30 electric motors, with push-button adjustments. Hughes designed the hospital bed specifically to alleviate the pain caused by moving with severe burn injuries. Although he never used the bed that he designed, Hughes' bed served as a prototype for the modern hospital bed. Hughes' doctors considered his recovery almost miraculous.

Many attribute his long-term dependence on opiates to his use of codeine as a painkiller during his convalescence. Yet Dietrich asserts that Hughes recovered the "hard way - no sleeping pills, no opiates of any kind". The trademark mustache he wore afterward hid a scar on his upper lip resulting from the accident.

The War Production Board (not the military) originally contracted with Henry Kaiser and Hughes to produce the gigantic HK-1 Hercules flying-boat for use during World War II to transport troops and equipment across the Atlantic as an alternative to seagoing troop-transport ships that were vulnerable to German U-boats. The military services opposed the project, thinking it would siphon resources from higher-priority programs, but Hughes' powerful allies in Washington, D.C. advocated for it. After disputes, Kaiser withdrew from the project and Hughes elected to continue it as the H-4 Hercules. However, the aircraft was not completed until after the end of World War II.

The Hercules was the world's largest flying boat, the largest aircraft made from wood, and, at , had the longest wingspan of any aircraft (the next-largest wingspan was about ). (The Hercules is no longer the longest nor heaviest aircraft ever built - surpassed by the Antonov An-225 "Mriya" produced in 1985.)

The Hercules flew only once for one mile (1.6 km), and above the water, with Hughes at the controls, on November 2, 1947.

Critics nicknamed the Hercules the "Spruce Goose", but it was actually made largely from birch (not spruce) rather than from aluminum, because the contract required that Hughes build the aircraft of "non-strategic materials". It was built in Hughes' Westchester, California, facility. In 1947, Howard Hughes was summoned to testify before the Senate War Investigating Committee to explain why the H-4 development had been so troubled, and why $22 million had produced only two prototypes of the XF-11. General Elliott Roosevelt and numerous other USAAF officers were also called to testify in hearings that transfixed the nation during August and November 1947. In hotly-disputed testimony over TWA's route awards and malfeasance in the defense-acquisition process, Hughes turned the tables on his main interlocutor, Maine Senator Owen Brewster, and the hearings were widely interpreted as a Hughes victory. After being displayed at the harbor of Long Beach, California, the Hercules was moved to McMinnville, Oregon, where it features at the Evergreen Aviation & Space Museum.

On November 4, 2017, the 70th anniversary of the only flight of the H-4 Hercules was celebrated at the Evergreen Aviation & Space Museum with Hughes' paternal cousin Michael Wesley Summerlin and Brian Palmer Evans, son of Hughes radio-technology pioneer Dave Evans, taking their positions in the recreation of a photo that was previously taken of Hughes, Dave Evans and Joe Petrali on board the H-4 Hercules.

In 1932 Hughes founded the Hughes Aircraft Company, a division of Hughes Tool Company, in a rented corner of a Lockheed Aircraft Corporation hangar in Burbank, California, to build the H-1 racer.

Shortly after founding the company, Hughes used the alias "Charles Howard" to accept a job as a baggage handler for American Airlines. He was soon promoted to co-pilot.
Hughes continued to work for American Airlines until his real identity was discovered.

During and after World War II Hughes fashioned his company into a major defense-contractor. The Hughes Helicopters division started in 1947 when helicopter manufacturer Kellett sold their latest design to Hughes for production. Hughes Aircraft became a major American aerospace- and defense-contractor, manufacturing numerous technology-related products that included spacecraft vehicles, military aircraft, radar systems, electro-optical systems, the first working laser, aircraft computer systems, missile systems, ion-propulsion engines (for space travel), commercial satellites, and other electronics systems.

In 1948 Hughes created a new division of Hughes Aircraft: the Hughes Aerospace Group. The Hughes Space and Communications Group and the Hughes Space Systems Division were later spun off in 1948 to form their own divisions and ultimately became the Hughes Space and Communications Company in 1961. In 1953 Howard Hughes gave all his stock in the Hughes Aircraft Company to the newly-formed Howard Hughes Medical Institute, thereby turning the aerospace and defense contractor into a tax-exempt charitable organization. The Howard Hughes Medical Institute sold Hughes Aircraft in 1985 to General Motors for $5.2 billion. In 1997 General Motors sold Hughes Aircraft to Raytheon and in 2000, sold Hughes Space & Communications to Boeing. A combination of Boeing, GM, and Raytheon acquired the Hughes Research Laboratories, which focused on advanced developments in microelectronics, information & systems sciences, materials, sensors, and photonics; their work-space spans from basic research to product delivery. It has particularly emphasized capabilities in high-performance integrated-circuits, high-power lasers, antennas, networking, and smart materials.

In 1939, at the urging of Jack Frye, president of Transcontinental & Western Airlines, the predecessor of Trans World Airlines (TWA), Hughes began to quietly purchase a majority share of TWA stock; he took a controlling interest in the airline by 1944. Although he never had an official position with TWA, Hughes handpicked the board of directors, which included Noah Dietrich, and often issued orders directly to airline staff. Hughes Tool Co. purchased the first 6 Stratoliners Boeing manufactured. Hughes used one personally, and the other 5 he let TWA operate.

Hughes is commonly credited as the driving force behind the Lockheed Constellation airliner, which Hughes and Frye ordered in 1939 as a long-range replacement for TWA's fleet of Boeing 307 Stratoliners. Hughes personally financed TWA's acquisition of 40 Constellations for $18 million, the largest aircraft-order in history up to that time. The Constellations were among the highest-performing commercial aircraft of the late 1940s and 1950s, and allowed TWA to pioneer nonstop transcontinental service. During World War II Hughes leveraged political connections in Washington to obtain rights for TWA to serve Europe, making it the only U.S. carrier with a combination of domestic and transatlantic routes.

After the announcement of the Boeing 707, Hughes opted to pursue a more advanced jet aircraft for TWA and approached Convair in late 1954. Convair proposed two concepts to Hughes, but Hughes was unable to decide which concept to adopt, and Convair eventually abandoned its initial jet project after the mockups of the 707 and Douglas DC-8 were unveiled. Even after competitors such as United Airlines, American Airlines and Pan American World Airways had placed large orders for the 707, Hughes only placed eight orders for 707s through the Hughes Tool Company and forbade TWA from using the aircraft. After finally beginning to reserve 707 orders in 1956, Hughes embarked on a plan to build his own "superior" jet aircraft for TWA, applied for CAB permission to sell Hughes aircraft to TWA, and began negotiations with the state of Florida to build a manufacturing plant there. However, he abandoned this plan around 1958, and in the interim, negotiated new contracts for 707 and Convair 880 aircraft and engines totaling $400 million.

The financing of TWA's jet orders precipitated the end of Hughes' relationship with Noah Dietrich, and ultimately Hughes's ouster from control of TWA. Hughes did not have enough cash on hand or future cash flow to pay for the orders, and did not immediately seek bank financing. Hughes's refusal to heed Dietrich's financing advice led to a major rift between the two by the end of 1956. Hughes believed that Dietrich wished to have Hughes committed as mentally incompetent, although the evidence of this is inconclusive. Dietrich resigned by telephone in May 1957 after repeated requests for stock options, which Hughes refused to grant, and with no further progress on the jet financing. As Hughes's mental state worsened, he ordered various tactics to delay payments to Boeing and Convair; his behavior led TWA's banks to insist that he be removed from management as a condition for further financing.

In 1960, Hughes was ultimately forced out of management of TWA, although he continued to own 78% of the company. In 1961, TWA filed suit against Hughes Tool Company, claiming that the latter had violated antitrust law by using TWA as a captive market for aircraft trading. The claim was largely dependent upon obtaining testimony from Hughes himself. Hughes went into hiding and refused to testify. A default judgment was issued against Hughes Tool Company for $135 million in 1963, but was overturned by the Supreme Court of the United States in 1973, on the basis that Hughes was immune from prosecution. In 1966, Hughes was forced to sell his TWA shares. The sale of his TWA shares brought Hughes $546,549,771.

Hughes acquired control of Boston-based Northeast Airlines in 1962. However, the airline's lucrative route authority between major northeastern cities and Miami was terminated by a CAB decision around the time of the acquisition, and Hughes sold control of the company to a trustee in 1964. Northeast went on to merge with Delta Air Lines in 1972.

In 1970, Hughes acquired San Francisco-based Air West and renamed it Hughes Airwest. Air West had been formed in 1968 by the merger of Bonanza Air Lines, Pacific Air Lines, and West Coast Airlines, all of which operated in the western U.S. By the late 1970s, Hughes Airwest operated an all-jet fleet of Boeing 727-200, Douglas DC-9-10, and McDonnell Douglas DC-9-30 jetliners serving an extensive route network in the western U.S. with flights to Mexico and western Canada as well. By 1980, the airline's route system reached as far east as Houston (Hobby Airport) and Milwaukee with a total of 42 destinations being served. Hughes Airwest was then acquired by and merged into Republic Airlines (1979–1986) in late 1980. Republic was subsequently acquired by and merged into Northwest Airlines which in turn was ultimately merged into Delta Air Lines in 2008.

Hughes had made numerous business partnerships through industrialist and producer, David Charnay. Their friendship and many partnerships began with the film "The Conqueror", which was first released to the public in 1956. The film caused many controversies due to its critical flop and radioactive location used in St. George, Utah that eventually led to Hughes buying up nearly every copy of the film he could, only to watch the film at home repeatedly for many nights in a row. Charnay later bought Four Star, the film and television production company that produced "The Conqueror." Hughes and Charnay's most published dealings were with a contested AirWest leveraged buyout (LBO). Charnay led the LBO buyout group that involved Howard Hughes and their partners acquiring Air West. Hughes, Charnay, as well as three others were indicted. The complexity of this LBO was the first of its kind. The indictment, made by U.S. Attorney DeVoe Heaton, accused the group of conspiring to drive down the stock price of Air West in order to pressure company directors to sell to Hughes. The charges were dismissed after a judge had determined that the indictment had failed to allege an illegal action on the part of Hughes, Charnay, and all the other accused in the indictment. Thompson, the federal judge that made the decision to dismiss the charges called the indictment one of the worst claims that he had ever seen. The charges were filed again, a second time, by U.S. Attorney DeVoe Heaton's assistant, Dean Vernon. The Federal Judge ruled on November 13, 1974 and elaborated to say that the case suggested a "reprehensible misuse of the power of great wealth", but in his judicial opinion, "no crime had been committed." The aftermath of the Air West deal was later settled with the SEC by paying former stockholders for alleged losses from the sale of their investment in Air West stock. As noted above, Air West was subsequently renamed Hughes Airwest. During a long pause between the years of the dismissed charges against Hughes, Charnay, and their partners, Howard Hughes mysteriously died mid-flight while on the way to Houston from Acapulco. No further attempts were made to file any indictments after Hughes died.

In 1953, Hughes launched the Howard Hughes Medical Institute in Miami, Florida (currently located in Chevy Chase, Maryland) with the expressed goal of basic biomedical research, including trying to understand, in Hughes' words, the "genesis of life itself", due to his lifelong interest in science and technology. Hughes' first will, which he signed in 1925 at the age of 19, stipulated that a portion of his estate should be used to create a medical institute bearing his name. When a major battle with the IRS loomed ahead, Hughes gave all his stock in the Hughes Aircraft Company to the Institute, thereby turning the aerospace and defense contractor into a for-profit entity of a fully tax-exempt charity. Hughes' internist, Verne Mason, who treated Hughes after his 1946 aircraft crash, was chairman of the Institute's medical advisory committee. The Howard Hughes Medical Institute's new board of trustees sold Hughes Aircraft in 1985 to General Motors for $5.2 billion, allowing the Institute to grow dramatically.

In 1954, Hughes transferred Hughes Aircraft to the foundation, which paid Hughes Tool Co. $18,000,000 for the assets. The foundation leased the land from Hughes Tool Co., which then subleased it to Hughes Aircraft Corp. The difference in rent, $2,000,000 per year, became the foundation's working capital.

The deal was the topic of a protracted legal battle between Hughes and the Internal Revenue Service, which Hughes ultimately won. After his death in 1976, many thought that the balance of Hughes' estate would go to the Institute, although it was ultimately divided among his cousins and other heirs, given the lack of a will to the contrary. The HHMI was the fourth largest private organization and one of the largest devoted to biological and medical research, with an endowment of $20.4 billion .

In 1972, during the cold war era, Hughes was approached by the CIA through his longtime partner, David Charnay, to help secretly recover the Soviet submarine K-129, which had sunk near Hawaii four years earlier. Hughes' involvement provided the CIA with a plausible cover story, conducting expensive civilian marine research at extreme depths and the mining of undersea manganese nodules. The recovery plan used the special-purpose salvage vessel "Glomar Explorer". In the summer of 1974, "Glomar Explorer" attempted to raise the Soviet vessel. However, during the recovery a mechanical failure in the ship's grapple caused half of the submarine to break off and fall to the ocean floor. This section is believed to have held many of the most sought-after items, including its code book and nuclear missiles. Two nuclear-tipped torpedoes and some cryptographic machines were recovered, along with the bodies of six Soviet submariners who were subsequently given formal burial at sea in a filmed ceremony. The operation, known as Project Azorian (but incorrectly referred to by the press as Project Jennifer), became public in February 1975 after secret documents were released, obtained by burglars of Hughes' headquarters in June 1974. Although he lent his name and his company's resources to the operation, Hughes and his companies had no operational involvement in the project. The "Glomar Explorer" was eventually acquired by Transocean and was sent to the scrap yard in 2015 during a large decline in oil prices.

In 1929, Hughes' wife, Ella, returned to Houston and filed for divorce. Hughes dated many famous women, including Billie Dove, Faith Domergue, Bette Davis, Ava Gardner, Olivia de Havilland, Katharine Hepburn, Hedy Lamarr, Ginger Rogers, Janet Leigh, Rita Hayworth, Mamie Van Doren and Gene Tierney. He also proposed to Joan Fontaine several times, according to her autobiography "No Bed of Roses". Jean Harlow accompanied him to the premiere of "Hell's Angels", but Noah Dietrich wrote many years later that the relationship was strictly professional, as Hughes apparently disliked Harlow personally. In his 1971 book, "Howard: The Amazing Mr. Hughes", Dietrich said that Hughes genuinely liked and respected Jane Russell, but never sought romantic involvement with her. According to Russell's autobiography, however, Hughes once tried to bed her after a party. Russell (who was married at the time) refused him, and Hughes promised it would never happen again. The two maintained a professional and private friendship for many years. Hughes remained good friends with Tierney who, after his failed attempts to seduce her, was quoted as saying "I don't think Howard could love anything that did not have a motor in it." Later, when Tierney's daughter Daria was born deaf and blind and with a severe learning disability because of Tierney's being exposed to rubella during her pregnancy, Hughes saw to it that Daria received the best medical care and paid all expenses.

In 1933, Hughes made a purchase of an unseen luxury steam yacht named the "Rover", which was previously owned by British shipping magnate Lord Inchcape. "I have never seen the "Rover" but bought it on the blueprints, photographs and the reports of Lloyd's surveyors. My experience is that the English are the most honest race in the world." Hughes renamed the yacht "Southern Cross" and later sold her to Swedish entrepreneur Axel Wenner-Gren.

On July 11, 1936, Hughes struck and killed a pedestrian named Gabriel S. Meyer with his car at the corner of 3rd Street and Lorraine in Los Angeles. After the crash, Hughes was taken to the hospital and certified as sober, but an attending doctor made a note that Hughes had been drinking. A witness to the crash told police that Hughes was driving erratically and too fast, and that Meyer had been standing in the safety zone of a streetcar stop. Hughes was booked on suspicion of negligent homicide and held overnight in jail until his attorney, Neil S. McCarthy, obtained a writ of habeas corpus for his release pending a coroner's inquest. By the time of the coroner's inquiry, however, the witness had changed his story and claimed that Meyer had moved directly in front of Hughes' car. Nancy Bayly (Watts), who was in the car with Hughes at the time of the crash, corroborated this version of the story. On July 16, 1936, Hughes was held blameless by a coroner's jury at the inquest into Meyer's death. Hughes told reporters outside the inquiry, "I was driving slowly and a man stepped out of the darkness in front of me."

On January 12, 1957, Hughes married actress Jean Peters at a small hotel in Tonopah, Nevada. The couple met in the 1940s, before Peters became a film actress. They had a highly publicized romance in 1947 and there was talk of marriage, but she said she could not combine it with her career. Some later claimed that Peters was "the only woman [Hughes] ever loved," and he reportedly had his security officers follow her everywhere even when they were not in a relationship. Such reports were confirmed by actor Max Showalter, who became a close friend of Peters while shooting "Niagara" (1953). Showalter told in an interview that because he frequently met with Peters, Hughes' men threatened to ruin his career if he did not leave her alone.

Shortly before the 1960 Presidential election, Richard Nixon was alarmed when it was revealed that his brother, Donald, received a $205,000 loan from Hughes. It has long been speculated that Nixon's drive to learn what the Democrats were planning in 1972 was based in part on his belief that the Democrats knew about a later bribe that his friend Bebe Rebozo had received from Hughes after Nixon took office.

In late 1971, Donald Nixon was collecting intelligence for his brother in preparation for the upcoming presidential election. One of his sources was John H. Meier, a former business adviser of Hughes who had also worked with Democratic National Committee Chairman Larry O'Brien.

Meier, in collaboration with former Vice President Hubert Humphrey and others, wanted to feed misinformation to the Nixon campaign. Meier told Donald that he was sure the Democrats would win the election because Larry O'Brien had a great deal of information on Richard Nixon's illicit dealings with Howard Hughes that had never been released; O'Brien did not actually have any such information, but Meier wanted Nixon to think he did. Donald told his brother that O'Brien was in possession of damaging Hughes information that could destroy his campaign. Terry Lenzner, who was the chief investigator for the Senate Watergate Committee, speculates that it was Nixon's desire to know what O'Brien knew about Nixon's dealings with Hughes that may have partially motivated the Watergate break-in.

Hughes was widely considered eccentric, and suffered from severe obsessive-compulsive disorder (OCD).

Dietrich wrote that Hughes always ate the same thing for dinner, a New York strip steak cooked medium rare, dinner salad, and peas, but only the smaller ones, pushing the larger ones aside. For breakfast, Hughes wanted his eggs cooked the way his family cook, Lily, made them. Hughes had a "phobia about germs", and "his passion for secrecy became a mania."

While directing "The Outlaw", Hughes became fixated on a small flaw in one of Jane Russell's blouses, claiming that the fabric bunched up along a seam and gave the appearance of two nipples on each breast. He wrote a detailed memorandum to the crew on how to fix the problem. Richard Fleischer, who directed "His Kind of Woman" with Hughes as executive producer, wrote at length in his autobiography about the difficulty of dealing with the tycoon. In his book, "Just Tell Me When to Cry", Fleischer explained that Hughes was fixated on trivial details and was alternately indecisive and obstinate. He also revealed that Hughes' unpredictable mood swings made him wonder if the film would ever be completed.

In 1958, Hughes told his aides that he wanted to screen some movies at a film studio near his home. He stayed in the studio's darkened screening room for more than four months, never leaving. He ate only chocolate bars and chicken and drank only milk, and was surrounded by dozens of Kleenex boxes that he continuously stacked and re-arranged. He wrote detailed memos to his aides giving them explicit instructions neither to look at him nor speak to him unless spoken to. Throughout this period, Hughes sat fixated in his chair, often naked, continually watching movies. When he finally emerged in the summer of 1958, his hygiene was terrible. He had neither bathed nor cut his hair and nails for weeks; this may have been due to allodynia, which results in a pain response to stimuli that would normally not cause pain.

After the screening room incident, Hughes moved into a bungalow at the Beverly Hills Hotel where he also rented rooms for his aides, his wife, and numerous girlfriends. He would sit naked in his bedroom with a pink hotel napkin placed over his genitals, watching movies. This may have been because Hughes found the touch of clothing painful due to allodynia. He may have watched movies to distract himself from his pain—a common practice among patients with intractable pain, especially those who do not receive adequate treatment. In one year, Hughes spent an estimated $11 million at the hotel.

Hughes began purchasing restaurant chains and four-star hotels that had been founded within the state of Texas. This included, if for only a short period, many unknown franchises currently out of business. He placed ownership of the restaurants with the Howard Hughes Medical Institute, and all licenses were resold shortly after.

Another time, he became obsessed with the 1968 film "Ice Station Zebra", and had it run on a continuous loop in his home. According to his aides, he watched it 150 times. Feeling guilty about the commercial, critical, and literal toxicity of his film "The Conqueror", he bought every copy of the film for $12 million, watching the film on repeat. Paramount Pictures acquired the rights of the film in 1979, 3 years after his death.

Hughes insisted on using tissues to pick up objects to insulate himself from germs. He would also notice dust, stains, or other imperfections on people's clothes and demand that they take care of them. Once one of the most visible men in America, Hughes ultimately vanished from public view, although tabloids continued to follow rumors of his behavior and whereabouts. He was reported to be terminally ill, mentally unstable, or even dead.

Injuries from numerous aircraft crashes caused Hughes to spend much of his later life in pain, and he eventually became addicted to codeine, which he injected intramuscularly. Hughes had his hair cut and nails trimmed only once a year, likely due to the pain caused by the RSD/CRPS, which was caused by the plane crashes. He also stored his urine in bottles.

The wealthy and aging Hughes, accompanied by his entourage of personal aides, began moving from one hotel to another, always taking up residence in the top floor penthouse. In the last ten years of his life, 1966 to 1976, Hughes lived in hotels in many cities—including Beverly Hills, Boston, Las Vegas, Nassau, Freeport, and Vancouver.

On November 24, 1966 (Thanksgiving Day), Hughes arrived in Las Vegas by railroad car and moved into the Desert Inn. Because he refused to leave the hotel and to avoid further conflicts with the owners, Hughes bought the Desert Inn in early 1967. The hotel's eighth floor became the nerve center of Hughes' empire and the ninth-floor penthouse became his personal residence. Between 1966 and 1968, he bought several other hotel-casinos, including the Castaways, New Frontier, the Landmark Hotel and Casino, and the Sands. He bought the small Silver Slipper casino for the sole purpose of moving its trademark neon silver slipper; visible from Hughes' bedroom, as it had apparently kept him awake at night.

After Hughes left the Desert Inn, hotel employees discovered that his drapes had not been opened during the time he lived there and had rotted through.

Hughes wanted to change the image of Las Vegas to something more glamorous. He wrote in a memo to an aide, "I like to think of Las Vegas in terms of a well-dressed man in a dinner jacket and a beautifully jeweled and furred female getting out of an expensive car." Hughes bought several local television stations (including KLAS-TV).

Hughes' considerable business holdings were overseen by a small panel unofficially dubbed "The Mormon Mafia" because of the many Latter-day Saints on the committee, led by Frank William Gay. In addition to supervising day-to-day business operations and Hughes' health, they also went to great pains to satisfy Hughes' every whim. For example, Hughes once became fond of Baskin-Robbins' banana nut ice cream, so his aides sought to secure a bulk shipment for him, only to discover that Baskin-Robbins had discontinued the flavor. They put in a request for the smallest amount the company could provide for a special order, 350 gallons (1,300 L), and had it shipped from Los Angeles. A few days after the order arrived, Hughes announced he was tired of banana nut and wanted only French vanilla ice cream. The Desert Inn ended up distributing free banana nut ice cream to casino customers for a year. In a 1996 interview, ex–Howard Hughes Chief of Nevada Operations Robert Maheu said, "There is a rumor that there is still some banana nut ice cream left in the freezer. It is most likely true."

As an owner of several major Las Vegas businesses, Hughes wielded much political and economic influence in Nevada and elsewhere. During the 1960s and early 1970s, he disapproved of underground nuclear testing at the Nevada Test Site. Hughes was concerned about the risk from residual nuclear radiation, and attempted to halt the tests. When the tests finally went through despite Hughes' efforts, the detonations were powerful enough that the entire hotel where he was staying trembled due to the shock waves. In two separate, last-ditch maneuvers, Hughes instructed his representatives to offer million-dollar bribes to both Presidents Lyndon B. Johnson and Richard Nixon.

In 1970, Jean Peters filed for divorce. The two had not lived together for many years. Peters requested a lifetime alimony payment of $70,000 a year, adjusted for inflation, and waived all claims to Hughes' estate. Hughes offered her a settlement of over a million dollars, but she declined it. Hughes did not insist on a confidentiality agreement from Peters as a condition of the divorce. Aides reported that Hughes never spoke ill of her. She refused to discuss her life with Hughes and declined several lucrative offers from publishers and biographers. Peters would state only that she had not seen Hughes for several years before their divorce and had dealt with him only by phone.

Hughes was living in the Intercontinental Hotel near Lake Managua in Nicaragua, seeking privacy and security, when a magnitude 6.5 earthquake damaged Managua in December 1972. As a precaution, Hughes moved first to a rather large tent, facing the hotel, then after a few days there to the Nicaraguan National Palace and stayed there as a guest of Anastasio Somoza Debayle before leaving for Florida on a private jet the following day. He subsequently moved into the Penthouse at the Xanadu Princess Resort on Grand Bahama Island, which he had recently purchased. He lived almost exclusively in the penthouse of the Xanadu Beach Resort & Marina for the last four years of his life. 

Hughes spent a total of $300 million on his many properties in Las Vegas.

In 1972, author Clifford Irving caused a media sensation when he claimed he had co-written an authorized autobiography of Hughes. Hughes was so reclusive that he did not immediately publicly refute Irving's statement, leading many to believe the Irving book was genuine. However, before the book's publication, Hughes finally denounced Irving in a teleconference and the entire project was eventually exposed as a hoax. Irving was later convicted of fraud and spent 17 months in prison. In 1974, the Orson Welles film "F for Fake" included a section on the Hughes biography hoax, leaving a question open as to whether it was actually Hughes who took part in the teleconference (since so few people had actually heard or seen him in recent years). In 1977, "The Hoax" by Clifford Irving was published in the United Kingdom, telling his story of these events. The 2006 film "The Hoax", starring Richard Gere, is also based on these events.

Hughes is reported to have died on April 5, 1976, at 1:27 p.m. on board an aircraft, Learjet 24B N855W, owned by Robert Graf and piloted by Jeff Abrams. He was en route from his penthouse at the Acapulco Fairmont Princess Hotel in Mexico to the Methodist Hospital in Houston. 

His reclusiveness and possibly his drug use made him practically unrecognizable. His hair, beard, fingernails, and toenails were long—his tall frame now weighed barely , and the FBI had to use fingerprints to conclusively identify the body. Howard Hughes' alias, John T. Conover, was used when his body arrived at a morgue in Houston on the day of his death.

A subsequent autopsy recorded kidney failure as the cause of death. Hughes was in extremely poor physical condition at the time of his death. He suffered from malnutrition and was covered in bedsores. While his kidneys were damaged, his other internal organs, including his brain, which had no visible damage other than illnesses, were deemed perfectly healthy. X-rays revealed five broken-off hypodermic needles in the flesh of his arms. To inject codeine into his muscles, Hughes had used glass syringes with metal needles that easily became detached.

Hughes is buried next to his parents at Glenwood Cemetery in Houston.

Approximately three weeks after Hughes' death, a handwritten will was found on the desk of an official of The Church of Jesus Christ of Latter-Day Saints in Salt Lake City, Utah. The so-called "Mormon Will" gave $1.56 billion to various charitable organizations (including $625 million to the Howard Hughes Medical Institute), nearly $470 million to the upper management in Hughes' companies and to his aides, $156 million to first cousin William Lummis, and $156 million split equally between his two ex-wives Ella Rice and Jean Peters.

A further $156 million was endowed to a gas-station owner, Melvin Dummar, who told reporters that in 1967, he found a disheveled and dirty man lying along U.S. Route 95, just north of Las Vegas. The man asked for a ride to Vegas. Dropping him off at the Sands Hotel, Dummar said the man told him that he was Hughes. Dummar later claimed that days after Hughes' death a "mysterious man" appeared at his gas station, leaving an envelope containing the will on his desk. Unsure if the will was genuine and unsure of what to do, Dummar left the will at the LDS Church office. In 1978, a Nevada court ruled the Mormon Will a forgery, and officially declared that Hughes had died intestate (without a valid will). Dummar's story was later adapted into Jonathan Demme's film "Melvin and Howard" in 1980.

Hughes' $2.5 billion estate was eventually split in 1983 among 22 cousins, including William Lummis, who serves as a trustee of the Howard Hughes Medical Institute. The Supreme Court of the United States ruled that Hughes Aircraft was owned by the Howard Hughes Medical Institute, which sold it to General Motors in 1985 for $5.2 billion. The court rejected suits by the states of California and Texas that claimed they were owed inheritance tax.

In 1984, Hughes' estate paid an undisclosed amount to Terry Moore, who claimed she and Hughes had secretly married on a yacht in international waters off Mexico in 1949 and never divorced. Moore never produced proof of a marriage, but her book, "The Beauty and the Billionaire," became a bestseller.


The moving image collection of Howard Hughes is held at the Academy Film Archive. The collection consists of over 200 items including 35mm and 16mm elements of feature films, documentaries, and television programs made or accumulated by Hughes.








</doc>
<doc id="14062" url="https://en.wikipedia.org/wiki?curid=14062" title="Hook of Holland">
Hook of Holland

Hook of Holland (, ) is a town in the southwestern corner of Holland (hence the name; "hoek" means "corner"), at the mouth of the New Waterway shipping canal into the North Sea. The town is administered by the municipality of Rotterdam as a district of that city. Its district covers an area of 16.7 km, of which 13.92 km is land. On 1 January 1999 it had an estimated population of 9,400.

Towns near "the Hook" () include Monster, 's-Gravenzande, Naaldwijk and Delft to the northeast, and Maassluis to the southeast. On the other side of the river is the Europort and the Maasvlakte. The wide sandy beach, one section of which is designated for use by naturists, runs for approximately 18 kilometres to Scheveningen and for most of this distance is backed by extensive sand dunes through which there are foot and cycle paths.

On the north side of the New Waterway, to the west of the town, is a pier, part of which is accessible to pedestrians and cyclists.

The Berghaven is a small harbour on the New Waterway where the Rotterdam and Europort pilots are based. This small harbour is only for the use of the pilot service, government vessels and the Hook of Holland lifeboat.

The Hook of Holland area was created as a sandbar in the Meuse estuary, when it became more and more silted after St. Elizabeth's flood of 1421. All kinds of plans were designed to improve the shipping channel to Rotterdam. In 1863 it was finally decided to construct the New Waterway which was dug between 1866 and 1868. The route ran through the Hook of Holland, where a primitive settlement, Old Hook (Oude Hoek - nowadays the Zuidelijk Strandcentrum), was created. Many workers and senior employees of the Rijkswaterstaat settled in Old Hook.

The Hook initially fell under the administrative authority of 's-Gravenzande. An attempt by the inhabitants to transform the place into an independent municipality failed and, on 1 January 1914, Hook of Holland was added to Rotterdam. After the First World War the village started to develop into a seaside resort. It has since been informally known as 'Rotterdam by the sea'.

During World War II, the Hook was one of the most important places for the Wehrmacht to hold because of its harbour, which comprised an important and strategic part of the Atlantic Wall.

Hook of Holland already had a ward council in 1947. Hook of Holland has been a borough since 1973. In 2014 it was replaced by an 'area committee'.

The Schiedam–Hoek van Holland railway is a 24-kilometre branch line from Schiedam Centrum station via Vlaardingen and Maassluis. The final two stations on the line are located within the town. Hoek van Holland Haven, the penultimate station, is close to the town centre, adjacent to the ferry terminal and the small harbour, the Berghaven. Hoek van Holland Strand, the terminus, is closest to the beach.

The railway line opened for service in 1893 and was electrified in 1935. International trains ran from Berlin and Moscow to connect these with London via the ferry service. Services on the line to Rotterdam Centraal station were being operated by NS every half hour during the day until April 2017, when the line was closed for conversion to metro standards. It was reopened in September 2019, as an extension of the Rotterdam Metro. The metro line service from Hoek van Holland does not offer direct connections to Rotterdam Centraal.

Hoek van Holland is also the location of an international ferry terminal, where service to eastern England has operated from since 1893, uninterrupted except for during the two World Wars. Currently, two routes are being operated: one, a day and night freight and passenger service, to Harwich, Essex and the other, a night, freight-only service to North Killingholme Haven, Lincolnshire. The passenger ferry service is operated by Stena Line as part of the Dutchflyer rail-ferry service between Hook van Holland Haven station and Harwich International station in England, from which Greater Anglia provides service to Liverpool Street station in central London.

A local ferry operated by RET links the Hook with the Maasvlakte part of the Port of Rotterdam.

The A20 motorway begins approximately 10 kilometres east of Hoek van Holland near Westerlee, heading east towards Rotterdam and Utrecht. It connects to the A4 heading north towards the Hague and Amsterdam 17 kilometres east of the town.




</doc>
<doc id="14063" url="https://en.wikipedia.org/wiki?curid=14063" title="Hugh Binning">
Hugh Binning

Hugh Binning (1627–1653) was a Scottish philosopher and theologian. He was born in Scotland during the reign of Charles I and was ordained in the (Presbyterian) Church of Scotland. He died in 1653, during the time of Oliver Cromwell and the Commonwealth of England.

Hugh Binning was the son of John Binning of Dalvennan, Straiton.and Margaret M'Kell. Margaret was the daughter of Rev. Matthew M'Kell,
who was a minister in the parish of Bothwell, Scotland, and sister of Hugh M'Kell, a minister in Edinburgh.
Binning was born on his father's estate in Dalvennan, Straiton, in the shire of Ayr. The family owned other lands in the parishes of Straiton and Colmonell as well as Maybole in Carrick. 

A precocious child, Binning was admitted to the study of philosophy at the University of Glasgow at age thirteen. Binning has been described as "an extraordinary instance of precocious learning and genius."

In 1645, James Dalrymple, 1st Viscount of Stair, who was Hugh's master (primary professor) in the study of philosophy, announced he was retiring from the University of Glasgow. Dalrymple was afterward President of the Court of Session, and Viscount Stair. After a national search for a replacement on the faculty, three men were selected to compete for the position. Binning was one of those selected, but was at a disadvantage because of his extreme youth and because he was not of noble birth. However, he had strong support from the existing faculty, who suggested that the candidates speak extemporaneously on any topic of the candidate's choice. After hearing Hugh speak, the other candidates withdrew, making Hugh a regent and professor of philosophy, while he was still 18 years old.

On 7 February 1648, (at the age of 21) Hugh was appointed an Advocate before the Court of Sessions (an attorney). In the same year, he married Barbara Simpson (sometimes called Mary), daughter of Rev. James Simpson a minister in Ireland. Their son, John, was born in 1650.

Binning was called on 25 October 1649. As minister of Govan, he was the successor of Mr. William Wilkie. His ordination took place on the 8th of January 1649, when Mr David Dickson, one of the theological professors at the College of Glasgow, and author of "Therapeutica Sacra", presided. He was ordained in January, at the age of 22, holding his regency until 14 May that year. At that time Govan was a separate town rather than part of Glasgow.

Hugh died around September 1653 and was buried in the churchyard of Govan, where Patrick Gillespie, then principal of the University of Glasgow, ordered a monument inscribed in Latin, roughly translated: 

Hugh's widow, Barbara (sometimes called Mary), then remarried James Gordon, an Anglican priest at Cumber in Ireland. Together they had a daughter,Jean who married Daniel MacKenzie, who was on the winning side of the Battle of Bothwell Bridge serving as an ensign under Lieutenant-Colonel William Ramsay (who became the third Earl of Dalhousie), in the Earl of Mar's Regiment of Foot.

Binning's son, John Binning, married Hanna Keir, who was born in Ireland. The Binnings were Covenanters, a resistance movement that objected to the return of Charles II (who was received into the Catholic Church on his deathbed). They were on the losing side in the 1679 Battle of Bothwell Bridge. Most of the rebels who were not executed were exiled to the Americas; about 30 Covenanters were exiled to the Carolinas on the Carolina Merchant in 1684. After the battle, John and Hanna were separated. 
In the aftermath of the battle at Bothwell Bridge, Binning's widow (now Barbara Gordon) tried to reclaim the family estate at Dalvennan by saying that John and his wife owed his stepfather a considerable some of money. The legal action was successful and Dalvennan became the possession of John's half-sister Jean, and her husband Daniel MacKenzie. In addition, Jean came into possession of Hanna Keir's property in Ireland.

By 1683, Jean was widowed. John Binning was branded a traitor, was sentenced to death and forfeited his property to the Crown. John's wife (Hanna Keir) was branded as a traitor and forfeited her property in Ireland. In 1685, Jean "donated" the Binning family's home at Dalvennan and other properties, along with the Keir properties to Roderick MacKenzie, who was a Scottish advocate of James II (James VII of Scotland), and the baillie of Carrick. According to an act of the Scottish Parliament, Roderick MacKenzie was also very effective in "suppressing the rebellious, fanatical party in the western and other shires of this realm, and putting the laws to vigorous execution against them".

Since Bothwell Bridge, Hanna had been hiding from the authorities. In 1685, Hanna was in Edinburgh where she was found during a sweep for subversives and imprisoned in the Tolbooth of Edinburgh, a combination city hall and prison. Those arrested with Hanna were exiled to North America, however, she developed dysentery and remained behind. By 1687, near death, Hanna petitioned the Privy Council of Scotland for her release; she was exiled to her family in Ireland, where she died around 1692.
In 1690, the Scottish Parliament rescinded John's fines and forfeiture, but he was unable to recover his family's estates, the courts suggesting that he had relinquished his claim to Dalvennan in exchange for forgiveness of debt, rather than forfeiture.

There is little documentation about John after his wife's death. John received a small income from royalties on his father's works after parliament extended copyrights on Binning's writings to him. However, the income was not significant and John made several petitions to the Scottish parliament for money, the last occurring in 1717. It is thought that he died in Somerset county, in southwestern England.

He died of consumption at the age of 26 on September 1653. He was remarkably popular as a preacher, having been considered "the most accomplished philosopher and divine in his time, and styled the Scottish Cicero." He married (cont. 17 May 1650), Mary (who died at Paisley in 1694) and had a son, John of Dalvennan. She was the daughter of Richard Simson, minister of Sprouston. After John's early death Mary married her second husband, James Gordon, minister of Comber, in Ireland. A marble tablet, with an inscription in classical Latin, was erected to his memory by his friend Mr Patrick Gillespie, who was then Principal of the University of Glasgow. It has been placed in the vestibule of the present parish church. The whole of his works are posthumous publications.

He was a follower of James Dalrymple. In later life, he was well known as an evangelical Christian.

Hugh Binning was born two years after Charles I became monarch of England, Ireland, and Scotland. At the time, each was an independent country sharing the same monarch. The Acts of Union 1707 integrated Scotland and England to form the Kingdom of Great Britain, and the Acts of Union 1800 integrated Ireland to form the United Kingdom of Great Britain and Ireland.

The period was dominated by both political and religious strife between the three independent countries. Religious disputes centered on questions such as whether religion was to be dictated by the monarch or was to be the choice of the people, and whether individuals had a direct relationship with God or needed to use an intermediary. Civil disputes centered on debates about the extent of the King's power (a question of the Divine right of kings), and specifically whether the King had the right to raise taxes and armed forces without the consent of the governed. These wars ultimately changed the relationship between king and subjects.

In 1638, the General Assembly of the Church of Scotland voted to remove bishops and the "Book of Common Prayer" that had been introduced by Charles I to impose the Anglican model on the Presbyterian Church of Scotland. Public riots followed, culminating in the Wars of the Three Kingdoms, an interrelated series of conflicts that took place in the three countries. The first conflict, which was also the first of the Bishops' Wars, took place in 1639 and was a single border skirmish between England and Scotland, also known as "the war the armys did not wanted to fight."

To maintain his English power base, Charles I made secret alliances with Catholic Ireland and Presbyterian Scotland to invade Anglican England, promising that each country could establish their own separate state religion. Once these secret entreaties became known to the English Long Parliament, the Congregationalist faction (of which Oliver Cromwell was a primary spokesman) took matters into its own hands and Parliament established an army separate from the King. Charles I was executed in January 1649, which led to the rule of Cromwell and the establishment of the Commonwealth. The conflicts concluded with The English Restoration of the monarchy and the return of Charles II in 1660.

The Act of Classes was passed by the Parliament of Scotland on 23 January 1649; the act banned Royalists (people supporting the monarchy) from holding political or military office. In exile, Charles II signed the Treaty of Breda (1650) with the Scottish Parliament; among other things, the treaty established Presbyterianism as the national religion. Charles was crowned King of Scots at Scone in January 1651. By September 1651, Scotland was annexed by England, its legislative institutions abolished, Presbyterianism dis-established, and Charles was forced into exile in France.

The Scottish Parliament rescinded the Act of Classes in 1651, which produced a split within Scottish Society. The sides of the conflict were called the Resolutioners (who supported the rescission of the act – supported the monarchy and the Scottish House of Stewart) and the Protesters (who supported Cromwell and the Commonwealth); Binning sided with the Protestors. Binning joined the Protesters in 1651. When Cromwell had sent troops to Scotland, he was also attempting to dis-establish Presbyterianism and the Church of Scotland, Binning spoke against Cromwell's act.

On Saturday 19 April 1651, Cromwell entered Glasgow and the next day he heard a sermon by three ministers who condemned him for invading Scotland. That evening, Cromwell summoned those ministers and others, to a debate on the issue. a discussion on some of the controverted points of the times was held in his presence, between his chaplains, the learned Dr John Owen, Joseph Caryl, and others on the one side, and some Scots ministers on the other. Mr. Binning, who was one of the disputants, apparently nonplussed the Independents, which led Cromwell to ask who the learned and bold young man was. Told it was Binning, he said: "He hath bound well, indeed," ... " but, laying his hand on his sword, this will lose all again." The late Mr. Orme was of the opinion that there is nothing improbable in the account of the meeting, but that such a meeting took place is certain. This appears from two letters which were written by Principal Robert Baillie, who was then Professor of Theology at the University of Glasgow.At the debate, Rev Hugh Binning is said to have out-debated Cromwell's ministers so completely that he silenced them.

Hugh Binning's political views were based on his theology. Binning was a Covenanter, a movement that began in Scotland at Greyfriars Kirkyard in 1638 with the National Covenant and continued with the 1643 Solemn League and Covenant—in effect a treaty between the English Long Parliament and Scotland for the preservation of the reformed religion in exchange for troops to confront the threat of Irish Catholic troops joining the Royalist army. Binning could also be described as a Protestor; both political positions were taken because of their religious implications. However, he saw the evils of the politics of his day was not a "fomenter of factions" writing "A Treatise of Christian Love" as a response.

Because of the tumultuous time in which Hugh Binning lived, politics and religion were inexorably intertwined. Binning was a Calvinist and follower of John Knox. As a profession, Binning was trained as a Philosopher, and he believed that philosophy was the servant of theology. He thought that both Philosophy and Theology should be taught in parallel. Binning's writing, which is primarily a collection of his sermons, "forms an important bridge between the 17th century, when philosophy in Scotland was heavily dominated by Calvinism, and the 18th century when figures such as Francis Hutcheson re-asserted a greater degree of independence between the two and allied philosophy with the developing human sciences."

Religiously, Hugh Binning was, what we would call today, an Evangelical Calvinist. He spoke on the primacy of God's love as the ground of salvation: 
"... our salvation is not the business of Christ alone, but the whole Godhead is interested in it deeply, so deeply that you cannot say who loves it most, or who likes it most. The Father is the very fountain of it, his love is the spring of all."

With regards to the extent of the 'atonement', Hugh Binning, did not hold that the offer of redemption applied only to the few that are elect but said that "the ultimate ground of faith is in the electing will of God." In Scotland, during the 1600s, the questions concerning atonement revolved around the terms in which the offer was expressed.

Binning believed that "forgiveness is based on Christ's death, understood as a satisfaction and as a sacrifice: 'If he had pardoned sin without any satisfaction what rich grace it had been! But truly, to provide the Lamb and sacrifice himself, to find out the ransom, and to exact it of his own Son, in our name, is a testimony
of mercy and grace far beyond that. But then, his justice is very conspicuous in this work'."

All of the works of Hugh Binning were published posthumously and were primarily collections of his sermons. Of his speaking style, it was said: "There is originality without any affectation, a rich imagination, without anything fanciful or extravert, the utmost simplicity, without an thing mean or trifling." 

(The Common Principles of the Christian Religion, fulltext) Quotations from the publication include: 







</doc>
<doc id="14064" url="https://en.wikipedia.org/wiki?curid=14064" title="Henry Home, Lord Kames">
Henry Home, Lord Kames

Henry Home, Lord Kames (169627 December 1782) was a Scottish advocate, judge, philosopher, writer and agricultural improver. A central figure of the Scottish Enlightenment, a founding member of the Philosophical Society of Edinburgh, and active in the Select Society, he acted as patron to some of the most influential thinkers of the Scottish Enlightenment, including the philosopher David Hume, the economist Adam Smith, the writer James Boswell, the chemical philosopher William Cullen, and the naturalist John Walker.

He was born at Kames House, between Eccles and Birgham, Berwickshire, the son of George Home of Kames. He was educated at home by a private tutor until the age of 16. 

In 1712 he was apprenticed as a lawyer under a Writer to the Signet in Edinburgh, was called to the Scottish bar as an advocate bar in 1724. He soon acquired reputation by a number of publications on the civil and Scottish law, and was one of the leaders of the Scottish Enlightenment. In 1752, he was "raised to the bench", thus acquiring the title of Lord Kames.

Kames held a primary interest in the production of Linen in Scotland and encouraged the development of Linen manufacture. Kames was one of the original proprietors of the British Linen Company, and a director between 1754-1756.

Home was on the panel of judges in the Joseph Knight case which ruled that there could be no slavery in Scotland.

His address in 1775 is shown as New Street on the Canongate. Cassell's clarifies that this was a very fine mansion at the head of the street, on its east side, facing onto the Canongate.

He is buried in the Home-Drummond plot at Kincardine-in-Menteith just west of Blair Drummond.

Home wrote much about the importance of property to society. In his "Essay Upon Several Subjects Concerning British Antiquities", written just after the Jacobite rising of 1745, he showed that the politics of Scotland were based not on loyalty to Kings, as the Jacobites had said, but on the royal land grants that lay at the base of feudalism, the system whereby the sovereign maintained "an immediate hold of the persons and property of his subjects".

In "Historical Law Tracts" Home described a four-stage model of social evolution that became "a way of organizing the history of Western civilization". The first stage was that of the hunter-gatherer, wherein families avoided each other as competitors for the same food. The second was that of the herder of domestic animals, which encouraged the formation of larger groups but did not result in what Home considered a true society. No laws were needed at these early stages except those given by the head of the family, clan, or tribe. Agriculture was the third stage, wherein new occupations such as "plowman, carpenter, blacksmith, stonemason" made "the industry of individuals profitable to others as well as to themselves", and a new complexity of relationships, rights, and obligations required laws and law enforcers. A fourth stage evolved with the development of market towns and seaports, "commercial society", bringing yet more laws and complexity but also providing more benefit. Lord Kames could see these stages within Scotland itself, with the pastoral Highlands, the agricultural Lowlands, the "polite" commercial towns of Glasgow and Edinburgh, and in the Western Isles a remaining culture of rude huts where fishermen and gatherers of seaweed eked out their subsistence living.

Home was a polygenist, he believed God had created different races on earth in separate regions. In his book "Sketches of the History of Man", in 1774, Home claimed that the environment, climate, or state of society could not account for racial differences, so that the races must have come from distinct, separate stocks.

The above studies created the genre of the story of civilization and defined the fields of anthropology and sociology and therefore the modern study of history for two hundred years.

In the popular book "Elements of Criticism" (1762) Home interrogated the notion of fixed or arbitrary rules of literary composition, and endeavoured to establish a new theory based on the principles of human nature. The late eighteenth-century tradition of sentimental writing was associated with his notion that 'the genuine rules of criticism are all of them derived from the human heart. Prof Neil Rhodes has argued that Lord Kames played a significant role in the development of English as an academic discipline in the Scottish Universities.

He enjoyed intelligent conversation and cultivated a large number of intellectual associates, among them John Home, David Hume and James Boswell.. Lord Monboddo was also a frequent debater of Kames, although these two usually had a fiercely competitive and adversarial relationship.

He was married to Agatha Drummond of Blair Drummond. Their children included George Drummond-Home.





</doc>
<doc id="14065" url="https://en.wikipedia.org/wiki?curid=14065" title="Harwich">
Harwich

Harwich is a town in Essex, England and one of the Haven ports, located on the coast with the North Sea to the east. It is in the Tendring district. Nearby places include Felixstowe to the northeast, Ipswich to the northwest, Colchester to the southwest and Clacton-on-Sea to the south. It is the northernmost coastal town within Essex.

Its position on the estuaries of the Stour and Orwell rivers and its usefulness to mariners as the only safe anchorage between the Thames and the Humber led to a long period of maritime significance, both civil and military. The town became a naval base in 1657 and was heavily fortified, with Harwich Redoubt, Beacon Hill Battery, and Bath Side Battery.

Harwich is the likely launch point of the "Mayflower" which carried English Puritans to North America, and is the presumed birthplace of "Mayflower" captain Christopher Jones.

Harwich today is contiguous with Dovercourt and the two, along with Parkeston, are often referred to collectively as Harwich.

The town's name means "military settlement", from Old English "here-wic".

The town received its charter in 1238, although there is evidence of earlier settlement – for example, a record of a chapel in 1177, and some indications of a possible Roman presence.

The town was the target of an abortive raid by French forces under Ayton Doria on 24 March 1339 during the Hundred Years' War.

Because of its strategic position, Harwich was the target for the invasion of Britain by William of Orange on 11 November 1688. However, unfavourable winds forced his fleet to sail into the English Channel instead and eventually land at Torbay. Due to the involvement of the Schomberg family in the invasion, Charles Louis Schomberg was made Marquess of Harwich.

Writer Daniel Defoe devotes a few pages to the town in "A tour thro' the Whole Island of Great Britain". Visiting in 1722, he noted its formidable fort and harbour "of a vast extent". The town, he recounts, was also known for an unusual chalybeate spring rising on Beacon Hill (a promontory to the north-east of the town), which "petrified" clay, allowing it to be used to pave Harwich's streets and build its walls. The locals also claimed that "the same spring is said to turn wood into iron", but Defoe put this down to the presence of "copperas" in the water. Regarding the atmosphere of the town, he states: "Harwich is a town of hurry and business, not much of gaiety and pleasure; yet the inhabitants seem warm in their nests and some of them are very wealthy".

Harwich played an important part in the Napoleonic and more especially the two world wars. Of particular note:

1793-1815—Post Office Station for communication with Europe, one of embarkation and evacuation bases for expeditions to Holland in 1799, 1809 and 1813/14; base for capturing enemy privateers. The dockyard built many ships for the Navy, including HMS "Conqueror" which captured the French Admiral Villeneuve at the Battle of Trafalgar. The Redoubt and the now-demolished Ordnance Building date from that era.

1914-18—base for the Royal Navy's Harwich Force light cruisers and destroyers under Commodore Tyrwhitt, and for British submarines. In November 1918 the German U-Boat fleet surrendered to the Royal Navy in the harbour.

1939-1945—one of main East Coast minesweeping and destroyer bases, at one period base for British and French submarines; assembled fleets for Dutch and Dunkirk evacuations and follow-up to D-Day; unusually a target in 1940 for Italian bombers.

Harwich Dockyard was established as a Royal Navy Dockyard in 1652. It ceased to operate as a Royal Dockyard in 1713 (though a Royal Navy presence was maintained until 1829). During the various wars with France and Holland, through to 1815, the dockyard was responsible for both building and repairing numerous warships. HMS "Conqueror", a 74-gun ship completed in 1801, captured the French admiral Villeneuve at Trafalgar.
The yard was then a semi-private concern, with the actual shipbuilding contracted to Joseph Graham, who was sometimes mayor of the town.
During World War II parts of Harwich were again requisitioned for naval use and ships were based at HMS "Badger"; "Badger" was decommissioned in 1946, but the Royal Naval Auxiliary Service maintained a headquarters on the site until 1992.

The Royal Navy no longer has a presence in Harwich but Harwich International Port at nearby Parkeston continues to offer regular ferry services to the Hook of Holland (Hoek van Holland) in the Netherlands. Mann Lines operates a roll-on roll-off ferry service from Harwich Navyard to Bremerhaven, Cuxhaven, Paldiski and Turku.
Many operations of the Port of Felixstowe and of Trinity House, the lighthouse authority, are managed from Harwich.

The Mayflower railway line serves Harwich and there are three operational passenger stations: , and . The line also allows freight trains to access the Port.

The port is famous for the phrase "Harwich for the Continent", seen on road signs and in London & North Eastern Railway (LNER) advertisements.

At least three pairs of lighthouses have been built over recent centuries as leading lights, to help guide vessels into Harwich. The earliest pair were wooden structures: the High Light stood on top of the old Town Gate, whilst the Low Light (featured in a painting by Constable) stood on the foreshore. Both were coal-fired.

In 1818 these were replaced by stone structures, designed by John Rennie Senior, which can still be seen today (they no longer function as lighthouses: one houses the town's maritime museum, the other is (in 2015) also being converted into a museum). They were owned by General Rebow of Wivenhoe Park, who was able to charge 1d per ton on all cargo entering the port, for upkeep of the lights. In 1836 Rebow's lease on the lights was purchased by Trinity House, but in 1863 they were declared redundant due to a change the position of the channel used by ships entering and leaving the port, caused by shifting sands.

They were in turn replaced by the pair of cast iron lights at nearby Dovercourt; these too remain in situ, but were decommissioned (again due to shifting of the channel) in 1917.

Despite, or perhaps because of, its small size Harwich is highly regarded in terms of architectural heritage, and the whole of the older part of the town, excluding Navyard Wharf, is a conservation area.

The regular street plan with principal thoroughfares connected by numerous small alleys indicates the town's medieval origins, although many buildings of this period are hidden behind 18th century facades.
The extant medieval structures are largely private homes. The house featured in the image of Kings Head St to the left is unique in the town and is an example of a sailmaker's house, thought to have been built circa 1600. Notable public buildings include the parish church of St. Nicholas (1821) in a restrained Gothic style, with many original furnishings, including a somewhat altered organ in the west end gallery. There is also the Guildhall of 1769, the only Grade I listed building in Harwich.
The Pier Hotel of 1860 and the building that was the Great Eastern Hotel of 1864 can both been seen on the quayside, both reflecting the town's new importance to travellers following the arrival of the Great Eastern Main Line from Colchester in 1854. In 1923, The Great Eastern Hotel was closed by the newly formed LNER, as the Great Eastern Railway had opened a new hotel with the same name at the new passenger port at Parkeston Quay, causing a decline in numbers.
The hotel became the Harwich Town Hall, which included the Magistrates Court and, following changes in local government, was sold and divided into apartments.

Also of interest are the High Lighthouse (1818), the unusual Treadwheel Crane (late 17th century), the Old Custom Houses on West Street, a number of Victorian shopfronts and the Electric Palace Cinema (1911), one of the oldest purpose-built cinemas to survive complete with its ornamental frontage and original projection room still intact and operational.
There is little notable building from the later parts of the 20th century, but major recent additions include the lifeboat station and two new structures for Trinity House. The Trinity House office building, next door to the Old Custom Houses, was completed in 2005. All three additions are influenced by the high-tech style.

Harwich has also historically hosted a number of notable inhabitants, linked with Harwich's maritime past.



Harwich is home to Harwich & Parkeston F.C.; Harwich and Dovercourt RFC; Harwich Rangers FC; Sunday Shrimpers; Harwich & Dovercourt Sailing Club; Harwich, Dovercourt & Parkeston Swimming Club; Harwich & Dovercourt Rugby Union Football Club; Harwich & Dovercourt Cricket Club; and Harwich Runners who with support from Harwich Swimming Club host the annual Harwich Triathlons.




</doc>
<doc id="14067" url="https://en.wikipedia.org/wiki?curid=14067" title="Hendrick Avercamp">
Hendrick Avercamp

Hendrick Avercamp (January 27, 1585 (bapt.) – May 15, 1634 (buried)) was a Dutch painter. Avercamp was born in Amsterdam, where he studied with the Danish-born portrait painter Pieter Isaacks (1569–1625), and perhaps also with David Vinckboons. In 1608 he moved from Amsterdam to Kampen in the province of Overijssel. Avercamp was deaf and mute and was known as "de Stomme van Kampen" (the mute of Kampen).

As one of the first landscape painters of the 17th-century Dutch school, he specialized in painting the Netherlands in winter. Avercamp's paintings are colorful and lively, with carefully crafted images of the people in the landscape. His works give a vivid depiction of sport and leisure in the Netherlands in the beginning of the 17th century. Many of Avercamp's paintings feature people ice skating on frozen lakes.

Avercamp's work enjoyed great popularity and he sold his drawings, many of which were tinted with water-color, as finished pictures to be pasted into the albums of collectors. The Royal Collection has an outstanding collection of his works.

Avercamp died in Kampen and was interred there in the Sint Nicolaaskerk.

Avercamp probably painted in his studio on the basis of sketches he had made in the winter.
Avercamp was famous even abroad for his winter landscapes. The passion for painting skating characters probably came from his childhood as he practiced skating with his parents. The last quarter of the 16th century, during which Avercamp was born, was one of the coldest periods of the Little Ice Age.

The Flemish painting tradition is mainly expressed in Avercamp's early work. This is consistent with the landscapes of Pieter Bruegel the Elder. Avercamp painted landscapes with a high horizon and many figures who are working on something. The paintings are narrative, with many anecdotes. For instance, included in the painting "Winter landscape with skaters" are several prurient details: a couple making love, naked buttocks, and a peeing male. 

Later in his life drawing the atmosphere was also important in his work. The horizon also gradually dropped down under more and more air.

Avercamp used the painting technique of aerial perspective. The depth is suggested by change of color in the distance. To the front objects are painted in richer colors, such as trees or a boat, while farther objects are lighter. This technique strengthens the impression of depth in the painting.

Avercamp has also painted cattle and seascapes.

Sometimes Avercamp used paper frames, which were a cheap alternative to oil paintings. He first drew with pen and ink. This work was then covered with finishing paint. The contours of the drawing remained. Even with this technique, Avercamp could show the pale wintry colors and nuances of the ice .

Avercamp produced about a hundred paintings. The bulk of his artwork can be seen in the Rijksmuseum in Amsterdam and the Mauritshuis in The Hague. 
From November 20, 2009 to February 15, 2010 the Rijksmuseum presented an exhibition of his work entitled "Little Ice Age".



</doc>
<doc id="14068" url="https://en.wikipedia.org/wiki?curid=14068" title="Hans Baldung">
Hans Baldung

Hans Baldung (1484 or 1485 – September 1545), also called Hans Baldung Grien, the "Grien" element being an early nickname after his preferred colour green, was a German artist in painting and printmaking who was considered the most gifted student of Albrecht Dürer. Throughout his lifetime, Baldung developed a distinctive style, full of color, expression and imagination. His talents were varied, and he produced a great and extensive variety of work including portraits, woodcuts, drawings, tapestries, altarpieces, stained glass, allegories and mythological motifs.

Hans was born in the small free city of Schwäbisch Gmünd, part of the East Württemberg region in former Swabia, Germany, in the year 1484 or 1485, into a family of intellectuals, academics and professionals, where his father, Johann Baldung, a university-educated jurist, had been an episcopal official between 1492 - 1505. Hans mother was Margarethe Herlin, daughter of Arbogast Herlin, he was not propertyless, but with unknown occupation. His uncle, Hieronymus Baldung, was a doctor in medicine, he had a son, Pius Hieronymus, that can be seen as Hans' cousin, who taught law at Freiburg, and became by 1527 chancellor of the Tyrol. In fact, Baldung was the first male in his family not to attend university, but was one of the first German artists to come from an academic family. His earliest training as an artist began around 1500 in the Upper Rhineland by an artist from Strasbourg.

Beginning in 1503, during the "Wanderjahre" ("Hiking years") required of artists of the time, Baldung became an assistant to Albrecht Dürer. Here, he may have been given his nickname "Grien". This name is thought to have come foremost from a preference to the color green: he seems to have worn green clothing. He probably also got this nickname to distinguish him from at least two other Hanses in Dürer's shop, Hans Schäufelein and Hans Suess von Kulmbach. He later included the name "Grien" in his monogram, and it has also been suggested that the name came from, or consciously echoed, "grienhals", a German word for witch—one of his signature themes. Hans quickly picked up Dürer's influence and style, and they became friends: Baldung seems to have managed Dürer's workshop during the latter's second sojourn in Venice. In a later trip to the Netherlands in 1521 Dürer's account book records that he took with him and sold prints by Baldung. On Dürer's death Baldung was sent a lock of his hair, which suggests a close friendship. Near the end of his Nuremberg years, Grien oversaw the production by Dürer of stained glass, woodcuts and engravings, and therefore developed an affinity for these media and for the Nuremberg master's handing of them.

In 1509, when Baldung's time in Nuremberg was complete, he moved back to Strasbourg and became a citizen there. He became a celebrity of the town, and received many important commissions. The following year he married Margarethe Herlin, a local merchant's daughter joined the guild "Zur Steltz", opened a workshop, and began signing his works with the HGB monogram that he used for the rest of his career. His style also became much more deliberately individual—a tendency art historians used to term "mannerist." He also stayed in Freiburg im Breisgau in 1513–1516 where he made, among other things, the .

In addition to traditional religious subjects, Baldung was concerned during these years with the profane theme of the imminence of death and with scenes of sorcery and witchcraft. He helped introduce supernatural and erotic themes into German art, although these were already amply present in Dürer's work. Most famously, he depicted witches, also a local interest: Strasbourg's humanists studied witchcraft and its bishop was charged with finding and prosecuting witches. His most characteristic works in this area are small in scale and mostly in the medium of drawing; these include a series of puzzling, often erotic allegories and mythological works executed in quill pen and ink and white body color on primed paper. The number of Hans Baldung's religious works diminished with the Protestant Reformation, which generally repudiated church art as either wasteful or idolatrous. But earlier, around the same time that he produced an important chiaroscuro woodcut of Adam and Eve, the artist became interested in themes related to death, the supernatural, witchcraft, sorcery, and the relation between the sexes. Baldung's fascination with witchcraft began early, with his first chiaroscuro print (1510) lasted to the end of his career.

Hans Baldung Grien's work depicting witches was produced in the first half of the 16th century, before witch hunting became a widespread cultural phenomenon in Europe. According to one view, Baldung's work did not represent widespread cultural beliefs at the time of creation but reflected largely individual choices. On the other hand, through his family, Baldung stood as closer to the leading intellectuals of the day than any of his contemporaries, and could draw on a burgeoning literature on witchcraft, as well as on developing juridical and forensic strategies for witch-hunting. Furthermore, Baldung never worked directly with any Reformation leaders to spread religious ideals through his artwork, although living in fervently religious Strasbourg, although he was a supporter of the movement, working on the high altar in the city of Münster, Germany.

Baldung was the first artist to heavily incorporate witches and witchcraft into his artwork (his mentor Albrecht Dürer had sporadically included them but not as prominently as Baldung would). During his lifetime there were few witch trials, therefore, some believe Baldung's depictions of witchcraft to be based on folklore rather than the cultural beliefs of his time. By contrast, throughout the early sixteenth century, humanism became very popular, and within this movement, Latin literature was valorized, particularly poetry and satire, some of which included views on witches that could be combined with witch lore massively accumulated in works such as the Malleus Maleficarum. Baldung partook in this culture, producing not only many works depicting Strasbourg humanists and scenes from ancient art and literature, but what an earlier literature on the artist described as his satirical take on his depiction of witches. Gert von der Osten comments on this aspect of "Baldung [treating] his witches humorously, an attitude that reflects the dominant viewpoint of the humanists in Strasbourg at this time who viewed witchcraft as 'lustig,' a matter that was more amusing than serious". However, the separation of a satirical tone from deadly serious vilifying intent proves difficult to maintain for Baldung as it is for many other artists, including his rough contemporary Hieronymus Bosch. Baldung's art simultaneously represents ideals presented in ancient Greek and Roman poetry, such as the pre-16th century notion that witches could control the weather, which Baldung is believed to have alluded to in his 1523 oil painting "Weather Witches", which showcases two attractive and naked witches in front of a stormy sky. 

Baldung also regularly incorporated scenes of witches flying in his art, a characteristic that had been contested centuries before his artwork came into being. Flying was inherently attributed to witches by those who believed in the myth of the Sabbath (without their ability to fly, the myth fragmented), such as Baldung, which he depicted in works like "Witches Preparing for the Sabbath Flight" (1514).

Throughout his life, Baldung painted numerous portraits, known for their sharp characterizations. While Dürer rigorously details his models, Baldung's style differs by focusing more on the personality of the represented character, an abstract conception of the model's state of mind. Baldung settled eventually in Strasbourg and then to Freiburg im Breisgau, where he executed what is held to be his masterpiece. Here in painted an eleven-panel altarpiece for the Freiburg Cathedral, still intact today, depicting scenes from the life of the Virgin, including, The Annunciation, The Visitation, The Nativity, The Flight into Egypt, The Crucifixion, Four Saints and The Donators. These depictions were a large part of the artist's greater body of work containing several renowned pieces of the Virgin.

The earliest pictures assigned to him by some are altar-pieces with the monogram H. B. interlaced, and the date of 1496, in the monastery chapel of Lichtenthal near Baden-Baden. Another early work is a portrait of the emperor Maximilian, drawn in 1501 on a leaf of a sketch-book now in the print-room at Karlsruhe. "The Martyrdom of St Sebastian and the Epiphany" (now Berlin, 1507), were painted for the market-church of Halle in Saxony.

Baldung's prints, though Düreresque, are very individual in style, and often in subject. They show little direct Italian influence. His paintings are less important than his prints. He worked mainly in woodcut, although he made six engravings, one very fine. He joined in the fashion for chiaroscuro woodcuts, adding a tone block to a woodcut of 1510. Most of his hundreds of woodcuts were commissioned for books, as was usual at the time; his "single-leaf" woodcuts (i.e. prints not for book illustration) are fewer than 100, though no two catalogues agree as to the exact number.

Unconventional as a draughtsman, his treatment of human form is often exaggerated and eccentric (hence his linkage, in the art historical literature, with European Mannerism), whilst his ornamental style—profuse, eclectic, and akin to the self-consciously "German" strain of contemporary limewood sculptors—is equally distinctive. Though Baldung has been commonly called the Correggio of the north, his compositions are a curious medley of glaring and heterogeneous colours, in which pure black is contrasted with pale yellow, dirty grey, impure red and glowing green. Flesh is a mere glaze under which the features are indicated by lines.

His works are notable for their individualistic departure from the Renaissance composure of his model, Dürer, for the wild and fantastic strength that some of them display, and for their remarkable themes. In the field of painting, his "Eve, the Serpent and Death" (National Gallery of Canada) shows his strengths well. There is special force in the "Death and the Maiden" panel of 1517 (Basel), in the "Weather Witches" (Frankfurt), in the monumental panels of "Adam" and "Eve" (Madrid), and in his many powerful portraits. Baldung's most sustained effort is the altarpiece of Freiburg, where the Coronation of the Virgin, and the Twelve Apostles, the Annunciation, Visitation, Nativity and Flight into Egypt, and the Crucifixion, with portraits of donors, are executed with some of that fanciful power that Martin Schongauer bequeathed to the Swabian school.

He is well known as a portrait painter, his works include historical pictures and portraits; among the latter may be named those of Maximilian I. and Charles V. His bust of Margrave Philip in the Munich Gallery tells us that he was connected with the reigning family of Baden as early as 1514. At a later period he had sittings with Margrave Christopher of Baden, Ottilia his wife, and all their children, and the picture containing these portraits is still in the gallery at Karlsruhe. Like Dürer and Cranach, Baldung supported the Protestant Reformation. He was present at the diet of Augsburg in 1518, and one of his woodcuts represents Luther in quasi-saintly guise, under the protection of (or being inspired by) the Holy Spirit, which hovers over him in the shape of a dove.




Attribution:




</doc>
<doc id="14070" url="https://en.wikipedia.org/wiki?curid=14070" title="Hammered dulcimer">
Hammered dulcimer

The hammered dulcimer (also called the hammer dulcimer, dulcimer, or tympanon) is a percussion-stringed instrument which consists of strings typically stretched over a trapezoidal resonant sound board. The hammered dulcimer is set before the musician, who in more traditional styles may sit cross-legged on the floor, or in a more modern style may stand or sit at a wooden support with legs. The player holds a small spoon-shaped mallet hammer in each hand to strike the strings (see Appalachian dulcimer). The Graeco-Roman "dulcimer" ("sweet song") derives from the Latin "dulcis" (sweet) and the Greek "melos" (song). The dulcimer, in which the strings are beaten with small hammers, originated from the psaltery, in which the strings are plucked. 
Hammered dulcimers and other similar instruments are traditionally played in Iraq, India, Iran, Southwest Asia, China, Korea, and parts of Southeast Asia, Central Europe (Hungary, Slovenia, Romania, Slovakia, Poland, Czech Republic, Switzerland (particularly Appenzell), Austria and Bavaria), the Balkans, Eastern Europe (Ukraine and Belarus), and Scandinavia. The instrument is also played in the United Kingdom (Wales, East Anglia, Northumbria), and the US, where its traditional use in folk music saw a notable revival in the late 20th century.

A dulcimer usually has two bridges, a bass bridge near the right and a treble bridge on the left side. The bass bridge holds up bass strings, which are played to the left of the bridge. The treble strings can be played on either side of the treble bridge. In the usual construction, playing them on the left side gives a note a fifth higher than playing them on the right of the bridge.

The dulcimer comes in various sizes, identified by the number of strings that cross each of the bridges. A 15/14, for example, has 15 strings crossing the treble bridge and 14 crossing the bass bridge, and can span three octaves. The strings of a hammered dulcimer are usually found in pairs, two strings for each note (though some instruments have three or four strings per note). Each set of strings is tuned in unison and is called a course. As with a piano, the purpose of using multiple strings per course is to make the instrument louder, although as the courses are rarely in perfect unison, a chorus effect usually results like a mandolin. A hammered dulcimer, like an autoharp, harp, or piano, requires a tuning wrench for tuning, since the dulcimer's strings are wound around tuning pins with square heads. (Ordinarily, 5 mm "zither pins" are used, similar to, but smaller in diameter than piano tuning pins, which come in various sizes ranging upwards from "1/0" or 7 mm.)

The strings of the hammered dulcimer are often tuned according to a circle of fifths pattern. Typically, the lowest note (often a G or D) is struck at the lower right-hand of the instrument, just to the left of the right-hand (bass) bridge. As a player strikes the courses above in sequence, they ascend following a repeating sequence of two whole steps and a half step. With this tuning, a diatonic scale is broken into two tetrachords, or groups of four notes. For example, on an instrument with D as the lowest note, the D major scale is played starting in the lower-right corner and ascending the bass bridge: D – E – F – G. This is the lower tetrachord of the D major scale. At this point the player returns to the bottom of the instrument and shifts to the treble strings to the right of the treble bridge to play the higher tetrachord: A – B – C – D. The player can continue up the scale on the right side of the treble bridge with E – F – G – A – B, but the next note will be C, not C, so he or she must switch to the left side of the treble bridge (and closer to the player) to continue the D major scale. See the drawing on the left above, in which "DO" would correspond to D (see Movable do solfège).

The shift from the bass bridge to the treble bridge is required because the bass bridge's fourth string G is the start of the lower tetrachord of the G scale. The player could go on up a couple notes (G - A - B), but the next note will be a flatted seventh (C natural in this case), because this note is drawn from the G tetrachord. This D major scale with a flatted seventh is the mixolydian mode in D.

The same thing happens as the player goes up the treble bridge – after getting to La (B in this case), one has to go to the left of the treble bridge. Moving from the left side of the bass bridge to the right side of the treble bridge is analogous to moving from the right side of the treble bridge to the left side of the treble bridge.

The whole pattern can be shifted up by three courses, so that instead of a D-major scale one would have a G-major scale, and so on. This transposes one equally tempered scale to another. Shifting down three courses transposes the D-major scale to A-major, but of course the first Do-Re-Mi would be shifted off the instrument.

This tuning results in most, but not all, notes of the chromatic scale being available. To fill in the gaps, many modern dulcimer builders include extra short bridges at the top and bottom of the soundboard, where extra strings are tuned to some or all of the missing pitches. Such instruments are often called "chromatic dulcimers" as opposed to the more traditional "diatonic dulcimers".

The tetrachord markers found on the bridges of most hammered dulcimers in the English-speaking world were introduced by the American player and maker Sam Rizzetta in the 1960s.

In the Alps there are also chromatic dulcimers with crossed strings, which are in a whole tone distance in every row. This chromatic "Salzburger hackbrett" was developed in the mid 1930s from the diatonic hammered dulcimer by Tobi Reizer and his son along with Franz Peyer and Heinrich Bandzauner. In the postwar period it was one of the instruments taught in state-sponsored music schools.

Hammered dulcimers of non-European descent may have other tuning patterns, and builders of European-style dulcimers sometimes experiment with alternate tuning patterns.

The instrument is referred to as "hammered" in reference to the small mallets (referred to as "hammers") that players use to strike the strings. Hammers are usually made of wood (most likely hardwoods such as maple, cherry, padauk, oak, walnut, or any other hardwood), but can also be made from any material, including metal and plastic. In the Western hemisphere, hammers are usually stiff, but in Asia, flexible hammers are often used. The head of the hammer can be left bare for a sharp attack sound, or can be covered with adhesive tape, leather, or fabric for a softer sound. Two-sided hammers are also available. The heads of two sided hammers are usually oval or round. Most of the time, one side is left as bare wood while the other side may be covered in leather or a softer material such as piano felt.

Several traditional players have used hammers that differ substantially from those in common use today. Paul Van Arsdale (1920-2018), a player from upstate New York, used flexible hammers made from hacksaw blades, with leather-covered wooden blocks attached to the ends (these were modeled after the hammers used by his grandfather, Jesse Martin). The Irish player John Rea (1915–1983) used hammers made of thick steel wire, which he made himself from old bicycle spokes wrapped with wool. Billy Bennington (1900–1986), a player from Norfolk, England, used cane hammers bound with wool.

The hammered dulcimer was extensively used during the Middle Ages in England, France, Italy, Germany, the Netherlands, and Spain. Although it had a distinctive name in each country, it was everywhere regarded as a kind of psalterium. The importance of the method of setting the strings in vibration by means of hammers, and its bearing on the acoustics of the instrument, were recognized only when the invention of the pianoforte had become a matter of history. It was then perceived that the psalterium (in which the strings were plucked) and the dulcimer (in which they were struck), when provided with keyboards would give rise to two distinct families of instruments, differing essentially in tone quality, in technique and in capabilities. The evolution of the psalterium resulted in the harpsichord; that of the dulcimer produced the pianoforte.

Versions of the hammered dulcimer are used throughout the world. In Eastern Europe, a larger descendant of the hammered dulcimer called the cimbalom is played and has been used by a number of classical composers, including Zoltán Kodály, Igor Stravinsky, and Pierre Boulez. The khim is the name used by the Thai, the Khmer, and the Laotians for the hammered dulcimer.





</doc>
