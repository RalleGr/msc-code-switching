<doc id="21383" url="https://en.wikipedia.org/wiki?curid=21383" title="Nigeria">
Nigeria

Nigeria (), officially the Federal Republic of Nigeria, is a sovereign country located in West Africa bordering Niger in the north, Chad in the northeast, Cameroon in the east, and Benin in the west. Its southern coast is on the Gulf of Guinea in the Atlantic Ocean. Nigeria is a federal republic comprising 36 states and the Federal Capital Territory, where the capital, Abuja, is located.

Nigeria has been home to a number of ancient and indigenous pre-colonial states and kingdoms over the millennia. The modern state originated from British colonial rule beginning in the 19th century, and took its present territorial shape with the merging of the Southern Nigeria Protectorate and Northern Nigeria Protectorate in 1914 by Lord Frederick Lugard. The British set up administrative and legal structures while practicing indirect rule through traditional chiefdoms; Nigeria became a formally independent federation on October 1, 1960. It experienced a civil war from 1967 to 1970. It thereafter alternated between democratically elected civilian governments and military dictatorships until it achieved a stable democracy in 1999, with the 2015 presidential election marking the first time an incumbent president had lost re-election.

A multinational state, Nigeria is inhabited by more than 250 ethnic groups with over 500 distinct languages all identifying with a wide variety of cultures. The three largest ethnic groups are the Hausa–Fulani in the north, Yoruba in the west, and Igbo in the east; comprising over 60% of the total population. The official language of Nigeria is English, chosen to facilitate linguistic unity at the national level. Nigeria is divided roughly in half between Christians, who live mostly in the southern part of the country, and Muslims, who live mostly in the north. Nigeria has respectively, the fifth-largest Muslim population in the world and the sixth-largest Christian population in the world, with the constitution ensuring freedom of religion. A minority of the population practice religions indigenous to Nigeria, such as those native to the Igbo and Yoruba ethnicities.

Nigeria is the most populous country in Africa and the seventh most populous country in the world, with an estimated 206 million inhabitants as of late 2019. Nigeria has the third-largest youth population in the world, after India and China, with more than 90 million of its population under the age of eighteen. Nigeria has the largest economy in Africa and is the world's 24th largest economy according to the list by the IMF (2020 estimates), worth more than $500 billion and $1 trillion in terms of nominal GDP and purchasing power parity, respectively. The 2013 debt-to-GDP ratio was 11 percent as of 2019 it has risen to an approximated figure of 16 percent. Nigeria is a lower middle-income economy with a gross national income per capita between $1,026 and $3,986. Nigeria is often referred to as the "Giant of Africa", owing to its large population and economy, it is also considered to be an emerging market by the World Bank; it has been identified as a regional power on the African continent, a middle power in international affairs, and has also been identified as an emerging global power. However, its Human Development Index ranks 158th in the world.

Nigeria is a member of the MINT group of countries, which are widely seen as the globe's next "BRIC-like" economies. It is also listed among the "Next Eleven" economies set to become among the biggest in the world. Nigeria is a founding member of the African Union and a member of many other international organizations, including the United Nations, the Commonwealth of Nations, the ECOWAS, and OPEC.

The name "" was taken from the Niger River running through the country. This name was coined on January 8, 1897, by British journalist Flora Shaw, who later married Lord Lugard, a British colonial administrator. The neighbouring Niger takes it name from the same river. The origin of the name "Niger", which originally applied to only the middle reaches of the Niger River, is uncertain. The word is likely an alteration of the Tuareg name "egerew n-igerewen" used by inhabitants along the middle reaches of the river around Timbuktu prior to 19th-century European colonialism.

The Nok civilisation of Nigeria flourished between 1,500 BC and AD 200. It produced life-sized terracotta figures that are some of the earliest known sculptures in Sub-Saharan Africa. and smelted iron by about 550 BC and possibly a few centuries earlier. Evidence of iron smelting has also been excavated at sites in the Nsukka region of southeast Nigeria: dating to 2000 BC at the site of Lejja (Uzomaka 2009) and to 750 BC and at the site of Opi. The Kingdom of Nri of the Igbo people consolidated in the 10th century and continued until it lost its sovereignty to the British in 1911. Nri was ruled by the Eze Nri, and the city of Nri is considered to be the foundation of Igbo culture. Nri and Aguleri, where the Igbo creation myth originates, are in the territory of the Umeuri clan. Members of the clan trace their lineages back to the patriarchal king-figure Eri. In West Africa, the oldest bronzes made using the lost-wax process were from Igbo-Ukwu, a city under Nri influence. The Yoruba kingdoms of Ife and Oyo in southwestern Nigeria became prominent in the 12th and 14th centuries, respectively. The oldest signs of human settlement at Ife's current site date back to the 9th century, and its material culture includes terracotta and bronze figures.

The Kano Chronicle highlights an ancient history dating to around 999 AD of the Hausa Sahelian city-state of Kano, with other major Hausa cities (or Hausa Bakwai) of: Daura, Hadeija, Kano, Katsina, Zazzau, Rano, and Gobir all having recorded histories dating back to the 10th century. With the spread of Islam from the 7th century AD, the area became known as "Sudan" or as "Bilad Al Sudan" (English: Land of the Blacks; Arabic: بلاد السودان‎). Since the populations were partially affiliated with the Arab Muslim culture of North Africa, they started to trade and be referred to by the Arabic speakers as "Al-Sudan" (meaning "The Blacks") as they were considered an extended part of the Muslim world. There are early historical references by medieval Arab and Muslim historians and geographers which refer to the Kanem-Bornu Empire as the regions major centre for Islamic civilization. It is likely that the medieval Hausa Kingdoms formed trading ties with the Bornu Empire, which became increasingly wealthy as the main transshipment centre for the captured sub-Saharan African Zanj slaves along the Arab slave trade. Hausa rulers also likely provided Sudanic peoples as a tributary to the Bornu Empire in order to avert war with the Empire. 

In the 16th century, Portuguese explorers were the first Europeans to begin significant, direct trade with peoples of Southern Nigeria, at the port they named Lagos and in Calabar along the region Slave Coast. Europeans traded goods with peoples at the coast; coastal trade with Europeans also marked the beginnings of the Atlantic slave trade. The port of Calabar on the historical Bight of Biafra (now commonly referred to as the Bight of Bonny) became one of the largest slave trading posts in West Africa in the era of the transatlantic slave trade. Other major slaving ports in Nigeria were located in Badagry, Lagos on the Bight of Benin and on Bonny Island on the Bight of Biafra. The majority of those enslaved and taken to these ports were captured in raids and wars. Usually the captives were taken back to the conquerors' territory as forced labour; after time, they were sometimes acculturated and absorbed into the conquerors' society. A number of slave routes were established throughout Nigeria linking the hinterland areas with the major coastal ports. Some of the more prolific slave trading kingdoms who participated in the transatlantic slave trade were linked with the Edo's Benin Empire in the south, Oyo Empire in the southwest, and the Aro Confederacy in the southeast. Benin's power lasted between the 15th and 19th centuries. Their dominance reached as far as the city of Eko (an Edo name later changed to Lagos by the Portuguese) and further. Oyo, at its territorial zenith in the late 17th to early 18th centuries, extended its influence from western Nigeria to modern-day Togo. The Edo's Benin Empire is located in southwestern Nigeria.

In the north, the incessant fighting amongst the Hausa city-states and the decline of the Bornu Empire gave rise to the Fulani people gaining headway into the region. Until this point, the Fulani a nomadic ethnic group primarily traversed the semi-desert Sahelian region, north of the Sudan, with cattle and avoided trade and intermingling with the Sudanic peoples. At the beginning of the 19th century, Usman dan Fodio led a successful jihad against the Hausa Kingdoms founding the centralised Sokoto Caliphate (also known as the Fulani Empire). The empire with Arabic as its official language grew rapidly under his rule and that of his descendants, who sent out invading armies in every direction. The vast landlocked empire connected the East with the West Sudan region and made inroads down south conquering parts of the Oyo Empire (modern day Kwara), and advanced towards the Yoruba heartland of Ibadan, with the goal of reaching the Atlantic Ocean. The territory controlled by the Empire included much of modern-day northern and central Nigeria. The Sultan sent out emirs to establish a suzerainty over the conquered territories and promote Islamic civilization, the Emirs in turn became increasingly rich and powerful though trade and slavery. By the 1890s, the largest slave population in the world, about two million, was concentrated in the territories of the Sokoto Caliphate. The use of slave labor was extensive, especially in agriculture. By the time of its break-up in 1903 into various European colonies, the Sokoto Caliphate was one of the largest pre-colonial African states.

A changing legal imperative (transatlantic slave trade outlawed by Britain in 1807) and economic imperative (a desire for political and social stability) led most European powers to support widespread cultivation of agricultural products, such as the palm, for use in European industry. The Atlantic slave trade was engaged in by European companies until it was outlawed in 1807. After that illegal smugglers purchased slaves along the coast by native slavers. Britain's West Africa Squadron sought to intercept the smugglers at sea. The rescued slaves were taken to Freetown, a colony in West Africa originally established for the resettlement of freed slaves from Britain. Britain intervened in the Lagos Kingship power struggle by bombarding Lagos in 1851, deposing the slave trade friendly Oba Kosoko, helping to install the amenable Oba Akitoye, and signing the Treaty between Great Britain and Lagos on 1January 1852. Britain annexed Lagos as a Crown Colony in August 1861 with the Lagos Treaty of Cession. British missionaries expanded their operations and traveled further inland. In 1864, Samuel Ajayi Crowther became the first African bishop of the Anglican Church.
In 1885, British claims to a West African sphere of influence received recognition from other European nations at the Berlin Conference. The following year, it chartered the Royal Niger Company under the leadership of Sir George Taubman Goldie. By the late 19th and early 20th centuries, the company had vastly succeeded in subjugating the independent southern kingdoms along the Niger River, the British conquered Benin in 1897, and, in the Anglo-Aro War (1901–1902), defeated other opponents. The defeat of these states opened up the Niger area to British rule. In 1900, the company's territory came under the direct control of the British government and established the Southern Nigeria Protectorate as a British protectorate and part of the British Empire, the foremost world power at the time.

By 1902, the British had begun plans to move north into the Sokoto Caliphate. Lord Frederick Lugard a British general, was tasked by the Colonial Office to implement the agenda. Lugard used rivalries between many of the emirs in the southern reach of the caliphate and the central Sokoto administration to prevent any defense as he worked towards the capital. As the British approached the city of Sokoto, the new Sultan Muhammadu Attahiru I organized a quick defense of the city and fought the advancing British-led forces. The British force quickly won, sending Attahiru I and thousands of followers on a Mahdist "hijra". In the northeast, the decline of the Bornu Empire gave rise to the British-controlled Borno Emirate which established Abubakar Garbai of Borno as the ruler.

In 1903, the British-victory in the Battle of Kano gave them a logistical edge in pacifying the heartland of the Sokoto Caliphate and parts of the former Bornu Empire. On March 13, 1903, at the grand market square of Sokoto, the last Vizier of the Caliphate officially conceded to British rule. The British appointed Muhammadu Attahiru II as the new Caliph. Fredrick Lugard abolished the Caliphate, but retained the title "Sultan" as a symbolic position in the newly organized Northern Nigeria Protectorate. This remnant became known as "Sokoto Sultanate Council". In June 1903, the British defeated the remaining forces of AttahiruI and killed him; by 1906 resistance to British rule had ended.

Amalgamation

On 1 January 1914, the British formally united the Southern Nigeria Protectorate and the Northern Nigeria Protectorate into the Colony and Protectorate of Nigeria. Administratively, Nigeria remained divided into the Northern and Southern Protectorates and Lagos Colony. Inhabitants of the southern region sustained more interaction, economic and cultural, with the British and other Europeans owing to the coastal economy.
Christian missions established Western educational institutions in the Protectorates. Under Britain's policy of indirect rule and validation of Islamic tradition, the Crown did not encourage the operation of Christian missions in the northern, Islamic part of the country. Some children of the southern elite went to Great Britain to pursue higher education. By independence in 1960, regional differences in modern educational access were marked. The legacy, though less pronounced, continues to the present day. Imbalances between North and South were expressed in Nigeria's political life as well. For instance, northern Nigeria did not outlaw slavery until 1936 whilst in other parts of Nigeria slavery was abolished soon after colonialism.

Following World War II, in response to the growth of Nigerian nationalism and demands for independence, successive constitutions legislated by the British government moved Nigeria toward self-government on a representative and increasingly federal basis. By the middle of the 20th century, a great wave for independence was sweeping across Africa. Nigeria achieved independence in 1960.

Nigeria gained independence from the United Kingdom on 1 October 1960, as the Federation of Nigeria, while retaining the British monarch, Elizabeth II, as nominal head of state and Queen of Nigeria. Independent Nigeria's founding government was a coalition of conservative parties: the Northern People's Congress (NPC) led by Sir Ahmadu Bello, a party dominated by Muslim Northerners, and the Igbo and Christian-dominated National Council of Nigeria and the Cameroons (NCNC) led by Nnamdi Azikiwe. Azikiwe replaced the colonial governor-general in November 1960. The opposition comprised the comparatively liberal Action Group (AG), which was largely dominated by the Yoruba and led by Obafemi Awolowo. At independence, the cultural and political differences were sharp among Nigeria's dominant ethnic groups: the Hausa–Fulani ('Northerners'), Igbo ('Easterners') and Yoruba ('Westerners'). An imbalance was created in the polity by the result of the 1961 plebiscite. Southern Cameroons (since renamed by separatists as Ambazonia) opted to join the Republic of Cameroon while Northern Cameroons chose to remain in Nigeria. The northern part of the country then became larger than the southern part. In 1963, the nation established a Federal Republic, with Azikiwe as its first president. When elections were held in 1965, the Nigerian National Democratic Party came to power in Nigeria's Western Region.

The disequilibrium and perceived corruption of the electoral and political process led, in 1966, to back-to-back military coups. The first coup was in January 1966 and was led mostly by Igbo soldiers under Majors Emmanuel Ifeajuna and Chukwuma Kaduna Nzeogwu. The coup plotters succeeded in assassinating Sir Ahmadu Bello and Abubakar Tafawa Balewa alongside prominent leaders of the Northern Region and also Premier Samuel Akintola of the Western Region, but the coup plotters struggled to form a central government. Senate President Nwafor Orizu handed over government control to the Army, then under the command of another Igbo officer, General Johnson Aguiyi-Ironsi. Later, the counter-coup of 1966, supported primarily by Northern military officers, facilitated the rise Yakubu Gowon as military head of state. Tension rose between North and South; Igbos in Northern cities suffered persecution and many fled to the Eastern Region.

In May 1967, Governor of the Eastern Region Lt. Colonel Emeka Ojukwu declared the region independence from the federation as a state called the Republic of Biafra, under his leadership. This declaration precipitated the Nigerian Civil War, which began as the official Nigerian government side attacked Biafra on 6 July 1967 at Garkem. The 30-month war, with a long siege of Biafra and its isolation from trade and supplies, ended in January 1970. Estimates of the number of dead in the former Eastern Region during the 30-month civil war range from one to three million. France, Egypt, the Soviet Union, Britain, Israel, and others were deeply involved in the civil war behind the scenes. Britain and the Soviet Union were the main military backers of the Nigerian government; with Nigeria utilizing air support from Egyptian pilots provided by Gamal Abdel Nasser, while France and Israel aided the Biafrans. The Congolese government, under President Joseph-Désiré Mobutu, took an early stand on the Biafran secession, voicing strong support for the Nigerian federal government and deploying thousands of troops to fight against the secessionists.

Following the war, Nigeria enjoyed the oil boom of the 1970s, during which the country joined OPEC and received huge oil revenues. Despite these revenues, the military government did little to improve the standard of living of the population, help small and medium businesses, or invest in infrastructure. As oil revenues fueled the rise of federal subsidies to states, the federal government became the centre of political struggle and the threshold of power in the country. As oil production and revenue rose, the Nigerian government became increasingly dependent on oil revenues and international commodity markets for budgetary and economic concerns. The coup in July 1975, led by Generals Shehu Musa Yar'Adua and Joseph Garba ousted Gowon, who fled to Britain. The coup plotters wanted to replace Gowon's autocratic rule with a triumvirate of three brigadier generals whose decisions could be vetoed by a Supreme Military Council. For this triumvirate, they convinced General Murtala Mohammad to become military head of state, with General Olusegun Obasanjo as his second-in-command, and General Theophilus Danjuma as the third. Together, the triumvirate introduces austerity measures to stem inflation, established a Corrupt Practices Investigation Bureau, replaced all military governors with new officers, and launched "Operation Deadwood" through which they fired 11,000 officials from the civil service.

Colonel Buka Suka Dimka launched the February 1976 coup against Nigeria's government, during which General Murtala Mohammed was assassinated. Dimka lacked widespread support among the military and his coup failed, forcing him to flee. After the coup attempt, General Olusegun Obasanjo was appointed military head of state. As head of state, Obasanjo vowed to continue Murtala's policies. Aware of the danger of alienating northern Nigerians, Obasanjo brought General Shehu Yar'Adua as his replacement and second-in-command as Chief of Staff, Supreme Headquarters completing the military triumvirate, with Obasanjo as head of state and General Theophilus Danjuma as Chief of Army Staff, the three went on to re-establish control over the military regime and organized the military's transfer of power programme: states creation and national delimitation, local government reforms and the constitutional drafting committee of the Second Nigerian Republic.

In 1977, constituent assembly was elected to draft a new constitution, which was published on September 21, 1978, when the ban on political activity was lifted. In 1979, five political parties competed in a series of elections in which Alhaji Shehu Shagari of the National Party of Nigeria (NPN) was elected president. Obasanjo peacefully transferred power to Shagari, becoming the first head of state in Nigerian history to willingly step down. All five parties won representation in the National Assembly. In August 1983 Shagari and the NPN were returned to power in a landslide victory, with a majority of seats in the National Assembly and control of 12 state governments. But the elections were marred by violence and allegations of widespread vote rigging and electoral malfeasance led to legal battles over the results. In the widely monitored 1979 election, Alhaji Shehu Shagari was elected on the NPN platform.

Beginning in 1979, Nigerians participated in a return to democracy when Olusegun Obasanjo transferred power to the civilian regime of Shehu Shagari. On October 1, 1979, Shehu Shagari was sworn in as the first President and Commander-in-Chief of the Federal Republic of Nigeria. The military carefully planned the return to civil rule putting in place measures to ensure that political parties have broader support than witnessed during the first republic. The Shagari government became viewed as corrupt by virtually all sectors of Nigerian society. In 1983 the inspectors of the state-owned Nigerian National Petroleum Corporation (NNPC) began to notice "the slow poisoning of the waters of this country". But there were also uncertainties, such as that first republic, political leaders may be unable to govern properly which would bring another batch of new military rulers.

The 1983 military coup d'état took place on New Year's Eve of that year. It was coordinated by key officers of the Nigerian military and led to the overthrow of the Second Nigerian Republic and the installation of Major General Muhammadu Buhari as Head of State. The military coup of Muhammadu Buhari shortly after the regime's re-election in 1984 was generally viewed as a positive development. Buhari promised major reforms, but his government fared little better than its predecessor. His regime was overthrown by another military coup in 1985.

General Buhari was overthrown in 1985 military coup d'état led by General Ibrahim Babangida, who established the Armed Forces Ruling Council and became military president and commander in chief of the armed forces. In 1986, he established the Nigerian Political Bureau of 1986 which made recommendations for the transition to the Third Nigerian Republic. In 1989, Babangida started making plans for the transition to the Third Nigerian Republic. He legalized the formation of political parties, and formed the two-party system with the Social Democratic Party (SDP) and National Republican Convention (NRC) ahead of the 1992 general elections. He urged all Nigerians to join either of the parties, which the late Chief Bola Ige famously referred to as "two leper hands." The two-party state had been a Political Bureau recommendation. In November 1991, after a census was conducted, the National Electoral Commission (NEC) announced on 24 January 1992 that both legislative elections to a bicameral National Assembly and a presidential election would be held later that year. A process of voting was adopted, referred to as Option A4. This process advocated that any candidate needed to pass through adoption for all elective positions from the local government, state government and federal government.

Babangida survived the 1990 Nigerian coup d'état attempt, then postponed a promised return to democracy to 1992. The 1993 presidential election held on June 12, the first since the military coup of 1983. The results though not officially declared by the National Electoral Commission – showed the duo of Moshood Abiola and Babagana Kingibe of the Social Democratic Party (SDP) defeated Bashir Tofa and Slyvester Ugoh of the National Republican Convention (NRC) by over 2.3 million votes. However, Babangida annulled the elections, leading to massive civilian protests that effectively shut down the country for weeks. In August 1993, Babangida finally kept his promise to relinquish power to a civilian government, but not before appointing Ernest Shonekan head of the Interim National Government. Babangida's regime has been considered the most corrupt, and responsible for creating a culture of corruption in Nigeria.

In late 1993, Shonekan's interim government, the shortest in the political history of the country was overthrown in the 1993 military coup d'état led by General Sani Abacha, who used military force on a wide scale to suppress the continuing civilian unrest. In 1995 the government hanged environmentalist Ken Saro-Wiwa on trumped-up charges in the deaths of four Ogoni elders. Lawsuits under the American Alien Tort Statute against Royal Dutch Shell and Brian Anderson, the head of Shell's Nigerian operation, settled out of court with Shell continuing to deny liability. Several hundred million dollars in accounts traced to Abacha were discovered in 1999. The regime came to an end in 1998, when the dictator died in the villa. He looted money to offshore accounts in western European banks and defeated coup plots by arresting and bribing generals and politicians. His successor, General Abdulsalami Abubakar, adopted a new constitution on 5 May 1999 which provided for multiparty elections.

On 29 May 1999, Abubakar transferred power to the winner of the 1999 presidential election, former military ruler General Olusegun Obasanjo as the second democratically elected civilian President of Nigeria heralding the beginning of the Fourth Nigerian Republic. This ended almost 33 years of military rule from 1966 until 1999, excluding the short-lived second republic (between 1979 and 1983) by military dictators who seized power in coups d'état and counter-coups during the Nigerian military juntas of 1966–1979 and 1983–1999.

Although the elections that brought Obasanjo to power in the 1999 presidential election and for a second term in the 2003 presidential election were condemned as unfree and unfair, Nigeria has shown marked improvements in attempts to tackle government corruption and hasten development. Ethnic violence for control over the oil-producing Niger Delta region and an insurgency in the North-East are some of the issues facing the country. Umaru Yar'Adua of the People's Democratic Party came into power in the general election of 2007. The international community, which had been observing Nigerian elections to encourage a free and fair process, condemned this one as being severely flawed. The then-president, Olusegun Obasanjo, acknowledged fraud and other electoral "lapses" but said the result reflected opinion polls. In a national television address in 2007, he added that if Nigerians did not like the victory of his handpicked successor, they would have an opportunity to vote again in four years. Yar'Adua died on 5 May 2010.  Goodluck Jonathan was sworn in as Yar'Adua's, becoming the 14th Head of State. Goodluck Jonathan served as acting president of Nigeria until 16 April 2011, when a new presidential election in Nigeria was conducted. He went on to win the elections, with the international media reporting the elections as having run smoothly with relatively little violence or voter fraud, in contrast to previous elections.

Ahead of the general election of 2015, a merger of the three biggest opposition parties – the Action Congress of Nigeria(ACN), the Congress for Progressive Change (CPC), the All Nigeria Peoples Party (ANPP), a faction of the All Progressives Grand Alliance (APGA) and the new PDP (nPDP), a faction of serving governors of the then ruling People's Democratic Party – formed the All Progressives Congress (APC). In the 2015 presidential election, former military head of state General Muhammadu Buhari, leader of the CPC faction of the APC – who had previously contested in the 2003, 2007, and 2011 presidential elections as the APC presidential candidate defeated incumbent President Goodluck Jonathan of the People's Democratic Party (PDP) by over two million votes, ending the party's sixteen year rule in the country, and marking the first time in the history of Nigeria that an incumbent president lost to an opposition candidate. Observers generally praised the election as being fair. Jonathan was generally praised for conceding defeat and limiting the risk of unrest. In the 2019 presidential election, Muhammadu Buhari was re-elected for a second term in office defeating his closet rival Atiku Abubakar.

Nigeria is a federal republic modelled after the United States, with executive power exercised by the President. It is influenced by the Westminster System model in the composition and management of the upper and lower houses of the bicameral legislature. The president is both head of state and head of the federal government; the leader is elected by popular vote to a maximum of two four-year terms. The president's power is checked by a Senate and a House of Representatives, which are combined in a bicameral body called the National Assembly. The Senate is a 109-seat body with three members from each state and one from the capital region of Abuja; members are elected by popular vote to four-year terms. The House contains 360 seats, with the number of seats per state determined by population.

Ethnocentrism, tribalism, religious persecution, and prebendalism have affected Nigerian politics both prior and subsequent to independence in 1960. All major parties have practised vote-rigging and other means of coercion to remain competitive. In the period before 1983 election, a report of experts prepared by the National Institute of Policy and Strategic Studies showed that only the 1959 and 1979 elections were held without systematic rigging. In 2012, Nigeria was estimated to have lost over $400 billion to corruption since independence. Kin-selective altruism has made its way into Nigerian politics, resulting in tribalist efforts to concentrate Federal power to a particular region of their interests through.

Hausa-Fulani, Yoruba and Igbo are the three largest ethnic groups in Nigeria and have maintained historical preeminence in Nigerian politics; competition amongst these three groups has fuelled animosity. Following the bloody civil war, nationalism has seen an increase in the southern part of the country leading to active secessionist movements such as the Oodua Peoples Congress (OPC) and the Movement for the Actualization of the Sovereign State of Biafra (MASSOB).

Because of the above issues, Nigeria's political parties are pan-national and secular in character (though this does not preclude the continuing preeminence of the dominant ethnicities). The two major political parties are the People's Democratic Party of Nigeria and the All Progressives Congress with twenty minor opposition parties are registered. As in many other African societies, prebendalism and high rates of corruption continue to constitute major challenges to Nigeria.

The country has a judicial branch, with the highest court being the Supreme Court of Nigeria. There are three distinct systems of law in Nigeria:


The Nigerian military are charged with protecting the Federal Republic of Nigeria, promoting Nigeria's global security interests, and supporting peacekeeping efforts, especially in West Africa. This is in support of the doctrine sometimes called Pax Nigeriana.

The Nigerian Military consist of an army, a navy, and an air force. The military in Nigeria have played a major role in the country's history since independence. Various juntas have seized control of the country and ruled it through most of its history. Its last period of military rule ended in 1999 following the sudden death of former dictator Sani Abacha in 1998. His successor, Abdulsalam Abubakar, handed over power to the democratically elected government of Olusegun Obasanjo the next year.

As Africa's most populated country, Nigeria has repositioned its military as a peacekeeping force on the continent. Since 1995, the Nigerian military, through ECOMOG mandates, have been deployed as peacekeepers in Liberia (1997), Ivory Coast (1997–1999), and Sierra Leone (1997–1999). Under an African Union mandate, it has stationed forces in Sudan's Darfur region to try to establish peace.

Nigeria has been pervaded by political corruption. Nigeria was ranked 143 out of 182 countries in Transparency International's 2011 Corruption Perceptions Index; however, it improved to 136th position in 2014. More than $400 billion were stolen from the treasury by Nigeria's leaders between 1960 and 1999. In 2015, incumbent President Muhammadu Buhari said corrupt officials have stolen $150 billion from Nigeria in the last 10 years.

Upon gaining independence in 1960, Nigeria made African unity the centrepiece of its foreign policy and played a leading role in the fight against the apartheid government in South Africa. One exception to the African focus was Nigeria's close relationship developed with Israel throughout the 1960s. The latter nation sponsored and oversaw the construction of Nigeria's parliament buildings.

Nigeria's foreign policy was tested in the 1970s after the country emerged united from its own civil war. It supported movements against white minority governments in the Southern Africa sub-region. Nigeria backed the African National Congress (ANC) by taking a committed tough line with regard to the South African government and their military actions in southern Africa. Nigeria was also a founding member of the Organisation for African Unity (now the African Union), and has tremendous influence in West Africa and Africa on the whole. Nigeria has additionally founded regional cooperative efforts in West Africa, functioning as standard-bearer for the Economic Community of West African States (ECOWAS) and ECOMOG, economic and military organizations, respectively.

With this Africa-centred stance, Nigeria readily sent troops to the Congo at the behest of the United Nations shortly after independence (and has maintained membership since that time). Nigeria also supported several Pan-African and pro-self government causes in the 1970s, including garnering support for Angola's MPLA, SWAPO in Namibia, and aiding opposition to the minority governments of Portuguese Mozambique, and Rhodesia.

Nigeria retains membership in the Non-Aligned Movement. In late November 2006, it organised an Africa-South America Summit in Abuja to promote what some attendees termed "South-South" linkages on a variety of fronts. Nigeria is also a member of the International Criminal Court, and the Commonwealth of Nations. It was temporarily expelled from the latter in 1995 when ruled by the Abacha regime.

Nigeria has remained a key player in the international oil industry since the 1970s, and maintains membership in Organization of the Petroleum Exporting Countries (OPEC), which it joined in July 1971. Its status as a major petroleum producer figures prominently in its sometimes volatile international relations with developed countries, notably the United States, and with developing countries.

Millions of Nigerians have emigrated during times of economic hardship, primarily to Europe, North America and Australia. It is estimated that over a million Nigerians have emigrated to the United States and constitute the Nigerian American populace. Individuals in many such Diasporic communities have joined the "Egbe Omo Yoruba" society, a national association of Yoruba descendants in North America.

In July 2019, UN ambassadors of 37 countries, including Nigeria, have signed a joint letter to the UNHRC defending China's treatment of Uyghurs in the Xinjiang region.

Since 2000, Sino-Nigerian trade relations have risen exponentially. There has been an increase in total trade of over 10,384 million dollars between the two nations from 2000 to 2016. However the structure of the Sino-Nigerian trade relationship has become a major political issue for the Nigerian state. This is illustrated by the fact that Chinese exports account for around 80 percent of total bilateral trade volumes. This has resulted in a serious trade imbalance, with Nigeria importing ten times more than it exports to China. Subsequently, Nigeria's economy is becoming over-reliant on cheap foreign imports to sustain itself, resulting in a clear decline in Nigerian Industry under such arrangements.

Nigeria may suffer a deterioration of its position in international affairs if the global transition to renewable energy is completed and international demand for its petroleum resources ceases. It is ranked 149 out of 156 countries in the index of Geopolitical Gains and Losses after energy transition (GeGaLo).

Nigeria is divided into thirty-six states and one Federal Capital Territory, which are further sub-divided into 774 Local Government Areas. In some contexts, the states are aggregated into six geopolitical zones: North West, North East, North Central, South West, South East, and South South. Nigeria has five cities with a population of over a million (from largest to smallest): Lagos, Kano, Ibadan, Benin City and Port Harcourt. Lagos is the largest city in Africa, with a population of over 12 million in its urban area.

Nigeria is located in western Africa on the Gulf of Guinea and has a total area of , making it the world's 32nd-largest country. It is comparable in size to Venezuela, and is about twice the size of the U.S. state of California. Its borders span , and it shares borders with Benin (), Niger (), Chad (), and Cameroon (including the separatist Ambazonia) . Its coastline is at least . Nigeria lies between latitudes 4° and 14°N, and longitudes 2° and 15°E.

The highest point in Nigeria is Chappal Waddi at . The main rivers are the Niger and the Benue, which converge and empty into the Niger Delta. This is one of the world's largest river deltas, and the location of a large area of Central African mangroves.

Nigeria has a varied landscape. The far south is defined by its tropical rainforest climate, where annual rainfall is a year. In the southeast stands the Obudu Plateau. Coastal plains are found in both the southwest and the southeast. This forest zone's most southerly portion is defined as "salt water swamp", also known as a mangrove swamp because of the large amount of mangroves in the area. North of this is fresh water swamp, containing different vegetation from the salt water swamp, and north of that is rainforest.

Nigeria's most expansive topographical region is that of the valleys of the Niger and Benue river valleys (which merge and form a Y-shape). To the southwest of the Niger is "rugged" highland. To the southeast of the Benue are hills and mountains, which form the Mambilla Plateau, the highest plateau in Nigeria. This plateau extends through the border with Cameroon, where the montane land is part of the Bamenda Highlands of Cameroon.

The area near the border with Cameroon close to the coast is rich rainforest and part of the Cross-Sanaga-Bioko coastal forests ecoregion, an important centre for biodiversity. It is habitat for the drill monkey, which is found in the wild only in this area and across the border in Cameroon. The areas surrounding Calabar, Cross River State, also in this forest, are believed to contain the world's largest diversity of butterflies. The area of southern Nigeria between the Niger and the Cross Rivers has lost most of its forest because of development and harvesting by increased population, with it being replaced by grassland ("see Cross-Niger transition forests").

Everything in between the far south and the far north is savannah (insignificant tree cover, with grasses and flowers located between trees). Rainfall is more limited, to between per year. The savannah zone's three categories are Guinean forest-savanna mosaic, Sudan savannah, and Sahel savannah. Guinean forest-savanna mosaic is plains of tall grass interrupted by trees. Sudan savannah is similar but with shorter grasses and shorter trees. Sahel savannah consists of patches of grass and sand, found in the northeast. In the Sahel region, rain is less than per year and the Sahara Desert is encroaching. In the dry northeast corner of the country lies Lake Chad, which Nigeria shares with Niger, Chad and Cameroon.

Nigeria is greatly endowed with numerous tree species of which the majority of them are native while few are exotic. Report shows that high percentage of man-made forests in the country is dominated with exotic species. This culminated from the assumption that exotic trees are fast growing. However, studies have also investigated the growth of indigenous trees in with that of exotic species.

Many countries in Africa are affected by Invasive Alien Species (IAS). In 2004, the IUCN–World Conservation Union identified 81 IAS in South Africa, 49 in Mauritius, 37 in Algeria and Madagascar, 35 in Kenya, 28 in Egypt, 26 in Ghana and Zimbabwe, and 22 in Ethiopia. However, very little is known about IAS in Nigeria, with most technical reports and literatures reporting fewer than 10 invasive plants in the country. Aside from plant invaders, "Rattus rattus" and Avian influenza virus were also considered IAS in Nigeria. The initial entry of IAS into Nigeria was mainly through exotic plant introductions by the colonial rulers either for forest tree plantations or for ornamental purposes. The entry of exotic plants into Nigeria during the post-independence era was encouraged by increasing economic activity, commencement of commercial oil explorations, introduction through ships, and introduction of ornamental plants by commercial floriculturists.

Due to overexploitation, the remaining natural ecosystems and primary forests in Nigeria are restricted to the protected areas which include one biosphere reserve, seven national parks, one World Heritage site, 12 Strict Nature Reserves (SNRs), 32 game reserves/wildlife sanctuaries, and hundreds of forest reserves. These are in addition to several ex-situ conservation sites such as arboreta, botanical gardens, zoological gardens, and gene banks managed by several tertiary and research institutions

In the semi-arid and dry sub-humid savanna's of West Africa, including Nigeria, numerous species of herbaceous dicots especially from the genera "Crotalaria", "Alysicarpus", "Cassia" and "Ipomea" are known to be widely used in livestock production. Quite often they are plucked or cut, and fed either as fresh or conserved fodders. The utilization of these and many other herbs growing naturally within the farm environment is opportunistic.

Many other species native to Nigeria, including Soybean and its varieties, serve as an important source of oil and protein in this region. There are also many plants with medicinal purposes that are used to aid the therapy in many organs. Some of these vegetations include, "Euphorbiaceae", that serve purposed to aid malaria, gastrointestinal disorders and many other infections. Different stress factors such as droughts, low soil nutrients and susceptibility to pests has contributed to Maize plantations being an integral part of agriculture in this region.

As industrialization has increased, it has also put species of trees in the forest at risk to air pollution and studies have shown that in certain part of Nigeria, trees have shown tolerance and grow in areas that have a significant amount air pollution

Nigeria's Delta region, home of the large oil industry, experiences serious oil spills and other environmental problems, which has caused conflict.

Waste management including sewage treatment, the linked processes of deforestation and soil degradation, and climate change or global warming are the major environmental problems in Nigeria. Waste management presents problems in a mega city like Lagos and other major Nigerian cities which are linked with economic development, population growth and the inability of municipal councils to manage the resulting rise in industrial and domestic waste. This huge waste management problem is also attributable to unsustainable environmental management lifestyles of Kubwa Community in the Federal Capital Territory, where there are habits of indiscriminate disposal of waste, dumping of waste along or into the canals, sewerage systems that are channels for water flows, and the like.

Haphazard industrial planning, increased urbanisation, poverty and lack of competence of the municipal government are seen as the major reasons for high levels of waste pollution in major cities of the country. Some of the 'solutions' have been disastrous to the environment, resulting in untreated waste being dumped in places where it can pollute waterways and groundwater.

In 2005 Nigeria had the highest rate of deforestation in the world, according to the Food and Agriculture Organization of the United Nations (FAO). That year, 12.2%, the equivalent of 11,089,000 hectares had been forested in the country. Between 1990 and 2000, Nigeria lost an average of 409,700 hectares of forest every year equal to an average annual deforestation rate of 2.4%. Between 1990 and 2005, in total Nigeria lost 35.7% of its forest cover, or around 6,145,000 hectares.

In 2010, thousands of people were inadvertently exposed to lead-containing soil / ore from informal gold mining within the northern state of Zamfara. While estimates vary, it is thought that upwards of 400 children died of acute lead poisoning, making this perhaps the largest lead poisoning fatality epidemic ever encountered. As of 2016, efforts to manage the exposure are ongoing.

Nigeria is classified as a mixed economy emerging market. It has reached lower middle income status according to the World Bank, with its abundant supply of natural resources, well-developed financial, legal, communications, transport sectors and stock exchange (the Nigerian Stock Exchange), which is the second largest in Africa.

Nigeria was ranked 21st in the world in terms of GDP (PPP) in 2015. Nigeria is the United States' largest trading partner in sub-Saharan Africa and supplies a fifth of its oil (11% of oil imports). It has the seventh-largest trade surplus with the U.S. of any country worldwide. Nigeria is the 50th-largest export market for U.S. goods and the 14th-largest exporter of goods to the U.S. The United States is the country's largest foreign investor. Following the oil price collapse in 2014–2016, combined with negative production shocks, the gross domestic product (GDP) growth rate dropped to 2.7% in 2015. In 2016 during its first recession in 25 years, the economy contracted by 1.6%. Fiscal year 2016 was characterized by currency depreciation and the attendant higher prices of petroleum products, electricity and imported foods pushed inflation to 18.55% in December 2016 from 9.55% in December 2015.

In 2019, the economy began to recover slightly with the nation's real GDP growing by 2.3% and the IMF estimating another increase of 2.3% in 2020.

Economic development has been hindered by years of military rule, corruption, and mismanagement. The restoration of democracy and subsequent economic reforms have successfully put Nigeria back on track towards achieving its full economic potential. it is the largest economy in Africa, having overtaken South Africa. Next to petrodollars, the second biggest source of foreign exchange earnings for Nigeria are remittances sent home by Nigerians living abroad.

During the oil boom of the 1970s, Nigeria accumulated a significant foreign debt to finance major infrastructural investments. With the fall of oil prices during the 1980s oil glut Nigeria struggled to keep up with its loan payments and eventually defaulted on its principal debt repayments, limiting repayment to the interest portion of the loans. Arrears and penalty interest accumulated on the unpaid principal, which increased the size of the debt. After negotiations by the Nigerian authorities, in October 2005 Nigeria and its Paris Club creditors reached an agreement under which Nigeria repurchased its debt at a discount of approximately 60%. Nigeria used part of its oil profits to pay the residual 40%, freeing up at least $1.15 billion annually for poverty reduction programmes. Nigeria made history in April 2006 by becoming the first African country to completely pay off its debt (estimated $30 billion) owed to the Paris Club.

Nigeria is trying to reach the first of the Sustainable Development Goals, which is to end poverty in all its forms by 2030.

, about 30% of Nigerians are employed in agriculture. Agriculture used to be the principal foreign exchange earner of Nigeria.

Major crops include beans, sesame, cashew nuts, cassava, cocoa beans, groundnuts, gum arabic, kolanut, maize (corn), melon, millet, palm kernels, palm oil, plantains, rice, rubber, sorghum, soybeans and yams. Cocoa is the leading non-oil foreign exchange earner. Rubber is the second-largest non-oil foreign exchange earner.

Prior to the Nigerian civil war, Nigeria was self-sufficient in food. Agriculture has failed to keep pace with Nigeria's rapid population growth, and Nigeria now relies upon food imports to sustain itself. The Nigerian government promoted the use of inorganic fertilizers in the 1970s. In August 2019, Nigeria closed its border with Benin to stop rice smuggling into the country as part of efforts to boost the local production.

Nigeria is the 12th largest producer of petroleum in the world and the 8th largest exporter, and has the 10th largest proven reserves. (The country joined OPEC in 1971.) Petroleum plays a large role in the Nigerian economy, accounting for 40% of GDP and 80% of Government earnings. However, agitation for better resource control in the Niger Delta, its main oil-producing region, has led to disruptions in oil production and prevents the country from exporting at 100% capacity.
The Niger Delta Nembe Creek Oil field was discovered in 1973 and produces from middle Miocene deltaic sandstone-shale in an anticline structural trap at a depth of . In June 2013, Shell announced a strategic review of its operations in Nigeria, hinting that assets could be divested. While many international oil companies have operated there for decades, by 2014 most were making moves to divest their interests, citing a range of issues including oil theft. In August 2014, Shell Oil Company said it was finalising its interests in four Nigerian oil fields.

Nigeria has a total of 159 oil fields and 1,481 wells in operation according to the Department of Petroleum Resources. The most productive region of the nation is the coastal Niger Delta Basin in the Niger Delta or "South-south" region which encompasses 78 of the 159 oil fields. Most of Nigeria's oil fields are small and scattered, and as of 1990, these small fields accounted for 62.1% of all Nigerian production. This contrasts with the sixteen largest fields which produced 37.9% of Nigeria's petroleum at that time.

In addition to its petroleum resources, Nigeria also has a wide array of underexploited mineral resources which include natural gas, coal, bauxite, tantalite, gold, tin, iron ore, limestone, niobium, lead and zinc. Despite huge deposits of these natural resources, the mining industry in Nigeria is still in its infancy.

Nigeria has a highly developed financial services sector, with a mix of local and international banks, asset management companies, brokerage houses, insurance companies and brokers, private equity funds and investment banks. Nigeria has one of the fastest growing telecommunications markets in the world, major emerging market operators (like MTN, 9mobile, Airtel and Globacom) basing their largest and most profitable centres in the country. Nigeria's ICT sector has experienced a lot of growth, representing 10% of the nation's GDP in 2018 as compared to just 1% in 2001. Lagos is regarded as one of the largest technology hubs in Africa with its thriving tech ecosysytem. Several startups like Paystack, Interswitch, Bolt and Piggyvest are leveraging technology to solve issues across different sectors.

Tourism in Nigeria centers largely on events, due to the country's ample amount of ethnic groups, but also includes rain forests, savannah, waterfalls, and other natural attractions.

Abuja is home to several parks and green areas. The largest, Millennium Park, was designed by architect Manfredi Nicoletti and officially opened in December 2003.
Lagos, subsequent to the re-modernization project achieved by the previous administration of Governor Raji Babatunde Fashola, is gradually becoming a major tourist destination, being one of the largest cities in Africa and in the world. Lagos is currently taking steps to become a global city. The 2009 Eyo carnival (a yearly festival originated from Iperu Remo, Ogun State), which took place on 25 April, was a step toward world city status. Currently, Lagos is primarily known as a business-oriented and a fast-paced community. Lagos has become an important location for African and "black" cultural identity. Many festivals are held in Lagos; festivals vary in offerings each year and may be held in different months. Some of the festivals are Festac Food Fair held in Festac Town Annually, Eyo Festival, Lagos Black Heritage Carnival, Lagos Carnival, Eko International Film Festival, Lagos Seafood Festac Festival, LAGOS PHOTO Festival and the Lagos Jazz Series, which is a unique franchise for high-quality live music in all genres with a focus on jazz. Established in 2010, the event takes place over a 3- to 5-day period at selected high quality outdoor venues. The music is as varied as the audience itself and features a diverse mix of musical genres from rhythm and blues to soul, Afrobeat, hip hop, bebop, and traditional jazz. The festivals provide entertainment of dance and song to add excitement to travelers during a stay in Lagos.

Lagos has a number of sandy beaches by the Atlantic Ocean, including Elegushi Beach and Alpha Beach. Lagos also has a number of private beach resorts including Inagbe Grand Beach Resort and several others in the outskirts. Lagos has a variety of hotels ranging from three star to five star hotels, with a mixture of local hotels such as Eko Hotels and Suites, Federal Palace Hotel and franchises of multinational chains such as Intercontinental Hotel, Sheraton and Four Points by Hilton. Other places of interest include the Tafawa Balewa Square, Festac town, The Nike Art Gallery, Freedom Park, Lagos and the Cathedral Church of Christ, Lagos.

Nigeria has a manufacturing industry that includes leather and textiles (centred in Kano, Abeokuta, Onitsha, and Lagos), Nigeria currently has an indigenous auto manufacturing company; Innoson Vehicle Manufacturing located in Nnewi. It produces Buses and SUVs. Car manufacturing (for the French car manufacturer Peugeot as well as for the English truck manufacturer Bedford, now a subsidiary of General Motors), T-shirts, plastics and processed food. In this regard, some foreign vehicle manufacturing companies like Nissan have made known their plans to have manufacturing plants in Nigeria. Ogun is considered to be Nigeria's current industrial hub, as most factories are located in Ogun and more companies are moving there, followed by Lagos.

Nigeria in recent years has been embracing industrialisation. It currently has an indigenous vehicle manufacturing company, Innoson Motors, which manufactures saloon cars, rapid transit buses, ambulances, firefighting trucks and SUVs. Nigeria also has a few electronic manufacturers like Zinox, the first branded Nigerian computer, and manufacturers of electronic gadgets such as tablet PCs. In 2013, Nigeria introduced a policy regarding import duty on vehicles to encourage local manufacturing companies in the country. The city of Aba in the south-eastern part of the country are well known for their handicrafts and shoes, known as "Aba made".

Nigeria's primary energy consumption was about 108 Mtoe in 2011. Most of the energy comes from traditional biomass and waste, which account for 83% of total primary production. The rest is from fossil fuels (16%) and hydropower (1%).

From independence, Nigeria has tried to develop a domestic nuclear industry for energy. Since 2004, Nigeria has a Chinese-origin research reactor at Ahmadu Bello University, and has sought the support of the International Atomic Energy Agency to develop plans for up to 4,000 MWe of nuclear capacity by 2027 according to the National Program for the Deployment of Nuclear Power for Generation of Electricity. Nigeria hoped to begin construction in 2011 and start nuclear power production in 2017–2020. On 27 July 2007 Nigeria's President Umaru Yar'Adua urged the country to embrace nuclear power in order to meet its growing energy needs. Construction has not begun but plans have not been canceled by 2016. In 2017, Nigeria signed the UN treaty on the Prohibition of Nuclear Weapons.

In April 2015, Nigeria began talks with Russia's state-owned Rosatom to collaborate on the design, construction and operation of four nuclear power plants by 2035, the first of which will be in operation by 2025. In June 2015, Nigeria selected two sites for the planned construction of the nuclear plants. Neither the Nigerian government nor Rosatom would disclose the specific locations of the sites, but it is believed that the nuclear plants will be sited in Akwa Ibom State, in South-South Nigeria, and Kogi State, in the central northern part of the country. Both sites are planned to house two plants each. In 2017 agreements were signed for the construction of the Itu nuclear power plant.

Nigeria suffers from lack of adequate transportation infrastructure. As of 1999, it's 194,394 kilometers of road networks are the main means of transportation. Of which (including of expressways) are paved roads and as of 1998 (west.), 134,326 kilometers ar unpaved roads of city, town and village roads. The railways have undergone a massive revamping with projects such as the Lagos-Kano Standard Gauge Railway being completed connecting northern cities of Kano, Kaduna, Abuja, Ibadan and Lagos.

There are 54 airports in Nigeria; the principal airports are Murtala Muhammed International Airport in Lagos and Nnamdi Azikiwe International Airport in Abuja. Three other international airports are Mallam Aminu Kano International Airport in Kano, Akanu Ibiam International Airport in Enugu and Port Harcourt International Airport in Port Harcourt. As with other transportation facilities, the airports suffer from a poor reputation for safety and operational efficiency.

The government has recently begun expanding this infrastructure to space-based communications. Nigeria has a space satellite that is monitored at the Nigerian National Space Research and Development Agency Headquarters in Abuja. The Nigerian government has commissioned the overseas production and launch of four satellites.

NigComSat-1, was the first Nigerian satellite built in 2004, was Nigeria's third satellite and Africa's first communication satellite. It was launched on 13 May 2007, aboard a Chinese Long March 3B carrier rocket, from the Xichang Satellite Launch Centre in China. The spacecraft was operated by NigComSat and the Nigerian Space Research and Development Agency. On 11 November 2008, NigComSat-1 failed in orbit after running out of power because of an anomaly in its solar array. It was based on the Chinese DFH-4 satellite bus, and carries a variety of transponders: four C-band; fourteen Ku-band; eight Ka-band; and two L-band. It was designed to provide coverage to many parts of Africa, and the Ka-band transponders would also cover Italy. The satellite was launched from Russia on 27 September 2003. Nigeriasat-1 was part of the worldwide Disaster Monitoring Constellation System. The primary objectives of the Nigeriasat-1 were: to give early warning signals of environmental disaster; to help detect and control desertification in the northern part of Nigeria; to assist in demographic planning; to establish the relationship between malaria vectors and the environment that breeds malaria and to give early warning signals on future outbreaks of meningitis using remote sensing technology; to provide the technology needed to bring education to all parts of the country through distant learning; and to aid in conflict resolution and border disputes by mapping out state and International borders.

NigeriaSat-2, Nigeria's second satellite, was built as a high-resolution earth satellite by Surrey Space Technology Limited, a United Kingdom-based satellite technology company. It has 2.5-metre resolution panchromatic (very high resolution), 5-metre multispectral (high resolution, NIR red, green and red bands), and 32-metre multispectral (medium resolution, NIR red, green and red bands) antennas, with a ground receiving station in Abuja. The NigeriaSat-2 spacecraft alone was built at a cost of over £35 million. This satellite was launched into orbit from a military base in China. On 10 November 2008 (0900 GMT), the satellite was reportedly switched off for analysis and to avoid a possible collision with other satellites. According to Nigerian Communications Satellite Limited, it was put into "emergency mode operation in order to effect mitigation and repairs". The satellite eventually failed after losing power on 11 November 2008. On 24 March 2009, the Nigerian Federal Ministry of Science and Technology, NigComSat Ltd. and CGWIC signed another contract for the in-orbit delivery of the NigComSat-1R satellite. NigComSat-1R was also a DFH-4 satellite, and the replacement for the failed NigComSat-1 was successfully launched into orbit by China in Xichang on 19 December 2011. The satellite, was stated to have a positive impact on national development in various sectors such as communications, internet services, health, agriculture, environmental protection and national security.

NigeriaEduSat-1 was a satellite designed, built, and owned by the Federal University of Technology Akure (FUTA), in conjunction with Nigeria's National Space Research and Development Agency and Japan's Kyushu Institute of Technology. It was equipped with 0.3 megapixel and 5 megapixel cameras, and with the rest of the satellite fleet took images of Nigeria. The satellite transmitted songs and poems as an outreach project to generate Nigerian interest in science. The signal could be received by amateur radio operators. The satellite constellation also conducted measurements of the atmospheric density above the Earth. The satellite cost about US$500,000 to manufacture and launch.

Nigeria's population increased by 57 million from 1990 to 2008, a 60% growth rate in less than two decades. As of 2017, the population stood at 191 million. Around 42.5% of the population were 14 years or younger, 19.6% were aged 15–24, 30.7% were aged 25–54, 4.0% aged 55–64, and 3.1% aged 65 years or older. The median age in 2017 was 18.4 years. Nigeria is the most populous country in Africa and accounts for about 17% of the continent's total population as of 2017; however, exactly how populous is a subject of speculation.

The United Nations estimates that the population in was at , distributed as 51.7% rural and 48.3% urban, and with a population density of 167.5 people per square kilometre. National census results in the past few decades have been disputed. The results of the most recent census were released in December 2006 and gave a population of 140,003,542. The only breakdown available was by gender: males numbered 71,709,859, females numbered 68,293,008. In June 2012, President Goodluck Jonathan said Nigerians should limit their number of children.

According to the United Nations, Nigeria has been undergoing explosive population growth and has one of the highest growth and fertility rates in the world. By their projections, Nigeria is one of eight countries expected to account collectively for half of the world's total population increase in 2005–2050. By 2100 the UN estimates that the Nigerian population will be between 505 million and 1.03 billion people (middle estimate: 730 million). In 1950, Nigeria had only 33 million people.

One in six Africans is Nigerian as of 2019. Presently, Nigeria is the seventh most populous country in the world. The birth rate is 35.2-births/1,000 population and the death rate is 9.6 deaths/1,000 population as of 2017, while the total fertility rate is 5.07 children born/woman.

Nigeria's largest city is Lagos. Lagos has grown from about 300,000 in 1950 to an estimated 13.4 million in 2017.

"See:List of ethnic groups in Nigeria"

Nigeria has more than 250 ethnic groups, with varying languages and customs, creating a country of rich ethnic diversity. The three largest ethnic groups are the Hausa, Yoruba and Igbo, together accounting for more than 70% of the population, while the Edo, Ijaw, Fulɓe, Kanuri, Urhobo-Isoko, Ibibio, Ebira, Nupe, Gbagyi, Jukun, Igala, Idoma and Tiv comprise between 25 and 30%; other minorities make up the remaining 5%.

The middle belt of Nigeria is known for its diversity of ethnic groups, including the Pyem, Goemai, and Kofyar. The official population count of each of Nigeria's ethnicities has always remained controversial and disputed as members of different ethnic groups believe the census is rigged to give a particular group (usually believed to be northern groups) numerical superiority.

There are small minorities of British, American, Indian, Chinese (est. 50,000), white Zimbabwean, Japanese, Greek, Syrian and Lebanese immigrants in Nigeria. Immigrants also include those from other West African or East African nations. These minorities mostly reside in major cities such as Lagos and Abuja, or in the Niger Delta as employees for the major oil companies. A number of Cubans settled in Nigeria as political refugees following the Cuban Revolution.

In the middle of the 19th century, a number of ex-slaves of Afro-Cuban and Afro-Brazilian descent and emigrants from Sierra Leone established communities in Lagos and other regions of Nigeria. Many ex-slaves came to Nigeria following the emancipation of slaves in the Americas. Many of the immigrants, sometimes called Saro (immigrants from Sierra Leone) and Amaro (ex-slaves from Brazil) later became prominent merchants and missionaries in these cities.

There are 521 languages that have been spoken in Nigeria; nine of them are now extinct.

In some areas of Nigeria, ethnic groups speak more than one language. The official language of Nigeria, English, was chosen to facilitate the cultural and linguistic unity of the country, owing to the influence of British colonisation which ended in 1960.

Many French speakers from surrounding countries have influenced the English spoken in the border regions of Nigeria and some Nigerian citizens have become fluent enough in French to work in the surrounding countries. The French spoken in Nigeria may be mixed with some native languages but is mostly spoken like the French spoken in Benin. French may also be mixed with English as it is in Cameroon.

The major languages spoken in Nigeria represent three major families of languages of Africa: the majority are Niger-Congo languages, such as Igbo, Yoruba, Ijaw, Fulfulde, Ogoni, and Edo. Kanuri, spoken in the northeast, primarily in Borno and Yobe State, is part of the Nilo-Saharan family, and Hausa is an Afroasiatic language.

Even though most ethnic groups prefer to communicate in their own languages, English as the official language is widely used for education, business transactions and for official purposes. English as a first language is used by only a small minority of the country's urban elite, and it is not spoken at all in some rural areas. Hausa is the most widely spoken of the three main languages spoken in Nigeria itself.

With the majority of Nigeria's populace in the rural areas, the major languages of communication in the country remain indigenous languages. Some of the largest of these, notably Yoruba and Igbo, have derived standardised languages from a number of different dialects and are widely spoken by those ethnic groups. Nigerian Pidgin English, often known simply as "Pidgin" or "Broken" (Broken English), is also a popular lingua franca, though with varying regional influences on dialect and slang. The pidgin English or Nigerian English is widely spoken within the Niger Delta Regions, predominantly in Warri, Sapele, Port Harcourt, Agenebode, Ewu, and Benin City.

Nigeria is a religiously diverse society, with Islam and Christianity being the most widely professed religions. Nigerians are nearly equally divided into Muslims and Christians, with a tiny minority of adherents of Traditional African religions and other religions. As common in other parts of Africa where Islam and Christianity are dominant, religious syncretism with the Traditional African religions is common throughout Nigeria.

Islam dominates North Western (Hausa, Fulani and others) and a good portion of Northern Eastern (Kanuri, Fulani and other groups) Nigeria. It also has a number of adherents in the South Western, Yoruba part of the country. Nigeria has the largest Muslim population in sub-Saharan Africa. Protestant and locally cultivated Christianity are also widely practiced in Western areas, while Roman Catholicism is a more prominent Christian feature of South Eastern Nigeria. Both Roman Catholicism and Protestantism are observed in the Ibibio, Annang, Efik, Ijo and Ogoni lands of the south.

The 1963 census indicated that 47% of Nigerians were Muslim, 34% Christian, and 18% members of local indigenous religions. The vast majority of Muslims in Nigeria are Sunni belonging to Maliki school of jurisprudence; however, a sizeable minority also belongs to Shafi Madhhab. A large number of Sunni Muslims are members of Sufi brotherhoods. Most Sufis follow the Qadiriyya, Tijaniyyah and/or the Mouride movements. A significant Shia minority exists ("see Shia in Nigeria"). Some northern states have incorporated Sharia law into their previously secular legal systems, which has brought about some controversy. Kano State has sought to incorporate Sharia law into its constitution. The majority of Quranists follow the Kalo Kato or Quraniyyun movement. There are also Ahmadiyya and Mahdiyya minorities, as well as Bahá'ís.

According to a 2001 report from "The World Factbook" by CIA, about 47% of Nigeria's population is Muslim, 43% are Christians and 10% adhere to local religions. An 18 December 2012 report on religion and public life by the Pew Research Center stated that in 2010, 49.3 percent of Nigeria's population was Christian, 48.8 percent was Muslim, and 1.9 percent were followers of indigenous and other religions, or unaffiliated. However, in a 2019 report released by Pew Research Center in 2015, the Muslim population was estimated to be 50%, and by 2060, according to the report, Muslims will account for 60% of the country.

The 2010 census of Association of Religion Data Archives has also reported that 46.5% of the total population was Christian, slightly larger than the Muslim population of 45.5%, while 7.7% were members of other religions. However, these estimates should be taken with caution because sample data is mostly collected from major urban areas in the south, which are predominantly Christian.

Among Christians, the Pew Research survey found that 74% were Protestant, 25% were Catholic, and 1% belonged to other Christian denominations, including a small Orthodox Christian community.
In terms of Nigeria's major ethnic groups, the Hausa ethnic group (predominant in the north) was found to be 95% Muslim and 5% Christian, the Yoruba tribe (predominant in the west) was equally split between Christians and Muslims with 10% adherents of traditional religions, while the Igbos (predominant in the east) and the Ijaw (south) were 98% Christian, with 2% practicing traditional religions. The middle belt of Nigeria contains the largest number of minority ethnic groups in Nigeria, who were found to be mostly Christians and members of traditional religions, with a small proportion of Muslims.

Leading Protestant churches in the country include the Church of Nigeria of the Anglican Communion, the Assemblies of God Church, the Nigerian Baptist Convention and The Synagogue, Church Of All Nations. Since the 1990s, there has been significant growth in many other churches, independently started in Africa by Africans, particularly the evangelical Protestant ones. These include the Redeemed Christian Church of God, Winners' Chapel, Christ Apostolic Church (the first Aladura Movement in Nigeria), Living Faith Church Worldwide, Deeper Christian Life Ministry, Evangelical Church of West Africa, Mountain of Fire and Miracles, Christ Embassy, Lord's Chosen Charismatic Revival Movement, Celestial Church of Christ, and Dominion City. In addition, The Church of Jesus Christ of Latter-day Saints, the Aladura Church, the Seventh-day Adventist and various indigenous churches have also experienced growth.

The Yoruba area contains a large Anglican population, while Igboland is a mix of Roman Catholics and Protestants, and the Edo area is composed predominantly of members of the Pentecostal Assemblies of God, which was introduced into Nigeria by Augustus Ehurie Wogu and his associates at Old Umuahia. For the Yoruba, the precise percentage of Muslims and Christians is unknown but in states like Lagos, Oyo, Ogun, Osun, Kwara, and Kogi, it is equally split between Christians and Muslims while the Yoruba states of Ekiti and Ondo are predominantly Christian.

Further, Nigeria has become an African hub for the Grail Movement and the Hare Krishnas, and the largest temple of the Eckankar religion is in Port Harcourt, Rivers State, with a total capacity of 10,000.

The Church of Jesus Christ of Latter-Day Saints (LDS) announced creation of new Owerri mission in Nigeria in 2016.

Health care delivery in Nigeria is a concurrent responsibility of the three tiers of government in the country, and the private sector. Nigeria has been reorganising its health system since the Bamako Initiative of 1987, which formally promoted community-based methods of increasing accessibility of drugs and health care services to the population, in part by implementing user fees. The new strategy dramatically increased accessibility through community-based health care reform, resulting in more efficient and equitable provision of services.
A comprehensive approach strategy was extended to all areas of health care, with subsequent improvement in the health care indicators and improvement in health care efficiency and cost.

HIV/AIDS rate in Nigeria is much lower compared to the other African nations such as Kenya or South Africa whose prevalence (percentage) rates are in the double digits. , the HIV prevalence rate among adults ages 15–49 was just 3.1 percent. , life expectancy in Nigeria is 52.62 years on average according to CIA, and just over half the population have access to potable water and appropriate sanitation; , the infant mortality is 8.4 deaths per 1000 live births.

Nigeria was the only country in Africa to have never eradicated polio, which it periodically exported to other African countries; Polio was cut 98% between 2009 and 2010. However, a major breakthrough came in December 2014, when it was reported that Nigeria had recorded zero polio cases in six months. In 2012, a new bone marrow donor program was launched by the University of Nigeria to help people with leukaemia, lymphoma, or sickle cell disease to find a compatible donor for a life-saving bone marrow transplant, which cures them of their conditions. Nigeria became the second African country to have successfully carried out this surgery. In the 2014 ebola outbreak, Nigeria was the first country to effectively contain and eliminate the Ebola threat that was ravaging three other countries in the West African region, the unique method of contact tracing employed by Nigeria became an effective method later used by countries such as the United States, when ebola threats were discovered.

The Nigerian health care system is continuously faced with a shortage of doctors known as 'brain drain', because of emigration by skilled Nigerian doctors to North America and Europe. In 1995, an estimated 21,000 Nigerian doctors were practising in the United States alone, which is about the same as the number of doctors working in the Nigerian public service. Retaining these expensively trained professionals has been identified as one of the goals of the government.

Education in Nigeria is overseen by the Ministry of Education. Local authorities take responsibility for implementing policy for state-controlled public education and state schools at a regional level. The education system is divided into Kindergarten, primary education, secondary education and tertiary education. After the 1970s oil boom, tertiary education was improved so it would reach every subregion of Nigeria. 68% of the Nigerian population is literate, and the rate for men (75.7%) is higher than that for women (60.6%).

Nigeria provides free, government-supported education, but attendance is not compulsory at any level, and certain groups, such as nomads and the handicapped, are under-served. The education system consists of six years of primary school, three years of junior secondary school, three years of senior secondary school, and four, five or six years of university education leading to a bachelor's degree. The government has majority control of university education. Tertiary education in Nigeria consists of Universities (Public and Private), Polytechnics, Monotechnics, and Colleges of education. The country has a total of 129 universities registered by NUC among which federal and state government own 40 and 39 respectively while 50 universities are privately owned. In order to increase the number of universities in Nigeria from 129 to 138 the Federal Government gave nine new private universities their licences in May 2015. The names of the universities that got licenses in Abuja included, Augustine University, Ilara, Lagos; Chrisland University, Owode, Ogun State; Christopher University, Mowe, Ogun State; Hallmark University, Ijebu-Itele, Ogun State; Kings University, Ode-Omu, Osun State; Micheal and Cecilia Ibru University, Owhrode, Delta State; Mountain Top University, Makogi/Oba Ogun state; Ritman University, Ikot-Epene, Akwa- Ibom State and Summit University, Offa, Kwara State.

First year entry requirements into most universities in Nigeria include: Minimum of SSCE/GCE Ordinary Level Credits at maximum of two sittings; Minimum cut-off marks in Joint Admission and Matriculation Board Entrance Examination (JAMB) of 180 and above out of a maximum of 400 marks are required. Candidates with minimum of Merit Pass in National Certificate of Education (NCE), National Diploma (ND) and other Advanced Level Certificates minimum qualifications with minimum of 5O/L Credits are given direct entry admission into the appropriate undergraduate degree programs. Students with required documents typically enter university from age 17–18 onwards and study for an academic degree.

Nigeria is home to a substantial network of organised crime, active especially in drug trafficking. Nigerian criminal groups are heavily involved in drug trafficking, shipping heroin from Asian countries to Europe and America; and cocaine from South America to Europe and South Africa. Various Nigerian Confraternities or student "campus cults" are active in both organised crime and in political violence as well as providing a network of corruption within Nigeria. As confraternities have extensive connections with political and military figures, they offer excellent alumni networking opportunities. The Supreme Vikings Confraternity, for example, boasts that twelve members of the Rivers State House of Assembly are cult members.

There is some major piracy in Nigeria, with attacks directed at all types of vessels. Consistent with the rise of Nigeria as an increasingly dangerous hot spot, 28 of the 30 seafarers kidnapped globally between January and June 2013 were in Nigeria. On lower levels of society, there are the "area boys", organised gangs mostly active in Lagos who specialise in mugging and small-scale drug dealing. Gang violence in Lagos resulted in 273 civilians and 84 policemen killed in the period of August 2000 to May 2001.

Internationally, Nigeria is infamous for a form of bank fraud dubbed "419", a type of advance fee fraud (named after Section 419 of the Nigerian Penal Code) along with the "Nigerian scam", a form of confidence trick practised by individuals and criminal syndicates. These scams involve a complicit Nigerian bank (the laws being set up loosely to allow it) and a scammer who claims to have money he needs to obtain from that bank. The victim is talked into exchanging bank account information on the premise that the money will be transferred to them and they will get to keep a cut. In reality, money is taken out instead, and/or large fees (which seem small in comparison with the imaginary wealth he awaits) are deducted. In 2003, the Nigerian Economic and Financial Crimes Commission (or EFCC) was created, ostensibly to combat this and other forms of organised financial crime.

Nigeria is described as the "poverty capital of the world", over 89 million of its population live in extreme poverty. Nigeria has largely failed to overcome the three reasons for this persistent poverty: income inequality, ethnic conflict, and political instability.

Because of its multitude of diverse, sometimes competing ethno-linguistic groups, Nigeria prior to independence was faced with sectarian tensions and violence, particularly in the oil-producing Niger Delta region, where both state and civilian forces employ varying methods of coercion in attempts to gain control over regional petroleum resources. Some of the ethnic groups like the Ogoni, have experienced severe environmental degradation due to petroleum extraction.

Since the end of the civil war in 1970, some ethnic violence has persisted. There has subsequently been a period of relative harmony since the Federal Government introduced tough new measures against religious violence in all affected parts of the country. The 2002 Miss World pageant was moved from Abuja to London in the wake of violent protests by Muslims in the Northern part of the country that left at least a hundred dead and more than 500 injured. The rioting erupted after Muslims in the country reacted in anger to comments made by a newspaper reporter. Muslim rioters in Kaduna killed an estimated 105 men, women, and children with a further 521 injured taken to hospital.

Since 2002, the country has seen sectarian violence by Boko Haram, a movement that seeks to abolish the secular system of government and establish Sharia law in the country. In the 2010 Jos riots, more than 500 people were killed by religious violence.

Between 2011 and 2018, Boko Haram has been responsible for more than 37,000 deaths in the region. The group's targets include both civilians and Nigerian security forces. In May 2014 Benin, Chad, Cameroon and Niger joined Nigeria in a united effort to combat Boko Haram in the aftermath of the 2014 Chibok kidnapping of 276 schoolgirls.

In April 2016, more than 500 people in ten villages in predominantly Christian areas in Agatu were murdered by Fulani herdsmen. A visiting Nigerian Senator reported that all the primary and post-primary schools, health centres, worship centres as well as the police station in the area were destroyed. The UNHCR representative said in 20 years of work, she had "never seen such a level of destruction". 130 Fulani adults and children were massacred in the Kaduna State in February 2019.

Nigeria is a state party of the Convention on the Elimination of All Forms of Discrimination Against Women It also has signed Maputo Protocol, an international treaty on women's rights, and the African Union Women's Rights Framework. Discrimination based on sex is a significant human rights issue, however. Forced marriages are common.
Child marriage remains common in Northern Nigeria. 39% of girls are married before age 15, although the Marriage Rights Act banning marriage of girls below 18 years of age was introduced on a federal level in 2008.

There is polygamy in Nigeria. Submission of the wife to her husband and domestic violence are common. Women have less land rights. Maternal mortality was at 814 per 100,000 live births in 2015. Female genital mutilation is common. In 2015, there was a federal ban.

In Nigeria, at least half a million suffer from vaginal fistula, largely as a result of lack of medical care. Early marriages can result in fistula. Most workers in the informal sector are women.

Women also face a large amount of inequality Politically in Nigeria, being subjugated to a bias which is sexist and reinforced by socio-cultural, economic and oppressive ways. Despite being politically emancipated, for many women in Nigeria their husbands still dictate their political choice, which upholds the patriarchal system.

Women's representation in government since Independence from Britain is also very poor. Women have been reduced to sideline roles in appointive posts throughout all levels in government, and still make an up a tiny minority of elected officials.
But nowadays with more education to the public Nigerian women are taking step to have more active roles in the public and with help of different intitivate more business are being started by women .

Nigeria's human rights record remains poor. According to the U.S. Department of State, the most significant human rights problems are: use of excessive force by security forces; impunity for abuses by security forces; arbitrary arrests; prolonged pretrial detention; judicial corruption and executive influence on the judiciary; rape, torture and other cruel, inhuman or degrading treatment of prisoners, detainees and suspects; harsh and life‑threatening prison and detention centre conditions; human trafficking for the purpose of prostitution and forced labour; societal violence and vigilante killings; child labour, child abuse and child sexual exploitation; domestic violence; discrimination based on ethnicity, region and religion.

Under the Shari'a penal code that applies to Muslims in twelve northern states, offences such as alcohol consumption, homosexuality, infidelity and theft carry harsh sentences, including amputation, lashing, stoning and long prison terms. According to 2013 survey by the Pew Research Center, 98% of Nigerians believe homosexuality should not be accepted by society.

Under a law signed in early 2014, same-sex couples who marry face up to 14 years each in prison. Witnesses or anyone who helps gay couples marry will be sentenced to 10 years behind bars. The bill also punishes the "public show of same-sex amorous relationships directly or indirectly" with ten years in prison. Another portion of the bill mandates 10 years in prison for those found guilty of organising, operating or supporting gay clubs, organizations and meetings.

In the Nigerian state of Akwa Ibom, about 15,000 children were branded as witches; most of them ended up abandoned and abused on the streets.

On 28 April 2020, Nigerian authorities arrested Mubarak Bala, a prominent Nigerian humanist and president of the Nigerian Humanist Association. He has been detained incommunicado and accused of blasphemy, after he wrote a post on Facebook expressing his beliefs. He has been denied access to his family and his lawyer and also been subjected to ill-treatment in police custody.

Nigerian citizens have authored many influential works of post-colonial literature in the English language. Nigeria's best-known writers are Wole Soyinka, the first African Nobel Laureate in Literature, and Chinua Achebe, best known for the novel "Things Fall Apart" (1958) and his controversial critique of Joseph Conrad.

Other Nigerian writers and poets who are well known internationally include John Pepper Clark, Ben Okri, Cyprian Ekwensi, Buchi Emecheta, Helon Habila, T. M. Aluko, Isaac Delano, Chimamanda Ngozi Adichie, Daniel O. Fagunwa, Femi Osofisan and Ken Saro Wiwa, who was executed in 1995 by the military regime.

Critically acclaimed writers of a younger generation include Adaobi Tricia Nwaubani, Chris Abani, Sefi Atta, Helon Habila, Helen Oyeyemi, Nnedi Okorafor, Kachi A. Ozumba, Sarah Ladipo Manyika, and Chika Unigwe.

Nigeria has had a huge role in the development of various genres of African music, including West African highlife, Afrobeat, Afrobeats, and palm-wine music, which fuses native rhythms with techniques that have been linked to the Congo, Brazil, Cuba, Jamaica and worldwide.

Many late 20th-century musicians such as Fela Kuti have famously fused cultural elements of various indigenous music with American jazz and soul to form Afrobeat which has in turn influenced hip hop music. JuJu music, which is percussion music fused with traditional music from the Yoruba nation and made famous by King Sunny Adé, is from Nigeria. Fuji music, a Yoruba percussion style, was created and popularised by Mr. Fuji, Alhaji Sikiru Ayinde Barrister.

Afan Music was invented and popularised by the Ewu-born poet and musician Umuobuarie Igberaese. There is a budding hip-hop movement in Nigeria. Kennis Music, the self-proclaimed number-one record label in Africa, and one of Nigeria's biggest record labels, has a roster almost entirely dominated by hip-hop artists.

Notable musicians from Nigeria include: Sade Adu, King Sunny Adé, Onyeka Onwenu, Dele Sosimi, Adewale Ayuba, Ezebuiro Obinna, Ebenezer Obey, Femi Kuti, Lagbaja, Dr. Alban, Bola Abimbola, Tuface Idibia, Aṣa, Nneka, Wale, P Square, Wizkid, Skepta, CB and D'Banj.

In November 2008, Nigeria's music scene (and that of Africa) received international attention when MTV hosted the continent's first African music awards show in Abuja. Additionally, the very first music video played on MTV Base Africa (the 100th station on the MTV network) was Tuface Idibia's pan-African hit "African Queen".

The Nigerian film industry is known as Nollywood (a blend of "Nigeria" and Hollywood) and is now the 2nd-largest producer of movies in the world after India's Bollywood. Nigerian film studios are based in Lagos, Kano and Enugu, forming a major portion of the local economy of these cities. Nigerian cinema is Africa's largest movie industry in terms of both value and the number of movies produced per year. Although Nigerian films have been produced since the 1960s, the country's film industry has been aided by the rise of affordable digital filming and editing technologies.

Some films and audio documentaries include:


The 2009 thriller film "The Figurine" is generally considered the game changer, which heightened the media attention towards New Nigerian Cinema revolution. The film was a critical and commercial success in Nigeria, and it was also screened in international film festivals. The 2010 film "Ijé" by Chineze Anyaene, overtook "The Figurine" to become the highest grossing Nigerian film; a record it held for four years, until it was overtaken in 2014 by "Half of a Yellow Sun"(2013). By 2016, this record was held by "The Wedding Party", a film by Kemi Adetiba.

By the end of 2013, the film industry reportedly hit a record breaking revenue of ₦1.72 trillion (US$11 billion). As of 2014, the industry was worth ₦853.9 billion (US$5.1 billion) making it the third most valuable film industry in the world, behind the United States and India. It contributed about 1.4% to Nigeria's economy; this was attributed to the increase in the number of quality films produced and more formal distribution methods.

T.B. Joshua's Emmanuel TV, originating from Nigeria, is one of the most viewed television stations across Africa.

There are many festivals in Nigeria, some of which date to the period before the arrival of the major religions in this ethnically and culturally diverse society. The main Muslim and Christian festivals are often celebrated in ways that are unique to Nigeria or unique to the people of a locality. The Nigerian Tourism Development Corporation has been working with the states to upgrade the traditional festivals, which may become important sources of tourism revenue.

Nigerian cuisine, like West African cuisine in general, is known for its richness and variety. Many different spices, herbs and flavourings are used in conjunction with palm oil or groundnut oil to create deeply flavoured sauces and soups often made very hot with chili peppers. Nigerian feasts are colourful and lavish, while aromatic market and roadside snacks cooked on barbecues or fried in oil are plentiful and varied.

Football is largely considered Nigeria's national sport and the country has its own Premier League of football. Nigeria's national football team, known as the "Super Eagles", has made the World Cup on Six occasions 1994, 1998, 2002, 2010, 2014, and most recently in 2018. In April 1994, the Super Eagles ranked 5th in the FIFA World Rankings, the highest ranking achieved by an African football team. They won the African Cup of Nations in 1980, 1994, and 2013, and have also hosted the U-17 & U-20 World Cup. They won the gold medal for football in the 1996 Summer Olympics (in which they beat Argentina) becoming the first African football team to win gold in Olympic football.

The nation's cadet team from Japan '93 produced some international players notably Nwankwo Kanu, a two-time African Footballer of the year who won the European Champions League with Ajax Amsterdam and later played with Inter Milan, Arsenal, West Bromwich Albion and Portsmouth. Other players who graduated from the junior teams are Nduka Ugbade, Jonathan Akpoborie, Victor Ikpeba, Celestine Babayaro, Wilson Oruma and Taye Taiwo. Some other famous Nigerian footballers include John Obi Mikel, Obafemi Martins, Vincent Enyeama, Yakubu, Rashidi Yekini, Peter Odemwingie and Jay-Jay Okocha.

According to the official May 2010 FIFA World Rankings, Nigeria was the second top-ranked football nation in Africa and the 21st highest in the world. Nigeria is also involved in other sports such as basketball, cricket and track and field. Boxing is also an important sport in Nigeria; Dick Tiger and Samuel Peter are both former World Champions.

Nigeria's national basketball team made the headlines internationally when it qualified for the 2012 Summer Olympics as it beat heavily favoured world elite teams such as Greece and Lithuania. Nigeria has been home to numerous internationally recognised basketball players in the world's top leagues in America, Europe and Asia. These players include Basketball Hall of Famer Hakeem Olajuwon, and later NBA draft picks Solomon Alabi, Yinka Dare, Obinna Ekezie, Festus Ezeli, Al-Farouq Aminu and Olumide Oyedeji.

Nigeria made history by qualifying the first bobsled team for the Winter Olympics from Africa when their women's two-man team qualified for the bobsled competition at the XXIII Olympic Winter Games in Pyeongchang, South Korea.

In the early 1990s, Scrabble was made an official sport in Nigeria. By the end of 2017, there were around 4,000 players in more than 100 clubs in the country. In 2015, Wellington Jighere became the first African player to win World Scrabble Championship.





</doc>
<doc id="21384" url="https://en.wikipedia.org/wiki?curid=21384" title="History of Nigeria">
History of Nigeria

The history of Nigeria can be traced to settlers trading across the middle East and Africa as early as 1100 BC. Numerous ancient African civilizations settled in the region that is known today as Nigeria, such as the Kingdom of Nri, the Benin Empire, and the Oyo Empire. Islam reached Nigeria through the Borno Empire between (1068 AD) and Hausa States around (1385 AD) during the 11th century, while Christianity came to Nigeria in the 15th century through Augustinian and Capuchin monks from Portugal. The Songhai Empire also occupied part of the region.

The history of Nigeria has been crucially impacted by the Transatlantic Slave Trade, which started in Nigeria in the late 15th century. At first, Europeans captured people who lived along the coast. The first slave trading post used by the British and the Portuguese is Badagry , a coastal harbour. The chains where they tied up young and virile young people still stands today. Later, they used local brokers to provide them with slaves. This activity escalated conflicts among the different ethnic groups in the region and disrupted older trade patterns through the Trans-Saharan route.

Lagos was invaded by British forces in 1851 and formally annexed in 1865. Nigeria became a British protectorate in 1901 while her colonization lasted until 1960, when an independence movement succeeded in gaining her independence. Nigeria first became a republic in 1963, but succumbed to military rule three years later after a bloody coup d'état. A separatist movement later formed the Republic of Biafra in 1967, leading to the three-year Nigerian Civil War. Nigeria became a republic once again after a new constitution was written in 1979. However, the republic was short-lived, when the military seized power again for another four years. A new republic was planned to be established in 1993, but was aborted by General Sani Abacha. Abacha died in 1998 and a fourth republic was later established the following year, which ended three decades of intermittent military rule.
Archaeological research, pioneered by Charles Thurstan Shaw has shown that people were already living in south-eastern Nigeria (specifically Igbo Ukwu, Nsukka, Afikpo and Ugwuele) 100,000 years ago. Excavations in Ugwuele, Afikpo and Nsukka show evidence of long habitations as early as 6,000 BC. However, by the 9th Century AD, it seemed clear that the Igbos had settled in Igboland. Shaw's excavations at Igbo-Ukwu, Nigeria revealed a 9th-century indigenous culture that created highly sophisticated work in bronze metalworking, independent of any Arab or European influence and centuries before other sites that were better known at the time of discovery.

The earliest known example of a fossil human skeleton found anywhere in West Africa, which is 13,000 years old, was found at Iwo-Eleru in Isarun, western Nigeria and attests to the antiquity of habitation in the region.

The Dufuna canoe was discovered in 1987 a few kilometers from the village of Dufuna, not far from the Komadugu Gana River, in Yobe State, Nigeria. Radiocarbon dating of a sample of charcoal found near the site dates the canoe at 8500 to 8000 years old, linking the site to Lake Mega Chad. It is the oldest boat to be discovered in Africa, and the second oldest known worldwide.

Microlithic and ceramic industries were also established by savanna pastoralists from at least the 4th millennium BC and were continued by subsequent agricultural communities. In the south, hunting and gathering gave way to subsistence farming around the same time, relying more on the indigenous yam and oil palm than on the cereals important in the North.

The stone axe heads, imported in great quantities from the north and used in opening the forest for agricultural development, were venerated by the Yoruba descendants of Neolithic pioneers as "thunderbolts" hurled to earth by the gods.

The Nok culture thrived from approximately 1,500 BC to about 200 AD on the Jos Plateau in north and central Nigeria and produced life-sized terracotta figures that include human heads, human figures, and animals. Iron smelting furnaces at Taruga, a Nok site, date from around 600 BC. The Nok culture is thought to have begun smelting iron by 600-500 BC and possibly some centuries earlier. Kainji Dam excavations revealed iron-working by the 2nd century BC. Evidence of iron smelting has also been excavated at sites in the Nsukka region of southeast Nigeria in what is now Igboland: dating to 2,000 BC at the site of Lejja (Uzomaka 2009) and to 750 BC and at the site of Opi (Holl 2009). The transition from Neolithic times to the Iron Age apparently was achieved indigenously without intermediate bronze production. Others have suggested that the technology moved west from the Nile Valley, although the Iron Age in the Niger River valley and the forest region appears to predate the introduction of metallurgy in the upper savanna by more than 800 years. The earliest iron technology in West Africa has also been found to be contemporary with or predate that of the Nile valley and North Africa, and some archaeologists believe that iron metallurgy was likely developed independently in sub-Saharan West Africa.

The Hausa Kingdoms were a collection of states started by the Hausa people, situated between the Niger River and Lake Chad. Their history is reflected in the Bayajidda legend, which describes the adventures of the Baghdadi hero Bayajidda culminating in the killing of the snake in the well of Daura and the marriage with the local queen magajiya Daurama. While the hero had a child with the queen, Bawo, and another child with the queen's maid-servant, Karbagari.

According to the Bayajidda legend, the Hausa states were founded by the sons of Bayajidda, a prince whose origin differs by tradition, but official canon records him as the person who married the last Kabara of Daura and heralded the end of the matriarchal monarchs that had erstwhile ruled the Hausa people. Contemporary historical scholarship views this legend as an allegory similar to many in that region of Africa that probably referenced a major event, such as a shift in ruling dynasties.

According to the Bayajidda legend, the Banza Bakwai states were founded by the seven sons of Karbagari ("Town-seizer"), the unique son of Bayajidda and the slave-maid, Bagwariya. They are called the Banza Bakwai meaning Bastard or Bogus Seven on account of their ancestress' slave status.


The Hausa Kingdoms began as seven states founded according to the Bayajidda legend by the six sons of Bawo, the unique son of the hero and the queen Magajiya Daurama in addition to the hero's son, Biram or Ibrahim, of an earlier marriage. 
The states included only kingdoms inhabited by Hausa-speakers:


Since the beginning of Hausa history, the seven states of Hausaland divided up production and labor activities in accordance with their location and natural resources. Kano and Rano were known as the "Chiefs of Indigo." Cotton grew readily in the great plains of these states, and they became the primary producers of cloth, weaving and dying it before sending it off in caravans to the other states within Hausaland and to extensive regions beyond. Biram was the original seat of government, while Zaria supplied labor and was known as the "Chief of Slaves." Katsina and Daura were the "Chiefs of the Market," as their geographical location accorded them direct access to the caravans coming across the desert from the north. Gobir, located in the west, was the "Chief of War" and was mainly responsible for protecting the empire from the invasive Kingdoms of Ghana and Songhai.
Islam arrived at Hausaland along the caravan routes. The famous "Kano Chronicle" records the conversion of Kano's ruling dynasty by clerics from Mali, demonstrating that the imperial influence of Mali extended far to the east. Acceptance of Islam was gradual and was often nominal in the countryside where folk religion continued to exert a strong influence. Nonetheless, Kano and Katsina, with their famous mosques and schools, came to participate fully in the cultural and intellectual life of the Islamic world. The Fulani began to enter the Hausa country in the 13th century and by the 15th century, they were tending cattle, sheep, and goats in Borno as well. The Fulani came from the Senegal River valley, where their ancestors had developed a method of livestock management based on transhumance. Gradually they moved eastward, first into the centers of the Mali and Songhai empires and eventually into Hausaland and Borno. Some Fulbe converted to Islam as early as the 11th century and settled among the Hausa, from whom they became racially indistinguishable. There they constituted a devoutly religious, educated elite who made themselves indispensable to the Hausa kings as government advisers, Islamic judges, and teachers.

The Hausa Kingdoms were first mentioned by Ya'qubi in the 9th-century and they were by the 15th-century vibrant trading centers competing with Kanem-Bornu and the Mali Empire. The primary exports were slaves, leather, gold, cloth, salt, kola nuts, and henna. At various moments in their history, the Hausa managed to establish central control over their states, but such unity has always proven short. In the 11th-century, the conquests initiated by Gijimasu of Kano culminated in the birth of the first united Hausa Nation under Queen Amina, the Sultana of Zazzau but severe rivalries between the states led to periods of domination by major powers like the Songhai, Kanem and the Fulani.

Despite relatively constant growth, the Hausa states were vulnerable to aggression and, although the vast majority of its inhabitants were Muslim by the 16th century, they were attacked by Fulani jihadists from 1804 to 1808. In 1808 the Hausa Nation was finally conquered by Usman dan Fodio and incorporated into the Hausa-Fulani Sokoto Caliphate.

Historically the Yoruba people have been the dominant group on the west bank of the Niger. Their nearest linguistic relatives are the Igala who live on the opposite side of the Niger's divergence from the Benue, and from whom they are believed to have split about 2,000 years ago. The Yoruba were organized in mostly patrilineal groups that occupied village communities and subsisted on agriculture. From approximately the 8th century, adjacent village compounds called "ile" coalesced into numerous territorial city-states in which clan loyalties became subordinate to dynastic chieftains. Urbanization was accompanied by high levels of artistic achievement, particularly in terracotta and ivory sculpture and in the sophisticated metal casting produced at Ife.

The Yoruba pay tribute to a pantheon composed of a Supreme Deity, Olorun and the Orisha. The Olorun is now called God in the Yoruba language. There are 400 deities called Orisha who perform various tasks. According to the Yoruba, Oduduwa is regarded as the ancestor of the Yoruba kings. According to one of the various myths about him, he founded Ife and dispatched his sons and daughters to establish similar kingdoms in other parts of what is today known as Yorubaland. The Yorubaland now consists of different tribes from different states which are located in the Southwestern part of the country, states like Lagos State, Oyo State, Ondo State, Osun State, Ekiti State and Ogun State, among others.

The Kingdom of Nri is considered to be the foundation of Igbo culture, and the oldest Kingdom in Nigeria. Nri and Aguleri, where the Igbo creation myth originates, are in the territory of the Umueri clan, who trace their lineages back to the patriarchal king-figure, Eri. Eri's origins are unclear, though he has been described as a "sky being" sent by Chukwu (God). He has been characterized as having first given societal order to the people of Anambra.

Archaeological evidence suggests that Nri hegemony in Igboland may go back as far as the 9th century, and royal burials have been unearthed dating to at least the 10th century. Eri, the god-like founder of Nri, is believed to have settled the region around 948 with other related Igbo cultures following after in the 13th century. The first Eze Nri (King of Nri), Ìfikuánim, followed directly after him. According to Igbo oral tradition, his reign started in 1043. At least one historian puts Ìfikuánim's reign much later, around 1225.

The Kingdom of Nri was a religio-polity, a sort of theocratic state, that developed in the central heartland of the Igbo region. The Nri had a taboo symbolic code with six types. These included human (such as the birth of twins), animal (such as killing or eating of pythons), object, temporal, behavioral, speech and place taboos. The rules regarding these taboos were used to educate and govern Nri's subjects. This meant that, while certain Igbo may have lived under different formal administration, all followers of the Igbo religion had to abide by the rules of the faith and obey its representative on earth, the Eze Nri.

With the decline of Nri kingdom in the 15th to 17th centuries, several states once under their influence, became powerful economic oracular oligarchies and large commercial states that dominated Igboland. The neighboring Awka city-state rose in power as a result of their powerful Agbala oracle and metalworking expertise. The Onitsha Kingdom, which was originally inhabited by Igbos from east of the Niger, was founded in the 16th century by migrants from Anioma (Western Igboland). Later groups like the Igala traders from the hinterland settled in Onitsha in the 18th century. Western Igbo kingdoms like Aboh, dominated trade in the lower Niger area from the 17th century until European penetration. The Umunoha state in the Owerri area used the "Igwe ka Ala" oracle at their advantage. However, the Cross River Igbo state like the Aro had the greatest influence in Igboland and adjacent areas after the decline of Nri.

The Arochukwu kingdom emerged after the Aro-Ibibio Wars from 1630 to 1720, and went on to form the Aro Confederacy which economically dominated Eastern Nigerian hinterland. The source of the Aro Confederacy's economic dominance was based on the judicial oracle of Ibini Ukpabi ("Long Juju") and their military forces which included powerful allies such as Ohafia, Abam, Ezza, and other related neighboring states. The Abiriba and Aro are Brothers whose migration is traced to the Ekpa Kingdom in East of Cross River; their exact take of location was at Ekpa (Mkpa) east of the Cross River. They crossed the river to Urupkam (Usukpam) west of the Cross River and founded two settlements: Ena Uda and Ena Ofia in present-day Erai. Aro and Abiriba cooperated to become a powerful economic force.

Igbo gods, like those of the Yoruba, were numerous, but their relationship to one another and human beings was essentially egalitarian, reflecting Igbo society as a whole. A number of oracles and local cults attracted devotees while the central deity, the earth mother and fertility figure Ala, was venerated at shrines throughout Igboland.

The weakness of a popular theory that Igbos were stateless rests on the paucity of historical evidence of pre-colonial Igbo society. There is a huge gap between the archaeological finds of Igbo Ukwu, which reveal a rich material culture in the heart of the Igbo region in the 8th century, and the oral traditions of the 20th century. Benin exercised considerable influence on the western Igbo, who adopted many of the political structures familiar to the Yoruba-Benin region, but Asaba and its immediate neighbours, such as Ibusa, Ogwashi-Ukwu, Okpanam, Issele-Azagba and Issele-Ukwu, were much closer to the Kingdom of Nri. Ofega was the queen for the Onitsha Igbo.Igbo imabana

The early independent kingdoms and states that make up present-day British colonialized Nigeria are (in alphabetical order):


During the 15th century Oyo and Benin surpassed Ife as political and economic powers, although Ife preserved its status as a religious center. Respect for the priestly functions of the "oni" of Ife was a crucial factor in the evolution of Yoruba culture. The Ife model of government was adapted at Oyo, where a member of its ruling dynasty controlled several smaller city-states. A state council (the "Oyo Mesi") named the "Alaafin" (king) and acted as a check on his authority. Their capital city was situated about 100 km north of present-day Oyo. Unlike the forest-bound Yoruba kingdoms, Oyo was in the savanna and drew its military strength from its cavalry forces, which established hegemony over the adjacent Nupe and the Borgu kingdoms and thereby developed trade routes farther to the north.

The Benin Empire (1440–1897; called "Bini" by locals) was a pre-colonial African state in what is now modern Nigeria. It should not be confused with the modern-day country called Benin, formerly called Dahomey.

Trade is the key to the emergence of organized communities in the sahelian portions of Nigeria. Prehistoric inhabitants adjusting to the encroaching desert were widely scattered by the third millennium BC, when the desiccation of the Sahara began. Trans-Saharan trade routes linked the western Sudan with the Mediterranean since the time of Carthage and with the Upper Nile from a much earlier date, establishing avenues of communication and cultural influence that remained open until the end of the 19th century. By these same routes, Islam made its way south into West Africa after the 9th century.

By then a string of dynastic states, including the earliest Hausa states, stretched into western and central Sudan. The most powerful of these states were Ghana, Gao, and Kanem, which were not within the boundaries of modern Nigeria but which influenced the history of the Nigerian savanna. Ghana declined in the 11th century but was succeeded by the Mali Empire which consolidated much of western Sudan in the 13th century.

Following the breakup of Mali, a local leader named Sonni Ali (1464–1492) founded the Songhai Empire in the region of middle Niger and western Sudan and took control of the trans-Saharan trade. Sonni Ali seized Timbuktu in 1468 and Djenné in 1473, building his regime on trade revenues and the cooperation of Muslim merchants. His successor Askia Muhammad Ture (1493–1528) made Islam the official religion, built mosques, and brought Muslim scholars, including al-Maghili (d.1504), the founder of an important tradition of Sudanic African Muslim scholarship, to Gao.

Although these western empires had little political influence on the Nigerian savanna before 1500 they had a strong cultural and economic impact that became more pronounced in the 16th century, especially because these states became associated with the spread of Islam and trade. Throughout the 16th-century much of northern Nigeria paid homage to Songhai in the west or to Borno, a rival empire in the east.

Borno's history is closely associated with Kanem, which had achieved imperial status in the Lake Chad basin by the 13th century. Kanem expanded westward to include the area that became Borno. The mai (king) of Kanem and his court accepted Islam in the 11th century, as the western empires also had done. Islam was used to reinforce the political and social structures of the state although many established customs were maintained. Women, for example, continued to exercise considerable political influence.

The "mai" employed his mounted bodyguard and an inchoate army of nobles to extend Kanem's authority into Borno. By tradition, the territory was conferred on the heir to the throne to govern during his apprenticeship. In the 14th century, however, dynastic conflict forced the then-ruling group and its followers to relocate in Borno, whereas a result the Kanuri emerged as an ethnic group in the late 14th and 15th centuries. The civil war that disrupted Kanem in the second half of the 14th century resulted in the independence of Borno.

Borno's prosperity depended on the trans-Sudanic slave trade and the desert trade in salt and livestock. The need to protect its commercial interests compelled Borno to intervene in Kanem, which continued to be a theatre of war throughout the 15th century and into the 16th century. Despite its relative political weakness in this period, Borno's court and mosques under the patronage of a line of scholarly kings earned fame as centres of Islamic culture and learning.

During the 16th century, the Songhai Empire reached its peak, stretching from the Senegal and Gambia rivers and incorporating part of Hausaland in the east. Concurrently the Saifawa Dynasty of Borno conquered Kanem and extended control west to Hausa cities not under Songhai authority. Largely because of Songhai's influence, there was a blossoming of Islamic learning and culture. Songhai collapsed in 1591 when a Moroccan army conquered Gao and Timbuktu. Morocco was unable to control the empire and the various provinces, including the Hausa states, became independent. The collapse undermined Songhai's hegemony over the Hausa states and abruptly altered the course of regional history.
Borno reached its pinnacle under "mai" Idris Aloma (ca. 1569–1600) during whose reign Kanem was reconquered. The destruction of Songhai left Borno uncontested and until the 18th-century Borno dominated northern Nigeria. Despite Borno's hegemony the Hausa states continued to wrestle for ascendancy. Gradually Borno's position weakened; its inability to check political rivalries between competing Hausa cities was one example of this decline. Another factor was the military threat of the Tuareg centred at Agades who penetrated the northern districts of Borno. The major cause of Borno's decline was a severe drought that struck the Sahel and savanna from in the middle of the 18th century. As a consequence, Borno lost many northern territories to the Tuareg whose mobility allowed them to endure the famine more effectively. Borno regained some of its former might in the succeeding decades, but another drought occurred in the 1790s, again weakening the state.

Ecological and political instability provided the background for the jihad of Usman dan Fodio. The military rivalries of the Hausa states strained the region's economic resources at a time when drought and famine undermined farmers and herders. Many Fulani moved into Hausaland and Borno, and their arrival increased tensions because they had no loyalty to the political authorities, who saw them as a source of increased taxation. By the end of the 18th century, some Muslim ulema began articulating the grievances of the common people. Efforts to eliminate or control these religious leaders only heightened the tensions, setting the stage for jihad.

According to the "Encyclopedia of African History", "It is estimated that by the 1890s the largest slave population of the world, about 2 million people, was concentrated in the territories of the Sokoto Caliphate. The use of slave labour was extensive, especially in agriculture."

The modern city of Calabar was founded in 1786 by Efik families who had left Creek Town, farther up the Calabar river, settling on the east bank in a position where they were able to dominate traffic with European vessels that anchored in the river, and soon becoming the most powerful in the region.
Akwa Akpa became a center of the slave trade, where slaves were exchanged for European goods.
Most slave ships that transported slaves from Calabar were English, and around 85% of these ships being from Bristol and Liverpool merchants.
The main ethnic group taken out of Calabar as slaves were the Igbo, although they were not the main ethnicity in the area.

With the suppression of the slave trade, palm oil and palm kernels became the main exports.
The chiefs of Akwa Akpa placed themselves under British protection in 1884.
From 1884 until 1906 Old Calabar was the headquarters of the Niger Coast Protectorate, after which Lagos became the main center.
Now called Calabar, the city remained an important port shipping ivory, timber, beeswax, and palm produce until 1916, when the railway terminus was opened at Port Harcourt, 145 km to the west.

Following the Napoleonic wars, the British expanded trade with the Nigerian interior. In 1885, British claims to a West African sphere of influence received international recognition; and in the following year, the Royal Niger Company was chartered under the leadership of Sir George Taubman Goldie. On the 31st of December 1899 the charter for the Royal Niger Company was revoked by the British Government, and the sum of £865.000 was paid to the company as compensation. The entire territory of the Royal Niger Company came into the hands of the British government. On 1 January 1900, the British Empire created the Southern Nigeria Protectorate and the Northern Nigeria Protectorate.

In 1914, the area was formally united as the Colony and Protectorate of Nigeria. Administratively, Nigeria remained divided into the Northern and Southern Provinces and Lagos Colony. Western education and the development of a modern economy proceeded more rapidly in the south than in the north, with consequences felt in Nigeria's political life ever since. Following World War II, in response to the growth of Nigerian nationalism and demands for independence, successive constitutions legislated by the British Government moved Nigeria toward self-government on a representative and increasingly federal basis. On 1 October 1954, the colony became the autonomous Federation of Nigeria. By the middle of the 20th century, the great wave for independence was sweeping across Africa. On 27 October 1958 Britain agreed that Nigeria would become an independent state on 1 October 1960.

The Federation of Nigeria was granted full independence on 1 October 1960 under a constitution that provided for a parliamentary government and a substantial measure of self-government for the country's three regions. From 1959 to 1960, Jaja Wachuku was the First Nigerian Speaker of the Nigerian Parliament, also called the "House of Representatives." Jaja Wachuku replaced Sir Frederick Metcalfe of Britain. Notably, as First Speaker of the House, Jaja Wachuku received Nigeria's Instrument of Independence, also known as Freedom Charter, on 1 October 1960, from Princess Alexandra of Kent, the Queen's representative at the Nigerian independence ceremonies. Queen Elizabeth II was monarch of Nigeria and head of state, and Nigeria was a member of the British Commonwealth of Nations. The Federal government was given exclusive powers in defence, foreign relations, and commercial and fiscal policy. The monarch of Nigeria was still head of state but legislative power was vested in a bicameral parliament, executive power in a prime minister and cabinet, and judicial authority in a Federal Supreme Court. Political parties, however, tended to reflect the makeup of the three main ethnic groups. The Nigerian People's Congress (NPC) represented conservative, Muslim, largely Hausa and Fulani interests that dominated the Northern Region. The northern region of the country, consisting of three-quarters of the land area and more than half the population of Nigeria. Thus the North dominated the federation government from the beginning of independence. In the 1959 elections held in preparation for independence, the NPC captured 134 seats in the 312-seat parliament.

Capturing 89 seats in the federal parliament was the second-largest party in the newly independent country the National Council of Nigerian Citizens (NCNC). The NCNC represented the interests of the Igbo- and Christian-dominated people of the Eastern Region of Nigeria. and the Action Group (AG) was a left-leaning party that represented the interests of the Yoruba people in the West. In the 1959 elections, the AG obtained 73 seats.

The first post-independence national government was formed by a conservative alliance of the NCNC and the NPC. Upon independence, it was widely expected that Ahmadu Bello the Sardauna of Sokoto, the undisputed strong man in Nigeria who controlled the North, would become Prime Minister of the new Federation Government. However, Bello chose to remain as premier of the North and as party boss of the NPC, selected Sir Abubakar Tafawa Balewa, a Hausa, to become Nigeria's first Prime Minister.

The Yoruba-dominated AG became the opposition under its charismatic leader Chief Obafemi Awolowo. However, in 1962, a faction arose within the AG under the leadership of Ladoke Akintola who had been selected as premier of the West. The Akintola faction argued that the Yoruba peoples were losing their pre-eminent position in business in Nigeria to people of the Igbo tribe because the Igbo-dominated NCNC was part of the governing coalition and the AG was not. The federal government Prime Minister, Balewa agreed with the Akintola faction and sought to have the AG join the government. The party leadership under Awolowo disagreed and replaced Akintola as premier of the West with one of their own supporters.
However, when the Western Region parliament met to approve this change, Akintola supporters in the parliament started a riot in the chambers of the parliament. Fighting between the members broke out. Chairs were thrown and one member grabbed the parliamentary Mace and wielded it like a weapon to attack the Speaker and other members. Eventually, the police with tear gas were required to quell the riot. In subsequent attempts to reconvene the Western parliament, similar disturbances broke out. Unrest continued in the West and contributed to the Western Region's reputation for, violence, anarchy and rigged elections. Federal Government Prime Minister Balewa declared martial law in the Western Region and arrested Awolowo and other members of his faction charged them with treason. Akintola was appointed to head a coalition government in the Western Region. Thus, the AG was reduced to an opposition role in their own stronghold.

In October 1963 Nigeria proclaimed itself the Federal Republic of Nigeria, and former Governor-General Nnamdi Azikiwe became the country's first President. From the outset, Nigeria's ethnic and religious tensions were magnified by the disparities in economic and educational development between the south and the north. The AG was manoeuvred out of control of the Western Region by the Federal Government and a new pro-government Yoruba party, the Nigerian National Democratic Party (NNDP), took over. Shortly afterwards the AG opposition leader, Chief Obafemi Awolowo, was imprisoned to be without foundation. The 1965 national election produced a major realignment of politics and a disputed result that set the country on the path to civil war. The dominant northern NPC went into a conservative alliance with the new Yoruba NNDP, leaving the Igbo NCNC to coalesce with the remnants of the AG in a progressive alliance. In the vote, widespread electoral fraud was alleged and riots erupted in the Yoruba West where heartlands of the AG discovered they had apparently elected pro-government NNDP representatives.

On 15 January 1966 a group of army officers (the Young Majors) mostly south-eastern Igbos, overthrew the NPC-NNDP government and assassinated the prime minister and the premiers of the northern and western regions. However, the bloody nature of the Young Majors coup caused another coup to be carried out by General Johnson Aguiyi-Ironsi. The Young Majors went into hiding. Major Emmanuel Ifeajuna fled to Kwame Nkrumah's Ghana where he was welcomed as a hero. Some of the Young Majors were arrested and detained by the Ironsi government. Among the Igbo people of the Eastern Region, these detainees were heroes. In the Northern Region, however, the Hausa and Fulani people demanded that the detainees be placed on trial for murder.

The federal military government that assumed power under General Johnson Aguiyi-Ironsi was unable to quiet ethnic tensions on the issue or other issues. Additionally, the Ironsi government was unable to produce a constitution acceptable to all sections of the country. Most fateful for the Ironsi government was the decision to issue Decree No. 34 which sought to unify the nation. Decree No. 34 sought to do away with the whole federal structure under which the Nigerian government had been organized since independence. Rioting broke out in the North. The Ironsi government's efforts to abolish the federal structure and the renaming the country the Republic of Nigeria on 24 May 1966 raised tensions and led to another coup by largely northern officers in July 1966, which established the leadership of Major General Yakubu Gowon. The name Federal Republic of Nigeria was restored on 31 August 1966. However, the subsequent massacre of thousands of Ibo in the north prompted hundreds of thousands of them to return to the south-east where increasingly strong Igbo secessionist sentiment emerged.
In a move towards greater autonomy to minority ethnic groups, the military divided the four regions into 12 states. However, the Igbo rejected attempts at constitutional revisions and insisted on full autonomy for the east.

The Central Intelligence Agency commented in October 1966 in a CIA Intelligence Memorandum that:

The situation is uncertain, with Nigeria, ..is sliding downhill faster and faster, with less and less chance unity and stability. Unless present army leaders and contending tribal elements soon reach agreement on a new basis for the association and take some effective measures to halt a seriously deteriorating security situation, there will be increasing internal turmoil, possibly including civil war.
On 29 May 1967, Lt. Col. Emeka Ojukwu, the military governor of the eastern region who emerged as the leader of increasing Igbo secessionist sentiment, declared the independence of the eastern region as the Republic of Biafra on 30 May 1967. The ensuing Nigerian Civil War resulted in an estimated 3.5 million deaths (mostly from starving children) before the war ended with Gowon's famous "No victor, no vanquished" speech in 1970.

Following the civil war, the country turned to the task of economic development. The U.S. intelligence community concluded in November 1970 that "...The Nigerian Civil War ended with relatively little rancour. The Igbos were accepted as fellow citizens in many parts of Nigeria, but not in some areas of former Biafra where they were once dominant. Iboland is an overpopulated, economically depressed area where massive unemployment is likely to continue for many years.

The U.S. analysts said that "...Nigeria is still very much a tribal society..." where local and tribal alliances count more than "national attachment. General Yakubu Gowon, head of the Federal Military Government (FMG) is the accepted national leader and his popularity has grown since the end of the war. The FMG is neither very efficient nor dynamic, but the recent announcement that it intends to retain power for six more years has generated little opposition so far. The Nigerian Army, vastly expanded during the war, is both the main support to the FMG and the chief threat to it. The troops are poorly trained and disciplined and some of the officers are turning to conspiracies and plotting. We think Gowon will have great difficulty in staying in office through the period which he said is necessary before the turnover of power to civilians. His sudden removal would dim the prospects for Nigerian stability."

"Nigeria's economy came through the war in better shape than expected." Problems exist with inflation, internal debt, and a huge military budget, competing with popular demands for government services. "The petroleum industry is expanding faster than expected and oil revenues will help defray military and social service expenditures... "Nigeria emerged from the war with a heightened sense of national pride mixed with an anti-foreign sentiment, and an intention to play a larger role in African and world affairs." British cultural influence is strong but its political influence is declining. The Soviet Union benefits from Nigerian appreciation of its help during the war, but is not trying for control. Nigerian relations with the US, cool during the war, are improving, but France may be seen as the future patron. "Nigeria is likely to take a more active role in funding liberation movements in southern Africa." Lagos, however, is not perceived as the "spiritual and bureaucratic capital of Africa"; Addis Ababa has that role..."
Foreign exchange earnings and government revenues increased spectacularly with the oil price rises of 1973–74. On July 29, 1975, Gen. Murtala Mohammed and a group of officers staged a bloodless coup, accusing Gen. Yakubu Gowon of corruption and delaying the promised return to civilian rule. General Mohammed replaced thousands of civil servants and announced a timetable for the resumption of civilian rule by 1 October 1979. He was assassinated on 13 February 1976 in an abortive coup and his chief of staff Lt. Gen. Olusegun Obasanjo became head of state.

A constituent assembly was elected in 1977 to draft a new constitution, which was published on 21 September 1978, when the ban on political activity was lifted. In 1979, five political parties competed in a series of elections in which Alhaji Shehu Shagari of the National Party of Nigeria (NPN) was elected president. All five parties won representation in the National Assembly.

During the 1950s prior to independence, oil was discovered off the coast of Nigeria. Almost immediately, the revenues from oil began to make Nigeria a wealthy nation. However, the spike in oil prices from $3 per barrel to $12 per barrel, following the Yom Kippur War in 1973 brought a sudden rush of money to Nigeria. Another sudden rise in the price of oil in 1979 to $19 per barrel occurred as a result of the lead up to the Iran–Iraq War. All of this meant that by 1979, Nigeria was the sixth largest producer of oil in the world with revenues from oil of $24 billion per year.

In 1982 the ruling National Party of Nigeria, a conservative alliance led by Shegu Shagari, had hoped to retain power through patronage and control over the Federal Election Commission. In August 1983, Shagari and the NPN were returned to power in a landslide with a majority of seats in the National Assembly and control of 12 state governments. But the elections were marred by violence and allegations of widespread voter fraud included missing returns, polling places failing to open, and obvious rigging of results. There was a fierce legal battle over the results, with the legitimacy of the victory at stake. .

On December 31, 1983, the military overthrew the Second Republic. Major General Muhammadu Buhari emerged as the leader of the Supreme Military Council (SMC), the country's new ruling body. The Buhari government was peacefully overthrown by the SMC's third-ranking member General Ibrahim Babangida in August 1985. Babangida (IBB) cited the misuse of power, violations of human rights by key officers of the SMC, and the government's failure to deal with the country's deepening economic crisis as justifications for the takeover. During his first days in office, President Babangida moved to restore freedom of the press and to release political detainees being held without charge. As part of a 15-month economic emergency plan, he announced pay cuts for the military, police, civil servants and the private sector. President Babangida demonstrated his intent to encourage public participation in decision making by opening a national debate on proposed economic reform and recovery measures. The public response convinced Babangida of intense opposition to an economic recession.

Head of State Babangida promised to return the country to civilian rule by 1990 which was later extended until January 1993. In early 1989 a constituent assembly completed a constitution and in the spring of 1989 political activity was again permitted. In October 1989 the government established two parties, the National Republican Convention (NRC) and the Social Democratic Party (SDP); other parties were not allowed to register.

In April 1990 mid-level officers attempted unsuccessfully to overthrow the government and 69 accused plotters were executed after secret trials before military tribunals. In December 1990 the first stage of partisan elections was held at the local government level. Despite the low turnout, there was no violence and both parties demonstrated strength in all regions of the country, with the SDP winning control of a majority of local government councils.

In December 1991 state legislative elections were held and Babangida decreed that previously banned politicians could contest in primaries scheduled for August. These were cancelled due to fraud and subsequent primaries scheduled for September also were cancelled. All announced candidates were disqualified from standing for president once a new election format was selected. The presidential election was finally held on 12 June 1993, with the inauguration of the new president scheduled to take place 27 August 1993, the eighth anniversary of President Babangida's coming to power.

In the historic 12 June 1993 presidential elections, which most observers deemed to be Nigeria's fairest, early returns indicated that wealthy Yoruba businessman M. K. O. Abiola won a decisive victory. However, on 23 June, Babangida, using several pending lawsuits as a pretence, annulled the election, throwing Nigeria into turmoil. More than 100 were killed in riots before Babangida agreed to hand power to an interim government on 27 August 1993. He later attempted to renege on this decision, but without popular and military support, he was forced to hand over to Ernest Shonekan, a prominent nonpartisan businessman. Shonekan was to rule until elections scheduled for February 1994. Although he had led Babangida's Transitional Council since 1993, Shonekan was unable to reverse Nigeria's economic problems or to defuse lingering political tension.

With the country sliding into chaos Defense Minister Sani Abacha assumed power and forced Shonekan's resignation on 17 November 1993. Abacha dissolved all democratic institutions and replaced elected governors with military officers. Although promising restoration of civilian rule he refused to announce a transitional timetable until 1995. Following the annulment of the June 12 election, the United States and others imposed sanctions on Nigeria including travel restrictions on government officials and suspension of arms sales and military assistance. Additional sanctions were imposed as a result of Nigeria's failure to gain full certification for its counter-narcotics efforts.

Although Abacha was initially welcomed by many Nigerians, disenchantment grew rapidly. Opposition leaders formed the National Democratic Coalition (NADECO), which campaigned to reconvene the Senate and other disbanded democratic institutions. On 11 June 1994 Moshood Kashimawo Olawale Abiola declared himself president and went into hiding until his arrest on 23 June. In response, petroleum workers called a strike demanding that Abacha release Abiola and hand over power to him. Other unions joined the strike, bringing economic life around Lagos and the southwest to a standstill. After calling off a threatened strike in July the Nigeria Labour Congress (NLC) reconsidered a general strike in August after the government imposed conditions on Abiola's release. On 17 August 1994, the government dismissed the leadership of the NLC and the petroleum unions, placed the unions under appointed administrators, and arrested Frank Kokori and other labor leaders.

The government alleged in early 1995 that military officers and civilians were engaged in a coup plot. Security officers rounded up the accused, including former Head of State Obasanjo and his deputy, retired General Shehu Musa Yar'Adua. After a secret tribunal, most of the accused were convicted and several death sentences were handed down. In 1994 the government set up the Ogoni Civil Disturbances Special Tribunal to try Ogoni activist Ken Saro-Wiwa and others for their alleged roles in the killings of four Ogoni politicians. The tribunal sentenced Saro-Wiwa and eight others to death and they were executed on 10 November 1995.

On 1 October 1995 Abacha announced the timetable for a three-year transition to civilian rule. Only five political parties were approved by the regime and voter turnout for local elections in December 1997 was under 10%. On 20 December 1997, the government arrested General Oladipo Diya, ten officers, and eight civilians on charges of coup plotting. The accused were tried before a Gen Victor Malu military tribunal in which Diya and five others- Late Gen AK Adisa, Gen Tajudeen Olnrewaju, Late Col OO Akiyode, Major Seun Fadipe and a civilian Engr Bola Adebanjo were sentenced to death to die by firing squad. Abacha enforced authority through the federal security system which is accused of numerous human rights abuses, including infringements on freedom of speech, assembly, association, travel, and violence against women.

Abacha died of heart failure on 8 June 1998 and was replaced by General Abdulsalami Abubakar. The military Provisional Ruling Council (PRC) under Abubakar commuted the sentences of those accused in the alleged coup during the Abacha regime and released almost all known civilian political detainees. Pending the promulgation of the constitution written in 1995, the government observed some provisions of the 1979 and 1989 constitutions. Neither Abacha nor Abubakar lifted the decree suspending the 1979 constitution, and the 1989 constitution was not implemented. The judiciary system continued to be hampered by corruption and lack of resources after Abacha's death. In an attempt to alleviate such problems Abubakar's government implemented a civil service pay raise and other reforms.

In August 1998 Abubakar appointed the Independent National Electoral Commission (INEC) to conduct elections for local government councils, state legislatures and governors, the national assembly, and president. The NEC successfully held elections on 5 December 1998, 9 January 1999, 20 February, and 27 February 1999, respectively. For local elections, nine parties were granted provisional registration with three fulfilling the requirements to contest the following elections. These parties were the People's Democratic Party (PDP), the All People's Party (APP), and the predominantly Yoruba Alliance for Democracy (AD). Former military head of state Olusegun Obasanjo, freed from prison by Abubakar, ran as a civilian candidate and won the presidential election. The PRC promulgated a new constitution based largely on the suspended 1979 constitution, before the 29 May 1999 inauguration of the new civilian president. The constitution includes provisions for a bicameral legislature, the National Assembly consisting of a 360-member House of Representatives and a 109-member Senate.

The emergence of democracy in Nigeria on May 1999 ended 16 years of consecutive military rule. Olusegun Obasanjo inherited a country suffering economic stagnation and the deterioration of most democratic institutions. Obasanjo, a former general, was admired for his stand against the Abacha dictatorship, his record of returning the federal government to civilian rule in 1979, and his claim to represent all Nigerians regardless of religion.

The new President took over a country that faced many problems, including a dysfunctional bureaucracy, collapsed infrastructure, and a military that wanted a reward for returning quietly to the barracks. The President moved quickly and retired hundreds of military officers holding political positions, established a blue-ribbon panel to investigate human rights violations, released scores of persons held without charge, and rescinded numerous questionable licenses and contracts left by the previous regimes. The government also moved to recover millions of dollars in funds secreted to overseas accounts.

Most civil society leaders and Nigerians witnessed marked improvements in human rights and freedom of the press under Obasanjo. As Nigeria works out representational democracy, conflicts persist between the Executive and Legislative branches over appropriations and other proposed legislation. A sign of federalism has been the growing visibility of state governors and the inherent friction between Abuja and the state capitals over resource allocation.

Communal violence has plagued the Obasanjo government since its inception. In May 1999 violence erupted in Kaduna State over the succession of an Emir resulting in more than 100 deaths. In November 1999, the army destroyed the town of Odi, Bayelsa State and killed scores of civilians in retaliation for the murder of 12 policemen by a local gang. In Kaduna in February–May 2000 over 1,000 people died in rioting over the introduction of criminal Shar'ia in the State. Hundreds of ethnic Hausa were killed in reprisal attacks in south-eastern Nigeria. In September 2001, over 2,000 people were killed in inter-religious rioting in Jos. In October 2001, hundreds were killed and thousands displaced in communal violence that spread across the states of Benue, Taraba, and Nasarawa. On 1 October 2001 Obasanjo announced the formation of a National Security Commission to address the issue of communal violence. Obasanjo was reelected in 2003.

The new president faces the daunting task of rebuilding a petroleum-based economy, whose revenues have been squandered through corruption and mismanagement. Additionally, the Obasanjo administration must defuse longstanding ethnic and religious tensions if it hopes to build a foundation for economic growth and political stability. Currently, there is conflict in the Niger Delta over the environmental destruction caused by oil drilling and the ongoing poverty in the oil-rich region.

A further major problem created by the oil industry is the drilling of pipelines by the local population in an attempt to drain off the petroleum for personal use or as a source of income. This often leads to major explosions and high death tolls. Particularly notable disasters in this area have been: 1) October 1998, Jesse, 1100 deaths, 2) July 2000, Jesse, 250 deaths, 3) September 2004, near Lagos, 60 deaths, 4) May 2006, Ilado, approx. 150-200 deaths (current estimate).

Two militants of an unknown faction shot and killed Ustaz Ja'afar Adam, a northern Muslim religious leader and Kano State official, along with one of his disciples in a mosque in Kano during dawn prayers on 13 April 2007. Obasanjo had recently stated on national radio that he would "deal firmly" with election fraud and violence advocated by "highly placed individuals." His comments were interpreted by some analysts as a warning to his Vice President and 2007 presidential candidate Atiku Abubakar.

In the 2007 general election, Umaru Yar'Adua and Goodluck Jonathan, both of the People's Democratic Party, were elected President and Vice President, respectively. The election was marred by electoral fraud, and denounced by other candidates and international observers.

Yar'Adua's presidency was fraught with uncertainty as media reports said he suffered from kidney and heart disease. In November 2009, he fell ill and was flown out of the country to Saudi Arabia for medical attention. He remained incommunicado for 50 days, by which time rumours were rife that he had died. This continued until the BBC aired an interview that was allegedly done via telephone from the president's sick bed in Saudi Arabia. As of January 2010, he was still abroad.

In February 2010, Goodluck Jonathan began serving as acting President in the absence of Yaradua. In May 2010, the Nigerian government learned of Yar'Adua's death after a long battle with existing health problems and an undisclosed illness. This lack of communication left the new acting President Jonathan with no knowledge of his predecessor's plans. Yar'Adua's Hausa-Fulani background gave him a political base in the northern regions of Nigeria, while Goodluck does not have the same ethnic and religious affiliations. This lack of primary ethnic support makes Jonathan a target for militaristic overthrow or regional uprisings in the area. With the increase of resource spending and oil exportation, Nigerian GDP and HDI (Human Development Index) have risen phenomenally since the economically stagnant rule of Sani Abacha, but the primary population still survives on less than US$2 per day. Goodluck Jonathan called for new elections and stood for re-election in April 2011, which he won. However, his re-election bid in 2015 was truncated with the emergence of former military ruler General Muhammadu Buhari, mainly on his inability to quell the rising insecurity in the country. General Muhammadu Buhari was declared the winner of the 2015 presidential elections. General Muhammadu Buhari took over the helm of affairs in May 2015 after a peaceful transfer of power from the Jonathan led administration.

Nigeria's Democracy day was originally celebrated on May 29, every year since General Olusegun Obasanjo emerged President in 1999.
However, on June 12, 2018, General Muhammadu Buhari, as president, announced a shift in this date from May 29 to June 12, as from the year 2019. This was to commemorate the June 12th election of 1993, and the events that surrounded it.

The Ibadan School dominated the academic study of Nigerian history until the 1970s. It arose at the University of Ibadan in the 1950s and remained dominant until the 1970s. The University of Ibadan was the first university to open in Nigeria, and its scholars set up the history departments at most of Nigeria's other universities, spreading the Ibadan historiography. Its scholars also wrote the textbooks that were used at all levels of the Nigerian education system for many years. The school's output appears in the "Ibadan History Series."

The leading scholars of the Ibadan School include Saburi Biobaku, Kenneth Dike, J. F. A. Ajayi, Adiele Afigbo, E. A. Ayandele, O. Ikime and Tekena Tamuno. Foreign scholars often associated with the school include Michael Crowder, Abdullahi Amith, J. B. Webster, R. J. Gavin, Robert Smith, and John D. Omer-Cooper. The school was characterized by its overt Nigerian nationalism and it was geared towards forging a Nigerian identity through publicizing the glories of pre-colonial history. The school was quite traditional in its subject matter, being largely confined to the political history that colleagues in Europe and North America were then rejecting. It was very modern, however, in the sources used. Much use was made of oral history and throughout the school took a strongly interdisciplinary approach to gather information. This was especially true after the founding of the Institute for African Studies that brought together experts from many disciplines.

The Ibadan School began to decline in importance the 1970s. The Nigerian Civil War led some to question whether Nigeria was, in fact, a unified nation with a national history. At the same time, rival schools developed. At Ahmadu Bello University in Zaria, Nigeria, the Islamic Legitimist school arose that rejected Western models in favour of the scholarly tradition of the Sokoto Caliphate and the Islamic world. From other parts of Africa, the Neo-Marxist school arrived and gained a number of supporters. Social, economic, and cultural history also began to grow in prominence.

In the 1980s Nigerian scholarship, in general, began to decline, and the Ibadan School was much affected. The military rulers looked upon the universities with deep suspicion and they were poorly funded. Many top minds were co-opted with plum jobs in the administration and left academia. Others left the country entirely for jobs at universities in the West. The economic collapse of the 1980s also greatly hurt the scholarly community, especially the sharp devaluation of the Nigerian currency. This made inviting foreign scholars, subscribing to journals, and attending conferences vastly more expensive. Many of the domestic journals, including the "Journal of the Historical Society of Nigeria", faltered and were only published rarely, if at all.





</doc>
<doc id="21385" url="https://en.wikipedia.org/wiki?curid=21385" title="Geography of Nigeria">
Geography of Nigeria

Nigeria is a country in West Africa. Nigeria shares land borders with the Republic of Benin in the west, Chad and Cameroon in the east, and Niger in the north. It also shares a border with the self-declared, but internationally unrecognized state of Ambazonia in the southeast. Its coast lies on the Gulf of Guinea in the south and it borders Lake Chad to the northeast. In the southeast, it also shares a border with the breakaway state of Ambazonia. Noted geographical features in Nigeria include the Adamawa highlands, Mambilla Plateau, Jos Plateau, Obudu Plateau, the Niger River, River Benue and Niger Delta.

Nigeria is found in the Tropics, where the climate is seasonally damp and very humid.
Nigeria is affected by four climate types; these climate types are distinguishable, as one moves from the southern part of Nigeria to the northern part of Nigeria through Nigeria's middle belt.

The tropical monsoon climate, designated by the Köppen climate classification as "Am", is found in the southern part of the country. This climate is influenced by the monsoons originating from the South Atlantic ocean, which is brought into the country by the (maritime tropical) MT airmass, a warm moist sea to land seasonal wind. Its warmth and high humidity gives it a strong tendency to ascend and produce copious rainfall, which is a result of the condensation of water vapour in the rapidly rising air.

The Tropical monsoon climate has a very small temperature range. Then temperature ranges are almost constant throughout the year, for example, Warri town in the southern part of Nigeria, records a maximum of for its hottest month while its lowest temperature is in its coldest month. The temperature difference of Warri town is not more than 2 °C (5 °F).

The southern part of Nigeria experiences heavy and abundant rainfall. These storms are usually convectional in nature due to the regions proximity, to the equatorial belt. The annual rainfall received in this region is very high, usually above the rainfall totals giving for tropical rainforest climates worldwide. Over of rainfall is received in the coastal region of Nigeria around the Niger delta area. Bonny town found in the coastal region of the Niger delta area in southern Nigeria receives well over of rainfall annually. The rest of the southeast receives between 2,000 and of rain per year.

The southern region of Nigeria experiences a double rainfall maxima characterised by two high rainfall peaks, with a short dry season and a longer dry season falling between and after each peaks. The first rainy season begins around March and last to the end of July with a peak in June, this rainy season is followed by a short dry break in August known as the August break which is a short dry season lasting for two to three weeks in August. This break is broken by the short rainy season starting around early September and lasting to mid October with a peak period at the end of September. The ending of the short rainy season in October is followed by long dry season. This period starts from late October and lasts until early March with peak dry conditions between early December and late February.

The tropical savanna climate or tropical wet and dry climate, is extensive in area and covers most of western Nigeria to central Nigeria beginning from the tropical rainforest climate boundary in southern Nigeria to the central part of Nigeria, where it exerts enormous influence on the region.

This climate, the tropical savanna climate exhibits a well marked rainy season and a dry season with a single peak known as the summer maximum due to its distance from the equator. Temperatures are above throughout the year. Abuja, Nigeria's capital city found in central Nigeria, has a temperature range of to , and an annual rainfall of about with a single rainfall maxima in September.

The single dry season experienced in this climate, the tropical savanna climate in central Nigeria beginning from December to March, is hot and dry with the Harmattan wind, a continental tropical (CT) airmass laden with dust from the Sahara Desert prevailing throughout this period.

With the Intertropical Convergence Zone (ITCZ) swinging northward over West Africa from the Southern Hemisphere in April, heavy showers coming from pre-monsoonal convective clouds mainly in the form of squall lines also known as the north easterlies formed mainly as a result of the interactions of the two dominant airmasses in Nigeria known as the Maritime tropical (south westerlies) and the Continental tropical (north easterlies), begins in central Nigeria while the Monsoons from the south atlantic ocean arrives in central Nigeria in July bringing with it high humidity, heavy cloud cover and heavy rainfall which can be daily occurrence lasting till September when the monsoons gradually begin retreating southward to the southern part of Nigeria. Rainfall totals in central Nigeria varies from in the lowlands of the river Niger Benue trough to over along the south western escarpment of the Jos Plateau.

The Sahel climate or tropical dry climate, is the predominant climate type in the northern part of Nigeria. Annual rainfall totals are lower compared to the southern and central part of Nigeria. The rainy season in the northern part of Nigeria last for only three to four months (June–September). The rest of the year is hot and dry with temperatures climbing as high as . Potiskum, Yobe State in the northeast of Nigeria recorded Nigeria’s lowest ever temperature of .

Alpine climate or highland climate or mountain climate are found on highlands regions in Nigeria. Highlands with the alpine climate in Nigeria, are well over above sea level. Due to their location in the tropics, this elevation is high enough to reach the temperate climate line in the tropics thereby giving the highlands, mountains and the plateau regions standing above this height, a cool mountain climate.

Nigeria, like the rest of West Africa and other tropical lands, has only two seasons. These are the dry season and the rainy season. The dry season is accompanied by a dust laden airmass from the Sahara Desert, locally known as Harmattan, or by its main name, The Tropical Continental (CT) airmass, while the rainy season is heavily influenced by an airmass originating from the south Atlantic ocean, locally known as the south western wind, or by its main name, The Tropical Maritime (MT) airmass. These two major wind systems in Nigeria are known as the trade winds.

The tropical maritime airmass (MT) is responsible for Nigeria's rainy season. This wind (the tropical maritime airmass) invades the country from February in the southern part of Nigeria while it takes longer for the wind to fully cover the whole of the country, reaching the northern part of Nigeria in June. Its invasion is as a result of the northward retreat, of the tropical continental airmass (CT) known as the harmattan. The northward retreat of the tropical continental airmass (CT), is caused by the sun's northward shift from the tropic of capricorn in the southern hemisphere to the tropic of cancer in the northern hemisphere. This shift begins from February and ends in June, when the sun is fully overhead, at the tropic of cancer in the northern hemisphere.

During this northward migration of the sun as a result of the earth tilting along its axis, the sun crosses the equator (around March), moving over west Africa at this time on its journey to the northern hemisphere. West Africa comes directly under the sun at this time. The sun is overhead throughout west Africa and over Nigeria during this period of the sun's northward migration to the tropic of cancer in the northern hemisphere.

The whole of West Africa is heated intensely as result of the increased insolation received from the sun being overhead over west Africa. Temperatures can climb as high as over west Africa during this time. Temperatures in the northern part of Nigeria can go as high as in cities like Maiduguri.

The high temperatures coupled with an increase in insolation causes a region of low pressure to develop over west Africa and Nigeria (between March to May). The Tropical continental airmass (CT) from the Sahara Desert in the northern part of west Africa, is weakened due to the overheating of the land surface in west Africa and Nigeria at this time. The Tropical continental airmass (CT) begins to retreat northwards to the Sahara Desert due to massive heating of the land which transfers heat in the form of convection into the Tropical continental airmass (CT) which constitutes the main layer of air above the land. This transfer of heat in the Tropical continental airmass (CT) in turn, causes the wind to expand and become lighter as this is the normal behaviour for winds moving above intensely heated grounds.
The Tropical continental airmass (CT) loses its strength as a major airmass in the region of west Africa and over Nigeria at this time (around February in the southern part of Nigeria to June in northern Nigeria) and begins to retreat coupled with the rising of air in form of convection within this airmass (Tropical continental airmass (CT)), further weakening the dominance of the wind over west Africa and Nigeria.
The Tropical continental airmass (CT) finally retreats from most part of Nigeria, and the West African atmosphere around April to May, leaving an empty atmosphere over Nigeria. The sun's rays enters into the atmosphere of Nigeria more intense than it does during the presence of the Tropical continental airmass, which contained dust (in form of haze) that reduced the intensity of the sun. The overheating of the west Africa land mass and Nigeria in particular creates a low pressure region over west Africa and Nigeria. This low pressure zone attracts the Tropical Maritime Airmass (MT) from the south Atlantic Ocean since areas of low pressures experiences inward blowing winds because winds are moving air blowing outwards from regions of high pressure to regions of low pressure.

The Tropical Maritime Airmass is a warm humid and unstable trade wind due to its warmth. Convectional currents are easily set up within the airmass whenever there is little instability in the airmass as a result of a slight to a very high orographic uplift in mountainous regions like the obudu plateau or the heating of the land which can trigger the formation of cumulonimbus cloud leading to thunderstorms within the airmass.

During the dominance of the Tropical Maritime Airmass (MT) in the rainy season of Nigeria, mornings are bright and sunny, the sun's heating of the land in the mornings and afternoons sets up convectional currents, these currents rise vertically and cumulonimbus clouds are formed, by afternoons to evenings, torrential downpour follows.

The Easterly wave or the African easterly waves is another major contributor of rainfall during the summer monsoons months of May to September in Nigeria.

The nature of this waves changes at about the 15 degrees line. The waves that pass south of this line carry moisture and create convection that leads to rain clouds. Nigeria's northern end is south of the 15 degrees line at about 14 degrees. Nigeria's location in the wetter part of the easterly waves south of the 15 degree line creates wetter climatic conditions for Nigeria especially during the monsoons.

The Tropical Continental Airmass (CT) locally known as the Harmattan, is a wind originating from North Africa which crosses the Sahara Desert into west Africa to Nigeria. This airmass dominates Nigeria's climate during the dry season from December to March. The Tropical continental airmass is dusty and creates a haze within the atmosphere of west Africa and Nigeria when it predominates. The haze is as a result of the dust within the airmass limiting visibility and blocking much of the sun's rays from reaching the earth. It is also a dry air mass formed over land in an area close to the equator. An example of Tropical Continental is a warm air mass that forms over northern Mexico.

The mass has no ability of forming rain due to low humidity within the airmass, since it crosses the Sahara Desert, it picks up dust instead of water thereby creating little chances for rainfall.

The airmass makes life difficult as a result of low visibility which hampers transportation.
The dust haze creates an almost desert conditions in the country during the dominance of the Tropical continental airmass (the harmattan). But its coming brings some relief to farmers since the low humidity present in the air quickens the drying of their crops.

Nigeria's location in the tropics has given her a tropical hot climate. Temperatures in Nigeria vary according to the seasons of the year as with other lands found in the tropics. Nigeria's seasons are determined by rainfall with rainy season and dry season being the major seasons in Nigeria.

The rainy season of Nigeria brings in cooler weather to the country as a result of an increased cloud cover that acts as a blockage of the intense sunshine of the tropics by blocking much of the suns rays in the rainy season; this in turn cools the land, and the winds above the ground remains cool thereby making for cooler temperatures during the rainy season. But afternoons in the rainy season can be hot and humid, a feature of tropical climates. In the rainy season it is damp, and the rainfalls are usually abundant.

The dry season of Nigeria is a period of little cloud cover in the southern part of Nigeria to virtually no cloud cover in the northern part of Nigeria. The sun shines through the atmosphere with little obstructions from the clear skies making the dry season in Nigeria a period of warm weather conditions. In the middle of the dry season around December, a dusty wind from the Sahara Desert called the Harmattan enters Nigeria from the northeastern part of the country blocking sun rays partially from shining and also creating haze in the atmosphere, this activities of the wind lowers temperatures considerably saving inhabitants for sometime, from the scorching heat that would have occurred as a result of clearer skies during the dry season. But with the withdrawal of this wind around March to April following the onset of the rainy season, temperatures can go as high as in some parts of Nigeria.

Semi temperate weather conditions prevail on the highlands in central Nigeria above above sea level, namely the Jos Plateau. Temperatures on the Jos plateau ranges between 16 °C to 25 °C which are cool all year round.

Temperate weather conditions occur on the highlands along the Nigeria Cameroon border, in the eastern part of Nigeria. Highlands in these region attain an average height of more than to some standing above above sea level. The climate on these highlands is temperate all year round. The major highlands in this region are the Obudu Plateau above , Mambilla Plateau above and Mt. Chappal Waddi above .

Nigeria's most expansive topographical region is that of the valleys of the Niger and Benue River valleys (which merge into each other and form a "y" shaped confluence at Lokoja). Plains rise to the north of the valleys. To the southwest of the Niger there is "rugged" highland, and to the southeast of the Benue hills and mountains are found all the way to the border with Cameroon. Coastal plains are found in both the southwest and the southeast.

The Niger Delta is located in the southern part of Nigeria. It is one of the world's largest arcuate fan-shaped river deltas.

The riverine area of the Niger Delta is a coastal belt of swamps bordering the Atlantic ocean. The swamps are vegetated tidal flats formed by a reticulate pattern of interconnected meandering creeks and tributaries of the Niger River.

The vegetation of the Niger Delta consist mainly of forest swamps. The forest are of two types, nearest the sea is a belt of saline and brackish Mangrove swamp separated from the sea by sand beach ridges within the mangrove swamp. Numerous sandy islands occur with fresh water vegetation. Fresh water swamps gradually supersede the mangrove on the landward side. About 70% of Nigeria's crude oil and gas production is from the area.

Rainfall in the coastal belt of the Niger Delta is heavy due to the closeness of the Delta region to the equator. Annual rainfall totals vary from 2,400 to over 4,000 millimeters.

Niger Delta cities and their annually rainfall totals in millimeters:


Nigeria is covered by three types of vegetation: forests (where there is significant tree cover), savannahs (insignificant tree cover, with grasses and flowers located between trees), and montane land. (The latter is the least common, and is mainly found in the mountains near the Cameroon border.) Both the forest zone and the savannah zone are divided into three parts.

Some of the forest zone's most southerly portion, especially around the Niger River and Cross River deltas, is mangrove swamp (see Central African mangroves). North of this is fresh water swamp, containing different vegetation from the salt water mangrove swamps, and north of that is rain forest.

The savannah zone's three categories are divided into mm' Guinean forest-savanna mosaic, made up of plains of tall grass which are interrupted by trees, the most common across the country; Sudan savannah, similar but with shorter grasses and shorter trees; and Sahel savannah patches of grass and sand, found in the northeast.

Nigeria, the most populous African country (with a population of over 182 million in 2015), is nearly equally divided between Christianity and Islam, though the exact ratio is uncertain. The majority of Nigerian Muslims are Sunni and are concentrated in the northern region of the country, while Christians dominate in the south. Most of Nigeria's Christians are Protestant (broadly defined) though about a quarter are Catholic.

Nigeria has the largest Muslim population in sub-Saharan Africa. Islam dominates the north and has a number of supporters in the southwestern, Yoruba part of the country. In terms of Nigeria's major ethnic groups' religious affiliations, the Hausa ethnic group in the north is mostly Muslim, the Yoruba tribe in the west is divided among mainly Christianity, Islam and traditional religions, while the Igbos of the east and the Ijaw in the south are predominantly Christians (Catholics) and some practitioners of traditional religions. The middle belt of Nigeria contains the most of the minority ethnic groups in Nigeria and they are mostly Christians and members of traditional religions with few Muslim converts.

The vast majority of Muslims in Nigeria are Sunni, belonging to Maliki school of jurisprudence; however, a sizeable minority also belongs to Shafi madhhab. Many Sunni Muslims are members of Sufi brotherhoods. Most Sufis follow the Qadiriyya, Tijaniyyah or Mouride movement. A significant Shia minority exists ("see Shia in Nigeria"). Some northern states have incorporated Sharia law into their previously secular legal systems, which has brought about some controversy. Kano State has sought to incorporate Sharia law into its constitution. The majority of Quranists follow the Kalo Kato or Quraniyyun movement. There are also Ahmadiyya and Mahdiyya minorities.

Read more

Nigeria's natural resources include but are not limited to petroleum (see petroleum in Nigeria), tin, columbite, iron ore, coal, limestone, lead, zinc, natural gas, hydropower, and arable land.

This is a list of the extreme points of Nigeria, the points that are farther north, south, east or west than any other location.



</doc>
<doc id="21386" url="https://en.wikipedia.org/wiki?curid=21386" title="Demographics of Nigeria">
Demographics of Nigeria

Nigeria is one of the most densely populated countries in Africa, with approximately 200 million people in an area of , and is also the country with the largest population in Africa and the seventh largest population in the world. Approximately 50% of Nigerians are urban dwellers, with the rate of urbanization being estimated at 4.3%. Nigeria is home to over 250 ethnic groups, with over 500 languages, and the variety of customs, and traditions among them gives the country great cultural diversity. The three largest ethnic groups are the Hausa 27.4% of the population; along with the Yoruba 21% and Igbo 18%. The Efik, Ibibio, Annang, and Ijaw constitute other Southeastern populations. The Urhobo-Isoko, Edo and Itsekiri constitute Nigerian's Midwest.

Most of the population is a young population, with 42.54% between the ages of 0–14. There is also a very high dependency ratio of the country at 88.2 dependants per 100 non-dependants.

Three of the main religious groups are Muslim at 45%, Christian at 45% and other indigenous beliefs at 10%. The predominantly Christian Igbo are found in the southeast. Roman Catholicism is the largest Christian denomination in Igboland, but Anglicanism is also strong, as are Pentecostal and other Evangelical denominations.

Persons of different ethnic backgrounds most commonly communicate in English, although knowledge of two or more Nigerian languages is widespread. Hausa, Igbo and Yoruba are the most widely used Nigerian languages. Nigerian Pidgin is used widely as an unofficial medium of communication especially in the Nigerian cities of Warri, Sapele, Ughelli, Benin and Port Harcourt.

Nigeria's population has been increasing rapidly for at least the last 5 decades due to very high birth rates, quadrupling its population during this time. Growth was fastest in the 1980s, after child mortality had dropped rapidly, and has slowed slightly since then as the birth rate has declined slightly. According to the 2017 revision of the World Population Prospects the total population was 185,989,640 in 2016, compared to only 37,860,000 in 1950. The proportion of children under the age of 15 in 2010 was 44.0%, 53.2% was between 15 and 65 years of age, while 2.7% was 65 years or older. There is a large population momentum, with 3.2 percent growth rate leading to the projected population.

Abuja has not successfully implemented family planning programs to reduce and space births because of a lack of political will, government financing, and the availability and affordability of services and products, as well as a cultural preference for large families. Increased educational attainment, especially among women, and improvements in health care are needed to encourage and to better enable parents to opt for smaller families.

The former Nigeria's Chairman of National Population Commission, Eze Duruiheoma, delivering Nigeria's statement in New York on Sustainable Cities, Human Mobility and International Migration in the 51st Session of Commission on Population and Development, said that "Nigeria remains the most populous in Africa, the seventh globally with an estimated population of over 198 million. The recent World Population Prospects predicts that by 2050, Nigeria will become the third most populated country in the world. Over the last 50 years, the Nigeria's urban population has grown at an average annual growth rate of more than 6.5 per cent without commensurate increase in social amenities and infrastructure." He also stated that the population "grew substantially from 17.3 in 1967 to 49.4 per cent in 2017."

Total Fertility Rate (TFR) (Wanted TFR) and Crude Birth Rate (CBR):

Fertility data as of 2013 (DHS Program):

Source: Demographic and Health Surveys (DHS)

∗ MICS surveys

Contraceptive prevalence, any methods (% of women ages 15–49)

∗ UNICEFs State of the Worlds Children and Child info, United Nations Population Divisions World Contraceptive Use, household surveys including Demographic and Health Surveys and Multiple Indicator Cluster Surveys.

The total population in sub-Saharan Africa is projected to increase to almost one billion people, making it the most populated region outside of South-Central Asia. According to the United Nations, the population of Nigeria will reach 411 million by 2050. Nigeria might then be the 3rd most populous country in the world. In 2100, the population of Nigeria may reach 794 million.While the overall population is expected to increase, the growth rate is estimated to decrease from 1.2 percent per year in 2010 to 0.4 percent per year in 2050. The birth rate is also projected to decrease from 20.7 to 13.7, while the death rate is projected to increase from 8.5 in 2010 to 9.8 in 2050. Life expectancy is all expected to increase from 67.0 years in 2010 to 75.2 years in 2050. By 2050, 69.6% of the population is estimated to be living in urban areas compared to 50.6% in 2010.

Registration of vital events in Nigeria is not complete. The Population Department of the United Nations prepared the following estimates.
Life expectancy from 1950 to 2015 ("UN World Population Prospects"):
The following demographic statistics of Nigeria in 2019 are from the World Population Review.


The following demographic statistics are from the CIA World Factbook, unless otherwise indicated.

Nigeria is Africa's most populous country. Significant population clusters are scattered throughout the country, with the highest density areas being in the south and southwest.

-0.2 migrant(s)/1,000 population (2017 est.) Country comparison to the world: 106th

-0.22 migrant(s)/1,000 population (2013 est.)

adult prevalence rate
2.8% (2017 est.)

people living with HIV/AIDS
<br>2.6 million (2007 est.)
<br>3.3 million (2009 est.)

definition: age 15 and over can read and write

Structure of the population (DHS 2013) (males 87 034, females 89 529 = 176 574):

Today millions of ethnic Nigerians live abroad, the largest communities can be found in the United Kingdom (500,000–3,000,000) and the United States (600,000–1,000,000 Nigerians), other countries that followed closely are South Africa, Gambia, and Canada respectively. There are also large groups in Ireland, Portugal and many other countries.
Inspiration for emigration is based heavily on socio-economical issues such as warfare, insecurity, economical instability and civil unrest. Between 1400–1900, of 1.4 million of 2 million emigrants were slaves sent to the Americas. This is due to the fact that the land now known as Nigeria was a central point for 4 slave trades during the 19th century. Though bondage represented a great deal, an estimated 30,000 Nigerian inhabitants would relocate to Kano City and Gambia to take advantage of financial opportunities afforded by fertile land and available natural resources. What's more, the presence of gold mines and rail lines along the Gold Coast, present-day Ghana, attracted an estimated 6,500 Nigerian citizens to attain financial gain and opportunity. The population of Nigerians in Ghana rose to roughly 149,000 before the 1969 alien expulsion order would displace nearly the entire population to surrounding countries.

Nigeria is nearly equally divided between Christianity and Islam. The majority of Nigerian Muslims are Sunni and are concentrated in the northern, central and south-western zones of the country, while Christians dominate in some central states (especially Plateau and Benue states), and the south-east and south-south regions. Other religions practiced in Nigeria include African Traditional Religion, Hinduism, Bahai, Judaism, The Grail Movement, and the Reformed Ògbóni Fraternity, one of the traditional socio-religious institutions of the Yorùbá people and their Òrìṣà religion known as Ẹ̀sìn Òrìṣà Ìbílẹ̀ in the Yorùbá language.

According to a 2009 Pew survey, 51.6% of Nigeria's population were Muslims. A later Pew study in 2011 calculated that Christians now formed 47.4% of the population. Adherents of other religions 1% make up of the population.

The shift of population balance between Muslims and Christians is a result of northern and southern Nigeria being in different stages of demographic transition. The Muslim-dominated north is in an earlier stage of the demographic transition with much higher fertility rates than the south, whose split Christian/Muslim population is further along in the transition, and whose fertility rates are declining. Decreasing fertility can be linked to more access to education, use of contraceptives, and differing beliefs regarding family planning.

The 1999 introduction of Sharia Law in twelve northern Nigerian states led to massive violence and unrest and caused an ethnic and religious rift between Sharia and Non-Sharia states, a divide that has deepened with time.

Nigeria is home to a substantial network of organized crime, active especially in drug trafficking.
Nigerian criminal groups are heavily involved in drug trafficking, shipping heroin from Asian countries to Europe and America; and cocaine from South America to Europe and South Africa.
The various Nigerian Confraternities or "campus cults" are active in both organized crime and in political violence as well as providing a network of corruption within Nigeria. As confraternities have extensive connections with political and military figures, they offer excellent alumni networking opportunities. The Supreme Vikings Confraternity, for example, boasts that twelve members of the Rivers State House of Assembly are cult members.
On lower levels of society, there are the "area boys", these are organized gangs mostly active in Lagos who specialize in mugging and small-scale drug dealing. According to official statistics, gang violence in Lagos resulted in 273 civilians and 84 policemen killed in the period of August 2000 to May 2001.

"The result of factors such as endemic local corruption, which facilitates illicit trafficking; the Biafra civil war, which contributed to a proliferation of firearms; the oil boom of the 1970s, which led to the embezzlement of public funds; and the economic crisis of the 1980s, which was accompanied by a rise in robberies. The expansion of the Nigerian diaspora and organized crime went hand in hand. Global migration boosted prostitution, drug trafficking and fraud, the three main activities of Nigerian syndicates. The smuggling of Nigerian sex workers became a whole industry that now extends from Switzerland to France and Italy (where black prostitutes are called "fireflies"), and has even reached the Prudish Kingdom of Saudi Arabia, from which 1,000 women are said to be deported every month by the authorities."

The high crime rate among Nigerian migrants also leads to stereotyping Nigerians as criminals; thus, in Cameroon, Nigerian migrants are perceived collectively by the inhabitants of Cameroon as likely to be oil smugglers or dealers in stolen cars. In the Netherlands, the debate on Nigerian crime reached an intensity described as a "moral panic" by one scholar. In Switzerland, the crime rate of Nigerian young males was reported as 620% that of Swiss males in same age group (2009 data), the second highest crime rate of any nationality, just below that of Angolan nationals (at 630%).

Nigeria is also pervaded by political corruption. It is ranked 136 out of 168 countries in Transparency International's 2015 Corruption Perceptions Index.



</doc>
<doc id="21387" url="https://en.wikipedia.org/wiki?curid=21387" title="Federal government of Nigeria">
Federal government of Nigeria

The federal government of Nigeria is composed of three distinct branches: legislative, executive, and judicial, whose powers are vested by the Constitution of Nigeria in the National Assembly, the President, and the federal courts, including the Supreme Court, respectively.

Nigeria is a federal republic, with executive power exercised by the president. The president is the head of state, the head of government, and the head of a multi-party system. Nigerian politics takes place within a framework of a federal, presidential, representative democratic republic, in which executive power is exercised by the government. Legislative power is held by the real government and the two chambers of the legislature: the House of Representatives and the Senate. Together, the two chambers make up the law-making body in Nigeria, called the National Assembly, which serves as a check on the executive arm of government. The highest judiciary arm of government in Nigeria is the Supreme Court of Nigeria which was created after independence and also practices Baron de Montesquieu's theory of the separation of powers based on the United States system and also practises checks and balances.

The law of Nigeria is based on the rule of law, the independence of the judiciary, and British common law (due to the long history of British colonial influence). The common law in the legal system is similar to common-law systems used in England and Wales and other Commonwealth countries. The constitutional framework for the legal system is provided by the Constitution of Nigeria.


There is a judicial branch, with the Supreme Court regarded as the highest court of the Nation.

The two fundamental sources of Nigerian law through legislation are

(1) Acts of British parliament, popularly referred to as statutes of general application.

(2) Local legislation (comprising enactments of the Nigerian legislatures from colonial period to date). There were other sources which though subsumed in Nigerian legislations were distinctly imported into the Nigerian legal systems. They are called the "criminal and penal codes" of Nigeria.

Nigerian legislation may be classified as follows. "The colonial era until 1960 , post independence legislation 1960-1966 , the military era 1966-1999".

The grant of independence to Nigeria was a milestone in the political history of the country. This period witnessed the consolidation of political gains made during the colonial era. Politicians genuinely focused their lapses in the polity. It achieved for herself a republican status by shaking off the last vestiges of colonial authority. However, despite the violent violation of its provisions, the constitution remained the subsequent administrations (military or otherwise).

The breakdown of law and order which occurred in the period under review would not be attributed to any defect in the Nigerian legal system. Corrupt practices both in the body politic and all aspects of Nigerian life eroded efficiency and progress. There were 8 coups generally five were successful and 3 were unsuccessful.

The president is elected through universal suffrage. He or she is both the chief of state and head of government, heading the Federal Executive Council, or cabinet.

The executive branch is divided into Federal Ministries, each headed by a minister appointed by the president. The president must include at least one member from each of the 36 states in his cabinet. The President's appointments are confirmed by the Senate of Nigeria. In some cases, a federal minister is responsible for more than one ministry (for example, Environment and Housing may be combined), or a minister may be assisted by one or more ministers of State.
Each ministry also has a Permanent Secretary, who is a senior civil servant.

The ministries are responsible for various parastatals (government-owned corporations), such as universities, the National Broadcasting Commission, and the Nigerian National Petroleum Corporation.
However, some parastatals are the responsibility of the Office of the Presidency, such as the Independent National Electoral Commission, the Economic and Financial Crimes Commission and the Federal Civil Service Commission.

The National Assembly of Nigeria has two chambers: the House of Representatives and the Senate. The House of Representatives is presided over by the Speaker of the House of Representatives. It has 360 members, who are elected for four-year terms in single-seat constituencies. The Senate, which has 109 members, is presided over by the President of the Senate. 108 members are elected for four-year terms in 36 three-seat constituencies, which correspond to the country's 36 states. One member is selected in the single-seat constituency of the federal capital.
The judicial branch consists of the Supreme Court of Nigeria, the Court of Appeals, the High Courts, and other trial courts such as the Magistrates', Customary, Sharia and other "specialised" courts. The National Judicial Council serves as an independent executive body, insulating the judiciary from the executive arm of government. The Supreme Court is presided over by the Chief Justice of Nigeria and thirteen associate justices, who are appointed by the President of Nigeria on the recommendation() of the National Judicial Council. These justices are subject to confirmation by the Senate.

Nigeria is made up of 36 states and 1 territory. They are: the Federal Capital Territory, Abia, Adamawa, Akwa Ibom, Anambra, Bauchi, Bayelsa, Benue, Borno, Cross River, Delta, Ebonyi, Edo, Ekiti, Enugu, Gombe, Imo, Jigawa, Kaduna, Kano, Katsina, Kebbi, Kogi, Kwara, Lagos, Nasarawa, Niger, Ogun, Ondo, Osun, Oyo, Plateau, Rivers, Sokoto, Taraba, Yobe, and Zamfara.

Each state is further divided into Local Government Areas (LGAs). There are 774 LGAs in Nigeria. Kano State has the largest number of LGAs at 44, and Bayelsa State has the fewest at 9. The Federal Capital Territory of Abuja has 6 LGAs. LGAs replaced the Districts that were the previous third-tier administrative units under the British government.

The military of Nigeria has played a major role in the country's history, often seizing control of the country and ruling it for long periods of time. Its last period of rule ended in 1999, following the death of the leader of the previous military junta Sani Abacha in 1998.

Active duty personnel in the three Nigerian armed services totals approximately 76,000. The Nigerian Army, which is the largest of the services, has about 60,000 personnel, deployed between two mechanized infantry divisions, one composite division (airborne and amphibious), the Lagos Garrison Command (a division-size unit), and the Abuja-based Brigade of Guards. The Nigerian Navy (7,000) is equipped with frigates, fast attack craft, corvettes, and coastal patrol boats. The Nigerian Air Force (9,000) flies transports, trainers, helicopters, and fighter aircraft; however, most of their vehicles are currently not operational. Recently, Marshal of the Nigerian Air Force, Sadique Abubakar, suggested the purchase of equipment after dumping the non-operational vehicles.

Nigeria currently has better foreign relations with its neighbors, due to its current state of democracy. It is a member of the African Union and sits on that organization's Peace and Security Council. In 1960, Nigeria joined both the United Nations and the Commonwealth of Nations; however, they were briefly suspended between 1995 and 1999.



</doc>
<doc id="21388" url="https://en.wikipedia.org/wiki?curid=21388" title="Economy of Nigeria">
Economy of Nigeria

The economy of Nigeria is a middle-income, mixed economy and emerging market, with expanding manufacturing, financial, service, communications, technology and entertainment sectors. It is ranked as the 27th-largest economy in the world in terms of nominal GDP, and the 24th-largest in terms of purchasing power parity. Nigeria has the largest economy in Africa; its re-emergent manufacturing sector became the largest on the continent in 2013, and it produces a large proportion of goods and services for the West African subcontinent. In addition, the debt-to-GDP ratio is 16.075 percent as of 2019.

Nigerian GDP at purchasing power parity (PPP) has almost tripled from $170 billion in 2000 to $451 billion in 2012, though estimates of the size of the informal sector (which is not included in official figures) put the actual numbers closer to $630 billion. Correspondingly, the GDP per capita doubled from $1400 per person in 2000 to an estimated $2,800 per person in 2012 (again, with the inclusion of the informal sector, it is estimated that GDP per capita hovers around $3,900 per person). (Population increased from 120 million in 2000 to 160 million in 2010). These figures were to be revised upwards by as much as 80% when metrics were to be recalculated subsequent to the rebasing of its economy in April 2014.

Although oil revenues contribute 2/3 of state revenues, oil only contributes about 9% to the GDP. Nigeria produces only about 2.7% of the world's oil supply. Although the petroleum sector is important, as government revenues still heavily rely on this sector, it remains a small part of the country's overall economy.

The largely subsistence agricultural sector has not kept up with rapid population growth, and Nigeria, once a large net exporter of food, now imports some of its food products, though mechanization has led to a resurgence in manufacturing and exporting of food products, and the move towards food sufficiency. In 2006, Nigeria came to an agreement with the Paris Club to buy back the bulk of its debts owed from them for a cash payment of roughly US$12 billion.

According to a Citigroup report published in February 2011, Nigeria will have the highest average GDP growth in the world between 2010 and 2050. Nigeria is one of two countries from Africa among 11 Global Growth Generators countries.

In 2014, Nigeria changed its economic analysis to account for rapidly growing contributors to its GDP, such as telecommunications, banking, and its film industry.

In 2005, Nigeria reached an agreement with the Paris Club of lending nations to eliminate all of its bilateral external debt. Under the agreement, the lenders will forgive most of the debt, and Nigeria will pay off the remainder with a portion of its energy revenues. Moreover, human capital is underdeveloped—Nigeria ranked 151 out of countries in the United Nations Development Index in 2004—and non-energy-related infrastructure is inadequate.

The NEEDS addressed basic deficiencies, such as the lack of freshwater for household use and irrigation, unreliable power supplies, decaying infrastructure, impediments to private enterprise, and corruption. NEEDS was intended to create 7 million new jobs, diversify the economy, boost non-energy exports, increase industrial capacity utilization, and improve agricultural productivity. A related initiative on the state level is the State Economic Empowerment Development Strategy (SEEDS).

A longer-term economic development program is the United Nations (UN)- sponsored National Millennium Goals for Nigeria. Under the program, which covers the years from 2000 to 2015, Nigeria is committed to achieving a wide range of ambitious objectives involving poverty reduction, education, gender equality, health, the environment, and international development cooperation. In an update released in 2004, the UN found that Nigeria was making progress toward achieving several goals but was falling short on others.

Specifically, Nigeria had advanced efforts to provide universal primary education, protect the environment.

A prerequisite for achieving many of these worthwhile objectives is curtailing endemic corruption, which stymies development and taints Nigeria's business environment. President Olusegun Obasanjo's campaign against corruption, which includes the arrest of officials accused of misdeeds and recovering stolen funds, has won praise from the World Bank. In September 2005, Nigeria, with the assistance of the World Bank, began to recover US$458 million of illicit funds that had been deposited in Swiss banks by the late military dictator Sani Abacha, who ruled Nigeria from 1993 to 1998. However, while broad-based progress has been slow, these efforts have begun to become evident in international surveys of corruption. Nigeria's ranking has consistently improved since 2001 ranking 147 out of 180 countries in Transparency International's 2007 Corruption Perceptions Index.

The Nigerian economy suffers from an ongoing supply crisis in the power sector. Despite a rapidly growing economy, some of the world's largest deposits of coal, oil and gas and the country's status as Africa's largest oil producer, power supply difficulties are frequently experienced by residents.

Two thirds of Nigerians expect living conditions to improve in the coming decades.

This is a chart of trend of gross domestic product of Nigeria at market prices estimated by the International Monetary Fund with figures in USD billions. Figures before 2000 are backwards projections from the 2000–2012 numbers, based on historical growth rates, and should be replaced when data becomes available. The figure for 2014 is derived from a rebasing of economical activity earlier in the year.
NOTES:

The US dollar exchange rate is an estimated average of the official rate throughout a year, and does not reflect the parallel market rate at which the general population accesses foreign exchange. This rate ranged from a high of 520 in March 2017 to a low of 350 in August 2017, due to a scarcity of forex (oil earnings had dropped by half), and to speculative activity as alleged by the Central Bank. All the while the official rate was pegged at 360.

Per capita income (as % of USA) is calculated using data from estimates in the PPP link above, and from census estimates, based on growth rates between census periods. For instance 2017 GDPs were 1,125 Billion (Nigeria) vs. 19,417 Billion (USA) and populations were estimated at 320 million vs 190 million. The ratio is therefore (1125/19417) / (190/320), which roughly comes to 0.0975. These are estimates and are intended to get a feel for the relative wealth and standard of living, as well as the market potential of its middle class.

This is a chart of trend of the global ranking of the Nigerian economy, in comparison with other countries of the world, derived from the historical List of countries by GDP (PPP).
This chart shows the variance in the parallel exchange rate at which the Dollar can be obtained with Naira in Lagos, with "Best" being cheaper for a Nigerian (i.e. stronger Naira).

For purchasing power parity comparisons, the US dollar is exchanged at 1 USD to 314.27 Nigerian naira (as of 2017).

Current GDP per capita of Nigeria expanded 132% in the sixties reaching a peak growth of 283% in the seventies. But this proved unsustainable and it consequently shrank by 66% in the 1980s. In the 1990s, diversification initiatives finally took effect and decadal growth was restored to 10%. Although GDP on a PPP basis did not increase until the 2000s.

In 2012, the GDP was composed of the following sectors: agriculture: 40%; services: 30%; manufacturing: 15%; oil: 14%. By 2015, the GDP was composed of the following sectors: agriculture: 18%; services: 55%; manufacturing: 16%; oil: 8%

In 2005 Nigeria's inflation rate was an estimated 15.6%. Nigeria's goal under the National Economic Empowerment Development Strategy (NEEDS) program is to reduce inflation to the single digits. By 2015, Nigeria's inflation stood at 9%. In 2005, the federal government had expenditures of US$13.54 billion but revenues of only US$12.86 billion, resulting in a budget deficit of 5%. By 2012, expenditures stood at $31.61 billion, while revenues was $54.48 billion.

Nigeria ranks sixth worldwide and first in Africa in farm output. The sector accounts for about 18% of GDP and almost one-third of employment. Nigeria has 19 million head of cattle, the largest in Africa. Though Nigeria is no longer a major exporter, due to local consumer boom, it is still a major producer of many agricultural products, including: cocoa, groundnuts (peanuts), rubber, and palm oil. Cocoa production, mostly from obsolete varieties and overage trees has increased from around 180,000 tons annually to 350,000 tons.

Major agricultural products include cassava (tapioca), corn, cocoa, millet, palm oil, peanuts, rice, rubber, sorghum, and yams. In 2003, livestock production, in order of metric tonnage, featured eggs, milk, beef and veal, poultry, and pork, respectively. In the same year, the total fishing catch was 505.8 metric tons. Roundwood removals totaled slightly less than 70 million cubic meters, and sawnwood production was estimated at 2 million cubic meters. The agricultural sector suffers from extremely low productivity, reflecting reliance on antiquated methods. Agriculture has failed to keep pace with Nigeria's rapid population growth, so that the country, which once exported food, now imports a significant amount of food to sustain itself. However, efforts are being made towards making the country food sufficient again.

Nigeria's proven oil reserves are estimated to be ; natural gas reserves are well over . Nigeria is a member of the Organization of Petroleum Exporting Countries (OPEC). The types of crude oil exported by Nigeria are Bonny light oil, Forcados crude oil, Qua Ibo crude oil and Brass River crude oil. Poor corporate relations with indigenous communities, vandalism of oil infrastructure, severe ecological damage, and personal security problems throughout the Niger Delta oil-producing region continue to plague Nigeria's oil sector.

Efforts are underway to reverse these troubles. A new entity, the Niger Delta Development Commission (NDDC), has been created to help catalyze economic and social development in the region. The U.S. remains Nigeria's largest buyer of crude oil, accounting for 40% of the country's total oil exports; Nigeria provides about 10% of overall U.S. oil imports and ranks as the fifth-largest source for U.S. imported oil.

The United Kingdom is Nigeria's largest trading partner followed by the United States. Although the trade balance overwhelmingly favors Nigeria, thanks to oil exports, a large portion of U.S. exports to Nigeria is believed to enter the country outside of the Nigerian government's official statistics, due to importers seeking to avoid Nigeria's tariffs. To counter smuggling and under-invoicing by importers, in May 2001, the Nigerian government instituted a full inspection program for all imports, and enforcement has been sustained.

On the whole, Nigerian high tariffs and non-tariff barriers are gradually being reduced, but much progress remains to be made. The government also has been encouraging the expansion of foreign investment, although the country's investment climate remains daunting to all but the most determined. The stock of U.S. investment is nearly $7 billion, mostly in the energy sector. Exxon Mobil and Chevron are the two largest U.S. corporations in offshore oil and gas production. Significant exports of liquefied natural gas started in late 1999 and are slated to expand as Nigeria seeks to eliminate gas flaring by 2008.

The pump price of P.M.S. as at 14 May 2020 stands at around ₦123.500 at fueling stations across Nigeria. An initial increase in the price of petrol (Premium Motor Spirit) from around ₦65 to ₦140 triggered by the removal of fuel subsidies on 1 January 2012, triggered a total strike and massive protests across the country. Then President Goodluck Ebele Jonathan later reached an agreement with the Nigerian Labour Congress and reduced the pump price to 97 naira. The pump price was further reduced by 10 to 87 naira in the run-up to the 2015 general elections. However, after the elections of Muhammadu Buhari, the fuel subsidies was removed again, and the pump price increased again, despite the fall in oil price.
Since the fall in oil prices in 2015 and 2016, the government exchange rate policy has limited devaluation of the naira due to inflation concerns by the President Muhammadu Buhari.

Nigeria ranks 27th worldwide and first in Africa in services' output.

Since undergoing severe distress in the mid-1990s, Nigeria's banking sector has witnessed significant growth over the last few years as new banks enter the financial market.

Private sector-led economic growth remains stymied by the high cost of doing business in Nigeria, including the need to duplicate essential infrastructure, the lack of effective due process, and nontransparent economic decision making, especially in government contracting. While corrupt practices are endemic, they are generally less flagrant than during military rule, and there are signs of improvement. In 2013, The World Bank in 2013 stated that since 1999, the Nigerian Stock Exchange has enjoyed strong performance, although equity as a means to foster corporate growth is being more utilized by Nigeria's private sector.

Principal ports are at Lagos (Apapa and Tin Can Island), Port Harcourt (Onne), and Calabar.

Extensive road repairs and new construction activities are gradually being implemented as state governments, in particular, spend their portions of enhanced government revenue allocations.

Five of Nigeria's airports (Lagos, Kano, Port Harcourt, Enugu and Abuja) currently fly to international destinations. The Nigerian Airforce began a new airline called United Nigeria, with a Boeing 737-500 in 2013. There are several domestic private Nigerian carriers, and air service among Nigeria's cities is generally dependable.

Electricity – production:
18.89 billion kWh (2009)

Electricity – production by source:
"fossil fuel:"
61.69%
"hydro:"
38.31%
"nuclear:"
0%
"other:"
<.1% (1998)

Electricity - consumption:
17.66 billion kWh (2009)

Electricity - exports:
40 million kWh (2003)

Electricity - imports:
0 kWh (1998)

Oil - production: 

Oil - consumption:

A major source of foreign exchange earnings for Nigeria are remittances sent home by Nigerians living abroad. In 2014, 17.5 million Nigerians lived in foreign countries, with the UK and the USA having more than 2 million Nigerians each.

According to the International Organization for Migration, Nigeria witnessed a dramatic increase in remittances sent home from overseas Nigerians, going from USD $2.3 billion in 2004 to $17.9 billion in 2007, representing 6.7% of GDP. The United States accounts for the largest portion of official remittances, followed by the United Kingdom, Italy, Canada, Spain and France. On the African continent, Egypt, Equatorial Guinea, Chad, Libya and South Africa are important source countries of remittance flows to Nigeria, while China is the biggest remittance-sending country in Asia.

In 2015, Nigeria had a labour force of 74 million. In 2003, the unemployment rate was 10.8% overall; by 2015, unemployment stood at 6.4%.

Since 1999, the Nigerian Labor Congress (NLC) a union umbrella organization, has called six general strikes to protest domestic fuel price increases. However, in March 2005 the government introduced legislation ending the NLC's monopoly over union organizing. In December 2005, the Nigerian Labour Congress (NLC) was lobbying for an increase in the minimum wage for federal workers. The existing minimum wage, which was introduced six years earlier but has not been adjusted since, has been whittled away by inflation to only US$42.80 per month.

According to the International Organization for Migration, the number of immigrants residing in Nigeria has more than doubled in recent decades – from 477,135 in 1991 to 971,450 in 2005. The majority of immigrants in Nigeria (74%) are from neighbouring Economic Community of West African States (ECOWAS), and that this number has increased considerably over the last decade, from 63% in 2001 to 97% in 2005.

The Human Development Index (HDI) shows in 2012 that Nigeria is ranked 156 with the value of 0.459 among 187 countries. As of 2015, Nigeria's HDI is ranked 152nd at 0.514. The comparative value for Sub-Saharan Africa is 0.475, 0.910 for the US, and 0.694 for the world average.

The value for the education index is 0.457, compared to the average in the US of 0.939. The expected years of schooling in Nigeria is 9.0 (16.00 in the US), while the mean years of schooling for adults over 25 years is 5.2 years (12.4 years in the US). Additionally, Nigeria is also facing a relatively high inequality, worsening the problem regarding the formation of human capital.

In the light of highly expansionary public sector fiscal policies in 2001, the government sought ways to head off higher inflation, leading to the implementation of stronger monetary policies by the Central Bank of Nigeria (CBN) and underspending of budgeted amounts. As a result of the CBN's efforts, the official exchange rate for the Naira had stabilized at about 112 Naira to the dollar. The combination of CBN's efforts to prop up the value of the Naira and excess liquidity resulting from government spending led the currency to be discounted by around 20% on the parallel (non-official) market.

A key condition of the Stand-by Arrangement has been closure of the gap between the official and parallel market exchange rates. The Inter Bank Foreign Exchange Market (IFEM) is closely tied to the official rate. Under IFEM, banks, oil companies, and the CBN can buy or sell their foreign exchange at government-influenced rates. Much of the informal economy, however, can only access foreign exchange through the parallel market. Companies can hold domiciliary accounts in private banks, and account holders have unfettered use of the funds.

Expanded government spending also has led to upward pressure on consumer prices. Inflation which had almost disappeared in April 2000 reached 14.5% by the end of the year and 18.7% in August 2001. In 2000, high oil prices resulted in government revenue of over $16 billion, about double the 1999 level. State and local governments demanded access to this "windfall" revenue, creating a tug-of-war between the federal government, which sought to control spending, and state governments desiring augmented budgets, preventing the government from making provision for periods of lower oil prices.

In 2016, the black market exchange rate of the Naira was about 60% above the official rate. The central bank releases about $200 million each week at the official exchange rate. However, some companies cite that budgets now include a 30% "premium" to be paid to central bank officials to get dollars.

The Obasanjo government supported "private-sector" led, "market oriented" economic growth and began extensive economic reform efforts. Although the government's anti-corruption campaign was left wanting, progress in injecting transparency and accountability into economic decision-making was notable. The dual exchange rate mechanism formally abolished in the 1999 budget remains in place in actuality.

During 2000 the government's privatization program showed signs of life and real promise with successful turnover to the private sector of state-owned banks, fuel distribution companies, and cement plants. However, the privatization process has slowed somewhat as the government confronts key parastatals such as the state telephone company NITEL and Nigerian Airways. The successful auction of GSM telecommunications licenses in January 2001 has encouraged investment in this vital sector.

Although the government has been stymied so far in its desire to deregulate downstream petroleum prices, state refineries, almost paralyzed in 2000, are producing at much higher capacities. By August 2001, gasoline lines disappeared throughout much of the country. The government still intends to pursue deregulation despite significant internal opposition, particularly from the Nigeria Labour Congress. To meet market demand the government incurs large losses importing gasoline to sell at subsidized prices.

Nigeria's foreign economic relations revolve around its role in supplying the world economy with oil and natural gas, even as the country seeks to diversify its exports, harmonize tariffs in line with a potential customs union sought by the Economic Community of West African States (ECOWAS), and encourage inflows of foreign portfolio and direct investment. In October 2005, Nigeria implemented the ECOWAS common external tariff, which reduced the number of tariff bands.

Prior to this revision, tariffs constituted Nigeria's second largest source of revenue after oil exports. In 2005 Nigeria achieved a major breakthrough when it reached an agreement with the Paris Club to eliminate its bilateral debt through a combination of write-downs and buybacks. Nigeria joined the Organization of the Petroleum Exporting Countries in July 1971 and the World Trade Organization in January 1995.

If the global transition to renewable energy is completed and international demand for Nigeria's petroleum resources ceases, Nigeria will be significantly weakened. It is ranked 149 out of 156 countries in the index of Geopolitical Gains and Losses after energy transition (GeGaLo).

In 2017, Nigeria imported about US$34.2 billion of goods. In 2017 the leading sources of imports were China (28%), the Belgium-Luxembourg (8.9%), the Netherlands (8.3%), South Korea (6.4%), the United States (6.0%) and the Republic of India (4.6%). Principal imports were manufactured goods, machinery and transport equipment, chemicals, and food and live animals.

In 2017, Nigeria exported about US$46.68 billion of goods. In 2017, the leading destinations for exports were India (18%), the United States (14%), Spain (9.7%), France (6.0%) and the Netherlands (4.9%). In 2017 oil accounted for 83% of merchandise exports. Natural rubber and cocoa are the country’s major agricultural exports.

In 2005, Nigeria posted a US$26 billion trade surplus, corresponding to almost 20% of gross domestic product. In 2005, Nigeria achieved a positive current account balance of US$9.6 billion. The Nigerian currency is the naira (NGN). As of June 2006, the exchange rate was about US$1=NGN128.4. As of June 2019, it stands at US$1 =NGN357. In recent years, Nigeria has expanded its trade relations with other developing countries such as India. Nigeria is the largest African crude oil supplier to India – it annually exports to India valued at US$10 billion annually.

India is the largest purchaser of Nigeria's oil which fulfills 20% to 25% of India's domestic oil demand. Indian oil companies are also involved in oil drilling operations in Nigeria and have plans to set up refineries there.

The trade volume between Nigeria and the United Kingdom rose by 35% from USD6.3 billion in 2010 to USD8.5 billion in 2011.

In 2012, Nigeria's external debt was an estimated $5.9 billion and N5.6 trillion domestic - putting total debt at $44 billion.

In April 2006, Nigeria became the first African country to fully pay off its debt owed to the Paris Club. This was structured as a debt write off of approximately $18 billion and a cash payment of approximately $12 billion.

In 2012, Nigeria received a net inflow of US$85.73 billion of foreign direct investment (FDI), much of which came from Nigerians in the diaspora. Most FDI is directed toward the energy and banking sectors. Any public designed to encourage inflow of foreign capital is capable of generating employment opportunities within the domestic economy. The Nigerian Enterprises Promotion (NEP) Decree of 1972 (revised in 1977) was intended to reduce foreign investment in the Nigerian economy.

The stock market capitalisation of listed companies in Nigeria was valued at $97.75 billion on 15 February 2008 by the Nigerian Stock Exchange.

The Swiss foreign ministry says it has done all it can to ensure that funds stolen by the late Nigerian dictator Sani Abacha were used properly in his homeland. The authorities were responding to allegations that $200 million (SFr240 million) of $700 million handed back by the Swiss Banks to Nigeria had been misappropriated.

Household income or consumption by percentage share:
"lowest 10%:"
2.6%
"highest 10%:"
35.8% (1996–97)

Industries:
crude oil, coal, tin, columbite, palm oil, peanuts, cotton, rubber, wood, hides and skins, textiles, cement and other construction materials, food products, footwear, chemicals, fertilizer, printing, ceramics, steel, small commercial ship construction and repair

Industrial production growth rate:
4.7% (2010 est.)

Agriculture – products:
cocoa, peanuts, palm oil, maize, rice, sorghum, millet, cassava (tapioca), yams, rubber; cattle, sheep, goats, pigs; timber; fish

Exchange rates:
Naira (NGN) per US$1 – 358 (2019), 157.3 (2012) 149.5 (2009), 120 (2006), 128 (2005), 132.89 (2004), 129.22 (2003), 120.58 (2002), 111.23 (2001)






</doc>
<doc id="21389" url="https://en.wikipedia.org/wiki?curid=21389" title="Telecommunications in Nigeria">
Telecommunications in Nigeria

Telecommunications in Nigeria include radio, television, fixed and mobile telephones, and the Internet.

Radio stations:
Radios:
23.5 million (1997).

Television stations: nearly 70 federal government-owned national and regional TV stations; all 36 states operate TV stations; several private TV stations operational; cable and satellite TV subscription services are available (2007).

Television sets:
56.9 million (2007).

Nigeria's media scene is one of the most vibrant in Africa. Newspapers, television and radio remains the most important medium of mass communication and information, with Social media rapidly emerging as the next big medium. International broadcasters, including the BBC, are popular. TV viewing is concentrated in urban areas.

The largest broadcasting companies are the government-owned Federal Radio Corporation of Nigeria (FRCN) and the Nigerian Television Authority (NTA). The NTA has two television services, one is NTA 1, which is distributed among NTA's six television zones.T7he other is NTA 2, which is distributed nationwide and is funded mostly by advertising. NITEL owns a majority of the transmitters that broadcast FRCN and NTA programming.

Each state also has a broadcasting company that broadcasts one or two locally operated terrestrial stations. This means that there are about 50 government owned, but partly independent television stations. Private players in the Nigerian television scene include: Silverbird Television (STV), Africa Independent Television (AIT), Channels Television, Superscreen Television, and several others. Most of their programming is aimed for the African and global markets and is broadcast globally from Lagos, Abuja, and Port Harcourt centres with affiliated TV stations in other cities in Nigeria and several African countries. African Independent Television (AIT) is a high-profile satellite television station broadcasting globally from its Lagos and Abuja centres. Other direct satellite television stations with international reach operating in Nigeria are Murhi International Television, ON Television, Galaxy TV, TV Continental, etc. all in Lagos.

There is general access to cable television like DSTV, HiTV, DaarSat, StarTimes and Infinity TV and other cable TVs in Nigeria.

Although the government censors the electronic media through the National Broadcasting Commission (NBC), which is responsible for monitoring and regulating broadcast media, there's no established proof towards Government's control of the media. Radio stations remain susceptible to attacks by political groups. For example, in January 2012 some media figures alleged the NBC warned radio stations not to broadcast stories about fuel subsidy protests.
Libel is a civil offense and requires defendants to prove the truth of opinion or value judgment contained in news reports or commentaries, or pay penalties. However, the media is allowed to broadcast "fair comment on matters of public interest". Penalties for defamation of character include two years' imprisonment and possible fines.

The law requires local television stations to limit programming from other countries to 40 percent and restricts foreign content of satellite broadcasting to 20 percent. The NBC's 2004 prohibition of live broadcasts of foreign news and programs remains in force, but does not apply to international cable or satellite services. The Voice of America is not allowed to broadcast programs through local affiliate stations.

On numerous occasions in the past, especially, during military regime, security forces and police have arrested and detained journalists who criticized the government. Reporting on matters such as political corruption and security issues are particularly sensitive. Politicians and political parties harass journalists perceived as reporting on them or their interests in a negative manner. During local and state elections, journalists have been intimidated for covering certain election-related events. The militant group Boko Haram threatens media outlets and has killed members of the press. On 20 January 2012, unknown gunmen killed Channels TV reporter Enenche Akogwu while he was reporting on the Boko Haram attacks and bombings in Kano that day. Journalists practice self-censorship.

Calling code: +234

International call prefix: 009

Connected lines:

Active lines:

Installed capacity:

Teledensity: 

Telephone system: further expansion and modernization of the fixed-line telephone network is needed; network quality remains a problem; the addition of a second fixed-line provider in 2002 resulted in faster growth but subscribership remains only about 1 per 100 persons; mobile-cellular services growing rapidly, in part responding to the shortcomings of the fixed-line network; multiple cellular providers operate nationally with a subscribership approaching 60 per 100 persons (2010);

Satellite earth stations: 3 Intelsat (2 Atlantic Ocean and 1 Indian Ocean) (2010);

Submarine cables: 

Deregulation of the mobile phone market has led to the introduction of Global System for Mobile Communication (GSM) network providers operating on the 900/1800 MHz spectrum, MTN Nigeria, Airtel Nigeria, Globacom, and 9mobile. Use of cell-phones has soared, and has mostly replaced the unreliable fixed line services of Nigerian Telecommunications Limited (NITEL).

With the expiration of the exclusivity period of the main GSM network providers, Nigeria's telecom regulator, the Nigerian Communications Commission (NCC), introduced the Unified Licensing Regime. It was hoped that telcoms with unified licences would be able to provide fixed and mobile telephony and Internet access as well as any other communications service they choose to offer. In March 2011 the NCC started registering SIM cards. The exercise was expected to last until 28 September 2011.

In 2015 the NTC fined MTN Nigeria a record $5.2 billion for issuing 5.2 million unregistered and pre-registered subscriber Identification Module Cards (SIMs). In 2017 the NTC sett up a 12-member task force in response to renewed proliferation of Unregistered and pre-registered SIM cards. The unregistered cards are considered a threat to Nigerian national security.

After a decade of failed privatization attempts, the incumbent national telcom NITEL and its mobile arm have been sold to NATCOM and now rebranded as NTEL.

Top-level domain: .ng

Internet users: 

Fixed broadband: 15,311 subscriptions, 136th in the world; less than 0.05% of the population, 185th in the world (2012).

Wireless broadband: 17.3 million subscriptions, 18th in the world; 10.2% of the population, 91st in the world (2012).

Internet hosts: 

IPv4: 1.0 million addresses allocated, 75th in the world, less than 0.05% of the world total, 5.9 addresses per 1000 people (2012).

Internet service providers:

There is satellite Internet access throughout the country. In most towns there are many privately owned and operated Internet cafes.

A new dimension to Internet connectivity has been introduced with millions of people accessing the Internet on their WAP-enabled mobile phones, smartphones and on their PCs using their phones as a modem. This is largely due to the introduction of GPRS (General Packet Radio Service) and EDGE (Enhanced Data Rates for GSM Evolution) connectivity by the GSM operators. All existing GSM networks presently offer GPRS services and have introduced 3G/UMTS.

Listed by the OpenNet Initiative as no evidence of Internet filtering in all four areas for which they test (political, social, conflict/security, and Internet tools) in October 2009.

There are few government restrictions on access to the Internet or credible reports the government monitors e-mail or Internet chat rooms. Although the constitution and law provide for freedom of speech, including for members of the press, the government sometimes restricts these rights in practice. Libel is a civil offense and requires defendants to prove the truth of opinion or value judgment contained in news reports or commentaries. Penalties include two years' imprisonment and possible fines. Militant groups such as Boko Haram threaten, attack, and kill journalists in connection with their reporting of the sect's activities. Journalists practice self-censorship.

Reporting on political corruption and security issues has proved to be particularly sensitive. On 24 October 2012 police in Bauchi State arraigned civil servant Abbas Ahmed Faggo before a court for allegedly defaming the character of Governor Isa Yuguda after he posted messages on his Facebook account accusing the governor of spending public funds on his son's wedding. On 4 November, the court discharged Faggo, but media reported the state government fired him later that month.

During 2012 several Internet news sites critical of the government experienced server problems, which site owners attributed to government interference. Such disruptions usually lasted a few hours.

In 2008 two journalists were arrested for publishing online articles and photos critical of the government.




</doc>
<doc id="21390" url="https://en.wikipedia.org/wiki?curid=21390" title="Transport in Nigeria">
Transport in Nigeria

Decaying infrastructure is one of the deficiencies that Nigeria's National Economic Empowerment Development Strategy (NEEDS) seeks to address. The government has begun to repair the country's poorly maintained road network. Because Nigeria's railways are in a perilous condition, the government is trying to rectify the situation by privatizing the Nigerian Railway Corporation. Similarly, the government is pursuing a strategy of partial port privatization by granting concessions to private port operators so that they can improve the quality of port facilities and operations.

Railways in Nigeria are operated by the Nigerian Railway Corporation. Nigeria's railway system has 3,984 kilometers of track, most of which is Cape gauge. The country has two major rail lines: a western line that connects Lagos to Nguru, and an eastern line that connects Port Harcourt to Maiduguri. The Lagos–Kano Standard Gauge Railway is being built in segments to replace the western Cape gauge line. Several metro systems are under construction.

Nigeria has the largest road network in West Africa and the second largest south of the Sahara, with roughly 108,000 km of surfaced roads in 1990.

However they are poorly maintained and are often cited as a cause for the country's high rate of road fatalities. In 2004 Nigeria's Federal Roads Maintenance Agency (FERMA) began to patch the 32,000 kilometre federal roads network, and in 2005 FERMA initiated a more substantial rehabilitation. The rainy season and poor equipment pose challenges to road maintenance.
These are the portions that are already modernized at motorway and expressway standard:
Figures from CIA World Factbook (1999):
<br>"Total:"
194,394 km
<br>"paved:"
60,068 km (including 1,194 km of expressways)
<br>"unpaved:"
134,326 km (1998 est.)
<br>"note:"
Some paved roads have lost their asphalt surface and are in very poor condition or have reverted to being gravel roads. Some of the road system is barely usable, especially in high rainfall areas of the south.

Nigeria's strategic location and size results in four routes of the Trans-African Highway network using its national road system:

Nigeria has 8,600 km of inland waterways. The longest are the Niger River and its tributary, the Benue River but the most used, especially by larger powered boats and for commerce, are in the Niger Delta and all along the coast from Lagos Lagoon to Cross River.

In 2004 Nigeria had 105 kilometers of pipelines for condensates, 1,896 kilometers for natural gas, 3,638 kilometers for oil, and 3,626 kilometers for refined products. Various pipeline projects are planned to expand the domestic distribution of natural gas and to export natural gas to Benin, Ghana, Togo through the West African Gas Pipeline, and, potentially, even to Algeria (where Mediterranean export terminals are located) by proposed Trans-Saharan gas pipeline. Energy pipelines are subject to sabotage by militant groups or siphoning by thieves.

crude oil 2,042 km; petroleum products 3,000 km; natural gas 500 km

The Nigerian Ports Authority (NPA) is responsible for managing Nigeria's ports, some of which have fallen behind international standards in terms of the quality of facilities and operational efficiency. Recognizing that the government lacks the funding and expertise to modernize facilities and run the ports efficiently, the NPA is pursuing partial port privatization by means of granting concessions to private port operators. Under the terms of concession agreements, the government would transfer operating rights to private companies for a finite number of years without forgoing ownership of the port land. Nigeria's principal container port is the port of Lagos, which handles about 5.75 million tons of cargo each year. The port, which consists of separate facilities at Apapa and Tin Can Island, has a rail connection to points inland. Port Harcourt, a transshipment port located 66 kilometers from the Gulf of Guinea along the Bonny River in the Niger Delta, handles about 815,000 tons of cargo each year and also has a railway connection. Both ports are not only responsible for Nigeria's seaborne trade but also serve inland countries such as Niger and Chad. A new port is under construction at Onne about 25 kilometers south of Port Harcourt. Relatively modern and efficient terminals managed by multinational oil companies handle most oil and gas exports.


The Lekki Port is under construction.


The Benin river port on the Benin river in Benin, Edo state; and Makurdi river port on the Benue River in Benue State are under construction.

The Nigerian Merchant Navy is not a legally recognized body, but the senior officers are represented by the Merchant Navy Officers' and Water Transport Senior Staff Association. 
The maritime industry is regulated by the Nigerian Maritime Administration and Safety Agency (NIMASA), which is responsible for regulations related to Nigerian shipping, maritime labor and coastal waters. The agency also undertakes inspections and provides search and rescue services.

"total:"
40 ships ( or over) totaling /
<br>"ships by type:"
bulk carrier 1, cargo ship 12, chemical tanker 4, petroleum tanker 22, specialized tanker 1 (1999 est.)

Nigeria's principal airports are Murtala Muhammed International Airport in Lagos and Nnamdi Azikiwe International Airport in Abuja. Three other international airports are Mallam Aminu Kano International Airport in Kano, Akanu Ibiam International Airport in Enugu and Port Harcourt International Airport in Port Harcourt. Overall, Nigeria's airports, whether international or regional, suffer from a poor reputation for operational efficiency and safety. Private domestic air carriers began to win business at the expense of Nigeria Airways, the former government-owned national airline which was declared bankrupt in 2004. The former national flag carrier, Air Nigeria, suspended operations in 2012. Arik Air is now a large airline serving Nigeria and has transported over 10 million passengers.

<br>"total:"
38
<br>"over 3,047 m:"
9
<br>"2,438 to 3,047 m:"
11
<br>"1,524 to 2,437 m:"
10
<br>"914 to 1,523 m:"
5
<br>"under 914 m:"
3 (2010 est.)

<br>"total:"
16
<br>"over 3,047 m:"
1
<br>"1,524 to 2,437 m:"
2
<br>"914 to 1,523 m:"
11
<br>"under 914 m:"
2 (2010 est.)

1 (1999 est.)
2 (2006) There are at least 15 heliports to date including those in the oil sector



</doc>
<doc id="21391" url="https://en.wikipedia.org/wiki?curid=21391" title="Nigerian Armed Forces">
Nigerian Armed Forces

The Nigerian Armed Forces are the armed forces of the Federal Republic of Nigeria. Its origins lie in the elements of the Royal West African Frontier Force that became Nigerian when independence was granted in 1960. In 1956 the Nigeria Regiment of the Royal West African Frontier Force (RWAFF) was renamed the Nigerian Military Forces, RWAFF, and in April 1958 the colonial government of Nigeria took over from the British War Office control of the Nigerian Military Forces.

Since its creation the Nigerian military has fought in a civil war – the conflict with Biafra in 1967–70 – and sent peacekeeping forces abroad both with the United Nations and as the backbone of the Economic Community of West African States (ECOWAS) Cease-fire Monitoring Group (ECOMOG) in Liberia and Sierra Leone. It has also seized power twice at home (1966 & 1983).

In the aftermath of the civil war, the much expanded size of the military, around 250,000 in 1977, consumed a large part of Nigeria’s resources under military rule for little productive return. The great expansion of the military during the civil war further entrenched the existing military hold on Nigerian society carried over from the first military regime. In doing so, it played an appreciable part in reinforcing the military’s nearly first-among-equals status within Nigerian society, and the linked decline in military effectiveness. Olusegun Obasanjo, who by 1999 had become President, bemoaned the fact in his inaugural address that year: ‘... Professionalism has been lost... my heart bleeds to see the degradation in the proficiency of the military.’

Training establishments in Nigeria include the prestigious officer entry Nigerian Defence Academy at Kaduna, the Armed Forces Command and Staff College, Jaji, and the National War College at Abuja. The U.S. commercial military contractor Military Professional Resources Inc. has been involved from around 1999–2000 in advising on civil-military relations for the armed forces.

The roles of a country’s armed forces are entrenched in her Constitution. The defence of the territorial integrity and other core interests of the nation form the major substance of such roles. Section 217-220 of the 1999 Constitution of Nigeria addresses the Nigerian Armed Forces:

The Nigerian Army (NA) is the land branch of the Nigerian Armed Forces and the largest among the armed forces. Major formations include the 1st Division, the 2nd Division, the 3rd Armoured Division, 81st Division, 82nd Division, and newly formed 8th, 7th and 6th, Divisions.

The Nigerian Navy (NN) is the sea branch of the Nigerian Armed Forces. The Nigerian Navy command structure today consists of the Naval Headquarters in Abuja, three operational commands with headquarters in Lagos, Calabar, and Bayelsa. Training command's headquarters are located in Lagos, the commercial capital of Nigeria, but with training facilities spread all over Nigeria. There are five operational bases, five forward operational bases (with two more soon to come on stream), two dockyards located in Lagos and Port Harcourt and two fleets based in Lagos and Calabar.

The Nigerian Air Force was formally established in January 1964 with technical assistance from West Germany. The air force started life as a transport unit with aircrew being trained in Canada, Ethiopia and Pakistan. The air force did not get a combat capability until a number of MiG-17 aircraft were presented by the Soviet Union in 1966.

In 2007 the Air Force had a strength of 10,000. It flies transport, trainer, helicopter, and fighter aircraft.
By 2019, the number of the Air Force 
personnel has increased to 15,000.

The Air Force sponsors the Air Force Military School, Jos, Nigeria and the Air Force Institute of Technology.

Nigeria also has pursued a policy of developing domestic training and military production capabilities. Nigeria has continued a strict policy of diversification in her military procurement from various countries.

There is a Joint Task Force in the Niger Delta region designated "Restore Hope." This is an inter service Operational Team comprising members of the Army, the Navy, and the Air Force to combat terrorism in the Niger Delta. JTF HQ is located at Yenagoa.

In December 1983, the new Major General Muhammadu Buhari regime announced that Nigeria could no longer afford an activist anti-colonial role in Africa. Anglophone ECOWAS members established ECOMOG, dominated by the Nigerian Army, in 1990 to intervene in the civil war in Liberia. The Army has demonstrated its capability to mobilize, deploy, and sustain brigade-sized forces in support of peacekeeping operations in Liberia. Smaller army forces have been previously sent on UN and ECOWAS deployments in the former Yugoslavia, Guinea-Bissau, and Sierra Leone. This doctrine of African military intervention by Nigeria is sometimes called Pax Nigeriana.

That policy statement did not deter Nigeria under Generals Ibrahim Babangida in 1990 and Sani Abacha in 1997 from sending ECOMOG peacekeeping forces under the auspices of ECOWAS into Liberia and later Sierra Leone when civil wars broke out in those countries. President Olusegun Obasanjo in August 2003 committed Nigerian troops once again into Liberia, at the urging of the United States, to provide an interim presence until the United Nations Mission in Liberia (UNMIL) arrived. Charles Taylor was subsequently eased out of power and exiled to Nigeria.

In October 2004, Nigerian troops again deployed into Darfur, Sudan to spearhead an African Union force to stop the genocide in Darfur. Nigeria has contributed more than 20,000 troops/police to various UN missions since 1960. The Nigeria Police Force and troops have participated in:


Nigerian officers have served as Chiefs of Defence in other countries, with Brigadier General Maxwell Khobe serving as Sierra Leone Chief of Staff in 1998–1999, and Nigerian officers acting as Command Officer-in-Charge of the Armed Forces of Liberia from at least 2007.



Nigerian Defence Staff

Nigerian Army

Nigerian Navy

Nigerian Air Force

</doc>
<doc id="21392" url="https://en.wikipedia.org/wiki?curid=21392" title="Foreign relations of Nigeria">
Foreign relations of Nigeria

Since independence, with Jaja Wachuku as the first Minister for Foreign Affairs and Commonwealth Relations, later called External Affairs, Nigerian foreign policy has been characterised by a focus on Africa as a regional power and by attachment to several fundamental principles: African unity and independence; capability to exercise hegemonic influence in the region: peaceful settlement of disputes; non-alignment and non-intentional interference in the internal affairs of other nations; and regional economic cooperation and development. In carrying out these principles, Nigeria participates in the African Union, the Economic Community of West African States (ECOWAS), the Non-Aligned Movement, the Commonwealth of Nations, and the United Nations.

Upon gaining independence in 1960, Nigeria quickly committed itself to improving the lives of the people of the country and harnessing the resources that remain vital to the economy of the country and her neighbours. By observing at what benefits and appropriate for the country, Nigeria became one of the founding members of the Organisation for African Unity (OAU), which later became the African Union. The Organisation for African Unity checks political stability of any African countries and encourages them to be holding regional meetings for the union. Nigeria backed the African National Congress (ANC) by taking a committed tough line with regard to the South African government and their military actions in southern Africa. Nigeria and Organisation for African Unity (OAU, now the African Union), has tremendous influence in West Africa nations and Africa on the whole. Nigeria has additionally founded regional cooperative efforts in West Africa, functioning as standard-bearer for ECOWAS and ECOMOG, economic and military organisations, respectively.

Similarly, when civil war broke out in Angola after the country gained independence from Portugal in 1975, Nigeria mobilised its diplomatic influence in Africa in support of the Popular Movement for the Liberation of Angola (MPLA). That support helped tip the balance in their favour, which led to OAU recognition of the MPLA over the National Union for the Total Independence of Angola.

Nigeria extended diplomatic support to another cause, Sam Nujoma's Southwest Africa People's Organization in Namibia, to stall the apartheid South African-installed government there. In 1977, the new General Olusegun Obasanjo's military regime donated $20 million to the Zimbabwean movement against the apartheid government of Rhodesia. Nigeria also sent military equipment to Mozambique to help the newly independent country suppress the South African-backed Mozambican National Resistance guerrillas. Nigeria also provided some military training at the Kaduna first mechanised army division and other material support to Joshua Nkomo and Robert Mugabe's guerrilla forces during the Zimbabwe War in 1979 against the white minority rule of Prime Minister Ian Douglas Smith, which was backed by the apartheid -government of South Africa.

Due to mismanagement of its economy and technology, Nigeria announced that it was launching a nuclear programme of "unlimited scope" of its own but failed. After the Nigerian Independence in 1960, Nigeria demonstrated its seriousness in improving the economy for the people and embarked on nationalizing some multi-national companies that traded with and broke the economic/trade embargo of the apartheid South African regime, the local operations of Barclays Bank was nationalised after that bank ignored the strong protests by the Nigeria populace.

Nigeria also nationalised the British Petroleum (BP) for supplying oil to South Africa. In 1982, the Alhaji Shehu Shagari government urged the visiting Pontiff Pope John Paul II to grant audience to the leaders of Southern Africa guerrilla organisations Oliver Tambo of the ANC and Sam Nujoma of SWAPO. In December 1983, the new Major General Muhammadu Buhari regime announced that Nigeria could no longer afford an apartheid government in Africa.

In pursuing the goal of regional economic cooperation and development, Nigeria helped create ECOWAS, which seeks to harmonise trade and investment practices for its 16 West African member countries and ultimately to achieve a full customs union. Nigeria also has taken the lead in articulating the views of developing nations on the need for modification of the existing international economic order.

Nigeria has played a central role in the ECOWAS efforts to end the civil war in Liberia and contributed the bulk of the ECOWAS peacekeeping forces sent there in 1990. Nigeria also has provided the bulk of troops for ECOMOG forces in Sierra Leone.

Nigeria has enjoyed generally good relations with its immediate neighbours.

Nigeria is a member of the following organizations:


The Babangida regime joined the Organisation of the Islamic Conference (OIC, now the Organisation of Islamic Cooperation), though President Obasanjo has indicated he might reconsider Nigeria's membership.comments are being made for Nigeria to establish more bilateral relations

Delimitation of international boundaries in the vicinity of Lake Chad, the lack of which led to border incidents in the past, has been completed and awaits ratification by Cameroon, Chad, Niger, and Nigeria; dispute with Cameroon over land and maritime boundaries around the Bakasi Peninsula is currently before the International Court of Justice; maritime boundary dispute with Equatorial Guinea because of disputed jurisdiction over oil-rich areas in the Gulf of Guinea.

The Federation of Nigeria became independent from the United Kingdom in 1960 with Queen Elizabeth II as Queen of Nigeria. Nigeria became a Commonwealth republic in 1963, when the Governor-General of Nigeria, Nnamdi Azikiwe became the first President of Nigeria.

Nigeria was suspended from the Commonwealth of Nations from 1995 until 1999, when its full membership was restored.



</doc>
<doc id="21393" url="https://en.wikipedia.org/wiki?curid=21393" title="History of Niue">
History of Niue

The history of Niue is the history of the area and people of Niue, including its indigenous Polynesian societies. Niue was first settled by Polynesian sailors from Samoa in around 900 AD. Further settlers (or possibly invaders) arrived from Tonga in the 16th century. 

The first known sighting of the island by a European was by Captain James Cook in 1774 during his second Pacific voyage. The pioneering missionary John Williams was the first European to land on the island in 1830. After years of British missionary activity, negotiations with the local kings for British protection of the island began in 1879. Lord Ranfurly, Governor of New Zealand proclaimed British Sovereignty over Niue in 1900, therefore laid the island under the patronage of New Zealand.

Niue lost around 4% of its population in World War I as 150 Niuean men were sent to France under the New Zealand army, of which nearly none returned. World War II however did not directly affect the island.

Niue became self-governing in 1974. Since then, the island has been shrinking in population from emigration due to frequent devastating natural disasters and lack of economic opportunities.

Until the beginning of the 18th century, there appears to have been no national government or national leader in Niue. Before that time, chiefs and heads of family exercised authority over segments of the population. Around 1700, the concept and practice of kingship appears to have been introduced through contact with Samoa or Tonga. From then on, a succession of "patu-iki" (kings) ruled the island, the first of whom was Puni-mata. Tui-toga, who reigned from 1875 to 1887, was the first Christian king of Niue. ("See": List of Niuean monarchs)

Captain James Cook was the first European to sight the island, but he was unable to land there due to fierce opposition by the local population. The "1911 Encyclopædia Britannica" claimed this was due to native fear of foreign disease. In response, Cook named Niue the "Savage Island".

Christian missionaries from the London Missionary Society converted most of the population circa 1846. In 1887, King Fataaiki wrote to Queen Victoria of the United Kingdom, requesting that Niue be placed under British protection, but his request was turned down. In 1900, in response to renewed requests, the island became a British protectorate, and the following year it was annexed by New Zealand. Niue's remoteness, as well as cultural and linguistic differences between its Polynesian inhabitants and those of the Cook Islands, caused it to be separately administered.

The island was visited by Captain John Erskine in "H.M.S. Havannah" in July 1849.

150 Niuean men, 4% of the island's population, served as soldiers in the New Zealand armed forces during World War I.

Niue gained its autonomy in 1974 in free association with New Zealand, which handles the island's military and foreign affairs. Niue had been offered autonomy in 1965 (along with the Cook Islands, which accepted), but had asked for its autonomy to be deferred another decade.

Niueans continue to be New Zealand citizens, and use standard New Zealand passports. Niueans who meet normal residence criteria in either country may vote or stand in that country's elections. Niue continues to use New Zealand currency, but issues its own postage stamps (New Zealand stamps are not valid for postage in Niue, nor Niuean stamps in New Zealand).

In January 2004, Niue was struck by a devastating cyclone (Cyclone Heta) which left 200 of the islands' 1600 inhabitants homeless. As a number of local residents chose afterwards not to rebuild, New Zealand's Foreign Affairs Minister Phil Goff speculated that Niue's status as a self-governing nation in free association with New Zealand might come into question if too many residents departed the island to maintain basic services. Soon afterwards, Niue Premier Young Vivian categorically rejected the possibility of altering the existing relationship with New Zealand.

The population of the island continues to drop (from a peak of 5,200 in 1966 to 2,100 in 2000), with substantial emigration to New Zealand.





</doc>
<doc id="21394" url="https://en.wikipedia.org/wiki?curid=21394" title="Geography of Niue">
Geography of Niue

Niue is a small island in the South Pacific Ocean, to the east of Tonga. It has an area of 260 square kilometres, and a coastline of 64 km. It claims an exclusive economic zone of 200 nm, and a territorial sea of 12 nm. It is one of world's largest coral islands.

Niue's climate is tropical, modified by south-east trade winds. Cyclones pose a natural hazard.

The terrain consists of steep coastal cliffs made from limestone and a central plateau. The lowest point is at sea level, and the highest is an unnamed point near Mutalau settlement, at 68 m.

The island's natural resources are fish and arable land. Land use in 1993 was as in the following table:

A current environmental issue is increasing attention to conservationist practices to counter loss of soil fertility from traditional slash-and-burn agriculture. Niue is a party to the following international agreements regarding the environment: Biodiversity, Climate Change-Kyoto Protocol, Desertification. Niue has signed but not ratified the Law of the Sea agreement.

Niue has signed a treaty with the United States in which the parties delimited the east–west maritime boundary between Niue and American Samoa. Niue is south of American Samoa.

This is a list of the extreme points of Niue, the points that are farther north, south, east or west than any other location.



</doc>
<doc id="21396" url="https://en.wikipedia.org/wiki?curid=21396" title="Politics of Niue">
Politics of Niue

Politics of Niue takes place in a framework of a parliamentary representative democratic dependency, whereby the Chief Minister is the head of government, and of a non-partisan system. Niue is self-governing in free association with New Zealand and is fully responsible for internal affairs. New Zealand retains some responsibility for external affairs, in consultation with Niue. The Niue Constitution Act 1974 (NZ) vests executive authority in Her Majesty the Queen in Right of New Zealand and the Governor-General of New Zealand. The constitution specifies that in everyday practice, it is exercised by a Cabinet of the Premier of Niue and three other ministers. The premier and ministers must be members of the Niue Assembly, the nation's legislative assembly.
The Judiciary is independent of the executive and the legislature.

The monarch is hereditary; her representative in relation to Niue (the Governor-General of New Zealand) is appointed by the monarch. The New Zealand high commissioner is appointed by, and acts solely as a diplomatic agent of, the New Zealand Government. The cabinet is chosen by the premier and appointed by the Speaker of the Niue Assembly and collectively responsible to Parliament.

The Cabinet is made up of four ministers, each overseeing a different portfolio. Each minister, with the exception of the Premier, has another Member of the Assembly assisting him/her in the operations of their portfolio. Each ministry also has Directory Generals serving as permanent employees of the ministries, as well as directors for each division.

The Assembly has 20 members elected for a three-year term, 6 elected on a nationwide list, called the common roll, and 14 representatives of the villages. Electors must be New Zealand citizens, resident for at least three months, and candidates must have been electors, resident for twelve months. The speaker is elected from among the members.

In Niue, political parties have never played an important role. There is, at present, no political party, and candidates to elections therefore run as independents. The only party ever to have existed, the Niue People's Party, disbanded in 2003.

As there are no political parties, there is no formal parliamentary Opposition, though there are MPs who oppose the government.

Below is a list of recent by-elections:

"See also:" Court system of Niue

The Judicial Committee of the Privy Council sitting in the United Kingdom is Niue's highest court. On the island, there is a Court of Appeal (which sat in New Zealand until 2009), and the High Court of Niue.

The current chief justice is Patrick Savage. Previous chief justices include Gaven Donne (1975–1982) and Heta Kenneth Hingston, who served as such for 14 years prior to Patrick Savage.

Initially, it was the Crown Counsel of New Zealand that provided legal assistance to those accused of serious offenses such as murder. In 1971, the Select Committee on the Appointment of a Public Defender recommended that the Government of Niue provide any offenders with court representation. John Funaki (a non-attorney) was the first to serve as the Public Defender of Niue in 1976. Even today, the government provides funding for a Public Defender.

Niue is divided in 14 villages each with its own village council whose members are elected and serve three-year terms.


Local Government in Niue is established under the provisions of the Niue Village Council Act 1967. Every village in Niue have a Village council, the term in office is three years before going back to the polls. The election of the members of the village council follows the same rules and regulations used in the General Election to elect members of the Niue Legislative Assembly (parliament). At the first meeting of the Village Council the Chairman will be elected, including the Deputy Chair and the appointment of the Secretary/Treasurer. The Village Council receives grants from the Government, donor agencies also fund some development projects. The Council use to organize show days and conduct fundraising activities to generate revenue to help run some of the activities of the village.

Before achieving independence in 1974, there was an Attorney General for Niue that also served as the Attorney General for New Zealand. However, it would not be until 1996 that Niue would create the official title of Attorney General after amending the Niue Act 1966. Nevertheless, the amendment would not create much of a constitutional change, and the introduction of the Interpretation Act 2004 instated the Crown Law Office as providing legal advice to the Niue government. As a result, it was advised in 2004 that the post of Attorney General be repealed.

The head of the Crown Law Office functions as a public servant, and the Public Service Commission designates the titles for the service officers. The Crown Law Office is responsible for advising the government ministries, and advises the police in regards to criminal prosecution. Due to the lack of attorneys in Niue, there are certain instances in which the office will provide legal presentation to Niue residents.
<nowiki>*</nowiki>He may have spent the majority of his service as the Acting Attorney General as the Niue government had difficulty filling the position.




</doc>
<doc id="21398" url="https://en.wikipedia.org/wiki?curid=21398" title="Transport in Niue">
Transport in Niue

Transport in Niue takes place on a road network, and via an (international) airport and a sea port.

A ring road around the island's coast is the major route, and roads cross the central plateau linking Alofi to the villages of Lakepa, Liku and Hakupu on the opposite coast. All villages in Niue are connected by roads. There are utility roads to the inland and some coastal areas, unsealed, used mainly for accessing taro plantations, coconut areas and walking access to the sea.

Niue International Airport in the west, south of Alofi, is the only airfield. It was extended in 1995 to allow Boeing 737 aircraft to take off with maximum weight. Boeing 737-300, 737-800 and Boeing 757 aircraft have used the airport. Air New Zealand is the only airline serving Niue, with a weekly flight from Auckland. The flight is operated with an A320 departing Auckland on Saturday and arriving the previous day due to the International Date Line. The flight from Niue departs on Friday. 

Niue has a sea port, Sir Robert's Wharf in Alofi, which can be used only by flat-bottomed smaller vessels. The cargo ship "Forum Pacific" from Reef Shipping uses the wharf when the sea is calm. Otherwise cargo vessels and fishing boats use moorings about 100 metres from the reef, and barges are used to offload their cargo.

Most Niuean households own a vehicle. There are four car-rental companies, which also hire bicycles, motorbikes and minibuses.

Railways:
0 km

Highways:
<br>"total:"
234 km
<br>"tarsealed:"
210 km
<br>"unsealed:"
24 km

Ports and harbors:
none; offshore anchorage only

Merchant marine:
none (1999 est.)

Airports:
1 (Niue International Airport)

Airports - with paved runways:
<br>"total:"
1
<br>"1,524 to 2,437 m:"
1 (1999 est.)


</doc>
<doc id="21399" url="https://en.wikipedia.org/wiki?curid=21399" title="Communications in Niue">
Communications in Niue

Communications in Niue include postal, telephone, internet, press and radio.

Postal services are through the Niue Post Office.

Telephone service is provided by Telecom Niue, the sole provider, which services 1,100 landlines and fixed wireless lines. It also operates a cellular telephone service on the AMPS and GSM platforms.

Telephones - main lines in use:
1,100 (800 land line, 300 fixed wireless) (2003)

Telephones - mobile cellular:
undisclosed (excludes 300 fixed wireless) (2003)

Telephones - GSM mobile cellular:
undisclosed (2011)

Telephone system:
<br>"domestic:"
single-line telephone system connects all villages on island
<br>"international:"
provided by Telecom Niue (IDD code: 683)

Radio broadcast stations:
AM 1, FM 1, shortwave 0 (1998)

Radios:
1,000 (1997)

Television broadcast stations:
1 (1997)

Televisions:
NA

Niue has only one printed newspaper, the "Niue Star", founded in 1993. Until 2002, the Auckland-based Pasifika Times was also circulated in Niue.

Niue has free Internet service through the efforts of the Internet Users Society Niue, established 1999. However users need to pay NZD$25 to a local IT company to register the MAC address of their WiFi card before being able to log into this WiFi network.

Alternatively, where ADSL is available, users can have connections through Telecom Niue's Internet Services located at Alofi through their island-wide distributed wireline.

The .nu TLD is assigned to Niue.

Niue, through an outside company, registers Internet domain names, so most .nu web addresses are not actually located in Niue. They are commonly used by Danish, Dutch and Swedish websites, because in those languages 'nu' means “now”.

Niue was the first country in the world to plan on offering free nationwide WiFi internet access, using the funds provided by the domain registrations. 95% of Niueans now have internet access at home, work or through the schools, making it the country with the highest per capita internet penetration in the world.



</doc>
<doc id="21402" url="https://en.wikipedia.org/wiki?curid=21402" title="Northern Mariana Islands">
Northern Mariana Islands

The Northern Mariana Islands, officially the Commonwealth of the Northern Mariana Islands (CNMI; ; Refaluwasch or Carolinian: "Commonwealth Téél Falúw kka Efáng llól Marianas"; formerly in Spanish: "Islas Marianas del Norte", in German: "Nördliche Marianen", and in Japanese: 北マリアナ諸島), is an insular area and commonwealth of the United States consisting of 14 islands in the northwestern Pacific Ocean. The CNMI includes the 14 northernmost islands in the Mariana Archipelago; the southernmost island, Guam, is a separate U.S. territory. The CNMI and Guam are the westernmost territories of the United States.

The United States Department of the Interior cites a landmass of . According to the 2010 United States Census, 53,883 people were living in the CNMI at that time. The vast majority of the population resides on Saipan, Tinian, and Rota. The other islands of the Northern Marianas are sparsely inhabited; the most notable among these is Pagan, which for various reasons over the centuries has experienced major population flux, but formerly had residents numbering in the thousands.

The administrative center is Capitol Hill, a village in northwestern Saipan. However, most publications consider Saipan to be the capital because the island is governed as a single municipality.

The first people to reach the Mariana Islands arrived at some point between 4000 BC and 2000 BC from Southeast Asia. After first contact with Spaniards, they eventually became known as the Chamorros, a Spanish word similar to "Chamori", the name of the indigenous caste system's higher division.

The ancient people of the Marianas raised colonnades of megalithic capped pillars called latte stones upon which they built their homes. The Spanish reported that by the time of their arrival, the largest of these were already in ruins, and that the Chamorros believed the ancestors who had erected the pillars lived in an era when people possessed supernatural abilities.

In 2013 archaeologists posited that the first people to settle in the Marianas may have made what was at that point the longest uninterrupted ocean-crossing voyage in human history. Archeological evidence indicates that Tinian may have been the first Pacific island to be settled.

The Portuguese navigator Ferdinand Magellan, sailing under the Spanish flag, arrived in 1521. He and his crew were the first Europeans to arrive in the Mariana Islands. He landed on Guam, the southernmost island of the Marianas, and claimed the archipelago for Spain. The Spanish ships were met offshore by the native Chamorros, who delivered refreshments and then helped themselves to a small boat belonging to Magellan's fleet. This led to a cultural clash: in Chamorro tradition, little property was private and taking something one needed, such as a boat for fishing, did not count as stealing. The Spanish did not understand this custom and fought the Chamorros until the boat was recovered. Three days after he had been welcomed on his arrival, Magellan fled the archipelago. Spain regarded the islands as annexed and later made them part of the Spanish East Indies in 1565. In 1734, the Spanish built a royal palace, the Plaza de España (Hagåtña), in Guam for the governor of the islands. The palace was largely destroyed during World War II, but portions of it remain.

Guam operated as an important stopover between Manila and Mexico for galleons carrying gold between the Philippines and Spain.

Most of the islands' native population (90–95%) died from European diseases carried by the Spaniards or married non-Chamorro settlers under Spanish rule. New settlers, primarily from the Philippines and the Caroline Islands, were brought to repopulate the islands. The Chamorro population gradually recovered, and Chamorro, Filipino, and Refaluwasch languages and other ethnic differences remain in the Marianas.

During the 17th century, Spanish colonists forcibly moved the Chamorros to Guam, to encourage assimilation and conversion to Roman Catholicism. By the time they were allowed to return to the Northern Marianas, many Carolinians from present-day eastern Yap State and western Chuuk State had settled in the Marianas. Both languages, as well as English, are now official in the commonwealth.

The Northern Marianas experienced an influx of immigration from the Carolines during the 19th century. Both this Carolinian subethnicity and Carolinians in the Carolines archipelago refer to themselves as the Refaluwasch. The indigenous Chamoru word for the same group of people is "gu'palao". They are usually referred to simply as "Carolinians", though unlike the other two monikers, this can also mean those who actually live in the Carolines and who may have no affiliation with the Marianas.

The conquering Spanish did not focus attempts at cultural suppression against Carolinian immigrants, whose immigration they allowed during a period when the indigenous Chamoru majority was being subjugated with land alienation, forced relocations and internment. Carolinians in the Marianas continue to be fluent in the Carolinian language, and have maintained many of the cultural distinctions and traditions of their ethnicity's land of ancestral origin.

Following its loss during the Spanish–American War of 1898, Spain ceded Guam to the United States and sold the remainder of the Marianas (i.e., the Northern Marianas), along with the Caroline Islands, to Germany under the German–Spanish Treaty of 1899. Germany administered the islands as part of its colony of German New Guinea and did little in terms of development.

Early in World War I, Japan declared war on Germany and invaded the Northern Marianas. In 1919, the League of Nations (LoN) awarded all of Germany's islands in the Pacific Ocean located north of the Equator, including the Northern Marianas, under mandate to Japan. Under this arrangement, the Japanese thus administered the Northern Marianas as part of the South Seas Mandate. During the Japanese period, sugar cane became the main industry of the islands. Garapan on Saipan was developed as a regional capital, and numerous Japanese (including ethnic Koreans, Okinawan, and Taiwanese) migrated to the islands. In the December 1939 census, the total population of the South Seas Mandate was 129,104, of whom 77,257 were Japanese (including ethnic Taiwanese and Koreans). On Saipan the pre-war population comprised 29,348 Japanese settlers and 3,926 Chamorro and Caroline Islanders; Tinian had 15,700 Japanese settlers (including 2,700 ethnic Koreans and 22 ethnic Chamorro).

On December 8, 1941, hours after the attack on Pearl Harbor, Japanese forces from the Marianas launched an invasion of Guam. Chamorros from the Northern Marianas, which had been under Japanese rule for more than 20 years, were brought to Guam to assist the Japanese administration. This, combined with the harsh treatment of Guamanian Chamorros during the 31-month occupation, created a rift that would become the main reason Guamanians rejected the reunification referendum approved by the Northern Marianas in the 1960s.
On June 15, 1944, the United States military invaded the Mariana Islands, starting the Battle of Saipan, which ended on July 9. Of the 30,000 Japanese troops defending Saipan, fewer than 1,000 remained alive at the battle's end. Many Japanese civilians were also killed, by disease, starvation, enemy fire, and suicide. Approximately 1,000 civilians committed suicide by jumping off the cliffs at Mt. Marpi or Marpi Point. U.S. forces then recaptured Guam on July 21, and invaded Tinian on July 24. A year later Tinian was the takeoff point for the "Enola Gay", the plane that dropped the atomic bomb on Hiroshima. Rota was left untouched (and isolated) until the Japanese surrender in August 1945, owing to its military insignificance.

The war did not end for everyone with the signing of the armistice. The last group of Japanese holdouts surrendered on Saipan on December 1, 1945. On Guam, Japanese soldier Shoichi Yokoi, unaware that the war had ended, hid in a jungle cave in the Talofofo area until 1972.

Japanese nationals were eventually repatriated to the Japanese home islands.

After Japan's defeat in World War II, the Northern Marianas were administered by the United States pursuant to Security Council Resolution 21 as part of the United Nations Trust Territory of the Pacific Islands, which assigned responsibility for defense and foreign affairs to the United States as trustee. Four referenda offering integration with Guam or changes to the islands' status were held in 1958, 1961, 1963 and 1969. On each occasion, a majority voted in favor of integration with Guam, but this did not happen: Guam rejected integration in a 1969 referendum. The people of the Northern Mariana Islands decided in the 1970s not to seek independence, but instead to forge closer links with the United States. Negotiations for commonwealth status began in 1972 and a covenant to establish a commonwealth in political union with the United States was approved in a 1975 referendum. A new government and constitution partially came into effect in on January 9, 1978 after being approved in a 1977 referendum. The United Nations approved this arrangement pursuant to Security Council Resolution 683. The Northern Mariana Islands came under U.S. sovereignty on November 4, 1986. Also on November 4, 1986, the Northern Mariana Islands constitution became fully effective under the Covenant.

The Northern Mariana Islands does not have voting representation in the United States Congress, but, since 2009, has been represented in the U.S. House of Representatives by a delegate who may participate in debate but may not vote on the floor. The commonwealth has no representation in the U.S. Senate.

The Northern Mariana Islands, together with Guam to the south, compose the Mariana Islands archipelago. The southern islands are limestone, with level terraces and fringing coral reefs. The northern islands are volcanic, with active volcanoes on several islands, including Anatahan, Pagan, and Agrihan. The volcano on Agrihan, Mount Agrihan, has the highest elevation at . An expedition organized by John D. Mitchler and Reid Larson made the first complete ascent to the summit of this peak on June 1, 2018.

Anatahan Volcano is a small volcanic island north of Saipan. It is about long and wide. Anatahan began erupting from its east crater on May 10, 2003. It has since alternated between eruptive and calm periods. On April 6, 2005, an estimated of ash and rock were ejected, causing a large, black cloud to drift south over Saipan and Tinian.


The Northern Mariana Islands have a tropical rainforest climate (Köppen: Af) moderated by seasonal northeast trade winds, with little seasonal temperature variation. The dry season runs from December to June; the rainy season runs from July to November and can include typhoons. The "Guinness Book of World Records" has said Saipan has the most equable climate in the world.

The Northern Mariana Islands have a multiparty presidential representative democratic system. They are a commonwealth of the United States. Federal funds to the commonwealth are administered by the Office of Insular Affairs of the U.S. Department of the Interior.

Replicating the separation of powers elsewhere in the United States, the executive branch is headed by the governor of the Northern Mariana Islands; legislative power is vested in the bicameral Northern Mariana Islands Commonwealth Legislature and the judicial power is vested in the CNMI Supreme Court and the trial courts inferior to it.

Some critics, including the author of the political website "Saipan Sucks", say that politics in the Northern Mariana Islands is often "more a function of family relationships and personal loyalties" where the size of one's extended family is more important than a candidate's personal qualifications. They charge that this is nepotism carried out within the trappings of democracy.

In April 2012, anticipating a loss of funding by 2014, the commonwealth's public pension fund declared Chapter 11 bankruptcy. The retirement fund is a defined benefit-type pension plan and was only partially funded by the government, with only $268.4 million in assets and $911 million in liabilities. The plan experienced low investment returns and a benefit structure that had been increased without raises in funding.

In August 2012, cries for impeachment arose, as the sitting governor Benigno Fitial was being held responsible for withholding payments from the pension fund, not paying the local utility (Commonwealth Utilities or "CUC") for government offices, cutting off funding to the only hospital in the Northern Marianas, interfering with the delivery of a subpoena to his attorney general, withholding required funds from the public schools, and for signing a sole source $190 million contract for power generation.

Northern Mariana Islands’ delegation to the 2016 Republican National Convention boasted about being “the most Republican territory” in the U.S. As of 2017, the Republican Party had large majorities in both the Northern Mariana Islands Senate and the Northern Mariana Islands House of Representatives.

The islands total . The table gives an overview, with the individual islands from north to south:

Administratively, the CNMI is divided into four municipalities:

The Northern Islands (north of Saipan) form the Northern Islands Municipality. The three main islands of the Southern Islands form the municipalities of Saipan, Tinian, and Rota, with uninhabited Aguijan forming part of Tinian municipality.

Because of volcanic threat, the northern islands have been evacuated. Human habitation was limited to Agrihan, Pagan, and Alamagan, but population varied due to various economic factors, including children's education. The 2010 census showed no residents in Northern Islands municipality and the Northern Islands' mayor office is located in "exile" on Saipan.

Saipan, Tinian, and Rota have the only ports and harbors, and are the only permanently populated islands.

For statistical purposes, the United States Census Bureau counts the four municipalities of the Northern Mariana Islands as county equivalents.

In 1947, the Northern Mariana Islands became part of the post–World War II United Nations Trust Territory of the Pacific Islands (TTPI). The United States became the TTPI's administering authority under the terms of a trusteeship agreement. In 1976, Congress approved the mutually negotiated Covenant to establish a Commonwealth of the Northern Mariana Islands in Political Union with the United States of America. The Covenant was codified on March 24, 1976 as Public Law 94-241. The Commonwealth of the Northern Mariana Islands (CNMI) government adopted its own constitution in 1977, and the new government took office in January 1978. Implementation of Covenant, which took effect on January 1, 1978, was completed on November 3, 1986, pursuant to Presidential Proclamation no. 5564; which placed into effect the Covenant With the Commonwealth of the Northern Mariana Islands, and the Compacts of Free Association With the Federated States of Micronesia and the Republic of the Marshall Islands This allowed the CNMI to be represented to the United States Government in Washington, DC by a "Resident Representative", elected at-large by CNMI voters and whose office was paid for by the CNMI government. The Consolidated Natural Resources Act of 2008 ("CNRA"), approved by the U.S. Congress on May 8, 2008, established a CNMI delegate's seat; Democrat Gregorio Sablan was elected in November 2008 as the first CNMI delegate and took office in the 111th Congress. Like the other five delegates, he can participate in debates and vote in committee but has no vote on the floor of the House of Representatives; and has no role in the U.S. Senate, but is equal to a Senator when he serves on a conference committee.

On December 22, 1990, the United Nations Trusteeship Council terminated the TTPI as it applied to the CNMI and five other of the TTPI's original seven districts (the Marshall Islands and the Federated States of Micronesia (Chuuk, Kosrae, Pohnpei and Yap)), this was acknowledged in United Nations Security Council Resolution 683 passed on the same day.
Under the Covenant, in general, United States federal law applies to CNMI. However, the CNMI is outside the customs territory of the United States and, although the internal revenue code does apply in the form of a local income tax, the income tax system is largely locally determined. According to the Covenant, the federal minimum wage and federal immigration laws "will not apply to the Northern Mariana Islands except in the manner and to the extent made applicable to them by the Congress by law after termination of the Trusteeship Agreement." The local control of minimum wage was superseded by the United States Congress in 2007.

Initially under the Covenant a separate immigration system existed in the CNMI, and U.S. immigration laws did not apply. But on November 28, 2009 the CNRA unilaterally amended the Covenant to match US law; specifically, CNRA § 702(a) amended the Covenant to state that "the provisions of the 'immigration laws' (as defined in section 101(a)(17) of the Immigration and Nationality Act (8 U.S.C. 1101(a)(17))) shall apply to the Commonwealth of the Northern Mariana Islands." Further, under CNRA § 702(a), the "immigration laws," as well as the amendments to the Covenant, "shall...supersede and replace all laws, provisions, or programs of the Commonwealth relating to the admission of aliens and the removal of aliens from the Commonwealth." Transition to U.S. immigration laws began November 28, 2009.

The CNMI has a United States territorial court which exercises jurisdiction over the District of the Northern Mariana Islands (DNMI), which is coterminous with the CNMI. The District Court for the Northern Mariana Islands was established by act of Congress in 1977, and began operations in January 1978. The court sits on the island of Saipan, but may sit other places within the commonwealth. The district court has the same jurisdiction as all other United States district courts, including diversity jurisdiction and bankruptcy jurisdiction. Appeals are taken to the Ninth Circuit.

Article III of the Covenant conferred United States citizenship on legally qualified CNMI residents, which generally included all citizens of the CNMI, and established U.S. birthright citizenship for persons born in the CNMI.

The Commonwealth of the Northern Mariana Islands benefits from its trading relationship with the federal government of the United States and cheap trained labor from Asia. Historically, the CNMI's economy has relied on tourism, mostly from Japan, and on the garment manufacturing sector. The economy has declined since quotas were lifted in 2005, eventually leading all the garment factories on Saipan to close by February 2009. Tourism also declined after 2005 when Japan Airlines stopped serving the Marianas.

The Northern Mariana Islands had successfully used its position as a free trade area with the U.S., while at the same time not being subject to the same labor laws. For example, the $3.05 per hour minimum wage in the commonwealth, which lasted from 1997 to 2007, was lower than in the U.S. and some other worker protections are weaker, leading to lower production costs. That allowed garments to be labeled "Made in USA" without having to comply with all U.S. labor laws. However, the U.S. minimum wage law signed by President George W. Bush on May 25, 2007, resulted in stepped increases in the Northern Marianas' minimum wage, which allowed it to reach the U.S. level in 2015. The first step (to $3.55) became effective July 25, 2007, and a yearly increase of $0.50 will take effect every May thereafter until the CNMI minimum wage equals the nationwide minimum wage. However, a law signed by President Obama in December 2009 delayed the yearly increase from May to September. In 2018 the minimum wage finally reached $7.25, matching the U.S. federal minimum wage.

The island's exemption from U.S. labor laws had led to many alleged exploitations, including recent claims of sweatshops, child labor, child prostitution and even forced abortions.

An immigration system mostly outside of federal U.S. control (which ended on November 28, 2009) resulted in a large number of Chinese migrant workers (about 15,000 during the peak years) employed in the islands' garment trade. However, the lifting of World Trade Organization restrictions on Chinese imports to the U.S. in 2005 had put the commonwealth-based trade under severe pressure, leading to a number of recent factory closures. Adding to the U.S.-imposed scheduled wage increases, the garment industry became extinct by 2009.

Agricultural production, primarily of tapioca, cattle, coconuts, breadfruit, tomatoes and melons, exists, but is relatively unimportant in the economy, representing only 1.7% of its GDP as of 2016.

Non-native islanders are not allowed to own land, but can lease it.

The islands have over 220 miles (350 km) of highways, three airports with paved runways (one about 9,800 feet [3,000 m] long; two around 6,600 feet [2,000 m]), three airports with unpaved runways, and one heliport. The main commercial airport is Saipan International Airport.

Mail service for the islands is provided by the U.S. Postal Service (USPS). Each major island has its own zip code in the 96950–96952 range, and the USPS two-letter abbreviation for the CNMI is MP. For phone service, the islands are included in the North American Numbering Plan, using area code 670.

Television service is provided by KPPI-LP, Channel 7, which simulcasts Guam's ABC affiliate KTGM, as well as WSZE, Channel 10, which simulcasts Guam's NBC affiliate KUAM-TV. About 10 radio stations broadcast within the CNMI.

In 2012 Michael Calabrese, Daniel Calarco, and Colin Richardson of "Slate" stated that CNMI internet prices were five times those of Guam, and that the price per megabit increases if a customer chooses a higher level internet package due to the limited bandwidth.

According to the 2010 census, the population of the CNMI as of April 1, 2010, was 53,883, down from 69,221 in 2000, a decrease of 22.2%. The decrease was reportedly due to a combination of factors including the demise of the garment industry (the vast majority of whose employees were females from China), economic crises, and a decline in tourism, one of the CNMI's primary sources of revenue.

Except for the U.S. Minor Outlying Islands, the Northern Mariana Islands are the least populous sub-federal jurisdiction in the United States, with fewer people than any of the 50 states, the other commonwealth and three self-governing territories, and the District of Columbia.

The official languages on the Northern Marianas Islands include English, Chamorro, and Carolinian. Many Philippine languages, Chinese, and other Pacific island languages are also spoken. Spanish is still retained in surnames but is no longer commonly used, though it is still familiar to some elders as a third or fourth language.


Owing to the Spanish missionaries in the Marianas, a large majority of Chamorros and Carolinians practice Roman Catholicism, including the use of rosaries and novenas. The Japanese occupation had the effect of creating a sizable Buddhist community which remained even after their departure. Due to influence of the United States, diverse denominations of Protestantism also entered the islands.
Many people on the Northern Mariana Islands are Roman Catholic or have traditional beliefs.
According to the Pew Research Center, 2010:

The Commonwealth of the Northern Mariana Islands Public School System operates public schools in the commonwealth and there are numerous private schools. Northern Marianas College is accredited by the Western Association of Schools and Colleges and offers a range of programs similar to other small U.S. community colleges.

Much of the Chamorro culture in the Mariana Islands was heavily influenced by the Spanish during the Spanish era, as well as by the Germans and Japanese. Respect is an important part of Chamorro culture, and one common display is the tradition of "manngingi'". This tradition has been around for centuries and involves an elder and a young Chamorro child. The child takes the hand of the elder, places it on their nose and says "ñot" to the men and "ñora" to the women with the elders responding "diosti ayudi" (from spanish "Señor", "Señora", "Dios Te Ayude"), meaning "God help you".

The Carolinian culture is very similar to the Chamorro culture with respect being very important. The Carolinian culture can be traced back to Yap and Chuuk, where the Carolinians originated.

Much of Chamorro cuisine is influenced by various cultures. Examples of popular foods of foreign origin include various types of sweet or savory empanada, originally introduced from Spain, and pancit, a noodle dish from the Philippines.

Archeological evidence reveals that rice has been cultivated in the Marianas since prehistoric times. Red rice made with achoti is a distinct staple food that strongly distinguishes Chamorro cuisine from that of other Pacific islands. It is commonly served for special events, such as parties (gupot or "fiestas"), novenas, and high school or college graduations. Fruits such as lemmai (breadfruit), mangga (mangoes), niyok (coconuts), and bilimbines (bilimbi, a fruit related to starfruit) are included in various local recipes. Korean, Chinese, Japanese, and American cuisine are also commonly available.

Local specialities include kelaguen, a dish in which meat is cooked in whole or in part by the action of citric acid rather than heat; tinaktak, a meat dish made with coconut milk; and kå'du fanihi (flying fox/fruit bat soup). Fruit bats have become scarce in modern times on several islands, primarily due to the overharvesting of the species and loss of habitat; hunting them is now illegal even though poaching still occurs.

The Marianas and the Hawaiian islands are the world's foremost consumers, per capita, of Spam, with Guam at the top of the list, and Hawaii second (details regarding the rest of the Marianas are often absent from statistics). Spam was introduced to the islands by the American military as war rations during the World War II era.

A small independent cinema of Northern Mariana Islands, producing mostly documentary films, developed in the 21st century thanks to the efforts of the Commonwealth and of the Northern Marianas College. Films had already been shot in the islands in the 20th century by foreign producers.

In 2002, a new § 2151 of the Commonwealth Code established within the Marianas Visitors Authority (MVA), a Commonwealth Film, Video and Media Office, also known as the Northern Mariana Islands Film Office, with the purpose of attracting foreign companies to produce movies in the Commonwealth and to develop a local cinema industry.

Team sports popular in the United States were introduced to the Northern Mariana Islands by American soldiers during World War II. Baseball is the islands' most popular sport. CNMI teams have made appearances in the Little League World Series (in the Little, Junior, Senior and Big league divisions) as well as winning gold medals in the Micronesian Games and South Pacific Games.

Basketball and mixed martial arts are also popular in the islands, which hosted the official 2009 Oceania Basketball Tournament. Trench Wars is the CNMI's Mixed Martial Arts brand. Fighters from the CNMI have competed in the Pacific Xtreme Combat as well as the UFC.

Other sports in the CNMI include Ultimate Frisbee, volleyball, tennis, soccer, outrigger sailing, softball, beach volleyball, rugby, golf, boxing, kickboxing, tae kwon do, track and field, Swimming, Triathlon, and American football.










</doc>
<doc id="21404" url="https://en.wikipedia.org/wiki?curid=21404" title="Geography of the Northern Mariana Islands">
Geography of the Northern Mariana Islands

This article is about the geography of the Northern Mariana Islands.

The Northern Mariana Islands, together with Guam to the south, compose the Mariana Islands. The southern islands are limestone, with level terraces and fringing coral reefs. The northern islands are volcanic, with active volcanoes on Anatahan, Pagan and Agrihan. The volcano on Agrihan has the highest elevation at . About one-fifth of the land is arable; another tenth is pasture. The primary natural resource is fish, some of which are endangered species, which leads to conflict. Also, development has created landfills which have contaminated the groundwater on Saipan, which could lead to disease.

Anatahan Volcano is a small volcanic island north of Saipan. It is about long and wide. Anatahan began erupting suddenly from its east crater on May 10, 2003, at about 6 p.m. (0800 UTC). It has since alternated between eruptive and calm periods. On April 6, 2005, approximately of ash and rock were ejected, causing a large, black cloud to drift south over Saipan and Tinian.

The islands have a tropical marine climate moderated by seasonal northeast trade winds. There is little seasonal temperature variation. The dry season runs from December to June, and the rainy season from July to November and can include typhoons. The Guinness Book of World Records has cited Saipan as having the most equable climate in the world. From 1927 to 1935, the temperature ranged from 19.6 degrees Celsius or 67.3 degrees Fahrenheit at the lowest to 31.4 degrees Celsius or 88.5 degrees Fahrenheit at the highest.



</doc>
<doc id="21405" url="https://en.wikipedia.org/wiki?curid=21405" title="Demographics of the Northern Mariana Islands">
Demographics of the Northern Mariana Islands

This article is about the demographic features of the population of the Northern Mariana Islands, including population density, ethnicity, education level, health of the populace, economic status, religious affiliations and other aspects of the population.

The following demographic statistics are from the CIA World Factbook 












According to the Pew Research Center, 2010:





</doc>
<doc id="21406" url="https://en.wikipedia.org/wiki?curid=21406" title="Politics of the Northern Mariana Islands">
Politics of the Northern Mariana Islands

Politics of the Northern Mariana Islands takes place in a framework of a presidential representative democratic system, whereby the Governor is head of government, and of a pluriform multi-party system. The Northern Mariana Islands are a commonwealth in political union with the United States. Executive power is exercised by the governor. Legislative power is vested in the two chambers of the legislature. The judiciary is independent of the executive and the legislature. Local government is carried out through three regional mayors.

The Northern Mariana Islands and the United States of America reached a Covenant Agreement which became fully effective on November 4, 1986. The Constitution of the Commonwealth of the Northern Mariana Islands became effective on January 1, 1978.

The Northern Mariana Islands Commonwealth Legislature has two chambers. The House of Representatives has 20 members, elected for a two-year term from seven districts. The Senate has 9 members, elected for a four-year term in two staggered classes.

Prior to January 2009, the Commonwealth maintained an elected "Resident Representative" in Washington, DC. As authorized by , the Commonwealth now elects a nonvoting delegate to the U.S. Congress (similar to other U.S. insular areas). The first election was held on November 4, 2008.

Commonwealth Supreme Court; Superior Court; Federal District Court

In November 2008, the Northern Mariana Islands held its first election for a delegate to the United States Congress. Gregorio "Kilili" Sablan won the election, and began his term of office in January 2009. The delegate serves as a member to some House committees and may vote in those committees, but the delegate is not permitted to vote on bills up for vote among all members of the House.

ESCAP (associate), INTERPOL (subbureau), SPC

Historically the Northern Mariana Islands have been subject to the colonizing powers of Spain, Germany, Japan, and the United States under a United Nations Trust Territory of the Pacific Islands Agreement. Each power contributed elements that mixed with local indigenous cultures to form the current political culture of the Northern Mariana Islands.

When United States citizenship was granted in 1986 to people who qualified as descendants of the Northern Marianas, few among the island's native population had been adequately prepared for democracy. As a result, politics in the Northern Mariana Islands is often "more a function of family relationships and personal loyalties" where the size of one's extended family is more important than a candidate's personal qualifications. Both scholarly works and the authors of the controversial website Saipansucks.com charge that this is nepotism carried out within the trappings of democracy.


</doc>
<doc id="21422" url="https://en.wikipedia.org/wiki?curid=21422" title="Norfolk Island">
Norfolk Island

Norfolk Island (, ; Norfuk: "Norf'k Ailen") is an Australian external territory located in the Pacific Ocean between New Zealand and New Caledonia, directly east of mainland Australia's Evans Head and about from Lord Howe Island. Together with the neighbouring Phillip Island and Nepean Island, the three islands collectively form the Territory of Norfolk Island. At the 2016 Australian census, it had inhabitants living on a total area of about . Its capital is Kingston.

The first known settlers in Norfolk Island were East Polynesians but they were long gone when Great Britain settled it as part of its 1788 settlement of Australia. The island served as a convict penal settlement from 6 March 1788 until 5 May 1855, except for an 11-year hiatus between 15 February 1814 and 6 June 1825, when it lay abandoned. On 8 June 1856, permanent civilian residence on the island began when descendents of the "Bounty" mutineers were relocated from Pitcairn Island. In 1914 the UK handed Norfolk Island over to Australia to administer as an external territory.

Native to the island, the evergreen Norfolk Island pine is a symbol of the island and is pictured on its flag. The pine is a key export for Norfolk Island, being a popular ornamental tree on mainland Australia (where two related species grow), and also worldwide.

Norfolk Island was uninhabited when first settled by Europeans, but evidence of earlier habitation was obvious. Archaeological investigation suggests that, in the thirteenth or fourteenth century, the island was settled by East Polynesian seafarers, either from the Kermadec Islands north of New Zealand, or from the North Island of New Zealand. However, both Polynesian and Melanesian artefacts have been found, so it is possible that people from New Caledonia, relatively close to the north, also reached Norfolk Island. Human occupation must have ceased at least a few hundred years before Europeans arrived. Ultimately, the relative isolation of the island, and its poor horticultural environment, were not favourable to long-term settlement.

The first European known to have sighted and landed on the island was Captain James Cook, on 10 October 1774, on his second voyage to the South Pacific on . He named it after Mary Howard, Duchess of Norfolk. Sir John Call argued the advantages of Norfolk Island in that it was uninhabited and that New Zealand flax grew there. In 1786, the British government included Norfolk Island as an auxiliary settlement, as proposed by John Call, in its plan for colonisation of the Colony of New South Wales. The decision to settle Norfolk Island was taken due to Empress Catherine II of Russia's decision to restrict sales of hemp. Practically all the hemp and flax required by the Royal Navy for cordage and sailcloth was imported from Russia.

When the First Fleet arrived at Port Jackson in January 1788, Governor Arthur Phillip ordered Lieutenant Philip Gidley King to lead a party of 15 convicts and seven free men to take control of Norfolk Island, and prepare for its commercial development. They arrived on 6 March. During the first year of the settlement, which was also called "Sydney" like its parent, more convicts and soldiers were sent to the island from New South Wales. Robert Watson, harbourmaster, arrived with the First Fleet as quartermaster of , and was still serving in that capacity when the ship was wrecked at Norfolk Island in 1790. Next year, he obtained and cultivated a grant of on the island.

As early as 1794, Lieutenant-Governor of New South Wales Francis Grose suggested its closure as a penal settlement, as it was too remote and difficult for shipping and too costly to maintain. The first group of people left in February 1805, and by 1808, only about 200 remained, forming a small settlement until the remnants were removed in 1813. A small party remained to slaughter stock and destroy all buildings, so that there would be no inducement for anyone, especially from other European powers, to visit and lay claim to the place. From February 1814 until June 1825, the island was abandoned.

In 1824 the British government instructed the Governor of New South Wales, Thomas Brisbane, to occupy Norfolk Island as a place to send "the worst description of convicts". Its remoteness, previously seen as a disadvantage, was now viewed as an asset for the detention of recalcitrant male prisoners. The convicts detained have long been assumed to be hardcore recidivists, or 'doubly-convicted capital respites' – that is, men transported to Australia who committed fresh colonial crimes for which they were sentenced to death, but were spared the gallows on condition of life at Norfolk Island. However, a 2011 study, using a database of Norfolk Island convicts, has demonstrated that the reality was somewhat different: more than half were detained at Norfolk Island without ever receiving a colonial conviction, and only 15% had been reprieved from a death sentence. Furthermore, the overwhelming majority of convicts sent to Norfolk Island had committed non-violent property offences, and the average length of detention there was three years. Nonetheless, Norfolk Island went through periods of unrest with convicts staging a number of uprisings and mutinies between 1826 and 1846, all of which failed. The British government began to wind down the second penal settlement after 1847, and the last convicts were removed to Tasmania in May 1855. The island was abandoned because transportation from the United Kingdom to Van Diemen's Land (Tasmania) had ceased in 1853, to be replaced by penal servitude in the UK.

The next settlement began on 8 June 1856, as the descendants of Tahitians and the HMS "Bounty" mutineers, including those of Fletcher Christian, were resettled from the Pitcairn Islands, which had become too small for their growing population. On 3 May 1856, 193 people had left Pitcairn Islands aboard the "Morayshire". On 8 June 194 people arrived, a baby having been born in transit. The Pitcairners occupied many of the buildings remaining from the penal settlements, and gradually established traditional farming and whaling industries on the island. Although some families decided to return to Pitcairn in 1858 and 1863, the island's population continued to grow. They accepted additional settlers, who often arrived on whaling vessels.

The island was a regular resort for whaling vessels in the age of sail. The first such ship was the "Britannia" in November 1793. The last on record was the "Andrew Hicks" in August–September 1907. They came for water, wood and provisions and sometimes they recruited islanders to serve as crewmen on their vessels.

In 1867, the headquarters of the Melanesian Mission of the Church of England was established on the island. In 1920 the Mission was relocated from Norfolk Island to the Solomon Islands to be closer to the focus of population.

Norfolk Island was the subject of several experiments in administration during the century. It began the nineteenth century as part of the Colony of New South Wales. On 29 September 1844, Norfolk Island was transferred from the Colony of New South Wales to the Colony of Van Diemen's Land. On 1 November 1856 Norfolk Island was separated from the Colony of Tasmania (formerly Van Diemen's Land) and constituted as a "distinct and separate Settlement, the affairs of which should until further Order in that behalf by Her Majesty be administered by a Governor to be for that purpose appointed". The Governor of New South Wales was constituted as the Governor of Norfolk Island.

On 19 March 1897 the office of the Governor of Norfolk Island was abolished and responsibility for the administration of Norfolk Island was vested in the Governor of the Colony of New South Wales. Yet, the island was not made a part of New South Wales and remained separate. The Colony of New South Wales ceased to exist upon the establishment of the Commonwealth of Australia on 1 January 1901, and from that date responsibility for the administration of Norfolk Island was vested in the Governor of the State of New South Wales.

The Parliament of the Commonwealth of Australia accepted the territory by the Norfolk Island Act 1913 (Cth), subject to British agreement; the Act received the assent on 19 December 1913. In preparation for the handover, a proclamation by the Governor of New South Wales on 23 December 1913 (in force when gazetted on 24 December) repealed "all laws heretofore in force in Norfolk Island" and replaced them by re-enacting a list of such laws. Among those laws was the Administration Law 1913 (NSW), which provided for appointment of an Administrator of Norfolk Island and of magistrates, and contained a code of criminal law.

British agreement was expressed on 30 March 1914, in a UK Order in Council made pursuant to the "Australian Waste Lands Act" 1855 (Imp). A proclamation by the Governor-General of Australia on 17 June 1914 gave effect to the Act and the Order as from 1 July 1914.

During World War II, the island became a key airbase and refuelling depot between Australia and New Zealand, and New Zealand and the Solomon Islands. The airstrip was constructed by Australian, New Zealand and the United States servicemen during 1942. Since Norfolk Island fell within New Zealand's area of responsibility, it was garrisoned by a New Zealand Army unit known as N Force at a large Army camp which had the capacity to house a strong force. N Force relieved a company of the Second Australian Imperial Force. The island proved too remote to come under attack during the war and N Force left the island in February 1944.

In 1979, Norfolk Island was granted limited self-government by Australia, under which the island elected a government that ran most of the island's affairs.

In 2006, a formal review process took place, in which the Australian government considered revising this model of government. The review was completed on 20 December 2006, when it was decided that there would be no changes in the governance of Norfolk Island.

Financial problems and a reduction in tourism led to Norfolk Island's administration appealing to the Australian federal government for assistance in 2010. In return, the islanders were to pay income tax for the first time but would be eligible for greater welfare benefits. However, by May 2013 agreement had not been reached and islanders were having to leave to find work and welfare. An agreement was finally signed in Canberra on 12 March 2015 to replace self-government with a local council but against the wishes of the Norfolk Island government. A majority of Norfolk Islanders objected to the Australian plan to make changes to Norfolk Island without first consulting them and allowing their say, with 68% of voters against forced changes.

On 4 October 2015, Norfolk Island changed its time zone from to .

In March 2015, the Australian Government announced comprehensive reforms for Norfolk Island. The action was justified on the grounds it was necessary "to address issues of sustainability which have arisen from the model of self-government requiring Norfolk Island to deliver local, state and federal functions since 1979". On 17 June 2015, the Norfolk Island Legislative Assembly was abolished, with the territory becoming run by an Administrator and an advisory council. Elections for a new Regional Council were held on 28 May 2016, with the new council taking office on 1 July 2016.

From that date, most Australian Commonwealth laws were extended to Norfolk Island. This means that taxation, social security, immigration, customs and health arrangements apply on the same basis as in mainland Australia. Travel between Norfolk Island and mainland Australia became domestic travel on 1 July 2016. For the 2016 Australian federal election, 328 people on Norfolk Island voted in the ACT electorate of Canberra, out of 117,248 total votes. For the 2019 Australian federal election Norfolk Island is covered by the electorate of Bean.

There is opposition to the reforms, led by Norfolk Island People for Democracy Inc., an association appealing to the United Nations to include the island on its list of "non-self-governing territories". There has also been movement to join New Zealand since the autonomy reforms.

The Territory of Norfolk Island is located in the South Pacific Ocean, east of the Australian mainland. Norfolk Island itself is the main island of the island group that the territory encompasses and is located at . It has an area of , with no large-scale internal bodies of water and of coastline. Norfolk was formed from several volcanic eruptions between 3.1 and 2.3 million years ago.

The island's highest point is Mount Bates reaching above sea level, located in the northwest quadrant of the island. The majority of the terrain is suitable for farming and other agricultural uses. Phillip Island, the second largest island of the territory, is located at , south of the main island.

The coastline of Norfolk Island consists, to varying degrees, of cliff faces. A downward slope exists towards Slaughter Bay and Emily Bay, the site of the original colonial settlement of Kingston. There are no safe harbour facilities on Norfolk Island, with loading jetties existing at Kingston and Cascade Bay. All goods not domestically produced are brought in by ship, usually to Cascade Bay. Emily Bay, protected from the Pacific Ocean by a small coral reef, is the only safe area for recreational swimming, although surfing waves can be found at Anson and Ball Bays.

The climate is subtropical and mild, with little seasonal differentiation. The island is the eroded remnant of a basaltic volcano active around 2.3 to 3 million years ago, with inland areas now consisting mainly of rolling plains. It forms the highest point on the Norfolk Ridge, part of the submerged continent Zealandia.

The area surrounding Mount Bates is preserved as the Norfolk Island National Park. The park, covering around 10% of the land of the island, contains remnants of the forests which originally covered the island, including stands of subtropical rainforest.

The park also includes the two smaller islands to the south of Norfolk Island, Nepean Island and Phillip Island. The vegetation of Phillip Island was devastated due to the introduction during the penal era of pest animals such as pigs and rabbits, giving it a red-brown colour as viewed from Norfolk; however, pest control and remediation work by park staff has recently brought some improvement to the Phillip Island environment.

The major settlement on Norfolk Island is Burnt Pine, located predominantly along Taylors Road, where the shopping centre, post office, bottle shop, telephone exchange and community hall are located. The settlement also exists over much of the island, consisting largely of widely separated homesteads.

Government House, the official residence of the Administrator, is located on Quality Row in what was the penal settlement of Kingston. Other government buildings, including the court, Legislative Assembly and Administration, are also located there. Kingston's role is largely a ceremonial one, however, with most of the economic impetus coming from Burnt Pine.

Norfolk Island has a mid-latitude and marine subtropical climate (Köppen: "Cfa"). The temperature almost never falls below or rises above . The absolute maximum recorded temperature is , while the absolute minimum is . Average annual precipitation is , with most rain falling from April to August. Other months receive significant amounts of precipitation as well.

Norfolk Island is part of the Interim Biogeographic Regionalisation for Australia region "Pacific Subtropical Islands" (PSI), and forms subregion PSI02, with an area of .

Norfolk Island has 174 native plants; 51 of them are endemic. At least 18 of the endemic species are rare or threatened. The Norfolk Island palm ("Rhopalostylis baueri") and the smooth tree-fern ("Cyathea brownii"), the tallest tree-fern in the world, are common in the Norfolk Island National Park but rare elsewhere on the island. Before European colonisation, most of Norfolk Island was covered with subtropical rain forest, the canopy of which was made of "Araucaria heterophylla" (Norfolk Island pine) in exposed areas, and the palm "Rhopalostylis baueri" and tree ferns "Cyathea brownii" and "C. australis" in moister protected areas. The understory was thick with lianas and ferns covering the forest floor. Only one small tract, , of rainforest remains, which was declared as the Norfolk Island National Park in 1986.

This forest has been infested with several introduced plants. The cliffs and steep slopes of Mount Pitt supported a community of shrubs, herbaceous plants, and climbers. A few tracts of cliff top and seashore vegetation have been preserved. The rest of the island has been cleared for pasture and housing. Grazing and introduced weeds currently threaten the native flora, displacing it in some areas. In fact, there are more weed species than native species on Norfolk Island.

As a relatively small and isolated oceanic island, Norfolk has few land birds but a high degree of endemicity among them. Norfolk Island is home to a radiation of about 40 endemic snail species. Many of the endemic bird species and subspecies have become extinct as a result of massive clearance of the island's native vegetation of subtropical rainforest for agriculture, hunting and persecution as agricultural pests. The birds have also suffered from the introduction of mammals such as rats, cats, pigs and goats, as well as from introduced competitors such as common blackbirds and crimson rosellas. Although the island is politically part of Australia, many of Norfolk Island's native birds show affinities to those of neighbouring New Zealand, such as the Norfolk kaka, Norfolk pigeon, and Norfolk boobook.

Extinctions include that of the endemic Norfolk kaka, Norfolk ground dove and Norfolk pigeon, while of the endemic subspecies the starling, triller, thrush and boobook owl are extinct, although the latter's genes persist in a hybrid population descended from the last female. Other endemic birds are the white-chested white-eye, which may be extinct, the Norfolk parakeet, the Norfolk gerygone, the slender-billed white-eye and endemic subspecies of the Pacific robin and golden whistler. Subfossil bones indicate that a species of "Coenocorypha" snipe was also found on the island and is now extinct, but the taxonomic relationships of this are unclear and have not been scientifically described yet.

The Norfolk Island Group Nepean Island is also home to breeding seabirds. The providence petrel was hunted to local extinction by the beginning of the 19th century but has shown signs of returning to breed on Phillip Island. Other seabirds breeding there include the white-necked petrel, Kermadec petrel, wedge-tailed shearwater, Australasian gannet, red-tailed tropicbird and grey ternlet. The sooty tern (known locally as the whale bird) has traditionally been subject to seasonal egg harvesting by Norfolk Islanders.

Norfolk Island, with neighbouring Nepean Island, has been identified by BirdLife International as an Important Bird Area because it supports the entire populations of white-chested and slender-billed white-eyes, Norfolk parakeets and Norfolk gerygones, as well as over 1% of the world populations of wedge-tailed shearwaters and red-tailed tropicbirds. Nearby Phillip Island is treated as a separate IBA.

Norfolk Island also has a botanical garden, which is home to a sizeable variety of plant species. However, the island has only one native mammal, Gould's wattled bat ("Chalinolobus gouldii"). It is very rare, and may already be extinct on the island.

The Norfolk swallowtail ("Papilio amynthor") is a species of butterfly that is found on Norfolk Island and the Loyalty Islands.

Cetaceans were historically abundant around the island as commercial hunts on the island were operating until 1956. Today, numbers of larger whales have disappeared, but even today many species such humpback whale, minke whale, sei whale, and dolphins can be observed close to shore, and scientific surveys have been conducted regularly. Southern right whales were once regular migrants to Norfolk, but were severely depleted by historical hunts, and further by recent illegal Soviet and Japanese whaling, resulting in none or very few, if remnants still live, right whales in these regions along with Lord Howe Island.

Whale sharks can be encountered off the island, too.


The population of Norfolk Island was 1,748 in the 2016 census, which had declined from a high of 2,601 in 2001.

In 2011, residents were 78% of the census count, with the remaining 22% being visitors. 16% of the population were 14 years and under, 54% were 15 to 64 years, and 24% were 65 years and over. The figures showed an ageing population, with many people aged 20–34 having moved away from the island.

Most islanders are of either European-only (mostly British) or combined European-Tahitian ancestry, being descendants of the "Bounty" mutineers as well as more recent arrivals from Australia and New Zealand. About half of the islanders can trace their roots back to Pitcairn Island.

This common heritage has led to a limited number of surnames among the Islanders – a limit constraining enough that the island's telephone directory also includes nicknames for many subscribers, such as Cane Toad, Dar Bizziebee, Lettuce Leaf, Goof, Paw Paw, Diddles, Rubber Duck, Carrots, and Tarzan.

Population
Population growth rate
Nationality
Citizenship (as of the 2011 census)

62% of the islanders are Christians. After the death of the first chaplain Rev G. H. Nobbs in 1884, a Methodist church was formed and in 1891 a Seventh-day Adventist congregation led by one of Nobbs' sons. Some unhappiness with G. H. Nobbs, the more organised and formal ritual of the Church of England service arising from the influence of the Melanesian Mission, decline in spirituality, the influence of visiting American whalers, literature sent by Christians overseas impressed by the Pitcairn story, and the adoption of Seventh-day Adventism by the descendants of the mutineers still on Pitcairn, all contributed to these developments.

The Roman Catholic Church began work in 1957 and in the late 1990s a group left the former Methodist (then Uniting Church) and formed a charismatic fellowship. In 2011, 34% of the ordinary residents identified as Anglican, 13% as Uniting Church, 12% as Roman Catholic and 3% as Seventh-day Adventist. 9% were from other religions. 24% had no religion, and 7% did not indicate a religion. Typical ordinary congregations in any church do not exceed 30 local residents . The three older denominations have good facilities. Ministers are usually short-term visitors.

Statistics:

Islanders speak both English and a creole language known as Norfuk, a blend of eighteenth century English and Tahitian. The Norfuk language is decreasing in popularity as more tourists come to the island and more young people leave for work and study reasons. However, efforts are being made to keep it alive via dictionaries and the renaming of some tourist attractions to their Norfuk equivalents.

In 2004 an act of the Norfolk Island Assembly made it a co-official language of the island. The act is long-titled: "An Act to recognise the Norfolk Island Language (Norf'k) as an official language of Norfolk Island". The "language known as 'Norf'k'" is described as the language "that is spoken by descendants of the first free settlers of Norfolk Island who were descendants of the settlers of Pitcairn Island". The act recognises and protects use of the language but does not require it; in official use, it must be accompanied by an accurate translation into English. 32% of the total population reported speaking a language other than English in the 2011 census, and just under three-quarters of the ordinarily resident population could speak Norfuk.

Languages

The sole school on the island, Norfolk Island Central School, provides education from kindergarten through to Year 12. The school has a contractual arrangement referred to as a Memorandum of Understanding with the New South Wales Department of Education and Communities regarding the teaching staff of the school, the latest of which took effect in January 2015. In 2015 enrolment at the Norfolk Island Central School was students.

No public tertiary education infrastructure exists on the Island. The Norfolk Island Central School works in partnership with Registered Training Organisations (RTOs) and local employers to support students accessing Vocational Education and Training (VET) courses.

Literacy is not recorded officially, but can be assumed to be roughly at a par with Australia's literacy rate, as islanders attend a school which uses a New South Wales curriculum, before traditionally moving to the mainland for further study.

While there was no "indigenous" culture on the island at the time of settlement, the Tahitian influence of the Pitcairn settlers has resulted in some aspects of Polynesian culture being adapted to that of Norfolk, including the hula dance. Local cuisine also shows influences from the same region.

Islanders traditionally spend a lot of time outdoors, with fishing and other aquatic pursuits being common pastimes, an aspect which has become more noticeable as the island becomes more accessible to tourism. Most island families have at least one member involved in primary production in some form.

Religious observance remains an important part of life for some islanders, particularly the older generations, but actual attendance is about 8% of the resident population plus some tourists. In the 2006 census 19.9% had no religion compared with 13.2% in 1996. Businesses are closed on Wednesday and Saturday afternoons and Sundays.

One of the island's residents was the novelist Colleen McCullough, whose works include "The Thorn Birds" and the "Masters of Rome" series as well as "Morgan's Run", set, in large part, on Norfolk Island.

Helen Reddy also moved to the island in 2002, and still maintains a house there.

American novelist James A. Michener, who served in the United States Navy during World War II, set one of the chapters of his episodic novel "Tales of the South Pacific" on Norfolk Island.

The island is one of the few locations outside North America to celebrate the holiday of Thanksgiving.

Norfolk Island is the only non-mainland Australian territory to have had self-governance. The "Norfolk Island Act 1979", passed by the Parliament of Australia in 1979, is the Act under which the island was governed until the passing of the "Norfolk Island Legislation Amendment Act" 2015 (Cth). The Australian government maintains authority on the island through an Administrator, currently Eric Hutchinson. From 1979 to 2015, a Legislative Assembly was elected by popular vote for terms of not more than three years, although legislation passed by the Australian Parliament could extend its laws to the territory at will, including the power to override any laws made by the assembly.

The Assembly consisted of nine seats, with electors casting nine equal votes, of which no more than two could be given to any individual candidate. It is a method of voting called a "weighted first past the post system". Four of the members of the Assembly formed the Executive Council, which devised policy and acted as an advisory body to the Administrator. The last Chief Minister of Norfolk Island was Lisle Snell. Other ministers included: Minister for Tourism, Industry and Development; Minister for Finance; Minister for Cultural Heritage and Community Services; and Minister for Environment.

All seats were held by independent candidates. Norfolk Island did not embrace party politics. In 2007 a branch of the Australian Labor Party was formed on Norfolk Island, with the aim of reforming the system of government.

Since July 2016 after the loss of self-government, residents of Norfolk Island have been required to enrol in the Division of Canberra. As is the case for all Australian citizens, enrolment and voting for Norfolk Islanders is compulsory.

Disagreements over the island's relationship with Australia were put in sharper relief by a 2006 review undertaken by the Australian government. Under the more radical of two models proposed in the review, the island's legislative assembly would have been reduced to the status of a local council. However, in December 2006, citing the "significant disruption" that changes to the governance would impose on the island's economy, the Australian government ended the review leaving the existing governance arrangements unaltered.

In a move that apparently surprised many islanders, the Chief Minister of Norfolk Island, David Buffett, announced on 6 November 2010 that the island would voluntarily surrender its self-government status in return for a financial bailout from the federal government to cover significant debts.

It was announced on 19 March 2015 that self-governance for the island would be revoked by the Commonwealth and replaced by a local council with the state of New South Wales providing services to the island. A reason given was that the island had never gained self-sufficiency and was being heavily subsidised by the Commonwealth, by $12.5  million in 2015 alone. It meant that residents would have to start paying Australian income tax, but they would also be covered by Australian welfare schemes such as Centrelink and Medicare.

The Norfolk Island Legislative Assembly decided to hold a referendum on the proposal. On 8 May 2015, voters were asked if Norfolk Islanders should freely determine their political status and their economic, social and cultural development, and to "be consulted at referendum or plebiscite on the future model of governance for Norfolk Island before such changes are acted upon by the Australian parliament". 68% out of 912 voters voted in favour. The Norfolk Island Chief Minister, Lisle Snell, said that "the referendum results blow a hole in Canberra's assertion that the reforms introduced before the Australian Parliament that propose abolishing the Legislative Assembly and Norfolk Island Parliament were overwhelmingly supported by the people of Norfolk Island".

The "Norfolk Island Legislation Amendment Act 2015" passed the Australian Parliament on 14 May 2015 (assented on 26 May 2015), abolishing self-government on Norfolk Island and transferring Norfolk Island into a council as part of New South Wales law. From 1 July 2016 Norfolk Island legislation will be transferred to New South Wales and subject to NSW legislation.

The island's official capital is Kingston; it is, however, more a centre of government than a sizeable settlement. The largest settlement is at Burnt Pine.

The most important local holiday is Bounty Day, celebrated on 8 June, in memory of the arrival of the Pitcairn Islanders in 1856.

Local ordinances and acts apply on the island, where most laws are based on the Australian legal system. Australian common law applies when not covered by either Australian or Norfolk Island law. Suffrage is universal at age eighteen.

As a territory of Australia, Norfolk Island does not have diplomatic representation abroad, or within the territory, and is also not a participant in any international organisations, other than sporting organisations.

The flag is three vertical bands of green, white, and green with a large green Norfolk Island pine tree centred in the slightly wider white band.

The Norfolk Island Regional Council was established in July 2016 to govern the territory at the local level in line with local governments in mainland Australia.

From 1788 until 1844 Norfolk Island was a part of the Colony of New South Wales. In 1844 it was severed from New South Wales and annexed to the Colony of Van Diemen's Land. With the demise of the third settlement and in contemplation that the inhabitants of Pitcairn Island would move to Norfolk Island, the "Australian Waste Lands Act" 1855 (Imp), gave the Queen in Council the power to "separate Norfolk Island from the Colony of Van Diemen's Land and to make such provision for the government of Norfolk Island as might seem expedient". In 1856 the Queen in Council ordered that Norfolk Island be a distinct and separate settlement, appointing the Governor of New South Wales to also be the Governor of Norfolk Island with "full power and authority to make laws for the order, peace, and good government" of the island. Under these arrangements Norfolk Island was effectively self-governing. Although Norfolk Island was a colony acquired by settlement, it was never within the "British Settlements Act".

The constitutional status of Norfolk Island was revisited in 1894 when the British Government appointed an inquiry into the administration of justice on the island. By this time there had been steps in Australia towards federation including the 1891 constitutional convention. There was a correspondence between the Governor of Norfolk Island, the British colonial office and the Governor of New Zealand as to how the island should be governed and by whom. Even within NSW it was felt that "the laws and system of government in the Colony of New South Wales would not prove suitable to the Island Community". In 1896 the Governor of New Zealand wrote "I am advised that, as far as my Ministers can ascertain, if any change is to take place in the government of Norfolk Island, the Islanders, while protesting against any change, would prefer to come under the control of New Zealand rather than that of New South Wales".

The British government decided not to annex Norfolk Island to the Colony of NSW and instead that the affairs of Norfolk Island would be administered by the Governor of NSW in that capacity rather than having a separate office as Governor of Norfolk Island. The order-in-council contemplated the future annexation of Norfolk Island to the Colony of NSW or to any federal body of which NSW form part. Norfolk Island was not a part of NSW and residents of Norfolk Island were not entitled to have their names placed on the NSW electoral roll. Norfolk Island was accepted as a territory of Australia, separate from any state, by the "Norfolk Island Act" 1913 (Cth), passed under the territories power, and made effective in 1914. Norfolk Island was given a limited form of self-government by the "Norfolk Island Act" 1979 (Cth).

There have been four challenges to the constitutional validity of the Australian Government's authority to administer Norfolk Island:

The Government of Australia thus holds that:

Much of the self-government under the 1979 legislation was repealed with effect from 2016. The reforms included, to the chagrin of some of the locals of Norfolk Island, a repeal of the preambular sections of the Act which originally were 3–4 pages recognising the particular circumstances in the history of Norfolk Island.

Consistent with the Australian position, the United Nations Decolonization Committee does not include Norfolk Island on its list of Non-Self-Governing Territories.

This legal position is disputed by some residents on the island. Some islanders claim that Norfolk Island was actually granted independence at the time Queen Victoria granted permission to Pitcairn Islanders to re-settle on the island.

Following reforms to the status of Norfolk Island there were mass protests by the local population. In 2015 it was reported that Norfolk Island was taking its argument for self-governance to the United Nations. A campaign to preserve the island's autonomy was formed, named Norfolk's Choice. A formal petition was lodged with the United Nations by Geoffrey Robertson on behalf of the local population on 25 April 2016.

Various suggestions for retaining the island's self-government have been proposed. In 2006 a UK MP, Andrew Rosindell, raised the possibility of the island becoming a self-governing British Overseas Territory. In 2013 the island's last chief minister, Lisle Snell, suggested independence, to be supported by income from fishing, offshore banking and foreign aid.

The laws of Norfolk Island were in a transitional state, under the Norfolk Island Applied Laws Ordinance 2016 (Cth), from 2016 until 2018. Laws of New South Wales as applying in Norfolk Island were suspended (with five major exceptions, which the 2016 Ordinance itself amended) until the end of June 2018. From 1 July 2018, all laws of New South Wales apply in Norfolk Island and, as "applied laws", are subject to amendment, repeal or suspension by federal ordinance. The Local Government Act 1993 (NSW) has been amended for application to Norfolk Island.

The island is subject to separate immigration controls from the remainder of Australia. Until recently, immigration to Norfolk Island even by other Australian citizens was heavily restricted. In 2012, immigration controls were relaxed with the introduction of an Unrestricted Entry Permit for all Australian and New Zealand citizens upon arrival and the option to apply for residency; the only criteria are to pass a police check and be able to pay into the local health scheme. From 1 July 2016, the Australian migration system replaced the immigration arrangements previously maintained by the Norfolk Island Government.

Australian citizens and residents from other parts of the nation now have an automatic right of residence on the island after meeting these criteria (Immigration (Amendment No. 2) Act 2012). Australian citizens can carry either a passport or a form of photo identification to travel to Norfolk Island. The Document of Identity, which is no longer issued, is also acceptable within its validity period. Citizens of all other nations must carry a passport to travel to Norfolk Island even if arriving from other parts of Australia. Holders of Australian visas who travel to Norfolk Island have departed the Australian Migration Zone. Unless they hold a multiple-entry visa, the visa will have ceased; in which case they will require another visa to re-enter mainland Australia.

Non-Australian citizens who are permanent residents of Norfolk Island may apply for Australian citizenship after meeting normal residence requirements and are eligible to take up residence in mainland Australia at any time through the use of a Confirmatory (Residence) visa (subclass 808). Children born on Norfolk Island are Australian citizens as specified by Australian nationality law.

Non-Australian citizens who are Australian permanent residents should be aware that during their stay on Norfolk Island they are "outside of Australia" for the purposes of the Migration Act. This means that not only will they need a still-valid migrant visa or Resident return visa to return from Norfolk Island to the mainland, but also the time spent in Norfolk Island will not be counted for satisfying the residency requirement for obtaining a Resident return visa in the future. On the other hand, as far as Australian nationality law is concerned, Norfolk Island is a part of Australia, and any time spent by an Australian permanent resident on Norfolk Island will count as time spent in Australia for the purpose of applying for Australian citizenship.

Norfolk Island Hospital is the only medical centre on the island. From 1 July 2016, medical treatment on Norfolk Island was covered by Medicare and the Pharmaceutical Benefits Scheme as it is on mainland Australia. Emergency medical treatment is covered by Medicare or a private health insurer. Although the hospital can perform minor surgery, serious medical conditions are not permitted to be treated on the island and patients are flown back to mainland Australia. Air charter transport can cost as much as , which is covered by the Australian Government. For serious emergencies, medical evacuations are provided by the Royal Australian Air Force. The island has one ambulance, staffed by St John Ambulance Australia volunteers.

The lack of medical facilities available in most remote communities has a major impact on the health care of Norfolk Islanders. As is consistent with other extremely remote regions, many older residents find it impossible to remain on the island when their health falters, many have to leave their homes and live in New Zealand or Australia to get medical care.

Defence is the responsibility of the Australian Defence Force. There are no active military installations or defence personnel on Norfolk Island. The Administrator may request the assistance of the Australian Defence Force if required.

Civilian law enforcement and community policing are provided by the Australian Federal Police. The normal deployment to the island is one sergeant and two constables. These are augmented by five local Special Members who have police powers but are not AFP employees.

The Norfolk Island Court of Petty Sessions is the equivalent of a Magistrates Court and deals with minor criminal, civil or regulatory matters. The Chief Magistrate of Norfolk Island is usually the current Chief Magistrate of the Australian Capital Territory. Three local Justices of the Peace have the powers of a Magistrate to deal with minor matters.

The Supreme Court of Norfolk Island deals with more serious criminal offences, more complex civil matters, administration of deceased estates and federal laws as they apply to the Territory. The Judges of the Supreme Court of Norfolk Island are generally appointed from among Justices of the Federal Court of Australia and may sit on the Australian mainland or convene a circuit court. Appeals are to the Federal Court of Australia.

As stated by the Legal Profession Act 1993, "a resident practitioner must hold a Norfolk Island practising certificate." , only one lawyer maintained a full-time legal practice on Norfolk Island.

Until 2016, Norfolk Island took its own censuses, separate from those taken by the Australian Bureau of Statistics for the remainder of Australia.

Prior to 2016, the Norfolk Island Postal Service was responsible for mail receipt and delivery on the island and issued its own postage stamps. With the merger of Norfolk Island as a regional council, the Norfolk Island Postal Service ceased to exist and all postage is now handled by Australia Post. Australia Post sends and receives mail from Norfolk Island with the postcode 2899.

Tourism, the primary economic activity, has steadily increased over the years. As Norfolk Island prohibits the importation of fresh fruit and vegetables, most produce is grown locally. Beef is both produced locally and imported. The island has one winery, Two Chimneys Wines.

The Australian government controls the exclusive economic zone (EEZ) and revenue from it extending around Norfolk Island equating to roughly , and territorial sea claims to from the island. There is a strong belief on the island that some of the revenue generated from Norfolk's EEZ should be available to provide services such as health and infrastructure on the island, which the island has been responsible for, similar to how the Northern Territory is able to access revenue from their mineral resources. The exclusive economic zone provides the Islanders with fish, its only major natural resource. Norfolk Island has no direct control over any marine areas but has an agreement with the Commonwealth through the Australian Fisheries Management Authority (AFMA) to fish "recreationally" in a small section of the EEZ known locally as "the Box". While there is speculation that the zone may include oil and gas deposits, this is not proven. There are no major arable lands or permanent farmlands, though about 25 percent of the island is a permanent pasture. There is no irrigated land. The island uses the Australian dollar as its currency.

In 2015 a company in Norfolk Island was granted a licence to export medicinal cannabis. The medicinal cannabis industry has been viewed by some as a means of reinvigorating the economy of Norfolk Island. The Commonwealth stepped in to overturn the decision, with the island's administrator, former Liberal MP Gary Hardgrave revoking the local licence to grow the crop. Legislation to allow the cultivation of cannabis in Australia for medical or scientific purposes passed Federal Parliament in February. The Victorian Government will be undertaking a small-scale, strictly controlled cannabis cultivation trial at a Victorian research facility.

Formerly, residents of Norfolk Island did not pay Australian federal taxes, which created a tax haven for locals and visitors alike. There was no income tax so the island's legislative assembly raised money through an import duty, fuel levy, medicare levy, goods and services tax of 12%, and local/international phone calls. The Chief Minister of Norfolk Island, David Buffett, announced on 6 November 2010 that the island would voluntarily surrender its tax-free status in return for a financial bailout from the federal government to cover significant debts. The introduction of income taxation came into effect on 1 July 2016. There is a variation of opinion on the island about these changes but with many understanding that for the island's governance to continue there is a need to pay into the commonwealth revenue pool in order for the island to have assistance in supporting its delivery of State government responsibilities such as health, education, Medicare, and infrastructure. Prior to these reforms, residents of Norfolk Island were not entitled to social services. It appears that the reforms do extend to companies and trustees and not only individuals.

, telephone main lines are in use, a mix of analog () and digital () circuits. Satellite communications services are planned. The island has a locally based radio station (Radio Norfolk), broadcasting on both AM and FM frequencies. There is also one television station, Norfolk TV, featuring local programming, plus transmitters for Australian channels ABC, SBS, Imparja Television and Seven. The Internet country code top-level domain (ccTLD) is .nf. A small GSM mobile network operates on the island across 3 towers, however no data transmission is available on this network. An 8-tower 4G/LTE 1800 MHz network has recently been installed improving Data service significantly on the island.

There are no railways, waterways, ports or harbours on the island. Loading jetties are located at Kingston and Cascade, but ships cannot get close to either of them. When a supply ship arrives, it is emptied by whaleboats towed by launches, five tonnes at a time. A mobile crane picks up the freight using nets and straps and lifts the freight onto the pier. Which jetty is used depends on the prevailing weather of the day; the jetty on the leeward side of the island is often used. If the wind changes significantly during unloading/loading, the ship will move around to the other side. Visitors often gather to watch the activity when a supply ship arrives. Norfolk Forwarding Services is the primary Freight Forwarding service for Norfolk Island handling both sea and airfreight. In 2017 Norfolk Forwarding Services shipped most of the freight for the Cascade Pier Project over a period of 18 months. 

There is one airport, Norfolk Island Airport. There are of roads on the island, paved and unpaved. Local law gives cows the right of way. Speed limits are low: maximum in the territory, in town and near schools. There was formerly an airline, Norfolk Island Airlines, which connected Norfolk Island with Brisbane. As of March 2018, there are no direct flights from New Zealand to Norfolk Island, leaving only services via Sydney and Brisbane. In mid 2018, Air Chathams announced it was looking to re-establish flights between Auckland and Norfolk Island and in August 2019 announced a weekly service between Auckland and Norfolk Island would begin on 6 September using a Convair 580.


Teams that Norfolk Island players qualify for:





 Government

General information

Archaeology and Polynesian settlement in prehistory

Others


</doc>
<doc id="21423" url="https://en.wikipedia.org/wiki?curid=21423" title="History of Norfolk Island">
History of Norfolk Island

The history of Norfolk Island dates back to the fourteenth or fifteenth century when it was settled by Polynesian seafarers.

Norfolk Island was first settled by East Polynesian seafarers either from the Kermadec Islands north of New Zealand or from the North Island of New Zealand. They arrived in the fourteenth or fifteenth century, and survived for several generations before disappearing. Their main village site has been excavated at Emily Bay, and they also left behind stone tools, the Polynesian rat, and banana trees as evidence of their sojourn. The "harakeke" ("Phormium tenax"), or New Zealand flax plant, was brought to Norfolk Island either from New Zealand directly or from Raoul Island (Sunday Island) by these Polynesian settlers. The so-called flax is, in fact, no relation of the European flax but is related to the daylily and other genera within the sub-family "Hemerocallidaceae". The final fate of the early settlers remains a mystery.

The first European known to have sighted the island was Captain James Cook, in 1774, on his second voyage to the South Pacific on HMS "Resolution". He named it after the Duchess of Norfolk (c. 1712 – 1773). The Duchess was dead at the time of the island's sighting by Cook, but Cook had set out from England in 1772 and could not have known of her May 1773 death.

Cook went ashore on Tuesday 11 October 1774, and is said to have been impressed with the tall straight trees and New Zealand flax plants, which, although not related to the Northern Hemisphere flax plants after which they are named, produce fibres of economic importance. He took samples back to Britain and reported on their potential uses for the Royal Navy.

Andrew Kippis as the biographer of this voyage puts it as follows:
At the time, Britain was heavily dependent on flax ("Linum usitatissimum") (for sails) and hemp ("Cannabis" sp.) (for ropes) from the shores of the Baltic Sea ports. Any threat to their supply endangered Britain's sea power. The UK also relied on timbers from New England for mainmasts, and these were not supplied after the American War of Independence. The alternative source of Norfolk Island for these, (or in the case of flax and hemp, similar) supplies is argued by some historians, notably Geoffrey Blainey in "", as being a major reason for the founding of the convict settlement of New South Wales by the First Fleet in 1788.

James Cook said that, "except for New Zealand, in no other island in the South Sea was wood and mast-timber so ready to hand".

Sir John Call, member of Parliament and the Royal Society, and former chief engineer of the East India Company, stated the advantages of Norfolk Island in a proposal for colonisation he put to the Home Office in August 1784: "This Island has an Advantage not common to New Caledonia, New Holland and New Zealand by not being inhabited, so that no Injury can be done by possessing it to the rest of Mankind…there seems to be nothing wanting but Inhabitants and Cultivation to make it a delicious Residence. The Climate, Soil, and Sea provide everything that can be expected from them. The Timber, Shrubs, Vegetables and Fish already found there need no Embellishment to pronounce them excellent samples; but the most invaluable of all is the Flax-plant, which grows more luxuriant than in New Zealand."

George Forster, who had been on Cook's second voyage to the Pacific and had been with him when he landed on Norfolk Island, was at the time professor of natural history at the University of Vilna (or Vilnius) in Polish Lithuania: Forster discussed the proposed Botany Bay colony in an article written in November 1786, "Neuholland, und die brittische Colonie in Botany Bay". Though unaware of the British intention to settle Norfolk Island, which was not announced until 5 December 1786, Forster referred to "the nearness of New Zealand; the excellent flax plant ("Phormium") that grows so abundantly there; its incomparable shipbuilding timber", as among the advantages of the new colony.

The proposal written by James Matra under the supervision of Sir Joseph Banks for establishing a settlement in New South Wales, stated that Botany Bay was: “no further than a fortnight from New Zealand, which is covered with timber even to the water's edge. The trees are so big and tall that a single tree is enough to make a mast of a first rate man of war. New Zealand produces in addition flax, which is an object equally of utility and curiosity. Any quantity of it might be raised in the colony, as this plant grows naturally in New Zealand. It can be made to serve the various purposes of cotton, hemp and linen, and is easier manufactured than any of them. In naval affairs, it could not fail of being of the utmost consequence; a cable of ten inches (250 mm) being supposed to be of equal strength and durability to one of European hemp of eighteen inches.

In 1786 the British government included Norfolk Island as an auxiliary settlement, as proposed by John Call, in its plan for colonisation of New South Wales. The flax and ship timber of New Zealand were attractive, but these prospective advantages were balanced by the obvious impossibility of forming a settlement there in the face of undoubted opposition from the native Maori. There was no native population to oppose a settlement on Norfolk Island, which also possessed those desirable natural resources, but the island was too small of itself to sustain a colony. Hence the ultimate decision for a dual colonisation along the lines proposed by Call.

The decision to settle Norfolk Island was taken under the impetus of the shock Britain had just received from Empress Catherine II of Russia. Practically all the hemp and flax required by the Royal Navy for cordage and sailcloth was imported from the Russian dominions through the ports of St. Petersburg (Kronstadt) and Riga. Comptroller of the Navy Sir Charles Middleton explained to Prime Minister Pitt in a letter of 5 September 1786: "It is for Hemp only we are dependent on Russia. Masts can be procured from Nova Scotia, and Iron in plenty from the Ores of this Country; but as it is impracticable to carry on a Naval War without Hemp, it is materially necessary to promote the growth of it in this Country and Ireland". In the summer of 1786, the Empress Catherine, in the context of tense negotiations on a renewed treaty of commerce, had emphasised her control over this vital commodity by asking the merchants who supplied it to restrict sales to English buyers: “the Empress has contrary to Custom speculated on this Commodity”, complained the author of a subsequent memorandum to the Home Secretary. “It is unnecessary”, said the memorandum, “to remark the Consequences which might result from a prohibition of supply from that Quarter altogether”. This implicit threat to the viability of the Royal Navy became apparent in mid-September (a month after the decision had been taken to settle Botany Bay) and caused the Pitt Administration to begin an urgent search for new sources of supply, including from Norfolk Island, which was then added to the plan to colonise New South Wales.

The need for an alternative non-Russian source of naval stores is indicated by the information from the British Ambassador in Copenhagen, Hugh Elliott, who wrote to Foreign Secretary, Lord Carmarthen on 12 August 1788: “There is no Topick so common in the Mouths of the Russian Ministers, as to insist on the Facility with which the Empress, when Mistress of the Baltic, either by Conquest, Influence, or Alliance with the other two Northern Powers, could keep England in a State of Dependence for its Baltic Commerce and Naval Stores”.

On 6 December 1786, an Order in Council was issued, designating "the Eastern Coast of New South Wales, or some one or other of the Islands adjacent" as the destination for transported convicts, as required by the Transportation Act of 1784 (24 Geo.III, c.56) that authorised the sending of convicted felons to any place appointed by the King in Council. Norfolk Island was thereby brought officially within the bounds of the projected colony.

An article in "The Daily Universal Register" (the forerunner of "The Times") of 23 December 1786 revealed the plan for a dual colonisation of Norfolk Island and Botany Bay: “The ships for Botany Bay are not to leave all the convicts there; some of them are to be taken to Norfolk Island, which is about eight hundred miles East of Botany Bay, and about four hundred miles short of New Zealand”.

The advantage of Britain's new colony in providing a non-Russian source of flax and hemp for naval supplies was referred to in an article in "Lloyd’s Evening Post" of 5 October 1787 which urged: “It is undoubtedly the interest of Great-Britain to remain neutral in the present contest between the Russians and the Turks” and observed, “Should England cease to render her services to the Empress of Russia, in a war against the Turks, there can be little of nothing to fear from her ill-will. England will speedily be enabled to draw from her colony of New South Wales, the staple of Russia, hemp and flax.”

Before the First Fleet sailed to found a convict settlement in New South Wales, Governor Arthur Phillip's final instructions, received less than three weeks before sailing, included the requirement to colonise Norfolk Island to prevent it falling into the hands of France, whose naval leaders were also showing interest in the Pacific.

Phillip's instructions given to him in April 1787 included an injunction to send a party to secure Norfolk Island "as soon as Circumstances may admit of it…. to prevent its being occupied by the Subjects of any other European Power". This could only have been a reference to the expedition then in the Pacific commanded by Jean-François de Galaup, comte de La Pérouse. "The Daily Universal Register" of 11 November 1786 had stated: "the Botany Bay scheme is laid aside, as there is a strong presumption that a squadron from Brest are now, or soon will be, in possession of the very spot we meant to occupy in New Holland". This may have been a reference to a report from the British Ambassador in Paris, who had believed that when La Pérouse's expedition set out from Brest in August 1785 it had as one of its objectives the establishment of a settlement in New Zealand to forestall the British.

La Pérouse did attempt to visit Norfolk Island, but only to investigate, not to take possession. He had instructions to investigate any colonies the British may have established and learned of the intention to settle Botany Bay and Norfolk Island from despatches sent to him from Paris through St. Petersburg and by land across Siberia to Petropavlovsk in Kamchatka, where he received them on 26 September 1787, just four days before his departure from that port. His ships, the "Boussole" and "Astrolabe", anchored off the northern side of the island on 13 January 1788, but at the time high seas were running that made it too dangerous for the two ships’ boats that were put out to attempt a landing: “It was obvious that I would have had to wait maybe for a very long time for a moment suitable for a landing and a visit to this island was not worth this sacrifice”, he recorded in his journal. Having noted that the island was still uninhabited, he was presumably the less inclined to risk a landing when there was no British settlement there to report on.

When the First Fleet arrived at Port Jackson in January 1788, Phillip ordered Lieutenant Philip Gidley King to lead a party of 15 convicts and seven free men, including surgeon Thomas Jamison (the future Principal Surgeon of New South Wales), to take control of the island and prepare for its commercial development. They arrived on 6 March 1788.

During the first year of the settlement, which was also called "Sydney" like its parent, more convicts and soldiers were sent to the island from New South Wales. A second village was started at Ball Bay, named after the captain of "HMS Supply", Lieutenant Henry Lidgbird Ball. On 8 January 1789, the first child was born, Norfolk King, the son of Philip Gidley King and a convict, Ann Inett. (Norfolk King went on to become the first British Naval officer born in Australia, and was a Lieutenant, commanding the schooner "Ballahoo" when an American privateer captured her.)

A "Letter from an Officer of Marines at New South Wales, 16 November 1788", published in the London newspaper, "The World," 15 May 1789, reported the glowing description of the island and its prospects by Philip Gidley King, but also drew attention to the fatal defect of the lack of a safe port: “The said Island lies near Port Jackson, and is nearly as large as the Isle of Wight. Lieutenant King, who was sent with a detachment of marines and some convicts, to settle there, gives the most flattering portrayal of it. The island is fully wooded. Its timber is in the opinion of everyone the most beautiful and finest in the world...they are most suitable for masts, yards, spars and such. The New Zealand flax-plant grows there in abundance. European grains and seeds also thrive wonderfully well on Norfolk Island. It only lacks a good port and suitable landing places, without which the island is of no use, but with them it would be of the greatest importance for Great Britain. How far these deficiencies can be improved by art and the hand of man, time must decide.”

An idealised vision of the new British settlement was given in the novel by Therese Forster, "Abentheuer auf einer Reise nach Neu-Holland [Adventures on a Voyage to New Holland]," published in the German women's magazine, "Flora" for 1793 and 1794:
We went towards the centre of this small island where at the foot of a round hill a crystal-clear river rushes forth, dividing up further on into several arms. Towards North and West the hill is covered with the most beautiful ploughed fields all the way down to the sea. The sight of these great flax fields is one of the loveliest I ever beheld. The slender stalks, of the most beautiful green and reaching far above a man's head, bent in the gentle breeze that blew from the sea. Their red blossoms, shining like rubies, danced in the green waves. The top of the hill and the whole of the south and east sides are covered with enormous pines whose dark green is enhanced by a pleasant foreground of cabbage palms and banana trees, and I also observed a low bush among them the fruit of which resembles our red currants but is much larger and hangs in purple and red clusters that help to give the whole a gay appearance. The dwellings of the colonists are strewn along the fringes of the forest and from my post I could see several of them. Simple houses surrounded by barns and stalls and the fields all enclosed with hedges give the region a youthful appearance the like of which is rarely found in Europe. And plants here bloom more luxuriantly and more perfectly with a natural vigour that knows no exhaustion and fears no poverty, a vigour that has disappeared from our continent.
It was soon found that the flax was difficult to prepare for manufacturing and no one had the necessary skills. An attempt was made to bring two Māori men to teach the skills of dressing and weaving flax, but this failed when it was discovered that weaving was considered women's work and the two men had little knowledge of it. The pine timber was found to be not resilient enough for masts and this industry was also abandoned.

More convicts were sent, and the island was seen as a farm, supplying Sydney with grain and vegetables during its early years of near-starvation. However, crops often failed due to the salty wind, rats, and caterpillars. The lack of a natural safe harbour hindered communication and the transport of supplies and produce.

Manning Clark observed that "at first the convicts behaved well, but as more arrived from Sydney Cove, they renewed their wicked practices". These included an attempted overthrow of King in January 1789 by convicts described by Margaret Hazzard as "incorrigible rogues who took his 'goodwill' for weakness". While some convicts responded well to the opportunities offered to become respectable, most remained "idle and miserable wretches" according to Clark, despite the climate and their isolation from previous haunts of crime.

The impending starvation at Sydney led to a great transplantation of convicts and marines to Norfolk Island in March 1790 on HMS "Sirius". This attempt to relieve the pressure on Sydney turned to disaster when "Sirius" was wrecked and, although there was no loss of life, some stores were destroyed, and the ship's crew was marooned for ten months. This news was met in Sydney with "unspeakable consternation". Norfolk Island was now further cut off from Sydney which, with the arrival of the Second Fleet with its cargo of sick and abused convicts, had more pressing problems with which to contend.

In spite of this the settlement grew slowly as more convicts were sent from Sydney. Many convicts chose to remain as settlers on the expiry of their sentence, and the population grew to over 1,000 by 1792. Norfolk Island in 1793 was described by Josef Espinosa y Tello, an officer of the Spanish expedition led by Alessandro Malaspina that visited New South Wales. 

The colony of Norfolk, settled shortly after that at Port Jackson, merits little attention both because of the small size of that island and because of the hilly nature of its terrain, and the particular circumstance of its lacking entirely an anchorage or a place where longboats can be drawn up with any security. Despite this, some 1,500 persons live there, and its fertile soil produces copiously all kinds of grains, although the difficulty of clearing the ground covered with trees and undergrowth retards the large harvests which the fertility of the land would yield without that obstacle. The pines are of a prodigious height, straight, thick and of the finest grain, and several have been felled of above 7 feet in diameter at the foot, six at 17 and five at 37 yards, having 147 feet of height in total and 120 to the first branches. The flax brought there from New Zealand bears a good aspect, but no great hopes are rested on its cultivation, and it seems that the second trials of this plant made in London have not achieved the happy outcome of the first.

Norfolk Island was governed by a succession of short-term commandants for the next 11 years, starting with King's replacement, Robert Ross 1789–1790. When Joseph Foveaux arrived as Lieutenant Governor in 1800, he found the settlement quite run down, little maintenance having been carried out in the previous four years, and he set about building it up, particularly through public works and attempts to improve education.

As early as 1794, Lieutenant-Governor of New South Wales Francis Grose suggested its closure as a penal settlement as it was too remote and difficult for shipping, and too costly to maintain. By 1803, the Secretary of State, Lord Hobart, called for the removal of part of the Norfolk Island military establishment, settlers and convicts to Van Diemen's Land, due to its great expense and the difficulties of communication between Norfolk Island and Sydney. This was achieved more slowly than anticipated, due to reluctance of settlers to uproot themselves from the land they had struggled to tame, and compensation claims for loss of stock. It was also delayed by King's insistence on its value for providing refreshment to the whalers. The first group of 159 left in February 1805 and comprised mainly convicts and their families and military personnel, only four settlers departing. Between November 1807 and September 1808, five groups of 554 people departed. Only about 200 remained, forming a small settlement until the remnants were removed in 1813. A small party remained to slaughter stock and destroy all buildings so that there would be no inducement for anyone, especially from another European power, to visit that place.

From 15 February 1814 to 6 June 1825 the island lay abandoned.

In 1824 the British government instructed the Governor of New South Wales Thomas Brisbane to occupy Norfolk Island as a place to send "the worst description of convicts". Its remoteness, seen previously as a disadvantage, was now viewed as an asset for the detention of the "twice-convicted" men, who had committed further crimes since arriving in New South Wales. Brisbane assured his masters that "the felon who is sent there is forever excluded from all hope of return" He saw Norfolk Island as "the nec plus ultra of Convict degradation". The convicts detained have long been assumed be a hardcore of recidivists, or 'doubly-convicted capital respites' – that is, men transported to Australia who committed fresh colonial crimes for which they were sentenced to death, and were spared the gallows on condition of life at Norfolk Island. However, a recent study has demonstrated, utilising a database of 6,458 Norfolk Island convicts, that the reality was somewhat different: more than half were detained at Norfolk Island without ever receiving a colonial conviction, and only 15% had been reprieved from a death sentence. Furthermore, the overwhelming majority of convicts sent to Norfolk Island had committed non-violent property sentences, the average length of detention was three years, and the scale of punishments inflicted upon the prisoners was significantly less than assumed.

His successor, Governor Ralph Darling, was even more severe than Brisbane, wishing that "every man should be worked in irons that the example may deter others from the commission of crime" and "to hold out [Norfolk Island] as a place of the extremest punishment short of death". Governor Arthur, in Van Diemen's Land, likewise believed that "when prisoners are sent to Norfolk Island, they should on no account be permitted to return. Transportation thither should be considered as the ultimate limit and a punishment short only of death". Reformation of the convicts was not seen as an objective of the Norfolk Island penal settlement.

The evidence that has passed down through the years points to the creation of a "Hell in Paradise". A widespread and popular notion of the harshness of penal settlements, including Norfolk Island, has come from the novel "For the Term of his Natural Life" by Marcus Clarke, which appears to be based on the writings and recollections of witnesses. However, though Clarke did carry out primary research, he selected the most sensational examples possible.

Following a convict mutiny in 1834, Father William Ullathorne, Vicar general of Sydney, visited Norfolk Island to comfort the mutineers due for execution. He found it "the most heartrending scene that I ever witnessed". Having the duty of informing the prisoners as to who was reprieved and who was to die, he was shocked to record as "a literal fact that each man who heard his reprieve wept bitterly, and that each man who heard of his condemnation to death went down on his knees with dry eyes, and thanked God.”

The 1846 report of magistrate Robert Pringle Stuart exposed the scarcity and poor quality of food, inadequacy of housing, horrors of torture and incessant flogging, insubordination of convicts, and corruption of overseers.

Bishop Robert Willson visited Norfolk Island from Van Diemen's Land on three occasions. Following his first visit in 1846 he reported to the House of Lords who, for the first time, came to realise the enormity of atrocities perpetrated under the British flag and attempted to remedy the evils. Willson returned in 1849 and found that many of the reforms had been implemented. However, rumours of resumed atrocities brought him back in 1852, and this visit resulted in a damning report, listing atrocities and blaming the system, which invested one man at this remote place with absolute power over so many people.

Only a handful of convicts left any written record and their descriptions (as quoted by Hazzard and Hughes) of living and working conditions, food and housing, and, in particular, the punishments given for seemingly trivial offences, are unremittingly horrifying, describing a settlement devoid of all human decency, under the iron rule of the tyrannical autocratic commandants. However, these conclusions have been reached by a reliance on a series of over-used (mainly published) sources, without their having been tested or drawn into question by detailed archival research. Such work is currently being done and has, for example, drawn into question the sensationalised version of Norfolk Island's past, such as in demonstrating that the widespread assumption that Norfolk Island convicts engaged in 'murder-suicide pacts' – that is, drawing lots to select a killer and willing victim to 'escape' from Norfolk Island – is a myth.

The actions of some of the commandants, such as Morisset and particularly Price appear to be excessively harsh. All but one were military officers, brought up in a system where discipline was severe throughout the period of transportation. In addition, the commandants relied on a large number of military guards, civil overseers, ex-convict constables, and convict informers to provide them with intelligence and carry out their orders.

Of the Commandants, only Alexander Maconochie appeared to reach the conclusion that brutality would breed defiance, as demonstrated by the mutinies of 1826, 1834 and 1846, and he attempted to apply his theories of penal reform, providing incentives as well as punishment. His methods were criticised as being too lenient and he was replaced, a move that returned the settlement to its harsh rule. However, recent research has also demonstrated that the level of punishment under Maconochie's regime was much higher than assumed, as the average number of lashes per flogging – 93 – was higher under Maconochie than at any other time during the second penal settlement's history.

The second penal settlement began to be wound down by the British government after 1847 and the last convicts were removed to Tasmania in May 1855. It was abandoned because transportation to Van Diemen's Land had ceased in 1853 and was replaced by penal servitude in the United Kingdom.

On 8 June 1856, the next settlement began on Norfolk Island. These were the descendants of Tahitians and the HMS "Bounty" mutineers, resettled from the Pitcairn Islands, which had become too small for their growing population. The British government had permitted the transfer of the Pitcairners to Norfolk, which was thus established as a colony separate from New South Wales but under the administration of that colony's governor. They left Pitcairn Islands on 3 May 1856 and arrived with 194 persons on 8 June.

The Pitcairners occupied many of the buildings remaining from the penal settlements, and gradually established their traditional farming and whaling industries on the island. Although some families decided to return to Pitcairn in 1858 and 1863, the island's population continued to slowly grow as the island accepted settlers, often arriving with whaling fleets.

In 1867, the headquarters of the Melanesian Mission of the Church of England were established on the island, and in 1882 the church of St. Barnabas was erected to the memory of the Mission's head Bishop John Coleridge Patteson, with windows designed by Edward Burne-Jones and executed by William Morris. In 1920 the Mission was relocated from the island to the Solomon Islands to be closer to its target population.

After the creation of the Commonwealth of Australia in 1901, Norfolk Island was placed under the authority of the new Commonwealth government to be administered as an external territory.

During World War II, the island became a key airbase and refuelling depot between Australia and New Zealand, and New Zealand and the Solomon Islands. Since Norfolk Island fell within New Zealand's area of responsibility it was garrisoned by a New Zealand Army unit known as N Force at a large Army camp which had the capacity to house a 1,500 strong force. N Force relieved a company of the Second Australian Imperial Force. The island proved too remote to come under attack during the war and N Force left the island in February 1944.

In the late 1960s a mini-invasion by British ex-pats followed after the island was featured on a BBC television documentary presented by Alan Whicker. Fifty families decided to emigrate from the United Kingdom to Norfolk Island as a result of the programme.

In 1979, Norfolk was granted limited self-government by Australia, under which the island elects a government that runs most of the island's affairs. As such, residents of Norfolk Island are not represented in the Commonwealth Parliament of Australia, making them the only group of residents of an Australian state or territory not represented there.

In 2006, a formal review process took place, in which the Australian government considered revising this model of government. The review was completed on 20 December 2006, when it was decided that there would be no changes in the governance of Norfolk Island.


</doc>
<doc id="21426" url="https://en.wikipedia.org/wiki?curid=21426" title="Politics of Norfolk Island">
Politics of Norfolk Island

Politics of Norfolk Island takes place in a framework of a parliamentary representative democratic entity. Norfolk Island is the only non-mainland Australian territory to have achieved self-governance. The Norfolk Island Act 1979, passed by the Parliament of Australia in 1979, is the Act under which the island is governed.

In a move that apparently surprised many islanders the Chief Minister of Norfolk Island David Buffett announced on 6 November 2010 that the island would voluntarily surrender its tax free status in return for a financial bailout from the federal government to cover significant debts.

It was announced on 19 March 2015 that self-governance for the island would be revoked by the Commonwealth and replaced by a local council with the state of New South Wales providing services to the island. A reason given was that the island had never gained self-sufficiency and was being heavily subsidised by the Commonwealth, by $12.5 million in 2015 alone. It meant residents would have to start paying Australian income tax, but they would also be covered by Australian welfare schemes such as Medicare.

The Norfolk Island Legislative of Assembly decided to hold a referendum on the proposal, to be held on 8 May 2015. Voters were asked if Norfolk Islanders should freely determine their political status, their economic, social and cultural development, and to "be consulted at referendum or plebiscite on the future model of governance for Norfolk Island before such changes are acted upon by the Australian parliament."

The outcome of the referendum echoed a resounding 'Yes' with 68% of the vote confirming that Norfolk Islanders should have the right to determine their political and cultural development freely and not have it imposed upon them. The Norfolk Island Chief Minister said that "the referendum results blow a hole in Canberra's assertion that the reforms introduced before the Australian Parliament that propose abolishing the Legislative Assembly and Norfolk Island Parliament were overwhelmingly supported by the people of Norfolk Island". 

The Norfolk Island Legislation Amendment Bill 2015 passed the Australian Parliament on 14 May 2015 (Assented on 26 May 2015) abolishing self-government on Norfolk Island and transferring Norfolk Island into a council as part of New South Wales law. From 1 July 2016 Norfolk Island legislation will be transferred to New South Wales and subject to NSW legislation.

From 1 July 2016, the Norfolk Island Regional Council was established to govern Norfolk Island at the local level as a local government area subject to the laws of New South Wales.

The Norfolk Island legislative Assembly was abolished on 1 July 2015 and replaced with the Australian Government maintaining authority on the island through an Administrator (currently Eric Hutchinson) who is appointed by the Governor-General of Australia. Two of the members of the Assembly would form the Executive Council, which devises policy and acts as an advisory body to the Administrator. This council would be headed by the Administrator of Norfolk Island.

Controversy exists as to the exact status of Norfolk Island. Despite the island's status as a self-governing territory of Australia, some Islanders claim that it was actually granted independence at the time Queen Victoria granted permission to Pitcairn Islanders to re-settle on the island. These views have been repeatedly rejected by the Australian parliament's joint committee on territories, most recently in 2004, and were also rejected by the High Court of Australia in "Berwick Ltd v Gray".

Disagreements over the island's relationship with Australia have been put in sharper relief by a 2006 review undertaken by the Australian government. Under the more radical of two proposed models proposed as a result of the review, the island's legislative assembly would be reduced to the status of a local council.

Residents of Norfolk Island who are citizens of Australia and meet the normal enrolment requirements are required to enrol to vote in Australian federal and once enrolled must vote. 393 people voted at the polling booths on Norfolk Island for the Canberra electorate at the 2016 Federal election, with 16.5% of votes being informal. 777 Norfolk Island residents were on the Commonwealth electoral roll , and 669 people voted at the booths on Norfolk Island in the 2019 Federal election in the newly created Bean electorate, with 17.8% of votes being informal. 

The election for the inaugural Norfolk Island Regional Council occurred on 28 May 2016, with the new council taking office on 1 July 2016. Three of the five councilors elected supported self-determination.

From 1 July 2016, Norfolk Island residents came under Australian levies, personal or business income and corporation taxation by the Australian Tax Office. Also both Centrelink and Medicare will apply to Norfolk Island. In addition, flights between mainland Australia and Norfolk Island became classified as domestic not international meaning a passport was no longer required by visiting Australian citizens. Despite New South Wales laws being applied on Norfolk Island, residents are not eligible to vote in New South Wales elections.

Some residents on Norfolk Island advocate independence from Australia. In 2013, Chief Minister Lisle Snell claimed that Norfolk Island could survive alone. He also told Radio Australia that 'Norfolk-Pitcairn people see themselves as a people with some rights to self-determination' that the Island's future relationship with Australia was not clear, but also stated that for the time being they need to integrate further with Australia for financial reasons.

As a territory of Australia, Norfolk Island does not have diplomatic representation abroad or within the territory. It is however a full participant in the Commonwealth Parliamentary Association (an international organisation) and a member in its own right of a number of international sporting organisations (e.g. the Commonwealth Games).


</doc>
<doc id="21433" url="https://en.wikipedia.org/wiki?curid=21433" title="New Testament">
New Testament

The New Testament (, transl. ; ) is the second division of the Christian biblical canon, the first being the Old Testament which is based primarily upon the Hebrew Bible. The New Testament discusses the teachings and person of Jesus, as well as events in first-century Christianity. Christians regard both the Old and New Testaments together as sacred scripture.

The New Testament is a collection of Christian texts originally written in the Koine Greek language, at different times by various different authors. While the Old Testament canon varies somewhat between different Christian denominations, the 27-book canon of the New Testament has been almost universally recognized within Christianity since at least Late Antiquity. Thus, in almost all Christian traditions today, the New Testament consists of 27 books: 

The earliest known complete list of the 27 books of the New Testament is found in a letter written by Athanasius, a 4th-century bishop of Alexandria, dated to 367 AD. The 27-book New Testament was first formally canonized during the councils of Hippo (393) and Carthage (397) in North Africa. Pope Innocent I ratified the same canon in 405, but it is probable that a Council in Rome in 382 under Pope Damasus I gave the same list first. These councils also provided the canon of the Old Testament, which included the apocryphal books.

There is no scholarly consensus on the date of composition of the latest New Testament texts. Conservative scholars John A. T. Robinson, Dan Wallace, and William F. Albright dated all the books of the New Testament before 70 AD. But most scholars date some New Testament texts much later than this. For example, Richard Pervo dates Luke-Acts to c. AD 115, and David Trobisch places Acts in the mid- to late second century, contemporaneous with the publication of the first New Testament canon.

The word '"testament"' in the expression New Testament refers to a new "'covenant"' or alliance that Christians believe God makes with the people of Israel, described in the books of the New Testament, which completes or fulfils what Christians refer to as the 'old' covenant of God with the people of Israel made on Mount Sinai through Moses, described in the books of the Old Testament. Christians traditionally view this new covenant as being prophesized in the Hebrew Bible's book of Jeremiah (31:31): "The days are coming, declares the LORD, when I will make a "new covenant" with the people of Israel and with the people of Judah."

The word "covenant" means 'agreement' (from Latin "con-venio" 'to agree' lit. 'to come together'): the use of the word "testament", which describes the different idea of written instructions for inheritance after death, to refer to the covenant with Israel in the Old Testament, is foreign to the original Hebrew word "brit" (בְּרִית) describing it, which only means 'alliance, covenant, pact' and never 'inheritance instructions after death'. This use comes from the transcription of Latin "testamentum" 'will (left after death)', a literal translation of Greek "diatheke" (διαθήκη) 'will (left after death)', which is the word used to translate Hebrew "brit" in the Septuagint.

The choice of this word "diatheke", by the Jewish translators of the Septuagint in Alexandria in the 3rd and 2nd century BCE, has been understood in Christian theology to imply a reinterpreted view of the Old Testament covenant with Israel as of a 'will left after death' (the death of Jesus) and has generated considerable attention from biblical scholars and theologians: in contrast to the Jewish usage where "brit" was the usual Hebrew word used to refer to pacts, alliances and covenants in general, like a common pact between two individuals, and to the one between God and Israel in particular, in the Greek world "diatheke" was virtually never used to refer to an alliance or covenant (one exception is noted in a passage from Aristophanes) and referred instead to a will left after the death of a person. There is scholarly debate as to the reason why the translators of the Septuagint chose the term "diatheke" to translate Hebrew "brit", instead of another Greek word generally used to refer to an alliance or covenant.

The use of the phrase "New Testament" (Koine Greek: , ) to describe a collection of first and second-century Christian Greek scriptures can be traced back to Tertullian in his work "Against Praxeas". Irenaeus uses the phrase "New Testament" several times, but does not use it in reference to any written text. In "Against Marcion", written c. 208 AD, Tertullian writes of:
And Tertullian continues later in the book, writing:
By the 4th century, the existence—even if not the exact contents—of both an Old and New Testament had been established. Lactantius, a 3rd–4th century Christian author wrote in his early-4th-century Latin "Institutiones Divinae" ("Divine Institutes"):
Eusebius describes the collection of Christian writings as "covenanted" (ἐνδιαθήκη) books in "Hist. Eccl." 3.3.1–7; 3.25.3; 5.8.1; 6.25.1.

Each of the four gospels in the New Testament narrates the life, death, and resurrection of Jesus of Nazareth, with the exception of Mark which in the original text ends with the empty tomb and has no account of the post-resurrection appearances. The word "gospel" derives from the Old English "gōd-spell" (rarely "godspel"), meaning "good news" or "glad tidings". The gospel was considered the "good news" of the coming Kingdom of Messiah, and the redemption through the life and death of Jesus, the central Christian message. Gospel is a calque (word-for-word translation) of the Greek word , "euangelion" ("eu-" "good", "-angelion" "message").

Starting in the late second century, the four narrative accounts of the life and work of Jesus Christ have been referred to as "The Gospel of ..." or "The Gospel according to ..." followed by the name of the supposed author. The first author to explicitly name the canonical gospels is Irenaeus of Lyon, who promoted the four canonical gospels in his book Against Heresies, written around 180. Whatever these admittedly early ascriptions may imply about the sources behind or the perception of these gospels, they are anonymous compositions.

The first three gospels listed above are classified as the Synoptic Gospels. They contain similar accounts of the events in Jesus's life and his teaching, due to their literary interdependence. The Gospel of John is structured differently and includes stories of several miracles of Jesus and sayings not found in the other three.

These four gospels that were eventually included in the New Testament were only a few among many other early Christian gospels. The existence of such texts is even mentioned at the beginning of the Gospel of Luke. Other early Christian gospels, such as the so-called "Jewish-Christian Gospels" or the Gospel of Thomas, also offer both a window into the context of early Christianity and may provide some assistance in the reconstruction of the historical Jesus.
The Acts of the Apostles is a narrative of the apostles' ministry and activity after Christ's death and resurrection, from which point it resumes and functions as a sequel to the Gospel of Luke. Examining style, phraseology, and other evidence, modern scholarship generally concludes that Acts and the Gospel of Luke share the same author, referred to as Luke–Acts. Luke-Acts does not name its author. Church tradition identified him as Luke the Evangelist, the companion of Paul, but the majority of scholars reject this due to the many differences between Acts and the authentic Pauline letters. The most probable date of composition is around 80–100 AD, although some scholars date it significantly later, and there is evidence that it was still being substantially revised well into the 2nd century.

The epistles of the New Testament are considered by Christians to be divinely inspired and holy letters, written by the apostles and disciples of Christ, to either local congregations with specific needs, or to New Covenant Christians in general, scattered about; or "catholic epistles."

The Pauline letters to churches are the thirteen New Testament books that present Paul the Apostle as their author. Six of the letters are disputed. Four are thought by most modern scholars to be pseudepigraphic, i.e., not actually written by Paul even if attributed to him within the letters themselves. Opinion is more divided on the other two disputed letters (2 Thessalonians and Colossians). These letters were written to Christian communities in specific cities or geographical regions, often to address issues faced by that particular community. Prominent themes include the relationship both to broader "pagan" society, to Judaism, and to other Christians.
[Disputed letters are marked with an asterisk (*).]

The last four Pauline letters in the New Testament are addressed to individual persons. They include the following:
[Disputed letters are marked with an asterisk (*).]

All of the above except for Philemon are known as the Pastoral epistles. They are addressed to individuals charged with pastoral oversight of churches and discuss issues of Christian living, doctrine and leadership. They often address different concerns to those of the preceding epistles. These letters are believed by many to be pseudepigraphic. Some scholars (e.g., Bill Mounce, Ben Witherington) will argue that the letters are genuinely Pauline, or at least written under Paul's supervision.

The Epistle to the Hebrews addresses a Jewish audience who had come to believe that Jesus was the anointed one (Hebrew: מָשִׁיחַ—transliterated in English as "Moshiach", or "Messiah"; Greek: Χριστός—transliterated in English as "Christos", for "Christ") who was predicted in the writings of the Hebrew Scriptures. The author discusses the superiority of the new covenant and the ministry of Jesus, to the Mosaic covenant and urges the readers in the practical implications of this conviction through the end of the epistle.

The book has been widely accepted by the Christian church as inspired by God and thus authoritative, despite the acknowledgment of uncertainties about who its human author was. Regarding authorship, although the Epistle to the Hebrews does not internally claim to have been written by the Apostle Paul, some similarities in wordings to some of the Pauline Epistles have been noted and inferred. In antiquity, some began to ascribe it to Paul in an attempt to provide the anonymous work an explicit apostolic pedigree.

In the 4th century, Jerome and Augustine of Hippo supported Paul's authorship. The Church largely agreed to include Hebrews as the fourteenth letter of Paul, and affirmed this authorship until the Reformation. The letter to the Hebrews had difficulty in being accepted as part of the Christian canon because of its anonymity. As early as the 3rd century, Origen wrote of the letter, "Men of old have handed it down as Paul's, but who wrote the Epistle God only knows."

Contemporary scholars often reject Pauline authorship for the epistle to the Hebrews, based on its distinctive style and theology, which are considered to set it apart from Paul's writings.

The Catholic epistles (or "general epistles") consist of both letters and treatises in the form of letters written to the church at large. The term "catholic" (Greek: καθολική, "katholikē"), used to describe these letters in the oldest manuscripts containing them, here simply means "general" or "universal". The authorship of a number of these is disputed.

The final book of the New Testament is the Book of Revelation, also known as the Apocalypse of John. In the New Testament canon, it is considered prophetical or apocalyptic literature. Its authorship has been attributed either to John the Apostle (in which case it is often thought that John the Apostle is John the Evangelist, i.e. author of the Gospel of John) or to another John designated "John of Patmos" after the island where the text says the revelation was received (1:9). Some ascribe the writership date as circa 81–96 AD, and others at around 68 AD. The work opens with letters to seven local congregations of Asia Minor and thereafter takes the form of an apocalypse, a "revealing" of divine prophecy and mysteries, a literary genre popular in ancient Judaism and Christianity.


The order in which the books of the New Testament appear differs between some collections and ecclesiastical traditions. In the Latin West, prior to the Vulgate (an early 5th-century Latin version of the Bible), the four Gospels were arranged in the following order: Matthew, John, Luke, and Mark. The Syriac Peshitta places the major Catholic epistles (James, 1 Peter, and 1 John) immediately after Acts and before the Pauline epistles.

The order of an early edition of the letters of Paul is based on the size of the letters: longest to shortest, though keeping 1 and 2 Corinthians and 1 and 2 Thessalonians together. The Pastoral epistles were apparently not part of the "Corpus Paulinum" in which this order originated and were later inserted after 2 Thessalonians and before Philemon. Hebrews was variously incorporated into the "Corpus Paulinum" either after 2 Thessalonians, after Philemon (i.e. at the very end), or after Romans.

The New Testament of the 16th-century Luther Bible continues, to this day, to place Hebrews, James, Jude, and the Apocalypse last. This reflects the thoughts of the Reformer Martin Luther on the canonicity of these books.

The books that eventually found a permanent place in the New Testament were not the only works of Christian literature produced in the earliest Christian centuries. The long process of canonization began early, sometimes with tacit reception of traditional texts, sometimes with explicit selection or rejection of particular texts as either acceptable or unacceptable for use in a given context (e.g., not all texts that were acceptable for private use were considered appropriate for use in the liturgy).

Over the course of history, those works of early Christian literature that survived but that did not become part of the New Testament have been variously grouped by theologians and scholars. Drawing upon, though redefining, an older term used in early Christianity and among Protestants when referring to those books found in the Christian Old Testament although not in the Jewish Bible, modern scholars began to refer to these works of early Christian literature not included in the New Testament as "apocryphal", by which was meant non-canonical.

Collected editions of these works were then referred to as the "New Testament apocrypha". Typically excluded from such published collections are the following groups of works: The Apostolic Fathers, the 2nd-century Christian apologists, the Alexandrians, Tertullian, Methodius of Olympus, Novatian, Cyprian, martyrdoms, and the Desert Fathers. Almost all other Christian literature from the period, and sometimes including works composed well into Late Antiquity, are relegated to the so-called New Testament apocrypha.

Although not considered to be inspired by God, these "apocryphal" works were produced in the same ancient context and often using the same language as those books that would eventually form the New Testament. Some of these later works are dependent (either directly or indirectly) upon books that would later come to be in the New Testament or upon the ideas expressed in them. There is even an example of a pseudepigraphical letter composed under the guise of a presumably lost letter of the Apostle Paul, the Epistle to the Laodiceans.

The books of the New Testament were all or nearly all written by Jewish Christians—that is, Jewish disciples of Christ, who lived in the Roman Empire, and under Roman occupation. Luke, who wrote the Gospel of Luke and the Book of Acts, is frequently thought of as an exception; scholars are divided as to whether Luke was a Gentile or a Hellenistic Jew. A few scholars identify the author of the Gospel of Mark as probably a Gentile, and similarly for the Gospel of Matthew, though most assert Jewish-Christian authorship.

According to the large majority of critical scholars, none of the authors of the Gospels were eyewitnesses or even explicitly claimed to be eyewitnesses. Bart D. Ehrman of the University of North Carolina has argued for a scholarly consensus that many New Testament books were not written by the individuals whose names are attached to them. He further argues that names were not ascribed to the gospels until around 185 AD. Other scholars concur. Many scholars believe that none of the gospels were written in the region of Palestine.

Christian tradition identifies John the Apostle with John the Evangelist, the supposed author of the Gospel of John. Traditionalists tend to support the idea that the writer of the Gospel of John himself claimed to be an eyewitness in their commentaries of John 21:24 and therefore the gospel was written by an eyewitness; however, this idea is rejected by the majority of modern scholars.

Most scholars hold to the two-source hypothesis, which posits that the Gospel of Mark was the first gospel to be written. On this view, the authors of the Gospel of Matthew and the Gospel of Luke used as sources the Gospel of Mark and a hypothetical Q document to write their individual gospel accounts. These three gospels are called the Synoptic Gospels, because they include many of the same stories, often in the same sequence, and sometimes in exactly the same wording. Scholars agree that the Gospel of John was written last, by using a different tradition and body of testimony. In addition, most scholars agree that the author of Luke also wrote the Acts of the Apostles. Scholars hold that these books constituted two-halves of a single work, Luke-Acts.

All four gospels and the Acts of the Apostles are anonymous works. The Gospel of John claims to be based on eyewitness testimony from the Disciple whom Jesus loved, but never names this character.

The same author appears to have written the Gospel of Luke and the Acts of the Apostles, and most refer to them as the Lucan texts. The most direct evidence comes from the prefaces of each book; both were addressed to Theophilus, and the preface to the Acts of the Apostles references "my former book" about the ministry of Jesus. Furthermore, there are linguistic and theological similarities between the two works, suggesting that they have a common author.
The Pauline epistles are the thirteen books in the New Testament traditionally attributed to Paul of Tarsus. The anonymous Epistle to the Hebrews is, despite unlikely Pauline authorship, often functionally grouped with these thirteen to form a corpus of fourteen "Pauline" epistles.

Seven letters are generally classified as "undisputed", expressing contemporary scholarly near consensus that they are the work of Paul: Romans, 1 Corinthians, 2 Corinthians, Galatians, Philippians, 1 Thessalonians and Philemon. Six additional letters bearing Paul's name do not currently enjoy the same academic consensus: Ephesians, Colossians, 2 Thessalonians, 1 Timothy, 2 Timothy and Titus.

While many scholars uphold the traditional view, some question whether the first three, called the "Deutero-Pauline Epistles", are authentic letters of Paul. As for the latter three, the "Pastoral epistles", some scholars uphold the traditional view of these as the genuine writings of the Apostle Paul; most, however, regard them as pseudepigrapha.

One might refer to the Epistle to the Laodiceans and the Third Epistle to the Corinthians as examples of works identified as pseudonymous. Since the early centuries of the church, there has been debate concerning the authorship of the anonymous Epistle to the Hebrews, and contemporary scholars generally reject Pauline authorship.

The epistles all share common themes, emphasis, vocabulary and style; they exhibit a uniformity of doctrine concerning the Mosaic Law, Jesus, faith, and various other issues. All of these letters easily fit into the chronology of Paul's journeys depicted in Acts of the Apostles.

The author of the Epistle of James identifies himself in the opening verse as "James, a servant of God and of the Lord Jesus Christ". From the middle of the 3rd century, patristic authors cited the "Epistle" as written by James the Just. Ancient and modern scholars have always been divided on the issue of authorship. Many consider the epistle to be written in the late 1st or early 2nd centuries.

The author of the First Epistle of Peter identifies himself in the opening verse as "Peter, an apostle of Jesus Christ", and the view that the epistle was written by St. Peter is attested to by a number of Church Fathers: Irenaeus (140–203), Tertullian (150–222), Clement of Alexandria (155–215) and Origen of Alexandria (185–253). Unlike The Second Epistle of Peter, the authorship of which was debated in antiquity, there was little debate about Peter's authorship of this first epistle until the 18th century. Although 2 Peter internally purports to be a work of the apostle, many biblical scholars have concluded that Peter is not the author. For an early date and (usually) for a defense of the Apostle Peter's authorship see Kruger, Zahn, Spitta, Bigg, and Green.

The Epistle of Jude title is written as follows: "Jude, a servant of Jesus Christ and a brother of James" (NRSV). The debate has continued over the author's identity as the apostle, the brother of Jesus, both, or neither.

The Gospel of John, the three Johannine epistles, and the Book of Revelation, exhibit marked similarities, although more so between the gospel and the epistles (especially the gospel and 1 John) than between those and Revelation. Most scholars therefore treat the five as a single corpus of Johannine literature, albeit not from the same author.

The gospel went through two or three "editions" before reaching its current form around AD 90–110. It speaks of an unnamed "disciple whom Jesus loved" as the source of its traditions, but does not say specifically that he is its author; Christian tradition identifies this disciple as the apostle John, but while this idea still has supporters, for a variety of reasons the majority of modern scholars have abandoned it or hold it only tenuously. It is significantly different from the synoptic gospels, with major variations in material, theological emphasis, chronology, and literary style, sometimes amounting to contradictions.

The author of the Book of Revelation identifies himself several times as "John". and states that he was on Patmos when he received his first vision. As a result, the author is sometimes referred to as John of Patmos. The author has traditionally been identified with John the Apostle to whom the Gospel and the epistles of John were attributed. It was believed that he was exiled to the island of Patmos during the reign of the Roman emperor Domitian, and there wrote Revelation. Justin Martyr (c. 100–165 AD) who was acquainted with Polycarp, who had been mentored by John, makes a possible allusion to this book, and credits John as the source. Irenaeus (c. 115–202) assumes it as a conceded point. According to the "Zondervan Pictorial Encyclopedia of the Bible", modern scholars are divided between the apostolic view and several alternative hypotheses put forth in the last hundred years or so. Ben Witherington points out that linguistic evidence makes it unlikely that the books were written by the same person.

The earliest manuscripts of New Testament books date from the late second to early third centuries (although see Papyrus 52 for a possible exception). These manuscripts place a clear upper limit on the dating of New Testament texts. Explicit references to NT books in extra-biblical documents can push this upper limit down a bit further. Irenaeus of Lyon names and quotes from most of the books in the New Testament in his book "Against Heresies", written around 180 AD. The Epistle of Polycarp to the Philippians, written some time between 110 and Polycarp's death in 155-167 AD, quotes or alludes to most New Testament texts. Ignatius of Antioch wrote letters referencing much of the New Testament. He lived from about 35AD to 107AD and is rumored to have been a disciple of the Apostle John. His writings reference the Gospels of John, Matthew, and Luke, as well as Peter, James, and Paul's Epistles. His writing is usually attributed to the end of his lifetime, which places the Gospels as First Century writings.

Literary analysis of the New Testament texts themselves can be used to date many of the books of the New Testament to the mid- to late first century. The earliest works of the New Testament are the letters of the Apostle Paul. It can be determined that 1 Thessalonians is likely the earliest of these letters, written around 52 AD.

The major languages spoken by both Jews and Greeks in the Holy Land at the time of Jesus were Aramaic and Koine Greek, and also a colloquial dialect of Mishnaic Hebrew. It is generally agreed by most scholars that the historical Jesus primarily spoke Aramaic, perhaps also some Hebrew and Koine Greek. The majority view is that all of the books that would eventually form the New Testament were written in the Koine Greek language.

As Christianity spread, these books were later translated into other languages, most notably, Latin, Syriac, and Egyptian Coptic. However, some of the Church Fathers imply or claim that Matthew was originally written in Hebrew or Aramaic, and then soon after was written in Koine Greek. Nevertheless, some scholars believe the Gospel of Matthew known today was composed in Greek and is neither directly dependent upon nor a translation of a text in a Semitic language.

The style of Koine Greek in which the New Testament is written differs from the general Koine Greek used by Greek writers of the same era, a difference that some scholars have explained by the fact that the authors of the New Testament, nearly all Jews and deeply familiar with the Septuagint, wrote in a Jewish-Greek dialect strongly influenced by Aramaic and Hebrew (see Jewish Koine Greek, related to the Greek of the Septuagint). But other scholars note that this view is arrived at by comparing the linguistic style of the New Testament to the preserved writings of the literary men of the era, who imitated the style of the great Attic texts and as a result did not reflect the everyday spoken language, so that that this difference in style could be explained by the New Testament being written, unlike other preserved literary material of the era, in the Koine Greek spoken in every day life, in order to appeal to the common people, a style which has also been found in contemporary non-Jewish texts such as private letters, receipts and petitions discovered in Egypt (where the dry air has preserved these documents which, as everyday material not deemed of literary importance, had not been copied by subsequent generations).

The process of canonization of the New Testament was complex and lengthy. In the initial centuries of early Christianity, there were many books widely considered by the church to be inspired, but there was no single formally recognized New Testament canon. The process was characterized by a compilation of books that apostolic tradition considered authoritative in worship and teaching, relevant to the historical situations in which they lived, and consonant with the Old Testament. Writings attributed to the apostles circulated among the earliest Christian communities and the Pauline epistles were circulating, perhaps in collected forms, by the end of the 1st century AD.

One of the earliest attempts at solidifying a canon was made by Marcion, "circa" 140 AD, who accepted only a modified version of Luke (the Gospel of Marcion) and ten of Paul's letters, while rejecting the Old Testament entirely. His canon was largely rejected by other groups of Christians, notably the proto-orthodox Christians, as was his theology, Marcionism. Adolf von Harnack, John Knox, and David Trobisch, among other scholars, have argued that the church formulated its New Testament canon partially in response to the challenge posed by Marcion.

Polycarp, Irenaeus and Tertullian held the epistles of Paul to be divinely inspired "scripture." Other books were held in high esteem but were gradually relegated to the status of New Testament apocrypha. Justin Martyr, in the mid 2nd century, mentions "memoirs of the apostles" as being read on Sunday alongside the "writings of the prophets".

The Muratorian fragment, dated at between 170 and as late as the end of the 4th century (according to the Anchor Bible Dictionary), may be the earliest known New Testament canon attributed to mainstream Christianity. It is similar, but not identical, to the modern New Testament canon.

The oldest clear endorsement of Matthew, Mark, Luke, and John being the only legitimate gospels was written "circa" 180 AD. A four gospel canon (the "Tetramorph") was asserted by Irenaeus, who refers to it directly in his polemic "Against Heresies":

The books considered to be authoritative by Irenaeus included the four gospels and many of the letters of Paul, although, based on the arguments Irenaeus made in support of only four authentic gospels, some interpreters deduce that the fourfold Gospel must have still been a novelty in Irenaeus's time.

By the early 200s, Origen may have been using the same twenty-seven books as in the Catholic New Testament canon, though there were still disputes over the canonicity of the Letter to the Hebrews, Epistle of James, II Peter, II John and III John and the Book of Revelation, known as the Antilegomena. Likewise, the Muratorian fragment is evidence that, perhaps as early as 200, there existed a set of Christian writings somewhat similar to the twenty-seven book NT canon, which included four gospels and argued against objections to them. Thus, while there was a good measure of debate in the Early Church over the New Testament canon, the major writings are claimed to have been accepted by almost all Christians by the middle of the 3rd century.

Origen was largely responsible for the collection of usage information regarding the texts that became the New Testament. The information used to create the late-4th-century Easter Letter, which declared accepted Christian writings, was probably based on the "Ecclesiastical History" [HE] of Eusebius of Caesarea, wherein he uses the information passed on to him by Origen to create both his list at HE 3:25 and Origen's list at HE 6:25. Eusebius got his information about what texts were then accepted and what were then disputed, by the third-century churches throughout the known world, a great deal of which Origen knew of firsthand from his extensive travels, from the library and writings of Origen.

In fact, Origen would have possibly included in his list of "inspired writings" other texts kept out by the likes of Eusebius—including the Epistle of Barnabas, Shepherd of Hermas, and 1 Clement. Notwithstanding these facts, "Origen is not the originator of the idea of biblical canon, but he certainly gives the philosophical and literary-interpretative underpinnings for the whole notion."

Eusebius, "circa" 300, gave a detailed list of New Testament writings in his "Ecclesiastical History" Book 3, Chapter XXV:

The Book of Revelation is counted as both accepted (Kirsopp Lake translation: "Recognized") and disputed, which has caused some confusion over what exactly Eusebius meant by doing so. From other writings of the church fathers, it was disputed with several canon lists rejecting its canonicity. EH 3.3.5 adds further detail on Paul: "Paul's fourteen epistles are well known and undisputed. It is not indeed right to overlook the fact that some have rejected the Epistle to the Hebrews, saying that it is disputed by the church of Rome, on the ground that it was not written by Paul." EH 4.29.6 mentions the Diatessaron: "But their original founder, Tatian, formed a certain combination and collection of the gospels, I know not how, to which he gave the title Diatessaron, and which is still in the hands of some. But they say that he ventured to paraphrase certain words of the apostle Paul, in order to improve their style."

In his Easter letter of 367, Athanasius, Bishop of Alexandria, gave a list of the books that would become the twenty-seven-book NT canon, and he used the word "canonized" ("kanonizomena") in regards to them. The first council that accepted the present canon of the New Testament may have been the Synod of Hippo Regius in North Africa (393 AD); the acts of this council, however, are lost. A brief summary of the acts was read at and accepted by the Council of Carthage (397) and the Council of Carthage (419). These councils were under the authority of St. Augustine, who regarded the canon as already closed.

Pope Damasus I's Council of Rome in 382, if the "Decretum Gelasianum" is correctly associated with it, issued a biblical canon identical to that mentioned above, or, if not, the list is at least a 6th-century compilation. Likewise, Damasus' commissioning of the Latin Vulgate edition of the Bible, c. 383, was instrumental in the fixation of the canon in the West. In "c." 405, Pope Innocent I sent a list of the sacred books to a Gallic bishop, Exsuperius of Toulouse. Christian scholars assert that, when these bishops and councils spoke on the matter, however, they were not defining something new but instead "were ratifying what had already become the mind of the Church."

The New Testament canon as it is now was first listed by St. Athanasius, Bishop of Alexandria, in 367, in a letter written to his churches in Egypt, Festal Letter 39. Also cited is the Council of Rome, but not without controversy. That canon gained wider and wider recognition until it was accepted at the Third Council of Carthage in 397 and 419.

Even this council did not settle the matter, however. Certain books, referred to as Antilegomena, continued to be questioned, especially James and Revelation. Even as late as the 16th century, the Reformer Martin Luther questioned (but in the end did not reject) the Epistle of James, the Epistle of Jude, the Epistle to the Hebrews and the Book of Revelation. To this day, German-language Luther Bibles are printed with these four books at the end of the canon, rather than in their traditional order as in other editions of the Bible.

In light of this questioning of the canon of Scripture by Protestants in the 16th century, the (Roman Catholic) Council of Trent reaffirmed the traditional western canon (i.e., the canon accepted at the 4th-century Council of Rome and Council of Carthage), thus making the Canon of Trent and the Vulgate Bible dogma in the Catholic Church. Later, Pope Pius XI on 2 June 1927 decreed the Comma Johanneum was open to dispute and Pope Pius XII on 3 September 1943 issued the encyclical "Divino afflante Spiritu", which allowed translations based on other versions than just the Latin Vulgate, notably in English the New American Bible.

Thus, some claim that, from the 4th century, there existed unanimity in the West concerning the New Testament canon (as it is today), and that, by the 5th century, the Eastern Church, with a few exceptions, had come to accept the Book of Revelation and thus had come into harmony on the matter of the canon. Nonetheless, full dogmatic articulations of the canon were not made until the Canon of Trent of 1546 for Roman Catholicism, the Thirty-Nine Articles of 1563 for the Church of England, the Westminster Confession of Faith of 1647 for Calvinism, and the Synod of Jerusalem of 1672 for the Greek Orthodox.

On the question of NT Canon formation generally, New Testament scholar Lee Martin McDonald has written that:
Christian scholars assert that when these bishops and councils spoke on the matter, they were not defining something new, but instead "were ratifying what had already become the mind of the Church".

Some synods of the 4th century published lists of canonical books (e.g. Hippo and Carthage). The existing 27-book canon of the New Testament was reconfirmed (for Roman Catholicism) in the 16th century with the Council of Trent (also called the Tridentine Council) of 1546, the Thirty-Nine Articles of 1563 for the Church of England, the Westminster Confession of Faith of 1647 for Calvinism, and the Synod of Jerusalem of 1672 for Eastern Orthodoxy. Although these councils did include statements about the canon, when it came to the New Testament they were only reaffirming the existing canon, including the Antilegomena.

According to the "Catholic Encyclopedia" article on the Canon of the New Testament: "The idea of a complete and clear-cut canon of the New Testament existing from the beginning, that is from Apostolic times, has no foundation in history. The Canon of the New Testament, like that of the Old, is the result of a development, of a process at once stimulated by disputes with doubters, both within and without the Church, and retarded by certain obscurities and natural hesitations, and which did not reach its final term until the dogmatic definition of the Tridentine Council."

In 331, Constantine I commissioned Eusebius to deliver fifty Bibles for the Church of Constantinople. Athanasius ("Apol. Const. 4") recorded Alexandrian scribes around 340 preparing Bibles for Constans. Little else is known, though there is plenty of speculation. For example, it is speculated that this may have provided motivation for canon lists, and that Codex Vaticanus and Codex Sinaiticus may be examples of these Bibles. Together with the Peshitta and Codex Alexandrinus, these are the earliest extant Christian Bibles. There is no evidence among the canons of the First Council of Nicaea of any determination on the canon.

Like other literature from antiquity, the text of the New Testament was (prior to the advent of the printing press) preserved and transmitted in manuscripts. Manuscripts containing at least a part of the New Testament number in the thousands. The earliest of these (like manuscripts containing other literature) are often very fragmentarily preserved. Some of these fragments have even been thought to date as early as the 2nd century (i.e., Papyrus 90, Papyrus 98, Papyrus 104, and famously Rylands Library Papyrus P52, though the early date of the latter has recently been called into question).

For each subsequent century, more and more manuscripts survive that contain a portion or all of the books that were held to be part of the New Testament at that time (for example, the New Testament of the 4th-century Codex Sinaiticus, once a complete Bible, contains the Epistle of Barnabas and the Shepherd of Hermas), though occasionally these manuscripts contain other works as well (e.g., Papyrus 72 and the Crosby-Schøyen Codex). The date when a manuscript was written, however, does not necessarily reflect the date of the form of text it contains. That is, later manuscripts can, and occasionally do, contain older forms of text or older readings.

Some of the more important manuscripts containing an early text of books of the New Testament are:


Textual criticism deals with the identification and removal of transcription errors in the texts of manuscripts. Ancient scribes made errors or alterations (such as including non-authentic additions). The New Testament has been preserved in more than 5,800 Greek manuscripts, 10,000 Latin manuscripts and 9,300 manuscripts in various other ancient languages including Syriac, Slavic, Ethiopic and Armenian. Even if the original Greek versions were lost, the entire New Testament could still be assembled from the translations.

In addition, there are so many quotes from the New Testament in early church documents and commentaries that the entire New Testament could also be assembled from these alone. Not all biblical manuscripts come from orthodox Christian writers. For example, the Gnostic writings of Valentinus come from the 2nd century AD, and these Christians were regarded as heretics by the mainstream church. The sheer number of witnesses presents unique difficulties, but it also gives scholars a better idea of how close modern Bibles are to the original versions.

On noting the large number of surviving ancient manuscripts, Bruce Metzger sums up the view on the issue by saying "The more often you have copies that agree with each other, especially if they emerge from different geographical areas, the more you can cross-check them to figure out what the original document was like. The only way they'd agree would be where they went back genealogically in a family tree that represents the descent of the manuscripts.

In attempting to determine the original text of the New Testament books, some modern textual critics have identified sections as additions of material, centuries after the gospel was written. These are called interpolations. In modern translations of the Bible, the results of textual criticism have led to certain verses, words and phrases being left out or marked as not original. According to Bart D. Ehrman, "These scribal additions are often found in late medieval manuscripts of the New Testament, but not in the manuscripts of the earlier centuries."

Most modern Bibles have footnotes to indicate passages that have disputed source documents. Bible Commentaries also discuss these, sometimes in great detail. While many variations have been discovered between early copies of biblical texts, almost all have no importance, as they are variations in spelling, punctuation, or grammar. Also, many of these variants are so particular to the Greek language that they would not appear in translations into other languages. For example, order of words (i.e. "man bites dog" versus "dog bites man") often does not matter in Greek, so textual variants that flip the order of words often have no consequences.

Outside of these unimportant variants, there are a couple variants of some importance. The two most commonly cited examples are the last verses of the "Gospel of Mark" and the story of the adulterous woman in the "Gospel of John". Many scholars and critics also believe that the Comma Johanneum reference supporting the Trinity doctrine in 1 John to have been a later addition. According to Norman Geisler and William Nix, "The New Testament, then, has not only survived in more manuscripts than any other book from antiquity, but it has survived in a purer form than any other great book—a form that is 99.5% pure"

The often referred to Interpreter's Dictionary of the Bible, a book written to prove the validity of the New Testament, says: " A study of 150 Greek [manuscripts] of the Gospel of Luke has revealed more than 30,000 different readings... It is safe to say that there is not one sentence in the New Testament in which the [manuscript] is wholly uniform." Most of the variation took place within the first three Christian centuries.

By the 4th century, textual "families" or types of text become discernible among New Testament manuscripts. A "text-type" is the name given to a family of texts with similar readings due to common ancestors and mutual correction. Many early manuscripts, however, contain individual readings from several different earlier forms of text. Modern texual critics have identified the following text-types among textual witnesses to the New Testament: The Alexandrian text-type is usually considered to generally preserve many early readings. It is represented, e.g., by Codex Vaticanus, Codex Sinaiticus and the Bodmer Papyri.

The Western text-type is generally longer and can be paraphrastic, but can also preserve early readings. The Western version of the Acts of the Apostles is, notably, 8.5% longer than the Alexandrian form of the text. Examples of the Western text are found in Codex Bezae, Codex Claromontanus, Codex Washingtonianus, the Old Latin (i.e., Latin translations made prior to the Vulgate), as well as in quotations by Marcion, Tatian, Irenaeus, Tertullian and Cyprian.

A text-type referred to as the "Caesarean text-type" and thought to have included witnesses such as Codex Koridethi and minuscule 565, can today be described neither as "Caesarean" nor as a text-type as was previously thought. However, the Gospel of Mark in Papyrus 45, Codex Washingtonianus and in Family 13 does indeed reflect a distinct type of text.

Increasing standardization of distinct (and once local) text-types eventually gave rise to the Byzantine text-type. Since most manuscripts of the New Testament do not derive from the first several centuries, that is, they were copied after the rise of the Byzantine text-type, this form of text is found the majority of extant manuscripts and is therefore often called the "Majority Text." As with all of the other (earlier) text-types, the Byzantine can also occasionally preserve early readings.

Biblical criticism is the scholarly "study and investigation of biblical writings that seeks to make discerning judgments about these writings." Viewing biblical texts as having human rather than supernatural origins, it asks when and where a particular text originated; how, why, by whom, for whom, and in what circumstances it was produced; what influences were at work in its production; what sources were used in its composition; and what message it was intended to convey.

It will vary slightly depending on whether the focus is on the Old Testament, the letters of the New Testament, or the Canonical Gospels. It also plays an important role in the quest for the historical Jesus. It also addresses the physical text, including the meaning of the words and the way in which they are used, its preservation, history, and integrity. Biblical criticism draws upon a wide range of scholarly disciplines including archaeology, anthropology, folklore, linguistics, Oral Tradition studies, history, and religious studies.

The textual variation among manuscript copies of books in the New Testament prompted attempts to discern the earliest form of text already in antiquity (e.g., by the 3rd-century Christian author Origen). The efforts began in earnest again during the Renaissance, which saw a revival of the study of ancient Greek texts. During this period, modern textual criticism was born. In this context, Christian humanists such as Lorenzo Valla and Erasmus promoted a return to the original Greek of the New Testament. This was the beginning of modern New Testament textual criticism, which over subsequent centuries would increasingly incorporate more and more manuscripts, in more languages (i.e., versions of the New Testament), as well as citations of the New Testament by ancient authors and the New Testament text in lectionaries in order to reconstruct the earliest recoverable form of the New Testament text and the history of changes to it.

Books that later formed the New Testament, like other Christian literature of the period, originated in a literary context that reveals relationships not only to other Christian writings, but also to Graeco-Roman and Jewish works. Of singular importance is the extensive use of and interaction with the Jewish Bible and what would become the Christian Old Testament. Both implicit and explicit citations, as well as countless allusions, appear throughout the books of the New Testament, from the Gospels and Acts, to the Epistles, to the Apocalypse.

The first translations (usually called "versions") of the New Testament were made beginning already at the end of 2nd century. The earliest versions of the New Testament are the translations into the Syriac, Latin, and Coptic languages. These three versions were made directly from the Greek, and are frequently cited in the apparatuses of modern critical editions.

Syriac was spoken in Syria, and Mesopotamia, and with dialect in Roman and Byzantine Palestine where it was known as Jewish Palestinian Aramaic. Several Syriac translations were made and have come to us. Most of the Old Syriac, however, as well as the Philoxonian version have been lost.

Tatian, the Assyrian, created the Diatessaron, a gospel harmony written in Syriac around 170 AD and the earliest form of the gospel not only in Syriac but probably also in Armenian.

In the 19th century, manuscript evidence was discovered for an "Old Syriac" version of the four distinct (i.e., not harmonized) gospels. These "separated" (Syriac: "da-Mepharreshe") gospels, though old, have been shown to be later than the Diatessaron. The Old Syriac gospels are fragmentarily preserved in two manuscripts: the 5th-century Curetonian Syriac and the Sinaitic Syriac from the 4th or 5th century.

No Old Syriac manuscripts of other portions of the New Testament survive, though Old Syriac readings, e.g. from the Pauline Epistles, can be discerned in citations made by Eastern fathers and in later Syriac versions. The Old Syriac version is a representative of the Western text-type. The Peshitta version was prepared in the beginning of the 5th century. It contains only 22 books (neither the Minor Catholic Epistles of 2 Peter, 2 and 3 John, and Jude, nor the Book of Revelation were part of this translation).

The Philoxenian probably was produced in 508 for Philoxenus, Bishop of Mabung.

The Gospels were likely translated into Latin as early as the last quarter of the 2nd century in North Africa ("Afra"). Not much later, there were also European Latin translations ("Itala"). There are about 80 Old Latin mansucripts. The Vetus Latina ("Old Latin") versions often contain readings with a Western type of text. (For the avoidance of confusion, these texts were written in Late Latin, not the early version of the Latin language known as Old Latin, pre 75 BC.)

The bewildering diversity of the Old Latin versions prompted Jerome to prepare another translation into Latin—the Vulgate. In many respects it was merely a revision of the Old Latin. There are currently around 8,000 manuscripts of the Vulgate.

There are several dialects of the Coptic language: Bohairic (northern dialect), Fayyumic, Sahidic (southern dialect), Akhmimic, and others. The first translation was made by at least the 3rd century into the Sahidic dialect (cop). This translation represents a mixed text, mostly Alexandrian, though also with Western readings.

A Bohairic translation was made later, but existed already in the 4th century. Though the translation makes less use of Greek words than the Sahidic, it does employ some Greek grammar (e.g., in word-order and the use of particles such as the syntactic construction μεν—δε). For this reason, the Bohairic translation can be helpful in the reconstruction of the early Greek text of the New Testament.

The continued spread of Christianity, and the foundation of national churches, led to the translation of the Bible—often beginning with books from the New Testament—into a variety of other languages at a relatively early date: Armenian, Georgian, Ethiopic, Persian, Sogdian, and eventually Gothic, Old Church Slavonic, Arabic, and Nubian.

Historically, throughout the Christian world and in the context of Christian missionary activity, the New Testament (or portions thereof) has been that part of the Christian Bible first translated into the vernacular. The production of such translations grew out of the insertion of vernacular glosses in biblical texts, as well as out of the production of biblical paraphrases and poetic renditions of stories from the life of Christ (e.g., the Heliand).

The 16th century saw the rise of Protestantism and an explosion of translations of the New (and Old) Testament into the vernacular. Notable are those of Martin Luther (1522), Jacques Lefèvre d'Étaples (1523), the Froschau Bible (1525–1529, revised in 1574), William Tyndale (1526, revised in 1534, 1535 and 1536), the Brest Bible (1563), and the Authorized Version (also called the "King James Version") (1611).

Most of these translations relied (though not always exclusively) upon one of the printed editions of the Greek New Testament edited by Erasmus, the "Novum Instrumentum omne"; a form of this Greek text emerged as the standard and is known as the Textus Receptus. This text, based on the majority of manuscripts is also used in the majority of translations that were made in the years 100 to 400 AD.

Translations of the New Testament made since the appearance of critical editions of the Greek text (notably those of Tischendorf, Westcott and Hort, and von Soden) have largely used them as their base text. Unlike the Textus Receptus, these have a pronounced Alexandrian character. Standard critical editions are those of Nestle-Åland (the text, though not the full critical apparatus of which is reproduced in the United Bible Societies' "Greek New Testament"), Souter, Vogels, Bover and Merk.

Notable translations of the New Testament based on these most recent critical editions include the Revised Standard Version (1946, revised in 1971), (1961, revised in 1973 and 2000), the Einheitsübersetzung (1970, final edition 1979), the New American Bible (1970, revised in 1986), the Traduction Oecuménique de la Bible (1988, revised in 2004), and the New Revised Standard Version (1989).

Though all Christian churches accept the New Testament as scripture, they differ in their understanding of the nature, extent, and relevance of its authority. Views of the authoritativeness of the New Testament often depend on the concept of "inspiration", which relates to the role of God in the formation of the New Testament. Generally, the greater the role of God in one's doctrine of inspiration, the more one accepts the doctrine of biblical inerrancy or authoritativeness of the Bible. One possible source of confusion is that these terms are difficult to define, because many people use them interchangeably or with very different meanings. This article will use the terms in the following manner:

All of these concepts depend for their meaning on the supposition that the text of Bible has been properly interpreted, with consideration for the intention of the text, whether literal history, allegory or poetry, etc. Especially the doctrine of inerrancy is variously understood according to the weight given by the interpreter to scientific investigations of the world.

The notion of unity in diversity of Scripture claims that the Bible presents a noncontradictory and consistent message concerning God and redemptive history. The fact of diversity is observed in comparing the diversity of time, culture, authors' perspectives, literary genre, and the theological themes.

Studies from many theologians considering the "unity in diversity" to be found in the New Testament (and the Bible as a whole) have been collected and summarized by New Testament theologian Frank Stagg. He describes them as some basic presuppositions, tenets, and concerns common among the New Testament writers, giving to the New Testament its "unity in diversity":

For the Roman Catholic Church, there are two modes of Revelation: Scripture and Tradition. Both of them are interpreted by the teachings of the Church. The Roman Catholic view is expressed clearly in the Catechism of the Catholic Church (1997):

§ 82: As a result the Church, to whom the transmission and interpretation of Revelation is entrusted, does not derive her certainty about all revealed truths from the holy Scriptures alone. Both Scripture and Tradition must be accepted and honoured with equal sentiments of devotion and reverence.

§ 107: The inspired books teach the truth. Since therefore all that the inspired authors or sacred writers affirm should be regarded as affirmed by the Holy Spirit, we must acknowledge that the books of Scripture firmly, faithfully, and without error teach that truth which God, for the sake of our salvation, wished to see confided to the Sacred Scriptures.
In Catholic terminology the teaching office is called the Magisterium. The Catholic view should not be confused with the two-source theory. As the Catechism states in §§ 80 and 81, Revelation has "one common source ... two distinct modes of transmission."

While many Eastern Orthodox writers distinguish between Scripture and Tradition, Bishop Kallistos Ware says that for the Orthodox there is only one source of the Christian faith, Holy Tradition, within which Scripture exists.

Traditional Anglicans believe that "Holy Scripture containeth all things necessary to salvation", (Article VI), but also that the Catholic Creeds "ought thoroughly to be received and believed" (Article VIII), and that the Church "hath authority in Controversies of Faith" and is "a witness and keeper of Holy Writ" (Article XX). Classical Anglicanism, therefore, like Orthodoxy, holds that Holy Tradition is the only safe guardian against perversion and innovation in the interpretation of Scripture.

In the famous words of Thomas Ken, Bishop of Bath and Wells: "As for my religion, I dye in the holy catholic and apostolic faith professed by the whole Church before the disunion of East and West, more particularly in the communion of the Church of England, as it stands distinguished from all Papal and Puritan innovations, and as it adheres to the doctrine of the Cross."

Following the doctrine of sola scriptura, Protestants believe that their traditions of faith, practice and interpretations carry forward what the scriptures teach, and so tradition is not a source of authority in itself. Their traditions derive authority from the Bible, and are therefore always open to reevaluation. This openness to doctrinal revision has extended in Liberal Protestant traditions even to the reevaluation of the doctrine of Scripture upon which the Reformation was founded, and members of these traditions may even question whether the Bible is infallible in doctrine, inerrant in historical and other factual statements, and whether it has uniquely divine authority. However, the adjustments made by modern Protestants to their doctrine of scripture vary widely.

Within the US, the Chicago Statement on Biblical Inerrancy (1978) is a statement, articulating evangelical views on this issue. Paragraph four of its summary states: "Being wholly and verbally God-given, Scripture is without error or fault in all its teaching, no less in what it states about God's acts in creation, about the events of world history, and about its own literary origins under God, than in its witness to God's saving grace in individual lives."

Mainline American Protestant denominations, including the United Methodist Church, Presbyterian Church USA, The Episcopal Church, and Evangelical Lutheran Church in America, do not teach the doctrine of inerrancy as set forth in the Chicago Statement. All of these churches have more ancient doctrinal statements asserting the authority of scripture, but may interpret these statements in such a way as to allow for a very broad range of teaching—from evangelicalism to skepticism. It is not an impediment to ordination in these denominations to teach that the scriptures contain errors, or that the authors follow a more or less unenlightened ethics that, however appropriate it may have seemed in the authors' time, moderns would be very wrong to follow blindly.

For example, ordination of women is universally accepted in the mainline churches, abortion is condemned as a grievous social tragedy but not always a personal sin or a crime against an unborn person, and homosexuality is sometimes recognized as a genetic propensity or morally neutral preference that should be neither encouraged nor condemned. In North America, the most contentious of these issues among these churches at the present time is how far the ordination of gay men and lesbians should be accepted.

Officials of the Presbyterian Church USA report: "We acknowledge the role of scriptural authority in the Presbyterian Church, but Presbyterians generally do not believe in biblical inerrancy. Presbyterians do not insist that every detail of chronology or sequence or prescientific description in scripture be true in literal form. Our confessions do teach biblical infallibility. Infallibility affirms the entire truthfulness of scripture without depending on every exact detail."

Those who hold a more liberal view of the Bible as a human witness to the glory of God, the work of fallible humans who wrote from a limited experience unusual only for the insight they have gained through their inspired struggle to know God in the midst of a troubled world. Therefore, they tend not to accept such doctrines as inerrancy. These churches also tend to retain the social activism of their evangelical forebears of the 19th century, placing particular emphasis on those teachings of scripture that teach compassion for the poor and concern for social justice.

The message of personal salvation is, generally speaking, of the good that comes to oneself and the world through following the New Testament's Golden Rule admonition to love others without hypocrisy or prejudice. Toward these ends, the "spirit" of the New Testament, more than the letter, is infallible and authoritative.

There are some movements that believe the Bible contains the teachings of Jesus but who reject the churches that were formed following its publication. These people believe all individuals can communicate directly with God and therefore do not need guidance or doctrines from a church. These people are known as Christian anarchists.

Messianic Judaism generally holds the same view of New Testament authority as evangelical Protestants. According to the view of some Messianic Jewish congregations, Jesus did not annul the Torah, but that its interpretation is revised and ultimately explained through the Apostolic Scriptures.

Jehovah's Witnesses accept the New Testament as divinely inspired Scripture, and as infallible in every detail, with equal authority as the Hebrew Scriptures. They view it as the written revelation and good news of the Messiah, the ransom sacrifice of Jesus, and the Kingdom of God, explaining and expounding the Hebrew Bible, not replacing but vitally supplementing it. They also view the New Testament as the primary instruction guide for Christian living, and church discipline. They generally call the New Testament the "Christian Greek Scriptures", and see only the "covenants" as "old" or "new", but not any part of the actual Scriptures themselves.

Oneness Pentecostalism subscribes to the common Protestant doctrine of "sola scriptura". They view the Bible as the inspired Word of God, and as absolutely inerrant in its contents (though not necessarily in every translation). They regard the New Testament as perfect and inerrant in every way, revealing the Lord Jesus Christ in the Flesh, and his Atonement, and which also explains and illuminates the Old Testament perfectly, and is part of the Bible canon, not because church councils or decrees claimed it so, but by witness of the Holy Spirit.

The Seventh-day Adventist Church holds the New Testament as the inspired Word of God, with God influencing the "thoughts" of the Apostles in the writing, not necessarily every word though. The first fundamental belief of the Seventh-Day Adventist church stated that "The Holy Scriptures are the infallible revelation of [God's] will." Adventist theologians generally reject the "verbal inspiration" position on Scripture held by many conservative evangelical Christians. They believe instead that God inspired the thoughts of the biblical authors and apostles, and that the writers then expressed these thoughts in their own words. This view is popularly known as "thought inspiration", and most Adventist members hold to that view. According to Ed Christian, former "JATS" editor, "few if any ATS members believe in verbal inerrancy".

Regarding the teachings of the New Testament compared to the Old, and the application in the New Covenant, Adventists have traditionally taught that the Decalogue is part of the moral law of God, which was not abrogated by the ministry and death of Jesus Christ. Therefore, the fourth commandment concerning the Sabbath is as applicable to Christian believers as the other nine. Adventists have often taught a distinction between "moral law" and "ceremonial law". According to Adventist beliefs, the moral law continues into the "New Testament era", but the ceremonial law was done away with by Jesus.

How the Mosaic law should be applied came up at Adventist conferences in the past, and Adventist theologians such as A. T. Jones and E. J. Waggoner looked at the problem addressed by Paul in Galatians as not the ceremonial law, but rather the wrong use of the law (legalism). They were opposed by Uriah Smith and George Butler at the 1888 Conference. Smith in particular thought the Galatians issue had been settled by Ellen White already, yet in 1890 she claimed justification by faith is "the third angel's message in verity."

Ellen White interpreted as saying that the ceremonial law was nailed to the cross.

Members of The Church of Jesus Christ of Latter-day Saints (LDS Church) believe that the New Testament, as part of the Christian biblical canon, is accurate "as far as it is translated correctly". They believe the Bible as originally revealed is the word of God, but that the processes of transcription and translation have introduced errors into the texts as currently available, and therefore they cannot be regarded as completely inerrant. In addition to the Old and New Testaments, the , the Doctrine and Covenants and the Pearl of Great Price are considered part of their scriptural canon.

 Despite the wide variety among Christian liturgies, texts from the New Testament play a role in almost all forms of Christian worship. In addition to some language derived from the New Testament in the liturgy itself (e.g., the Trisagion may be based on Apocalypse 4:8, and the beginning of the "Hymn of Praise" draws upon Luke 2:14), the reading of extended passages from the New Testament is a practice common to almost all Christian worship, liturgical or not.

These readings are most often part of an established lectionary (i.e., selected texts to be read at church services on specific days), and (together with an Old Testament reading and a Psalm) include a non-gospel reading from the New Testament and culminate with a Gospel reading. No readings from the Book of Revelation, however, are included in the standard lectionary of the Eastern Orthodox churches.

Central to the Christian liturgy is the celebration of the Eucharist or "Holy Communion". The Words of Institution that begin this rite are drawn directly from 1 Corinthians 11:23–26. In addition, the communal recitation of the Lord's Prayer (in the form found in the Gospel of Matthew 6:9–13) is also a standard feature of Christian worship.

 Most of the influence of the New Testament upon the arts has come from the Gospels and the Book of Revelation. Literary expansion of the Nativity of Jesus found in the Gospels of Matthew and Luke began already in the 2nd century, and the portrayal of the Nativity has continued in various art forms to this day. The earliest Christian art would often depict scenes from the New Testament such as the raising of Lazarus, the baptism of Jesus or the motif of the Good Shepherd.

Biblical paraphrases and poetic renditions of stories from the life of Christ (e.g., the Heliand) became popular in the Middle Ages, as did the portrayal of the arrest, trial and execution of Jesus in Passion plays. Indeed, the Passion became a central theme in Christian art and music. The and Passion of Jesus, as portrayed in one or more of the , has also been a theme in film, almost since the inception of the medium (e.g., "La Passion", France, 1903).







</doc>
<doc id="21435" url="https://en.wikipedia.org/wiki?curid=21435" title="Nerve">
Nerve

A nerve is an enclosed, cable-like bundle of nerve fibres called axons, in the peripheral nervous system. A nerve transmits electrical impulses and is the basic unit of the peripheral nervous system. A nerve provides a common pathway for the electrochemical nerve impulses called action potentials that are transmitted along each of the axons to peripheral organs or, in the case of sensory nerves, from the periphery back to the central nervous system. Each axon within the nerve is an extension of an individual neuron, along with other supportive cells such as some Schwann cells that coat the axons in myelin.

Within a nerve, each axon is surrounded by a layer of connective tissue called the endoneurium. The axons are bundled together into groups called fascicles, and each fascicle is wrapped in a layer of connective tissue called the perineurium. Finally, the entire nerve is wrapped in a layer of connective tissue called the epineurium.

In the central nervous system, the analogous structures are known as nerve tracts.

Each nerve is covered on the outside by a dense sheath of connective tissue, the epineurium. Beneath this is a layer of fat cells, the perineurium, which forms a complete sleeve around a bundle of axons. Perineurial septae extend into the nerve and subdivide it into several bundles of fibres. Surrounding each such fibre is the endoneurium. This forms an unbroken tube from the surface of the spinal cord to the level where the axon synapses with its muscle fibres, or ends in sensory receptors. The endoneurium consists of an inner sleeve of material called the glycocalyx and an outer, delicate, meshwork of collagen fibres. Nerves are bundled and often travel along with blood vessels, since the neurons of a nerve have fairly high energy requirements.

Within the endoneurium, the individual nerve fibres are surrounded by a low-protein liquid called endoneurial fluid. This acts in a similar way to the cerebrospinal fluid in the central nervous system and constitutes a blood-nerve barrier similar to the blood-brain barrier. Molecules are thereby prevented from crossing the blood into the endoneurial fluid. During the development of nerve edema from nerve irritation (or injury), the amount of endoneurial fluid may increase at the site of irritation. This increase in fluid can be visualized using magnetic resonance neurography, and thus MR neurography can identify nerve irritation and/or injury.

Nerves are categorized into three groups based on the direction that signals are conducted:

Nerves can be categorized into two groups based on where they connect to the central nervous system:

Specific terms are used to describe nerves and their actions. A nerve that supplies information to the brain from an area of the body, or controls an action of the body is said to "innervate" that section of the body or organ. Other terms relate to whether the nerve affects the same side ("ipsilateral") or opposite side ("contralateral") of the body, to the part of the brain that supplies it.

Nerve growth normally ends in adolescence, but can be re-stimulated with a molecular mechanism known as "Notch signaling".

If the axons of a neuron are damaged, as long as the cell body of the neuron is not damaged, the axons would regenerate and remake the synaptic connections with neurons with the help of guidepost cells. This is also referred to as neuroregeneration.

The nerve begins the process by destroying the nerve distal to the site of injury allowing Schwann cells, basal lamina, and the neurilemma near the injury to begin producing a regeneration tube. Nerve growth factors are produced causing many nerve sprouts to bud. When one of the growth processes finds the regeneration tube, it begins to grow rapidly towards its original destination guided the entire time by the regeneration tube. Nerve regeneration is very slow and can take up to several months to complete. While this process does repair some nerves, there will still be some functional deficit as the repairs are not perfect.

A nerve conveys information in the form of electrochemical impulses (as nerve impulses known as action potentials) carried by the individual neurons that make up the nerve. These impulses are extremely fast, with some myelinated neurons conducting at speeds up to 120 m/s. The impulses travel from one neuron to another by crossing a synapse, where the message is converted from electrical to chemical and then back to electrical.

Nerves can be categorized into two groups based on function:

The nervous system is the part of an animal that coordinates its actions by transmitting signals to and from different parts of its body. In vertebrates it consists of two main parts, the central nervous system (CNS) and the peripheral nervous system (PNS). The CNS consists of the brain and spinal cord. The PNS consists mainly of nerves, which are enclosed bundles of the long fibers or axons, that connect the CNS to every other part of the body.

Nerves that transmit signals from the brain are called "motor" or "efferent" nerves, while those nerves that transmit information from the body to the CNS are called "sensory" or "afferent". Spinal nerves serve both functions and are called "mixed" nerves. The PNS is divided into three separate subsystems, the somatic, autonomic, and enteric nervous systems. Somatic nerves mediate voluntary movement.

The autonomic nervous system is further subdivided into the sympathetic and the parasympathetic nervous systems. The sympathetic nervous system is activated in cases of emergencies to mobilize energy, while the parasympathetic nervous system is activated when organisms are in a relaxed state. The enteric nervous system functions to control the gastrointestinal system. Both autonomic and enteric nervous systems function involuntarily. Nerves that exit from the cranium are called cranial nerves while those exiting from the spinal cord are called spinal nerves.

Cancer can spread by invading the spaces around nerves. This is particularly common in head and neck cancer, and prostate and colorectal cancer.

Nerves can be damaged by physical injury as well conditions like carpal tunnel syndrome and repetitive strain injury. Autoimmune diseases such as Guillain–Barré syndrome, neurodegenerative diseases, polyneuropathy, infection, neuritis, diabetes, or failure of the blood vessels surrounding the nerve all cause nerve damage, which can vary in severity.

Multiple sclerosis is a disease associated with extensive nerve damage. It occurs when the macrophages of an individual's own immune system damage the myelin sheaths that insulate the axon of the nerve.

A pinched nerve occurs when pressure is placed on a nerve, usually from swelling due to an injury, or pregnancy and can result in pain, weakness, numbness or paralysis, an example being carpal tunnel syndrome. Symptoms can be felt in areas far from the actual site of damage, a phenomenon called referred pain. Referred pain can happen when the damage causes altered signalling to other areas.

Neurologists usually diagnose disorders of the nerves by a physical examination, including the testing of reflexes, walking and other directed movements, muscle weakness, proprioception, and the sense of touch. This initial exam can be followed with tests such as nerve conduction study, electromyography (EMG), and computed tomography (CT).

A neuron is called "identified" if it has properties that distinguish it from every other neuron in the same animal—properties such as location, neurotransmitter, gene expression pattern, and connectivity—and if every individual organism belonging to the same species has exactly one neuron with the same set of properties. In vertebrate nervous systems, very few neurons are "identified" in this sense. Researchers believe humans have none—but in simpler nervous systems, some or all neurons may be thus unique.

In vertebrates, the best known identified neurons are the gigantic Mauthner cells of fish. Every fish has two Mauthner cells, located in the bottom part of the brainstem, one on the left side and one on the right. Each Mauthner cell has an axon that crosses over, innervating (stimulating) neurons at the same brain level and then travelling down through the spinal cord, making numerous connections as it goes. The synapses generated by a Mauthner cell are so powerful that a single action potential gives rise to a major behavioral response: within milliseconds the fish curves its body into a C-shape, then straightens, thereby propelling itself rapidly forward. Functionally this is a fast escape response, triggered most easily by a strong sound wave or pressure wave impinging on the lateral line organ of the fish. Mauthner cells are not the only identified neurons in fish—there are about 20 more types, including pairs of "Mauthner cell analogs" in each spinal segmental nucleus. Although a Mauthner cell is capable of bringing about an escape response all by itself, in the context of ordinary behavior other types of cells usually contribute to shaping the amplitude and direction of the response.

Mauthner cells have been described as command neurons. A command neuron is a special type of identified neuron, defined as a neuron that is capable of driving a specific behavior all by itself. Such neurons appear most commonly in the fast escape systems of various species—the squid giant axon and squid giant synapse, used for pioneering experiments in neurophysiology because of their enormous size, both participate in the fast escape circuit of the squid. The concept of a command neuron has, however, become controversial, because of studies showing that some neurons that initially appeared to fit the description were really only capable of evoking a response in a limited set of circumstances.

In organisms of radial symmetry, nerve nets serve for the nervous system. There is no brain or centralised head region, and instead there are interconnected neurons spread out in nerve nets. These are found in Cnidaria, Ctenophora and Echinodermata.

Herophilos 335–280 BCE, described the optic nerve and the oculomotor nerve for sight and eye movement. Analysis of the nerves in the cranium allowed him to differentiate between blood vessels and nerves i.e. , "“string (plant fiber), nerve”".





</doc>
<doc id="21436" url="https://en.wikipedia.org/wiki?curid=21436" title="Negligence">
Negligence

Negligence (Lat. "negligentia") is a failure to exercise appropriate and or ethical ruled care expected to be exercised amongst specified circumstances. The area of tort law known as "negligence" involves harm caused by failing to act as a form of "carelessness" possibly with extenuating circumstances. The core concept of negligence is that people should exercise reasonable care in their actions, by taking account of the potential harm that they might foreseeably cause to other people or property.

Someone who suffers loss caused by another's negligence may be able to sue for damages to compensate for their harm. Such loss may include physical injury, harm to property, psychiatric illness, or economic loss. The law on negligence may be assessed in general terms according to a five-part model which includes the assessment of duty, breach, actual cause, proximate cause, and damages.

Some things must be established by anyone who wants to sue in negligence. These are what are called the "elements" of negligence.

Most jurisdictions say that there are four elements to a negligence action:

Some jurisdictions narrow the definition down to three elements: duty, breach and proximately caused harm. Some jurisdictions recognize five elements, duty, breach, actual cause, proximate cause, and damages. However, at their heart, the various definitions of what constitutes negligent conduct are very similar.

The legal liability of a defendant to a plaintiff is based on the defendant's failure to fulfil a responsibility, recognised by law, of which the plaintiff is the intended beneficiary. The first step in determining the existence of a legally recognised responsibility is the concept of an obligation or duty. In the tort of negligence the term used is duty of care 

The case of "Donoghue v Stevenson" [1932] established the modern law of negligence, laying the foundations of the duty of care and the fault principle which, (through the Privy Council), have been adopted throughout the Commonwealth. May Donoghue and her friend were in a café in Paisley. The friend bought Mrs Donoghue a ginger beer float. She drank some of the beer and later poured the remainder over her ice-cream and was horrified to see the decomposed remains of a snail exit the bottle. Donoghue suffered nervous shock and gastro-enteritis, but did not sue the cafe owner, instead suing the manufacturer, Stevenson. (As Mrs Donoghue had not herself bought the ginger beer, the doctrine of privity precluded a contractual action against Stevenson).

The Scottish judge, Lord MacMillan, considered the case to fall within a new category of delict (the Scots law nearest equivalent of tort). The case proceeded to the House of Lords, where Lord Atkin interpreted the biblical ordinance to 'love thy neighbour' as a legal requirement to 'not harm thy neighbour.' He then went on to define neighbour as "persons who are so closely and directly affected by my act that I ought reasonably to have them in contemplation as being so affected when I am directing my mind to the acts or omissions that are called in question."

In England the more recent case of "Caparo Industries Plc v Dickman" [1990] introduced a 'threefold test' for a duty of care. Harm must be (1) reasonably foreseeable (2) there must be a relationship of proximity between the plaintiff and defendant and (3) it must be 'fair, just and reasonable' to impose liability. However, these act as guidelines for the courts in establishing a duty of care; much of the principle is still at the discretion of judges.

In Australia, "Donoghue v Stevenson" was used as a persuasive precedent in the case of "Grant v Australian Knitting Mills" (AKR) (1936). This was a landmark case in the development of negligence law in Australia.

Whether a duty of care is owed for psychiatric, as opposed to physical, harm was discussed in the Australian case of "Tame v State of New South Wales; Annetts v Australian Stations Pty Ltd" (2002). Determining a duty for mental harm has now been subsumed into the "Civil Liability Act 2002" in New South Wales. The application of Part 3 of the "Civil Liability Act 2002" (NSW) was demonstrated in "Wicks v SRA (NSW); Sheehan v SRA (NSW)".

Once it is established that the defendant owed a duty to the plaintiff/claimant, the matter of whether or not that duty was breached must be settled. The test is both subjective and objective. The defendant who knowingly (subjective, which is totally based on observation and personal prejudice or view) exposes the plaintiff/claimant to a substantial risk of loss, breaches that duty. The defendant who fails to realize the substantial risk of loss to the plaintiff/claimant, which any reasonable person [objective,Which is totally based on ground facts and reality without any personal prejudice or point of view.] in the same situation would clearly have realized, also breaches that duty. However, whether the test is objective or subjective may depend upon the particular case involved.

There is a reduced threshold for the standard of care owed by children. In the Australian case of "McHale v Watson", McHale, a 9-year-old girl was blinded in one eye after being hit by the ricochet of a sharp metal rod thrown by a 12-year-old boy, Watson. The defendant child was held not to have the level of care to the standard of an adult, but of a 12-year-old child with similar experience and intelligence. Kitto J explained that a child's lack of foresight is a characteristic they share with others at that stage of development. The same principle was demonstrated to exist in English law in "Mullin v Richards".

Certain jurisdictions, also provide for breaches where professionals, such as doctors, fail to warn of risks associated with medical treatments or procedures. Doctors owe both objective and subjective duties to warn; and breach of either is sufficient to satisfy this element in a court of law. For example, the Civil Liability Act in Queensland outlines a statutory test incorporating both objective and subjective elements. For example, an obstetrician who fails to warn a mother of complications arising from childbirth may be held to have breached their professional duty of care.

In "Donoghue v Stevenson", Lord Macmillan declared that "the categories of negligence are never closed"; and in "Dorset Yacht v Home Office" it was held that the government had no immunity from suit when they negligently failed to prevent the escape of juvenile offenders who subsequently vandalise a boatyard. In other words, all members of society have a duty to exercise reasonable care toward others and their property. In "Bolton v. Stone" (1951), the House of Lords held that a defendant was not negligent if the damage to the plaintiff were not a reasonably foreseeable consequence of his conduct. In the case, a Miss Stone was struck on the head by a cricket ball while standing outside a cricket ground. Finding that no batsman would normally be able hit a cricket ball far enough to reach a person standing as far away as was Miss Stone, the court held her claim would fail because the danger was not reasonably or sufficiently foreseeable. As stated in the opinion, 'reasonable risk' cannot be judged with the benefit of hindsight. In "Roe v Minister of Health", Lord Denning said the past should not be viewed through rose coloured spectacles, finding no negligence on the part of medical professionals accused of using contaminated medical jars, since contemporary standards would have indicated only a low possibility of medical jar contamination.

"For the rule in the U.S., see": Calculus of negligence

Further establishment of conditions of intention or malice where applicable may apply in cases of gross negligence.

In order for liability to result from a negligent act or omission, it is necessary to prove not only that the injury was caused by that negligence, but also that there is a legally sufficient connection between the act and the negligence.

For a defendant to be held liable, it must be shown that the particular acts or omissions were the cause of the loss or damage sustained. Although the notion sounds simple, the causation between one's breach of duty and the harm that results to another can at times be very complicated. The basic test is to ask whether the injury would have occurred 'but for', or without, the accused party's breach of the duty owed to the injured party. In Australia, the High Court has held that the 'but for' test is not the exclusive test of causation because it cannot address a situation where there is more than one cause of damage. When 'but for' test is not satisfied and the case is an exceptional one, a commonsense test ('Whether and Why' test) will be applied
Even more precisely, if a breaching party materially increases the risk of harm to another, then the breaching party can be sued to the value of harm that he caused.

Asbestos litigations which have been ongoing for decades revolve around the issue of causation. Interwoven with the simple idea of a party causing harm to another are issues on insurance bills and compensations, which sometimes drove compensating companies out of business.

Sometimes factual causation is distinguished from 'legal causation' to avert the danger of defendants being exposed to, in the words of Cardozo, J., "liability in an indeterminate amount for an indeterminate time to an indeterminate class." It is said a new question arises of how remote a consequence a person's harm is from another's negligence. We say that one's negligence is 'too remote' (in England) or not a 'proximate cause' (in the U.S.) of another's harm if one would 'never' reasonably foresee it happening. Note that a 'proximate cause' in U.S. terminology (to do with the chain of events between the action and the injury) should not be confused with the 'proximity test' under the English duty of care (to do with closeness of relationship). The idea of legal causation is that if no one can foresee something bad happening, and therefore take care to avoid it, how could anyone be responsible? For instance, in "Palsgraf v. Long Island Rail Road Co." the judge decided that the defendant, a railway, was not liable for an injury suffered by a distant bystander. The plaintiff, Palsgraf, was hit by coin-operated scale which toppled because of fireworks explosion that fell on her as she waited on a train platform. The scales fell because of a far-away commotion but it was not clear that what type of commotion caused the scale to fall,either it was the explosion's effect or the confused movement of the terrified people. A train conductor had run to help a man into a departing train. The man was carrying a package as he jogged to jump in the train door. The package had fireworks in it. The conductor mishandled the passenger or his package, causing the package to fall. The fireworks slipped and exploded on the ground causing shockwaves to travel through the platform, which became the cause of commotion on platform, and as a consequence, the scales fell. Because Palsgraf was hurt by the falling scales, she sued the train company who employed the conductor for negligence.

The defendant train company argued it should not be liable as a matter of law, because despite the fact that they employed the employee, who was negligent, his negligence was too remote from the plaintiff's injury. On appeal, the majority of the court agreed, with four judges adopting the reasons, written by Judge Cardozo, that the defendant owed no duty of care to the plaintiff, because a duty was owed only to foreseeable plaintiffs. Three judges dissented, arguing, as written by Judge Andrews, that the defendant owed a duty to the plaintiff, regardless of foreseeability, because all men owe one another a duty not to act negligently.

Such disparity of views on the element of remoteness continues to trouble the judiciary. Courts that follow Cardozo's view have greater control in negligence cases. If the court can find that, as a matter of law, the defendant owed no duty of care to the plaintiff, the plaintiff will lose his case for negligence before having a chance to present to the jury. Cardozo's view is the majority view. However, some courts follow the position put forth by Judge Andrews. In jurisdictions following the minority rule, defendants must phrase their remoteness arguments in terms of proximate cause if they wish the court to take the case away from the jury.

Remoteness takes another form, seen in "The Wagon Mound (No. 2)". The Wagon Mound was a ship in Sydney harbour. The ship leaked oil creating a slick in part of the harbour. The wharf owner asked the ship owner about the danger and was told he could continue his work because the slick would not burn. The wharf owner allowed work to continue on the wharf, which sent sparks onto a rag in the water which ignited and created a fire which burnt down the wharf. The Privy Council determined that the wharf owner 'intervened' in the causal chain, creating a responsibility for the fire which canceled out the liability of the ship owner.

In Australia the concept of remoteness, or proximity, was tested with the case of "Jaensch v Coffey". The wife of a policeman, Mrs Coffey suffered a nervous shock injury from the aftermath of a motor vehicle collision although she was not actually at the scene at the time of the collision. The court upheld that, in addition to it being reasonably foreseeable that his wife might suffer such an injury, it required that there be sufficient proximity between the plaintiff and the defendant who caused the collision. Here there was sufficient causal proximity. See also "Kavanagh v Akhtar", "Imbree v McNeilly", and "Tame v NSW".

Even though there is breach of duty, and the cause of some injury to the defendant, a plaintiff may not recover unless he can prove that the defendant's breach caused a pecuniary injury. This should not be mistaken with the requirements that a plaintiff prove harm to recover. As a general rule, a plaintiff can only rely on a legal remedy to the point that he proves that he suffered a loss; it was reasonably foreseeable. It means something more than pecuniary loss is a necessary element of the plaintiff's case in negligence. When damages are not a necessary element, a plaintiff can win his case without showing that he suffered any loss; he would be entitled to nominal damages and any other damages according to proof. (See "Constantine v Imperial Hotels Ltd" [1944] KB]).

Negligence is different in that the plaintiff must prove his loss, and a particular kind of loss, to recover. In some cases, a defendant may not dispute the loss, but the requirement is significant in cases where a defendant cannot deny his negligence, but the plaintiff suffered no pecuniary loss as a result even though he had suffered emotional injury or damage but he cannot be compensated for these kind of losses.The plaintiff can be compensated for emotional or non-pecuniary losses on the condition that If the plaintiff can prove pecuniary loss, then he can also obtain damages for non-pecuniary injuries, such as emotional distress.

The requirement of pecuniary loss can be shown in a number of ways. A plaintiff who is physically injured by allegedly negligent conduct may show that he had to pay a medical bill. If his property is damaged, he could show the income lost because he could not use it, the cost to repair it, although he could only recover for one of these things.

The damage may be physical, purely economic, both physical and economic (loss of earnings following a personal injury,) or reputational (in a defamation case).

In English law, the right to claim for purely economic loss is limited to a number of 'special' and clearly defined circumstances, often related to the nature of the duty to the plaintiff as between clients and lawyers, financial advisers, and other professions where money is central to the consultative services.

Emotional distress has been recognized as an actionable tort. Generally, emotional distress damages had to be parasitic. That is, the plaintiff could recover for emotional distress caused by injury, but only if it accompanied a physical or pecuniary injury.

A claimant who has suffered only emotional distress and no pecuniary loss would not recover for negligence. However, courts have recently allowed recovery for a plaintiff to recover for purely emotional distress under certain circumstances. The state courts of California allowed recovery for emotional distress aloneeven in the absence of any physical injury, when the defendant physically injures a relative of the plaintiff, and the plaintiff witnesses it.

The eggshell skull rule is a legal doctrine upheld in some tort law systems, which holds that a tortfeasor is liable for the full extent of damage caused, even where the extent of the damage is due to the unforeseen frailty of the claimant. The eggshell skull rule was recently maintained in Australia in the case of "Kavanagh v Akhtar".

Damages place a monetary value on the harm done, following the principle of "restitutio in integrum" (Latin for "restoration to the original condition"). Thus, for most purposes connected with the quantification of damages, the degree of culpability in the breach of the duty of care is irrelevant. Once the breach of the duty is established, the only requirement is to compensate the victim.

One of the main tests that is posed when deliberating whether a claimant is entitled to compensation for a tort, is the "reasonable person". The test is self-explanatory: would a reasonable person (as determined by a judge or jury), under the given circumstances, have done what the defendant did to cause the injury in question; or, in other words, would a reasonable person, acting reasonably, have engaged in similar conduct when compared to the one whose actions caused the injury in question? Simple as the "reasonable person" test sounds, it is very complicated. It is a risky test because it involves the opinion of either the judge or the jury that can be based on limited facts. However, as vague as the "reasonable person" test seems, it is extremely important in deciding whether or not a plaintiff is entitled to compensation for a negligence tort.

Damages are compensatory in nature. Compensatory damages addresses a plaintiff/claimant's losses (in cases involving physical or mental injury the amount awarded also compensates for pain and suffering). The award should make the plaintiff whole, sufficient to put the plaintiff back in the position he or she was before Defendant's negligent act. Anything more would unlawfully permit a plaintiff to profit from the tort.

There are also two other general principles relating to damages. Firstly, the award of damages should take place in the form of a single lump sum payment. Therefore, a defendant should not be required to make periodic payments (however some statutes give exceptions for this). Secondly, the Court is not concerned with how the plaintiff uses the award of damages. For example, if a plaintiff is awarded $100,000 for physical harm, the plaintiff is not required to spend this money on medical bills to restore them to their original position - they can spend this money any way they want.


The United States generally recognizes four elements to a negligence action: duty, breach, proximate causation and injury. A plaintiff who makes a negligence claim must prove all four elements of negligence in order to win his or her case. Therefore, if it is highly unlikely that the plaintiff can prove one of the elements, the defendant may request judicial resolution early on, to prevent the case from going to a jury. This can be by way of a demurrer, motion to dismiss, or motion for summary judgment.

The elements allow a defendant to test a plaintiff's accusations before trial, as well as providing a guide to the finder of fact at trial (the judge in a bench trial, or jury in a jury trial) to decide whether the defendant is or is not liable. Whether the case is resolved with or without trial again depends heavily on the particular facts of the case, and the ability of the parties to frame the issues to the court. The duty and causation elements in particular give the court the greatest opportunity to take the case from the jury, because they directly involve questions of policy. The court can find that regardless of any disputed facts, the case may be resolved as a matter of law from undisputed facts because as a matter of law the defendant cannot be legally responsible for the plaintiff's injury under a theory of negligence.

On appeal, depending on the disposition of the case and the question on appeal, the court reviewing a trial court's determination that the defendant was negligent will analyze at least one of the elements of the cause of action to determine if it is properly supported by the facts and law. For example, in an appeal from a final judgment after a jury verdict, the appellate court will review the record to verify that the jury was properly instructed on each contested element, and that the record shows sufficient evidence for the jury's findings. On an appeal from a dismissal or judgment against the plaintiff without trial, the court will review "de novo" whether the court below properly found that the plaintiff could not prove any or all of his or her case.

Res Ipsa Loquitor Latin for "it speaks for itself." To prove negligence under this doctrine the plaintiff must prove (1) the incident does not usually happen without negligence (2) the object that caused the harm was under the defendants control (3) the plaintiff did not contribute to the cause. 

Negligence Per Se comes down to whether or not a party violated a standard in law meant to protect the public such as a building code or speed limit. 




</doc>
<doc id="21437" url="https://en.wikipedia.org/wiki?curid=21437" title="Niger River">
Niger River

The Niger River (; , ) is the principal river of West Africa, extending about . Its drainage basin is in area. Its source is in the Guinea Highlands in southeastern Guinea. It runs in a crescent through Mali, Niger, on the border with Benin and then through Nigeria, discharging through a massive delta, known as the Niger Delta or the Oil Rivers, into the Gulf of Guinea in the Atlantic Ocean. The Niger is the third-longest river in Africa, exceeded only by the Nile and the Congo River (also known as the Zaïre River). Its main tributary is the Benue River.

The Niger has different names in the different languages of the region:
The earliest use of the name "Niger" for the river is by Leo Africanus in his "Della descrittione dell’Africa et delle cose notabili che ivi sono" published in Italian in 1550. The name may come from Berber phrase "ger-n-ger" meaning "river of rivers". As Timbuktu was the southern end of the principal Trans-Saharan trade route to the western Mediterranean, it was the source of most European knowledge of the region.

Medieval European maps applied the name "Niger" to the middle reaches of the river, in modern Mali, but "Quorra (Kworra)" to the lower reaches in modern Nigeria, as these were not recognized at the time as being the same river. When European colonial powers began to send ships along the west coast of Africa in the 16th and 17th centuries, the Senegal River was often postulated to be the seaward end of the Niger. The Niger Delta, pouring into the Atlantic through mangrove swamps and thousands of distributaries along more than , was thought to be no more than coastal wetlands. It was only with the 18th-century visits of Mungo Park, who travelled down the Niger River and visited the great Sahelian empires of his day, that Europeans correctly identified the course of the Niger and extended the name to its entire course.

The modern nations of Nigeria and Niger take their names from the river, marking contesting national claims by colonial powers of the "Upper", "Lower" and "Middle" Niger river basin during the Scramble for Africa at the end of the 19th century.

The Niger River is a relatively "clear" river, carrying only a tenth as much sediment as the Nile because the Niger's headwaters lie in ancient rocks that provide little silt. Like the Nile, the Niger floods yearly; this begins in September, peaks in November, and finishes by May.

An unusual feature of the river is the Inner Niger Delta, which forms where its gradient suddenly decreases. The result is a region of braided streams, marshes, and lakes the size of Belgium; the seasonal floods make the Delta extremely productive for both fishing and agriculture.

The river loses nearly two-thirds of its potential flow in the Inner Delta between Ségou and Timbuktu to seepage and evaporation. All the water from the Bani River, which flows into the Delta at Mopti, does not compensate for the 'losses'. The average 'loss' is estimated at 31 km/year, but varies considerably between years. The river is then joined by various tributaries, but also loses more water to evaporation. The quantity of water entering Nigeria measured in Yola was estimated at 25 km/year before the 1980s and at 13.5 km/year during the 1980s. The most important tributary of the Niger in Nigeria is the Benue River which merges with the river at Lokoja in Nigeria. The total volume of tributaries in Nigeria is six times higher than the inflow into Nigeria, with a flow near the mouth of the river standing at 177.0 km/year before the 1980s and 147.3 km/year during the 1980s.

The Niger takes one of the most unusual routes of any major river, a boomerang shape that baffled geographers for two centuries. Its source is just 240 km (150 mi) inland from the Atlantic Ocean, but the river runs directly away from the sea into the Sahara Desert, then takes a sharp right turn near the ancient city of Timbuktu (Tombouctou) and heads southeast to the Gulf of Guinea.

This strange geography apparently came about because the Niger River is two ancient rivers joined together. The upper Niger, from the source west of Timbuktu to the bend in the current river near Timbuktu, once emptied into a now dry lake to the east northeast of Timbuktu, while the lower Niger started to the south of Timbuktu and flowed south into the Gulf of Guinea. Over time upstream erosion by the lower Niger resulted in stream capture of the upper Niger by the lower Niger.

The northern part of the river, known as the "Niger bend", is an important area because it is the major river and source of water in that part of the Sahara desert. This made it the focal point of trade across the western Sahara, and the centre of the Sahelian kingdoms of Mali and Gao.

The surrounding Niger River Basin is one of the distinct physiographic sections of the Sudan province, which in turn is part of the larger African massive physiographic division.

At the end of the African Humid Period around 5,500 years before present, the modern Sahara Desert, once a savanna, underwent desertification. As plant species sharply declined, humans migrated to the fertile Niger River bend region, with abundant resources including plants for grazing and fish. Like in the Fertile Crescent, many food crops were domesticated in the Niger River region, including yams, African rice (Oryza glaberrima), and pearl millet. The Sahara aridification may have triggered, or at least accelerated, these domestications. Agriculture, as well as fishing and animal husbandry, led to the rise of settlements like Djenné-Djenno in the Inner Delta, now a World Heritage Site.

The region of the Niger bend, in the Sahel, was a key origin and destination for trans-Saharan trade, fueling the wealth of great empires such as the Ghana, Mali, and Songhai Empires. Major trading ports along the river, including Timbuktu and Gao, became centers of learning and culture. Trade to the Niger bend region also brought Islam to the region in approximately the 14th century CE. Much of the northern Niger basin remains Muslim today, although the southern reaches of the river tend to be Christian.

Classical writings on the interior of the Sahara begins with Ptolemy, who mentions two rivers in the desert: the "Gir" (Γειρ) and farther south, the "Nigir" (Νιγειρ). The first has been since identified as the Wadi Ghir on the north western edge of the Tuat, along the borders of modern Morocco and Algeria. This would likely have been as far as Ptolemy would have had consistent records. The Ni-Ger was likely speculation, although the name stuck as that of a river south of the Mediterranean's "known world". Suetonius reports Romans traveling to the "Ger", although in reporting any river's name derived from a Berber language, in which "gher" means "watercourse", confusion could easily arise. Pliny connected these two rivers as one long watercourse which flowed (via lakes and underground sections) into the Nile, a notion which persisted in the Arab and European worlds – and further added the Senegal River as the "Ger" – until the 19th century. 

While the true course of the Niger was presumably known to locals, it was a mystery to the outside world until the late 18th century. Ancient Romans such as Pliny (N.H. 5.10) thought that the river near Timbuktu was part of the Nile River, a belief also held by Ibn Battuta, while early European explorers thought that it flowed west and joined the Senegal River. The connection to the Nile River was made not simply because this was then known as the great river of "Aethiopia" (by which all lands south of the desert were called by Classical writers), but because the Nile like the Niger flooded every summer. Through the descriptions of Leo Africanus and even Ibn Battuta – despite his visit to the river – the myth connecting the Niger to the Nile persisted. 

Many European expeditions to plot the river were unsuccessful. In 1788 the African Association was formed in England to promote the exploration of Africa in the hopes of locating the Niger, and in June 1796 the Scottish explorer Mungo Park was the first European to lay eyes on the middle portion of the river since antiquity (and perhaps ever). He wrote a famous account "Travels in the Interior of Africa," which appeared in 1799. Park proposed a theory that the Niger and Congo were the same river. Although the Niger Delta would seem like an obvious candidate, it was a maze of streams and swamps that did not look like the head of a great river. He died in 1806 on a second expedition attempting to prove the Niger-Congo connection. The theory became the leading one in Europe. A number of failed expeditions followed however the mystery of the Niger would not be solved for another 25 years, in 1830, when Richard Lander and his brother became the first Europeans to follow the course of the Niger to the ocean.

On October 24, 1946 three Frenchmen, Jean Sauvy, Pierre Ponty and movie maker Jean Rouch, former civil servants in the African French colonies, set out to travel the entire length of the river, as no one else seemed to have done previously. They travelled from the very beginning of the river near Kissidougou in Guinea, walking at first till a raft could be used, then changing to various local crafts as the river broadened and changed. Two of them reached the ocean on March 25, 1947, with Pierre Ponty having had to leave the expedition at Niamey, somewhat past the halfway mark. They carried a 16mm movie camera, the resulting footage giving Jean Rouch his first two ethnographic documentaries: "Au pays des mages noirs", and "La chasse à l’hippopotame". A camera was used to illustrate Jean Rouch's subsequent book "Le Niger En Pirogue" (Fernand Nathan, 1954), as well as Jean Sauvy's “Descente du Niger” (L'Harmattan 2001). A typewriter was brought as well, on which Pierre Ponty produced newspaper articles he mailed out whenever possible.

The water in the Niger River basin is partially regulated through dams. In Mali the Sélingué Dam on the Sankarani River is mainly used for hydropower, but also permits irrigation. Two diversion dams, one at Sotuba just downstream of Bamako, and one at Markala, just downstream of Ségou, are used to irrigate about 54,000 hectares. In Nigeria the Kainji Dam, Shiroro Dam, newly Zungeru Dam and the Jebba dam are used to generate hydropower.

The water resources of the Niger River are under pressure due to increased water abstraction for irrigation and due to the impact of climate change. The construction of dams for hydropower generation is underway or envisaged in order to alleviate chronic power shortages in the countries of the Niger basin.

The FAO estimates the irrigation potential of all countries in the Niger river basin at 2.8 million hectares. Only 0.93m hectares (ha) were under irrigation in the late 1980s. The irrigation potential was estimated at 1.68m ha in Nigeria 0.56m ha in Mali, and the actual irrigated area was 0.67m ha and 0.19m ha.

In order to further coordinate their efforts, in April 2008 the riparian countries which form the Niger Basin Authority adopted a Niger Basin Water Charta, a basin-wide 30-year investment plan and a 5-year priority investment plan. The Charta promotes Integrated Water Resources Management, defines procedures for the examination and approval of new projects, provides a framework for the allocation of water resources between sectors, commits to maintain the integrity of aquatic ecosystems and defines mechanisms for the settlement of disputes between countries and for user participation. Investments include the expansion of irrigated agriculture to improve food security, the construction of the Taoussa (or Tossaye) dam in Mali and the Kandadji Dam in Niger (the latter has been under construction since August 2008), as well as the rehabilitation of the Kainji dam, Shiroro Dam, Jebba dam and the newly Zungeru Dam in Nigeria.

Most of the investments are funded or are expected to be funded through aid. For example, the Kandadji Dam is financed by the Islamic Development Bank, the African Development Bank and the OPEC Development Fund. The World Bank approved a US$500 million soft loan in July 2007 to finance projects in the basin over a 12-year period. Funding will be awarded in two phases. The initial $185 million credit will go to Nigeria, Guinea, Benin, Mali and Niger. The second, $315 million investment, is slated for Burkina Faso, Cameroon, Chad and Ivory Coast. Besides financing the rehabilitation of dams in Nigeria, the loan will also fund the "sustainable management of selected degraded ecosystems and rehabilitation of small water infrastructure" and capacity building.

In September 2009, the Nigerian government commenced a 36 billion naira dredging of the Niger River from Baro to Warri, a move which will see silt removed from several hundred kilometres. The dredging is intended to make it easier for goods to be transported to isolated settlements located deep within from the Atlantic Ocean. Estimated to be completed within six to eight months, it had first been proposed and then postponed for 43 years previously by the then government. Speaking in Lokoja, Nigerian President Umaru Yar'Adua stated that the project would lead to "all-year-round navigability" on the River Niger and that he hoped that, by 2020, Nigeria would have become one of the twenty most industrialised nations in the world. Alhaji Ibrahim Bio, the Nigerian Minister of Transport, said his ministry would work to make certain the project would be completed within its designated timeframe. Some activists have, however, opposed the project in the past, claiming it may have negative effects on waterside villagers.

In late March 2010 the dredging project was 50% complete.






</doc>
<doc id="21440" url="https://en.wikipedia.org/wiki?curid=21440" title="Neutral monism">
Neutral monism

Neutral monism is an umbrella term for a class of metaphysical theories. These theories reject the dichotomy of mind and matter, believing the fundemental nature of reality to be neither mental nor physical; in other words it is "neutral".

Physicalists believe reality is fundamentally material; Idealists believe reality is fundamentally mental; Dualists believe reality is both fundamentally mental and fundamentally physical; Neutral monists believe this as a false dichotomy.

Neutral monism largely overlaps with dual-aspect theory. However, it shares little in common with other forms of monism, such as idealism and physicalism.

Neutral monism is similar to dualism in that both take reality to have both mental and physical properties irreducible to one another. Unlike dualism however, neutral monism does not take these properties to be fundamental or separate from one another from any meaningful sense. Dualism takes the mind to supervene on matter, or - though this is less common - for matter to supervene on the mind. Neutral monism, in contrast, take both mind and matter to supervene on a neutral third substance.

While schematic differences and neutral monism are quite stark, contemporary conceptions of the theories overlap in certain key areas. For instance, Chalmers (1996) maintains that the difference between neutral monism and his preferred property dualism can, at times, be mostly semantic.

Panpsychism is a class of theories that believe consciousness is ubiquitous. Some neutral monist theories are panpsychist and some panpsychist theories are neutral monist. However, the two don't always overlap. For instance, Russellian monism is not panpsychism in response to the combination problem. Conversely, some versions of property dualism are panpsychist, but not neutral monistic.

Neutral monism about the mind–body relationship is described by C. D. Broad in one of his earlier works, "The Mind and Its Place in Nature". Broad's list of possible views about the mind-body problem, which became known simply as "Broad's famous list of 1925" (see chapter XIV of Broad's book) states the basis of what this theory had been and was to become. Some examples of philosophers who are seen to have a neutral monist view are Baruch Spinoza, David Hume, Roberto Ardigò, Ernst Mach, Richard Avenarius, Kenneth Sayre, Joseph Petzoldt and Jonathan Westphal. There are few self-proclaimed neutral monists. Most who are regarded as of this view were classified as such after their deaths.
Earlier, William James had propounded the notion in his essay "Does Consciousness Exist?" in 1904 (reprinted in "Essays in Radical Empiricism" in 1912). Whately Carington in his book "Matter, Mind, and Meaning" (1949) advocated a form of neutral monism. He held that mind and matter both consist of the same kind of components known as "cognita" or sense data. Russian psychologist Boris Sidis also appears to have adhered to some form of neutral monism. William James was one of the earliest philosophers to fully articulate a complete neutral monist view of the world. He did so largely in reaction to neo-Kantianism, which was prevalent at the time.

Bertrand Russell is perhaps the best known advocate of neutral monism. Russel expressed interest in neutral monism early on his career, and officially endorsed the view from 1919 onward. He has hailed the ontology as the "supreme maxim in scientific philosophising". Russell's conception of neutral monism went through a number of iterations throughout his career. Russell's personal brand of neutral can be referred to as "Russell's neutral monism" or Russellian monism.

David Chalmers has been known to express sympathy toward neutral monism. In "The Conscious Mind" (1996) he concludes that facts about consciousness are "further facts about our world" and that there ought to be more to reality than just the physical. He then goes on to engage with a Platonic rendition of neutral monism that holds information as fundamental. Though Chalmers believes neutral monism and panpsychism ought to be taken seriously, he considers the combination problem to be point of concern. He considers Russell's solution of "protophenominal properties" to be ad hoc, and thinks such speculation undercuts the parsimony that made neutral monism initially appealing.

According to Stephen Stich and Ted Warfield, neutral monism has not been a popular view in philosophy as it is difficult to develop or understand the nature of the neutral elements.

Substance can have both "extrinsic" properties and "intrinsic" properties. Extrinsic properties are properties that are outwardly observable, such structures and form. Intrinsic properties are properties that are not outwardly observable and concern the intrinsic nature of a thing. By it's very nature physics deals with the extrinsic properties of matter (if they weren't intrinsic, then they couldn't be described mathematically). As a consequence, most of the positive claims in these fields are related to the extrinsic properties of reality. When it comes to describing the intrinsic nature of matter physics "is silent". However, just because the intrinsic properties of matter are unknown does not mean they don't exist. There are arguments to be made that the intrinsic properties of matter must necessarily exist. As Chalmers puts it, a world of "pure causal flux" may be logically impossible, for there is "nothing for causation to relate." 

Consciousness plays an interesting role in this picture. It cannot be seen through extrinsic signatures (as is evidenced by the problem of other minds), but it surely exists. It would seem, then, that it fits the criteria for an intrinsic property of at least some matter (specifically gray matter). So if (1) consciousness is the only intrinsic property of matter there is evidence for, and (2) matter must necessarily have intrinsic properties. Neutral monists take these two premises and take it to inductively infer that all matter has intrinsic conscious properties.

This also helps solve the mind-body problem. If conscious properties are the intrinsic part of matter that is doing the relating, then there is no need for mind and body to react. Physical causes are merely external realisations of mental causes, and the correlations between the brain and mind may demonstrate. 

Critics of neutral monism cite the combination problem as it's biggest challenge. Though Russell has proposed "protophenominal" properties as potential solutions to this problem, critics such as David Chalmers consider it to be ad hoc. It is not clear what "protophenominal" means, or how such an idea differs from standard physicalism.

Annika Harris, author of "Conscious: A Brief Guide to the Fundamental Mystery of the Mind" has dismissed the combination problem. By her account, the combination problem ceases to be relevant once one understands that the sense of being a "self" experiencing the world is a mere illusion. Taking on a view reminiscent of platonic variations of neutral monism, she argues that consciousness may exist simultaneously within individual neurons and within their higher order structures. The mind may have no one consciousness system, but is rather a conglomeration of overlapping conscious systems continuously changing. Chalmers considers a similar possibility in his exploration of platonic neutral monism However, he dismisses it for its "redundancy." So far, laws of nature have proven to be parsimonious and symmetrical. The notion of multiple overlapping conscious systems realised from the same information could be break from this routine, thus providing reason for skepticism.

Neutral monism is largely unfalsifiable, which tilts the weight of justification onto its parsimony. However, Micheal Huemer has argued that - though it is useful within the domain of physics - there's no reason to believe that parsimony is a theoretical virtue within philosophy. If accepted, this conclusion undercuts much of the justification underlying neutral monism (with the possible exception of Russellian monism).

This form of neutral monism was formulated by William James. It was done mostly in response to his colleges dismissal of its rank "among first principles". Consciousness, in William James perspective, is the epistemic foundation upon which all other knowledge rests; if an ontology is incompatible with its existence, then it is the ontology that must be dismissed, not consciousness. William James considered "the perceived and the perceiver" to simply be two sides of the same coin.

Russellian monism most famously differs from other views of neutral monism in its proposed solution to the combination problem. Russell proposes the existence of "paraphenomenal" properties, that may give rise to consciousness when organised in a certain way.

Not all Platonic theories are neutral monist, but some neutral monist theories are Platonic. Platonic versions of neutral monism have become more prevalent in recent decades. Those these views vary in the details, they usually take a form similar to more common forms of radical Platonism such as the Mathematical Universe Hypothesis; the difference being that they do not see such theories as sufficient for consciousness. As Chalmers points out, information will play a crucial role in any adequate theory of consciousness as the correlations between brain states and mental states must be accounted for. So, platonic versions of neutral monism argue that information is realised both physically and phenomenologically.

Some may also find Platonism appealing thanks to its parsimony: logical truths may necessarily exist, and the mental and physical are mere consequences of this necessary existence. These theories also have the advantage of having coherently defined the neutral variable, thus having overcome what's long been a major challenge for neutral monism.




</doc>
<doc id="21442" url="https://en.wikipedia.org/wiki?curid=21442" title="Necronomicon">
Necronomicon

The Necronomicon, also referred to as the Book of the Dead, or under a purported original Arabic title of "Kitab al-Azif", is a fictional grimoire (textbook of magic) appearing in stories by the horror writer H. P. Lovecraft and his followers. It was first mentioned in Lovecraft's 1924 short story "The Hound", written in 1922, though its purported author, the "Mad Arab" Abdul Alhazred, had been quoted a year earlier in Lovecraft's "The Nameless City". Among other things, the work contains an account of the Old Ones, their history, and the means for summoning them.

Other authors such as August Derleth and Clark Ashton Smith also cited the Necronomicon in their works. Lovecraft approved of other writers building on his work, believing such common allusions built up "a background of evil verisimilitude." Many readers have believed it to be a real work, with booksellers and librarians receiving many requests for it; pranksters have listed it in rare book catalogues, and a student smuggled a card for it into the Yale University Library's card catalog.

Capitalizing on the notoriety of the fictional volume, real-life publishers have printed many books entitled "Necronomicon" since Lovecraft's death.

How Lovecraft conceived the name "Necronomicon" is not clear—Lovecraft said that the title came to him in a dream. Although some have suggested that Lovecraft was influenced primarily by Robert W. Chambers' collection of short stories "The King in Yellow", which centers on a mysterious and disturbing play in book form, Lovecraft is not believed to have read that work until 1927.

Donald R. Burleson has argued that the idea for the book was derived from Nathaniel Hawthorne, though Lovecraft himself noted that "mouldy hidden manuscripts" were one of the stock features of Gothic literature.

Lovecraft wrote that the title, as translated from the Greek language, meant "an image of the law of the dead", compounded respectively from "nekros" "dead", "nomos" "law", and "eikon" "image". Robert M. Price notes that the title has been variously translated by others as "Book of the names of the dead", "Book of the laws of the dead", "Book of dead names" and "Knower of the laws of the dead". S. T. Joshi states that Lovecraft's own etymology is "almost entirely unsound. The last portion of it is particularly erroneous, since "-ikon" is nothing more than a neuter adjectival suffix and has nothing to do with "eikõn" (image)." Joshi translates the title as "Book considering (or classifying) the dead."

Lovecraft was often asked about the veracity of the "Necronomicon", and always answered that it was completely his invention. In a letter to Willis Conover, Lovecraft elaborated upon his typical answer:

Now about the "terrible and forbidden books”—I am forced to say that most of them are purely imaginary. There never was any Abdul Alhazred or "Necronomicon", for I invented these names myself. Robert Bloch devised the idea of Ludvig Prinn and his "De Vermis Mysteriis", while the "Book of Eibon" is an invention of Clark Ashton Smith's. Robert E. Howard is responsible for Friedrich von Junzt and his "Unaussprechlichen Kulten"... As for seriously-written books on dark, occult, and supernatural themes—in all truth they don’t amount to much. That is why it’s more fun to invent mythical works like the "Necronomicon" and "Book of Eibon".

Reinforcing the book's fictionalization, the name of the book's supposed author, Abdul Alhazred, is not even a grammatically correct Arabic name. "Abdul" means "the worshiper/slave of the", and standing alone it would make no sense, as Alhazred is not a surname in the Western sense, but a reference to a person's place of birth, and its English translation starts with another "the". Lovecraft's first use of the name "Abdul Alhazred" was a pseudonym he gave to himself as a five-year-old.

In 1927, Lovecraft wrote a brief pseudo-history of the Necronomicon. It was published in 1938, after his death, as "History of the "Necronomicon"". According to this account, the book was originally called "", an Arabic word that Lovecraft defined as "that nocturnal sound (made by insects) supposed to be the howling of demons", drawing on a footnote by Samuel Henley in Henley's translation of "Vathek". Henley, commenting upon a passage which he translated as "those nocturnal insects which presage evil", alluded to the diabolic legend of Beelzebub, "Lord of the Flies" and to Psalm 91:5, which in some 16th Century English Bibles (such as Myles Coverdale's 1535 translation) describes "bugges by night" where later translations render "terror by night". One Arabic/English dictionary translates "`Azīf" (عزيف) as "whistling (of the wind); weird sound or noise". Gabriel Oussani defined it as "the eerie sound of the jinn in the wilderness". The tradition of "`azif al jinn" (عزيف الجن) is linked to the phenomenon of "singing sand".

In the "History", Alhazred is said to have been a "half-crazed Arab" who worshipped the Lovecraftian entities Yog-Sothoth and Cthulhu in the early 700s CE. He is described as being from Sanaá in Yemen. He visited the ruins of Babylon, the "subterranean secrets" of Memphis and the Empty Quarter of Arabia. In his last years, he lived in Damascus, where he wrote "Al Azif" before his sudden and mysterious death in 738. In subsequent years, Lovecraft wrote, the "Azif" "gained considerable, though surreptitious circulation amongst the philosophers of the age." In 950, it was translated into Greek and given the title "" by Theodorus Philetas, a fictional scholar from Constantinople. This version "impelled certain experimenters to terrible attempts" before being "suppressed and burnt" in 1050 by Patriarch Michael (a historical figure who died in 1059).

After this attempted suppression, the work was "only heard of furtively" until it was translated from Greek into Latin by Olaus Wormius. (Lovecraft gives the date of this edition as 1228, though the real-life Danish scholar Olaus Wormius lived from 1588 to 1624.) Both the Latin and Greek text, the "History" relates, were banned by Pope Gregory IX in 1232, though Latin editions were apparently published in 15th century Germany and 17th century Spain. A Greek edition was printed in Italy in the first half of the 16th century. The Elizabethan magician John Dee (1527-c. 1609) allegedly translated the book—presumably into English—but Lovecraft wrote that this version was never printed and only fragments survive. (The connection between Dee and the "Necronomicon" was suggested by Lovecraft's friend Frank Belknap Long.)

According to Lovecraft, the Arabic version of "Al Azif" had already disappeared by the time the Greek version was banned in 1050, though he cites "a vague account of a secret copy appearing in San Francisco during the current [20th] century" that "later perished in fire". The Greek version, he writes, has not been reported "since the burning of a certain Salem man's library in 1692" (an apparent reference to the Salem witch trials). (In the story "The Diary of Alonzo Typer", the character Alonzo Typer finds a Greek copy.) According to "History of the "Necronomicon"" the very act of studying the text is inherently dangerous, as those who attempt to master its arcane knowledge generally meet terrible ends.

The "Necronomicon" is mentioned in a number of Lovecraft's short stories and in his novellas "At the Mountains of Madness" and "The Case of Charles Dexter Ward". However, despite frequent references to the book, Lovecraft was very sparing of details about its appearance and contents. He once wrote that "if anyone were to try to write the "Necronomicon", it would disappoint all those who have shuddered at cryptic references to it."

In "The Nameless City" (1921), a rhyming couplet that appears at two points in the story is ascribed to Abdul Alhazred:

<poem>That is not dead which can eternal lie. 
And with strange aeons even death may die.</poem>

The same couplet appears in "The Call of Cthulhu" (1928), where it is identified as a quotation from the "Necronomicon". This "much-discussed" couplet, as Lovecraft calls it in the latter story, has also been quoted in works by other authors, including Brian Lumley's "The Burrowers Beneath", which adds a long paragraph preceding the couplet.

In his story "History of the "Necronomicon"", Lovecraft states that it is rumored that artist R.U. Pickman (from his story "Pickman's Model") owned a Greek translation of the text, but it vanished along with the artist in early 1926.

The "Necronomicon" is undoubtedly a substantial text, as indicated by its description in "The Dunwich Horror" (1929). In the story, Wilbur Whateley visits Miskatonic University's library to consult the "unabridged" version of the "Necronomicon" for a spell that would have appeared on the 751st page of his own inherited, but defective, Dee edition. The "Necronomicon" passage in question states:

Nor is it to be thought...that man is either the oldest or the last of earth's masters, or that the common bulk of life and substance walks alone. The Old Ones were, the Old Ones are, and the Old Ones shall be. Not in the spaces we know, but between them, they walk serene and primal, undimensioned and to us unseen. Yog-Sothoth knows the gate. Yog-Sothoth is the gate. Yog-Sothoth is the key and guardian of the gate. Past, present, future, all are one in Yog-Sothoth. He knows where the Old Ones broke through of old, and where They shall break through again. He knows where They had trod earth's fields, and where They still tread them, and why no one can behold Them as They tread. By Their smell can men sometimes know Them near, but of Their semblance can no man know, saving only in the features of those They have begotten on mankind; and of those are there many sorts, differing in likeness from man's truest eidolon to that shape without sight or substance which is Them. They walk unseen and foul in lonely places where the Words have been spoken and the Rites howled through at their Seasons. The wind gibbers with Their voices, and the earth mutters with Their consciousness. They bend the forest and crush the city, yet may not forest or city behold the hand that smites. Kadath in the cold waste hath known Them, and what man knows Kadath? The ice desert of the South and the sunken isles of Ocean hold stones whereon Their seal is engraven, but who hath seen the deep frozen city or the sealed tower long garlanded with seaweed and barnacles? Great Cthulhu is Their cousin, yet can he spy Them only dimly. Iä! Shub-Niggurath! As a foulness shall ye know Them. Their hand is at your throats, yet ye see Them not; and Their habitation is even one with your guarded threshold. Yog-Sothoth is the key to the gate, whereby the spheres meet. Man rules now where They ruled once; They shall soon rule where man rules now. After summer is winter, after winter summer. They wait patient and potent, for here shall They reign again.

The "Necronomicon"s appearance and physical dimensions are not clearly stated in Lovecraft's work. Other than the obvious black letter editions, it is commonly portrayed as bound in leather of various types and having metal clasps. Moreover, editions are sometimes disguised. In "The Case of Charles Dexter Ward", for example, John Merrit pulls down a book labelled "Qanoon-e-Islam" from Joseph Curwen’s bookshelf and discovers to his disquiet that it is actually the "Necronomicon".

Many commercially available versions of the book fail to include any of the contents that Lovecraft describes. The Simon "Necronomicon" in particular has been criticized for this.

According to Lovecraft's "History of the "Necronomicon"", copies of the original "Necronomicon" were held by only five institutions worldwide:


The Miskatonic University also holds the Latin translation by Olaus Wormius, printed in Spain in the 17th century.

Other copies, Lovecraft wrote, were kept by private individuals. Joseph Curwen, as noted, had a copy in "The Case of Charles Dexter Ward" (1941). A version is held in Kingsport in "The Festival" (1925). The provenance of the copy read by the narrator of "The Nameless City" is unknown; a version is read by the protagonist in "The Hound" (1924).

Although Lovecraft insisted that the book was pure invention (and other writers invented passages from the book for their own works), there are accounts of some people actually believing the "Necronomicon" to be a real book. Lovecraft himself sometimes received letters from fans inquiring about the "Necronomicon"s authenticity. Pranksters occasionally listed the "Necronomicon" for sale in book store newsletters or inserted phony entries for the book in library card catalogues (where it may be checked out to one 'A. Alhazred', ostensibly the book's author and original owner). The Vatican also receives requests for this book from those who believe the Vatican Library holds a copy.

Similarly, the university library of Tromsø, Norway, lists a translated version of the "Necronomicon", attributed to Petrus de Dacia and published in 1994, although the document is listed as "unavailable".

In 1973, Owlswick Press issued an edition of the "Necronomicon" written in an indecipherable, apparently fictional language known as "Duriac". This was a limited edition of 348. The book contains a brief introduction by L. Sprague de Camp.

The line between fact and fiction was further blurred in the late 1970s when a book purporting to be a translation of "the real" "Necronomicon" was published. This book, by the pseudonymous "Simon," had little connection to the fictional Lovecraft Mythos but instead was based on Sumerian mythology. It was later dubbed the "Simon "Necronomicon"". Going into trade paperback in 1980 it has never been out of print and has sold 800,000 copies by 2006 making it the most popular "Necronomicon" to date. Despite its contents, the book's marketing focused heavily on the Lovecraft connection and made sensational claims for the book's magical power. The blurb states it was "potentially, the most dangerous Black Book known to the Western World". Three additional volumes have since been published — "The Necronomicon Spellbook", a book of pathworkings with the 50 names of Marduk; "Dead Names: The Dark History of the Necronomicon", a history of the book itself and of the late 1970s New York occult scene; and "The Gates Of The Necronomicon", instructions on pathworking with the Simon "Necronomicon".

A hoax version of the "Necronomicon", edited by George Hay, appeared in 1978 and included an introduction by the paranormal researcher and writer Colin Wilson. David Langford described how the book was prepared from a computer analysis of a discovered "cipher text" by Dr. John Dee. The resulting "translation" was in fact written by occultist Robert Turner, but it was far truer to the Lovecraftian version than the Simon text and even incorporated quotations from Lovecraft's stories in its passages. Wilson also wrote a story, "The Return of the Lloigor", in which the Voynich manuscript turns out to be a copy of the "Necronomicon".

With the success of the Simon "Necronomicon" the controversy surrounding the actual existence of the "Necronomicon" was such that a detailed book, "The Necronomicon Files", was published in 1998 attempting to prove once and for all the book was pure fiction. It covered the well-known "Necronomicon"s in depth, especially the Simon one, along with a number of more obscure ones. It was reprinted and expanded in 2003.

In 2004, "Necronomicon: The Wanderings of Alhazred", by Canadian occultist Donald Tyson, was published by Llewellyn Worldwide. The Tyson "Necronomicon" is generally thought to be closer to Lovecraft's vision than other published versions. Donald Tyson has clearly stated that the "Necronomicon" is fictional, but that has not prevented his book from being the center of some controversy. Tyson has since published "Alhazred", a novelization of the life of the "Necronomicon"s author.

Kenneth Grant, the British occultist, disciple of Aleister Crowley, and head of the Typhonian Ordo Templi Orientis, suggested in his book "The Magical Revival" (1972) that there was an unconscious connection between Crowley and Lovecraft. He thought they both drew on the same occult forces; Crowley via his magic and Lovecraft through the dreams which inspired his stories and the "Necronomicon". Grant claimed that the "Necronomicon" existed as an astral book as part of the Akashic records and could be accessed through ritual magic or in dreams. Grant's ideas on Lovecraft were featured heavily in the introduction to the Simon "Necronomicon" and also have been backed by Tyson.





Notes
Bibliography




</doc>
<doc id="21443" url="https://en.wikipedia.org/wiki?curid=21443" title="Neal Stephenson">
Neal Stephenson

Neal Town Stephenson (born October 31, 1959) is an American writer known for his works of speculative fiction. His novels have been categorized as science fiction, historical fiction, cyberpunk, postcyberpunk, and baroque.

Stephenson's work explores mathematics, cryptography, linguistics, philosophy, currency, and the history of science. He also writes non-fiction articles about technology in publications such as "Wired". He has written novels with his uncle, George Jewsbury ("J. Frederick George"), under the collective pseudonym Stephen Bury.

Stephenson has worked part-time as an advisor for Blue Origin, a company (founded by Jeff Bezos) developing a spacecraft and a space launch system, and is also a cofounder of Subutai Corporation, whose first offering is the interactive fiction project "The Mongoliad". He is currently Magic Leap's Chief Futurist.

Born on October 31, 1959 in Fort Meade, Maryland, Stephenson came from a family of engineers and scientists; his father is a professor of electrical engineering while his paternal grandfather was a physics professor. His mother worked in a biochemistry laboratory, and her father was a biochemistry professor. Stephenson's family moved to Champaign-Urbana, Illinois, in 1960 and then in 1966 to Ames, Iowa. He graduated from Ames High School in 1977.

Stephenson studied at Boston University, first specializing in physics, then switching to geography after he found that it would allow him to spend more time on the university mainframe. He graduated in 1981 with a B.A. in geography and a minor in physics. Since 1984, Stephenson has lived mostly in the Pacific Northwest and currently lives in Seattle with his family.

Stephenson's first novel, "The Big U", published in 1984, is a satirical take on life at American Megaversity, a vast, bland, and alienating research university beset by chaotic riots. His next novel, "Zodiac" (1988), is a thriller following a radical environmentalist in his struggle against corporate polluters. Neither novel attracted much critical attention on first publication, but showcased concerns that Stephenson would further develop in his later work.

Stephenson's breakthrough came in 1992 with "Snow Crash", a cyberpunk or post-cyberpunk novel fusing memetics, computer viruses, and other high-tech themes with Sumerian mythology, along with a sociological extrapolation of extreme laissez-faire capitalism and collectivism. Stephenson at this time would later be described by Mike Godwin as "a slight, unassuming grad-student type whose soft-spoken demeanor gave no obvious indication that he had written the manic apotheosis of cyberpunk science fiction." In 1994, Stephenson joined with his uncle, J. Frederick George, to publish a political thriller, "Interface", under the pen name "Stephen Bury"; they followed this in 1996 with "The Cobweb".

Stephenson's next solo novel, published in 1995, was "The Diamond Age: or A Young Lady's Illustrated Primer". The plot involves weapons implanted in characters' skulls, near-limitless replicators for everything from mattresses to foods, smartpaper, and air and blood-sanitizing nanobots. It is set in a grim future world of limited resources populated by hard-edged survivalists.

This was followed by "Cryptonomicon" in 1999, a novel including concepts ranging from Alan Turing's research into codebreaking and cryptography during the Second World War, to a modern attempt to set up a data haven. In 2013, "Cryptonomicon" won the Prometheus Hall of Fame Award.

"The Baroque Cycle" is a series of historical novels set in the 17th and 18th centuries, and is in some respects a prequel to "Cryptonomicon". It was originally published in three volumes of two or three books each – "Quicksilver" (2003), "The Confusion", (2004) and "The System of the World" (2004) – but was subsequently republished as eight separate books: "Quicksilver", "King of the Vagabonds", "Odalisque", "Bonanza", "Juncto", "Solomon's Gold", "Currency", and "System of the World". (The titles and exact breakdown vary in different markets.) "The System of the World" won the Prometheus Award in 2005.

Following this, Stephenson wrote "Anathem" (2008), a long and detailed novel of speculative fiction. It is set in an Earthlike world (perhaps in an alternative reality), deals with metaphysics, and refers heavily to Ancient Greek philosophy, while at the same time being a complex commentary on the insubstantiality of today's society.

In May 2010, the Subutai Corporation, of which Stephenson was named chairman, announced the production of an experimental multimedia fiction project called "The Mongoliad", which centered upon a narrative written by Stephenson and other speculative fiction authors.

Stephenson's novel "REAMDE" was released on September 20, 2011. The title is a play on the common filename README. This thriller, set in the present, centers around a group of MMORPG developers caught in the middle of Chinese cyber-criminals, Islamic terrorists, and Russian mafia.

On August 7, 2012, Stephenson released a collection of essays and other previously published fiction entitled "Some Remarks: Essays and Other Writing". This collection also includes a new essay and a short story created specifically for this volume.

In late 2013, Stephenson stated that he was working on a multi-volume work of historical novels that would "have a lot to do with scientific and technological themes and how those interact with the characters and civilisation during a particular span of history". He expected the first two volumes to be released in mid-to-late 2014. However, at about the same time, he shifted his attention to a science fiction novel, "Seveneves", which was completed about a year later and was published in May 2015. On June 8, 2016, plans were announced to adapt "Seveneves" for the screen.

In May 2016, as part of a video discussion with Bill Gates, Stephenson revealed that he had just submitted the manuscript for a new historical novel—"a time travel book"—co-written with Nicole Galland, one of his "Mongoliad" coauthors. This was released as "The Rise and Fall of D.O.D.O." on June 13, 2017.

In June 2019 his next novel "Fall; or, Dodge in Hell" was published. It is a near-future novel that explores mind uploading into the cloud, and contains characters from 2011's "Reamde", 1999's "Cryptonomicon", and other books. 

In his earlier novels Stephenson deals heavily in pop culture–laden metaphors and imagery and in quick, hip dialogue, as well as in extended narrative monologues. The tone of his books is generally more irreverent and less serious than that of previous cyberpunk novels such as those of William Gibson.

Stephenson's books tend to have elaborate plots drawing on numerous technological and sociological ideas at the same time. The discursive nature of his writing, together with significant plot and character complexity and an abundance of detail suggests a baroque writing style, which Stephenson brought fully to bear in the three-volume "Baroque Cycle". His book "The Diamond Age" follows a simpler plot but features "neo-Victorian" characters and employs Victorian-era literary conceits. In keeping with the baroque style, Stephenson's books have become longer as he has gained recognition. For example, the paperback editions of "Cryptonomicon" are over eleven hundred pages long with the novel containing various digressions, including a lengthy erotic story about antique furniture and stockings.

Stephenson worked at Blue Origin—Jeff Bezos' spaceflight company—for seven years in the early 2000s when its focus was on "novel alternate approaches to space, alternate propulsion systems, and business models", but left after Blue became a more standard aerospace company.

In 2012, Stephenson launched a Kickstarter campaign for CLANG, a realistic sword-fighting fantasy game. The concept was to use motion control to provide an immersive experience. The campaign's funding goal of $500,000 was reached by the target date of July 9, 2012 on Kickstarter, but funding options remained open and the project continued to accept contributions on its official site. The project ran out of money in September 2013. This, and the circumstances around it, angered some backers with some threatening a class action lawsuit. The CLANG project ended in September 2014 without being completed. Stephenson took part of the responsibility for the project's failure, stating, "I probably focused too much on historical accuracy and not enough on making it sufficiently fun to attract additional investment".

In 2014, Stephenson was hired as Chief Futurist by the Florida-based company Magic Leap. Magic Leap claims to be developing a revolutionary form of augmented reality, not too different from technologies Stephenson previously has described in his science fiction books.








</doc>
<doc id="21444" url="https://en.wikipedia.org/wiki?curid=21444" title="Niccolò Machiavelli">
Niccolò Machiavelli

Niccolò di Bernardo dei Machiavelli (, ; ; 3 May 1469 – 21 June 1527) was an Italian Renaissance diplomat, philosopher and writer, best known for "The Prince" ("Il Principe"), written in 1513. He has often been called the father of modern political philosophy or political science.

For many years he served as a senior official in the Florentine Republic with responsibilities in diplomatic and military affairs. He wrote comedies, carnival songs, and poetry. His personal correspondence is of high importance to historians and scholars. He worked as secretary to the Second Chancery of the Republic of Florence from 1498 to 1512, when the Medici were out of power. 

Machiavelli's name came to evoke unscrupulous politicians of the sort Machiavelli advised most famously in "The Prince." Machiavelli considered political battles, not through a lens of morality, but as though they are a board game with established rules. His experience showed him that politics have always been played with deception, treachery and crime. He also notably said that a ruler who is establishing a kingdom or a republic, and is criticized for his deeds, including violence, should be excused when the intention and the result is beneficial. Machiavelli’s "Prince" was much read as a manuscript long before it was published in 1532 and the reaction was mixed. Some considered it a straightforward description of "the evil means used by bad rulers; others read in it evil recommendations to tyrants to help them maintain their power."

The term "Machiavellian" often connotes political deceit, deviousness, and realpolitik. Even though Machiavelli has become most famous for his work on principalities, scholars also give attention to the exhortations in his other works of political philosophy. While much less well known than "The Prince", the "Discourses on Livy" (composed ) is often said to have paved the way of modern republicanism.

Machiavelli was born in Florence, Italy, the third child and first son of attorney Bernardo di Niccolò Machiavelli and his wife, Bartolomea di Stefano Nelli. The Machiavelli family is believed to be descended from the old marquesses of Tuscany and to have produced thirteen Florentine Gonfalonieres of Justice, one of the offices of a group of nine citizens selected by drawing lots every two months and who formed the government, or Signoria; but he was never a full citizen of Florence because of the nature of Florentine citizenship in that time even under the republican regime. Machiavelli married Marietta Corsini in 1502.

Machiavelli was born in a tumultuous era in which popes waged acquisitive wars against Italian city-states, and people and cities often fell from power as France, Spain, and the Holy Roman Empire battled for regional influence and control. Political-military alliances continually changed, featuring condottieri (mercenary leaders), who changed sides without warning, and the rise and fall of many short-lived governments.

Machiavelli was taught grammar, rhetoric, and Latin. It is thought that he did not learn Greek even though Florence was at the time one of the centers of Greek scholarship in Europe. In 1494 Florence restored the republic, expelling the Medici family that had ruled Florence for some sixty years. Shortly after the execution of Savonarola, Machiavelli was appointed to an office of the second chancery, a medieval writing office that put Machiavelli in charge of the production of official Florentine government documents. Shortly thereafter, he was also made the secretary of the "Dieci di Libertà e Pace."

In the first decade of the sixteenth century, he carried out several diplomatic missions, most notably to the Papacy in Rome. Florence sent him to Pistoia to pacify the leaders of two opposing factions which had broken into riots in 1501 and 1502; when this failed, the leaders were banished from the city, a strategy which Machiavelli had favored from the outset. From 1502 to 1503, he witnessed the brutal reality of the state-building methods of Cesare Borgia (1475–1507) and his father, Pope Alexander VI, who were then engaged in the process of trying to bring a large part of Central Italy under their possession. The pretext of defending Church interests was used as a partial justification by the Borgias. Other excursions to the court of Louis XII and the Spanish court influenced his writings such as "The Prince".

At the start of the 16th century, Machiavelli conceived of a militia for Florence, and he then began recruiting and creating it. He distrusted mercenaries (a distrust that he explained in his official reports and then later in his theoretical works for their unpatriotic and uninvested nature in the war that makes their allegiance fickle and often unreliable when most needed), and instead staffed his army with citizens, a policy that was to be repeatedly successful. By February of 1506 he was able to have marching on parade four hundred farmers, suited (including iron breastplates), and armed with lances and small fire arms. Under his command, Florentine citizen-soldiers defeated Pisa in 1509.

Machiavelli's success did not last. In August 1512, the Medici, backed by Pope Julius II, used Spanish troops to defeat the Florentines at Prato. In the wake of the siege, Soderini resigned as Florentine head of state and left in exile. The experience would, like Machiavelli's time in foreign courts and with the Borgia, heavily influence his political writings.
The Florentine city-state and the republic were dissolved, and Machiavelli was deprived of office and banished from the city for a year. In 1513, the Medici accused him of conspiracy against them and had him imprisoned. Despite being subjected to torture ("with the rope", in which the prisoner is hanged from his bound wrists from the back, forcing the arms to bear the body's weight and dislocating the shoulders), he denied involvement and was released after three weeks.

Machiavelli then retired to his farm estate at Sant'Andrea in Percussina, near San Casciano in Val di Pesa, where he devoted himself to studying and writing his political treatises. He visited places in France, Germany, and Italy where he had represented the Florentine republic. Despairing of the opportunity to remain directly involved in political matters, after a time, he began to participate in intellectual groups in Florence and wrote several plays that (unlike his works on political theory) were both popular and widely known in his lifetime. Politics remained his main passion and, to satisfy this interest, he maintained a well-known correspondence with more politically connected friends, attempting to become involved once again in political life. In a letter to Francesco Vettori, he described his experience:

When evening comes, I go back home, and go to my study. On the threshold, I take off my work clothes, covered in mud and filth, and I put on the clothes an ambassador would wear. Decently dressed, I enter the ancient courts of rulers who have long since died. There, I am warmly welcomed, and I feed on the only food I find nourishing and was born to savour. I am not ashamed to talk to them and ask them to explain their actions and they, out of kindness, answer me. Four hours go by without my feeling any anxiety. I forget every worry. I am no longer afraid of poverty or frightened of death. I live entirely through them.

Machiavelli died in 1527 at 58 after receiving his last rites. He was buried at the Church of Santa Croce in Florence. An epitaph honouring him is inscribed on his monument. The Latin legend reads: ("So great a name (has) no adequate praise" or "No eulogy (would be) a match for such a great name").

Machiavelli's best-known book "Il Principe" contains several maxims concerning politics. Instead of the more traditional target audience of a hereditary prince, it concentrates on the possibility of a "new prince". To retain power, the hereditary prince must carefully balance the interests of a variety of institutions to which the people are accustomed. By contrast, a new prince has the more difficult task in ruling: He must first stabilise his newfound power in order to build an enduring political structure. Machiavelli suggests that the social benefits of stability and security can be achieved in the face of moral corruption. Machiavelli believed that public and private morality had to be understood as two different things in order to rule well. As a result, a ruler must be concerned not only with reputation, but also must be positively willing to act unscrupulously at the right times. Machiavelli believed as a ruler, it was better to be widely feared than to be greatly loved; a loved ruler retains authority by obligation while a feared leader rules by fear of punishment. As a political theorist, Machiavelli emphasized the "necessity" for the methodical exercise of brute force or deceit including extermination of entire noble families to head off any chance of a challenge to the prince's authority.

Scholars often note that Machiavelli glorifies instrumentality in state building, an approach embodied by the saying, often attributed to interpretations of "The Prince", "The ends justify the means". Fraud and deceit are held by Machiavelli as necessary for a prince to use. Violence may be necessary for the successful stabilization of power and introduction of new political institutions. Force may be used to eliminate political rivals, to destroy resistant populations, and to purge the community of other men strong enough of a character to rule, who will inevitably attempt to replace the ruler. Machiavelli has become infamous for such political advice, ensuring that he would be remembered in history through the adjective, "Machiavellian".

Due to the treatise's controversial analysis on politics, the Catholic Church banned "The Prince", putting it on the "Index Librorum Prohibitorum". Humanists also viewed the book negatively, including Erasmus of Rotterdam. As a treatise, its primary intellectual contribution to the history of political thought is the fundamental break between political realism and political idealism, due to it being a manual on acquiring and keeping political power. In contrast with Plato and Aristotle, Machiavelli insisted that an imaginary ideal society is not a model by which a prince should orient himself.

Concerning the differences and similarities in Machiavelli's advice to ruthless and tyrannical princes in "The Prince" and his more republican exhortations in "Discourses on Livy", few assert that "The Prince", although written as advice for a monarchical prince, contains arguments for the superiority of republican regimes, similar to those found in the "Discourses". In the 18th century, the work was even called a satire, for example by Jean-Jacques Rousseau.

Scholars such as Leo Strauss and Harvey Mansfield have stated that sections of "The Prince" and his other works have deliberately esoteric statements throughout them. However, Mansfield states that this is the result of Machiavelli seeing grave and serious things as humorous because they are "manipulable by men", and sees them as grave because they "answer human necessities".

Other interpretations include for example that of Antonio Gramsci, who argued that Machiavelli's audience for this work was not even the ruling class but the common people because the rulers already knew these methods through their education.

The "Discourses on the First Ten Books of Titus Livius", written around 1517, published in 1531, often referred to simply as the "Discourses" or "Discorsi", is nominally a discussion regarding the classical history of early Ancient Rome, although it strays very far from this subject matter and also uses contemporary political examples to illustrate points. Machiavelli presents it as a series of lessons on how a republic should be started and structured. It is a much larger work than "The Prince", and while it more openly explains the advantages of republics, it also contains many similar themes from his other works. For example, Machiavelli has noted that to save a republic from corruption, it is necessary to return it to a "kingly state" using violent means. He excuses Romulus for murdering his brother Remus and co-ruler Titus Tatius to gain absolute power for himself in that he established a "civil way of life". Commentators disagree about how much the two works agree with each other, as Machiavelli frequently refers to leaders of republics as "princes". Machiavelli even sometimes acts as an advisor to tyrants. Other scholars have pointed out the aggrandizing and imperialistic features of Machiavelli's republic. Nevertheless, it became one of the central texts of modern republicanism, and has often been argued to be a more comprehensive work than "The Prince".

Commentators have taken very different approaches to Machiavelli and not always agreed. Major discussion has tended to be about two issues: first, how unified and philosophical his work is, and second, concerning how innovative or traditional it is.

There is some disagreement concerning how best to describe the unifying themes, if there are any, that can be found in Machiavelli's works, especially in the two major political works, "The Prince" and "Discourses". Some commentators have described him as inconsistent, and perhaps as not even putting a high priority in consistency. Others such as Hans Baron have argued that his ideas must have changed dramatically over time. Some have argued that his conclusions are best understood as a product of his times, experiences and education. Others, such as Leo Strauss and Harvey Mansfield, have argued strongly that there is a very strong and deliberate consistency and distinctness, even arguing that this extends to all of Machiavelli's works including his comedies and letters.

Commentators such as Leo Strauss have gone so far as to name Machiavelli as the deliberate originator of modernity itself. Others have argued that Machiavelli is only a particularly interesting example of trends which were happening around him. In any case Machiavelli presented himself at various times as someone reminding Italians of the old virtues of the Romans and Greeks, and other times as someone promoting a completely new approach to politics.

That Machiavelli had a wide range of influences is in itself not controversial. Their relative importance is however a subject of on-going discussion. It is possible to summarize some of the main influences emphasized by different commentators.

I. The Mirror of Princes genre

II. Classical republicanism

Commentators such as Quentin Skinner and J.G.A. Pocock, in the so-called "Cambridge School" of interpretation, have asserted that some of the republican themes in Machiavelli's political works, particularly the "Discourses on Livy", can be found in medieval Italian literature which was influenced by classical authors such as Sallust.

III. Classical political philosophy: Xenophon, Plato and Aristotle
The Socratic school of classical political philosophy, especially Aristotle, had become a major influence upon European political thinking in the late Middle Ages. It existed both in the Catholicised form presented by Thomas Aquinas, and in the more controversial "Averroist" form of authors like Marsilius of Padua. Machiavelli was critical of Catholic political thinking and may have been influenced by Averroism. But he rarely cites Plato and Aristotle, and most likely did not approve of them. Leo Strauss argued that the strong influence of Xenophon, a student of Socrates more known as an historian, rhetorician and soldier, was a major source of Socratic ideas for Machiavelli, sometimes not in line with Aristotle. While interest in Plato was increasing in Florence during Machiavelli's lifetime, Machiavelli does not show particular interest in him, but was indirectly influenced by his readings of authors such as Polybius, Plutarch and Cicero.

The major difference between Machiavelli and the Socratics, according to Strauss, is Machiavelli's materialism, and therefore his rejection of both a teleological view of nature and of the view that philosophy is higher than politics. With their teleological understanding of things, Socratics argued that desirable things tend to happen by nature, as if nature desired them, but Machiavelli claimed that such things happen by blind chance or human action.

IV. Classical materialism

Strauss argued that Machiavelli may have seen himself as influenced by some ideas from classical materialists such as Democritus, Epicurus and Lucretius. Strauss however sees this also as a sign of major innovation in Machiavelli, because classical materialists did not share the Socratic regard for political life, while Machiavelli clearly did.

V. Thucydides

Some scholars note the similarity between Machiavelli and the Greek historian Thucydides, since both emphasized power politics. Strauss argued that Machiavelli may indeed have been influenced by pre-Socratic philosophers, but he felt it was a new combination:
...contemporary readers are reminded by Machiavelli's teaching of Thucydides; they find in both authors the same "realism," i.e., the same denial of the power of the gods or of justice and the same sensitivity to harsh necessity and elusive chance. Yet Thucydides never calls in question the intrinsic superiority of nobility to baseness, a superiority that shines forth particularly when the noble is destroyed by the base. Therefore Thucydides' History arouses in the reader a sadness which is never aroused by Machiavelli's books. In Machiavelli we find comedies, parodies, and satires but nothing reminding of tragedy. One half of humanity remains outside of his thought. There is no tragedy in Machiavelli because he has no sense of the sacredness of "the common." — 

Amongst commentators, there are a few consistently made proposals concerning what was most new in Machiavelli's work.

Machiavelli is sometimes seen as the prototype of a modern empirical scientist, building generalizations from experience and historical facts, and emphasizing the uselessness of theorizing with the imagination.

Machiavelli felt that his early schooling along the lines of a traditional classical education was essentially useless for the purpose of understanding politics. Nevertheless, he advocated intensive study of the past, particularly regarding the founding of a city, which he felt was a key to understanding its later development. Moreover, he studied the way people lived and aimed to inform leaders how they should rule and even how they themselves should live. Machiavelli denies the classical opinion that living virtuously always leads to happiness. For example, Machiavelli viewed misery as "one of the vices that enables a prince to rule." Machiavelli stated that "it would be best to be both loved and feared. But since the two rarely come together, anyone compelled to choose will find greater security in being feared than in being loved." In much of Machiavelli's work, he often states that the ruler must adopt unsavory policies for the sake of the continuance of his regime.

A related and more controversial proposal often made is that he described how to do things in politics in a way which seemed neutral concerning who used the advice—tyrants or good rulers. That Machiavelli strove for realism is not doubted, but for four centuries scholars have debated how best to describe his morality. "The Prince" made the word "Machiavellian" a byword for deceit, despotism, and political manipulation. Leo Strauss declared himself inclined toward the traditional view that Machiavelli was self-consciously a "teacher of evil," since he counsels the princes to avoid the values of justice, mercy, temperance, wisdom, and love of their people in preference to the use of cruelty, violence, fear, and deception. Strauss takes up this opinion because he asserted that failure to accept the traditional opinion misses the "intrepidity of his thought" and "the graceful subtlety of his speech." Italian anti-fascist philosopher Benedetto Croce (1925) concludes Machiavelli is simply a "realist" or "pragmatist" who accurately states that moral values in reality do not greatly affect the decisions that political leaders make. German philosopher Ernst Cassirer (1946) held that Machiavelli simply adopts the stance of a political scientist—a Galileo of politics—in distinguishing between the "facts" of political life and the "values" of moral judgment. On the other hand, Walter Russell Mead has argued that "The Prince"s advice presupposes the importance of ideas like legitimacy in making changes to the political system.

Machiavelli is generally seen as being critical of Christianity as it existed in his time, specifically its effect upon politics, and also everyday life. In his opinion, Christianity, along with the teleological Aristotelianism that the church had come to accept, allowed practical decisions to be guided too much by imaginary ideals and encouraged people to lazily leave events up to providence or, as he would put it, chance, luck or fortune. While Christianity sees modesty as a virtue and pride as sinful, Machiavelli took a more classical position, seeing ambition, spiritedness, and the pursuit of glory as good and natural things, and part of the virtue and prudence that good princes should have. Therefore, while it was traditional to say that leaders should have virtues, especially prudence, Machiavelli's use of the words "virtù" and "prudenza" was unusual for his time, implying a spirited and immodest ambition. Mansfield describes his usage of "virtu" as a "compromise with evil". Famously, Machiavelli argued that virtue and prudence can help a man control more of his future, in the place of allowing fortune to do so.

On the other hand, humanism in Machiavelli's time meant that classical pre-Christian ideas about virtue and prudence, including the possibility of trying to control one's future, were not unique to him. But humanists did not go so far as to promote the extra glory of deliberately aiming to establish a new state, in defiance of traditions and laws.

While Machiavelli's approach had classical precedents, it has been argued that it did more than just bring back old ideas and that Machiavelli was not a typical humanist. argues that the way Machiavelli combines classical ideas is new. While Xenophon and Plato also described realistic politics and were closer to Machiavelli than Aristotle was, they, like Aristotle, also saw philosophy as something higher than politics. Machiavelli was apparently a materialist who objected to explanations involving formal and final causation, or teleology.

Machiavelli's promotion of ambition among leaders while denying any higher standard meant that he encouraged risk-taking, and innovation, most famously the founding of new modes and orders. His advice to princes was therefore certainly not limited to discussing how to maintain a state. It has been argued that Machiavelli's promotion of innovation led directly to the argument for progress as an aim of politics and civilization. But while a belief that humanity can control its own future, control nature, and "progress" has been long-lasting, Machiavelli's followers, starting with his own friend Guicciardini, have tended to prefer peaceful progress through economic development, and not warlike progress. As Harvey wrote: "In attempting other, more regular and scientific modes of overcoming fortune, Machiavelli's successors formalized and emasculated his notion of virtue."

Machiavelli however, along with some of his classical predecessors, saw ambition and spiritedness, and therefore war, as inevitable and part of human nature.

Strauss concludes his 1958 book "Thoughts on Machiavelli" by proposing that this promotion of progress leads directly to the modern arms race. Strauss argued that the unavoidable nature of such arms races, which have existed before modern times and led to the collapse of peaceful civilizations, provides us with both an explanation of what is most truly dangerous in Machiavelli's innovations, but also the way in which the aims of his immoral innovation can be understood.

Machiavelli shows repeatedly that he saw religion as man-made, and that the value of religion lies in its contribution to social order and the rules of morality must be dispensed with if security requires it. In "The Prince," the "Discourses," and in the "Life of Castruccio Castracani," he describes "prophets", as he calls them, like Moses, Romulus, Cyrus the Great, and Theseus (he treated pagan and Christian patriarchs in the same way) as the greatest of new princes, the glorious and brutal founders of the most novel innovations in politics, and men whom Machiavelli assures us have always used a large amount of armed force and murder against their own people. He estimated that these sects last from 1,666 to 3,000 years each time, which, as pointed out by Leo Strauss, would mean that Christianity became due to start finishing about 150 years after Machiavelli. Machiavelli's concern with Christianity as a sect was that it makes men weak and inactive, delivering politics into the hands of cruel and wicked men without a fight.

While fear of God can be replaced by fear of the prince, if there is a strong enough prince, Machiavelli felt that having a religion is in any case especially essential to keeping a republic in order. For Machiavelli, a truly great prince can never be conventionally religious himself, but he should make his people religious if he can. According to he was not the first person to ever explain religion in this way, but his description of religion was novel because of the way he integrated this into his general account of princes.

Machiavelli's judgment that governments need religion for practical political reasons was widespread among modern proponents of republics until approximately the time of the French Revolution. This therefore represents a point of disagreement between himself and late modernity.

Despite the classical precedents, which Machiavelli was not the only one to promote in his time, Machiavelli's realism and willingness to argue that good ends justify bad things, is seen as a critical stimulus towards some of the most important theories of modern politics.

Firstly, particularly in the "Discourses on Livy," Machiavelli is unusual in the positive side he sometimes seems to describe in factionalism in republics. For example, quite early in the "Discourses," (in Book I, chapter 4), a chapter title announces that "the disunion" of the plebs and senate in Rome ""kept Rome free"." That a community has different components whose interests must be balanced in any good regime is an idea with classical precedents, but Machiavelli's particularly extreme presentation is seen as a critical step towards the later political ideas of both a division of powers or checks and balances, ideas which lay behind the US constitution, as well as many other modern state constitutions.

Similarly, the modern economic argument for capitalism, and most modern forms of economics, was often stated in the form of "public virtue from private vices." Also in this case, even though there are classical precedents, Machiavelli's insistence on being both realistic and ambitious, not only admitting that vice exists but being willing to risk encouraging it, is a critical step on the path to this insight.

Mansfield however argues that Machiavelli's own aims have not been shared by those he influenced. Machiavelli argued against seeing mere peace and economic growth as worthy aims on their own, if they would lead to what Mansfield calls the "taming of the prince."

Machiavelli is most famous for a short political treatise, "The Prince", written in 1513 but not published until 1532, five years after his death. Although he privately circulated "The Prince" among friends, the only theoretical work to be printed in his lifetime was "The Art of War", which was about military science. Since the 16th century, generations of politicians remain attracted and repelled by its neutral acceptance, and also positive encouragement, of the immorality of powerful men, described especially in "The Prince" but also in his other works.

His works are sometimes even said to have contributed to the modern negative connotations of the words "politics" and "politician", and it is sometimes thought that it is because of him that "Old Nick" became an English term for the Devil. More obviously, the adjective "Machiavellian" became a term describing a form of politics that is "marked by cunning, duplicity, or bad faith". "Machiavellianism" also remains a popular term used casually in political discussions, often as a byword for bare-knuckled political realism.

While Machiavellianism is notable in the works of Machiavelli, scholars generally agree that his works are complex and have equally influential themes within them. For example, J.G.A. saw him as a major source of the republicanism that spread throughout England and North America in the 17th and 18th centuries and Leo , whose view of Machiavelli is quite different in many ways, had similar remarks about Machiavelli's influence on republicanism and argued that even though Machiavelli was a teacher of evil he had a "grandeur of vision" that led him to advocate immoral actions. Whatever his intentions, which are still debated today, he has become associated with any proposal where "the end justifies the means". For example, Leo wrote:

To quote Robert Bireley:

Machiavelli's ideas had a profound impact on political leaders throughout the modern west, helped by the new technology of the printing press. During the first generations after Machiavelli, his main influence was in non-republican governments. Pole reported that "The Prince" was spoken of highly by Thomas Cromwell in England and had influenced Henry VIII in his turn towards Protestantism, and in his tactics, for example during the Pilgrimage of Grace. A copy was also possessed by the Catholic king and emperor Charles V. In France, after an initially mixed reaction, Machiavelli came to be associated with Catherine de' Medici and the St. Bartholomew's Day massacre. As reports, in the 16th century, Catholic writers "associated Machiavelli with the Protestants, whereas Protestant authors saw him as Italian and Catholic". In fact, he was apparently influencing both Catholic and Protestant kings.

One of the most important early works dedicated to criticism of Machiavelli, especially "The Prince", was that of the Huguenot, Innocent Gentillet, whose work commonly referred to as "Discourse against Machiavelli" or "Anti Machiavel" was published in Geneva in 1576. He accused Machiavelli of being an atheist and accused politicians of his time by saying that his works were the "Koran of the courtiers", that "he is of no reputation in the court of France which hath not Machiavel's writings at the fingers ends". Another theme of Gentillet was more in the spirit of Machiavelli himself: he questioned the effectiveness of immoral strategies (just as Machiavelli had himself done, despite also explaining how they could sometimes work). This became the theme of much future political discourse in Europe during the 17th century. This includes the Catholic Counter Reformation writers summarised by Bireley: Giovanni Botero, Justus Lipsius, Carlo Scribani, Adam Contzen, Pedro de Ribadeneira, and Diego de Saavedra Fajardo. These authors criticized Machiavelli, but also followed him in many ways. They accepted the need for a prince to be concerned with reputation, and even a need for cunning and deceit, but compared to Machiavelli, and like later modernist writers, they emphasized economic progress much more than the riskier ventures of war. These authors tended to cite Tacitus as their source for realist political advice, rather than Machiavelli, and this pretense came to be known as "Tacitism". "Black tacitism" was in support of princely rule, but "red tacitism" arguing the case for republics, more in the original spirit of Machiavelli himself, became increasingly important.
Modern materialist philosophy developed in the 16th, 17th and 18th centuries, starting in the generations after Machiavelli. This philosophy tended to be republican, but as with the Catholic authors, Machiavelli's realism and encouragement of using innovation to try to control one's own fortune were more accepted than his emphasis upon war and factional violence. Not only was innovative economics and politics a result, but also modern science, leading some commentators to say that the 18th century Enlightenment involved a "humanitarian" moderating of Machiavellianism.

The importance of Machiavelli's influence is notable in many important figures in this endeavor, for example Bodin, Francis Bacon, Algernon Sidney, Harrington, John Milton, Spinoza, Rousseau, Hume, Edward Gibbon, and Adam Smith. Although he was not always mentioned by name as an inspiration, due to his controversy, he is also thought to have been an influence for other major philosophers, such as Montaigne, Descartes, Hobbes, Locke and Montesquieu.

Although Jean-Jacques Rousseau is associated with very different political ideas he was also influenced by him, although he viewed Machiavelli's work as a satirical piece in which Machiavelli exposes the faults of a one-man rule rather than exalting amorality.

In the seventeenth century it was in England that Machiavelli's ideas were most substantially developed and adapted, and that republicanism came once more to life; and out of seventeenth-century English republicanism there were to emerge in the next century not only a theme of English political and historical reflection—of the writings of the Bolingbroke circle and of Gibbon and of early parliamentary radicals—but a stimulus to the Enlightenment in Scotland, on the Continent, and in America.
Scholars have argued that Machiavelli was a major indirect and direct influence upon the political thinking of the Founding Fathers of the United States due to his overwhelming favoritism of republicanism and the republican type of government. According to John McCormick, it is still very much debatable whether or not Machiavelli was "an advisor of tyranny or partisan of liberty." Benjamin Franklin, James Madison and Thomas Jefferson followed Machiavelli's republicanism when they opposed what they saw as the emerging aristocracy that they feared Alexander Hamilton was creating with the Federalist Party. Hamilton learned from Machiavelli about the importance of foreign policy for domestic policy, but may have broken from him regarding how rapacious a republic needed to be in order to survive. George Washington was less influenced by Machiavelli.

The Founding Father who perhaps most studied and valued Machiavelli as a political philosopher was John Adams, who profusely commented on the Italian's thought in his work, "A Defence of the Constitutions of Government of the United States of America". In this work, John Adams praised Machiavelli, with Algernon Sidney and Montesquieu, as a philosophic defender of mixed government. For Adams, Machiavelli restored empirical reason to politics, while his analysis of factions was commendable. Adams likewise agreed with the Florentine that human nature was immutable and driven by passions. He also accepted Machiavelli's belief that all societies were subject to cyclical periods of growth and decay. For Adams, Machiavelli lacked only a clear understanding of the institutions necessary for good government.

The 20th-century Italian Communist Antonio Gramsci drew great inspiration from Machiavelli's writings on ethics, morals, and how they relate to the State and revolution in his writings on Passive Revolution, and how a society can be manipulated by controlling popular notions of morality.

Joseph Stalin read "The Prince" and annotated his own copy.

In the 20th century there was also renewed interest in Machiavelli's "La Mandragola" (1518), which received numerous stagings, including several in New York, at the New York Shakespeare Festival in 1976 and the Riverside Shakespeare Company in 1979, as a musical comedy by Peer Raben in Munich's antiteater in 1971, and at London's National Theatre in 1984.


Besides being a statesman and political scientist, Machiavelli also translated classical works, and was a playwright ("Clizia", "Mandragola"), a poet ("Sonetti", "Canzoni", "Ottave", "Canti carnascialeschi"), and a novelist ("Belfagor arcidiavolo").

Some of his other work:

"Della Lingua" (Italian for "Of the Language") (1514), a dialogue about Italy's language is normally attributed to Machiavelli.

Machiavelli's literary executor, Giuliano de' Ricci, also reported having seen that Machiavelli, his grandfather, made a comedy in the style of Aristophanes which included living Florentines as characters, and to be titled "Le Maschere". It has been suggested that due to such things as this and his style of writing to his superiors generally, there was very likely some animosity to Machiavelli even before the return of the Medici.

Christopher Marlowe's play "The Jew of Malta" (ca. 1589) contains a prologue by a character called Machiavel, a Senecan ghost based on Machiavelli. Machiavel expresses the cynical view that power is amoral, saying "I count religion but a childish toy,/And hold there is no sin but ignorance."

Machiavelli is a character in the novel "Romola" (1862-1863), by George Eliot.

Somerset Maugham's last book "Then and Now" fictionalizes Machiavelli's interactions with Cesare Borgia, which formed the foundation of "The Prince".

Niccolò Machiavelli plays a vital role in the young adult book series "The Secrets of the Immortal Nicholas Flamel". He is an immortal working in national security for the French government.

Niccolò Machiavelli aids Cesare Borgia and protagonist Nicholas Dawson in their dangerous intrigues in Cecelia Holland's 1979 historical novel "City of God". David Maclaine writes that in the novel, Machiavelli "is an off-stage presence whose spirit permeates this work of intrigue and betrayal ... It is a brilliant introduction to the people and events that gave us the word 'Machiavellian.'" Machiavelli appears as an Immortal adversary of Duncan MacLeod in Nancy Holder's 1997 "Highlander" novel "The Measure of a Man", and is a character in Michael Scott's novel series "The Secrets of the Immortal Nicholas Flamel" (2007–2012). Machiavelli is also one of the main characters in "The Enchantress of Florence" (2008) by Salman Rushdie, mostly referred to as "Niccolò 'il Macchia", and the central protagonist in the 2012 novel "The Malice of Fortune" by Michael Ennis.

Television dramas centering on the early Renaissance have also made use of Machiavelli to underscore his influence in early modern political philosophy. Machiavelli has been featured as a supporting character in "The Tudors" (2007–2010), Borgia (2011–2014) and "The Borgias" (2011–2013). and the 1981 BBC mini series The Borgias.

Machiavelli appears in the popular historical video games "Assassin's Creed II" (2009) and "" (2010), in which he is portrayed as a member of the secret society of Assassins.

A highly fictionalised version of Machiavelli appears in the BBC children's TV series "Leonardo" (2011–2012), in which he is "Mac", a black streetwise hustler who is best friends with fellow teenagers Leonardo da Vinci, Mona Lisa, and Lorenzo di Medici. In the 2013 episode "Ewings Unite!" of the television series "Dallas", legendary oil baron J.R. Ewing wills his copy of "The Prince" to his adopted nephew Christopher Ewing, telling him to "use it, because being smart and sneaky is an unbeatable combination." In "Da Vinci's Demons" (2013–2015)—an American historical fantasy drama series that presents a fictional account of Leonardo da Vinci's early life—Eros Vlahos plays a young Niccolò "Nico" Machiavelli, although the character's full name is not revealed until the finale of the second season.

The 1967 "The Time Tunnel" episode "The Death Merchant" stars famed character actor Malachi Throne as Niccolò Machiavelli, who has been time-displaced to the Battle of Gettysburg. The character's personality and behaviour seem to portray Cesare Borgia rather than Machiavelli himself, suggesting that the writers may have confused the two.

Machiavelli is played by Damian Lewis in the 2013 BBC radio play "The Prince" written by Jonathan Myerson. Together with his defence attorney Lucrezia Borgia (Helen McCrory), he presents examples from history to the devil to support his political theories and appeal his sentence in Hell.

The historical novel "The City of Man" (2009) by Michael Harrington fully portrays the complex personalities of the two main characters—Girolamo Savonarola and a formative Niccolò Machiavelli—in opposition during the turbulent last decade of 15th century Florence. The portrayal of Machiavelli draws from his later writings and observations of the chaotic events of his youth before rising from obscurity to be appointed as Second Chancellor of the Florentine Republic at the age of twenty-nine, only one month after Savonarola's execution. Major characters include Lorenzo de' Medici, his son Piero, Michelangelo, Sandro Botticelli, Pico della Mirandola, Marsilio Ficino, Pope Alexander VI (Rodrigo Borgia), Cesare Borgia (model for The Prince), Piero and Tommaso Soderini, Il Cronaca and the diarist, Luca Landucci.

The American rapper Tupac Shakur read Machiavelli while in prison and became greatly influenced by his work. Upon his release from prison, Tupac honored Machiavelli in 1996 by changing his own rap name from 2Pac to Makaveli.

In the 1993 crime drama "A Bronx Tale", local mob boss Sonny tells his young protege Calogero that while he was doing a 10-year sentence in jail, he passed the time and stayed out of trouble by reading Machiavelli, whom he describes as "a famous writer from 500 years ago"—and then tells him how Machiavelli's philosophy, including his famous advice about how it is preferable for a leader to be feared rather than loved if he cannot be both—have made him a successful mob boss.


Collections

The Prince

The Discourses on Livy

The Art of War

Florentine Histories

Correspondence

Poetry and comedy


</doc>
<doc id="21445" url="https://en.wikipedia.org/wiki?curid=21445" title="November">
November

November is the eleventh month of the year in the Julian and Gregorian Calendars, the fourth and last of four months to have a length of 30 days and the fifth and last of five months to have a length of fewer than 31 days. November was the ninth month of the calendar of Romulus . November retained its name (from the Latin "novem" meaning "nine") when January and February were added to the Roman calendar.
November is a month of late spring in the Southern Hemisphere and late autumn in the Northern Hemisphere. Therefore, November in the Southern Hemisphere is the seasonal equivalent of May in the Northern Hemisphere and vice versa. In Ancient Rome, Ludi Plebeii was held from November 4–17, Epulum Jovis was held on November 13 and Brumalia celebrations began on November 24. These dates do not correspond to the modern Gregorian calendar.

November was referred to as Blōtmōnaþ by the Anglo-Saxons. Brumaire and Frimaire were the months on which November fell in the French Republican Calendar.

November meteor showers include the Andromedids, which occurs from September 25 to December 6 and generally peak around November 9–14, the Leonids, which occurs from November 15–20, the Alpha Monocerotids, which occurs from November 15–25 with the peak on November 21–22, the Northern Taurids, which occurs from October 20 to December 10, and the Southern Taurids, which occurs from September 10 – November 20, and the Phoenicids; which occur from November 29 to December 9 with the peak occurring on December 5–6. The Orionids, which occurs in late October, sometimes lasts into November.

The Western zodiac signs, for the month of November, are Scorpio (October 23 – November 21) and Sagittarius (November 22 – December 21).


"This list does not necessarily imply either official status or general observance."





First Sunday: November 1 

First Monday: November 2 

Tuesday after the first Monday: November 3 

First Wednesday: November 4 

First Thursday: November 5 

First Friday: November 6 

First Saturday: November 7 

Second Sunday: November 8 

Week of November 8: November 8–14 

Week of November 11: November 8–14 

Second Monday: November 9 

Second Thursday: November 12 

The 13th when falling on a Friday: November 13

Second Saturday: November 14 

Third Sunday: November 15

Third week: November 15–21

Third Monday: November 16 

Weekdays of the third week: November 16–20 

Wednesday of the third week: November 18 

Third Thursday: November 19 

Third Friday: November 20 

Third Friday until the next Monday: November 20–22 

Saturday before Fourth Thursday: November 21 

Last Week: November 22–28 

Day before fourth Thursday: November 25 

Last Wednesday: November 25

Fourth Thursday: November 26 

Day after fourth Thursday: November 27 

Fourth Saturday: November 28 

Saturday after Thanksgiving: November 28

Fourth Sunday: November 29 
Last Sunday: November 29

Monday after fourth Thursday in November: November 30 



</doc>
<doc id="21446" url="https://en.wikipedia.org/wiki?curid=21446" title="November 9">
November 9






</doc>
<doc id="21447" url="https://en.wikipedia.org/wiki?curid=21447" title="November 11">
November 11





</doc>
<doc id="21448" url="https://en.wikipedia.org/wiki?curid=21448" title="November 27">
November 27





</doc>
<doc id="21452" url="https://en.wikipedia.org/wiki?curid=21452" title="November 18">
November 18





</doc>
<doc id="21453" url="https://en.wikipedia.org/wiki?curid=21453" title="Neville Chamberlain">
Neville Chamberlain

Arthur Neville Chamberlain (; 18 March 18699 November 1940) was a British politician of the Conservative Party who served as Prime Minister of the United Kingdom from May 1937 to May 1940. He is best known for his foreign policy of appeasement, and in particular for his signing of the Munich Agreement on 30 September 1938, conceding the German-speaking Sudetenland region of Czechoslovakia to Germany. Following the German invasion of Poland on 1 September 1939, which marked the beginning of World War II, Chamberlain announced the declaration of war on Germany two days later and led Great Britain through the first eight months of the war until his resignation as prime minister on 10 May 1940.

After working in business and local government, and after a short spell as Director of National Service in 1916 and 1917, Chamberlain followed his father, Joseph Chamberlain, and older half-brother, Austen Chamberlain, in becoming a Member of Parliament in the 1918 general election for the new Birmingham Ladywood division at the age of 49. He declined a junior ministerial position, remaining a backbencher until 1922. He was rapidly promoted in 1923 to Minister of Health and then Chancellor of the Exchequer. After a short-lived Labour-led government, he returned as Minister of Health, introducing a range of reform measures from 1924 to 1929. He was appointed Chancellor of the Exchequer in the National Government in 1931.

Chamberlain succeeded Stanley Baldwin as prime minister on 28 May 1937. His premiership was dominated by the question of policy towards an increasingly aggressive Germany, and his actions at Munich were widely popular among the British at the time. In response to Hitler's continued aggression, Chamberlain pledged Great Britain to defend Poland's independence if the latter were attacked, an alliance that brought his country into war after the German invasion of Poland. The failure of Allied forces to prevent the German invasion of Norway caused the House of Commons to hold the historic Norway Debate in May 1940. Chamberlain's conduct of the war was heavily criticised by members of all parties and, in a vote of confidence, his government's majority was greatly reduced. Accepting that a national government supported by all the main parties was essential, Chamberlain resigned the premiership because the Labour and Liberal parties would not serve under his leadership. Although he still led the Conservative Party, he was succeeded as prime minister by his colleague Winston Churchill. Until ill health forced him to resign on 22 September 1940, Chamberlain was an important member of the war cabinet as Lord President of the Council, heading the government in Churchill's absence. Chamberlain died aged 71 on 9 November 1940 of cancer, six months after leaving the premiership.

Chamberlain's reputation remains controversial among historians, the initial high regard for him being entirely eroded by books such as "Guilty Men", published in July 1940, which blamed Chamberlain and his associates for the Munich accord and for allegedly failing to prepare the country for war. Most historians in the generation following Chamberlain's death held similar views, led by Churchill in "The Gathering Storm". Some later historians have taken a more favourable perspective of Chamberlain and his policies, citing government papers released under the Thirty Year Rule and arguing that going to war with Germany in 1938 would have been disastrous as the UK was unprepared. Nonetheless, Chamberlain is still unfavourably ranked amongst British prime ministers.

Chamberlain was born on 18 March 1869 in a house called Southbourne in the Edgbaston district of Birmingham. He was the only son of the second marriage of Joseph Chamberlain, who later became Mayor of Birmingham and a Cabinet minister. His mother was Florence Kenrick, cousin to William Kenrick MP; she died when he was a small boy. Joseph Chamberlain had had another son, Austen Chamberlain, by his first marriage. Neville Chamberlain was educated at home by his elder sister Beatrice Chamberlain and later at Rugby School. Joseph Chamberlain then sent Neville to Mason College, now University of Birmingham. Neville Chamberlain had little interest in his studies there, and in 1889 his father apprenticed him to a firm of accountants. Within six months he became a salaried employee.

In an effort to recoup diminished family fortunes, Joseph Chamberlain sent his younger son to establish a sisal plantation on Andros Island in the Bahamas. Neville Chamberlain spent six years there but the plantation was a failure, and Joseph Chamberlain lost £50,000.

On his return to England, Neville Chamberlain entered business, purchasing (with assistance from his family) Hoskins & Company, a manufacturer of metal ship berths. Chamberlain served as managing director of Hoskins for 17 years during which time the company prospered. He also involved himself in civic activities in Birmingham. In 1906, as Governor of Birmingham's General Hospital, and along with "no more than fifteen" other dignitaries, Chamberlain became a founding member of the national United Hospitals Committee of the British Medical Association. 

At forty, Chamberlain was expecting to remain a bachelor, but in 1910 he fell in love with Anne Cole, a recent connection by marriage, and married her the following year. They met through his Aunt Lilian, the Canadian-born widow of Joseph Chamberlain's brother Herbert, who in 1907 had married Anne Cole's uncle Alfred Clayton Cole, a director of the Bank of England.

She encouraged and supported his entry into local politics and was to be his constant companion, helper, and trusted colleague, fully sharing his interests in housing and other political and social activities after his election as an MP. The couple had a son and a daughter.

Chamberlain initially showed little interest in politics, though his father and half-brother were in Parliament. During the "Khaki election" of 1900 he made speeches in support of Joseph Chamberlain's Liberal Unionists. The Liberal Unionists were allied with the Conservatives and later merged with them under the name "Unionist Party", which in 1925 became known as the "Conservative and Unionist Party". In 1911, Neville Chamberlain successfully stood as a Liberal Unionist for Birmingham City Council for the All Saints' Ward, located within his father's parliamentary constituency.

Chamberlain was made chairman of the Town Planning Committee. Under his direction, Birmingham soon adopted one of the first town planning schemes in Britain. The start of the First World War in 1914 prevented implementation of his plans. In 1915, Chamberlain became Lord Mayor of Birmingham. Apart from his father Joseph, five of Chamberlain's uncles had also attained the chief Birmingham civic dignity: they were Joseph's brother Richard Chamberlain, William and George Kenrick, Charles Beale, who had been four times Lord Mayor and Sir Thomas Martineau. As a Lord Mayor in wartime, Chamberlain had a huge burden of work and he insisted that his councillors and officials work equally hard. He halved the Lord Mayor's expense allowance and cut back on the number of civic functions expected of the incumbent. In 1915, Chamberlain was appointed a member of the Central Control Board on liquor traffic.

In December 1916, Prime Minister David Lloyd George offered Chamberlain the new position of Director of National Service, with responsibility for co-ordinating conscription and ensuring that essential war industries were able to function with sufficient workforces. His tenure was marked by conflict with Lloyd George; in August 1917, having received little support from the Prime Minister, Chamberlain resigned. The relationship between Chamberlain and Lloyd George would, thereafter, be one of mutual hatred.

Chamberlain decided to stand for the House of Commons, and was adopted as Unionist candidate for Birmingham Ladywood. After the war ended, a general election was called almost immediately. The campaign in this constituency was notable because his Liberal Party opponent was Mrs Margery Corbett Ashby, one of the seventeen women candidates who stood for Parliament at the first election at which women were eligible to do so. Chamberlain reacted to this intervention by being one of the few male candidates to specifically target women voters deploying his wife, issuing a special leaflet headed "A word to the Ladies" and holding two meetings in the afternoon. Chamberlain was elected with almost 70% of the vote and a majority of 6,833. He was 49 years old, which remains to date the greatest age at which any future Prime Minister has first been elected to the Commons.

Chamberlain threw himself into parliamentary work, begrudging the times when he was unable to attend debates and spending much time on committee work. He was chairman of the national Unhealthy Areas Committee (1919–21) and in that role, had visited the slums of London, Birmingham, Leeds, Liverpool and Cardiff. Consequently, in March 1920, Bonar Law offered him a junior post at the Ministry of Health on behalf of the Prime Minister, but Chamberlain was unwilling to serve under Lloyd George and was offered no further posts during Lloyd George's premiership. When Law resigned as party leader, Austen Chamberlain took his place as head of the Unionists in Parliament. Unionist leaders were willing to fight the 1922 election in coalition with the Lloyd George Liberals, but on 19 October, Unionist MPs held a meeting at which they voted to fight the election as a single party. Lloyd George resigned, as did Austen Chamberlain, and Law was recalled from retirement to lead the Unionists as Prime Minister.

Many high-ranking Unionists refused to serve under Law to the benefit of Chamberlain, who rose over the course of ten months from backbencher to Chancellor of the Exchequer. Law initially appointed Chamberlain Postmaster General and Chamberlain was sworn of the Privy Council. When Sir Arthur Griffith-Boscawen, the Minister of Health, lost his seat in the 1922 election and was defeated in a by-election in March 1923 by future Home Secretary James Chuter Ede, Law offered the position to Chamberlain. Two months later, Law was diagnosed with advanced, terminal throat cancer. He immediately resigned and was replaced by Chancellor of the Exchequer Stanley Baldwin. In August 1923, Baldwin promoted Chamberlain to the position of Chancellor of the Exchequer.

Chamberlain served only five months in the office before the Conservatives were defeated in the 1923 general election. Ramsay MacDonald became the first Labour Prime Minister, but his government fell within months, necessitating another general election. By a margin of only 77 votes, Chamberlain narrowly defeated the Labour candidate, Oswald Mosley, who later led the British Union of Fascists. Believing he would lose if he stood again in Birmingham Ladywood, Chamberlain arranged to be adopted for Birmingham Edgbaston, the district of the city where he was born and which was a much safer seat, which he would hold for the rest of his life. The Unionists won the election, but Chamberlain declined to serve again as Chancellor, preferring his former position as Minister of Health.

Within two weeks of his appointment as Minister of Health, Chamberlain presented the Cabinet with an agenda containing 25 pieces of legislation he hoped to see enacted. Before he left office in 1929, 21 of the 25 bills had passed into law. Chamberlain sought the abolition of the elected Poor Law Boards of Guardians which administered relief—and which in some areas were responsible for rates. Many of the Boards were controlled by Labour, and such Boards had defied the government by distributing relief funds to the able-bodied unemployed. In 1929, Chamberlain initiated the Local Government Act 1929 to abolish the Poor Law boards entirely. Chamberlain spoke in the Commons for two and a half hours on the second reading of the Bill, and when he concluded he was applauded by all parties. The Bill passed into law.

Though Chamberlain struck a conciliatory note during the 1926 General Strike, in general he had poor relations with the Labour opposition. Future Labour Prime Minister Clement Attlee complained that Chamberlain "always treated us like dirt," and in April 1927 Chamberlain wrote: "More and more do I feel an utter contempt for their lamentable "stupidity"." His poor relations with the Labour Party later played a major part in his downfall as Prime Minister.

Baldwin called a general election for 30 May 1929, resulting in a hung parliament with Labour holding the most seats. Baldwin and his government resigned and Labour, under MacDonald, again took office. In 1931, the MacDonald government faced a serious crisis as the May Report revealed that the budget was unbalanced, with an expected shortfall of £120 million. The Labour government resigned on 24 August, and MacDonald formed a National Government supported by most Conservative MPs. Chamberlain once again returned to the Ministry of Health.

After the 1931 general election, in which supporters of the National Government (mostly Conservatives) won an overwhelming victory, MacDonald designated Chamberlain as Chancellor of the Exchequer. Chamberlain proposed a 10% tariff on foreign goods and lower or no tariffs on goods from the colonies and the Dominions. Joseph Chamberlain had advocated a similar policy, "Imperial Preference"; Neville Chamberlain laid his bill before the House of Commons on 4 February 1932, and concluded his address by noting the appropriateness of his seeking to enact his father's proposal. At the end of the speech, Sir Austen Chamberlain walked down from the backbenches and shook his brother's hand. The Import Duties Act 1932 passed Parliament easily.

Chamberlain presented his first budget in April 1932. He maintained the severe budget cuts that had been agreed at the inception of the National Government. Interest on the war debt was a major cost. Chamberlain reduced the annual interest rate on most of Britain's war debt from 5% to 3.5%. Between 1932 and 1938, Chamberlain halved the percentage of the budget devoted to interest on the war debt.

Chamberlain hoped that a cancellation of the war debt owed to the United States could be negotiated. In June 1933, Britain hosted the World Monetary and Economic Conference, which came to nothing as US President Franklin D. Roosevelt sent word that he would not consider any war debt cancellation. By 1934, Chamberlain was able to declare a budget surplus and reverse many of the cuts in unemployment compensation and civil servant salaries he had made after taking office. He told the Commons, "We have now finished the story of "Bleak House" and are sitting down this afternoon to enjoy the first chapter of "Great Expectations"."

The Unemployed Assistance Board (UAB, established by the Unemployment Act 1934) was largely Chamberlain's creation, and he wished to see the issue of unemployment assistance removed from party political argument. Moreover, Chamberlain "saw the importance of 'providing some interest in life for the large numbers of men never likely to get work', and out of this realisation was to come the responsibility of the UAB for the 'welfare', not merely the maintenance, of the unemployed."

Defence spending had been heavily cut in Chamberlain's early budgets. By 1935, faced with a resurgent Germany under Hitler's leadership (see German re-armament), he was convinced of the need for rearmament. Chamberlain especially urged the strengthening of the Royal Air Force, realising that Britain's historical bulwark, the English Channel, was no defence against air power.

In 1935, MacDonald stood down as Prime Minister, and Baldwin became Prime Minister for the third time. In the 1935 general election, the Conservative-dominated National Government lost 90 seats from its massive 1931 majority, but still retained an overwhelming majority of 255 in the House of Commons. During the campaign, deputy Labour leader Arthur Greenwood had attacked Chamberlain for spending money on rearmament, saying that the rearmament policy was "the merest scaremongering; disgraceful in a statesman of Mr Chamberlain's responsible position, to suggest that more millions of money needed to be spent on armaments."

Chamberlain is believed to have had a significant role in the 1936 abdication crisis. He wrote in his diary that Wallis Simpson, Edward VIII's intended wife, was "an entirely unscrupulous woman who is not in love with the King but is exploiting him for her own purposes. She has already ruined him in money and jewels ..." In common with the rest of the Cabinet, except Duff Cooper, he agreed with Baldwin that the King should abdicate if he married Simpson, and on 6 December he and Baldwin both stressed that the King should make his decision before Christmas; by one account, he believed that the uncertainty was "hurting the Christmas trade". The King abdicated on 10 December, four days after the meeting.

Soon after the abdication Baldwin announced that he would remain until shortly after the coronation of King George VI and Queen Elizabeth. On 28 May, two weeks after the Coronation, Baldwin resigned, advising the King to send for Chamberlain. Austen did not live to see his brother's final "climb ... to the top of the greasy pole," having died two months earlier.

Upon his accession Chamberlain considered calling a general election, but with three and a half years remaining in the current Parliament's term he decided to wait. At 68 he was the second-oldest person in the 20th century (behind Sir Henry Campbell-Bannerman) to become Prime Minister for the first time, and was widely seen as a caretaker who would lead the Conservative Party until the next election and then step down in favour of a younger man, with Foreign Secretary Anthony Eden a likely candidate. From the start of Chamberlain's premiership a number of would-be successors were rumoured to be jockeying for position.

Chamberlain had disliked what he considered to be the overly sentimental attitude of both Baldwin and MacDonald on Cabinet appointments and reshuffles. Although he had worked closely with the President of the Board of Trade, Walter Runciman, on the tariff issue, Chamberlain dismissed him from his post, instead offering him the token position of Lord Privy Seal, which an angry Runciman declined. Chamberlain thought Runciman, a member of the Liberal National Party, to be lazy. Soon after taking office Chamberlain instructed his ministers to prepare two-year policy programmes. These reports were to be integrated with the intent of co-ordinating the passage of legislation through the current Parliament, the term of which was to expire in November 1940.

At the time of his succession Chamberlain's personality was not well known to the public, though he had made annual budget broadcasts for six years. According to Chamberlain biographer Robert Self, these appeared relaxed and modern, showing an ability to speak directly to the camera. Chamberlain had few friends among his parliamentary colleagues; an attempt by his Parliamentary Private Secretary, Lord Dunglass (later Prime Minister himself as Alec Douglas-Home), to bring him to the Commons Smoking Room to socialise with colleagues ended in embarrassing silence. Chamberlain compensated for these shortcomings by devising the most sophisticated press management system employed by a Prime Minister up to that time, with officials at Number 10, led by his chief of press George Steward, convincing members of the press that they were colleagues sharing power and insider knowledge, and should espouse the government line.

Chamberlain saw his elevation to the premiership as the final glory in a career as a domestic reformer, not realising that he would be remembered for foreign policy decisions. One reason he sought the settlement of European issues was the hope it would allow him to concentrate on domestic affairs.

Soon after attaining the premiership, Chamberlain obtained passage of the Factories Act 1937. This Act was aimed at bettering working conditions in factories, and placed limits on the working hours of women and children. In 1938, Parliament enacted the Coal Act 1938, which allowed for nationalisation of coal deposits. Another major law passed that year was the Holidays with Pay Act 1938. Though the Act only recommended that employers give workers a week off with pay, it led to a great expansion of holiday camps and other leisure accommodation for the working classes. The Housing Act 1938 provided subsidies aimed at encouraging slum clearance and maintained rent control. Chamberlain's plans for the reform of local government were shelved because of the outbreak of war in 1939. Likewise, the raising of the school-leaving age to 15, scheduled for implementation on 1 September 1939, did not go into effect.

Relations between the United Kingdom and the Irish Free State had been strained since the 1932 appointment of Éamon de Valera as President of the Executive Council. The Anglo-Irish Trade War, sparked by the withholding of money that Ireland had agreed to pay the United Kingdom, had caused economic losses on both sides, and the two nations were anxious for a settlement. The de Valera government also sought to sever the remaining ties between Ireland and the UK, such as ending the King's status as Irish Head of State. As Chancellor, Chamberlain had taken a hard-line stance against concessions to the Irish, but as premier sought a settlement with Ireland, being persuaded that the strained ties were affecting relations with other Dominions.

Talks had been suspended under Baldwin in 1936 but resumed in November 1937. De Valera sought not only to alter the constitutional status of Ireland, but to overturn other aspects of the Anglo-Irish Treaty, most notably the issue of partition, as well as obtaining full control of the three "Treaty Ports" which had remained in British control. Britain, on the other hand, wished to retain the Treaty Ports, at least in time of war, and to obtain the money that Ireland had agreed to pay.

The Irish proved very tough negotiators, so much so that Chamberlain complained that one of de Valera's offers had "presented United Kingdom ministers with a three-leafed shamrock, none of the leaves of which had any advantages for the UK." With the talks facing deadlock, Chamberlain made the Irish a final offer in March 1938 which acceded to many Irish positions, though he was confident that he had "only given up the small things," and the agreements were signed on 25 April 1938. The issue of partition was not resolved, but the Irish agreed to pay £10 million to the British. There was no provision in the treaties for British access to the Treaty Ports in time of war, but Chamberlain accepted de Valera's oral assurance that in the event of war the British would have access. Conservative backbencher Winston Churchill attacked the agreements in Parliament for surrendering the Treaty Ports, which he described as the "sentinel towers of the Western Approaches". When war came, de Valera denied Britain access to the Treaty Ports under Irish neutrality. Churchill railed against these treaties in "The Gathering Storm", stating that he "never saw the House of Commons more completely misled" and that "members were made to feel very differently about it when our existence hung in the balance during the Battle of the Atlantic." Chamberlain believed that the Treaty Ports were unusable if Ireland was hostile, and deemed their loss worthwhile to assure friendly relations with Dublin.

Chamberlain sought to conciliate Germany and make the Nazi state a partner in a stable Europe. He believed Germany could be satisfied by the restoration of some of her colonies, and during the Rhineland crisis of March 1936 he had stated that "if we were in sight of an all-round settlement the British government ought to consider the question" of restoration of colonies.

The new Prime Minister's attempts to secure such a settlement were frustrated because Germany was in no hurry to talk to Britain. Foreign Minister Konstantin von Neurath was supposed to visit Britain in July 1937 but cancelled his visit. Lord Halifax, the Lord President of the Council, visited Germany privately in November and met Hitler and other German officials. Both Chamberlain and British Ambassador to Germany Nevile Henderson pronounced the visit a success. Foreign Office officials complained that the Halifax visit made it appear Britain was too eager for talks, and the Foreign Secretary, Anthony Eden, felt that he had been bypassed.

Chamberlain also bypassed Eden while the Foreign Secretary was on holiday by opening direct talks with Italy, an international pariah for its invasion and conquest of Ethiopia. At a Cabinet meeting on 8 September 1937, Chamberlain indicated that he saw "the lessening of the tension between this country and Italy as a very valuable contribution toward the pacification and appeasement of Europe" which would "weaken the Rome–Berlin axis." The Prime Minister also set up a private line of communication with the Italian "Duce" Benito Mussolini through the Italian Ambassador, Count Dino Grandi.

In February 1938, Hitler began to press the Austrian government to accept "Anschluß," or union between Germany and Austria. Chamberlain believed that it was essential to cement relations with Italy in the hope that an Anglo–Italian alliance would forestall Hitler from imposing his rule over Austria. Eden believed that Chamberlain was being too hasty in talking with Italy and holding out the prospect of "de jure" recognition of Italy's conquest of Ethiopia. Chamberlain concluded that Eden would have to accept his policy or resign. The Cabinet heard both men out but unanimously decided for Chamberlain, and despite efforts by other Cabinet members to prevent it, Eden resigned from office. In later years, Eden tried to portray his resignation as a stand against appeasement (Churchill described him in "The Second World War" as "one strong young figure standing up against long, dismal, drawling tides of drift and surrender") but many ministers and MPs believed there was no issue at stake worth resignation. Chamberlain appointed Lord Halifax as Foreign Secretary in Eden's place.

In March 1938 Austria became a part of Germany in the "Anschluß". Though the beleaguered Austrians requested help from Britain, none was forthcoming. Britain did send Berlin a strong note of protest. In addressing the Cabinet shortly after German forces crossed the border, Chamberlain placed blame on both Germany and Austria. Chamberlain noted,

On 14 March, the day after the "Anschluß," Chamberlain addressed the House of Commons and strongly condemned the methods used by the Germans in the takeover of Austria. Chamberlain's address met with the approval of the House.
With Austria absorbed by Germany, attention turned to Hitler's obvious next target, the Sudetenland region of Czechoslovakia. With three million ethnic Germans, the Sudetenland represented the largest German population outside the "Reich" and Hitler began to call for the union of the region with Germany. Britain had no military obligations toward Czechoslovakia, but France and Czechoslovakia had a mutual assistance pact and both the French and Czechoslovaks also had an alliance with the Soviet Union. After the fall of Austria, the Cabinet's Foreign Policy Committee considered seeking a "grand alliance" to thwart Germany or, alternatively, an assurance to France of assistance if the French went to war. Instead, the committee chose to advocate that Czechoslovakia be urged to make the best terms it could with Germany. The full Cabinet agreed with the committee's recommendation, influenced by a report from the chiefs of staff stating that there was little that Britain could do to help the Czechs in the event of a German invasion. Chamberlain reported to an amenable House that he was unwilling to limit his government's discretion by giving commitments.

Britain and Italy signed an agreement in April 1938. In exchange for "de jure" recognition of Italy's Ethiopian conquest, Italy agreed to withdraw some Italian "volunteers" from the Nationalist (pro-Franco) side of the Spanish Civil War. By this point, the Nationalists strongly had the upper hand in that conflict, and they completed their victory the following year. Later that month, the new French Prime Minister, Édouard Daladier, came to London for talks with Chamberlain, and agreed to follow the British position on Czechoslovakia.

In May, Czech border guards shot two Sudeten German farmers who were trying to cross the border from Germany into Czechoslovakia without stopping for border controls. This incident caused unrest among the Sudeten Germans, and Germany was then said to be moving troops to the border. In response to the report, Prague moved troops to the German border. Halifax sent a note to Germany warning that if France intervened in the crisis on Czechoslovakia's behalf, Britain might support France. Tensions appeared to calm, and Chamberlain and Halifax were applauded for their "masterly" handling of the crisis. Though it was not known at the time, it later became clear that Germany had had no plans for a May invasion of Czechoslovakia. Nonetheless, the Chamberlain government received strong and almost unanimous support from the British press.

Negotiations between the Czech government and the Sudeten Germans dragged on through mid-1938. They achieved little result; Sudeten leader Konrad Henlein was under private instructions from Hitler not to reach an agreement. On 3 August, Walter Runciman (by now Lord Runciman) travelled to Prague as a mediator sent by the British government. Over the next two weeks, Runciman met separately with Henlein, Czechoslovak President Edvard Beneš, and other leaders, but made no progress. On 30 August. Chamberlain met his Cabinet and Ambassador Henderson and secured their backing—with only First Lord of the Admiralty Duff Cooper dissenting against Chamberlain's policy to pressure Czechoslovakia into making concessions, on the ground that Britain was then in no position to back up any threat to go to war.

Chamberlain realised that Hitler would likely signal his intentions in his 12 September speech at the annual Nuremberg Rally, and so the Prime Minister discussed with his advisors how to respond if war seemed likely. In consultation with his close advisor Sir Horace Wilson, Chamberlain set out "Plan Z". If war seemed inevitable, Chamberlain would fly to Germany to negotiate directly with Hitler.

Lord Runciman continued his work, attempting to pressure the Czechoslovak government into concessions. On 7 September there was an altercation involving Sudeten members of the Czechoslovak parliament in the North Moravian city of Ostrava ("Mährisch-Ostrau" in German). The Germans made considerable propaganda out of the incident, though the Prague government tried to conciliate them by dismissing Czech police who had been involved. As the tempest grew, Runciman concluded that there was no point in attempting further negotiations until after Hitler's speech. The mission never resumed.

There was tremendous tension in the final days before Hitler's speech on the last day of the Rally, as Britain, France, and Czechoslovakia all partially mobilised their troops. Thousands gathered outside 10 Downing Street on the night of the speech. At last Hitler addressed his wildly enthusiastic followers:

The following morning, 13 September, Chamberlain and the Cabinet were informed by Secret Service sources that all German embassies had been told that Germany would invade Czechoslovakia on 25 September. Convinced that the French would not fight (Daladier was privately proposing a three-Power summit to settle the Sudeten question), Chamberlain decided to implement "Plan Z" and sent a message to Hitler that he was willing to come to Germany to negotiate. Hitler accepted and Chamberlain flew to Germany on the morning of 15 September; this was the first time, excepting a short jaunt at an industrial fair, that Chamberlain had ever flown. Chamberlain flew to Munich and then travelled by rail to Hitler's retreat at Berchtesgaden.

The face to face meeting lasted about three hours. Hitler demanded the annexation of the Sudetenland, and through questioning him, Chamberlain was able to obtain assurances that Hitler had no designs on the remainder of Czechoslovakia or on the areas in Eastern Europe which had German minorities. After the meeting Chamberlain returned to London, believing that he had obtained a breathing space during which agreement could be reached and the peace preserved. Under the proposals made at Berchtesgaden the Sudetenland would be annexed by Germany if a plebiscite in the Sudetenland favoured it. Czechoslovakia would receive international guarantees of its independence which would replace existing treaty obligations—principally the French pledge to the Czechoslovaks. The French agreed to the requirements. Under considerable pressure the Czechoslovaks also agreed, causing the Czechoslovak government to fall.

Chamberlain flew back to Germany, meeting Hitler in Bad Godesberg on 22 September. Hitler brushed aside the proposals of the previous meeting, saying "that won't do any more". Hitler demanded immediate occupation of the Sudetenland and that Polish and Hungarian territorial claims on Czechoslovakia be addressed. Chamberlain objected strenuously, telling Hitler that he had worked to bring the French and Czechoslovaks into line with Germany's demands, so much so that he had been accused of giving in to dictators and had been booed on his departure that morning. Hitler was unmoved.

That evening, Chamberlain told Lord Halifax that the "meeting with Herr Hitler had been most unsatisfactory". The following day, Hitler kept Chamberlain waiting until mid-afternoon, when he sent a five-page letter, in German, outlining the demands he had made orally the previous day. Chamberlain replied by offering to act as an intermediary with the Czechoslovaks, and suggested that Hitler put his demands in a memorandum which could be circulated to the French and Czechoslovaks.

The leaders met again late on the evening of 23 September—a meeting which stretched into the early morning hours. Hitler demanded that fleeing Czechs in the zones to be occupied take nothing with them. He extended his deadline for occupation of the Sudetenland to 1 October—the date he had long before secretly set for the invasion of Czechoslovakia. The meeting ended amicably, with Chamberlain confiding to Hitler his hopes they would be able to work out other problems in Europe in the same spirit. Hitler hinted that the Sudetenland fulfilled his territorial ambitions in Europe. Chamberlain flew back to London, saying "It is up to the Czechs now."

Hitler's proposals met with resistance not only from the French and Czechoslovaks, but also from some members of Chamberlain's cabinet. With no agreement in sight, war seemed inevitable. The Prime Minister issued a press statement calling on Germany to abandon the threat of force in exchange for British help in obtaining the concessions it sought. On the evening of 27 September, Chamberlain addressed the nation by radio, and after thanking those who wrote to him, stated:

On 28 September, Chamberlain called on Hitler to invite him to Germany again to seek a solution through a summit involving the British, French, Germans, and Italians. Hitler replied favourably, and word of this response came to Chamberlain as he was winding up a speech in the House of Commons which sat in gloomy anticipation of war. Chamberlain informed the House of this in his speech. The response was a passionate demonstration, with members cheering Chamberlain wildly. Even diplomats in the galleries applauded. Lord Dunglass later commented, "There were a lot of appeasers in Parliament that day."

On the morning of 29 September Chamberlain left Heston Aerodrome (to the east of today's Heathrow Airport) for his third and final visit to Germany. On arrival in Munich the British delegation was taken directly to the "Führerbau", where Daladier, Mussolini, and Hitler soon arrived. The four leaders and their translators held an informal meeting; Hitler said that he intended to invade Czechoslovakia on 1 October. Mussolini distributed a proposal similar to Hitler's Bad Godesberg terms. In reality, the proposal had been drafted by German officials and transmitted to Rome the previous day. The four leaders debated the draft and Chamberlain raised the question of compensation for the Czechoslovak government and citizens, but Hitler refused to consider this.

The leaders were joined by advisors after lunch, and hours were spent on long discussions of each clause of the "Italian" draft agreement. Late that evening the British and French left for their hotels, saying that they had to seek advice from their respective capitals. Meanwhile, the Germans and Italians enjoyed the feast which Hitler had intended for all the participants. During this break, Chamberlain advisor Sir Horace Wilson met with the Czechoslovaks; he informed them of the draft agreement and asked which districts were particularly important to them. The conference resumed at about 10 pm and was mostly in the hands of a small drafting committee. At 1:30 am the Munich Agreement was ready for signing, though the signing ceremony was delayed when Hitler discovered that the ornate inkwell on his desk was empty.

Chamberlain and Daladier returned to their hotel and informed the Czechoslovaks of the agreement. The two Prime Ministers urged quick acceptance by the Czechoslovaks of the agreement, since the evacuation by the Czechs was to begin the following day. At 12:30 pm the Czechoslovak government in Prague objected to the decision but agreed to its terms.

Before leaving the ""Führerbau"," Chamberlain requested a private conference with Hitler. Hitler agreed, and the two met at Hitler's apartment in the city later that morning. Chamberlain urged restraint in the implementation of the agreement and requested that the Germans not bomb Prague if the Czechs resisted, to which Hitler seemed agreeable. Chamberlain took from his pocket a paper headed "Anglo–German Agreement," which contained three paragraphs, including a statement that the two nations considered the Munich Agreement "symbolic of the desire of our two peoples never to go to war again." According to Chamberlain, Hitler interjected ""Ja! Ja!"" ("Yes! Yes!") as the Prime Minister read it. The two men signed the paper then and there. When, later that day, German Foreign Minister Joachim von Ribbentrop remonstrated with Hitler for signing it, the Führer replied, "Oh, don't take it so seriously. That piece of paper is of no further significance whatever." Chamberlain, on the other hand, patted his breast pocket when he returned to his hotel for lunch and said, "I've got it!" Word leaked of the outcome of the meetings before Chamberlain's return, causing delight among many in London but gloom for Churchill and his supporters.

Chamberlain returned to London in triumph. Large crowds mobbed Heston, where he was met by the Lord Chamberlain, the Earl of Clarendon, who gave him a letter from King George VI assuring him of the Empire's lasting gratitude and urging him to come straight to Buckingham Palace to report. The streets were so packed with cheering people that it took Chamberlain an hour and a half to journey the nine miles (14 km) from Heston to the Palace. After reporting to the King, Chamberlain and his wife appeared on the Palace balcony with the King and Queen. He then went to Downing Street; both the street and the front hall of Number 10 were packed. As he headed upstairs to address the crowd from a first-floor window, someone called to him, "Neville, go up to the window and say 'peace for our time'." Chamberlain turned around and responded, "No, I don't do that sort of thing." Nevertheless, in his statement to the crowd, Chamberlain recalled the words of his predecessor, Benjamin Disraeli, upon the latter's return from the Congress of Berlin:

King George issued a statement to his people, "After the magnificent efforts of the Prime Minister in the cause of peace it is my fervent hope that a new era of friendship and prosperity may be dawning among the peoples of the world." When the King met Duff Cooper, who resigned as First Lord of the Admiralty over the Munich Agreement, he told Cooper that he respected people who had the courage of their convictions, but could not agree with him. He wrote to his mother, Queen Mary, that "the Prime Minister was delighted with the results of his mission, as are we all." The dowager queen responded to her son with anger against those who spoke against the Prime Minister: "He brought home peace, why can't they be grateful?" Most newspapers supported Chamberlain uncritically, and he received thousands of gifts, from a silver dinner service to many of his trademark umbrellas.

The Commons discussed the Munich Agreement on 3 October. Though Cooper opened by setting forth the reasons for his resignation and Churchill spoke harshly against the pact, no Conservative voted against the government. Only between 20 and 30 abstained, including Churchill, Eden, Cooper, and Harold Macmillan.

In the aftermath of Munich, Chamberlain continued to pursue a course of cautious rearmament. He told the Cabinet in early October 1938, "<nowiki>[I]</nowiki>t would be madness for the country to stop rearming until we were convinced that other countries would act in the same way. For the time being, therefore, we should relax no particle of effort until our deficiencies had been made good." Later in October, he resisted calls to put industry on a war footing, convinced that such an action would show Hitler that the Prime Minister had decided to abandon Munich. Chamberlain hoped that the understanding he had signed with Hitler at Munich would lead toward a general settlement of European disputes, but Hitler expressed no public interest in following up on the accord. Having considered a general election immediately following Munich, Chamberlain instead reshuffled his Cabinet. By the end of the year, public concerns caused Chamberlain to conclude that "to get rid of this uneasy and disgruntled House of Commons by a General Election" would be "suicidal".

Despite Hitler's relative quietness as the "Reich" absorbed the Sudetenland, foreign policy concerns continued to preoccupy Chamberlain. He made trips to Paris and Rome, hoping to persuade the French to hasten their rearmament and Mussolini to be a positive influence on Hitler. Several of his Cabinet members, led by Foreign Secretary Lord Halifax, began to draw away from the appeasement policy. Halifax was by now convinced that Munich, though "better than a European war," had been "a horrid business and humiliating". Public revulsion over the pogrom of "Kristallnacht" on 9 November 1938 made any attempt at a "rapprochement" with Hitler unacceptable, though Chamberlain did not abandon his hopes.

Still hoping for reconciliation with Germany, Chamberlain made a major speech in Birmingham on 28 January 1939, in which he expressed his desire for international peace, and had an advance copy sent to Hitler at Berchtesgaden. Hitler seemed to respond; in his "Reichstag" speech on 30 January 1939, he stated that he wanted a "long peace". Chamberlain was confident that improvements in British defence since Munich would bring the dictator to the bargaining table. This belief was reinforced by a German official's conciliatory speech welcoming Ambassador Henderson back to Berlin after an absence for medical treatment in Britain. Chamberlain responded with a speech in Blackburn on 22 February hoping that the nations would resolve their differences through trade, and was gratified when his comments were printed in German newspapers. With matters appearing to improve, Chamberlain's rule over the House of Commons was firm and he was convinced the government would "romp home" in a late 1939 election.

On 15 March 1939, Germany invaded the Czech provinces of Bohemia and Moravia, including Prague. Though Chamberlain's initial parliamentary response was, according to biographer Nick Smart, "feeble," within 48 hours he had spoken more forcefully against the German aggression. In another Birmingham speech, on 17 March, Chamberlain warned that Hitler was attempting to "dominate the world by force" and that "no greater mistake could be made than to suppose that because it believes war to be a senseless and cruel thing the nation has so lost its fibre that it will not take part to the utmost of its power in resisting such a challenge if it were ever made." The Prime Minister questioned whether the invasion of Czechoslovakia was "the end of an old adventure, or the beginning of a new" and whether it was "a step in the direction of an attempt to dominate the world by force." Colonial Secretary Malcolm MacDonald said, "whereas the Prime Minister was once a strong advocate of peace, he has now definitely swung around to the war point of view." This speech was met with widespread approval in Britain and recruitment for the armed services increased considerably.

Chamberlain set out to build an interlocking series of defence pacts among the remaining European countries as a means of deterring Hitler from war. He sought an agreement among Britain, France, the USSR, and Poland, whereby the first three would go to the assistance of Poland if her independence were threatened, but Polish mistrust of the Soviet Union caused those negotiations to fail. Instead, on 31 March 1939, Chamberlain informed an approving House of Commons of British and French guarantees that they would lend Poland all possible aid in the event of any action which threatened Polish independence. In the ensuing debate, Eden stated that the nation was now united behind the government. Even Churchill and Lloyd George praised Chamberlain's government for issuing the guarantee to Poland.

The Prime Minister took other steps to deter Hitler from aggression. He doubled the size of the Territorial Army, created a Ministry of Supply to expedite the provision of equipment to the armed forces, and instituted peacetime conscription. The Italian invasion of Albania on 7 April 1939 led to guarantees being given to Greece and Romania. On 17 June 1939, Handley Page received an order for 200 Hampden twin-engined medium bombers, and by 3 September 1939, the chain of radar stations girdling the British coast was fully operational.

Chamberlain was reluctant to seek a military alliance with the Soviet Union; he distrusted Joseph Stalin ideologically and felt that there was little to gain, given the recent massive purges in the Red Army. Much of his Cabinet favoured such an alliance, and when Poland withdrew her objection to an Anglo–Soviet alliance, Chamberlain had little choice but to proceed. The talks with Soviet Foreign Minister Vyacheslav Molotov, to which Britain sent only a low-level delegation, dragged on over several months and eventually foundered on 14 August 1939 when Poland and Romania refused to allow Soviet troops to be stationed on their territories. A week after the failure of these talks, the Soviet Union and Germany signed the Molotov–Ribbentrop Pact, committing the countries to non-aggression toward each other. A secret agreement divided up Poland in the event of war. Chamberlain had disregarded rumours of a Soviet–German "rapprochement" and was dismissive of the publicly announced pact, stating that it in no way affected British obligations toward Poland. On 23 August 1939, Chamberlain had Henderson deliver a letter to Hitler telling him that Britain was fully prepared to comply with its obligations to Poland. Hitler instructed his generals to prepare for an invasion of Poland, telling them, "Our enemies are small worms. I saw them at Munich."

Germany invaded Poland in the early morning of 1 September 1939. The British Cabinet met late that morning and issued a warning to Germany that unless it withdrew from Polish territory Britain would carry out its obligations to Poland. When the House of Commons met at 6:00 pm, Chamberlain and Labour deputy leader Arthur Greenwood (deputising for the sick Clement Attlee) entered the chamber to loud cheers. Chamberlain spoke emotionally, laying the blame for the conflict on Hitler.

No formal declaration of war was immediately made. French Foreign Minister Georges Bonnet stated that France could do nothing until its parliament met on the evening of 2 September. Bonnet was trying to rally support for a Munich-style summit proposed by the Italians to be held on 5 September. The British Cabinet demanded that Hitler be given an ultimatum at once, and if troops were not withdrawn by the end of 2 September, that war be declared forthwith. Chamberlain and Halifax were convinced by Bonnet's pleas from Paris that France needed more time for mobilisation and evacuation, and postponed the expiry of the ultimatum (which had in fact not yet been served). Chamberlain's lengthy statement to the House of Commons made no mention of an ultimatum, and the House received it badly. When Greenwood rose to "speak for the working classes," Conservative backbencher Leo Amery urged him, "Speak for England, Arthur," implying that the Prime Minister was not doing so. Chamberlain replied that telephone difficulties were making it hard to communicate with Paris and tried to dispel fears that the French were weakening. He had little success; too many members knew of Bonnet's efforts. National Labour MP and diarist Harold Nicolson later wrote, "In those few minutes he flung away his reputation." The seeming delay gave rise to fears that Chamberlain would again seek a settlement with Hitler. Chamberlain's last peacetime Cabinet met at 11:30 that night, with a thunderstorm raging outside, and determined that the ultimatum would be presented in Berlin at nine o'clock the following morning—to expire two hours later, before the House of Commons convened at noon. At 11:15 am, 3 September 1939, Chamberlain addressed the nation by radio, stating that the United Kingdom was at war with Germany:

That afternoon Chamberlain addressed the House of Commons' first Sunday session in over 120 years. He spoke to a quiet House in a statement which even opponents termed "restrained and therefore effective":

Chamberlain instituted a War Cabinet and invited the Labour and Liberal parties to join his government, but they declined. He restored Churchill to the Cabinet as First Lord of the Admiralty, with a seat in the War Cabinet. Chamberlain also gave Eden a government post (Dominions Secretary) but not a seat in the small War Cabinet. The new First Lord proved to be a difficult Cabinet colleague, deluging the Prime Minister with a sea of lengthy memos. Chamberlain castigated Churchill for sending so many memos, as the two met in War Cabinet every day. Chamberlain suspected, correctly as it proved after the war, that "these letters are for the purpose of quotation in the Book that he will write hereafter." Chamberlain was also able to deter some of Churchill's more extreme plans, such as Operation Catherine, which would have sent three heavily armoured battleships into the Baltic Sea with an aircraft carrier and other support vessels as a means of stopping shipments of iron ore to Germany. With the naval war the only significant front involving the British in the early months of the conflict, the First Lord's obvious desire to wage a ruthless, victorious war established him as a leader-in-waiting in the public consciousness and among parliamentary colleagues.

With little land action in the west, the initial months of the war were dubbed the "Bore War," later renamed the "Phoney War" by journalists. Chamberlain, in common with most Allied officials and generals, felt the war could be won relatively quickly by keeping economic pressure on Germany through a blockade while continuing rearmament. The Prime Minister was reluctant to go too far in altering the British economy. The government submitted an emergency war budget about which Chamberlain stated, "the only thing that matters is to win the war, though we may go bankrupt in the process." Government expenditures rose by little more than the rate of inflation between September 1939 and March 1940. Despite these difficulties, Chamberlain still enjoyed approval ratings as high as 68% and almost 60% in April 1940.

In early 1940 the Allies approved a naval campaign designed to seize the northern part of Norway, a neutral country, including the key port of Narvik, and possibly also to seize the iron mines at Gällivare in northern Sweden, from which Germany obtained much of its iron ore. As the Baltic froze in winter, the iron ore was then sent south by ship from Narvik. The Allies planned to begin by mining Norwegian waters, thus provoking a German reaction in Norway, and then would occupy much of the country. Unforeseen by the Allies, Germany had also planned to occupy Norway, and on 9 April German troops occupied Denmark and began an invasion of Norway. German forces quickly overran much of the country. The Allies sent troops to Norway, but they met with little success, and on 26 April the War Cabinet ordered a withdrawal. The Prime Minister's opponents decided to turn the adjournment debate for the Whitsun recess into a challenge to Chamberlain, who soon heard about the plan. After initial anger, Chamberlain determined to fight.

What became known as the "Norway debate" opened on 7 May, and lasted for two days. The initial speeches, including Chamberlain's, were nondescript, but Admiral of the Fleet Sir Roger Keyes, member for Portsmouth North, in full uniform, delivered a withering attack on the conduct of the Norway campaign, though he excluded Churchill from criticism. Leo Amery then delivered a speech which he concluded by echoing Oliver Cromwell's words on dissolving the Long Parliament: "You have sat here too long for any good you are doing. Depart, I say, and let us have done with you. In the name of God, go!" When Labour announced that they would call for a division of the House of Commons, Chamberlain called upon his "friends—and I still have some friends in this House—to support the Government tonight." Because the use of the word "friends" was a conventional term to refer to party colleagues, and, according to biographer Robert Self, many MPs took it that way, it was an "error of judgment" for Chamberlain to refer to party loyalty "when the gravity of the war situation required national unity." Lloyd George joined the attackers, and Churchill concluded the debate with a vigorous speech in support of the government. When the division took place, the government, which had a normal majority of over 200, prevailed by only 81, with 38 MPs in receipt of the government whip voting against it, with between 20 and 25 abstaining.

Chamberlain spent much of 9 May in meetings with his Cabinet colleagues. Many Conservative MPs, even those who had voted against the government, indicated on 9 May and in the days following that they did not wish Chamberlain to depart but rather would seek to reconstruct his government. Chamberlain decided that he would resign unless the Labour Party was willing to join his government, and so he met with Attlee later that day. Attlee was unwilling, but agreed to consult his National Executive then meeting in Bournemouth. Chamberlain favoured Halifax as the next Prime Minister, but Halifax proved reluctant to press his own claims, and Churchill emerged as the choice. The following day, Germany invaded the Low Countries and Chamberlain considered remaining in office. Attlee confirmed that Labour would not serve under Chamberlain, though they were willing to serve under someone else. Accordingly, Chamberlain went to Buckingham Palace to resign and advise the King to send for Churchill. Churchill later expressed gratitude to Chamberlain for not advising the King to send for Halifax, who would have commanded the support of most government MPs. In a resignation broadcast that evening, Chamberlain told the nation,

Queen Elizabeth told Chamberlain that her daughter, Princess Elizabeth, wept as she heard the broadcast. Churchill wrote to express his gratitude for Chamberlain's willingness to stand by him in the nation's hour of need, and Lord Baldwin, the only living former Prime Minister besides Chamberlain and Lloyd George, wrote, "You have passed through fire since we were talking together only a fortnight ago, and you have come out pure gold."

In a departure from usual practice, Chamberlain did not issue any resignation Honours list. With Chamberlain remaining leader of the Conservative Party, and with many MPs still supporting him and distrusting the new Prime Minister, Churchill refrained from any purge of Chamberlain loyalists. Churchill wished Chamberlain to return to the Exchequer, but he declined, convinced that this would lead to difficulties with the Labour Party. Instead, he accepted the post of Lord President of the Council with a seat in the shrunken five-member War Cabinet. When Chamberlain entered the House of Commons on 13 May 1940, for the first time since his resignation, "MPs lost their heads, they shouted, they cheered, they waved their order papers, and his reception was a regular ovation." The House received Churchill coolly; some of his great speeches to the chamber, such as "We shall fight on the beaches," met with only half-hearted enthusiasm.

Chamberlain's fall from power left him deeply depressed; he wrote, "Few men can have known such a reversal of fortune in so short a time." He especially regretted the loss of Chequers as "a place where I have been so happy," though after a farewell visit there by the Chamberlains on 19 June, he wrote, "I am content now that I have done that, and shall put Chequers out of my mind." As Lord President, Chamberlain assumed vast responsibilities over domestic issues and chaired the War Cabinet during Churchill's many absences. Attlee later remembered him as "free from any of the rancour he might have felt against us. He worked very hard and well: a good chairman, a good committeeman, always very businesslike." As chairman of the Lord President's Committee, he exerted great influence over the wartime economy. Halifax reported to the War Cabinet on 26 May 1940, with the Low Countries conquered and French Prime Minister Paul Reynaud warning that France might have to sign an armistice, that diplomatic contacts with a still-neutral Italy offered the possibility of a negotiated peace. Halifax urged following up and seeing if a worthwhile offer could be obtained. The battle over the course of action within the War Cabinet lasted three days; Chamberlain's statement on the final day, that there was unlikely to be an acceptable offer and that the matter should not be pursued at that time, helped persuade the War Cabinet to reject negotiations.

Twice in May 1940, Churchill broached the subject of bringing Lloyd George into the government. Each time, Chamberlain indicated that due to their longtime antipathy he would immediately retire if Lloyd George were appointed a minister. Churchill did not appoint Lloyd George, but brought up the subject with Chamberlain again early in June. This time, Chamberlain agreed to Lloyd George's appointment provided Lloyd George gave a personal assurance to put aside the feud. Lloyd George declined to serve in Churchill's government.

Chamberlain worked to bring his Conservative Party in line behind Churchill, working with the Chief Whip, David Margesson, to overcome members' suspicions and dislikes of the Prime Minister. On 4 July, after the British attack on the French fleet, Churchill entered the chamber to a great cheer from Conservative MPs orchestrated by the two, and the Prime Minister was almost overcome with emotion at the first cheer he had received from his own party's benches since May. Churchill returned the loyalty, refusing to consider Labour and Liberal attempts to expel Chamberlain from the government. When criticisms of Chamberlain appeared in the press, and when Chamberlain learned that Labour intended to use an upcoming secret session of Parliament as a platform to attack him, he told Churchill that he could only defend himself by attacking Labour. The Prime Minister intervened with the Labour Party and the press and the criticism ceased, according to Chamberlain, "like turning off a tap".

In July 1940, a polemic titled "Guilty Men" was released by "Cato"—a pseudonym for three journalists (future Labour leader Michael Foot, former Liberal MP Frank Owen, and the Conservative Peter Howard). It attacked the record of the National Government, alleging that it had failed to prepare adequately for war. It called for the removal of Chamberlain and other ministers who had allegedly contributed to the British disasters of the early part of the war. The short book sold more than 200,000 copies, many of which were passed from hand-to-hand, and went into 27 editions in the first few months, despite not being carried by several major bookshops. According to historian David Dutton, "its impact upon Chamberlain's reputation, both among the general public and within the academic world, was profound indeed."

Chamberlain had long enjoyed excellent health, except for occasional attacks of gout, but by July 1940 he was in almost constant pain. He sought treatment, and later that month entered hospital for surgery. Surgeons discovered that he was suffering from terminal bowel cancer, but they concealed it from him, instead telling him that he would not require further surgery. Chamberlain resumed work in mid-August. He returned to his office on 9 September, but renewed pain, compounded by the night-time bombing of London which forced him to go to an air raid shelter and denied him rest, sapped his energy, and he left London for the last time on 19 September, returning to Highfield Park in Heckfield. Chamberlain offered his resignation to Churchill on 22 September 1940. The Prime Minister was initially reluctant to accept, but as both men realised that Chamberlain would never return to work, Churchill finally allowed him to resign. The Prime Minister asked if Chamberlain would accept the highest order of British chivalry, the Order of the Garter, of which his brother had been a member. Chamberlain refused, saying he would "prefer to die plain 'Mr Chamberlain' like my father before me, unadorned by any title."

In the short time remaining to him, Chamberlain was angered by the "short, cold and for the most part depreciatory" press comments on his retirement, according to him written "without the slightest sign of sympathy for the man or even any comprehension that there may be a human tragedy in the background." The King and Queen drove down from Windsor to visit the dying man on 14 October. Chamberlain received hundreds of sympathetic letters from friends and supporters. He wrote to John Simon, who had served as Chancellor of the Exchequer in Chamberlain's government:

Chamberlain died of bowel cancer on 9 November 1940 at the age of 71. A funeral service took place at Westminster Abbey (due to wartime security concerns, the date and time were not widely publicised). After cremation, his ashes were interred in the Abbey next to those of Bonar Law. Churchill eulogised Chamberlain in the House of Commons three days after his death:

Though some Chamberlain supporters found Churchill's oratory to be faint praise of the late Prime Minister, Churchill added less publicly, "Whatever shall I do without poor Neville? I was relying on him to look after the Home Front for me." Amongst others who paid tribute to Chamberlain in the Commons and in the House of Lords on 12 November 1940 were Foreign Secretary Lord Halifax (1st Earl of Halifax, Edward Wood), the Leader of the Labour Party, Clement Attlee, and the Liberal Party leader and Air Minister, Sir Archibald Sinclair. Lloyd George, the only former Prime Minister remaining in the Commons, had been expected to speak, but absented himself from the proceedings. Ever close to his family, the executors of Chamberlain's will were his cousins, Wilfred Byng Kenrick and Sir Wilfrid Martineau, both of whom, like Chamberlain, were Lord Mayors of Birmingham.

A few days before his death, Neville Chamberlain wrote,

"Guilty Men" was not the only Second World War tract that damaged Chamberlain's reputation. "We Were Not All Wrong", published in 1941, took a similar tack to "Guilty Men", arguing that Liberal and Labour MPs, and a small number of Conservatives, had fought against Chamberlain's appeasement policies. The author, Liberal MP Geoffrey Mander, had voted against conscription in 1939. Another polemic against Conservative policies was "Why Not Trust the Tories" (1944, written by "Gracchus", who was later revealed to be future Labour minister Aneurin Bevan), which castigated the Conservatives for the foreign policy decisions of Baldwin and Chamberlain. Though a few Conservatives offered their own versions of events, most notably MP Quintin Hogg in his 1945 "The Left was Never Right", by the end of the war, there was a very strong public belief that Chamberlain was culpable for serious diplomatic and military misjudgements that had nearly caused Britain's defeat.

Chamberlain's reputation was devastated by these attacks from the left. In 1948, with the publication of "The Gathering Storm", the first volume of Churchill's six-volume set, "The Second World War", Chamberlain sustained an even more serious assault from the right. While Churchill stated privately, "this is not history, this is my case", his series was still hugely influential. Churchill depicted Chamberlain as well-meaning but weak, blind to the threat posed by Hitler, and oblivious to the fact that (according to Churchill) Hitler could have been removed from power by a grand coalition of European states. Churchill suggested that the year's delay between Munich and war worsened Britain's position, and criticised Chamberlain for both peacetime and wartime decisions. In the years following the publication of Churchill's books, few historians questioned his judgment.

Anne Chamberlain, the former premier's widow, suggested that Churchill's work was filled with matters that "are not real misstatements that could easily be corrected, but wholesale omissions and assumptions that certain things are now recognised as facts which actually have no such position".

Many of Chamberlain's family letters and his extensive personal papers were bequeathed by his family in 1974 to the Birmingham University Archives. During the war, the Chamberlain family had commissioned historian Keith Feiling to produce an official biography, and gave him access to Chamberlain's private diaries and papers. While Feiling had the right of access to official papers as the official biographer of a recently deceased person, he may not have been aware of the provision, and the Cabinet Secretary denied his requests for access.

Though Feiling produced what historian David Dutton described in 2001 as "the most impressive and persuasive single-volume biography" of Chamberlain (completed during the war and published in 1946), he could not repair the damage already done to Chamberlain's reputation.

Conservative MP Iain Macleod's 1961 biography of Chamberlain was the first major biography of a revisionist school of thought on Chamberlain. The same year, A. J. P. Taylor, in his "The Origins of the Second World War", found that Chamberlain had adequately rearmed Britain for defence (though a rearmament designed to defeat Germany would have taken massive additional resources) and described Munich as "a triumph for all that was best and most enlightened in British life ... <nowiki>[and]</nowiki> for those who had courageously denounced the harshness and short-sightedness of Versailles".

The adoption of the "thirty-year rule" in 1967 made available many of the papers of the Chamberlain government over the subsequent three years, helping to explain why Chamberlain acted as he did. The resultant works greatly fuelled the revisionist school, although they also included books that strongly criticised Chamberlain, such as Keith Middlemas's 1972 "Diplomacy of Illusion" (which portrayed Chamberlain as a seasoned politician with strategic blindness when it came to Germany). Released papers indicated that, contrary to claims made in "Guilty Men", Chamberlain had neither ignored the advice of the Foreign Office nor had he disregarded and run roughshod over his Cabinet. Other released papers showed that Chamberlain had considered seeking a grand coalition amongst European governments like that later advocated by Churchill, but had rejected it on the ground that the division of Europe into two camps would make war more, not less likely. They also showed that Chamberlain had been advised that the Dominions, pursuing independent foreign policies under the Statute of Westminster, had indicated that Chamberlain could not depend on their help in the event of a Continental war. The Chiefs of Staff report, which indicated that Britain could not forcibly prevent Germany from conquering Czechoslovakia, was first publicly known at this time.
In reaction to the revisionist school of thought regarding Chamberlain a post-revisionist school emerged beginning in the 1990s, using the released papers to justify the initial conclusions of "Guilty Men". Oxford historian R. A. C. Parker argued that Chamberlain could have forged a close alliance with France after the "Anschluß", in early 1938, and begun a policy of containment of Germany under the auspices of the League of Nations. While many revisionist writers had suggested that Chamberlain had had few or no choices in his actions, Parker argued that Chamberlain and his colleagues had chosen appeasement over other viable policies. In his two volumes, "Chamberlain and Appeasement" (1993) and "Churchill and Appeasement" (2000), Parker stated that Chamberlain, due to his "powerful, obstinate personality" and his skill in debate, caused Britain to embrace appeasement instead of effective deterrence. Parker also suggested that had Churchill held high office in the second half of the 1930s Churchill would have built a series of alliances which would have deterred Hitler, and perhaps would have caused Hitler's domestic opponents to procure his removal.

Dutton observes that Chamberlain's reputation, for good or ill, will probably always be closely tied to evaluation of his policy toward Germany:




Explanatory notes
Citations





</doc>
<doc id="21454" url="https://en.wikipedia.org/wiki?curid=21454" title="Nicanor Parra">
Nicanor Parra

Nicanor Segundo Parra Sandoval (5 September 1914 – 23 January 2018) was a Chilean poet and physicist. He is considered one of the most influential poets in the Spanish language of the 20th century, often compared with Pablo Neruda. Parra described himself as an "anti-poet," due to his distaste for standard poetic pomp and function; after recitations he would exclaim ""Me retracto de todo lo dicho"" ("I take back everything I said").

Parra, the son of a schoolteacher, was born in 1914 in San Fabián de Alico, near Chillán, in Chile. He came from the artistically prolific Parra family of performers, musicians, artists, and writers. His sister, Violeta Parra, was a folk singer, as was his brother Roberto Parra Sandoval.

In 1933, he entered the Instituto Pedagógico of the University of Chile, where he qualified as a teacher of mathematics and physics in 1938, one year after the publication of his first book, "Cancionero sin Nombre". After teaching in Chilean secondary schools, in 1943 he enrolled in Brown University in the United States to study physics. In 1948, he attended Oxford University to study cosmology. He returned to Chile as a professor at the Universidad de Chile in 1952. Parra served as a professor of theoretical physics at the University of Chile from 1952 to 1991, and was a visiting professor at Louisiana State University, New York University, and Yale University. He read his poetry in England, France, Russia, Mexico, Cuba, and the United States. He published dozens of books.

His collection "Poemas y Antipoemas" (1954) is a classic of Latin American literature, one of the most influential Spanish poetry collections of the twentieth century. It is cited as an inspiration by American Beat writers such as Allen Ginsberg.
A fictionalized version of Parra appeared in Alejandro Jodorowsky's autobiographical film "Endless Poetry" (2016).

Parra died on 23 January 2018, at 7:00 am, in La Reina in Santiago de Chile, at the age of 103.

Parra was proposed on four occasions for the Nobel Prize in Literature. On 1 December 2011, Parra won the Spanish Ministry of Culture's Cervantes Prize, the most important literary prize in the Spanish-speaking world. On 7 June 2012, he won the Pablo Neruda Ibero-American Poetry Award.


English translations



</doc>
<doc id="21458" url="https://en.wikipedia.org/wiki?curid=21458" title="Norma MacMillan">
Norma MacMillan

Norma MacMillan (September 15, 1921 – March 16, 2001) was a Canadian actress and voice actress, best known for voicing numerous animation and claymation children's characters, including Casper the Friendly Ghost on "The New Casper Cartoon Show", Gumby on "The Gumby Show" and Davey on "Davey and Goliath".

MacMillan was born on September 15, 1921, in Vancouver, British Columbia, Canada, and began her career there as a stage actress. It was in Vancouver that she met, worked with and married her producer/manager husband Thor Arngrim. In 1954, MacMillan, her husband and his business partner Stuart Baker, set out for Toronto where she began landing work voicing children's roles for CBC.

After she and her husband moved to New York, MacMillan lent her voice talents to numerous roles; as "Casper the Friendly Ghost" on "The New Casper Cartoon Show", as "Gumby" on "The Gumby Show", as "Sweet Polly Purebred" in the "Underdog" cartoons, and as "Davey" on the claymation series "Davey and Goliath" among others. In addition to these roles, MacMillan also voiced the roles of John-John and Caroline Kennedy in the world record setting "The First Family" album of 1962.

In addition to her voice roles, MacMillan also appeared as an on-screen actress in various television and films roles. Her on-screen work included guest-starring roles on such television shows as "Columbo", "She's the Sheriff", "Webster" and "Thirtysomething". During this time, she also appeared in feature films, including "", "Big Business", "Love at Stake", "", "Big Bully", and "Mrs. Delafield Wants to Marry" with Katharine Hepburn.

MacMillan appeared in numerous television commercials, but perhaps her most visible acting role was the part she played in the 1980s as the sweet, demure, naive "Aunt Martha" opposite 's "Aunt Harriet" for Kraft Foods mayonnaise commercials. Upon returning to Vancouver with her husband in the mid-1990s, MacMillan joined the Co-Op Radio's Sunday show for senior citizens and was a board member of the local 411 Seniors Centre.

While in Canada, MacMillan went on to voice characters in a number of later animated series and films such as "Funky Fables", "Fat Dog Mendoza", "Madeline", "Generation O!", "Milo's Bug Quest" and "The Animated Adventures of Tom Sawyer".

MacMillan was the mother of Stefan Arngrim (born December 23, 1955), who played Barry Lockridge on "Land of the Giants", and Alison Arngrim (born January 18, 1962), who played Nellie Oleson on "Little House on the Prairie". MacMillan and her husband Thor returned to Canada in 1993. 

MacMillan died in March 2001, at the age of 79 and Thor died in 2009 in Vancouver, British Columbia.



</doc>
<doc id="21459" url="https://en.wikipedia.org/wiki?curid=21459" title="Nevanlinna Prize">
Nevanlinna Prize

The Rolf Nevanlinna Prize, known from 2022 as the IMU Abacus Medal, is awarded once every four years at the International Congress of Mathematicians, for outstanding contributions in Mathematical Aspects of Information Sciences including:


The prize was established in 1981 by the Executive Committee of the International Mathematical Union and named for the Finnish mathematician Rolf Nevanlinna. It consists of a gold medal and cash prize. Like the Fields Medal the prize is targeted at younger mathematicians, and only those younger than 40 on January 1 of the award year are eligible.

The prize was named to honour the Finnish mathematician Rolf Nevanlinna who had died a year before the prize's creation in 1981. The medal features a profile of Nevanlinna, the text "Rolf Nevanlinna Prize", and very small characters "RH 83" on its obverse. RH refers to Raimo Heino, the medal's designer, and 83 to the year of first minting. On the reverse, two figures related to the University of Helsinki, the prize sponsor, are engraved. The rim bears the name of the prizewinner.

Alexander Soifer, president of the World Federation of National Mathematics Competitions, complained about the prize's honouring of Nevanlinna, as he was a supporter of Hitler and had acted as a representative for the Finnish Volunteer Battalion of the Waffen-SS during World War II. Soifer discussed Nevanlinna's wartime activities in a 2015 book, and forwarded his personal and his organization’s requests to the Executive Committee of IMU to change the Prize's name. In July 2018, the 18th General Assembly of the IMU decided to remove the name of Rolf Nevanlinna from the prize. It was later announced that the prize would be named the IMU Abacus Medal.




</doc>
<doc id="21460" url="https://en.wikipedia.org/wiki?curid=21460" title="November 1">
November 1





</doc>
<doc id="21461" url="https://en.wikipedia.org/wiki?curid=21461" title="November 2">
November 2





</doc>
<doc id="21462" url="https://en.wikipedia.org/wiki?curid=21462" title="Normal distribution">
Normal distribution

formula_14

In probability theory, a normal (or Gaussian or Gauss or Laplace–Gauss) distribution is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function is
The parameter formula_3 is the mean or expectation of the distribution (and also its median and mode), while the parameter formula_18 is its standard deviation. The variance of the distribution is formula_6. A random variable with a Gaussian distribution is said to be normally distributed, and is called a normal deviate.

Normal distributions are important in statistics and are often used in the natural and social sciences to represent real-valued random variables whose distributions are not known. Their importance is partly due to the central limit theorem. It states that, under some conditions, the average of many samples (observations) of a random variable with finite mean and variance is itself a random variable—whose distribution converges to a normal distribution as the number of samples increases. Therefore, physical quantities that are expected to be the sum of many independent processes, such as measurement errors, often have distributions that are nearly normal.

Moreover, Gaussian distributions have some unique properties that are valuable in analytic studies. For instance, any linear combination of a fixed collection of normal deviates is a normal deviate. Many results and methods, such as propagation of uncertainty and least squares parameter fitting, can be derived analytically in explicit form when the relevant variables are normally distributed.

A normal distribution is sometimes informally called a bell curve. However, many other distributions are bell-shaped (such as the Cauchy, Student's "t", and logistic distributions).

The simplest case of a normal distribution is known as the "standard normal distribution". This is a special case when formula_20 and formula_21, and it is described by this probability density function:

Here, the factor formula_23 ensures that the total area under the curve formula_24 is equal to one. The factor formula_25 in the exponent ensures that the distribution has unit variance (i.e., variance being equal to one), and therefore also unit standard deviation. This function is symmetric around formula_26, where it attains its maximum value formula_23 and has inflection points at formula_28 and formula_29.

Authors differ on which normal distribution should be called the "standard" one. Carl Friedrich Gauss, for example, defined the standard normal as having a variance of formula_30. That is:

On the other hand,Stephen Stigler goes even further, defining the standard normal as having a variance of formula_32:

Every normal distribution is a version of the standard normal distribution, whose domain has been stretched by a factor formula_18 (the standard deviation) and then translated by formula_3 (the mean value):

The probability density must be scaled by formula_37 so that the integral is still 1.

If formula_38 is a standard normal deviate, then formula_39 will have a normal distribution with expected value formula_3 and standard deviation formula_18. Conversely, if formula_42 is a normal deviate with parameters formula_3 and formula_6, then the distribution formula_45 will have a standard normal distribution. This variate is also called the standardized form of formula_42.

The probability density of the standard Gaussian distribution (standard normal distribution, with zero mean and unit variance) is often denoted with the Greek letter formula_47 (phi). The alternative form of the Greek letter phi, formula_48, is also used quite often.

The normal distribution is often referred to as formula_49 or formula_50. Thus when a random variable formula_42 is normally distributed with mean formula_3 and variance formula_6, one may write

Some authors advocate using the precision formula_55 as the parameter defining the width of the distribution, instead of the deviation formula_18 or the variance formula_6. The precision is normally defined as the reciprocal of the variance, formula_58. The formula for the distribution then becomes

This choice is claimed to have advantages in numerical computations when formula_18 is very close to zero, and simplifies formulas in some contexts, such as in the Bayesian inference of variables with multivariate normal distribution.

Alternatively, the reciprocal of the standard deviation formula_61 might be defined as the "precision", in which case the expression of the normal distribution becomes

According to Stigler, this formulation is advantageous because of a much simpler and easier-to-remember formula, and simple approximate formulas for the quantiles of the distribution.

Normal distributions form an exponential family with natural parameters formula_63 and formula_64, and natural statistics "x" and "x". The dual expectation parameters for normal distribution are and .

The cumulative distribution function (CDF) of the standard normal distribution, usually denoted with the capital Greek letter formula_65 (phi), is the integral

The related error function formula_67 gives the probability of a random variable, with normal distribution of mean 0 and variance 1/2 falling in the range formula_68. That is:

These integrals cannot be expressed in terms of elementary functions, and are often said to be special functions. However, many numerical approximations are known; see below for more.

The two functions are closely related, namely

For a generic normal distribution with density formula_71, mean formula_3 and deviation formula_18, the cumulative distribution function is

The complement of the standard normal CDF, formula_75, is often called the Q-function, especially in engineering texts. It gives the probability that the value of a standard normal random variable formula_42 will exceed formula_77: formula_78. Other definitions of the formula_79-function, all of which are simple transformations of formula_65, are also used occasionally.

The graph of the standard normal CDF formula_65 has 2-fold rotational symmetry around the point (0,1/2); that is, formula_82. Its antiderivative (indefinite integral) can be expressed as follows: 

The CDF of the standard normal distribution can be expanded by Integration by parts into a series:

where formula_85 denotes the double factorial.

An asymptotic expansion of the CDF for large "x" can also be derived using integration by parts. For more, see Error function#Asymptotic expansion.

About 68% of values drawn from a normal distribution are within one standard deviation "σ" away from the mean; about 95% of the values lie within two standard deviations; and about 99.7% are within three standard deviations. This fact is known as the 68-95-99.7 (empirical) rule, or the "3-sigma rule".

More precisely, the probability that a normal deviate lies in the range between formula_86 and formula_87 is given by
To 12 significant figures, the values for formula_89 are:

For large formula_90, one can use the approximation formula_91.

The quantile function of a distribution is the inverse of the cumulative distribution function. The quantile function of the standard normal distribution is called the probit function, and can be expressed in terms of the inverse error function:
For a normal random variable with mean formula_3 and variance formula_6, the quantile function is
The quantile formula_96 of the standard normal distribution is commonly denoted as formula_97. These values are used in hypothesis testing, construction of confidence intervals and Q-Q plots. A normal random variable formula_42 will exceed formula_99 with probability formula_100, and will lie outside the interval formula_101 with probability formula_102. In particular, the quantile formula_103 is 1.96; therefore a normal random variable will lie outside the interval formula_104 in only 5% of cases.

The following table gives the quantile formula_97 such that formula_42 will lie in the range formula_101 with a specified probability formula_108. These values are useful to determine tolerance interval for sample averages and other statistical estimators with normal (or asymptotically normal) distributions:. NOTE: the following table shows formula_109, not formula_96 as defined above.

For small formula_108, the quantile function has the useful asymptotic expansion 
formula_112

The normal distribution is the only distribution whose cumulants beyond the first two (i.e., other than the mean and variance) are zero. It is also the continuous distribution with the maximum entropy for a specified mean and variance. Geary has shown, assuming that the mean and variance are finite, that the normal distribution is the only distribution where the mean and variance calculated from a set of independent draws are independent of each other.

The normal distribution is a subclass of the elliptical distributions. The normal distribution is symmetric about its mean, and is non-zero over the entire real line. As such it may not be a suitable model for variables that are inherently positive or strongly skewed, such as the weight of a person or the price of a share. Such variables may be better described by other distributions, such as the log-normal distribution or the Pareto distribution.

The value of the normal distribution is practically zero when the value formula_77 lies more than a few standard deviations away from the mean (e.g., a spread of three standard deviations covers all but 0.27% of the total distribution). Therefore, it may not be an appropriate model when one expects a significant fraction of outliers—values that lie many standard deviations away from the mean—and least squares and other statistical inference methods that are optimal for normally distributed variables often become highly unreliable when applied to such data. In those cases, a more heavy-tailed distribution should be assumed and the appropriate robust statistical inference methods applied.

The Gaussian distribution belongs to the family of stable distributions which are the attractors of sums of independent, identically distributed distributions whether or not the mean or variance is finite. Except for the Gaussian which is a limiting case, all stable distributions have heavy tails and infinite variance. It is one of the few distributions that are stable and that have probability density functions that can be expressed analytically, the others being the Cauchy distribution and the Lévy distribution.

The normal distribution with density formula_114 (mean formula_3 and standard deviation formula_116) has the following properties:

Furthermore, the density formula_48 of the standard normal distribution (i.e. formula_20 and formula_128) also has the following properties:

The plain and absolute moments of a variable formula_42 are the expected values of formula_138 and formula_139, respectively. If the expected value formula_3 of formula_42 is zero, these parameters are called "central moments". Usually we are interested only in moments with integer order formula_142.

If formula_42 has a normal distribution, these moments exist and are finite for any formula_108 whose real part is greater than −1. For any non-negative integer formula_108, the plain central moments are:
Here formula_147 denotes the double factorial, that is, the product of all numbers from formula_90 to 1 that have the same parity as formula_149

The central absolute moments coincide with plain moments for all even orders, but are nonzero for odd orders. For any non-negative integer formula_150

The last formula is valid also for any non-integer formula_152 When the mean formula_153 the plain and absolute moments can be expressed in terms of confluent hypergeometric functions formula_154 and formula_155

These expressions remain valid even if formula_108 is not integer. See also generalized Hermite polynomials.

The expectation of formula_42 conditioned on the event that formula_42 lies in an interval formula_160 is given by
where formula_71 and formula_162 respectively are the density and the cumulative distribution function of formula_42. For formula_164 this is known as the inverse Mills ratio. Note that above, density formula_71 of formula_42 is used instead of standard normal density as in inverse Mills ratio, so here we have formula_6 instead of formula_18.

The Fourier transform of a normal density formula_71 with mean formula_3 and standard deviation formula_18 is

where formula_173 is the imaginary unit. If the mean formula_20, the first factor is 1, and the Fourier transform is, apart from a constant factor, a normal density on the frequency domain, with mean 0 and standard deviation formula_37. In particular, the standard normal distribution formula_48 is an eigenfunction of the Fourier transform.

In probability theory, the Fourier transform of the probability distribution of a real-valued random variable formula_42 is closely connected to the characteristic function formula_178 of that variable, which is defined as the expected value of formula_179, as a function of the real variable formula_180 (the frequency parameter of the Fourier transform). This definition can be analytically extended to a complex-value variable formula_180. The relation between both is:

The moment generating function of a real random variable formula_42 is the expected value of formula_184, as a function of the real parameter formula_180. For a normal distribution with density formula_71, mean formula_3 and deviation formula_18, the moment generating function exists and is equal to

The cumulant generating function is the logarithm of the moment generating function, namely

Since this is a quadratic polynomial in formula_180, only the first two cumulants are nonzero, namely the mean formula_3 and the variance formula_6.

Within Stein's method the Stein operator and class of a random variable formula_194 are formula_195 and formula_196 the class of all absolutely continuous functions formula_197.

In the limit when formula_18 tends to zero, the probability density formula_114 eventually tends to zero at any formula_200, but grows without limit if formula_201, while its integral remains equal to 1. Therefore, the normal distribution cannot be defined as an ordinary function when formula_202.

However, one can define the normal distribution with zero variance as a generalized function; specifically, as Dirac's "delta function" formula_203 translated by the mean formula_3, that is formula_205
Its CDF is then the Heaviside step function translated by the mean formula_3, namely

Of all probability distributions over the reals with a specified mean formula_3 and variance formula_6, the normal distribution formula_49 is the one with maximum entropy. If formula_42 is a continuous random variable with probability density formula_114, then the entropy of formula_42 is defined as

where formula_215 is understood to be zero whenever formula_216. This functional can be maximized, subject to the constraints that the distribution is properly normalized and has a specified variance, by using variational calculus. A function with two Lagrange multipliers is defined:

where formula_114 is, for now, regarded as some density function with mean formula_3 and standard deviation formula_18.

At maximum entropy, a small variation formula_221 about formula_114 will produce a variation formula_223 about formula_224 which is equal to 0:

Since this must hold for any small formula_221, the term in brackets must be zero, and solving for formula_114 yields:

Using the constraint equations to solve for formula_229 and formula_230 yields the density of the normal distribution:

The entropy of a normal distribution is equal to

The family of normal distributions is closed under linear transformations: if formula_233 is normally distributed with mean formula_3 and standard deviation formula_18, then the variable formula_236, for any real numbers formula_237 and formula_238, is also normally distributed, with
mean formula_239 and standard deviation formula_240.

Also if formula_241 and formula_242 are two independent normal random variables, with means formula_243, formula_244 and standard deviations formula_245, formula_246, then their sum formula_247 will also be normally distributed, with mean formula_248 and variance formula_249.

In particular, if formula_42 and formula_251 are independent normal deviates with zero mean and variance formula_6, then formula_253 and formula_254 are also independent and normally distributed, with zero mean and variance formula_255. This is a special case of the polarization identity.

Also, if formula_241, formula_242 are two independent normal deviates with mean formula_3 and deviation formula_18, and formula_237, formula_238 are arbitrary real numbers, then the variable
is also normally distributed with mean formula_3 and deviation formula_18. It follows that the normal distribution is stable (with exponent formula_265).

More generally, any linear combination of independent normal deviates is a normal deviate.

For any positive integer formula_266, any normal distribution with mean formula_267 and variance formula_6 is the distribution of the sum of formula_266 independent normal deviates, each with mean formula_270 and variance formula_271. This property is called infinite divisibility.

Conversely, if formula_241 and formula_242 are independent random variables and their sum formula_247 has a normal distribution, then both formula_241 and formula_242 must be normal deviates.

This result is known as Cramér’s decomposition theorem, and is equivalent to saying that the convolution of two distributions is normal if and only if both are normal. Cramér's theorem implies that a linear combination of independent non-Gaussian variables will never have an exactly normal distribution, although it may approach it arbitrarily closely.

Bernstein's theorem states that if formula_42 and formula_251 are independent and formula_253 and formula_254 are also independent, then both "X" and "Y" must necessarily have normal distributions.

More generally, if formula_281 are independent random variables, then two distinct linear combinations formula_282 and formula_283will be independent if and only if all formula_284 are normal and formula_285, where formula_286 denotes the variance of formula_284.

 </math>

The central limit theorem states that under certain (fairly common) conditions, the sum of many random variables will have an approximately normal distribution. More specifically, where formula_297 are independent and identically distributed random variables with the same arbitrary distribution, zero mean, and variance formula_6 and formula_38 is their
mean scaled by formula_300
Then, as formula_90 increases, the probability distribution of formula_38 will tend to the normal distribution with zero mean and variance formula_6.

The theorem can be extended to variables formula_305 that are not independent and/or not identically distributed if certain constraints are placed on the degree of dependence and the moments of the distributions.

Many test statistics, scores, and estimators encountered in practice contain sums of certain random variables in them, and even more estimators can be represented as sums of random variables through the use of influence functions. The central limit theorem implies that those statistical parameters will have asymptotically normal distributions.

The central limit theorem also implies that certain distributions can be approximated by the normal distribution, for example:

Whether these approximations are sufficiently accurate depends on the purpose for which they are needed, and the rate of convergence to the normal distribution. It is typically the case that such approximations are less accurate in the tails of the distribution.

A general upper bound for the approximation error in the central limit theorem is given by the Berry–Esseen theorem, improvements of the approximation are given by the Edgeworth expansions.

If "X" is distributed normally with mean "μ" and variance "σ", then

If formula_241 and formula_242 are two independent standard normal random variables with mean 0 and variance 1, then


The split normal distribution is most directly defined in terms of joining scaled sections of the density functions of different normal distributions and rescaling the density to integrate to one. The truncated normal distribution results from rescaling a section of a single density function.

The notion of normal distribution, being one of the most important distributions in probability theory, has been extended far beyond the standard framework of the univariate (that is one-dimensional) case (Case 1). All these extensions are also called "normal" or "Gaussian" laws, so a certain ambiguity in names exists.

A random variable "X" has a two-piece normal distribution if it has a distribution

where "μ" is the mean and "σ" and "σ" are the standard deviations of the distribution to the left and right of the mean respectively.

The mean, variance and third central moment of this distribution have been determined

where E("X"), V("X") and T("X") are the mean, variance, and third central moment respectively.

One of the main practical uses of the Gaussian law is to model the empirical distributions of many different random variables encountered in practice. In such case a possible extension would be a richer family of distributions, having more than two parameters and therefore being able to fit the empirical distribution more accurately. The examples of such extensions are:

It is often the case that we do not know the parameters of the normal distribution, but instead want to estimate them. That is, having a sample formula_348 from a normal formula_349 population we would like to learn the approximate values of parameters formula_3 and formula_6. The standard approach to this problem is the maximum likelihood method, which requires maximization of the "log-likelihood function":
Taking derivatives with respect to formula_3 and formula_6 and solving the resulting system of first order conditions yields the "maximum likelihood estimates":

Estimator formula_356 is called the "sample mean", since it is the arithmetic mean of all observations. The statistic formula_357 is complete and sufficient for formula_3, and therefore by the Lehmann–Scheffé theorem, formula_356 is the uniformly minimum variance unbiased (UMVU) estimator. In finite samples it is distributed normally:
The variance of this estimator is equal to the "μμ"-element of the inverse Fisher information matrix formula_361. This implies that the estimator is finite-sample efficient. Of practical importance is the fact that the standard error of formula_356 is proportional to formula_363, that is, if one wishes to decrease the standard error by a factor of 10, one must increase the number of points in the sample by a factor of 100. This fact is widely used in determining sample sizes for opinion polls and the number of trials in Monte Carlo simulations.

From the standpoint of the asymptotic theory, formula_356 is consistent, that is, it converges in probability to formula_3 as formula_366. The estimator is also asymptotically normal, which is a simple corollary of the fact that it is normal in finite samples:

The estimator formula_368 is called the "sample variance", since it is the variance of the sample (formula_348). In practice, another estimator is often used instead of the formula_368. This other estimator is denoted formula_371, and is also called the "sample variance", which represents a certain ambiguity in terminology; its square root formula_372 is called the "sample standard deviation". The estimator formula_371 differs from formula_368 by having instead of "n" in the denominator (the so-called Bessel's correction):
The difference between formula_371 and formula_368 becomes negligibly small for large "n"s. In finite samples however, the motivation behind the use of formula_371 is that it is an unbiased estimator of the underlying parameter formula_6, whereas formula_368 is biased. Also, by the Lehmann–Scheffé theorem the estimator formula_371 is uniformly minimum variance unbiased (UMVU), which makes it the "best" estimator among all unbiased ones. However it can be shown that the biased estimator formula_368 is "better" than the formula_371 in terms of the mean squared error (MSE) criterion. In finite samples both formula_371 and formula_368 have scaled chi-squared distribution with degrees of freedom:
The first of these expressions shows that the variance of formula_371 is equal to formula_388, which is slightly greater than the "σσ"-element of the inverse Fisher information matrix formula_361. Thus, formula_371 is not an efficient estimator for formula_6, and moreover, since formula_371 is UMVU, we can conclude that the finite-sample efficient estimator for formula_6 does not exist.

Applying the asymptotic theory, both estimators formula_371 and formula_368 are consistent, that is they converge in probability to formula_6 as the sample size formula_366. The two estimators are also both asymptotically normal:
In particular, both estimators are asymptotically efficient for formula_6.

By Cochran's theorem, for normal distributions the sample mean formula_356 and the sample variance "s" are independent, which means there can be no gain in considering their joint distribution. There is also a converse theorem: if in a sample the sample mean and sample variance are independent, then the sample must have come from the normal distribution. The independence between formula_356 and "s" can be employed to construct the so-called "t-statistic":
This quantity "t" has the Student's t-distribution with degrees of freedom, and it is an ancillary statistic (independent of the value of the parameters). Inverting the distribution of this "t"-statistics will allow us to construct the confidence interval for "μ"; similarly, inverting the "χ" distribution of the statistic "s" will give us the confidence interval for "σ":

where "t" and are the "p"th quantiles of the "t"- and "χ"-distributions respectively. These confidence intervals are of the "confidence level" , meaning that the true values "μ" and "σ" fall outside of these intervals with probability (or significance level) "α". In practice people usually take , resulting in the 95% confidence intervals. The approximate formulas in the display above were derived from the asymptotic distributions of formula_356 and "s". The approximate formulas become valid for large values of "n", and are more convenient for the manual calculation since the standard normal quantiles "z" do not depend on "n". In particular, the most popular value of , results in .

Normality tests assess the likelihood that the given data set {"x", ..., "x"} comes from a normal distribution. Typically the null hypothesis "H" is that the observations are distributed normally with unspecified mean "μ" and variance "σ", versus the alternative "H" that the distribution is arbitrary. Many tests (over 40) have been devised for this problem, the more prominent of them are outlined below:

Bayesian analysis of normally distributed data is complicated by the many different possibilities that may be considered:

The formulas for the non-linear-regression cases are summarized in the conjugate prior article.

The following auxiliary formula is useful for simplifying the posterior update equations, which otherwise become fairly tedious.

This equation rewrites the sum of two quadratics in "x" by expanding the squares, grouping the terms in "x", and completing the square. Note the following about the complex constant factors attached to some of the terms:

A similar formula can be written for the sum of two vector quadratics: If x, y, z are vectors of length "k", and A and B are symmetric, invertible matrices of size formula_411, then

where

Note that the form x′ A x is called a quadratic form and is a scalar:
In other words, it sums up all possible combinations of products of pairs of elements from x, with a separate coefficient for each. In addition, since formula_415, only the sum formula_416 matters for any off-diagonal elements of A, and there is no loss of generality in assuming that A is symmetric. Furthermore, if A is symmetric, then the form formula_417

Another useful formula is as follows:

where formula_419

For a set of i.i.d. normally distributed data points X of size "n" where each individual point "x" follows formula_420 with known variance σ, the conjugate prior distribution is also normally distributed.

This can be shown more easily by rewriting the variance as the precision, i.e. using τ = 1/σ. Then if formula_421 and formula_422 we proceed as follows.

First, the likelihood function is (using the formula above for the sum of differences from the mean):

Then, we proceed as follows:

In the above derivation, we used the formula above for the sum of two quadratics and eliminated all constant factors not involving "μ". The result is the kernel of a normal distribution, with mean formula_425 and precision formula_426, i.e.

This can be written as a set of Bayesian update equations for the posterior parameters in terms of the prior parameters:

That is, to combine "n" data points with total precision of "nτ" (or equivalently, total variance of "n"/"σ") and mean of values formula_429, derive a new total precision simply by adding the total precision of the data to the prior total precision, and form a new mean through a "precision-weighted average", i.e. a weighted average of the data mean and the prior mean, each weighted by the associated total precision. This makes logical sense if the precision is thought of as indicating the certainty of the observations: In the distribution of the posterior mean, each of the input components is weighted by its certainty, and the certainty of this distribution is the sum of the individual certainties. (For the intuition of this, compare the expression "the whole is (or is not) greater than the sum of its parts". In addition, consider that the knowledge of the posterior comes from a combination of the knowledge of the prior and likelihood, so it makes sense that we are more certain of it than of either of its components.)

The above formula reveals why it is more convenient to do Bayesian analysis of conjugate priors for the normal distribution in terms of the precision. The posterior precision is simply the sum of the prior and likelihood precisions, and the posterior mean is computed through a precision-weighted average, as described above. The same formulas can be written in terms of variance by reciprocating all the precisions, yielding the more ugly formulas

For a set of i.i.d. normally distributed data points X of size "n" where each individual point "x" follows formula_420 with known mean μ, the conjugate prior of the variance has an inverse gamma distribution or a scaled inverse chi-squared distribution. The two are equivalent except for having different parameterizations. Although the inverse gamma is more commonly used, we use the scaled inverse chi-squared for the sake of convenience. The prior for σ is as follows:

The likelihood function from above, written in terms of the variance, is:

where

Then:

The above is also a scaled inverse chi-squared distribution where

or equivalently

Reparameterizing in terms of an inverse gamma distribution, the result is:

For a set of i.i.d. normally distributed data points X of size "n" where each individual point "x" follows formula_420 with unknown mean μ and unknown variance σ, a combined (multivariate) conjugate prior is placed over the mean and variance, consisting of a normal-inverse-gamma distribution.
Logically, this originates as follows:

The priors are normally defined as follows:

The update equations can be derived, and look as follows:

The respective numbers of pseudo-observations add the number of actual observations to them. The new mean hyperparameter is once again a weighted average, this time weighted by the relative numbers of observations. Finally, the update for formula_442 is similar to the case with known mean, but in this case the sum of squared deviations is taken with respect to the observed data mean rather than the true mean, and as a result a new "interaction term" needs to be added to take care of the additional error source stemming from the deviation between prior and data mean.
The prior distributions are

Therefore, the joint prior is

The likelihood function from the section above with known variance is:

Writing it in terms of variance rather than precision, we get:

where formula_447

Therefore, the posterior is (dropping the hyperparameters as conditioning factors):

In other words, the posterior distribution has the form of a product of a normal distribution over "p"("μ" | "σ") times an inverse gamma distribution over "p"(σ), with parameters that are the same as the update equations above.
The occurrence of normal distribution in practical problems can be loosely classified into four categories:

Certain quantities in physics are distributed normally, as was first demonstrated by James Clerk Maxwell. Examples of such quantities are:

"Approximately" normal distributions occur in many situations, as explained by the central limit theorem. When the outcome is produced by many small effects acting "additively and independently", its distribution will be close to normal. The normal approximation will not be valid if the effects act multiplicatively (instead of additively), or if there is a single external influence that has a considerably larger magnitude than the rest of the effects.

There are statistical methods to empirically test that assumption, see the above Normality tests section.


In regression analysis, lack of normality in residuals simply indicates that the model postulated is inadequate in accounting for the tendency in the data and needs to be augmented; in other words, normality in residuals can always be achieved given a properly constructed model.

In computer simulations, especially in applications of the Monte-Carlo method, it is often desirable to generate values that are normally distributed. The algorithms listed below all generate the standard normal deviates, since a can be generated as , where "Z" is standard normal. All these algorithms rely on the availability of a random number generator "U" capable of producing uniform random variates.

The standard normal CDF is widely used in scientific and statistical computing.

The values Φ("x") may be approximated very accurately by a variety of methods, such as numerical integration, Taylor series, asymptotic series and continued fractions. Different approximations are used depending on the desired level of accuracy.

Shore (1982) introduced simple approximations that may be incorporated in stochastic optimization models of engineering and operations research, like reliability engineering and inventory analysis. Denoting p=Φ(z), the simplest approximation for the quantile function is:

This approximation delivers for "z" a maximum absolute error of 0.026 (for 0.5 ≤ "p" ≤ 0.9999, corresponding to 0 ≤ "z" ≤ 3.719). For "p" < 1/2 replace "p" by 1 − "p" and change sign. Another approximation, somewhat less accurate, is the single-parameter approximation:

The latter had served to derive a simple approximation for the loss integral of the normal distribution, defined by

This approximation is particularly accurate for the right far-tail (maximum error of 10 for z≥1.4). Highly accurate approximations for the CDF, based on Response Modeling Methodology (RMM, Shore, 2011, 2012), are shown in Shore (2005).

Some more approximations can be found at: Error function#Approximation with elementary functions. In particular, small "relative" error on the whole domain for the CDF formula_65 and the quantile function formula_457 as well, is achieved via an explicitly invertible formula by Sergei Winitzki in 2008.

Some authors attribute the credit for the discovery of the normal distribution to de Moivre, who in 1738 published in the second edition of his ""The Doctrine of Chances"" the study of the coefficients in the binomial expansion of . De Moivre proved that the middle term in this expansion has the approximate magnitude of formula_458, and that "If "m" or ½"n" be a Quantity infinitely great, then the Logarithm of the Ratio, which a Term distant from the middle by the Interval "ℓ", has to the middle Term, is formula_459." Although this theorem can be interpreted as the first obscure expression for the normal probability law, Stigler points out that de Moivre himself did not interpret his results as anything more than the approximate rule for the binomial coefficients, and in particular de Moivre lacked the concept of the probability density function.

In 1809 Gauss published his monograph ""Theoria motus corporum coelestium in sectionibus conicis solem ambientium"" where among other things he introduces several important statistical concepts, such as the method of least squares, the method of maximum likelihood, and the "normal distribution". Gauss used "M", , to denote the measurements of some unknown quantity "V", and sought the "most probable" estimator of that quantity: the one that maximizes the probability of obtaining the observed experimental results. In his notation φΔ is the probability law of the measurement errors of magnitude Δ. Not knowing what the function "φ" is, Gauss requires that his method should reduce to the well-known answer: the arithmetic mean of the measured values. Starting from these principles, Gauss demonstrates that the only law that rationalizes the choice of arithmetic mean as an estimator of the location parameter, is the normal law of errors:

where "h" is "the measure of the precision of the observations". Using this normal law as a generic model for errors in the experiments, Gauss formulates what is now known as the non-linear weighted least squares (NWLS) method.

Although Gauss was the first to suggest the normal distribution law, Laplace made significant contributions. It was Laplace who first posed the problem of aggregating several observations in 1774, although his own solution led to the Laplacian distribution. It was Laplace who first calculated the value of the integral in 1782, providing the normalization constant for the normal distribution. Finally, it was Laplace who in 1810 proved and presented to the Academy the fundamental central limit theorem, which emphasized the theoretical importance of the normal distribution.

It is of interest to note that in 1809 an Irish mathematician Adrain published two derivations of the normal probability law, simultaneously and independently from Gauss. His works remained largely unnoticed by the scientific community, until in 1871 they were "rediscovered" by Abbe.

In the middle of the 19th century Maxwell demonstrated that the normal distribution is not just a convenient mathematical tool, but may also occur in natural phenomena: "The number of particles whose velocity, resolved in a certain direction, lies between "x" and "x" + "dx" is

Since its introduction, the normal distribution has been known by many different names: the law of error, the law of facility of errors, Laplace's second law, Gaussian law, etc. Gauss himself apparently coined the term with reference to the "normal equations" involved in its applications, with normal having its technical meaning of orthogonal rather than "usual". However, by the end of the 19th century some authors had started using the name "normal distribution", where the word "normal" was used as an adjective – the term now being seen as a reflection of the fact that this distribution was seen as typical, common – and thus "normal". Peirce (one of those authors) once defined "normal" thus: "...the 'normal' is not the average (or any other kind of mean) of what actually occurs, but of what "would", in the long run, occur under certain circumstances." Around the turn of the 20th century Pearson popularized the term "normal" as a designation for this distribution.
Also, it was Pearson who first wrote the distribution in terms of the standard deviation "σ" as in modern notation. Soon after this, in year 1915, Fisher added the location parameter to the formula for normal distribution, expressing it in the way it is written nowadays:

The term "standard normal", which denotes the normal distribution with zero mean and unit variance came into general use around the 1950s, appearing in the popular textbooks by P.G. Hoel (1947) ""Introduction to mathematical statistics"" and A.M. Mood (1950) ""Introduction to the theory of statistics"".




</doc>
<doc id="21465" url="https://en.wikipedia.org/wiki?curid=21465" title="Niklas Luhmann">
Niklas Luhmann

Niklas Luhmann (; ; December 8, 1927 – November 6, 1998) was a German sociologist, philosopher of social science, and a prominent thinker in systems theory, who is considered one of the most important social theorists of the 20th century.

Luhmann was born in Lüneburg, Free State of Prussia, where his father's family had been running a brewery for several generations. He entered the Gymnasium Johanneum at Luneburg in 1937. In 1943, he was conscripted as a Luftwaffenhelfer in World War II and served for two years until, at the age of 17, he was taken prisoner of war by American troops in 1945. After the war Luhmann studied law at the University of Freiburg from 1946 to 1949, when he obtained a law degree, and then began a career in Lüneburg's public administration. During a sabbatical in 1961, he went to Harvard, where he met and studied under Talcott Parsons, then the world's most influential social systems theorist.

In later years, Luhmann dismissed Parsons' theory, developing a rival approach of his own. Leaving the civil service in 1962, he lectured at the national Deutsche Hochschule für Verwaltungswissenschaften (University for Administrative Sciences) in Speyer, Germany. In 1965, he was offered a position at the Sozialforschungsstelle (Social Research Centre) of the University of Münster, led by Helmut Schelsky.
1965/66 he studied one semester of sociology at the University of Münster.

Two earlier books were retroactively accepted as a PhD thesis and habilitation at the University of Münster in 1966, qualifying him for a university professorship. In 1968/1969, he briefly served as a lecturer at Theodor Adorno's former chair at the University of Frankfurt and then was appointed full professor of sociology at the newly founded University of Bielefeld, Germany (until 1993). He continued to publish after his retirement, when he finally found the time to complete his magnum opus, "Die Gesellschaft der Gesellschaft" (literally, "The Society of Society"), which was published in 1997, and translated subsequently in English, under the title "Theory of Society" (volume I in 2012 and volume II in 2013). This work described segmented societies where territory is a dividing line.

Luhmann wrote prolifically, with more than 70 books and nearly 400 scholarly articles published on a variety of subjects, including law, economy, politics, art, religion, ecology, mass media, and love. While his theories have yet to make a major mark in American sociology, his theory is currently well known and popular in German sociology, and has also been rather intensively received in Japan and Eastern Europe, including Russia. His relatively low profile elsewhere is partly due to the fact that translating his work is a difficult task, since his writing presents a challenge even to readers of German, including many sociologists. (p. xxvii Social Systems 1995)

Much of Luhmann's work directly deals with the operations of the legal system and his autopoietic theory of law is regarded as one of the more influential contributions to the sociology of law and socio-legal studies.

Luhmann is probably best known to North Americans for his debate with the critical theorist Jürgen Habermas over the potential of social systems theory. Like his erstwhile mentor Talcott Parsons, Luhmann is an advocate of "grand theory", although neither in the sense of philosophical foundationalism nor in the sense of "meta-narrative" as often invoked in the critical works of post-modernist writers. Rather, Luhmann's work tracks closer to complexity theory broadly speaking, in that it aims to address any aspect of social life within a universal theoretical framework — as the diversity of subjects he wrote on indicates. Luhmann's theory is sometimes dismissed as highly abstract and complex, particularly within the Anglophone world, whereas his work has had a more lasting influence on scholars from German-speaking countries, Scandinavia and Italy.

Luhmann himself described his theory as "labyrinthine" or "non-linear" and claimed he was deliberately keeping his prose enigmatic to prevent it from being understood "too quickly", which would only produce simplistic misunderstandings.

Luhmann's systems theory focuses on three topics, which are interconnected in his entire work.
The core element of Luhmann's theory pivots around the problem of the contingency of meaning and thereby it becomes a theory of communication. Social systems are systems of communication, and society is the most encompassing social system. Being the social system that comprises all (and only) communication, today's society is a world society. A system is defined by a boundary between itself and its environment, dividing it from an infinitely complex, or (colloquially) chaotic, exterior. The interior of the system is thus a zone of reduced complexity: Communication within a system operates by selecting only a limited amount of all information available outside. This process is also called "reduction of complexity". The criterion according to which information is selected and processed is meaning (in German, "Sinn"). Both social systems and psychic systems (see below for an explanation of this distinction) operate by processing meaning.

Furthermore, each system has a distinctive identity that is constantly reproduced in its communication and depends on what is considered meaningful and what is not. If a system fails to maintain that identity, it ceases to exist as a system and dissolves back into the environment it emerged from. Luhmann called this process of reproduction from elements previously filtered from an over-complex environment autopoiesis (pronounced "auto-poy-E-sis"; literally: self-creation), using a term coined in cognitive biology by Chilean thinkers Humberto Maturana and Francisco Varela. Social systems are "operationally closed" in that while they use and rely on resources from their environment, those resources do not become part of the systems' operation. Both thought and digestion are important preconditions for communication, but neither appears in communication as such.

Maturana, however, argued very vocally that this appropriation of autopoietic theory was conceptually unsound, as it presupposes the autonomy of communications from actual persons. That is, by describing social systems as operationally closed networks of communications, Luhmann (according to Maturana) ignores the fact that communications presuppose human communicators. Autopoiesis only applies to networks of processes that reproduce themselves, but communications are reproduced by humans. For this reason, the analogy from biology to sociology does not, in this case, hold. On the other hand, Luhmann explicitly stressed that he does not refer to a "society without humans", but to the fact that communication is autopoietic. Communication is made possible by human bodies and consciousness, but this does not make communication operationally open. To "participate" in communication, one must be able to render one's thoughts and perceptions into elements of communication. This can only ever occur as a communicative operation (thoughts and perceptions cannot be directly transmitted) and must therefore satisfy internal system conditions that are specific to communication: intelligibility, reaching an addressee and gaining acceptance.

Luhmann likens the operation of autopoiesis (the filtering and processing of information from the environment) to a program, making a series of logical distinctions (in German, "Unterscheidungen"). Here, Luhmann refers to the British mathematician G. Spencer-Brown's logic of distinctions that Maturana and Varela had earlier identified as a model for the functioning of any cognitive process. The supreme criterion guiding the "self-creation" of any given system is a defining binary code. This binary code is not to be confused with the computers operation: Luhmann (following Spencer-Brown and Gregory Bateson) assumes that auto-referential systems are continuously confronted with the dilemma of disintegration/continuation. This dilemma is framed with an ever-changing set of available choices; every one of those potential choices can be the system's selection or not (a binary state, selected/rejected). The influence of Spencer-Brown's book, "Laws of Form", on Luhmann can hardly be overestimated.

Although Luhmann first developed his understanding of social systems theory under Parsons' influence, he soon moved away from the Parsonian concept. The most important difference is that Parsons framed systems as forms of action, in accordance with the AGIL paradigm. Parsons' systems theory treats systems as operationally open, and interactive through an input and output schema. Influenced by second-order cybernetics, Luhmann instead treats systems as autopoietic and operationally closed. Systems must continually construct themselves and their perspective of reality through processing the distinction between system and environment, and self-reproduce themselves as the product of their own elements. Social systems are defined by Luhmann not as action but as recursive communication. Modern society is defined as a world system consisting of the sum total of all communication happening at once, and individual function systems (such as the economy, politics, science, love, art, the media, etc.) are described as social subsystems which have "outdifferentiated" from the social system and achieved their own operational closure and autopoiesis.

Another difference is that Parsons asks how certain subsystems contribute to the functioning of overall society. Luhmann starts with the differentiation of the systems themselves out of a nondescript environment. While he does observe how certain systems fulfill functions that contribute to "society" as a whole, he dispenses with the assumption of "a priori" cultural or normative consensus or "complimentary purpose" which was common to Durkheim and Parsons' conceptualization of a social function. For Luhmann, functional differentiation is a consequence of selective pressure under temporalized complexity, and it occurs as function systems independently establish their own ecological niches by performing a function. Functions are therefore not the coordinated components of the organic social whole, but rather contingent and selective responses to reference problems which obey no higher principle of order and could have been responded to in other ways.

Finally, the systems' autopoietic closure is another fundamental difference from Parsons' concept. Each system works strictly according to its very own code and can observe other systems only by applying its code to their operations. For example, the code of the economy involves the application of the distinction between payment and non-payment. Other system operations appear within the economic field of references only insofar as this economic code can be applied to them. Hence, a political decision becomes an economic operation when it is observed as a government spending money or not. Likewise, a legal judgement may also be an economic operation when settlement of a contractual dispute obliges one party to pay for the goods or services they had acquired. The codes of the economy, politics and law operate autonomously, but their "interpenetration" is evident when observing "events" which simultaneously involve the participation of more than one system.

One seemingly peculiar, but within the overall framework strictly logical, axiom of Luhmann's theory is the human being's position outside any social system, initially developed by Parsons. Consisting of "pure communicative actions" (a reference to Jürgen Habermas) any social system requires human consciousnesses (personal or psychical systems) as an obviously necessary, but nevertheless environmental resource. In Luhmann's terms, human beings are neither part of society nor of any specific systems, just as they are not part of a conversation. Luhmann himself once said concisely that he was "not interested in people". That is not to say that people were not a matter for Luhmann, but rather, the communicative actions of people are constituted (but not defined) by society, and society is constituted (but not defined) by the communicative actions of people: society is people's environment, and people are society's environment.

Thus, sociology can explain how persons can change society; the influence of the environment (the people) on the system (the society), the so-called ""structural coupling"". In fact Luhmann himself replied to the relevant criticism by stating that "In fact the theory of autopoietic systems could bear the title "Taking Individuals Seriously", certainly more seriously than our humanistic tradition" (Niklas Luhmann, "Operational Closure and Structural Coupling: The Differentiation of the Legal System", Cardozo Law Review, vol. 13: 1422). This approach has attracted criticism from those who argue that Luhmann has at no point demonstrated the operational closure of social systems, or in fact that autopoietic social systems actually exist. He has instead taken this as a premise or presupposition, resulting in the logical need to exclude humans from social systems, which prevents the social systems view from accounting for the individual behavior, action, motives, or indeed existence of any individual person.

Luhmann was devoted to the ideal of non-normative science introduced to sociology in the early 20th century by Max Weber and later re-defined and defended against its critics by Karl Popper. However, in an academic environment that never strictly separated descriptive and normative theories of society, Luhmann's sociology has widely attracted criticism from various intellectuals, including Jürgen Habermas.

Luhmann's systems theory is not without its critics; his definitions of "autopoietic" and "social system" differ from others.
At the same time his theory is being applied or used worldwide by sociologists and other scholars. It is often used in analyses dealing with corporate social responsibility, organisational legitimacy, governance structures as well as with sociology of law and of course general sociology. His systems theory has also been used to study media discourse of various energy technologies throughout the US, including smart grids, carbon capture and storage, and wind energy.

Luhmann was famous for his extensive use of the "slip box" or "Zettelkasten" note-taking method. He built up a zettelkasten of some 90,000 index cards for his research, and credited it with making his extraordinarily prolific writing possible. It was digitized and made available online in 2019. Luhmann described the zettelkasten as part of his research into systems theory in the essay "Kommunikation mit Zettelkästen".

Luhmann also appears as a character in Paul Wühr's work of literature "Das falsche Buch", along with Ulrich Sonnemann, Johann Georg Hamann, Richard Buckminster Fuller and others.

Luhmann owned a pub called "Pons" in his parents' house in his native town of Lüneburg. The house, which also contained his father's brewery, had been in his family since 1857.






</doc>
<doc id="21466" url="https://en.wikipedia.org/wiki?curid=21466" title="Natacha Atlas">
Natacha Atlas

Natacha Atlas (; born 20 March 1964) is an Egyptian-British singer known for her fusion of Arabic and Western music, particularly hip-hop. She once termed her music ""cha'abi moderne"" (modern popular music). Her music has been influenced by many styles including Maghrebain, hip hop, drum and bass and reggae.

Atlas began her career as part of the world fusion group Transglobal Underground. In 1995, she began to focus on her solo career with the release of "Diaspora". She has since released seven solo albums and been a part of numerous collaborations. Her version of "Mon amie la rose" became a surprise success in France, reaching 16 on the French Singles Charts in 1999. Her most recent creation "Myriad Road" was released on 23 October 2015. It was produced by French Lebanese jazz musician Ibrahim Maalouf.

Natacha Atlas was born in Brussels of Anglo Egyptian parentage. Her British mother was born Christian becoming Buddhist in the 1970s. Her father, of Egyptian descent, deeply interested in Sufi mysticism and the Gurdjieff philosophy of the fourth way, also studied Chinese medicine and Taoism. 

Atlas was raised listening to music from both east and west and in the course of her upbringing learned to be tolerant of all religions.

After her parents separated, Atlas went to live in Northampton, England with her mother. 

Atlas grew up speaking French and English, and later learned Arabic and Spanish. She sings in several languages, including in modern colloquial Arabic, although she admits that she is not entirely at ease in it.

Atlas returned to Belgium at age 24 and began her career with two jobs: belly dancing and being the lead singer of a Belgian salsa band. In April 1989, she made her recording début as guest vocalist on Balearic beat-band ¡Loca!'s "Encantador" (Nation Records).
In 1991, Atlas co-wrote/recorded the ¡Loca! single "Timbal" and co-wrote/guested with Jah Wobble's Invaders of the Heart composing five tracks for their "Rising Above Bedlam" album (Oval Records). Through recording with ¡Loca!, she met Nation-labelmates Transglobal Underground (TGU), a British ethnic electronica band with a Middle Eastern/South Asian focus. At the time, TGU had a top 40 hit, "Templehead", and Atlas became their lead singer / belly dancer. Additionally in 1991, Atlas collaborated with Bauhaus/Love and Rockets/Tones on Tail guitarist and vocalist Daniel Ash on his debut solo album "Coming Down". She contributed extensive vocal work as well as keyboards and bass guitar.

Most of Atlas' earlier albums were produced by Tim Whelan and Hamilton Lee from Transglobal Underground. "Diaspora" (1995), "Halim" (1997) (in honour of Egyptian singer Abdel Halim Hafez), "Gedida" (1998) and "Ayeshteni" (2001).

Atlas has always spoken her mind about the way both she and Transglobal Underground were seen by the UK press back in the late '90s/early 2000s. "Someone from the "New Musical Express" rang us about a feature we're to do with them and said 'We don't want it to be about the multi-cultural angle'. In other words that fad is over. And I'm personally insulted... what other angle is there for us?! I get sick of it all."

In 1999, Atlas collaborated with David Arnold on the song "One Brief Moment". The single featured a cover version of the theme song from the James Bond film "You Only Live Twice". Two years earlier, Atlas had collaborated with Arnold on the album "Shaken and Stirred", recording the song "From Russia with Love" for the eponymous film (originally performed by Matt Monro).

Also in 1999, she collaborated with Jean Michel Jarre for the track "C'est La Vie" on his album "Métamorphoses". The track was released as a single.

In 2003, Atlas provided vocals for the Kolo folk dance song "'Ajde Jano" on Nigel Kennedy and Kroke's album, "East Meets East". In 2005, Atlas contributed the song "Just Like A Dream" (from "Something Dangerous") to the charity album "Voyces United for UNHCR".

Her music has been used in a number of soundtracks. Her song "Kidda" was featured on the "Sex and the City 2" soundtrack and in the 2005 video game "" on . In 2003, her voice is heard in "Hulk" in the song "Captured". Additionally, her song "Bathaddak" is one of the songs included in the 2007 Xbox 360 exclusive video game "Project Gotham Racing 4". Her cover of "I Put a Spell On You" was used in the 2002 film "Divine Intervention" by Palestinian director Elia Suleiman.

Atlas was originally billed to star in and provide the soundtrack to the film "Whatever Lola Wants", directed by Nabil Ayouch. However, shooting delays caused Atlas to only be involved in the film's soundtrack. Her song "Gafsa" ("Halim", 1997) was used as the main soundtrack during the Korean film "Bin-Jip" (also known as "3-Iron") (2004) by Kim Ki-Duk. She participated in the piece "Light of Life (Ibelin Reprise)" for the soundtrack of Ridley Scott's "Kingdom of Heaven".

In 2007, Atlas collaborated with Belinda Carlisle for Belinda's seventh album "Voila". She contributed additional vocals on songs "Ma Jeunesse Fout Le Camp," "La Vie En Rose", "Bonnie et Clyde" and "Des Ronds Dans L'Eau." "Voila" was released via Rykodisc in the U.K. on 5 February 2007 and in the U.S. the following day.

The 2007 film "Brick Lane" features four songs with vocals by Atlas, "Adam's Lullaby", "Running Through the Night", "Love Blossoms" and "Rite of Passage". On 23 May 2008 Atlas released a new album, "Ana Hina", which was well received by critics.

In 2008, two of Atlas' songs, "Kidda" and "Ghanwa Bossanova", were used in Shamim Sarif's romantic comedy about two women, "I Can't Think Straight".

In 2008, she sang lead in the song "Habibe" from Peter Gabriel's long-awaited album and project, "Big Blue Ball".

On 20 September 2010 Atlas released "Mounqaliba". Co-produced by Samy Bishai, it explored classical instrumentation, jazz and traditional Arabic styles and was inspired by the poems of Indian poet Rabindranath Tagore. She is also composing the music for Francoise Charpat's upcoming film.

In May 2013, Natacha Atlas released "Expressions: Live in Toulouse", an album which showcased her expressive voice using largely orchestral arrangements augmented by Middle Eastern percussion.

Atlas has recently moved into the jazz genre with "Myriad Road" (2015) and "Strange Days" (2019).

In 1999, Atlas married Syrian kanun player Abdullah Chhadeh. The couple divorced in 2005.

Atlas is now in a relationship with British Egyptian violinist Samy Bishai, who produced her 2010 release "Mounqaliba". The couple divide their time between London and France.

Atlas has said in the past that she is "technically Muslim" and that she identifies with Sufism. She also stated that her father has some Sephardic Jewish ancestry. Atlas said more recently, "These days I prefer to say that I'm Anglo-Middle Eastern and leave the religion out of it." She is, however, open to other forms of spirituality because "it's important to be tolerant".

In 2001, she was appointed by Mary Robinson as a Goodwill Ambassador for the United Nations Conference Against Racism. Robinson chose Atlas because "she embodies the message that there is a strength in diversity. That our differences – be they ethnic, racial or religious – are a source of riches to be embraced rather than feared". She was a Goodwill Ambassador for the United Nations Conference Against Racism.

Atlas is a proponent of The Zeitgeist Movement. She included clips from "" in her 2010 album "Mounqaliba".

In a joint interview with the Israeli singer Yasmin Levy, Atlas noted the risk of the collaboration because feelings of anti-Zionism across the Arab world were mostly tainted by anti-Semitism “Some Arabic artists wouldn't even consider working with anyone Jewish.” Of her experience of working with Levy, Atlas said:

“We spent a lot of time in this little room, just talking and drinking wine”, recalls Natacha, “and it was like I’d known her all my life. I’d missed that female Middle Eastern company, as most of the Middle Eastern people I know here are men.”

In March 2011, Atlas announced that she had joined the boycott of Israel and had withdrawn from a scheduled performance in Israel. She gave her reasoning as follows:

"I would have personally asked my Israeli fans face-to-face to fight this apartheid with peace in their hearts, but after much deliberation I now see that it would be more effective a statement to not go to Israel until this systemized apartheid is abolished once and for all."

By May 2014, when she gave a concert at the Méditerranée Festival in Ashdod , Atlas had clearly changed her mind on the issue of boycott:

“For years,” Natacha Atlas told me, “I boycotted Israel and refused to perform here. But when I met a Palestinian fellow who’s married to an Israeli Jewish woman, something in me changed. Suddenly, this chance personal acquaintanceship made me think that maybe there should be another way. There’s nothing easier than to boycott and say that I don’t want to see Israel or meet Israelis or come here and perform. But then what? Where does that get you?”






</doc>
<doc id="21470" url="https://en.wikipedia.org/wiki?curid=21470" title="List of national anthems">
List of national anthems

Most nation states have an anthem, defined as "a song, as of praise, devotion, or patriotism"; most anthems are either marches or hymns in style. A song or hymn can become a national anthem under the state's constitution, by a law enacted by its legislature, or simply by tradition. A royal anthem is a patriotic song similar to a national anthem, but it specifically praises or prays for a monarch or royal dynasty. Such anthems are usually performed at public appearances by the monarch or during other events of royal importance. Some states use their royal anthem as the national anthem, such as the state anthem of Jordan.

There are multiple claimants to the position of oldest national anthem. Among the national anthems, the first to be composed was the Dutch national anthem, the "Wilhelmus", which was written between 1568 and 1572. This has both Dutch and English language versions and is unusual in being an acrostic in both languages. The Japanese anthem, "Kimigayo", employs the oldest lyrics of any national anthem, taking its words from the "Kokin Wakashū", which was first published in 905, yet these words were not set to music until 1880. The first anthem to be officially adopted as such was the Spanish anthem "La Marcha Real", in 1770; its origins remain unclear; it is suggested that it has 16th century Venetian origins, or even that it was composed by king Frederick the Great himself; it is also one of the few national anthems that has never had official lyrics. Anthems became increasingly popular among European states in the 18th century. For example, the British national anthem "God Save the Queen" was first performed as "God Save the King" in 1745. The French anthem "La Marseillaise" was written half a century later in 1792, and adopted in 1795.

National anthems are usually written in the most common language of the state, whether "de facto" or official. States with multiple national languages may offer several versions of their anthem. For instance, Switzerland's national anthem has different lyrics for each of the country's four official languages: French, German, Italian, and Romansh. One of New Zealand's two national anthems is commonly sung with the first verse in Māori ("Aotearoa") and the second in English ("God Defend New Zealand"). The tune is the same but the lyrics have different meanings. South Africa's national anthem is unique in that it is two different songs put together with five of the country's eleven official languages being used, in which each language comprises a stanza.






</doc>
<doc id="21473" url="https://en.wikipedia.org/wiki?curid=21473" title="Nikola Tesla">
Nikola Tesla

Nikola Tesla (; ; ; 10 July 1856 – 7 January 1943) was a Serbian-American inventor, electrical engineer, mechanical engineer, and futurist who is best known for his contributions to the design of the modern alternating current (AC) electricity supply system.

Born and raised in the Austrian Empire, Tesla studied engineering and physics in the 1870s without receiving a degree, and gained practical experience in the early 1880s working in telephony and at Continental Edison in the new electric power industry. In 1884 he emigrated to the United States, where he became a naturalized citizen. He worked for a short time at the Edison Machine Works in New York City before he struck out on his own. With the help of partners to finance and market his ideas, Tesla set up laboratories and companies in New York to develop a range of electrical and mechanical devices. His alternating current (AC) induction motor and related polyphase AC patents, licensed by Westinghouse Electric in 1888, earned him a considerable amount of money and became the cornerstone of the polyphase system which that company eventually marketed.

Attempting to develop inventions he could patent and market, Tesla conducted a range of experiments with mechanical oscillators/generators, electrical discharge tubes, and early X-ray imaging. He also built a wireless-controlled boat, one of the first ever exhibited. Tesla became well known as an inventor and demonstrated his achievements to celebrities and wealthy patrons at his lab, and was noted for his showmanship at public lectures. Throughout the 1890s, Tesla pursued his ideas for wireless lighting and worldwide wireless electric power distribution in his high-voltage, high-frequency power experiments in New York and Colorado Springs. In 1893, he made pronouncements on the possibility of wireless communication with his devices. Tesla tried to put these ideas to practical use in his unfinished Wardenclyffe Tower project, an intercontinental wireless communication and power transmitter, but ran out of funding before he could complete it.

After Wardenclyffe, Tesla experimented with a series of inventions in the 1910s and 1920s with varying degrees of success. Having spent most of his money, Tesla lived in a series of New York hotels, leaving behind unpaid bills. He died in New York City in January 1943. Tesla's work fell into relative obscurity following his death, until 1960, when the General Conference on Weights and Measures named the SI unit of magnetic flux density the tesla in his honor. There has been a resurgence in popular interest in Tesla since the 1990s.

Nikola Tesla was born an ethnic Serb in the village of Smiljan, within the Military Frontier, in the Austrian Empire (present day Croatia), on 1856. His father, Milutin Tesla (1819–1879), was an Eastern Orthodox priest. Tesla's mother, Đuka Mandić (1822–1892), whose father was also an Orthodox priest, had a talent for making home craft tools and mechanical appliances and the ability to memorize Serbian epic poems. Đuka had never received a formal education. Tesla credited his eidetic memory and creative abilities to his mother's genetics and influence. Tesla's progenitors were from western Serbia, near Montenegro.

Tesla was the fourth of five children. He had three sisters, Milka, Angelina and Marica, and an older brother named Dane, who was killed in a horse riding accident when Tesla was aged five. In 1861, Tesla attended primary school in Smiljan where he studied German, arithmetic, and religion. In 1862, the Tesla family moved to the nearby Gospić, where Tesla's father worked as parish priest. Nikola completed primary school, followed by middle school. In 1870, Tesla moved to Karlovac to attend high school at the Higher Real Gymnasium where the classes were held in German, as it was usual throughout schools within the Austro-Hungarian Military Frontier.

Tesla later wrote that he became interested in demonstrations of electricity by his physics professor. Tesla noted that these demonstrations of this "mysterious phenomena" made him want "to know more of this wonderful force". Tesla was able to perform integral calculus in his head, which prompted his teachers to believe that he was cheating. He finished a four-year term in three years, graduating in 1873.

In 1873, Tesla returned to Smiljan. Shortly after he arrived, he contracted cholera, was bedridden for nine months and was near death multiple times. Tesla's father, in a moment of despair, (who had originally wanted him to enter the priesthood) promised to send him to the best engineering school if he recovered from the illness.

In 1874, Tesla evaded conscription into the Austro-Hungarian Army in Smiljan by running away southeast of Lika to Tomingaj, near Gračac. There he explored the mountains wearing hunter's garb. Tesla said that this contact with nature made him stronger, both physically and mentally. He read many books while in Tomingaj and later said that Mark Twain's works had helped him to miraculously recover from his earlier illness.

In 1875, Tesla enrolled at Austrian Polytechnic in Graz on a Military Frontier scholarship. During his first year, Tesla never missed a lecture, earned the highest grades possible, passed nine exams (nearly twice as many as required), started a Serb cultural club, and even received a letter of commendation from the dean of the technical faculty to his father, which stated, "Your son is a star of first rank." During his second year, Tesla came into conflict with Professor Poeschl over the Gramme dynamo, when Tesla suggested that commutators were not necessary.

Tesla claimed that he worked from 3 a.m. to 11 p.m., no Sundays or holidays excepted. He was "mortified when [his] father made light of [those] hard won honors." After his father's death in 1879, Tesla found a package of letters from his professors to his father, warning that unless he were removed from the school, Tesla would die through overwork. At the end of his second year, Tesla lost his scholarship and became addicted to gambling. During his third year, Tesla gambled away his allowance and his tuition money, later gambling back his initial losses and returning the balance to his family. Tesla said that he "conquered [his] passion then and there," but later in the United States he was again known to play billiards. When examination time came, Tesla was unprepared and asked for an extension to study, but was denied. He did not receive grades for the last semester of the third year and he never graduated from the university.

In December 1878, Tesla left Graz and severed all relations with his family to hide the fact that he dropped out of school. His friends thought that he had drowned in the nearby Mur River. Tesla moved to Maribor, where he worked as a draftsman for 60 florins per month. He spent his spare time playing cards with local men on the streets.

In March 1879, Tesla's father went to Maribor to beg his son to return home, but he refused. Nikola suffered a nervous breakdown around the same time. On 24 March 1879, Tesla was returned to Gospić under police guard for not having a residence permit.

On 17 April 1879, Milutin Tesla died at the age of 60 after contracting an unspecified illness. Some sources say that he died of a stroke. During that year, Tesla taught a large class of students in his old school in Gospić.

In January 1880, two of Tesla's uncles put together enough money to help him leave Gospić for Prague, where he was to study. He arrived too late to enroll at Charles-Ferdinand University; he had never studied Greek, a required subject; and he was illiterate in Czech, another required subject. Tesla did, however, attend lectures in philosophy at the university as an auditor but he did not receive grades for the courses.

In 1881, Tesla moved to Budapest, Hungary, to work under Tivadar Puskás at a telegraph company, the Budapest Telephone Exchange. Upon arrival, Tesla realized that the company, then under construction, was not functional, so he worked as a draftsman in the Central Telegraph Office instead. Within a few months, the Budapest Telephone Exchange became functional, and Tesla was allocated the chief electrician position. During his employment, Tesla made many improvements to the Central Station equipment and claimed to have perfected a telephone repeater or amplifier, which was never patented nor publicly described.

In 1882, Tivadar Puskás got Tesla another job in Paris with the Continental Edison Company. Tesla began working in what was then a brand new industry, installing indoor incandescent lighting citywide in the form of an electric power utility. The company had several subdivisions and Tesla worked at the Société Electrique Edison, the division in the Ivry-sur-Seine suburb of Paris in charge of installing the lighting system. There he gained a great deal of practical experience in electrical engineering. Management took notice of his advanced knowledge in engineering and physics and soon had him designing and building improved versions of generating dynamos and motors. They also sent him on to troubleshoot engineering problems at other Edison utilities being built around France and in Germany.

In 1884, Edison manager Charles Batchelor, who had been overseeing the Paris installation, was brought back to the United States to manage the Edison Machine Works, a manufacturing division situated in New York City, and asked that Tesla be brought to the United States as well. In June 1884, Tesla emigrated and began working almost immediately at the Machine Works on Manhattan's Lower East Side, an overcrowded shop with a workforce of several hundred machinists, laborers, managing staff, and 20 "field engineers" struggling with the task of building the large electric utility in that city. As in Paris, Tesla was working on troubleshooting installations and improving generators. Historian W. Bernard Carlson notes Tesla may have met company founder Thomas Edison only a couple of times. One of those times was noted in Tesla's autobiography where, after staying up all night repairing the damaged dynamos on the ocean liner SS "Oregon", he ran into Batchelor and Edison, who made a quip about their "Parisian" being out all night. After Tesla told them he had been up all night fixing the "Oregon" Edison commented to Batchelor that "this is a damned good man". One of the projects given to Tesla was to develop an arc lamp-based street lighting system. Arc lighting was the most popular type of street lighting but it required high voltages and was incompatible with the Edison low-voltage incandescent system, causing the company to lose contracts in cities that wanted street lighting as well. Tesla's designs were never put into production, possibly because of technical improvements in incandescent street lighting or because of an installation deal that Edison made with an arc lighting company.

Tesla had been working at the Machine Works for a total of six months when he quit. What event precipitated his leaving is unclear. It may have been over a bonus he did not receive, either for redesigning generators or for the arc lighting system that was shelved. Tesla had previous run-ins with the Edison company over unpaid bonuses he believed he had earned. In his autobiography, Tesla stated the manager of the Edison Machine Works offered a $50,000 bonus to design "twenty-four different types of standard machines" "but it turned out to be a practical joke". Later versions of this story have Thomas Edison himself offering and then reneging on the deal, quipping "Tesla, you don't understand our American humor". The size of the bonus in either story has been noted as odd since Machine Works manager Batchelor was stingy with pay and the company did not have that amount of cash (equivalent to $12 million today) on hand. Tesla's diary contains just one comment on what happened at the end of his employment, a note he scrawled across the two pages covering 7 December 1884, to 4 January 1885, saying "Good by to the Edison Machine Works".

Soon after leaving the Edison company, Tesla was working on patenting an arc lighting system, possibly the same one he had developed at Edison. In March 1885, he met with patent attorney Lemuel W. Serrell, the same attorney used by Edison, to obtain help with submitting the patents. Serrell introduced Tesla to two businessmen, Robert Lane and Benjamin Vail, who agreed to finance an arc lighting manufacturing and utility company in Tesla's name, the Tesla Electric Light & Manufacturing. Tesla worked for the rest of the year obtaining the patents that included an improved DC generator, the first patents issued to Tesla in the US, and building and installing the system in Rahway, New Jersey. Tesla's new system gained notice in the technical press, which commented on its advanced features.

The investors showed little interest in Tesla's ideas for new types of alternating current motors and electrical transmission equipment. After the utility was up and running in 1886, they decided that the manufacturing side of the business was too competitive and opted to simply run an electric utility. They formed a new utility company, abandoning Tesla's company and leaving the inventor penniless. Tesla even lost control of the patents he had generated, since he had assigned them to the company in exchange for stock. He had to work at various electrical repair jobs and as a ditch digger for $2 per day. Later in life Tesla recounted that part of 1886 as a time of hardship, writing "My high education in various branches of science, mechanics and literature seemed to me like a mockery".

In late 1886, Tesla met Alfred S. Brown, a Western Union superintendent, and New York attorney Charles F. Peck. The two men were experienced in setting up companies and promoting inventions and patents for financial gain. Based on Tesla's new ideas for electrical equipment, including a thermo-magnetic motor idea, they agreed to back the inventor financially and handle his patents. Together they formed the Tesla Electric Company in April 1887, with an agreement that profits from generated patents would go ⅓ to Tesla, ⅓ to Peck and Brown, and ⅓ to fund development. They set up a laboratory for Tesla at 89 Liberty Street in Manhattan, where he worked on improving and developing new types of electric motors, generators, and other devices.

In 1887, Tesla developed an induction motor that ran on alternating current (AC), a power system format that was rapidly expanding in Europe and the United States because of its advantages in long-distance, high-voltage transmission. The motor used polyphase current, which generated a rotating magnetic field to turn the motor (a principle that Tesla claimed to have conceived in 1882). This innovative electric motor, patented in May 1888, was a simple self-starting design that did not need a commutator, thus avoiding sparking and the high maintenance of constantly servicing and replacing mechanical brushes.

Along with getting the motor patented, Peck and Brown arranged to get the motor publicized, starting with independent testing to verify it was a functional improvement, followed by press releases sent to technical publications for articles to run concurrent with the issue of the patent. Physicist William Arnold Anthony (who tested the motor) and "Electrical World" magazine editor Thomas Commerford Martin arranged for Tesla to demonstrate his AC motor on 16 May 1888 at the American Institute of Electrical Engineers. Engineers working for the Westinghouse Electric & Manufacturing Company reported to George Westinghouse that Tesla had a viable AC motor and related power system—something Westinghouse needed for the alternating current system he was already marketing. Westinghouse looked into getting a patent on a similar commutator-less, rotating magnetic field-based induction motor developed in 1885 and presented in a paper in March 1888 by Italian physicist Galileo Ferraris, but decided that Tesla's patent would probably control the market.
In July 1888, Brown and Peck negotiated a licensing deal with George Westinghouse for Tesla's polyphase induction motor and transformer designs for $60,000 in cash and stock and a royalty of $2.50 per AC horsepower produced by each motor. Westinghouse also hired Tesla for one year for the large fee of $2,000 ($ in today's dollars) per month to be a consultant at the Westinghouse Electric & Manufacturing Company's Pittsburgh labs.

During that year, Tesla worked in Pittsburgh, helping to create an alternating current system to power the city's streetcars. He found it a frustrating period because of conflicts with the other Westinghouse engineers over how best to implement AC power. Between them, they settled on a 60-cycle AC system that Tesla proposed (to match the working frequency of Tesla's motor), but they soon found that it would not work for streetcars, since Tesla's induction motor could run only at a constant speed. They ended up using a DC traction motor instead.

Tesla's demonstration of his induction motor and Westinghouse's subsequent licensing of the patent, both in 1888, came at the time of extreme competition between electric companies. The three big firms, Westinghouse, Edison, and Thomson-Houston, were trying to grow in a capital-intensive business while financially undercutting each other. There was even a "war of currents" propaganda campaign going on with Edison Electric trying to claim their direct current system was better and safer than the Westinghouse alternating current system. Competing in this market meant Westinghouse would not have the cash or engineering resources to develop Tesla's motor and the related polyphase system right away.

Two years after signing the Tesla contract, Westinghouse Electric was in trouble. The near collapse of Barings Bank in London triggered the financial panic of 1890, causing investors to call in their loans to Westinghouse Electric. The sudden cash shortage forced the company to refinance its debts. The new lenders demanded that Westinghouse cut back on what looked like excessive spending on acquisition of other companies, research, and patents, including the per motor royalty in the Tesla contract. At that point, the Tesla induction motor had been unsuccessful and was stuck in development. Westinghouse was paying a $15,000-a-year guaranteed royalty even though operating examples of the motor were rare and polyphase power systems needed to run it were even rarer. In early 1891, George Westinghouse explained his financial difficulties to Tesla in stark terms, saying that, if he did not meet the demands of his lenders, he would no longer be in control of Westinghouse Electric and Tesla would have to "deal with the bankers" to try to collect future royalties. The advantages of having Westinghouse continue to champion the motor probably seemed obvious to Tesla and he agreed to release the company from the royalty payment clause in the contract. Six years later Westinghouse purchased Tesla's patent for a lump sum payment of $216,000 as part of a patent-sharing agreement signed with General Electric (a company created from the 1892 merger of Edison and Thomson-Houston).

The money Tesla made from licensing his AC patents made him independently wealthy and gave him the time and funds to pursue his own interests. In 1889, Tesla moved out of the Liberty Street shop Peck and Brown had rented and for the next dozen years worked out of a series of workshop/laboratory spaces in Manhattan. These included a lab at 175 Grand Street (1889–1892), the fourth floor of 33–35 South Fifth Avenue (1892–1895), and sixth and seventh floors of 46 & 48 East Houston Street (1895–1902). Tesla and his hired staff conducted some of his most significant work in these workshops.

In the summer of 1889, Tesla traveled to the 1889 Exposition Universelle in Paris and learned of Heinrich Hertz's 1886–1888 experiments that proved the existence of electromagnetic radiation, including radio waves. Tesla found this new discovery "refreshing" and decided to explore it more fully. In repeating, and then expanding on, these experiments, Tesla tried powering a Ruhmkorff coil with a high speed alternator he had been developing as part of an improved arc lighting system but found that the high-frequency current overheated the iron core and melted the insulation between the primary and secondary windings in the coil. To fix this problem Tesla came up with his "oscillating transformer", with an air gap instead of insulating material between the primary and secondary windings and an iron core that could be moved to different positions in or out of the coil. Later called the Tesla coil, it would be used to produce high-voltage, low-current, high frequency alternating-current electricity. He would use this resonant transformer circuit in his later wireless power work.

On 30 July 1891, aged 35, Tesla became a naturalized citizen of the United States. In the same year, he patented his Tesla coil.

After 1890, Tesla experimented with transmitting power by inductive and capacitive coupling using high AC voltages generated with his Tesla coil. He attempted to develop a wireless lighting system based on near-field inductive and capacitive coupling and conducted a series of public demonstrations where he lit Geissler tubes and even incandescent light bulbs from across a stage. He spent most of the decade working on variations of this new form of lighting with the help of various investors but none of the ventures succeeded in making a commercial product out of his findings.

In 1893 at St. Louis, Missouri, the Franklin Institute in Philadelphia, Pennsylvania and the National Electric Light Association, Tesla told onlookers that he was sure a system like his could eventually conduct "intelligible signals or perhaps even power to any distance without the use of wires" by conducting it through the Earth.

Tesla served as a vice-president of the American Institute of Electrical Engineers from 1892 to 1894, the forerunner of the modern-day IEEE (along with the Institute of Radio Engineers).

By the beginning of 1893, Westinghouse engineer Charles F. Scott and then Benjamin G. Lamme had made progress on an efficient version of Tesla's induction motor. Lamme found a way to make the polyphase system it would need compatible with older single phase AC and DC systems by developing a rotary converter. Westinghouse Electric now had a way to provide electricity to all potential customers and started branding their polyphase AC system as the "Tesla Polyphase System". They believed that Tesla's patents gave them patent priority over other polyphase AC systems.

Westinghouse Electric asked Tesla to participate in the 1893 World's Columbian Exposition in Chicago where the company had a large space in the "Electricity Building" devoted to electrical exhibits. Westinghouse Electric won the bid to light the Exposition with alternating current and it was a key event in the history of AC power, as the company demonstrated to the American public the safety, reliability, and efficiency of an alternating current system that was polyphase and could also supply the other AC and DC exhibits at the fair.

A special exhibit space was set up to display various forms and models of Tesla's induction motor. The rotating magnetic field that drove them was explained through a series of demonstrations including an "Egg of Columbus" that used the two phase coil found in an induction motor to spin a copper egg making it stand on end.

Tesla visited the fair for a week during its six-month run to attend the International Electrical Congress and put on a series of demonstrations at the Westinghouse exhibit. A specially darkened room had been set up where Tesla showed his wireless lighting system, using a demonstration he had previously performed throughout America and Europe; these included using high-voltage, high-frequency alternating current to light wireless gas-discharge lamps.

An observer noted:

During his presentation at the International Electrical Congress in the Columbian Exposition Agriculture Hall, Tesla introduced his steam powered reciprocating electricity generator that he patented that year, something he thought was a better way to generate alternating current. Steam was forced into the oscillator and rushed out through a series of ports, pushing a piston up and down that was attached to an armature. The magnetic armature vibrated up and down at high speed, producing an alternating magnetic field. This induced alternating electric current in the wire coils located adjacent. It did away with the complicated parts of a steam engine/generator, but never caught on as a feasible engineering solution to generate electricity.

In 1893, Edward Dean Adams, who headed up the Niagara Falls Cataract Construction Company, sought Tesla's opinion on what system would be best to transmit power generated at the falls. Over several years, there had been a series of proposals and open competitions on how best to use power generated by the falls. Among the systems proposed by several US and European companies were two-phase and three-phase AC, high-voltage DC, and compressed air. Adams asked Tesla for information about the current state of all the competing systems. Tesla advised Adams that a two-phased system would be the most reliable, and that there was a Westinghouse system to light incandescent bulbs using two-phase alternating current. The company awarded a contract to Westinghouse Electric for building a two-phase AC generating system at the Niagara Falls, based on Tesla's advice and Westinghouse's demonstration at the Columbian Exposition that they could build a complete AC system. At the same time, a further contract was awarded to General Electric to build the AC distribution system.

In 1895, Edward Dean Adams, impressed with what he saw when he toured Tesla's lab, agreed to help found the Nikola Tesla Company, set up to fund, develop, and market a variety of previous Tesla patents and inventions as well as new ones. Alfred Brown signed on, bringing along patents developed under Peck and Brown. The board was filled out with William Birch Rankine and Charles F. Coaney. It found few investors; the mid-1890s was a tough time financially, and the wireless lighting and oscillators patents it was set up to market never panned out. The company handled Tesla's patents for decades to come.

In the early morning hours of 13 March 1895, the South Fifth Avenue building that housed Tesla's lab caught fire. It started in the basement of the building and was so intense Tesla's 4th floor lab burned and collapsed into the second floor. The fire not only set back Tesla's ongoing projects, it destroyed a collection of early notes and research material, models, and demonstration pieces, including many that had been exhibited at the 1893 Worlds Colombian Exposition. Tesla told "The New York Times" "I am in too much grief to talk. What can I say?" After the fire Tesla moved to 46 & 48 East Houston Street and rebuilt his lab on the 6th and 7th floors.

Starting in 1894, Tesla began investigating what he referred to as radiant energy of "invisible" kinds after he had noticed damaged film in his laboratory in previous experiments (later identified as "Roentgen rays" or "X-Rays"). His early experiments were with Crookes tubes, a cold cathode electrical discharge tube. Tesla may have inadvertently captured an X-ray image—predating, by a few weeks, Wilhelm Röntgen's December 1895 announcement of the discovery of X-rays when he tried to photograph Mark Twain illuminated by a Geissler tube, an earlier type of gas discharge tube. The only thing captured in the image was the metal locking screw on the camera lens.

In March 1896, after hearing of Röntgen's discovery of X-ray and X-ray imaging (radiography), Tesla proceeded to do his own experiments in X-ray imaging, developing a high energy single terminal vacuum tube of his own design that had no target electrode and that worked from the output of the Tesla Coil (the modern term for the phenomenon produced by this device is "bremsstrahlung" or "braking radiation"). In his research, Tesla devised several experimental setups to produce X-rays. Tesla held that, with his circuits, the "instrument will ... enable one to generate Roentgen rays of much greater power than obtainable with ordinary apparatus".

Tesla noted the hazards of working with his circuit and single-node X-ray-producing devices. In his many notes on the early investigation of this phenomenon, he attributed the skin damage to various causes. He believed early on that damage to the skin was not caused by the Roentgen rays, but by the ozone generated in contact with the skin, and to a lesser extent, by nitrous acid. Tesla incorrectly believed that X-rays were longitudinal waves, such as those produced in waves in plasmas. These plasma waves can occur in force-free magnetic fields.

On 11 July 1934, the "New York Herald Tribune" published an article on Tesla, in which he recalled an event that occasionally took place while experimenting with his single-electrode vacuum tubes. A minute particle would break off the cathode, pass out of the tube, and physically strike him:

Tesla said he could feel a sharp stinging pain where it entered his body, and again at the place where it passed out. In comparing these particles with the bits of metal projected by his "electric gun," Tesla said, "The particles in the beam of force ... will travel much faster than such particles ... and they will travel in concentrations".

In 1898, Tesla demonstrated a boat that used a coherer-based radio control—which he dubbed "telautomaton"—to the public during an electrical exhibition at Madison Square Garden. Tesla tried to sell his idea to the US military as a type of radio-controlled torpedo, but they showed little interest. Remote radio control remained a novelty until World War I and afterward, when a number of countries used it in military programs. Tesla took the opportunity to further demonstrate "Teleautomatics" in an address to a meeting of the Commercial Club in Chicago, while he was travelling to Colorado Springs, on 13 May 1899.

From the 1890s through 1906, Tesla spent a great deal of his time and fortune on a series of projects trying to develop the transmission of electrical power without wires. It was an expansion of his idea of using coils to transmit power that he had been demonstrating in wireless lighting. He saw this as not only a way to transmit large amounts of power around the world but also, as he had pointed out in his earlier lectures, a way to transmit worldwide communications.

At the time Tesla was formulating his ideas, there was no feasible way to wirelessly transmit communication signals over long distances, let alone large amounts of power. Tesla had studied radio waves early on, and came to the conclusion that part of existing study on them, by Hertz, was incorrect. Also, this new form of radiation was widely considered at the time to be a short-distance phenomenon that seemed to die out in less than a mile. Tesla noted that, even if theories on radio waves were true, they were totally worthless for his intended purposes since this form of "invisible light" would diminish over distance just like any other radiation and would travel in straight lines right out into space, becoming "hopelessly lost".

By the mid-1890s, Tesla was working on the idea that he might be able to conduct electricity long distance through the Earth or the atmosphere, and began working on experiments to test this idea including setting up a large resonance transformer magnifying transmitter in his East Houston Street lab. Seeming to borrow from a common idea at the time that the Earth's atmosphere was conductive, he proposed a system composed of balloons suspending, transmitting, and receiving, electrodes in the air above in altitude, where he thought the lower pressure would allow him to send high voltages (millions of volts) long distances.

To further study the conductive nature of low pressure air, Tesla set up an experimental station at high altitude in Colorado Springs during 1899. There he could safely operate much larger coils than in the cramped confines of his New York lab, and an associate had made an arrangement for the El Paso Power Company to supply alternating current free of charge. To fund his experiments, he convinced John Jacob Astor IV to invest $100,000 ($ in today's dollars) to become a majority share holder in the Nikola Tesla Company. Astor thought he was primarily investing in the new wireless lighting system. Instead, Tesla used the money to fund his Colorado Springs experiments. Upon his arrival, he told reporters that he planned to conduct wireless telegraphy experiments, transmitting signals from Pikes Peak to Paris.

There, he conducted experiments with a large coil operating in the megavolts range, producing artificial lightning (and thunder) consisting of millions of volts and discharges of up to in length, and, at one point, inadvertently burned out the generator in El Paso, causing a power outage. The observations he made of the electronic noise of lightning strikes led him to (incorrectly) conclude that he could use the entire globe of the Earth to conduct electrical energy.

During his time at his laboratory, Tesla observed unusual signals from his receiver which he speculated to be communications from another planet. He mentioned them in a letter to a reporter in December 1899 and to the Red Cross Society in December 1900. Reporters treated it as a sensational story and jumped to the conclusion Tesla was hearing signals from Mars. He expanded on the signals he heard in a 9 February 1901 "Collier's Weekly" article entitled "Talking With Planets", where he said it had not been immediately apparent to him that he was hearing "intelligently controlled signals" and that the signals could have come from Mars, Venus, or other planets. It has been hypothesized that he may have intercepted Guglielmo Marconi's European experiments in July 1899—Marconi may have transmitted the letter S (dot/dot/dot) in a naval demonstration, the same three impulses that Tesla hinted at hearing in Colorado—or signals from another experimenter in wireless transmission.

Tesla had an agreement with the editor of "The Century Magazine" to produce an article on his findings. The magazine sent a photographer to Colorado to photograph the work being done there. The article, titled "The Problem of Increasing Human Energy", appeared in the June 1900 edition of the magazine. He explained the superiority of the wireless system he envisioned but the article was more of a lengthy philosophical treatise than an understandable scientific description of his work, illustrated with what were to become iconic images of Tesla and his Colorado Springs experiments.

Tesla made the rounds in New York trying to find investors for what he thought would be a viable system of wireless transmission, wining and dining them at the Waldorf-Astoria's Palm Garden (the hotel where he was living at the time), The Players Club, and Delmonico's. In March 1901, he obtained $150,000 ($ in today's dollars) from J. Pierpont Morgan in return for a 51% share of any generated wireless patents, and began planning the Wardenclyffe Tower facility to be built in Shoreham, New York, east of the city on the North Shore of Long Island.

By July 1901, Tesla had expanded his plans to build a more powerful transmitter to leap ahead of Marconi's radio-based system, which Tesla thought was a copy of his own. He approached Morgan to ask for more money to build the larger system, but Morgan refused to supply any further funds. In December 1901, Marconi successfully transmitted the letter S from England to Newfoundland, defeating Tesla in the race to be first to complete such a transmission. A month after Marconi's success, Tesla tried to get Morgan to back an even larger plan to transmit messages and power by controlling "vibrations throughout the globe". Over the next five years, Tesla wrote more than 50 letters to Morgan, pleading for and demanding additional funding to complete the construction of Wardenclyffe. Tesla continued the project for another nine months into 1902. The tower was erected to its full height of . In June 1902, Tesla moved his lab operations from Houston Street to Wardenclyffe.

Investors on Wall Street were putting their money into Marconi's system, and some in the press began turning against Tesla's project, claiming it was a hoax. The project came to a halt in 1905, and in 1906, the financial problems and other events may have led to what Tesla biographer Marc J. Seifer suspects was a nervous breakdown on Tesla's part. Tesla mortgaged the Wardenclyffe property to cover his debts at the Waldorf-Astoria, which eventually mounted to $20,000 ($ in today's dollars). He lost the property in foreclosure in 1915, and in 1917 the Tower was demolished by the new owner to make the land a more viable real estate asset.

After Wardenclyffe closed, Tesla continued to write to Morgan; after "the great man" died, Tesla wrote to Morgan's son Jack, trying to get further funding for the project. In 1906, Tesla opened offices at 165 Broadway in Manhattan, trying to raise further funds by developing and marketing his patents. He went on to have offices at the Metropolitan Life Tower from 1910 to 1914; rented for a few months at the Woolworth Building, moving out because he could not afford the rent; and then to office space at 8 West 40th Street from 1915 to 1925. After moving to 8 West 40th Street, he was effectively bankrupt. Most of his patents had run out and he was having trouble with the new inventions he was trying to develop.

On his 50th birthday, in 1906, Tesla demonstrated a 16,000 rpm bladeless turbine. During 1910–1911, at the Waterside Power Station in New York, several of his bladeless turbine engines were tested at 100–5,000 hp. Tesla worked with several companies including from 1919–1922 in Milwaukee, for Allis-Chalmers. He spent most of his time trying to perfect the Tesla turbine with Hans Dahlstrand, the head engineer at the company, but engineering difficulties meant it was never made into a practical device. Tesla did license the idea to a precision instrument company and it found use in the form of luxury car speedometers and other instruments.

When World War I broke out, the British cut the transatlantic telegraph cable linking the US to Germany in order to control the flow of information between the two countries. They also tried to shut off German wireless communication to and from the US by having the US Marconi Company sue the German radio company Telefunken for patent infringement. Telefunken brought in the physicists Jonathan Zenneck and Karl Ferdinand Braun for their defense, and hired Tesla as a witness for two years for $1,000 a month. The case stalled and then went moot when the US entered the war against Germany in 1917.

In 1915, Tesla attempted to sue the Marconi Company for infringement of his wireless tuning patents. Marconi's initial radio patent had been awarded in the US in 1897, but his 1900 patent submission covering improvements to radio transmission had been rejected several times, before it was finally approved in 1904, on the grounds that it infringed on other existing patents including two 1897 Tesla wireless power tuning patents. Tesla's 1915 case went nowhere, but in a related case, where the Marconi Company tried to sue the US government over WWI patent infringements, a Supreme Court of the United States 1943 decision restored the prior patents of Oliver Lodge, John Stone, and Tesla. The court declared that their decision had no bearing on Marconi's claim as the first to achieve radio transmission, just that since Marconi's claim to certain patented improvements were questionable, the company could not claim infringement on those same patents.

On 6 November 1915, a Reuters news agency report from London had the 1915 Nobel Prize in Physics awarded to Thomas Edison and Nikola Tesla; however, on 15 November, a Reuters story from Stockholm stated the prize that year was being awarded to Sir William Henry Bragg and William Lawrence Bragg "for their services in the analysis of crystal structure by means of X-rays". There were unsubstantiated rumors at the time that either Tesla or Edison had refused the prize. The Nobel Foundation said, "Any rumor that a person has not been given a Nobel Prize because he has made known his intention to refuse the reward is ridiculous"; a recipient could decline a Nobel Prize only after he is announced a winner.

There have been subsequent claims by Tesla biographers that Edison and Tesla were the original recipients and that neither was given the award because of their animosity toward each other; that each sought to minimize the other's achievements and right to win the award; that both refused ever to accept the award if the other received it first; that both rejected any possibility of sharing it; and even that a wealthy Edison refused it to keep Tesla from getting the $20,000 prize money.

In the years after these rumors, neither Tesla nor Edison won the prize (although Edison received one of 38 possible bids in 1915 and Tesla received one of 38 possible bids in 1937).

Tesla won numerous medals and awards over this time. They include:

Tesla attempted to market several devices based on the production of ozone. These included his 1900 Tesla Ozone Company selling an 1896 patented device based on his Tesla Coil, used to bubble ozone through different types of oils to make a therapeutic gel. He also tried to develop a variation of this a few years later as a room sanitizer for hospitals.

Tesla theorized that the application of electricity to the brain enhanced intelligence. In 1912, he crafted "a plan to make dull students bright by saturating them unconsciously with electricity," wiring the walls of a schoolroom and, "saturating [the schoolroom] with infinitesimal electric waves vibrating at high frequency. The whole room will thus, Mr. Tesla claims, be converted into a health-giving and stimulating electromagnetic field or 'bath.'" The plan was, at least provisionally, approved by then superintendent of New York City schools, William H. Maxwell.

Before World War I, Tesla sought overseas investors. After the war started, Tesla lost the funding he was receiving from his patents in European countries.

In the August 1917 edition of the magazine "Electrical Experimenter", Tesla postulated that electricity could be used to locate submarines via using the reflection of an "electric ray" of "tremendous frequency," with the signal being viewed on a fluorescent screen (a system that has been noted to have a superficial resemblance to modern radar). Tesla was incorrect in his assumption that high frequency radio waves would penetrate water. Émile Girardeau, who helped develop France's first radar system in the 1930s, noted in 1953 that Tesla's general speculation that a very strong high-frequency signal would be needed was correct. Girardeau said, "(Tesla) was prophesying or dreaming, since he had at his disposal no means of carrying them out, but one must add that if he was dreaming, at least he was dreaming correctly".

In 1928, Tesla received , for a biplane capable of taking off vertically (VTOL aircraft) and then of being "gradually tilted through manipulation of the elevator devices" in flight until it was flying like a conventional plane. Tesla thought the plane would sell for less than $1,000, although the aircraft has been described as impractical, although it has early resemblances to the V-22 Osprey used by the US military. This was his last patent and at this time Tesla closed his last office at 350 Madison Ave., which he had moved into two years earlier.

Tesla lived at the Waldorf Astoria in New York City from 1900 and ran up a large bill. He moved to the St. Regis Hotel in 1922 and followed a pattern from then on of moving to a different hotel every few years and leaving unpaid bills behind.

Tesla walked to the park every day to feed the pigeons. He began feeding them at the window of his hotel room and nursed injured birds back to health. He said that he had been visited by a certain injured white pigeon daily. He spent over $2,000 to care for the bird, including a device he built to support her comfortably while her broken wing and leg healed. Tesla stated:

Tesla's unpaid bills, as well as complaints about the mess made by pigeons, led to his eviction from the St. Regis in 1923. He was also forced to leave the Hotel Pennsylvania in 1930 and the Hotel Governor Clinton in 1934. At one point he also took rooms at the Hotel Marguery.

Tesla moved to the Hotel New Yorker in 1934. At this time Westinghouse Electric & Manufacturing Company began paying him $125 per month in addition to paying his rent. Accounts of how this came about vary. Several sources claim that Westinghouse was concerned, or possibly warned, about potential bad publicity arising from the impoverished conditions in which their former star inventor was living. The payment has been described as being couched as a "consulting fee" to get around Tesla's aversion to accepting charity. Tesla biographer Marc Seifer described the Westinghouse payments as a type of "unspecified settlement". In any case, Westinghouse provided the funds for Tesla for the rest of his life.

In 1931, a young journalist whom Tesla befriended, Kenneth M. Swezey, organized a celebration for the inventor's 75th birthday. Tesla received congratulatory letters from more than 70 pioneers in science and engineering, including Albert Einstein, and he was also featured on the cover of "Time" magazine. The cover caption "All the world's his power house" noted his contribution to electrical power generation.
The party went so well that Tesla made it an annual event, an occasion where he would put out a large spread of food and drink—featuring dishes of his own creation. He invited the press in order to see his inventions and hear stories about his past exploits, views on current events, and sometimes baffling claims.
At the 1932 party, Tesla claimed he had invented a motor that would run on cosmic rays.
In 1933 at age 77, Tesla told reporters at the event that, after 35 years of work, he was on the verge of producing proof of a new form of energy. He claimed it was a theory of energy that was "violently opposed" to Einsteinian physics, and could be tapped with an apparatus that would be cheap to run and last 500 years. He also told reporters he was working on a way to transmit individualized private radio wavelengths, working on breakthroughs in metallurgy, and developing a way to photograph the retina to record thought.

At the 1934 occasion, Tesla told reporters he had designed a superweapon he claimed would end all war. He called it "teleforce", but was usually referred to as his death ray. Tesla described it as a defensive weapon that would be put up along the border of a country and be used against attacking ground-based infantry or aircraft. Tesla never revealed detailed plans of how the weapon worked during his lifetime but, in 1984, they surfaced at the Nikola Tesla Museum archive in Belgrade. The treatise, "The New Art of Projecting Concentrated Non-dispersive Energy through the Natural Media", described an open-ended vacuum tube with a gas jet seal that allows particles to exit, a method of charging slugs of tungsten or mercury to millions of volts, and directing them in streams (through electrostatic repulsion). Tesla tried to interest the US War Department, the United Kingdom, the Soviet Union, and Yugoslavia in the device.

In 1935 at his 79th birthday party, Tesla covered many topics. He claimed to have discovered the cosmic ray in 1896 and invented a way to produce direct current by induction, and made many claims about his mechanical oscillator. Describing the device (which he expected would earn him $100 million within two years) he told reporters that a version of his oscillator had caused an earthquake in his 46 East Houston Street lab and neighboring streets in Lower Manhattan in 1898. He went on to tell reporters his oscillator could destroy the Empire State Building with 5 lbs of air pressure. He also explained a new technique he developed using his oscillators he called "Telegeodynamics", using it to transmit vibrations into the ground that he claimed would work over any distance to be used for communication or locating underground mineral deposits.

In his 1937 Grand Ballroom of Hotel New Yorker event, Tesla received the Order of the White Lion from the Czechoslovak ambassador and a medal from the Yugoslav ambassador. On questions concerning the death ray, Tesla stated, "But it is not an experiment ... I have built, demonstrated and used it. Only a little time will pass before I can give it to the world."

In the fall of 1937 at the age of 81, after midnight one night, Tesla left the Hotel New Yorker to make his regular commute to the cathedral and library to feed the pigeons. While crossing a street a couple of blocks from the hotel, Tesla was unable to dodge a moving taxicab and was thrown to the ground. His back was severely wrenched and three of his ribs were broken in the accident. The full extent of his injuries was never known; Tesla refused to consult a doctor, an almost lifelong custom, and never fully recovered.

On 7 January 1943, at the age of 86, Tesla died alone in Room 3327 of the Hotel New Yorker. His body was later found by maid Alice Monaghan after she had entered Tesla's room, ignoring the "do not disturb" sign that Tesla had placed on his door two days earlier. Assistant medical examiner H.W. Wembley examined the body and ruled that the cause of death had been coronary thrombosis.

Two days later the Federal Bureau of Investigation ordered the Alien Property Custodian to seize Tesla's belongings. John G. Trump, a professor at M.I.T. and a well-known electrical engineer serving as a technical aide to the National Defense Research Committee, was called in to analyze the Tesla items, which were being held in custody. After a three-day investigation, Trump's report concluded that there was nothing which would constitute a hazard in unfriendly hands, stating:

In a box purported to contain a part of Tesla's "death ray", Trump found a 45-year-old multidecade resistance box.

On 10 January 1943, New York City mayor Fiorello La Guardia read a eulogy written by Slovene-American author Louis Adamic live over the WNYC radio while violin pieces "Ave Maria" and "Tamo daleko" were played in the background. On 12 January, two thousand people attended a state funeral for Tesla at the Cathedral of St. John the Divine in Manhattan. After the funeral, Tesla's body was taken to the Ferncliff Cemetery in Ardsley, New York, where it was later cremated. The following day, a second service was conducted by prominent priests in the Trinity Chapel (today's Serbian Orthodox Cathedral of Saint Sava) in New York City.

In 1952, following pressure from Tesla's nephew, Sava Kosanović, Tesla's entire estate was shipped to Belgrade in 80 trunks marked N.T. In 1957, Kosanović's secretary Charlotte Muzar transported Tesla's ashes from the United States to Belgrade. The ashes are displayed in a gold-plated sphere on a marble pedestal in the Nikola Tesla Museum.

Tesla obtained around 300 patents worldwide for his inventions. Some of Tesla's patents are not accounted for, and various sources have discovered some that have lain hidden in patent archives. There are a minimum of 278 known patents issued to Tesla in 26 countries. Many of Tesla's patents were in the United States, Britain, and Canada, but many other patents were approved in countries around the globe. Many inventions developed by Tesla were not put into patent protection.

Tesla was tall and weighed , with almost no weight variance from 1888 to about 1926. His appearance was described by newspaper editor Arthur Brisbane as "almost the tallest, almost the thinnest and certainly the most serious man who goes to Delmonico's regularly". He was an elegant, stylish figure in New York City, meticulous in his grooming, clothing, and regimented in his daily activities, an appearance he maintained so as to further his business relationships. He was also described as having light eyes, "very big hands", and "remarkably big" thumbs.

Tesla read many works, memorizing complete books, and supposedly possessed a photographic memory. He was a polyglot, speaking eight languages: Serbo-Croatian, Czech, English, French, German, Hungarian, Italian, and Latin. Tesla related in his autobiography that he experienced detailed moments of inspiration. During his early life, Tesla was repeatedly stricken with illness. He suffered a peculiar affliction in which blinding flashes of light appeared before his eyes, often accompanied by visions. Often, the visions were linked to a word or idea he might have come across; at other times they provided the solution to a particular problem he had encountered. Just by hearing the name of an item, he could envision it in realistic detail. Tesla visualized an invention in his mind with extreme precision, including all dimensions, before moving to the construction stage, a technique sometimes known as picture thinking. He typically did not make drawings by hand but worked from memory. Beginning in his childhood, Tesla had frequent flashbacks to events that had happened previously in his life.

Tesla never married, explaining that his chastity was very helpful to his scientific abilities. He once said in earlier years that he felt he could never be worthy enough for a woman, considering women superior in every way. His opinion had started to sway in later years when he felt that women were trying to outdo men and make themselves more dominant. This "new woman" was met with much indignation from Tesla, who felt that women were losing their femininity by trying to be in power. In an interview with the "Galveston Daily News" on 10 August 1924 he stated, "In place of the soft voiced, gentle woman of my reverent worship, has come the woman who thinks that her chief success in life lies in making herself as much as possible like man—in dress, voice and actions, in sports and achievements of every kind ... The tendency of women to push aside man, supplanting the old spirit of cooperation with him in all the affairs of life, is very disappointing to me". Although he told a reporter in later years that he sometimes felt that by not marrying, he had made too great a sacrifice to his work, Tesla chose to never pursue or engage in any known relationships, instead finding all the stimulation he needed in his work.

Tesla was asocial and prone to seclude himself with his work. However, when he did engage in a social life, many people spoke very positively and admiringly of Tesla. Robert Underwood Johnson described him as attaining a "distinguished sweetness, sincerity, modesty, refinement, generosity, and force". His secretary, Dorothy Skerrit, wrote: "his genial smile and nobility of bearing always denoted the gentlemanly characteristics that were so ingrained in his soul". Tesla's friend, Julian Hawthorne, wrote, "seldom did one meet a scientist or engineer who was also a poet, a philosopher, an appreciator of fine music, a linguist, and a connoisseur of food and drink".

Tesla was a good friend of Francis Marion Crawford, Robert Underwood Johnson, Stanford White, Fritz Lowenstein, George Scherff, and Kenneth Swezey. In middle age, Tesla became a close friend of Mark Twain; they spent a lot of time together in his lab and elsewhere. Twain notably described Tesla's induction motor invention as "the most valuable patent since the telephone". At a party thrown by actress Sarah Bernhardt in 1896, Tesla met Indian Hindu monk Vivekananda and the two talked about how the inventor's ideas on energy seemed to match up with Vedantic cosmology. In the late 1920s, Tesla befriended George Sylvester Viereck, a poet, writer, mystic, and later, a Nazi propagandist. Tesla occasionally attended dinner parties held by Viereck and his wife.

Tesla could be harsh at times and openly expressed disgust for overweight people, such as when he fired a secretary because of her weight. He was quick to criticize clothing; on several occasions, Tesla directed a subordinate to go home and change her dress. When Thomas Edison died, in 1931, Tesla contributed the only negative opinion to "The New York Times", buried in an extensive coverage of Edison's life:

Tesla claimed never to sleep more than two hours per night. However, he did admit to "dozing" from time to time "to recharge his batteries". During his second year of study at Graz, Tesla developed a passionate proficiency for billiards, chess, and card-playing, sometimes spending more than 48 hours in a stretch at a gaming table. On one occasion at his laboratory, Tesla worked for a period of 84 hours without rest. Kenneth Swezey, a journalist whom Tesla had befriended, confirmed that Tesla rarely slept. Swezey recalled one morning when Tesla called him at 3 a.m.: "I was sleeping in my room like one dead ... Suddenly, the telephone ring awakened me ... [Tesla] spoke animatedly, with pauses, [as he] ... work[ed] out a problem, comparing one theory to another, commenting; and when he felt he had arrived at the solution, he suddenly closed the telephone."

Tesla worked every day from 9:00a.m. until 6:00p.m. or later, with dinner at exactly 8:10 p.m., at Delmonico's restaurant and later the Waldorf-Astoria Hotel. Tesla then telephoned his dinner order to the headwaiter, who also could be the only one to serve him. "The meal was required to be ready at eight o'clock ... He dined alone, except on the rare occasions when he would give a dinner to a group to meet his social obligations. Tesla then resumed his work, often until 3:00a.m."

For exercise, Tesla walked between per day. He curled his toes one hundred times for each foot every night, saying that it stimulated his brain cells.

In an interview with newspaper editor Arthur Brisbane, Tesla said that he did not believe in telepathy, stating, "Suppose I made up my mind to murder you," he said, "In a second you would know it. Now, isn't that wonderful? By what process does the mind get at all this?" In the same interview, Tesla said that he believed that all fundamental laws could be reduced to one.

Tesla became a vegetarian in his later years, living on only milk, bread, honey, and vegetable juices.

Tesla disagreed with the theory of atoms being composed of smaller subatomic particles, stating there was no such thing as an electron creating an electric charge. He believed that if electrons existed at all, they were some fourth state of matter or "sub-atom" that could exist only in an experimental vacuum and that they had nothing to do with electricity. Tesla believed that atoms are immutable—they could not change state or be split in any way. He was a believer in the 19th-century concept of an all-pervasive ether that transmitted electrical energy.

Tesla was generally antagonistic towards theories about the conversion of matter into energy. He was also critical of Einstein's theory of relativity, saying:

Tesla claimed to have developed his own physical principle regarding matter and energy that he started working on in 1892, and in 1937, at age 81, claimed in a letter to have completed a "dynamic theory of gravity" that "[would] put an end to idle speculations and false conceptions, as that of curved space". He stated that the theory was "worked out in all details" and that he hoped to soon give it to the world. Further elucidation of his theory was never found in his writings.

Tesla is widely considered by his biographers to have been a humanist in philosophical outlook on top of his gifts as a technological scientist.
This did not preclude Tesla, like many of his era, becoming a proponent of an imposed selective breeding version of eugenics.

Tesla expressed the belief that human "pity" had come to interfere with the natural "ruthless workings of nature". Though his argumentation did not depend on a concept of a "master race" or the inherent superiority of one person over another, he advocated for eugenics. In a 1937 interview he stated:

In 1926, Tesla commented on the ills of the social subservience of women and the struggle of women toward gender equality, and indicated that humanity's future would be run by "Queen Bees". He believed that women would become the dominant sex in the future.

Tesla made predictions about the relevant issues of a post-World War I environment in a printed article, "Science and Discovery are the great Forces which will lead to the Consummation of the War" (20 December 1914). Tesla believed that the League of Nations was not a remedy for the times and issues.

Tesla was raised an Orthodox Christian. Later in life he did not consider himself to be a "believer in the orthodox sense," said he opposed religious fanaticism, and said "Buddhism and Christianity are the greatest religions both in number of disciples and in importance". He also said "To me, the universe is simply a great machine which never came into being and never will end" and "what we call 'soul' or 'spirit,' is nothing more than the sum of the functionings of the body. When this functioning ceases, the 'soul' or the 'spirit' ceases likewise".

Tesla wrote a number of books and articles for magazines and journals. Among his books are "", compiled and edited by Ben Johnston in 1983 from a series of 1919 magazine articles by Tesla which were republished in 1977; "The Fantastic Inventions of Nikola Tesla" (1993), compiled and edited by David Hatcher Childress; and "The Tesla Papers".

Many of Tesla's writings are freely available online, including the article "The Problem of Increasing Human Energy," published in "The Century Magazine" in 1900, and the article "Experiments With Alternate Currents Of High Potential And High Frequency," published in his book "Inventions, Researches and Writings of Nikola Tesla".

Tesla's legacy has endured in books, films, radio, TV, music, live theater, comics, and video games. The impact of the technologies invented or envisioned by Tesla is a recurring theme in several types of science fiction.










Footnotes
Citations
Books

Publications

Journals
Video



</doc>
<doc id="21474" url="https://en.wikipedia.org/wiki?curid=21474" title="Natural number">
Natural number

In mathematics, the natural numbers are those used for counting (as in "there are "six" coins on the table") and ordering (as in "this is the "third" largest city in the country"). In common mathematical terminology, words colloquially used for counting are "cardinal numbers", and words used for ordering are "ordinal numbers". The natural numbers can, at times, appear as a convenient set of codes (labels or "names"); that is, as what linguists call nominal numbers, forgoing many or all of the properties of being a number in a mathematical sense. The set of natural numbers is often denoted by the symbol formula_1.

Some definitions, including the standard ISO 80000-2, begin the natural numbers with , corresponding to the non-negative integers (collectively denoted by the symbol formula_2), whereas others start with 1, corresponding to the positive integers (collectively denoted by the symbol formula_3).

Texts that exclude zero from the natural numbers sometimes refer to the natural numbers together with zero as the whole numbers, while in other writings, that term is used instead for the integers (including negative integers).

The natural numbers are a basis from which many other number sets may be built by extension: the integers (Grothendieck group), by including (if not yet in) the neutral element 0 and an additive inverse (−) for each nonzero natural number ; the rational numbers, by including a multiplicative inverse () for each nonzero integer (and also the product of these inverses by integers); the real numbers by including with the rationals the limits of (converging) Cauchy sequences of rationals; the complex numbers, by including with the real numbers the unresolved square root of minus one (and also the sums and products thereof); and so on. These chains of extensions make the natural numbers canonically embedded (identified) in the other number systems.

Properties of the natural numbers, such as divisibility and the distribution of prime numbers, are studied in number theory. Problems concerning counting and ordering, such as partitioning and enumerations, are studied in combinatorics.

In common language, particularly in primary school education, natural numbers may be called counting numbers to intuitively exclude the negative integers and zero, and also to contrast the discreteness of counting to the continuity of measurement — a hallmark characteristic of real numbers.

The most primitive method of representing a natural number is to put down a mark for each object. Later, a set of objects could be tested for equality, excess or shortage—by striking out a mark and removing an object from the set.

The first major advance in abstraction was the use of numerals to represent numbers. This allowed systems to be developed for recording large numbers. The ancient Egyptians developed a powerful system of numerals with distinct hieroglyphs for 1, 10, and all powers of 10 up to over 1 million. A stone carving from Karnak, dating back from around 1500 BCE and now at the Louvre in Paris, depicts 276 as 2 hundreds, 7 tens, and 6 ones; and similarly for the number 4,622. The Babylonians had a place-value system based essentially on the numerals for 1 and 10, using base sixty, so that the symbol for sixty was the same as the symbol for one—its value being determined from context.

A much later advance was the development of the idea that  can be considered as a number, with its own numeral. The use of a 0 digit in place-value notation (within other numbers) dates back as early as 700 BCE by the Babylonians, who omitted such a digit when it would have been the last symbol in the number. The Olmec and Maya civilizations used 0 as a separate number as early as the , but this usage did not spread beyond Mesoamerica. The use of a numeral 0 in modern times originated with the Indian mathematician Brahmagupta in 628 CE. However, 0 had been used as a number in the medieval computus (the calculation of the date of Easter), beginning with Dionysius Exiguus in 525 CE, without being denoted by a numeral (standard Roman numerals do not have a symbol for 0). Instead, "nulla" (or the genitive form "nullae") from "nullus", the Latin word for "none", was employed to denote a 0 value.

The first systematic study of numbers as abstractions is usually credited to the Greek philosophers Pythagoras and Archimedes. Some Greek mathematicians treated the number 1 differently than larger numbers, sometimes even not as a number at all. Euclid, for example, defined a unit first and then a number as a multitude of units, thus by his definition, a unit is not a number and there are no unique numbers (e.g., any two units from indefinitely many units is a 2).

Independent studies on numbers also occurred at around the same time in India, China, and Mesoamerica.

In 19th century Europe, there was mathematical and philosophical discussion about the exact nature of the natural numbers. A school of Naturalism stated that the natural numbers were a direct consequence of the human psyche. Henri Poincaré was one of its advocates, as was Leopold Kronecker, who summarized his belief as "God made the integers, all else is the work of man".

In opposition to the Naturalists, the constructivists saw a need to improve upon the logical rigor in the foundations of mathematics. In the 1860s, Hermann Grassmann suggested a recursive definition for natural numbers, thus stating they were not really natural—but a consequence of definitions. Later, two classes of such formal definitions were constructed; later still, they were shown to be equivalent in most practical applications.

Set-theoretical definitions of natural numbers were initiated by Frege. He initially defined a natural number as the class of all sets that are in one-to-one correspondence with a particular set. However, this definition turned out to lead to paradoxes, including Russell's paradox. To avoid such paradoxes, the formalism was modified so that a natural number is defined as a particular set, and any set that can be put into one-to-one correspondence with that set is said to have that number of elements.

The second class of definitions was introduced by Charles Sanders Peirce, refined by Richard Dedekind, and further explored by Giuseppe Peano; this approach is now called Peano arithmetic. It is based on an axiomatization of the properties of ordinal numbers: each natural number has a successor and every non-zero natural number has a unique predecessor. Peano arithmetic is equiconsistent with several weak systems of set theory. One such system is ZFC (with the axiom of infinity replaced by its negation). Theorems that can be proved in ZFC but cannot be proved using the Peano Axioms include Goodstein's theorem.

With all these definitions, it is convenient to include 0 (corresponding to the empty set) as a natural number. Including 0 is now the common convention among set theorists and logicians. Other mathematicians also include 0, and computer languages often start from zero when enumerating items like loop counters and string- or array-elements. On the other hand, many mathematicians have kept the older tradition to take 1 to be the first natural number.

Since different properties are customarily associated to the tokens and (e.g., neutral elements for addition and multiplications, respectively), it is important to know which version of "natural numbers", generically denoted by formula_4 is employed in the case under consideration. This can be done by explanation in prose, by explicitly writing down the set, or by qualifying the generic identifier with a super- or subscript (see also in #Notation), for example, like this:

Mathematicians use N or (an N in blackboard bold) to refer to the set of all natural numbers. Older texts have also occasionally employed "J" as the symbol for this set.

To be unambiguous about whether 0 is included or not, sometimes a subscript (or superscript) "0" is added in the former case, and a superscript "" (or subscript "1") is added in the latter case:

Alternatively, since natural numbers naturally embed in the integers, they may be referred to as the positive, or the non-negative integers, respectively.

The set of natural numbers is an infinite set. By definition, this kind of infinity is called countable infinity. All sets that can be put into a bijective relation to the natural numbers are said to have this kind of infinity. This is also expressed by saying that the cardinal number of the set is aleph-naught ().

One can recursively define an addition operator on the natural numbers by setting and for all , . Here, should be read as "successor". This turns the natural numbers into a commutative monoid with identity element 0, the so-called free object with one generator. This monoid satisfies the cancellation property, and can be embedded in a group (in the group theory sense of the word). The smallest group containing the natural numbers is the integers.

If 1 is defined as , then . That is, is simply the successor of .

Analogously, given that addition has been defined, a multiplication operator formula_9 can be defined via and . This turns into a free commutative monoid with identity element 1; a generator set for this monoid is the set of prime numbers.

Addition and multiplication are compatible, which is expressed in the distribution law: . These properties of addition and multiplication make the natural numbers an instance of a commutative semiring. Semirings are an algebraic generalization of the natural numbers where multiplication is not necessarily commutative. The lack of additive inverses, which is equivalent to the fact that is not closed under subtraction (that is, subtracting one natural from another does not always result in another natural), means that is "not" a ring; instead it is a semiring (also known as a "rig").

If the natural numbers are taken as "excluding 0", and "starting at 1", the definitions of + and × are as above, except that they begin with and .

In this section, juxtaposed variables such as indicate the product , and the standard order of operations is assumed.

A total order on the natural numbers is defined by letting if and only if there exists another natural number where . This order is compatible with the arithmetical operations in the following sense: if , and are natural numbers and , then and .

An important property of the natural numbers is that they are well-ordered: every non-empty set of natural numbers has a least element. The rank among well-ordered sets is expressed by an ordinal number; for the natural numbers, this is denoted as (omega).

In this section, juxtaposed variables such as indicate the product , and the standard order of operations is assumed.

While it is in general not possible to divide one natural number by another and get a natural number as result, the procedure of "division with remainder" is available as a substitute: for any two natural numbers and with there are natural numbers and such that

The number is called the "quotient" and is called the "remainder" of the division of by . The numbers and are uniquely determined by and . This Euclidean division is key to several other properties (divisibility), algorithms (such as the Euclidean algorithm), and ideas in number theory.

The addition (+) and multiplication (×) operations on natural numbers as defined above have several algebraic properties:

Two important generalizations of natural numbers arise from the two uses of counting and ordering: cardinal numbers and ordinal numbers.

The least ordinal of cardinality (that is, the initial ordinal of ) is but many well-ordered sets with cardinal number have an ordinal number greater than . 

For finite well-ordered sets, there is a one-to-one correspondence between ordinal and cardinal numbers; therefore they can both be expressed by the same natural number, the number of elements of the set. This number can also be used to describe the position of an element in a larger finite, or an infinite, sequence.

A countable non-standard model of arithmetic satisfying the Peano Arithmetic (that is, the first-order Peano axioms) was developed by Skolem in 1933. The hypernatural numbers are an uncountable model that can be constructed from the ordinary natural numbers via the ultrapower construction.

Georges Reeb used to claim provocatively that "The naïve integers don't fill up" . Other generalizations are discussed in the article on numbers.

Many properties of the natural numbers can be derived from the five Peano axioms: 


These are not the original axioms published by Peano, but are named in his honor. Some forms of the Peano axioms have 1 in place of 0. In ordinary arithmetic, the successor of formula_12 is formula_15. Replacing axiom 5 by an axiom schema, one obtains a (weaker) first-order theory called "Peano arithmetic".

In the area of mathematics called set theory, a specific construction due to John von Neumann defines the natural numbers as follows:

With this definition, a natural number is a particular set with elements, and if and only if is a subset of . The standard definition, now called definition of von Neumann ordinals, is: "each ordinal is the well-ordered set of all smaller ordinals."

Also, with this definition, different possible interpretations of notations like (-tuples versus mappings of into ) coincide.

Even if one does not accept the axiom of infinity and therefore cannot accept that the set of all natural numbers exists, it is still possible to define any one of these sets.

Although the standard construction is useful, it is not the only possible construction. Ernst Zermelo's construction goes as follows:




</doc>
<doc id="21476" url="https://en.wikipedia.org/wiki?curid=21476" title="Natural logarithm">
Natural logarithm

The natural logarithm of a number is its logarithm to the base of the mathematical constant , where is an irrational and transcendental number approximately equal to . The natural logarithm of is generally written as , , or sometimes, if the base is implicit, simply . Parentheses are sometimes added for clarity, giving , , or . This is done particularly when the argument to the logarithm is not a single symbol, so as to prevent ambiguity.

The natural logarithm of is the power to which would have to be raised to equal . For example, is , because . The natural logarithm of itself, , is , because , while the natural logarithm of is , since .

The natural logarithm can be defined for any positive real number as the area under the curve from to (with the area being negative when ). The simplicity of this definition, which is matched in many other formulas involving the natural logarithm, leads to the term "natural". The definition of the natural logarithm can then be extended to give logarithm values for negative numbers and for all non-zero complex numbers, although this leads to a multi-valued function: see Complex logarithm for more.

The natural logarithm function, if considered as a real-valued function of a real variable, is the inverse function of the exponential function, leading to the identities:

Like all logarithms, the natural logarithm maps multiplication into addition:

Logarithms can be defined for any positive base other than 1, not only . However, logarithms in other bases differ only by a constant multiplier from the natural logarithm, and can be defined in terms of the latter. For instance, the base-2 logarithm (also called the binary logarithm) is equal to the natural logarithm divided by , the natural logarithm of 2.

Logarithms are useful for solving equations in which the unknown appears as the exponent of some other quantity. For example, logarithms are used to solve for the half-life, decay constant, or unknown time in exponential decay problems. They are important in many branches of mathematics and scientific disciplines, and are used in finance to solve problems involving compound interest.

The concept of the natural logarithm was worked out by Gregoire de Saint-Vincent and Alphonse Antonio de Sarasa before 1649. Their work involved quadrature of the hyperbola with equation , by determination of the area of hyperbolic sectors. Their solution generated the requisite "hyperbolic logarithm" function, which had the properties now associated with the natural logarithm.

An early mention of the natural logarithm was by Nicholas Mercator in his work "Logarithmotechnia", published in 1668, although the mathematics teacher John Speidell had already compiled a table of what in fact were effectively natural logarithms in 1619. It has been said that Speidell's logarithms were to the base , but this is not entirely true due to complications with the values being expressed as integers.

The notations and both refer unambiguously to the natural logarithm of , and without an explicit base may also refer to the natural logarithm. This usage is common in mathematics, along with some scientific contexts as well as in many programming languages. In some other contexts such as chemistry, however, can be used to denote the common (base 10) logarithm. It may also refer to the binary (base 2) logarithm in the context of computer science, particularly in the context of time complexity.

The natural logarithm can be defined in several equivalent ways. The natural logarithm of a positive, real number may be defined as the area under the graph of the hyperbola with equation between and . This is the integral
If is less than , then this area is considered to be negative.

This function is a logarithm because it satisfies the fundamental multiplicative property of a logarithm:

This can be demonstrated by splitting the integral that defines into two parts, and then making the variable substitution (so ) in the second part, as follows:

In elementary terms, this is simply scaling by in the horizontal direction and by in the vertical direction. Area does not change under this transformation, but the region between and is reconfigured. Because the function is equal to the function , the resulting area is precisely .

The number can then be defined to be the unique real number such that . Alternatively, if the exponential function, denoted or , has been defined first, say by using an infinite series, then the natural logarithm may be defined as its inverse function. In other words, is that function such that . Since the range of the exponential function is all positive real numbers, and since the exponential function is strictly increasing, this is well-defined for all positive .

The statement is true for formula_15, and we now show that formula_16 for all formula_17, which completes the proof by the fundamental theorem of calculus. Hence, we want to show that

(Note that we have not yet proved that this statement is true.) If this is true, then by multiplying the middle statement by the positive quantity formula_19 and subtracting formula_20 we would obtain

This statement is trivially true for formula_23 since the left hand side is negative or zero. For formula_24 it is still true since both factors on the left are less than 1 (recall that formula_25). Thus this last statement is true and by repeating our steps in reverse order we find that formula_16 for all formula_17. This completes the proof.

An alternate proof is to observe that formula_28 under the given conditions. This can be proved, e.g., by the norm inequalities. Taking logarithms and using formula_29 completes the proof.

The derivative of the natural logarithm as a real-valued function on the positive reals is given by

How to establish this derivative of the natural logarithm depends on how it is defined firsthand. If the natural logarithm is defined as the integral
then the derivative immediately follows from the first part of the fundamental theorem of calculus.

On the other hand, if the natural logarithm is defined as the inverse of the (natural) exponential function, then the derivative (for "x" > 0) can be found by using the properties of the logarithm and a definition of the exponential function. From the definition of the number formula_32 the exponential function can be defined as formula_33, where formula_34 The derivative can then be found from first principles.

If formula_36 then

This is the Taylor series for ln "x" around 1. A change of variables yields the Mercator series:

valid for |"x"| ≤ 1 and "x" ≠ −1.

Leonhard Euler, disregarding formula_39, nevertheless applied this series to "x" = −1, in order to show that the harmonic series equals the (natural) logarithm of 1/(1 − 1), that is, the logarithm of infinity. Nowadays, more formally, one can prove that the harmonic series truncated at "N" is close to the logarithm of "N", when "N" is large, with the difference converging to the Euler–Mascheroni constant.

At right is a picture of ln(1 + "x") and some of its Taylor polynomials around 0. These approximations converge to the function only in the region −1 < "x" ≤ 1; outside of this region the higher-degree Taylor polynomials evolve to "worse" approximations for the function.

A useful special case for positive integers "n", taking formula_40, is:

If formula_42 then

Now, taking formula_44 for positive integers "n", we get:

If formula_46 then
Since
we arrive at
Using the substitution formula_44 again for positive integers "n", we get: 

This is, by far, the fastest converging of the series described here.

The natural logarithm allows simple integration of functions of the form "g"("x") = "f" '("x")/"f"("x"): an antiderivative of "g"("x") is given by ln(|"f"("x")|). This is the case because of the chain rule and the following fact:

In other words,

and

Here is an example in the case of "g"("x") = tan("x"):

Letting "f"("x") = cos("x"):

where "C" is an arbitrary constant of integration.

The natural logarithm can be integrated using integration by parts:

Let:

then:

For ln("x") where "x" > 1, the closer the value of "x" is to 1, the faster the rate of convergence. The identities associated with the logarithm can be leveraged to exploit this:

Such techniques were used before calculators, by referring to numerical tables and performing manipulations such as those above.

The natural logarithm of 10, which has the decimal expansion 2.30258509..., plays a role for example in the computation of natural logarithms of numbers represented in scientific notation, as a mantissa multiplied by a power of 10:

This means that one can effectively calculate the logarithms of numbers with very large or very small magnitude using the logarithms of a relatively small set of decimals in the range formula_64.

To compute the natural logarithm with many digits of precision, the Taylor series approach is not efficient since the convergence is slow. Especially if is near 1, a good alternative is to use Halley's method or Newton's method to invert the exponential function, because the series of the exponential function converges more quickly. For finding the value of to give using Halley's method, or equivalently to give using Newton's method, the iteration simplifies to
which has cubic convergence to .

Another alternative for extremely high precision calculation is the formula

where denotes the arithmetic-geometric mean of 1 and , and

with chosen so that bits of precision is attained. (For most purposes, the value of 8 for m is sufficient.) In fact, if this method is used, Newton inversion of the natural logarithm may conversely be used to calculate the exponential function efficiently. (The constants ln 2 and π can be pre-computed to the desired precision using any of several known quickly converging series.)

Based on a proposal by William Kahan and first implemented in the Hewlett-Packard HP-41C calculator in 1979 (referred to under "LN1" in the display, only), some calculators, operating systems (for example Berkeley UNIX 4.3BSD), computer algebra systems and programming languages (for example C99) provide a special natural logarithm plus 1 function, alternatively named LNP1, or log1p to give more accurate results for logarithms close to zero by passing arguments "x", also close to zero, to a function log1p("x"), which returns the value ln(1+"x"), instead of passing a value "y" close to 1 to a function returning ln("y"). The function log1p avoids in the floating point arithmetic a near cancelling of the absolute term 1 with the second term from the Taylor expansion of the ln, thereby allowing for a high accuracy for both the argument and the result near zero.

In addition to base the IEEE 754-2008 standard defines similar logarithmic functions near 1 for binary and decimal logarithms: formula_68 and formula_69.

Similar inverse functions named "expm1", "expm" or "exp1m" exist as well, all with the meaning of 

An identity in terms of the inverse hyperbolic tangent,
gives a high precision value for small values of on systems that do not implement .

The computational complexity of computing the natural logarithm (using the arithmetic-geometric mean) is O("M"("n") ln "n"). Here "n" is the number of digits of precision at which the natural logarithm is to be evaluated and "M"("n") is the computational complexity of multiplying two "n"-digit numbers.

While no simple continued fractions are available, several generalized continued fractions are, including:

These continued fractions—particularly the last—converge rapidly for values close to 1. However, the natural logarithms of much larger numbers can easily be computed, by repeatedly adding those of smaller numbers, with similarly rapid convergence.

For example, since 2 = 1.25 × 1.024, the natural logarithm of 2 can be computed as:

Furthermore, since 10 = 1.25 × 1.024, even the natural logarithm of 10 can be computed similarly as:

The exponential function can be extended to a function which gives a complex number as for any arbitrary complex number "x"; simply use the infinite series with "x" complex. This exponential function can be inverted to form a complex logarithm that exhibits most of the properties of the ordinary logarithm. There are two difficulties involved: no "x" has ; and it turns out that . Since the multiplicative property still works for the complex exponential function, , for all complex "z" and integers "k".

So the logarithm cannot be defined for the whole complex plane, and even then it is multi-valued—any complex logarithm can be changed into an "equivalent" logarithm by adding any integer multiple of 2"i" at will. The complex logarithm can only be single-valued on the cut plane. For example, = or or -, etc.; and although can be defined as 2"i", or 10"i" or −6"i", and so on.



</doc>
<doc id="21477" url="https://en.wikipedia.org/wiki?curid=21477" title="Neogene">
Neogene

The Neogene ( ) (informally Upper Tertiary or Late Tertiary) is a geologic period and system that spans 20.45 million years from the end of the Paleogene Period million years ago (Mya) to the beginning of the present Quaternary Period Mya. The Neogene is sub-divided into two epochs, the earlier Miocene and the later Pliocene. Some geologists assert that the Neogene cannot be clearly delineated from the modern geological period, the Quaternary. The term "Neogene" was coined in 1853 by the Austrian palaeontologist Moritz Hörnes (1815–1868).

During this period, mammals and birds continued to evolve into modern forms, while other groups of life remained relatively unchanged. Early hominids, the ancestors of humans, appeared in Africa near the end of the period. Some continental movement took place, the most significant event being the connection of North and South America at the Isthmus of Panama, late in the Pliocene. This cut off the warm ocean currents from the Pacific to the Atlantic Ocean, leaving only the Gulf Stream to transfer heat to the Arctic Ocean. The global climate cooled considerably over the course of the Neogene, culminating in a series of continental glaciations in the Quaternary Period that follows.

In ICS terminology, from upper (later, more recent) to lower (earlier):

The Pliocene Epoch is subdivided into 2 ages:


The Miocene Epoch is subdivided into 6 ages:
In different geophysical regions of the world, other regional names are also used for the same or overlapping ages and other timeline subdivisions.

The terms "Neogene System" (formal) and "Upper Tertiary System" (informal) describe the rocks deposited during the "Neogene Period".

The continents in the Neogene were very close to their current positions. The Isthmus of Panama formed, connecting North and South America. The Indian subcontinent continued to collide with Asia, forming the Himalayas. Sea levels fell, creating land bridges between Africa and Eurasia and between Eurasia and North America.

The global climate became seasonal and continued an overall drying and cooling trend which began at the start of the Paleogene. The ice caps on both poles began to grow and thicken, and by the end of the period the first of a series of glaciations of the current Ice Age began.

Marine and continental flora and fauna have a modern appearance. The reptile group Choristodera became extinct in the early part of the period, while the amphibians known as Allocaudata disappeared at the end. Mammals and birds continued to be the dominant terrestrial vertebrates, and took many forms as they adapted to various habitats. The first hominins, the ancestors of humans, may have appeared in southern Europe and migrated into Africa.

In response to the cooler, seasonal climate, tropical plant species gave way to deciduous ones and grasslands replaced many forests. Grasses therefore greatly diversified, and herbivorous mammals evolved alongside it, creating the many grazing animals of today such as horses, antelope, and bison. Eucalyptus fossil leaves occur in the Miocene of New Zealand, where the genus is not native today, but have been introduced from Australia.

The Neogene traditionally ended at the end of the Pliocene Epoch, just before the older definition of the beginning of the Quaternary Period; many time scales show this division.

However, there was a movement amongst geologists (particularly marine geologists) to also include ongoing geological time (Quaternary) in the Neogene, while others (particularly terrestrial geologists) insist the Quaternary to be a separate period of distinctly different record. The somewhat confusing terminology and disagreement amongst geologists on where to draw what hierarchical boundaries is due to the comparatively fine divisibility of time units as time approaches the present, and due to geological preservation that causes the youngest sedimentary geological record to be preserved over a much larger area and to reflect many more environments than the older geological record. By dividing the Cenozoic Era into three (arguably two) periods (Paleogene, Neogene, Quaternary) instead of seven epochs, the periods are more closely comparable to the duration of periods in the Mesozoic and Paleozoic eras.

The International Commission on Stratigraphy (ICS) once proposed that the Quaternary be considered a sub-era (sub-erathem) of the Neogene, with a beginning date of 2.58 Ma, namely the start of the Gelasian Stage. In the 2004 proposal of the ICS, the Neogene would have consisted of the Miocene and Pliocene epochs. The International Union for Quaternary Research (INQUA) counterproposed that the Neogene and the Pliocene end at 2.58 Ma, that the Gelasian be transferred to the Pleistocene, and the Quaternary be recognized as the third period in the Cenozoic, citing key changes in Earth's climate, oceans, and biota that occurred 2.58 Ma and its correspondence to the Gauss-Matuyama magnetostratigraphic boundary. In 2006 ICS and INQUA reached a compromise that made Quaternary a subera, subdividing Cenozoic into the old classical Tertiary and Quaternary, a compromise that was rejected by International Union of Geological Sciences because it split both Neogene and Pliocene in two.

Following formal discussions at the 2008 International Geological Congress in Oslo, Norway, the ICS decided in May 2009 to make the Quaternary the youngest period of the Cenozoic Era with its base at 2.58 Mya and including the Gelasian age, which was formerly considered part of the Neogene Period and Pliocene Epoch. Thus the Neogene Period ends bounding the succeeding Quaternary Period at 2.58 Mya.



</doc>
<doc id="21481" url="https://en.wikipedia.org/wiki?curid=21481" title="Notary public">
Notary public

A notary public (or notary or public notary) of the common law is a public officer constituted by law to serve the public in non-contentious matters usually concerned with estates, deeds, powers-of-attorney, and foreign and international business. A notary's main functions are to administer oaths and affirmations, take affidavits and statutory declarations, witness and authenticate the execution of certain classes of documents, take acknowledgments of deeds and other conveyances, protest notes and bills of exchange, provide notice of foreign drafts, prepare marine or ship's protests in cases of damage, provide exemplifications and notarial copies, and perform certain other official acts depending on the jurisdiction. Any such act is known as a notarization. The term "notary public" only refers to common-law notaries and should not be confused with civil-law notaries.

With the exceptions of Louisiana, Puerto Rico, Quebec (whose private law is based on civil law), and British Columbia (whose notarial tradition stems from scrivener notary practice), a notary public in the rest of the United States and most of Canada has powers that are far more limited than those of civil-law or other common-law notaries, both of whom are qualified lawyers admitted to the bar: such notaries may be referred to as notaries-at-law or lawyer notaries. Therefore, at common law, notarial service is distinctly different from the practice of law, and giving legal advice and preparing legal instruments is forbidden to lay notaries such as those appointed throughout most of the United States of America.

Notaries are appointed by a government authority, such as a court or lieutenant governor, or by a regulating body often known as a society or faculty of notaries public. For lawyer notaries, an appointment may be for life, while lay notaries are usually commissioned for a briefer term, with the possibility of renewal.

In most common law countries, appointments and their number for a given notarial district are highly regulated. However, since the majority of American notaries are lay persons who provide officially required services, commission numbers are not regulated, which is part of the reason why there are far more notaries in the United States than in other countries (4.5 million vs. approx. 740 in England and Wales and approx. 1,250 in Australia and New Zealand). Furthermore, all U.S. and some Canadian notarial functions are applied to domestic affairs and documents, where fully systematized attestations of signatures and acknowledgment of deeds are a universal requirement for document authentication. By contrast, outside North American common law jurisdictions, notarial practice is restricted to international legal matters or where a foreign jurisdiction is involved, and almost all notaries are also qualified lawyers.

For the purposes of authentication, most countries require commercial or personal documents which originate from or are signed in another country to be notarized before they can be used or officially recorded or before they can have any legal effect. To these documents a notary affixes a notarial certificate which attests to the execution of the document, usually by the person who appears before the notary, known as an appearer or constituent (U.S.). In places where lawyer notaries are the norm, a notary may also draft legal instruments known as notarial acts or deeds which have probative value and executory force, as they do in civil law jurisdictions. Originals or secondary originals are then filed and stored in the notary's archives, or protocol.

Notaries are generally required to undergo special training in the performance of their duties. Some must also first serve as an apprentice before being commissioned or licensed to practice their profession. In many countries, even licensed lawyers, e.g., barristers or solicitors, must follow a prescribed specialized course of study and be mentored for two years before being allowed to practice as a notary (e.g., British Columbia, England). However, notaries public in the U.S., of which the vast majority are lay people, require only a brief training seminar and are expressly forbidden to engage in any activities that could be construed as the unlicensed practice of law unless they are also qualified attorneys. Notarial practice is universally considered to be distinct and separate from that of an attorney (solicitor/barrister). In England and Wales, there is a course of study for notaries which is conducted under the auspices of the University of Cambridge and the Society of Notaries of England and Wales. In the State of Victoria, Australia, applicants for appointment must first complete a Graduate Diploma of Notarial Practice which is administered by the Sir Zelman Cowen Centre in Victoria University, Melbourne.

In bi-juridical jurisdictions, such as South Africa or Louisiana, the office of notary public is a legal profession with educational requirements similar to those for attorneys. Many even have institutes of higher learning that offer degrees in notarial law. Therefore, despite their name, "notaries public" in these jurisdictions are in effect civil law notaries.

Notaries public (also called "notaries", "notarial officers", or "public notaries") hold an office that can trace its origins back to the ancient Roman Republic, when they were called "scribae" ("scribes"), "tabelliones forenses", or "personae publicae".

The history of notaries is set out in detail in Chapter 1 of "Brooke's Notary" (13th edition):

A collection of articles on notary history, including Ancient Egypt, Phoenicia, Babylonia, Rome, Greece, medieval Europe, the Renaissance, Columbus, Spanish Conquistadors, French Louisiana, New England colonial notaries, Republic of Texas notaries and Colorado Old West notaries, is available in the notary history section of the Colorado Notary Blog at the following link.

The duties and functions of notaries public are described in "Brooke's Notary" on page 19 in these terms:

A notary, in almost all common law jurisdictions other than most of North America, is a practitioner trained in the drafting and execution of legal documents. Notaries traditionally recorded matters of judicial importance as well as private transactions or events where an officially authenticated record or a document drawn up with professional skill or knowledge was required. The functions of notaries specifically include the preparation of certain types of documents (including international contracts, deeds, wills, and powers of attorney) and certification of their due execution, administering of oaths, witnessing affidavits and statutory declarations, certification of copy documents, noting and protesting of bills of exchange, and the preparation of ships' protests.

Documents certified by notaries are sealed with the notary's seal or stamp and are recorded by the notary in a register (also called a "protocol") maintained and permanently kept by him or her. These are known as "notarial acts". 
In countries subscribing to the Hague Convention Abolishing the Requirement of Legalization for Foreign Public Documents or Apostille Convention, only one further act of certification is required, known as an apostille, and is issued by a government department (usually the Foreign Affairs Department or similar). For countries which are not subscribers to that convention, an "authentication" or "legalization" must be provided by one of a number of methods, including by the Foreign Affairs Ministry of the country from which the document is being sent or the embassy, Consulate-General, consulate or High Commission of the country to which it is being sent.

In all Australian states and territories (except Queensland) notaries public are appointed by the Supreme Court of the relevant state or territory. Very few have been appointed as a notary for more than one state or territory.

Queensland, like New Zealand, continues the practice of appointment by the Archbishop of Canterbury acting through the Master of the Faculties.

Australian notaries are lawyers and are members of the Australian and New Zealand College of Notaries, the Society of Notaries of New South Wales Inc., the Public Notaries Society of Western Australia Inc, and other state-based societies. The overall number of lawyers who choose to become a notary is relatively low. For example, in South Australia (a state with a population of 1.5 million), of the over 2,500 lawyers in that state only about 100 are also notaries and most of those do not actively practice as such. In Melbourne, Victoria, in 2002 there were only 66 notaries for a city with a population of 3.5 million and only 90 for the entire state. In Western Australia, there are approximately 58 notaries as at 2017 for a city with a population of 2.07 million people. Compare this with the United States where it has been estimated that there are nearly 5 million notaries for a nation with a population of 296 million.

As Justice Debelle of the Supreme Court of South Australia said in the case of "In The Matter of an Application by Marilyn Reys Bos to be a Public Notary" [2003] SASC 320, delivered 12 September 2003, in refusing the application by a non-lawyer for appointment as a notary:

Historically there have been some very rare examples of patent attorneys or accountants being appointed, but that now seems to have ceased.

However, there are three significant differences between notaries and other lawyers.


Their principal duties include:


It is usual for Australian notaries to use an embossed seal with a red wafer, and now some notaries also use an inked stamp replicating the seal. It is also common for the seal or stamp to include the notary's chosen logo or symbol.

In South Australia and Scotland, it is acceptable for a notary to use the letters "NP" after their name. Thus a South Australian notary may have "John Smith LLB NP" or similar on his business card or letterhead.

Australian notaries do not hold "commissions" which can expire. Generally, once appointed they are authorized to act as a notary for life and can only be "struck off" the Roll of Notaries for proven misconduct. In certain states, for example, New South Wales and Victoria, they cease to be qualified to continue as a notary once they cease to hold a practicing certificate as a legal practitioner. Even judges, who do not hold practicing certificates, are not eligible to continue to practice as notaries.

Notaries in some states of Australia are regulated by legislation. In New South Wales the Public Notaries Act 1997 applies and in Victoria the Public Notaries Act 2001 applies.

There are also Notary Societies throughout Australia and the societies keep a searchable list of their members. In New South Wales, The Society of Notaries of New South Wales Inc.; in Queensland The Society of Notaries Queensland Inc.; in South Australia the Notaries' Society of South Australia Inc. and in Victoria, The Society of Notaries of Victoria Inc..

Notaries collecting information for the purposes of verification of the signature of the deponent might retain the details of documents which identify the deponent, and this information is subject to the Privacy Act 1988. A notary must protect the personal information the notary holds from misuse and loss and from unauthorised access, modification or disclosure.

All Australian jurisdictions also have justices of the peace (JP) or commissioners for affidavits and other unqualified persons who are qualified to take affidavits or statutory declarations and to certify documents. However they can only do so if the relevant affidavit, statutory declaration or copy document is to be used only in Australia and not in a foreign country, with the possible exception of a few Commonwealth countries not including the United Kingdom or New Zealand except for very limited purposes. Justices of the peace (JPs) are (usually) laypersons who have minimal, if any, training (depending on the jurisdiction) but are of proven good character. Therefore, a US notary resembles an Australian JP rather than an Australian notary.

Canadian notaries public (except in the Province of British Columbia and Quebec) are very much like their American counterparts, generally restricted to administering oaths, witnessing signatures on affidavits and statutory declarations, providing acknowledgements, certifying true copies, and so forth.

In British Columbia, a notary public is more like a British or Australian notary. Notaries are appointed for life by the Supreme Court of British Columbia and as a self-regulating profession, the Society of Notaries Public of British Columbia is the regulatory body overseeing and setting standards to maintain public confidence. A BC Notary is also a Commissioner for Taking Affidavits for British Columbia, by reason of office. Furthermore, BC notaries exercise far greater power, able to dispense legal advice and draft public instruments including:


In Nova Scotia a person may be a notary public, a commissioner of oaths, or both. A notary public and a commissioner of oaths are regulated by the provincial Notaries and Commissioners Act. Individuals hold a commission granted to them by the Minister of Justice.

Under the Act a notary public in has the "power of drawing, passing, keeping and issuing all deeds and contracts, charter-parties and other mercantile transactions in this Province, and also of attesting all commercial instruments brought before him for public protestation, and otherwise of acting as is usual in the office of notary, and may demand, receive and have all the rights, profits and emoluments rightfully appertaining and belonging to the said calling of notary during pleasure."

Under the Act a commissioner of oaths is "authorized to administer oaths and take and receive affidavits, declarations and affirmations within the Province in and concerning any cause, matter or thing, depending or to be had in the Supreme Court, or any other court in the Province."

Every barrister of the Supreme Court of Nova Scotia is a commissioner of oaths but must receive an additional commission to act as a notary public.

"A Commissioner of Oaths is deemed to be an officer of the Supreme Court of Nova Scotia. Commissioners take declarations concerning any matter to come before a court in the Province.". Additionally, individuals with other specific qualifications, such as being a current Member of the Legislative Assembly, commissioned officer of the Royal Canadian Mounted Police or Canadian Forces make act as if explicitly being a Commissioner of Oaths.

In Quebec, civil-law notaries ("notaires") are full lawyers licensed to practice notarial law and regulated by the Chamber of Notaries of Quebec. Quebec notaries draft and prepare major legal instruments (notarial acts), provide complex legal advice, represent clients (out of court) and make appearances on their behalf, act as arbitrator, mediator, or conciliator, and even act as a court commissioner in non-contentious matters. To become a notary in Quebec, a candidate must hold a bachelor's degree in civil law and a one-year Master's in notarial law and serve a traineeship ("stage") before being admitted to practice.

The concept of notaries public in Quebec does not exist. Instead, the province has Commissioners of Oaths ("Commissaires à l'assermentation") which serve to authenticate legal documents at a fixed maximal rate of $5.00CAD.

The Commissioner of Oaths is empowered to administer and witness the swearing of oaths or solemn affirmations in the taking of an affidavit for any potential legal matter under the provincial or state legislation.

Witnessing the signature process and certification service are common tasks for the Commissioner of Oaths. Documents and attachments may need authentication, attestation, certification or notarization.

The central government appoints notaries for the whole or any part of the country. State governments, too, appoint notaries for the whole or any part of the states. On an application being made, any person who had been practicing as a Lawyer for at least ten years is eligible to be appointed a notary. The applicant, if not a legal practitioner, should be a member of the Indian Legal Service or have held an office under the central or state government, requiring special knowledge of law, after enrollment as an advocate or held an office in the department of Judge, Advocate-General or in the armed forces.

Notary public is a trained lawyer that should pass some special examinations to be able to open their office and start their work. Persian meaning of this word is means head of the office and their assistant called . Both these persons should have bachelor's degree in law or master's degree in civil-law.

There is archival evidence showing that public notaries, acting pursuant to papal and imperial authority, practised in Ireland in the 13th century, and it is reasonable to assume that notaries functioned here before that time. In Ireland, public notaries were at various times appointed by the Archbishop of Canterbury and the Archbishop of Armagh. The position remained so until the Reformation.

After the Reformation, persons appointed to the office of public notary either in Great Britain or Ireland received the faculty by royal authority, and appointments under faculty from the Pope and the emperor ceased.

In 1871, under the Matrimonial Causes and Marriage Law (Ireland) Amendment 1870, the jurisdiction previously exercised by the Archbishop of Armagh in the appointment of notaries was vested in and became exercisable by the Lord Chancellor of Ireland.

In 1920, the power to appoint notaries public was transferred to the Lord Lieutenant of Ireland. The position in Ireland changed once again in 1924 following the establishment of the Irish Free State. Under the Courts of Justice Act, 1924 the jurisdiction over notaries public was transferred to the Chief Justice of the Irish Free State.

In 1961, under the Courts (Supplemental Provisions) Act of that year, and the power to appoint notaries public became exercisable by the Chief Justice. This remains the position in Ireland, where notaries are appointed on petition to the Supreme Court, after passing prescribed examinations. The governing body is the Faculty of Notaries Public in Ireland. The vast majority of notaries in Ireland are also solicitors. A non-solicitor, who was successful in the examinations as set by the governing body, applied in the standard way to the Chief Justice to be appointed a notary public. The Chief Justice heard the adjourned application on 3 March 2009 and appointed the non-solicitor as a notary on 18 July 2011.

In Ireland notaries public cannot agree on a standard fee due to competition law. In practice the price per signature appears to be €85. A cheaper alternative is to visit a commissioner for oaths who will charge less per signature, but that is only possible where whoever is to receive a document will recognize the signature of a commissioner for oaths.

A notary public is a lawyer authorized by the Attorney General. The fees are regulated by the Notary Public (Fees) Rules 1954.

A commissioner for oaths is a person appointed by the Chief Justice under section 11 of Court of Judicature Act 1964, and Commissioners for Oaths Rules 1993.

A notary public in New Zealand is a lawyer authorised by the Archbishop of Canterbury in England to officially witness signatures on legal documents, collect sworn statements, administer oaths and certify the authenticity of legal documents usually for use overseas.

The Master of the Faculties appoints notaries in the exercise of the general authorities granted by s 3 of the Ecclesiastical Licences Act 1533 and Public Notaries Act 1833. Recommendations are made by the New Zealand Society of Notaries, which normally requires and applicant to have 10 years’ experience post admission as a lawyer and 5 years as a Law Firm Partner or equivalent.

Also because of Te Tiriti o Waitangi 1840 (a protectorate treaty between Her Majesty the Queen of England and the Maori tribes) each tribe is considered an independent sovereign authority and have their own form of governance with a confederation due to their constitution or Declaration of Independence- He Wakaputanga o te Rangatiratanga o Nu Tireni 1835 . Tribal chiefs (Rangatira),or tribal government administrators delegated in the position of notary public, may notarize legal documents, witness signatures, collect sworn statements, administer oaths and certify the authenticity of legal documents for use overseas. They may certify under the jurisdiction of Nu Tireni, Aotearoa, Te Ika a Maui, or Te Waipounamu.[citation required?]

Notaries in Sri Lanka are more akin to civil law notaries, their main functions are conveyancing, drafting of legal instruments, etc. They are appointed under the Notaries Ordinance No 1 of 1907. They must pass exam held by the Ministry of Justice and apprentice under senior notary for a period of two years. Alternatively, attorneys at law who pass the conveyancing exam are also admitted as a notary public under warrant of the Minister. The Minister of Justice may appoint any attorney at law as a Commissioner for Oaths, authorized to certify and authenticate the affidavit/documents and any such other certificates that are submitted by the general public with the intention of certifying by the Commissioner for Oath.

After the passage of the Ecclesiastical Licences Act 1533, which was a direct result of the Reformation in England, all notary appointments were issued directly through the Court of Faculties. The Court of Faculties is attached to the office of the Archbishop of Canterbury.

In England and Wales there are two main classes of notaries – general notaries and scrivener notaries. Their functions are almost identical. All notaries, like solicitors, barristers, legal executives, costs lawyers and licensed conveyancers, are also commissioners for oaths. They also acquire the same powers as solicitors and other law practitioners, with the exception of the right to represent others before the courts (unless also members of the bar or admitted as a solicitor) once they are commissioned notaries. In practice almost all English notaries, and all Scottish ones, are also solicitors, and usually practise as solicitors.

Commissioners of oaths are able to undertake the bulk of routine domestic attestation work within the UK. Many documents, including signatures for normal property transactions, do not need professional attestation of signature at all, a lay witness being sufficient.

In practice the need for notaries in purely English legal matters is very small; for example they are not involved in normal property transactions. Since a great many solicitors also perform the function of commissioners for oaths and can witness routine declarations etc. (all are qualified to do so, but not all offer the service), most work performed by notaries relates to international matters in some way. They witness or authenticate documents to be used abroad. Many English notaries have strong foreign language skills and often a foreign legal qualification. The work of notaries and solicitors in England is separate although most notaries are solicitors. The Notaries Society gives the number of notaries in England and Wales as "about 1,000," all but seventy of whom are solicitors.

Scrivener notaries get their name from the Scriveners' Company. Until 1999, when they lost this monopoly, they were the only notaries permitted to practise in the City of London. They used not to have to first qualify as solicitors, but they had knowledge of foreign laws and languages.

Currently to qualify as a notary public in England and Wales it is necessary to have earned a law degree or qualified as a solicitor or barrister in the past five years, and then to take a two-year distance-learning course styled the Postgraduate Diploma in Notarial Practice. At the same time, any applicant must also gain practical experience. The few who go on to become scrivener notaries require further study of two foreign languages and foreign law and a two-year mentorship under an active Scrivener notary.

The other notaries in England are either ecclesiastical notaries whose functions are limited to the affairs of the Church of England or other qualified persons who are not trained as solicitors or barristers but satisfy the Master of the Faculties of the Archbishop of Canterbury that they possess an adequate understanding of the law. Both the latter two categories are required to pass examinations set by the Master of Faculties.

The regulation of notaries was modernised by section 57 of the Courts and Legal Services Act 1990.

Notarial services generally include: 

Notaries public have existed in Scotland since the 13th century and developed as a distinct element of the Scottish legal profession. Those who wish to practice as a notary must petition the Court of Session. This petition is usually presented at the same time as a petition to practice as a solicitor, but can sometimes be earlier or later. However, to qualify, a notary must hold a current Practising Certificate from the Law Society of Scotland, a new requirement from 2007, before which all Scottish solicitors were automatically notaries.

Whilst notaries in Scotland are always solicitors, the profession remains separate in that there are additional rules and regulations governing notaries and it is possible to be a solicitor, but not a notary. Since 2007 an additional Practising Certificate is required, so now most, but not all, solicitors in Scotland are notaries – a significant difference from the English profession. They are also separate from notaries in other jurisdictions of the United Kingdom.

The profession is administered by the Council of the Law Society of Scotland under the Law Reform (Miscellaneous Provisions) (Scotland) Act 1990.

In Scotland, the duties and services provided by the notary are similar to England and Wales, although they are needed for some declarations in divorce matters for which they are not in England. Their role declined following the Law Agents (Scotland) Amendment Act 1896 which stipulated only enrolled law agents could become notaries and the Conveyancing (Scotland) Act 1924 which extended notarial execution to law agents. The primary functions of a Scottish notary are:

In the United States, a notary public is a person appointed by a state government (e.g., the governor, lieutenant governor, state secretary, or in some cases the state legislature) and whose primary role is to serve the public as an impartial witness when important documents are signed. Since the notary is a state officer, a notary's duties may vary widely from state to state and in most cases bars a notary from acting outside their home state unless they also have a commission there as well.

In 32 states the main requirements are to fill out a form and pay a fee; many states have restrictions concerning notaries with criminal histories, but the requirements vary from state to state. Notaries in 18 states and the District of Columbia are required to take a course, pass an exam, or both; the education or exam requirements in Delaware and Kansas only apply to notaries who will perform electronic notarizations.

A notary is almost always permitted to notarize a document anywhere in the state where their commission is issued. Some states simply issue a commission "at large" meaning no indication is made as to from what county the person's commission was issued, but some states do require the notary include the county of issue of their commission as part of the jurat, or where seals are required, to indicate the county of issue of their commission on the seal. Merely because a state requires indicating the county where the commission was issued does not necessarily mean that the notary is restricted to notarizing documents in that county, although some states may impose this as a requirement.

Some states (Montana, Wyoming, North Dakota, among others) allow a notary who is commissioned in a state bordering that state to also act as a notary in the state if the other allows the same. Thus someone who was commissioned in Montana could notarize documents in Wyoming and North Dakota, and a notary commissioned in Wyoming could notarize documents in Montana. A notary from Wyoming could not notarize documents while in North Dakota (or the inverse) unless they had a commission from North Dakota or a state bordering North Dakota that also allowed North Dakota notaries to practice in that state as well.

Notaries in the United States are much less closely regulated than notaries in most other common-law countries, typically because U.S. notaries have little legal authority. In the United States, a lay notary may not offer legal advice or prepare documents – except in Louisiana and Puerto Rico – and in most cases cannot recommend how a person should sign a document or what type of notarization is necessary. There are some exceptions; for example, Florida notaries may take affidavits, draft inventories of safe deposit boxes, draft protests for payment of dishonored checks and promissory notes, and solemnize marriages. In most states, a notary can also certify or attest a copy or facsimile.

The most common notarial acts in the United States are the taking of acknowledgements and oaths. Many professions may require a person to double as a notary public, which is why US court reporters are often notaries as this enables them to swear in witnesses (deponents) when they are taking depositions, and secretaries, bankers, and some lawyers are commonly notaries public. Despite their limited role, some American notaries may also perform a number of far-ranging acts not generally found anywhere else. Depending on the jurisdiction, they may: take depositions, certify any and all petitions (ME), witness third-party absentee ballots (ME), provide no-impediment marriage licenses, solemnize civil marriages (ME, FL, SC), witness the opening of a safe deposit box or safe and take an official inventory of its contents, take a renunciation of dower or inheritance (SC), and so on.

"An acknowledgment is a formal [oral] declaration before an authorized public officer. It is made by a person executing [signing] an instrument who states that it was their free act and deed." That is, the person signed it without undue influence and for the purposes detailed in it. A certificate of acknowledgment is a written statement signed (and in some jurisdictions, sealed) by the notary or other authorized official that serves to prove that the acknowledgment occurred. The form of the certificate varies from jurisdiction to jurisdiction, but will be similar to the following:

Before me, the undersigned authority, on this ______ day of ___________, 20__ personally appeared _________________________, to me well known to be the person who executed the foregoing instrument, and he/she acknowledged before me that he/she executed the same as his/her voluntary act and deed.
A jurat is the official written statement by a notary public that they have administered and witnessed an oath or affirmation for an oath of office, or on an affidavit – that is, that a person has sworn to or affirmed the truth of information contained in a document, under penalty of perjury, whether that document is a lengthy deposition or a simple statement on an application form. The simplest form of jurat and the oath or affirmation administered by a notary are:

In the U.S., notarial acts normally include what is called a venue or caption, that is, an official listing of the place where a notarization occurred, usually in the form of the state and county and with the abbreviation "ss." (for Latin "scilicet", "to wit") normally referred to as a "subscript", often in these forms:

The venue is usually set forth at the beginning of the instrument or at the top of the notary's certificate. If at the head of the document, it is usually referred to as a caption. In times gone by, the notary would indicate the street address at which the ceremony was performed, and this practice, though unusual today, is occasionally encountered.

The laws throughout the United States vary on the requirement for a notary to keep and maintain records. Some states require records, some suggest or encourage records, or do not require or recommend records at all.

The California Secretary of State, Notary Public & Special Filings Section, is responsible for appointing and commissioning qualified persons as notaries public for four-year terms.

Prior to sitting for the notary exam, one must complete a mandatory six-hour course of study. This required course of study is conducted either in an online, home study, or in-person format via an approved notary education vendor. Both prospective notaries as well as current notaries seeking reappointment must undergo an "expanded" FBI and California Department of Justice background check.

Various statutes, rules, and regulations govern notaries public. California law sets maximum, but not minimum, fees for services related to notarial acts (e.g., per signature: acknowledgment $15, jurat $15, certified power of attorney $15, et cetera) A finger print (typically the right thumb) may be required in the notary journal based on the transaction in question (e.g., deed, quitclaim deed, deed of trust affecting real property, power of attorney document, et cetera). Documents with blank spaces cannot be notarized (a further anti-fraud measure). California explicitly prohibits notaries public from using literal foreign language translation of their title.
The use of a notary seal is required.

Notarial acts performed in Colorado are governed under the Notaries Public Act, 12-55-101, et seq. Pursuant to the Act, notaries are appointed by the Secretary of State for a term not to exceed four years. Notaries may apply for appointment or reappointment online at the Secretary of State's website. A notary may apply for reappointment to the notary office 90 days before their commission expires. Since May 2010, all new notaries and expired notaries are required to take an approved training course and pass an examination to ensure minimal competence of the Notaries Public Act. A course of instruction approved by the Secretary of State may be administered by approved vendors and shall bear an emblem with a certification number assigned by the Secretary of State's office. An approved course of instruction covers relevant provisions of the Colorado Notaries Public Act, the Model Notary Act, and widely accepted best practices. In addition to courses offered by approved vendors, the Secretary of State offers free certification courses at the Secretary of State's office. To sign up for a free course, visit the notary public training page at the following link. A third party seeking to verify the status of a Colorado notary may do so by visiting the Secretary of State's website at the following link. Constituents seeking an apostille or certificate of magistracy are requested to complete the form found on the following page before sending in their documents or presenting at the Secretary of State's office.

Florida notaries public are appointed by the Governor to serve a four-year term. New applicants and commissioned notaries public must be bona fide residents of the State of Florida, and first time applicants must complete a mandatory three-hour education course administered by an approved educator. Florida state law also requires that a notary public post bond in the amount of $7,500.00. A bond is required in order to compensate an individual harmed as a result of a breach of duty by the notary. Applications are submitted and processed through an authorized bonding agency. Florida is one of three states (Maine and South Carolina are the others) where a notary public can solemnize the rites of matrimony (perform a marriage ceremony).

The Florida Department of State appoints civil law notaries, also called "Florida International Notaries", who must be Florida attorneys who have practiced law for five or more years. Applicants must attend a seminar and pass an exam administered by the Florida Department of State or any private vendor approved by the department. Such civil law notaries are appointed for life and may perform all of the acts of a notary public in addition to preparing authentic acts.

Notaries public in Illinois are appointed by the Secretary of State for a four-year term. Also, residents of a state bordering Illinois (Iowa, Kentucky, Missouri, Wisconsin) who work or have a place of business in Illinois can be appointed for a one-year term. Notaries must be United States citizens (though the requirement that a notary public must be a United States citizen is unconstitutional; see "Bernal v. Fainter"), or aliens lawfully admitted for permanent residence; be able to read and write the English language; be residents of (or employed within) the State of Illinois for at least 30 days; be at least 18 years old; not be convicted of a felony; and not had a notary commission revoked or suspended during the past 10 years.

An applicant for the notary public commission must also post a $5,000 bond, usually with an insurance company and pay an application fee of $10. The application is usually accompanied with an oath of office. If the Secretary of State's office approves the application, the Secretary of State then sends the commission to the clerk of the county where the applicant resides. If the applicant records the commission with the county clerk, they then receive the commission. Illinois law prohibits notaries from using the literal Spanish translation in their title and requires them to use a rubber stamp seal for their notarizations. The notary public can then perform their duties anywhere in the state, as long as the notary resides (or works or does business) in the county where they were appointed.

A notary public in Kentucky is appointed by either the Secretary of State or the Governor to administer oaths and take proof of execution and acknowledgements of instruments. Notaries public fulfill their duties to deter fraud and ensure proper execution. There are two separate types of notaries public that are commissioned in Kentucky. They are Notary Public: State at Large and Notary Public: Special Commission. They have two distinct sets of duties and two different routes of commissioning. For both types of commissions, applicants must be eighteen (18) years of age, of good moral character (not a convicted felon) and capable of discharging the duties imposed upon him/her by law. In addition, the application must be approved by one of the following officials in the county of application: a Circuit Judge, the Circuit Court Clerk, the county Judge/Executive, the County Clerk, a county Magistrate or member of the Kentucky General Assembly. The term of office for both types of notary public is four years.

A "Notary Public: State at Large" is either a resident or non-resident of Kentucky who is commissioned to perform notarial acts anywhere within the physical borders of the Commonwealth of Kentucky that may be recorded either in-state or in another state. In order to become a Notary Public: State at Large, the applicant must be a resident of the county from which he/she makes application or be principally employed in the county from which he/she makes the application. A completed application is sent to the Secretary of State's office with the required fee. Once the application is approved by the Secretary of State, the commission is sent to the county clerk in the county of application and a notice of appointment is sent to the applicant. The applicant will have thirty days to go to the county clerk's office where they will be required to 1.) Post either a surety or property bond (bonding requirements and amounts vary by county) 2.) Take the Oath/Affirmation of Office and 3.) File and record the commission with the county clerk.

A "Notary Public: Special Commission" is either a resident or non-resident of Kentucky who is commissioned to perform notarial acts either inside or outside the borders of the Commonwealth on documents that must be recorded in Kentucky. The main difference in the appointment process is that, unlike a Notary Public: State at Large, a Notary Public: Special Commission is not required to post bond before taking the oath/affirmation nor are they required to be a resident or employed in Kentucky. In addition, where a Notary Public: State at Large is commissioned directly by the Secretary of State, a Notary Public: Special Commission is appointed by the Governor on the recommendation of the Secretary of State. It is permitted to hold a commission as both a Notary Public: State at Large and a Notary Public: Special Commission, however separate applications and filing fees are required.

A Kentucky Notary Public is not required to use a seal or stamp and a notarization with just the signature of the notary is considered to be valid. It is, however, recommended that a seal or stamp be used as they may be required on documents recorded or used in another state. If a seal or stamp is used, it is required to have the name of the notary as listed on their commission as well as their full title of office (Notary Public: State at Large or Notary Public: Special Commission). A notary journal is also recommended but not required (except in the case of recording protests, which must be recorded in a well-bound and indexed journal).

Louisiana notaries public are commissioned by the Governor. They are the only notaries to be appointed for life. The Louisiana notary public is a civil law notary with broad powers, as authorized by law, usually reserved for the American style combination "barrister/solicitor" lawyers and other legally authorized practitioners in other states. A commissioned notary in Louisiana is a civil law notary that can perform/prepare many civil law notarial acts usually associated with attorneys and other legally authorized practitioners in other states, except represent another person or entity before a court of law for a fee (unless they are also admitted to the bar). Notaries are not allowed to give "legal" advice, but they are allowed to give "notarial" advice – i.e., explain or recommend what documents are needed or required to perform a certain act – and do all things necessary or incidental to the performance of their civil law notarial duties. They can prepare any document a civil law notary can prepare (to include inventories, appraisements, partitions, wills, protests, matrimonial contracts, conveyances, and, generally, all contracts and instruments in writing) and, if ordered or requested to by a judge, prepare certain notarial legal documents, in accordance with law, to be returned and filed with that court of law.

Maine Notaries Public are appointed by the Secretary of State to serve a seven-year term. In 1981, the process to merge the office of Justice of the Peace into that of Notary Public began, with all the duties of a Justice of the Peace fully transferred to a Notary Public in 1988. Because of this, Maine is one of three states (Florida and South Carolina are the others) where a Notary Public has the authority to solemnize the rites of matrimony (perform a marriage ceremony).

Maryland notaries public are appointed by the governor on the recommendation of the secretary of state to serve a four-year term. New applicants and commissioned notaries public must be bona fide residents of the State of Maryland or work in the state. An application must be approved by a state senator before it is submitted to the secretary of state. The official document of appointment is imprinted with the signatures of the governor and the secretary of state as well as the Great Seal of Maryland. Before exercising the duties of a notary public, an appointee must appear before the clerk of one of Maryland's 24 circuit courts to take an oath of office.

A bond is not required. Seals are required, and notary is required to keep a log of all notarial acts, indicating the name of the person, their address, what type of document is being notarized, the type of ID used to authenticate them (or that they are known personally) by the notary, and the person's signature. The notary's log is the only document for which a notary may write their own certificate.

When having a person make an affidavit, state law requires the person state the phrase "under penalty of perjury."

Minnesota notaries public are commissioned by the Governor with the advice and consent of the Senate for a five-year term. All commissions expire on 31 January of the fifth year following the year of issue. Citizens and resident aliens over the age of 18 years apply to the Secretary of State for appointment and reappointment. Residents of adjoining counties in adjoining states may also apply for a notary commission in Minnesota. Notaries public have the power to administer all oaths required or authorized to be administered in the state; take and certify all depositions to be used in any of the courts of the state; take and certify all acknowledgments of deeds, mortgages, liens, powers of attorney and other instruments in writing or electronic records; and receive, make out and record notarial protests. The Secretary of State's website () provides more information about the duties, requirements and appointments of notaries public.

Montana notaries public are appointed by the Secretary of State and serve a four-year term. A Montana notary public has jurisdiction throughout the states of Montana, North Dakota, and Wyoming. These states permit notaries from neighboring states to act in the state in the same manner as one from that state under reciprocity, e.g., as long as that state grants notaries from neighboring states to act in their state. [Montana Code 1-5-605]

The Secretary of State is charged with the responsibility of appointing notaries by the provisions of Chapter 240 of the Nevada Revised Statutes. Nevada notaries public who are not also practicing attorneys are prohibited by law from using "notario", "notario publico" or any non-English term to describe their services. (2005 Changes to NRS 240)

Notaries are commissioned by the State Treasurer for a period of five years. Notaries must also be sworn in by the clerk of the county in which they reside. A person can become a notary in the state of New Jersey if they: (1) are over the age of 18; (2) are a resident of New Jersey OR is regularly employed in New Jersey and lives in an adjoining state; (3) have never been convicted of a crime under the laws of any state or the United States, for an offense involving dishonesty, or a crime of the first or second degree, unless the person has met the requirements of the Rehabilitated Convicted Offenders Act (). Notary applications must be endorsed by a state legislator.

Notaries in the state of New Jersey serve as impartial witnesses to the signing of documents, attests to the signature on the document, and may also administer oaths and affirmations. Seals are not required; many people prefer them and as a result, most notaries have seals in addition to stamps. Notaries may administer oaths and affirmations to public officials and officers of various organizations. They may also administer oaths and affirmations in order to execute jurats for affidavits/verifications, and to swear in witnesses.

Notaries are prohibited from predating actions; lending notary equipment to someone else (stamps, seals, journals, etc.); preparing legal documents or giving legal advice; appearing as a representative of another person in a legal proceeding. Notaries should also refrain from notarizing documents in which they have a personal interest.

Pursuant to state law, attorneys licensed in New Jersey may administer oaths and affirmations

New York notaries are empowered to administer oaths and affirmations (including oaths of office), to take affidavits and depositions, to receive and certify acknowledgments or proofs (of execution) of deeds, mortgages and powers of attorney and other instruments in writing; to demand acceptance or payment of foreign and inland bills of exchange, promissory notes and obligations in writing, and to protest these (that is, certify them) for non-acceptance or non-payment. Additional powers include required presence at a forced opening of an abandoned safe deposit box and certain election law privileges regarding petitioning. They are not authorized to perform a civil marriage ceremony, nor certify "true copies" of certain publicly recorded documents. Every county clerk's office in New York State (including within the City of New York) must have a notary public available to serve the public free of charge, during business hours with no limit on quantity or type of document.

Attorneys admitted to the New York Bar are eligible to apply for and receive an appointment as a notary public in the State of New York. "Nota bene": they are not "automatically" appointed as a notary public because they are a member of the New York Bar. An interested attorney is required to follow the same appointment process as a non-attorney; however, the proctored, written state examination requirement is waived by statute for members of the bar in good standing.

New York notaries initially must pass a test and then renew their status every 4 years.

A notary in the Commonwealth of Pennsylvania is empowered to perform seven distinct official acts: take affidavits, verifications, acknowledgments and depositions, certify copies of documents, administer oaths and affirmations, and protest dishonored negotiable instruments. A notary is strictly prohibited from giving legal advice or drafting legal documents such as contracts, mortgages, leases, wills, powers of attorney, liens or bonds. Pennsylvania is one of the few states with a successful Electronic Notarization Initiative.

South Carolina notaries public are appointed by the Governor to serve a ten-year term. All applicants must first have that application endorsed by a state legislator before submitting their application to the Secretary of State. South Carolina is one of three states (Florida and Maine are the others) where a notary public can solemnize the rites of matrimony (perform a marriage ceremony) (2005). If you live in South Carolina but work in North Carolina, Georgia or Washington, DC, these states will permit you to become a notary public for their state. South Carolina does not offer this provision to out-of-state residents that work in South Carolina(2012).

Utah notaries public are appointed by the Lieutenant Governor to serve a four-year term. Utah used to require that impression seals be used, but now it is optional. The seal must be in purple ink.

A Virginia notary must either be a resident of Virginia or work in Virginia, and is authorized to acknowledge signatures, take oaths, and certify copies of non-government documents which are not otherwise available, e.g. a notary cannot certify a copy of a birth or death certificate since a certified copy of the document can be obtained from the issuing agency. Changes to the law effective 1 July 2008 imposes certain new requirements; while seals are still not required, if they are used they must be photographically reproducible. Also, the notary's registration number must appear on any document notarized. Changes to the law effective 1 July 2008 will permit notarization of electronic signatures.

On 1 July 2012, Virginia became the first state to authorize a signer to be in a remote location and have a document notarized electronically by an approved Virginia electronic notary using audio-visual conference technology by passing the bills SB 827 and HB 2318.

In Washington any adult resident of the state, or resident of Oregon or Idaho who is employed in Washington or member of the United States military or their spouse, may apply to become a notary public. Applicants for commissioning as a Notary Public must: (a) be literate in the English language, (b) be endorsed by three adult residents of Washington who are not related to the applicant, (c) pay $30, (d) possess a surety bond in the amount of $10,000, (e) swear under oath to act in accordance with the state's laws governing the practice of notaries. In addition, the director of licensing is authorized to deny a commission to any applicant who has had a professional license revoked, has been convicted of a serious crime, or who has been found culpable of misconduct during a previous term as a notary public. 
A notary public is appointed for a term of 4 years.

Notaries public in this state are also referred to under law as a Conservator of the Peace as per Attorney General decision on 4 June 1921

Wyoming notaries public are appointed by the Secretary of State and serve a four-year term. A Wyoming notary public has jurisdiction throughout the states of Wyoming and Montana. These states permit notaries from neighboring states to act in the state in the same manner as one from that state under reciprocity, e.g. as long as that state grants notaries from neighboring states to act in their state.

A Maryland requirement that to obtain a commission, a notary declare their belief in God, as required by the Maryland Constitution, was found by the United States Supreme Court in "Torcaso v. Watkins", to be unconstitutional. Historically, some states required that a notary be a citizen of the United States. However, the U.S. Supreme Court, in the case of "Bernal v. Fainter" , declared that to be impermissible.

In the U.S., there are reports of notaries (or people claiming to be notaries) having taken advantage of the differing roles of notaries in common law and civil law jurisdictions to engage in the unauthorized practice of law. The victims of such scams are typically illegal immigrants from civil law countries who need assistance with, for example, their immigration papers and want to avoid hiring an attorney. Confusion often results from the mistaken premise that a notary public in the United States serves the same function as a "Notario Publico" in Spanish-speaking countries (which are civil law countries, "see below"). For this reason, some states, like Texas, require that notaries specify that they are not "Notario Publico" when advertising services in languages other than English. Prosecutions in such cases are difficult, as the victims are often deported and thus unavailable to testify.

Certain members of the United States Armed Forces are given the powers of a notary under federal law (). Some military members have authority to certify documents or administer oaths, without being given all notarial powers (, , ). In addition to the powers granted by the federal government, some states have enacted laws granting notarial powers to commissioned officers.

Certain personnel at U.S. embassies and consulates may be given the powers of a notary under federal law ( and ).

The role of notaries in civil law countries is much greater than in common law countries. Civilian notaries are full-time lawyers and holders of a public office who routinely undertake non-contentious transactional work done in common law countries by attorneys/solicitors, as well as, in some countries, those of government registries, title offices, and public recorders. The qualifications imposed by civil law countries are much greater, requiring generally an undergraduate law degree, a graduate degree in notarial law and practice, three or more years of practical training ("articles") under an established notary, and must sit a national examination to be admitted to practice. Typically, notaries work in private practice and are fee earners, but a small minority of countries have salaried public service (or "government" / "state") notaries (e.g., Ukraine, Russia, Baden-Württemberg in Germany (until 2017), certain cantons of Switzerland, Portugal).

Notaries in civil law countries have had a critical historical role in providing archives. A considerable amount of historical data of tremendous value is available in France, Spain and Italy thanks to notarial minutes, contracts and conveyances, some of great antiquity which have reached us in spite of losses, deteriorations and willful destructions.

Civil law notaries have jurisdiction over strictly non-contentious domestic civil-private law in the areas of property law, family law, agency, wills and succession, and company formation. The point to which a country's notarial profession monopolizes these areas can vary greatly. On one extreme is France (and French-derived systems) which statutorily give notaries a monopoly over their reserved areas of practice, as opposed to Austria where there is no discernible monopoly whatsoever and notaries are in direct competition with attorneys/solicitors.

In the few United States jurisdictions where trained notaries are allowed (such as Louisiana, Puerto Rico), the practice of these legal practitioners is limited to legal advice on purely non-contentious matters that fall within the purview of a notary's reserved areas of practice.

Thailand is a mixed law country with strong civil law traditional. Public notaries in Thailand are Thai lawyers who have a special license.

Upon the death of President Warren G. Harding in 1923, Calvin Coolidge was sworn in as president by his father, John Calvin Coolidge, Sr., a Vermont notary public. However, as there was some controversy as to whether a state notary public had the authority to administer the presidential oath of office, Coolidge took the oath, again, upon returning to Washington.




</doc>
<doc id="21482" url="https://en.wikipedia.org/wiki?curid=21482" title="Nairobi">
Nairobi

Nairobi () is the capital and the largest city of Kenya. The name comes from the Maasai phrase "Enkare Nairobi", which translates to "cool water", a reference to the Nairobi River which flows through the city. The city proper had a population of 4,397,073 in the 2019 census, while the metropolitan area has a population of 9,354,580. The city is popularly referred to as the Green City in the Sun.

Nairobi was founded in 1899 by the colonial authorities in British East Africa, as a rail depot on the Uganda Railway. The town quickly grew to replace Mombasa as the capital of Kenya in 1907. After independence in 1963, Nairobi became the capital of the Republic of Kenya. During Kenya's colonial period, the city became a centre for the colony's coffee, tea and sisal industry. The city lies on the River Athi in the southern part of the country, and has an elevation of above sea level.

According to the 2019 census, in the administrative area of Nairobi, 4,397,073 inhabitants lived within .

Home to thousands of Kenyan businesses and over 100 major international companies and organizations, including the United Nations Environment Programme (UN Environment) and the United Nations Office at Nairobi (UNON), Nairobi is an established hub for business and culture. The Nairobi Securities Exchange (NSE) is one of the largest in Africa and the second-oldest exchange on the continent. It is Africa's fourth-largest exchange in terms of trading volume, capable of making 10 million trades a day.

Nairobi is found within the Greater Nairobi Metropolitan region, which consists of 5 out of 47 counties in Kenya, which generates about 60% of the entire nation's GDP. The counties are:

The site of Nairobi was originally part of an uninhabited swamp. The name Nairobi itself comes from the Maasai expression meaning "cool waters", referring to the cold water stream which flowed through the area. With the arrival of the Uganda Railway, the site was identified by Sir George Whitehouse for a store depot, shunting ground and camping ground for the Indian labourers working on the railway. Whitehouse, chief engineer of the railway, favoured the site as an ideal resting place due to its high elevation, temperate climate and being situated before the steep ascent of the Limuru escarpments. His choice was however criticised by officials within the Protectorate government who felt the site was too flat, poorly drained and relatively infertile.
In 1898, Arthur Church was commissioned to design the first town layout for the railway depot. It constituted two streets – Victoria Street and Station Street, ten avenues, staff quarters and an Indian commercial area. The railway arrived at Nairobi on 30 May 1899, and soon Nairobi replaced Machakos as the headquarters of the provincial administration for Ukamba province. On the arrival of the railway, Whitehouse remarked that "Nairobi itself will in the course of the next two years become a large and flourishing place and already there are many applications for sites for hotels, shops and houses. The town's early years were however beset with problems of malaria leading to at least one attempt to have the town moved. In the early 1900s, Bazaar Street (now Biashara Street) was completely rebuilt after an outbreak of plague and the burning of the original town.

Between 1902 and 1910, the town's population rose from 5,000 to 16,000 and grew around administration and tourism, initially in the form of big game hunting. In 1907, Nairobi replaced Mombasa as the capital of the East Africa Protectorate. In 1908, a further outbreak of the plague led to Europeans concluding that the cause was unhygienic conditions in the Indian Bazaar. The government responded by restricting lower class Indians and African natives to specific quarters for residence and trade setting a precedent for racial segregation in the commercial sphere. By the outset of the First World War, Nairobi was well established as a European settler colony through immigration and land alienation. In 1919, Nairobi was declared to be a municipality.

In 1921, Nairobi had 24,000 residents, of which 12,000 were native Africans. The next decade would see a growth in native African communities into Nairobi, where they would go on to constitute a majority for the first time. In February 1926, colonial officer Eric Dutton passed through Nairobi on his way to Mount Kenya, and said of the city:
The continuous expansion of the city began to anger the Maasai, as the city was devouring their land to the south. It also angered the Kikuyu people, who wanted the land returned to them. After the end of World War II, this friction developed into the Mau Mau rebellion. Jomo Kenyatta, Kenya's future president, was jailed for his involvement even though there was no evidence linking him to the rebellion. The pressure exerted from the locals onto the British resulted in Kenyan independence in 1963, with Nairobi as the capital of the new republic.

After independence, Nairobi grew rapidly and this growth put pressure on the city's infrastructure. Power cuts and water shortages were a common occurrence, though in the past few years better city planning has helped to put some of these problems in check.

On 11 September 1973, the Kenyatta International Conference Centre KICC was open to the public. The 28-storey building at the time was designed by the Norwegian architect Karl Henrik Nøstvik and Kenyan David Mutiso. The construction was done in three phases. Phase I was the construction of the podium, Phase II consisted of the main tower, and Phase III involved the Plenary. Construction was completed in 1973, with the opening ceremony occurring on 11 September and being presided over by Kenya's founding father President Kenyatta. It is the only building within the city with a helipad that is open to the public. Of the buildings built in the Seventies, the KICC was the most eco-friendly and most environmentally conscious structure; its main frame was constructed with locally available materials gravel, sand, cement and wood, and it had wide open spaces which allowed for natural aeration and natural lighting. Cuboids made up the plenary hall, the tower consisted of a cylinder composed of several cuboids, and the amphitheater and helipad both resembled cones. The tower was built around a concrete core and it had no walls but glass windows, which allowed for maximum natural lighting. It had the largest halls in eastern and central Africa.

Three years prior in 1972, the World Bank approved funds for further expansion of the then Nairobi Airport (now Jomo Kenyatta International Airport), including a new international and domestic passenger terminal building, the airport's first dedicated cargo and freight terminal, new taxiways, associated aprons, internal roads, car parks, police and fire stations, a State Pavilion, airfield and roadway lighting, fire hydrant system, water, electrical, telecommunications and sewage systems, a dual carriageway passenger access road, security, drainage and the building of the main access road to the airport (Airport South Road). The total cost of the project was more than US$29 million (US$111.8 million in 2013 dollars). On 14 March 1978, construction of the terminal building was completed on the other side of the airport's single runway and opened by President Jomo Kenyatta less than five months before his death. The airport was renamed Jomo Kenyatta International Airport in memory of its First President.

The United States Embassy, then located in downtown Nairobi, was bombed in August 1998 by Al-Qaeda, as one of a series of US embassy bombings. It is now the site of a memorial park.

On 9 November 2012, President Mwai Kibaki opened the KES 31 billion Thika Superhighway. This mega-project of Kenya started in 2009 and ended in 2011. It involved expanding the four-lane carriageway to eight lanes, building underpasses, providing interchanges at roundabouts, erecting flyovers and building underpasses to ease congestion. The 50.4-kilometre road was built in three phases: Uhuru Highway to Muthaiga Roundabout; Muthaiga Roundabout to Kenyatta University and; Kenyatta University to Thika Town.

On 31 May 2017, The current president Uhuru Kenyatta inaugurated the Standard Gauge railway which runs from Nairobi to Mombasa and vice versa. It was primarily built by a Chinese firm with about 90% of total funding from China and about 10% from the Kenyan government. A second phase is also being built which will link Naivasha to the existing route and also the Uganda border.

The city is situated at and and occupies .

Nairobi is situated between the cities of Kampala and Mombasa. As Nairobi is adjacent to the eastern edge of the Rift Valley, minor earthquakes and tremors occasionally occur. The Ngong Hills, located to the west of the city, are the most prominent geographical feature of the Nairobi area. Mount Kenya is situated north of Nairobi, and Mount Kilimanjaro is towards the south-east.

The Nairobi River and its tributaries traverse through the Nairobi County and joins the larger River Athi on the eastern edge of the county. 

Nobel Peace Prize laureate Wangari Maathai fought fiercely to save the indigenous Karura Forest in northern Nairobi which was under threat of being replaced by housing and other infrastructure.

Nairobi's western suburbs stretch all the way from the Kenyatta National Hospital in the south to the UN headquarters at Gigiri suburb in the north, a distance of about . The city is centred on the City Square, which is located in the Central Business District. The Kenyan Parliament buildings, the Holy Family Cathedral, Nairobi City Hall, Nairobi Law Courts, and the Kenyatta Conference Centre all surround the square.
Under the Köppen climate classification, Nairobi has a subtropical highland climate (Cwb). At above sea level, evenings may be cool, especially in the June/July season, when the temperature can drop to . The sunniest and warmest part of the year is from December to March, when temperatures average in the mid-twenties Celsius during the day. The mean maximum temperature for this period is .

There are rainy seasons, but rainfall can be moderate. The cloudiest part of the year is just after the first rainy season, when, until September, conditions are usually overcast with drizzle. As Nairobi is situated close to the equator, the differences between the seasons are minimal. The seasons are referred to as the wet season and dry season. The timing of sunrise and sunset varies little throughout the year for the same reason.

Nairobi is divided into a series of constituencies with each being represented by members of Parliament in the National Assembly. These constituencies are: Makadara, Kamukunji, Starehe, Langata, Dagoretti, Westlands, Kasarani, and Embakasi. The main administrative divisions of Nairobi are Central, Dagoretti, Embakasi, Kasarani, Kibera, Makadara, Pumwani, and Westlands. Most of the upmarket suburbs are situated to the west and north-central of Nairobi, where most European settlers resided during the colonial times AKA 'Ubabini'. These include Karen, Langata, Lavington, Gigiri, Muthaiga, Brookside, Spring Valley, Loresho, Kilimani, Kileleshwa, Hurlingham, Runda, Kitisuru, Nyari, Kyuna, Lower Kabete, Westlands, and Highridge, although Kangemi, Kawangware, and Dagoretti are lower income areas close to these affluent suburbs. The city's colonial past is commemorated by many English place-names.

Most lower-middle and upper middle income neighbourhoods are located in the north-central areas such as Highridge, Parklands, Ngara, Pangani, and areas to the southwest and southeast of the metropolitan area near the Jomo Kenyatta International Airport. The most notable ones include Avenue Park, Fedha, Pipeline, Donholm, Greenfields, Nyayo, Taasia, Baraka, Nairobi West, Madaraka, Siwaka, South B, South C, Mugoya, Riverbank, Hazina, Buru Buru, Uhuru, Harambee Civil Servants', Akiba, Kimathi, Pioneer, and Koma Rock to the centre-east and Kasarani to northeast area among others. The low and lower income estates are located mainly in far eastern Nairobi. These include, Umoja, Kariokor, Dandora, Kariobangi, Kayole, Embakasi, and Huruma. Kitengela suburb, though located further southeast, Ongata Rongai and Kiserian further southwest, and Ngong/Embulbul suburbs also known as 'Diaspora' to the far west are considered part of the Greater Nairobi Metropolitan area. More than 90% of Nairobi residents work within the Nairobi Metropolitan area, in the formal and informal sectors. Many Somali immigrants have also settled in Eastleigh, nicknamed "Little Mogadishu".

The Kibera slum in Nairobi (with an estimated population of at least 500,000 to over 1,000,000 people) was thought to be Africa's second largest slum. However, recent census results have shown that Kibera is indeed much smaller than originally thought.

Nairobi has many parks and open spaces throughout the city. Much of the city has dense tree-cover and plenty of green spaces. The most famous park in Nairobi is Uhuru Park. The park borders the central business district and the neighbourhood Upper Hill. Uhuru ("Freedom" in Swahili) Park is a centre for outdoor speeches, services, and rallies. The park was to be built over by former President Daniel arap Moi, who wanted the 62-storey headquarters of his party, the Kenya African National Union, situated in the park. However, the park was saved following a campaign by Nobel Peace Prize winner Wangari Maathai.

Central Park is adjacent to Uhuru Park, and includes a memorial for Jomo Kenyatta, the first president of Kenya, and the Moi Monument, built in 1988 to commemorate the second president's first decade in power. Other notable open spaces include Jeevanjee Gardens, City Park, 7 August Memorial Park, and Nairobi Arboretum.

The colonial 1948 Master Plan for Nairobi still acts as the governing mechanism when it comes to making decisions related to urban planning. The Master Plan at the time, which was designed for 250,000 people, allocated 28% of Nairobi's land to public space, but because of rapid population growth, much of the vitality of public spaces within the city are increasingly threatened. City Park, the only natural park in Nairobi, for example, was originally 150 acres, but has since lost approximately 50 acres of land to private development through squatting and illegal alienation which began in the 1980s.

The City of Nairobi enjoys the status of a full administrative County.

The Nairobi province differs in several ways from other Kenyan regions. The county is entirely urban. It has only one local council, Nairobi City Council. Nairobi Province was not divided into "districts" until 2007, when three districts were created. In 2010, along with the new constitution, Nairobi was renamed a county.

Nairobi County has 17 constituencies. Constituency name may differ from division name, such that Starehe Constituency is equal to Central Division, Lang'ata Constituency to Kibera division, and Kamukunji Constituency to Pumwani Division in terms of boundaries.

Nairobi is divided into 17 constituencies and 85 wards, mostly named after residential estates. Kibera Division, for example, includes Kibera (Kenya's largest slum) as well as affluent estates of Karen and Langata.

Nairobi is home to the Nairobi Securities Exchange (NSE), one of Africa's largest stock exchanges. The NSE was officially recognised as an overseas stock exchange by the London Stock Exchange in 1953. The exchange is Africa's 4th largest in terms of trading volumes, and 5th largest in terms of Market Capitalization as a percentage of GDP.

Nairobi is the regional headquarters of several international companies and organisations. In 2007, General Electric, Young & Rubicam, Google, Coca-Cola, IBM Services, and Cisco Systems relocated their African headquarters to the city. The United Nations Office at Nairobi hosts UN Environment and UN-Habitat headquarters.

Several of Africa's largest companies are headquartered in Nairobi. Safaricom, the largest company in Kenya by assets and profitability is headquartered in Nairobi, KenGen, which is the largest African stock outside South Africa, is based in the city. Kenya Airways, Africa's fourth largest airline, uses Nairobi's Jomo Kenyatta International Airport as a hub.

Nairobi has not been left behind by the FinTech phenomenon that has taken over worldwide. It has produced a couple of tech firms like Craft Silicon, Kangai Technologies, and Jambo Pay which have been in the forefront of technology, innovation and cloud based computing services. Their products are widely used and have considerable market share presence within Kenya and outside its borders.

Goods manufactured in Nairobi include clothing, textiles, building materials, processed foods, beverages, and cigarettes. Several foreign companies have factories based in and around the city. These include Goodyear, General Motors, Toyota Motors, and Coca-Cola.

Nairobi has a large tourist industry, being both a tourist destination and a transport hub.

Nairobi has grown around its central business district. This takes a rectangular shape, around the Uhuru Highway, Haille Selassie Avenue, Moi Avenue, and University Way. It features many of Nairobi's important buildings, including the City Hall and Parliament Building. The city square is also located within the perimeter.

Most of the skyscrapers in this region are the headquarters of businesses and corporations, such as I&M and the Kenyatta International Conference Centre. The United States Embassy bombing took place in this district, prompting the building of a new embassy building in the suburbs.

In 2011, the city was considered to have about 4 million residents. A large beautification project took place in the Central Business District, as the city prepared to host the 2006 Afri-Cities summit. Iconic buildings such as the Kenyatta International Conference Centre had their exteriors cleaned and repainted.

Nairobi downtown area or central business district is bordered to the southwest by Uhuru Park and Central Park. The Mombasa to Kampala railway runs to the southeast of the district.

Two areas outside of the Central Business District area that are seeing a growth in companies and office space are Upper Hill, which is located, approximately from the Central Business District and Westlands, which is also about the same distance, away from the city centre.

Companies that have moved from the Central Business District to Upper Hill include Citibank and in 2007, Coca-Cola began construction of their East and Central African headquarters in Upper Hill, cementing the district as the preferred location for office space in Nairobi. The largest office development in this area is UAP Tower, completed recently in 2015 and officially opened for business on July 4, 2016. It is a 33-storey tower and reaches a height of 163 meters. The World Bank and International Finance Corporation (part of the World Bank Group) are also located in Upper Hill at the Delta Center, Menegai Road. Earlier on, they were located in the Hill Park Building and CBA Building respectively (both also in Upper Hill), and prior to that in View Park towers in the Central Business District.

To accommodate the large demand for floor space in Nairobi, various commercial projects are being constructed. New business parks are being built in the city, including the flagship Nairobi Business Park.

Construction boom and real estate development projects

Nairobi is undergoing a construction boom. Major real estate projects and skyscrapers are coming up in the city. Among them are:The pinnacle twin towers which will tower at 314 m, Britam Tower (200 m), Avic International Africa headquarters (176 m), Prism tower (140 m), Pan Africa insurance towers, Pallazzo offices, and many other projects. Shopping malls are also being constructed like the recently completed Garden city Mall, Centum's Two rivers Mall, The Hub in Karen, Karen waterfront, Thika Greens, and the recently reconstructed Westgate Mall. High-class residential apartments for living are coming up like Le Mac towers, a residential tower in Westlands Nairobi with 23 floors. Avic International is also putting up a total of four residential apartments on Waiyaki way: a 28-level tower, two 24-level towers, and a 25-level tower. Hotel towers are also being erected in the city. Avic International is putting up a 30-level hotel tower of 141 m in the Westlands. The hotel tower will be operated by Marriot group. Jabavu limited is constructing a 35 floor hotel tower in Upper Hill which will be high over 140 metres in the city skyline. Arcon Group Africa has also announced plans to erect a skyscraper in Upper hill which will have 66 floors and tower over 290 metres, further cementing Upper hill as the preferred metropolis for multinational corporations launching their operations in the Kenyan capital.
Also see List of tallest buildings in Kenya

Population of Nairobi between 1906 and 2019

Nairobi has experienced one of the highest growth rates of any city in Africa. Since its foundation in 1899, Nairobi has grown to become the second largest city in the African Great Lakes, despite being one of youngest cities in the region. The growth rate of Nairobi is 4.1% a year. It is estimated that Nairobi's population will reach 5 million in 2025.

These data fit remarkably closely (r^2 = 0.9994) to a logistic curve with t(0) = 1900, P(0)=8500, r = 0.059 and K = 8,000,000. This suggests a 2011 growth rate of 3.5% (the CIA estimate of 4.5% cited above would have been true in 2005). According to this curve, the population of the city will be below 4 million in 2015, and will reach 5 million in 2025.

Given this high population growth, owing itself both to urban migration and high birth rates, the economy has yet to catch up. Unemployment is estimated at 40% within the city, mainly in the high-density, low income areas of the city which can make them seem even denser than the higher-income neighborhoods.


Kenya National Theatre, and the Kenya National Archives. Art galleries in Nairobi include the Rahimtulla Museum of Modern Art (Ramoma), the Mizizi Arts Centre, and the Nairobi National Museum.
There is also the Karen Blixen Museum and the Nairobi National Museum. There is Kuona Art Center for visual artists in Nairobi.

By the mid twentieth century, many foreigners settled in Nairobi from other parts of the British Empire, primarily India and parts of (present-day) Pakistan. These immigrants were workers who arrived to construct the Kampala – Mombasa railway, settling in Nairobi after its completion, and also merchants from Gujarat. Nairobi also has established communities from Somalia and Sudan.

Nairobi has two informal nicknames. The first is "The Green City in the Sun", which is derived from the city's foliage and warm climate. The second is the "Safari Capital of the World", which is used due to Nairobi's prominence as a hub for safari tourism.

"Kwani?" is Kenya's first literary journal and was established by writers living in Nairobi. Nairobi's publishing houses have also produced the works of some of Kenya's authors, including Ngũgĩ wa Thiong'o and Meja Mwangi who were part of post-colonial writing.

Many film makers also practice their craft out of Nairobi. Film-making is still young in the country, but people like producer Njeri Karago and director Judy Kibinge are paving the way for others.

Perhaps the most famous book and film set in Nairobi is "Out of Africa". The book was written by Karen Blixen, whose pseudonym was Isak Dinesen, and it is her account of living in Kenya. Karen Blixen lived in the Nairobi area from 1917 to 1931. The neighbourhood in which she lived, Karen, is named after her.

In 1985, "Out of Africa" was made into a film, directed by Sydney Pollack. The film won 28 awards, including seven Academy Awards. The popularity of the film prompted the opening of Nairobi's Karen Blixen Museum.

Nairobi is also the setting of many of the novels of Ngũgĩ wa Thiong'o, Kenya's foremost writer.

Nairobi has been the set of several other American and British films. The most recent of these was "The Constant Gardener" (2005), a large part of which was filmed in the city. The story revolves around a British diplomat in Nairobi whose wife is murdered in northern Kenya. Much of the filming was in the Kibera slum.

Among the latest Kenyan actors in Hollywood who identify with Nairobi is Lupita Nyong'o. Lupita received an Oscar award for best supporting actress in her role as Patsy in the film "12 Years a Slave" during the "86th Academy Awards" at the Dolby theatre in Los Angeles. Lupita is the daughter of Kenyan politician Peter Anyang' Nyong'o.

Most new Hollywood films are nowadays screened at Nairobi's cinemas. Up until the early 1990s, there were only a few film theatres and the repertoire was limited. There are also two drive-in cinemas in Nairobi.

In 2015 and 2016, Nairobi was the focus point for the American television series "Sense8" which shot its first and second seasons partly in the city. The TV series has high reviews in The Internet Movie Database (IMDB).

In 2015 Nairobi was also featured in the British thriller film "Eye in the Sky", which is a story about a lieutenant general and a colonel who faced political opposition after ordering a drone missile strike to take out a group of suicide bombers in Nairobi.

In 2017, the name "Nairobi" was taken as a code-name by a female main character in the famous Spanish TV series "Money Heist".

In Nairobi, there are a range of restaurants and, besides being home to "nyama choma" which is a local term used to refer to roasted meat, there are American fast food restaurants such as KFC, Subway, Domino's Pizza, Pizza Hut, Hardee's and Burger King which are popular, and the longer established South African chains, Galittos, Steers, PizzaMojo, Spur Steak Ranches. Coffee houses, doubling up as restaurants, mostly frequented by the upper middle classes, such as Artcaffe, Nairobi Java House and Dormans have become increasingly popular in recent days. Traditional food joints such as the popular K'osewe's in the city centre and Amaica, which specialize in African delicacies, are also widespread. The Kenchic franchise which specialized in old-school chicken and chips meals was also popular, particularly among the lower classes and students, with restaurants all over the city and its suburbs. However, as of February 2016, Kenchic stopped operating its eatery business. Upscale restaurants often specialize in specific cuisines such as Italian, Lebanese, Ethiopian, French, but are more likely to be found in five star hotels and the wealthier suburbs in the West and South of the city.

Nairobi has an annual restaurant week (NRW) at the beginning of the year, January–February. Nairobi's restaurants offer dining packages at reduced prices. NRW is managed by Eatout Kenya which is an online platform that lists and reviews restaurants in Nairobi, and provides a platform for Kenyan foodies to congregate and share.

Nairobi is the centre of Kenya's music scene. Benga is a Kenyan genre which was developed in Nairobi. The style is a fusion of jazz and Luo music forms. Mugithi is another popular genre in Kenya, with its origins in the central parts of the country. A majority of music videos of leading local musicians are also filmed in the city.

In the 1970s, Nairobi became the prominent centre for music in the African Great Lakes. During this period, Nairobi was established as a hub of soukous music. This genre was originally developed in Kinshasa and Brazzaville. After the political climate in the region deteriorated, many Congolese artists relocated to Nairobi. Artists such as Orchestra Super Mazembe moved from Congo to Nairobi and found great success. Virgin records became aware of the popularity of the genre and signed recording contracts with several soukous artists.

More recently, Nairobi has become the centre of the Kenyan hip hop scene, with Kalamashaka, Gidi Gidi Majimaji being the pioneers of urban music in Kenya. The genre has become very popular amongst local youth, and domestic musicians have become some of the most popular in the region. Successful artists based in Nairobi include Jua Cali, Nonini, Camp Mulla, Juliani, Eric Wainaina, Suzanna Owinyo and Nameless. Popular Record labels include Ogopa DJs, Grand Pa Records, Main Switch, Red Black and Green Republik, Calif Records and Bornblack Music Group.

Many foreign musicians who tour Africa perform in Nairobi. Bob Marley's first-ever visit to Africa started in Nairobi. Acts that have performed in Nairobi include Lost Boyz, Wyclef Jean, Shaggy, Akon, Eve, T.O.K, Sean Paul, Wayne Wonder, Alaine, Konshens, Ja Rule, and Morgan Heritage, and Cabo Snoop. Other international musicians who have performed in Nairobi include the rocking show by Don Carlos, Demarco, Busy Signal, Mr. Vegas and the Elephant man crew.

Nairobi, including the coastal towns of Mombasa and Diani, have recently become the centre of Electronic Dance Music (EDM) in Kenya producing DJs as well as producers like Jack Rooster, Euggy, DJ Fita, Noise on Demand, DJ Vidza, DJ Coco EM. Prominent international composers and DJs have also toured in Nairobi, including Diplo, Major Lazer, Kyau & Albert, Solarity, Ronski Speed, and Boom Jinx.

Many nightclubs in and around the city have witnessed a growth in the population that exclusively listen to Electronic Dance Music, especially amongst the younger generations. These youth also support many local EDM producers and DJs, such as Jahawi, Mikhail Kuzi, Barney Barrow, Jack Rooster, HennessyLive, Trancephilic5 As well as up and comers such as L.A Dave, Eric K, Raj El Rey, Tom Parker and more.

Gospel music is also very popular in Nairobi just as in the rest of Kenya, with gospel artistes having a great impact in the mostly Christian city. Artistes such as Esther Wahome, Eunice Njeri, Daddy Owen, Emmy Kosgei and the late Angela Chibalonza, among others, have a great pull over the general population while others like MOG, Juliani, Ecko dyda, DK Kwenye Beat have great influence over the younger generation. Their concerts are also very popular and they have as much influence as the great secular artistes. The most popular are Groove tours, TSO (Totally Sold Out) new year concerts.

Musical group Sauti Sol performed for U.S. President Barack Obama when he was in the city for the 2015 Global Entrepreneurship Summit.

Nairobi is the African Great Lakes region's sporting centre. The premier sports facility in Nairobi and generally in Kenya is the Moi International Sports Centre in the suburb of Kasarani. The complex was completed in 1987, and was used to host the 1987 All Africa Games. The complex comprises a 60,000 seater stadium, the second largest in the African Great Lakes (after Tanzania's new national stadium), a 5,000 seater gymnasium, and a 2,000 seater aquatics centre.

The Nyayo National Stadium is Nairobi's second largest stadium renowned for hosting global rugby event under the "Safaricom Sevens." Completed in 1983, the stadium has a capacity of 30,000. This stadium is primarily used for football. The facility is located close to the Central Business District, which makes it a convenient location for political gatherings.

Nairobi City Stadium is the city's first stadium, and used for club football. Nairobi Gymkhana is the home of the Kenyan cricket team, and was a venue for the 2003 Cricket World Cup. Notable annual events staged in Nairobi include Safari Rally (although it lost its World Rally Championship status in 2003), Safari Sevens rugby union tournament, and Nairobi Marathon.

Football is the most popular sport in the city by viewership and participation. This is highlighted by the number of football clubs in the city, including Kenyan Premier League sides Gor Mahia, A.F.C. Leopards, Tusker and Mathare United.

There are six golf courses within a 20 km radius of Nairobi. The oldest 18-hole golf course in the city is the Royal Nairobi Golf Club. It was established in 1906 by the British, just seven years after the city was founded. Other notable golf clubs include the Windsor Country Club, Karen Country Club, and Muthaiga Golf Club. The Kenya Open golf tournament, which is part of the European Tour, takes place in Nairobi. The Ngong Racecourse in Nairobi is the centre of horse racing in Kenya.

Rugby is also a popular sport in Nairobi with 8 of the 12 top flight clubs based here.

Basketball is also a popular sport played in the city's srimary, Secondary and college leagues. Many of the city's urban youth are basketball fans and watch the American NBA.

Among the places of worship, they are predominantly Christian churches and temples : Roman Catholic Archdiocese of Nairobi (Catholic Church), Anglican Church of Kenya (Anglican Communion), Presbyterian Church of East Africa (World Communion of Reformed Churches), Baptist Convention of Kenya (Baptist World Alliance), Assemblies of God. There are also Muslim mosques including Jamia Mosque.

The majority of schools follow either the Kenyan Curriculum or the British Curriculum. There is also International School of Kenya and Rosslyn Academy, both of which follow the North American Curriculum, Swedish school in N'gong, and the German school in Gigiri.

Nairobi is home to several Universities and Colleges.



Numerous other universities have also opened satellite campuses in Nairobi. The Railways Training Institute established in 1956, is also a notable institution of higher learning with a campus in Nairobi.

Major plans are being implemented in the need to decongest the city's traffic and the completion of Thika Road has given the city a much needed face-lift attributed to road's enhancement of global standards. Several projects have been completed (Syokimau Rail Station, the Eastern and Northern Bypasses) while numerous other projects are still underway. The country's head of state announced (when he opened Syokimau Rail Service) that Kenya was collaborating with other countries in the region to develop railway infrastructure to improve regional connectivity under the ambitious LAPPSET project which is the single largest and most expensive in the continent.

Kenya signed a bilateral agreement with Uganda to facilitate joint development of the Mombasa-Malaba-Kampala standard gauge railway. A branch line will also be extended to Kisumu.

Similarly, Kenya signed a Memorandum of Understanding with the Government of Ethiopia for the development of Lamu-Addis Ababa standard gauge railway. Under the Lamu-South Sudan and Ethiopia Transport Corridor Project, the development of a railway component is among the priority projects.

The development of these critical transport facilities will, besides reducing transport costs due to faster movement of goods and people within the region, also increase trade, improve the socio-economic welfare of Northern Kenya and boost the country's potential in attracting investments from all over the world.

The first phase of the standard gauge railway project was launched on 31 May 2017 by the President of Kenya Uhuru Kenyatta in a ceremony that saw thousands of Kenyans ride on the inaugural trip free of charge. The two passenger locomotives christened "Madaraka Express" operate daily trips between Nairobi and Mombasa.

Jomo Kenyatta International Airport is the largest airport in Kenya. Domestic travelers made up 40% of overall passengers in 2016. An increase of 32% in 5 yrs since 2012. JKIA had more than 7 million passengers going through it in 2016. In February 2017, JKIA received a Category One Status from the FAA boosting the airport's status as a Regional Aviation hub.

Wilson Airport is a general-aviation airport handling smaller aircraft, mostly propeller-driven. In July 2016, construction of a new air traffic control Tower commenced at a cost of KES 163 million (approximately US$1.63 million).

Eastleigh Airport is a military base airport. In its earlier years, it was utilised as a landing strip in the pre-jet airline era. It was mostly used as a British passenger and mail route from Southampton to Cape Town in the 1930s & 1940s. This route was served by flying boats between Britain and Kisumu and then by land-based aircraft on the routes to the south.

Matatus are the most common form of public transport in Nairobi.
Matatu, which literally translates to "three cents for a ride" (nowadays much more) are privately owned minibuses, and the most popular form of local transport. They generally seat fourteen to twenty-four. Matatus operate within Nairobi, its environs and suburbs and from Nairobi to other towns around the country. The matatu's route is imprinted along a yellow stripe on the side of the bus, and matatus plying specific routes have specific route numbers. However, in November 2014 President Uhuru Kenyatta lifted the ban on the yellow stripe and allowed matatus to maintain the colourful graphics in an effort to support the youth in creating employment. Matatus in Nairobi were easily distinguishable by their extravagant paint schemes, as owners would paint their matatu with various colourful decorations, such as their favourite football team or hip hop artist. More recently, some have even painted Barack Obama's face on their vehicle. They are notorious for their poor safety records, which are a result of overcrowding and reckless driving. Due to the intense competition between matatus, many are equipped with powerful sound systems and television screens to attract more customers.

However, in 2004, a law was passed requiring all matatus to include seat belts and speed governors and to be painted with a yellow stripe. At first, this caused a furore amongst Matatu operators, but they were pressured by government and the public to make the changes. Matatus are now limited to . However, many of the matatu vehicles have had their speed governors disabled, which is evident by them travelling at speeds well over .

Buses are increasingly becoming common in the city with some even going to the extents of installing complimentary WiFi systems in partnership with the leading mobile service provider. There are four major bus companies operating the city routes and are the traditional Kenya Bus Service (KBS), and newer private operators Citi Hoppa, Compliant MOA and Double M. The Citi Hoppa buses are distinguishable by their green livery, the Double M buses are painted purple, Compliant MOA by their distinctively screaming names and mix of white, blue colours while the KBS buses are painted blue.

Companies such as Easy Coach, Crown Bus, Coast Bus, Modern Coast, Eldoret Express, Chania, the Guardian Angel, Spanish and Mash Poa run scheduled buses and luxury coaches to other cities and towns.

Nairobi was founded as a railway town, and the main headquarters of Kenya Railways (KR) is still situated at Nairobi railway station, which is located near the city centre. The line runs through Nairobi, from Mombasa to Kampala. Its main use is freight traffic connecting Nairobi to Mombasa and Kisumu. A number of morning and evening commuter trains connect the centre with the suburbs, but the city has no proper light rail, tramway, or rapid transit lines. A proposal has been passed for the construction of a commuter rail line. The country's third president since independence, President Mwai Kibaki on Tuesday, 13 November 2012 launched the Syokimau Rail Service marking a major milestone in the history of railway development in the country. The opening of the station marked another milestone in efforts to realise various projects envisaged under the Vision 2030 Economic Blueprint. The new station has a train that ferries passengers from Syokimau to the city centre cutting travel time by half. Opening of the station marks the completion of the first phase of the Sh24b Nairobi Commuter Rail Network that is geared at easing traffic congestion in Nairobi, blamed for huge economic losses. Other modern stations include Imara Daima Railway Station and Makadara Railway Station.

The new Mombasa-Nairobi Standard Gauge Railway connects the port city of Mombasa and Nairobi. The new railway line has virtually replaced the old metre-gauge railway. The Nairobi Terminus is located at Syokimau, some 20 km from the city centre. Passengers travelling from Mombasa are transferred the short distance into the CBD with the metre-gauge trains.

Nairobi is served by highways that link Mombasa to Kampala in Uganda and Arusha in Tanzania. These are earmarked to ease the daily motor traffic within and surrounding the metro area. However, driving in Nairobi is chaotic. Most of the roads are tarmacked and there are signs showing directions to certain neighbourhoods. The city is connected to the Jomo Kenyatta International Airport by the Mombasa Highway, which passes through Industrial Area, South B, South C and Embakasi. Ongata Rongai, Langata and Karen are connected to the city centre by Langata Road, which runs to the south. Lavington, Riverside, and Westlands are connected by Waiyaki Way. Kasarani, Eastlands, and Embakasi are connected by Thika Road, Jogoo Road, and Outer Ring Road.

Highways connect the city with other major towns such as Mombasa, Machakos, Voi, (A109), Eldoret, Kisumu, Nakuru, Naivasha, and Namanga Border Tanzania (A104).

Nairobi is undergoing major road constructions to update its infrastructure network. The new systems of roads, flyovers, and bridges would cut outrageous traffic levels caused the inability of the current infrastructure to cope with the soaring economic growth in the past few years. It is also a major component of Kenya's Vision 2030 and Nairobi Metropolis plans. Most roads now are well lit and surfaced with adequate signage.

94% of the piped water supply for Nairobi comes from rivers and reservoirs in the Aberdare Range north of the city, of which the reservoir of the Thika Dam is the most important one. Water distribution losses – technically called non-revenue water – are 40%, and only 40% of those with house connections receive water continuously. Slum residents receive water through water kiosks and end up paying much higher water prices than those fortunate enough to have access to piped water at their residence.

There is wide variety regarding standards of living in Nairobi. Most wealthy Kenyans live in Nairobi, but the majority of Nairobians are of average and low income. Half of the population has been estimated to live in slums which cover just 5% of the city area. The growth of these slums is a result of urbanisation, poor town planning, and the unavailability of loans for low income earners.

Kibera is one of the largest slums in Africa, and is situated to the west of Nairobi. (Kibera comes from the Nubian word Kibra, meaning "forest" or "jungle"). The slums cover two square kilometres and are on government land. Kibera has been the setting for several films, the most recent being "The Constant Gardener".

Other notable slums include Mathare and Korogocho. Altogether, 66 areas are counted as slums within Nairobi.

Many Nairobi non-slum-dwellers live in relatively good housing conditions. Large houses can be found in many of the upmarket neighbourhoods, especially to the west of Nairobi. Historically, British occupiers have settled in Gigiri, Muthaiga, Langata and Karen. Other middle and high income estates include Parklands, Westlands, Hurlingham, Kilimani, Milimani, Spring Valley, Lavington, Rosslyn, Kitisuru, and Nairobi Hill.

To accommodate the growing middle class, many new apartments and housing developments are being built in and around the city. The most notable development is "Greenpark", at Athi River, Machakos County from Nairobi's Central Business District. Over 5,000 houses, villas and apartments are being constructed at this development, including leisure, retail and commercial facilities. The development is being marketed to families, as are most others within the city. Eastlands also houses most of the city's middle class and includes South C, South B, Embakasi, Buru Buru, Komarock, Donholm, Umoja, and various others.

Throughout the 2000s, Nairobi had struggled with rising crime, earning a reputation for being a dangerous city and the nickname "Nairobbery," a name which persists today. On 7 August 1998, the US Embassy was bombed, killing 224 people and injuring 4000. In 2001, the United Nations International Civil Service Commission rated Nairobi as among the most insecure cities in the world, classifying the city as "status C". In the United Nations report, it was stated that in 2001, nearly one third of all Nairobi residents experienced some form of robbery in the city. The head of one development agency cited the notoriously high levels of violent armed robberies, burglaries, and carjackings. Crime had risen in Nairobi as a result of unplanned urbanisation, with a minimal number of police stations and a proper security infrastructure. However, many claim that the biggest factor for the city's alarming crime rate is police corruption, which leaves many criminals unpunished. As a security precaution, most large houses have a watch guard, burglar grills, and dogs to patrol their grounds during the night. Most crimes, however, occur around the poor neighbourhoods where it gets dangerous during night hours.

In 2006, crime decreased in the city, due to increased security and an improved police presence. Despite this, in 2007, the Kenyan government and US State Department have announced that Nairobi is experiencing a greater level of violent crime than in previous years. Since then, the government has taken measures to combat crime with heavy police presence in and around the city while US government has updated its travel warning for the country.

Following a grenade attack in October 2011 by a local Kenyan man, with terrorist links, the city faced a heightened security presence. Fears spread over further promised retaliations by the Al-Shabaab group of rebels over Kenya's involvement in a coordinated operation with the Somalian military against the insurgent outfit.

There have been a spate of blasts in Nairobi which started on 10 March 2012, where assailants threw grenades at a busy bus station and a blue-collar bar in Nairobi, killing nine and injuring more than 50. On 28 May 2012, 28 people were injured in an explosion in a shopping complex in downtown Nairobi, near Moi avenue. On 21 September 2013, Al-Shabaab-associated militants attacked the Westgate Mall. 67 people were killed.

On January 15, 2019, five gunmen attacked the DusitD2 hotel in Nairobi's Westlands neighborhood. The attack began with a suicide bomber in the hotel lobby, and was followed by gunfire. Terror group al-Shabaab claimed responsibility for the attack that killed 21 people. The attack was unexpected, because the area that it took place in is generally understood to be a very safe area. Citizens of many countries were inside the hotel due to Nairobi being East Africa's economic hub.

Nairobi is home to most of Kenya's news and media organisations. The city is also home to the region's largest newspapers: the "Daily Nation" and "The Standard". These are circulated within Kenya and cover a range of domestic and regional issues. Both newspapers are published in English.

Kenya Broadcasting Corporation, a state-run television and radio station, is headquartered in the city. Kenya Television Network is part of the Standard Group and was Kenya's first privately owned TV station. The Nation Media Group runs NTV which is based in Nairobi. There are also a number of prominent radio stations located in Kenya's capital including KISS 100, Capital FM, East FM, Kameme FM, Metro FM, and Family FM, among others.

Several multinational media organisations have their regional headquarters in Nairobi. These include the BBC, CNN, Agence France-Presse, Reuters, Deutsche Welle, and the Associated Press. The East African bureau of CNBC Africa is located in Nairobi's city centre, while the Nairobi bureau of "The New York Times" is located in the suburb of Gigiri. The broadcast headquarters of CCTV Africa are located in Nairobi.

Nairobi has grown since 1899. A population projection in the 21st century is listed below.
Nairobi is twinned with:


</doc>
<doc id="21483" url="https://en.wikipedia.org/wiki?curid=21483" title="Numeral (linguistics)">
Numeral (linguistics)

In linguistics, a numeral (or number word) in the broadest sense is a word or phrase that describes a numerical quantity. Some theories of grammar use the word "numeral" to refer to cardinal numbers that act as a determiner to specify the quantity of a noun, for example the "two" in "two hats". Some theories of grammar do not include determiners as a part of speech and consider "two" in this example to be an adjective. Some theories consider "numeral" to be a synonym for "number" and assign all numbers (including ordinal numbers like the compound word "seventy-fifth") to a part of speech called "numerals" Numerals in the broad sense can also be analyzed as a noun ("three is a small number"), as a pronoun ("the two went to town"), or for a small number of words as an adverb ("I rode the slide twice").

Numerals can express relationships like quantity (cardinal numbers), sequence (ordinal numbers), frequency (once, twice), and part (fraction).

Numerals may be attributive, as in "two dogs", or pronominal, as in "I saw two (of them)".

Many words of different parts of speech indicate number or quantity. Such words are called quantifiers. Examples are words such as "every", "most", "least", "some", etc. Numerals are distinguished from other quantifiers by the fact that they designate a specific number. Examples are words such as "five, ten, fifty, one hundred, etc." They may or may not be treated as a distinct part of speech; this may vary, not only with the language, but with the choice of word. For example, "dozen" serves the function of a noun, "first" serves the function of an adjective, and "twice" serves the function of an adverb. In Old Church Slavonic, the cardinal numbers 5 to 10 were feminine nouns; when quantifying a noun, that noun was declined in the genitive plural like other nouns that followed a noun of quantity (one would say the equivalent of "five of people"). In English grammar, the classification ""numeral"" (viewed as a part of speech) is reserved for those words which have distinct grammatical behavior: when a numeral modifies a noun, it may replace the article: the/some dogs played in the park" → twelve dogs played in the park". (Note that *"dozen dogs played in the park" is not grammatical, so "dozen" is not a numeral in this sense.) English numerals indicate cardinal numbers. However, not all words for cardinal numbers are necessarily numerals. For example, "million" is grammatically a noun, and must be preceded by an article or numeral itself.

Numerals may be simple, such as 'eleven', or compound, such as 'twenty-three'.

In linguistics, however, numerals are classified according to purpose: examples are ordinal numbers ("first", "second", "third", etc.; from 'third' up, these are also used for fractions), multiplicative numbers ("once", "twice", and "thrice"), multipliers ("single", "double", and "triple"), and distributive numbers ("singly", "doubly", and "triply"). Georgian, Latin, and Romanian (see Romanian distributive numbers) have regular distributive numbers, such as Latin "singuli" "one-by-one", "bini" "in pairs, two-by-two", "terni" "three each", etc. In languages other than English, there may be other kinds of number words. For example, in Slavic languages there are collective numbers which describe sets, such as "pair" or "dozen" in English (see Russian numerals, Polish numerals).

Some languages have a very limited set of numerals, and in some cases they arguably do not have any numerals at all, but instead use more generic quantifiers, such as 'pair' or 'many'. However, by now most such languages have borrowed the numeral system or part of the numeral system of a national or colonial language, though in a few cases (such as Guarani ), a numeral system has been invented internally rather than borrowed. Other languages had an indigenous system but borrowed a second set of numerals anyway. An example is Japanese, which uses either native or Chinese-derived numerals depending on what is being counted.

In many languages, such as Chinese, numerals require the use of numeral classifiers. Many sign languages, such as ASL, incorporate numerals.

English has derived numerals for multiples of its base ("fifty, sixty," etc), and some languages have simplex numerals for these, or even for numbers between the multiples of its base. Balinese, for example, currently has a decimal system, with words for 10, 100, and 1000, but has additional simplex numerals for 25 (with a second word for 25 only found in a compound for 75), 35, 45, 50, 150, 175, 200 (with a second found in a compound for 1200), 400, 900, and 1600. In Hindustani, the numerals between 10 and 100 have developed to the extent that they need to be learned independently.

In many languages, numerals up to the base are a distinct part of speech, while the words for powers of the base belong to one of the other word classes. In English, these higher words are hundred 10, thousand 10, million 10, and higher powers of a thousand (short scale) or of a million (long scale—see names of large numbers). These words cannot modify a noun without being preceded by an article or numeral (*"hundred dogs played in the park"), and so are nouns.

In East Asia, the higher units are hundred, thousand, myriad 10, and powers of myriad. In India, they are hundred, thousand, lakh 10, crore 10, and so on. The Mesoamerican system, still used to some extent in Mayan languages, was based on powers of 20: "bak’" 400 (20), "pik" 8000 (20), "kalab" 160,000 (20), etc.

The cardinal numbers have numerals. In the following tables, [and] indicates that the word "and" is used in some dialects (such as British English), and omitted in other dialects (such as American English).

This table demonstrates the standard English construction of some cardinal numbers. (See next table for names of larger cardinals.)

This table compares the English names of cardinal numbers according to various American, British, and Continental European conventions. See English numerals or names of large numbers for more information on naming numbers.

There is no consistent and widely accepted way to extend cardinals beyond centillion (centilliard).

The following table details the myriad, octad, chinese myriad, Chinese long and -yllion names for powers of 10.

There is also a Knuth-proposed system notation of numbers, named the -yllion system. For instance, in this system, 10 would be represented as 1'0000,0000;0000,0000:0000,0000;0000,0000. 

This is a table of English names for non-negative rational numbers less than or equal to 1. It also lists alternative names, but there is no widespread convention for the names of extremely small positive numbers.

Keep in mind that rational numbers like 0.12 can be represented in infinitely many ways, e.g. "zero-point-one-two" (0.12), "twelve percent" (12%), "three twenty-fifths" (), "nine seventy-fifths" (), "six fiftieths" (), "twelve hundredths" (), "twenty-four two-hundredths" (), etc.
Various terms have arisen to describe commonly used measured quantities.

Not all peoples count, at least not verbally. Specifically, there is not much need for counting among hunter-gatherers who do not engage in commerce. Many languages around the world have no numerals above two to four (if they're actually numerals at all, and not some other part of speech)—or at least did not before contact with the colonial societies—and speakers of these languages may have no tradition of using the numerals they did have for counting. Indeed, several languages from the Amazon have been independently reported to have no specific number words other than 'one'. These include Nadëb, pre-contact Mocoví and Pilagá, Culina and pre-contact Jarawara, Jabutí, Canela-Krahô, Botocudo (Krenák), Chiquitano, the Campa languages, Arabela, and Achuar. Some languages of Australia, such as Warlpiri, do not have words for quantities above two, as did many Khoisan languages at the time of European contact. Such languages do not have a word class of 'numeral'.

Most languages with both numerals and counting use base 8, 10, 12, or 20. Base 10 appears to come from counting one's fingers, base 20 from the fingers and toes, base 8 from counting the spaces between the fingers (attested in California), and base 12 from counting the knuckles (3 each for the four fingers).

Many languages of Melanesia have (or once had) counting systems based on parts of the body which do not have a numeric base; there are (or were) no numerals, but rather nouns for relevant parts of the body—or simply pointing to the relevant spots—were used for quantities. For example, 1–4 may be the fingers, 5 'thumb', 6 'wrist', 7 'elbow', 8 'shoulder', etc., across the body and down the other arm, so that the opposite little finger represents a number between 17 (Torres Islands) to 23 (Eleman). For numbers beyond this, the torso, legs and toes may be used, or one might count back up the other arm and back down the first, depending on the people.

Binary systems are base 2, often using zeros and ones. With only two symbols binary is useful for logical systems like computers.

Base 3 counting has practical usage in some analog logic, in baseball scoring and in self–similar mathematical structures.

Some Austronesian and Melanesian ethnic groups, some Sulawesi and some Papua New Guineans, count with the base number four, using the term "asu" and "aso", the word for dog, as the ubiquitous village dog has four legs. This is argued by anthropologists to be also based on early humans noting the human and animal shared body feature of two arms and two legs as well as its ease in simple arithmetic and counting. As an example of the system's ease a realistic scenario could include a farmer returning from the market with fifty "asu" heads of pig (200), less 30 "asu" (120) of pig bartered for 10 "asu" (40) of goats noting his new pig count total as twenty "asu": 80 pigs remaining. The system has a correlation to the dozen counting system and is still in common use in these areas as a natural and easy method of simple arithmetic.

Quinary systems are based on the number 5. It is almost certain the quinary system developed from counting by fingers (five fingers per hand). An example are the Epi languages of Vanuatu, where 5 is "luna" 'hand', 10 "lua-luna" 'two hand', 15 "tolu-luna" 'three hand', etc. 11 is then "lua-luna tai" 'two-hand one', and 17 "tolu-luna lua" 'three-hand two'.

5 is a common "auxiliary base", or "sub-base", where 6 is 'five and one', 7 'five and two', etc. Aztec was a vigesimal (base-20) system with sub-base 5.

The Morehead-Maro languages of Southern New Guinea are examples of the rare base 6 system with monomorphemic words running up to 6. Examples are Kanum and Kómnzo. The Sko languages on the North Coast of New Guinea follow a base-24 system with a sub-base of 6.

Septenary systems are very rare, as few natural objects consistently have seven distinctive features. Traditionally, it occurs in week-related timing. It has been suggested that the Palikur language has a base-seven system, but this is dubious.

Octal counting systems are based on the number 8. Examples can be found in the Yuki language of California and in the Pamean languages of Mexico, because the Yuki and Pame keep count by using the four spaces between their fingers rather than the fingers themselves.

It has been suggested that Nenets has a base-nine system.

A majority of traditional number systems are decimal. This dates back at least to the ancient Egyptians, who used a wholly decimal system. Anthropologists hypothesize this may be due to humans having five digits per hand, ten in total. There are many regional variations including:


Duodecimal systems are based on 12.

These include:


Duodecimal numeric systems have some practical advantages over decimal. It is much easier to divide the base digit twelve (which is a highly composite number) by many important divisors in market and trade settings, such as the numbers 2, 3, 4 and 6.

Because of several measurements based on twelve, many Western languages have words for base-twelve units such as "dozen", "gross" and "great gross", which allow for rudimentary duodecimal nomenclature, such as "two gross six dozen" for 360. Ancient Romans used a decimal system for integers, but switched to duodecimal for fractions, and correspondingly Latin developed a rich vocabulary for duodecimal-based fractions (see Roman numerals). A notable fictional duodecimal system was that of J. R. R. Tolkien's Elvish languages, which used duodecimal as well as decimal.

Hexadecimal systems are based on 16.

The traditional Chinese units of measurement were base-16. For example, one jīn (斤) in the old system equals sixteen taels. The suanpan (Chinese abacus) can be used to perform hexadecimal calculations such as additions and subtractions.

South Asian monetary systems were base-16. One rupee in Pakistan and India was divided into 16 annay. A single anna was subdivided into four paisa or twelve pies (thus there were 64 paise or 192 pies in a rupee). The anna was demonetised as a currency unit when India decimalised its currency in 1957, followed by Pakistan in 1961.

Vigesimal numbers use the number 20 as the base number for counting. Anthropologists are convinced the system originated from digit counting, as did bases five and ten, twenty being the number of human fingers and toes combined.
The system is in widespread use across the world. Some include the classical Mesoamerican cultures, still in use today in the modern indigenous languages of their descendants, namely the Nahuatl and Mayan languages (see Maya numerals). A modern national language which uses a full vigesimal system is Dzongkha in Bhutan.

Partial vigesimal systems are found in some European languages: Basque, Celtic languages, French (from Celtic), Danish, and Georgian. In these languages the systems are vigesimal up to 99, then decimal from 100 up. That is, 140 is 'one hundred two score', not *seven score, and there is no numeral for 400.

The term "score" originates from tally sticks, and is perhaps a remnant of Celtic vigesimal counting. It was widely used to learn the pre-decimal British currency in this idiom: "a dozen pence and a score of bob", referring to the 20 shillings in a pound. For Americans the term is most known from the opening of the Gettysburg Address: ""Four score and seven years ago our fathers..."".

The Sko languages have a base-24 system with a sub-base of 6.

Ngiti has base 32.

Ekari has a base-60 system. Sumeria had a base-60 system with a decimal sub-base (perhaps a conflation of the decimal and a duodecimal systems of its constituent peoples), which was the origin of the numbering of modern degrees, minutes, and seconds.

Supyire is said to have a base-80 system; it counts in twenties (with 5 and 10 as sub-bases) up to 80, then by eighties up to 400, and then by 400s (great scores).
799 [i.e. 400 + (4 x 80) + (3 x 20) + {10 + (5 + 4)}]’

A database Numeral Systems of the World's Languages compiled by Eugene S.L. Chan of Hong Kong is hosted by the Max Planck Institute for Evolutionary Anthropology in Leipzig, Germany. The database currently contains data for about 4000 languages.




</doc>
<doc id="21485" url="https://en.wikipedia.org/wiki?curid=21485" title="Neutrino">
Neutrino

A neutrino ( or ) (denoted by the Greek letter ) is a fermion (an elementary particle with spin of) that interacts only via the weak subatomic force and gravity. The neutrino is so named because it is electrically neutral and because its rest mass is so small ("-ino") that it was long thought to be zero. The mass of the neutrino is much smaller than that of the other known elementary particles. The weak force has a very short range, the gravitational interaction is extremely weak, and neutrinos do not participate in the strong interaction. Thus, neutrinos typically pass through normal matter unimpeded and undetected.

Weak interactions create neutrinos in one of three leptonic flavors: electron neutrinos muon neutrinos (), or tau neutrinos (), in association with the corresponding charged lepton. Although neutrinos were long believed to be massless, it is now known that there are three discrete neutrino masses with different tiny values, but they do not correspond uniquely to the three flavors. A neutrino created with a specific flavor has an associated specific quantum superposition of all three mass states. As a result, neutrinos oscillate between different flavors in flight. For example, an electron neutrino produced in a beta decay reaction may interact in a distant detector as a muon or tau neutrino. Although only differences between squares of the three mass values are known as of 2019, cosmological observations imply that the sum of the three masses must be less than one millionth that of the electron.

For each neutrino, there also exists a corresponding antiparticle, called an "antineutrino", which also has spin of and no electric charge. Antineutrinos are distinguished from the neutrinos by having opposite signs of lepton number and right-handed instead of left-handed chirality. To conserve total lepton number (in nuclear beta decay), electron neutrinos only appear together with positrons (anti-electrons) or electron-antineutrinos, whereas electron antineutrinos only appear with electrons or electron neutrinos.

Neutrinos are created by various radioactive decays; the following list is not exhaustive, but includes some of those processes:

The majority of neutrinos which are detected about the Earth are from nuclear reactions inside the Sun. At the surface of the Earth, the flux is about 65 billion () solar neutrinos, per second per square centimeter. Neutrinos can be used for tomography of the interior of the earth.

Research is intense in the hunt to elucidate the essential nature of neutrinos, with aspirations of finding:

The neutrino was postulated first by Wolfgang Pauli in 1930 to explain how beta decay could conserve energy, momentum, and angular momentum (spin). In contrast to Niels Bohr, who proposed a statistical version of the conservation laws to explain the observed continuous energy spectra in beta decay, Pauli hypothesized an undetected particle that he called a "neutron", using the same "-on" ending employed for naming both the proton and the electron. He considered that the new particle was emitted from the nucleus together with the electron or beta particle in the process of beta decay.

James Chadwick discovered a much more massive neutral nuclear particle in 1932 and named it a neutron also, leaving two kinds of particles with the same name. Earlier (in 1930) Pauli had used the term "neutron" for both the neutral particle that conserved energy in beta decay, and a presumed neutral particle in the nucleus; initially he did not consider these two neutral particles as distinct from each other. The word "neutrino" entered the scientific vocabulary through Enrico Fermi, who used it during a conference in Paris in July 1932 and at the Solvay Conference in October 1933, where Pauli also employed it. The name (the Italian equivalent of "little neutral one") was jokingly coined by Edoardo Amaldi during a conversation with Fermi at the Institute of Physics of via Panisperna in Rome, in order to distinguish this light neutral particle from Chadwick's heavy neutron.

In Fermi's theory of beta decay, Chadwick's large neutral particle could decay to a proton, electron, and the smaller neutral particle (now called an "electron antineutrino"):

Fermi's paper, written in 1934, unified Pauli's neutrino with Paul Dirac's positron and Werner Heisenberg's neutron–proton model and gave a solid theoretical basis for future experimental work. The journal "Nature" rejected Fermi's paper, saying that the theory was "too remote from reality". He submitted the paper to an Italian journal, which accepted it, but the general lack of interest in his theory at that early date caused him to switch to experimental physics.

By 1934, there was experimental evidence against Bohr's idea that energy conservation is invalid for beta decay: At the Solvay conference of that year, measurements of the energy spectra of beta particles (electrons) were reported, showing that there is a strict limit on the energy of electrons from each type of beta decay. Such a limit is not expected if the conservation of energy is invalid, in which case any amount of energy would be statistically available in at least a few decays. The natural explanation of the beta decay spectrum as first measured in 1934 was that only a limited (and conserved) amount of energy was available, and a new particle was sometimes taking a varying fraction of this limited energy, leaving the rest for the beta particle. Pauli made use of the occasion to publicly emphasize that the still-undetected "neutrino" must be an actual particle.

In 1942, Wang Ganchang first proposed the use of beta capture to experimentally detect neutrinos. In the 20 July 1956 issue of "Science", Clyde Cowan, Frederick Reines, F. B. Harrison, H. W. Kruse, and A. D. McGuire published confirmation that they had detected the neutrino, a result that was rewarded almost forty years later with the 1995 Nobel Prize.

In this experiment, now known as the Cowan–Reines neutrino experiment, antineutrinos created in a nuclear reactor by beta decay reacted with protons to produce neutrons and positrons:

The positron quickly finds an electron, and they annihilate each other. The two resulting gamma rays (γ) are detectable. The neutron can be detected by its capture on an appropriate nucleus, releasing a gamma ray. The coincidence of both events – positron annihilation and neutron capture – gives a unique signature of an antineutrino interaction.

In February 1965, the first neutrino found in nature was identified in one of South Africa's gold mines by a group which included Friedel Sellschop. The experiment was performed in a specially prepared chamber at a depth of 3 km in the ERPM mine near Boksburg. A plaque in the main building commemorates the discovery. The experiments also implemented a primitive neutrino astronomy and looked at issues of neutrino physics and weak interactions.

The antineutrino discovered by Cowan and Reines is the antiparticle of the electron neutrino.

In 1962, Leon M. Lederman, Melvin Schwartz and Jack Steinberger showed that more than one type of neutrino exists by first detecting interactions of the muon neutrino (already hypothesised with the name "neutretto"), which earned them the 1988 Nobel Prize in Physics.

When the third type of lepton, the tau, was discovered in 1975 at the Stanford Linear Accelerator Center, it was also expected to have an associated neutrino (the tau neutrino). First evidence for this third neutrino type came from the observation of missing energy and momentum in tau decays analogous to the beta decay leading to the discovery of the electron neutrino. The first detection of tau neutrino interactions was announced in 2000 by the DONUT collaboration at Fermilab; its existence had already been inferred by both theoretical consistency and experimental data from the Large Electron–Positron Collider.

In the 1960s, the now-famous Homestake experiment made the first measurement of the flux of electron neutrinos arriving from the core of the Sun and found a value that was between one third and one half the number predicted by the Standard Solar Model. This discrepancy, which became known as the solar neutrino problem, remained unresolved for some thirty years, while possible problems with both the experiment and the solar model were investigated, but none could be found. Eventually it was realized that both were actually correct, and that the discrepancy between them was due to neutrinos being more complex than was previously assumed. It was postulated that the three neutrinos had nonzero and slightly different masses, and could therefore oscillate into undetectable flavors on their flight to the Earth. This hypothesis was investigated by a new series of experiments, thereby opening a new major field of research that still continues. Eventual confirmation of the phenomenon of neutrino oscillation led to two Nobel prizes, to Raymond Davis, Jr., who conceived and led the Homestake experiment, and to Art McDonald, who led the SNO experiment, which could detect all of the neutrino flavors and found no deficit.

A practical method for investigating neutrino oscillations was first suggested by Bruno Pontecorvo in 1957 using an analogy with kaon oscillations; over the subsequent 10 years he developed the mathematical formalism and the modern formulation of vacuum oscillations. In 1985 Stanislav Mikheyev and Alexei Smirnov (expanding on 1978 work by Lincoln Wolfenstein) noted that flavor oscillations can be modified when neutrinos propagate through matter. This so-called Mikheyev–Smirnov–Wolfenstein effect (MSW effect) is important to understand because many neutrinos emitted by fusion in the Sun pass through the dense matter in the solar core (where essentially all solar fusion takes place) on their way to detectors on Earth.

Starting in 1998, experiments began to show that solar and atmospheric neutrinos change flavors (see Super-Kamiokande and Sudbury Neutrino Observatory). This resolved the solar neutrino problem: the electron neutrinos produced in the Sun had partly changed into other flavors which the experiments could not detect.

Although individual experiments, such as the set of solar neutrino experiments, are consistent with non-oscillatory mechanisms of neutrino flavor conversion, taken altogether, neutrino experiments imply the existence of neutrino oscillations. Especially relevant in this context are the reactor experiment KamLAND and the accelerator experiments such as MINOS. The KamLAND experiment has indeed identified oscillations as the neutrino flavor conversion mechanism involved in the solar electron neutrinos. Similarly MINOS confirms the oscillation of atmospheric neutrinos and gives a better determination of the mass squared splitting. Takaaki Kajita of Japan, and Arthur B. McDonald of Canada, received the 2015 Nobel Prize for Physics for their landmark finding, theoretical and experimental, that neutrinos can change flavors.

Raymond Davis, Jr. and Masatoshi Koshiba were jointly awarded the 2002 Nobel Prize in Physics. Both conducted pioneering work on solar neutrino detection, and Koshiba's work also resulted in the first real-time observation of neutrinos from the SN 1987A supernova in the nearby Large Magellanic Cloud. These efforts marked the beginning of neutrino astronomy.

SN 1987A represents the only verified detection of neutrinos from a supernova. However, many stars have gone supernova in the universe, leaving a theorized diffuse supernova neutrino background.

Neutrinos have half-integer spin (½ ); therefore they are fermions. Neutrinos are leptons. They have only been observed to interact through the weak force, although it is assumed that they also interact gravitationally.

Weak interactions create neutrinos in one of three leptonic flavors: electron neutrinos (), muon neutrinos (), or tau neutrinos (), associated with the corresponding charged leptons, the electron (), muon (), and tau (), respectively.

Although neutrinos were long believed to be massless, it is now known that there are three discrete neutrino masses; each neutrino flavor state is a linear combination of the three discrete mass eigenstates. Although only differences of squares of the three mass values are known as of 2016, experiments have shown that these masses are tiny in magnitude. From cosmological measurements, it has been calculated that the sum of the three neutrino masses must be less than one millionth that of the electron.

More formally, neutrino flavor eigenstates (creation and annihilation combinations) are not the same as the neutrino mass eigenstates (simply labelled “1”, “2”, and “3”). As of 2016, it is not known which of these three is the heaviest. In analogy with the mass hierarchy of the charged leptons, the configuration with mass 2 being lighter than mass 3 is conventionally called the “normal hierarchy”, while in the “inverted hierarchy”, the opposite would hold. Several major experimental efforts are underway to help establish which is correct.

A neutrino created in a specific flavor eigenstate is in an associated specific quantum superposition of all three mass eigenstates. This is possible because the three masses differ so little that they cannot be experimentally distinguished within any practical flight path, due to the uncertainty principle. The proportion of each mass state in the produced pure flavor state has been found to depend profoundly on that flavor. The relationship between flavor and mass eigenstates is encoded in the PMNS matrix. Experiments have established values for the elements of this matrix.

A non-zero mass allows neutrinos to possibly have a tiny magnetic moment; if so, neutrinos would interact electromagnetically, although no such interaction has ever been observed.

Neutrinos oscillate between different flavors in flight. For example, an electron neutrino produced in a beta decay reaction may interact in a distant detector as a muon or tau neutrino, as defined by the flavor of the charged lepton produced in the detector. This oscillation occurs because the three mass state components of the produced flavor travel at slightly different speeds, so that their quantum mechanical wave packets develop relative phase shifts that change how they combine to produce a varying superposition of three flavors. Each flavor component thereby oscillates as the neutrino travels, with the flavors varying in relative strengths. The relative flavor proportions when the neutrino interacts represent the relative probabilities for that flavor of interaction to produce the corresponding flavor of charged lepton.

There are other possibilities in which neutrino could oscillate even if they were massless: If Lorentz symmetry were not an exact symmetry, neutrinos could experience Lorentz-violating oscillations.

Neutrinos traveling through matter, in general, undergo a process analogous to light traveling through a transparent material. This process is not directly observable because it does not produce ionizing radiation, but gives rise to the MSW effect. Only a small fraction of the neutrino's energy is transferred to the material.

For each neutrino, there also exists a corresponding antiparticle, called an "antineutrino", which also has no electric charge and half-integer spin. They are distinguished from the neutrinos by having opposite signs of lepton number and opposite chirality. As of 2016, no evidence has been found for any other difference. In all observations so far of leptonic processes (despite extensive and continuing searches for exceptions), there is never any change in overall lepton number; for example, if total lepton number is zero in the initial state, electron neutrinos appear in the final state together with only positrons (anti-electrons) or electron-antineutrinos, and electron antineutrinos with electrons or electron neutrinos.

Antineutrinos are produced in nuclear beta decay together with a beta particle, in which, e.g., a neutron decays into a proton, electron, and antineutrino. All antineutrinos observed thus far possess right-handed helicity (i.e. only one of the two possible spin states has ever been seen), while neutrinos are left-handed. Nevertheless, as neutrinos have mass, their helicity is frame-dependent, so it is the related frame-independent property of chirality that is relevant here.

Antineutrinos were first detected as a result of their interaction with protons in a large tank of water. This was installed next to a nuclear reactor as a controllable source of the antineutrinos (See: Cowan–Reines neutrino experiment).
Researchers around the world have begun to investigate the possibility of using antineutrinos for reactor monitoring in the context of preventing the proliferation of nuclear weapons.

Because antineutrinos and neutrinos are neutral particles, it is possible that they are the same particle. Particles that have this property are known as Majorana particles, named after the Italian physicist Ettore Majorana who first proposed the concept. For the case of neutrinos this theory has gained popularity as it can be used, in combination with the seesaw mechanism, to explain why neutrino masses are so small compared to those of the other elementary particles, such as electrons or quarks. Majorana neutrinos would have the property that the neutrino and antineutrino could be distinguished only by chirality; what experiments observe as a difference between the neutrino and antineutrino could simply be due to one particle with two possible chiralities.

, it is not known whether neutrinos are Majorana or Dirac particles. It is possible to test this property experimentally. For example, if neutrinos are indeed Majorana particles, then lepton-number violating processes such as neutrinoless double beta decay would be allowed, while they would not if neutrinos are Dirac particles. Several experiments have been and are being conducted to search for this process, e.g. GERDA, EXO, and SNO+. The cosmic neutrino background is also a probe of whether neutrinos are Majorana particles, since there should be a different number of cosmic neutrinos detected in either the Dirac or Majorana case.

Neutrinos can interact with a nucleus, changing it to another nucleus. This process is used in radiochemical neutrino detectors. In this case, the energy levels and spin states within the target nucleus have to be taken into account to estimate the probability for an interaction. In general the interaction probability increases with the number of neutrons and protons within a nucleus.

It is very hard to uniquely identify neutrino interactions among the natural background of radioactivity. For this reason, in early experiments a special reaction channel was chosen to facilitate the identification: the interaction of an antineutrino with one of the hydrogen nuclei in the water molecules. A hydrogen nucleus is a single proton, so simultaneous nuclear interactions, which would occur within a heavier nucleus, don't need to be considered for the detection experiment. Within a cubic metre of water placed right outside a nuclear reactor, only relatively few such interactions can be recorded, but the setup is now used for measuring the reactor's plutonium production rate.

Very much like neutrons do in nuclear reactors, neutrinos can induce fission reactions within heavy nuclei. So far, this reaction has not been measured in a laboratory, but is predicted to happen within stars and supernovae. The process affects the abundance of isotopes seen in the universe. Neutrino fission of deuterium nuclei has been observed in the Sudbury Neutrino Observatory, which uses a heavy water detector.

There are three known types ("flavors") of neutrinos: electron neutrino , muon neutrino , and tau neutrino , named after their partner leptons in the Standard Model (see table at right). The current best measurement of the number of neutrino types comes from observing the decay of the boson. This particle can decay into any light neutrino and its antineutrino, and the more available types of light neutrinos, the shorter the lifetime of the  boson. Measurements of the lifetime have shown that three light neutrino flavors couple to the . The correspondence between the six quarks in the Standard Model and the six leptons, among them the three neutrinos, suggests to physicists' intuition that there should be exactly three types of neutrino.

There are several active research areas involving the neutrino. Some are concerned with testing predictions of neutrino behavior. Other research is focused on measurement of unknown properties of neutrinos; there is special interest in experiments that determine their masses and rates of CP violation, which cannot be predicted from current theory.

International scientific collaborations install large neutrino detectors near nuclear reactors or in neutrino beams from particle accelerators to better constrain the neutrino masses and the values for the magnitude and rates of oscillations between neutrino flavors. These experiments are thereby searching for the existence of CP violation in the neutrino sector; that is, whether or not the laws of physics treat neutrinos and antineutrinos differently.

The KATRIN experiment in Germany began to acquire data in June 2018 to determine the value of the mass of the electron neutrino, with other approaches to this problem in the planning stages.

Despite their tiny masses, neutrinos are so numerous that their gravitational force can influence other matter in the universe.

The three known neutrino flavors are the only established elementary particle candidates for dark matter, specifically hot dark matter, although the conventional neutrinos seem to be essentially ruled out as substantial proportion of dark matter based on observations of the cosmic microwave background. It still seems plausible that heavier, sterile neutrinos might compose warm dark matter, if they exist.

Other efforts search for evidence of a sterile neutrino – a fourth neutrino flavor that does not interact with matter like the three known neutrino flavors. The possibility of "sterile" neutrinos is unaffected by the Z boson decay measurements described above: If their mass is greater than half the Z boson's mass, they could not be a decay product. Therefore, heavy sterile neutrinos would have a mass of at least 45.6 GeV.

The existence of such particles is in fact hinted by experimental data from the LSND experiment. On the other hand, the currently running MiniBooNE experiment suggested that sterile neutrinos are not required to explain the experimental data, although the latest research into this area is on-going and anomalies in the MiniBooNE data may allow for exotic neutrino types, including sterile neutrinos. A recent re-analysis of reference electron spectra data from the Institut Laue-Langevin has also hinted at a fourth, sterile neutrino.

According to an analysis published in 2010, data from the Wilkinson Microwave Anisotropy Probe of the cosmic background radiation is compatible with either three or four types of neutrinos.

Another hypothesis concerns "neutrinoless double-beta decay", which, if it exists, would violate lepton number conservation. Searches for this mechanism are underway but have not yet found evidence for it. If they were to, then what are now called antineutrinos could not be true antiparticles.

Cosmic ray neutrino experiments detect neutrinos from space to study both the nature of neutrinos and the cosmic sources producing them.

Before neutrinos were found to oscillate, they were generally assumed to be massless, propagating at the speed of light. According to the theory of special relativity, the question of neutrino velocity is closely related to their mass: If neutrinos are massless, they must travel at the speed of light, and if they have mass they cannot reach the speed of light. Due to their tiny mass, the predicted speed is extremely close to the speed of light in all experiments, and current detectors are not sensitive to the expected difference.

Also some Lorentz-violating variants of quantum gravity might allow faster-than-light neutrinos. A comprehensive framework for Lorentz violations is the Standard-Model Extension (SME).

The first measurements of neutrino speed were made in the early 1980s using pulsed pion beams (produced by pulsed proton beams hitting a target). The pions decayed producing neutrinos, and the neutrino interactions observed within a time window in a detector at a distance were consistent with the speed of light. This measurement was repeated in 2007 using the MINOS detectors, which found the speed of neutrinos to be, at the 99% confidence level, in the range between and . The central value of is higher than the speed of light but, with uncertainty taken into account, is also consistent with a velocity of exactly "c" or slightly less. This measurement set an upper bound on the mass of the muon neutrino at with 99% confidence. After the detectors for the project were upgraded in 2012, MINOS refined their initial result and found agreement with the speed of light, with the difference in the arrival time of neutrinos and light of −0.0006% (±0.0012%).

A similar observation was made, on a much larger scale, with supernova 1987A (SN 1987A). 10 MeV antineutrinos from the supernova were detected within a time window that was consistent with the speed of light for the neutrinos. So far, all measurements of neutrino speed have been consistent with the speed of light.

In September 2011, the OPERA collaboration released calculations showing velocities of 17 GeV and 28 GeV neutrinos exceeding the speed of light in their experiments. In November 2011, OPERA repeated its experiment with changes so that the speed could be determined individually for each detected neutrino. The results showed the same faster-than-light speed. In February 2012, reports came out that the results may have been caused by a loose fiber optic cable attached to one of the atomic clocks which measured the departure and arrival times of the neutrinos. An independent recreation of the experiment in the same laboratory by ICARUS found no discernible difference between the speed of a neutrino and the speed of light.

In June 2012, CERN announced that new measurements conducted by all four Gran Sasso experiments (OPERA, ICARUS, Borexino and LVD) found agreement between the speed of light and the speed of neutrinos, finally refuting the initial OPERA claim.

The Standard Model of particle physics assumed that neutrinos are massless. The experimentally established phenomenon of neutrino oscillation, which mixes neutrino flavour states with neutrino mass states (analogously to CKM mixing), requires neutrinos to have nonzero masses. Massive neutrinos were originally conceived by Bruno Pontecorvo in the 1950s. Enhancing the basic framework to accommodate their mass is straightforward by adding a right-handed Lagrangian.

Providing for neutrino mass can be done in two ways, and some proposals use both:

The strongest upper limit on the masses of neutrinos comes from cosmology: the Big Bang model predicts that there is a fixed ratio between the number of neutrinos and the number of photons in the cosmic microwave background. If the total energy of all three types of neutrinos exceeded an average of per neutrino, there would be so much mass in the universe that it would collapse. This limit can be circumvented by assuming that the neutrino is unstable, but there are limits within the Standard Model that make this difficult. A much more stringent constraint comes from a careful analysis of cosmological data, such as the cosmic microwave background radiation, galaxy surveys, and the Lyman-alpha forest. These indicate that the summed masses of the three neutrinos must be less than .

The Nobel prize in Physics 2015 was awarded to Takaaki Kajita and Arthur B. McDonald for their experimental discovery of neutrino oscillations, which demonstrates that neutrinos have mass.

In 1998, research results at the Super-Kamiokande neutrino detector determined that neutrinos can oscillate from one flavor to another, which requires that they must have a nonzero mass. While this shows that neutrinos have mass, the absolute neutrino mass scale is still not known. This is because neutrino oscillations are sensitive only to the difference in the squares of the masses. The best estimate of the difference in the squares of the masses of mass eigenstates 1 and 2 was published by KamLAND in 2005: |Δ"m"| = . In 2006, the MINOS experiment measured oscillations from an intense muon neutrino beam, determining the difference in the squares of the masses between neutrino mass eigenstates 2 and 3. The initial results indicate |Δ"m"| = 0.0027 eV, consistent with previous results from Super-Kamiokande. Since |Δ"m"| is the difference of two squared masses, at least one of them has to have a value which is at least the square root of this value. Thus, there exists at least one neutrino mass eigenstate with a mass of at least .

In 2009, lensing data of a galaxy cluster were analyzed to predict a neutrino mass of about . This surprisingly high value requires that the three neutrino masses be nearly equal, with neutrino oscillations on the order of milli-electron-volts. In 2016 this was updated to a mass of . It predicts 3 sterile neutrinos of the same mass, stems with the Planck dark matter fraction and the non-observation of neutrinoless double beta decay. The masses lie below the Mainz-Troitsk upper bound of for the electron antineutrino. The latter is being tested since June 2018 in the KATRIN experiment, that searches for a mass between and .

A number of efforts are under way to directly determine the absolute neutrino mass scale in laboratory experiments. The methods applied involve nuclear beta decay (KATRIN and MARE).

On 31 May 2010, OPERA researchers observed the first tau neutrino candidate event in a muon neutrino beam, the first time this transformation in neutrinos had been observed, providing further evidence that they have mass.

In July 2010, the 3-D MegaZ DR7 galaxy survey reported that they had measured a limit of the combined mass of the three neutrino varieties to be less than . A tighter upper bound yet for this sum of masses, , was reported in March 2013 by the Planck collaboration, whereas a February 2014 result estimates the sum as 0.320 ± 0.081 eV based on discrepancies between the cosmological consequences implied by Planck's detailed measurements of the cosmic microwave background and predictions arising from observing other phenomena, combined with the assumption that neutrinos are responsible for the observed weaker gravitational lensing than would be expected from massless neutrinos.

If the neutrino is a Majorana particle, the mass may be calculated by finding the half-life of neutrinoless double-beta decay of certain nuclei. The current lowest upper limit on the Majorana mass of the neutrino has been set by KamLAND-Zen: 0.060–0.161 eV.

Standard Model neutrinos are fundamental point-like particles, without any width or volume. Since the neutrino is an elementary particle it does not have a size in the same sense as everyday objects. Properties associated with conventional "size" are absent: There is no minimum distance between them, and neutrinos cannot be condensed into a separate uniform substance that occupies a finite volume.

Experimental results show that within the margin of error, all produced and observed neutrinos have left-handed helicities (spins antiparallel to momenta), and all antineutrinos have right-handed helicities. In the massless limit, that means that only one of two possible chiralities is observed for either particle. These are the only chiralities included in the Standard Model of particle interactions.

It is possible that their counterparts (right-handed neutrinos and left-handed antineutrinos) simply do not exist. If they do, their properties are substantially different from observable neutrinos and antineutrinos. It is theorized that they are either very heavy (on the order of GUT scale—see "Seesaw mechanism"), do not participate in weak interaction (so-called "sterile neutrinos"), or both.

The existence of nonzero neutrino masses somewhat complicates the situation. Neutrinos are produced in weak interactions as chirality eigenstates. Chirality of a massive particle is not a constant of motion; helicity is, but the chirality operator does not share eigenstates with the helicity operator. Free neutrinos propagate as mixtures of left- and right-handed helicity states, with mixing amplitudes on the order of . This does not significantly affect the experiments, because neutrinos involved are nearly always ultrarelativistic, and thus mixing amplitudes are vanishingly small. Effectively, they travel so quickly and time passes so slowly in their rest-frames that they do not have enough time to change over any observable path. For example, most solar neutrinos have energies on the order of –, so the fraction of neutrinos with "wrong" helicity among them cannot exceed .

An unexpected series of experimental results for the rate of decay of heavy highly charged radioactive ions circulating in a storage ring has provoked theoretical activity in an effort to find a convincing explanation. The rates of weak decay of two radioactive species with half lives of about 40 seconds and 200 seconds are found to have a significant oscillatory modulation, with a period of about 7 seconds.
The observed phenomenon is known as the GSI anomaly, as the storage ring is a facility at the GSI Helmholtz Centre for Heavy Ion Research in Darmstadt Germany. As the decay process produces an electron neutrino, some of the proposed explanations for the observed oscillation rate invoke neutrino properties. Initial ideas related to flavour oscillation were met with skepticism. A more recent proposal involves mass differences between neutrino mass eigenstates.

Nuclear reactors are the major source of human-generated neutrinos. The majority of energy in a nuclear reactor is generated by fission (the four main fissile isotopes in nuclear reactors are , , and ), the resultant neutron-rich daughter nuclides rapidly undergo additional beta decays, each converting one neutron to a proton and an electron and releasing an electron antineutrino (). Including these subsequent decays, the average nuclear fission releases about of energy, of which roughly 95.5% is retained in the core as heat, and roughly 4.5% (or about ) is radiated away as antineutrinos. For a typical nuclear reactor with a thermal power of , the total power production from fissioning atoms is actually , of which is radiated away as antineutrino radiation and never appears in the engineering. This is to say, of fission energy is "lost" from this reactor and does not appear as heat available to run turbines, since antineutrinos penetrate all building materials practically without interaction.

The antineutrino energy spectrum depends on the degree to which the fuel is burned (plutonium-239 fission antineutrinos on average have slightly more energy than those from uranium-235 fission), but in general, the "detectable" antineutrinos from fission have a peak energy between about 3.5 and , with a maximum energy of about . There is no established experimental method to measure the flux of low-energy antineutrinos. Only antineutrinos with an energy above threshold of can trigger inverse beta decay and thus be unambiguously identified (see below). An estimated 3% of all antineutrinos from a nuclear reactor carry an energy above this threshold. Thus, an average nuclear power plant may generate over antineutrinos per second above this threshold, but also a much larger number ( this number) below the energy threshold, which cannot be seen with present detector technology.

Some particle accelerators have been used to make neutrino beams. The technique is to collide protons with a fixed target, producing charged pions or kaons. These unstable particles are then magnetically focused into a long tunnel where they decay while in flight. Because of the relativistic boost of the decaying particle, the neutrinos are produced as a beam rather than isotropically. Efforts to design an accelerator facility where neutrinos are produced through muon decays are ongoing. Such a setup is generally known as a "neutrino factory".

Nuclear weapons also produce very large quantities of neutrinos. Fred Reines and Clyde Cowan considered the detection of neutrinos from a bomb prior to their search for reactor neutrinos; a fission reactor was recommended as a better alternative by Los Alamos physics division leader J.M.B. Kellogg. Fission weapons produce antineutrinos (from the fission process), and fusion weapons produce both neutrinos (from the fusion process) and antineutrinos (from the initiating fission explosion).

Neutrinos are produced together with the natural background radiation. In particular, the decay chains of and isotopes, as well as, include beta decays which emit antineutrinos. These so-called geoneutrinos can provide valuable information on the Earth's interior. A first indication for geoneutrinos was found by the KamLAND experiment in 2005, updated results have been presented by KamLAND and Borexino. The main background in the geoneutrino measurements are the antineutrinos coming from reactors.
Atmospheric neutrinos result from the interaction of cosmic rays with atomic nuclei in the Earth's atmosphere, creating showers of particles, many of which are unstable and produce neutrinos when they decay. A collaboration of particle physicists from Tata Institute of Fundamental Research (India), Osaka City University (Japan) and Durham University (UK) recorded the first cosmic ray neutrino interaction in an underground laboratory in Kolar Gold Fields in India in 1965.

Solar neutrinos originate from the nuclear fusion powering the Sun and other stars.
The details of the operation of the Sun are explained by the Standard Solar Model. In short: when four protons fuse to become one helium nucleus, two of them have to convert into neutrons, and each such conversion releases one electron neutrino.

The Sun sends enormous numbers of neutrinos in all directions. Each second, about 65 billion () solar neutrinos pass through every square centimeter on the part of the Earth orthogonal to the direction of the Sun. Since neutrinos are insignificantly absorbed by the mass of the Earth, the surface area on the side of the Earth opposite the Sun receives about the same number of neutrinos as the side facing the Sun.

In 1966, Colgate and White calculated that neutrinos carry away most of the gravitational energy released by the collapse of massive stars, events now categorized as Type Ib and Ic and Type II supernovae. When such stars collapse, matter densities at the core become so high () that the degeneracy of electrons is not enough to prevent protons and electrons from combining to form a neutron and an electron neutrino. A second and more profuse neutrino source is the thermal energy (100 billion kelvins) of the newly formed neutron core, which is dissipated via the formation of neutrino–antineutrino pairs of all flavors.

Colgate and White's theory of supernova neutrino production was confirmed in 1987, when neutrinos from Supernova 1987A were detected. The water-based detectors Kamiokande II and IMB detected 11 and 8 antineutrinos (lepton number = −1) of thermal origin, respectively, while the scintillator-based Baksan detector found 5 neutrinos (lepton number = +1) of either thermal or electron-capture origin, in a burst less than 13 seconds long. The neutrino signal from the supernova arrived at earth several hours before the arrival of the first electromagnetic radiation, as expected from the evident fact that the latter emerges along with the shock wave. The exceptionally feeble interaction with normal matter allowed the neutrinos to pass through the churning mass of the exploding star, while the electromagnetic photons were slowed.

Because neutrinos interact so little with matter, it is thought that a supernova's neutrino emissions carry information about the innermost regions of the explosion. Much of the "visible" light comes from the decay of radioactive elements produced by the supernova shock wave, and even light from the explosion itself is scattered by dense and turbulent gases, and thus delayed. The neutrino burst is expected to reach Earth before any electromagnetic waves, including visible light, gamma rays, or radio waves. The exact time delay of the electromagnetic waves' arrivals depends on the velocity of the shock wave and on the thickness of the outer layer of the star. For a Type II supernova, astronomers expect the neutrino flood to be released seconds after the stellar core collapse, while the first electromagnetic signal may emerge hours later, after the explosion shock wave has had time to reach the surface of the star. The Supernova Early Warning System project uses a network of neutrino detectors to monitor the sky for candidate supernova events; the neutrino signal will provide a useful advance warning of a star exploding in the Milky Way.

Although neutrinos pass through the outer gases of a supernova without scattering, they provide information about the deeper supernova core with evidence that here, even neutrinos scatter to a significant extent. In a supernova core the densities are those of a neutron star (which is expected to be formed in this type of supernova), becoming large enough to influence the duration of the neutrino signal by delaying some neutrinos. The 13 second-long neutrino signal from SN 1987A lasted far longer than it would take for unimpeded neutrinos to cross through the neutrino-generating core of a supernova, expected to be only 3200 kilometers in diameter for SN 1987A.

The number of neutrinos counted was also consistent with a total neutrino energy of , which was estimated to be nearly all of the total energy of the supernova.

For an average supernova, approximately 10 (an octodecillion) neutrinos are released, but the actual number detected at a terrestrial detector formula_1 will be far smaller, at the level of

where formula_3 is the mass of the detector (with e.g. Super Kamiokande having a mass of 50 kton) and formula_4 is the distance to the supernova. Hence in practice it will only be possible to detect neutrino bursts from supernovae within or nearby the Milky Way (our own galaxy). In addition to the detection of neutrinos from individual supernovae, it should also be possible to detect the diffuse supernova neutrino background, which originates from all supernovae in the Universe.

The energy of supernova neutrinos ranges from a few to several tens of MeV. The sites where cosmic rays are accelerated are expected to produce neutrinos that are at least one million times more energetic, produced from turbulent gaseous environments left over by supernova explosions: the supernova remnants. The origin of the cosmic rays was attributed to supernovas by Walter Baade and Fritz Zwicky; this hypothesis was refined by Vitaly L. Ginzburg and Sergei I. Syrovatsky who attributed the origin to supernova remnants, and supported their claim by the crucial remark, that the cosmic ray losses of the Milky Way is compensated, if the efficiency of acceleration in supernova remnants is about 10 percent. Ginzburg and Syrovatskii's hypothesis is supported by the specific mechanism of "shock wave acceleration" happening in supernova remnants, which is consistent with the original theoretical picture drawn by Enrico Fermi, and is receiving support from observational data. The very-high-energy neutrinos are still to be seen, but this branch of neutrino astronomy is just in its infancy. The main existing or forthcoming experiments that aim at observing very-high-energy neutrinos from our galaxy are Baikal, AMANDA, IceCube, ANTARES, NEMO and Nestor. Related information is provided by very-high-energy gamma ray observatories, such as VERITAS, HESS and MAGIC. Indeed, the collisions of cosmic rays are supposed to produce charged pions, whose decay give the neutrinos, and also neutral pions, whose decay give gamma rays: the environment of a supernova remnant is transparent to both types of radiation.

Still-higher-energy neutrinos, resulting from the interactions of extragalactic cosmic rays, could be observed with the Pierre Auger Observatory or with the dedicated experiment named ANITA.

It is thought that, just like the cosmic microwave background radiation left over from the Big Bang, there is a background of low-energy neutrinos in our Universe. In the 1980s it was proposed that these may be the explanation for the dark matter thought to exist in the universe. Neutrinos have one important advantage over most other dark matter candidates: They are known to exist. This idea also has serious problems.

From particle experiments, it is known that neutrinos are very light. This means that they easily move at speeds close to the speed of light. For this reason, dark matter made from neutrinos is termed "hot dark matter". The problem is that being fast moving, the neutrinos would tend to have spread out evenly in the universe before cosmological expansion made them cold enough to congregate in clumps. This would cause the part of dark matter made of neutrinos to be smeared out and unable to cause the large galactic structures that we see.

These same galaxies and groups of galaxies appear to be surrounded by dark matter that is not fast enough to escape from those galaxies. Presumably this matter provided the gravitational nucleus for formation. This implies that neutrinos cannot make up a significant part of the total amount of dark matter.

From cosmological arguments, relic background neutrinos are estimated to have density of 56 of each type per cubic centimeter and temperature () if they are massless, much colder if their mass exceeds . Although their density is quite high, they have not yet been observed in the laboratory, as their energy is below thresholds of most detection methods, and due to extremely low neutrino interaction cross-sections at sub-eV energies. In contrast, boron-8 solar neutrinos—which are emitted with a higher energy—have been detected definitively despite having a space density that is lower than that of relic neutrinos by some 6 orders of magnitude.

Neutrinos as such cannot be detected directly, because they do not ionize the materials they are passing through (they do not carry electric charge and other proposed effects, like the MSW effect, do not produce traceable radiation). A unique reaction to identify antineutrinos, sometimes referred to as inverse beta decay, as applied by Reines and Cowan (see below), requires a very large detector to detect a significant number of neutrinos. All detection methods require the neutrinos to carry a minimum threshold energy. So far, there is no detection method for low-energy neutrinos, in the sense that potential neutrino interactions (for example by the MSW effect) cannot be uniquely distinguished from other causes. Neutrino detectors are often built underground to isolate the detector from cosmic rays and other background radiation.

Antineutrinos were first detected in the 1950s near a nuclear reactor. Reines and Cowan used two targets containing a solution of cadmium chloride in water. Two scintillation detectors were placed next to the cadmium targets. Antineutrinos with an energy above the threshold of caused charged current interactions with the protons in the water, producing positrons and neutrons. This is very much like decay, where energy is used to convert a proton into a neutron, a positron () and an electron neutrino () is emitted:

From known decay:

In the Cowan and Reines experiment, instead of an outgoing neutrino, you have an incoming antineutrino () from a nuclear reactor:

The resulting positron annihilation with electrons in the detector material created photons with an energy of about . Pairs of photons in coincidence could be detected by the two scintillation detectors above and below the target. The neutrons were captured by cadmium nuclei resulting in gamma rays of about that were detected a few microseconds after the photons from a positron annihilation event.

Since then, various detection methods have been used. Super Kamiokande is a large volume of water surrounded by photomultiplier tubes that watch for the Cherenkov radiation emitted when an incoming neutrino creates an electron or muon in the water. The Sudbury Neutrino Observatory is similar, but used heavy water as the detecting medium, which uses the same effects, but also allows the additional reaction any-flavor neutrino photo-dissociation of deuterium, resulting in a free neutron which is then detected from gamma radiation after chlorine-capture. Other detectors have consisted of large volumes of chlorine or gallium which are periodically checked for excesses of argon or germanium, respectively, which are created by electron-neutrinos interacting with the original substance. MINOS used a solid plastic scintillator coupled to photomultiplier tubes, while Borexino uses a liquid pseudocumene scintillator also watched by photomultiplier tubes and the NOνA detector uses liquid scintillator watched by avalanche photodiodes. The IceCube Neutrino Observatory uses of the Antarctic ice sheet near the south pole with photomultiplier tubes distributed throughout the volume.

The University of Liverpool ND280 detector employs the novel use of gadolinium encased light detectors in a temperature controlled magnetic field capturing double light pulse events. The T2K experiment developed the technology and practical experiments were successful in both Japan and at Wylfa power station.

Neutrinos' low mass and neutral charge mean they interact exceedingly weakly with other particles and fields. This feature of weak interaction interests scientists because it means neutrinos can be used to probe environments that other radiation (such as light or radio waves) cannot penetrate.

Using neutrinos as a probe was first proposed in the mid-20th century as a way to detect conditions at the core of the Sun. The solar core cannot be imaged directly because electromagnetic radiation (such as light) is diffused by the great amount and density of matter surrounding the core. On the other hand, neutrinos pass through the Sun with few interactions. Whereas photons emitted from the solar core may require 40,000 years to diffuse to the outer layers of the Sun, neutrinos generated in stellar fusion reactions at the core cross this distance practically unimpeded at nearly the speed of light.

Neutrinos are also useful for probing astrophysical sources beyond the Solar System because they are the only known particles that are not significantly attenuated by their travel through the interstellar medium. Optical photons can be obscured or diffused by dust, gas, and background radiation. High-energy cosmic rays, in the form of swift protons and atomic nuclei, are unable to travel more than about 100 megaparsecs due to the Greisen–Zatsepin–Kuzmin limit (GZK cutoff). Neutrinos, in contrast, can travel even greater distances barely attenuated.

The galactic core of the Milky Way is fully obscured by dense gas and numerous bright objects. Neutrinos produced in the galactic core might be measurable by Earth-based neutrino telescopes.

Another important use of the neutrino is in the observation of supernovae, the explosions that end the lives of highly massive stars. The core collapse phase of a supernova is an extremely dense and energetic event. It is so dense that no known particles are able to escape the advancing core front except for neutrinos. Consequently, supernovae are known to release approximately 99% of their radiant energy in a short (10 second) burst of neutrinos. These neutrinos are a very useful probe for core collapse studies.

The rest mass of the neutrino is an important test of cosmological and astrophysical theories (see "Dark matter"). The neutrino's significance in probing cosmological phenomena is as great as any other method, and is thus a major focus of study in astrophysical communities.

The study of neutrinos is important in particle physics because neutrinos typically have the lowest mass, and hence are examples of the lowest-energy particles theorized in extensions of the Standard Model of particle physics.

In November 2012, American scientists used a particle accelerator to send a coherent neutrino message through 780 feet of rock. This marks the first use of neutrinos for communication, and future research may permit binary neutrino messages to be sent immense distances through even the densest materials, such as the Earth's core.

In July 2018, the IceCube Neutrino Observatory announced that they have traced an extremely-high-energy neutrino that hit their Antarctica-based research station in September 2017 back to its point of origin in the blazar TXS 0506 +056 located 3.7 billion light-years away in the direction of the constellation Orion. This is the first time that a neutrino detector has been used to locate an object in space and that a source of cosmic rays has been identified.





</doc>
<doc id="21488" url="https://en.wikipedia.org/wiki?curid=21488" title="Nanotechnology">
Nanotechnology

Nanotechnology (or "nanotech") is manipulation of matter on an atomic, molecular, and supramolecular scale. The earliest, widespread description of nanotechnology referred to the particular technological goal of precisely manipulating atoms and molecules for fabrication of macroscale products, also now referred to as molecular nanotechnology. A more generalized description of nanotechnology was subsequently established by the National Nanotechnology Initiative, which defined nanotechnology as the manipulation of matter with at least one dimension sized from 1 to 100 nanometers. This definition reflects the fact that quantum mechanical effects are important at this quantum-realm scale, and so the definition shifted from a particular technological goal to a research category inclusive of all types of research and technologies that deal with the special properties of matter which occur below the given size threshold. It is therefore common to see the plural form "nanotechnologies" as well as "nanoscale technologies" to refer to the broad range of research and applications whose common trait is size.

Nanotechnology as defined by size is naturally broad, including fields of science as diverse as surface science, organic chemistry, molecular biology, semiconductor physics, energy storage, engineering, microfabrication, and molecular engineering. The associated research and applications are equally diverse, ranging from extensions of conventional device physics to completely new approaches based upon molecular self-assembly, from developing new materials with dimensions on the nanoscale to direct control of matter on the atomic scale.

Scientists currently debate the future implications of nanotechnology. Nanotechnology may be able to create many new materials and devices with a vast range of applications, such as in nanomedicine, nanoelectronics, biomaterials energy production, and consumer products. On the other hand, nanotechnology raises many of the same issues as any new technology, including concerns about the toxicity and environmental impact of nanomaterials, and their potential effects on global economics, as well as speculation about various doomsday scenarios. These concerns have led to a debate among advocacy groups and governments on whether special regulation of nanotechnology is warranted.

The concepts that seeded nanotechnology were first discussed in 1959 by renowned physicist Richard Feynman in his talk "There's Plenty of Room at the Bottom", in which he described the possibility of synthesis via direct manipulation of atoms.

In 1960, Egyptian engineer Mohamed Atalla and Korean engineer Dawon Kahng at Bell Labs fabricated the first MOSFET (metal–oxide–semiconductor field-effect transistor) with a gate oxide thickness of 100 nm, along with a gate length of 20µm. In 1962, Atalla and Kahng fabricated a nanolayer-base metal–semiconductor junction (M–S junction) transistor that used gold (Au) thin films with a thickness of 10 nm.

The term "nano-technology" was first used by Norio Taniguchi in 1974, though it was not widely known. Inspired by Feynman's concepts, K. Eric Drexler used the term "nanotechnology" in his 1986 book "Engines of Creation: The Coming Era of Nanotechnology", which proposed the idea of a nanoscale "assembler" which would be able to build a copy of itself and of other items of arbitrary complexity with atomic control. Also in 1986, Drexler co-founded The Foresight Institute (with which he is no longer affiliated) to help increase public awareness and understanding of nanotechnology concepts and implications.

The emergence of nanotechnology as a field in the 1980s occurred through convergence of Drexler's theoretical and public work, which developed and popularized a conceptual framework for nanotechnology, and high-visibility experimental advances that drew additional wide-scale attention to the prospects of atomic control of matter. Since the popularity spike in the 1980s, most of nanotechnology has involved investigation of several approaches to making mechanical devices out of a small number of atoms.

In the 1980s, two major breakthroughs sparked the growth of nanotechnology in modern era. First, the invention of the scanning tunneling microscope in 1981 which provided unprecedented visualization of individual atoms and bonds, and was successfully used to manipulate individual atoms in 1989. The microscope's developers Gerd Binnig and Heinrich Rohrer at IBM Zurich Research Laboratory received a Nobel Prize in Physics in 1986. Binnig, Quate and Gerber also invented the analogous atomic force microscope that year.

Second, fullerenes were discovered in 1985 by Harry Kroto, Richard Smalley, and Robert Curl, who together won the 1996 Nobel Prize in Chemistry. C was not initially described as nanotechnology; the term was used regarding subsequent work with related graphene tubes (called carbon nanotubes and sometimes called Bucky tubes) which suggested potential applications for nanoscale electronics and devices. The discovery of carbon nanotubes is largely attributed to Sumio Iijima of NEC in 1991, for which Iijima won the inaugural 2008 Kavli Prize in Nanoscience.

In 1987, Bijan Davari led an IBM research team that demonstrated the first MOSFET with a 10 nm gate oxide thickness, using tungsten-gate technology. Multi-gate MOSFETs enabled scaling below 20 nm gate length, starting with the FinFET (fin field-effect transistor), a three-dimensional, non-planar, double-gate MOSFET. The FinFET originates from the research of Digh Hisamoto at Hitachi Central Research Laboratory in 1989. At UC Berkeley, FinFET devices were fabricated by a group consisting of Hisamoto along with TSMC's Chenming Hu and other international researchers including Tsu-Jae King Liu, Jeffrey Bokor, Hideki Takeuchi, K. Asano, Jakub Kedziersk, Xuejue Huang, Leland Chang, Nick Lindert, Shibly Ahmed and Cyrus Tabery. The team fabricated FinFET devices down to a 17nm process in 1998, and then 15nm in 2001. In 2002, a team including Yu, Chang, Ahmed, Hu, Liu, Bokor and Tabery fabricated a 10nm FinFET device.

In the early 2000s, the field garnered increased scientific, political, and commercial attention that led to both controversy and progress. Controversies emerged regarding the definitions and potential implications of nanotechnologies, exemplified by the Royal Society's report on nanotechnology. Challenges were raised regarding the feasibility of applications envisioned by advocates of molecular nanotechnology, which culminated in a public debate between Drexler and Smalley in 2001 and 2003.

Meanwhile, commercialization of products based on advancements in nanoscale technologies began emerging. These products are limited to bulk applications of nanomaterials and do not involve atomic control of matter. Some examples include the Silver Nano platform for using silver nanoparticles as an antibacterial agent, nanoparticle-based transparent sunscreens, carbon fiber strengthening using silica nanoparticles, and carbon nanotubes for stain-resistant textiles.

Governments moved to promote and fund research into nanotechnology, such as in the U.S. with the National Nanotechnology Initiative, which formalized a size-based definition of nanotechnology and established funding for research on the nanoscale, and in Europe via the European Framework Programmes for Research and Technological Development.

By the mid-2000s new and serious scientific attention began to flourish. Projects emerged to produce nanotechnology roadmaps which center on atomically precise manipulation of matter and discuss existing and projected capabilities, goals, and applications.

In 2006, a team of Korean researchers from the Korea Advanced Institute of Science and Technology (KAIST) and the National Nano Fab Center developed a 3 nm MOSFET, the world's smallest nanoelectronic device. It was based on gate-all-around (GAA) FinFET technology.

Over sixty countries created nanotechnology research and development (R&D) government programs between 2001 and 2004. Government funding was exceeded by corporate spending on nanotechnology R&D, with most of the funding coming from corporations based in the United States, Japan and Germany. The top five organizations that filed the most intellectual patents on nanotechnology R&D between 1970 and 2011 were Samsung Electronics (2,578 first patents), Nippon Steel (1,490 first patents), IBM (1,360 first patents), Toshiba (1,298 first patents) and Canon (1,162 first patents). The top five organizations that published the most scientific papers on nanotechnology research between 1970 and 2012 were the Chinese Academy of Sciences, Russian Academy of Sciences, Centre national de la recherche scientifique, University of Tokyo and Osaka University.

Nanotechnology is the engineering of functional systems at the molecular scale. This covers both current work and concepts that are more advanced. In its original sense, nanotechnology refers to the projected ability to construct items from the bottom up, using techniques and tools being developed today to make complete, high performance products.

One nanometer (nm) is one billionth, or 10, of a meter. By comparison, typical carbon-carbon bond lengths, or the spacing between these atoms in a molecule, are in the range , and a DNA double-helix has a diameter around 2 nm. On the other hand, the smallest cellular life-forms, the bacteria of the genus "Mycoplasma", are around 200 nm in length. By convention, nanotechnology is taken as the scale range following the definition used by the National Nanotechnology Initiative in the US. The lower limit is set by the size of atoms (hydrogen has the smallest atoms, which are approximately a quarter of a nm kinetic diameter) since nanotechnology must build its devices from atoms and molecules. The upper limit is more or less arbitrary but is around the size below which phenomena not observed in larger structures start to become apparent and can be made use of in the nano device. These new phenomena make nanotechnology distinct from devices which are merely miniaturised versions of an equivalent macroscopic device; such devices are on a larger scale and come under the description of microtechnology.

To put that scale in another context, the comparative size of a nanometer to a meter is the same as that of a marble to the size of the earth. Or another way of putting it: a nanometer is the amount an average man's beard grows in the time it takes him to raise the razor to his face.

Two main approaches are used in nanotechnology. In the "bottom-up" approach, materials and devices are built from molecular components which assemble themselves chemically by principles of molecular recognition. In the "top-down" approach, nano-objects are constructed from larger entities without atomic-level control.

Areas of physics such as nanoelectronics, nanomechanics, nanophotonics and nanoionics have evolved during the last few decades to provide a basic scientific foundation of nanotechnology.

Several phenomena become pronounced as the size of the system decreases. These include statistical mechanical effects, as well as quantum mechanical effects, for example the "quantum size effect" where the electronic properties of solids are altered with great reductions in particle size. This effect does not come into play by going from macro to micro dimensions. However, quantum effects can become significant when the nanometer size range is reached, typically at distances of 100 nanometers or less, the so-called quantum realm. Additionally, a number of physical (mechanical, electrical, optical, etc.) properties change when compared to macroscopic systems. One example is the increase in surface area to volume ratio altering mechanical, thermal and catalytic properties of materials. Diffusion and reactions at nanoscale, nanostructures materials and nanodevices with fast ion transport are generally referred to nanoionics. "Mechanical" properties of nanosystems are of interest in the nanomechanics research. The catalytic activity of nanomaterials also opens potential risks in their interaction with biomaterials.

Materials reduced to the nanoscale can show different properties compared to what they exhibit on a macroscale, enabling unique applications. For instance, opaque substances can become transparent (copper); stable materials can turn combustible (aluminium); insoluble materials may become soluble (gold). A material such as gold, which is chemically inert at normal scales, can serve as a potent chemical catalyst at nanoscales. Much of the fascination with nanotechnology stems from these quantum and surface phenomena that matter exhibits at the nanoscale.

Modern synthetic chemistry has reached the point where it is possible to prepare small molecules to almost any structure. These methods are used today to manufacture a wide variety of useful chemicals such as pharmaceuticals or commercial polymers. This ability raises the question of extending this kind of control to the next-larger level, seeking methods to assemble these single molecules into supramolecular assemblies consisting of many molecules arranged in a well defined manner.

These approaches utilize the concepts of molecular self-assembly and/or supramolecular chemistry to automatically arrange themselves into some useful conformation through a bottom-up approach. The concept of molecular recognition is especially important: molecules can be designed so that a specific configuration or arrangement is favored due to non-covalent intermolecular forces. The Watson–Crick basepairing rules are a direct result of this, as is the specificity of an enzyme being targeted to a single substrate, or the specific folding of the protein itself. Thus, two or more components can be designed to be complementary and mutually attractive so that they make a more complex and useful whole.

Such bottom-up approaches should be capable of producing devices in parallel and be much cheaper than top-down methods, but could potentially be overwhelmed as the size and complexity of the desired assembly increases. Most useful structures require complex and thermodynamically unlikely arrangements of atoms. Nevertheless, there are many examples of self-assembly based on molecular recognition in biology, most notably Watson–Crick basepairing and enzyme-substrate interactions. The challenge for nanotechnology is whether these principles can be used to engineer new constructs in addition to natural ones.

Molecular nanotechnology, sometimes called molecular manufacturing, describes engineered nanosystems (nanoscale machines) operating on the molecular scale. Molecular nanotechnology is especially associated with the molecular assembler, a machine that can produce a desired structure or device atom-by-atom using the principles of mechanosynthesis. Manufacturing in the context of productive nanosystems is not related to, and should be clearly distinguished from, the conventional technologies used to manufacture nanomaterials such as carbon nanotubes and nanoparticles.

When the term "nanotechnology" was independently coined and popularized by Eric Drexler (who at the time was unaware of an earlier usage by Norio Taniguchi) it referred to a future manufacturing technology based on molecular machine systems. The premise was that molecular scale biological analogies of traditional machine components demonstrated molecular machines were possible: by the countless examples found in biology, it is known that sophisticated, stochastically optimised biological machines can be produced.

It is hoped that developments in nanotechnology will make possible their construction by some other means, perhaps using biomimetic principles. However, Drexler and other researchers have proposed that advanced nanotechnology, although perhaps initially implemented by biomimetic means, ultimately could be based on mechanical engineering principles, namely, a manufacturing technology based on the mechanical functionality of these components (such as gears, bearings, motors, and structural members) that would enable programmable, positional assembly to atomic specification. The physics and engineering performance of exemplar designs were analyzed in Drexler's book "Nanosystems".

In general it is very difficult to assemble devices on the atomic scale, as one has to position atoms on other atoms of comparable size and stickiness. Another view, put forth by Carlo Montemagno, is that future nanosystems will be hybrids of silicon technology and biological molecular machines. Richard Smalley argued that mechanosynthesis are impossible due to the difficulties in mechanically manipulating individual molecules.

This led to an exchange of letters in the ACS publication Chemical & Engineering News in 2003. Though biology clearly demonstrates that molecular machine systems are possible, non-biological molecular machines are today only in their infancy. Leaders in research on non-biological molecular machines are Dr. Alex Zettl and his colleagues at Lawrence Berkeley Laboratories and UC Berkeley. They have constructed at least three distinct molecular devices whose motion is controlled from the desktop with changing voltage: a nanotube nanomotor, a molecular actuator, and a nanoelectromechanical relaxation oscillator. See nanotube nanomotor for more examples.

An experiment indicating that positional molecular assembly is possible was performed by Ho and Lee at Cornell University in 1999. They used a scanning tunneling microscope to move an individual carbon monoxide molecule (CO) to an individual iron atom (Fe) sitting on a flat silver crystal, and chemically bound the CO to the Fe by applying a voltage.

The nanomaterials field includes subfields which develop or study materials having unique properties arising from their nanoscale dimensions.

These seek to arrange smaller components into more complex assemblies.

These seek to create smaller devices by using larger ones to direct their assembly.

These seek to develop components of a desired functionality without regard to how they might be assembled.


These subfields seek to anticipate what inventions nanotechnology might yield, or attempt to propose an agenda along which inquiry might progress. These often take a big-picture view of nanotechnology, with more emphasis on its societal implications than the details of how such inventions could actually be created.

Nanomaterials can be classified in 0D, 1D, 2D and 3D nanomaterials. The dimensionality play a major role in determining the characteristic of nanomaterials including physical, chemical and biological characteristics. With the decrease in dimensionality, an increase in surface-to-volume ratio is observed. This indicate that smaller dimensional nanomaterials have higher surface area compared to 3D nanomaterials. Recently, two dimensional (2D) nanomaterials are extensively investigated for electronic, biomedical, drug delivery and biosensor applications.

There are several important modern developments. The atomic force microscope (AFM) and the Scanning Tunneling Microscope (STM) are two early versions of scanning probes that launched nanotechnology. There are other types of scanning probe microscopy. Although conceptually similar to the scanning confocal microscope developed by Marvin Minsky in 1961 and the scanning acoustic microscope (SAM) developed by Calvin Quate and coworkers in the 1970s, newer scanning probe microscopes have much higher resolution, since they are not limited by the wavelength of sound or light.

The tip of a scanning probe can also be used to manipulate nanostructures (a process called positional assembly). Feature-oriented scanning methodology may be a promising way to implement these nanomanipulations in automatic mode. However, this is still a slow process because of low scanning velocity of the microscope.

Various techniques of nanolithography such as optical lithography, X-ray lithography, dip pen nanolithography, electron beam lithography or nanoimprint lithography were also developed. Lithography is a top-down fabrication technique where a bulk material is reduced in size to nanoscale pattern.

Another group of nanotechnological techniques include those used for fabrication of nanotubes and nanowires, those used in semiconductor fabrication such as deep ultraviolet lithography, electron beam lithography, focused ion beam machining, nanoimprint lithography, atomic layer deposition, and molecular vapor deposition, and further including molecular self-assembly techniques such as those employing di-block copolymers. The precursors of these techniques preceded the nanotech era, and are extensions in the development of scientific advancements rather than techniques which were devised with the sole purpose of creating nanotechnology and which were results of nanotechnology research.

The top-down approach anticipates nanodevices that must be built piece by piece in stages, much as manufactured items are made. Scanning probe microscopy is an important technique both for characterization and synthesis of nanomaterials. Atomic force microscopes and scanning tunneling microscopes can be used to look at surfaces and to move atoms around. By designing different tips for these microscopes, they can be used for carving out structures on surfaces and to help guide self-assembling structures. By using, for example, feature-oriented scanning approach, atoms or molecules can be moved around on a surface with scanning probe microscopy techniques. At present, it is expensive and time-consuming for mass production but very suitable for laboratory experimentation.

In contrast, bottom-up techniques build or grow larger structures atom by atom or molecule by molecule. These techniques include chemical synthesis, self-assembly and positional assembly. Dual polarisation interferometry is one tool suitable for characterisation of self assembled thin films. Another variation of the bottom-up approach is molecular beam epitaxy or MBE. Researchers at Bell Telephone Laboratories like John R. Arthur. Alfred Y. Cho, and Art C. Gossard developed and implemented MBE as a research tool in the late 1960s and 1970s. Samples made by MBE were key to the discovery of the fractional quantum Hall effect for which the 1998 Nobel Prize in Physics was awarded. MBE allows scientists to lay down atomically precise layers of atoms and, in the process, build up complex structures. Important for research on semiconductors, MBE is also widely used to make samples and devices for the newly emerging field of spintronics.

However, new therapeutic products, based on responsive nanomaterials, such as the ultradeformable, stress-sensitive Transfersome vesicles, are under development and already approved for human use in some countries.

Because of the variety of potential applications (including industrial and military), governments have invested billions of dollars in nanotechnology research. Prior to 2012, the USA invested $3.7 billion using its National Nanotechnology Initiative, the European Union invested $1.2 billion, and Japan invested $750 million. Over sixty countries created nanotechnology research and development (R&D) programs between 2001 and 2004. In 2012, the US and EU each invested on nanotechnology research, followed by Japan with . Global investment reached in 2012. Government funding was exceeded by corporate R&D spending on nanotechnology research, which was in 2012. The largest corporate R&D spenders were from the US, Japan and Germany which accounted for a combined .

As of August 21, 2008, the Project on Emerging Nanotechnologies estimates that over 800 manufacturer-identified nanotech products are publicly available, with new ones hitting the market at a pace of 3–4 per week. The project lists all of the products in a publicly accessible online database. Most applications are limited to the use of "first generation" passive nanomaterials which includes titanium dioxide in sunscreen, cosmetics, surface coatings, and some food products; Carbon allotropes used to produce gecko tape; silver in food packaging, clothing, disinfectants and household appliances; zinc oxide in sunscreens and cosmetics, surface coatings, paints and outdoor furniture varnishes; and cerium oxide as a fuel catalyst.

Further applications allow tennis balls to last longer, golf balls to fly straighter, and even bowling balls to become more durable and have a harder surface. Trousers and socks have been infused with nanotechnology so that they will last longer and keep people cool in the summer. Bandages are being infused with silver nanoparticles to heal cuts faster. Video game consoles and personal computers may become cheaper, faster, and contain more memory thanks to nanotechnology. Also, to build structures for on chip computing with light, for example on chip optical quantum information processing, and picosecond transmission of information.

Nanotechnology may have the ability to make existing medical applications cheaper and easier to use in places like the general practitioner's office and at home. Cars are being manufactured with nanomaterials so they may need fewer metals and less fuel to operate in the future.

Scientists are now turning to nanotechnology in an attempt to develop diesel engines with cleaner exhaust fumes. Platinum is currently used as the diesel engine catalyst in these engines. The catalyst is what cleans the exhaust fume particles. First a reduction catalyst is employed to take nitrogen atoms from NOx molecules in order to free oxygen. Next the oxidation catalyst oxidizes the hydrocarbons and carbon monoxide to form carbon dioxide and water. Platinum is used in both the reduction and the oxidation catalysts. Using platinum though, is inefficient in that it is expensive and unsustainable. Danish company InnovationsFonden invested DKK 15 million in a search for new catalyst substitutes using nanotechnology. The goal of the project, launched in the autumn of 2014, is to maximize surface area and minimize the amount of material required. Objects tend to minimize their surface energy; two drops of water, for example, will join to form one drop and decrease surface area. If the catalyst's surface area that is exposed to the exhaust fumes is maximized, efficiency of the catalyst is maximized. The team working on this project aims to create nanoparticles that will not merge. Every time the surface is optimized, material is saved. Thus, creating these nanoparticles will increase the effectiveness of the resulting diesel engine catalyst—in turn leading to cleaner exhaust fumes—and will decrease cost. If successful, the team hopes to reduce platinum use by 25%.

Nanotechnology also has a prominent role in the fast developing field of Tissue Engineering. When designing scaffolds, researchers attempt to mimic the nanoscale features of a cell's microenvironment to direct its differentiation down a suitable lineage. For example, when creating scaffolds to support the growth of bone, researchers may mimic osteoclast resorption pits.

Researchers have successfully used DNA origami-based nanobots capable of carrying out logic functions to achieve targeted drug delivery in cockroaches. It is said that the computational power of these nanobots can be scaled up to that of a Commodore 64.

Commercial nanoelectronic semiconductor device fabrication began in the 2010s. In 2013, SK Hynix began commercial mass-production of a 16nm process, TSMC began production of a 16nm FinFET process, and Samsung Electronics began production of a 10nm process. TSMC began production of a 7 nm process in 2017, and Samsung began production of a 5 nm process in 2018. In 2019, Samsung announced plans for the commercial production of a 3nm GAAFET process by 2021.

Commercial production of nanoelectronic semiconductor memory also began in the 2010s. In 2013, SK Hynix began mass-production of 16nm NAND flash memory, and Samsung began production of 10nm multi-level cell (MLC) NAND flash memory. In 2017, TSMC began production of SRAM memory using a 7 nm process.

An area of concern is the effect that industrial-scale manufacturing and use of nanomaterials would have on human health and the environment, as suggested by nanotoxicology research. For these reasons, some groups advocate that nanotechnology be regulated by governments. Others counter that overregulation would stifle scientific research and the development of beneficial innovations. Public health research agencies, such as the National Institute for Occupational Safety and Health are actively conducting research on potential health effects stemming from exposures to nanoparticles.

Some nanoparticle products may have unintended consequences. Researchers have discovered that bacteriostatic silver nanoparticles used in socks to reduce foot odor are being released in the wash. These particles are then flushed into the waste water stream and may destroy bacteria which are critical components of natural ecosystems, farms, and waste treatment processes.

Public deliberations on risk perception in the US and UK carried out by the Center for Nanotechnology in Society found that participants were more positive about nanotechnologies for energy applications than for health applications, with health applications raising moral and ethical dilemmas such as cost and availability.

Experts, including director of the Woodrow Wilson Center's Project on Emerging Nanotechnologies David Rejeski, have testified that successful commercialization depends on adequate oversight, risk research strategy, and public engagement. Berkeley, California is currently the only city in the United States to regulate nanotechnology; Cambridge, Massachusetts in 2008 considered enacting a similar law, but ultimately rejected it. Over the next several decades, applications of nanotechnology will likely include much higher-capacity computers, active materials of various kinds, and cellular-scale biomedical devices.

Nanofibers are used in several areas and in different products, in everything from aircraft wings to tennis rackets. Inhaling airborne nanoparticles and nanofibers may lead to a number of pulmonary diseases, e.g. fibrosis. Researchers have found that when rats breathed in nanoparticles, the particles settled in the brain and lungs, which led to significant increases in biomarkers for inflammation and stress response and that nanoparticles induce skin aging through oxidative stress in hairless mice.

A two-year study at UCLA's School of Public Health found lab mice consuming nano-titanium dioxide showed DNA and chromosome damage to a degree "linked to all the big killers of man, namely cancer, heart disease, neurological disease and aging".

A major study published more recently in Nature Nanotechnology suggests some forms of carbon nanotubes – a poster child for the "nanotechnology revolution" – could be as harmful as asbestos if inhaled in sufficient quantities. Anthony Seaton of the Institute of Occupational Medicine in Edinburgh, Scotland, who contributed to the article on carbon nanotubes said "We know that some of them probably have the potential to cause mesothelioma. So those sorts of materials need to be handled very carefully." In the absence of specific regulation forthcoming from governments, Paull and Lyons (2008) have called for an exclusion of engineered nanoparticles in food. A newspaper article reports that workers in a paint factory developed serious lung disease and nanoparticles were found in their lungs.

Calls for tighter regulation of nanotechnology have occurred alongside a growing debate related to the human health and safety risks of nanotechnology. There is significant debate about who is responsible for the regulation of nanotechnology. Some regulatory agencies currently cover some nanotechnology products and processes (to varying degrees) – by "bolting on" nanotechnology to existing regulations – there are clear gaps in these regimes. Davies (2008) has proposed a regulatory road map describing steps to deal with these shortcomings.

Stakeholders concerned by the lack of a regulatory framework to assess and control risks associated with the release of nanoparticles and nanotubes have drawn parallels with bovine spongiform encephalopathy ("mad cow" disease), thalidomide, genetically modified food, nuclear energy, reproductive technologies, biotechnology, and asbestosis. Dr. Andrew Maynard, chief science advisor to the Woodrow Wilson Center's Project on Emerging Nanotechnologies, concludes that there is insufficient funding for human health and safety research, and as a result there is currently limited understanding of the human health and safety risks associated with nanotechnology. As a result, some academics have called for stricter application of the precautionary principle, with delayed marketing approval, enhanced labelling and additional safety data development requirements in relation to certain forms of nanotechnology.

The Royal Society report identified a risk of nanoparticles or nanotubes being released during disposal, destruction and recycling, and recommended that "manufacturers of products that fall under extended producer responsibility regimes such as end-of-life regulations publish procedures outlining how these materials will be managed to minimize possible human and environmental exposure" (p. xiii).

The Center for Nanotechnology in Society has found that people respond to nanotechnologies differently, depending on application – with participants in public deliberations more positive about nanotechnologies for energy than health applications – suggesting that any public calls for nano regulations may differ by technology sector.



</doc>
<doc id="21489" url="https://en.wikipedia.org/wiki?curid=21489" title="NetHack">
NetHack

NetHack is an open source single-player roguelike video game, first released in 1987 and maintained by the NetHack DevTeam. The game is a software fork of the 1982 game "Hack", itself inspired by the 1980 game "Rogue". The player takes the role as one of several pre-defined character classes to descend through multiple dungeon floors, fighting monsters and collecting treasure, to recover the "Amulet of Yendor" at the lowest floor and then escape. As a traditional roguelike, "NetHack" features procedural-generated dungeons and treasure, hack and slash combat, tile-based gameplay (using ASCII graphics by default but with optional graphical tilesets), and permadeath, forcing the player to restart anew should their character die. While "Rogue", "Hack" and other earlier roguelikes stayed true to a high fantasy setting, "NetHack" introduced humorous and anachronistic elements over time, including popular cultural reference to works such as "Discworld" and "Raiders of the Lost Ark".

Comparing it with "Rogue", "Engadget"s Justin Olivetti wrote that it took its exploration aspect and "made it far richer with an encyclopedia of objects, a larger vocabulary, a wealth of pop culture mentions, and a puzzler's attitude." In 2000, "Salon" described it as "one of the finest gaming experiences the computing world has to offer".

Before starting a game, players choose their character's race, role, sex, and alignment, or allow the game to assign the attributes randomly. There are traditional fantasy roles such as knight, wizard, rogue, and priest; but there are also unusual roles, including archaeologist, tourist, and caveman. The player character's role and alignment dictate which deity the character serves in the game, "how other monsters react toward you", as well as character skills and attributes.

After the player character is created, the main objective is introduced. To win the game, the player must retrieve the Amulet of Yendor, found at the lowest level of the dungeon, and offer it to their deity. Successful completion of this task rewards the player with the gift of immortality, and the player is said to "ascend", attaining the status of demigod. Along the path to the amulet, a number of sub-quests must be completed, including one class-specific quest.

The player's character is, unless they opt not to be, accompanied by a pet animal, typically a kitten or little dog, although knights begin with a saddled pony. Pets grow from fighting, and they can be changed by various means. Most of the other monsters may also be tamed using magic or food.

"NetHack"'s dungeon spans about fifty primary levels, most of which are procedurally generated when the player character enters them for the first time. A typical level contains a way "up" and "down" to other levels. These may be stairways, ladders, trapdoors, etc. Levels also contain several "rooms" joined by corridors. These rooms are randomly generated rectangles (as opposed to the linear corridors) and may contain features such as altars, shops, fountains, traps, thrones, pools of water, and sinks based on the randomly generated features of the room. Some specific levels follow one of many fixed designs or contain fixed elements. Later versions of the game added special branches of dungeon levels. These are optional routes that may feature more challenging monsters but can reward more desirable treasure to complete the main dungeon. Levels, once generated, remained persistent, in contrast to games that followed "Moria"-style of level generation.

"NetHack" features a variety of items: weapons (melee or ranged), armor to protect the player, scrolls and spellbooks to read, potions to quaff, wands, rings, amulets, and an assortment of tools, such as keys and lamps.

"NetHack"<nowiki>'</nowiki>s identification of items is almost identical to "Rogue"<nowiki>'</nowiki>s. For example, a newly discovered potion may be referred to as a "pink potion" with no other clues as to its identity. Players can perform a variety of actions and tricks to deduce, or at least narrow down, the identity of the potion. The most obvious is the somewhat risky tactic of simply drinking it. All items of a certain type will have the same description. For instance, all "scrolls of enchant weapon" may be labeled "TEMOV", and once one has been identified, all "scrolls of enchant weapon" found later will be labeled unambiguously as such. Starting a new game will scramble the items descriptions again, so the "silver ring" that is a "ring of levitation" in one game might be a "ring of hunger" in another.

As in many other roguelike games, all items in "NetHack" are either "blessed", "uncursed", or "cursed". The majority of items are found uncursed, but the blessed or cursed status of an item is unknown until it is identified or detected through other means.

Generally, a blessed item will be more powerful than an uncursed item, and a cursed item will be less powerful, with the added disadvantage that once it has been equipped by the player, it cannot be easily unequipped. Where an object would bestow an effect upon the character, a curse will generally make the effect harmful, or increase the amount of harm done. However, there are very specific exceptions. For example, drinking a cursed "potion of gain level" will make the character literally rise through the ceiling to the level above, instead of gaining an experience level.

As in other roguelike games, "NetHack" features permadeath: expired characters cannot be revived.

Although "NetHack" can be completed by new or intermediate players without any artificial limitations, experienced players can attempt "conducts" for an additional challenge. These are voluntary restrictions on actions taken, such as using no wishes, following a vegetarian or vegan diet, or even killing no monsters. While conducts are generally tracked by the game and are displayed at death or ascension, unofficial conducts are practiced within the community.

When a player dies, the cause of death and score is created and added to the list where the player's character is ranked against other previous characters. The prompt "Do you want your possessions identified?" is given by default at the end of any game, allowing the player to learn any unknown properties of the items in their inventory at death. The player's attributes (such as resistances, luck, and others), conduct (usually self-imposed challenges, such as playing as an atheist or a vegetarian), and a tally of creatures killed, may also be displayed.

The game sporadically saves a level on which a character has died and then integrates that level into a later game. This is done via "bones files", which are saved on the computer hosting the game. A player using a publicly hosted copy of the game can thus encounter the remains and possessions of many other players, although many of these possessions may have become cursed.

Because of the numerous ways that a player-character could die between a combination of their own actions as well as from reactions from the game's interacting systems, players frequently refer to untimely deaths as "Yet Another Stupid Death" (YASD). Such deaths are considered part of learning to play "NetHack" as to avoid conditions where the same death may happen again.

"NetHack" does allow players to save the game so that one does not have to complete the game in one session, but on opening a new game, the previous save file is subsequently wiped as to enforce the permadeath option. One option some players use is to make a backup copy of the save game file before playing a game, and should their character die, restoring from the copied version, a practice known as "save scumming". Additionally, players can also manipulate the "bones files" in a manner not intended by the developers. While these help the player to learn the game and get around limits of permadeath, both are considered forms of cheating the game.

"NetHack" is largely based on discovering secrets and tricks during gameplay. It can take years for one to become well-versed in them, and even experienced players routinely discover new ones. A number of "NetHack" fan sites and discussion forums offer lists of game secrets known as "spoilers".

"NetHack" was originally created with only a simple ASCII text-based user interface, although the option to use something more elaborate was added later in its development. Interface elements such as the environment, entities, and objects are represented by arrangements of ASCII or Extended ASCII glyphs, "DEC graphics", or "IBM graphics" mode. In addition to the environment, the interface also displays character and situational information.

A detailed example:
The player (the '@' sign, a wizard in this case) has entered the level via the stairs (the '<' sign) and killed a few monsters, leaving their corpses (the '%' signs) behind. Exploring, the player has uncovered three rooms joined by corridors (the '#' signs): one with an altar (the '_' sign), another empty, and the final one (that the player is currently in) containing a potion (the '!' sign) and chest (the '(' sign). The player has just moved onto a square containing a silver ring. Parts of the level are still unexplored (probably accessible through the door to the west (the '+' sign)) and the player has yet to find the downstairs (a '>' sign) to the next level.

Apart from the original termcap interface shown above, there are other interfaces that replace standard screen representations with two-dimensional images, or tiles, collectively known as "tiles mode". Graphic interfaces of this kind have been successfully implemented on the Amiga, the X Window System, the Microsoft Windows GUI, the Qt toolkit, and the GNOME libraries.

Enhanced graphical options also exist, such as the isometric perspective of "Falcon's Eye" and "Vulture's Eye", or the three-dimensional rendering that noegnud offers. "Vulture's Eye" is a fork of the now defunct Falcon's Eye project. "Vulture's Eye" adds additional graphics, sounds, bug fixes and performance enhancements and is under active development in an open collaborative environment.

"NetHack" is a software derivative of "Hack", which itself was inspired by "Rogue". "Hack" was created by students Jay Fenlason, Kenny Woodland, Mike Thome, and Jonathan Payne at Lincoln-Sudbury Regional High School as part of a computer class, after seeing and playing "Rogue" at the University of California Berkeley computer labs. The group had tried to get the source code of "Rogue" from Glenn Wichman and Michael Toy to build upon, but Wichman and Toy had refused, forcing the students to build the dungeon-creation routines on their own. As such, the game was named "Hack" in part for the hack-and-slash gameplay and that the code to generate the dungeons was considered a programming hack. After their classes ended, the students' work on the program also ended, though they had a working game. Fenlason provided the source code to a local USENIX conference, and eventually it was uploaded to USENET newsgroups. The code drew the attention of many players who started working to modify and improve the game as well as port it to other computer systems. "Hack" did not have any formal maintainer and while one person was generally recognized to hold the main code to the current version of "Hack", many software forks emerged from the unorganized development of the game.

Eventually, Mike Stephenson took on the role as maintainer of the "Hack" source code. At this point, he decided to create a new fork of the game, bringing in novel ideas from Izchak Miller, a philosophy professor at University of Pennsylvania, and Janet Walz, another computer hacker. They called themselves the DevTeam and renamed their branch "NetHack" since their collaboration work was done over the Internet. They expanded the bestiary and other objects in the game, and drew from other sources outside of the high fantasy setting, such as from "Discworld" with the introduction of the tourist character class. Knowing of the multiple forks of "Hack" that existed, the DevTeam established a principle that while the game was open source and anyone could create a fork as a new project, only a few select members in the DevTeam could make modifications to the main source repository of the game, so that players could be assured that the DevTeam's release was the legitimate version of "NetHack".

The DevTeam's first release of "NetHack" was on 28 July 1987. 

The core DevTeam had expanded with the release of "NetHack" 3.0 in July 1989. By that point, they had established a tight-lipped culture, revealing little, if anything, between releases. Owing to the ever-increasing depth and complexity found in each release, the development team enjoys a near-mythical status among fans. This perceived omniscience is captured in the initialism TDTTOE, "The DevTeam Thinks of Everything", in that many of the possible emergent gameplay elements that could occur due to the behavior of the complex game systems had already been programmed in by the DevTeam. Since version 3.0, the DevTeam has typically kept to minor bug fix updates, represented by a change in the third version number (e.g. v3.0.1 over v3.0.0), and only releases major updates (v3.1.0 over v3.0.0) when significant new features are added to the game, including support for new platforms. Many of those from the community that helped with the ports to other systems were subsequently invited to be part of the DevTeam as the team's needs grew, with Stephenson remaining the key member currently.

Updates to the game were generally regular from around 1987 through 2003, with the DevTeam releasing v3.4.3 in December 2003. Subsequent updates from the DevTeam included new tilesets and compatibility with variants of Mac OS, but no major updates to the game had been made. In the absence of new releases from the developers, several community-made updates to the code and variants developed by fans emerged. 

On 7 December 2015, version 3.6.0 was released, the first major release in over a decade. While the patch did not add major new gameplay features, the update was designed to prepare the game for expansion in the future, with the DevTeam's patch notes stating "This release consists of a series of foundational changes in the team, underlying infrastructure and changes to the approach to game development". Stephenson said that despite the number of roguelike titles that had emerged since the v3.4.3 release, they saw that "NetHack" was still being talked about online in part due to its high degree of portability, and decided to continue its development. According to DevTeam member Paul Winner, they looked to evaluate what community features had been introduced in the prior decade to improve the game while maintaining the necessary balance. The update came shortly after the death of Terry Pratchett, whose "Discworld" had been influential on the game, and the new update included a tribute to him. With the v3.6.0 release, "NetHack" remains "one of the oldest games still being developed". 

A public read-only mirror of "NetHack" git repository was made available on 10 February 2016. Since v3.6.0, the DevTeam has continued to push updates to the title, with the latest being v3.6.6 on 8 March 2020. Version 3.7.0 is currently in development.

, the official source release supports the following systems: Windows, Linux, macOS, Windows CE, OS/2, Unix (BSD, System V, Solaris, HP-UX), BeOS, and VMS.

"NetHack" is released under the NetHack General Public License, which was written in 1989 by Mike Stephenson, patterned after the GNU bison license (which was written by Richard Stallman in 1988). Like the Bison license, and Stallman's later GNU General Public License, the "NetHack" license was written to allow the free sharing and modification of the source code under its protection. At the same time, the license explicitly states that the source code is not covered by any warranty, thus protecting the original authors from litigation. The NetHack General Public License is a copyleft software license certified as an open source license by the Open Source Initiative.

The NetHack General Public License allows anyone to port the game to a platform not supported by the official DevTeam, provided that they use the same license. Over the years this licensing has led to a large number of ports and internationalized versions in German, Japanese, and Spanish. The license also allows for software forks as long as they are distributed under the same license, except that the creator of a derivative work is allowed to offer warranty protection on the new work. The derivative work is required to indicate the modifications made and the dates of changes. In addition, the source code of the derivative work must be made available, free of charge except for nominal distribution fees. This has also allowed source code forks of "NetHack" including "Slash'EM" and "UnNetHack".

Bugs, humorous messages, stories, experiences, and ideas for the next version are discussed on the Usenet newsgroup rec.games.roguelike.nethack.

A public server at nethack.alt.org, commonly known as "NAO", gives players access to NetHack through a Telnet or SSH interface. A browser-based client is also available on the same site. Ebonhack connects to NAO with a graphical tiles-based interface.

During the whole month of November, the annual /dev/null NetHack Tournament took place every year from 1999 to 2016. The Junethack Cross-Variant Summer Tournament has taken place annually since 2011.

The Facebook artificial intelligence (AI) research team, along with researchers at the University of Oxford, the New York University, the Imperial College London, and University College London, developed an open-source platform called the NetHack Learning Environment, designed to teach AI agents to play "NetHack". The base environment is able to manuevuer the agent and fight its way through dungeons, but the team seeks community help to build an AI on the complexities of "NetHack" interconnected systems, using implicit knowledge that comes from player-made resources, thus given a means for programmers to hook into the environment with additional resources. 




</doc>
