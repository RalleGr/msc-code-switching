<doc id="13764" url="https://en.wikipedia.org/wiki?curid=13764" title="Hassium">
Hassium

Hassium is a chemical element with the symbol Hs and the atomic number 108. Hassium is highly radioactive; the most stable known isotope, Hs, has a half-life of approximately 16 seconds. One of its isotopes, Hs, has magic numbers of both protons and neutrons for deformed nuclei, which gives it greater stability against spontaneous fission. Hassium is a superheavy element; it has only been produced in a laboratory in very small quantities by fusing heavy nuclei with lighter ones. Natural occurrences of the element have been hypothesised, but none has ever been found.

The principal innovation that led to the discovery of hassium was the technique of cold fusion, in which the fused nuclei did not differ by mass as much as in earlier techniques. The technique was first tested at the Joint Institute for Nuclear Research (JINR) in Dubna, Moscow Oblast, Russian SFSR, Soviet Union, in 1974. The first attempts to synthesize element 108 were made in two different experiments at JINR in 1978. More attempts were made at the same venue in 1983 and then in 1984; the latter resulted in a claim that element 108 had been produced. Later in 1984, a synthesis claim followed from the Gesellschaft für Schwerionenforschung (GSI) in Darmstadt, Hesse, West Germany. The 1993 report by the Transfermium Working Group, formed by the International Union of Pure and Applied Chemistry and the International Union of Pure and Applied Physics, concluded the report from Darmstadt was more conclusive on its own and the major credit was assigned to the German scientists. GSI formally announced they wished to name the element "hassium" after the German state of Hesse home to the facility in 1992; this name was accepted as final in 1997.

In the periodic table of elements, hassium is a transactinide element, a member of the 7th period and group 8; it is thus the sixth member of the 6d series of transition metals. Chemistry experiments have confirmed that hassium behaves as the heavier homologue to osmium, reacting readily with oxygen to form a volatile tetroxide. The chemical properties of hassium have only been partly characterized, but they compare well with the chemistry of the other group 8 elements.

Nuclear reactions used in the 1960s resulted in high excitation energies that required expulsion of four or five neutrons; these reactions used targets made of elements with high atomic numbers to maximize the size difference between the two nuclei in a reaction. While this increased the chance of fusion due to the lower electrostatic repulsion between the target and the projectile, the formed compound nuclei often broke apart and did not survive to form a new element. Moreover, fusion processes inevitably produce neutron-poor nuclei, as heavier elements require more neutrons per proton to maximize stability; therefore, the necessary ejection of neutrons results in final products with typically have shorter lifetimes. As such, light beams (6 to 10 protons) only allowed synthesis of elements up to 106.

To advance to heavier elements, Soviet physicist Yuri Oganessian at the Joint Institute for Nuclear Research (JINR) in Dubna, Moscow Oblast, Russian SFSR, Soviet Union, proposed a different mechanism, in which the bombarded nucleus would be lead-208, which has magic numbers of protons and neutrons, or another nucleus close to it. Each proton and neutron has a fixed value of rest energy; those of all protons are equal and so are those of all neutrons. In a nucleus, some of this energy is diverted to binding protons and neutrons; if a nucleus has a magic number of protons and/or neutrons, then even more of its rest energy is diverted, which gives the nuclide additional stability. This additional stability requires more energy for an external nucleus to break the existing one and penetrate it. More energy diverted to binding nucleons means less rest energy, which in turn means less mass (mass is proportional to the rest energy). More equal atomic numbers of the reacting nuclei result in greater electrostatic repulsion between them, but the lower mass excess of the target nucleus balances it. This leaves less excitation energy for the newly created compound nucleus, which necessitates fewer neutron ejections to reach a stable state. Because of this energy difference, the former mechanism became known as "hot fusion" and the latter as "cold fusion".

Cold fusion was first declared successful in 1974 at JINR, when it was tested for synthesis of the yet-undiscovered element 106. These new nuclei were projected to decay via spontaneous fission. The physicists at JINR concluded those were not seen before because no fissioning nucleus known at the time showed similar parameters of fission and because changing either of the two nuclei in the reactions negated the seen effects. Physicists at the Lawrence Berkeley Laboratory (LBL; originally Radiation Laboratory, RL, and later Lawrence Berkeley National Laboratory, LBNL) of the University of California in Berkeley, California, United States, also expressed great interest in the new technique. When asked about how far this new method could go and if lead targets were a physics' Klondike, Oganessian responded, "Klondike may be an exaggeration [...] But soon, we will try to get elements 107...108 in these reactions."

The synthesis of element 108 was first attempted in 1978 by a research team led by Oganessian at the JINR. The team used a reaction that would generate element 108, specifically, the isotope 108, from fusion of radium (specifically, the isotope and calcium . The researchers were uncertain in interpreting their data, and their paper did not unambiguously claim to have discovered the element. The same year, another team at JINR investigated the possibility of synthesis of element 108 in reactions between lead and iron ; they were uncertain in interpreting the data, suggesting the possibility that element 108 had not been created.

In 1983, new experiments were performed at JINR. The experiments probably resulted in the synthesis of element 108; bismuth was bombarded with manganese to obtain 108, lead , was bombarded with iron to obtain 108, and californium was bombarded with neon to obtain 108. These experiments were not claimed as a discovery and Oganessian announced them in a conference rather than in a written report.

In 1984, JINR researchers in Dubna performed experiments set up identically to the previous ones; they bombarded bismuth and lead targets with ions of lighter elements manganese and iron, respectively. Twenty-one spontaneous fission events were recorded; the researchers concluded they were caused by 108.

Later in 1984, a research team led by Peter Armbruster and Gottfried Münzenberg at Gesellschaft für Schwerionenforschung (GSI; "Institute for Heavy Ion Research") in Darmstadt, Hesse, West Germany, attempted to create element 108. The team bombarded a lead target with accelerated iron nuclei. GSI's experiment to create element 108 was delayed until after their creation of element 109 in 1982, as prior calculations had suggested that even–even isotopes of element 108 would have spontaneous fission half-lives of less than one microsecond, making them difficult to detect and identify. The element 108 experiment finally went ahead after 109 had been synthesized and was found to decay by alpha emission, suggesting that isotopes of element 108 would do likewise, and this was corroborated by an experiment aimed at synthesizing isotopes of element 106. GSI reported synthesis of three atoms of 108. Two years later, they reported synthesis of one atom of the even–even 108.

In 1985, the International Union of Pure and Applied Chemistry (IUPAC) and the International Union of Pure and Applied Physics (IUPAP) formed the Transfermium Working Group (TWG) to assess discoveries and establish final names for elements with atomic numbers greater than 100. The party held meetings with delegates from the three competing institutes; in 1990, they established criteria for recognition of an element and in 1991, they finished the work of assessing discoveries and disbanded. These results were published in 1993.

According to the report, the 1984 works from JINR and GSI simultaneously and independently established synthesis of element 108. Of the two 1984 works, the one from GSI was said to be sufficient as a discovery on its own. The JINR work, which preceded the GSI one, "very probably" displayed synthesis of element 108. However, that was determined in retrospect given the work from Darmstadt; the JINR work focused on chemically identifying remote granddaughters of element 108 isotopes (which could not exclude the possibility that these daughter isotopes had other progenitors), while the GSI work clearly identified the decay path of those element 108 isotopes. The report concluded that the major credit should be awarded to GSI. In written responses to this ruling, both JINR and GSI agreed with its conclusions. In the same response, GSI confirmed that they and JINR were able to resolve all conflicts between them.

Historically, a newly discovered element was named by its discoverer. The first regulation came in 1947, when IUPAC decided that naming required regulation in case there are conflicting names. These matters were to be resolved by the Commission of Inorganic Nomenclature and the Commission of Atomic Weights. They would review the names in case of a conflict and select one; the decision would be based on a number of factors, such as usage, and would not be an indicator of priority of a claim. The two commissions would recommend a name to the IUPAC Council, which would be the final authority. The discoverers held the right to name an element, but their name would be subject to approval by IUPAC. The Commission of Atomic Weights distanced itself from element naming in most cases.

Under Mendeleev's nomenclature for unnamed and undiscovered elements, hassium would be known as "eka-osmium", as in "the first element below osmium in the periodic table" (from Sanskrit "eka" meaning "one"). In 1979, IUPAC published recommendations according to which the element was to be called "unniloctium" and assigned the corresponding symbol of "Uno", a systematic element name as a placeholder until the element was discovered and the discovery then confirmed, and a permanent name was decided. Although these recommendations were widely followed in the chemical community, the competing physicists in the field ignored them. They either called it "element 108", with the symbols "E108", "(108)" or "108", or used the proposed name "hassium".

In 1990, in an attempt to break a deadlock in establishing priority of discovery and naming of several elements, IUPAC reaffirmed in its nomenclature of inorganic chemistry that after existence of an element was established, the discoverers could propose a name. (In addition, the Commission of Atomic Weights was excluded from the naming process.) The first publication on criteria for an element discovery, released in 1991, specified the need for recognition by TWG.

Armbruster and his colleagues, the officially recognized German discoverers, held a naming ceremony for the elements 107 through 109, which had all been recognized as discovered by GSI, on 7 September 1992. For element 108, the scientists proposed the name "hassium". It is derived from the Latin name "Hassia" for the German state of Hesse where the institute is located. This name was proposed to IUPAC in a written response to their ruling on priority of discovery claims of elements, signed 29 September 1992.

The process of naming of element 108 was a part of a larger process of naming a number of elements starting with element 101; three teams—JINR, GSI, and LBL—claimed discoveries of several elements and the right to name those elements. Sometimes, these claims clashed; since a discoverer was considered entitled to naming of an element, conflicts over priority of discovery often resulted in conflicts over names of these new elements. These conflicts became known as the Transfermium Wars. Different suggestions to name the whole set of elements from 101 onward and they occasionally assigned names suggested by one team to be used for elements discovered by another. However, not all suggestions were met with equal approval; the teams openly protested naming proposals on several occasions.

In 1994, IUPAC Commission on Nomenclature of Inorganic Chemistry recommended that element 108 be named "hahnium" (Hn) after the German physicist Otto Hahn so elements named after Hahn and Lise Meitner (it was recommended element 109 should be named meitnerium, following GSI's suggestion) would be next to each other, honouring their joint discovery of nuclear fission; IUPAC commented that they felt the German suggestion was obscure. GSI protested, saying this proposal contradicted the long-standing convention of giving the discoverer the right to suggest a name; the American Chemical Society supported GSI. The name "hahnium", albeit with the different symbol Ha, had already been proposed and used by the American scientists for element 105, for which they had a discovery dispute with JINR; they thus protested the confusing scrambling of names. Following the uproar, IUPAC formed an ad hoc committee of representatives from the national adhering organizations of the three countries home to the competing institutions; they produced a new set of names in 1995. Element 108 was again named "hahnium"; this proposal was also retracted. The final compromise was reached in 1996 and published in 1997; element 108 was named "hassium" (Hs). Simultaneously, the name "dubnium" (Db; from Dubna, the JINR location) was assigned to element 105, and the name "hahnium" was not used for any element.

The official justification for this naming, alongside that of darmstadtium for element 110, was that it completed a set of geographic names for the location of the GSI; this set had been initiated by 19th-century names europium and germanium. This set would serve as a response to earlier naming of americium, californium, and berkelium for elements discovered in Berkeley. Armbruster commented on this, "this bad tradition was established by Berkeley. We wanted to do it for Europe." Later, when commenting on the naming of element 112, Armbruster said, "I did everything to ensure that we do not continue with German scientists and German towns."

Hassium has no stable or naturally occurring isotopes. Several radioactive isotopes have been synthesized in the laboratory, either by fusing two atoms or by observing the decay of heavier elements. As of 2019, the quantity of all hassium ever produced was on the order of hundreds of atoms. Twelve isotopes with mass numbers ranging from 263 to 277 (with the exceptions of 272, 274, and 276) have been reported, four of which—hassium-265, -267, -269, and -277—have known metastable states, although that of hassium-277 is unconfirmed. Most of these isotopes decay predominantly through alpha decay; this is the most common for all isotopes for which comprehensive decay characteristics are available, the only exception being hassium-277, which undergoes spontaneous fission. Lighter isotopes were usually synthesized by direct fusion between two lighter nuclei, whereas heavier isotopes were typically observed as decay products of nuclei with larger atomic numbers.

Atomic nuclei have well-established nuclear shells, and the existence of these shells provides nuclei with additional stability. If a nucleus has certain numbers of protons or neutrons, called magic numbers, that complete certain nuclear shells, then the nucleus is even more stable against decay. The highest known magic numbers are 82 for protons and 126 for neutrons. This notion is sometimes expanded to include additional numbers between those magic numbers, which also provide some additional stability and indicate closure of "sub-shells". In contrast to the better-known lighter nuclei, superheavy nuclei are deformed. Until the 1960s, the liquid drop model was the dominant explanation for nuclear structure. It suggested that the fission barrier would disappear for nuclei with about 280 nucleons. It was thus thought that spontaneous fission would occur nearly instantly before nuclei could form a structure that could stabilize them; it appeared that nuclei with Z ≈ 103 were too heavy to exist for a considerable length of time.

The later nuclear shell model suggested that nuclei with about 300 nucleons would form an island of stability in which nuclei will be more resistant to spontaneous fission and will primarily undergo alpha decay with longer half-lives, and the next doubly magic nucleus (having magic numbers of both protons and neutrons) is expected to lie in the center of the island of stability in the vicinity of "Z" = 110–114 and the predicted magic neutron number "N" = 184. Subsequent discoveries suggested that the predicted island might be further than originally anticipated; they also showed that nuclei intermediate between the long-lived actinides and the predicted island are deformed, and gain additional stability from shell effects. The addition to the stability against the spontaneous fission should be particularly great against spontaneous fission, although increase in stability against the alpha decay would also be pronounced. The center of the region on a chart of nuclides that would correspond to this stability for deformed nuclei was determined as Hs, with 108 expected to be a magic number for protons for deformed nuclei—nuclei that are far from spherical—and 162 a magic number for neutrons for such nuclei. Experiments on lighter superheavy nuclei, as well as those closer to the expected island, have shown greater than previously anticipated stability against spontaneous fission, showing the importance of shell effects on nuclei.

Theoretical models predict a region of instability for some hassium isotopes to lie around "A" = 275 and "N" = 168–170, which is between the predicted neutron shell closures at "N" = 162 for deformed nuclei and "N" = 184 for spherical nuclei. Nuclides within this region are predicted to have low fission barrier heights, resulting in short partial half-lives toward spontaneous fission. This prediction is supported by the observed 11 millisecond half-life of Hs and that of the neighbouring isobar Mt because the hindrance factors from the odd nucleon were shown to be much lower than otherwise expected. The measured half-lives are even lower than those predicted for the even–even Hs and Ds, which suggests a gap in stability away from the shell closures and perhaps a weakening of the shell closures in this region.

In 1991, Polish physicists Zygmunt Patyk and Adam Sobiczewski predicted that 108 is a proton magic number for deformed nuclei and 162 is a neutron magic number for such nuclei. This means such nuclei are permanently deformed in their ground state but have high, narrow fission barriers to further deformation and hence relatively long life-times toward spontaneous fission. Computational prospects for shell stabilization for Hs made it a promising candidate for a deformed doubly magic nucleus. Experimental data is scarce, but the existing data is interpreted by the researchers to support the assignment of "N" = 162 as a magic number. In particular, this conclusion was drawn from the decay data of Hs, Hs, and Hs. In 1997, Polish physicist Robert Smolańczuk calculated that the isotope Hs may be the most stable superheavy nucleus against alpha decay and spontaneous fission as a consequence of the predicted "N" = 184 shell closure.

Hassium is not known to occur naturally on Earth; the half-lives of all of its known isotopes are short enough that no primordial hassium would have survived to the present day. This does not rule out the possibility of the existence of unknown, longer-lived isotopes or nuclear isomers, some of which could still exist in trace quantities if they are long-lived enough. As early as 1914, German physicist Richard Swinne proposed element 108 as a source of X-rays in the Greenland ice sheet. Although Swinne was unable to verify this observation and thus did not claim discovery, he proposed in 1931 the existence of regions of long-lived transuranic elements, including one around "Z" = 108.

In 1963, Soviet geologist and physicist Viktor Cherdyntsev, who had previously claimed the existence of primordial curium-247, claimed to have discovered element 108—specifically the 108 isotope, which supposedly had a half-life of 400 to 500 million years—in natural molybdenite and suggested the provisional name "sergenium" (symbol Sg); this name takes its origin from the name for the Silk Road and was explained as "coming from Kazakhstan" for it. His rationale for claiming that sergenium was the heavier homologue to osmium was that minerals supposedly containing sergenium formed volatile oxides when boiled in nitric acid, similarly to osmium.

Cherdyntsev's findings were criticized by Soviet physicist Vladimir Kulakov on the grounds that some of the properties Cherdyntsev claimed sergenium had were inconsistent with the then-current nuclear physics. The chief questions raised by Kulakov were that the claimed alpha decay energy of sergenium was many orders of magnitude lower than expected and the half-life given was eight orders of magnitude shorter than what would be predicted for a nuclide alpha-decaying with the claimed decay energy. At the same time, a corrected half-life in the region of 10 years would be impossible because it would imply the samples contained about 100 milligrams of sergenium. In 2003, it was suggested that the observed alpha decay with energy 4.5 MeV could be due to a low-energy and strongly enhanced transition between different hyperdeformed states of a hassium isotope around Hs, thus suggesting that the existence of superheavy elements in nature was at least possible, although unlikely.

In 2006, Russian geologist Alexei Ivanov hypothesized that an isomer of Hs might have a half-life of around years, which would explain the observation of alpha particles with energies of around 4.4 MeV in some samples of molybdenite and osmiridium. This isomer of Hs could be produced from the beta decay of Bh and Sg, which, being homologous to rhenium and molybdenum respectively, should occur in molybdenite along with rhenium and molybdenum if they occurred in nature. Because hassium is homologous to osmium, it should occur along with osmium in osmiridium if it occurs in nature. The decay chains of Bh and Sg are hypothetical and the predicted half-life of this hypothetical hassium isomer is not long enough for any sufficient quantity to remain on Earth. It is possible that more Hs may be deposited on the Earth as the Solar System travels through the spiral arms of the Milky Way; this would explain excesses of plutonium-239 found on the ocean floors of the Pacific Ocean and the Gulf of Finland. However, minerals enriched with Hs are predicted to have excesses of its daughters uranium-235 and lead-207; they would also have different proportions of elements that are formed during spontaneous fission, such as krypton, zirconium, and xenon. The natural occurrence of hassium in minerals such as molybdenite and osmiride is theoretically possible, but very unlikely.

In 2004, JINR started a search for natural hassium in the Modane Underground Laboratory in Modane, Auvergne-Rhône-Alpes, France; this was done underground to avoid interference and false positives from cosmic rays. In 2008–09, an experiment run in the laboratory resulted in detection of several registered events of neutron multiplicity (number of emitted free neutrons after a nucleus hit has been hit by a neutron and fissioned) above three in natural osmium, and in 2012–13, these findings were reaffirmed in another experiment run in the laboratory. These results hinted natural hassium could potentially exist in nature in amounts that allow its detection by the means of analytical chemistry, but this conclusion is based on an explicit assumption that there is a long-lived hassium isotope to which the registered events could be attributed.

Since Hs may be particularly stable against alpha decay and spontaneous fission, it was considered as a candidate to exist in nature. This nuclide, however, is predicted to be very unstable toward beta decay and any beta-stable isotopes of hassium such as Hs would be too unstable in the other decay channels to be observed in nature. A 2012 search for Hs in nature along with its homologue osmium at the Maier-Leibnitz Laboratory in Garching, Bavaria, Germany, was unsuccessful, setting an upper limit to its abundance at of hassium per gram of osmium.

Various calculations suggest that hassium should be the heaviest group 8 element so far, consistently with the periodic law. Its properties should generally match those expected for a heavier homologue of osmium; as is the case for all transactinides, a few deviations are expected to arise from relativistic effects.

Very few properties of hassium or its compounds have been measured; this is due to its extremely limited and expensive production and the fact that hassium (and its parents) decays very quickly. A few singular chemistry-related properties have been measured, such as enthalpy of adsorption of hassium tetroxide, but properties of hassium metal remain unknown and only predictions are available.

Relativistic effects on hassium should arise due to the high charge of its nuclei, which causes the electrons around the nucleus to move faster—so fast their velocity becomes comparable to the speed of light. There are three main effects: the direct relativistic effect, the indirect relativistic effect, and spin–orbit splitting. (The existing calculations do not account for Breit interactions, but those are negligible, and their omission can only result in an uncertainty of the current calculations of no more than 2%.)

As atomic number increases, so does the electrostatic attraction between an electron and the nucleus. This causes the velocity of the electron to increase, which leads to an increase in its mass. This in turn leads to contraction of the atomic orbitals, most specifically the s and p orbitals. Their electrons become more closely attached to the atom and harder to pull from the nucleus. This is the direct relativistic effect. It was originally thought to be strong only for the innermost electrons, but was later established to significantly influence valence electrons as well.

Since the s and p orbitals are closer to the nucleus, they take a bigger portion of the electric charge of the nucleus on themselves ("shield" it). This leaves less charge for attraction of the remaining electrons, whose orbitals therefore expand, making them easier to pull from the nucleus. This is the indirect relativistic effect. As a result of the combination of the direct and indirect relativistic effects, the Hs ion, compared to the neutral atom, lacks a 6d electron, rather than a 7s electron. In comparison, Os lacks a 6s electron compared to the neutral atom. The ionic radius (in oxidation state +8) of hassium is greater than that of osmium because of the relativistic expansion of the 6p orbitals, which are the outermost orbitals for an Hs ion (although in practice such highly charged ions would be too polarised in chemical environments to have much reality).

There are several kinds of electronic orbitals, denoted by the letters s, p, d, and f (g orbitals are expected to start being chemically active among elements after element 120). Each of these corresponds to an azimuthal quantum number "l": s to 0, p to 1, d to 2, and f to 3. Every electron also corresponds to a spin quantum number "s", which may equal either +1/2 or −1/2. Thus, the total angular momentum quantum number "j = l" + "s" is equal to "j" = "l" ± 1/2 (except for "l" = 0, for which for both electrons in each orbital "j =" 0 + 1/2 = 1/2). Spin of an electron interacts with its orbit, and this interaction is relativistic. It leads to a split of a subshell into two with different energies (the one with "j" = "l" − 1/2 is lower in energy and thus these electrons more difficult to extract): for instance, of the six 6p electrons, two become 6p and four become 6p. This is the spin–orbit splitting (sometimes also referred to as subshell splitting or "jj" coupling). It is most visible with p electrons, which do not play an important role in the chemistry of hassium, but those for d and f electrons are within the same order of magnitude (quantitatively, spin–orbit splitting in expressed in energy units, such as electronvolts).

These relativistic effects are responsible for the expected increase of the ionization energy, decrease of the electron affinity, and increase of stability of the +8 oxidation state compared to osmium; without them, the trends would be reversed. Relativistic effects decrease the atomization energies of the compounds of hassium because the spin–orbit splitting of the d orbital lowers binding energy between electrons and the nucleus and because relativistic effects decrease ionic character in bonding.

The previous members of group 8 have relatively high melting points: Fe, 1538 °C; Ru, 2334 °C; Os, 3033 °C. Much like them, hassium is predicted to be a solid at room temperature although its melting point has not been precisely calculated. Hassium should crystallize in the hexagonal close-packed structure (/ = 1.59), similarly to its lighter congener osmium. Pure metallic hassium is calculated to have a bulk modulus (resistance to uniform compression) of 450 GPa, comparable with that of diamond, 442 GPa. Hassium is expected to have a bulk density of 41 g/cm at standard pressure and temperature, the highest of any of the 118 known elements and nearly twice the highest density of an element observed to this day (22.6 g/cm).

The atomic radius of hassium is expected to be around 126 pm. Due to the relativistic stabilization of the 7s orbital and destabilization of the 6d orbital, the Hs ion is predicted to have an electron configuration of [Rn] 5f 6d 7s, giving up a 6d electron instead of a 7s electron, which is the opposite of the behaviour of its lighter homologues. The Hs ion is expected to have an electron configuration of [Rn] 5f 6d 7s, analogous to that calculated for the Os ion. In chemical compounds, hassium is calculated to display bonding characteristic for a d-block element, whose bonding will be primarily executed by 6d and 6d orbitals; compared to the elements from the previous periods, 7s, 6p, 6p, and 7p orbitals should be more important.

Hassium is the sixth member of the 6d series of transition metals and is expected to be much like the platinum group metals. Some of these properties were confirmed by gas-phase chemistry experiments. The group 8 elements portray a wide variety of oxidation states but ruthenium and osmium readily portray their group oxidation state of +8; this state becomes more stable down the group. This oxidation state is extremely rare: among stable elements, only ruthenium, osmium, and xenon are able to attain it in reasonably stable compounds. Hassium is expected to follow its congeners and have a stable +8 state, but like them it should show lower stable oxidation states such as +6, +4, +3, and +2. Hassium(IV) is expected to be more stable than hassium(VIII) in aqueous solution. Hassium should be a rather noble metal. The standard reduction potential for the Hs/Hs couple is expected to be 0.4 V.

The group 8 elements show a distinctive oxide chemistry. All of the lighter members have known or hypothetical tetroxides, MO. Their oxidizing power decreases as one descends the group. FeO is not known due to its extraordinarily large electron affinity—the amount of energy released when an electron is added to a neutral atom or molecule to form a negative ion—which results in the formation of the well-known oxyanion ferrate(VI), . Ruthenium tetroxide, RuO, which is formed by oxidation of ruthenium(VI) in acid, readily undergoes reduction to ruthenate(VI), . Oxidation of ruthenium metal in air forms the dioxide, RuO. In contrast, osmium burns to form the stable tetroxide, OsO, which complexes with the hydroxide ion to form an osmium(VIII) -"ate" complex, [OsO(OH)]. Therefore, hassium should behave as a heavier homologue of osmium by forming of a stable, very volatile tetroxide HsO, which undergoes complexation with hydroxide to form a hassate(VIII), [HsO(OH)]. Ruthenium tetroxide and osmium tetroxide are both volatile due to their symmetrical tetrahedral molecular geometry and because they are charge-neutral; hassium tetroxide should similarly be a very volatile solid. The trend of the volatilities of the group 8 tetroxides is experimentally known to be RuO < OsO > HsO, which confirms the calculated results. In particular, the calculated enthalpies of adsorption—the energy required for the adhesion of atoms, molecules, or ions from a gas, liquid, or dissolved solid to a surface—of HsO, −(45.4 ± 1) kJ/mol on quartz, agrees very well with the experimental value of −(46 ± 2) kJ/mol.

The first goal for chemical investigation was the formation of the tetroxide; it was chosen because ruthenium and osmium form volatile tetroxides, being the only transition metals to display a stable compound in the +8 oxidation state. Despite this selection for gas-phase chemical studies being clear from the beginning, chemical characterization of hassium was considered a difficult task for a long time. Although hassium isotopes were first synthesized in 1984, it was not until 1996 that a hassium isotope long-lived enough to allow chemical studies was synthesized. Unfortunately, this hassium isotope, Hs, was synthesized indirectly from the decay of Cn; not only are indirect synthesis methods not favourable for chemical studies, but the reaction that produced the isotope Cn had a low yield—its cross section was only 1 pb—and thus did not provide enough hassium atoms for a chemical investigation. Direct synthesis of Hs and Hs in the reaction Cm(Mg,"x"n)Hs ("x" = 4 or 5) appeared more promising because the cross section for this reaction was somewhat larger at 7 pb. This yield was still around ten times lower than that for the reaction used for the chemical characterization of bohrium. New techniques for irradiation, separation, and detection had to be introduced before hassium could be successfully characterized chemically.

Ruthenium and osmium have very similar chemistry due to the lanthanide contraction but iron shows some differences from them; for example, although ruthenium and osmium form stable tetroxides in which the metal is in the +8 oxidation state, iron does not. In preparation for the chemical characterization of hassium, research focused on ruthenium and osmium rather than iron because hassium was expected to be similar to ruthenium and osmium, as the predicted data on hassium closely matched that of those two.

The first chemistry experiments were performed using gas thermochromatography in 2001, using the synthetic osmium radioisotopes Os and Os as a reference. During the experiment, seven hassium atoms were synthesized using the reactions Cm(Mg,5n)Hs and Cm(Mg,4n)Hs. They were then thermalized and oxidized in a mixture of helium and oxygen gases to form hassium tetroxide molecules.

The measured deposition temperature of hassium tetroxide was higher than that of osmium tetroxide, which indicated the former was the less volatile one, and this placed hassium firmly in group 8. The enthalpy of adsorption for HsO measured, , was significantly lower than the predicted value, , indicating OsO is more volatile than HsO, contradicting earlier calculations that implied they should have very similar volatilities. For comparison, the value for OsO is . (The calculations that yielded a closer match to the experimental data came after the experiment, in 2008.) It is possible hassium tetroxide interacts differently with silicon nitride than with silicon dioxide, the chemicals used for the detector; further research is required to establish whether there is a difference between such interactions and whether it has influenced the measurements. Such research would include more accurate measurements of the nuclear properties of Hs and comparisons with RuO in addition to OsO.

In 2004, scientists reacted hassium tetroxide and sodium hydroxide to form sodium hassate(VIII), a reaction that is well known with osmium. This was the first acid-base reaction with a hassium compound, forming sodium hassate(VIII):

The team from the University of Mainz planned in 2008 to study the electrodeposition of hassium atoms using the new TASCA facility at GSI. Their aim was to use the reaction Ra(Ca,4n)Hs. Scientists at GSI were hoping to use TASCA to study the synthesis and properties of the hassium(II) compound hassocene, Hs(CH), using the reaction Ra(Ca,"x"n). This compound is analogous to the lighter compounds ferrocene, ruthenocene, and osmocene, and is expected to have the two cyclopentadienyl rings in an eclipsed conformation like ruthenocene and osmocene and not in a staggered conformation like ferrocene. Hassocene, which is expected to be a stable and highly volatile compound, was chosen because it has hassium in the low formal oxidation state of +2—although the bonding between the metal and the rings is mostly covalent in metallocenes—rather than the high +8 state that had previously been investigated, and relativistic effects were expected to be stronger in the lower oxidation state. The highly symmetrical structure of hassocene and its low number of atoms make relativistic calculations easier. , there are no experimental reports of hassocene.


</doc>
<doc id="13765" url="https://en.wikipedia.org/wiki?curid=13765" title="Henry Kissinger">
Henry Kissinger

Henry Alfred Kissinger (; ; born Heinz Alfred Kissinger; May 27, 1923) is an American politician, diplomat, and geopolitical consultant who served as United States Secretary of State and National Security Advisor under the presidential administrations of Richard Nixon and Gerald Ford. A Jewish refugee who fled Nazi Germany with his family in 1938, he became National Security Advisor in 1969 and U.S. Secretary of State in 1973. For his actions negotiating a ceasefire in Vietnam, Kissinger received the 1973 Nobel Peace Prize under controversial circumstances, with two members of the committee resigning in protest.

A practitioner of "Realpolitik", Kissinger played a prominent role in United States foreign policy between 1969 and 1977. During this period, he pioneered the policy of "détente" with the Soviet Union, orchestrated the opening of relations with the People's Republic of China, engaged in what became known as shuttle diplomacy in the Middle East to end the Yom Kippur War, and negotiated the Paris Peace Accords, ending American involvement in the Vietnam War. Kissinger has also been associated with such controversial policies as U.S. involvement in the 1973 Chilean military coup, a "green light" to Argentina's military junta for their Dirty War, and U.S. support for Pakistan during the Bangladesh War despite the genocide being perpetrated by his allies. After leaving government, he formed Kissinger Associates, an international geopolitical consulting firm. Kissinger has written over a dozen books on diplomatic history and international relations.

Kissinger remains a controversial and polarizing figure in American politics, both condemned as an alleged war criminal by many journalists, political activists, and human rights lawyers, as well as venerated as a highly effective U.S. Secretary of State by many prominent international relations scholars.

Kissinger was born Heinz Alfred Kissinger in Fürth, Bavaria, Germany in 1923 to a German Jewish family. His father Louis Kissinger (1887–1982) was a schoolteacher. His mother Paula (Stern) Kissinger (1901–1998), from Leutershausen, was a homemaker. His brother, Walter Kissinger, was born in 1924. The surname Kissinger was adopted in 1817 by his great-great-grandfather Meyer Löb, after the Bavarian spa town of Bad Kissingen. In his youth, Kissinger enjoyed playing soccer. He played for the youth wing of SpVgg Fürth, which was one of the nation's best clubs at the time. 

In 1938, when Kissinger was 15 years old, he and his family fled Germany as a result of Nazi persecution. The family briefly emigrated to London before arriving in New York City on September 5.

Kissinger spent his high school years in the Washington Heights section of Upper Manhattan as part of the German Jewish immigrant community that resided there at the time. Although Kissinger assimilated quickly into American culture, he never lost his pronounced German accent, due to childhood shyness that made him hesitant to speak. After his first year at George Washington High School, he began attending school at night and worked in a shaving brush factory during the day.

Following high school, Kissinger enrolled in the City College of New York, studying accounting. He excelled academically as a part-time student, continuing to work while enrolled. His studies were interrupted in early 1943, when he was drafted into the US Army.

Kissinger underwent basic training at Camp Croft in Spartanburg, South Carolina. On June 19, 1943, while stationed in South Carolina, at the age of 20 years, he became a naturalized U.S. citizen. The army sent him to study engineering at Lafayette College, Pennsylvania, but the program was canceled, and Kissinger was reassigned to the 84th Infantry Division. There, he made the acquaintance of Fritz Kraemer, a fellow Jewish immigrant from Germany who noted Kissinger's fluency in German and his intellect, and arranged for him to be assigned to the military intelligence section of the division. Kissinger saw combat with the division, and volunteered for hazardous intelligence duties during the Battle of the Bulge.

During the American advance into Germany, Kissinger, only a private, was put in charge of the administration of the city of Krefeld, owing to a lack of German speakers on the division's intelligence staff. Within eight days he had established a civilian administration. Kissinger was then reassigned to the Counter Intelligence Corps (CIC), where he became a CIC Special Agent holding the enlisted rank of sergeant. He was given charge of a team in Hanover assigned to tracking down Gestapo officers and other saboteurs, for which he was awarded the Bronze Star. In June 1945, Kissinger was made commandant of the Bensheim metro CIC detachment, Bergstrasse district of Hesse, with responsibility for de-Nazification of the district. Although he possessed absolute authority and powers of arrest, Kissinger took care to avoid abuses against the local population by his command.

In 1946, Kissinger was reassigned to teach at the European Command Intelligence School at Camp King and, as a civilian employee following his separation from the army, continued to serve in this role.

Henry Kissinger received his AB degree "summa cum laude", Phi Beta Kappa in political science from Harvard College in 1950, where he lived in Adams House and studied under William Yandell Elliott. His senior undergraduate thesis, titled "The Meaning of History: Reflections on Spengler, Toynbee and Kant", was over 400 pages long. He received his MA and PhD degrees at Harvard University in 1951 and 1954, respectively. In 1952, while still a graduate student at Harvard, he served as a consultant to the director of the Psychological Strategy Board.

His doctoral dissertation was titled "Peace, Legitimacy, and the Equilibrium (A Study of the Statesmanship of Castlereagh and Metternich)". In his PhD dissertation, Kissinger first introduced the concept of "legitimacy", which he defined as: "Legitimacy as used here should not be confused with justice. It means no more than an international agreement about the nature of workable arrangements and about the permissible aims and methods of foreign policy". An international order accepted by all of the major powers is "legitimate" whereas an international order not accepted by one or more of the great powers is "revolutionary" and hence dangerous. Thus, when after the Congress of Vienna in 1815, the leaders of Britain, France, Austria, Prussia and Russia agreed to co-operate in the Concert of Europe to preserve the peace, in Kissinger's viewpoint this international system was "legitimate" because it was accepted by the leaders of all five of the Great Powers of Europe. Notably, Kissinger's "primat der aussenpolitik" approach to diplomacy took it for granted that as long as the decision-makers in the major states were willing to accept the international order, then it is "legitimate" with questions of public opinion and morality dismissed as irrelevant.

Kissinger remained at Harvard as a member of the faculty in the Department of Government and, with Robert R. Bowie, co-founded the Center for International Affairs in 1958 where he served as associate director. In 1955, he was a consultant to the National Security Council's Operations Coordinating Board. During 1955 and 1956, he was also study director in nuclear weapons and foreign policy at the Council on Foreign Relations. He released his book "Nuclear Weapons and Foreign Policy" the following year. The book which was a critique of the Eisenhower Administration's "massive retaliation" nuclear doctrine caused much controversy at the time with its advocacy of using tactical nuclear weapons on a regular basis to win wars.

From 1956 to 1958 he worked for the Rockefeller Brothers Fund as director of its Special Studies Project. He was director of the Harvard Defense Studies Program between 1958 and 1971. He was also director of the Harvard International Seminar between 1951 and 1971. Outside of academia, he served as a consultant to several government agencies and think tanks, including the Operations Research Office, the Arms Control and Disarmament Agency, Department of State, and the RAND Corporation.

Keen to have a greater influence on U.S. foreign policy, Kissinger became foreign policy advisor to the presidential campaigns of Nelson Rockefeller, supporting his bids for the Republican nomination in 1960, 1964, and 1968. Kissinger first met Richard Nixon at a party hosted by Clare Booth Luce in 1967, saying that he found him more "thoughtful" than what he expected. During the Republican primaries in 1968, Kissinger again served as the foreign policy adviser to Rockefeller and in July 1968 called Nixon "the most dangerous of all the men running to have as president". Initially upset when Nixon won the Republican nomination, the ambitious Kissinger soon changed his mind about Nixon and contacted a Nixon campaign aide, Richard Allen, to state he was willing to do anything to help Nixon win. After Nixon became president in January 1969, Kissinger was appointed as National Security Advisor.

Kissinger served as National Security Advisor and Secretary of State under President Richard Nixon, and continued as Secretary of State under Nixon's successor Gerald Ford. The relationship between Nixon and Kissinger was unusually close, and has been compared to the relationships of Woodrow Wilson and Colonel House, or Franklin D. Roosevelt and Harry Hopkins. In all three cases, the State Department was relegated to a backseat role in developing foreign policy. Kissinger and Nixon shared a penchant for secrecy and conducted numerous "backchannel" negotiations, such as that through the Soviet Ambassador to the United States, Anatoly Dobrynin, that excluded State Department experts. Historian David Rothkopf has looked at the personalities of Nixon and Kissinger:

A proponent of "Realpolitik", Kissinger played a dominant role in United States foreign policy between 1969 and 1977. In that period, he extended the policy of "détente". This policy led to a significant relaxation in US–Soviet tensions and played a crucial role in 1971 talks with Chinese Premier Zhou Enlai. The talks concluded with a rapprochement between the United States and the People's Republic of China, and the formation of a new strategic anti-Soviet Sino-American alignment. He was jointly awarded the 1973 Nobel Peace Prize with Lê Đức Thọ for helping to establish a ceasefire and U.S. withdrawal from Vietnam. The ceasefire, however, was not durable. Thọ declined to accept the award and Kissinger appeared deeply ambivalent about it (donating his prize money to charity, not attending the award ceremony and later offering to return his prize medal). As National Security Advisor, in 1974 Kissinger directed the much-debated National Security Study Memorandum 200.

Kissinger initially had little interest in China when began his work as National Security Adviser in 1969, and the driving force being the rapprochement with China was Nixon. When Chiang Ching-kuo arrived in Washington in April 1970 for a visit, both Nixon and Kissinger promised him that they would never abandon Taiwan or make any compromises with Mao Zedong, although Nixon did speak vaguely of his wish to improve relations with the People's Republic. 

Kissinger made two trips to the People's Republic of China in July and October 1971 (the first of which was made in secret) to confer with Premier Zhou Enlai, then in charge of Chinese foreign policy. During his visit to Beijing, the main issue turned out to be Taiwan, as Zhou demanded the United States recognize that Taiwan was a legitimate part of the People's Republic of China, pull U.S. forces out of Taiwan, and end military support for the Kuomintang regime. Kissinger gave way by promising to pull U.S. forces out of Taiwan, saying two-thirds would be pulled out when the Vietnam war ended and the rest to be pulled out as Sino-American relations improved.

In October 1971, as Kissinger was making his second trip to the People's Republic, the issue of which Chinese government deserved to be represented in the United Nations came up again. Out of concern to not be seen abandoning an ally, the United States tried to promote a compromise under which both Chinese regimes would be UN members, although Kissinger called it "an essentially doomed rearguard action". While American ambassador to the UN George H. W. Bush was lobbying for the "two Chinas" formula, Kissinger was removing favorable references to Taiwan from a speech that Rogers was preparing, as he expected the Republic of China to be expelled from the UN. During his second visit to Beijing, Kissinger told Zhou that according to a public opinion poll 62% of Americans wanted Taiwan to remain an UN member, and asked him to consider the "two Chinas" compromise to avoid offending American public opinion. Zhou responded with his claim that the People's Republic was the legitimate government of all China and no compromise was possible with the Taiwan issue. Kissinger said that the United States could not totally sever ties with Chiang, who had been an ally in World War II. Kissinger told Nixon that Bush was "too soft and not sophisticated" enough to properly represent the United States at the UN, and expressed no anger when the UN General Assembly voted to expel Taiwan and give China's seat on the UN Security Council to the People's Republic. 

His trips paved the way for the groundbreaking 1972 summit between Nixon, Zhou, and Communist Party of China Chairman Mao Zedong, as well as the formalization of relations between the two countries, ending 23 years of diplomatic isolation and mutual hostility. The result was the formation of a tacit strategic anti-Soviet alliance between China and the United States. Kissinger's diplomacy led to economic and cultural exchanges between the two sides and the establishment of "liaison offices" in the Chinese and American capitals, though full normalization of relations with the People's Republic of China would not occur until 1979.

Kissinger's involvement in Indochina started prior to his appointment as National Security Adviser to Nixon. While still at Harvard, he had worked as a consultant on foreign policy to both the White House and State Department. In a 1967 peace initiative, he would mediate between Washington and Hanoi.

When he came into office in 1969, Kissinger favored a negotiating strategy under which the United States and North Vietnam would sign an armistice and agreed to pull their troops out of South Vietnam while the South Vietnamese government and the Viet Cong were to agree to a coalition government. Kissinger had doubts about Nixon's theory of "linkage", believing that this would give the Soviet Union leverage over the United States and unlike Nixon was less concerned about the ultimate fate of South Vietnam. Through Kissinger did not regard South Vietnam as important in its own right, he believed it was necessary to support South Vietnam to maintain the United States as a global power, believing that none of America's allies would trust the United States if South Vietnam were abandoned too quickly. 

In early 1969, Kissinger was opposed to the plans for Operation Menu, the bombing of Cambodia, fearing that Nixon was acting rashly with no plans for the diplomatic fall-out, but on March 16, 1969 Nixon announced the bombing would start the next day. As he saw the president was committed, he became more and more supportive. Kissinger would play a key role in bombing Cambodia to disrupt raids into South Vietnam from Cambodia, as well as the 1970 Cambodian Incursion and subsequent widespread bombing of Khmer Rouge targets in Cambodia. 

The Paris peace talks had become stalemated by late 1969 owing to the obstructionism of the South Vietnamese delegation. The South Vietnamese President Nguyễn Văn Thiệu did not want the United States to withdraw from Vietnam, and out of frustration with him, Kissinger decided to begin secret peace talks with Tho in Paris parallel to the official talks that the South Vietnamese were unaware of. 

In June 1971, Kissinger supported Nixon's effort to ban the Pentagon Papers saying the "hemorrhage of state secrets" to the media was making diplomacy impossible. 

On August 1, 1972, Kissinger met Tho again in Paris, and for first time, he seemed willing to compromise, saying that political and military terms of an armistice could be treated separately and hinted that his government was no longer willing to make the overthrow of Thiệu a precondition.

On the evening of October 8, 1972 at a secret meeting of Kissinger and Tho in Paris came the decisive breakthrough in the talks. Tho began with "a very realistic and very simple proposal" for a ceasefire that would see the Americans pull all their forces out of Vietnam in exchange for the release of all the POWs in North Vietnam. Kissinger accepted Tho's offer as the most best deal possible, saying that the "mutual withdrawal formula" had to be abandoned as it been "unobtainable through ten years of war...We could not make it a condition for a final settlement. We had long passed that threshold". 

In the fall of 1972, both Kissinger and Nixon were frustrated with Thiệu's refusal to accept any sort of peace deal calling for withdrawal of American forces. On October 21 Kissinger and the American ambassador Ellsworth Bunker arrived in Saigon to show Thiệu the peace agreement. Thiệu refused to sign the peace agreement and demanded very extensive amendments that Kissinger reported to Nixon "verge on insanity". 

Through Nixon had initially supported Kissinger against Thiệu, H.R. Haldeman and John Ehrlichman urged him to reconsider, arguing that Thiệu's objections had merit. Nixon wanted 69 amendments to the draft peace agreement included in the final treaty, and ordered Kissinger back to Paris to force Tho to accept them. Kissinger regarded Nixon's 69 amendments as "preposterous" as he knew Tho would never accept them. As expected, Tho refused to consider any of the 69 amendments, and on December 13, 1972 left Paris for Hanoi. Kissinger by this stage was worked up into a state of fury after Tho walked out of the Paris talks and told Nixon: "They're just a bunch of shits. Tawdry, filthy shits". 

On January 8, 1973, Kissinger and Tho met again in Paris and the next day reached an agreement, which in main points was essentially the same as the one Nixon had rejected in October with only cosmetic concessions to the Americans. Thiệu once again rejected the peace agreement, only to receive an ultimatum from Nixon which caused Thiệu to reluctantly accept the peace agreement. On January 27, 1973, Kissinger and Tho signed a peace agreement that called for the complete withdrawal of all U.S forces from Vietnam by March in exchange for North Vietnam freeing all the U.S POWs. 

Along with Le Duc Tho, Kissinger was awarded the Nobel Peace Prize on December 10, 1973, for their work in negotiating the ceasefires contained in the Paris Peace Accords on "Ending the War and Restoring Peace in Vietnam", signed the previous January. According to Irwin Abrams, this prize was the most controversial to date. For the first time in the history of the Peace Prize, two members left the Nobel Committee in protest. Tho rejected the award, telling Kissinger that peace had not been restored in South Vietnam. Kissinger wrote to the Nobel Committee that he accepted the award "with humility," and "donated the entire proceeds to the children of American servicemembers killed or missing in action in Indochina." After the Fall of Saigon in 1975, Kissinger attempted to return the award.

By the summer of 1974, the U.S. embassy reported that morale in the ARVN had fallen to dangerously low levels and it was uncertain how much more longer South Vietnam would last. In August 1974, Congress passed a bill limiting American aid to South Vietnam to $700 million annually. By November 1974, Kissinger lobbied Brezhnev to end Soviet military aid to North Vietnam. The same month, he also lobbied Mao and Zhou to end Chinese military aid to North Vietnam. On April 15, 1975, Kissinger testified before the Senate Appropriations Committee, urging Congress to increase the military aid budget to South Vietnam by another $700 million to save the ARVN as the PAVN was rapidly advancing on Saigon, which was refused. Kissinger maintained at the time, and still maintains, that if only Congress had approved of his request for another $700 million South Vietnam would have been saved.

Nixon supported Pakistan's strongman, General Yahya Khan, in the Bangladesh Liberation War in 1971. Kissinger sneered at people who "bleed" for "the dying Bengalis" and ignored the first telegram from the United States consul general in East Pakistan, Archer K. Blood, and 20 members of his staff, which informed the US that their allies West Pakistan were undertaking, in Blood's words, "a selective genocide" targeting the Bengali intelligentsia, supporters of independence for East Pakistan, and the Hindu minority. In the second, more famous, Blood Telegram the word genocide was again used to describe the events, and further that with its continuing support for West Pakistan the US government had "evidenced [...] moral bankruptcy".
As a direct response to the dissent against US policy Kissinger and Nixon ended Archer Blood's tenure as United States consul general in East Pakistan and put him to work in the State Department's Personnel Office. Christopher Clary argues that Nixon and Kissinger were unconsciously biased, leading them to overestimate the likelihood of Pakistani victory against Bengali rebels.

Kissinger was particularly concerned about the expansion of Soviet influence in the Indian Subcontinent as a result of a treaty of friendship recently signed by India and the USSR, and sought to demonstrate to the People's Republic of China (Pakistan's ally and an enemy of both India and the USSR) the value of a tacit alliance with the United States.

Kissinger had also come under fire for private comments he made to Nixon during the Bangladesh–Pakistan War in which he described Indian Prime Minister Indira Gandhi as a "bitch" and a "witch". He also said "The Indians are bastards", shortly before the war. Kissinger has since expressed his regret over the comments.

As National Security Adviser under Nixon, Kissinger pioneered the policy of "détente" with the Soviet Union, seeking a relaxation in tensions between the two superpowers. As a part of this strategy, he negotiated the Strategic Arms Limitation Talks (culminating in the SALT I treaty) and the Anti-Ballistic Missile Treaty with Leonid Brezhnev, General Secretary of the Soviet Communist Party. Negotiations about strategic disarmament were originally supposed to start under the Johnson Administration but were postponed in protest upon the invasion by Warsaw Pact troops of Czechoslovakia in August 1968.

Nixon felt his administration had neglected relations with the Western European states in his first term and in September 1972 decided that if he was reelected that 1973 would be the "Year of Europe" as the United States would focus on relations with the states of the European Economic Community (EEC) which had emerged as a serious economic rival by 1970. Applying his favorite "linkage" concept, Nixon intended henceforward economic relations with Europe would not be severed from security relations, and if the EEC states wanted changes in American tariff and monetary policies, the price would be defense spending on their part. Kissinger in particular as part of the "Year of Europe" wanted to "revitalize" NATO, which he called a "decaying" alliance as he believed that there was nothing at present to stop the Red Army from overrunning Western Europe in a conventional forces conflict. The "linkage" concept more applied to the question of security as Kissinger noted that the United States was going to sacrifice NATO for the sake of "citrus fruits".

According to notes taken by H.R. Haldeman, Nixon "ordered his aides to exclude all Jewish-Americans from policy-making on Israel", including Kissinger. One note quotes Nixon as saying "get K. [Kissinger] out of the play—Haig handle it".

In 1973, Kissinger did not feel that pressing the Soviet Union concerning the plight of Jews being persecuted there was in the interest of U.S. foreign policy. In conversation with Nixon shortly after a meeting with Israeli Prime Minister Golda Meir on March 1, 1973, Kissinger stated, "The emigration of Jews from the Soviet Union is not an objective of American foreign policy, and if they put Jews into gas chambers in the Soviet Union, it is not an American concern. Maybe a humanitarian concern." 

In September 1973, Nixon fired Rogers as Secretary of State and replaced him with Kissinger. He would later state he had not been given enough time to know the Middle East as he settled into the State Department. Kissinger later admitted that he was so engrossed with the Paris peace talks to end the Vietnam war that he and others in Washington missed the significance of the Egyptian-Saudi alliance. Sadat expected as a reward that the United States would respond by pressuring Israel to return the Sinai to Egypt, but after receiving no response from the United States, by November 1972 Sadat moved again closer to the Soviet Union, buying a massive amount of Soviet arms for a war he planned to launch against Israel in 1973. 

Kissinger delayed telling President Richard Nixon about the start of the Yom Kippur War in 1973 to keep him from interfering. On October 6, 1973, the Israelis informed Kissinger about the attack at 6 am; Kissinger waited nearly 3 and a half hours before he informed Nixon. According to Kissinger, he was notified at 6:30 a.m. (12:30 pm. Israel time) that war was imminent, and his urgent calls to the Soviets and Egyptians were ineffective. On October 12, under Nixon's direction, and against Kissinger's initial advice, while Kissinger was on his way to Moscow to discuss conditions for a cease-fire, Nixon sent a message to Brezhnev giving Kissinger full negotiating authority. Kissinger wanted to stall a ceasefire to gain more time for Israel to push across the Suez Canal to the African side, and wanted to be perceived as a mere presidential emissary who needed to consult the White House all the time as a stalling tactic.
Kissinger promised the Israeli Prime Minister Golda Meir that the United States would replace its losses in equipment after the war, but sought initially to delay arm shipments to Israel, as he believed it would improve the odds of making peace along the lines of United Nations Security Council Resolution 242. In 1973, Meir requested $850 million worth of American arms and equipment to replace its material losses. Nixon instead sent some $2 billion worth. The arms lift enraged King Faisal of Saudi Arabia, and he retaliated on October 20, 1973 by placing a total embargo on oil shipments to the United States, to be joined by all of the other oil-producing Arab states except Iraq and Libya. 

On November 7, 1973, Kissinger flew to Riyadh to meet King Faisal and to ask him to end the oil embargo in exchange for promising to be "even handed" in the Arab-Israeli dispute. Despite all of Kissinger's efforts to charm him, Faisal refused to end the oil embargo. Only on March 19, 1974 did the king end the oil embargo, after Sadat reported to him that the United States was being more "even handed" and after Kissinger had promised to sell Saudi Arabia weapons that it had previously denied under the grounds that they might be used against Israel. 

Kissinger pressured the Israelis to cede some of the newly captured land back to its Arab neighbors, contributing to the first phases of Israeli–Egyptian non-aggression. In 1973–74, Kissinger engaged in "shuttle diplomacy" flying between Tel Aviv, Cairo and Damascus in a bid to make the armistice the basis of a preferment peace. Kissinger's first meeting with Assad lasted 6 hours and 30 minutes, causing the press to believe for a moment that he had been kidnapped by the Syrians. In his memoirs, Kissinger described how, during the course of his 28 meetings in Damascus in 1973–74, Assad "negotiated tenaciously and daringly like a riverboat gambler to make sure he had exacted the last sliver of available concessions".

In contrast, Kissinger's negotiations with Sadat, through not without difficulties, were more fruitful. The move saw a warming in U.S.–Egyptian relations, bitter since the 1950s, as the country moved away from its former independent stance and into a close partnership with the United States.

A major concern for Kissinger was the possibility of Soviet influence in the Persian Gulf. In April 1969, Iraq came into conflict with Iran when Shah Mohammad Reza Pahlavi renounced the 1937 treaty governing the Shatt-al-Arab river. After two years of skirmishes along the border, President Ahmed Hassan al-Bakr broke off diplomatic relations with Iran on December 1, 1971. In May 1972, Nixon and Kissinger visited Tehran to tell the Shah that there would be no "second-guessing of his requests" to buy American weapons. At the same time, Nixon and Kissinger agreed a plan of the Shah's that the United States together with Iran and Israel would support the Kurdish "peshmerga" guerrillas fighting for independence from Iraq. Kissinger later wrote that after Vietnam, there was no possibility of deploying American forces in the Middle East, and henceforward Iran was to act as America's surrogate in the Persian Gulf. Kissinger described the Baathist regime in Iraq as a potential threat to the United States and believed that building up Iran and supporting the "peshmerga" was the best counterweight.

Following a period of steady relations between the U.S. Government and the Greek military regime after 1967, Secretary of State Kissinger was faced with the coup by the Greek junta and the Turkish invasion of Cyprus in July and August 1974. In an August 1974 edition of "The New York Times", it was revealed that Kissinger and State Department were informed in advance οf the impending coup by the Greek junta in Cyprus. Indeed, according to the journalist, the official version of events as told by the State Department was that it felt it had to warn the Greek military regime not to carry out the coup. Kissinger was a target of anti-American sentiment which was a significant feature of Greek public opinion at the time—particularly among young people—viewing the U.S. role in Cyprus as negative. In a demonstration by students in Heraklion, Crete, soon after the second phase of the Turkish invasion in August 1974, slogans such as "Kissinger, murderer", "Americans get out", "No to Partition" and "Cyprus is no Vietnam" were heard. Some years later, Kissinger expressed the opinion that the Cyprus issue was resolved in 1974.

The United States continued to recognize and maintain relationships with non-left-wing governments, democratic and authoritarian alike. John F. Kennedy's Alliance for Progress was ended in 1973. In 1974, negotiations over a new settlement for the Panama Canal began, and they eventually led to the Torrijos-Carter Treaties and the handing over of the Canal to Panamanian control.

Kissinger initially supported the normalization of United States-Cuba relations, broken since 1961 (all U.S.–Cuban trade was blocked in February 1962, a few weeks after the exclusion of Cuba from the Organization of American States because of U.S. pressure). However, he quickly changed his mind and followed Kennedy's policy. After the involvement of the Cuban Revolutionary Armed Forces in the independence struggles in Angola and Mozambique, Kissinger said that unless Cuba withdrew its forces relations would not be normalized. Cuba refused.

Chilean Socialist Party presidential candidate Salvador Allende was elected by a plurality of 36.2 percent in 1970, causing serious concern in Washington, D.C. due to his openly socialist and pro-Cuban politics. The Nixon administration, with Kissinger's input, authorized the Central Intelligence Agency (CIA) to encourage a military coup that would prevent Allende's inauguration, but the plan was not successful.

On September 11, 1973, Allende died during a military coup launched by Army Commander-in-Chief Augusto Pinochet, who became President. In September 1976, Orlando Letelier, a Chilean opponent of the new Pinochet regime, was assassinated in Washington, D.C. with a car bomb. Previously, Kissinger had helped secure his release from prison, and had chosen to cancel a letter to Chile warning them against carrying out any political assassinations. This murder was part of Operation Condor, a covert program of political repression and assassination carried out by Southern Cone nations that Kissinger has been accused of being involved in.

On September 10, 2001, the family of Chilean general René Schneider filed a suit against Kissinger, accusing him of collaborating in arranging Schneider's kidnapping which resulted in his death. The case was later dismissed by a U.S. District Court, citing separation of powers: "The decision to support a coup of the Chilean government to prevent Dr. Allende from coming to power, and the means by which the United States Government sought to effect that goal, implicate policy makers in the murky realm of foreign affairs and national security best left to the political branches." Decades later, the CIA admitted its involvement in the kidnapping of General Schneider, but not his murder, and subsequently paid the group responsible for his death $35,000 "to keep the prior contact secret, maintain the goodwill of the group, and for humanitarian reasons."

Kissinger took a similar line as he had toward Chile when the Argentine military, led by Jorge Videla, toppled the elected government of Isabel Perón in 1976 with a process called the National Reorganization Process by the military, with which they consolidated power, launching brutal reprisals and "disappearances" against political opponents. An October 1987 investigative report in The Nation broke the story of how, in a June 1976 meeting in the Hotel Carrera in Santiago, Kissinger gave the military junta in neighboring Argentina the "green light" for their own clandestine repression against leftwing guerrillas and other dissidents, thousands of whom were kept in more than 400 secret concentration camps before they were executed. During a meeting with Argentine foreign minister César Augusto Guzzetti, Kissinger assured him that the United States was an ally, but urged him to "get back to normal procedures" quickly before the U.S. Congress reconvened and had a chance to consider sanctions.

As the article published in "The Nation" noted, as the state-sponsored terror mounted, conservative Republican U.S. Ambassador to Buenos Aires Robert C. Hill "'was shaken, he became very disturbed, by the case of the son of a thirty-year embassy employee, a student who was arrested, never to be seen again,' recalled former "New York Times" reporter Juan de Onis. 'Hill took a personal interest.' He went to the Interior Minister, a general with whom he had worked on drug cases, saying, 'Hey, what about this? We're interested in this case.' He questioned (Foreign Minister Cesar) Guzzetti and, finally, President Jorge R. Videla himself. 'All he got was stonewalling; he got nowhere.' de Onis said. 'His last year was marked by increasing disillusionment and dismay, and he backed his staff on human rights right to the hilt."

In a letter to "The Nation" editor Victor Navasky, protesting publication of the article, Kissinger claimed that: "At any rate, the notion of Hill as a passionate human rights advocate is news to all his former associates." Yet Kissinger aide Harry W. Shlaudeman later disagreed with Kissinger, telling the oral historian William E. Knight of the Association for Diplomatic Studies and Training Foreign Affairs Oral History Project: "It really came to a head when I was Assistant Secretary, or it began to come to a head, in the case of Argentina where the dirty war was in full flower. Bob Hill, who was Ambassador then in Buenos Aires, a very conservative Republican politician -- by no means liberal or anything of the kind, began to report quite effectively about what was going on, this slaughter of innocent civilians, supposedly innocent civilians -- this vicious war that they were conducting, underground war. He, at one time in fact, sent me a back-channel telegram saying that the Foreign Minister, who had just come for a visit to Washington and had returned to Buenos Aires, had gloated to him that Kissinger had said nothing to him about human rights. I don't know -- I wasn't present at the interview."

Navasky later wrote in his book about being confronted by Kissinger, "'Tell me, Mr. Navasky,' [Kissinger] said in his famous guttural tones, 'how is it that a short article in a obscure journal such as yours about a conversation that was supposed to have taken place years ago about something that did or didn't happen in Argentina resulted in sixty people holding placards denouncing me a few months ago at the airport when I got off the plane in Copenhagen?'"

According to declassified state department files, Kissinger also attempted to thwart the Carter Administration's efforts to halt the mass killings by the 1976–83 military dictatorship.

In September 1976 Kissinger was actively involved in negotiations regarding the Rhodesian Bush War. Kissinger, along with South Africa's Prime Minister John Vorster, pressured Rhodesian Prime Minister Ian Smith to hasten the transition to black majority rule in Rhodesia. With FRELIMO in control of Mozambique and even South Africa withdrawing its support, Rhodesia's isolation was nearly complete. According to Smith's autobiography, Kissinger told Smith of Mrs. Kissinger's admiration for him, but Smith stated that he thought Kissinger was asking him to sign Rhodesia's "death certificate". Kissinger, bringing the weight of the United States, and corralling other relevant parties to put pressure on Rhodesia, hastened the end of minority-rule.

The Portuguese decolonization process brought U.S. attention to the former Portuguese colony of East Timor, which declared its independence in 1975. Indonesian president Suharto regarded East Timor as rightfully part of Indonesia. In December 1975, Suharto discussed invasion plans during a meeting with Kissinger and President Ford in the Indonesian capital of Jakarta. Both Ford and Kissinger made clear that U.S. relations with Indonesia would remain strong and that it would not object to the proposed annexation. They only wanted it done "fast" and proposed that it be delayed until after they had returned to Washington. Accordingly, Suharto delayed the operation for one day. Finally on December 7 Indonesian forces invaded the former Portuguese colony. U.S. arms sales to Indonesia continued, and Suharto went ahead with the annexation plan. According to Ben Kiernan, the invasion and occupation resulted in the deaths of nearly a quarter of the Timorese population from 1975 to 1981.

In February 1976, Kissinger considered launching air strikes against ports and military installations in Cuba, as well as deploying Marine battalions based at the US Navy base at Guantanamo Bay, in retaliation for Cuban President Fidel Castro's decision in late 1975 to send troops to Angola to help the newly independent nation fend off attacks from South Africa and right-wing guerrillas.

Kissinger left office when Democrat Jimmy Carter defeated Republican Gerald Ford in the 1976 presidential elections. Kissinger continued to participate in policy groups, such as the Trilateral Commission, and to maintain political consulting, speaking, and writing engagements.

After Kissinger left office in 1977, he was offered an endowed chair at Columbia University. There was student opposition to the appointment, which became a subject of media commentary. Columbia canceled the appointment as a result.

Kissinger was then appointed to Georgetown University's Center for Strategic and International Studies. He taught at Georgetown's Edmund Walsh School of Foreign Service for several years in the late 1970s. In 1982, with the help of a loan from the international banking firm of E.M. Warburg, Pincus and Company, Kissinger founded a consulting firm, Kissinger Associates, and is a partner in affiliate Kissinger McLarty Associates with Mack McLarty, former chief of staff to President Bill Clinton. He also serves on the board of directors of Hollinger International, a Chicago-based newspaper group, and as of March 1999, was a director of Gulfstream Aerospace.

In September 1989, the "Wall Street Journal"'s John Fialka disclosed that Kissinger took a direct economic interest in US-China relations in March 1989 with the establishment of China Ventures, Inc., a Delaware limited partnership, of which he was chairman of the board and chief executive officer. A US$75 million investment in a joint venture with the Communist Party government's primary commercial vehicle at the time, China International Trust & Investment Corporation (CITIC), was its purpose. Board members were major clients of Kissinger Associates. Kissinger was criticised for not disclosing his role in the venture when called upon by ABC's Peter Jennings to comment the morning after the June 4, 1989 Tiananmen Square massacre. Kissinger's position was generally supportive of Deng Xiaoping's decision to use the military against the demonstrating students and he opposed economic sanctions.

From 1995 to 2001, Kissinger served on the board of directors for Freeport-McMoRan, a multinational copper and gold producer with significant mining and milling operations in Papua, Indonesia. In February 2000, then-president of Indonesia Abdurrahman Wahid appointed Kissinger as a political advisor. He also serves as an honorary advisor to the United States-Azerbaijan Chamber of Commerce.

In 1998, in response to the 2002 Winter Olympic bid scandal, the International Olympic Committee formed a commission, called the “2000 Commission,” to recommend reforms, which Kissinger served on. This service led in 2000 to his appointment as one of five IOC “honor members,” a category the organization described as granted to “eminent personalities from outside the IOC who have rendered particularly outstanding services to it.”

From 2000–2006, Kissinger served as chairman of the board of trustees of Eisenhower Fellowships. In 2006, upon his departure from Eisenhower Fellowships, he received the Dwight D. Eisenhower Medal for Leadership and Service.

In November 2002, he was appointed by President George W. Bush to chair the newly established National Commission on Terrorist Attacks Upon the United States to investigate the September 11 attacks. Kissinger stepped down as chairman on December 13, 2002, rather than reveal his business client list, when queried about potential conflicts of interest.

In the Rio Tinto espionage case of 2009–2010, Kissinger was paid $5 million to advise the multinational mining company how to distance itself from an employee who had been arrested in China for bribery.

Kissinger—along with William Perry, Sam Nunn, and George Shultz—has called upon governments to embrace the vision of a world free of nuclear weapons, and in three "Wall Street Journal" op-eds proposed an ambitious program of urgent steps to that end. The four have created the Nuclear Threat Initiative to advance this agenda. In 2010, the four were featured in a documentary film entitled "Nuclear Tipping Point". The film is a visual and historical depiction of the ideas laid forth in the "Wall Street Journal" op-eds and reinforces their commitment to a world without nuclear weapons and the steps that can be taken to reach that goal.

In December 2008, Kissinger was given the American Patriot Award by the National Defense University Foundation "in recognition for his distinguished career in public service." Earlier that year, a NDU professor had blown the whistle on the fact that a Chilean colleague at the William J. Perry Center for Hemispheric Defense Studies of U.S. Southern Command headquartered at NDU had not only been a member of Pinochet's DINA death squad operation (the same organization responsible for the 1976 car bomb murder of former Chilean Foreign Minister Orlando Letelier and American aide Ronni Karpen Moffitt less than a mile from the White House), but was in addition accused of participating in the torture and murder of seven detainees in Chile. The whistleblower, Martin Edwin Andersen, was not only a senior staff member who earlier—as a senior advisor for policy planning at the Criminal Division of the U.S. Department of Justice—was the first national security whistleblower to receive the U.S. Office of Special Counsel's "Public Servant Award," but was also the same person who broke the story in "The Nation" on Kissinger's "green light" for Argentina's dirty "war."

On November 17, 2016, Kissinger met with then President-elect Donald Trump during which they discussed global affairs. Kissinger also met with President Trump at the White House in May 2017.

In an interview with Charlie Rose on August 17, 2017, Kissinger said about President Trump: "I'm hoping for an Augustinian moment, for St. Augustine ... who in his early life followed a pattern that was quite incompatible with later on when he had a vision, and rose to sainthood. One does not expect the president to become that, but it's conceivable ..." Kissinger also argued that Russian President Vladimir Putin wanted to weaken Hillary Clinton, not elect Donald Trump. Kissinger said that Putin "thought—wrongly incidentally—that she would be extremely confrontational ... I think he tried to weaken the incoming president [Clinton]".

In several articles of his and interviews that he gave during the Yugoslav wars, he criticized the United States' policies in Southeast Europe, among other things for the recognition of Bosnia and Herzegovina as a sovereign state, which he described as a foolish act. Most importantly he dismissed the notion of Serbs and Croats being aggressors or separatist, saying that "they can't be separating from something that has never existed". In addition, he repeatedly warned the West against inserting itself into a conflict that has its roots at least hundreds of years back in time, and said that the West would do better if it allowed the Serbs and Croats to join their respective countries. Kissinger shared similarly critical views on Western involvement in Kosovo. In particular, he held a disparaging view of the Rambouillet Agreement:

However, as the Serbs did not accept the Rambouillet text and NATO bombings started, he opted for a continuation of the bombing as NATO's credibility was now at stake, but dismissed the use of ground forces, claiming that it was not worth it.

In 2006, it was reported in the book "" by Bob Woodward that Kissinger met regularly with President George W. Bush and Vice President Dick Cheney to offer advice on the Iraq War. Kissinger confirmed in recorded interviews with Woodward that the advice was the same as he had given in a column in "The Washington Post" on August 12, 2005: "Victory over the insurgency is the only meaningful exit strategy."

In an interview on the BBC's "Sunday AM" on November 19, 2006, Kissinger was asked whether there is any hope left for a clear military victory in Iraq and responded, "If you mean by 'military victory' an Iraqi government that can be established and whose writ runs across the whole country, that gets the civil war under control and sectarian violence under control in a time period that the political processes of the democracies will support, I don't believe that is possible. ... I think we have to redefine the course. But I don't believe that the alternative is between military victory as it had been defined previously, or total withdrawal."

In an interview with Peter Robinson of the Hoover Institution on April 3, 2008, Kissinger reiterated that even though he supported the 2003 invasion of Iraq, he thought that the George W. Bush administration rested too much of its case for war on Saddam's supposed weapons of mass destruction. Robinson noted that Kissinger had criticized the administration for invading with too few troops, for disbanding the Iraqi Army, and for mishandling relations with certain allies.

Kissinger said in April 2008 that "India has parallel objectives to the United States," and he called it an ally of the U.S.

Kissinger was present at the opening ceremony of the 2008 Beijing Summer Olympics. A few months before the Games opened, as controversy over China's human rights record was intensifying due to criticism by Amnesty International and other groups of the widespread use of the death penalty and other issues, Kissinger told the PRC's official press agency Xinhua: “I think one should separate Olympics as a sporting event from whatever political disagreements people may have had with China. I expect that the games will proceed in the spirit for which they were designed, which is friendship among nations, and that other issues are discussed in other forums.” He said China had made huge efforts to stage the Games. “Friends of China should not use the Olympics to pressure China now.” He added that he would bring two of his grandchildren to watch the Games and planned to attend the opening ceremony. During the Games, he participated with Australian swimmer Ian Thorpe, film star Jackie Chan, and former British PM Tony Blair at a Peking University forum on the qualities that make a champion. He sat with his wife Nancy Kissinger, President George W. Bush, former President George H. W. Bush, and Foreign Minister Yang Jiechi at the men's basketball game between China and the U.S.

In 2011, Kissinger published "On China", chronicling the evolution of Sino-American relations and laying out the challenges to a partnership of 'genuine strategic trust' between the U.S. and China.

In his 2011 book "On China", his 2014 book "World Order" and in a 2018 interview with "Financial Times", Kissinger stated that he believes China wants to restore its historic role as the Middle Kingdom and be "the principal adviser to all humanity".

Kissinger's position on this issue of U.S.–Iran talks was reported by the "Tehran Times" to be that "Any direct talks between the U.S. and Iran on issues such as the nuclear dispute would be most likely to succeed if they first involved only diplomatic staff and progressed to the level of secretary of state before the heads of state meet." In 2016, Kissinger said that the biggest challenge facing the Middle East is the "potential domination of the region by an Iran that is both imperial and jihadist." He further wrote in August 2017 that if the Islamic Revolutionary Guard Corps of Iran and its Shiite allies were allowed to fill the territorial vacuum left by a militarily defeated Islamic State of Iraq and the Levant, the region would be left with a land corridor extending from Iran to the Levant "which could mark the emergence of an Iranian radical empire." Commenting on the Joint Comprehensive Plan of Action, Kissinger said that he wouldn't have agreed to it, but that Trump's plan to end the agreement after it was signed would "enable the Iranians to do more than us."

On March 5, 2014, "The Washington Post" published an op-ed piece by Kissinger, 11 days before the Crimean referendum on whether Autonomous Republic of Crimea should officially rejoin Ukraine or join neighboring Russia. In it, he attempted to balance the Ukrainian, Russian and Western desires for a functional state. He made four main points:

Kissinger also wrote: "The west speaks Ukrainian; the east speaks mostly Russian. Any attempt by one wing of Ukraine to dominate the other—as has been the pattern—would lead eventually to civil war or break up."

Following the publication of his book titled "World Order", Kissinger participated in an interview with Charlie Rose and updated his position on Ukraine, which he sees as a possible geographical mediator between Russia and the West. In a question he posed to himself for illustration regarding re-conceiving policy regarding Ukraine, Kissinger stated: "If Ukraine is considered an outpost, then the situation is that its eastern border is the NATO strategic line, and NATO will be within of Volgograd. That will never be accepted by Russia. On the other hand, if the Russian western line is at the border of Poland, Europe will be permanently disquieted. The Strategic objective should have been to see whether one can build Ukraine as a bridge between East and West, and whether one can do it as a kind of a joint effort."

In December 2016, Kissinger advised then President-elect Donald Trump to accept "Crimea as a part of Russia" in an attempt to secure a rapprochement between the United States and Russia, whose relations soured as a result of the Crimean crisis.

When asked if he explicitly considered Russia's sovereignty over Crimea legitimate, Kissinger answered in the affirmative, reversing the position he took in his "Washington Post" op-ed.

In 2019, Kissinger wrote about the increasing tendency to give control of nuclear weapons to computers operating with Artificial Intelligence (AI) that: “Adversaries’ ignorance of AI-developed configurations will become a strategic advantage". Kissinger argued that giving power to launch nuclear weapons to computers using algorithms to make decisions would eliminate the human factor and give the advantage to the state that had the most effective AI system as a computer can make decisions about war and peace far faster than any human ever could. Just as an AI-enhanced computer can win chess games by anticipating human decision-making, an AI-enhanced computer could be useful in a crisis as in a nuclear war, the side that strikes first would have the advantage by destroying the opponent's nuclear capacity. Kissinger also noted there was always the danger that a computer would make a decision to start a nuclear war that before diplomacy had been exhausted or the algorithm controlling the AI might make a decision to start a nuclear war that would be not understandable to the operators. Kissinger also warned the use of AI to control nuclear weapons would impose "opacity" on the decision-making process as the algorithms that control the AI system are not readily understandable, destabilizing the decision-making process as "...grand strategy requires an understanding of the capabilities and military deployments of potential adversaries. But if more and more intelligence becomes opaque, how will policy makers understand the views and abilities of their adversaries and perhaps even allies? Will many different internets emerge or, in the end, only one? What will be the implications for cooperation? For confrontation? As AI becomes ubiquitous, new concepts for its security need to emerge."

On April 3, 2020 Kissinger shared his diagnostic view of the COVID-19 pandemic, saying that it threatens the "liberal world order". Kissinger added that the virus does not know borders although global leaders are trying to address the crisis on a mainly national basis. He stressed that the key is not a purely national effort but greater international cooperation.

At the height of Kissinger's prominence, many commented on his wit. In February 1972, at the Washington Press Club annual congressional dinner, "Kissinger mocked his reputation as a secret swinger." The insight, "Power is the ultimate aphrodisiac", is widely attributed to him, although Kissinger was paraphrasing Napoleon Bonaparte. Four scholars at the College of William & Mary ranked Kissinger as the most effective U.S. Secretary of State in the 50 years to 2015. A number of activists and human rights lawyers, however, have sought his prosecution for alleged war crimes. According to historian and Kissinger biographer Niall Ferguson, however, accusing Kissinger alone of war crimes "requires a double standard" because "nearly all the secretaries of state ... and nearly all the presidents" have taken similar actions. But Ferguson continues “this is not to say that it’s all OK.”
Some have blamed Kissinger for injustices in American foreign policy during his tenure in government. In September 2001, relatives and survivors of General Rene Schneider (former head of the Chilean general staff) filed civil proceedings in Federal Court in Washington, DC, and, in April 2002, a petition for Kissinger's arrest was filed in the High Court in London by human rights campaigner Peter Tatchell, citing the destruction of civilian populations and the environment in Indochina during the years 1969–75. British-American journalist and author Christopher Hitchens authored "The Trial of Henry Kissinger", in which Hitchens calls for the prosecution of Kissinger "for war crimes, for crimes against humanity, and for offenses against common or customary or international law, including conspiracy to commit murder, kidnap, and torture". Critics on the right, such as Ray Takeyh, have faulted Kissinger for his role in the Nixon administration's opening to China and secret negotiations with North Vietnam. Takeyh writes that while rapprochement with China was a worthy goal, the Nixon administration failed to achieve any meaningful concessions from Chinese officials in return, as China continued to support North Vietnam and various "revolutionary forces throughout the Third World," "nor does there appear to be even a remote, indirect connection between Nixon and Kissinger's diplomacy and the communist leadership's decision, after Mao's bloody rule, to move away from a communist economy towards state capitalism."

On Vietnam, Takeyh claims that Kissinger's negotiations with Le Duc Tho were intended only "to secure a 'decent interval' between America's withdrawal and South Vietnam's collapse." Johannes Kadura offers a more positive assessment of Nixon and Kissinger's strategy, arguing that the two men "simultaneously maintained a Plan A of further supporting Saigon and a Plan B of shielding Washington should their maneuvers prove futile." According to Kadura, the "decent interval" concept has been "largely misrepresented," in that Nixon and Kissinger "sought to gain time, make the North turn inward, and create a perpetual equilibrium" rather than acquiescing in the collapse of South Vietnam, but the strength of the anti-war movement and the sheer unpredictability of events in Indochina compelled them to prepare for the possibility that South Vietnam might collapse despite their best efforts. Kadura concludes: "Without Nixon, Kissinger, and Ford's clever use of triangular diplomacy ... The Soviets and the Chinese could have been tempted into a far more aggressive stance" following the "U.S. defeat in Indochina" than actually occurred.

Kissinger's record was brought up during the 2016 Democratic Party presidential primaries. Hillary Clinton had cultivated a close relationship with Kissinger, describing him as a "friend" and a source of "counsel." During the Democratic Primary Debates, Clinton touted Kissinger's praise for her record as Secretary of State. In response, candidate Bernie Sanders issued a critique of Kissinger's foreign policy, declaring, "I am proud to say that Henry Kissinger is not my friend. I will not take advice from Henry Kissinger."

Kissinger married Ann Fleischer on February 6, 1949. They had two children, Elizabeth and David, and divorced in 1964. On March 30, 1974, he married Nancy Maginnes. They now live in Kent, Connecticut, and in New York City. Kissinger's son David Kissinger served as an executive with NBCUniversal before becoming head of Conaco, Conan O'Brien's production company. In February 1982, at the age of 58, Henry Kissinger underwent coronary bypass surgery.

Kissinger described "Diplomacy" as his favorite game in a 1973 interview.

Daryl Grove characterised Kissinger as one of the most influential people in the growth of soccer in the United States. Kissinger was named chairman of the North American Soccer League board of directors in 1978.

Since his childhood, Kissinger has been a fan of his hometown's soccer club, SpVgg Greuther Fürth. Even during his time in office, the German Embassy informed him about the team's results every Monday morning. He is an honorary member with lifetime season-tickets. In September 2012 Kissinger attended a home game in which SpVgg Greuther Fürth lost, 0–2, against Schalke after promising years ago he would attend a Greuther Fürth home game if they were promoted to the Bundesliga, the top football league in Germany, from the 2. Bundesliga.











</doc>
<doc id="13767" url="https://en.wikipedia.org/wiki?curid=13767" title="Hydra (genus)">
Hydra (genus)

Hydra ( ) is a genus of small, fresh-water organisms of the phylum Cnidaria and class Hydrozoa. They are native to the temperate and tropical regions. Biologists are especially interested in "Hydra" because of their regenerative ability – they do not appear to die of old age, or indeed to age at all.

"Hydra" has a tubular, radially symmetric body up to long when extended, secured by a simple adhesive foot called the basal disc. Gland cells in the basal disc secrete a sticky fluid that accounts for its adhesive properties.

At the free end of the body is a mouth opening surrounded by one to twelve thin, mobile tentacles. Each tentacle, or cnida (plural: cnidae), is clothed with highly specialised stinging cells called cnidocytes. Cnidocytes contain specialized structures called nematocysts, which look like miniature light bulbs with a coiled thread inside. At the narrow outer edge of the cnidocyte is a short trigger hair called a cnidocil. Upon contact with prey, the contents of the nematocyst are explosively discharged, firing a dart-like thread containing neurotoxins into whatever triggered the release. This can paralyze the prey, especially if many hundreds of nematocysts are fired.

"Hydra" has two main body layers, which makes it "diploblastic". The layers are separated by mesoglea, a gel-like substance. The outer layer is the epidermis, and the inner layer is called the gastrodermis, because it lines the stomach. The cells making up these two body layers are relatively simple. Hydramacin is a bactericide recently discovered in "Hydra"; it protects the outer layer against infection. A single "Hydra" is composed of 50,000 to 100,000 cells which consist of three specific stem cell populations that will create many different cell types. These stem cells will continually renew themselves in the body column"." "Hydras" have two significant structures on their body: the "head" and the "foot". When a "Hydra" is cut in half, each half will regenerate and form into a small "Hydra"; the "head" will regenerate a "foot" and the "foot" will regenerate a "head". If the "Hydra" is sliced into many segments then the middle slices will form both a "head" and a "foot".

Respiration and excretion occur by diffusion throughout the surface of the epidermis, while larger excreta are discharged through the mouth.

The nervous system of "Hydra" is a nerve net, which is structurally simple compared to more derived animal nervous systems. "Hydra" does not have a recognizable brain or true muscles. Nerve nets connect sensory photoreceptors and touch-sensitive nerve cells located in the body wall and tentacles.

The structure of the nerve net has two levels: 

Some have only two sheets of neurons.

If "Hydra" are alarmed or attacked, the tentacles can be retracted to small buds, and the body column itself can be retracted to a small gelatinous sphere. "Hydra" generally react in the same way regardless of the direction of the stimulus, and this may be due to the simplicity of the nerve nets.

"Hydra" are generally or sessile, but do occasionally move quite readily, especially when hunting. They have two distinct methods for moving – 'looping' and 'somersaulting'. They do this by bending over and attaching themselves to the with the mouth and tentacles and then relocate the foot, which provides the usual attachment, this process is called looping. In somersaulting, the body then bends over and makes a new place of attachment with the foot. By this process of "looping" or "somersaulting", a "Hydra" can move several inches (c. 100 mm) in a day. "Hydra" may also move by amoeboid motion of their bases or by detaching from the substrate and floating away in the current.

When food is plentiful, many "Hydra" reproduce asexually by producing buds in the body wall, which grow to be miniature adults and break away when they are mature.

When a hydra is well fed, a new bud can form every two days. When conditions are harsh, often before winter or in poor feeding conditions, sexual reproduction occurs in some "Hydra". Swellings in the body wall develop into either ovaries or testes. The testes release free-swimming gametes into the water, and these can fertilize the egg in the ovary of another individual. The fertilized eggs secrete a tough outer coating, and, as the adult dies (due to starvation or cold), these resting eggs fall to the bottom of the lake or pond to await better conditions, whereupon they hatch into nymph "Hydra". Some "Hydra" species, like "Hydra circumcincta" and "Hydra viridissima", are hermaphrodites and may produce both testes and ovaries at the same time.

Many members of the Hydrozoa go through a body change from a polyp to an adult form called a medusa, which is usually the life stage where sexual reproduction occurs, but "Hydra" do not progress beyond the polyp phase.

"Hydra" mainly feed on aquatic invertebrates such as "Daphnia" and "Cyclops".

While feeding, "Hydra" extend their body to maximum length and then slowly extend their tentacles. Despite their simple construction, the tentacles of "Hydra" are extraordinarily extensible and can be four to five times the length of the body. Once fully extended, the tentacles are slowly manoeuvred around waiting for contact with a suitable prey animal. Upon contact, nematocysts on the tentacle fire into the prey, and the tentacle itself coils around the prey. Within 30 seconds, most of the remaining tentacles will have already joined in the attack to subdue the struggling prey. Within two minutes, the tentacles will have surrounded the prey and moved it into the opened mouth aperture. Within ten minutes, the prey will have been engulfed within the body cavity, and digestion will have started. "Hydra" are able to stretch their body wall considerably in order to digest prey more than twice their size. After two or three days, the indigestible remains of the prey will be discharged through the mouth aperture via contractions.

The feeding behaviour of "Hydra" demonstrates the sophistication of what appears to be a simple nervous system.

Some species of "Hydra" exist in a mutual relationship with various types of unicellular algae. The algae are protected from predators by "Hydra" and, in return, photosynthetic products from the algae are beneficial as a food source to "Hydra".

The feeding response in "Hydra" is induced by glutathione (specifically in the reduced state as GSH) released from damaged tissue of injured prey. There are several methods conventionally used for quantification of the feeding response. In some, the duration for which the mouth remains open is measured. Other methods rely on counting the number of "Hydra" among a small population showing the feeding response after addition of glutathione. Recently, an assay for measuring the feeding response in hydra has been developed. In this method, the linear two-dimensional distance between the tip of the tentacle and the mouth of hydra was shown to be a direct measure of the extent of the feeding response. This method has been validated using a starvation model, as starvation is known to cause enhancement of the "Hydra" feeding response.

"Hydra" undergoes morphallaxis (tissue regeneration) when injured or severed. Typically, "Hydras" will reproduce by just budding off a whole new individual, the bud will occur around two-thirds of the way down the body axis. When a "Hydra" is cut in half, each half will regenerate and form into a small "Hydra"; the "head" will regenerate a "foot" and the "foot" will regenerate a "head". This regeneration occurs without cell division. If the "Hydra" is sliced into many segments then the middle slices will form both a "head" and a "foot". The polarity of the regeneration is explained by two pairs of positional value gradients. There is both a head and foot activation and inhibition gradient. The head activation and inhibition works in an opposite direction of the pair of foot gradients. The evidence for these gradients was shown in the early 1900s with grafting experiments. The inhibitors for both gradients have shown to be important to block the bud formation. The location that the bud will form is where the gradients are low for both the head and foot. "Hydras" are capable of regenerating from pieces of tissue from the body and additionally after tissue dissociation from reaggregates.

Daniel Martinez claimed in a 1998 article in "Experimental Gerontology" that "Hydra" are biologically immortal. This publication has been widely cited as evidence that "Hydra" do not senesce (do not age), and that they are proof of the existence of non-senescing organisms generally. In 2010, Preston Estep published (also in "Experimental Gerontology") a letter to the editor arguing that the Martinez data refute the hypothesis that "Hydra" do not senesce.

The controversial unlimited life span of "Hydra" has attracted much attention from scientists. Research today appears to confirm Martinez' study. "Hydra" stem cells have a capacity for indefinite self-renewal. The transcription factor "forkhead box O" (FoxO) has been identified as a critical driver of the continuous self-renewal of "Hydra". In experiments, a drastically reduced population growth resulted from FoxO down-regulation.

In bilaterally symmetrical organisms (Bilateria), the transcription factor FoxO impacts stress response, lifespan, and increase in stem cells. If this transcription factor is knocked down in bilaterian model organisms, such as fruit flies and nematodes, their lifespan is significantly decreased. In experiments on "H. vulgaris" (a radially symmetrical member of phylum Cnidaria), when FoxO levels were decreased, there was a negative impact of many key features of the "Hydra", but no death was observed, thus it is believed other factors may contribute to the apparent lack of aging in these creatures.

While "Hydra" immortality is well-supported today, the implications for human aging are still controversial. There is much optimism; however, it appears that researchers still have a long way to go before they are able to understand how the results of their work might apply to the reduction or elimination of human senescence.

An ortholog comparison analysis done within the last decade demonstrated that "Hydra" share a minimum of 6,071 genes with humans. "Hydra" is becoming an increasingly better model system as more genetic approaches become available. A draft of the genome of "Hydra magnipapillata" was reported in 2010.



</doc>
<doc id="13768" url="https://en.wikipedia.org/wiki?curid=13768" title="Hydrus">
Hydrus

Hydrus is a small constellation in the deep southern sky. It was one of twelve constellations created by Petrus Plancius from the observations of Pieter Dirkszoon Keyser and Frederick de Houtman and it first appeared on a 35-cm (14 in) diameter celestial globe published in late 1597 (or early 1598) in Amsterdam by Plancius and Jodocus Hondius. The first depiction of this constellation in a celestial atlas was in Johann Bayer's Uranometria of 1603. The French explorer and astronomer Nicolas Louis de Lacaille charted the brighter stars and gave their Bayer designations in 1756. Its name means "male water snake", as opposed to Hydra, a much larger constellation that represents a female water snake. It remains below the horizon for most Northern Hemisphere observers.

The brightest star is the 2.8-magnitude Beta Hydri, also the closest reasonably bright star to the south celestial pole. Pulsating between magnitude 3.26 and 3.33, Gamma Hydri is a variable red giant 60 times the diameter of our Sun. Lying near it is VW Hydri, one of the brightest dwarf novae in the heavens. Four star systems in Hydrus have been found to have exoplanets to date, including HD 10180, which could bear up to nine planetary companions.

Hydrus was one of the twelve constellations established by the Dutch astronomer Petrus Plancius from the observations of the southern sky by the Dutch explorers Pieter Dirkszoon Keyser and Frederick de Houtman, who had sailed on the first Dutch trading expedition, known as the "Eerste Schipvaart", to the East Indies. It first appeared on a 35-cm (14 in) diameter celestial globe published in 1598 in Amsterdam by Plancius with Jodocus Hondius. The first depiction of this constellation in a celestial atlas was in the German cartographer Johann Bayer's "Uranometria" of 1603. De Houtman included it in his southern star catalogue the same year under the Dutch name "De Waterslang", "The Water Snake", it representing a type of snake encountered on the expedition rather than a mythical creature. The French explorer and astronomer Nicolas Louis de Lacaille called it "l’Hydre Mâle" on the 1756 version of his planisphere of the southern skies, distinguishing it from the feminine Hydra. The French name was retained by Jean Fortin in 1776 for his "Atlas Céleste", while Lacaille Latinised the name to Hydrus for his revised "Coelum Australe Stelliferum" in 1763.

Irregular in shape, Hydrus is bordered by Mensa to the southeast, Eridanus to the east, Horologium and Reticulum to the northeast, Phoenix to the north, Tucana to the northwest and west, and Octans to the south; Lacaille had shortened Hydrus' tail to make space for this last constellation he had drawn up. Covering 243 square degrees and 0.589% of the night sky, it ranks 61st of the 88 constellations in size. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is "Hyi". The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of 12 segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between −57.85° and −82.06°. As one of the deep southern constellations, it remains below the horizon at latitudes north of the 30th parallel in the Northern Hemisphere, and is circumpolar at latitudes south of the 50th parallel in the Southern Hemisphere. Indeed, Herman Melville mentions it and Argo Navis in Moby Dick "beneath effulgent Antarctic Skies", highlighting his knowledge of the southern constellations from whaling voyages. A line drawn between the long axis of the Southern Cross to Beta Hydri and then extended 4.5 times will mark a point due south. Hydrus culminates at midnight around 26 October.

Keyzer and de Houtman assigned fifteen stars to the constellation in their Malay and Madagascan vocabulary, with a star that would be later designated as Alpha Hydri marking the head, Gamma the chest and a number of stars that were later allocated to Tucana, Reticulum, Mensa and Horologium marking the body and tail. Lacaille charted and designated 20 stars with the Bayer designations Alpha through to Tau in 1756. Of these, he used the designations Eta, Pi and Tau twice each, for three sets of two stars close together, and omitted Omicron and Xi. He assigned Rho to a star that subsequent astronomers were unable to find.

Beta Hydri, the brightest star in Hydrus, is a yellow star of apparent magnitude 2.8, lying 24 light-years from Earth. It has about 104% of the mass of the Sun and 181% of the Sun's radius, with more than three times the Sun's luminosity. The spectrum of this star matches a stellar classification of G2 IV, with the luminosity class of 'IV' indicating this is a subgiant star. As such, it is a slightly more evolved star than the Sun, with the supply of hydrogen fuel at its core becoming exhausted. It is the nearest subgiant star to the Sun and one of the oldest stars in the solar neighbourhood. Thought to be between 6.4 and 7.1 billion years old, this star bears some resemblance to what the Sun may look like in the far distant future, making it an object of interest to astronomers. It is also the closest bright star to the south celestial pole.

Located at the northern edge of the constellation and just southwest of Achernar is Alpha Hydri, a white sub-giant star of magnitude 2.9, situated 72 light-years from Earth. Of spectral type F0IV, it is beginning to cool and enlarge as it uses up its supply of hydrogen. It is twice as massive and 3.3 times as wide as our sun and 26 times more luminous. A line drawn between Alpha Hydri and Beta Centauri is bisected by the south celestial pole.

In the southeastern corner of the constellation is Gamma Hydri, a red giant of spectral type M2III located 214 light-years from Earth. It is a semi-regular variable star, pulsating between magnitudes 3.26 and 3.33. Observations over five years were not able to establish its periodicity. It is around 1.5 to 2 times as massive as our Sun, and has expanded to about 60 times the Sun's diameter. It shines with about 655 times the luminosity of the Sun. Located 3° northeast of Gamma is the VW Hydri, a dwarf nova of the SU Ursae Majoris type. It is a close binary system that consists of a white dwarf and another star, the former drawing off matter from the latter into a bright accretion disk. These systems are characterised by frequent eruptions and less frequent supereruptions. The former are smooth, while the latter exhibit short "superhumps" of heightened activity. One of the brightest dwarf novae in the sky, it has a baseline magnitude of 14.4 and can brighten to magnitude 8.4 during peak activity. BL Hydri is another close binary system composed of a low mass star and a strongly magnetic white dwarf. Known as a polar or AM Herculis variable, these produce polarized optical and infrared emissions and intense soft and hard X-ray emissions to the frequency of the white dwarf's rotation period—in this case 113.6 minutes.
There are two notable optical double stars in Hydrus. Pi Hydri, composed of Pi Hydri and Pi Hydri, is divisible in binoculars. Around 476 light-years distant, Pi is a red giant of spectral type M1III that varies between magnitudes 5.52 and 5.58. Pi is an orange giant of spectral type K2III and shining with a magnitude of 5.7, around 488 light-years from Earth.

Eta Hydri is the other optical double, composed of Eta and Eta. Eta is a blue-white main sequence star of spectral type B9V that was suspected of being variable, and is located just over 700 light-years away. Eta has a magnitude of 4.7 and is a yellow giant star of spectral type G8.5III around 218 light-years distant, which has evolved off the main sequence and is expanding and cooling on its way to becoming a red giant. Calculations of its mass indicate it was most likely a white A-type main sequence star for most of its existence, around twice the mass of our Sun. A planet, Eta2 Hydri b, greater than 6.5 times the mass of Jupiter was discovered in 2005, orbiting around Eta every 711 days at a distance of 1.93 astronomical units (AU).

Three other systems have been found to have planets, most notably the Sun-like star HD 10180, which has seven planets, plus possibly an additional two for a total of nine—as of 2012 more than any other system to date, including the Solar System. Lying around from the Earth, it has an apparent magnitude of 7.33.

GJ 3021 is a solar twin—a star very like our own Sun—around 57 light-years distant with a spectral type G8V and magnitude of 6.7. It has a Jovian planet companion (GJ 3021 b). Orbiting about 0.5 AU from its sun, it has a minimum mass 3.37 times that of Jupiter and a period of around 133 days. The system is a complex one as the faint star GJ 3021B orbits at a distance of 68 AU; it is a red dwarf of spectral type M4V.

HD 20003 is a star of magnitude 8.37. It is a yellow main sequence star of spectral type G8V a little cooler and smaller than our Sun around 143 light-years away. It has two planets that are around 12 and 13.5 times as massive as the Earth with periods of just under 12 and 34 days respectively.

Hydrus contains only faint deep-sky objects. IC 1717 was a deep-sky object discovered by the Danish astronomer John Louis Emil Dreyer in the late 19th century. The object at the coordinate Dreyer observed is no longer there, and is now a mystery. It was very likely to have been a faint comet. PGC 6240, known as the White Rose Galaxy, is a giant spiral galaxy surrounded by shells resembling rose petals, located around 345 million light years from the Solar System. Unusually, it has cohorts of globular clusters of three distinct ages suggesting bouts of post-starburst formation following a merger with another galaxy. The constellation also contains a spiral galaxy, NGC 1511, which lies edge on to observers on Earth and is readily viewed in amateur telescopes.

Located mostly in Dorado, the Large Magellanic Cloud extends into Hydrus. The globular cluster NGC 1466 is an outlying component of the galaxy, and contains many RR Lyrae-type variable stars. It has a magnitude of 11.59 and is thought to be over 12 billion years old. Two stars, HD 24188 of magnitude 6.3 and HD 24115 of magnitude 9.0, lie nearby in its foreground. NGC 602 is composed of an emission nebula and a young, bright open cluster of stars that is an outlying component on the eastern edge of the Small Magellanic Cloud, a satellite galaxy to the Milky Way. Most of the cloud is located in the neighbouring constellation Tucana.



</doc>
<doc id="13770" url="https://en.wikipedia.org/wiki?curid=13770" title="Hercules">
Hercules

Hercules () is a Roman hero and god. He was the Roman equivalent of the Greek divine hero Heracles, who was the son of Zeus (Roman equivalent Jupiter) and the mortal Alcmene. In classical mythology, Hercules is famous for his strength and for his numerous far-ranging adventures.

The Romans adapted the Greek hero's iconography and myths for their literature and art under the name "Hercules". In later Western art and literature and in popular culture, "Hercules" is more commonly used than "Heracles" as the name of the hero. Hercules was a multifaceted figure with contradictory characteristics, which enabled later artists and writers to pick and choose how to represent him. This article provides an introduction to representations of Hercules in the later tradition.

Although he was seen as the champion of the weak and a great protector, Hercules' personal problems started at birth. Hera sent two witches to prevent the birth, but they were tricked by one of Alcmene's servants and sent to another room. Hera then sent serpents to kill him in his cradle, but Hercules strangled them both. In one version of the myth, Alcmene abandoned her baby in the woods in order to protect him from Hera's wrath, but he was found by the goddess Athena who brought him to Hera, claiming he was an orphan child left in the woods who needed nourishment. Hera suckled Hercules at her own breast until the infant bit her nipple, at which point she pushed him away, spilling her milk across the night sky and so forming the Milky Way. She then gave the infant back to Athena and told her to take care of the baby herself. In feeding the child from her own breast, the goddess inadvertently imbued him with further strength and power.

Hercules is known for his many adventures, which took him to the far reaches of the Greco-Roman world. One cycle of these adventures became canonical as the "Twelve Labours", but the list has variations. One traditional order of the labours is found in the "Bibliotheca" as follows:

Hercules had a greater number of "deeds on the side" "(parerga)" that have been popular subjects for art, including:

The Latin name "Hercules" was borrowed through Etruscan, where it is represented variously as Heracle, Hercle, and other forms. Hercules was a favorite subject for Etruscan art, and appears often on bronze mirrors. The Etruscan form "Herceler" derives from the Greek "Heracles" via syncope. A mild oath invoking Hercules ("Hercule!" or "Mehercle!") was a common interjection in Classical Latin.

Hercules had a number of myths that were distinctly Roman. One of these is Hercules' defeat of Cacus, who was terrorizing the countryside of Rome. The hero was associated with the Aventine Hill through his son Aventinus. Mark Antony considered him a personal patron god, as did the emperor Commodus. Hercules received various forms of religious veneration, including as a deity concerned with children and childbirth, in part because of myths about his precocious infancy, and in part because he fathered countless children. Roman brides wore a special belt tied with the "knot of Hercules", which was supposed to be hard to untie. The comic playwright Plautus presents the myth of Hercules' conception as a sex comedy in his play "Amphitryon"; Seneca wrote the tragedy "Hercules Furens" about his bout with madness. During the Roman Imperial era, Hercules was worshipped locally from Hispania through Gaul.

Tacitus records a special affinity of the Germanic peoples for Hercules. In chapter 3 of his "Germania", Tacitus states:

Some have taken this as Tacitus equating the Germanic "Þunraz" with Hercules by way of "interpretatio romana".

In the Roman era Hercules' Club amulets appear from the 2nd to 3rd century, distributed over the empire (including Roman Britain, c.f. Cool 1986), mostly made of gold, shaped like wooden clubs. A specimen found in Köln-Nippes bears the inscription [culi]", confirming the association with Hercules.

In the 5th to 7th centuries, during the Migration Period, the amulet is theorized to have rapidly spread from the Elbe Germanic area across Europe. These Germanic "Donar's Clubs" were made from deer antler, bone or wood, more rarely also from bronze or precious metals. The amulet type is replaced by the Viking Age Thor's hammer pendants in the course of the Christianization of Scandinavia from the 8th to 9th century.
After the Roman Empire became Christianized, mythological narratives were often reinterpreted as allegory, influenced by the philosophy of late antiquity. In the 4th century, Servius had described Hercules' return from the underworld as representing his ability to overcome earthly desires and vices, or the earth itself as a consumer of bodies. In medieval mythography, Hercules was one of the heroes seen as a strong role model who demonstrated both valor and wisdom, while the monsters he battles were regarded as moral obstacles. One glossator noted that when Hercules became a constellation, he showed that strength was necessary to gain entrance to Heaven.

Medieval mythography was written almost entirely in Latin, and original Greek texts were little used as sources for Hercules' myths.

The Renaissance and the invention of the printing press brought a renewed interest in and publication of Greek literature. Renaissance mythography drew more extensively on the Greek tradition of Heracles, typically under the Romanized name Hercules, or the alternate name Alcides. In a chapter of his book "Mythologiae" (1567), the influential mythographer Natale Conti collected and summarized an extensive range of myths concerning the birth, adventures, and death of the hero under his Roman name Hercules. Conti begins his lengthy chapter on Hercules with an overview description that continues the moralizing impulse of the Middle Ages:
Hercules, who subdued and destroyed monsters, bandits, and criminals, was justly famous and renowned for his great courage. His great and glorious reputation was worldwide, and so firmly entrenched that he'll always be remembered. In fact the ancients honored him with his own temples, altars, ceremonies, and priests. But it was his wisdom and great soul that earned those honors; noble blood, physical strength, and political power just aren't good enough.
In 1600, the citizens of Avignon bestowed on Henry of Navarre (the future King Henry IV of France) the title of the "Hercule Gaulois" ("Gallic Hercules"), justifying the extravagant flattery with a genealogy that traced the origin of the House of Navarre to a nephew of Hercules' son Hispalus.

The Road of Hercules is a route across Southern Gaul that is associated with the path Hercules took during his 10th labor of retrieving the Cattle of Geryon from the Red Isles. Hannibal took the same path on his march towards Italy and encouraged the belief that he was the second Hercules. Primary sources often make comparisons between Hercules and Hannibal. Hannibal further tried to invoke parallels between himself and Hercules by starting his march on Italy by visiting the shrine of Hercules at Gades. While crossing the alps, he performed labors in a heroic manner. A famous example was noted by Livy, when Hannibal fractured the side of a cliff that was blocking his march.

In ancient Roman society women were usually limited to two types of cults. Those that address feminine matters such as childbirth, and cults that required virginal chastity. However, there is evidence suggesting there were female worshippers of Apollo, Mars, Jupiter, and Hercules. Some scholars believe that women were completely prohibited from any of Hercules's cults. Others believe it was only the "Ara Maxima" that they were not allowed to worship at. Macrobius in his first book of "Saturnalia" paraphrases from Varro's actinology: ""For when Hercules was bringing the cattle of Geryon through Italy, a woman replied to the thirsty hero that she could not give him water because it was the day of the Goddess Women and it was unlawful for a man to taste what had been prepared for her. Hercules, therefore, when he was about to offer a sacrifice forbid the presence of women and ordered Potitius and Pinarius who where in charge of his rites, not to allow any women from taking part"". Macrobius states that women were restricted in their participation in Hercules cults, but to what extent remains ambiguous. He mentions that women were not allowed to participate in Sacrum which is general term used to describe anything that was believed to have belonged to the gods. This could include anything from a precious item to a temple. Due to the general nature of a Sacrum, we can not judge the extent of the prohibition from Macrobius alone. There is also ancient writings on this topic from Aulus Gellius when speaking on how Romans swore oaths. He mentioned that Roman women do not swear on Hercules, nor to Roman men swear on Castor. He went on to say that women refrain from sacrificing to Hercules. Propertius, whom in his poem 4.9 also mentions similar information as Macrobius. This is evidence that he was also using Varro as a source.

There is evidence of Hercules worship in myth in the Latin epic poem "The Aeneid". In the 8th book of the poem Aeneas finally reaches the future site of Rome, where he meets Evander and the Arcadians making sacrifices to Hercules on the banks of the Tiber river. They share a feast, and Evander tells the story of how Hercules defeated the monster Cascus, and describes him as a triumphant hero. Translated from the Latin text of Vergil, Evander stated: "Time brought to us in our time of need the aid and arrival of a god. For there came that mightiest avenger, the victor Hercules, proud with the slaughter and the spoils of threefold Geryon, and he drove the mighty bulls here, and the cattle filled both valley and riverside.

Hercules was also mentioned in the Fables of Gaius Julius Hyginus. For example, in his fable about Philoctetes he tells the story of how Philoctetes built a funeral pyre for Hercules so his body could be consumed and raised to immortality.

According to Livy (9.44.16) Romans were commemorating military victories by building statues to Hercules as early as 305 BCE. Also, philosopher Piny the Elder dates Hercules worship back to the time of Evander, by accrediting him with erecting a statue in the Forum Boarium of Hercules. Scholars agree that there would have been 5–7 temples in Augustan Rome. There are believed to be related Republican "triumphatores," however, not necessarily triumphal dedications. There is two temples located in the Campus Martius. One, being the Temple of Hercules Musarum, dedicated between 187 and 179 BCE by M. Fulvius Nobilior. And the other being the Temple of Hercules Custos, likely renovated by Sulla in the 80s BCE.

In Roman works of art and in Renaissance and post-Renaissance art, Hercules can be identified by his attributes, the lion skin and the gnarled club (his favorite weapon); in mosaic he is shown tanned bronze, a virile aspect.

Hercules was among the earliest figures on ancient Roman coinage, and has been the main motif of many collector coins and medals since. One example is the 20 euro Baroque Silver coin issued on September 11, 2002. The obverse side of the coin shows the Grand Staircase in the town palace of Prince Eugene of Savoy in Vienna, currently the Austrian Ministry of Finance. Gods and demi-gods hold its flights, while Hercules stands at the turn of the stairs.

Six successive ships of the British Royal Navy, from the 18th to the 20th century, bore the name HMS "Hercules".

In the French Navy, there were no less than nineteen ships called "Hercule", plus three more named "Alcide" which is another name of the same hero.

Hercules' name was also used for five ships of the US Navy, four ships of the Spanish Navy, four of the Argentine Navy and two of the Swedish Navy, as well as for numerous civilian sailing and steam ships – see links at Hercules (ship).

In modern aviation a military transport aircraft produced by Lockheed Martin carries the title Lockheed C-130 Hercules.

A series of nineteen Italian Hercules movies were made in the late 1950s and early 1960s. The actors who played Hercules in these films were Steve Reeves, Gordon Scott, Kirk Morris, Mickey Hargitay, Mark Forest, Alan Steel, Dan Vadis, Brad Harris, Reg Park, Peter Lupus (billed as Rock Stevens) and Michael Lane. A number of English-dubbed Italian films that featured the name of Hercules in their title were not intended to be movies about Hercules.





</doc>
<doc id="13772" url="https://en.wikipedia.org/wiki?curid=13772" title="History of Poland">
History of Poland

The history of Poland () spans over a thousand years, from medieval tribes, Christianization and monarchy; through Poland's Golden Age, expansionism and becoming one of the largest European powers; to its collapse and partitions, two world wars, communism, and the restoration of democracy.

The roots of Polish history can be traced to the Iron Age, when the territory of present-day Poland was settled by various tribes including Celts, Scythians, Germanic clans, Sarmatians, Slavs and Balts. However, it was the West Slavic Lechites, the closest ancestors of ethnic Poles, who established permanent settlements in the Polish lands during the Early Middle Ages. The Lechitic Western Polans, a tribe whose name means "people living in open fields", dominated the region, and gave Poland - which lies in the North-Central European Plain - its name.

The first ruling dynasty, the Piasts, emerged in the 10th century AD. Duke Mieszko I is considered the "de facto" creator of the Polish state and is widely recognized for his adoption of Western Christianity in 966 CE. Mieszko's dominion was formally reconstituted as a medieval kingdom in 1025 by his son Bolesław I the Brave, known for military expansion under his rule. The most successful and the last Piast monarch, Casimir III the Great, presided over a period of economic prosperity and territorial aggrandizement before his death in 1370 without male heirs. The period of the Jagiellonian dynasty in the 14th–16th centuries brought close ties with the Lithuania, a cultural Renaissance in Poland and continued territorial expansion as well as Polonization that culminated in the establishment of the Polish–Lithuanian Commonwealth in 1569, one of Europe's largest countries.

The Commonwealth was able to sustain the levels of prosperity achieved during the Jagiellonian period, while its political system matured as a unique noble democracy with an elective monarchy. From the mid-17th century, however, the huge state entered a period of decline caused by devastating wars and the deterioration of its political system. Significant internal reforms were introduced in the late 18th century, such as Europe's first Constitution of 3 May 1791, but neighboring powers did not allow the reforms to advance. The existence of the Commonwealth ended in 1795 after a series of invasions and partitions of Polish territory carried out by the Russian Empire in the east, the Kingdom of Prussia in the west and the Habsburg Monarchy in the south. From 1795 until 1918, no truly independent Polish state existed, although strong Polish resistance movements operated. The opportunity to regain sovereignty only materialized after World War I, when the three partitioning imperial powers were fatally weakened in the wake of war and revolution.

The Second Polish Republic was established in 1918 and existed as an independent state until 1939, when Nazi Germany and the Soviet Union invaded Poland, marking the beginning of World War II. Millions of Polish citizens of different faiths or identities perished in the course of the Nazi occupation of Poland between 1939 and 1945 through planned genocide and extermination. A Polish government-in-exile nonetheless functioned throughout the war and the Poles contributed to the Allied victory through participation in military campaigns on both the eastern and western fronts. The westward advances of the Soviet Red Army in 1944 and 1945 compelled Nazi Germany's forces to retreat from Poland, which led to the establishment of a satellite communist country, known from 1952 as the Polish People's Republic.

As a result of territorial adjustments mandated by the Allies at the end of World War II in 1945, Poland's geographic centre of gravity shifted towards the west and the re-defined Polish lands largely lost their historic multi-ethnic character through the extermination, expulsion and migration of various ethnic groups during and after the war. By the late 1980s, the Polish reform movement Solidarity became crucial in bringing about a peaceful transition from a planned economy and a communist state to a capitalist economic system and a liberal parliamentary democracy. This process resulted in the creation of the modern Polish state, the Third Polish Republic, founded in 1989.

In prehistoric and protohistoric times, over a period of at least 600,000 years, the area of present-day Poland was intermittently inhabited by members of the genus "Homo". It went through the Stone Age, Bronze Age and Iron Age stages of development, along with the nearby regions. The Neolithic period ushered in the Linear Pottery culture, whose founders migrated from the Danube River area beginning about 5500 BC. This culture was distinguished by the establishment of the first settled agricultural communities in modern Polish territory. Later, between about 4400 and 2000 BC, the native post-Mesolithic populations would also adopt and further develop the agricultural way of life.
Poland's Early Bronze Age began around 2400–2300 BC, whereas its Iron Age commenced c. 750–700 BC. One of the many cultures that have been uncovered, the Lusatian culture, spanned the Bronze and Iron Ages and left notable settlement sites. Around 400 BC, Poland was settled by Celts of the La Tène culture. They were soon followed by emerging cultures with a strong Germanic component, influenced first by the Celts and then by the Roman Empire. The Germanic peoples migrated out of the area by about 500 AD during the great Migration Period of the European Dark Ages. Wooded regions to the north and east were settled by Balts.

According to mainstream archaeological research, Slavs have resided in modern Polish territories for only 1,500 years. However, recent genetic studies determined that people who live in the current territory of Poland include the descendants of the people who inhabited the area for thousands of years, beginning in the early Neolithic period.

The West Slavic and Lechitic peoples as well as any remaining minority clans on ancient Polish lands were organized into tribal units, of which the larger ones were later known as the Polish tribes; the names of many tribes are found on the list compiled by the anonymous Bavarian Geographer in the 9th century. In the 9th and 10th centuries, these tribes gave rise to developed regions along the upper Vistula, the coast of the Baltic Sea and in Greater Poland. The latest tribal undertaking, in Greater Poland, resulted in the formation of a lasting political structure in the 10th century that became the state of Poland.

Poland was established as a state under the Piast dynasty, which ruled the country between the 10th and 14th centuries. Historical records referring to the Polish state begin with the rule of Duke Mieszko I, whose reign commenced sometime before 963 and continued until his death in 992. Mieszko converted to Christianity in 966, following his marriage to Princess Doubravka of Bohemia, a fervent Christian. The event is known as the "baptism of Poland", and its date is often used to mark a symbolic beginning of Polish statehood. Mieszko completed a unification of the Lechitic tribal lands that was fundamental to the new country's existence. Following its emergence, Poland was led by a series of rulers who converted the population to Christianity, created a strong kingdom and fostered a distinctive Polish culture that was integrated into the broader European culture.

Mieszko's son, Duke Bolesław I the Brave (r. 992–1025), established a Polish Church structure, pursued territorial conquests and was officially crowned the first king of Poland in 1025, near the end of his life. Bolesław also sought to spread Christianity to parts of eastern Europe that remained pagan, but suffered a setback when his greatest missionary, Adalbert of Prague, was killed in Prussia in 997. During the Congress of Gniezno in the year 1000, Holy Roman Emperor Otto III recognized the Archbishopric of Gniezno, an institution crucial for the continuing existence of the sovereign Polish state. During the reign of Otto's successor, Holy Roman Emperor Henry II, Bolesław fought prolonged wars with the Kingdom of Germany between 1002 and 1018.

Bolesław I's expansive rule overstretched the resources of the early Polish state, and it was followed by a collapse of the monarchy. Recovery took place under Casimir I the Restorer (r. 1039–58). Casimir's son Bolesław II the Generous (r. 1058–79) became involved in a conflict with Bishop Stanislaus of Szczepanów that ultimately caused his downfall. Bolesław had the bishop murdered in 1079 after being excommunicated by the Polish church on charges of adultery. This act sparked a revolt of Polish nobles that led to Bolesław's deposition and expulsion from the country. Around 1116, Gallus Anonymus wrote a seminal chronicle, the "Gesta principum Polonorum", intended as a glorification of his patron Bolesław III Wrymouth (r. 1107–38), a ruler who revived the tradition of military prowess of Bolesław I's time. Gallus' work remains a paramount written source for the early history of Poland.

After Bolesław III divided Poland among his sons in his Testament of 1138, internal fragmentation eroded the Piast monarchical structures in the 12th and 13th centuries. In 1180, Casimir II the Just, who sought papal confirmation of his status as a senior duke, granted immunities and additional privileges to the Polish Church at the Congress of Łęczyca. Around 1220, Wincenty Kadłubek wrote his "Chronica seu originale regum et principum Poloniae", another major source for early Polish history. In 1226, one of the regional Piast dukes, Konrad I of Masovia, invited the Teutonic Knights to help him fight the Baltic Prussian pagans. The Teutonic Order destroyed the Prussians but kept their lands, which resulted in centuries of warfare between Poland and the Teutonic Knights, and later between Poland and the German Prussian state. The first Mongol invasion of Poland began in 1240; it culminated in the defeat of Polish and allied Christian forces and the death of the Silesian Piast Duke Henry II the Pious at the Battle of Legnica in 1241. In 1242, Wrocław became the first Polish municipality to be incorporated, as the period of fragmentation brought economic development and growth of towns. New cities were founded and existing settlements were granted town status per Magdeburg Law. In 1264, Bolesław the Pious granted Jewish liberties in the Statute of Kalisz.

Attempts to reunite the Polish lands gained momentum in the 13th century, and in 1295, Duke Przemysł II of Greater Poland managed to become the first ruler since Bolesław II to be crowned king of Poland. He ruled over a limited territory and was soon killed. In 1300–05 King Wenceslaus II of Bohemia also reigned as king of Poland. The Piast Kingdom was effectively restored under Władysław I the Elbow-high (r. 1306–33), who became king in 1320. In 1308, the Teutonic Knights seized Gdańsk and the surrounding region of Pomerelia.

King Casimir III the Great (r. 1333–70), Władysław's son and the last of the Piast rulers, strengthened and expanded the restored Kingdom of Poland, but the western provinces of Silesia (formally ceded by Casimir in 1339) and most of Polish Pomerania were lost to the Polish state for centuries to come. Progress was made in the recovery of the separately governed central province of Mazovia, however, and in 1340, the conquest of Red Ruthenia began, marking Poland's expansion to the east. The Congress of Kraków, a vast convocation of central, eastern, and northern European rulers probably assembled to plan an anti-Turkish crusade, took place in 1364, the same year that the future Jagiellonian University, one of the oldest European universities, was founded. On 9 October 1334, Casimir III confirmed the privileges granted to Jews in 1264 by Bolesław the Pious and allowed them to settle in Poland in great numbers.

After the Polish royal line and Piast junior branch died out in 1370, Poland came under the rule of Louis I of Hungary of the Capetian House of Anjou, who presided over a union of Hungary and Poland that lasted until 1382. In 1374, Louis granted the Polish nobility the Privilege of Koszyce to assure the succession of one of his daughters in Poland. His youngest daughter Jadwiga (d. 1399) assumed the Polish throne in 1384.

In 1386, Grand Duke Jogaila of Lithuania converted to Catholicism and married Queen Jadwiga of Poland. This act enabled him to become a king of Poland himself, and he ruled as Władysław II Jagiełło until his death in 1434. The marriage established a personal Polish–Lithuanian union ruled by the Jagiellonian dynasty. The first in a series of formal "unions" was the Union of Krewo of 1385, whereby arrangements were made for the marriage of Jogaila and Jadwiga. The Polish–Lithuanian partnership brought vast areas of Ruthenia controlled by the Grand Duchy of Lithuania into Poland's sphere of influence and proved beneficial for the nationals of both countries, who coexisted and cooperated in one of the largest political entities in Europe for the next four centuries. When Queen Jadwiga died in 1399, the Kingdom of Poland fell to her husband's sole possession.
In the Baltic Sea region, Poland's struggle with the Teutonic Knights continued and culminated in the Battle of Grunwald (1410), a great victory that the Poles and Lithuanians were unable to follow up with a decisive strike against the main seat of the Teutonic Order at Malbork Castle. The Union of Horodło of 1413 further defined the evolving relationship between the Kingdom of Poland and the Grand Duchy of Lithuania.

The privileges of the "szlachta" (nobility) kept expanding and in 1425 the rule of "Neminem captivabimus", which protected the noblemen from arbitrary royal arrests, was formulated.

The reign of the young Władysław III (1434–44), who succeeded his father Władysław II Jagiełło and ruled as king of Poland and Hungary, was cut short by his death at the Battle of Varna against the forces of the Ottoman Empire. This disaster led to an interregnum of three years that ended with the accession of Władysław's brother Casimir IV Jagiellon in 1447.

Critical developments of the Jagiellonian period were concentrated during Casimir IV's long reign, which lasted until 1492. In 1454, Royal Prussia was incorporated by Poland and the Thirteen Years' War of 1454–66 with the Teutonic state ensued. In 1466, the milestone Peace of Thorn was concluded. This treaty divided Prussia to create East Prussia, the future Duchy of Prussia, a separate entity that functioned as a fief of Poland under the administration of the Teutonic Knights. Poland also confronted the Ottoman Empire and the Crimean Tatars in the south, and in the east helped Lithuania fight the Grand Duchy of Moscow. The country was developing as a feudal state, with a predominantly agricultural economy and an increasingly dominant landed nobility. Kraków, the royal capital, was turning into a major academic and cultural center, and in 1473 the first printing press began operating there. With the growing importance of "szlachta" (middle and lower nobility), the king's council evolved to become by 1493 a bicameral General Sejm (parliament) that no longer represented exclusively top dignitaries of the realm.

The "Nihil novi" act, adopted in 1505 by the Sejm, transferred most of the legislative power from the monarch to the Sejm. This event marked the beginning of the period known as "Golden Liberty", when the state was ruled in principle by the "free and equal" Polish nobility. In the 16th century, the massive development of folwark agribusinesses operated by the nobility led to increasingly abusive conditions for the peasant serfs who worked them. The political monopoly of the nobles also stifled the development of cities, some of which were thriving during the late Jagiellonian era, and limited the rights of townspeople, effectively holding back the emergence of the middle class.

In the 16th century, Protestant Reformation movements made deep inroads into Polish Christianity and the resulting Reformation in Poland involved a number of different denominations. The policies of religious tolerance that developed in Poland were nearly unique in Europe at that time and many who fled regions torn by religious strife found refuge in Poland. The reigns of King Sigismund I the Old (1506–1548) and King Sigismund II Augustus (1548–1572) witnessed an intense cultivation of culture and science (a Golden Age of the Renaissance in Poland), of which the astronomer Nicolaus Copernicus (1473–1543) is the best known representative. Jan Kochanowski (1530–1584) was a poet and the premier artistic personality of the period. In 1525, during the reign of Sigismund I, the Teutonic Order was secularized and Duke Albert performed an act of homage before the Polish king (the Prussian Homage) for his fief, the Duchy of Prussia. Mazovia was finally fully incorporated into the Polish Crown in 1529.

The reign of Sigismund II ended the Jagiellonian period, but gave rise to the Union of Lublin (1569), an ultimate fulfillment of the union with Lithuania. This agreement transferred Ukraine from the Grand Duchy of Lithuania to Poland and transformed the Polish–Lithuanian polity into a real union, preserving it beyond the death of the childless Sigismund II, whose active involvement made the completion of this process possible.

Livonia in the far northeast was incorporated by Poland in 1561 and Poland entered the Livonian War against Russia. The executionist movement, which attempted to check the progressing domination of the state by the magnate families of Poland and Lithuania, peaked at the Sejm in Piotrków in 1562–63. On the religious front, the Polish Brethren split from the Calvinists, and the Protestant Brest Bible was published in 1563. The Jesuits, who arrived in 1564, were destined to make a major impact on Poland's history.

The Union of Lublin of 1569 established the Polish–Lithuanian Commonwealth, a federal state more closely unified than the earlier political arrangement between Poland and Lithuania. The union was run largely by the nobility through the system of central parliament and local assemblies, but was headed by elected kings. The formal rule of the nobility, who were proportionally more numerous than in other European countries, constituted an early democratic system ("a sophisticated noble democracy"), in contrast to the absolute monarchies prevalent at that time in the rest of Europe. 

The beginning of the Commonwealth coincided with a period in Polish history when great political power was attained and advancements in civilization and prosperity took place. The Polish–Lithuanian Union became an influential participant in European affairs and a vital cultural entity that spread Western culture (with Polish characteristics) eastward. In the second half of the 16th century and the first half of the 17th century, the Commonwealth was one of the largest and most populous states in contemporary Europe, with an area approaching and a population of about ten million. Its economy was dominated by export-focused agriculture. Nationwide religious toleration was guaranteed at the Warsaw Confederation in 1573.

After the rule of the Jagiellonian dynasty ended in 1572, Henry of Valois (later King Henry III of France) was the winner of the first "free election" by the Polish nobility, held in 1573. He had to agree to the restrictive "pacta conventa" obligations and fled Poland in 1574 when news arrived of the vacancy of the French throne, to which he was the heir presumptive. From the start, the royal elections increased foreign influence in the Commonwealth as foreign powers sought to manipulate the Polish nobility to place candidates amicable to their interests. The reign of Stephen Báthory of Hungary followed (r. 1576–1586). He was militarily and domestically assertive and is revered in Polish historical tradition as a rare case of successful elective king. The establishment of the legal Crown Tribunal in 1578 meant a transfer of many appellate cases from the royal to noble jurisdiction.

A period of rule under the Swedish House of Vasa began in the Commonwealth in the year 1587. The first two kings from this dynasty, Sigismund III (r. 1587–1632) and Władysław IV (r. 1632–1648), repeatedly attempted to intrigue for accession to the throne of Sweden, which was a constant source of distraction for the affairs of the Commonwealth. At that time, the Catholic Church embarked on an ideological counter-offensive and the Counter-Reformation claimed many converts from Polish and Lithuanian Protestant circles. In 1596, the Union of Brest split the Eastern Christians of the Commonwealth to create the Uniate Church of the Eastern Rite, but subject to the authority of the pope. The Zebrzydowski rebellion against Sigismund III unfolded in 1606–1608.

Seeking supremacy in Eastern Europe, the Commonwealth fought wars with Russia between 1605 and 1618 in the wake of Russia's Time of Troubles; the series of conflicts is referred to as the Polish–Muscovite War or the "Dymitriads". The efforts resulted in expansion of the eastern territories of the Polish–Lithuanian Commonwealth, but the goal of taking over the Russian throne for the Polish ruling dynasty was not achieved. Sweden sought supremacy in the Baltic during the Polish–Swedish wars of 1617–1629, and the Ottoman Empire pressed from the south in the Battles at Cecora in 1620 and Khotyn in 1621. The agricultural expansion and serfdom policies in Polish Ukraine resulted in a series of Cossack uprisings. Allied with the Habsburg Monarchy, the Commonwealth did not directly participate in the Thirty Years' War. Władysław's IV reign was mostly peaceful, with a Russian invasion in the form of the Smolensk War of 1632–1634 successfully repelled. The Orthodox Church hierarchy, banned in Poland after the Union of Brest, was re-established in 1635.

During the reign of John II Casimir Vasa (r. 1648–1668), the third and last king of his dynasty, the nobles' democracy fell into decline as a result of foreign invasions and domestic disorder. These calamities multiplied rather suddenly and marked the end of the Polish Golden Age. Their effect was to render the once powerful Commonwealth increasingly vulnerable to foreign intervention.

The Cossack Khmelnytsky Uprising of 1648–1657 engulfed the south-eastern regions of the Polish crown; its long-term effects were disastrous for the Commonwealth. The first "liberum veto" (a parliamentary device that allowed any member of the Sejm to dissolve a current session immediately) was exercised by a deputy in 1652. This practice would eventually weaken Poland's central government critically. In the Treaty of Pereyaslav (1654), the Ukrainian rebels declared themselves subjects of the Tsar of Russia. The Second Northern War raged through the core Polish lands in 1655–1660; it included a brutal and devastating invasion of Poland referred to as the Swedish Deluge. The war ended in 1660 with the Treaty of Oliva, which resulted in the loss of some of Poland's northern possessions. In 1657 the Treaty of Bromberg established the independence of the Duchy of Prussia. The Commonwealth forces did well in the Russo-Polish War (1654–1667), but the end result was the permanent division of Ukraine between Poland and Russia, as agreed to in the Truce of Andrusovo (1667). Towards the end of the war, the Lubomirski's rebellion, a major magnate revolt against the king, destabilized and weakened the country. The large-scale slave raids of the Crimean Tatars also had highly deleterious effects on the Polish economy. "Merkuriusz Polski", the first Polish newspaper, was published in 1661.

In 1668, grief-stricken at the recent death of his wife and frustrated by the disastrous political setbacks of his reign, John II Casimir abdicated the throne and fled to France.

King Michał Korybut Wiśniowiecki, a native Pole, was elected to replace John II Casimir in 1669. The Polish–Ottoman War (1672–76) broke out during his reign, which lasted until 1673, and continued under his successor, John III Sobieski (r. 1674–1696). Sobieski intended to pursue Baltic area expansion (and to this end he signed the secret Treaty of Jaworów with France in 1675), but was forced instead to fight protracted wars with the Ottoman Empire. By doing so, Sobieski briefly revived the Commonwealth's military might. He defeated the expanding Muslims at the Battle of Khotyn in 1673 and decisively helped deliver Vienna from a Turkish onslaught at the Battle of Vienna in 1683. Sobieski's reign marked the last high point in the history of the Commonwealth: in the first half of the 18th century, Poland ceased to be an active player in international politics. The Treaty of Perpetual Peace (1686) with Russia was the final border settlement between the two countries before the First Partition of Poland in 1772.

The Commonwealth, subjected to almost constant warfare until 1720, suffered enormous population losses and massive damage to its economy and social structure. The government became ineffective in the wake of large-scale internal conflicts, corrupted legislative processes and manipulation by foreign interests. The nobility fell under the control of a handful of feuding magnate families with established territorial domains. The urban population and infrastructure fell into ruin, together with most peasant farms, whose inhabitants were subjected to increasingly extreme forms of serfdom. The development of science, culture and education came to a halt or regressed.

The royal election of 1697 brought a ruler of the Saxon House of Wettin to the Polish throne: Augustus II the Strong (r. 1697–1733), who was able to assume the throne only by agreeing to convert to Roman Catholicism. He was succeeded by his son Augustus III (r. 1734–1763). The reigns of the Saxon kings (who were both simultaneously prince-electors of Saxony) were disrupted by competing candidates for the throne and witnessed further disintegration of the Commonwealth.

The Great Northern War of 1700–1721, a period seen by the contemporaries as a temporary eclipse, may have been the fatal blow that brought down the Polish political system. Stanisław Leszczyński was installed as king in 1704 under Swedish protection, but lasted only a few years. The Silent Sejm of 1717 marked the beginning of the Commonwealth's existence as a Russian protectorate: the Tsardom would guarantee the reform-impeding Golden Liberty of the nobility from that time on in order to cement the Commonwealth's weak central authority and a state of perpetual political impotence. In a resounding break with traditions of religious tolerance, Protestants were executed during the Tumult of Thorn in 1724. In 1732, Russia, Austria and Prussia, Poland's three increasingly powerful and scheming neighbors, entered into the secret Treaty of the Three Black Eagles with the intention of controlling the future royal succession in the Commonwealth. The War of the Polish Succession was fought in 1733–1735 to assist Leszczyński in assuming the throne of Poland for a second time. Amidst considerable foreign involvement, his efforts were unsuccessful. The Kingdom of Prussia became a strong regional power and succeeded in wresting the historically Polish province of Silesia from the Habsburg Monarchy in the Silesian Wars; it thus constituted an ever-greater threat to Poland's security.

The personal union between the Commonwealth and the Electorate of Saxony did give rise to the emergence of a reform movement in the Commonwealth and the beginnings of the Polish Enlightenment culture, the major positive developments of this era. The first Polish public library was the Załuski Library in Warsaw, opened to the public in 1747.

During the later part of the 18th century, fundamental internal reforms were attempted in the Polish–Lithuanian Commonwealth as it slid into extinction. The reform activity, initially promoted by the magnate Czartoryski family faction known as the "Familia", provoked a hostile reaction and military response from neighboring powers, but it did create conditions that fostered economic improvement. The most populous urban center, the capital city of Warsaw, replaced Danzig (Gdańsk) as the leading trade center, and the importance of the more prosperous urban social classes increased. The last decades of the independent Commonwealth's existence were characterized by aggressive reform movements and far-reaching progress in the areas of education, intellectual life, art and the evolution of the social and political system.

The royal election of 1764 resulted in the elevation of Stanisław August Poniatowski, a refined and worldly aristocrat connected to the Czartoryski family, but hand-picked and imposed by Empress Catherine the Great of Russia, who expected him to be her obedient follower. Stanisław August ruled the Polish–Lithuanian state until its dissolution in 1795. The king spent his reign torn between his desire to implement reforms necessary to save the failing state and the perceived necessity of remaining in a subordinate relationship to his Russian sponsors.

The Bar Confederation (1768–1772) was a rebellion of nobles directed against Russia's influence in general and Stanisław August, who was seen as its representative, in particular. It was fought to preserve Poland's independence and the nobility's traditional interests. After several years, it was brought under control by forces loyal to the king and those of the Russian Empire.

Following the suppression of the Bar Confederation, parts of the Commonwealth were divided up among Prussia, Austria and Russia in 1772 at the instigation of Frederick the Great of Prussia, an action that became known as the First Partition of Poland: the outer provinces of the Commonwealth were seized by agreement among the country's three powerful neighbors and only a rump state remained. In 1773, the "Partition Sejm" ratified the partition under duress as a "fait accompli". However, it also established the Commission of National Education, a pioneering in Europe education authority often called the world's first ministry of education.

The long-lasting session of parliament convened by King Stanisław August is known as the Great Sejm or Four-Year Sejm; it first met in 1788. Its landmark achievement was the passing of the Constitution of 3 May 1791, the first singular pronouncement of a supreme law of the state in modern Europe. A moderately reformist document condemned by detractors as sympathetic to the ideals of the French Revolution, it soon generated strong opposition from the conservative circles of the Commonwealth's upper nobility and from Empress Catherine of Russia, who was determined to prevent the rebirth of a strong Commonwealth. The nobility's Targowica Confederation, formed in Russian imperial capital of Saint Petersburg, appealed to Catherine for help, and in May 1792, the Russian army entered the territory of the Commonwealth. The Polish–Russian War of 1792, a defensive war fought by the forces of the Commonwealth against Russian invaders, ended when the Polish king, convinced of the futility of resistance, capitulated by joining the Targowica Confederation. The Russian-allied confederation took over the government, but Russia and Prussia in 1793 arranged for the Second Partition of Poland anyway. The partition left the country with a critically reduced territory that rendered it essentially incapable of an independent existence. The Commonwealth's Grodno Sejm of 1793, the last Sejm of the state's existence, was compelled to confirm the new partition.

Radicalized by recent events, Polish reformers (whether in exile or still resident in the reduced area remaining to the Commonwealth) were soon working on preparations for a national insurrection. Tadeusz Kościuszko, a popular general and a veteran of the American Revolution, was chosen as its leader. He returned from abroad and issued Kościuszko's proclamation in Kraków on March 24, 1794. It called for a national uprising under his supreme command. Kościuszko emancipated many peasants in order to enroll them as "kosynierzy" in his army, but the hard-fought insurrection, despite widespread national support, proved incapable of generating the foreign assistance necessary for its success. In the end, it was suppressed by the combined forces of Russia and Prussia, with Warsaw captured in November 1794 in the aftermath of the Battle of Praga.

In 1795, a Third Partition of Poland was undertaken by Russia, Prussia and Austria as a final division of territory that resulted in the effective dissolution of the Polish–Lithuanian Commonwealth. King Stanisław August Poniatowski was escorted to Grodno, forced to abdicate, and retired to Saint Petersburg. Tadeusz Kościuszko, initially imprisoned, was allowed to emigrate to the United States in 1796.

The response of the Polish leadership to the last partition is a matter of historical debate. Literary scholars found that the dominant emotion of the first decade was despair that produced a moral desert ruled by violence and treason. On the other hand, historians have looked for signs of resistance to foreign rule. Apart from those who went into exile, the nobility took oaths of loyalty to their new rulers and served as officers in their armies.

Although no sovereign Polish state existed between 1795 and 1918, the idea of Polish independence was kept alive throughout the 19th century. There were a number of uprisings and other armed undertakings waged against the partitioning powers. Military efforts after the partitions were first based on the alliances of Polish émigrés with post-revolutionary France. Jan Henryk Dąbrowski's Polish Legions fought in French campaigns outside of Poland between 1797 and 1802 in hopes that their involvement and contribution would be rewarded with the liberation of their Polish homeland. The Polish national anthem, "Poland Is Not Yet Lost", or "Dąbrowski's Mazurka", was written in praise of his actions by Józef Wybicki in 1797.

The Duchy of Warsaw, a small, semi-independent Polish state, was created in 1807 by Napoleon in the wake of his defeat of Prussia and the signing of the Treaties of Tilsit with Emperor Alexander I of Russia. The Army of the Duchy of Warsaw, led by Józef Poniatowski, participated in numerous campaigns in alliance with France, including the successful Austro-Polish War of 1809, which, combined with the outcomes of other theaters of the War of the Fifth Coalition, resulted in an enlargement of the duchy's territory. The French invasion of Russia in 1812 and the German Campaign of 1813 saw the duchy's last military engagements. The Constitution of the Duchy of Warsaw abolished serfdom as a reflection of the ideals of the French Revolution, but it did not promote land reform.

After Napoleon's defeat, a new European order was established at the Congress of Vienna, which met in the years 1814 and 1815. Adam Jerzy Czartoryski, a former close associate of Emperor Alexander I, became the leading advocate for the Polish national cause. The Congress implemented a new partition scheme, which took into account some of the gains realized by the Poles during the Napoleonic period. 

The Duchy of Warsaw was replaced in 1815 with a new Kingdom of Poland, unofficially known as Congress Poland. The residual Polish kingdom was joined to the Russian Empire in a personal union under the Russian tsar and it was allowed its own constitution and military. East of the kingdom, large areas of the former Polish–Lithuanian Commonwealth remained directly incorporated into the Russian Empire as the Western Krai. These territories, along with Congress Poland, are generally considered to form the Russian Partition. The Russian, Prussian, and Austrian "partitions" are informal names for the lands of the former Commonwealth, not actual units of administrative division of Polish–Lithuanian territories after partitions. The Prussian Partition included a portion separated as the Grand Duchy of Posen. Peasants under the Prussian administration were gradually enfranchised under the reforms of 1811 and 1823. The limited legal reforms in the Austrian Partition were overshadowed by its rural poverty. The Free City of Cracow was a tiny republic created by the Congress of Vienna under the joint supervision of the three partitioning powers. Despite the bleak from the standpoint of Polish patriots political situation, economic progress was made in the lands taken over by foreign powers because the period after the Congress of Vienna witnessed a significant development in the building of early industry.

Economic historians have made new estimates on GDP per capita, 1790–1910. They confirm the hypothesis of semi-peripheral development of Polish territories in the 19th century and the slow process of catching-up with the core economies.

The increasingly repressive policies of the partitioning powers led to resistance movements in partitioned Poland, and in 1830 Polish patriots staged the November Uprising. This revolt developed into a full-scale war with Russia, but the leadership was taken over by Polish conservatives who were reluctant to challenge the empire and hostile to broadening the independence movement's social base through measures such as land reform. Despite the significant resources mobilized, a series of errors by several successive chief commanders appointed by the insurgent Polish National Government led to the defeat of its forces by the Russian army in 1831. Congress Poland lost its constitution and military, but formally remained a separate administrative unit within the Russian Empire.

After the defeat of the November Uprising, thousands of former Polish combatants and other activists emigrated to Western Europe. This phenomenon, known as the Great Emigration, soon dominated Polish political and intellectual life. Together with the leaders of the independence movement, the Polish community abroad included the greatest Polish literary and artistic minds, including the Romantic poets Adam Mickiewicz, Juliusz Słowacki, Cyprian Norwid, and the composer Frédéric Chopin. In occupied and repressed Poland, some sought progress through nonviolent activism focused on education and economy, known as organic work; others, in cooperation with the emigrant circles, organized conspiracies and prepared for the next armed insurrection.

The planned national uprising failed to materialize because the authorities in the partitions found out about secret preparations. The Greater Poland uprising ended in a fiasco in early 1846. In the Kraków uprising of February 1846, patriotic action was combined with revolutionary demands, but the result was the incorporation of the Free City of Cracow into the Austrian Partition. The Austrian officials took advantage of peasant discontent and incited villagers against the noble-dominated insurgent units. This resulted in the Galician slaughter of 1846, a large-scale rebellion of serfs seeking relief from their post-feudal condition of mandatory labor as practiced in "folwarks". The uprising freed many from bondage and hastened decisions that led to the abolition of Polish serfdom in the Austrian Empire in 1848. A new wave of Polish involvement in revolutionary movements soon took place in the partitions and in other parts of Europe in the context of the Spring of Nations revolutions of 1848 (e.g. Józef Bem's participation in the revolutions in Austria and Hungary). The 1848 German revolutions precipitated the Greater Poland uprising of 1848, in which peasants in the Prussian Partition, who were by then largely enfranchised, played a prominent role.

As a matter of continuous policy, the Russian autocracy kept assailing Polish national core values of language, religion and culture. In consequence, despite the limited liberalization measures allowed in Congress Poland under the rule of Tsar Alexander II of Russia, a renewal of popular liberation activities took place in 1860–1861. During large-scale demonstrations in Warsaw, Russian forces inflicted numerous casualties on the civilian participants. The "Red", or left-wing faction of Polish activists, which promoted peasant enfranchisement and cooperated with Russian revolutionaries, became involved in immediate preparations for a national uprising. The "White", or right-wing faction, was inclined to cooperate with the Russian authorities and countered with partial reform proposals. In order to cripple the manpower potential of the Reds, Aleksander Wielopolski, the conservative leader of the government of Congress Poland, arranged for a partial selective conscription of young Poles for the Russian army in the years 1862 and 1863. This action hastened the outbreak of hostilities. The January Uprising, joined and led after the initial period by the Whites, was fought by partisan units against an overwhelmingly advantaged enemy. The uprising lasted from January 1863 to the spring of 1864, when Romuald Traugutt, the last supreme commander of the insurgency, was captured by the tsarist police.

On 2 March 1864, the Russian authority, compelled by the uprising to compete for the loyalty of Polish peasants, officially published an enfranchisement decree in Congress Poland along the lines of an earlier land reform proclamation of the insurgents. The act created the conditions necessary for the development of the capitalist system on central Polish lands. At the time when most Poles realized the futility of armed resistance without external support, the various sections of Polish society were undergoing deep and far-reaching evolution in the areas of social, economic and cultural development.

The failure of the January Uprising in Poland caused a major psychological trauma and became a historic watershed; indeed, it sparked the development of modern Polish nationalism. The Poles, subjected within the territories under the Russian and Prussian administrations to still stricter controls and increased persecution, sought to preserve their identity in non-violent ways. After the uprising, Congress Poland was downgraded in official usage from the "Kingdom of Poland" to the "Vistula Land" and was more fully integrated into Russia proper, but not entirely obliterated. The Russian and German languages were imposed in all public communication, and the Catholic Church was not spared from severe repression. Public education was increasingly subjected to Russification and Germanisation measures. Illiteracy was reduced, most effectively in the Prussian partition, but education in the Polish language was preserved mostly through unofficial efforts. The Prussian government pursued German colonization, including the purchase of Polish-owned land. On the other hand, the region of Galicia (western Ukraine and southern Poland) experienced a gradual relaxation of authoritarian policies and even a Polish cultural revival. Economically and socially backward, it was under the milder rule of the Austro-Hungarian Monarchy and from 1867 was increasingly allowed limited autonomy. "Stańczycy", a conservative Polish pro-Austrian faction led by great land owners, dominated the Galician government. The Polish Academy of Learning (an academy of sciences) was founded in Kraków in 1872.

Social activities termed "organic work" consisted of self-help organizations that promoted economic advancement and work on improving the competitiveness of Polish-owned businesses, industrial, agricultural or other. New commercial methods of generating higher productivity were discussed and implemented through trade associations and special interest groups, while Polish banking and cooperative financial institutions made the necessary business loans available. The other major area of effort in organic work was educational and intellectual development of the common people. Many libraries and reading rooms were established in small towns and villages, and numerous printed periodicals manifested the growing interest in popular education. Scientific and educational societies were active in a number of cities. Such activities were most pronounced in the Prussian Partition.

Positivism in Poland replaced Romanticism as the leading intellectual, social and literary trend. It reflected the ideals and values of the emerging urban bourgeoisie. Around 1890, the urban classes gradually abandoned the positivist ideas and came under the influence of modern pan-European nationalism.

Under the partitioning powers, economic diversification and progress, including large-scale industrialisation, were introduced in the traditionally agrarian Polish lands, but this development turned out to be very uneven. Advanced agriculture was practiced in the Prussian Partition, except for Upper Silesia, where the coal-mining industry created a large labor force. The densest network of railroads was built in German-ruled western Poland. In Russian Congress Poland, a striking growth of industry, railways and towns took place, all against the background of an extensive, but less productive agriculture. The industrial initiative, capital and know-how were provided largely by entrepreneurs who were not ethnic Poles. Warsaw (a metallurgical center) and Łódź (a textiles center) grew rapidly, as did the total proportion of urban population, making the region the most economically advanced in the Russian Empire (industrial production exceeded agricultural production there by 1909). The coming of the railways spurred some industrial growth even in the vast Russian Partition territories outside of Congress Poland. The Austrian Partition was rural and poor, except for the industrialized Cieszyn Silesia area. Galician economic expansion after 1890 included oil extraction and resulted in the growth of Lemberg (Lwów, Lviv) and Kraków.

Economic and social changes involving land reform and industrialization, combined with the effects of foreign domination, altered the centuries-old social structure of Polish society. Among the newly emergent strata were wealthy industrialists and financiers, distinct from the traditional, but still critically important landed aristocracy. The intelligentsia, an educated, professional or business middle class, often originated from lower gentry, landless or alienated from their rural possessions, and from urban people. Many smaller agricultural enterprises based on serfdom did not survive the land reforms. The industrial proletariat, a new underprivileged class, was composed mainly of poor peasants or townspeople forced by deteriorating conditions to migrate and search for work in urban centers in their countries of origin or abroad. Millions of residents of the former Commonwealth of various ethnic groups worked or settled in Europe and in North and South America.

Social and economic changes were partial and gradual. The degree of industrialisation, relatively fast-paced in some areas, lagged behind the advanced regions of Western Europe. The three partitions developed different economies and were more economically integrated with their mother states than with each other. In the Prussian Partition, for example, agricultural production depended heavily on the German market, whereas the industrial sector of Congress Poland relied more on the Russian market.

In the 1870s–1890s, large-scale socialist, nationalist, agrarian and other political movements of great ideological fervor became established in partitioned Poland and Lithuania, along with corresponding political parties to promote them. Of the major parties, the socialist First Proletariat was founded in 1882, the Polish League (precursor of National Democracy) in 1887, the Polish Social Democratic Party of Galicia and Silesia in 1890, the Polish Socialist Party in 1892, the Marxist Social Democracy of the Kingdom of Poland and Lithuania in 1893, the agrarian People's Party of Galicia in 1895 and the Jewish socialist Bund in 1897. Christian democracy regional associations allied with the Catholic Church were also active; they united into the Polish Christian Democratic Party in 1919. 

The main minority ethnic groups of the former Commonwealth, including Ukrainians, Lithuanians, Belarusians and Jews, were getting involved in their own national movements and plans, which met with disapproval on the part of those Polish independence activists who counted on an eventual rebirth of the Commonwealth or the rise of a Commonwealth-inspired federal structure (a political movement referred to as Prometheism).

Around the start of the 20th century, the Young Poland cultural movement, centered in Austrian Galicia, took advantage of a milieu conducive to liberal expression in that region and was the source of Poland's finest artistic and literary productions. In this same era, Marie Skłodowska Curie, a pioneer radiation scientist, performed her groundbreaking research in Paris.

The Revolution of 1905–1907 in Russian Poland, the result of many years of pent-up political frustrations and stifled national ambitions, was marked by political maneuvering, strikes and rebellion. The revolt was part of much broader disturbances throughout the Russian Empire associated with the general Revolution of 1905. In Poland, the principal revolutionary figures were Roman Dmowski and Józef Piłsudski. Dmowski was associated with the right-wing nationalist movement National Democracy, whereas Piłsudski was associated with the Polish Socialist Party. As the authorities re-established control within the Russian Empire, the revolt in Congress Poland, placed under martial law, withered as well, partially as a result of tsarist concessions in the areas of national and workers' rights, including Polish representation in the newly created Russian Duma. The collapse of the revolt in the Russian Partition, coupled with intensified Germanization in the Prussian Partition, left Austrian Galicia as the territory where Polish patriotic action was most likely to flourish.

In the Austrian Partition, Polish culture was openly cultivated, and in the Prussian Partition, there were high levels of education and living standards, but the Russian Partition remained of primary importance for the Polish nation and its aspirations. About 15.5 million Polish-speakers lived in the territories most densely populated by Poles: the western part of the Russian Partition, the Prussian Partition and the western Austrian Partition. Ethnically Polish settlement spread over a large area further to the east, including its greatest concentration in the Vilnius Region, amounted to only over 20% of that number.
Polish paramilitary organizations oriented toward independence, such as the Union of Active Struggle, were formed in 1908–1914, mainly in Galicia. The Poles were divided and their political parties fragmented on the eve of World War I, with Dmowski's National Democracy (pro-Entente) and Piłsudski's faction assuming opposing positions.

The outbreak of World War I in the Polish lands offered Poles unexpected hopes for achieving independence as a result of the turbulence that engulfed the empires of the partitioning powers. All three of the monarchies that had benefited from the partition of Polish territories (Germany, Austria and Russia) were dissolved by the end of the war, and many of their territories were dispersed into new political units. At the start of the war, the Poles found themselves conscripted into the armies of the partitioning powers in a war that was not theirs. Furthermore, they were frequently forced to fight each other, since the armies of Germany and Austria were allied against Russia. Piłsudski's paramilitary units stationed in Galicia were turned into the Polish Legions in 1914 and as a part of the Austro-Hungarian Army fought on the Russian front until 1917, when the formation was disbanded. Piłsudski, who refused demands that his men fight under German command, was arrested and imprisoned by the Germans and became a heroic symbol of Polish nationalism.

Due to a series of German victories on the Eastern Front, the area of Congress Poland became occupied by the Central Powers of Germany and Austria; Warsaw was captured by the Germans on 5 August 1915. In the Act of 5th November 1916, a fresh incarnation of the Kingdom of Poland ("Królestwo Regencyjne") was proclaimed by Germany and Austria on formerly Russian-controlled territories, within the German "Mitteleuropa" scheme. The sponsor states were never able to agree on a candidate to assume the throne, however; rather, it was governed in turn by German and Austrian governor-generals, a Provisional Council of State, and a Regency Council. This increasingly autonomous puppet state existed until November 1918, when it was replaced by the newly established Republic of Poland. The existence of this "kingdom" and its planned Polish army had a positive effect on the Polish national efforts on the Allied side, but in the Treaty of Brest-Litovsk of March 1918 the victorious in the east Germany imposed harsh conditions on defeated Russia and ignored Polish interests. Toward the end of the war, the German authorities engaged in massive, purposeful devastation of industrial and other economic potential of Polish lands in order to impoverish the country, a likely future competitor of Germany.

The independence of Poland had been campaigned for in Russia and in the West by Dmowski and in the West by Ignacy Jan Paderewski. Tsar Nicholas II of Russia, and then the leaders of the February Revolution and the October Revolution of 1917, installed governments who declared in turn their support for Polish independence. In 1917, France formed the Blue Army (placed under Józef Haller) that comprised about 70,000 Poles by the end of the war, including men captured from German and Austrian units and 20,000 volunteers from the United States. There was also a 30,000-men strong Polish anti-German army in Russia. Dmowski, operating from Paris as head of the Polish National Committee (KNP), became the spokesman for Polish nationalism in the Allied camp. On the initiative of Woodrow Wilson's Fourteen Points, Polish independence was officially endorsed by the Allies in June 1918.

In all, about two million Poles served in the war, counting both sides, and about 400–450,000 died. Much of the fighting on the Eastern Front took place in Poland, and civilian casualties and devastation were high.

The final push for independence of Poland took place on the ground in October–November 1918. Near the end of the war, Austro-Hungarian and German units were being disarmed, and the Austrian army's collapse freed Cieszyn and Kraków at the end of October. Lviv was then contested in the Polish–Ukrainian War of 1918–1919. Ignacy Daszyński headed the first short-lived independent Polish government in Lublin from 7 November, the leftist Provisional People's Government of the Republic of Poland, proclaimed as a democracy. Germany, now defeated, was forced by the Allies to stand down its large military forces in Poland. Overtaken by the German Revolution of 1918–1919 at home, the Germans released Piłsudski from prison. He arrived in Warsaw on 10 November and was granted extensive authority by the Regency Council; Piłsudski's authority was also recognized by the Lublin government. On 22 November, he became the temporary head of state. Piłsudski was held by many in high regard, but was resented by the right-wing National Democrats. The emerging Polish state was internally divided, heavily war-damaged and economically dysfunctional.

After more than a century of foreign rule, Poland regained its independence at the end of World War I as one of the outcomes of the negotiations that took place at the Paris Peace Conference of 1919. The Treaty of Versailles that emerged from the conference set up an independent Polish nation with an outlet to the sea, but left some of its boundaries to be decided by plebiscites. The largely German-inhabited Free City of Danzig was granted a separate status that guaranteed its use as a port by Poland. In the end, the settlement of the German-Polish border turned out to be a prolonged and convoluted process. The dispute helped engender the Greater Poland Uprising of 1918–1919, the three Silesian uprisings of 1919–1921, the East Prussian plebiscite of 1920, the Upper Silesia plebiscite of 1921 and the 1922 Silesian Convention in Geneva.

Other boundaries were settled by war and subsequent treaties. A total of six border wars were fought in 1918–1921, including the Polish–Czechoslovak border conflicts over Cieszyn Silesia in January 1919.

As distressing as these border conflicts were, the Polish–Soviet War of 1919–1921 was the most important series of military actions of the era. Piłsudski had entertained far-reaching anti-Russian cooperative designs in Eastern Europe, and in 1919 the Polish forces pushed eastward into Lithuania, Belarus and Ukraine by taking advantage of the Russian preoccupation with a civil war, but they were soon confronted with the Soviet westward offensive of 1918–1919. Western Ukraine was already a theater of the Polish–Ukrainian War, which eliminated the proclaimed West Ukrainian People's Republic in July 1919. In the autumn of 1919, Piłsudski rejected urgent pleas from the former Entente powers to support Anton Denikin's White movement in its advance on Moscow. The Polish–Soviet War proper began with the Polish Kiev Offensive in April 1920. Allied with the Directorate of Ukraine of the Ukrainian People's Republic, the Polish armies had advanced past Vilnius, Minsk and Kiev by June. At that time, a massive Soviet counter-offensive pushed the Poles out of most of Ukraine. On the northern front, the Soviet army reached the outskirts of Warsaw in early August. A Soviet triumph and the quick end of Poland seemed inevitable. However, the Poles scored a stunning victory at the Battle of Warsaw (1920). Afterwards, more Polish military successes followed, and the Soviets had to pull back. They left swathes of territory populated largely by Belarusians or Ukrainians to Polish rule. The new eastern boundary was finalized by the Peace of Riga in March 1921.

The defeat of the Russian armies forced Vladimir Lenin and the Soviet leadership to postpone their strategic objective of linking up with the German and other European revolutionary leftist collaborators to spread communist revolution. Lenin also hoped for generating support for the Red Army in Poland, which failed to materialize.

Piłsudski's seizure of Vilnius in October 1920 (known as Żeligowski's Mutiny) was a nail in the coffin of the already poor Lithuania–Poland relations that had been strained by the Polish–Lithuanian War of 1919–1920; both states would remain hostile to one another for the remainder of the interwar period. Piłsudski's concept of Intermarium (an East European federation of states inspired by the tradition of the multiethnic Polish–Lithuanian Commonwealth that would include a hypothetical multinational successor state to the Grand Duchy of Lithuania) had the fatal flaw of being incompatible with his assumption of Polish domination, which would amount to an encroachment on the neighboring peoples' lands and aspirations. At the time of rising national movements, the plan thus ceased being a feature of Poland's politics. A larger federated structure was also opposed by Dmowski's National Democrats. Their representative at the Peace of Riga talks, Stanisław Grabski, opted for leaving Minsk, Berdychiv, Kamianets-Podilskyi and the surrounding areas on the Soviet side of the border. The National Democrats did not want to assume the lands they considered politically undesirable, as such territorial enlargement would result in a reduced proportion of citizens who were ethnically Polish.

The Peace of Riga settled the eastern border by preserving for Poland a substantial portion of the old Commonwealth's eastern territories at the cost of partitioning the lands of the former Grand Duchy of Lithuania (Lithuania and Belarus) and Ukraine. The Ukrainians ended up with no state of their own and felt betrayed by the Riga arrangements; their resentment gave rise to extreme nationalism and anti-Polish hostility. The Kresy (or borderland) territories in the east won by 1921 would form the basis for a swap arranged and carried out by the Soviets in 1943–1945, who at that time compensated the re-emerging Polish state for the eastern lands lost to the Soviet Union with conquered areas of eastern Germany.

The successful outcome of the Polish–Soviet War gave Poland a false sense of its prowess as a self-sufficient military power and encouraged the government to try to resolve international problems through imposed unilateral solutions. The territorial and ethnic policies of the interwar period contributed to bad relations with most of Poland's neighbors and uneasy cooperation with more distant centers of power, especially France and Great Britain.

Among the chief difficulties faced by the government of the new Polish republic was the lack of an integrated infrastructure among the formerly separate partitions, a deficiency that disrupted industry, transportation, trade, and other areas.

The first Polish legislative election for the re-established Sejm (national parliament) took place in January 1919. A temporary Small Constitution was passed by the body the following month.

The rapidly growing population of Poland within its new boundaries was ¾ agricultural and ¼ urban; Polish was the primary language of only ⅔ of the inhabitants of the new country. The minorities had very little voice in the government. The permanent March Constitution of Poland was adopted in March 1921. At the insistence of the National Democrats, who were concerned about how aggressively Józef Piłsudski might exercise presidential powers if he were elected to office, the constitution mandated limited prerogatives for the presidency.

The proclamation of the March Constitution was followed by a short and turbulent period of constitutional order and parliamentary democracy that lasted until 1926. The legislature remained fragmented, without stable majorities, and governments changed frequently. The open-minded Gabriel Narutowicz was elected president constitutionally (without a popular vote) by the National Assembly in 1922. However, members of the nationalist right-wing faction did not regard his elevation as legitimate. They viewed Narutowicz rather as a traitor whose election was pushed through by the votes of alien minorities. Narutowicz and his supporters were subjected to an intense harassment campaign, and the president was assassinated on 16 December 1922, after serving only five days in office.

Land reform measures were passed in 1919 and 1925 under pressure from an impoverished peasantry. They were partially implemented, but resulted in the parcellation of only 20% of the great agricultural estates. Poland endured numerous economic calamities and disruptions in the early 1920s, including waves of workers' strikes such as the 1923 Kraków riot. The German–Polish customs war, initiated by Germany in 1925, was one of the most damaging external factors that put a strain on Poland's economy. On the other hand, there were also signs of progress and stabilization, for example a critical reform of finances carried out by the competent government of Władysław Grabski, which lasted almost two years. Certain other achievements of the democratic period having to do with the management of governmental and civic institutions necessary to the functioning of the reunited state and nation were too easily overlooked. Lurking on the sidelines was a disgusted army officer corps unwilling to subject itself to civilian control, but ready to follow the retired Piłsudski, who was highly popular with Poles and just as dissatisfied with the Polish system of government as his former colleagues in the military.

On 12 May 1926, Piłsudski staged the May Coup, a military overthrow of the civilian government mounted against President Stanisław Wojciechowski and the troops loyal to the legitimate government. Hundreds died in fratricidal fighting. Piłsudski was supported by several leftist factions who ensured the success of his coup by blocking the railway transportation of government forces. He also had the support of the conservative great landowners, a move that left the right-wing National Democrats as the only major social force opposed to the takeover.

Following the coup, the new regime initially respected many parliamentary formalities, but gradually tightened its control and abandoned pretenses. The Centrolew, a coalition of center-left parties, was formed in 1929, and in 1930 called for the "abolition of dictatorship". In 1930, the Sejm was dissolved and a number of opposition deputies were imprisoned at the Brest Fortress. Five thousand political opponents were arrested ahead of the Polish legislative election of 1930, which was rigged to award a majority of seats to the pro-regime Nonpartisan Bloc for Cooperation with the Government (BBWR).

The authoritarian Sanation regime ("sanation" meant to denote "healing") that Piłsudski led until his death in 1935 (and would remain in place until 1939) reflected the dictator's evolution from his center-left past to conservative alliances. Political institutions and parties were allowed to function, but the electoral process was manipulated and those not willing to cooperate submissively were subjected to repression. From 1930, persistent opponents of the regime, many of the leftist persuasion, were imprisoned and subjected to staged legal processes with harsh sentences, such as the Brest trials, or else detained in the Bereza Kartuska prison and similar camps for political prisoners. About three thousand were detained without trial at different times at the Bereza internment camp between 1934 and 1939. In 1936 for example, 369 activists were taken there, including 342 Polish communists. Rebellious peasants staged riots in 1932, 1933 and the 1937 peasant strike in Poland. Other civil disturbances were caused by striking industrial workers (e.g. events of the "Bloody Spring" of 1936), nationalist Ukrainians and the activists of the incipient Belarusian movement. All became targets of ruthless police-military pacification. Besides sponsoring political repression, the regime fostered Józef Piłsudski's cult of personality that had already existed long before he assumed dictatorial powers.

Piłsudski signed the Soviet–Polish Non-Aggression Pact in 1932 and the German–Polish Non-Aggression Pact in 1934, but in 1933 he insisted that there was no threat from the East or West and said that Poland's politics were focused on becoming fully independent without serving foreign interests. He initiated the policy of maintaining an equal distance and an adjustable middle course regarding the two great neighbors, later continued by Józef Beck. Piłsudski kept personal control of the army, but it was poorly equipped, poorly trained and had poor preparations in place for possible future conflicts. His only war plan was a defensive war against a Soviet invasion. The slow modernization after Piłsudski's death fell far behind the progress made by Poland's neighbors and measures to protect the western border, discontinued by Piłsudski from 1926, were not undertaken until March 1939.

Sanation deputies in the Sejm used a parliamentary maneuver to abolish the democratic March Constitution and push through a more authoritarian April Constitution in 1935; it reduced the powers of the Sejm, which Piłsudski despised. The process and the resulting document were seen as illegitimate by the anti-Sanation opposition, but during World War II, the Polish government-in-exile recognized the April Constitution in order to uphold the legal continuity of the Polish state.

Marshal Piłsudski considered the possbilility of a preventive war against Germany. Polish troops near the German border lead to intervention by the League of Nations forceing Poland to withdraw troops from Hel peninsula and from Danzig. The Polish press raised rather extreme demands for a Poland stretching to Oder and Neisse or even to the Elbe.

When Marshal Piłsudski died in 1935, he retained the support of dominant sections of Polish society even though he never risked testing his popularity in an honest election. His regime was dictatorial, but at that time only Czechoslovakia remained democratic in all of the regions neighboring Poland. Historians have taken widely divergent views of the meaning and consequences of the coup Piłsudski perpetrated and his personal rule that followed.

Independence stimulated the development of Polish culture in the Interbellum and intellectual achievement was high. Warsaw, whose population almost doubled between World War I and World War II, was a restless, burgeoning metropolis. It outpaced Kraków, Lwów and Wilno, the other major population centers of the country.

Mainstream Polish society was not affected by the repressions of the Sanation authorities overall; many Poles enjoyed relative stability, and the economy improved markedly between 1926 and 1929, only to become caught up in the global Great Depression. After 1929, the country's industrial production and gross national income slumped by about 50%.

The Great Depression brought low prices for farmers and unemployment for workers. Social tensions increased, including rising antisemitism. A major economic transformation and multi-year state plan to achieve national industrial development, as embodied in the Central Industrial Region initiative launched in 1936, was led by Minister Eugeniusz Kwiatkowski. Motivated primarily by the need for a native arms industry, the initiative was in progress at the time of the outbreak of World War II. Kwiatkowski was also the main architect of the earlier Gdynia seaport project.

The prevalent in political circles nationalism was fueled by the large size of Poland's minority populations and their separate agendas. According to the language criterion of the Polish census of 1931, the Poles constituted 69% of the population, Ukrainians 15%, Jews (defined as speakers of the Yiddish language) 8.5%, Belarusians 4.7%, Germans 2.2%, Lithuanians 0.25%, Russians 0.25% and Czechs 0.09%, with some geographical areas dominated by a particular minority. In time, the ethnic conflicts intensified, and the Polish state grew less tolerant of the interests of its national minorities. In interwar Poland, compulsory free general education substantially reduced illiteracy rates, but discrimination was practiced in a way that resulted in a dramatic decrease in the number of Ukrainian language schools and official restrictions on Jewish attendance at selected schools in the late 1930s.

The population grew steadily, reaching 35 million in 1939. However, the overall economic situation in the interwar period was one of stagnation. There was little money for investment inside Poland, and few foreigners were interested in investing there. Total industrial production barely increased between 1913 and 1939 (within the area delimited by the 1939 borders), but because of population growth (from 26.3 million in 1919 to 34.8 million in 1939), the "per capita" output actually decreased by 18%.

Conditions in the predominant agricultural sector kept deteriorating between 1929 and 1939, which resulted in rural unrest and a progressive radicalization of the Polish peasant movement that became increasingly inclined toward militant anti-state activities. It was firmly repressed by the authorities. According to Norman Davies, the failures of the Sanation regime (combined with the objective economic realities) caused a radicalization of the Polish masses by the end of the 1930s, but he warns against drawing parallels with the incomparably more repressive regimes of Nazi Germany or the Stalinist Soviet Union.

After Piłsudski's death in 1935, Poland was governed until (and initially during) the German invasion of 1939 by old allies and subordinates known as "Piłsudski's colonels". They had neither the vision nor the resources to cope with the perilous situation facing Poland in the late 1930s. The colonels had gradually assumed greater powers during Piłsudski's life by manipulating the ailing marshal behind the scenes. Eventually they achieved an overt politicization of the army that did nothing to help prepare the country for war.

Foreign policy was the responsibility of Józef Beck, under whom Polish diplomacy attempted balanced approaches toward Germany and the Soviet Union, unfortunately without success, on the basis of a flawed understanding of the European geopolitics of his day. Beck had numerous foreign policy schemes and harbored illusions of Poland's status as a great power. He alienated most of Poland's neighbors, but is not blamed by historians for the ultimate failure of relations with Germany. The principal events of his tenure were concentrated in its last two years. In the case of the 1938 Polish ultimatum to Lithuania, the Polish action nearly resulted in a German takeover of southwest Lithuania, the Klaipėda Region (Memel Territory), which had a largely German population. Also in 1938, the Polish government opportunistically undertook a hostile action against the Czechoslovak state as weakened by the Munich Agreement and annexed a small piece of territory on its borders. In this case, Beck's understanding of the consequences of the Polish military move turned out to be completely mistaken, because in the end the German occupation of Czechoslovakia markedly weakened Poland's own position. Furthermore, Beck erroneously believed that Nazi-Soviet ideological contradictions would preclude their cooperation.

At home, increasingly alienated and suppressed minorities threatened unrest and violence. Extreme nationalist circles such as the National Radical Camp grew more outspoken. One of the groups, the Camp of National Unity, combined many nationalists with Sanation supporters and was connected to the new strongman, Marshal Edward Rydz-Śmigły, whose faction of the Sanation ruling movement was increasingly nationalistic.

In the late 1930s, the exile bloc Front Morges united several major Polish anti-Sanation figures, including Ignacy Paderewski, Władysław Sikorski, Wincenty Witos, Wojciech Korfanty and Józef Haller. It gained little influence inside Poland, but its spirit soon reappeared during World War II, within the Polish government-in-exile.

In October 1938, Joachim von Ribbentrop first proposed German-Polish territorial adjustments and Poland's participation in the Anti-Comintern Pact against the Soviet Union. The status of the Free City of Danzig was one of the key bones of contention. Approached by Ribbentrop again in March 1939, the Polish government expressed willingness to address issues causing German concern, but effectively rejected Germany's stated demands and thus refused to allow Poland to be turned by Adolf Hitler into a German puppet state. Hitler, incensed by the British and French declarations of support for Poland, abrogated the German–Polish Non-Aggression Pact in late April 1939.

To protect itself from an increasingly aggressive Nazi Germany, already responsible for the annexations of Austria (in the Anschluss of 1938), Czechoslovakia (in 1939) and a part of Lithuania after the 1939 German ultimatum to Lithuania, Poland entered into a military alliance with Britain and France (the 1939 Anglo-Polish military alliance and the Franco-Polish alliance (1921), as updated in 1939). However, the two Western powers were defense-oriented and not in a strong position, either geographically or in terms of resources, to assist Poland. Attempts were therefore made by them to induce Soviet-Polish cooperation, which they viewed as the only militarily viable arrangement.

Diplomatic manoeuvers continued in the spring and summer of 1939, but in their final attempts, the Franco-British talks with the Soviets in Moscow on forming an anti-Nazi defensive military alliance failed. Warsaw's refusal to allow the Red Army to operate on Polish territory doomed the Western efforts. The final contentious Allied-Soviet exchanges took place on 21 and 23 August 1939. The regime of Joseph Stalin was the target of an intense German counter-initiative and was concurrently involved in increasingly effective negotiations with Hitler's agents. On 23 August, an outcome contrary to the exertions of the Allies became a reality: in Moscow, Germany and the Soviet Union hurriedly signed the Molotov–Ribbentrop Pact, which secretly provided for the dismemberment of Poland into Nazi- and Soviet-controlled zones.

On 1 September 1939, Hitler ordered an invasion of Poland, the opening event of World War II. Poland had signed an Anglo-Polish military alliance as recently as the 25th of August, and had long been in alliance with France. The two Western powers soon declared war on Germany, but they remained largely inactive (the period early in the conflict became known as the Phoney War) and extended no aid to the attacked country. The technically and numerically superior "Wehrmacht" formations rapidly advanced eastwards and engaged massively in the murder of Polish civilians over the entire occupied territory. On 17 September, a Soviet invasion of Poland began. The Soviet Union quickly occupied most of the areas of eastern Poland that were inhabited by a significant Ukrainian and Belarusian minority. The two invading powers divided up the country as they had agreed in the secret provisions of the Molotov–Ribbentrop Pact. Poland's top government officials and military high command fled the war zone and arrived at the Romanian Bridgehead in mid-September. After the Soviet entry they sought refuge in Romania.

Among the military operations in which Poles held out the longest (until late September or early October) were the Siege of Warsaw, the Battle of Hel and the resistance of the Independent Operational Group Polesie. Warsaw fell on 27 September after a heavy German bombardment that killed tens of thousands civilians and soldiers. Poland was ultimately partitioned between Germany and the Soviet Union according to the terms of the German–Soviet Frontier Treaty signed by the two powers in Moscow on 29 September.

Gerhard Weinberg has argued that the most significant Polish contribution to World War II was sharing its code-breaking results. This allowed the British to perform the cryptanalysis of the Enigma and decipher the main German military code, which gave the Allies a major advantage in the conflict. As regards actual military campaigns, some Polish historians have argued that simply resisting the initial invasion of Poland was the country's greatest contribution to the victory over Nazi Germany, despite its defeat. The Polish Army of nearly one million men significantly delayed the start of the Battle of France, planned by the Germans for 1939. When the Nazi offensive in the West did happen, the delay caused it to be less effective, a possibly crucial factor in the victory of the Battle of Britain.

After Germany invaded the Soviet Union as part of its Operation Barbarossa in June 1941, the whole of pre-war Poland was overrun and occupied by German troops.

German-occupied Poland was divided from 1939 into two regions: Polish areas annexed by Nazi Germany directly into the German "Reich" and areas ruled under a so-called General Government of occupation. The Poles formed an underground resistance movement and a Polish government-in-exile that operated first in Paris, then, from July 1940, in London. Polish-Soviet diplomatic relations, broken since September 1939, were resumed in July 1941 under the Sikorski–Mayski agreement, which facilitated the formation of a Polish army (the Anders' Army) in the Soviet Union. In November 1941, Prime Minister Sikorski flew to the Soviet Union to negotiate with Stalin on its role on the Soviet-German front, but the British wanted the Polish soldiers in the Middle East. Stalin agreed, and the army was evacuated there.

The organizations forming the Polish Underground State that functioned in Poland throughout the war were loyal to and formally under the Polish government-in-exile, acting through its Government Delegation for Poland. During World War II, hundreds of thousands of Poles joined the underground Polish Home Army ("Armia Krajowa"), a part of the Polish Armed Forces of the government-in-exile. About 200,000 Poles fought on the Western Front in the Polish Armed Forces in the West loyal to the government-in-exile, and about 300,000 in the under the Soviet command on the Eastern Front. The pro-Soviet resistance movement in Poland, led by the Polish Workers' Party, was active from 1941. It was opposed by the gradually forming extreme nationalistic National Armed Forces.

Beginning in late 1939, hundreds of thousands of Poles from the Soviet-occupied areas were deported and taken east. Of the upper-ranking military personnel and others deemed uncooperative or potentially harmful by the Soviets, about 22,000 were secretly executed by them at the Katyn massacre. In April 1943, the Soviet Union broke off deteriorating relations with the Polish government-in-exile after the German military announced the discovery of mass graves containing murdered Polish army officers. The Soviets claimed that the Poles committed a hostile act by requesting that the Red Cross investigate these reports.

From 1941, the implementation of the Nazi Final Solution began, and the Holocaust in Poland proceeded with force. Warsaw was the scene of the Warsaw Ghetto Uprising in April–May 1943, triggered by the liquidation of the Warsaw Ghetto by German SS units. The elimination of Jewish ghettos in German-occupied Poland took place in many cities. As the Jewish people were being removed to be exterminated, uprisings were waged against impossible odds by the Jewish Combat Organization and other desperate Jewish insurgents.

At a time of increasing cooperation between the Western Allies and the Soviet Union in the wake of the Nazi invasion of 1941, the influence of the Polish government-in-exile was seriously diminished by the death of Prime Minister Władysław Sikorski, its most capable leader, in a plane crash on 4 July 1943. Around that time, Polish-communist civilian and military organizations opposed to the government, led by Wanda Wasilewska and supported by Stalin, were formed in the Soviet Union.

In July 1944, the Soviet Red Army and Soviet-controlled Polish People's Army entered the territory of future postwar Poland. In protracted fighting in 1944 and 1945, the Soviets and their Polish allies defeated and expelled the German army from Poland at a cost of over 600,000 Soviet soldiers lost.

The greatest single undertaking of the Polish resistance movement in World War II and a major political event was the Warsaw Uprising that began on 1 August 1944. The uprising, in which most of the city's population participated, was instigated by the underground Home Army and approved by the Polish government-in-exile in an attempt to establish a non-communist Polish administration ahead of the arrival of the Red Army. The uprising was originally planned as a short-lived armed demonstration in expectation that the Soviet forces approaching Warsaw would assist in any battle to take the city. The Soviets had never agreed to an intervention, however, and they halted their advance at the Vistula River. The Germans used the opportunity to carry out a brutal suppression of the forces of the pro-Western Polish underground.

The bitterly fought uprising lasted for two months and resulted in the death or expulsion from the city of hundreds of thousands of civilians. After the defeated Poles surrendered on 2 October, the Germans carried out a planned destruction of Warsaw on Hitler's orders that obliterated the remaining infrastructure of the city. The Polish First Army, fighting alongside the Soviet Red Army, entered a devastated Warsaw on 17 January 1945.

From the time of the Tehran Conference in late 1943, there was broad agreement among the three Great Powers (the United States, the United Kingdom, and the Soviet Union) that the locations of the borders between Germany and Poland and between Poland and the Soviet Union would be fundamentally changed after the conclusion of World War II. Stalin's view that Poland should be moved far to the west was accepted by Polish communists, whose organizations included the Polish Workers' Party and the Union of Polish Patriots. The communist-led State National Council, a quasi-parliamentary body, was in existence in Warsaw from the beginning of 1944. In July 1944, a communist-controlled Polish Committee of National Liberation was established in Lublin, to nominally govern the areas liberated from German control. The move prompted protests from Prime Minister Stanisław Mikołajczyk and his Polish government-in-exile.

By the time of the Yalta Conference in February 1945, the communists had already established a Provisional Government of the Republic of Poland. The Soviet position at the conference was strong because of their decisive contribution to the war effort and as a result of their occupation of immense amounts of land in central and eastern Europe. The Great Powers gave assurances that the communist provisional government would be converted into an entity that would include democratic forces from within the country and active abroad, but the London-based government-in-exile was not mentioned. A Provisional Government of National Unity and subsequent democratic elections were the agreed stated goals. The disappointing results of these plans and the failure of the Western powers to ensure a strong participation of non-communists in the immediate post-war Polish government were seen by many Poles as a manifestation of Western betrayal.

A lack of accurate data makes it difficult to document numerically the extent of the human losses suffered by Polish citizens during World War II. Additionally, many assertions made in the past must be considered suspect due to flawed methodology and a desire to promote certain political agendas. The last available enumeration of ethnic Poles and the large ethnic minorities is the Polish census of 1931. Exact population figures for 1939 are therefore not known.

According to the United States Holocaust Memorial Museum, at least 3 million Polish Jews and at least 1.9 million non-Jewish Polish civilians were killed. According to the historians Brzoza and Sowa, about 2 million ethnic Poles were killed, but it is not known, even approximately, how many Polish citizens of other ethnicities perished, including Ukrainians, Belarusians, and Germans. Millions of Polish citizens were deported to Germany for forced labor or to German extermination camps such as Treblinka, Auschwitz and Sobibór. Nazi Germany intended to exterminate the Jews completely, in actions that have come to be described collectively as the Holocaust. The Poles were to be expelled from areas controlled by Nazi Germany through a process of resettlement that started in 1939. Such Nazi operations matured into a plan known as the "Generalplan Ost" that amounted to displacement, enslavement and partial extermination of the Slavic people and was expected to be completed within 15 years.

The majority of Poles remained indifferent to the Jewish plight, and neither assisted nor persecuted Jews. Of those who have helped rescue, shelter and protect Jews from the Nazi atrocity, Yad Vashem and the State of Israel have recognized 6,992 individuals as "Righteous Among the Nations".

In an attempt to incapacitate Polish society, the Nazis and the Soviets executed tens of thousands of members of the intelligentsia and community leadership during events such as the German AB-Aktion in Poland, Operation Tannenberg and the Katyn massacre. Over 95% of the Jewish losses and 90% of the ethnic Polish losses were caused directly by Nazi Germany, whereas 5% of the ethnic Polish losses were caused by the Soviets and 5% by Ukrainian nationalists. The large-scale Jewish presence in Poland that had endured for centuries was rather quickly put to an end by the policies of extermination implemented by the Nazis during the war. Waves of displacement and emigration that took place both during and after the war removed from Poland a majority of the Jews who survived. Further significant Jewish emigration followed events such as the Polish October political thaw of 1956 and the 1968 Polish political crisis.

In 1940–1941, some 325,000 Polish citizens were deported by the Soviet regime. The number of Polish citizens who died at the hands of the Soviets is estimated at less than 100,000.

In 1943–1944, Ukrainian nationalists associated with the Organization of Ukrainian Nationalists (OUN) and the Ukrainian Insurgent Army perpetrated the Massacres of Poles in Volhynia and Eastern Galicia. Estimates of the number of Polish civilian victims vary greatly, from tens to hundreds of thousands.

Approximately 90% of Poland's war casualties were the victims of prisons, death camps, raids, executions, the annihilation of ghettos, epidemics, starvation, excessive work and ill treatment. The war left one million children orphaned and 590,000 persons disabled. The country lost 38% of its national assets (whereas Britain lost only 0.8%, and France only 1.5%). Nearly half of pre-war Poland was expropriated by the Soviet Union, including the two great cultural centers of Lwów and Wilno.

The policies of Nazi Germany have been judged after the war by the International Military Tribunal at the Nuremberg trials and Polish genocide trials to be aimed at extermination of Jews, Poles and Roma, and to have "all the characteristics of genocide in the biological meaning of this term".

By the terms of the 1945 Potsdam Agreement signed by the three victorious Great Powers, the Soviet Union retained most of the territories captured as a result of the Molotov–Ribbentrop Pact of 1939, including western Ukraine and western Belarus, and gained others. Lithuania and the Königsberg area of East Prussia were officially incorporated into the Soviet Union, in the case of the former without the recognition of the Western powers.

Poland was compensated with the bulk of Silesia, including Breslau (Wrocław) and Grünberg (Zielona Góra), the bulk of Pomerania, including Stettin (Szczecin), and the greater southern portion of the former East Prussia, along with Danzig (Gdańsk), pending a final peace conference with Germany which eventually never took place. 
Collectively referred to by the Polish authorities as the "Recovered Territories", they were included in the reconstituted Polish state. With Germany's defeat Poland was thus shifted west in relation to its prewar location, to the area between the Oder–Neisse and Curzon lines, which resulted in a country more compact and with much broader access to the sea. The Poles lost 70% of their pre-war oil capacity to the Soviets, but gained from the Germans a highly developed industrial base and infrastructure that made a diversified industrial economy possible for the first time in Polish history.
The flight and expulsion of Germans from what was eastern Germany prior to the war began before and during the Soviet conquest of those regions from the Nazis, and the process continued in the years immediately after the war. 
8,030,000 Germans were evacuated, expelled, or migrated by 1950. 

Early expulsions in Poland were undertaken by the Polish communist authorities even before the Potsdam Conference (the "wild expulsions" from June to mid July 1945, when the Polish military and militia expelled nearly all people from the districts immediately east of the Oder–Neisse line), to ensure the establishment of ethnically homogeneous Poland. About 1% (100,000) of the German civilian population east of the Oder–Neisse line perished in the fighting prior to the surrender in May 1945, and afterwards some 200,000 Germans in Poland were employed as forced labor prior to being expelled. Many Germans died in labor camps such as the Zgoda labour camp and the Potulice camp. Of those Germans who remained within the new borders of Poland, many later chose to emigrate to post-war Germany.

On the other hand, 1.5–2 million ethnic Poles moved or were expelled from the previously Polish areas annexed by the Soviet Union. The vast majority were resettled in the former German territories. At least one million Poles remained in what had become the Soviet Union, and at least half a million ended up in the West or elsewhere outside of Poland. However, contrary to the official declaration that the former German inhabitants of the Recovered Territories had to be removed quickly to house Poles displaced by the Soviet annexation, the Recovered Territories initially faced a severe population shortage.

Many exiled Poles could not return to the country for which they had fought because they belonged to political groups incompatible with the new communist regimes, or because they originated from areas of pre-war eastern Poland that were incorporated into the Soviet Union (see Polish population transfers (1944–1946)). Some were deterred from returning simply on the strength of warnings that anyone who had served in military units in the West would be endangered. Many Poles were pursued, arrested, tortured and imprisoned by the Soviet authorities for belonging to the Home Army or other formations (see Anti-communist resistance in Poland (1944–1946)), or were persecuted because they had fought on the Western front.

Territories on both sides of the new Polish-Ukrainian border were also "ethnically cleansed". Of the Ukrainians and Lemkos living in Poland within the new borders (about 700,000), close to 95% were forcibly moved to the Soviet Ukraine, or (in 1947) to the new territories in northern and western Poland under Operation Vistula. In Volhynia, 98% of the Polish pre-war population was either killed or expelled; in Eastern Galicia, the Polish population was reduced by 92%. According to Timothy D. Snyder, about 70,000 Poles and about 20,000 Ukrainians were killed in the ethnic violence that occurred in the 1940s, both during and after the war.

According to an estimate by historian Jan Grabowski, about 50,000 of the 250,000 Polish Jews who escaped the Nazis during the liquidation of ghettos survived without leaving Poland (the remainder perished). More were repatriated from the Soviet Union and elsewhere, and the February 1946 population census showed about 300,000 Jews within Poland's new borders. Of the surviving Jews, many chose to emigrate or felt compelled to because of the anti-Jewish violence in Poland.

Because of changing borders and the mass movements of people of various nationalities, the emerging communist Poland ended up with a mainly homogeneous, ethnically Polish population (97.6% according to the December 1950 census). The remaining members of ethnic minorities were not encouraged, by the authorities or by their neighbors, to emphasize their ethnic identities.

In response to the February 1945 Yalta Conference directives, a Polish Provisional Government of National Unity was formed in June 1945 under Soviet auspices; it was soon recognized by the United States and many other countries. The Soviet domination was apparent from the beginning, as prominent leaders of the Polish Underground State were brought to trial in Moscow (the "Trial of the Sixteen" of June 1945). In the immediate post-war years, the emerging communist rule was challenged by opposition groups, including militarily by the so-called "cursed soldiers", of whom thousands perished in armed confrontations or were pursued by the Ministry of Public Security and executed. Such guerillas often pinned their hopes on expectations of an imminent outbreak of World War III and defeat of the Soviet Union. The Polish right-wing insurgency faded after the amnesty of February 1947.

The Polish people's referendum of June 1946 was arranged by the communist Polish Workers' Party to legitimize its dominance in Polish politics and claim widespread support for the party's policies. Although the Yalta agreement called for free elections, the Polish legislative election of January 1947 was controlled by the communists. Some democratic and pro-Western elements, led by Stanisław Mikołajczyk, former prime minister-in-exile, participated in the Provisional Government and the 1947 elections, but were ultimately eliminated through electoral fraud, intimidation and violence. In times of severe political confrontation and radical economic change, members of Mikołajczyk's agrarian movement (the Polish People's Party) attempted to preserve the existing aspects of mixed economy and protect property and other rights. However, after the 1947 elections, the Government of National Unity ceased to exist and the communists moved towards abolishing the post-war partially pluralistic "people's democracy" and replacing it with a state socialist system. The communist-dominated front Democratic Bloc of the 1947 elections, turned into the Front of National Unity in 1952, became officially the source of governmental authority. The Polish government-in-exile, lacking international recognition, remained in continuous existence until 1990.

The Polish People's Republic ("Polska Rzeczpospolita Ludowa") was established under the rule of the communist Polish United Workers' Party (PZPR). The name change from the Polish Republic was not officially adopted, however, until the proclamation of the Constitution of the Polish People's Republic in 1952.

The ruling PZPR was formed by the forced amalgamation in December 1948 of the communist Polish Workers' Party (PPR) and the historically non-communist Polish Socialist Party (PPS). The PPR chief had been its wartime leader Władysław Gomułka, who in 1947 declared a "Polish road to socialism" as intended to curb, rather than eradicate, capitalist elements. In 1948 he was overruled, removed and imprisoned by Stalinist authorities. The PPS, re-established in 1944 by its left wing, had since been allied with the communists. The ruling communists, who in post-war Poland preferred to use the term "socialism" instead of "communism" to identify their ideological basis, needed to include the socialist junior partner to broaden their appeal, claim greater legitimacy and eliminate competition on the political Left. The socialists, who were losing their organization, were subjected to political pressure, ideological cleansing and purges in order to become suitable for unification on the terms of the PPR. The leading pro-communist leaders of the socialists were the prime ministers Edward Osóbka-Morawski and Józef Cyrankiewicz.

During the most oppressive phase of the Stalinist period (1948–1953), terror was justified in Poland as necessary to eliminate reactionary subversion. Many thousands of perceived opponents of the regime were arbitrarily tried and large numbers were executed. The People's Republic was led by discredited Soviet operatives such as Bolesław Bierut, Jakub Berman and Konstantin Rokossovsky. The independent Catholic Church in Poland was subjected to property confiscations and other curtailments from 1949, and in 1950 was pressured into signing an accord with the government. In 1953 and later, despite a partial thaw after the death of Stalin that year, the persecution of the Church intensified and its head, Cardinal Stefan Wyszyński, was detained. A key event in the persecution of the Polish Church was the Stalinist show trial of the Kraków Curia in January 1953.

In the Warsaw Pact, formed in 1955, the Polish Army was the second largest, after the Soviet Army.

In 1944, large agricultural holdings and former German property in Poland started to be redistributed through land reform, and industry started to be nationalized. Communist restructuring and the imposition of work-space rules encountered active worker opposition already in the years 1945–1947. The moderate Three-Year Plan of 1947–1949 continued with the rebuilding, socialization and socialist restructuring of the economy. It was followed by the Six-Year Plan of 1950–1955 for heavy industry. The rejection of the Marshall Plan in 1947 made aspirations for catching up with West European standards of living unrealistic.

The government's highest economic priority was the development of heavy industry useful to the military. State-run or controlled institutions common in all the socialist countries of eastern Europe were imposed on Poland, including collective farms and worker cooperatives. The latter were dismantled in the late 1940s as not socialist enough, although they were later re-established; even small-scale private enterprises were eradicated. Stalinism introduced heavy political and ideological propaganda and indoctrination in social life, culture and education.

Great strides were made, however, in the areas of employment (which became nearly full), universal public education (which nearly eradicated adult illiteracy), health care and recreational amenities. Many historic sites, including the central districts of Warsaw and Gdańsk, both devastated during the war, were rebuilt at great cost.

The communist industrialization program led to increased urbanization and educational and career opportunities for the intended beneficiaries of the social transformation, along the lines of the peasants-workers-working intelligentsia paradigm. The most significant improvement was accomplished in the lives of Polish peasants, many of whom were able to leave their impoverished and overcrowded village communities for better conditions in urban centers. Those who stayed behind took advantage of the implementation of the 1944 land reform decree of the Polish Committee of National Liberation, which terminated the antiquated but widespread parafeudal socioeconomic relations in Poland. The Stalinist attempts at establishing collective farms generally failed. Due to urbanization, the national percentage of the rural population decreased in communist Poland by about 50%. A majority of Poland's residents of cities and towns still live in apartment blocks built during the communist era, in part to accommodate migrants from rural areas.

In March 1956, after the 20th Congress of the Communist Party of the Soviet Union in Moscow ushered in de-Stalinization, Edward Ochab was chosen to replace the deceased Bolesław Bierut as first secretary of the Polish United Workers' Party. As a result, Poland was rapidly overtaken by social restlessness and reformist undertakings; thousands of political prisoners were released and many people previously persecuted were officially rehabilitated. Worker riots in Poznań in June 1956 were violently suppressed, but they gave rise to the formation of a reformist current within the communist party.

Amidst the continuing social and national upheaval, a further shakeup took place in the party leadership as part of what is known as the Polish October of 1956. While retaining most traditional communist economic and social aims, the regime led by Władysław Gomułka, the new first secretary of the PZPR, liberalized internal life in Poland. The dependence on the Soviet Union was somewhat mollified, and the state's relationships with the Church and Catholic lay activists were put on a new footing. A repatriation agreement with the Soviet Union allowed the repatriation of hundreds of thousands of Poles who were still in Soviet hands, including many former political prisoners. Collectivization efforts were abandoned—agricultural land, unlike in other Comecon countries, remained for the most part in the private ownership of farming families. State-mandated provisions of agricultural products at fixed, artificially low prices were reduced, and from 1972 eliminated.

The legislative election of 1957 was followed by several years of political stability that was accompanied by economic stagnation and curtailment of reforms and reformists. One of the last initiatives of the brief reform era was a nuclear weapons–free zone in Central Europe proposed in 1957 by Adam Rapacki, Poland's foreign minister.

Culture in the Polish People's Republic, to varying degrees linked to the intelligentsia's opposition to the authoritarian system, developed to a sophisticated level under Gomułka and his successors. The creative process was often compromised by state censorship, but significant works were created in fields such as literature, theater, cinema and music, among others. Journalism of veiled understanding and varieties of native and Western popular culture were well represented. Uncensored information and works generated by émigré circles were conveyed through a variety of channels. The Paris-based "Kultura" magazine developed a conceptual framework for dealing with the issues of borders and the neighbors of a future free Poland, but for ordinary Poles Radio Free Europe was of foremost importance.

One of the confirmations of the end of an era of greater tolerance was the expulsion from the communist party of several prominent "Marxist revisionists" in the 1960s.

In 1965, the Conference of Polish Bishops issued the Letter of Reconciliation of the Polish Bishops to the German Bishops, a gesture intended to heal bad mutual feelings left over from World War II. In 1966, the celebrations of the 1,000th anniversary of the Christianization of Poland led by Cardinal Stefan Wyszyński and other bishops turned into a huge demonstration of the power and popularity of the Catholic Church in Poland.

The post-1956 liberalizing trend, in decline for a number of years, was reversed in March 1968, when student demonstrations were suppressed during the 1968 Polish political crisis. Motivated in part by the Prague Spring movement, the Polish opposition leaders, intellectuals, academics and students used a historical-patriotic "Dziady" theater spectacle series in Warsaw (and its termination forced by the authorities) as a springboard for protests, which soon spread to other centers of higher education and turned nationwide. The authorities responded with a major crackdown on opposition activity, including the firing of faculty and the dismissal of students at universities and other institutions of learning. At the center of the controversy was also the small number of Catholic deputies in the Sejm (the Znak Association members) who attempted to defend the students.

In an official speech, Gomułka drew attention to the role of Jewish activists in the events taking place. This provided ammunition to a nationalistic and antisemitic communist party faction headed by Mieczysław Moczar that was opposed to Gomułka's leadership. Using the context of the military victory of Israel in the Six-Day War of 1967, some in the Polish communist leadership waged an antisemitic campaign against the remnants of the Jewish community in Poland. The targets of this campaign were accused of disloyalty and active sympathy with Israeli aggression. Branded "Zionists", they were scapegoated and blamed for the unrest in March 1968, which eventually led to the emigration of much of Poland's remaining Jewish population (about 15,000 Polish citizens left the country).

With the active support of the Gomułka regime, the Polish People's Army took part in the infamous Warsaw Pact invasion of Czechoslovakia in August 1968, after the Brezhnev Doctrine was informally announced.

In the final major achievement of Gomułka diplomacy, the governments of Poland and West Germany signed in December 1970 the Treaty of Warsaw, which normalized their relations and made possible meaningful cooperation in a number of areas of bilateral interest. In particular, West Germany recognized the post-World War II "de facto" border between Poland and East Germany.

Price increases for essential consumer goods triggered the Polish protests of 1970. In December, there were disturbances and strikes in the Baltic Sea port cities of Gdańsk, Gdynia, and Szczecin that reflected deep dissatisfaction with living and working conditions in the country. The activity was centered in the industrial shipyard areas of the three coastal cities. Dozens of protesting workers and bystanders were killed in police and military actions, generally under the authority of Gomułka and Minister of Defense Wojciech Jaruzelski. In the aftermath, Edward Gierek replaced Gomułka as first secretary of the communist party. The new regime was seen as more modern, friendly and pragmatic, and at first it enjoyed a degree of popular and foreign support.

To revitalize the economy, from 1971 the Gierek regime introduced wide-ranging reforms that involved large-scale foreign borrowing. These actions initially caused improved conditions for consumers, but in a few years the strategy backfired and the economy deteriorated. Another attempt to raise food prices resulted in the June 1976 protests. The Workers' Defence Committee (KOR), established in response to the crackdown that followed, consisted of dissident intellectuals determined to support industrial workers, farmers and students persecuted by the authorities. The opposition circles active in the late 1970s were emboldened by the Helsinki Conference processes.

In October 1978, the Archbishop of Kraków, Cardinal Karol Józef Wojtyła, became Pope John Paul II, head of the Catholic Church. Catholics and others rejoiced at the elevation of a Pole to the papacy and greeted his June 1979 visit to Poland with an outpouring of emotion.

Fueled by large infusions of Western credit, Poland's economic growth rate was one of the world's highest during the first half of the 1970s, but much of the borrowed capital was misspent, and the centrally planned economy was unable to use the new resources effectively. The 1973 oil crisis caused recession and high interest rates in the West, to which the Polish government had to respond with sharp domestic consumer price increases. The growing debt burden became insupportable in the late 1970s, and negative economic growth set in by 1979.

Around 1 July 1980, with the Polish foreign debt standing at more than $20 billion, the government made yet another attempt to increase meat prices. Workers responded with escalating work stoppages that culminated in the 1980 general strikes in Lublin. In mid-August, labor protests at the Gdańsk Shipyard gave rise to a chain reaction of strikes that virtually paralyzed the Baltic coast by the end of the month and, for the first time, closed most coal mines in Silesia. The Inter-Enterprise Strike Committee coordinated the strike action across hundreds of workplaces and formulated the 21 demands as the basis for negotiations with the authorities. The Strike Committee was sovereign in its decision-making, but was aided by a team of "expert" advisers that included the well-known dissidents Jacek Kuroń, Karol Modzelewski, Bronisław Geremek and Tadeusz Mazowiecki.

On 31 August 1980, representatives of workers at the Gdańsk Shipyard, led by an electrician and activist Lech Wałęsa, signed the Gdańsk Agreement with the government that ended their strike. Similar agreements were concluded in Szczecin (the Szczecin Agreement) and in Silesia. The key provision of these agreements was the guarantee of the workers' right to form independent trade unions and the right to strike. Following the successful resolution of the largest labor confrontation in communist Poland's history, nationwide union organizing movements swept the country.

Edward Gierek was blamed by the Soviets for not following their "fraternal" advice, not shoring up the communist party and the official trade unions and allowing "anti-socialist" forces to emerge. On 5 September 1980, Gierek was replaced by Stanisław Kania as first secretary of the PZPR.

Delegates of the emergent worker committees from all over Poland gathered in Gdańsk on 17 September and decided to form a single national union organization named "Solidarity".

While party–controlled courts took up the contentious issues of Solidarity's legal registration as a trade union (finalized by November 10), planning had already begun for the imposition of martial law. A parallel farmers' union was organized and strongly opposed by the regime, but Rural Solidarity was eventually registered (12 May 1981). In the meantime, a rapid deterioration of the authority of the communist party, disintegration of state power and escalation of demands and threats by the various Solidarity–affiliated groups were occurring. According to Kuroń, a "tremendous social democratization movement in all spheres" was taking place and could not be contained. Wałęsa had meetings with Kania, which brought no resolution to the impasse.

Following the Warsaw Pact summit in Moscow, the Soviet Union proceeded with a massive military build-up along Poland's border in December 1980, but during the summit Kania forcefully argued with Leonid Brezhnev and other allied communists leaders against the feasibility of an external military intervention, and no action was taken. The United States, under presidents Jimmy Carter and Ronald Reagan, repeatedly warned the Soviets about the consequences of a direct intervention, while discouraging an open insurrection in Poland and signaling to the Polish opposition that there would be no rescue by the NATO forces.

In February 1981, Defense Minister General Wojciech Jaruzelski assumed the position of prime minister. The Solidarity social revolt had thus far been free of any major use of force, but in March 1981 in Bydgoszcz three activists were beaten up by the secret police. In a nationwide "warning strike" the 9.5-million-strong Solidarity union was supported by the population at large, but a general strike was called off by Wałęsa after the 30 March settlement with the government. Both Solidarity and the communist party were badly split and the Soviets were losing patience. Kania was re-elected at the Party Congress in July, but the collapse of the economy continued and so did the general disorder.

At the first Solidarity National Congress in September–October 1981 in Gdańsk, Lech Wałęsa was elected national chairman of the union with 55% of the vote. An appeal was issued to the workers of the other East European countries, urging them to follow in the footsteps of Solidarity. To the Soviets, the gathering was an "anti-socialist and anti-Soviet orgy" and the Polish communist leaders, increasingly led by Jaruzelski and General Czesław Kiszczak, were ready to apply force.

In October 1981, Jaruzelski was named first secretary of the PZPR. The Plenum's vote was 180 to 4, and he kept his government posts. Jaruzelski asked parliament to ban strikes and allow him to exercise extraordinary powers, but when neither request was granted, he decided to proceed with his plans anyway.

On 12–13 December 1981, the regime declared martial law in Poland, under which the army and the ZOMO special police forces were used to crush Solidarity. The Soviet leaders insisted that Jaruzelski pacifies the opposition with the forces at his disposal, without Soviet involvement. Almost all Solidarity leaders and many affiliated intellectuals were arrested or detained. Nine workers were killed in the Pacification of Wujek. The United States and other Western countries responded by imposing economic sanctions against Poland and the Soviet Union. Unrest in the country was subdued, but continued.

During martial law, Poland was ruled by the so-called Military Council of National Salvation. The open or semi-open opposition communications, as recently practiced, were replaced by underground publishing (known in the eastern bloc as Samizdat), and Solidarity was reduced to a few thousand underground activists.

Having achieved some semblance of stability, the Polish regime relaxed and then rescinded martial law over several stages. By December 1982 martial law was suspended and a small number of political prisoners, including Wałęsa, were released. Although martial law formally ended in July 1983 and a partial amnesty was enacted, several hundred political prisoners remained in jail. Jerzy Popiełuszko, a popular pro-Solidarity priest, was abducted and murdered by security functionaries in October 1984.

Further developments in Poland occurred concurrently with and were influenced by the reformist leadership of Mikhail Gorbachev in the Soviet Union (processes known as Glasnost and Perestroika). In September 1986, a general amnesty was declared and the government released nearly all political prisoners. However, the country lacked basic stability, as the regime's efforts to organize society from the top down had failed, while the opposition's attempts at creating an "alternate society" were also unsuccessful. With the economic crisis unresolved and societal institutions dysfunctional, both the ruling establishment and the opposition began looking for ways out of the stalemate. Facilitated by the indispensable mediation of the Catholic Church, exploratory contacts were established.

Student protests resumed in February 1988. Continuing economic decline led to strikes across the country in April, May and August. The Soviet Union, increasingly destabilized, was unwilling to apply military or other pressure to prop up allied regimes in trouble. The Polish government felt compelled to negotiate with the opposition and in September 1988 preliminary talks with Solidarity leaders ensued in Magdalenka. Numerous meetings that took place involved Wałęsa and General Kiszczak, among others. In November, the regime made a major public relations mistake by allowing a televised debate between Wałęsa and Alfred Miodowicz, chief of the All-Poland Alliance of Trade Unions, the official trade union organization. The fitful bargaining and intra-party squabbling led to the official Round Table Negotiations in 1989, followed by the Polish legislative election in June of that year, a watershed event marking the fall of communism in Poland.

The Polish Round Table Agreement of April 1989 called for local self-government, policies of job guarantees, legalization of independent trade unions and many wide-ranging reforms. The current Sejm promptly implemented the deal and agreed to National Assembly elections that were set for 4 June and 18 June. Only 35% of the seats in the Sejm (national legislature's lower house) and all of the Senate seats were freely contested; the remaining Sejm seats (65%) were guaranteed for the communists and their allies.

The failure of the communists at the polls (almost all of the contested seats were won by the opposition) resulted in a political crisis. The new April Novelization to the constitution called for re-establishment of the Polish presidency and on 19 July the National Assembly elected the communist leader, General Wojciech Jaruzelski, to that office. His election, seen at the time as politically necessary, was barely accomplished with tacit support from some Solidarity deputies, and the new president's position was not strong. Moreover, the unexpected definitiveness of the parliamentary election results created new political dynamics and attempts by the communists to form a government failed.

On 19 August, President Jaruzelski asked journalist and Solidarity activist Tadeusz Mazowiecki to form a government; on 12 September, the Sejm voted approval of Prime Minister Mazowiecki and his cabinet. Mazowiecki decided to leave the economic reform entirely in the hands of economic liberals led by the new Deputy Prime Minister Leszek Balcerowicz, who proceeded with the design and implementation of his "shock therapy" policy. For the first time in post-war history, Poland had a government led by non-communists, setting a precedent soon to be followed by other Eastern Bloc nations in a phenomenon known as the Revolutions of 1989. Mazowiecki's acceptance of the "thick line" formula meant that there would be no "witch-hunt", i.e., an absence of revenge seeking or exclusion from politics in regard to former communist officials.

In part because of the attempted indexation of wages, inflation reached 900% by the end of 1989, but was soon dealt with by means of radical methods. In December 1989, the Sejm approved the Balcerowicz Plan to transform the Polish economy rapidly from a centrally planned one to a free market economy. The Constitution of the Polish People's Republic was amended to eliminate references to the "leading role" of the communist party and the country was renamed the "Republic of Poland". The communist Polish United Workers' Party dissolved itself in January 1990. In its place, a new party, Social Democracy of the Republic of Poland, was created. "Territorial self-government", abolished in 1950, was legislated back in March 1990, to be led by locally elected officials; its fundamental unit was the administratively independent gmina.

In October 1990, the constitution was amended to curtail the term of President Jaruzelski. In November 1990, the German–Polish Border Treaty, with unified Germany, was signed.

In November 1990, Lech Wałęsa was elected president for a five-year term; in December, he became the first popularly elected president of Poland. Poland's first free parliamentary election was held in October 1991. 18 parties entered the new Sejm, but the largest representation received only 12% of the total vote.

There were several post-Solidarity governments between the 1989 election and the 1993 election, after which the "post-communist" left-wing parties took over. In 1993, the formerly Soviet Northern Group of Forces, a vestige of past domination, left Poland.

In 1995, Aleksander Kwaśniewski of the Social Democratic Party was elected president and remained in that capacity for the next ten years (two terms).

In 1997, the new Constitution of Poland was finalized and approved in a referendum; it replaced the Small Constitution of 1992, an amended version of the communist constitution.

Poland joined NATO in 1999. Elements of the Polish Armed Forces have since participated in the Iraq War and the Afghanistan War. Poland joined the European Union as part of its enlargement in 2004. However, Poland has not adopted the euro as its currency and legal tender, but instead uses the Polish złoty.

After the election of the conservative Law and Justice party in 2015, the Polish government repeatedly clashed with EU institutions on the issue of judicial reform and was accused by the European Commission and the European Parliament of undermining "European Values" and eroding democratic standards. However, the Polish government headed by the Law and Justice party maintained that the reforms were necessary due to the prevalence of corruption within the Polish judiciary and the continued presence of holdover Communist era judges.

"a."Piłsudski's family roots in the Polonized gentry of the Grand Duchy of Lithuania and the resulting perspective of seeing himself and people like him as legitimate Lithuanians put him in conflict with modern Lithuanian nationalists (who in Piłsudski's lifetime redefined the scope and meaning of the "Lithuanian" identity), and, by extension, with other nationalists including the Polish modern nationalist movement.

"b."In 1938, Poland and Romania refused to agree to a Franco-British proposal that in the event of war with Nazi Germany, Soviet forces would be allowed to cross their territories to aid Czechoslovakia. The Polish ruling elites considered the Soviets in some ways more threatening than the Nazis.

The Soviet Union repeatedly declared intention to fulfill its obligations under the 1935 treaty with Czechoslovakia and defend Czechoslovakia militarily. A transfer of land and air forces through Poland and/or Romania was required and the Soviets approached about it the French, who also had a treaty with Czechoslovakia (and with Poland and with the Soviet Union). Edward Rydz-Śmigły rebuked the French suggestion on that matter in 1936, and in 1938 Józef Beck pressured Romania not to allow even Soviet warplanes to fly over its territory. Like Hungary, Poland was looking into using the German-Czechoslovak conflict to settle its own territorial grievances, namely disputes over parts of Zaolzie, Spiš and Orava.

"c." In October 1939, the British Foreign Office notified the Soviets that the United Kingdom would be satisfied with a postwar creation of small ethnic Poland, patterned after the Duchy of Warsaw. An establishment of Poland restricted to "minimal size", according to ethnographic boundaries (such as the lands common to both the prewar Poland and postwar Poland), was planned by the Soviet People's Commissariat for Foreign Affairs in 1943–1944. Such territorial reduction was recommended by Ivan Maisky to Vyacheslav Molotov in early 1944, because of what Maisky saw as Poland's historically unfriendly disposition toward Russia and the Soviet Union, likely in some way to continue. Joseph Stalin opted for a larger version, allowing a "swap" (territorial compensation for Poland), which involved the eastern lands gained by Poland at the Peace of Riga of 1921 and now lost, and eastern Germany conquered from the Nazis in 1944–1945. In regard to the several major disputed areas: Lower Silesia west of the Oder and the Eastern Neisse rivers (the British wanted it to remain a part of the future German state), Stettin (in 1945 the German communists already established their administration there), "Zakerzonia" (western Red Ruthenia demanded by the Ukrainians), and the Białystok region (Białystok was claimed by the communists of the Byelorussian SSR), the Soviet leader made decisions that favored Poland.

Other territorial and ethnic scenarios were also possible, generally with possible outcomes less advantageous to Poland than the form the country assumed.

"d."Timothy D. Snyder spoke of about 100,000 Jews killed by Poles during the Nazi occupation, the majority probably by members of the collaborationist Blue Police. This number would have likely been many times higher had Poland entered into an alliance with Germany in 1939, as advocated by some Polish historians and others.

"e."Some may have falsely claimed the Jewish identity hoping for permission to emigrate. The communist authorities, pursuing the concept of Poland of single ethnicity (in accordance with the recent border changes and expulsions), were allowing the Jews to leave the country. For a discussion of early communist Poland's ethnic politics, see Timothy D. Snyder, "The Reconstruction of Nations", chapters on modern "Ukrainian Borderland".

"f."A Communist Party of Poland had existed in the past, but was eliminated in Stalin's purges in 1938.

"g."The Soviet leadership, which had previously ordered the crushing of the Uprising of 1953 in East Germany, the Hungarian Revolution of 1956 and the Prague Spring in 1968, in late 1970 became worried about potential demoralizing effects that deployment against Polish workers would have on the Polish army, a crucial Warsaw Pact component. The Soviets withdrew their support for Gomułka, who insisted on the use of force; he and his close associates were subsequently ousted from the Polish Politburo by the Polish Central Committee.

"h."East of the Molotov-Ribbentrop line, the population was 43% Polish, 33% Ukrainian, 8% Belarusian and 8% Jewish. The Soviet Union did not want to appear as an aggressor, and moved its troops to eastern Poland under the pretext of offering protection to "the kindred Ukrainian and Belorussian people".

"i."Joseph Stalin at the 1943 Tehran Conference discussed with Winston Churchill and Franklin D. Roosevelt new post-war borders in central-eastern Europe, including the shape of a future Poland. He endorsed the Piast Concept, which justified a massive shift of Poland's frontiers to the west. Stalin resolved to secure and stabilize the western reaches of the Soviet Union and disable the future military potential of Germany by constructing a compact and ethnically defined Poland (along with the Soviet ethnic Ukraine, Belarus and Lithuania) and by radically altering the region's system of national borders. After 1945, the Polish communist regime wholeheartedly adopted and promoted the Piast Concept, making it the centerpiece of their claim to be the true inheritors of Polish nationalism. After all the killings and population transfers during and after the war, the country was 99% "Polish".

"j.""All the currently available documents of Nazi administration show that, together with the Jews, the stratum of the Polish intelligentsia was marked for total extermination. In fact, Nazi Germany achieved this goal almost by half, since Poland lost 50 percent of her citizens with university diplomas and 35 percent of those with a gimnazium diploma." According to Brzoza and Sowa, 450,000 of Polish citizens had completed higher, secondary, or trade school education by the outbreak of the war. 37.5% of people with higher education perished, 30% of those with general secondary education, and 53.3% of trade school graduates.

"k."Decisive political events took place in Poland shortly before the Hungarian Revolution of 1956. Władysław Gomułka, a reformist party leader, was reinstated to the Politburo of the PZPR and the Eighth Plenum of its Central Committee was announced to convene on 19 October 1956, all without seeking a Soviet approval. The Soviet Union responded with military moves and intimidation and its "military-political delegation", led by Nikita Khrushchev, quickly arrived in Warsaw. Gomułka tried to convince them of his loyalty but insisted on the reforms that he considered essential, including a replacement of Poland's Soviet-trusted minister of defense, Konstantin Rokossovsky. The disconcerted Soviets returned to Moscow, the PZPR Plenum elected Gomułka first secretary and removed Rokossovsky from the Politburo. On 21 October, the Soviet Presidium followed Khrushchev's lead and decided unanimously to "refrain from military intervention" in Poland, a decision likely influenced also by the ongoing preparations for the invasion of Hungary. The Soviet gamble paid off, because Gomułka in the coming years turned out to be a very dependable Soviet ally and an orthodox communist.

However, unlike the other Warsaw Pact countries, Poland did not endorse the Soviet armed intervention in Hungary. The Hungarian Revolution was intensely supported by the Polish public.

"l."The delayed reinforcements were coming and the government military commanders General Tadeusz Rozwadowski and Władysław Anders wanted to keep on fighting the coup perpetrators, but President Stanisław Wojciechowski and the government decided to surrender to prevent the imminent spread of civil war. The coup brought to power the "Sanation" regime under Józef Piłsudski (Edward Rydz-Śmigły after Piłsudski's death). The Sanation regime persecuted the opposition within the military and in general. Rozwadowski died after abusive imprisonment, according to some accounts murdered. Another major opponent of Piłsudski, General Włodzimierz Zagórski, disappeared in 1927. According to Aleksandra Piłsudska, the marshal's wife, following the coup and for the rest of his life Piłsudski lost his composure and appeared over-burdened.

At the time of Rydz-Śmigły's command, the Sanation camp embraced the ideology of Roman Dmowski, Piłsudski's nemesis. Rydz-Śmigły did not allow General Władysław Sikorski, an enemy of the Sanation movement, to participate as a soldier in the country's defense against the Invasion of Poland in September 1939. During World War II in France and then in Britain, the Polish government-in-exile became dominated by anti-Sanation politicians. The perceived Sanation followers were in turn persecuted (in exile) under prime ministers Sikorski and Stanisław Mikołajczyk.

"m."General Zygmunt Berling of the Soviet-allied First Polish Army attempted in mid-September a crossing of the Vistula and landing at Czerniaków to aid the insurgents, but the operation was defeated by the Germans and the Poles suffered heavy losses.

"n."The decision to launch the Warsaw Uprising resulted in the destruction of the city, its population and its elites and has been a source of lasting controversy. According to the historians Czesław Brzoza and Andrzej Leon Sowa, orders of further military offensives, issued at the end of August 1944 as a continuation of Operation Tempest, show a loss of the sense of responsibility for the country's fate on the part of the underground Polish leadership.

"o."One of the party leaders Mieczysław Rakowski, who abandoned his mentor Gomułka following the 1970 crisis, saw the demands of the demonstrating workers as "exclusively socialist" in character, because of the way they were phrased. Most people in communist Poland, including opposition activists, did not question the supremacy of socialism or the socialist idea; misconduct by party officials, such as not following the provisions of the constitution, was blamed. From the time of Gierek, this assumed standard of political correctness was increasingly challenged: pluralism, and then free market, became frequently used concepts.

"p."The Polish Sanation authorities were provoked by the independence-seeking Organization of Ukrainian Nationalists (OUN). OUN engaged in political assassinations, terror and sabotage, to which the Polish state responded with a repressive campaign in the 1930s, as Józef Piłsudski and his successors imposed collective responsibility on the villagers in the affected areas. After the disturbances of 1933 and 1934, the Bereza Kartuska prison camp was established; it became notorious for its brutal regime. The government brought Polish settlers and administrators to parts of Volhynia with a centuries-old tradition of Ukrainian peasant rising against Polish land owners (and to Eastern Galicia). In the late 1930s, after Piłsudski's death, military persecution intensified and a policy of "national assimilation" was aggressively pursued. Military raids, public beatings, property confiscations and the closing and destruction of Orthodox churches aroused lasting enmity in Galicia and antagonized Ukrainian society in Volhynia at the worst possible moment, according to Timothy D. Snyder. However, he also notes that "Ukrainian terrorism and Polish reprisals touched only part of the population, leaving vast regions unaffected" and "the OUN's nationalist prescription, a Ukrainian state for ethnic Ukrainians alone was far from popular". Halik Kochanski wrote of the legacy of bitterness between the Ukrainians and Poles that soon exploded in the context of World War II. See also: History of the Ukrainian minority in Poland.

"q."In Poland, officials of central government (the provincial office of "wojewoda") can overrule elected territorial and municipal local governments. However, in such cases "wojewoda" decisions have sometimes been invalidated by courts.

"r."Foreign policy was one of the few governmental areas in which Piłsudski took an active interest. He saw Poland's role and opportunity as lying in Eastern Europe and advocated passive relations with the West. He felt that a German attack should not be feared, because even if this unlikely event were to take place, the Western powers would be bound to restrain Germany and come to Poland's rescue.

"s."According to the researcher Jan Sowa, the Commonwealth failed as a state because it was not able to conform to the emerging new European order established at the Peace of Westphalia of 1648. Poland's elective kings, restricted by the self-serving and short-sighted nobility, could not impose a strong and efficient central government with its characteristic post-Westphalian internal and external sovereignty. The inability of Polish kings to levy and collect taxes (and therefore sustain a standing army) and conduct independent foreign policy were among the chief obstacles to Poland competing effectively on the changed European scene, where absolutist power was a prerequisite for survival and became the foundation for the abolition of serfdom and gradual formation of parliamentarism.

"t."Besides the Home Army there were other major underground fighting formations: Bataliony Chłopskie, National Armed Forces (NSZ) and Gwardia Ludowa (later Armia Ludowa). From 1943, the leaders of the nationalistic NSZ collaborated with Nazi Germany in a case unique in occupied Poland. The NSZ conducted an anti-communist civil war. Before the arrival of the Soviets, the NSZ's Holy Cross Mountains Brigade left Poland under the protection of the German army. According to the historians Czesław Brzoza and Andrzej Leon Sowa, participation figures given for the underground resistance are often inflated. In the spring of 1944, the time of the most extensive involvement of the underground organizations, there were most likely considerably fewer than 500,000 military and civilian personnel participating, over the entire spectrum, from the right wing to the communists.

"u."According to Jerzy Eisler, about 1.1 million people may have been imprisoned or detained in 1944–1956 and about 50,000 may have died because of the struggle and persecution, including about 7,000 soldiers of the right-wing underground killed in the 1940s. According to Adam Leszczyński, up to 30,000 people were killed by the communist regime during the first several years after the war.

"v."According to Andrzej Stelmachowski, one of the key participants of the Polish systemic transformation, Minister Leszek Balcerowicz pursued extremely liberal economic policies, often extraordinarily painful for society. The December 1989 Sejm statute of credit relations reform introduced an "incredible" system of privileges for banks, which were allowed to unilaterally alter interest rates on already existing contracts. The exceedingly high rates they instantly introduced ruined many previously profitable enterprises and caused a complete breakdown of the apartment block construction industry, which had long-term deleterious effects on the state budget as well. Balcerowicz's policies also caused permanent damage to Polish agriculture, an area in which he lacked expertise, and to the often successful and useful Polish cooperative movement.

According to Karol Modzelewski, a dissident and critic of the economic transformation, in 1989 Solidarity no longer existed, having been in reality eliminated during the martial law period. What the "post-Solidarity elites" did in 1989 amounted to a betrayal of the old Solidarity base, and the retribution was only a matter of time.

"w."Led by Władysław Anders, the Polish II Corps fought in 1944–1945 in the Allied Italian Campaign, where the corps' main engagement was the Battle of Monte Cassino.

"x."The Piast Concept, of which the chief proponent was Jan Ludwik Popławski (late 19th century), was based on the claim that the Piast homeland was inhabited by so-called "native" aboriginal Slavs and Slavonic Poles since time immemorial and only later was "infiltrated" by "alien" Celts, Germanic peoples, and others. After 1945, the so-called "autochthonous" or "aboriginal" school of Polish prehistory received official backing and a considerable degree of popular support in Poland. According to this view, the Lusatian Culture, which flourished between the Oder and the Vistula in the early Iron Age, was said to be Slavonic; all non-Slavonic tribes and peoples recorded in the area at various points in ancient times were dismissed as "migrants" and "visitors". In contrast, the critics of this theory, such as Marija Gimbutas, regarded it as an unproved hypotheses and for them the date and origin of the westward migration of the Slavs were largely uncharted; the Slavonic connections of the Lusatian Culture were entirely imaginary; and the presence of an ethnically mixed and constantly changing collection of peoples on the North European Plain was taken for granted.

"y."According to the count presented by Prime Minister and Internal Affairs Minister Felicjan Sławoj Składkowski before the Sejm committee in January 1938, 818 people were killed in police suppression of labor protests (industrial and agricultural) during the 1932–1937 period.

"z."John II Casimir Vasa is known for his remarkable and accurate prediction of the Partitions of Poland, made over a century before the event's occurrence.

"a1."According to war historian Ben Macintyre, "The Polish contribution to allied victory in the Second World War was extraordinary, perhaps even decisive, but for many years it was disgracefully played down, obscured by the politics of the Cold War."

"b1."Piłsudski left the Polish Socialist Party in 1914 and severed his connections with the socialist movement, but many activists from the Left and of other political orientations presumed his continuing involvement there.

"c1."Woodrow Wilson's Fourteen Points program was subsequently weakened by internal developments in the US, Britain, France, and Germany. In the last case, Poland was denied the city of Danzig on the Baltic coast.

"d1."The government of Soviet Russia issued in August 1918 a decree strongly supportive of the independence of Poland, but at that time no Polish lands were under Russian control.

More recent general history of Poland books in English


Published in Poland





</doc>
<doc id="13773" url="https://en.wikipedia.org/wiki?curid=13773" title="Hradčany">
Hradčany

Hradčany (; ), the Castle District, is the district of the city of Prague, Czech Republic surrounding Prague Castle.

The castle is one of the biggest in the world at about in length and an average of about wide. Its history stretches back to the 9th century. St Vitus Cathedral is located in the castle area.

Most of the district consists of noble historical . There are many other attractions for visitors: romantic nooks, peaceful places and beautiful lookouts.

Hradčany was an independent borough until 1784, when the four independent boroughs that had formerly constituted Prague were proclaimed a single city. The other three were Malá Strana (, Lesser Quarter), Staré Město (, Old Town) and Nové Město (, New Town).



</doc>
<doc id="13774" url="https://en.wikipedia.org/wiki?curid=13774" title="Houston">
Houston

Houston ( ) is the most populous city in the U.S. state of Texas, fourth most populous city in the United States, most populous city in the Southern United States, as well as the sixth most populous in North America, with an estimated 2019 population of 2,320,268. Located in Southeast Texas near Galveston Bay and the Gulf of Mexico, it is the seat of Harris County and the principal city of the Greater Houston metropolitan area, which is the fifth most populous metropolitan statistical area in the United States and the second most populous in Texas after the Dallas-Fort Worth metroplex, with a population of 7,066,141 in 2019.

Comprising a total area of , Houston is the eighth most expansive city in the United States (including consolidated city-counties). It is the largest city in the United States by total area, whose government is not consolidated with that of a county, parish or borough. Though primarily in Harris County, small portions of the city extend into Fort Bend and Montgomery counties, bordering other principal communities of Greater Houston such as Sugar Land and The Woodlands.

The city of Houston was founded by land investors on August 30, 1836, at the confluence of Buffalo Bayou and White Oak Bayou (a point now known as Allen's Landing) and incorporated as a city on June 5, 1837. The city is named after former General Sam Houston, who was president of the Republic of Texas and had won Texas' independence from Mexico at the Battle of San Jacinto east of Allen's Landing. After briefly serving as the capital of the Texas Republic in the late 1830s, Houston grew steadily into a regional trading center for the remainder of the 19th century.

The arrival of the 20th century saw a convergence of economic factors which fueled rapid growth in Houston, including a burgeoning port and railroad industry, the decline of Galveston as Texas' primary port following a devastating 1900 hurricane, the subsequent construction of the Houston Ship Channel, and the Texas oil boom. In the mid-20th century, Houston's economy diversified as it became home to the Texas Medical Center—the world's largest concentration of healthcare and research institutions—and NASA's Johnson Space Center, where the Mission Control Center is located.

Houston's economy since the late 19th century has a broad industrial base in energy, manufacturing, aeronautics, and transportation. Leading in healthcare sectors and building oilfield equipment, Houston has the second most Fortune 500 headquarters of any U.S. municipality within its city limits (after New York City). The Port of Houston ranks first in the United States in international waterborne tonnage handled and second in total cargo tonnage handled. Nicknamed the "Bayou City" "Space City", "H-Town", and "the 713", Houston has become a global city, with strengths in culture, medicine, and research. The city has a population from various ethnic and religious backgrounds and a large and growing international community. Houston is the most diverse metropolitan area in Texas and has been described as the most racially and ethnically diverse major metropolis in the U.S. It is home to many cultural institutions and exhibits, which attract more than 7 million visitors a year to the Museum District. Houston has an active visual and performing arts scene in the Theater District and offers year-round resident companies in all major performing arts.

The Houston area is located on land that was once home of the Karankawa (kə rang′kə wä′,-wô′,-wə) and the Atakapa (əˈtɑːkəpə) indigenous peoples for at least 2,000 years before the first known settlers arrived. These tribes are almost nonexistent today; this was most likely caused by foreign disease, as well as competition with various exploration groups in the 18th and 19th centuries. However, the land remained largely uninhabited until settlement in the 1830s.

The Allen brothers—Augustus Chapman and John Kirby—explored town sites on Buffalo Bayou and Galveston Bay. According to historian David McComb, "[T]he brothers, on August 26, 1836, bought from Elizabeth E. Parrott, wife of T.F.L. Parrott and widow of John Austin, the south half of the lower league [ tract] granted to her by her late husband. They paid $5,000 total, but only $1,000 of this in cash; notes made up the remainder."

The Allen brothers ran their first advertisement for Houston just four days later in the "Telegraph and Texas Register", naming the notional town in honor of President Sam Houston. They successfully lobbied the Republic of Texas Congress to designate Houston as the temporary capital, agreeing to provide the new government with a state capitol building. About a dozen persons resided in the town at the beginning of 1837, but that number grew to about 1,500 by the time the Texas Congress convened in Houston for the first time that May. The Republic of Texas granted Houston incorporation on June 5, 1837, as James S. Holman became its first mayor. In the same year, Houston became the county seat of Harrisburg County (now Harris County).

In 1839, the Republic of Texas relocated its capital to Austin. The town suffered another setback that year when a yellow fever epidemic claimed about one life out of every eight residents. Yet it persisted as a commercial center, forming a symbiosis with its Gulf Coast port, Galveston. Landlocked farmers brought their produce to Houston, using Buffalo Bayou to gain access to Galveston and the Gulf of Mexico. Houston merchants profited from selling staples to farmers and shipping the farmers' produce to Galveston.

The great majority of slaves in Texas came with their owners from the older slave states. Sizable numbers, however, came through the domestic slave trade. New Orleans was the center of this trade in the Deep South, but slave dealers were in Houston. Thousands of enslaved blacks lived near the city before the American Civil War. Many of them near the city worked on sugar and cotton plantations, while most of those in the city limits had domestic and artisan jobs.

In 1840, the community established a chamber of commerce in part to promote shipping and navigation at the newly created port on Buffalo Bayou.

By 1860, Houston had emerged as a commercial and railroad hub for the export of cotton. Railroad spurs from the Texas inland converged in Houston, where they met rail lines to the ports of Galveston and Beaumont. During the American Civil War, Houston served as a headquarters for General John Magruder, who used the city as an organization point for the Battle of Galveston. After the Civil War, Houston businessmen initiated efforts to widen the city's extensive system of bayous so the city could accept more commerce between Downtown and the nearby port of Galveston. By 1890, Houston was the railroad center of Texas.

In 1900, after Galveston was struck by a devastating hurricane, efforts to make Houston into a viable deep-water port were accelerated. The following year, the discovery of oil at the Spindletop oil field near Beaumont prompted the development of the Texas petroleum industry. In 1902, President Theodore Roosevelt approved a $1 million improvement project for the Houston Ship Channel. By 1910, the city's population had reached 78,800, almost doubling from a decade before. African Americans formed a large part of the city's population, numbering 23,929 people, which was nearly one-third of Houston's residents.

President Woodrow Wilson opened the deep-water Port of Houston in 1914, seven years after digging began. By 1930, Houston had become Texas' most populous city and Harris County the most populous county. In 1940, the U.S. Census Bureau reported Houston's population as 77.5% white and 22.4% black.

When World War II started, tonnage levels at the port decreased and shipping activities were suspended; however, the war did provide economic benefits for the city. Petrochemical refineries and manufacturing plants were constructed along the ship channel because of the demand for petroleum and synthetic rubber products by the defense industry during the war. Ellington Field, initially built during World War I, was revitalized as an advanced training center for bombardiers and navigators. The Brown Shipbuilding Company was founded in 1942 to build ships for the U.S. Navy during World War II. Due to the boom in defense jobs, thousands of new workers migrated to the city, both blacks and whites competing for the higher-paying jobs. President Roosevelt had established a policy of nondiscrimination for defense contractors, and blacks gained some opportunities, especially in shipbuilding, although not without resistance from whites and increasing social tensions that erupted into occasional violence. Economic gains of blacks who entered defense industries continued in the postwar years.

In 1945, the M.D. Anderson Foundation formed the Texas Medical Center. After the war, Houston's economy reverted to being primarily port-driven. In 1948, the city annexed several unincorporated areas, more than doubling its size. Houston proper began to spread across the region.

In 1950, the availability of air conditioning provided impetus for many companies to relocate to Houston, where wages were lower than those in the North; this resulted in an economic boom and produced a key shift in the city's economy toward the energy sector.

The increased production of the expanded shipbuilding industry during World War II spurred Houston's growth, as did the establishment in 1961 of NASA's "Manned Spacecraft Center" (renamed the Lyndon B. Johnson Space Center in 1973). This was the stimulus for the development of the city's aerospace industry. The Astrodome, nicknamed the "Eighth Wonder of the World", opened in 1965 as the world's first indoor domed sports stadium.

During the late 1970s, Houston had a population boom as people from the Rust Belt states moved to Texas in large numbers. The new residents came for numerous employment opportunities in the petroleum industry, created as a result of the Arab oil embargo. With the increase in professional jobs, Houston has become a destination for many college-educated persons, most recently including African Americans in a reverse Great Migration from northern areas.

In 1997, Houstonians elected Lee P. Brown as the city's first African American mayor.

In June 2001, Tropical Storm Allison dumped up to of rain on parts of Houston, causing what was then the worst flooding in the city's history. The storm cost billions of dollars in damage and killed 20 people in Texas. By December of the same year, Houston-based energy company Enron collapsed into the largest U.S. bankruptcy (at that time), a result of being investigated for off-the-books partnerships which were allegedly used to hide debt and inflate profits. The company lost no less than $70 billion.

In August 2005, Houston became a shelter to more than 150,000 people from New Orleans, who evacuated from Hurricane Katrina. One month later, about 2.5 million Houston-area residents evacuated when Hurricane Rita approached the Gulf Coast, leaving little damage to the Houston area. This was the largest urban evacuation in the history of the United States. In September 2008, Houston was hit by Hurricane Ike. As many as 40% of residents refused to leave Galveston Island because they feared the type of traffic problems that had happened after Hurricane Rita.

During its recent history, Houston has flooded several times from heavy rainfall, which has been becoming increasingly common. This has been exacerbated by a lack of zoning laws, which allowed unregulated building of residential homes and other structures in flood-prone areas. During the floods in 2015 and 2016, each of which dropped at least a foot of rain, parts of the city were covered in several inches of water. Even worse flooding happened in late August 2017, when Hurricane Harvey stalled over southeastern Texas, much like Tropical Storm Allison did sixteen years earlier, causing severe flooding in the Houston area, with some areas receiving over of rain. The rainfall exceeded 50 inches in several areas locally, breaking the national record for rainfall. The damage for the Houston area is estimated at up to $125 billion U.S. dollars, and it is considered to be one of the worst natural disasters in the history of the United States, with the death toll exceeding 70 people. On January 31, 2018, the Houston City Council agreed to forgive large water bills thousands of households faced in the aftermath of Hurricane Harvey, as Houston Public Works found 6,362 homeowners' water utility bills had at least doubled.

Houston has also been the site of numerous industrial disasters and construction accidents. In 2019, OSHA found that Texas was the leading state in the nation for crane accidents. In Houston, a 2008 crane collapse at a refinery killed 4 people and injured 6. The crane that collapsed was one of the largest cranes in the nation, possessing a 400-foot boom that can lift more than a million pounds. Due to the industrial infrastructure in and around Houston, natural disasters like Hurricane Harvey have also led to numerous toxic spills and disasters, including the 2017 Arkema plant explosion.

Houston is located east of Austin, west of the Louisiana border, and south of Dallas. The city has a total area of ; this comprises over of land and covered by water. Most of Houston is located on the gulf coastal plain, and its vegetation is classified as Western Gulf coastal grasslands while further north, it transitions into a subtropical jungle, the Big Thicket. Much of the city was built on forested land, marshes, or swamps, and are all still visible in surrounding areas. Flat terrain and extensive greenfield development have combined to worsen flooding. Downtown stands about above sea level, and the highest point in far northwest Houston is about in elevation. The city once relied on groundwater for its needs, but land subsidence forced the city to turn to ground-level water sources such as Lake Houston, Lake Conroe, and Lake Livingston. The city owns surface water rights for 1.20 billion gallons of water a day in addition to 150 million gallons a day of groundwater.

Houston has four major bayous passing through the city that accept water from the extensive drainage system. Buffalo Bayou runs through Downtown and the Houston Ship Channel, and has three tributaries: White Oak Bayou, which runs through the Houston Heights community northwest of Downtown and then towards Downtown; Brays Bayou, which runs along the Texas Medical Center; and Sims Bayou, which runs through the south of Houston and Downtown Houston. The ship channel continues past Galveston and then into the Gulf of Mexico.

Houston is a flat marshy area where an extensive drainage system has been built. The adjoining prairie land drains into the city, which is prone to flooding. Underpinning Houston's land surface are unconsolidated clays, clay shales, and poorly cemented sands up to several miles deep. The region's geology developed from river deposits formed from the erosion of the Rocky Mountains. These sediments consist of a series of sands and clays deposited on decaying organic marine matter, that over time, transformed into oil and natural gas. Beneath the layers of sediment is a water-deposited layer of halite, a rock salt. The porous layers were compressed over time and forced upward. As it pushed upward, the salt dragged surrounding sediments into salt dome formations, often trapping oil and gas that seeped from the surrounding porous sands. The thick, rich, sometimes black, surface soil is suitable for rice farming in suburban outskirts where the city continues to grow.

The Houston area has over 150 active faults (estimated to be 300 active faults) with an aggregate length of up to , including the Long Point–Eureka Heights fault system which runs through the center of the city. No significant historically recorded earthquakes have occurred in Houston, but researchers do not discount the possibility of such quakes having occurred in the deeper past, nor occurring in the future. Land in some areas southeast of Houston is sinking because water has been pumped out of the ground for many years. It may be associated with slip along the faults; however, the slippage is slow and not considered an earthquake, where stationary faults must slip suddenly enough to create seismic waves. These faults also tend to move at a smooth rate in what is termed "fault creep", which further reduces the risk of an earthquake.

Houston was incorporated in 1837 and adopted a ward system of representation shortly afterward in 1840. The six original wards of Houston are the progenitors of the 11 modern-day geographically-oriented Houston City Council districts, though the city abandoned the ward system in 1905 in favor of a commission government, and, later, the existing mayor–council government.

Locations in Houston are generally classified as either being inside or outside the Interstate 610 loop. The "Inner Loop" encompasses a area which includes Downtown, pre–World War II residential neighborhoods and streetcar suburbs, and newer high-density apartment and townhouse developments. Outside the loop, the city's typology is more suburban, though many major business districts—such as Uptown, Westchase, and the Energy Corridor—lie well outside the urban core. In addition to Interstate 610, two additional loop highways encircle the city: Beltway 8, with a radius of approximately from Downtown, and State Highway 99 (the Grand Parkway), with a radius of . Approximately 470,000 people lived within the Interstate 610 loop, while 1.65 million lived between Interstate 610 and Beltway 8 and 2.25 million lived within Harris County outside Beltway 8 in 2015.

Though Houston is the largest city in the United States without formal zoning regulations, it has developed similarly to other Sun Belt cities because the city's land use regulations and legal covenants have played a similar role. Regulations include mandatory lot size for single-family houses and requirements that parking be available to tenants and customers. Such restrictions have had mixed results. Though some have blamed the city's low density, urban sprawl, and lack of pedestrian-friendliness on these policies, others have credited the city's land use patterns with providing significant affordable housing, sparing Houston the worst effects of the 2008 real estate crisis. The city issued 42,697 building permits in 2008 and was ranked first in the list of healthiest housing markets for 2009.

In referendums in 1948, 1962, and 1993, voters rejected efforts to establish separate residential and commercial land-use districts. Consequently, rather than a single central business district as the center of the city's employment, multiple districts have grown throughout the city in addition to Downtown, which include Uptown, the Texas Medical Center, Midtown, Greenway Plaza, Memorial City, the Energy Corridor, Westchase, and Greenspoint.

Houston had the fifth-tallest skyline in North America (after New York City, Chicago, Toronto and Miami) and 36th-tallest in the world in 2015. A seven-mile (11 km) system of tunnels and skywalks links Downtown buildings containing shops and restaurants, enabling pedestrians to avoid summer heat and rain while walking between buildings.

In the 1960s, Downtown Houston consisted of a collection of midrise office structures. Downtown was on the threshold of an energy industryled boom in 1970. A succession of skyscrapers was built throughout the 1970s—many by real estate developer Gerald D. Hines—culminating with Houston's tallest skyscraper, the 75-floor, -tall JPMorgan Chase Tower (formerly the Texas Commerce Tower), completed in 1982. It is the tallest structure in Texas, 19th tallest building in the United States, and was previously 85th-tallest skyscraper in the world, based on highest architectural feature. In 1983, the 71-floor, -tall Wells Fargo Plaza (formerly Allied Bank Plaza) was completed, becoming the second-tallest building in Houston and Texas. Based on highest architectural feature, it is the 21st-tallest in the United States. In 2007, Downtown had over 43 million square feet (4,000,000 m²) of office space.

Centered on Post Oak Boulevard and Westheimer Road, the Uptown District boomed during the 1970s and early 1980s when a collection of midrise office buildings, hotels, and retail developments appeared along Interstate 610 West. Uptown became one of the most prominent instances of an edge city. The tallest building in Uptown is the 64-floor, -tall, Philip Johnson and John Burgee designed landmark Williams Tower (known as the Transco Tower until 1999). At the time of construction, it was believed to be the world's tallest skyscraper outside a central business district. The new 20-story Skanska building and BBVA Compass Plaza are the newest office buildings built in Uptown after 30 years. The Uptown District is also home to buildings designed by noted architects I. M. Pei, César Pelli, and Philip Johnson. In the late 1990s and early 2000s, a mini-boom of midrise and highrise residential tower construction occurred, with several over 30 stories tall. Since 2000 over 30 skyscrapers have been developed in Houston; all told, 72 high-rises tower over the city, which adds up to about 8,300 units. In 2002, Uptown had more than 23 million square feet (2,100,000 m²) of office space with 16 million square feet (1,500,000 m²) of class A office space.

Houston's climate is classified as humid subtropical ("Cfa" in the Köppen climate classification system), typical of the Southern United States. While not located in Tornado Alley, like much of Northern Texas, spring supercell thunderstorms sometimes bring tornadoes to the area.

Prevailing winds are from the south and southeast during most of the year, which bring heat and moisture from the nearby Gulf of Mexico and Galveston Bay.

During the summer, with temperatures reaching or exceeding on an average of 106.5 days per year, including a majority of days from June to September; additionally, an average of 4.6 days per year reach or exceed . Houston's characteristic subtropical humidity often results in a higher apparent temperature, and summer mornings average over 90% relative humidity. Air conditioning is ubiquitous in Houston; in 1981, annual spending on electricity for interior cooling exceeded $600 million (equivalent to $ billion in ), and by the late 1990s, approximately 90% of Houston homes featured air conditioning systems. The record highest temperature recorded in Houston is at Bush Intercontinental Airport, during September 4, 2000, and again on August 27, 2011.

Houston has mild winters, with occasional cold spells. In January, the normal mean temperature at George Bush Intercontinental Airport is , with an average of 13 days per year with a low at or below , occurring on average between December 3 and February 20, allowing for a growing season of 286 days. Twenty-first century snow events in Houston include a storm on December 24, 2004, which saw of snow accumulate in parts of the metro area, and an event on December 7, 2017, which precipitated of snowfall. Snowfalls of at least on both December 10, 2008, and December 4, 2009, marked the first time measurable snowfall had occurred in two consecutive years in the city's recorded history. Overall, Houston has seen measurable snowfall 38 times between 1895 and 2018. On February 14 and 15, 1895, Houston received of snow, its largest snowfall from one storm on record. The coldest temperature officially recorded in Houston was on January 18, 1930.

Houston generally receives ample rainfall, averaging about annually based on records between 1981 and 2010. Many parts of the city have a high risk of localized flooding due to flat topography, ubiquitous low-permeability clay-silt prairie soils, and inadequate infrastructure. During the mid-2010s, Greater Houston experienced consecutive major flood events in 2015 ("Memorial Day"), 2016 ("Tax Day"), and 2017 (Hurricane Harvey). Overall, there have been more casualties and property loss from floods in Houston than in any other locality in the United States. The majority of rainfall occurs between April and October (the wet season of Southeast Texas), when the moisture from the Gulf of Mexico evaporates extensively over the city.

Houston has excessive ozone levels and is routinely ranked among the most ozone-polluted cities in the United States. Ground-level ozone, or smog, is Houston's predominant air pollution problem, with the American Lung Association rating the metropolitan area's ozone level twelfth on the "Most Polluted Cities by Ozone" in 2017, after major cities such as Los Angeles, Phoenix, New York City, and Denver. The industries located along the ship channel are a major cause of the city's air pollution. The rankings are in terms of peak-based standards, focusing strictly on the worst days of the year; the average ozone levels in Houston are lower than what is seen in most other areas of the country, as dominant winds ensure clean, marine air from the Gulf. Excessive man-made emissions in the Houston area led to a persistent increase of atmospheric carbon dioxide over the city. Such an increase, often regarded as "CO2 urban dome," is driven by a combination of strong emissions and stagnant atmospheric conditions. Moreover, Houston is the only metropolitan area with less than ten million citizens where such CO2 dome can be detected by satellites.

Because of Houston's wet season and proximity to the Gulf Coast, the city is prone to flooding from heavy rains; the most notable flooding events include Tropical Storm Allison in 2001 and Hurricane Harvey in 2017, along with most recent Tropical Storm Imelda in 2019. In response to Hurricane Harvey, Mayor Sylvester Turner of Houston initiated plans to require developers to build homes that will be less susceptible to flooding by raising them two feet above the 500-year floodplain. Hurricane Harvey damaged hundreds of thousands of homes and dumped trillions of gallons of water into the city. In places this led to feet of standing water that blocked streets and flooded homes. The Houston City Council passed this regulation in 2018 with a vote of 9–7. Had these floodplain development rules had been in place all along, it is estimated that 84% of homes in the 100-year and 500-year floodplains would have been spared damage.

In a recent case testing these regulations, near the Brickhouse Gulley, an old golf course that long served as a floodplain and reservoir for flood waters, announced a change of heart toward intensifying development. A nation-wide developer, Meritage Homes, bought the land and planned to develop the 500-year floodplain into 900 new residential homes. Their plan would bring in $360 million in revenue and boost city population and tax revenue. In order to meet the new floodplain regulations, the developers needed to elevate lowest floors two feet above the 500 year floodplain, equivalent to five or six feet above the 100-year base flood elevation, and build a channel to direct stormwater runoff toward detention basins. Before Hurricane Harvey, the city had bought back $10.7 million in houses in this area specifically to take them out of danger. After Hurricane Harvey this sudden change of heart seems likely to have been motivated by the prospect of additional tax revenues. In addition to developing new streets and single-family housing within a floodplain, a flowing flood-water stream termed a floodway runs through the development area, a most dangerous place to encounter during any future flooding event. Under Texas law Harris County, like other more rural Texas counties, cannot direct developers where to build or not build via land use controls such as a zoning ordinance, and instead can only impose general floodplain regulations for enforcement during subdivision approvals and building permit approvals.

The 2010 United States Census reported that Houston had a population of 2,100,263 residents. In 2017, the census-estimated population rose to 2,312,717, and in 2018 to 2,325,502. An estimated 600,000 undocumented immigrants resided in the Houston area in 2017, comprising nearly 9% of the city's metropolitan population.

Per the American Community Survey's 2014-2018 estimates, Houston's age distribution was 486,083 under 15; 147,710 aged 15 to 19; 603,586 aged 20 to 34; 726,877 aged 35 to 59; and 357,834 aged 60 and older. The median age was 33.1, up from 32.9 in 2017 and down from 33.5 in 2014; the city's youthfulness was attributed to an influx of an African American New Great Migration, Hispanic or Latin American, and Asian immigrants into Texas. For every 100 females, there were 98.5 males.

There were 976,745 housing units in 2018 and 849,105 households. An estimated 42.9% of Houstonians owned housing units with an average of 2.67 persons per household. The median monthly owner costs with a mortgage were $1,598, and $524 without a mortgage. Houston's median gross rent from 2014-2018 was $990. The median household income in 2018 was $51,140 and 20.6% of Houstonians lived at or below the poverty line.

Houston is a majority-minority city. The Rice University Kinder Institute for Urban Research, a think tank, has described Greater Houston as "one of the most ethnically and culturally diverse metropolitan areas in the country". Houston's diversity, historically fueled by large waves of Hispanic or Latino and Asian immigrants, has been attributed to its relatively low cost of living, strong job market, and role as a hub for refugee resettlement. Houston has long been known as a popular destination for African Americans due to the city's well-established and influential Black or African American community. Houston is also home to the largest African American community in Texas. A 2012 Kinder Institute report found that, based on the evenness of population distribution between the four major racial groups in the United States (non-Hispanic white, non-Hispanic black, Hispanic or Latino, and Asian), Greater Houston was the most ethnically diverse metropolitan area in the United States, ahead of New York City.

In 2017, according to the U.S. Census Bureau, non-Hispanic whites made up 24.9% of the population of Houston proper, Hispanics or Latinos 44.5%, Blacks or African Americans 22.9%, and Asians 6.7%. In 2018, non-Hispanic whites made up 23.7% of the population, Hispanics or Latinos 44.9%, Blacks or African Americans 23.3%, and Asians 8.2%. The largest Hispanic or Latin American ethnic groups in the city were Mexican Americans (31.6%), Puerto Ricans (0.8%), and Cuban Americans (0.8%) in 2018.

Houston has a higher proportion of minorities than non-Hispanic whites. In 2010, whites (including Hispanic whites) made up 57.6% of the city of Houston's population; 24.6% of the total population was non-Hispanic whites. Blacks or African Americans made up 22.5% of Houston's population, American Indians made up 0.3% of the population, Asians made up 6.9% (1.7% Vietnamese, 1.3% Chinese, 1.3% Indian, 0.9% Pakistani, 0.4% Filipino, 0.3% Korean, 0.1% Japanese) and Pacific Islanders made up 0.1%. Individuals from some other race made up 15.69% of the city's population. Individuals from two or more races made up 2.1% of the city.

At the 2000 U.S. census, the racial makeup of the city in was 49.3% White, 25.3% Black or African American, 5.3% Asian, 0.7% American Indian, 0.1% Pacific Islander, 16.5% from some other race, and 3.1% from two or more races. In addition, Hispanics made up 37.4% of Houston's population in 2000, while non-Hispanic whites made up 30.8%. The proportion of non-Hispanic whites in Houston has decreased significantly since 1970, when it was 62.4%.

Houston is home to one of the largest LGBT communities and pride parades in the United States. In 2018 the city scored a 70 out of 100 for LGBT friendliness. Jordan Blum of the "Houston Chronicle" stated levels of LGBT acceptance and discrimination varied in 2016.

Before the 1970s, the city's gay bars were spread around Downtown Houston and what is now Midtown Houston. LGBT Houstonians needed to have a place to socialize after the closing of the gay bars. They began going to Art Wren, a 24-hour restaurant in Montrose. LGBT community members were attracted to Montrose as a neighborhood after encountering it while patronizing Art Wren, and they began to gentrify the neighborhood and assist its native inhabitants with property maintenance. Within Montrose, new gay bars began to open. By 1985, the flavor and politics of the neighborhood were heavily influenced by the LGBT community and in 1990, according to Hill, 19% of Montrose residents identified as LGBT. Paul Broussard was murdered in Montrose in 1991.

In February 2015 a 17-year-old gay student at Lutheran High School North reported that the school forced him to leave since he refused to take down YouTube videos discussing his sexuality. The school's executive director, Wayne Kramer, referred to the student handbook, which stated: "Lutheran High North reserves the right, within its sole discretion, to refuse admission of an applicant and/or to discontinue enrollment of a current student participating in, promoting, supporting or condoning: pornography, sexual immorality, homosexual activity or bisexual activity".

Before the legalization of same-sex marriage in the United States the first marriage in Houston took place on October 5, 1972. Houston elected the first openly lesbian mayor of a major city in 2009, and she served until 2016. During her tenure she authorized the Houston Equal Rights Ordinance which was intended to improve anti-discrimination coverage based on sexual orientation and gender identity in the city, specifically in areas such as housing and occupation where no anti-discrimination policy existed.

Houston and its metropolitan area are the third most religious and Christian area by percentage of population in the United States, and second in Texas behind the Dallas–Fort Worth metroplex. Historically, Houston has been a center of Protestant Christianity, being part of the Bible Belt. Other Christian groups including Eastern and Oriental Orthodox Christianity, and non-Christian religions did not grow for much of the city's history because immigration was predominantly from Western Europe (which at the time was dominated by Western Christianity and favored by the quotas in federal immigration law). The Immigration and Nationality Act of 1965 removed the quotas, allowing for the growth of other religions.

According to a 2014 study by the Pew Research Center, 73% of the population of the Houston area identified themselves as Christians, about 50% of whom claimed Protestant affiliations and about 19% claimed Roman Catholic affiliations. Nationwide, about 71% of respondents identified as Christians. About 20% of Houston-area residents claimed no religious affiliation, compared to about 23% nationwide. The same study says that area residents identifying with other religions (including Judaism, Buddhism, Islam, and Hinduism) collectively made up about 7% of the area population.

Lakewood Church in Houston, led by Pastor Joel Osteen, is the largest church in the United States. A megachurch, it had 44,800 weekly attendees in 2010, up from 11,000 weekly in 2000. Since 2005 it has occupied the former Compaq Center sports stadium. In September 2010, "Outreach Magazine" published a list of the 100 largest Christian churches in the United States, and inside the list were the following Houston-area churches: Lakewood, Second Baptist Church Houston, Woodlands Church, Church Without Walls and First Baptist Church. According to the list, Houston and Dallas were tied as the second most popular city for megachurches.The Roman Catholic Archdiocese of Galveston-Houston, the largest Catholic jurisdiction in Texas and fifth-largest in the United States, was established in 1847. The Roman Catholic Archdiocese of Galveston-Houston claims approximately 1.7 million Catholics within its boundaries. Other prominent Catholic jurisdictions include the Eastern Catholic Ruthenian Greek Catholic Church and Ukrainian Greek Catholic Church.

A variety of Eastern and Oriental Orthodox churches can be found in Houston. Immigrants from Eastern Europe, the Middle East, Ethiopia, India and other areas have added to Houston's Eastern and Oriental Orthodox population. As of 2011 in the entire State of Texas there were 32,000 people who actively attend Orthodox churches. In 2013 Father John Whiteford, the pastor of St. Jonah Orthodox Church near Spring, stated that there were about 6,000-9,000 Eastern Orthodox Christians in Houston. The most prominent Eastern and Oriental Orthodox jurisdictions are the Greek Orthodox Archdiocese of America, the Antiochian Orthodox Archdiocese of North America, the Coptic Orthodox Church of Alexandria, and Ethiopian Orthodox Tewahedo Church.

Houston's Jewish community, estimated at 47,000 in 2001, has been present in the city since the 1800s. Houstonian Jews have origins from throughout the United States, Israel, Mexico, Russia, and other places. As of 2016 there were over 40 synagogues in Greater Houston. The largest synagogues in Houston are Congregation Beth Yeshurun, a Conservative Jewish temple, and the Reform Jewish congregations Beth Israel and Emanu-El.

Houston has a large and diverse Muslim community; it is the largest in Texas and the Southern United States, as of 2012. It is estimated that Muslims made up 1.2% of Houston's population. As of 2016, Muslims in the Houston area included South Asians, Middle Easterners, Africans, Turks, and Indonesians. In 2000 there were over 41 mosques and storefront religious centers, with the largest being the "Al-Noor" Mosque (Mosque of Light) of the Islamic Society of Greater Houston. The Hindu, Sikh, and Buddhist communities form a growing sector of the religious demographic after Judaism and Islam. One of the largest Hindu temples in the metropolitan area is BAPS Shri Swaminarayan Mandir Houston, affiliated with the Swaminarayan Sampradaya denomination. Of the irreligious community 16% practiced nothing in particular, 3% were agnostic, and 2% were atheist.

Houston is recognized worldwide for its energy industry—particularly for oil and natural gas—as well as for biomedical research and aeronautics. Renewable energy sources—wind and solar—are also growing economic bases in the city. The Houston Ship Channel is also a large part of Houston's economic base. Because of these strengths, Houston is designated as a global city by the Globalization and World Cities Study Group and Network and global management consulting firm A.T. Kearney. The Houston area is the top U.S. market for exports, surpassing New York City in 2013, according to data released by the U.S. Department of Commerce's International Trade Administration. In 2012, the Houston–The Woodlands–Sugar Land area recorded $110.3 billion in merchandise exports. Petroleum products, chemicals, and oil and gas extraction equipment accounted for roughly two-thirds of the metropolitan area's exports last year. The top three destinations for exports were Mexico, Canada, and Brazil.

The Houston area is a leading center for building oilfield equipment. Much of its success as a petrochemical complex is due to its busy ship channel, the Port of Houston. In the United States, the port ranks first in international commerce and 16th among the largest ports in the world. Unlike most places, high oil and gasoline prices are beneficial for Houston's economy, as many of its residents are employed in the energy industry. Houston is the beginning or end point of numerous oil, gas, and products pipelines.

The Houston–The Woodlands–Sugar Land metro area's gross domestic product (GDP) in 2016 was $478 billion, making it the sixth-largest of any metropolitan area in the United States and larger than Iran's, Colombia's, or the United Arab Emirates' GDP. Only 27 countries other than the United States have a gross domestic product exceeding Houston's regional gross area product (GAP). In 2010, mining (which consists almost entirely of exploration and production of oil and gas in Houston) accounted for 26.3% of Houston's GAP up sharply in response to high energy prices and a decreased worldwide surplus of oil production capacity, followed by engineering services, health services, and manufacturing.

The University of Houston System's annual impact on the Houston area's economy equates to that of a major corporation: $1.1 billion in new funds attracted annually to the Houston area, $3.13 billion in total economic benefit, and 24,000 local jobs generated. This is in addition to the 12,500 new graduates the U.H. System produces every year who enter the workforce in Houston and throughout Texas. These degree-holders tend to stay in Houston. After five years, 80.5% of graduates are still living and working in the region.

In 2006, the Houston metropolitan area ranked first in Texas and third in the U.S. within the category of "Best Places for Business and Careers" by "Forbes" magazine. Ninety-one foreign governments have established consular offices in Houston's metropolitan area, the third-highest in the nation. Forty foreign governments maintain trade and commercial offices here with 23 active foreign chambers of commerce and trade associations. Twenty-five foreign banks representing 13 nations operate in Houston, providing financial assistance to the international community.

In 2008, Houston received top ranking on "Kiplinger's Personal Finance" "Best Cities of 2008" list, which ranks cities on their local economy, employment opportunities, reasonable living costs, and quality of life. The city ranked fourth for highest increase in the local technological innovation over the preceding 15 years, according to "Forbes" magazine. In the same year, the city ranked second on the annual "Fortune" 500 list of company headquarters, first for "Forbes" magazine's "Best Cities for College Graduates", and first on their list of "Best Cities to Buy a Home". In 2010, the city was rated the best city for shopping, according to "Forbes".

In 2012, the city was ranked number one for paycheck worth by "Forbes" and in late May 2013, Houston was identified as America's top city for employment creation.

In 2013, Houston was identified as the number one U.S. city for job creation by the U.S. Bureau of Statistics after it was not only the first major city to regain all the jobs lost in the preceding economic downturn, but also after the crash, more than two jobs were added for every one lost. Economist and vice president of research at the Greater Houston Partnership Patrick Jankowski attributed Houston's success to the ability of the region's real estate and energy industries to learn from historical mistakes. Furthermore, Jankowski stated that "more than 100 foreign-owned companies relocated, expanded or started new businesses in Houston" between 2008 and 2010, and this openness to external business boosted job creation during a period when domestic demand was problematically low. Also in 2013, Houston again appeared on "Forbes"' list of "Best Places for Business and Careers".

Located in the American South, Houston is a diverse city with a large and growing international community. The Greater Houston metropolitan area is home to an estimated 1.1 million (21.4 percent) residents who were born outside the United States, with nearly two-thirds of the area's foreign-born population from south of the United States–Mexico border. Additionally, more than one in five foreign-born residents are from Asia. The city is home to the nation's third-largest concentration of consular offices, representing 92 countries.

Many annual events celebrate the diverse cultures of Houston. The largest and longest-running is the annual Houston Livestock Show and Rodeo, held over 20 days from early to late March, and is the largest annual livestock show and rodeo in the world. Another large celebration is the annual night-time Houston Gay Pride Parade, held at the end of June. Other notable annual events include the Houston Greek Festival, Art Car Parade, the Houston Auto Show, the Houston International Festival, and the Bayou City Art Festival, which is considered to be one of the top five art festivals in the United States.

Houston is highly regarded for its diverse food and restaurant culture. Several major publications have consistently named Houston one of "America's Best Food Cities".

Houston received the official nickname of "Space City" in 1967 because it is the location of NASA's Lyndon B. Johnson Space Center. Other nicknames often used by locals include "Bayou City", "Clutch City", "Crush City", "Magnolia City", "H-Town", and "Culinary Capital of the South".

The Houston Theater District, located in Downtown, is home to nine major performing arts organizations and six performance halls. It is the second-largest concentration of theater seats in a downtown area in the United States.

Houston is one of few United States cities with permanent, professional, resident companies in all major performing arts disciplines: opera (Houston Grand Opera), ballet (Houston Ballet), music (Houston Symphony Orchestra), and theater (The Alley Theatre, Theatre Under the Stars). Houston is also home to folk artists, art groups and various small progressive arts organizations.

Houston attracts many touring Broadway acts, concerts, shows, and exhibitions for a variety of interests. Facilities in the Theater District include the Jones Hall—home of the Houston Symphony Orchestra and Society for the Performing Arts—and the Hobby Center for the Performing Arts.

The Museum District's cultural institutions and exhibits attract more than 7 million visitors a year. Notable facilities include The Museum of Fine Arts, the Houston Museum of Natural Science, the Contemporary Arts Museum Houston, the Station Museum of Contemporary Art, the Holocaust Museum Houston, the Children's Museum of Houston, and the Houston Zoo.

Located near the Museum District are The Menil Collection, Rothko Chapel, the Moody Center for the Arts and the Byzantine Fresco Chapel Museum.

Bayou Bend is a facility of the Museum of Fine Arts that houses one of America's most prominent collections of decorative art, paintings, and furniture. Bayou Bend is the former home of Houston philanthropist Ima Hogg.

The National Museum of Funeral History is located in Houston near the George Bush Intercontinental Airport. The museum houses the original Popemobile used by Pope John Paul II in the 1980s along with numerous hearses, embalming displays, and information on famous funerals.

Venues across Houston regularly host local and touring rock, blues, country, dubstep, and Tejano musical acts. While Houston has never been widely known for its music scene, Houston hip-hop has become a significant, independent music scene that is influential nationwide. Houston is the birthplace of the chopped and screwed remixing-technique in Hip-hop which was pioneered by DJ Screw from the city. Some other notable Hip-hop artists from the area include Slim Thug, Paul Wall, Mike Jones, Bun B, Geto Boys, Trae tha Truth, Kirko Bangz, Z-Ro, South Park Mexican, Travis Scott and Megan Thee Stallion.

The Theater District is a 17-block area in the center of Downtown Houston that is home to the Bayou Place entertainment complex, restaurants, movies, plazas, and parks. Bayou Place is a large multilevel building containing full-service restaurants, bars, live music, billiards, and Sundance Cinema. The Bayou Music Center stages live concerts, stage plays, and stand-up comedy.
Space Center Houston is the official visitors' center of NASA's Lyndon B. Johnson Space Center. The Space Center has many interactive exhibits including moon rocks, a shuttle simulator, and presentations about the history of NASA's manned space flight program. Other tourist attractions include the Galleria (Texas' largest shopping mall, located in the Uptown District), Old Market Square, the Downtown Aquarium, and Sam Houston Race Park.

Houston's current Chinatown and the Mahatma Gandhi District are two major ethnic enclaves, reflecting Houston's multicultural makeup. Restaurants, bakeries, traditional-clothing boutiques, and specialty shops can be found in both areas.

Houston is home to 337 parks, including Hermann Park, Terry Hershey Park, Lake Houston Park, Memorial Park, Tranquility Park, Sesquicentennial Park, Discovery Green, Buffalo Bayou Park and Sam Houston Park. Within Hermann Park are the Houston Zoo and the Houston Museum of Natural Science. Sam Houston Park contains restored and reconstructed homes which were originally built between 1823 and 1905. A proposal has been made to open the city's first botanic garden at Herman Brown Park.

Of the 10 most populous U.S. cities, Houston has the most total area of parks and green space, . The city also has over 200 additional green spaces—totaling over that are managed by the city—including the Houston Arboretum and Nature Center. The Lee and Joe Jamail Skatepark is a public skatepark owned and operated by the city of Houston, and is one of the largest skateparks in Texas consisting of a 30,000-ft (2,800 m)in-ground facility.

The Gerald D. Hines Waterwall Park—located in the Uptown District of the city—serves as a popular tourist attraction and for weddings and various celebrations. A 2011 study by Walk Score ranked Houston the 23rd most walkable of the 50 largest cities in the United States.

Houston has sports teams for every major professional league except the National Hockey League. The Houston Astros are a Major League Baseball expansion team formed in 1962 (known as the "Colt .45s" until 1965) that won the World Series in 2017 and appeared in both the 2005 and 2019 World Series. It is the only MLB team to have won pennants in both modern leagues. The Houston Rockets are a National Basketball Association franchise based in the city since 1971. They have won two NBA Championships, one in 1994 and another in 1995 under star players Hakeem Olajuwon, Otis Thorpe, Clyde Drexler, Vernon Maxwell, and Kenny Smith. The Houston Texans are a National Football League expansion team formed in 2002. The Houston Dynamo is a Major League Soccer franchise that has been based in Houston since 2006, winning two MLS Cup titles in 2006 and 2007. The Houston Dash team plays in the National Women's Soccer League. The Houston SaberCats are a rugby team that plays in Major League Rugby.

Minute Maid Park (home of the Astros) and Toyota Center (home of the Rockets), are located in Downtown Houston. Houston has the NFL's first retractable-roof stadium with natural grass, NRG Stadium (home of the Texans). Minute Maid Park is also a retractable-roof stadium. Toyota Center also has the largest screen for an indoor arena in the United States built to coincide with the arena's hosting of the 2013 NBA All-Star Game. BBVA Compass Stadium is a soccer-specific stadium for the Houston Dynamo, the Texas Southern Tigers football team, and Houston Dash, located in East Downtown. Aveva Stadium (home of the SaberCats) is located in south Houston. In addition, NRG Astrodome was the first indoor stadium in the world, built in 1965. Other sports facilities include Hofheinz Pavilion (Houston Cougars basketball), Rice Stadium (Rice Owls football), and NRG Arena. TDECU Stadium is where the University of Houston's Cougars football team plays.

Houston has hosted several major sports events: the 1968, 1986 and 2004 Major League Baseball All-Star Games; the 1989, 2006 and 2013 NBA All-Star Games; Super Bowl VIII, Super Bowl XXXVIII, and Super Bowl LI, as well as hosting the 1981, 1986, 1994 and 1995 NBA Finals, winning the latter two, and hosting the 2005 World Series, 2017 World Series and 2019 World Series. The city won its first baseball championship during the 2017 event. NRG Stadium hosted Super Bowl LI on February 5, 2017.

The city has hosted several major professional and college sporting events, including the annual Houston Open golf tournament. Houston hosts the annual Houston College Classic baseball tournament every February, and the Texas Kickoff and Bowl in September and December, respectively.

The Grand Prix of Houston, an annual auto race on the IndyCar Series circuit was held on a 1.7-mile temporary street circuit in NRG Park. The October 2013 event was held using a tweaked version of the 2006–2007 course. The event had a 5-year race contract through 2017 with IndyCar. In motorcycling, the Astrodome hosted an AMA Supercross Championship round from 1974 to 2003 and the NRG Stadium since 2003.

Houston is also one of the first cities in the world to have a major eSports team represent it, in the form of the Houston Outlaws. The Outlaws play in the Overwatch League and are one of two Texan teams, the other being the Dallas Fuel. Houston is also one of eight cities to have an XFL team, the Houston Roughnecks.

The city of Houston has a strong mayoral form of municipal government. Houston is a home rule city and all municipal elections in the Texas are nonpartisan. The city's elected officials are the mayor, city controller and 16 members of the Houston City Council. The current mayor of Houston is Sylvester Turner, a Democrat elected on a nonpartisan ballot. Houston's mayor serves as the city's chief administrator, executive officer, and official representative, and is responsible for the general management of the city and for seeing that all laws and ordinances are enforced.

The original city council line-up of 14 members (nine district-based and five at-large positions) was based on a U.S. Justice Department mandate which took effect in 1979. At-large council members represent the entire city. Under the city charter, once the population in the city limits exceeded 2.1 million residents, two additional districts were to be added. The city of Houston's official 2010 census count was 600 shy of the required number; however, as the city was expected to grow beyond 2.1 million shortly thereafter, the two additional districts were added for, and the positions filled during, the August 2011 elections.

The city controller is elected independently of the mayor and council. The controller's duties are to certify available funds prior to committing such funds and processing disbursements. The city's fiscal year begins on July 1 and ends on June 30. Chris Brown is the city controller, serving his first term .

As the result of a 2015 referendum in Houston, a mayor is elected for a four-year term, and can be elected to as many as two consecutive terms. The term limits were spearheaded in 1991 by conservative political activist Clymer Wright. During 1991–2015, the city controller and city council members were subjected to a two-year, three-term limitation–the 2015 referendum amended term limits to two four-year terms. some councilmembers who served two terms and won a final term will have served eight years in office, whereas a freshman councilmember who won a position in 2013 can serve up to two additional terms under the previous term limit law–a select few will have at least 10 years of incumbency once their term expires.

Houston is considered to be a politically divided city whose balance of power often sways between Republicans and Democrats. Much of the city's wealthier areas vote Republican while the city's working class and minority areas vote Democratic. According to the 2005 Houston Area Survey, 68 percent of non-Hispanic whites in Harris County are declared or favor Republicans while 89 percent of non-Hispanic blacks in the area are declared or favor Democrats. About 62 percent of Hispanics (of any race) in the area are declared or favor Democrats. The city has often been known to be the most politically diverse city in Texas, a state known for being generally conservative. As a result, the city is often a contested area in statewide elections. In 2009, Houston became the first U.S. city with a population over 1 million citizens to elect a gay mayor, by electing Annise Parker.

Texas has banned sanctuary cities, but Houston Mayor Sylvester Turner said that Houston will not assist ICE agents with immigration raids.

Houston had 303 homicides in 2015 and 302 homicides in 2016. Officials predicted there would be 323 homicides in 2016. Instead, there was no increase in Houston's homicide rate between 2015 and 2016.

Houston's murder rate ranked 46th of U.S. cities with a population over 250,000 in 2005 (per capita rate of 16.3 murders per 100,000 population). In 2010, the city's murder rate (per capita rate of 11.8 murders per 100,000 population) was ranked sixth among U.S. cities with a population of over 750,000 (behind New York City, Chicago, Detroit, Dallas, and Philadelphia) according to the Federal Bureau of Investigation.

Murders fell by 37 percent from January to June 2011, compared with the same period in 2010. Houston's total crime rate including violent and nonviolent crimes decreased by 11 percent. The FBI's Uniform Crime Report (UCR) indicates a downward trend of violent crime in Houston over the ten- and twenty-year periods ending in 2016, which is consistent with national trends. This trend toward lower rates of violent crime in Houston includes the murder rate, though it had seen a four-year uptick that lasted through 2015. Houston's violent crime rate was 8.6% percent higher in 2016 from the previous year. However, from 2006 to 2016, violent crime was still down 12 percent in Houston.

Houston is a significant hub for trafficking of cocaine, cannabis, heroin, MDMA, and methamphetamine due to its size and proximity to major illegal drug exporting nations. Houston is one of the country's largest hubs for human trafficking.

In the early 1970s, Houston, Pasadena and several coastal towns were the site of the Houston mass murders, which at the time were the deadliest case of serial killing in American history.

In 1853 the first execution in Houston took place in public at Founder's Cemetery in the Fourth Ward; initially the cemetery was the execution site, but post-1868 executions took place in the jail facilities.

Nineteen school districts exist within the city of Houston. The Houston Independent School District (HISD) is the seventh-largest school district in the United States and the largest in Texas. HISD has 112 campuses that serve as magnet or vanguard schools—specializing in such disciplines as health professions, visual and performing arts, and the sciences. There are also many charter schools that are run separately from school districts. In addition, some public school districts also have their own charter schools.

The Houston area encompasses more than 300 private schools, many of which are accredited by Texas Private School Accreditation Commission recognized agencies. The Houston Area independent schools offer education from a variety of different religious as well as secular viewpoints. The Houston area Catholic schools are operated by the Roman Catholic Archdiocese of Galveston-Houston.

Four distinct state universities are located in Houston. The University of Houston (UH) is a nationally recognized and is the flagship institution of the University of Houston System. The university in Texas, the University of Houston has nearly 44,000 students on its campus in the Third Ward. The University of Houston–Clear Lake and the University of Houston–Downtown are universities within the University of Houston System; they are not branch campuses of the University of Houston. Slightly west of the University of Houston is Texas Southern University (TSU), one of the largest and most comprehensive historically black universities in the United States with approximately 10,000 students. Texas Southern University is the first state university in Houston, founded in 1927.

Several private institutions of higher learning are located within the city. Rice University, the most selective university in Texas and one of the most selective in the United States, is a private, secular institution with a high level of research activity. Founded in 1912, Rice's historic, heavily wooded campus, located adjacent to Hermann Park and the Texas Medical Center, hosts approximately 4,000 undergraduate and 3,000 post-graduate students. To the north in Neartown, the University of St. Thomas, founded in 1947, is Houston's only Catholic university. St. Thomas provides a liberal arts curriculum for roughly 3,000 students at its historic 19-block campus along Montrose Boulevard. In southwest Houston, Houston Baptist University (HBU), founded in 1960, offers bachelor's and graduate degrees at its Sharpstown campus. The school is affiliated with the Baptist General Convention of Texas and has a student population of approximately 3,000.

Three community college districts have campuses in and around Houston. The Houston Community College System (HCC) serves most of Houston proper; its main campus and headquarters are located in Midtown. Suburban northern and western parts of the metropolitan area are served by various campuses of the Lone Star College System, while the southeastern portion of Houston is served by San Jacinto College, and a northeastern portion is served by Lee College. The Houston Community College and Lone Star College systems are among the 10 largest institutions of higher learning in the United States.

Houston also hosts a number of graduate schools in law and healthcare. The University of Houston Law Center and Thurgood Marshall School of Law at Texas Southern University are public, ABA-accredited law schools, while the South Texas College of Law, located in Downtown, serves as a private, independent alternative. The Texas Medical Center is home to a high density of health professions schools, including two medical schools: McGovern Medical School, part of The University of Texas Health Science Center at Houston, and Baylor College of Medicine, a highly selective private institution. Prairie View A&M University's nursing school is located in the Texas Medical Center. Additionally, both Texas Southern University and the University of Houston have pharmacy schools, and the University of Houston hosts a college of optometry.

The primary network-affiliated television stations are KPRC-TV (NBC), KHOU (CBS), KTRK-TV (ABC), KRIV (Fox), KIAH (The CW), KTXH (MyNetworkTV), KXLN-DT (Univision) and KTMD-TV (Telemundo). KTRK-TV, KRIV, KTXH, KXLN-DT and KTMD-TV operate as owned-and-operated stations of their networks.

The Houston–The Woodlands–Sugar Land metropolitan area is served by one public television station and one public radio station. KUHT ("Houston Public Media") is a PBS member station and is the first public television station in the United States. Houston Public Radio is listener-funded and comprises one NPR member station, KUHF ("News 88.7"). The University of Houston System owns and holds broadcasting licenses to KUHT and KUHF. The stations broadcast from the Melcher Center for Public Broadcasting, located on the campus of the University of Houston.

Houston and its metropolitan area are served by the "Houston Chronicle", its only major daily newspaper with wide distribution. Hearst Communications, which owns and operates the "Houston Chronicle", bought the assets of the "Houston Post"—its long-time rival and main competition—when "Houston Post" ceased operations in 1995. The "Houston Post" was owned by the family of former Lieutenant Governor Bill Hobby of Houston. The only other major publication to serve the city is the "Houston Press"—which was a free alternative weekly newspaper before the destruction caused by Hurricane Harvey resulted in the publication switching to an online-only format on November 2, 2017. Other notable publications include "Houston Forward Times", "OutSmart", "and La Voz de Houston". "Houston Forward Times" is one of the largest black-owned newspapers in the metropolitan area and owned by Forward Times Publishing Company. "OutSmart" is a LGBT magazine in Houston and was ranked "Best Local Magazine" by the "Houston Press" in 2008. "La Voz de Houston" is the "Houston Chronicle"'s Spanish-language newspaper and the largest in the area.

Houston is the seat of the Texas Medical Center, which describes itself as containing the world's largest concentration of research and healthcare institutions. All 49 member institutions of the Texas Medical Center are non-profit organizations. They provide patient and preventive care, research, education, and local, national, and international community well-being. Employing more than 73,600 people, institutions at the medical center include 13 hospitals and two specialty institutions, two medical schools, four nursing schools, and schools of dentistry, public health, pharmacy, and virtually all health-related careers. It is where one of the first—and still the largest—air emergency service, Life Flight, was created, and an inter-institutional transplant program was developed. Around 2007, more heart surgeries were performed at the Texas Medical Center than anywhere else in the world.

Some of the academic and research health institutions at the center include MD Anderson Cancer Center, Baylor College of Medicine, UT Health Science Center, Memorial Hermann Hospital, Houston Methodist Hospital, Texas Children's Hospital, and University of Houston College of Pharmacy.

In the 2000s, the Baylor College of Medicine was annually considered within the top ten medical schools in the nation; likewise, the MD Anderson Cancer Center had been consistently ranked as one of the top two U.S. hospitals specializing in cancer care by "U.S. News & World Report" since 1990. The Menninger Clinic, a psychiatric treatment center, is affiliated with Baylor College of Medicine and the Houston Methodist Hospital System. With hospital locations nationwide and headquarters in Houston, the Triumph Healthcare hospital system was the third largest long term acute care provider nationally in 2005.

Houston is considered an automobile-dependent city, with an estimated 77.2% of commuters driving alone to work in 2016, up from 71.7% in 1990 and 75.6% in 2009. In 2016, another 11.4% of Houstonians carpooled to work, while 3.6% used public transit, 2.1% walked, and 0.5% bicycled. A commuting study estimated that the median length of commute in the region was in 2012. According to the 2013 American Community Survey, the average work commute in Houston (city) takes 26.3 minutes. A 1999 Murdoch University study found that Houston had both the lengthiest commute and lowest urban density of 13 large American cities surveyed, and a 2017 Arcadis study ranked Houston 22nd out of 23 American cities in transportation sustainability. Harris County is one of the largest consumers of gasoline in the United States, ranking second (behind Los Angeles County) in 2013.

Despite the region's high rate of automobile usage, attitudes towards transportation among Houstonians indicate a growing preference for walkability. A 2017 study by the Rice University Kinder Institute for Urban Research found that 56% of Harris County residents have a preference for dense housing in a mixed-use, walkable setting as opposed to single-family housing in a low-density area. A plurality of survey respondents also indicated that traffic congestion was the most significant problem facing the metropolitan area. In addition, many households in the city of Houston have no car. In 2015, 8.3 percent of Houston households lacked a car, which was virtually unchanged in 2016 (8.1 percent). The national average was 8.7 percent in 2016. Houston averaged 1.59 cars per household in 2016, compared to a national average of 1.8.

The eight-county Greater Houston metropolitan area contains over of roadway, of which 10%, or approximately , is limited-access highway. The Houston region's extensive freeway system handles over 40% of the regional daily vehicle miles traveled (VMT). Arterial roads handle an additional 40% of daily VMT, while toll roads, of which Greater Houston has , handle nearly 10%.

Greater Houston possesses a hub-and-spoke limited-access highway system, in which a number of freeways radiate outward from Downtown, with ring roads providing connections between these radial highways at intermediate distances from the city center. The city is crossed by three Interstate highways, Interstate 10, Interstate 45, and Interstate 69 (commonly known as U.S. Route 59), as well as a number of other United States routes and state highways. Major freeways in Greater Houston are often referred to by either the cardinal direction or geographic location they travel towards. Highways that follow the cardinal convention include U.S. Route 290 ("Northwest Freeway"), Interstate 45 north of Downtown ("North Freeway"), Interstate 10 east of Downtown "(East Freeway"), Texas State Highway 288 ("South" "Freeway"), and Interstate 69 south of Downtown ("Southwest Freeway"). Highways that follow the location convention include Interstate 10 west of Downtown ("Katy Freeway"), Interstate 69 north of Downtown ("Eastex Freeway"), Interstate 45 south of Downtown ("Gulf Freeway"), and Texas State Highway 225 ("La Porte" or "Pasadena Freeway").

Three loop freeways provide north–south and east–west connectivity between Greater Houston's radial highways. The innermost loop is Interstate 610, commonly known as the "Inner Loop", which encircles Downtown, the Texas Medical Center, Greenway Plaza, the cities of West University Place and Southside Place, and many core neighborhoods. The State Highway Beltway 8, often referred to as "the Beltway", forms the middle loop at a radius of roughly . A third, loop with a radius of approximately , State Highway 99 (the "Grand Parkway"), is currently under construction, with six of eleven segments completed . Completed segments D through G provide a continuous limited-access tollway connection between Sugar Land, Katy, Cypress, Spring, and Porter.

A system of toll roads, operated by the Harris County Toll Road Authority (HCTRA) and Fort Bend County Toll Road Authority (FBCTRA), provides additional options for regional commuters. The Sam Houston Tollway, which encompasses the mainlanes of Beltway 8 (as opposed to the frontage roads, which are untolled), is the longest tollway in the system, covering the entirety of the Beltway with the exception of a free section between Interstate 45 and Interstate 69 near George Bush Intercontinental Airport. The region is serviced by four spoke tollways: a set of managed lanes on the Katy Freeway; the Hardy Toll Road, which parallels Interstate 45 north of Downtown up to Spring; the Westpark Tollway, which services Houston's western suburbs out to Fulshear; and Fort Bend Parkway, which connects to Sienna Plantation. Westpark Tollway and Fort Bend Parkway are operated conjunctly with the Fort Bend County Toll Road Authority.

Greater Houston's freeway system is monitored by Houston TranStar, a partnership of four government agencies which is responsible for providing transportation and emergency management services to the region.

Greater Houston's arterial road network is established at the municipal level, with the City of Houston exercising planning control over both its incorporated area and extraterritorial jurisdiction (ETJ). Therefore, Houston exercises transportation planning authority over a area over five counties, many times larger than its corporate area. The "Major Thoroughfare and Freeway Plan", updated annually, establishes the city's street hierarchy, identifies roadways in need of widening, and proposes new roadways in unserved areas. Arterial roads are organized into four categories, in decreasing order of intensity: "major thoroughfares", "transit corridor streets", "collector streets", and "local streets". Roadway classification affects anticipated traffic volumes, roadway design, and right of way breadth. Ultimately, the system is designed to ferry traffic from neighborhood streets to major thoroughfares, which connect into the limited-access highway system. Notable arterial roads in the region include Westheimer Road, Memorial Drive, Texas State Highway 6, Farm to Market Road 1960, Bellaire Boulevard, and Telephone Road.

The Metropolitan Transit Authority of Harris County (METRO) provides public transportation in the form of buses, light rail, high-occupancy vehicle (HOV) lanes, and paratransit to fifteen municipalities throughout the Greater Houston area and parts of unincorporated Harris County. METRO's service area covers containing a population of 3.6 million.

METRO's local bus network services approximately 275,000 riders daily with a fleet of over 1,200 buses. The agency's 75 local routes contain nearly 8,900 stops and saw nearly 67 million boardings during the 2016 fiscal year. A park and ride system provides commuter bus service from 34 transit centers scattered throughout the region's suburban areas; these express buses operate independently of the local bus network and utilize the region's extensive system of HOV lanes. Downtown and the Texas Medical Center have the highest rates of transit use in the region, largely due to the park and ride system, with nearly 60% of commuters in each district utilizing public transit to get to work.

METRO began light rail service in 2004 with the opening of the north-south Red Line connecting Downtown, Midtown, the Museum District, the Texas Medical Center, and NRG Park. In the early 2010s, two additional lines—the Green Line, servicing the East End, and the Purple Line, servicing the Third Ward—opened, and the Red Line was extended northward to Northline, bringing the total length of the system to . Two light rail lines outlined in a five-line system approved by voters in a 2003 referendum have yet to be constructed. The Uptown Line, which would run along Post Oak Boulevard in Uptown, is currently under construction as a bus rapid transit line—the city's first—while the University Line has been postponed indefinitely. The light rail system saw approximately 16.8 million boardings in fiscal year 2016.

Amtrak's thrice-weekly Los Angeles–New Orleans serves Houston at a station northwest of downtown. There were 14,891 boardings and alightings in FY2008, 20,327 in FY2012, and 20,205 in FY2018.

A daily Amtrak Thruway Motorcoach connects Houston with Amtrak's Chicago–San Antonio at Longview.

Houston City Council approved the Houston Bike Plan in March 2017, at that time entering the plan into the Houston Code of Ordinances.

Houston has the largest number of bike commuters in Texas with over 160 miles of dedicated bikeways. The city is currently in the process of expanding its on and off street bikeway network. In 2015, Downtown Houston added a cycle track on Lamar Street, running from Sam Houston Park to Discovery Green. In August 2017, Houston City Council approved spending for construction of 13 additional miles of bike trails.

Houston's bicycle sharing system started service with nineteen stations in May 2012. Houston Bcycle (also known as B-Cycle), a local non-profit, runs the subscription program, supplying bicycles and docking stations, while partnering with other companies to maintain the system. The network expanded to 29 stations and 225 bicycles in 2014, registering over 43,000 checkouts of equipment during the first half of the same year. In 2017, Bcycle logged over 142,000 check outs while expanding to 56 docking stations.

The Houston Airport System, a branch of the municipal government, oversees the operation of three major public airports in the city. Two of these airports, George Bush Intercontinental Airport and William P. Hobby Airport, offer commercial aviation service to a variety of domestic and international destinations and served 55 million passengers in 2016. The third, Ellington Airport, is home to the Ellington Field Joint Reserve Base. The Federal Aviation Administration and the state of Texas selected the Houston Airport System as "Airport of the Year" in 2005, largely due to the implementation of a $3.1 billion airport improvement program for both major airports in Houston.

George Bush Intercontinental Airport (IAH), located north of Downtown Houston between Interstates 45 and 69, is the eighth busiest commercial airport in the United States (by total passengers and aircraft movements) and forty-third busiest globally. The five-terminal, five-runway, airport served 40 million passengers in 2016, including 10 million international travelers. In 2006, the United States Department of Transportation named IAH the fastest-growing of the top ten airports in the United States. The Houston Air Route Traffic Control Center is located at Bush Intercontinental.

Houston was the headquarters of Continental Airlines until its 2010 merger with United Airlines with headquarters in Chicago; regulatory approval for the merger was granted in October of that year. Bush Intercontinental is currently United Airlines' second largest hub, behind O'Hare International Airport. United Airlines' share of the Houston Airport System's commercial aviation market was nearly 60% in 2017 with 16 million enplaned passengers. In early 2007, Bush Intercontinental Airport was named a model "port of entry" for international travelers by U.S. Customs and Border Protection.

William P. Hobby Airport (HOU), known as Houston International Airport until 1967, operates primarily short- to medium-haul domestic and international flights to 60 destinations. The four-runway, facility is located approximately southeast of Downtown Houston. In 2015, Southwest Airlines launched service from a new international terminal at Hobby to several destinations in Mexico, Central America, and the Caribbean. These were the first international flights flown from Hobby since the opening of Bush Intercontinental in 1969. Houston's aviation history is showcased in the 1940 Air Terminal Museum, located in the old terminal building on the west side of the airport. In 2009, Hobby Airport was recognized with two awards for being one of the top five performing airports globally and for customer service by Airports Council International.

Houston's third municipal airport is Ellington Airport, used by the military, government (including NASA) and general aviation sectors.

The Mayor's Office of Trade and International Affairs (MOTIA) is the city's liaison to Houston's sister cities and to the national governing organization, Sister Cities International. Through their official city-to-city relationships, these volunteer associations promote people-to-people diplomacy and encourage citizens to develop mutual trust and understanding through commercial, cultural, educational, and humanitarian exchanges.




</doc>
<doc id="13776" url="https://en.wikipedia.org/wiki?curid=13776" title="Head (disambiguation)">
Head (disambiguation)

The head is the part of an animal or human that usually includes the brain, eyes, ears, nose, and mouth.

Head may also refer to:















</doc>
<doc id="13777" url="https://en.wikipedia.org/wiki?curid=13777" title="Hard disk drive">
Hard disk drive

A hard disk drive (HDD), hard disk, hard drive, or fixed disk is an electro-mechanical data storage device that uses magnetic storage to store and retrieve digital data using one or more rigid rapidly rotating platters coated with magnetic material. The platters are paired with magnetic heads, usually arranged on a moving actuator arm, which read and write data to the platter surfaces. Data is accessed in a random-access manner, meaning that individual blocks of data can be stored and retrieved in any order. HDDs are a type of non-volatile storage, retaining stored data even when powered off.

Introduced by IBM in 1956, HDDs were the dominant secondary storage device for general-purpose computers beginning in the early 1960s. HDDs maintained this position into the modern era of servers and personal computers, though personal computing devices produced in large volume, like cell phones and tablets, rely on flash products. More than 224 companies have produced HDDs historically, though after extensive industry consolidation most units are manufactured by Seagate, Toshiba, and Western Digital. HDDs dominate the volume of storage produced (exabytes per year) for servers. Though production is growing slowly (by exabytes shipped), sales revenues and unit shipments are declining because solid-state drives (SSDs) have higher data-transfer rates, higher areal storage density, better reliability, and much lower latency and access times.

The revenues for SSDs, most of which use NAND, slightly exceed those for HDDs. Flash storage products had more than twice the revenue of hard disk drives . Though SSDs have four to nine times higher cost per bit, they are replacing HDDs in applications where speed, power consumption, small size, high capacity and durability are important. Cost per bit for SSDs is falling, and the price premium over HDDs has narrowed.

The primary characteristics of an HDD are its capacity and performance. Capacity is specified in unit prefixes corresponding to powers of : a 1-terabyte (TB) drive has a capacity of gigabytes (GB; where 1 gigabyte = bytes). Typically, some of an HDD's capacity is unavailable to the user because it is used by the file system and the computer operating system, and possibly inbuilt redundancy for error correction and recovery. Also there is confusion regarding storage capacity, since capacities are stated in decimal Gigabytes (powers of 10) by HDD manufacturers, whereas some operating systems report capacities in binary Gibibytes, which results in a smaller number than advertised. Performance is specified by the time required to move the heads to a track or cylinder (average access time) adding the time it takes for the desired sector to move under the head (average latency, which is a function of the physical rotational speed in revolutions per minute), and finally the speed at which the data is transmitted (data rate).

The two most common form factors for modern HDDs are 3.5-inch, for desktop computers, and 2.5-inch, primarily for laptops. HDDs are connected to systems by standard interface cables such as PATA (Parallel ATA), SATA (Serial ATA), USB or SAS (Serial Attached SCSI) cables.

The first production IBM hard disk drive, the 350 disk storage, shipped in 1957 as a component of the IBM 305 RAMAC system. It was approximately the size of two medium-sized refrigerators and stored five million six-bit characters (3.75 megabytes) on a stack of 52 disks (100 surfaces used). The 350 had a single arm with two read/write heads, one up and one down, that moved both horizontally across a pair of platters and vertically from one set of platters to a second set. Variants of the IBM 350 were the IBM 355, IBM 7300 and IBM 1405.

In 1961 IBM announced, and in 1962 shipped, the IBM 1301 disk storage unit,which superseded
the IBM 350 and similar drives. The 1301 consisted of one (for Model 1) or two (for model 2) modules, each containg 25 platters, each platter about thick and in diameter. While the earlier IBM disk drives used only two read/write heads per arm, the 1301 used an array of 48 heads (comb), each array moving horizontally as a single unit, one head per surface used. Cylinder-mode read/write operations were supported, and the heads flew about 250 micro-inches (about 6 µm) above the platter surface. Motion of the head array depended upon a binary adder system of hydraulic actuators which assured repeatable positioning. The 1301 cabinet was about the size of three home refrigerators placed side by side, storing the equivalent of about 21 million eight-bit bytes per module. Access time was about a quarter of a second.

Also in 1962, IBM introduced the model 1311 disk drive, which was about the size of a washing machine and stored two million characters on a removable disk pack. Users could buy additional packs and interchange them as needed, much like reels of magnetic tape. Later models of removable pack drives, from IBM and others, became the norm in most computer installations and reached capacities of 300 megabytes by the early 1980s. Non-removable HDDs were called "fixed disk" drives.

In 1963 IBM introduced the 1302, with twice the track capacity and twice as many tracks per cylinder as the 1301. The 1302 had one (for Model 1) or two (for Model 2) modules, each containing a separate comb for the first 250 tracks and the last 250 tracks.

Some high-performance HDDs were manufactured with one head per track, "e.g.", Burroughs B-475 in 1964, IBM 2305 in 1970, so that no time was lost physically moving the heads to a track and the only latency was the time for the desired block of data to rotate into position under the head. Known as fixed-head or head-per-track disk drives, they were very expensive and are no longer in production.

In 1973, IBM introduced a new type of HDD code-named "Winchester". Its primary distinguishing feature was that the disk heads were not withdrawn completely from the stack of disk platters when the drive was powered down. Instead, the heads were allowed to "land" on a special area of the disk surface upon spin-down, "taking off" again when the disk was later powered on. This greatly reduced the cost of the head actuator mechanism, but precluded removing just the disks from the drive as was done with the disk packs of the day. Instead, the first models of "Winchester technology" drives featured a removable disk module, which included both the disk pack and the head assembly, leaving the actuator motor in the drive upon removal. Later "Winchester" drives abandoned the removable media concept and returned to non-removable platters.

Like the first removable pack drive, the first "Winchester" drives used platters in diameter. A few years later, designers were exploring the possibility that physically smaller platters might offer advantages. Drives with non-removable eight-inch platters appeared, and then drives that used a form factor (a mounting width equivalent to that used by contemporary floppy disk drives). The latter were primarily intended for the then-fledgling personal computer (PC) market.

As the 1980s began, HDDs were a rare and very expensive additional feature in PCs, but by the late 1980s their cost had been reduced to the point where they were standard on all but the cheapest computers.

Most HDDs in the early 1980s were sold to PC end users as an external, add-on subsystem. The subsystem was not sold under the drive manufacturer's name but under the subsystem manufacturer's name such as Corvus Systems and Tallgrass Technologies, or under the PC system manufacturer's name such as the Apple ProFile. The IBM PC/XT in 1983 included an internal 10 MB HDD, and soon thereafter internal HDDs proliferated on personal computers.

External HDDs remained popular for much longer on the Apple Macintosh. Many Macintosh computers made between 1986 and 1998 featured a SCSI port on the back, making external expansion simple. Older compact Macintosh computers did not have user-accessible hard drive bays (indeed, the Macintosh 128K, Macintosh 512K, and Macintosh Plus did not feature a hard drive bay at all), so on those models external SCSI disks were the only reasonable option for expanding upon any internal storage.

HDD improvements have been driven by increasing areal density, listed in the table above. Applications expanded through the 2000s, from the mainframe computers of the late 1950s to most mass storage applications including computers and consumer applications such as storage of entertainment content.

In the 2000s and 2010s, NAND began supplanting HDDs in applications requiring portability or high performance. NAND performance is improving faster than HDDs, and applications for HDDs are eroding. In 2018, the largest hard drive had a capacity of 15 TB, while the largest capacity SSD had a capacity of 100 TB. , HDDs were forecast to reach 100 TB capacities around 2025, but the expected pace of improvement was pared back to 50 TB by 2026. Smaller form factors, 1.8-inches and below, were discontinued around 2010. The cost of solid-state storage (NAND), represented by Moore's law, is improving faster than HDDs. NAND has a higher price elasticity of demand than HDDs, and this drives market growth. During the late 2000s and 2010s, the product life cycle of HDDs entered a mature phase, and slowing sales may indicate the onset of the declining phase.

The 2011 Thailand floods damaged the manufacturing plants and impacted hard disk drive cost adversely between 2011 and 2013.

A modern HDD records data by magnetizing a thin film of ferromagnetic material on both sides of a disk. Sequential changes in the direction of magnetization represent binary data bits. The data is read from the disk by detecting the transitions in magnetization. User data is encoded using an encoding scheme, such as run-length limited encoding, which determines how the data is represented by the magnetic transitions.

A typical HDD design consists of a "" that holds flat circular disks, called platters, which hold the recorded data. The platters are made from a non-magnetic material, usually aluminum alloy, glass, or ceramic. They are coated with a shallow layer of magnetic material typically 10–20 nm in depth, with an outer layer of carbon for protection. For reference, a standard piece of copy paper is thick.

The platters in contemporary HDDs are spun at speeds varying from 4,200 RPM in energy-efficient portable devices, to 15,000 rpm for high-performance servers. The first HDDs spun at 1,200 rpm and, for many years, 3,600 rpm was the norm. , the platters in most consumer-grade HDDs spin at 5,400 or 7,200 RPM.

Information is written to and read from a platter as it rotates past devices called read-and-write heads that are positioned to operate very close to the magnetic surface, with their flying height often in the range of tens of nanometers. The read-and-write head is used to detect and modify the magnetization of the material passing immediately under it.

In modern drives, there is one head for each magnetic platter surface on the spindle, mounted on a common arm. An actuator arm (or access arm) moves the heads on an arc (roughly radially) across the platters as they spin, allowing each head to access almost the entire surface of the platter as it spins. The arm is moved using a voice coil actuator or in some older designs a stepper motor. Early hard disk drives wrote data at some constant bits per second, resulting in all tracks having the same amount of data per track but modern drives (since the 1990s) use zone bit recording – increasing the write speed from inner to outer zone and thereby storing more data per track in the outer zones.

In modern drives, the small size of the magnetic regions creates the danger that their magnetic state might be lost because of thermal effects⁠ ⁠— thermally induced magnetic instability which is commonly known as the "superparamagnetic limit". To counter this, the platters are coated with two parallel magnetic layers, separated by a three-atom layer of the non-magnetic element ruthenium, and the two layers are magnetized in opposite orientation, thus reinforcing each other. Another technology used to overcome thermal effects to allow greater recording densities is perpendicular recording, first shipped in 2005, and used in certain HDDs.

In 2004, a higher-density recording media was introduced, consisting of coupled soft and hard magnetic layers. So-called "exchange spring media" magnetic storage technology, also known as "exchange coupled composite media", allows good writability due to the write-assist nature of the soft layer. However, the thermal stability is determined only by the hardest layer and not influenced by the soft layer.

A typical HDD has two electric motors: a spindle motor that spins the disks and an actuator (motor) that positions the read/write head assembly across the spinning disks. The disk motor has an external rotor attached to the disks; the stator windings are fixed in place. Opposite the actuator at the end of the head support arm is the read-write head; thin printed-circuit cables connect the read-write heads to amplifier electronics mounted at the pivot of the actuator. The head support arm is very light, but also stiff; in modern drives, acceleration at the head reaches 550 "g".

The "" is a permanent magnet and moving coil motor that swings the heads to the desired position. A metal plate supports a squat neodymium-iron-boron (NIB) high-flux magnet. Beneath this plate is the moving coil, often referred to as the "voice coil" by analogy to the coil in loudspeakers, which is attached to the actuator hub, and beneath that is a second NIB magnet, mounted on the bottom plate of the motor (some drives have only one magnet).

The voice coil itself is shaped rather like an arrowhead and is made of doubly coated copper magnet wire. The inner layer is insulation, and the outer is thermoplastic, which bonds the coil together after it is wound on a form, making it self-supporting. The portions of the coil along the two sides of the arrowhead (which point to the center of the actuator bearing) then interact with the magnetic field of the fixed magnet. Current flowing radially outward along one side of the arrowhead and radially inward on the other produces the tangential force. If the magnetic field were uniform, each side would generate opposing forces that would cancel each other out. Therefore, the surface of the magnet is half north pole and half south pole, with the radial dividing line in the middle, causing the two sides of the coil to see opposite magnetic fields and produce forces that add instead of canceling. Currents along the top and bottom of the coil produce radial forces that do not rotate the head.

The HDD's electronics control the movement of the actuator and the rotation of the disk and perform reads and writes on demand from the disk controller. Feedback of the drive electronics is accomplished by means of special segments of the disk dedicated to servo feedback. These are either complete concentric circles (in the case of dedicated servo technology) or segments interspersed with real data (in the case of embedded servo technology). The servo feedback optimizes the signal-to-noise ratio of the GMR sensors by adjusting the voice coil of the actuated arm. The spinning of the disk also uses a servo motor. Modern disk firmware is capable of scheduling reads and writes efficiently on the platter surfaces and remapping sectors of the media which have failed.

Modern drives make extensive use of error correction codes (ECCs), particularly Reed–Solomon error correction. These techniques store extra bits, determined by mathematical formulas, for each block of data; the extra bits allow many errors to be corrected invisibly. The extra bits themselves take up space on the HDD, but allow higher recording densities to be employed without causing uncorrectable errors, resulting in much larger storage capacity. For example, a typical 1 TB hard disk with 512-byte sectors provides additional capacity of about 93 GB for the ECC data.

In the newest drives, , low-density parity-check codes (LDPC) were supplanting Reed–Solomon; LDPC codes enable performance close to the Shannon Limit and thus provide the highest storage density available.

Typical hard disk drives attempt to "remap" the data in a physical sector that is failing to a spare physical sector provided by the drive's "spare sector pool" (also called "reserve pool"), while relying on the ECC to recover stored data while the number of errors in a bad sector is still low enough. The S.M.A.R.T (Self-Monitoring, Analysis and Reporting Technology) feature counts the total number of errors in the entire HDD fixed by ECC (although not on all hard drives as the related S.M.A.R.T attributes "Hardware ECC Recovered" and "Soft ECC Correction" are not consistently supported), and the total number of performed sector remappings, as the occurrence of many such errors may predict an HDD failure.

The "No-ID Format", developed by IBM in the mid-1990s, contains information about which sectors are bad and where remapped sectors have been located.

Only a tiny fraction of the detected errors end up as not correctable. Examples of specified uncorrected bit read error rates include:
Within a given manufacturers model the uncorrected bit error rate is typically the same regardless of capacity of the drive.

The worst type of errors are silent data corruptions which are errors undetected by the disk firmware or the host operating system; some of these errors may be caused by hard disk drive malfunctions while others originate elsewhere in the connection between the drive and the host.

The rate of areal density advancement was similar to Moore's law (doubling every two years) through 2010: 60% per year during 1988–1996, 100% during 1996–2003 and 30% during 2003–2010. Speaking in 1997, Gordon Moore called the increase "flabbergasting", while observing later that growth cannot continue forever. Price improvement decelerated to −12% per year during 2010–2017, as the growth of areal density slowed. The rate of advancement for areal density slowed to 10% per year during 2010–2016, and there was difficulty in migrating from perpendicular recording to newer technologies.

As bit cell size decreases, more data can be put onto a single drive platter. In 2013, a production desktop 3 TB HDD (with four platters) would have had an areal density of about 500 Gbit/in which would have amounted to a bit cell comprising about 18 magnetic grains (11 by 1.6 grains). Since the mid-2000s areal density progress has been challenged by a superparamagnetic trilemma involving grain size, grain magnetic strength and ability of the head to write. In order to maintain acceptable signal to noise smaller grains are required; smaller grains may self-reverse (electrothermal instability) unless their magnetic strength is increased, but known write head materials are unable to generate a strong enough magnetic field sufficient to write the medium in the increasingly smaller space taken by grains.

Magnetic storage technologies are being developed to address this trilemma, and compete with flash memory–based solid-state drives (SSDs). In 2013, Seagate introduced shingled magnetic recording (SMR), intended as something of a "stopgap" technology between PMR and Seagate's intended successor heat-assisted magnetic recording (HAMR), SMR utilises overlapping tracks for increased data density, at the cost of design complexity and lower data access speeds (particularly write speeds and random access 4k speeds). By contrast, Western Digital focused on developing ways to seal helium-filled drives instead of the usual filtered air. This reduces turbulence and friction, and fits more platters into the same enclosure space, though helium gas is notoriously difficult to prevent escaping.

Other recording technologies are under development , including Seagate's heat-assisted magnetic recording (HAMR). HAMR requires a different architecture with redesigned media and read/write heads, new lasers, and new near-field optical transducers. HAMR is expected to ship commercially in late 2020 or 2021. Technical issues delayed the introduction of HAMR by a decade, from earlier projections of 2009, 2015, 2016, and the first half of 2019. Some drives have adopted dual independent actuator arms to increase read/write speeds and compete with SSDs. HAMR's planned successor, bit-patterned recording (BPR), has been removed from the roadmaps of Western Digital and Seagate. Western Digital's microwave-assisted magnetic recording (MAMR), is expected to be shipped commercially in 2021, with sampling in 2020. Two-dimensional magnetic recording (TDMR) and "current perpendicular to plane" giant magnetoresistance (CPP/GMR) heads have appeared in research papers. A 3D-actuated vacuum drive (3DHD) concept has been proposed.

The rate of areal density growth has dropped below the historical Moore's law rate of 40% per year. Depending upon assumptions on feasibility and timing of these technologies, Seagate forecasts that areal density will grow 20% per year during 2020–2034.

The highest-capacity desktop HDDs had 16 TB in late 2019.

The capacity of a hard disk drive, as reported by an operating system to the end user, is smaller than the amount stated by the manufacturer for several reasons: the operating system using some space, use of some space for data redundancy, and space use for file system structures. Also the difference in capacity reported in SI decimal prefixed units vs. binary prefixes can lead to a false impression of missing capacity.

Modern hard disk drives appear to their host controller as a contiguous set of logical blocks, and the gross drive capacity is calculated by multiplying the number of blocks by the block size. This information is available from the manufacturer's product specification, and from the drive itself through use of operating system functions that invoke low-level drive commands.

The gross capacity of older HDDs is calculated as the product of the number of cylinders per recording zone, the number of bytes per sector (most commonly 512), and the count of zones of the drive. Some modern SATA drives also report cylinder-head-sector (CHS) capacities, but these are not physical parameters because the reported values are constrained by historic operating system interfaces. The C/H/S scheme has been replaced by logical block addressing (LBA), a simple linear addressing scheme that locates blocks by an integer index, which starts at LBA 0 for the first block and increments thereafter. When using the C/H/S method to describe modern large drives, the number of heads is often set to 64, although a typical hard disk drive, , has between one and four platters.

In modern HDDs, spare capacity for defect management is not included in the published capacity; however, in many early HDDs a certain number of sectors were reserved as spares, thereby reducing the capacity available to the operating system.

For RAID subsystems, data integrity and fault-tolerance requirements also reduce the realized capacity. For example, a RAID 1 array has about half the total capacity as a result of data mirroring, while a RAID 5 array with drives loses of capacity (which equals to the capacity of a single drive) due to storing parity information. RAID subsystems are multiple drives that appear to be one drive or more drives to the user, but provide fault tolerance. Most RAID vendors use checksums to improve data integrity at the block level. Some vendors design systems using HDDs with sectors of 520 bytes to contain 512 bytes of user data and eight checksum bytes, or by using separate 512-byte sectors for the checksum data.

Some systems may use hidden partitions for system recovery, reducing the capacity available to the end user.

Data is stored on a hard drive in a series of logical blocks. Each block is delimited by markers identifying its start and end, error detecting and correcting information, and space between blocks to allow for minor timing variations. These blocks often contained 512 bytes of usable data, but other sizes have been used. As drive density increased, an initiative known as Advanced Format extended the block size to 4096 bytes of usable data, with a resulting significant reduction in the amount of disk space used for block headers, error checking data, and spacing.

The process of initializing these logical blocks on the physical disk platters is called "low-level formatting", which is usually performed at the factory and is not normally changed in the field. "High-level formatting" writes data structures used by the operating system to organize data files on the disk. This includes writing partition and file system structures into selected logical blocks. For example, some of the disk space will be used to hold a directory of disk file names and a list of logical blocks associated with a particular file.

Examples of partition mapping scheme include Master boot record (MBR) and GUID Partition Table (GPT). Examples of data structures stored on disk to retrieve files include the File Allocation Table (FAT) in the DOS file system and inodes in many UNIX file systems, as well as other operating system data structures (also known as metadata). As a consequence, not all the space on an HDD is available for user files, but this system overhead is usually small compared with user data.

The total capacity of HDDs is given by manufacturers using SI decimal prefixes such as gigabytes (1 GB = 1,000,000,000 bytes) and terabytes (1 TB = 1,000,000,000,000 bytes). This practice dates back to the early days of computing; by the 1970s, "million", "mega" and "M" were consistently used in the decimal sense for drive capacity. However, capacities of memory are quoted using a binary interpretation of the prefixes, i.e. using powers of 1024 instead of 1000.

Software reports hard disk drive or memory capacity in different forms using either decimal or binary prefixes. The Microsoft Windows family of operating systems uses the binary convention when reporting storage capacity, so an HDD offered by its manufacturer as a 1 TB drive is reported by these operating systems as a 931 GB HDD. Mac OS X 10.6 ("Snow Leopard") uses decimal convention when reporting HDD capacity. The default behavior of the command-line utility on Linux is to report the HDD capacity as a number of 1024-byte units.

The difference between the decimal and binary prefix interpretation caused some consumer confusion and led to class action suits against HDD manufacturers. The plaintiffs argued that the use of decimal prefixes effectively misled consumers while the defendants denied any wrongdoing or liability, asserting that their marketing and advertising complied in all respects with the law and that no class member sustained any damages or injuries.

HDD price per byte improved at the rate of −40% per year during 1988–1996, −51% per year during 1996–2003 and −34% per year during 2003–2010. The price improvement decelerated to −13% per year during 2011–2014, as areal density increase slowed and the 2011 Thailand floods damaged manufacturing facilities and have held at -11% per year during 2010–2017.

The Federal Reserve Board has published a quality-adjusted price index for large-scale enterprise storage systems including three or more enterprise HDDs and associated controllers, racks and cables. Prices for these large-scale storage systems improved at the rate of ‒30% per year during 2004–2009 and ‒22% per year during 2009–2014.

IBM's first hard disk drive, the IBM 350, used a stack of fifty 24-inch platters, stored 3.75 MB of data (approximately the size of one modern digital picture), and was of a size comparable to two large refrigerators. In 1962, IBM introduced its model 1311 disk, which used six 14-inch (nominal size) platters in a removable pack and was roughly the size of a washing machine. This became a standard platter size for many years, used also by other manufacturers. The IBM 2314 used platters of the same size in an eleven-high pack and introduced the "drive in a drawer" layout. sometimes called the"pizza oven", although the "drawer" was not the complete drive. Into the 1970s HDDs were offered in standalone cabinets of varying dimensions containing from one to four HDDs.

Beginning in the late 1960s drives were offered that fit entirely into a chassis that would mount in a 19-inch rack. Digital's RK05 and RL01 were early examples using single 14-inch platters in removable packs, the entire drive fitting in a 10.5-inch-high rack space (six rack units). In the mid-to-late 1980s the similarly sized Fujitsu Eagle, which used (coincidentally) 10.5-inch platters, was a popular product.

With increasing sales of microcomputers having built in floppy-disk drives (FDDs), HDDs that would fit to the FDD mountings became desirable. Starting with the Shugart Associates SA1000 HDD "Form factors", initially followed those of 8-inch, 5½-inch, and 3½-inch floppy disk drives. Although referred to by these nominal sizes, the actual sizes for those three drives respectively are 9.5″, 5.75″ and 4″ wide. Because there were no smaller floppy disk drives, smaller HDD form factors developed from product offerings or industry standards. 2½-inch drives are actually 2.75″ wide.

, 2½-inch and 3½-inch hard disks are the most popular sizes. By 2009, all manufacturers had discontinued the development of new products for the 1.3-inch, 1-inch and 0.85-inch form factors due to falling prices of flash memory, which has no moving parts. While nominal sizes are in inches, actual dimensions are specified in millimeters.

The factors that limit the time to access the data on an HDD are mostly related to the mechanical nature of the rotating disks and moving heads, including:

Delay may also occur if the drive disks are stopped to save energy.

Defragmentation is a procedure used to minimize delay in retrieving data by moving related items to physically proximate areas on the disk. Some computer operating systems perform defragmentation automatically. Although automatic defragmentation is intended to reduce access delays, performance will be temporarily reduced while the procedure is in progress.

Time to access data can be improved by increasing rotational speed (thus reducing latency) or by reducing the time spent seeking. Increasing areal density increases throughput by increasing data rate and by increasing the amount of data under a set of heads, thereby potentially reducing seek activity for a given amount of data. The time to access data has not kept up with throughput increases, which themselves have not kept up with growth in bit density and storage capacity.

, a typical 7,200-rpm desktop HDD has a sustained "disk-to-buffer" data transfer rate up to 1,030 Mbit/s. This rate depends on the track location; the rate is higher for data on the outer tracks (where there are more data sectors per rotation) and lower toward the inner tracks (where there are fewer data sectors per rotation); and is generally somewhat higher for 10,000-rpm drives. A current widely used standard for the "buffer-to-computer" interface is 3.0 Gbit/s SATA, which can send about 300 megabyte/s (10-bit encoding) from the buffer to the computer, and thus is still comfortably ahead of today's disk-to-buffer transfer rates. Data transfer rate (read/write) can be measured by writing a large file to disk using special file generator tools, then reading back the file. Transfer rate can be influenced by file system fragmentation and the layout of the files.

HDD data transfer rate depends upon the rotational speed of the platters and the data recording density. Because heat and vibration limit rotational speed, advancing density becomes the main method to improve sequential transfer rates. Higher speeds require a more powerful spindle motor, which creates more heat. While areal density advances by increasing both the number of tracks across the disk and the number of sectors per track, only the latter increases the data transfer rate for a given rpm. Since data transfer rate performance tracks only one of the two components of areal density, its performance improves at a lower rate.

Other performance considerations include quality-adjusted price, power consumption, audible noise, and both operating and non-operating shock resistance.

Current hard drives connect to a computer over one of several bus types, including parallel ATA, Serial ATA , SCSI, Serial Attached SCSI (SAS), and Fibre Channel. Some drives, especially external portable drives, use IEEE 1394, or USB. All of these interfaces are digital; electronics on the drive process the analog signals from the read/write heads. Current drives present a consistent interface to the rest of the computer, independent of the data encoding scheme used internally, and independent of the physical number of disks and heads within the drive.

Typically a DSP in the electronics inside the drive takes the raw analog voltages from the read head and uses PRML and Reed–Solomon error correction to decode the data, then sends that data out the standard interface. That DSP also watches the error rate detected by error detection and correction, and performs bad sector remapping, data collection for Self-Monitoring, Analysis, and Reporting Technology, and other internal tasks.

Modern interfaces connect the drive to the host interface with a single data/control cable. Each drive also has an additional power cable, usually direct to the power supply unit. Older interfaces had separate cables for data signals and for drive control signals.

Due to the extremely close spacing between the heads and the disk surface, HDDs are vulnerable to being damaged by a head crash – a failure of the disk in which the head scrapes across the platter surface, often grinding away the thin magnetic film and causing data loss. Head crashes can be caused by electronic failure, a sudden power failure, physical shock, contamination of the drive's internal enclosure, wear and tear, corrosion, or poorly manufactured platters and heads.

The HDD's spindle system relies on air density inside the disk enclosure to support the heads at their proper flying height while the disk rotates. HDDs require a certain range of air densities to operate properly. The connection to the external environment and density occurs through a small hole in the enclosure (about 0.5 mm in breadth), usually with a filter on the inside (the "breather filter"). If the air density is too low, then there is not enough lift for the flying head, so the head gets too close to the disk, and there is a risk of head crashes and data loss. Specially manufactured sealed and pressurized disks are needed for reliable high-altitude operation, above about . Modern disks include temperature sensors and adjust their operation to the operating environment. Breather holes can be seen on all disk drives – they usually have a sticker next to them, warning the user not to cover the holes. The air inside the operating drive is constantly moving too, being swept in motion by friction with the spinning platters. This air passes through an internal recirculation (or "recirc") filter to remove any leftover contaminants from manufacture, any particles or chemicals that may have somehow entered the enclosure, and any particles or outgassing generated internally in normal operation. Very high humidity present for extended periods of time can corrode the heads and platters.

For giant magnetoresistive (GMR) heads in particular, a minor head crash from contamination (that does not remove the magnetic surface of the disk) still results in the head temporarily overheating, due to friction with the disk surface, and can render the data unreadable for a short period until the head temperature stabilizes (so called "thermal asperity", a problem which can partially be dealt with by proper electronic filtering of the read signal).

When the logic board of a hard disk fails, the drive can often be restored to functioning order and the data recovered by replacing the circuit board with one of an identical hard disk. In the case of read-write head faults, they can be replaced using specialized tools in a dust-free environment. If the disk platters are undamaged, they can be transferred into an identical enclosure and the data can be copied or cloned onto a new drive. In the event of disk-platter failures, disassembly and imaging of the disk platters may be required. For logical damage to file systems, a variety of tools, including fsck on UNIX-like systems and CHKDSK on Windows, can be used for data recovery. Recovery from logical damage can require file carving.

A common expectation is that hard disk drives designed and marketed for server use will fail less frequently than consumer-grade drives usually used in desktop computers. However, two independent studies by Carnegie Mellon University and Google found that the "grade" of a drive does not relate to the drive's failure rate.

A 2011 summary of research, into SSD and magnetic disk failure patterns by Tom's Hardware summarized research findings as follows:

To minimize cost and overcome failures of individual HDDs, storage systems providers rely on redundant HDD arrays. HDDs that fail are replaced on an ongoing basis.





More than 200 companies have manufactured HDDs over time, but consolidations have concentrated production to just three manufacturers today: Western Digital, Seagate, and Toshiba. Production is mainly in the Pacific rim.

Worldwide revenue for disk storage declined eight percent per year, from a peak of $38 billion in 2012 to $22 billion (estimated) in 2019. Production of HDD storage grew 15% per year during 2011–2017, from 335 to 780 exabytes per year. HDD shipments declined seven percent per year during this time period, from 620 to 406 million units. HDD shipments were projected to drop by 18% during 2018–2019, from 375 million to 309 million units. In 2018, Seagate has 40% of unit shipments, Western Digital has 37% of unit shipments, while Toshiba has 23% of unit shipments. The average sales price for the two largest manufacturers was $60 per unit in 2015.

HDDs are being superseded by solid-state drives (SSDs) in markets where their higher speed (up to 4950 megabytes per second for M.2 (NGFF) NVME SSDs or 2500 megabytes per second for PCIe expansion card drives), ruggedness, and lower power are more important than price, since the bit cost of SSDs is four to nine times higher than HDDs. , HDDs are reported to have a failure rate of 2–9% per year, while SSDs have fewer failures: 1–3% per year. However, SSDs have more un-correctable data errors than HDDs.

SSDs offer larger capacities (up to 100 TB) than the largest HDD and/or higher storage densities (100 TB and 30 TB SSDs are housed in 2.5 inch HDD cases but with the same height as a 3.5-inch HDD), although their cost remains prohibitive.

A laboratory demonstration of a 1.33-Tb 3D NAND chip with 96 layers (NAND commonly used in solid state drives (SSDs)) had 5.5 Tbit/in , while the maximum areal density for HDDs is 1.5 Tbit/in. The areal density of flash memory is doubling every two years, similar to Moore's law (40% per year) and faster than the 10–20% per year for HDDs. , the maximum capacity was 16 terabytes for an HDD, and 100 terabytes for an SSD. HDDs were used in 70% of the desktop and notebook computers produced in 2016, and SSDs were used in 30%. The usage share of HDDs is declining and could drop below 50% in 2018–2019 according to one forecast, because SSDs are replacing smaller-capacity (less than one-terabyte) HDDs in desktop and notebook computers and MP3 players.

The market for silicon-based flash memory (NAND) chips, used in SSDs and other applications, is growing faster than for HDDs. Worldwide NAND revenue grew 16% per year from $22 billion to $57 billion during 2011–2017, while production grew 45% per year from 19 exabytes to 175 exabytes.

External hard disk drives typically connect via USB; variants using USB 2.0 interface generally have slower data transfer rates when compared to internally mounted hard drives connected through SATA. Plug and play drive functionality offers system compatibility and features large storage options and portable design. , available capacities for external hard disk drives ranged from 500 GB to 10 TB.

External hard disk drives are usually available as assembled integrated products but may be also assembled by combining an external enclosure (with USB or other interface) with a separately purchased drive. They are available in 2.5-inch and 3.5-inch sizes; 2.5-inch variants are typically called "portable external drives", while 3.5-inch variants are referred to as "desktop external drives". "Portable" drives are packaged in smaller and lighter enclosures than the "desktop" drives; additionally, "portable" drives use power provided by the USB connection, while "desktop" drives require external power bricks.

Features such as encryption, biometric security or multiple interfaces (for example, FireWire) are available at a higher cost. There are pre-assembled external hard disk drives that, when taken out from their enclosures, cannot be used internally in a laptop or desktop computer due to embedded USB interface on their printed circuit boards, and lack of SATA (or Parallel ATA) interfaces.




</doc>
<doc id="13782" url="https://en.wikipedia.org/wiki?curid=13782" title="Hebrew calendar">
Hebrew calendar

The Hebrew calendar (Hebrew: , ), also called Jewish calendar, is a lunisolar calendar used today predominantly for Jewish religious observances. It determines the dates for Jewish holidays and the appropriate public reading of Torah portions, "yahrzeits" (dates to commemorate the death of a relative), and daily Psalm readings, among many ceremonial uses. In Israel, it is used for religious purposes, provides a time frame for agriculture and is an official calendar for civil purposes, although the latter usage has been steadily declining in favor of the Gregorian calendar.

The present Hebrew calendar is the product of evolution, including a Babylonian influence. Until the Tannaitic period (approximately 10–220 CE), the calendar employed a new crescent moon, with an additional month normally added every two or three years to correct for the difference between twelve lunar months and the solar year. The year in which it was added was based on observation of natural agriculture-related events in ancient Israel. Through the Amoraic period (200–500 CE) and into the Geonic period, this system was gradually displaced by the mathematical rules used today. The principles and rules were fully codified by Maimonides in the in the 12th century. Maimonides' work also replaced counting "years since the destruction of the Temple" with the modern creation-era .

The Hebrew lunar year is about eleven days shorter than the solar year and uses the 19-year Metonic cycle to bring it into line with the solar year, with the addition of an intercalary month every two or three years, for a total of seven times per 19 years. Even with this intercalation, the average Hebrew calendar year is longer by about 6 minutes and 40 seconds than the current mean tropical year, so that every 217 years the Hebrew calendar will fall a day behind the current mean tropical year; and about every 238 years it will fall a day behind the mean Gregorian calendar year.

The era used since the Middle Ages is the epoch (Latin for "in the year of the world"; , "from the creation of the world"). As with (A.D. or AD), the words or abbreviation for (A.M. or AM) for the era should properly "precede" the date rather than follow it. 

AM began at sunset on and will end at sunset on .

The Jewish day is of no fixed length. Based on the classic rabbinic interpretation of Genesis ("There was evening and there was morning, one day"), a day in the rabbinic Hebrew calendar runs from sunset (the start of "the evening") to the next sunset. The same definition appears in the Bible in Leviticus 23:32, where the holiday of Yom Kippur is defined as lasting "from evening to evening". Halachically, a day ends and a new one starts when three stars are visible in the sky. The time between true sunset and the time when the three stars are visible (known as 'tzait ha'kochavim') is known as 'bein hashmashot', and there are differences of opinion as to which day it falls into for some uses. This may be relevant, for example, in determining the date of birth of a child born during that gap.

There is no clock in the Jewish scheme, so that the local civil clock is used. Though the civil clock, including the one in use in Israel, incorporates local adoptions of various conventions such as time zones, standard times and daylight saving, these have no place in the Jewish scheme. The civil clock is used only as a reference point – in expressions such as: "Shabbat starts at ...". The steady progression of sunset around the world and seasonal changes results in gradual civil time changes from one day to the next based on observable astronomical phenomena (the sunset) and not on man-made laws and conventions.

In Judaism, an hour is defined as 1/12 of the time from sunrise to sunset, so an hour can be less than 60 minutes in winter, and more than 60 minutes in summer. This proportional hour is known as a "sha'ah z'manit" (lit. a time-related hour). A Jewish hour is divided into 1080 "halakim" (singular: "helek") or parts. A part is 3⅓ seconds or / minute. The ultimate ancestor of the helek was a small Babylonian time period called a "barleycorn", itself equal to / of a Babylonian "time degree" (1° of celestial rotation). These measures are not generally used for everyday purposes.

Instead of the international date line convention, there are varying opinions as to where the day changes. One opinion uses the antimeridian of Jerusalem (located at 144°47' W, passing through eastern Alaska). Other opinions exist as well. (See International date line in Judaism.)

The weekdays start with Sunday (day 1, or "Yom Rishon") and proceed to Saturday (day 7), Shabbat. Since some calculations use division, a remainder of 0 signifies Saturday.

While calculations of days, months and years are based on fixed hours equal to / of a day, the beginning of each "halachic" day is based on the local time of sunset. The end of the Shabbat and other Jewish holidays is based on nightfall ("Tzeth haKochabim") which occurs some amount of time, typically 42 to 72 minutes, after sunset. According to Maimonides, nightfall occurs when three medium-sized stars become visible after sunset. By the 17th century, this had become three second-magnitude stars. The modern definition is when the center of the sun is 7° below the geometric (airless) horizon, somewhat later than civil twilight at 6°. The beginning of the daytime portion of each day is determined both by dawn and sunrise. Most "halachic" times are based on some combination of these four times and vary from day to day throughout the year and also vary significantly depending on location. The daytime hours are often divided into "Sha'oth Zemaniyoth" or "Halachic hours" by taking the time between sunrise and sunset or between dawn and nightfall and dividing it into 12 equal hours. The nighttime hours are similarly divided into 12 equal portions, albeit a different amount of time than the "hours" of the daytime. The earliest and latest times for Jewish services, the latest time to eat chametz on the day before Passover and many other rules are based on "Sha'oth Zemaniyoth". For convenience, the modern day using "Sha'oth Zemaniyoth" is often discussed as if sunset were at 6:00 pm, sunrise at 6:00 am and each hour were equal to a fixed hour. For example, "halachic" noon may be after 1:00 pm in some areas during daylight saving time. Within the Mishnah, however, the numbering of the hours starts with the "first" hour after the start of the day.

The Hebrew week (, ) is a cycle of seven days, mirroring the seven-day period of the Book of Genesis in which the world is created. Each day of the week runs from sunset to the following sunset and is figured locally. The weekly cycle, which runs concurrently with but independently of the monthly and annual cycles. 

The names for the days of the week are simply the day number within the week, with Shabbat being the seventh day. In Hebrew, these names may be abbreviated using the numerical value of the Hebrew letters, for example ("Day 1", or Yom Rishon ()):


The names of the days of the week are modeled on the seven days mentioned in the creation story (). For example, "... And there was evening and there was morning, a second day" corresponds to "Yom Sheni" meaning "second day". (However, for days 1, 6, and 7 the modern name differs slightly from the version in Genesis.)

The seventh day, Shabbat, as its Hebrew name indicates, is a day of rest in Judaism. In Talmudic Hebrew, the word "Shabbat" () can also mean "week", so that in ritual liturgy a phrase like "Yom Reviʻi beShabbat" means "the fourth day in the week".

The period from 1 Adar (or Adar II, in leap years) to 29 Marcheshvan contains all of the festivals specified in the Bible – Pesach (15 Nisan), Shavuot (6 Sivan), Rosh Hashanah (1 Tishrei), Yom Kippur (10 Tishrei), Sukkot (15 Tishrei), and Shemini Atzeret (22 Tishrei). This period is fixed, during which no adjustments are made.
There are additional rules in the Hebrew calendar to prevent certain holidays from falling on certain days of the week. (See Rosh Hashanah postponement rules, below.) These rules are implemented by adding an extra day to Marcheshvan (making it 30 days long) or by removing one day from Kislev (making it 29 days long). Accordingly, a common Hebrew calendar year can have a length of 353, 354 or 355 days, while a leap Hebrew calendar year can have a length of 383, 384 or 385 days.

The Hebrew calendar is a lunisolar calendar, meaning that months are based on lunar months, but years are based on solar years. The calendar year features twelve lunar months of twenty-nine or thirty days, with an intercalary lunar month added periodically to synchronize the twelve lunar cycles with the longer solar year. (These extra months are added seven times every nineteen years. See Leap months, below.) The beginning of each Jewish lunar month is based on the appearance of the new moon. Although originally the new lunar crescent had to be observed and certified by witnesses, the moment of the true new moon is now approximated arithmetically as the molad, which is the mean new moon to a precision of one part.

The mean period of the lunar month (precisely, the synodic month) is very close to 29.5 days. Accordingly, the basic Hebrew calendar year is one of twelve lunar months alternating between 29 and 30 days:

In leap years (such as 5779) an additional month, Adar I (30 days) is added after Shevat, while the regular Adar is referred to as "Adar II."

The insertion of the leap month mentioned above is based on the requirement that Passover—the festival celebrating the Exodus from Egypt, which took place in the spring—always occurs in the [northern hemisphere's] spring season. Since the adoption of a fixed calendar, intercalations in the Hebrew calendar have been assigned to fixed points in a 19-year cycle. Prior to this, the intercalation was determined empirically.

Maimonides, discussing the calendrical rules in his Mishneh Torah (1178), notes: "By how much does the solar year exceed the lunar year? By approximately 11 days. Therefore, whenever this excess accumulates to about 30 days, or a little more or less, one month is added and the particular year is made to consist of 13 months, and this is the so-called embolismic (intercalated) year. For the year could not consist of twelve months plus so-and-so many days, since it is said: throughout the months of the year (), which implies that we should count the year by months and not by days."

The Bible does not directly mention the addition of "embolismic" or intercalary months. However, without the insertion of embolismic months, Jewish festivals would gradually shift outside of the seasons required by the Torah. This has been ruled as implying a requirement for the insertion of embolismic months to reconcile the lunar cycles to the seasons, which are integral to solar yearly cycles.

In a regular ("kesidran") year, Marcheshvan has 29 days and Kislev has 30 days. However, because of the Rosh Hashanah postponement rules (see below) Kislev may lose a day to have 29 days, and the year is called a short ("chaser") year, or Marcheshvan may acquire an additional day to have 30 days, and the year is called a full ("maleh") year. The calendar rules have been designed to ensure that Rosh Hashanah does not fall on a Sunday, Wednesday or Friday. This is to ensure that Yom Kippur does not directly precede or follow Shabbat, which would create practical difficulties, and that Hoshana Rabbah is not on a Shabbat, in which case certain ceremonies would be lost for a year.

The 12 lunar months of the Hebrew calendar are the normal months from new moon to new moon: the year normally contains twelve months averaging 29.52 days each. The discrepancy compared to the mean synodic month of 29.53 days is due to Adar I in a leap year always having thirty days. This means that the calendar year normally contains 354 days, roughly 11 days shorter than the solar year.

Traditionally, for the Babylonian and Hebrew lunisolar calendars, the years 3, 6, 8, 11, 14, 17, and 19 are the long (13-month) years of the Metonic cycle. This cycle forms the basis of the Christian ecclesiastical calendar and the Hebrew calendar and is used for the computation of the date of Easter each year.

During leap years Adar I (or Adar Aleph – "first Adar") is added before the regular Adar. Adar I is actually considered to be the extra month, and has 30 days. Adar II (or Adar Bet – "second Adar") is the "real" Adar, and has the usual 29 days. For this reason, holidays such as Purim are observed in Adar II, not Adar I.

The Hebrew calendar year conventionally begins on Rosh Hashanah. However, other dates serve as the beginning of the year for different religious purposes.

There are three qualities that distinguish one year from another: whether it is a leap year or a common year; on which of four permissible days of the week the year begins; and whether it is a deficient, regular, or complete year. Mathematically, there are 24 (2×4×3) possible combinations, but only 14 of them are valid. Each of these patterns is called a "keviyah" (Hebrew קביעה for "a setting" or "an established thing"), and is encoded as a series of two or three Hebrew letters. See Four gates.

In Hebrew there are two common ways of writing the year number: with the thousands, called ("major era"), and without the thousands, called ("minor era"). Thus, the current year is written as ' ‎() using the "major era" and ' ‎(%1000) using the "minor era".

In 1178 CE, Maimonides wrote in the Mishneh Torah that he had chosen the epoch from which calculations of all dates should be as "the third day of Nisan in this present year ... which is the year 4938 of the creation of the world" (22 March 1178). He included all the rules for the calculated calendar and their scriptural basis, including the modern epochal year in his work, and beginning formal usage of the "anno mundi" era. From the eleventh century, "anno mundi" dating became dominant throughout most of the world's Jewish communities. Today, the rules detailed in Maimonides' calendrical code are those generally used by Jewish communities throughout the world.

Since the codification by Maimonides in 1178, the Jewish calendar has used the Anno Mundi epoch (Latin for "in the year of the world," abbreviated "AM" or "A.M.", Hebrew ), sometimes referred to as the "Hebrew era", to distinguish it from other systems based on some computation of creation, such as the Byzantine calendar.

There is also reference in the Talmud to years since the creation based on the calculation in the "Seder Olam Rabbah" of Rabbi Jose ben Halafta in about 160 CE. By his calculation, based on the Masoretic Text, Adam was created in 3760 BCE, later confirmed by the Muslim chronologist al-Biruni as 3448 years before the Seleucid era. An example is the c. 8th century Baraita of Samuel.

According to rabbinic reckoning, the beginning of "year 1" is "not" Creation, but about one year before Creation, with the new moon of its first month (Tishrei) to be called "molad tohu" (the mean new moon of chaos or nothing). The Jewish calendar's epoch (reference date), 1 Tishrei AM 1, is equivalent to Monday, 7 October 3761 BCE in the proleptic Julian calendar, the equivalent tabular date (same daylight period) and is about one year "before" the traditional Jewish date of Creation on 25 Elul AM 1, based upon the "Seder Olam Rabbah". Thus, adding 3760 before Rosh Hashanah or 3761 after to a Julian year number starting from 1 CE will yield the Hebrew year. For earlier years there may be a discrepancy [see: Missing years (Jewish calendar)].

The "Seder Olam Rabbah" also recognized the importance of the Jubilee and Sabbatical cycles as a long-term calendrical system, and attempted at various places to fit the Sabbatical and Jubilee years into its chronological scheme.

Occasionally, "Anno Mundi" is styled as "Anno Hebraico (AH)", though this is subject to confusion with notation for the Islamic Hijri year.

The Jewish calendar has several distinct new years, used for different purposes. The use of multiple starting dates for a year is comparable to different starting dates for civil "calendar years", "tax or fiscal years", "academic years", and so on. The "Mishnah" (c. 200 CE) identifies four new-year dates:

The 1st of Nisan is the new year for kings and festivals; the 1st of Elul is the new year for the cattle tithe... the 1st of Tishri is the new year for years, of the years of release and jubilee years, for the planting and for vegetables; and the 1st of Shevat is the new year for trees—so the school of Shammai; and the school of Hillel say: On the 15th thereof.

Two of these dates are especially prominent:


For the dates of the Jewish New Year see Jewish and Israeli holidays 2000–2050 or calculate using the section "Conversion between Jewish and civil calendars".

The Jewish calendar is based on the Metonic cycle of 19 years, of which 12 are common (non-leap) years of 12 months and 7 are leap years of 13 months. To determine whether a Jewish year is a leap year, one must find its position in the 19-year Metonic cycle. This position is calculated by dividing the Jewish year number by 19 and finding the remainder. (Since there is no year 0, a remainder of 0 indicates that the year is year 19 of the cycle.) For example, the Jewish year divided by 19 results in a remainder of % 19, indicating that it is year of the Metonic cycle. 

Years 3, 6, 8, 11, 14, 17, and 19 of the Metonic cycle are leap years. To assist in remembering this sequence, some people use the mnemonic Hebrew word <nowiki>GUCHADZaT</nowiki> , where the Hebrew letters "gimel-vav-het aleph-dalet-zayin-tet" are used as Hebrew numerals equivalent to 3, 6, 8, 1, 4, 7, 9. The "keviyah" records whether the year is leap or common: פ for "peshuta" (פשוטה), meaning simple and indicating a common year, and מ indicating a leap year (me'uberet, מעוברת).

Another memory aid notes that intervals of the major scale follow the same pattern as do Jewish leap years, with "do" corresponding to year 19 (or 0): a whole step in the scale corresponds to two common years between consecutive leap years, and a half step to one common year between two leap years. This connection with the major scale is more plain in the context of 19 equal temperament: counting the tonic as 0, the notes of the major scale in 19 equal temperament are numbers 0 (or 19), 3, 6, 8, 11, 14, 17, the same numbers as the leap years in the Hebrew calendar.

A simple rule for determining whether a year is a leap year has been given above. However, there is another rule which not only tells whether the year is leap but also gives the fraction of a month by which the calendar is behind the seasons, useful for agricultural purposes. To determine whether year "n" of the calendar is a leap year, find the remainder on dividing [(7 × "n") + 1] by 19. If the remainder is 6 or less it is a leap year; if it is 7 or more it is not. For example, the The This works because as there are seven leap years in nineteen years the difference between the solar and lunar years increases by 7/19-month per year. When the difference goes above 18/19-month this signifies a leap year, and the difference is reduced by one month.

To calculate the day on which Rosh Hashanah of a given year will fall, it is necessary first to calculate the expected molad (moment of lunar conjunction or new moon) of Tishrei in that year, and then to apply a set of rules to determine whether the first day of the year must be postponed. The molad can be calculated by multiplying the number of months that will have elapsed since some (preceding) molad whose weekday is known by the mean length of a (synodic) lunar month, which is 29 days, 12 hours, and 793 parts (there are 1080 "parts" in an hour, so that one part is equal to 3 seconds). The very first molad, the molad tohu, fell on Sunday evening at 11.11 in the local time of Jerusalem, or -3761/10/6 (Proleptic Julian calendar) 20:50:23.1 UTC, or in Jewish terms Day 2, 5 hours, and 204 parts.

In calculating the number of months that will have passed since the known molad that one uses as the starting point, one must remember to include any leap months that falls within the elapsed interval, according to the cycle of leap years. A 19-year cycle of 235 synodic months has 991 weeks 2 days 16 hours 595 parts, a common year of 12 synodic months has 50 weeks 4 days 8 hours 876 parts, while a leap year of 13 synodic months has 54 weeks 5 days 21 hours 589 parts.

The two months whose numbers of days may be adjusted, Marcheshvan and Kislev, are the eighth and ninth months of the Hebrew year, whereas Tishrei is the seventh month (in the traditional counting of the months, even though it is the first month of a new calendar year). Any adjustments needed to postpone Rosh Hashanah must be made to the adjustable months in the year that precedes the year of which the Rosh Hashanah will be the first day.

Just four potential conditions are considered to determine whether the date of Rosh Hashanah must be postponed. These are called the Rosh Hashanah postponement rules, or "deḥiyyot":


The first of these rules ("deḥiyyat molad zaken") is referred to in the Talmud. Nowadays, molad zaken is used as a device to prevent the molad falling on the second day of the month. The second rule, ("deḥiyyat lo ADU"), is applied for religious reasons.

Another two rules are applied much less frequently and serve to prevent impermissible year lengths. Their names are Hebrew acronyms that refer to the ways they are calculated:


At the innovation of the sages, the calendar was arranged to ensure that Yom Kippur would not fall on a Friday or Sunday, and Hoshana Rabbah would not fall on Shabbat. These rules have been instituted because Shabbat restrictions also apply to Yom Kippur, so that if Yom Kippur were to fall on Friday, it would not be possible to make necessary preparations for Shabbat (such as candle lighting). Similarly, if Yom Kippur fell on a Sunday, it would not be possible to make preparations for Yom Kippur because the preceding day is Shabbat. Additionally, the laws of Shabbat override those of Hoshana Rabbah, so that if Hoshana Rabbah were to fall on Shabbat certain rituals that are a part of the Hoshana Rabbah service (such as carrying willows, which is a form of work) could not be performed.

To prevent Yom Kippur (10 Tishrei) from falling on a Friday or Sunday, Rosh Hashanah (1 Tishrei) cannot fall on Wednesday or Friday. Likewise, to prevent Hoshana Rabbah (21 Tishrei) from falling on a Saturday, Rosh Hashanah cannot fall on a Sunday. This leaves only four days on which Rosh Hashanah can fall: Monday, Tuesday, Thursday, and Saturday, which are referred to as the "four gates". Each day is associated with a number (its order in the week, beginning with Sunday as day 1). Numbers in Hebrew have been traditionally denominated by Hebrew letters. Thus the "keviyah" uses the letters ה ,ג ,ב and ז (representing 2, 3, 5, and 7, for Monday, Tuesday, Thursday, and Saturday) to denote the starting day of the year.

The postponement of the year is compensated for by adding a day to the second month or removing one from the third month. A Jewish common year can only have 353, 354, or 355 days. A leap year is always 30 days longer, and so can have 383, 384, or 385 days.

Whether a year is deficient, regular, or complete is determined by the time between two adjacent Rosh Hashanah observances and the leap year. While the "keviyah" is sufficient to describe a year, a variant specifies the day of the week for the first day of Pesach (Passover) in lieu of the year length.

A Metonic cycle equates to 235 lunar months in each 19-year cycle. This gives an average of 6,939 days, 16 hours, and 595 parts for each cycle. But due to the Rosh Hashanah postponement rules (preceding section) a cycle of 19 Jewish years can be either 6,939, 6,940, 6,941, or 6,942 days in duration. Since none of these values is evenly divisible by seven, the Jewish calendar repeats exactly only following 36,288 Metonic cycles, or 689,472 Jewish years. There is a near-repetition every 247 years, except for an excess of 50 minutes 16 seconds (905 parts).

The annual calendar of a numbered Hebrew year, displayed as 12 or 13 months partitioned into weeks, can be determined by consulting the table of Four gates, whose inputs are the year's position in the 19-year cycle and its molad Tishrei. The resulting type ("keviyah") of the desired year in the body of the table is a triple consisting of two numbers and a letter (written left-to-right in English). The left number of each triple is the day of the week of , Rosh Hashanah ; the letter indicates whether that year is deficient (D), regular (R), or complete (C), the number of days in Chesvan and Kislev; while the right number of each triple is the day of the week of , the first day of Passover or Pesach , within the same Hebrew year (next Julian/Gregorian year). The "keviyah" in Hebrew letters are written right-to-left, so their days of the week are reversed, the right number for and the left for . The year within the 19-year cycle alone determines whether that year has one or two Adars.

This table numbers the days of the week and hours for the limits of molad Tishrei in the Hebrew manner for calendrical calculations, that is, both begin at , thus is noon Saturday. The years of a 19-year cycle are organized into four groups: common years after a leap year but before a common year ; common years between two leap years ; common years after a common year but before a leap year ; and leap years , all between common years. The oldest surviving table of Four gates was written by Saadia Gaon (892–942). It is so named because it identifies the four allowable days of the week on which can occur.

Comparing the days of the week of molad Tishrei with those in the "keviyah" shows that during 39% of years is not postponed beyond the day of the week of its molad Tishrei, 47% are postponed one day, and 14% are postponed two days. This table also identifies the seven types of common years and seven types of leap years. Most are represented in any 19-year cycle, except one or two may be in neighboring cycles. The most likely type of year is 5R7 in 18.1% of years, whereas the least likely is 5C1 in 3.3% of years. The day of the week of is later than that of by one, two or three days for common years and three, four or five days for leap years in deficient, regular or complete years, respectively.

See Jewish and Israeli holidays 2000–2050

From very early times, the Mesopotamian lunisolar calendar was in wide use by the countries of the western Asia region. The structure, which was also used by the Israelites, was based on lunar months with the intercalation of an additional month to bring the cycle closer to the solar cycle, although there is no mention of this additional month anywhere in the Hebrew Bible.
Biblical references to the pre-exilic calendar include ten of the twelve months identified by number rather than by name. Prior to the Babylonian exile, the names of only four months are referred to in the Tanakh:

All of these are believed to be Canaanite names. The last three of these names are only mentioned in connection with the building of the First Temple; Håkan Ulfgard suggests that the use of what are rarely used Canaanite (or in the case of Ethanim perhaps Northwest-semitic) names indicates that "the author is consciously utilizing an archaizing terminology, thus giving the impression of an ancient story...".

During the Babylonian captivity, the Jewish people adopted the Babylonian names for the months. The Babylonian calendar descended directly from the Sumerian calendar. These Babylonian month-names (such as Nisan, Iyyar, Tammuz, Ab, Elul, Tishri and Adar) are shared with the modern Syrian calendar (currently used in the Arabic-speaking countries of the Fertile crescent) and the modern Assyrian calendar, indicating a common origin. The origin is thought to be the Babylonian calendar. The modern Turkish calendar includes the names Şubat (February), Nisan (April), Temmuz (July) and Eylul (September). The former name for October was Tesrin.

According to some Christian and Karaite sources, the tradition in ancient Israel was that 1 Nisan would not start until the barley is ripe, being the test for the onset of spring. If the barley was not ripe, an intercalary month would be added before Nisan.

In the 1st century, Josephus stated that while –

Moses...appointed Nisan...as the first month for the festivals...the commencement of the year for everything relating to divine worship, but for selling and buying and other ordinary affairs he preserved the ancient order [i. e. the year beginning with Tishrei]."

Edwin Thiele has concluded that the ancient northern Kingdom of Israel counted years using the ecclesiastical new year starting on 1 Aviv (Nisan), while the southern Kingdom of Judah counted years using the civil new year starting on 1 Tishrei. The practice of the Kingdom of Israel was also that of Babylon, as well as other countries of the region. The practice of Judah is continued in modern Judaism.

Before the adoption of the current "Anno Mundi" year numbering system, other systems were used. In early times, the years were counted from some significant historic event such as the Exodus. During the period of the monarchy, it was the widespread practice in western Asia to use era year numbers according to the accession year of the monarch of the country involved. This practice was followed by the united kingdom of Israel, kingdom of Judah, kingdom of Israel, Persia, and others. Besides, the author of Kings coordinated dates in the two kingdoms by giving the accession year of a monarch in terms of the year of the monarch of the other kingdom, though some commentators note that these dates do not always synchronise. Other era dating systems have been used at other times. For example, Jewish communities in the Babylonian diaspora counted the years from the first deportation from Israel, that of Jehoiachin in 597 BCE. The era year was then called "year of the captivity of Jehoiachin".

During the Hellenistic Maccabean period, Seleucid era counting was used, at least in Land of Israel (under Greek influence at the time). The Books of the Maccabees used Seleucid era dating exclusively, as did Josephus writing in the Roman period. From the 1st-10th centuries, the center of world Judaism was in the Middle East (primarily Iraq and Palestine), and Jews in these regions also used Seleucid era dating, which they called the "Era of Contracts [or Documents]". The Talmud states:

Rav Aha bar Jacob then put this question: How do we know that our Era [of Documents] is connected with the Kingdom of Greece at all? Why not say that it is reckoned from the Exodus from Egypt, omitting the first thousand years and giving the years of the next thousand? In that case, the document is really post-dated!<br>Said Rav Nahman: In the Diaspora the Greek Era alone is used.<br>He [Rav Aha] thought that Rav Nahman wanted to dispose of him anyhow, but when he went and studied it thoroughly he found that it is indeed taught [in a Baraita]: In the Diaspora the Greek Era alone is used.

The use of the era of documents (i.e., Seleucid era) continued till the 16th century in the East, and was employed even in the 19th century among the Jews of Yemen.

Occasionally in Talmudic writings, reference was made to other starting points for eras, such as destruction era dating, being the number of years since the 70 CE destruction of the Second Temple. In the 8th and 9th centuries, as the center of Jewish life moved from Babylonia to Europe, counting using the Seleucid era "became meaningless", and thus was replaced by the "anno mundi system". There is indication that Jews of the Rhineland in the early Middle Ages used the "years after the destruction of the Temple".

When the observational form of the calendar was in use, whether or not an embolismic month was announced after the "last month" (Adar) depended on 'aviv [i.e., the ripeness of barley], fruits of trees, and the equinox. On two of these grounds it should be intercalated, but not on one of them alone. It may be noted that in the Bible the name of the first month, "Aviv", literally means "spring". Thus, if Adar was over and spring had not yet arrived, an additional month was observed.

The Tanakh contains several commandments related to the keeping of the calendar and the lunar cycle, and records changes that have taken place to the Hebrew calendar. stresses the importance in Israelite religious observance of the new month (Hebrew: , Rosh Chodesh, "beginning of the month"): "... in your new moons, ye shall blow with the trumpets over your burnt-offerings..." Similarly in . "The beginning of the month" meant the appearance of a new moon, and in . "This month is to you".

According to the "Mishnah" and Tosefta, in the Maccabean, Herodian, and Mishnaic periods, new months were determined by the sighting of a new crescent, with two eyewitnesses required to testify to the Sanhedrin to having seen the new lunar crescent at sunset. The practice in the time of Gamaliel II (c. 100 CE) was for witnesses to select the appearance of the moon from a collection of drawings that depicted the crescent in a variety of orientations, only a few of which could be valid in any given month. These observations were compared against calculations.

At first the beginning of each Jewish month was signaled to the communities of Israel and beyond by fires lit on mountaintops, but after the Samaritans began to light false fires, messengers were sent. The inability of the messengers to reach communities outside Israel before mid-month High Holy Days (Succot and Passover) led outlying communities to celebrate scriptural festivals for two days rather than one, observing the second feast-day of the Jewish diaspora because of uncertainty of whether the previous month ended after 29 or 30 days.
It has been noted that the procedures described in the Mishnah and Tosefta are all plausible procedures for regulating an empirical lunar calendar. Fire-signals, for example, or smoke-signals, are known from the pre-exilic Lachish ostraca. Furthermore, the Mishnah contains laws that reflect the uncertainties of an empirical calendar. Mishnah Sanhedrin, for example, holds that when one witness holds that an event took place on a certain day of the month, and another that the same event took place on the following day, their testimony can be held to agree, since the length of the preceding month was uncertain. Another Mishnah takes it for granted that it cannot be known in advance whether a year's lease is for twelve or thirteen months. Hence it is a reasonable conclusion that the Mishnaic calendar was actually used in the Mishnaic period.

The accuracy of the Mishnah's claim that the Mishnaic calendar was also used in the late Second Temple period is less certain. One scholar has noted that there are no laws from Second Temple period sources that indicate any doubts about the length of a month or of a year. This led him to propose that the priests must have had some form of computed calendar or calendrical rules that allowed them to know in advance whether a month would have 30 or 29 days, and whether a year would have 12 or 13 months.

Between 70 and 1178 CE, the observation-based calendar was gradually replaced by a mathematically calculated one.

The Talmuds indicate at least the beginnings of a transition from a purely empirical to a computed calendar. Samuel of Nehardea (c. 165-254) stated that he could determine the dates of the holidays by calculation rather than observation. According to a statement attributed to Yose (late 3rd century), Purim could not fall on a Sabbath nor a Monday, lest Yom Kippur fall on a Friday or a Sunday. This indicates that, by the time of the redaction of the Jerusalem Talmud (c. 400 CE), there were a fixed number of days in all months from Adar to Elul, also implying that the extra month was already a second Adar added before the regular Adar. Elsewhere, Rabbi Simon is reported to have counseled "those who make the computations" not to set Rosh Hashana or Hoshana Rabbah on Shabbat. This indicates that there was a group who "made computations" and controlled, to some extent, the day of the week on which Rosh Hashana would fall.

There is a tradition, first mentioned by Hai Gaon (died 1038 CE), that Hillel b. R. Yehuda "in the year 670 of the Seleucid era" (i.e., 358–359 CE) was responsible for the new calculated calendar with a fixed intercalation cycle. Later writers, such as Nachmanides, explained Hai Gaon's words to mean that the entire computed calendar was due to Hillel b. Yehuda in response to persecution of Jews. Maimonides (12th century) stated that the Mishnaic calendar was used "until the days of Abaye and Rava" (c. 320–350 CE), and that the change came when "the land of Israel was destroyed, and no permanent court was left." Taken together, these two traditions suggest that Hillel b. Yehuda (whom they identify with the mid-4th-century Jewish patriarch Ioulos, attested in a letter of the Emperor Julian, and the Jewish patriarch Ellel, mentioned by Epiphanius) instituted the computed Hebrew calendar because of persecution. H. Graetz linked the introduction of the computed calendar to a sharp repression following a failed Jewish insurrection that occurred during the rule of the Christian emperor Constantius and Gallus. A later writer, S. Lieberman, argued instead that the introduction of the fixed calendar was due to measures taken by Christian Roman authorities to prevent the Jewish patriarch from sending calendrical messengers.

Both the tradition that Hillel b. Yehuda instituted the complete computed calendar, and the theory that the computed calendar was introduced due to repression or persecution, have been questioned. Furthermore, two Jewish dates during post-Talmudic times (specifically in 506 and 776) are impossible under the rules of the modern calendar, indicating that its arithmetic rules were developed in Babylonia during the times of the Geonim (7th to 8th centuries). The Babylonian rules required the delay of the first day of Tishrei when the new moon occurred after noon.

Except for the epoch year number (the fixed reference point at the beginning of year 1, which at that time was one year later than the epoch of the modern calendar), the calendar rules reached their current form by the beginning of the 9th century, as described by the Persian Muslim astronomer al-Khwarizmi in 823. Al-Khwarizmi's study of the Jewish calendar describes the 19-year intercalation cycle, the rules for determining on what day of the week the first day of the month Tishrī shall fall, the interval between the Jewish era (creation of Adam) and the Seleucid era, and the rules for determining the mean longitude of the sun and the moon using the Jewish calendar. Not all the rules were in place by 835.

In 921, Aaron ben Meïr proposed changes to the calendar. Though the proposals were rejected, they indicate that all of the rules of the modern calendar (except for the epoch) were in place before that date. In 1000, the Muslim chronologist al-Biruni described all of the modern rules of the Hebrew calendar, except that he specified three different epochs used by various Jewish communities being one, two, or three years later than the modern epoch.

While imprisoned in Auschwitz, Jews made every effort to observe Jewish tradition in the camps, despite the monumental dangers in doing so. The Hebrew calendar, which is a tradition with great importance to Jewish practice and rituals was particularly dangerous since no tools of telling of time, such as watches and calendars were permitted in the camps. The keeping of a Hebrew calendar was a rarity amongst prisoners and there are only two known surviving calendars that were made in Auschwitz, both of which were made by women. Before this, the tradition of making a Hebrew calendar was greatly assumed to be the job of a man in Jewish society.

Early Zionist pioneers were impressed by the fact that the calendar preserved by Jews over many centuries in far-flung diasporas, as a matter of religious ritual, was geared to the climate of their original country: the Jewish New Year marks the transition from the dry season to the rainy one, and major Jewish holidays such as Sukkot, Passover, and Shavuot correspond to major points of the country's agricultural year such as planting and harvest.

Accordingly, in the early 20th century the Hebrew calendar was re-interpreted as an agricultural rather than religious calendar.

After the creation of the State of Israel, the Hebrew calendar became one of the official calendars of Israel, along with the Gregorian calendar. Holidays and commemorations not derived from previous Jewish tradition were to be fixed according to the Hebrew calendar date. For example, the Israeli Independence Day falls on 5 Iyar, Jerusalem Reunification Day on 28 Iyar, Yom HaAliyah on 10 Nisan, and the Holocaust Commemoration Day on 27 Nisan.

Nevertheless, since the 1950s usage of the Hebrew calendar has steadily declined, in favor of the Gregorian calendar. At present, Israelis—except for the religiously observant—conduct their private and public life according to the Gregorian calendar, although the Hebrew calendar is still widely acknowledged, appearing in public venues such as banks (where it is legal for use on cheques and other documents, though only rarely do people make use of this option) and on the mastheads of newspapers.

The Jewish New Year (Rosh Hashanah) is a two-day public holiday in Israel. However, since the 1980s an increasing number of secular Israelis celebrate the Gregorian New Year (usually known as "Silvester Night"—"ליל סילבסטר") on the night between 31 December and 1 January. Prominent rabbis have on several occasions sharply denounced this practice, but with no noticeable effect on the secularist celebrants.

Wall calendars commonly used in Israel are hybrids. Most are organised according to Gregorian rather than Jewish months, but begin in September, when the Jewish New Year usually falls, and provide the Jewish date in small characters.

Outside of Rabbinic Judaism, evidence shows a diversity of practice.

Karaites use the lunar month and the solar year, but the Karaite calendar differs from the current Rabbinic calendar in a number of ways. The Karaite calendar is identical to the Rabbinic calendar used before the Sanhedrin changed the Rabbinic calendar from the lunar, observation based, calendar to the current, mathematically based, calendar used in Rabbinic Judaism today.

In the lunar Karaite calendar, the beginning of each month, the Rosh Chodesh, can be calculated, but is confirmed by the observation in Israel of the first sightings of the new moon. This may result in an occasional variation of a maximum of one day, depending on the inability to observe the new moon. The day is usually "picked up" in the next month.

The addition of the leap month (Adar II) is determined by observing in Israel the ripening of barley at a specific stage (defined by Karaite tradition) (called aviv), rather than using the calculated and fixed calendar of rabbinic Judaism. Occasionally this results in Karaites being one month ahead of other Jews using the calculated rabbinic calendar. The "lost" month would be "picked up" in the next cycle when Karaites would observe a leap month while other Jews would not.

Furthermore, the seasonal drift of the rabbinic calendar is avoided, resulting in the years affected by the drift starting one month earlier in the Karaite calendar.

Also, the four rules of postponement of the rabbinic calendar are not applied, since they are not mentioned in the Tanakh. This can affect the dates observed for all the Jewish holidays in a particular year by one or two days.

In the Middle Ages many Karaite Jews outside Israel followed the calculated rabbinic calendar, because it was not possible to retrieve accurate aviv barley data from the land of Israel. However, since the establishment of the State of Israel, and especially since the Six-Day War, the Karaite Jews that have made "aliyah" can now again use the observational calendar.

The Samaritan community's calendar also relies on lunar months and solar years. Calculation of the Samaritan calendar has historically been a secret reserved to the priestly family alone, and was based on observations of the new crescent moon. More recently, a 20th-century Samaritan High Priest transferred the calculation to a computer algorithm. The current High Priest confirms the results twice a year, and then distributes calendars to the community.

The epoch of the Samaritan calendar is year of the entry of the Children of Israel into the Land of Israel with Joshua. The month of Passover is the first month in the Samaritan calendar, but the year number increments in the sixth month. Like in the Rabbinic calendar, there are seven leap years within each 19-year cycle. However, the Rabbinic and Samaritan calendars' cycles are not synchronized, so Samaritan festivals—notionally the same as the Rabbinic festivals of Torah origin—are frequently one month off from the date according to the Rabbinic calendar. Additionally, as in the Karaite calendar, the Samaritan calendar does not apply the four rules of postponement, since they are not mentioned in the Tanakh. This can affect the dates observed for all the Jewish holidays in a particular year by one or two days.

Many of the Dead Sea (Qumran) Scrolls have references to a unique calendar, used by the people there, who are often assumed to be Essenes.

The year of this calendar used the ideal Mesopotamian calendar of twelve 30-day months, to which were added 4 days at the equinoxes and solstices (cardinal points), making a total of 364 days.

There was some ambiguity as to whether the cardinal days were at the beginning of the months or at the end, but the clearest calendar attestations give a year of four seasons, each having three months of 30, 30, and 31 days with the cardinal day the extra day at the end, for a total of 91 days, or exactly 13 weeks. Each season started on the 4th day of the week (Wednesday), every year. (Ben-Dov, "Head of All Years", pp. 16–17)

With only 364 days, it is clear that the calendar would after a few years be very noticeably different from the actual seasons, but there is nothing to indicate what was done about this problem. Various suggestions have been made by scholars. One is that nothing was done and the calendar was allowed to change with respect to the seasons. Another suggestion is that changes were made irregularly, only when the seasonal anomaly was too great to be ignored any longer. (Ben-Dov, "Head of All Years", pp. 19–20)

The writings often discuss the moon, but the calendar was not based on the movement of the moon any more than indications of the phases of the moon on a modern western calendar indicate that that is a lunar calendar. Recent analysis of one of the last scrolls remaining to be deciphered has revealed it relates to this calendar and that the sect used the word "tekufah" to identify each of the four special days marking the transitions between the seasons.

Calendrical evidence for the postexilic Persian period is found in papyri from the Jewish colony at Elephantine, in Egypt. These documents show that the Jewish community of Elephantine used the Egyptian and Babylonian calendars.

The Sardica paschal table shows that the Jewish community of some eastern city, possibly Antioch, used a calendrical scheme that kept Nisan 14 within the limits of the Julian month of March. Some of the dates in the document are clearly corrupt, but they can be emended to make the sixteen years in the table consistent with a regular intercalation scheme. Peter, the bishop of Alexandria (early 4th century CE), mentions that the Jews of his city "hold their Passover according to the course of the moon in the month of Phamenoth, or according to the intercalary month every third year in the month of Pharmuthi", suggesting a fairly consistent intercalation scheme that kept Nisan 14 approximately between Phamenoth 10 (March 6 in the 4th century CE) and Pharmuthi 10 (April 5). Jewish funerary inscriptions from Zoar, south of the Dead Sea, dated from the 3rd to the 5th century, indicate that when years were intercalated, the intercalary month was at least sometimes a repeated month of Adar. The inscriptions, however, reveal no clear pattern of regular intercalations, nor do they indicate any consistent rule for determining the start of the lunar month.

In 1178, Maimonides included all the rules for the calculated calendar and their scriptural basis, including the modern epochal year in his work, "Mishneh Torah". Today, the rules detailed in Maimonides' code are those generally used by Jewish communities throughout the world.

A "new moon" (astronomically called a lunar conjunction and, in Hebrew, a molad) is the moment at which the sun and moon are aligned horizontally with respect to a north-south line (technically, they have the same ecliptical longitude). The period between two new moons is a synodic month. The actual length of a synodic month varies from about 29 days 6 hours and 30 minutes (29.27 days) to about 29 days and 20 hours (29.83 days), a variation range of about 13 hours and 30 minutes. Accordingly, for convenience, a long-term average length, identical to the mean synodic month of ancient times (also called the molad interval) is used. The molad interval is formula_1 days, or 29 days, 12 hours, and 793 "parts" (1 "part" = / minute; 3 "parts" = 10 seconds) (i.e., 29.530594 days), and is the same value determined by the Babylonians in their System B about 300 BCE and was adopted by the Greek astronomer Hipparchus in the 2nd century BCE and by the Alexandrian astronomer Ptolemy in the "Almagest" four centuries later (who cited Hipparchus as his source). Its remarkable accuracy (less than one second from the true value) is thought to have been achieved using records of lunar eclipses from the 8th to 5th centuries BCE.

This value is as close to the correct value of 29.530589 days as it is possible for a value to come that is rounded off to whole "parts". The discrepancy makes the molad interval about 0.6 seconds too long. Put another way, if the molad is taken as the time of mean conjunction at some reference meridian, then this reference meridian is drifting slowly eastward. If this drift of the reference meridian is traced back to the mid-4th century, the traditional date of the introduction of the fixed calendar, then it is found to correspond to a longitude midway between the Nile and the end of the Euphrates. The modern molad moments match the mean solar times of the lunar conjunction moments near the meridian of Kandahar, Afghanistan, more than 30° east of Jerusalem.

Furthermore, the discrepancy between the molad interval and the mean synodic month is accumulating at an accelerating rate, since the mean synodic month is progressively shortening due to gravitational tidal effects. Measured on a strictly uniform time scale, such as that provided by an atomic clock, the mean synodic month is becoming gradually longer, but since the tides slow Earth's rotation rate even more, the mean synodic month is becoming gradually shorter in terms of mean solar time.

The mean year of the current mathematically based Hebrew calendar is 365 days 5 hours 55 minutes and 25+/ seconds (365.2468 days) – computed as the molad/monthly interval of 29.530594 days × 235 months in a 19-year metonic cycle ÷ 19 years per cycle. In relation to the Gregorian calendar, the mean Gregorian calendar year is 365 days 5 hours 49 minutes and 12 seconds (365.2425 days), and the drift of the Hebrew calendar in relation to it is about a day every 231 years.

Although the molad of Tishrei is the only molad moment that is not ritually announced, it is actually the only one that is relevant to the Hebrew calendar, for it determines the provisional date of Rosh Hashanah, subject to the Rosh Hashanah postponement rules. The other monthly molad moments are announced for mystical reasons. With the moladot on average almost 100 minutes late, this means that the molad of Tishrei lands one day later than it ought to in (100 minutes) ÷ (1440 minutes per day) = 5 of 72 years or nearly 7% of years.

Therefore, the seemingly small drift of the moladot is already significant enough to affect the date of Rosh Hashanah, which then cascades to many other dates in the calendar year and sometimes, due to the Rosh Hashanah postponement rules, also interacts with the dates of the prior or next year. The molad drift could be corrected by using a progressively shorter molad interval that corresponds to the actual mean lunar conjunction interval at the original molad reference meridian. Furthermore, the molad interval determines the calendar mean year, so using a progressively shorter molad interval would help correct the excessive length of the Hebrew calendar mean year, as well as helping it to "hold onto" the northward equinox for the maximum duration.

When the 19-year intercalary cycle was finalised in the 4th century, the earliest Passover (in year 16 of the cycle) coincided with the northward equinox, which means that Passover fell near the "first" full moon after the northward equinox, or that the northward equinox landed within one lunation before 16 days after the "molad" of "Nisan". This is still the case in about 80% of years; but, in about 20% of years, Passover is a month late by these criteria (as it was in AM 5765, 5768 and 5776, the 8th, 11th and 19th years of the 19-year cycle = Gregorian 2005, 2008 and 2016 CE). Presently, this occurs after the "premature" insertion of a leap month in years 8, 11, and 19 of each 19-year cycle, which causes the northward equinox to land on exceptionally early Hebrew dates in such years. This problem will get worse over time, and so beginning in AM 5817 (2057 CE), year 3 of each 19-year cycle will also be a month late. If the calendar is not amended, then Passover will start to land on or after the summer solstice around AM 16652 (12892 CE). In theory, the exact year when this will begin to occur depends on uncertainties in the future tidal slowing of the Earth rotation rate, and on the accuracy of predictions of precession and Earth axial tilt.
The seriousness of the spring equinox drift is widely discounted on the grounds that Passover will remain in the spring season for many millennia, and the text of the Torah is generally not interpreted as having specified tight calendrical limits. The Hebrew calendar also drifts with respect to the autumn equinox, and at least part of the harvest festival of Sukkot is already more than a month after the equinox in years 1, 9, and 12 of each 19-year cycle; beginning in AM 5818 (2057 CE), this will also be the case in year 4. (These are the same year numbers as were mentioned for the spring season in the previous paragraph, except that they get incremented at Rosh Hashanah.) This progressively increases the probability that Sukkot will be cold and wet, making it uncomfortable or impractical to dwell in the traditional "succah" during Sukkot. The first winter seasonal prayer for rain is not recited until "Shemini Atzeret", after the end of Sukkot, yet it is becoming increasingly likely that the rainy season in Israel will start before the end of Sukkot.

No equinox or solstice will ever be more than a day or so away from its mean date according to the solar calendar, while nineteen Jewish years average 6939d 16h 33m 03s compared to the 6939d 14h 26m 15s of nineteen mean tropical years. This discrepancy has mounted up to six days, which is why the earliest Passover currently falls on 26 March (as in AM 5773 / 2013 CE).

Given the length of the year, the length of each month is fixed as described above, so the real problem in determining the calendar for a year is determining the number of days in the year. In the modern calendar, this is determined in the following manner.

The day of Rosh Hashanah and the length of the year are determined by the time and the day of the week of the Tishrei "molad", that is, the moment of the average conjunction. Given the Tishrei "molad" of a certain year, the length of the year is determined as follows:

First, one must determine whether each year is an ordinary or leap year by its position in the 19-year Metonic cycle. Years 3, 6, 8, 11, 14, 17, and 19 are leap years.

Secondly, one must determine the number of days between the starting Tishrei "molad" (TM1) and the Tishrei "molad" of the next year (TM2). For calendar descriptions in general the day begins at 6 p.m., but for the purpose of determining Rosh Hashanah, a "molad" occurring on or after noon is treated as belonging to the next day (the first "deḥiyyah"). All months are calculated as 29d, 12h, 44m, 3s long (MonLen). Therefore, in an ordinary year TM2 occurs 12 × MonLen days after TM1. This is usually 354 calendar days after TM1, but if TM1 is on or after 3:11:20 a.m. and before noon, it will be 355 days. Similarly, in a leap year, TM2 occurs 13 × MonLen days after TM1. This is usually 384 days after TM1, but if TM1 is on or after noon and before 2:27:16 p.m., TM2 will be only 383 days after TM1. In the same way, from TM2 one calculates TM3. Thus the four natural year lengths are 354, 355, 383, and 384 days.

However, because of the holiday rules, Rosh Hashanah cannot fall on a Sunday, Wednesday, or Friday, so if TM2 is one of those days, Rosh Hashanah in year 2 is postponed by adding one day to year 1 (the second "deḥiyyah"). To compensate, one day is subtracted from year 2. It is to allow for these adjustments that the system allows 385-day years (long leap) and 353-day years (short ordinary) besides the four natural year lengths.

But how can year 1 be lengthened if it is already a long ordinary year of 355 days or year 2 be shortened if it is a short leap year of 383 days? That is why the third and fourth "deḥiyyah"s are needed.

If year 1 is already a long ordinary year of 355 days, there will be a problem if TM1 is on a Tuesday, as that means TM2 falls on a Sunday and will have to be postponed, creating a 356-day year. In this case, Rosh Hashanah in year 1 is postponed from Tuesday (the third "deḥiyyah"). As it cannot be postponed to Wednesday, it is postponed to Thursday, and year 1 ends up with 354 days.

On the other hand, if year 2 is already a short year of 383 days, there will be a problem if TM2 is on a Wednesday. because Rosh Hashanah in year 2 will have to be postponed from Wednesday to Thursday and this will cause year 2 to be only 382 days long. In this case, year 2 is extended by one day by postponing Rosh Hashanah in year 3 from Monday to Tuesday (the fourth "deḥiyyah"), and year 2 will have 383 days.

Given the importance in Jewish ritual of establishing the accurate timing of monthly and annual times, some futurist writers and researchers have considered whether a "corrected" system of establishing the Hebrew date is required. The mean year of the current mathematically based Hebrew calendar has "drifted" an average of 7–8 days late relative to the equinox relationship that it originally had. It is not possible, however, for any individual Hebrew date to be a week or more "late", because Hebrew months always begin within a day or two of the "molad" moment. What happens instead is that the traditional Hebrew calendar "prematurely" inserts a leap month one year before it "should have been" inserted, where "prematurely" means that the insertion causes the spring equinox to land more than 30 days before the latest acceptable moment, thus causing the calendar to run "one month late" until the time when the leap month "should have been" inserted prior to the following spring. This presently happens in 4 years out of every 19-year cycle (years 3, 8, 11, and 19), implying that the Hebrew calendar currently runs "one month late" more than 21% of the time.

Dr. Irv Bromberg has proposed a 353-year cycle of 4,366 months, which would include 130 leap months, along with use of a progressively shorter "molad" interval, which would keep an amended fixed arithmetic Hebrew calendar from drifting for more than seven millennia. It takes about 3 centuries for the spring equinox to drift an average of th of a "molad" interval earlier in the Hebrew calendar. That is a very important time unit, because it can be cancelled by simply truncating a 19-year cycle to 11 years, omitting 8 years including three leap years from the sequence. That is the essential feature of the 353-year leap cycle. ().

Religious questions abound about how such a system might be implemented and administered throughout the diverse aspects of the world Jewish community.

The times below (moladot Nisan) can be used to determine the day the Jewish ecclesiastical (spring) year starts over a period of nineteen years:

Every nineteen years this time is 2 days, 16 hours, 33 1/18 minutes later in the week. That is either the same or the previous day in the civil calendar, depending on whether the difference in the day of the week is three or two days. If 29 February is included fewer than five times in the nineteen – year period the date will be later by the number of days which corresponds to the difference between the actual number of insertions and five. If the year is due to start on Sunday, it actually begins on the following Tuesday if the following year is due to start on Friday morning. If due to start on Monday, Wednesday or Friday it actually begins on the following day. If due to start on Saturday, it actually begins on the following day if the previous year was due to begin on Monday morning.

The table below lists, for a Jewish year commencing on 23 March, the civil date of the first day of each month. If the year does not begin on 23 March, each month's first day will differ from the date shown by the number of days that the start of the year differs from 23 March. The correct column is the one which shows the correct starting date for the following year in the last row. If 29 February falls within a Jewish month the first day of later months will be a day earlier than shown.

In the Julian calendar, every 76 years the Jewish year is due to start 5h 47 14/18m earlier, and 3d 18h 12 4/18m later in the week.






</doc>
<doc id="13786" url="https://en.wikipedia.org/wiki?curid=13786" title="The Holocaust Industry">
The Holocaust Industry

The Holocaust Industry: Reflections on the Exploitation of Jewish Suffering is a 2000 book by Norman Finkelstein, in which the author argues that the American Jewish establishment exploits the memory of the Nazi Holocaust for political and financial gain, as well as to further the interests of Israel. According to Finkelstein, this "Holocaust industry" has corrupted Jewish culture and the authentic memory of the Holocaust.

Finkelstein states that his consciousness of "the Nazi holocaust" is rooted in his parents' experiences in the Warsaw Ghetto; with the exception of his parents themselves, "every family member on both sides was exterminated by the Nazis". Nonetheless, during his childhood, no one ever asked any questions about what his mother and father had suffered. He suggests, "This was not a respectful silence. It was indifference." It was only after the establishment of "the Holocaust industry", he suggests, that outpourings of anguish over the plight of the Jews in World War II began. This ideology in turn served to endow Israel with a status as "'victim' state" despite its "horrendous" human rights record.

According to Finkelstein, his book is "an anatomy and an indictment of the Holocaust industry". He argues that "'The Holocaust' is an ideological representation of the Nazi holocaust".

In the foreword to the first paperback edition, Finkelstein notes that the first hardback edition had been a considerable hit in several European countries and many languages, but had been largely ignored in the United States. He sees "The New York Times" as the main promotional vehicle of the "Holocaust industry", and says that the 1999 Index listed 273 entries for the Holocaust and just 32 entries for the entire continent of Africa.

The second (2003) edition contained 100 pages of new material, primarily in chapter 3 on the World Jewish Congress lawsuit against Swiss banks. Finkelstein set out to provide a guide to the relevant sections of the case. He feels that the presiding judge elected not to docket crucial documents, and that the Claims Resolution Tribunal could no longer be trusted. Finkelstein claims the CRT was on course to vindicate the Swiss banks before it changed tack in order to "protect the blackmailers' reputation".

In addition to support from individuals such as Noam Chomsky and Alexander Cockburn, the Holocaust historian Raul Hilberg praised Finkelstein's book: 
The book received negative reviews. According to Israeli journalist Yair Sheleg, in August 2000, German historian Hans Mommsen called it "a most trivial book, which appeals to easily aroused anti-Semitic prejudices." Wolfgang Benz stated to "Le Monde": "It is impossible to learn anything from Finkelstein's book. At best, it is interesting for a psychotherapist." The reviewer of this daily added that Norman Finkelstein "hardly cares about nuance" and Rony Brauman wrote in the preface to the French edition ("L'Industrie de l'Holocauste", Paris, La Fabrique, 2001) that some assertions of N. Finkelstein (especially on the impact of the Six-days war) are wrong, others being pieces of "propaganda". Historian Peter Novick, whose work Finkelstein described as providing the "initial stimulus" for "The Holocaust Industry", asserted in the July 28, 2000 issue of "The Jewish Chronicle" (London) that the book is replete with "false accusations", "egregious misrepresentations", "absurd claims" and "repeated mis-statements" ("A charge into darkness that sheds no light"). Finkelstein replied to the allegations by Novick on his homepage. Hasia Diner has accused Peter Novick and Finkelstein of being "harsh critics of American Jewry from the left," and challenges the notion reflected in their books that American Jews did not begin to commemorate the Holocaust until after 1967.

Andrew Ross, reviewing the book for "Salon", wrote:

Jonathan Freedland in a column for "The Guardian" wrote that unlike Novick's book, "The Holocaust Industry" does not share its "sensitivity or human empathy - surely prerequisites of any meaningful debate about the Holocaust". Freedland accused Finkelstein of having constructed "an elaborate conspiracy theory, in which the Jews were pushed from apathy to obsession about the Holocaust by a corrupt Jewish leadership bent on building international support for Israel".

Finkelstein responded to his critics in the foreword to the second edition, writing "Mainstream critics allege that I conjured a 'conspiracy theory' while those on the Left ridicule the book as a defense of 'the banks'. None, so far as I can tell, question my actual findings."

Finkelstein claims that there are two known frauds connected to the Holocaust, that of "The Painted Bird" by Polish writer Jerzy Kosinski – which was published as fiction – and "Fragments" by Binjamin Wilkomirski. He claims that Kosinski and Wilkomirski were defended even after their supposed frauds had been exposed. He identifies some of the defenders as members of the "Holocaust Industry", and writes that they also support each other. Elie Wiesel supported Kosinski; Israel Gutman and Daniel Goldhagen (see below) supported Wilkomirski; Wiesel and Gutman support Goldhagen.

Finkelstein compares the media treatment of the Holocaust and the media treatment of other genocides such as the Holodomor and the Armenian Genocide, particularly by members of what he calls "The Holocaust Industry". One to 1.5 million Armenians died in the years between 1915 and 1917/1923 - denial includes the claim that they were the result of a civil war within World War I, or refusal to accept there were deaths. In 2001, Israeli Foreign Minister Shimon Peres went so far as to dismiss it as "allegations". However, by this time historical consensus was changing, and, according to Finkelstein, he was "angrily compared ... to a holocaust denier" by Israel Charny, executive director of the Institute on the Holocaust and Genocide in Jerusalem.

According to Finkelstein, Elie Wiesel characterized any suggestion that he has profited from the "Holocaust Industry", or even any criticism at all, as Holocaust denial. Questioning a survivor's testimony, denouncing the role of Jewish collaborators, suggesting that Germans suffered during the bombing of Dresden or that any state except Germany committed crimes in World War II are all evidence of Holocaust denial – according to Deborah Lipstadt – and Finkelstein says the most "insidious" forms of Holocaust denial are "immoral equivalencies", denying the uniqueness of The Holocaust. Finkelstein examines the implications of applying this standard to another member of the "Holocaust Industry", Daniel Goldhagen, who argued that Serbian actions in Kosovo "are, in their essence, different from those of Nazi Germany only in scale".

According to Finkelstein, Deborah Lipstadt claims there is widespread Holocaust denial - yet in "Denying the Holocaust" (1993) her prime example is Arthur Butz, author of "The Hoax of the Twentieth Century". The chapter on him is entitled "Entering the Mainstream" - but Finkelstein considers that, were it not for the likes of Lipstadt, no one would ever have heard of Arthur Butz. Finkelstein claims that Holocaust deniers have as much influence in the US as the Flat Earth Society (p. 69).

Publishing history of "The Holocaust Industry":




</doc>
<doc id="13787" url="https://en.wikipedia.org/wiki?curid=13787" title="Hermetic Order of the Golden Dawn">
Hermetic Order of the Golden Dawn

The Hermetic Order of the Golden Dawn (; or, more commonly, the Golden Dawn ("Aurora Aurea")) was a secret society devoted to the study and practice of the occult, metaphysics, and paranormal activities during the late 19th and early 20th centuries. Known as a magical order, the Hermetic Order of the Golden Dawn was active in Great Britain and focused its practices on theurgy and spiritual development. Many present-day concepts of ritual and magic that are at the centre of contemporary traditions, such as Wicca and Thelema, were inspired by the Golden Dawn, which became one of the largest single influences on 20th-century Western occultism.

The three founders, William Robert Woodman, William Wynn Westcott and Samuel Liddell Mathers, were Freemasons. Westcott appears to have been the initial driving force behind the establishment of the Golden Dawn.

The Golden Dawn system was based on hierarchy and initiation like the Masonic lodges; however women were admitted on an equal basis with men. The "Golden Dawn" was the first of three Orders, although all three are often collectively referred to as the "Golden Dawn". The First Order taught esoteric philosophy based on the Hermetic Qabalah and personal development through study and awareness of the four classical elements as well as the basics of astrology, tarot divination, and geomancy. The Second or "Inner" Order, the "Rosae Rubeae et Aureae Crucis", taught magic, including scrying, astral travel, and alchemy. The Third Order was that of the "Secret Chiefs", who were said to be highly skilled; they supposedly directed the activities of the lower two orders by spirit communication with the Chiefs of the Second Order.

The foundational documents of the original Order of the Golden Dawn, known as the Cipher Manuscripts, are written in English using the Trithemius cipher. The manuscripts give the specific outlines of the Grade Rituals of the Order and prescribe a curriculum of graduated teachings that encompass the Hermetic Qabalah, astrology, occult tarot, geomancy, and alchemy.

According to the records of the Order, the manuscripts passed from Kenneth R. H. Mackenzie, a Masonic scholar, to the Rev. A. F. A. Woodford, whom British occult writer Francis King describes as the fourth founder (although Woodford died shortly after the Order was founded). The documents did not excite Woodford, and in February 1886 he passed them on to Freemason William Wynn Westcott, who managed to decode them in 1887. Westcott, pleased with his discovery, called on fellow Freemason Samuel Liddell MacGregor Mathers for a second opinion. Westcott asked for Mathers' help to turn the manuscripts into a coherent system for lodge work. Mathers in turn asked fellow Freemason William Robert Woodman to assist the two, and he accepted. Mathers and Westcott have been credited with developing the ritual outlines in the Cipher Manuscripts into a workable format. Mathers, however, is generally credited with the design of the curriculum and rituals of the Second Order, which he called the "Rosae Rubae et Aureae Crucis" ("Ruby Rose and Golden Cross" or the "RR et AC").

In October 1887, Westcott claimed to have written to a German countess and prominent Rosicrucian named Anna Sprengel, whose address was said to have been found in the decoded Cipher Manuscripts. According to Westcott, Sprengel claimed the ability to contact certain supernatural entities, known as the Secret Chiefs, that were considered the authorities over any magical order or esoteric organization. Westcott purportedly received a reply from Sprengel granting permission to establish a Golden Dawn temple and conferring honorary grades of Adeptus Exemptus on Westcott, Mathers, and Woodman. The temple was to consist of the five grades outlined in the manuscripts.

In 1888, the Isis-Urania Temple was founded in London. In contrast to the S.R.I.A. and Masonry, women were allowed and welcome to participate in the Order in "perfect equality" with men. The Order was more of a philosophical and metaphysical teaching order in its early years. Other than certain rituals and meditations found in the Cipher manuscripts and developed further, "magical practices" were generally not taught at the first temple.

For the first four years, the Golden Dawn was one cohesive group later known as the "First Order" or "Outer Order". A "Second Order" or "Inner Order" was established and became active in 1892. The Second Order consisted of members known as "adepts", who had completed the entire course of study for the First Order. The Second Order was formally established under the name "Ordo Rosae Rubeae et Aureae Crucis" (the Order of the Red Rose and the Golden Cross).

Eventually, the Osiris temple in Weston-super-Mare, the Horus temple in Bradford (both in 1888), and the Amen-Ra temple in Edinburgh (1893) were founded. In 1893 Mathers founded the Ahathoor temple in Paris.

In 1890, Westcott's alleged correspondence with Anna Sprengel suddenly ceased. He claimed to have received word from Germany that she was dead and that her companions did not approve of the founding of the Order and no further contact was to be made. If the founders were to contact the Secret Chiefs, apparently, it had to be done on their own. In 1892, Mathers professed that a link to the Secret Chiefs had been established. Subsequently, he supplied rituals for the Second Order. The rituals were based on the tradition of the tomb of Christian Rosenkreuz, and a "Vault of Adepts" became the controlling force behind the Outer Order. Later in 1916, Westcott claimed that Mathers also constructed these rituals from materials he received from Frater Lux ex Tenebris, a purported "Continental Adept".

Some followers of the Golden Dawn tradition believe that the Secret Chiefs were not human or supernatural beings, but rather symbolic representations of actual or legendary sources of spiritual esotericism. The term came to stand for a great leader or teacher of a spiritual path or practice that found its way into the teachings of the Order.

By the mid-1890s, the Golden Dawn was well established in Great Britain, with over one hundred members from every class of Victorian society. Many celebrities belonged to the Golden Dawn, such as the actress Florence Farr, the Irish revolutionary Maud Gonne, the Irish poet William Butler Yeats, the Welsh author Arthur Machen, and the English authors Evelyn Underhill and Aleister Crowley.

In 1896 or 1897, Westcott broke all ties to the Golden Dawn, leaving Mathers in control. It has been speculated that his departure was due to his having lost a number of occult-related papers in a hansom cab. Apparently, when the papers were found, Westcott's connection to the Golden Dawn was discovered and brought to the attention of his employers. He may have been told to either resign from the Order or to give up his occupation as coroner. After Westcott's departure, Mathers appointed Florence Farr to be Chief Adept in Anglia. Dr. Henry B. Pullen Burry succeeded Westcott as Cancellarius—one of the three Chiefs of the Order.

Mathers was the only active founding member after Westcott's departure. Due to personality clashes with other members and frequent absences from the center of Lodge activity in Great Britain, however, challenges to Mathers's authority as leader developed among the members of the Second Order.

Toward the end of 1899, the Adepts of the Isis-Urania and Amen-Ra temples had become dissatisfied with Mathers' leadership, as well as his growing friendship with Aleister Crowley. They had also become anxious to make contact with the Secret Chiefs themselves, instead of relying on Mathers as an intermediary. Within the Isis-Urania temple, disputes were arising between Farr's "The Sphere", a secret society within the Isis-Urania, and the rest of the Adepti Minores.

Crowley was refused initiation into the Adeptus Minor grade by the London officials. Mathers overrode their decision and quickly initiated him at the Ahathoor temple in Paris on January 16, 1900. Upon his return to the London temple, Crowley requested from Miss Cracknell, the acting secretary, the papers acknowledging his grade, to which he was now entitled. To the London Adepts, this was the final straw. Farr, already of the opinion that the London temple should be closed, wrote to Mathers expressing her wish to resign as his representative, although she was willing to carry on until a successor was found. Mathers believed Westcott was behind this turn of events and replied on February 16. On March 3, a committee of seven Adepts was elected in London, and requested a full investigation of the matter. Mathers sent an immediate reply, declining to provide proof, refusing to acknowledge the London temple, and dismissing Farr as his representative on March 23. In response, a general meeting was called on March 29 in London to remove Mathers as chief and expel him from the Order.

In 1901, W. B. Yeats privately published a pamphlet titled "Is the Order of R. R. & A. C. to Remain a Magical Order?"
After the Isis-Urania temple claimed its independence, there were even more disputes, leading to Yeats resigning. A committee of three was to temporarily govern, which included P.W. Bullock, M.W. Blackden and J. W. Brodie-Innes. After a short time, Bullock resigned, and Dr. Robert Felkin took his place.

In 1903, A. E. Waite and Blackden joined forces to retain the name Isis-Urania, while Felkin and other London members formed the Stella Matutina. Yeats remained in the Stella Matutina until 1921, while Brodie-Innes continued his Amen-Ra membership in Edinburgh.

Once Mathers realised that reconciliation was impossible, he made efforts to reestablish himself in London. The Bradford and Weston-super-Mare temples remained loyal to him, but their numbers were few. He then appointed Edward Berridge as his representative. According to Francis King, historical evidence shows that there were "twenty three members of a flourishing Second Order under Berridge-Mathers in 1913."

J.W. Brodie-Innes continued leading the Amen-Ra temple, deciding that the revolt was unjustified. By 1908, Mathers and Brodie-Innes were in complete accord. According to sources that differ regarding the actual date, sometime between 1901 and 1913 Mathers renamed the branch of the Golden Dawn remaining loyal to his leadership to Alpha et Omega. Brodie-Innes assumed command of the English and Scottish temples, while Mathers concentrated on building up his Ahathoor temple and extending his American connections. According to occultist Israel Regardie, the Golden Dawn had spread to the United States of America before 1900 and a Thoth-Hermes temple had been founded in Chicago. By the beginning of the First World War in 1914, Mathers had established two to three American temples.

Most temples of the Alpha et Omega and Stella Matutina closed or went into abeyance by the end of the 1930s, with the exceptions of two Stella Matutina temples: Hermes Temple in Bristol, which operated sporadically until 1970, and the Smaragdum Thallasses Temple (commonly referred to as Whare Ra) in Havelock North, New Zealand, which operated regularly until its closure in 1978.

Much of the hierarchical structure for the Golden Dawn came from the Societas Rosicruciana in Anglia, which was itself derived from the Order of the Golden and Rosy Cross.




The paired numbers attached to the Grades relate to positions on the Tree of Life. The Neophyte Grade of "0=0" indicates no position on the Tree. In the other pairs, the first numeral is the number of steps up from the bottom (Malkuth), and the second numeral is the number of steps down from the top (Kether).

The First Order Grades were related to the four elements of Earth, Air, Water, and Fire, respectively. The Aspirant to a Grade received instruction on the metaphysical meaning of each of these Elements and had to pass a written examination and demonstrate certain skills to receive admission to that Grade.

The Portal Grade was an "Invisible" or in-between grade separating the First Order from the Second Order.


While no temples in the original chartered lineage of the Golden Dawn survived past the 1970s, several organizations have since revived its teachings and rituals. Among these, the following are notable:

The Hermetic Order is a Secret Societies option in Civilization VI: Ethiopia Pack.





</doc>
<doc id="13790" url="https://en.wikipedia.org/wiki?curid=13790" title="Hash function">
Hash function

A hash function is any function that can be used to map data of arbitrary size to fixed-size values. The values returned by a hash function are called "hash values", "hash codes", "digests", or simply "hashes". The values are used to index a fixed-size table called a "hash table". Use of a hash function to index a hash table is called "hashing" or "scatter storage addressing".

Hash functions and their associated hash tables are used in data storage and retrieval applications to access data in a small and nearly constant time per retrieval, and storage space only fractionally greater than the total space required for the data or records themselves. Hashing is a computationally and storage space efficient form of data access which avoids the non-linear access time of ordered and unordered lists and structured trees, and the often exponential storage requirements of direct access of state spaces of large or variable-length keys.

Use of hash functions relies on statistical properties of key and function interaction: worst case behavior is intolerably bad with a vanishingly small probability, and average case behavior can be nearly optimal (minimal collisions).

Hash functions are related to (and often confused with) checksums, check digits, fingerprints, lossy compression, randomization functions, error-correcting codes, and ciphers. Although the concepts overlap to some extent, each one has its own uses and requirements and is designed and optimized differently.

A hash function takes an input as a key, which is associated with a datum or record and used to identify it to the data storage and retrieval application. The keys may be fixed length, like an integer, or variable length, like a name. In some cases, the key is the datum itself. The output is a hash code used to index a hash table holding the data or records, or pointers to them.

A hash function may be considered to perform three functions:
A good hash function satisfies two basic properties: 1) it should be very fast to compute; 2) it should minimize duplication of output values (collisions). Hash functions rely on generating favorable probability distributions for their effectiveness, reducing access time to nearly constant. High table loading factors, pathological key sets and poorly designed hash functions can result in access times approaching linear in the number of items in the table. 
Hash functions can be designed to give best worst-case performance, good performance under high table loading factors, and in special cases, perfect (collisionless) mapping of keys into hash codes. Implementation is based on parity-preserving bit operations (XOR and ADD), multiply, or divide. A necessary adjunct to the hash function is a collision-resolution method that employs an auxiliary data structure like linked lists, or systematic probing of the table to find an empty slot.

Hash functions are used in conjunction with Hash table to store and retrieve data items or data records. The hash function translates the key associated with each datum or record into a hash code which is used to index the hash table. When an item is to be added to the table, the hash code may index an empty slot (also called a bucket), in which case the item is added to the table there. If the hash code indexes a full slot, some kind of collision resolution is required: the new item may be omitted (not added to the table), or replace the old item, or it can be added to the table in some other location by a specified procedure. That procedure depends on the structure of the hash table: In "chained hashing", each slot is the head of a linked list or chain, and items that collide at the slot are added to the chain. Chains may be kept in random order and searched linearly, or in serial order, or as a self-ordering list by frequency to speed up access. In "open address hashing", the table is probed starting from the occupied slot in a specified manner, usually by linear probing, quadratic probing, or double hashing until an open slot is located or the entire table is probed (overflow). Searching for the item follows the same procedure until the item is located, an open slot is found or the entire table has been searched (item not in table).

Hash functions are also used to build caches for large data sets stored in slow media. A cache is generally simpler than a hashed search table, since any collision can be resolved by discarding or writing back the older of the two colliding items.

Hash functions are an essential ingredient of the Bloom filter, a space-efficient probabilistic data structure that is used to test whether an element is a member of a set.

A special case of hashing is known as geometric hashing or "the grid method". In these applications, the set of all inputs is some sort of metric space, and the hashing function can be interpreted as a partition of that space into a grid of "cells". The table is often an array with two or more indices (called a "grid file", "grid index", "bucket grid", and similar names), and the hash function returns an index tuple. This principle is widely used in computer graphics, computational geometry and many other disciplines, to solve many proximity problems in the plane or in three-dimensional space, such as finding closest pairs in a set of points, similar shapes in a list of shapes, similar images in an image database, and so on.

Hash tables are also used to implement associative arrays and dynamic sets.

A good hash function should map the expected inputs as evenly as possible over its output range. That is, every hash value in the output range should be generated with roughly the same probability. The reason for this last requirement is that the cost of hashing-based methods goes up sharply as the number of "collisions"—pairs of inputs that are mapped to the same hash value—increases. If some hash values are more likely to occur than others, a larger fraction of the lookup operations will have to search through a larger set of colliding table entries.

Note that this criterion only requires the value to be "uniformly distributed", not "random" in any sense. A good randomizing function is (barring computational efficiency concerns) generally a good choice as a hash function, but the converse need not be true.

Hash tables often contain only a small subset of the valid inputs. For instance, a club membership list may contain only a hundred or so member names, out of the very large set of all possible names. In these cases, the uniformity criterion should hold for almost all typical subsets of entries that may be found in the table, not just for the global set of all possible entries.

In other words, if a typical set of "m" records is hashed to "n" table slots, the probability of a bucket receiving many more than "m"/"n" records should be vanishingly small. In particular, if "m" is less than "n", very few buckets should have more than one or two records. A small number of collisions is virtually inevitable, even if "n" is much larger than "m" – see the birthday problem.

In special cases when the keys are known in advance and the key set is static, a hash function can be found that achieves absolute (or collisionless) uniformity. Such a hash function is said to be "perfect". There is no algorithmic way of constructing such a function - searching for one is a factorial function of the number of keys to be mapped versus the number of table slots they're mapped into. Finding a perfect hash function over more than a very small set of keys is usually computationally infeasible; the resulting function is likely to be more computationally complex than a standard hash function, and provides only a marginal advantage over a function with good statistical properties that yields a minimum number of collisions. See universal hash function.

When testing a hash function, the uniformity of the distribution of hash values can be evaluated by the chi-squared test. This test is a goodness-of-fit measure: it's the actual distribution of items in buckets versus the expected (or uniform) distribution of items. The formula is:
formula_1
where: formula_2 is the number of keys, formula_3 is the number of buckets, formula_4 is the number of items in bucket formula_5

A ratio within one confidence interval (0.95 - 1.05) is indicative that the hash function evaluated has an expected uniform distribution.

Hash functions can have some technical properties that make it more likely that they'll have a uniform distribution when applied. One is the strict avalanche criterion: whenever a single input bit is complemented, each of the output bits changes with a 50% probability. The reason for this property is that selected subsets of the key space may have low variability. In order for the output to be uniformly distributed, a low amount of variability, even one bit, should translate into a high amount of variability (i.e. distribution over the table space) in the output. Each bit should change with probability 50% because if some bits are reluctant to change, the keys become clustered around those values. If the bits want to change too readily, the mapping is approaching a fixed XOR function of a single bit. Standard tests for this property have been described in the literature. The relevance of the criterion to a multiplicative hash function is assessed here.

In data storage and retrieval applications, use of a hash function is a trade off between search time and data storage space. If search time were unbounded, a very compact unordered linear list would be the best medium; if storage space were unbounded, a randomly accessible structure indexable by the key value would be very large, very sparse, but very fast. A hash function takes a finite amount of time to map a potentially large key space to a feasible amount of storage space searchable in a bounded amount of time regardless of the number of keys. In most applications, it is highly desirable that the hash function be computable with minimum latency and secondarily in a minimum number of instructions.

Computational complexity varies with the number of instructions required and latency of individual instructions, with the simplest being the bitwise methods (folding), followed by the multiplicative methods, and the most complex (slowest) are the division-based methods.

Because collisions should be infrequent, and cause a marginal delay but are otherwise harmless, it's usually preferable to choose a faster hash function over one that needs more computation but saves a few collisions.

Division-based implementations can be of particular concern, because division is microprogrammed on nearly all chip architectures. Divide (modulo) by a constant can be inverted to become a multiply by the word-size multiplicative-inverse of the constant. This can be done by the programmer, or by the compiler. Divide can also be reduced directly into a series of shift-subtracts and shift-adds, though minimizing the number of such operations required is a daunting problem; the number of assembly instructions resulting may be more than a dozen, and swamp the pipeline. If the architecture has a hardware multiply functional unit, the multiply-by-inverse is likely a better approach.

We can allow the table size "n" to not be a power of 2 and still not have to perform any remainder or division operation, as these computations are sometimes costly. For example, let "n" be significantly less than 2. Consider a pseudorandom number generator function "P"(key) that is uniform on the interval [0, 2 − 1]. A hash function uniform on the interval [0, n-1] is "n" "P"(key)/2. We can replace the division by a (possibly faster) right bit shift: "nP"(key) » "b".

If keys are being hashed repeatedly, and the hash function is costly, computing time can be saved by precomputing the hash codes and storing them with the keys. Matching hash codes almost certainly mean the keys are identical. This technique is used for the transposition table in game-playing programs, which stores a 64-bit hashed representation of the board position.

A "universal hashing" scheme is a randomized algorithm that selects a hashing function "h" among a family of such functions, in such a way that the probability of a collision of any two distinct keys is 1/"m", where "m" is the number of distinct hash values desired—independently of the two keys. Universal hashing ensures (in a probabilistic sense) that the hash function application will behave as well as if it were using a random function, for any distribution of the input data. It will, however, have more collisions than perfect hashing and may require more operations than a special-purpose hash function.

A hash function is applicable in a variety of situations.
A hash function that allows only certain table sizes, strings only up to a certain length, or can't accept a seed (i.e. allow double hashing) isn't as useful as one that does.

A hash procedure must be deterministic—meaning that for a given input value it must always generate the same hash value. In other words, it must be a function of the data to be hashed, in the mathematical sense of the term. This requirement excludes hash functions that depend on external variable parameters, such as pseudo-random number generators or the time of day. It also excludes functions that depend on the memory address of the object being hashed in cases that the address may change during execution (as may happen on systems that use certain methods of garbage collection), although sometimes rehashing of the item is possible.

The determinism is in the context of the reuse of the function. For example, Python adds the feature that hash functions make use of a randomized seed that is generated once when the Python process starts in addition to the input to be hashed. The Python hash is still a valid hash function when used within a single run. But if the values are persisted (for example, written to disk) they can no longer be treated as valid hash values, since in the next run the random value might differ.

It is often desirable that the output of a hash function have fixed size (but see below). If, for example, the output is constrained to 32-bit integer values, the hash values can be used to index into an array. Such hashing is commonly used to accelerate data searches. 
Producing fixed-length output from variable length input can be accomplished by breaking the input data into chunks of specific size. Hash functions used for data searches use some arithmetic expression which iteratively processes chunks of the input (such as the characters in a string) to produce the hash value.

In many applications, the range of hash values may be different for each run of the program, or may change along the same run (for instance, when a hash table needs to be expanded). In those situations, one needs a hash function which takes two parameters—the input data "z", and the number "n" of allowed hash values.

A common solution is to compute a fixed hash function with a very large range (say, 0 to 2 − 1), divide the result by "n", and use the division's remainder. If "n" is itself a power of 2, this can be done by bit masking and bit shifting. When this approach is used, the hash function must be chosen so that the result has fairly uniform distribution between 0 and "n" − 1, for any value of "n" that may occur in the application. Depending on the function, the remainder may be uniform only for certain values of "n", e.g. odd or prime numbers.

When the hash function is used to store values in a hash table that outlives the run of the program, and the hash table needs to be expanded or shrunk, the hash table is referred to as a dynamic hash table.

A hash function that will relocate the minimum number of records when the table is resized is desirable.
What is needed is a hash function "H"("z","n") – where "z" is the key being hashed and "n" is the number of allowed hash values – such that "H"("z","n" + 1) = "H"("z","n") with probability close to "n"/("n" + 1).

Linear hashing and spiral storage are examples of dynamic hash functions that execute in constant time but relax the property of uniformity to achieve the minimal movement property. Extendible hashing uses a dynamic hash function that requires space proportional to "n" to compute the hash function, and it becomes a function of the previous keys that have been inserted. Several algorithms that preserve the uniformity property but require time proportional to "n" to compute the value of "H"("z","n") have been invented.

A hash function with minimal movement is especially useful in distributed hash tables.

In some applications, the input data may contain features that are irrelevant for comparison purposes. For example, when looking up a personal name, it may be desirable to ignore the distinction between upper and lower case letters. For such data, one must use a hash function that is compatible with the data equivalence criterion being used: that is, any two inputs that are considered equivalent must yield the same hash value. This can be accomplished by normalizing the input before hashing it, as by upper-casing all letters.

There are several common algorithms for hashing integers. The method giving the best distribution is data-dependent. One of the simplest and most common methods in practice is the modulo division method.

If the data to be hashed is small enough, one can use the data itself (reinterpreted as an integer) as the hashed value. The cost of computing this "identity" hash function is effectively zero. This hash function is perfect, as it maps each input to a distinct hash value.

The meaning of "small enough" depends on the size of the type that is used as the hashed value. For example, in Java, the hash code is a 32-bit integer. Thus the 32-bit integer codice_1 and 32-bit floating-point codice_2 objects can simply use the value directly; whereas the 64-bit integer codice_3 and 64-bit floating-point codice_4 cannot use this method.

Other types of data can also use this hashing scheme. For example, when mapping character strings between upper and lower case, one can use the binary encoding of each character, interpreted as an integer, to index a table that gives the alternative form of that character ("A" for "a", "8" for "8", etc.). If each character is stored in 8 bits (as in extended ASCII or ISO Latin 1), the table has only 2 = 256 entries; in the case of Unicode characters, the table would have 17×2 = entries.

The same technique can be used to map two-letter country codes like "us" or "za" to country names (26 = 676 table entries), 5-digit zip codes like 13083 to city names ( entries), etc. Invalid data values (such as the country code "xx" or the zip code 00000) may be left undefined in the table or mapped to some appropriate "null" value.

If the keys are uniformly or sufficiently uniformly distributed over the key space, so that the key values are essentially random, they may be considered to be already 'hashed'. In this case, any number of any bits in the key may be dialed out and collated as an index into the hash table. A simple such hash function would be to mask off the bottom "m" bits to use as an index into a table of size 2.

A folding hash code is produced by dividing the input into n sections of m bits, where 2^m is the table size, and using a parity-preserving bitwise operation like ADD or XOR, to combine the sections. The final operation is a mask or shift to trim off any excess bits at the high or low end.
For example, for a table size of 15 bits and key value of 0x0123456789ABCDEF, there are 5 sections 0x4DEF, 0x1357, 0x159E, 0x091A and 0x8. Adding, we obtain 0x7AA4, a 15-bit value.

A mid-squares hash code is produced by squaring the input and extracting an appropriate number of middle digits or bits. For example, if the input is 123,456,789 and the hash table size 10,000, squaring the key produces 1.524157875019e16, so the hash code is taken as the middle 4 digits of the 17-digit number (ignoring the high digit) 8750. The mid-squares method produces a reasonable hash code if there are not a lot of leading or trailing zeros in the key. This is a variant of multiplicative hashing, but not as good, because an arbitrary key is not a good multiplier.

A standard technique is to use a modulo function on the key, by selecting a divisor formula_6 which is a prime number close to the table size, so formula_7. The table size is usually a power of 2. This gives a distribution from formula_8. This gives good results over a large number of key sets. A significant drawback of division hashing is that division is microprogrammed on most modern architectures including x86, and can be 10 times slower than multiply. A second drawback is that it won't break up clustered keys. For example, the keys 123000, 456000, 789000, etc. modulo 1000 all map to the same address. This technique works well in practice because many key sets are sufficiently random already, and the probability that a key set will be cyclical by a large prime number is small.

Algebraic coding is a variant of the division method of hashing which uses division by a polynomial modulo 2 instead of an integer to map n bits to m bits. In this approach, formula_9 and we postulate an formula_3th degree polynomial formula_11. A key formula_12 can be regarded as the polynomial formula_13. The remainder using polynomial arithmetic modulo 2 is formula_14. Then formula_15. If formula_16 is constructed to have t or fewer non-zero coefficients, then keys differing by t or fewer bits are guaranteed to not collide.

Z a function of k, t and n, a divisor of 2-1, is constructed from the GF(2) field. Knuth gives an example: for n=15, m=10 and t=7, formula_17. The derivation is as follows: 

The usual outcome is that either n will get large, or t will get large, or both, in order for the scheme to be computationally feasible. Therefore, its more suited to hardware or microcode implementation.

See also unique permutation hashing, which has a guaranteed best worst-case insertion time.

Standard multiplicative hashing uses the formula formula_33 which produces a hash value in formula_34. The value formula_35 is an appropriately chosen value that should be relatively prime to formula_36; it should be large and its binary representation a random mix of 1's and 0's. An important practical special case occurs when formula_37 and formula_38 are powers of 2 and formula_39 is the machine word size. In this case this formula becomes formula_40. This is special because arithmetic modulo formula_41 is done by default in low-level programming languages and integer division by a power of 2 is simply a right-shift, so, in C, for example, this function becomes
and for fixed formula_3 and formula_39 this translates into a single integer multiplication and right-shift making it one of the fastest hash functions to compute.

Multiplicative hashing is susceptible to a "common mistake" that leads to poor diffusion—higher-value input bits do not affect lower-value output bits. A transmutation on the input which shifts the span of retained top bits down and XORs or ADDs them to the key before the multiplication step corrects for this. So the resulting function looks like:

Fibonacci hashing is a form of multiplicative hashing in which the multiplier is formula_44, where formula_45 is the machine word length and 
formula_46 (phi) is the golden ratio. formula_46 is an irrational number with approximate value 5/3, and decimal expansion of 1.618033... A property of this multiplier is that it uniformly distributes over the table space, blocks of consecutive keys with respect to any block of bits in the key. Consecutive keys within the high bits or low bits of the key (or some other field) are relatively common. The multipliers for various word lengths formula_45 are:

Tabulation hashing, more generally known as "Zobrist hashing" after Albert Zobrist, an American computer scientist, is a method for constructing universal families of hash functions by combining table lookup with XOR operations. This algorithm has proven to be very fast and of high quality for hashing purposes (especially hashing of integer-number keys).

Zobrist hashing was originally introduced as a means of compactly representing chess positions in computer game playing programs. A unique random number was assigned to represent each type of piece (six each for black and white) on each space of the board. Thus a table of 64x12 such numbers is initialized at the start of the program. The random numbers could be any length, but 64 bits was natural due to the 64 squares on the board. A position was transcribed by cycling through the pieces in a position, indexing the corresponding random numbers (vacant spaces were not included in the calculation), and XORing them together (the starting value could be 0, the identity value for XOR, or a random seed). The resulting value was reduced by modulo, folding or some other operation to produce a hash table index. The original Zobrist hash was stored in the table as the representation of the position.

Later, the method was extended to hashing integers by representing each byte in each of 4 possible positions in the word by a unique 32-bit random number. Thus, a table of 2x4 of such random numbers is constructed. A 32-bit hashed integer is transcribed by successively indexing the table with the value of each byte of the plain text integer and XORing the loaded values together (again, the starting value can be the identity value or a random seed). The natural extension to 64-bit integers is by use of a table of 2x8 64-bit random numbers.

This kind of function has some nice theoretical properties, one of which is called "3-tuple independence" meaning every 3-tuple of keys is equally likely to be mapped to any 3-tuple of hash values.

A hash function can be designed to exploit existing entropy in the keys. If the keys have leading or trailing zeros, or particular fields that are unused, always zero or some other constant, or generally vary little, then masking out only the volatile bits and hashing on those will provide a better and possibly faster hash function. Selected divisors or multipliers in the division and multiplicative schemes may make more uniform hash functions if the keys are cyclic or have other redundancies.

When the data values are long (or variable-length) character strings—such as personal names, web page addresses, or mail messages—their distribution is usually very uneven, with complicated dependencies. For example, text in any natural language has highly non-uniform distributions of characters, and character pairs, characteristic of the language. For such data, it is prudent to use a hash function that depends on all characters of the string—and depends on each character in a different way.

Simplistic hash functions may add the first and last "n" characters of a string along with the length, or form a word-size hash from the middle 4 characters of a string. This saves iterating over the (potentially long) string,
but hash functions which do not hash on all characters of a string can readily become linear due to redundancies, clustering or other pathologies in the key set. Such strategies may be effective as a custom hash function if the structure of the keys is such that either the middle, ends or other field(s) are zero or some other invariant constant that doesn't differentiate the keys; then the invariant parts of the keys can be ignored.

The paradigmatic example of folding by characters is to add up the integer values of all the characters in the string. A better idea is to multiply the hash total by a constant, typically a sizeable prime number, before adding in the next character, ignoring overflow. Using exclusive 'or' instead of add is also a plausible alternative. The final operation would be a modulo, mask, or other function to reduce the word value to an index the size of the table. The weakness of this procedure is that information may cluster in the upper or lower bits of the bytes, which clustering will remain in the hashed result and cause more collisions than a proper randomizing hash. ASCII byte codes, for example, have an upper bit of 0 and printable strings don't use the first 32 byte codes, so the information (95 byte codes) is clustered in the remaining bits in an unobvious manner.

The classic approach dubbed the PJW hash based on the work of Peter. J. Weinberger at ATT Bell Labs in the 1970s, was originally designed for hashing identifiers into compiler symbol tables as given in the "Dragon Book". This hash function offsets the bytes 4 bits before ADDing them together. When the quantity wraps, the high 4 bits are shifted out and if non-zero, XORed back into the low byte of the cumulative quantity. The result is a word size hash code to which a modulo or other reducing operation can be applied to produce the final hash index.

Today, especially with the advent of 64-bit word sizes, much more efficient variable length string hashing by word-chunks is available.

Modern microprocessors will allow for much faster processing, if 8-bit character strings are not hashed by processing one character at a time, but by interpreting the string as an array of 32 bit or 64 bit integers and hashing/accumulating these "wide word" integer values by means of arithmetic operations (e.g. multiplication by constant and bit-shifting). The final word, which may have unoccupied byte positions, is filled with zeros or a specified "randomizing" value before being folded into the hash. The accumulated hash code is reduced by a final modulo or other operation to yield an index into the table.

Analogous to the way an ASCII or EBCDIC character string representing a decimal number is converted to a numeric quantity for computing, a variable length string can be converted as (xa+xa+...+xa+x). This is simply a polynomial in a non-zero "radix" "a"!=1 that takes the components (x,x...,x) as the characters of the input string of length k. It can be used directly as the hash code, or a hash function applied to it to map the potentially large value to the hash table size. The value of "a" is usually a prime number at least large enough to hold the number of different characters in the character set of potential keys. Radix conversion hashing of strings minimizes the number of collisions. Available data sizes may restrict the maximum length of string that can be hashed with this method. For example, a 128-bit double long word will hash only a 26 character alphabetic string (ignoring case) with a radix of 29; a printable ASCII string is limited to 9 characters using radix 97 and a 64-bit long word. However, alphabetic keys are usually of modest length, because keys must be stored in the hash table. Numeric character strings are usually not a problem; 64 bits can count up to 10, or 19 decimal digits with radix 10.

In some applications, such as substring search, one can compute a hash function "h" for every "k"-character substring of a given "n"-character string by advancing a window of width "k" characters along the string; where "k" is a fixed integer, and "n" is greater than "k". The straightforward solution, which is to extract such a substring at every character position in the text and compute "h" separately, requires a number of operations proportional to "k"·"n". However, with the proper choice of "h", one can use the technique of rolling hash to compute all those hashes with an effort proportional to "mk" + "n" where "m" is the number of occurrences of the substring.

The most familiar algorithm of this type is Rabin-Karp with best and average case performance "O(n+mk)" and worst case "O(n·k)" (in all fairness, the worst case here is gravely pathological: both the text string and substring are composed of a repeated single character, such as t="AAAAAAAAAAA", and s="AAA"). The hash function used for the algorithm is usually the Rabin fingerprint, designed to avoid collisions in 8-bit character strings, but other suitable hash functions are also used.

Worst case result for a hash function can be assessed two ways: theoretical and practical. Theoretical worst case is the probability that all keys map to a single slot. Practical worst case is expected longest probe sequence (hash function + collision resolution method). This analysis considers uniform hashing, that is, any key will map to any particular slot with probability 1/m, characteristic of universal hash functions.

While Knuth worries about adversarial attack on real time systems, Gonnet has shown that the probability of such a case is "ridiculously small". His representation was that the probability of k of n keys mapping to a single slot is formula_49 where formula_50 is the load factor, n/m.

The term "hash" offers a natural analogy with its non-technical meaning (to "chop" or "make a mess" out of something), given how hash functions scramble their input data to derive their output. In his research for the precise origin of the term, Donald Knuth notes that, while Hans Peter Luhn of IBM appears to have been the first to use the concept of a hash function in a memo dated January 1953, the term itself would only appear in published literature in the late 1960s, on Herbert Hellerman's "Digital Computer System Principles", even though it was already widespread jargon by then.



</doc>
<doc id="13791" url="https://en.wikipedia.org/wiki?curid=13791" title="High jump">
High jump

The high jump is a track and field event in which competitors must jump unaided over a horizontal bar placed at measured heights without dislodging it. In its modern most practiced format, a bar is placed between two standards with a crash mat for landing. In the modern era, athletes run towards the bar and use the Fosbury Flop method of jumping, leaping head first with their back to the bar. Since ancient times, competitors have introduced increasingly effective techniques to arrive at the current form.

The discipline is, alongside the pole vault, one of two vertical clearance events to feature on the Olympic athletics programme. It is contested at the World Championships in Athletics and IAAF World Indoor Championships, and is a common occurrence at track and field meetings. The high jump was among the first events deemed acceptable for women, having been held at the 1928 Olympic Games.

Javier Sotomayor (Cuba) is the current men's record holder with a jump of set in 1993 – the longest standing record in the history of the men's high jump. Stefka Kostadinova (Bulgaria) has held the women's world record at since 1987, also the longest-held record in the event.

The rules for the high jump are set internationally by the International Association of Athletics Federations (IAAF). Jumpers must take off on one foot. A jump is considered a failure if the bar is dislodged by the action of the jumper whilst jumping or the jumper touches the ground or breaks the plane of the near edge of the bar before clearance. The technique one uses for the jump must be almost flawless in order to have a chance of clearing a high bar.

Competitors may begin jumping at any height announced by the chief judge, or may pass, at their own discretion. Most competitions state that three consecutive missed jumps, at any height or combination of heights, will eliminate the jumper from competition.

The victory goes to the jumper who clears the greatest height during the final. Tie-breakers are used for any place in which scoring occurs. If two or more jumpers tie for one of these places, the tie-breakers are: 1) the fewest misses at the height at which the tie occurred; and 2) the fewest misses throughout the competition.

If the event remains tied for first place (or a limited advancement position to a subsequent meet), the jumpers have a jump-off, beginning at the next greater height. Each jumper has one attempt. The bar is then alternately lowered and raised until only one jumper succeeds at a given height.

The first recorded high jump event took place in Scotland in the 19th century. Early jumpers used either an elaborate straight-on approach or a scissors technique. In later years, soon then after, the bar was approached diagonally, and the jumper threw first the inside leg and then the other over the bar in a scissoring motion. Around the turn of the 20th century, techniques began to change, beginning with the Irish-American Michael Sweeney's "Eastern cut-off". By taking off like the scissors and extending his spine and flattening out over the bar, Sweeney raised the world record to in 1895.

Another American, George Horine, developed an even more efficient technique, the "Western roll". In this style, the bar again is approached on a diagonal, but the inner leg is used for the take-off, while the outer leg is thrust up to lead the body sideways over the bar. Horine increased the world standard to in 1912. His technique was predominant through the Berlin Olympics of 1936, in which the event was won by Cornelius Johnson at .

American and Soviet jumpers were the most successful for the next four decades, and they pioneered the evolution of the straddle technique. Straddle jumpers took off as in the Western roll, but rotated their (belly-down) torso around the bar, obtaining the most efficient and highest clearance (of the bar) up to that time. Straddle-jumper, Charles Dumas, was the first to clear 7 feet (2.13 m), in 1956, American John Thomas pushed the world mark to in 1960. Valeriy Brumel took over the event for the next four years. The elegant Soviet jumper radically sped up his approach run, took the record up to , and won the Olympic gold medal in 1964, before a motorcycle accident ended his career.

American coaches, including two-time NCAA champion Frank Costello of the University of Maryland, flocked to Russia to learn from Brumel and his coaches. However, it would be a solitary innovator at Oregon State University, Dick Fosbury, who would bring the high jump into the next century. Taking advantage of the raised, softer landing areas by then in use, Fosbury added a new twist to the outmoded Eastern Cut-off. He directed himself over the bar head and shoulders first, sliding over on his back and landing in a fashion which would likely have broken his neck in the old, sawdust landing pits. After he used this Fosbury flop to win the 1968 Olympic gold medal, the technique began to spread around the world, and soon "floppers" were dominating international high jump competitions. The last straddler to set a world record was Vladimir Yashchenko, who cleared in 1977 and then indoors in 1978.

Among renowned high jumpers following Fosbury's lead were Americans Dwight Stones and his rival, tall Franklin Jacobs of Paterson, NJ, who cleared , over his head (a feat equalled 27 years later by Sweden's Stefan Holm); Chinese record-setters Ni-chi Chin and Zhu Jianhua; Germans Gerd Wessig and Dietmar Mögenburg; Swedish Olympic medalist and former world record holder Patrik Sjöberg; and female jumpers Iolanda Balaş of Romania, Ulrike Meyfarth of Germany and Italy's Sara Simeoni.

The most important aspect to put of all pieces of the jump together is the body mechanics the jumper uses to jump. Technique and form has evolved greatly over the history of high jump. The popularity of a style depend upon the time period as listed here:

Beginnings (1790 - 1875) --> two legged lift over bar / 
Basic Scissors (1875 - 1892) --> standing jump and straight run-up / 
Eastern Cut-off scissors (1892 - 1912) --> scissors with rotation / 
Western Roll (1912 - 1930) --> early straddle technique / 
Straddle (1930 - 1960) --> basic straddle technique / 
Dive Straddle (1960 - 1978) --> advanced straddle technique / 
Fosbury Flop (1968 - current) --> the currently most common technique used /

The Fosbury Flop is currently deemed as the most efficient way for competitors of the event to propel themselves over the bar. Still depending on the individual athletes specific strengths and weaknesses there are variations on the separate pieces that make up the jump.

For a Fosbury flop depending on the athletes jump foot they will start on the right of left of the mat. Placing their jump foot furthest away from the high jump mat. The athlete will have an eight to ten step approach in total, the last five steps being a curve with three or five steps before on a straight. The athlete will want to mark their approach to attempt to find as much consistency as possible.

The approach run of the high jump may actually be more important than the take-off. If a high jumper runs with bad timing or without enough aggression, clearing a high bar becomes more of a challenge. The approach requires a certain shape or curve, the right amount of speed, and the correct number of strides. The approach angle is also critical for optimal height.

The straight run will build the momentum and set the tone for the athletes jump. The athlete will start by pushing off with the take off foot with slow powerful steps then begin to quicken and accelerate them. The athlete should be tall and running up right by the end of their three or five steps.

On the first step of the curve the athletes take off foot will be landing, they will want to continue accelerating and curving focusing the body towards the opposite back corner of the high jump mat. While staying tall, erect, and leaning away from the mat the athlete should make sure that their final two steps are flat footed, rolling from the heel to toe as well as being the quickest steps.

Most great straddle jumpers have a run at angles of about 30 to 40 degrees. The length of the run is determined by the speed of the person's approach. A slower run requires about 8 strides. However, a faster high jumper might need about 13 strides. A greater run speed allows a greater part of the body's forward momentum to be converted upward.

The J type approach, favored by Fosbury floppers, allows for horizontal speed, the ability to turn in the air (centripetal force), and good take-off position. This allows for horizontal momentum to turn into vertical momentum, propelling the jumper off the ground and over the bar. The approach should be a hard controlled stride so that a person does not fall from creating an angle with speed. Athletes should run tall and lean on the curve, from the ankles and not the hips. This allows the correct angle to force their hips to rotate during take-off, which allows their center of gravity to pass under the bar.

The take off can have slight variations depending on what feels most natural to the athlete. The double arm take off and the single arm take off. With most things in common, for both the athlete should make sure not to take off at the center of the bar. The plant foot should be the foot furthest away from the bar, angled towards the opposite back corner of the matt, and driving the non take off leg knee up. Keeping in mind this is a vertical jump pushing all force straight up. This will be accompanied with a one or two arm swing while driving the knee.

Unlike the classic straddle technique, where the take-off foot is "planted" in the same spot at every height, flop-style jumpers must adjust their take-off as the bar is raised. Their approach run must be adjusted slightly so that their take-off spot is slightly further out from the bar in order to allow their hips to clear the bar while still maintaining enough momentum to carry their legs across the bar. Jumpers attempting to reach record heights commonly fail when most of their energy is directed into the vertical effort, and they brush the bar off the standards with the backs of their legs as they stall out in mid-air.

An effective approach shape can be derived from physics. For example, the rate of backward spin required as the jumper crosses the bar to facilitate shoulder clearance on the way up and foot clearance on the way down can be determined by computer simulation. This rotation rate can be back-calculated to determine the required angle of lean away from the bar at plant, based on how long the jumper is on the take-off foot. This information, together with the jumper's speed in the curve, can be used to calculate the radius of the curved part of the approach. This is a lot of work and requires measurements of running speed and time of take-off foot on the ground. However, one can work in the opposite direction by assuming an approach radius and watching the resulting backward rotation. This only works if some basic rules are followed in how one executes the approach and take-off. 
Drills can be practiced to solidify the approach. One drill is to run in a straight line (the linear part of the approach) and then run two to three circles spiraling into one another. Another is to run or skip a circle of any size, two to three times in a row. It is important to train to leap upwards without first leaning into the bar, allowing the momentum of the J approach to carry the body across the bar.

The athlete's non take off leg knee will naturally turn their body placing them in the air with their back to the bar. The athlete will then drive their shoulders to the back of their feet arching their body over the bar. The athlete can look over their right should then judge appropriately when to kick both feet over their head causing their body to miss the bar and land on the mat.

In high jump, it helps if the athlete is tall, has long legs, and limited weight on their body. They must have a strong lower body and flexibility will help a lot as well. High jumpers tend to go through very vigorous training methods to achieve this ideal body frame.

High jumpers must have a fast approach so it is crucial to work on speed and also speed endurance. Many high jump competitions may take hours and athletes must make sure they have the endurance to last the entire competition. Common sprint endurance workouts for high jumpers include 200-, 400-, and 800-meter training. Other speed endurance training methods such as hill training or a ladder workout may also be used.

It is crucial for high jumpers to have strong lower bodies and cores, as the bar progressively gets higher, the strength of an athlete's legs (along with speed and technique) will help propel them over the bar. Squats, deadlifts, and core exercises will help a high jumper to achieve these goals. It is important, however, for a high jumper to keep a slim figure as any unnecessary weight makes it difficult to jump higher.

Arguably the most important training for a high jumper is plyometric training. Because high jump is such a technical event, any mistake in the technique could either lead to failure, injury, or both. To prevent these from happening, high jumpers tend to focus heavily on plyometrics. This includes hurdle jumps, flexibility training, skips, or scissor kick training. Plyometric workouts tend to be performed at the beginning of the workout.




Athletes who have won multiple titles at the two most important competitions, the Olympic Games and the World Championships:


Kostadinova and Sotomayor are the only high jumpers to have been Olympic Champion, World Champion and broken the world record.


All time lists of athletes with the highest recorded jumps above their own height.

, 73 different female athletes had ever been able to jump .





</doc>
<doc id="13792" url="https://en.wikipedia.org/wiki?curid=13792" title="Heraclitus">
Heraclitus

Heraclitus of Ephesus (; ; , 501/0BC) son of Bloson, was a pre-Socratic Ionian Greek philosopher, and a native of the city of Ephesus, in modern-day Turkey and then part of the Persian Empire.

Due to the oracular and paradoxical nature of his philosophy, and his fondness for word play, he was called "The Obscure" even in antiquity. He wrote a single work, "On Nature", but the obscurity is made worse by its remaining only in fragments. His cryptic utterances have been the subject of numerous interpretations. He has been seen variously as a "material monist or a process philosopher; a scientific cosmologist, a metaphysician, or mainly a religious thinker; an empiricist, a rationalist, or a mystic; a conventional thinker or a revolutionary; a developer of logic or one who denied the law of non-contradiction; the first genuine philosopher or an anti-intellectual obscurantist."

He was of distinguished parentage but eschewed his privileged life for a lonely one as a philosopher. Little else is known about his early life and education. He regarded himself as self-taught and a pioneer of wisdom. He was considered a misanthrope given to depression; he was also called "the weeping philosopher", in contrast to Democritus, "the laughing philosopher".

Heraclitus believed the world was in accordance with "Logos" (literally, "word", "reason", or "account"). He also believed the world was ultimately made of fire. He was committed to a unity of opposites and harmony in the world. He was most famous for his insistence on ever-present change, or flux or becoming, as the characteristic feature of the world, as stated in the famous saying, "No man ever steps in the same river twice" as well as "Panta rhei", everything flows. This aspect of his philosophy is contrasted with that of Parmenides, who believed in being, and that nothing changes. Both had an influence on Plato and thus, some speculate, on all of Western philosophy.

The dates for Heraclitus are uncertain. Scholars have generally believed that either Parmenides was responding to Heraclitus, or Heraclitus to Parmenides, though opinion on who was responding to whom has varied over the course of the 20th and 21st centuries. Most figure Parmenides was responding to Heraclitus, and therefore Heraclitus was the older of the two. Heraclitus is silent on Parmenides, yet Parmenides seems possibly to refer to him, and Heraclitus refers to the likes of Pythagoras.

The main source for the life of Heraclitus is the notable doxographer Diogenes Laërtius, although some have questioned the validity of his account as "a tissue of Hellenistic anecdotes, most of them obviously fabricated on the basis of statements in the preserved fragments". It also seems the stories about Heraclitus could be invented to illustrate his character as inferred from his writings.

Diogenes Laërtius said that Heraclitus flourished in the 69th Olympiad, 504–501 BC. Considerations such as that he was probably older than Parmenides, and a contemporary of Pythagoras, makes this time frame a reasonable "floruit". His dates of birth and death are based on a life span of 60 years, the age at which Diogenes Laërtius says he died, with this floruit in the middle.
Heraclitus was born to an aristocratic family in Ephesus, in the Persian Empire, in what is today called Efes, Turkey. His father was named either Blosôn or Herakôn. Diogenes Laërtius says that he abdicated the kingship ("basileia") in favor of his brother and Strabo confirms that there was a ruling family in Ephesus descended from the Ionian founder, Androclus, which still kept the title and could sit in the chief seat at the games, as well as a few other privileges. How much power the king had is another question, for Ephesus had been part of the Persian Empire since 547 BC and was ruled by a satrap, a more distant figure, as Cyrus the Great allowed the Ionians considerable autonomy.

Diogenes Laërtius says that Heraclitus used to play knucklebones with the youths in the great temple of Artemis, the Artemisium, one of the largest temples of the 6th century BC and one of the Seven Wonders of the Ancient World. When asked to start making laws he refused saying that the constitution ("politeia") was "ponêra", which can mean either that it was fundamentally wrong or that he considered it toilsome. Two extant letters between Heraclitus and Darius I, quoted by Diogenes Laërtius, are undoubtedly later forgeries.

With regard to education, Diogenes Laërtius says that Heraclitus was "wondrous" from childhood. Diogenes relates that Sotion said he was a "hearer" of Xenophanes, which contradicts Heraclitus' statement (so says Diogenes Laërtius) that he had taught himself by questioning himself. Burnet states in any case that "... Xenophanes left Ionia before Herakleitos was born." Diogenes Laërtius relates that as a boy Heraclitus had said he "knew nothing" but later claimed to "know everything". He "heard no one" but "questioned himself".

Diogenes Laërtius relates that Heraclitus had a poor opinion of human affairs. He said "The mysteries practiced among men are unholy mysteries." Timon of Phlius is said to have called him a "mob-reviler". He was not afraid of being a contrarian. He said "Corpses are more fit to be cast out than dung."
Heraclitus was no advocate of equality, "One is ten thousand to me, if he be the best." He is generally considered an opponent of democracy. Yet he thinks "All men have a claim to self-ascertainment and sound thinking," and "Thinking is common to all." Heraclitus stressed the heedless unconsciousness of humankind. "The waking have one common world, but the sleeping turn aside each into a world of his own ("idios kosmos")." "Hearing they do not understand, like the deaf. Of them does the saying bear witness: 'present, they are absent.'

He also compares the ignorance of the average man to dogs; "Dogs, also, bark at what they do not know." He advises us, "Let us not conjecture randomly about the most important things" and said "a fool is excited by every word."

He criticizes Hesiod, Pythagoras, Xenophanes, and Hecataeus as lacking understanding though learned, and has the most scorn for Pythagoras. Though he grants, "Men that love wisdom must be inquirers into very many things indeed;" he said that "The knowledge of the most famous persons, which they guard, is but opinion."

He also thought that Homer and Archilochus deserved to be beaten. The only man of note he praises is Bias of Priene, one of the Seven Sages of Greece, whose famous maxim is "most men are bad." "For what thought or wisdom have they? They follow the poets and take the crowd as their teacher, knowing not that "the many are bad and few good."

He hated the Athenians and his fellow Ephesians, wishing the latter wealth in punishment for their wicked ways. The Ephesians would "do well to end their lives, every grown man of them, and leave the city to beardless boys, for that they have driven out Hermodorus, the worthiest man among them, saying, 'We will have none who is worthiest among us; or if there be any such, let him go elsewhere and consort with others."

According to Diogenes Laërtius: "Finally, he became a hater of his kind ("misanthrope") and wandered the mountains [...] making his diet of grass and herbs."

Heraclitus' life as a philosopher was interrupted by dropsy. The physicians he consulted were unable to prescribe a cure. Diogenes Laërtius lists various stories about Heraclitus' death: In two versions, Heraclitus was cured of the dropsy and died of another disease. In one account, however, the philosopher "buried himself in a cowshed, expecting that the noxious damp humour would be drawn out of him by the warmth of the manure", while another says he treated himself with a liniment of cow manure and, after a day prone in the sun, died and was interred in the marketplace. According to Neathes of Cyzicus, after smearing himself with dung, Heraclitus was devoured by dogs. He died after 478 BC from a hydropsy.

Burnet has a different theory:"Herakleitos said (fr. 68) that it was death to souls to become water; and we are told accordingly that he died of dropsy. He said (fr. 114) that the Ephesians should leave their city to their children, and (fr. 79) that Time was a child playing draughts. We are therefore told that he refused to take any part in public life, and went to play with the children in the temple of Artemis. He said (fr. 85) that corpses were more fit to be cast out than dung; and we are told that he covered himself with dung when attacked with dropsy. Lastly, he is said to have argued at great length with his doctors because of fr. 58. For these tales see Diog.ix. 3–5."

Heraclitus was known to have produced a single work on papyrus, "On Nature". Diogenes Laërtius tells us that Heraclitus deposited his book as a dedication in the Artemisium. As with the other pre-Socratics, his writings survive now only in quoted by other authors. In the case of Heraclitus, there are over one hundred. These are catalogued using the Diels–Kranz numbering system.

Diogenes Laërtius also states that Heraclitus' work was "a continuous treatise...but was divided into three discourses, one on the universe, another on politics, and a third on theology." He does not say whether Heraclitus divided them this way or someone else did. Theophrastus says (in Diogenes Laërtius) "...some parts of his work [are] half-finished, while other parts [made] a strange medley."

Burnet does not think the work had a title:"We do not know the title of the work of Herakleitos.—if, indeed, it had one— and it is not easy to form a clear idea of its contents. We are told that it was divided into three discourses: one dealing with the universe, one political, and one theological. It is not to be supposed that this division is due to Herakleitos himself; all we can infer is that the work fell naturally into these three parts when the Stoic commentators took their editions of it in hand."We do know the work's opening lines, proving it was indeed a continuous work. Aristotle quotes part of the opening line in the "Rhetoric" to outline the difficulty in punctuating Heraclitus without ambiguity; whether "forever" applied to "being" or to "prove". Sextus Empiricus in "Against the Mathematicians" quotes the whole thing: 
"Of this "Logos" being forever do men prove to be uncomprehending, both before they hear and once they have heard it. For, though all things come to pass in accordance with this "Logos", they are like the unexperienced experiencing words and deeds such as I explain when I distinguish each thing according to its nature and show how it is. Other men are unaware of what they do when they are awake just as they are forgetful of what they do when they are asleep."

Many subsequent philosophers in this period refer to the work. Says Kahn: "Down to the time of Plutarch and Clement, if not later, the little book of Heraclitus was available in its original form to any reader who chose to seek it out." Diogenes Laërtius says: "the book acquired such fame that it produced partisans of his philosophy who were called Heracliteans." Cratylus was one such follower. Antisthenes was another.

At some time in antiquity he acquired this epithet denoting that his major sayings were difficult to understand, with frequent paradox, metaphor, and pregnant utterances. In the "Metaphysics" Aristotle mentions how some say Heraclitus denied the law of noncontradiction, and accuses him of not reasoning. According to Diogenes Laërtius, Timon of Phlius called him "the Riddler" (; ), and explained that Heraclitus wrote his book "rather unclearly" ("asaphesteron") so that only the "capable" should attempt it. Heraclitus himself wrote "The lord whose is the oracle at Delphi neither speaks nor hides his meaning, but gives a sign."
By the time of Cicero he had become "the dark" (; ) because he had spoken "nimis obscurē", "too obscurely", concerning nature and had done so deliberately in order to be misunderstood. The customary English translation of follows the Latin, "the Obscure".

A later tradition referred to Heraclitus as the "weeping philosopher", as opposed to Democritus, who is known as the "laughing philosopher". This was their reaction to the folly of mankind. Diogenes Laërtius ascribes the theory that Heraclitus did not complete some of his works because of melancholia to Theophrastus, though apparently in Theophrastus's time this meant impulsiveness. If Stobaeus writes correctly, Sotion in the early 1st century AD was already combining the two in the imaginative duo of weeping and laughing philosophers: "Among the wise, instead of anger, Heraclitus was overtaken by tears, Democritus by laughter."

The view is also expressed by the satirist Juvenal:

The motif was also adopted by Lucian of Samosata in his "Sale of Creeds", in which the duo is sold together as a complementary product in the satirical auction of philosophers.

Heraclitus's philosophy of change is commonly called becoming, and can be seen in a dialectical relationship and contrasted with Parmenides' concept of "being". For this reason, Heraclitus and Parmenides are commonly considered to be two of the founders of ontology and the issue of the One and the Many, and thus pivotal in the history of Western philosophy and metaphysics. 

Diogenes Laërtius has a quote summing up Heraclitus's philosophy: "All things come into being by conflict of opposites, and the sum of things ( "ta hola", "the whole") flows like a stream."

The meaning of "Logos" (λόγος) is subject to interpretation: "word", "account", "principle", "plan", "formula", "measure", "proportion", "reckoning." Though Heraclitus "quite deliberately plays on the various meanings of "logos"", there is no compelling reason to suppose that he used it in a special technical sense, significantly different from the way it was used in ordinary Greek of his time.

Zeller's opinion of Heraclitean logos:"λόγος  in my [Zeller's] opinion, refers indeed primarily to the discourse, but also to the contents of the discourse, the truth expressed in it; a confusion and identification of different ideas, united and apparently included in one word, which should least of all surprise us in Heracleitus. He [Heraclitus] says: ‘ This discourse (the theory of the world laid down in his work) is not recognised by men, although it ever exists (i.e. that which always exists, contains the eternal order of things, the eternal truth), for although all happens according to it (and thus its truth is confirmed by all facts universally) men behave as if they had never had any experience of it, when words or things present themselves to them, as I here represent them ’ (when the views here brought forward are shown them by instruction or by their own perceptions)"The later Stoics understood the "Logos" as "the account which governs everything," and Hippolytus, a Church Father in the 3rd century AD, identified it as meaning the Christian "Word of God", such as in , "In the beginning was the Word ("logos") and the Word was God."

Burnet's view of the relationship between Heraclitean logos and Johannine logos:"In any case, the Johannine doctrine of the logos has nothing to do with Herakleitos or with anything at all in Greek philosophy, but comes from the Hebrew Wisdom literature. See Rendel Harris, "The Origin of the Prologue to St. John's Gospel" in "The Expositor", 1916, pp. 147 sqq."

Heraclitus's ideas about the "Logos" are expressed in three famous but obscure fragments, with the first cited above, and two others. People must "follow the common" and not live having "their own judgement ("phronēsis")". He seems to say the "Logos" is a public fact perhaps like a proposition or formula, though he would not have considered such things as abstract objects or even immaterial. The last quote can even be taken to be a statement against making arguments "ad hominem":
For this reason it is necessary to follow what is common. But although the "Logos" is common, most people live as if they had their own private understanding.
Listening not to me but to the Logos...

Like the Milesians before him, Thales with water, Anaximander with apeiron, and Anaximenes with air, Heraclitus considered fire as the "arche", the most fundamental element, which gave rise to the other elements, perhaps because living people are warm. Norman Melchert interpreted Heraclitus as using "fire" metaphorically, in lieu of "Logos", as the origin of all things. Others see it as a metaphor for change, like a dancing and flickering flame, or perhaps all of these. It is also speculated this shows the influence of Persian Zoroastrianism, with its concept of Atar.
This world, which is the same for all, no one of gods or men has made. But it always was and will be: an ever-living fire, with measures of it kindling, and measures going out.
All things are an interchange for fire, and fire for all things, just like goods for gold and gold for goods.The thunderbolt that steers the course of all things.

The first quote is the earliest use of "kosmos" in any extant Greek text.

On Heraclitus using Fire as a new primary substance, Burnet writes:"All this made it necessary for him to seek out a new primary substance. He wanted not merely something from which opposites could be “ separated out,” but something which of its own nature would pass into everything else, while everything else would pass in turn into it. This he found in Fire, and it is easy to see why, if we consider the phenomenon of combustion. The quantity of fire in a flame burning steadily appears to remain the same, the flame seems to be what we call a “ thing.” And yet the substance of it is continually changing. It is always passing away in smoke, ‘and its place is always being taken by fresh matter from the fuel that feeds it. This is just what we want. If we regard the world as an ” ever-living fire ” (fr. 20), we can understand how it is always becoming all things, while all things are always returning to it."

In a seeming response to Anaximander, Heraclitus also believed in a unity of opposites. He characterized all existing entities by pairs of contrary properties

This is most famously expressed with his claim "Mortals are immortals and immortals are mortals, the one living the others' death and dying the others' life". This is taken to mean men are mortal gods, and gods immortal men. He would also point out that sleep is like death. He was fond of speaking this way. He also said "Man kindles a light for himself in the night-time, when he has died but is alive. The sleeper, whose vision has been put out, lights up from the dead; he that is awake lights up from the sleeping," and "All the things we see when awake are death, even as all we see in slumber are sleep."

In this union of opposites, of both generation and destruction, Heraclitus called the oppositional processes (), "strife", and hypothesizes that the apparently stable state, (), or "justice", is a harmony of it. Anaximander described the same as injustice. Aristotle mentions that Heraclitus disliked Homer because he wished strife would leave the world, which for Heraclitus would destroy the world; "there would be no harmony without high and low notes, and no animals without male and female, which are opposites."

Heraclitus is the original philosopher to claim that war is a good thing. He also wrote "Every beast is driven to pasture by blows."
We must know that war is common to all and strife is justice, and that all things come into being through strife necessarily.
Gods and men honor those who are slain in battle.
The people must fight for its law as for its walls.

In a metaphor and one of the earliest uses of a force in the history of philosophy, Heraclitus compares the union of opposites to a strung bow or lyre held in shape by an equilibrium of the string tension:There is a harmony in the bending back ( "palintropos") as in the case of the bow and the lyre.

He claims this shows something true yet invisible about reality; "a hidden harmony is better than an apparent one." He also noted "the bow's name is life, though its work is death," a play on both bow and life being the same word as written – biós; further evidence of a continuous, written work.

On the unity of opposites, Burnet says:"The " strife of opposites " is really an “ attunement ” (armonia). From this it follows that wisdom is not a knowledge of many things, but the perception of the underlying unity of the warring opposites. That this really was the fundamental thought of Herakleitos is stated by Philo. He says: " For that which is made up of both the opposites is one; and, when the one is divided, the opposites are disclosed. Is not this just what the Greeks say their great and much belauded Herakleitos put in the forefront of his philosophy as summing it all up, and boasted of as a new discovery? ” "

On Heraclitus' teachings of the one and many, Burnet writes: "The truth Herakleitos proclaimed was that the world is at once one and many, and that it is just the “ opposite tension ” of the opposites that constitutes the unity of the One. It is the same conclusion as that of Pythagoras, though it is put in another way." Burnet also writes about Plato's understanding of Heraclitus:"According to Plato, then, Herakleitos taught that reality was at once many and one. This was not meant as a logical principle. The identity which Herakleitos explains as consisting in difference is just that of the primary substance in all its manifestations. This identity had been realised already by the Milesians, but they had found a difficulty in the difference. Anaximander had treated the strife of opposites as an “ injustice,” and what Herakleitos set himself to show was that, on the contrary, it was the highest justice (fr. 62)." 

Heraclitus also said "The way up and the way down is one and the same." Similarly he said "In writing, the course taken, straight and crooked, is one and the same." This can be interpreted in various ways.

One interpretation is that it shows his monism, though perhaps a dialectical one. Heraclitus does believe all is one. The full quote is "Listening not to me but to the Logos it is wise to agree that all things are one."
The one is made up of all things, and all things issue from the one.
Hesiod is most men's teacher. Men think he knew very many things, a man who did not know day or night! They are one.
Concerning a circle the beginning and end are common.

Another is it illustrates the cyclical nature of reality and transformation, a replacement of one element by another, "turnings of fire". This might be another "hidden harmony" and is more consistent with pluralism, not monism.
The death of fire is the birth of air, and the death of air is the birth of water.
For it is death to souls to become water, and death to water to become earth. But water comes from earth; and from water, soul.
Cold things become warm, and what is warm cools; what is wet dries, and the parched is moistened.
And it is the same thing in us that is quick and dead, awake and asleep, young and old; the former are shifted and become the latter, and the latter in turn are shifted and become the former.

This has also been interpreted to advocate relativism.
Good and ill are one.
Asses prefer straw to gold.
The sea is the purest and impurest water. Fish can drink it and it is good for them, to me it is undrinkable and destructive.

Heraclitus recognized the fundamental changing of objects with the flow of time (i.e., impermanence) and the philosophical issue of "becoming".

He is credited with the phrase (panta rhei) "everything flows." This famous aphorism used to characterize Heraclitus' thought comes from Simplicius, a neoplatonist, and from Plato's "Cratylus". The word "rhei" (as in rheology) is the Greek word for "to stream", and is etymologically related to Rhea according to Plato's "Cratylus". Compare with the Latin adages "Omnia mutantur" and "Tempora mutantur" (8 AD) and the Buddhist and Hindu concepts of "anicca."

On Heraclitus' teachings on Flux, Burnet writes:"Fire burns continuously and without interruption. It is always consuming fuel and always liberating smoke. Everything is either mounting upwards to serve as fuel, or sinking down wards after having nourished the flame. It follows that the whole of reality is like an ever-flowing stream, and that nothing is ever at rest for a moment. The substance of the things we see is in constant change. Even as we look at them, some of the stuff of which they are composed has already passed into something else, while fresh stuff has come into them from another source. This is usually summed up, appropriately enough, in the phrase "All things are flowing ” (panta rei), though this does not seem to be a quotation from Herakleitos. Plato, however, expresses the idea quite clearly. " Nothing ever is, everything is becoming "; " All things are in motion like streams ”; "All things are passing, and nothing abides ”; " Herakleitos says somewhere that all things pass and naught abides; and, comparing things to the current of a river, he says you cannot step twice into the same stream ” (cf. fr. 41). these are the terms in which he describes the system."

His philosophy has been summed up with another famous adage, "No man ever steps in the same river twice." It can be contrasted with Parmenides's statement that "whatever is, is, and what is not cannot be." Heraclitus uses the river image more than once:

Ever-newer waters flow on those who step into the same rivers.We both step and do not step in the same rivers. We are and are not.

The idea is referenced twice in Plato's "Cratylus". Instead of "flow" Plato uses "chōrei", "to change place" (; )."All entities move and nothing remains still""Everything changes and nothing remains still ... and ... you cannot step twice into the same stream"

Simplicius references it thus:"...the natural philosophers who follow Heraclitus, keeping in view the perpetual flux of generation and the fact that all corporeal things are coming to be and departing and never really are (as Timaeus said too) claim that all things are always in flux and that you could not step twice in the same river."

According to Aristotle, Cratylus went a step beyond his master's doctrine and proclaimed that one cannot step into the same river once. Compare the Japanese tale "Hōjōki," (1200 AD) which contains the same image of the changing river.

However, the German classicist and philosopher interprets this fragment as an indication by Heraclitus, for the world as a steady constant: "You will not find anything, in which the river remains constant. [...] Just the fact, that there is a particular river bed, that there is a source and an estuary etc. is something, that stays identical. And this is [...] the concept of a river".

Heraclitus does seem to say change is what unites things, as with his unity of opposites, or the quote "Even the "kykeon" falls apart if it is not stirred." and "Changing it rests."

Flux is also expressed by the fact that, rather than thinking the same Sun will rise tomorrow as rose today, Heraclitus said the Sun is new every day.

By "God" Heraclitus does not mean a single God as "primum movens" of all things, God as Creator, for the universe is eternal, "it always was and will be;" but the divine as opposed to human; the immortal as opposed to the mortal, the cyclical as opposed to the transient. It is arguably more accurate to speak of "the Divine" and not of "God".

Heraclitus distinguishes between human laws and divine law ( ). He said both God and fire are "want and surfeit". In addition to seeing fire as the most fundamental substance, he presents fire as the divine cosmos. Fire is both a substance and a motivator of change, it is active in altering other things. Heraclitus describes it as "the judging and convicting of all things." Judgment here is literally "to separate" (κρίνειν "krinein").

In antiquity this was interpreted to mean that eventually all things will be consumed by fire, a doctrine called ecpyrosis. Hippolytus, from whom we get the quotation, sees it as a reference to divine judgment and Hell. However, he removes the human sense of justice from his concept of God: "To God all things are fair and good and just, but people hold some things wrong and some right."

God's custom has wisdom but human custom does not. Wisdom is "to know the thought by which all things are steered through all things", which must not imply that people are or can be wise. Only Zeus is wise. To some degree then Heraclitus seems to be in the mystic's position of urging people to follow God's plan without much of an idea what that may be. In fact there is a note of despair: "The fairest universe ( ) is but a heap of rubbish ( ) piled up ( , i.e. "poured out") at random ( "aimlessly")." Bertrand Russell presents Heraclitus as a mystic in his "Mysticism and Logic".

There is the frivolity of a child in both man and God. "Eternity is a child moving counters in a game; the kingly power is a child's." Nietzsche explains this enigmatic quote as "And as the child and the artist plays, so too plays the ever living fire, it builds up and tears down, in innocence – such is the game eternity plays with itself." This quote may also be why there is the story of Heraclitus giving up his kingship to his brother.

Heraclitus also stated "human opinions are children's toys." However, "Man is called a baby by God, even as a child [is called a baby] by a man." Heraclitus also states "We should not act and speak like 'children of our parents", interpreted by Marcus Aurelius to mean not simply accept what others believe.
He regarded the soul as being a mixture of fire and water, with fire being the noble part of the soul, and water the ignoble part. A soul should therefore aim toward becoming more full of fire and less full of water: a "dry" soul was best. According to Heraclitus, worldly pleasures (drinking most apparently) made the soul "moist", and he considered mastering one's worldly desires to be a noble pursuit which purified the soul's fire. The soul also has a self-increasing "Logos". He believed we breathe in the "logos", as Anaximenes would say of air and the soul. He also stated "It is hard to fight with one's heart's desire. Whatever it wishes to get, it purchases at the cost of soul."

This influential quote by Heraclitus "Ethos anthropoi daimon" has led to numerous interpretations. It seems to state one's luck is related to one's character. Whether in this context "daimon" can indeed be translated to mean "fate" is disputed; however, it lends much sense to Heraclitus' observations and conclusions about human nature in general. While the translation with "fate" is generally accepted as in Kahn's "a man's character is his divinity", in some cases, it may also stand for the soul of the departed.

Some have interpreted and some fragments support Heraclitus as a kind of proto-empiricist, such as "the things that can be seen, heard and learned are what I prize the most," or "The sun is the size that it appears," "the width of a human foot. but W. K. C. Guthrie disputes this interpretation, citing for "Eyes and ears are bad witnesses to men who have barbarian souls." He also said "sight tells falsehoods" and that "nature loves to hide". He also warned against hearsay, "Eyes are better witnesses than the ears."

The sense of smell also seemed to play a role in his philosophy. "If all things were turned to smoke, the nostrils would distinguish them." and "Souls smell in Hades."

Heraclitus's most famous follower was Cratylus, who was presented by Plato as a linguistic naturalist, one who believes names must apply naturally to their objects. According to Aristotle, he took the view that nothing can be said about the ever-changing world, and "ended by thinking that one need not say anything, and only moved his finger." He seemed to hold the view continuous change warrants skepticism because we cannot define a thing that does not have a permanent nature. 20th century linguistic philosophy saw a rise in considerations brought up by Cratylus in Plato's dialogue, and thus offered the doctrine called Cratylism.

Parmenides's proem argues that change is impossible, and may very well have been referring to Heraclitus with such passages as "Undiscerning crowds, who hold that it is and is not the same, and all things travel in opposite directions!".

The pluralists were the first to try and reconcile Heraclitus and Parmenides. Anaxagoras may have been influenced by Heraclitus in his refusal to separate the opposites. Empedocles forces of Love and Hate were probably influenced by Heraclitus' Harmony and Strife. Empedocles is also credited with introducing the concept of the four classical elements.

Plato is the most famous to try and reconcile Heraclitus and Parmenides, and through him both influence virtually all subsequent Western philosophy. Plato knew of Heraclitus through Cratylus, and thus wrote his dialogue of the same name. Plato thought the views of Heraclitus entailed that no entity may ever occupy a single state at a single time, and argued against him as follows:How can that be a real thing which is never in the same state? ... for at the moment that the observer approaches, then they become other ... so that you cannot get any further in knowing their nature or state ... but if that which knows and that which is known exist ever ... then I do not think they can resemble a process or flux ...

However, Plato does seem influenced by Heraclitus in his concept of the world as always changing, and thus our inability to have knowledge of particulars, and by Parmenides in needing another world, the Platonic realm, where things remain unchanging and universals exist as the objects of knowledge, the Forms. He gives this in the "Symposium", sounding very much like Heraclitus: Even during the period for which any living being is said to live and retain his identity – as a man, for example, is called the same man from boyhood to old age – he does not in fact retain the same attributes, although he is called the same person: he is always becoming a new being and undergoing a process of loss and reparation, which affects his hair, his flesh, his bones, his blood and his whole body. And not only his body, but his soul as well. No man's character, habits, opinions desires pleasures pains and fears remain always the same: new ones come into existence and old ones disappear.

Pyrrhonism is a school of philosophical skepticism which flourished between the 3rd century BCE and about the 3rd century CE. One major figure in the school, Aenesidemus, claimed in a now-lost work that Pyrrhonism was a way to Heraclitean philosophy, since opposites appearing to be the case about the same thing leads into opposites being the case about the same thing, and the Pyrrhonists say that opposites appear to be the case about the same thing, while the Heracliteans move from this to their being the case. A later Pyrrhonist philosopher, Sextus Empiricus, disagreed, arguing that opposites' appearing to be the case about the same thing is not a dogma of the Pyrrhonists but a matter
occurring not only to the Pyrrhonists but also to the other philosophers, and, indeed, to all mankind.

Stoicism was a philosophical school which flourished between the 3rd century BC and about the 3rd century AD. It began among the Greeks and became a major philosophy of the Roman Empire before declining with the rise of Christianity in the 3rd century.

While most scholars believe Heraclitus had little effect on the Stoics, scholar A. A. Long argues otherwise. According to him, throughout their long tenure the Stoics believed that the major tenets of their philosophy derived from the thought of Heraclitus, "the importance of Heraclitus to later Stoics is evident most plainly in Marcus Aurelius." Explicit connections of the earliest Stoics to Heraclitus showing how they arrived at their interpretation are missing but they can be inferred from the Stoic fragments, which Long concludes are "modifications of Heraclitus."

The Stoic modification of Heraclitus' idea of the Logos was also influential on Jewish philosophers such as Philo of Alexandria, who connected it to "Wisdom personified" as God's creative principle. Philo uses the term Logos throughout his treatises on Hebrew Scripture in a manner clearly influenced by the Stoics.

With regard to Stoic modification of Heraclitus, Burnet writes:"Another difficulty we have to face is that most of the commentators on Herakleitos mentioned in Diogenes were Stoics. Now, the Stoics held the Ephesian in peculiar veneration, and sought to interpret him as far as possible in accordance with their own system. Further, they were fond of “ accommodating ” the views of earlier thinkers to their own, and this has had serious consequences. In particular, the Stoic theories of the logos and the ekpyrosis are constantly ascribed to Herakleitos, and the very fragments are adulterated with scraps of Stoic terminology."

The Stoics were interested in Heraclitus' treatment of fire. The earliest surviving Stoic work, the "Hymn to Zeus" of Cleanthes, a work transitional from pagan polytheism to the modern religions and philosophies, though not explicitly referencing Heraclitus, adopts what appears to be the Heraclitean logos modified. Zeus rules the universe with law ("nomos") wielding on its behalf the "forked servant", the "fire" of the "ever-living lightning." So far nothing has been said that differs from the Zeus of Homer. But then, says Cleanthes, Zeus uses the fire to "straighten out the common logos" that travels about ("phoitan", "to frequent") mixing with the greater and lesser lights (heavenly bodies). This is Heraclitus' logos, but now it is confused with the "common "nomos"", which Zeus uses to "make the wrong ("perissa", left or odd) right ("artia", right or even)" and "order ("kosmein") the disordered ("akosma")."

The Church Fathers were the leaders of the early Christian Church during its first five centuries of existence, roughly contemporaneous to Stoicism under the Roman Empire. The works of dozens of writers in hundreds of pages have survived. All of them had something to say about the Christian form of the "Logos". The Catholic Church found it necessary to distinguish between the Christian "logos" and that of Heraclitus, in order to distance itself from pagans and convert them to Christianity. Church use of the methods and conclusions of ancient philosophy as such was as yet far in the future, even though many were converted philosophers.

Hippolytus of Rome therefore identifies Heraclitus along with the other Pre-Socratics (and Academics) as sources of heresy. In "Refutation of All Heresies", one of the best sources on quotes from Heraclitus, Hippolytus says: "What the blasphemous folly is of Noetus, and that he devoted himself to the tenets of Heraclitus the Obscure, not to those of Christ." Hippolytus then goes on to present an inscrutable quote: "God ("theos") is day and night, winter and summer, ... but he takes various shapes, just as fire, when it is mingled with spices, is named according to the savor of each." The fragment seems to support pantheism if taken literally. German physicist and philosopher Max Bernard Weinstein classed his view as a predecessor of pandeism.

Hippolytus condemns the obscurity of it. He cannot accuse Heraclitus of being a heretic so he says instead: "Did not (Heraclitus) the Obscure anticipate Noetus in framing a system ...?" The apparent pantheist deity of Heraclitus (if that is what the fragment means) must be equal to the union of opposites and therefore must be corporeal and incorporeal, divine and not-divine, dead and alive, etc., and the Trinity can only be reached by some sort of illusory shape-shifting.

The Christian apologist Justin Martyr, however, took a much more positive view of him. In his First Apology, he said both Socrates and Heraclitus were Christians before Christ: "those who lived reasonably are Christians, even though they have been thought atheists; as, among the Greeks, Socrates and Heraclitus, and men like them." 

The weeping philosopher was still considered an indispensable motif for philosophy through the modern period.

Michel de Montaigne proposed two archetypical views of human affairs based on them, selecting Democritus' for himself.

G. W. F. Hegel gave Heraclitus high praise. According to him, "the origin of philosophy is to be dated from Heraclitus." He attributes dialectics to Heraclitus rather than, as Aristotle did, to Zeno of Elea. "There is no proposition of Heraclitus which I have not adopted in my Logic."

Friedrich Engels who associated with the Young Hegelians also gave Heraclitus the credit for inventing dialectics, relevant to his own dialectical materialism. Ferdinand Lasalle was another socialist also influenced by Heraclitus. 

Friedrich Nietzsche was profoundly influenced by Heraclitus, as can be seen in his Philosophy in the Tragic Age of the Greeks. Nietzsche sees him as a confident opposition to Anaximander's pessimism. Oswald Spengler was influenced by Nietzsche and also wrote his dissertation on Heraclitus.

Martin Heidegger is also influenced by Heraclitus, as seen in his Introduction to Metaphysics, and takes a very different interpretation than Nietzsche and several others. According to Heidegger, "In Heraclitus, to whom is ascribed the doctrine of becoming as diametrically opposed to Parmenides' doctrine of being, says the same as Parmenides."

Karl Popper wrote much on Heraclitus, and both Popper and Heraclitus believe in invisible processes at work.

The weeping philosopher may have also been mentioned in William Shakespeare's "The Merchant of Venice". J. M. E. McTaggart's illustration of the A-series and B-series of time has been seen as an analogous application to time of Heraclitus and Parmenides views of all of reality, respectively. A. N. Whitehead's process philosophy bears a resemblance to Heraclitus.

Carl Jung wrote that Heraclitus "discovered the most marvellous of all psychological laws: the regulative function of opposites ...by which he meant that sooner or later everything runs into its opposite." Jung adopted this law, enantiodromia, into his analytical psychology. He related it with Chinese classics, stating: "If the Western world had followed his lead, we would all be Chinese in our viewpoint instead of Christian. We can think of Heraclitus as making the switch between the East and the West." Furthermore, Jung suggested that Heraclitus was named "the dark" not because his style was too difficult, but precisely "because he spoke too plainly" about the paradoxical nature of existence "and called life itself an “ever-living fire.”"

Heraclitus has been done several times in western art, especially as part of the weeping and laughing philosopher motif, and with globes.

Donato Bramante painted a fresco, "Democritus and Heraclitus," in Casa Panigarola in Milan in 1477. Heraclitus's most famous depiction in art is in Raphael's "School of Athens," painted around 1510. Raphael chose to depict Michelangelo as Heraclitus. He and Diogenes of Sinope are the only ones to sit alone in the painting.

Salvator Rosa also painted Democritus and Heraclitus, as did Luca Giordano, together and separately in the 1650s or so. Giuseppe Torretti sculpted busts of the same in 1705. Giuseppe Antonio Petrini painted "Weeping Heraclitus" circa 1750.

Franz Tymmermann in 1538 painted a weeping Heraclitus. Johann Christoph Ludwig Lücke sculpted busts of the same in the 1750s. Franz Xaver Messerschmidt also sculpted them.

In 1619, the Dutch Cornelis van Haarlem also painted a laughing Democritus and weeping Heraclitus. Hendrick ter Brugghen's paintings of Heraclitus and Democritus separately in 1628 hang in the Rijksmuseum, and he also painted them together.

Around 1630, Dutch painter Johannes Moreelse painted Heraclitus ringing his hands over a globe, sad at the state of the world, and another with Democritus laughing at one. Dirck van Baburen also painted the pair. Egbert van Heemskerck did as well.

Peter Paul Rubens painted the pair twice in 1603. Nicolaes Pickenoy also painted the pair.

Etienne Parrocel painted him, as did Charles-Antoine Coypel.

Jusepe de Ribera painted the pair in 1630.





</doc>
<doc id="13793" url="https://en.wikipedia.org/wiki?curid=13793" title="Harrison Schmitt">
Harrison Schmitt

Harrison Hagan "Jack" Schmitt (born July 3, 1935) is an American geologist, retired NASA astronaut, university professor, former U.S. senator from New Mexico, and the most recent person still living to have walked on the Moon.

In December 1972, as one of the crew on board Apollo 17, Schmitt became the first member of NASA's first scientist-astronaut group to fly in space. As Apollo 17 was the last of the Apollo missions, he also became the twelfth and second-youngest person to set foot on the Moon and the second-to-last person to step off of the Moon (he boarded the Lunar Module shortly before commander Eugene Cernan). Schmitt also remains the only professional scientist to have flown beyond low Earth orbit and to have visited the Moon. He was influential within the community of geologists supporting the Apollo program and, before starting his own preparations for an Apollo mission, had been one of the scientists training those Apollo astronauts chosen to visit the lunar surface.

Schmitt resigned from NASA in August 1975 to run for election to the United States Senate as a member from New Mexico. As the Republican candidate in the 1976 election, he defeated Democratic incumbent Joseph Montoya. In the 1982 election, Schmitt was defeated by Democrat Jeff Bingaman.

Born July 3, 1935, in Santa Rita, New Mexico, Schmitt grew up in nearby Silver City, and is a graduate of the Western High School (class of 1953). He received a B.S. degree in geology from the California Institute of Technology in 1957 and then spent a year studying geology at the University of Oslo in Norway. He received a Ph.D. in geology from Harvard University in 1964, based on his geological field studies in Norway.

Before joining NASA as a member of the first group of scientist-astronauts in June 1965, he worked at the U.S. Geological Survey's Astrogeology Center at Flagstaff, Arizona, developing geological field techniques that would be used by the Apollo crews. Following his selection, Schmitt spent his first year at Air Force UPT learning to become a jet pilot. Upon his return to the astronaut corps in Houston, he played a key role in training Apollo crews to be geologic observers when they were in lunar orbit and competent geologic field workers when they were on the lunar surface. After each of the landing missions, he participated in the examination and evaluation of the returned lunar samples and helped the crews with the scientific aspects of their mission reports.

Schmitt spent considerable time becoming proficient in the CSM and LM systems. In March 1970 he became the first of the scientist-astronauts to be assigned to space flight, joining Richard F. Gordon Jr. (Commander) and Vance Brand (Command Module Pilot) on the Apollo 15 backup crew. The flight rotation put these three in line to fly as prime crew on the third following mission, Apollo 18. When Apollo 18 and Apollo 19 were cancelled in September 1970, the community of lunar geologists supporting Apollo felt so strongly about the need to land a professional geologist on the Moon, that they pressured NASA to reassign Schmitt to a remaining flight. As a result, Schmitt was assigned in August 1971 to fly on the last mission, Apollo 17, replacing Joe Engle as Lunar Module Pilot. Schmitt landed on the Moon with commander Gene Cernan in December 1972.

Schmitt claims to have taken the photograph of the Earth known as "The Blue Marble", possibly one of the most widely distributed photographic images in existence. NASA officially credits the image to the entire Apollo 17 crew.

While on the Moon's surface, Schmitt — the only geologist in the astronaut corps — collected the rock sample designated Troctolite 76535, which has been called "without doubt the most interesting sample returned from the Moon". Among other distinctions, it is the central piece of evidence suggesting that the Moon once possessed an active magnetic field.

As he returned to the Lunar Module before Cernan, Schmitt is the next-to-last person to have walked on the Moon's surface. Since the death of Cernan in 2017, Schmitt is the most recent person to have walked on the Moon who is still alive.

After the completion of Apollo 17, Schmitt played an active role in documenting the Apollo geologic results and also took on the task of organizing NASA's Energy Program Office.

On August 30, 1975, Schmitt resigned from NASA to seek election as a Republican to the United States Senate representing New Mexico in the 1976 election. Schmitt campaigned for fourteen months, and his campaign focused on the future.

In the Republican primary, held on June 1, 1976, Schmitt defeated Eugene Peirce. In the election, Schmitt opposed two-term Democratic incumbent Joseph Montoya. He defeated Montoya 57% to 42%.

He served one term and, notably, was the chairman of the Science, Technology, and Space Subcommittee of the United States Senate Committee on Commerce.

He sought a second term in 1982, facing state Attorney General Jeff Bingaman. Bingaman attacked Schmitt for not paying enough attention to local matters; his campaign slogan asked, "What on Earth has he done for you lately?" This, combined with the deep recession, proved too much for Schmitt to overcome; he was defeated, 54% to 46%.

Following his Senate term, Schmitt has been a consultant in business, geology, space, and public policy.

Schmitt is an adjunct professor of engineering physics at the University of Wisconsin–Madison, and has long been a proponent of lunar resource utilization. In 1997 he proposed the Interlune InterMars Initiative, listing among its goals the advancement of private-sector acquisition and use of lunar resources, particularly lunar helium-3 as a fuel for notional nuclear fusion reactors.

Schmitt was chair of the NASA Advisory Council, whose mandate is to provide technical advice to the NASA Administrator, from November 2005 until his abrupt resignation on October 16, 2008. In November 2008, he quit the Planetary Society over policy advocacy differences, citing the organization's statements on "focusing on Mars as the driving goal of human spaceflight" (Schmitt said that going back to the Moon would speed progress toward a manned Mars mission), on "accelerating research into global climate change through more comprehensive Earth observations" (Schmitt voiced objections to the notion of a present "scientific consensus" on climate change as any policy guide), and on international cooperation (which he felt would retard rather than accelerate progress), among other points of divergence.

In January 2011, he was appointed as secretary of the New Mexico Energy, Minerals and Natural Resources Department in the cabinet of Governor Susana Martinez, but was forced to give up the appointment the following month after refusing to submit to a required background investigation. "El Paso Times" called him the "most celebrated" candidate for New Mexico energy secretary.

Schmitt wrote a book entitled "Return to the Moon: Exploration, Enterprise, and Energy in the Human Settlement of Space" in 2006.

He lives in Silver City, New Mexico, and spends some of his summer at his northern Minnesota lake cabin.

Schmitt is also involved in several civic projects, including the improvement of the Senator Harrison H. Schmitt Big Sky Hang Glider Park in Albuquerque, New Mexico.

Schmitt's view on climate change emphasizes natural over human factors as driving climate. Schmitt has expressed the view that the risks posed by climate change are overrated and suggests instead that climate change is a tool for people who are trying to increase the size of government. He resigned his membership in the Planetary Society primarily because of its Mars-first policy, but also because of its stance on global warming, writing in his resignation letter that the "'global warming scare' is being used as a political tool to increase government control over American lives, incomes and decision making. It has no place in the Society's activities." Schmitt spoke at the March 2009 International Conference on Climate Change sponsored by the Heartland Institute. He appeared in December that year on the Fox Business Network, saying "[t]he CO scare is a red herring".

In a 2009 interview with conspiracy theorist and radio host Alex Jones, Schmitt asserted a link between Soviet Communism and the American environmental movement: "I think the whole trend really began with the fall of the Soviet Union. Because the great champion of the opponents of liberty, namely communism, had to find some other place to go and they basically went into the environmental movement." At the Heartland Institute's sixth International Conference on Climate Change Schmitt said that climate change was a stalking horse for National Socialism.

Schmitt co-authored a May 8, 2013 "Wall Street Journal" opinion column with William Happer, contending that increasing levels of carbon dioxide in the atmosphere are not significantly correlated with global warming, attributing the "single-minded demonization of this natural and essential atmospheric gas" to advocates of government control of energy production. Noting a positive relationship between crop resistance to drought and increasing carbon dioxide levels, the authors argued, "Contrary to what some would have us believe, increased carbon dioxide in the atmosphere will benefit the increasing population on the planet by increasing agricultural productivity."



Schmitt was one of five inductees into the International Space Hall of Fame in 1977. He was one of 24 Apollo astronauts who were inducted into the U.S. Astronaut Hall of Fame in 1997.

Schmitt is one of the astronauts featured in the 2007 documentary "In the Shadow of the Moon". He also contributed to the book "NASA's Scientist-Astronauts" by David Shayler and Colin Burgess.




</doc>
<doc id="13795" url="https://en.wikipedia.org/wiki?curid=13795" title="Hilaire Rouelle">
Hilaire Rouelle

Hilaire Marin Rouelle (15 February 1718 – 7 April 1779) was an 18th-century French chemist. Commonly cited as the 1773 discoverer of urea, he was not the first to do so. Dutch scientist Herman Boerhaave had discovered this chemical as early as 1727. Rouelle is known as "le cadet" (the younger) to distinguish him from his older brother, Guillaume-François Rouelle, who was also a chemist.


</doc>
<doc id="13798" url="https://en.wikipedia.org/wiki?curid=13798" title="Halon">
Halon

Halon may refer to:



</doc>
<doc id="13800" url="https://en.wikipedia.org/wiki?curid=13800" title="Harrisonburg">
Harrisonburg

Harrisonburg may refer to a place in the United States:



</doc>
<doc id="13802" url="https://en.wikipedia.org/wiki?curid=13802" title="Hammer">
Hammer

A hammer is a tool consisting of a weighted "head" fixed to a long handle that is swung to deliver an impact to a small area of an object. This can be, for example, to drive nails into wood, to shape metal (as with a forge), or to crush rock. Hammers are used for a wide range of driving, shaping, and breaking applications. 

The modern hammer head is typically made of steel which has been heat treated for hardness, and the handle (also known as a haft or helve) is typically made of wood or plastic.

The claw hammer has a "claw" to pull nails out of wood, and is commonly found in an inventory of household tools in North America. Other types of hammer vary in shape, size, and structure, depending on their purposes. Hammers used in many trades include sledgehammers, mallets, and ball-peen hammers. Although most hammers are hand tools, powered hammers, such as steam hammers and trip hammers, are used to deliver forces beyond the capacity of the human arm. There are over 40 different types of hammers that have many different types of uses.

The use of simple hammers dates to around 3.3 million years ago according to the 2012 find made by Sonia Harmand and Jason Lewis of Stony Brook University, who while excavating a site near Kenya's Lake Turkana discovered a very large deposit of various shaped stones including those used to strike wood, bone, or other stones to break them apart and shape them. The first hammers were made without handles. Stones attached to sticks with strips of leather or animal sinew were being used as hammers with handles by about 30,000 BCE during the middle of the Paleolithic Stone Age. The addition of a handle gave the user better control and less accidents. The hammer became the number one tool. Used for building, food and protection.

The hammer's archaeological record shows that it may be the oldest tool for which definite evidence exists of its early existence.

A traditional hand-held hammer consists of a separate head and a handle, which can be fastened together by means of a special wedge made for the purpose, or by glue, or both. This two-piece design is often used to combine a dense metallic striking head with a non-metallic mechanical-shock-absorbing handle (to reduce user fatigue from repeated strikes). If wood is used for the handle, it is often hickory or ash, which are tough and long-lasting materials that can dissipate shock waves from the hammer head. Rigid fiberglass resin may be used for the handle; this material does not absorb water or decay but does not dissipate shock as well as wood.

A loose hammer head is hazardous because it can literally "fly off the handle" when in use, becoming a dangerous uncontrolled missile. Wooden handles can often be replaced when worn or damaged; specialized kits are available covering a range of handle sizes and designs, plus special wedges for attachment.

Some hammers are one-piece designs made mostly of a single material. A one-piece metallic hammer may optionally have its handle coated or wrapped in a resilient material such as rubber, for improved grip and to reduce user fatigue.

The hammer head may be surfaced with a variety of materials including brass, bronze, wood, plastic, rubber, or leather. Some hammers have interchangeable striking surfaces, which can be selected as needed or replaced when worn out.

A large hammer-like tool is a "maul" (sometimes called a "beetle"), a wood- or rubber-headed hammer is a "mallet", and a hammer-like tool with a cutting blade is usually called a "hatchet". The essential part of a hammer is the head, a compact solid mass that is able to deliver a blow to the intended target without itself deforming. The impacting surface of the tool is usually flat or slightly rounded; the opposite end of the impacting mass may have a ball shape, as in the ball-peen hammer. Some upholstery hammers have a magnetized face, to pick up tacks. In the hatchet, the flat hammer head may be secondary to the cutting edge of the tool.

The impact between steel hammer heads and the objects being hit can create sparks, which may ignite flammable or explosive gases. These are a hazard in some industries such as underground coal mining (due to the presence of methane gas), or in other hazardous environments such as petroleum refineries and chemical plants. In these environments, a variety of non-sparking metal tools are used, primarily made of aluminium or beryllium copper. In recent years, the handles have been made of durable plastic or rubber, though wood is still widely used because of its shock-absorbing qualities and repairability.


Mechanically-powered hammers often look quite different from the hand tools, but nevertheless, most of them work on the same principle. They include:
In professional framing carpentry, the manual hammer has almost been completely replaced by the nail gun. In professional upholstery, its chief competitor is the staple gun.


A hammer is a simple force amplifier that works by converting mechanical work into kinetic energy and back.

In the swing that precedes each blow, the hammer head stores a certain amount of kinetic energy—equal to the length "D" of the swing times the force "f" produced by the muscles of the arm and by gravity. When the hammer strikes, the head is stopped by an opposite force coming from the target, equal and opposite to the force applied by the head to the target. If the target is a hard and heavy object, or if it is resting on some sort of anvil, the head can travel only a very short distance "d" before stopping. Since the stopping force "F" times that distance must be equal to the head's kinetic energy, it follows that "F" is much greater than the original driving force "f"—roughly, by a factor "D"/"d". In this way, great strength is not needed to produce a force strong enough to bend steel, or crack the hardest stone.

The amount of energy delivered to the target by the hammer-blow is equivalent to one half the mass of the head times the square of the head's speed at the time of impact formula_1. While the energy delivered to the target increases linearly with mass, it increases quadratically with the speed (see the effect of the handle, below). High tech titanium heads are lighter and allow for longer handles, thus increasing velocity and delivering the same energy with less arm fatigue than that of a heavier steel head hammer. A titanium head has about 3% recoil energy and can result in greater efficiency and less fatigue when compared to a steel head with up to 30% recoil. Dead blow hammers use special rubber or steel shot to absorb recoil energy, rather than bouncing the hammer head after impact.

The handle of the hammer helps in several ways. It keeps the user's hands away from the point of impact. It provides a broad area that is better-suited for gripping by the hand. Most importantly, it allows the user to maximize the speed of the head on each blow. The primary constraint on additional handle length is the lack of space to swing the hammer. This is why sledgehammers, largely used in open spaces, can have handles that are much longer than a standard carpenter's hammer. The second most important constraint is more subtle. Even without considering the effects of fatigue, the longer the handle, the harder it is to guide the head of the hammer to its target at full speed.

Most designs are a compromise between practicality and energy efficiency. With too long a handle, the hammer is inefficient because it delivers force to the wrong place, off-target. With too short a handle, the hammer is inefficient because it doesn't deliver enough force, requiring more blows to complete a given task. Modifications have also been made with respect to the effect of the hammer on the user. Handles made of shock-absorbing materials or varying angles attempt to make it easier for the user to continue to wield this age-old device, even as nail guns and other powered drivers encroach on its traditional field of use.

As hammers must be used in many circumstances, where the position of the person using them cannot be taken for granted, trade-offs are made for the sake of practicality. In areas where one has plenty of room, a long handle with a heavy head (like a sledgehammer) can deliver the maximum amount of energy to the target. It is not practical to use such a large hammer for all tasks, however, and thus the overall design has been modified repeatedly to achieve the optimum utility in a wide variety of situations.

Gravity exerts a force on the hammer head. If hammering downwards, gravity increases the acceleration during the hammer stroke and increases the energy delivered with each blow. If hammering upwards, gravity reduces the acceleration during the hammer stroke and therefore reduces the energy delivered with each blow. Some hammering methods, such as traditional mechanical pile drivers, rely entirely on gravity for acceleration on the down stroke.

A hammer may cause significant injury if it strikes the body. Both manual and powered hammers can cause peripheral neuropathy or a variety of other ailments when used improperly. Awkward handles can cause repetitive stress injury (RSI) to hand and arm joints, and uncontrolled shock waves from repeated impacts can injure nerves and the skeleton. Additionally, striking metal objects with a hammer may produce small metallic projectiles which can become lodged in the eye. It is therefore recommended to wear safety glasses.

A war hammer is a late medieval weapon of war intended for close combat action.

The hammer, being one of the most used tools by man, has been used very much in symbols such as flags and heraldry. In the Middle Ages, it was used often in blacksmith guild logos, as well as in many family symbols. The hammer and pick are used as a symbol of mining. 

In mythology, the gods Thor, Hercules and Sucello all had hammers that appear in their lore and carried different meanings. In Norse mythology, Thor, the god of thunder and lightning, wields a hammer named Mjölnir. Many artifacts of decorative hammers have been found, leading modern practitioners of this religion to often wear reproductions as a sign of their faith.

In American folklore, the hammer of John Henry represents the strength and endurance of a man.

A well-known symbol with a hammer in it is the Hammer and Sickle, which was the symbol of the former Soviet Union and is strongly linked to communism and early socialism. The hammer in this symbol represents the industrial working class (and the sickle represents the agricultural working class). The hammer is used in some coat of arms in former socialist countries like East Germany. Similarly, the Hammer and Sword symbolizes Strasserism, a strand of National Socialism seeking to appeal to the working class.

In Pink Floyd - The Wall, two hammers crossed are used as a symbol for the fascist takeover of the concert during "In the Flesh". This also has the meaning of the hammer beating down any "nails" that stick out.

The gavel, a small wooden mallet, is used to symbolize a mandate to preside over a meeting or judicial proceeding, and a graphic image of one is used as a symbol of legislative or judicial decision-making authority.

Judah Maccabee was nicknamed "The Hammer", possibly in recognition of his ferocity in battle. The name "Maccabee" may derive from the Aramaic "maqqaba". (see .)

The hammer in the song "If I Had a Hammer" represents a relentless message of justice broadcast across the land. The song became a symbol of the civil rights movement.




</doc>
<doc id="13804" url="https://en.wikipedia.org/wiki?curid=13804" title="Hiragana">
Hiragana

Hiragana and katakana are both kana systems. With one or two minor exceptions, each syllable in the Japanese language (strictly, each mora) is represented by one character (or one digraph) in each system. This may be either a vowel such as ""a"" (hiragana あ); a consonant followed by a vowel such as ""ka"" (か) or ""n"" (ん), a nasal sonorant which, depending on the context, sounds either like English "m", "n" or "ng" () when syllable-final or like the nasal vowels of French, Portuguese or Galician. Because the characters of the kana do not represent single consonants (except in the case of ん "n"), the kana are referred to as syllabic symbols and not alphabetic letters.

Hiragana is used to write "okurigana" (kana suffixes following a kanji root, for example to inflect verbs and adjectives), various grammatical and function words including particles, as well as miscellaneous other native words for which there are no kanji or whose kanji form is obscure or too formal for the writing purpose. Words that do have common kanji renditions may also sometimes be written instead in hiragana, according to an individual author's preference, for example to impart an informal feel. Hiragana is also used to write "furigana", a reading aid that shows the pronunciation of kanji characters.

There are two main systems of ordering hiragana: the old-fashioned iroha ordering and the more prevalent gojūon ordering.

The modern hiragana syllabary consists of 46 base characters:

These are conceived as a 5×10 grid ("gojūon", , "Fifty Sounds"), as illustrated in the adjacent table, read and so forth, with the singular consonant appended to the end. Of the 50 theoretically possible combinations, "yi" and "wu" do not exist in the language and "ye", "wi" and "we" are obsolete (or virtually obsolete) in modern Japanese. "wo" (を) is usually pronounced as a vowel ("o") in modern Japanese and is preserved in only one use, as a particle.

Romanization of the kana does not always strictly follow the consonant-vowel scheme laid out in the table. For example, ち, nominally "ti", is very often romanised as "chi" in an attempt to better represent the actual sound in Japanese.

These basic characters can be modified in various ways. By adding a "dakuten" marker ( ゛), a voiceless consonant is turned into a voiced consonant: "k"→"g", "ts/s"→"z", "t"→"d", "h"→"b" and "ch"/"sh"→"j". For example, か ("ka") becomes が ("ga"). Hiragana beginning with an "h" sound can also add a "handakuten" marker ( ゜) changing the "h" to a "p". For example, は ("ha") becomes ぱ ("pa").

A small version of the hiragana for "ya", "yu", or "yo" (ゃ, ゅ or ょ respectively) may be added to hiragana ending in "i". This changes the "i" vowel sound to a glide (palatalization) to "a", "u" or "o". For example, き ("ki") plus ゃ (small "ya") becomes ("kya"). Addition of the small "y" kana is called "yōon".

A small "tsu" っ, called a "sokuon", indicates that the following consonant is geminated (doubled). In Japanese this is an important distinction in pronunciation; for example, compare , "saka", "hill" with , "sakka", "author". The "sokuon" also sometimes appears at the end of utterances, where it denotes a glottal stop, as in (, Ouch!). However, it cannot be used to double the "na", "ni", "nu", "ne", "no" syllables' consonants – to double these, the singular "n" (ん) is added in front of the syllable, as in みんな ("minna", "all").

Hiragana usually spells long vowels with the addition of a second vowel kana; for example, おかあさん ("o-ka-a-sa-n", "mother"). The "chōonpu" (long vowel mark) (ー) used in katakana is rarely used with hiragana, for example in the word , "rāmen", but this usage is considered non-standard in Japanese; the Okinawan language uses chōonpu with hiragana. In informal writing, small versions of the five vowel kana are sometimes used to represent trailing off sounds (, "haa", , "nee"). Standard and voiced iteration marks are written in hiragana as ゝ and ゞ respectively.

The following table shows the complete hiragana together with the Hepburn romanization and IPA transcription in the "gojūon" order. Hiragana with "dakuten" or "handakuten" follow the "gojūon" kana without them, with the "yōon" kana following. Obsolete and normally unused kana are shown in brackets and . Those in bold do not use the initial sound for that row. For all syllables besides ん, the pronunciation indicated is for word-initial syllables, for mid-word pronunciations see below.

In the middle of words, the "g" sound (normally ) may turn into a velar nasal or velar fricative . An exception to this is numerals; 15 "jūgo" is considered to be one word, but is pronounced as if it was "jū" and "go" stacked end to end: .

In many accents, the "j" and "z" sounds are pronounced as affricates ( and , respectively) at the beginning of utterances and fricatives in the middle of words. For example, "sūji" 'number', "zasshi" 'magazine'.

In archaic forms of Japanese, there existed the "kwa" ( ) and "gwa" ( ) digraphs. In modern Japanese, these phonemes have been phased out of usage and only exist in the extended katakana digraphs for approximating foreign language words.

The singular "n" is pronounced before "t", "ch", "ts", "n", "r", "z", "j" and "d", before "m", "b" and "p", before "k" and "g", at the end of utterances, and some kind of high nasal vowel before vowels, palatal approximants ("y"), fricative consonants "s", "sh", "h", "f" and "w".

In kanji readings, the diphthongs "ou" and "ei" are today usually pronounced (long o) and (long e) respectively. For example, (lit. "toukyou") is pronounced 'Tokyo', and "sensei" is 'teacher'. However, "tou" is pronounced 'to inquire', because the "o" and "u" are considered distinct, "u" being the verb ending in the dictionary form. Similarly, "shite iru" is pronounced 'is doing'.

For a more thorough discussion on the sounds of Japanese, please refer to Japanese phonology.

An early, now obsolete, hiragana-esque form of "ye" may have existed (𛀁 ) in pre-Classical Japanese (prior to the advent of kana), but is generally represented for purposes of reconstruction by the kanji 江, and its hiragana form is not present in any known orthography. In modern orthography, "ye" can also be written as いぇ (イェ in katakana).

It is true that in early periods of kana, hiragana and katakana letters for "ye" were used, but soon after the distinction between /ye/ and /e/ went away, and letters and glyphs were not established.
Though "ye" did appear in some textbooks during the Meiji period along with another kana for "yi" in the form of cursive 以. Today it is considered a Hentaigana by scholars and is encoded in Unicode 10 ().
Hiragana also appeared in different Meiji-era textbooks (). Although there are several possible source kanji, it is likely to have been derived from a cursive form of the , although a related variant sometimes listed () is from a cursive form of . However, it was never commonly used.

With a few exceptions for sentence particles は, を, and へ (normally "ha", "wo", and "he", but instead pronounced as "wa", "o", and "e", respectively), and a few other arbitrary rules, Japanese, when written in kana, is phonemically orthographic, i.e. there is a one-to-one correspondence between kana characters and sounds, leaving only words' pitch accent unrepresented. This has not always been the case: a previous system of spelling, now referred to as historical kana usage, differed substantially from pronunciation; the three above-mentioned exceptions in modern usage are the legacy of that system.

There are two hiragana pronounced "ji" (じ and ぢ) and two hiragana pronounced "zu" (ず and づ), but to distinguish them, particularly when typing Japanese, sometimes "ぢ" is written as "di" and "づ" is written as "du". These pairs are not interchangeable. Usually, "ji" is written as じ and "zu" is written as ず. There are some exceptions. If the first two syllables of a word consist of one syllable without a "dakuten" and the same syllable with a "dakuten", the same hiragana is used to write the sounds. For example, "chijimeru" ('to boil down' or 'to shrink') is spelled ちぢめる and "tsuzuku" ('to continue') is . For compound words where the dakuten reflects "rendaku" voicing, the original hiragana is used. For example, "chi" ( 'blood') is spelled ち in plain hiragana. When "hana" ('nose') and "chi" ('blood') combine to make "hanaji" ( 'nose bleed'), the sound of changes from "chi" to "ji". So "hanaji" is spelled according to ち: the basic hiragana used to transcribe . Similarly, "tsukau" (; 'to use') is spelled in hiragana, so "kanazukai" (; 'kana use', or 'kana orthography') is spelled in hiragana.

However, this does not apply when kanji are used phonetically to write words that do not relate directly to the meaning of the kanji (see also ateji). The Japanese word for 'lightning', for example, is "inazuma" (). The component means 'rice plant', is written in hiragana and is pronounced: "ina". The component means 'wife' and is pronounced "tsuma" (つま) when written in isolation—or frequently as "zuma" when it features after another syllable. Neither of these components have anything to do with 'lightning', but together they do when they compose the word for 'lightning'. In this case, the default spelling in hiragana rather than is used.

Officially, ぢ and づ do not occur word-initially pursuant to modern spelling rules. There were words such as "jiban" 'ground' in the historical kana usage, but they were unified under じ in the modern kana usage in 1946, so today it is spelled exclusively . However, "zura" 'wig' (from "katsura") and "zuke" (a sushi term for lean tuna soaked in soy sauce) are examples of word-initial づ today. Some people write the word for hemorrhoids as ぢ (normally じ) for emphasis.

No standard Japanese words begin with the kana ん ("n"). This is the basis of the word game shiritori. ん "n" is normally treated as its own syllable and is separate from the other "n"-based kana ("na", "ni" etc.). A notable exception to this is the colloquial negative verb conjugation; for example "wakaranai" meaning "[I] don't understand" is rendered as "wakaran". It is however not a contraction of the former, but instead comes from the classic negative verb conjugation ぬ "nu" ( "wakaranu").

ん is sometimes directly followed by a vowel ("a", "i", "u", "e" or "o") or a palatal approximant ("ya", "yu" or "yo"). These are clearly distinct from the "na", "ni" etc. syllables, and there are minimal pairs such as "kin'en" 'smoking forbidden', "kinen" 'commemoration', "kinnen" 'recent years'. In Hepburn romanization, they are distinguished with an apostrophe, but not all romanization methods make the distinction. For example, past prime minister Junichiro Koizumi's first name is actually "Jun'ichirō" pronounced 

There are a few hiragana that are rarely used. ゐ "wi" and ゑ "we" are obsolete outside of Okinawan orthography. 𛀁 "e" was an alternate version of え "e" before spelling reform, and was briefly reused for "ye" during initial spelling reforms, but is now completely obsolete. ゔ "vu" is a modern addition used to represent the /v/ sound in foreign languages such as English, but since Japanese from a phonological standpoint does not have a /v/ sound, it is pronounced as /b/ and mostly serves as a more accurate indicator of a word's pronunciation in its original language. However, it is rarely seen because loanwords and transliterated words are usually written in katakana, where the corresponding character would be written as ヴ. , , for "ja"/"ju"/"jo" are theoretically possible in rendaku, but are practically never used. For example, 'throughout Japan' could be written , but is practically always 

The "myu" kana is extremely rare in originally Japanese words; linguist Haruhiko Kindaichi raises the example of the Japanese family name Omamyūda and claims it is the only occurrence amongst pure Japanese words. Its katakana counterpart is used in many loanwords, however.

Hiragana developed from "man'yōgana", Chinese characters used for their pronunciations, a practice that started in the 5th century. The oldest examples of Man'yōgana include the Inariyama Sword, an iron sword excavated at the Inariyama Kofun in 1968. This sword is thought to be made in the year (most commonly taken to be A.D. 471).
The forms of the hiragana originate from the cursive script style of Chinese calligraphy. The figure below shows the derivation of hiragana from manyōgana via cursive script. The upper part shows the character in the regular script form, the center character in red shows the cursive script form of the character, and the bottom shows the equivalent hiragana. The cursive script forms are not strictly confined to those in the illustration.

Male authors came to write literature using hiragana. Hiragana was used for unofficial writing such as personal letters, while katakana and Chinese were used for official documents. In modern times, the usage of hiragana has become mixed with katakana writing. Katakana is now relegated to special uses such as recently borrowed words (i.e., since the 19th century), names in transliteration, the names of animals, in telegrams, and for emphasis.

Originally, for all syllables there was more than one possible hiragana. In 1900, the system was simplified so each syllable had only one hiragana. The deprecated hiragana are now known as .

The pangram poem "Iroha-uta" ("ABC song/poem"), which dates to the 10th century, uses every hiragana once (except "n" ん, which was just a variant of む before the Muromachi era).

The following table shows the method for writing each hiragana character. It is arranged in the traditional way, beginning top right and reading columns down. The numbers and arrows indicate the stroke order and direction respectively. <br>

Hiragana was added to the Unicode Standard in October, 1991 with the release of version 1.0.

The Unicode block for Hiragana is U+3040–U+309F:

The Unicode hiragana block contains precomposed characters for all hiragana in the modern set, including small vowels and yōon kana for compound syllables, plus the archaic ゐ "wi" and ゑ "we" and the rare ゔ "vu"; the archaic 𛀁 "ye" is included in plane 1 at U+1B001 (see below). All combinations of hiragana with "dakuten" and "handakuten" used in modern Japanese are available as precomposed characters, and can also be produced by using a base hiragana followed by the combining dakuten and handakuten characters (U+3099 and U+309A, respectively). This method is used to add the diacritics to kana that are not normally used with them, for example applying the dakuten to a pure vowel or the handakuten to a kana not in the h-group.

Characters U+3095 and U+3096 are small か ("ka") and small け ("ke"), respectively. U+309F is a ligature of より ("yori") occasionally used in vertical text. U+309B and U+309C are spacing (non-combining) equivalents to the combining dakuten and handakuten characters, respectively.

Historic and variant forms of Japanese kana characters were first added to the Unicode Standard in October, 2010 with the release of version 6.0, with significantly more added in 2017 as part of Unicode 10.

The Unicode block for Kana Supplement is U+1B000–U+1B0FF, and is immediately followed by the Kana Extended-A block (U+1B100–U+1B12F). These blocks include mainly hentaigana (historic or variant hiragana):

The Unicode block for Small Kana Extension is U+1B130–U+1B16F:

In the following character sequences a kana from the /k/ row is modified by a "handakuten" combining mark to indicate that a syllable starts with an initial nasal, known as "bidakuon". As of Unicode 13.0, these character combinations are explicitly called out as Named Sequences:




</doc>
<doc id="13805" url="https://en.wikipedia.org/wiki?curid=13805" title="Hohenstaufen">
Hohenstaufen

The Hohenstaufen ( , , ), also called Staufer, was a noble dynasty of unclear origin that rose to rule the Duchy of Swabia from 1079 and to royal rule in the Holy Roman Empire during the Middle Ages from 1138 until 1254. The most prominent kings Frederick I (1155), Henry VI (1191) and Frederick II (1220) ascended the imperial throne and also ruled Italy and Burgundy. The non-contemporary name is derived from a family castle on the Hohenstaufen mountain at the northern fringes of the Swabian Jura near the town of Göppingen. Under Hohenstaufen reign the Holy Roman Empire reached its greatest territorial extent from 1155 to 1268.

The name Hohenstaufen was first used in the 14th century to distinguish the "high" ("hohen") conical hill named Staufen in the Swabian Jura, in the district of Göppingen, from the village of the same name in the valley below. The new name was only applied to the hill castle of Staufen by historians in the 19th century, to distinguish it from other castles of the same name. The name of the dynasty followed, but in recent decades the trend in German historiography has been to prefer the name Staufer, which is closer to contemporary usage.

The name "Staufen" itself derives from "Stauf" (OHG "stouf", akin to Early Modern English stoup), meaning "chalice". This term was commonly applied to conical hills in Swabia in the Middle Ages. It is a contemporary term for both the hill and the castle, although its spelling in the Latin documents of the time varies considerably: "Sthouf", "Stophe", "Stophen", "Stoyphe", "Estufin" etc. The castle was built or at least acquired by Duke Frederick I of Swabia in the latter half of the 11th century.

Members of the family occasionally used the toponymic surname "de Stauf" or variants thereof. Only in the 13th century does the name come to be applied to the family as a whole. Around 1215 a chronicler referred to the "emperors of Stauf". In 1247, the Emperor Frederick II himself referred to his family as the "domus Stoffensis" (Staufer house), but this was an isolated instance. Otto of Freising (d. 1158) associated the Staufer with the town of Waiblingen and around 1230 Burchard of Ursberg referred to the Staufer as of the "royal lineage of the Waiblingens" ("regia stirps Waiblingensium"). The exact connection between the family and Waiblingen is not clear, but as a name for the family it became very popular. The pro-imperial Ghibelline faction of the Italian civic rivalries of the 13th and 14th centuries derived its name from Waiblingen.

In Italian historiography, the Staufer are known as the "Svevi" (Swabians).

The origin remains unclear, however, Staufer counts are mentioned in a document of emperor Otto III in 987 as descendants of counts of the region of "Riesgau" near Nördlingen in the Duchy of Swabia, who were related to the Bavarian "Sieghardinger" family. A local count Frederick (d. about 1075) is mentioned as progenitor in a pedigree drawn up by Abbot Wibald of Stavelot at the behest of Emperor Frederick Barbarossa in 1153. He held the office of a Swabian count palatine; his son Frederick of Buren (c.1020–1053) married Hildegard of Egisheim-Dagsburg (d. 1094/95), a niece of Pope Leo IX. Their son Frederick I was appointed Duke of Swabia at Hohenstaufen Castle by the Salian king Henry IV of Germany in 1079.

At the same time, Duke Frederick I was engaged to the king's approximately seventeen-year-old daughter, Agnes. Nothing is known about Frederick's life before this event, but he proved to be an imperial ally throughout Henry's struggles against other Swabian lords, namely Rudolf of Rheinfelden, Frederick's predecessor, and the Zähringen and Welf lords. Frederick's brother Otto was elevated to the Strasbourg bishopric in 1082.

Upon Frederick's death, he was succeeded by his son, Duke Frederick II, in 1105. Frederick II remained a close ally of the Salians, he and his younger brother Conrad were named the king's representatives in Germany when the king was in Italy. Around 1120, Frederick II married Judith of Bavaria from the rival House of Welf.

When the last male member of the Salian dynasty, Emperor Henry V, died without heirs in 1125, a controversy arose about the succession. Duke Frederick II and Conrad, the two current male Staufers, by their mother Agnes, were grandsons of late Emperor Henry IV and nephews of Henry V. Frederick attempted to succeed to the throne of the Holy Roman Emperor (formally known as the King of the Romans) through a customary election, but lost to the Saxon duke Lothair of Supplinburg. A civil war between Frederick's dynasty and Lothair's ended with Frederick's submission in 1134. After Lothair's death in 1137, Frederick's brother Conrad was elected King as Conrad III.

Because the Welf duke Henry the Proud, son-in-law and heir of Lothair and the most powerful prince in Germany, who had been passed over in the election, refused to acknowledge the new king, Conrad III deprived him of all his territories, giving the Duchy of Saxony to Albert the Bear and that of Bavaria to Leopold IV, Margrave of Austria. In 1147, Conrad heard Bernard of Clairvaux preach the Second Crusade at Speyer, and he agreed to join King Louis VII of France in a great expedition to the Holy Land which failed.

Conrad's brother Duke Frederick II died in 1147, and was succeeded in Swabia by his son, Duke Frederick III. When King Conrad III died without adult heir in 1152, Frederick also succeeded him, taking both German royal and Imperial titles.

Frederick I (Reign 2 January 1155 – 10 June 1190), known as Frederick Barbarossa because of his red beard, struggled throughout his reign to restore the power and prestige of the German monarchy against the dukes, whose power had grown both before and after the Investiture Controversy under his Salian predecessors. As royal access to the resources of the church in Germany was much reduced, Frederick was forced to go to Italy to find the finances needed to restore the king's power in Germany. He was soon crowned emperor in Italy, but decades of warfare on the peninsula yielded scant results. The Papacy and the prosperous city-states of the Lombard League in northern Italy were traditional enemies, but the fear of Imperial domination caused them to join ranks to fight Frederick. Under the skilled leadership of Pope Alexander III, the alliance suffered many defeats but ultimately was able to deny the emperor a complete victory in Italy. Frederick returned to Germany. He had vanquished one notable opponent, his Welf cousin, Duke Henry the Lion of Saxony and Bavaria in 1180, but his hopes of restoring the power and prestige of the monarchy seemed unlikely to be met by the end of his life.

During Frederick's long stays in Italy, the German princes became stronger and began a successful colonization of Slavic lands. Offers of reduced taxes and manorial duties enticed many Germans to settle in the east in the course of the "Ostsiedlung". In 1163 Frederick waged a successful campaign against the Kingdom of Poland in order to re-install the Silesian dukes of the Piast dynasty. With the German colonization, the Empire increased in size and came to include the Duchy of Pomerania. A quickening economic life in Germany increased the number of towns and Imperial cities, and gave them greater importance. It was also during this period that castles and courts replaced monasteries as centers of culture. Growing out of this courtly culture, Middle High German literature reached its peak in lyrical love poetry, the Minnesang, and in narrative epic poems such as "Tristan", "Parzival", and the "Nibelungenlied".

Frederick died in 1190 while on the Third Crusade and was succeeded by his son, Henry VI. Elected king even before his father's death, Henry went to Rome to be crowned emperor. He married Princess Constance of Sicily, and deaths in his wife's family gave him claim of succession and possession of the Kingdom of Sicily in 1189 and 1194 respectively, a source of vast wealth. Henry failed to make royal and Imperial succession hereditary, but in 1196 he succeeded in gaining a pledge that his infant son Frederick would receive the German crown. Faced with difficulties in Italy and confident that he would realize his wishes in Germany at a later date, Henry returned to the south, where it appeared he might unify the peninsula under the Hohenstaufen name. After a series of military victories, however, he fell ill and died of natural causes in Sicily in 1197. His underage son Frederick could only succeed him in Sicily and Malta, while in the Empire the struggle between the House of Staufen and the House of Welf erupted once again.

Because the election of a three-year-old boy to be German king appeared likely to make orderly rule difficult, the boy's uncle, Duke Philip of Swabia, brother of late Henry VI, was designated to serve in his place. Other factions however favoured a Welf candidate. In 1198, two rival kings were chosen: the Hohenstaufen Philip of Swabia and the son of the deprived Duke Henry the Lion, the Welf Otto IV. A long civil war began; Philip was about to win when he was murdered by the Bavarian count palatine Otto VIII of Wittelsbach in 1208. Pope Innocent III initially had supported the Welfs, but when Otto, now sole elected monarch, moved to appropriate Sicily, Innocent changed sides and accepted young Frederick II and his ally, King Philip II of France, who defeated Otto at the 1214 Battle of Bouvines. Frederick had returned to Germany in 1212 from Sicily, where he had grown up, and was elected king in 1215. When Otto died in 1218, Fredrick became the undisputed ruler, and in 1220 was crowned Holy Roman Emperor.

Philip changed the coat of arms from a black lion on a gold shield to three leopards, probably derived from the arms of his Welf rival Otto IV.

The conflict between the Staufer dynasty and the Welf had irrevocably weakened the Imperial authority and the Norman kingdom of Sicily became the base for Staufer rule.

Emperor Frederick II spent little time in Germany as his main concerns lay in Southern Italy. He founded the University of Naples in 1224 to train future state officials and reigned over Germany primarily through the allocation of royal prerogatives, leaving the sovereign authority and imperial estates to the ecclesiastical and secular princes. He made significant concessions to the German nobles, such as those put forth in an imperial statute of 1232, which made princes virtually independent rulers within their territories. These measures favoured the further fragmentation of the Empire.

By the 1226 Golden Bull of Rimini, Frederick had assigned the military order of the Teutonic Knights to complete the conquest and conversion of the Prussian lands. A reconciliation with the Welfs took place in 1235, whereby Otto the Child, grandson of the late Saxon duke Henry the Lion, was named Duke of Brunswick and Lüneburg. The power struggle with the popes continued and resulted in Fredrick's excommunication in 1227. In 1239, Pope Gregory IX excommunicated Fredrick again, and in 1245 he was condemned as a heretic by a church council. Although Frederick was one of the most energetic, imaginative, and capable rulers of the time, he was not concerned with drawing the disparate forces in Germany together. His legacy was thus that local rulers had more authority after his reign than before it. The clergy also had become more powerful.

By the time of Frederick's death in 1250, little centralized power remained in Germany. The Great Interregnum, a period in which there were several elected rival kings, none of whom was able to achieve any position of authority, followed the death of Frederick's son King Conrad IV of Germany in 1254. The German princes vied for individual advantage and managed to strip many powers away from the diminished monarchy. Rather than establish sovereign states however, many nobles tended to look after their families. Their many male heirs created more and smaller estates, and from a largely free class of officials previously formed, many of these assumed or acquired hereditary rights to administrative and legal offices. These trends compounded political fragmentation within Germany. The period was ended in 1273 with the election of Rudolph of Habsburg, a godson of Frederick.

Conrad IV was succeeded as duke of Swabia by his only son, two-year-old Conradin. By this time, the office of duke of Swabia had been fully subsumed into the office of the king, and without royal authority had become meaningless. In 1261, attempts to elect young Conradin king were unsuccessful. He also had to defend Sicily against an invasion, sponsored by Pope Urban IV (Jacques Pantaléon) and Pope Clement IV (Guy Folques), by Charles of Anjou, a brother of the French king. Charles had been promised by the popes the Kingdom of Sicily, where he would replace the relatives of Frederick II. Charles had defeated Conradin's uncle Manfred, King of Sicily, in the Battle of Benevento on 26 February 1266. The king himself, refusing to flee, rushed into the midst of his enemies and was killed. Conradin's campaign to retake control ended with his defeat in 1268 at the Battle of Tagliacozzo, after which he was handed over to Charles, who had him publicly executed at Naples. With Conradin, the direct line of the Dukes of Swabia finally ceased to exist, though most of the later emperors were descended from the Staufer dynasty indirectly.

During the political decentralization of the late Staufer period, the population had grown from an estimated 8 million in 1200 to about 14 million in 1300, and the number of towns increased tenfold. The most heavily urbanized areas of Germany were located in the south and the west. Towns often developed a degree of independence, but many were subordinate to local rulers if not immediate to the emperor. Colonization of the east also continued in the thirteenth century, most notably through the efforts of the Teutonic Knights. German merchants also began trading extensively on the Baltic.

The Kyffhäuser Monument was erected to commemorate Frederick I, and was inaugurated in 1896. 

On October 29, 1968, the 700th anniversary of the death of Konradin, a society known as "Society for Staufer History" () was founded in Göppingen.

The Castel del Monte, Apulia which was built during the 1240s by the Emperor Frederick II was designated as a World Heritage Site in 1996.

The German artist, Hans Kloss, painted his "" depicting in great detail the history of the House of Hohenstaufen, located in .

From 2000 to 2018, the Committee of Staufer Friends () has built thirty-eight Staufer steles () in Germany, France, Italy, Austria, Czech Republic and the Netherlands.

The first ruling Hohenstaufen, Conrad III, like the last one, Conrad IV, was never crowned emperor. After a 20-year period (Great interregnum 1254–1273), the first Habsburg was elected king.

"Note: The following kings are already listed above as German Kings"

"Note: Some of the following kings are already listed above as German Kings"

"Note: Some of the following dukes are already listed above as German Kings"

 

Notes:
"For further detailed dynastic relationships, see also :Family tree of the German monarchs".




</doc>
<doc id="13806" url="https://en.wikipedia.org/wiki?curid=13806" title="History of Malaysia">
History of Malaysia

Malaysia is located on a strategic sea-lane that exposes it to global trade and various cultures. Strictly, the name "Malaysia" is a modern concept, created in the second half of the 20th century. However, contemporary Malaysia regards the entire history of Malaya and Borneo, spanning thousands of years back to Prehistoric times, as its own history, and as such it is treated in this page.

An early western account of the area is seen in Ptolemy's book "Geographia," which mentions a "Golden Khersonese," now identified as the Malay Peninsula. Hinduism and Buddhism from India and China dominated early regional history, reaching their peak during the reign of the Sumatra-based Srivijaya civilisation, whose influence extended through Sumatra, Java, the Malay Peninsula and much of Borneo from the 7th to the 13th centuries.

Although Muslims had passed through the Malay Peninsula as early as the 10th century, it was not until the 14th century that Islam first firmly established itself. The adoption of Islam in the 14th century saw the rise of a number of sultanates, the most prominent of which were the Sultanate of Malacca and the Sultanate of Brunei. Islam had a profound influence on the Malay people, but has also been influenced by them. The Portuguese were the first European colonial powers to establish themselves on the Malay Peninsula and Southeast Asia, capturing Malacca in 1511, followed by the Dutch in 1641. However, it was the British who, after initially establishing bases at Jesselton, Kuching, Penang and Singapore, ultimately secured their hegemony across the territory that is now Malaysia. The Anglo-Dutch Treaty of 1824 defined the boundaries between British Malaya and the Netherlands East Indies (which became Indonesia). On the other hand, the Anglo-Siamese Treaty of 1909 defined the boundaries between British Malaya and Siam (which became Thailand)). The fourth phase of foreign influence was an immigration of Chinese and Indian workers to meet the needs of the colonial economy created by the British in the Malay Peninsula and Borneo.

Japanese invasion during World War II ended British domination in Malaysia. The subsequent occupation of Malaya, North Borneo and Sarawak from 1942 to 1945 unleashed nationalism. In the Peninsula, the Malayan Communist Party took up arms against the British. A tough military response ended the insurgency and brought about the establishment of an independent for MALAYA on 31st August 1957. on 16 September 1963, Malaya , Singapore , Sabah and Sarawak are joined together formed as Malaysia. Approximately two years later, the Malaysian parliament passed a bill without the consent of signatories of the Malaysia Agreement 1963 to separate Singapore from the Federation. A confrontation with Indonesia occurred in the early-1960s. Race riots in 1969 led to the imposition of emergency rule, and a curtailment of political life and civil liberties which has never been fully reversed. Since 1970 the Barisan Nasional coalition headed by United Malays National Organisation (UMNO) had governed Malaysia until defeated by the Pakatan Harapan coalition which was headed by ex-UMNO leader Mahathir Mohamad on 10 May 2018. On March 2020, the Pakatan Harapan coalition fell when non-PKR, DAP, and AMANAH party members come together to form a government led-by BERSATU leader Muhyiddin Yassin.

Stone hand-axes from early hominoids, probably Homo erectus, have been unearthed in Lenggong. They date back 1.83 million years, the oldest evidence of hominid habitation in Southeast Asia. The earliest evidence of modern human habitation in Malaysia is the 40,000-year-old skull excavated from the Niah Caves in today's Sarawak, nicknamed "Deep Skull". It was excavated from a deep trench uncovered by Barbara and Tom Harrisson (a British ethnologist) in 1958. this is also the oldest modern human skull in Southeast Asia. The skull probably belongs to a 16-to 17-year-old adolescent girl. The first foragers visited the West Mouth of Niah Caves (located southwest of Miri) 40,000 years ago when Borneo was connected to the mainland of Southeast Asia. The landscape around the Niah Caves was drier and more exposed than it is now. Prehistorically, the Niah Caves were surrounded by a combination of closed forests with bush, parkland, swamps, and rivers. The foragers were able to survive in the rainforest through hunting, fishing, and gathering molluscs and edible plants. Mesolithic and Neolithic burial sites have also been found in the area. The area around the Niah Caves has been designated the Niah National Park.

A study of Asian genetics points to the idea that the original humans in East Asia came from Southeast Asia. The oldest complete skeleton found in Malaysia is 11,000-year-old Perak Man unearthed in 1991. The indigenous groups on the peninsula can be divided into three ethnicities, the Negritos, the Senoi, and the proto-Malays. The first inhabitants of the Malay Peninsula were most probably Negritos. These Mesolithic hunters were probably the ancestors of the Semang, an ethnic Negrito group who have a long history in the Malay Peninsula.

The Senoi appear to be a composite group, with approximately half of the maternal mitochondrial DNA lineages tracing back to the ancestors of the Semang and about half to later ancestral migrations from Indochina. Scholars suggest they are descendants of early Austroasiatic-speaking agriculturalists, who brought both their language and their technology to the southern part of the peninsula approximately 4,000 years ago. They united and coalesced with the indigenous population.
The Proto Malays have a more diverse origin and had settled in Malaysia by 1000 BC as a result of Austronesian expansion. Although they show some connections with other inhabitants in Maritime Southeast Asia, some also have an ancestry in Indochina around the time of the Last Glacial Maximum about 20,000 years ago. Anthropologists support the notion that the Proto-Malays originated from what is today Yunnan, China. This was followed by an early-Holocene dispersal through the Malay Peninsula into the Malay Archipelago. Around 300 BC, they were pushed inland by the Deutero-Malays, an Iron Age or Bronze Age people descended partly from the Chams of Cambodia and Vietnam. The first group in the peninsula to use metal tools, the Deutero-Malays were the direct ancestors of today's Malaysian Malays, and brought with them advanced farming techniques. The Malays remained politically fragmented throughout the Malay archipelago, although a common culture and social structure was shared.

In the first millennium CE, Malays became the dominant race on the peninsula. The small early states that were established were greatly influenced by Indian culture, as was most of Southeast Asia. Indian influence in the region dates back to at least the 3rd century BCE. South Indian culture was spread to Southeast Asia by the south Indian Pallava dynasty in the 4th and 5th century.

In ancient Indian literature, the term "Suvarnadvipa" or the "Golden Peninsula" is used in "Ramayana", and some argued that it may be a reference to the Malay Peninsula. The ancient Indian text "Vayu Purana" also mentioned a place named "Malayadvipa" where gold mines may be found, and this term has been proposed to mean possibly Sumatra and the Malay Peninsula. The Malay Peninsula was shown on Ptolemy's map as the "Golden Khersonese". He referred to the Straits of Malacca as "Sinus Sabaricus".

Trade relations with China and India were established in the 1st century BC. Shards of Chinese pottery have been found in Borneo dating from the 1st century following the southward expansion of the Han Dynasty. In the early centuries of the first millennium, the people of the Malay Peninsula adopted the Indian religions of Hinduism and Buddhism, religions which had a major effect on the language and culture of those living in Malaysia. The Sanskrit writing system was used as early as the 4th century.

There were numerous Malay kingdoms in the 2nd and 3rd century, as many as 30, mainly based on the Eastern side of the Malay peninsula. Among the earliest kingdoms known to have been based in the Malay Peninsula is the ancient kingdom of Langkasuka, located in the northern Malay Peninsula and based somewhere on the west coast. It was closely tied to Funan in Cambodia, which also ruled part of northern Malaysia until the 6th century. In the 5th century, the Kingdom of Pahang was mentioned in the "Book of Song". According to the Sejarah Melayu ("Malay Annals"), the Khmer prince Raja Ganji Sarjuna founded the kingdom of Gangga Negara (modern-day Beruas, Perak) in the 700s. Chinese chronicles of the 5th century CE speak of a great port in the south called Guantoli, which is thought to have been in the Straits of Malacca. In the 7th century, a new port called Shilifoshi is mentioned, and this is believed to be a Chinese rendering of Srivijaya.

Gangga Negara is believed to be a lost semi-legendary Hindu kingdom mentioned in the Malay Annals that covered present day Beruas, Dinding and Manjung in the state of Perak, Malaysia with Raja Gangga Shah Johan as one of its kings. Gangga Negara means "a city on the Ganges" in Sanskrit, the name derived from Ganganagar in northwest India where the Kambuja peoples inhabited. Researchers believe that the kingdom was centered at Beruas. Another Malay annal Hikayat Merong Mahawangsa known as Kedah Annals, Gangga Negara may have been founded by Merong Mahawangsa's son Raja Ganji Sarjuna of Kedah, allegedly a descendant of Alexander the Great or by the Khmer royalties no later than the 2nd century.

The first research into the Beruas kingdom was conducted by Colonel James Low in 1849 and a century later, by H.G. Quaritch Wales. According to the Museum and Antiquities Department, both researchers agreed that the Gangga Negara kingdom existed between 100 – 1000 CE but could not ascertain the exact site. For years, villagers had unearthed artefacts believed to be from the ancient kingdoms, most of which are at present displayed at the Beruas Museum. Artefacts on display include a 128 kg cannon, swords, kris, coins, tin ingots, pottery from the Ming Dynasty and various eras, and large jars. They can be dated back to the 5th and 6th century. Through these artefacts, it has been postulated that Pengkalan (Ipoh), Kinta Valley, Tanjung Rambutan, Bidor and Sungai Siput were part of the kingdom. Artifacts also suggest that the kingdom's centre might have shifted several times. Gangga Negara was renamed to Beruas after the establishment of Islam there.

Ptolemy, a Greek geographer, astronomer, and astrologer, had written about Golden Chersonese, which indicates trade with India and China has existed since the 1st century AD.,

As early as the 1st century AD, Southeast Asia was the place of a network of coastal city-states, the center of which was the ancient Khmer Funan kingdom in the south of what is now Vietnam. This network encompassed the southern part of the Indochinese peninsula and the western part of the Malay archipelago. These coastal cities had a continuous trade as well as tributary relations with China from a very early period, at the same time being in constant contact with Indian traders. They seem to have shared a common indigenous culture.

Gradually, the rulers of the western part of the archipelago adopted Indian cultural and political models e.g. proof of such Indian influence on Indonesian art in the 5th century. Three inscriptions found in Palembang (South Sumatra) and on Bangka Island, written in a form of Malay and in an alphabet derived from the Pallava script, are proof that the archipelago had definitely adopted Indian models while maintaining their indigenous language and social system. These inscriptions reveal the existence of a "Dapunta Hyang" (lord) of Srivijaya who led an expedition against his enemies and who curses those who will not obey his law.

Being on the maritime route between China and South India, the Malay peninsula was involved in this trade The Bujang Valley, being strategically located at the northwest entrance of the Strait of Malacca as well as facing the Bay of Bengal, was continuously frequented by Chinese and south Indian traders. Such was proven by the discovery of trade ceramics, sculptures, inscriptions and monuments dated from the 5th to 14th century CE.

The Bujang Valley was continuously administered by different thalassocratical powers including Funan, Srivijaya, and Majapahit before the trade declined.

In Kedah there are remains showing Buddhist and Hindu influences which have been known for about a century now from the discoveries reported by Col. Low and has recently been subjected to a fairly exhaustive investigation by Dr. Quaritch Wales. Dr. Wales investigated no fewer than thirty sites roundabout Kedah.

An inscribed stone bar, rectangular in shape, bears the "ye-dharmma" formula in Pallava script of the 7th century, thus proclaiming the Buddhist character of the shrine near the find-spot (site I) of which only the basement survives. It is inscribed on three faces in "Pallava script" of the 6th century, possibly earlier.

Except for the Cherok Tokkun Inscription which was engraved on a large boulder, other inscriptions discovered in Bujang Valley are comparatively small in size and probably were brought in by Buddhist pilgrimage or traders.

Between the 7th and the 13th century, much of the Malay peninsula was under the Buddhist Srivijaya empire. The site of Srivijaya's centre is thought be at a river mouth in eastern Sumatra, based near what is now Palembang. For over six centuries the Maharajahs of Srivijaya ruled a maritime empire that became the main power in the archipelago. The empire was based around trade, with local kings (dhatus or community leaders) swearing allegiance to the central lord for mutual profit.

The relation between Srivijaya and the Chola Empire of south India was friendly during the reign of Raja Raja Chola I but during the reign of Rajendra Chola I the Chola Empire invaded Srivijaya cities (see Chola invasion of Srivijaya).
In 1025 and 1026 Gangga Negara was attacked by Rajendra Chola I of the Chola Empire, the Tamil emperor who is now thought to have laid Kota Gelanggi to waste. Kedah—known as "Kedaram", "Cheh-Cha" (according to "I-Ching") or "Kataha", in ancient Pallava or Sanskrit—was in the direct route of the invasions and was ruled by the Cholas from 1025. A second invasion was led by Virarajendra Chola of the Chola dynasty who conquered Kedah in the late 11th century. The senior Chola's successor, Vira Rajendra Chola, had to put down a Kedah rebellion to overthrow other invaders. The coming of the Chola reduced the majesty of Srivijaya, which had exerted influence over Kedah, Pattani and as far as Ligor. During the reign of Kulothunga Chola I Chola overlordship was established over the Srivijaya province kedah in the late 11th century. The expedition of the Chola Emperors had such a great impression to the Malay people of the medieval period that their name was mentioned in the corrupted form as Raja Chulan in the medieval Malay chronicle Sejarah Melaya. Even today the Chola rule is remembered in Malaysia as many Malaysian princes have names ending with Cholan or Chulan, one such was the Raja of Perak called Raja Chulan.
Pattinapalai, a Tamil poem of the 2nd century CE, describes goods from Kedaram heaped in the broad streets of the Chola capital. A 7th-century Indian drama, "Kaumudhimahotsva", refers to Kedah as Kataha-nagari. The "Agnipurana" also mentions a territory known as Anda-Kataha with one of its boundaries delineated by a peak, which scholars believe is Gunung Jerai. Stories from the "Katasaritasagaram" describe the elegance of life in Kataha. The Buddhist kingdom of Ligor took control of Kedah shortly after. Its king Chandrabhanu used it as a base to attack Sri Lanka in the 11th century and ruled the northern parts, an event noted in a stone inscription in Nagapattinum in Tamil Nadu and in the Sri Lankan chronicles, "Mahavamsa".

At times, the Khmer kingdom, the Siamese kingdom, and even Cholas kingdom tried to exert control over the smaller Malay states. The power of Srivijaya declined from the 12th century as the relationship between the capital and its vassals broke down. Wars with the Javanese caused it to request assistance from China, and wars with Indian states are also suspected. In the 11th century, the centre of power shifted to Malayu, a port possibly located further up the Sumatran coast near the Jambi River. The power of the Buddhist Maharajas was further undermined by the spread of Islam. Areas which were converted to Islam early, such as Aceh, broke away from Srivijaya's control. By the late 13th century, the Siamese kings of Sukhothai had brought most of Malaya under their rule. In the 14th century, the Hindu Java-based Majapahit empire came into possession of the peninsula.

An excavation by Tom Harrisson in 1949 unearthed a series of Chinese ceramics at Santubong (near Kuching) that date to the Tang and the Song dynasties in the 8th to 13th century AD. It is possible that Santubong was an important seaport in Sarawak during the period, but its importance declined during the Yuan dynasty, and the port was deserted during the Ming dynasty. Other archaeological sites in Sarawak can be found inside the Kapit, Song, Serian, and Bau districts.

After decades of Javanese domination, there were several last efforts made by Sumatran rulers to revive the old prestige and fortune of Malay-Srivijayan Mandala. Several attempts to revive Srivijaya were made by the fleeing princes of Srivijaya. According to the Malay Annals, a new ruler named Sang Sapurba was promoted as the new paramount of Srivijayan mandala. It was said that after his accession to Seguntang Hill with his two younger brothers, Sang Sapurba entered into a sacred covenant with Demang Lebar Daun, the native ruler of Palembang. The newly installed sovereign afterwards descended from the hill of Seguntang into the great plain of the Musi river, where he married Wan Sendari, the daughter of the local chief, Demang Lebar Daun. Sang Sapurba was said to have reigned in Minangkabau lands.

In 1324, a Srivijaya prince, Sri Maharaja Sang Utama Parameswara Batara Sri Tribuwana (Sang Nila Utama), founded the Kingdom of Singapura (Temasek). According to tradition, he was related to Sang Sapurba. He maintained control over Temasek for 48 years. He was recognized as ruler over Temasek by an envoy of the Chinese Emperor sometime around 1366. He was succeeded by his son Paduka Sri Pekerma Wira Diraja (1372–1386) and grandson, Paduka Seri Rana Wira Kerma (1386–1399). In 1401, the last ruler, Paduka Sri Maharaja Parameswara, was expelled from Temasek by forces from Majapahit or Ayutthaya. He later headed north and founded the Sultanate of Malacca in 1402. The Sultanate of Malacca succeeded the Srivijaya Empire as a Malay political entity in the archipelago.

Islam came to the Malay Archipelago through the Arab and Indian traders in the 13th century, ending the age of Hinduism and Buddhism. It arrived in the region gradually, and became the religion of the elite before it spread to the commoners. The Islam in Malaysia was influenced by previous religions and was originally not orthodox.

The port of Malacca on the west coast of the Malay Peninsula was founded in 1400 by Parameswara, a Srivijaya prince fleeing Temasek (now Singapore), Parameswara in particular sailed to Temasek to escape persecution. There he came under the protection of Temagi, a Malay chief from Patani who was appointed by the king of Siam as regent of Temasek. Within a few days, Parameswara killed Temagi and appointed himself regent. Some five years later he had to leave Temasek, due to threats from Siam. During this period, a Javanese fleet from Majapahit attacked Temasek.
Parameswara headed north to found a new settlement. At Muar, Parameswara considered siting his new kingdom at either Biawak Busuk or at Kota Buruk. Finding that the Muar location was not suitable, he continued his journey northwards. Along the way, he reportedly visited Sening Ujong (former name of present-day Sungai Ujong) before reaching a fishing village at the mouth of the Bertam River (former name of the Melaka River), and founded what would become the Malacca Sultanate. Over time this developed into modern-day Malacca Town. According to the "Malay Annals", here Parameswara saw a mouse deer outwitting a dog resting under a Malacca tree. Taking this as a good omen, he decided to establish a kingdom called Malacca. He built and improved facilities for trade. The Malacca Sultanate is commonly considered the first independent state in the peninsula.
In 1404, the first official Chinese trade envoy led by Admiral Yin Qing arrived in Malacca. Later, Parameśwara was escorted by Zheng He and other envoys in his successful visits. Malacca's relationships with Ming granted protection to Malacca against attacks from Siam and Majapahit and Malacca officially submitted as a protectorate of Ming China. This encouraged the development of Malacca into a major trade settlement on the trade route between China and India, Middle East, Africa and Europe. To prevent the Malaccan empire from falling to the Siamese and Majapahit, he forged a relationship with the Ming dynasty of China for protection. Following the establishment of this relationship, the prosperity of the Malacca entrepôt was then recorded by the first Chinese visitor, Ma Huan, who travelled together with Admiral Zheng He. In Malacca during the early 15th century, Ming China actively sought to develop a commercial hub and a base of operation for their treasure voyages into the Indian Ocean. Malacca had been a relatively insignificant region, not even qualifying as a polity prior to the voyages according to both Ma Huan and Fei Xin, and was a vassal region of Siam. In 1405, the Ming court dispatched Admiral Zheng He with a stone tablet enfeoffing the Western Mountain of Malacca as well as an imperial order elevating the status of the port to a country. The Chinese also established a government depot (官廠) as a fortified cantonment for their soldiers. Ma Huan reported that Siam did not dare to invade Malacca thereafter. The rulers of Malacca, such as Parameswara in 1411, would pay tribute to the Chinese emperor in person.

The emperor of Ming Dynasty China was sending out fleets of ships to expand trade. Admiral Zheng He called at Malacca and brought Parameswara with him on his return to China, a recognition of his position as legitimate ruler of Malacca. In exchange for regular tribute, the Chinese emperor offered Melaka protection from the constant threat of a Siamese attack. Because of its strategic location, Malacca was an important stopping point for Zheng He's fleet. Due to Chinese involvement, Malacca had grown as key alternative to other important and established ports.The Chinese and Indians who settled in the Malay Peninsula before and during this period are the ancestors of today's Baba-Nyonya and Chitty community. According to one theory, Parameswara became a Muslim when he married a Princess of Pasai and he took the fashionable Persian title "Shah", calling himself Iskandar Shah. Chinese chronicles mention that in 1414, the son of the first ruler of Malacca visited the Ming emperor to inform them that his father had died. Parameswara's son was then officially recognised as the second ruler of Melaka by the Chinese Emperor and styled Raja Sri Rama Vikrama, Raja of Parameswara of Temasek and Malacca and he was known to his Muslim subjects as Sultan Sri Iskandar Zulkarnain Shah or Sultan Megat Iskandar Shah. He ruled Malacca from 1414 to 1424. Through the influence of Indian Muslims and, to a lesser extent, Hui people from China, Islam became increasingly common during the 15th century.

After an initial period paying tribute to the Ayutthaya, the kingdom rapidly assumed the place previously held by Srivijaya, establishing independent relations with China, and exploiting its position dominating the Straits to control the China-India maritime trade, which became increasingly important when the Mongol conquests closed the overland route between China and the west.
Within a few years of its establishment, Malacca officially adopted Islam. Parameswara became a Muslim, and because Malacca was under a Muslim prince, the conversion of Malays to Islam accelerated in the 15th century. The political power of the Malacca Sultanate helped Islam's rapid spread through the archipelago. Malacca was an important commercial centre during this time, attracting trade from around the region. By the start of the 16th century, with the Malacca Sultanate in the Malay peninsula and parts of Sumatra, the Demak Sultanate in Java, and other kingdoms around the Malay archipelago increasingly converting to Islam, it had become the dominant religion among Malays, and reached as far as the modern-day Philippines, leaving Bali as an isolated outpost of Hinduism today.

Malacca's reign lasted little more than a century, but during this time became the established centre of Malay culture. Most future Malay states originated from this period. Malacca became a cultural centre, creating the matrix of the modern Malay culture: a blend of indigenous Malay and imported Indian, Chinese and Islamic elements. Malacca's fashions in literature, art, music, dance and dress, and the ornate titles of its royal court, came to be seen as the standard for all ethnic Malays. The court of Malacca also gave great prestige to the Malay language, which had originally evolved in Sumatra and been brought to Malacca at the time of its foundation. In time Malay came to be the official language of all the Malaysian states, although local languages survived in many places. After the fall of Malacca, the Sultanate of Brunei became the major centre of Islam.

Before its conversion to Islam, Brunei was known as Poni and it was a vassal-state to the Majapahit Empire. By the 15th century, the empire became a Muslim state, when the King of Brunei converted to Islam, brought by Muslim Indians and Arab merchants from other parts of Maritime Southeast Asia, who came to trade and spread Islam. During the rule of Bolkiah, the fifth Sultan, the empire controlled the coastal areas of northwest Borneo (present-day Brunei, Sarawak and Sabah) and reached the Philippines at Seludong (present-day Manila), Sulu Archipelago and included parts of the island of Mindanao. In the 16th century, the Brunei empire's influence also extended as far as Kapuas River delta in West Kalimantan.

Other sultanates in the area had close relations with the Royal House of Brunei, being in some cases effectively under the hegemony of the Brunei ruling family for periods of time, such as the Malay sultans of Pontianak, Samarinda and as far as Banjarmasin who treated the Sultan of Brunei as their leader. The Malay Sultanate of Sambas in present-day West Kalimantan and Sultanate of Sulu in Southern Philippines in particular had developed dynastic relations with the royal house of Brunei. The Sultanate of Sarawak (covering present day Kuching, known to the Portuguese cartographers as "Cerava," and one of the five great seaports on the island of Borneo), though under the influence of the Brunei, was self-governed under Sultan Tengah before being fully integrated into the Bruneian Empire upon the Tengah's death in 1641.

The Bruneian empire began to decline during the arrival of western powers. Spain sent several expeditions from Mexico to invade Brunei's territories in the Philippines. They conquered the Bruneian colony of Islamic Manila, Christianized its people, and laid siege to Sulu. Eventually the Spanish, their Visayan allies and their Latin-American recruits assaulted Brunei itself during the Castilian War. The invasion was only temporary as the Spanish then retreated.
However, Brunei was unable to regain the territory it lost in the Philippines. Yet, it still maintained sway in Borneo. By the early 19th century, Sarawak had become a loosely governed territory under the control of the Brunei Sultanate. The Bruneian Empire had authority only along the coastal regions of Sarawak held by semi-independent Malay leaders. Meanwhile, the interior of Sarawak suffered from tribal wars fought by Iban, Kayan, and Kenyah peoples, who aggressively fought to expand their territories.

Following the discovery of antimony ore in the Kuching region, Pangeran Indera Mahkota (a representative of the Sultan of Brunei) began to develop the territory between 1824 and 1830. When antimony production increased, the Brunei Sultanate demanded higher taxes from Sarawak; this led to civil unrest and chaos. In 1839, Sultan Omar Ali Saifuddin II (1827–1852), ordered his uncle Pengiran Muda Hashim to restore order. It was around this time that James Brooke (who would later become the first White Rajah of Sarawak) arrived in Sarawak, and Pengiran Muda Hashim requested his assistance in the matter, but Brooke refused. However, he agreed to a further request during his next visit to Sarawak in 1841. Pangeran Muda Hashim signed a treaty in 1841 surrendering Sarawak to Brooke. On 24 September 1841, Pengiran Muda Hashim bestowed the title of governor on James Brooke. This appointment was later confirmed by the Sultan of Brunei in 1842.

In 1843, James Brooke decided to create a pro-British Brunei government by installing Pengiran Muda Hashim into the Brunei Court as he would be taking the Brooke's advice. James Brooke forced Brunei to appoint Hashim under the guns of East India Company's steamer "Phlegethon", an example of a wider policy of British gunboat diplomacy. The Brunei Court was unhappy with Hashim's appointment and had him assassinated in 1845. In retaliation, James Brooke attacked the Kampong Ayer, the capital of Brunei. After the incident, the Sultan of Brunei sent an apology letter to Queen Victoria. The sultan also confirmed James Brooke's possession of Sarawak and his mining rights of antimony without paying tribute to Brunei. In 1846 Brooke effectively became the Rajah of Sarawak and founded the White Rajah Dynasty of Sarawak.

From the 15th century onwards, the Portuguese started seeking a maritime route towards Asia. In 1511, Afonso de Albuquerque led an expedition to Malaya which seized Malacca with the intent of using it as a base for activities in southeast Asia. This was the first colonial claim on what is now Malaysia. The son of the last Sultan of Malacca, Sultan Alauddin Riayat Shah II fled to the southern tip of the peninsula, where he founded a state that which became the Sultanate of Johor. Another son created the Perak Sultanate to the north. By the late 16th century, the tin mines of northern Malaya had been discovered by European traders, and Perak grew wealthy on the proceeds of tin exports. Portuguese influence was strong, as they aggressively tried to convert the population of Malacca to Catholicism. In 1571, the Spanish captured Manila and established a colony in the Philippines, reducing the Sultanate of Brunei's power.
After the fall of Malacca to Portugal, the Johor Sultanate on the southern Malay peninsula and the Sultanate of Aceh on northern Sumatra moved to fill the power vacuum left behind. The three powers struggled to dominate the Malay peninsula and the surrounding islands. Meanwhile, the importance of the Strait of Malacca as an East-West shipping route was growing, while the islands of Southeast Asia were themselves prized sources of natural resources (metals, spices, etc.) whose inhabitants were being further drawn in the global economy.

After the founding of the Johor Sultanate in 1528 by Alauddin Riayat Shah II, it grew powerful enough to rival the Portuguese though it was never able to recapture the city. Instead it expanded in other directions, building in 130 years one of the largest Malay states. In this time the numerous attempts to recapture Malacca led to a strong backlash from the Portuguese, whose raids even reached Johor's capital of Johor Lama in 1587.

In 1607, the Sultanate of Aceh rose as the powerful and wealthiest state in the Malay archipelago. Under Iskandar Muda's reign, the sultanate's control was extended over a number of Malay states. A notable conquest was Perak, a tin-producing state on the Peninsula. In Iskandar Muda's disastrous campaign against Malacca in 1629, the combined Portuguese and Johor forces managed to destroy all the ships of his formidable fleet and 19,000 troops according to a Portuguese account. Aceh forces were not destroyed, however, as Aceh was able to conquer Kedah within the same year and took many of its citizens to Aceh. The Sultan's son-in-law, Iskandar Thani, the former prince of Pahang later became Iskandar Muda's successor. The conflict over control of the straits went on until 1641, when the Dutch (allied to Johor) gained control of Malacca.

In the early 17th century, the Dutch East India Company ("Vereenigde Oost-Indische Compagnie", or VOC) was established. During this time the Dutch were at war with Spain, which absorbed the Portuguese Empire due to the Iberian Union. The Dutch expanded across the archipelago, forming an alliance with Johor and using this to push the Portuguese out of Malacca in 1641. Backed by the Dutch, Johor established a loose hegemony over the Malay states, except Perak, which was able to play off Johor against the Siamese to the north and retain its independence. The Dutch did not interfere in local matters in Malacca, but at the same time diverted most trade to its colonies on Java.

The weakness of the small coastal Malay states led to the immigration of the Bugis, escaping from Dutch colonisation of Sulawesi, who established numerous settlements on the peninsula which they used to interfere with Dutch trade. They seized control of Johor following the assassination of the last Sultan of the old Melaka royal line in 1699. Bugis expanded their power in the states of Johor, Kedah, Perak, and Selangor. The Minangkabau from central Sumatra migrated into Malaya, and eventually established their own state in Negeri Sembilan. The fall of Johor left a power vacuum on the Malay Peninsula which was partly filled by the Siamese kings of Ayutthaya kingdom, who made the five northern Malay states—Kedah, Kelantan, Patani, Perlis, and Terengganu — their vassals. Johor's eclipse also left Perak as the unrivalled leader of the Malay states.

The economic importance of Malaya to Europe grew rapidly during the 18th century. The fast-growing tea trade between China and United Kingdom increased the demand for high-quality Malayan tin, which was used to line tea-chests. Malayan pepper also had a high reputation in Europe, while Kelantan and Pahang had gold mines. The growth of tin and gold mining and associated service industries led to the first influx of foreign settlers into the Malay world – initially Arabs and Indians, later Chinese.

English traders had been present in Malay waters since the 17th century. However, with the arrival of the British, European power became dominant in Malaysia. Before the mid-19th-century British interests in the region were predominantly economic, with little interest in territorial control. Already the most powerful coloniser in India, the British were looking towards southeast Asia for new resources. The growth of the China trade in British ships increased the East India Company's desire for bases in the region. Various islands were used for this purpose, but the first permanent acquisition was Penang, leased from the Sultan of Kedah in 1786. This was followed soon after by the leasing of a block of territory on the mainland opposite Penang (known as Province Wellesley). In 1795, during the Napoleonic Wars, the British with the consent of the Netherlands occupied Dutch Melaka to forestall possible French encroachment in the area.

When Malacca was handed back to the Dutch in 1815, the British governor, Stamford Raffles, looked for an alternative base, and in 1819 he acquired Singapore from the Sultan of Johor. The exchange of the British colony of Bencoolen for Malacca with the Dutch left the British as the sole colonial power on the peninsula. The territories of the British were set up as free ports, attempting to break the monopoly held by other colonial powers at the time, and making them large bases of trade. They allowed Britain to control all trade through the straits of Malacca. British influence was increased by Malayan fears of Siamese expansionism, to which Britain made a useful counterweight. During the 19th century the Malay Sultans aligned themselves with the British Empire, due to the benefits of associations with the British and the belief in superior British civilisation.

In 1824, British hegemony in Malaya (before the name Malaysia) was formalised by the Anglo-Dutch Treaty, which divided the Malay archipelago between Britain and the Netherlands. The Dutch evacuated Melaka and renounced all interest in Malaya, while the British recognised Dutch rule over the rest of the East Indies. By 1826 the British controlled Penang, Malacca, Singapore, and the island of Labuan, which they established as the crown colony of the Straits Settlements, administered first under the East India Company until 1867, when they were transferred to the Colonial Office in London.

Initially, the British followed a policy of non-intervention in relations between the Malay states. The commercial importance of tin mining in the Malay states to merchants in the Straits Settlements led to infighting between the aristocracy on the peninsula. The destabilisation of these states damaged the commerce in the area, causing British intervention. The wealth of Perak's tin mines made political stability there a priority for British investors, and Perak was thus the first Malay state to agree to the supervision of a British resident. British gunboat diplomacy was employed to bring about a peaceful resolution to civil disturbances caused by Chinese and Malay gangsters employed in a political fight between Ngah Ibrahim and Raja Muda Abdullah. The Pangkor Treaty of 1874 paved the way for the expansion of British influence in Malaya. The British concluded treaties with some Malay states, installing “residents” who advised the Sultans and soon became the effective rulers of their states. These advisors held power in everything except to do with Malay religion and customs.

Johor alone resisted, by modernising and giving British and Chinese investors legal protection. By the turn of the 20th century, the states of Pahang, Selangor, Perak, and Negeri Sembilan, known together as the Federated Malay States, had British advisors. In 1909 the Siamese kingdom was compelled to cede Kedah, Kelantan, Perlis and Terengganu, which already had British advisors, over to the British. Sultan Abu Bakar of Johor and Queen Victoria were personal acquaintances who recognised each other as equals. It was not until 1914 that Sultan Abu Bakar's successor, Sultan Ibrahim, accepted a British adviser. The four previously Thai states and Johor were known as the Unfederated Malay States. The states under the most direct British control developed rapidly, becoming the largest suppliers in the world of first tin, then rubber.

By 1910, the pattern of British rule in the Malay lands was established. The Straits Settlements were a Crown colony, ruled by a governor under the supervision of the Colonial Office in London. Their population was about half Chinese, but all residents, regardless of race, were British subjects. The first four states to accept British residents, Perak, Selangor, Negeri Sembilan, and Pahang, were termed the Federated Malay States: while technically independent, they were placed under a Resident-General in 1895, making them British colonies in all but name. The Unfederated Malay States (Johore, Kedah, Kelantan, Perlis, and Terengganu) had a slightly larger degree of independence, although they were unable to resist the wishes of their British residents for long. Johor, as Britain's closest ally in Malay affairs, had the privilege of a written constitution, which gave the Sultan the right to appoint his own Cabinet, but he was generally careful to consult the British first.

During the late 19th century the British also gained control of the north coast of Borneo, where Dutch rule had never been established. Development on the Peninsula and Borneo were generally separate until the 19th century. The eastern part of this region (now Sabah) was under the nominal control of the Sultan of Sulu, who later became a vassal of the Spanish East Indies. The rest was the territory of the Sultanate of Brunei. In 1841, British adventurer James Brooke helped the Sultan of Brunei suppress a revolt, and in return received the title of raja and the right to govern the Sarawak River District. In 1846, his title was recognised as hereditary, and the "White Rajahs" began ruling Sarawak as a recognised independent state. The Brookes expanded Sarawak at the expense of Brunei.

In 1881, the British North Borneo Company was granted control of the territory of British North Borneo, appointing a governor and legislature. It was ruled from the office in London. Its status was similar to that of a British Protectorate, and like Sarawak it expanded at the expense of Brunei. Until the Philippine independence on 1946, seven British-controlled islands in the north-eastern part of Borneo named Turtle Islands and Cagayan de Tawi-Tawi were ceded to the Philippine government by the Crown colony government of North Borneo. The Philippines then under its irredentism motive since the administration of President Diosdado Macapagal laying claim to eastern Sabah in a basis the territory was part of the present-defunct Sultanate of Sulu's territory. In 1888, what was left of Brunei was made a British protectorate, and in 1891 another Anglo-Dutch treaty formalised the border between British and Dutch Borneo.

Unlike some colonial powers, the British always saw their empire as primarily an economic concern, and its colonies were expected to turn a profit for British shareholders. Malaya's obvious attractions were its tin and gold mines, but British planters soon began to experiment with tropical plantation crops—tapioca, gambier, pepper, and coffee. But in 1877 the rubber plant was introduced from Brazil, and rubber soon became Malaya's staple export, stimulated by booming demand from European industry. Rubber was later joined by palm oil as an export earner. All these industries required a large and disciplined labour force, and the British did not regard the Malays as reliable workers. The solution was the importation of plantation workers from India, mainly Tamil-speakers from South India. A small group of Malabaris were brought from the current place called Kerala to help with the rubber plantations, resulting in the small Malabari population seen in Malaysia today. The mines, mills and docks also attracted a flood of immigrant workers from southern China. Soon towns like Singapore, Penang, and Ipoh were majority Chinese, as was Kuala Lumpur, founded as a tin-mining centre in 1857. By 1891, when Malaya's first census was taken, Perak and Selangor, the main tin-mining states, had Chinese majorities.

The Chinese mostly arrived poor; yet their belief in industriousness and frugality, their emphasis in their children's education and their maintenance of Confucian family hierarchy, as well as their voluntary connection with tightly knit networks of mutual aid societies (run by "Hui-Guan" 會館, or non-profit organisations with nominal geographic affiliations from different parts of China) all contributed to their prosperity. In the 1890s Yap Ah Loy, who held the title of Kapitan China of Kuala Lumpur, was the richest man in Malaya, owning a chain of mines, plantations and shops. Malaya's banking and insurance industries were run by the Chinese from the start, and Chinese businesses, usually in partnership with London firms, soon had a stranglehold on the economy. Since the Malay Sultans tended to spend well beyond their means, they were soon indebted to Chinese bankers, and this gave the Chinese political as well as economic leverage. At first the Chinese immigrants were mostly men, and many intended to return home when they had made their fortunes. Many did go home, but many more stayed. At first they married Malay women, producing a community of Sino-Malayans or baba people, but soon they began importing Chinese brides, establishing permanent communities and building schools and temples.

The Indians were initially less successful, since unlike the Chinese they came mainly as indentured labourers to work in the rubber plantations, and had few of the economic opportunities that the Chinese had. They were also a less united community, since they were divided between Hindus and Muslims and along lines of language and caste. An Indian commercial and professional class emerged during the early 20th century, but the majority of Indians remained poor and uneducated in rural ghettos in the rubber-growing areas.

Traditional Malay society had great difficulty coping with both the loss of political sovereignty to the British and of economic power to the Chinese. By the early 20th century it seemed possible that the Malays would become a minority in their own country. The Sultans, who were seen as collaborators with both the British and the Chinese, lost some of their traditional prestige, particularly among the increasing number of Malays with a western education, but the mass of rural Malays continued to revere the Sultans and their prestige was thus an important prop for colonial rule. A small class of Malay nationalist intellectuals began to emerge during the early 20th century, and there was also a revival of Islam in response to the perceived threat of other imported religions, particularly Christianity. In fact few Malays converted to Christianity, although many Chinese did. The northern regions, which were less influenced by western ideas, became strongholds of Islamic conservatism, as they have remained.

The one consolation to Malay pride was that the British allowed them a virtual monopoly of positions in the police and local military units, as well as a majority of those administrative positions open to non-Europeans. While the Chinese mostly built and paid for their own schools and colleges, importing teachers from China, the colonial government fostered education for Malays, opening Malay College in 1905 and creating the Malay Administrative Service in 1910. (The college was dubbed "Bab ud-Darajat" – the Gateway to High Rank.) A Malay Teachers College followed in 1922, and a Malay Women's Training College in 1935. All this reflected the official British policy that Malaya belonged to the Malays, and that the other races were but temporary residents. This view was increasingly out of line with reality, and contained the seeds of much future trouble.

The Malay teacher's college had lectures and writings that nurtured Malay nationalism and anti-colonialist sentiments. Due to this it is known as the birthplace of Malay nationalism. In 1938, Ibrahim Yaacob, an alumnus of Sultan Idris College, established the Kesatuan Melayu Muda (Young Malays Union or KMM) in Kuala Lumpur. It was the first nationalist political organisation in British Malaya, advocating for the union of all Malays regardless of origin, and fighting for Malay rights and against British Imperialism. A specific ideal the KMM held was "Panji Melayu Raya", which called for the unification of British Malaya and Dutch East Indies.

In the years before World War II, the British were concerned with finding the balance between a centralised state and maintaining the power of the Sultans in Malaya. There were no moves to give Malaya a unitary government, and in fact in 1935 the position of Resident-General of the Federated States was abolished, and its powers decentralised to the individual states. With their usual tendency to racial stereotyping, the British regarded the Malays as amiable but unsophisticated and rather lazy, incapable of self-government, although making good soldiers under British officers. They regarded the Chinese as clever but dangerous—and indeed during the 1920s and 1930s, reflecting events in China, the Chinese Nationalist Party (the Kuomintang) and the Communist Party of China built rival clandestine organisations in Malaya, leading to regular disturbances in the Chinese towns. The British saw no way that Malaya's disparate collection of states and races could become a nation, let alone an independent one.

Although a belligerent as part of the British Empire, Malaya saw little action during World War I, except for the sinking of the Russian cruiser Zhemchug by the German cruiser SMS Emden on 28 October 1914 during the Battle of Penang.
The outbreak of war in the Pacific in December 1941 found the British in Malaya completely unprepared. During the 1930s, anticipating the rising threat of Japanese naval power, they had built a great naval base at Singapore, but never anticipated an invasion of Malaya from the north. Because of the demands of the war in Europe, there was virtually no British air capacity in the Far East. The Japanese were thus able to attack from their bases in French Indo-China with impunity, and despite stubborn resistance from British, Australian, and Indian forces, they overran Malaya in two months. Singapore, with no landward defences, no air cover, and no water supply, was forced to surrender in February 1942, doing irreparable damage to British prestige. British North Borneo and Brunei were also occupied.

The Japanese had a racial policy just as the British did. They regarded the Malays as a colonial people liberated from British imperialist rule, and fostered a limited form of Malay nationalism, which gained them some degree of collaboration from the Malay civil service and intellectuals. (Most of the Sultans also collaborated with the Japanese, although they maintained later that they had done so unwillingly.) The Malay nationalist Kesatuan Melayu Muda, advocates of "Melayu Raya", collaborated with the Japanese, based on the understanding that Japan would unite the Dutch East Indies, Malaya and Borneo and grant them independence. The occupiers regarded the Chinese, however, as enemy aliens, and treated them with great harshness: during the so-called "sook ching" (purification through suffering), up to 80,000 Chinese in Malaya and Singapore were killed. Chinese businesses were expropriated and Chinese schools either closed or burned down. Not surprisingly the Chinese, led by the Malayan Communist Party (MCP), became the backbone of the Malayan Peoples' Anti-Japanese Army (MPAJA), a force similar to the Soviet-supported Partisan rebel forces led by local Communist parties in the Eastern European theatre. With British assistance, the MPAJA became the most effective resistance force in the occupied Asian countries.

Although the Japanese argued that they supported Malay nationalism, they offended Malay nationalism by allowing their ally Thailand to re-annex the four northern states, Kedah, Perlis, Kelantan, and Terengganu that had been surrendered to the British in 1909. The loss of Malaya's export markets soon produced mass unemployment which affected all races and made the Japanese increasingly unpopular.

During occupation, ethnic tensions were raised and nationalism grew. The Malayans were thus on the whole glad to see the British back in 1945, but things could not remain as they were before the war, and a stronger desire for independence grew. Britain was bankrupt and the new Labour government was keen to withdraw its forces from the East as soon as possible. Colonial self-rule and eventual independence were now British policy. The tide of colonial nationalism sweeping through Asia soon reached Malaya. But most Malays were more concerned with defending themselves against the MCP which was mostly made up of Chinese, than with demanding independence from the British; indeed, their immediate concern was that the British not leave and abandon the Malays to the armed Communists of the MPAJA, which was the largest armed force in the country.

In 1944, the British drew up plans for a Malayan Union, which would turn the Federated and Unfederated Malay States, plus Penang and Malacca (but not Singapore), into a single Crown colony, with a view towards independence. The Bornean territories and Singapore were left out as it was thought this would make union more difficult to achieve. There was however strong opposition from the Malays, who opposed the weakening of the Malay rulers and the granting of citizenship to the ethnic Chinese and other minorities. The British had decided on equality between races as they perceived the Chinese and Indians as more loyal to the British during the war than the Malays. The Sultans, who had initially supported it, backed down and placed themselves at the head of the resistance.

In 1946, the United Malays National Organisation (UMNO) was founded by Malay nationalists led by Dato Onn bin Jaafar, the Chief Minister of Johor. UMNO favoured independence for Malaya, but only if the new state was run exclusively by the Malays. Faced with implacable Malay opposition, the British dropped the plan for equal citizenship. The Malayan Union was thus established in 1946, and was dissolved in 1948 and replaced by the Federation of Malaya, which restored the autonomy of the rulers of the Malay states under British protection.

Meanwhile, the Communists were moving towards open insurrection. The MPAJA had been disbanded in December 1945, and the MCP organised as a legal political party, but the MPAJA's arms were carefully stored for future use. The MCP policy was for immediate independence with full equality for all races. This meant it recruited very few Malays. The Party's strength was in the Chinese-dominated trade unions, particularly in Singapore, and in the Chinese schools, where the teachers, mostly born in China, saw the Communist Party of China as the leader of China's national revival. In March 1947, reflecting the international Communist movement's "turn to left" as the Cold War set in, the MCP leader Lai Tek was purged and replaced by the veteran MPAJA guerrilla leader Chin Peng, who turned the party increasingly to direct action. These rebels, under the leadership of the MCP, launched guerrilla operations designed to force the British out of Malaya. In July, following a string of assassinations of plantation managers, the colonial government struck back, declaring a State of Emergency, banning the MCP and arresting hundreds of its militants. The Party retreated to the jungle and formed the Malayan Peoples' Liberation Army, with about 13,000 men under arms, all Chinese.

The Malayan Emergency as it was known, lasted from 1948 to 1960 and involved a long anti-insurgency campaign by Commonwealth troops in Malaya. The British strategy, which proved ultimately successful, was to isolate the MCP from its support base by a combination of economic and political concessions to the Chinese and the resettlement of Chinese squatters into "New Villages" in "white areas" free of MCP influence. In December 1948, 24 villagers were executed by British troops. From 1949 the MCP campaign lost momentum and the number of recruits fell sharply. Although the MCP succeeded in assassinating the British High Commissioner, Sir Henry Gurney, in October 1951, this turn to terrorist tactics alienated many moderate Chinese from the Party. The arrival of Lt.-Gen Sir Gerald Templer as British commander in 1952 was the beginning of the end of the Emergency. Templer invented the techniques of counter-insurgency warfare in Malaya and applied them ruthlessly. Although the insurgency was defeated Commonwealth troops remained with the backdrop of the Cold War. Against this backdrop, independence for the Federation within the Commonwealth was granted on 31 August 1957, with Tunku Abdul Rahman as the first prime minister.

Chinese reaction against the MCP was shown by the formation of the Malayan Chinese Association (MCA) in 1949 as a vehicle for moderate Chinese political opinion. Its leader Tan Cheng Lock favoured a policy of collaboration with UMNO to win Malayan independence on a policy of equal citizenship, but with sufficient concessions to Malay sensitivities to ease nationalist fears. Tan formed a close collaboration with Tunku (Prince) Abdul Rahman, the Chief Minister of Kedah and from 1951 successor to Datuk Onn as leader of UMNO. Since the British had announced in 1949 that Malaya would soon become independent whether the Malayans liked it or not, both leaders were determined to forge an agreement their communities could live with as a basis for a stable independent state. The UMNO-MCA Alliance, which was later joined by the Malayan Indian Congress (MIC), won convincing victories in local and state elections in both Malay and Chinese areas between 1952 and 1955.

The introduction of elected local government was another important step in defeating the Communists. After Joseph Stalin's death in 1953, there was a split in the MCP leadership over the wisdom of continuing the armed struggle. Many MCP militants lost heart and went home, and by the time Templer left Malaya in 1954, the Emergency was over, although Chin Peng led a diehard group that lurked in the inaccessible country along the Thai border for many years.

During 1955 and 1956 UMNO, the MCA and the British hammered out a constitutional settlement for a principle of equal citizenship for all races. In exchange, the MCA agreed that Malaya's head of state would be drawn from the ranks of the Malay Sultans, that Malay would be the official language, and that Malay education and economic development would be promoted and subsidised. In effect, this meant that Malaya would be run by the Malays, particularly since they continued to dominate the civil service, the army and the police, but that the Chinese and Indians would have proportionate representation in the Cabinet and the parliament, would run those states where they were the majority, and would have their economic position protected. The difficult issue of who would control the education system was deferred until after independence. This came on 31 August 1957, when Tunku Abdul Rahman became the first Prime Minister of independent Malaya.

This left the unfinished business of the other British-ruled territories in the region. After the Japanese surrender the Brooke family and the British North Borneo Company gave up their control of Sarawak and North Borneo respectively, and these became British Crown Colonies. They were much less economically developed than Malaya, and their local political leaderships were too weak to demand independence. Singapore, with its large Chinese majority, achieved autonomy in 1955, and in 1959 the young leader Lee Kuan Yew became Prime Minister. The Sultan of Brunei remained as a British client in his oil-rich enclave. Between 1959 and 1962 the British government orchestrated complex negotiations between these local leaders and the Malayan government.

On 24 April 1961, Lee Kuan Yew proposed the idea of forming Malaysia during a meeting to Tunku Abdul Rahman, after which Tunku invited Lee to prepare a paper elaborating on this idea. On 9 May, Lee sent the final version of the paper to Tunku and then deputy Malayan Prime Minister Abdul Razak. There were doubts about the practicality of the idea but Lee assured the Malayan government of continued Malay political dominance in the new federation. Razak supported the idea of the new federation and worked to convince Tunku to back it. On 27 May 1961, Abdul Rahman proposed the idea of forming "Malaysia", which would consist of Brunei, Malaya, North Borneo, Sarawak, and Singapore, all except Malaya still under British rule. It was stated that this would allow the central government to better control and combat communist activities, especially in Singapore. It was also feared that if Singapore became independent, it would become a base for Chinese chauvinists to threaten Malayan sovereignty. The proposed inclusion of British territories besides Singapore was intended to keep the ethnic composition of the new nation similar to that of Malaya, with the Malay and indigenous populations of the other territories canceling out the Chinese majority in Singapore.

Although Lee Kuan Yew supported the proposal, his opponents from the Singaporean Socialist Front (Barisan Sosialis) resisted, arguing that this was a ploy for the British to continue controlling the region. Most political parties in Sarawak were also against the merger, and in North Borneo, where there were no political parties, community representatives also stated their opposition. Although the Sultan of Brunei supported the merger, the Parti Rakyat Brunei opposed it as well. At the Commonwealth Prime Ministers Conference in 1961, Abdul Rahman explained his proposal further to its opponents. In October, he obtained agreement from the British government to the plan, provided that feedback be obtained from the communities involved in the merger.
The Cobbold Commission, named after its head, Lord Cobbold, conducted a study in the Borneo territories and approved a merger with North Borneo and Sarawak; however, it was found that a substantial number of Bruneians opposed merger. North Borneo drew up a list of points, referred to as the 20-point agreement, proposing terms for its inclusion in the new federation. Sarawak prepared a similar memorandum, known as the 18-point agreement. Some of the points in these agreements were incorporated into the eventual constitution, some were instead accepted orally. These memoranda are often cited by those who believe that Sarawak's and North Borneo's rights have been eroded over time. A referendum was conducted in Singapore to gauge opinion, and 70% supported merger with substantial autonomy given to the state government. The Sultanate of Brunei withdrew from the planned merger due to opposition from certain segments of its population as well as arguments over the payment of oil royalties and the status of the sultan in the planned merger. Additionally, the Bruneian Parti Rakyat Brunei staged an armed revolt, which, though it was put down, was viewed as potentially destabilising to the new nation.

After reviewing the Cobbold Commission's findings, the British government appointed the Landsdowne Commission to draft a constitution for Malaysia. The eventual constitution was essentially the same as the 1957 constitution, albeit with some rewording; for instance, giving recognition to the special position of the natives of the Borneo States. North Borneo, Sarawak and Singapore were also granted some autonomy unavailable to the states of Malaya. After negotiations in July 1963, it was agreed that Malaysia would come into being on 31 August 1963, consisting of Malaya, North Borneo, Sarawak, and Singapore. The date was to coincide with the independence day of Malaya and the British giving self-rule to Sarawak and North Borneo. However, Indonesia and the Philippines strenuously objected to this development, with Indonesia claiming Malaysia represented a form of "neocolonialism" and the Philippines claiming North Borneo as its territory. The opposition from the Indonesian government led by Sukarno and attempts by the Sarawak United People's Party delayed the formation of Malaysia. Due to these factors, an eight-member UN team was formed to re-ascertain whether North Borneo and Sarawak truly wanted to join Malaysia. Malaysia formally came into being on 16 September 1963, consisting of Malaya, North Borneo, Sarawak, and Singapore. In 1963 the total population of Malaysia was about 10 million.

At the time of independence, Malaya had great economic advantages. It was among the world's leading producers of three valuable commodities; rubber, tin, and palm oil, and was also a significant iron ore producer. These export industries gave the Malayan government a healthy surplus to invest in industrial development and infrastructure projects. Like other developing nations in the 1950s and 1960s, Malaya (and later Malaysia) placed great stress on state planning, although UMNO was never a socialist party. The First and Second Malayan Plans (1956–60 and 1961–65 respectively) stimulated economic growth through state investment in industry and repairing infrastructure such as roads and ports, which had been damaged and neglected during the war and the Emergency. The government was keen to reduce Malaya's dependence on commodity exports, which put the country at the mercy of fluctuating prices. The government was also aware that demand for natural rubber was bound to fall as the production and use of synthetic rubber expanded. Since a third of the Malay workforce worked in the rubber industry it was important to develop alternative sources of employment. Competition for Malaya's rubber markets meant that the profitability of the rubber industry increasingly depended on keeping wages low, which perpetuated rural Malay poverty.

Both Indonesia and the Philippines withdrew their ambassadors from Malaya on 15 September 1963, the day before Malaysia's formation. In Jakarta the British and Malayan embassies were stoned, and the British consulate in Medan was ransacked with Malaya's consul taking refuge in the US consulate. Malaysia withdrew its ambassadors in response, and asked Thailand to represent Malaysia in both countries.

Indonesian President Sukarno, backed by the powerful Communist Party of Indonesia (PKI), chose to regard Malaysia as a "neocolonialist" plot against his country, and backed a Communist insurgency in Sarawak, mainly involving elements of the local Chinese community. Indonesian irregular forces were infiltrated into Sarawak, where they were contained by Malaysian and Commonwealth of Nations forces. This period of "Konfrontasi", an economic, political, and military confrontation lasted until the downfall of Sukarno in 1966. The Philippines objected to the formation of the federation, claiming North Borneo was part of Sulu, and thus the Philippines. In 1966 the new president, Ferdinand Marcos, dropped the claim, although it has since been revived and is still a point of contention marring Philippine-Malaysian relations.

The Depression of the 1930s, followed by the outbreak of the Sino-Japanese War, had the effect of ending Chinese emigration to Malaya. This stabilised the demographic situation and ended the prospect of the Malays becoming a minority in their own country. At the time of independence in 1957, Malays comprised 55% of the population, Chinese 35% and Indians 10%. This balance was altered by the inclusion of the majority-Chinese Singapore, upsetting many Malays. The federation increased the Chinese proportion to close to 40%. Both UMNO and the MCA were nervous about the possible appeal of Lee's People's Action Party (then seen as a radical socialist party) to voters in Malaya, and tried to organise a party in Singapore to challenge Lee's position there. Lee in turn threatened to run PAP candidates in Malaya at the 1964 federal elections, despite an earlier agreement that he would not do so (see PAP-UMNO Relations). Racial tensions intensified as PAP created an opposition alliance aiming for equality between races. This provoked Tunku Abdul Rahman to demand that Singapore withdraw from Malaysia. While the Singaporean leaders attempted to keep Singapore as a part of the Federation, the Malaysian Parliament voted 126–0 on 9 August 1965 in favor of the expulsion of Singapore.

The most vexed issues of independent Malaysia were education and the disparity of economic power among the ethnic communities. The Malays felt unhappy with the wealth of the Chinese community, even after the expulsion of Singapore. Malay political movements emerged based around this. However, since there was no effective opposition party, these issues were contested mainly within the coalition government, which won all but one seat in the first post-independence Malayan Parliament. The two issues were related, since the Chinese advantage in education played a large part in maintaining their control of the economy, which the UMNO leaders were determined to end. The MCA leaders were torn between the need to defend their own community's interests and the need to maintain good relations with UMNO. This produced a crisis in the MCA in 1959, in which a more assertive leadership under Lim Chong Eu defied UMNO over the education issue, only to be forced to back down when Tunku Abdul Rahman threatened to break up the coalition.

The Education Act of 1961 put UMNO's victory on the education issue into legislative form. Henceforward Malay and English would be the only teaching languages in secondary schools, and state primary schools would teach in Malay only. Although the Chinese and Indian communities could maintain their own Chinese and Tamil-language primary schools, all their students were required to learn Malay, and to study an agreed "Malayan curriculum". Most importantly, the entry exam to the University of Malaya (which moved from Singapore to Kuala Lumpur in 1963) would be conducted in Malay, even though most teaching at the university was in English until the 1970s. This had the effect of excluding many Chinese students. At the same time Malay schools were heavily subsidised, and Malays were given preferential treatment. This obvious defeat for the MCA greatly weakened its support in the Chinese community.

As in education, the UMNO government's unspoken agenda in the field of economic development aimed to shift economic power away from the Chinese and towards the Malays. The two Malayan Plans and the First Malaysian Plan (1966–1970) directed resources heavily into developments which would benefit the rural Malay community, such as village schools, rural roads, clinics, and irrigation projects. Several agencies were set up to enable Malay smallholders to upgrade their production and to increase their incomes. The Federal Land Development Authority (FELDA) helped many Malays to buy farms or to upgrade ones they already owned. The state also provided a range of incentives and low-interest loans to help Malays start businesses, and government tendering systematically favoured Malay companies, leading many Chinese-owned businesses to "Malayanise" their management. All this certainly tended to reduce to gap between Chinese and Malay standards of living, although some argued that this would have happened anyway as Malaysia's trade and general prosperity increased.

The collaboration of the MCA and the MIC in these policies weakened their hold on the Chinese and Indian electorates. At the same time, the effects of the government's affirmative action policies of the 1950s and 1960s had been to create a discontented class of educated but underemployed Malays. This was a dangerous combination, and led to the formation of a new party, the Malaysian People's Movement (Gerakan Rakyat Malaysia) in 1968. Gerakan was a deliberately non-communal party, bringing in Malay trade unionists and intellectuals as well as Chinese and Indian leaders. At the same time, an Islamist party, the Islamic Party of Malaysia (PAS) and a Democratic socialist party, the Democratic Action Party (DAP), gained increasing support, at the expense of UMNO and the MCA respectively.

Following the end of the Malayan Emergency in 1960, the predominantly ethnic Chinese Malayan National Liberation Army, armed wing of the Malayan Communist Party, had retreated to the Malaysian-Thailand border where it had regrouped and retrained for future offensives against the Malaysian government. The insurgency officially began when the MCP ambushed security forces in Kroh–Betong, in the northern part of Peninsular Malaysia, on 17 June 1968. Instead of declaring a "state of emergency" as the British had done previously, the Malaysian government responded to the insurgency by introducing several policy initiatives including the Security and Development Program (KESBAN), "Rukun Tetangga" (Neighbourhood Watch), and the RELA Corps (People's Volunteer Group).

At the May 1969 federal elections, the UMNO-MCA-MIC Alliance polled only 48% of the vote, although it retained a majority in the legislature. The MCA lost most of the Chinese-majority seats to Gerakan or DAP candidates. The victorious opposition celebrated by holding a motorcade on the main streets of Kuala Lumpur with supporters holding up brooms as a signal of its intention to make sweeping changes. Fear of what the changes might mean for them (as much of the country's businesses were Chinese-owned), a Malay backlash resulted, leading rapidly to riots and inter-communal violence in which about 6,000 Chinese homes and businesses were burned and at least 184 people were killed, although Western diplomatic sources at the time suggested a toll of close to 600, with most of the victims are Chinese. The government declared a state of emergency, and a National Operations Council, headed by Deputy Prime Minister Tun Abdul Razak, took power from the government of Tunku Abdul Rahman, who, in September 1970, was forced to retire in favour of Abdul Razak. It consisted of nine members, mostly Malay, and wielded full political and military power.

Using the Emergency-era Internal Security Act (ISA), the new government suspended Parliament and political parties, imposed press censorship and placed severe restrictions on political activity. The ISA gave the government power to intern any person indefinitely without trial. These powers were widely used to silence the government's critics, and have never been repealed. The Constitution was changed to make illegal any criticism, even in Parliament, of the Malaysian monarchy, the special position of Malays in the country, or the status of Malay as the national language.

In 1971 Parliament reconvened, and a new government coalition, the National Front (Barisan Nasional), was formed in 1973 to replace the Alliance party. The coalition consisted of UMNO, the MCA, the MIC, Gerakan, PPP, and regional parties in Sabah and Sarawak. The PAS also joined the Front but was expelled in 1977. The DAP was left outside as the only significant opposition party. Abdul Razak held office until his death in 1976. He was succeeded by Datuk Hussein Onn, the son of UMNO's founder Onn Jaafar, and then by Tun Mahathir Mohamad, who had been Education Minister since 1981, and who held power for 22 years. During these years policies were put in place which led to the rapid transformation of Malaysia's economy and society, such as the controversial New Economic Policy, which was intended to increase proportionally the share of the economic "pie" of the bumiputras as compared to other ethnic groups—was launched by Prime Minister Tun Abdul Razak. Malaysia has since maintained a delicate ethno-political balance, with a system of government that has attempted to combine overall economic development with political and economic policies that promote equitable participation of all races.

In 1970 three-quarters of Malaysians living below the poverty line were Malays, the majority of Malays were still rural workers, and Malays were still largely excluded from the modern economy. The government's response was the New Economic Policy of 1971, which was to be implemented through a series of four five-year plans from 1971 to 1990. The plan had two objectives: the elimination of poverty, particularly rural poverty, and the elimination of the identification between race and prosperity. This latter policy was understood to mean a decisive shift in economic power from the Chinese to the Malays, who until then made up only 5% of the professional class.

Poverty was tackled through an agricultural policy which resettled 250,000 Malays on newly cleared farmland, more investment in rural infrastructure, and the creation of free trade zones in rural areas to create new manufacturing jobs. Little was done to improve the living standards of the low-paid workers in plantation agriculture, although this group steadily declined as a proportion of the workforce. By 1990 the poorest parts of Malaysia were rural Sabah and Sarawak, which lagged significantly behind the rest of the country. During the 1970s and '80s rural poverty did decline, particularly in the Malayan Peninsula, but critics of the government's policy contend that this was mainly due to the growth of overall national prosperity (due in large part to the discovery of important oil and gas reserves) and migration of rural people to the cities rather than to state intervention. These years saw rapid growth in Malaysian cities, particularly Kuala Lumpur, which became a magnet for immigration both from rural Malaya and from poorer neighbours such as Indonesia, Bangladesh, Thailand and the Philippines. Urban poverty became a problem for the first time, with shanty towns growing up around the cities.

The second arm of government policy, driven mainly by Mahathir first as Education Minister and then as Prime Minister, was the transfer of economic power to the Malays. Mahathir greatly expanded the number of secondary schools and universities throughout the country, and enforced the policy of teaching in Malay rather than English. This had the effect of creating a large new Malay professional class. It also created an unofficial barrier against Chinese access to higher education, since few Chinese are sufficiently fluent in Malay to study at Malay-language universities. Chinese families therefore sent their children to universities in Singapore, Australia, Britain or the United States – by 2000, for example, 60,000 Malaysians held degrees from Australian universities. This had the unintended consequence of exposing large numbers of Malaysians to life in Western countries, creating a new source of discontent. Mahathir also greatly expanded educational opportunities for Malay women – by 2000 half of all university students were women.
To find jobs for all these new Malay graduates, the government created several agencies for intervention in the economy. The most important of these were PERNAS (National Corporation Ltd.), PETRONAS (National Petroleum Ltd.), and HICOM (Heavy Industry Corporation of Malaysia), which not only directly employed many Malays but also invested in growing areas of the economy to create new technical and administrative jobs which were preferentially allocated to Malays. As a result, the share of Malay equity in the economy rose from 1.5% in 1969 to 20.3% in 1990, and the percentage of businesses of all kinds owned by Malays rose from 39 percent to 68 percent. This latter figure was deceptive because many businesses that appeared to be Malay-owned were still indirectly controlled by Chinese, but there is no doubt that the Malay share of the economy considerably increased. The Chinese remained disproportionately powerful in Malaysian economic life, but by 2000 the distinction between Chinese and Malay business was fading as many new corporations, particularly in growth sectors such as information technology, were owned and managed by people from both ethnic groups.

Malaysia's rapid economic progress since 1970, which was only temporarily disrupted by the Asian financial crisis of 1997, has not been matched by change in Malaysian politics. The repressive measures passed in 1970 remain in place. Malaysia has had regular elections since 1974, and although campaigning is reasonably free at election time, it is in effect a one-party state, with the UMNO-controlled National Front usually winning nearly all the seats, while the DAP wins some Chinese urban seats and the PAS some rural Malay ones. Since the DAP and the PAS have diametrically opposed policies, they have been unable to form an effective opposition coalition. There is almost no criticism of the government in the media and public protest remains severely restricted. The ISA continues to be used to silence dissidents, and the members of the UMNO youth movement are deployed to physically intimidate opponents.

The restoration of democracy after the 1969 crisis caused disputes in the UMNO, a struggle of power which increased after the death of Tun Abdul Razak. The ailing Datuk Hussein Bin Onn replaced him, but the fight for control shifted to appointing the deputy prime minister. Mahathir Mohamad was chosen, an advocate of Bumiputra who also tried to benefit the other ethnic communities.

Under the premiership of Mahathir Mohamad, Malaysia experienced economic growth from the 1980s, a 1985–86 property market depression, and returned to growth through to the mid-1990s. Mahathir increased privatisation and introduced the New Development Policy (NDP), designed to increase economic wealth for all Malaysians, rather than just Malays. The period saw a shift from an agriculture-based economy to one based on manufacturing and industry in areas such as computers and consumer electronics. It was during this period, too, that the physical landscape of Malaysia changed with the emergence of numerous mega-projects. Notable amongst these projects were the construction of the Petronas Twin Towers (at the time the tallest building in the world, and, as of 2016, still the tallest twin building), Kuala Lumpur International Airport (KLIA), the North–South Expressway, the Sepang International Circuit, the Multimedia Super Corridor (MSC), the Bakun hydroelectric dam, and Putrajaya, the new federal administrative capital.

Under Mahathir Mohamad's long Prime Ministership (1981–2003), Malaysia's political culture became increasingly centralised and authoritarian, due to Mahathir's belief that the multiethnic Malaysia could only remain stable through controlled democracy. In 1986–87, he faced leadership challenges among his own party. There were also attacks by the government on several non-governmental organisations (NGO) which were critical of various government policies. There were also issues such the questioning by MCA's Lee Kim Sai over the use of the term "pendatang" (immigrants) that was seen as challenging Malay's bumiputra status, as well as rumours of forced conversion to or from Islam. Mahathir initiated a crackdown on opposition dissidents with the use of the Internal Security Act named Operation Lalang. The Internal Security Act was invoked in October 1987 arresting 106 people, including opposition leaders. The head of the judiciary and five members of the supreme court who had questioned his use of the ISA were also arrested, and a clampdown on Malaysia's press occurred.

This culminated in the dismissal and imprisonment on unsubstantiated charges of the Deputy Prime Minister, Anwar Ibrahim, in 1997 after an internal dispute within the government. The complicity of the judiciary in this piece of persecution was seen as a particularly clear sign of the decline of Malaysian democracy. The Anwar affair led to the formation of a new party, the People's Justice Party, or Keadilan, led by Anwar's wife, Wan Azizah Wan Ismail. At the 1999 elections Keadilan formed a coalition with the DAP and the PAS known as the Alternative Front (Barisan Alternatif). The result of this was that the PAS won a number of Malay seats from UMNO, but many Chinese voters disapproved of this unnatural alliance with the Islamist PAS, causing the DAP to lose many of its seats to the MCA, including that of its veteran leader, Lim Kit Siang. Wan Azizah won her husband's former constituency in Penang but otherwise Keadilan made little impact.

In the late 1990s, Malaysia was shaken by the Asian financial crisis, which damaged Malaysia's assembly line-based economy. Mahathir combated it initially with IMF approved policies. However, the devaluation of the Ringgit and the deepening recession caused him to create his own programme, based on protecting Malaysia from foreign investors and reinvigorating the economy through construction projects and the lowering of interest rates. The policies caused Malaysia's economy to rebound by 2002, but brought disagreement between Mahathir and his deputy, Anwar Ibrahim, who backed the IMF policies. This led to the sacking of the Anwar, causing political unrest. Anwar was arrested and banned from politics on what are considered trumped up charges. In 2003 Mahathir, Malaysia's longest serving prime minister, voluntarily retired in favour of his new deputy, Abdullah Ahmad Badawi. In November 2007 two anti-government rallies occurred, precipitated by allegations of corruption and discrepancies in the election system that heavily favoured the ruling political coalition, National Front (Barisan Nasional), which has been in power since Malaya achieved independence.

Dato Seri Abdullah Ahmad Badawi freed Anwar, which was seen as a portent of a mild liberalisation. At the 2004 election, the National Front led by Abdullah had a massive victory, virtually wiping out the PAS and Keadilan, although the DAP recovered the seats it had lost in 1999. This victory was seen as the result mainly of Abdullah's personal popularity and the strong recovery of Malaysia's economy, which has lifted the living standards of many Malaysians to almost first world standards, coupled with an ineffective opposition. The government's objective is for Malaysia to become a fully developed country by 2020 as expressed in "Wawasan 2020". It leaves unanswered, however, the question of when and how Malaysia will acquire a first world political system (a multi-party democracy, a free press, an independent judiciary and the restoration of civil and political liberties) to go with its new economic maturity.

In November 2007, Malaysia was rocked by two anti-government rallies. The 2007 Bersih Rally which was attended by 40,000 people was held in Kuala Lumpur on 10 November 2007, to campaign for electoral reform. It was precipitated by allegations of corruption and discrepancies in the Malaysian election system that heavily favour the ruling political party, Barisan Nasional, which has been in power since Malaysia achieved its independence in 1957. Another rally was held on 25 November 2007, in Kuala Lumpur led by HINDRAF. The rally organiser, the Hindu Rights Action Force, had called the protest over alleged discriminatory policies favouring ethnic Malays. The crowd was estimated to be between 5,000 and 30,000. In both cases the government and police tried to prevent the gatherings from taking place.

On 16 October 2008, HINDRAF was banned when the government labelled the organisation as "a threat to national security".

Najib Razak entered office as Prime Minister with a sharp focus on domestic economic issues and political reform. On his first day as Prime Minister, Najib announced as his first actions the removal of bans on two opposition newspapers, "Suara Keadilan" and "Harakahdaily", run by the opposition leader Datuk Seri Anwar Ibrahim-led People's Justice Party and the Pan Islamic Party, respectively, and the release of 13 people held under the Internal Security Act. Among the released detainees were two ethnic Indian activists who were arrested in December 2007 for leading an anti-government campaign, three foreigners and eight suspected Islamic militants. Najib also pledged to conduct a comprehensive review of the much-criticised law which allows for indefinite detention without trial. In the speech, he emphasised his commitment to tackling poverty, restructuring Malaysian society, expanding access to quality education for all, and promoting renewed "passion for public service". He also deferred and abandoned the digital television transition plan of all free-to-air broadcasters such as Radio Televisyen Malaysia.

Malaysia Day, celebrating the formation of Malaysia on 16 September 1963, was declared a public holiday in 2010 in complement to the existing 31 August celebration of Hari Merdeka.

In September 2016 Mahathir submitted a request to the King requesting Najib be dismissed, although no action was taken on this.

Tun Dr Mahathir Mohamad, who left UMNO in 2016 and formed his own political party, the Malaysian United Indigenous Party which teamed up with three other political parties to form Pakatan Harapan, was sworn in as the Prime Minister of Malaysia after winning the election on 10 May 2018. He defeated Najib Razak who led Barisan Nasional political party that had previously ruled Malaysia for 61 years since 1957. Najib Razak was defeated by Tun Dr Mahathir Mohamad due to the factors such as the ongoing political scandal which is 1Malaysia Development Berhad scandal that has arisen since 2015, the introduction of Goods and Services Tax (Malaysia) of 6% since 1 April 2015, high cost of living and openly extreme criticism against Tun Dr. Mahathir Mohamad.
The unpopular tax was reduced to 0% on 1 June 2018. Government of Malaysia under Tun Dr Mahathir tabled for first reading Bill to repeal GST in Parliament on 31 July 2018 (Dewan Rakyat). GST was successfully replaced with Sales Tax and Service Tax starting 1 September 2018.




</doc>
<doc id="13808" url="https://en.wikipedia.org/wiki?curid=13808" title="History of Israel">
History of Israel

The Land of Israel, also known as the Holy Land or Palestine, is the birthplace of the Jewish people, the place where the final form of the Hebrew Bible is thought to have been compiled, and the birthplace of Judaism and Christianity. It contains sites sacred to Judaism, Samaritanism, Christianity, Islam, Druze and the Bahá'í Faith. The region has come under the sway of various empires and, as a result, has hosted a wide variety of ethnicities. However, the land was predominantly Jewish (who are themselves an outgrowth of the earlier Canaanites) from roughly 1,000 years before the Common Era (BCE) until the 3rd century of the Common Era (CE). The adoption of Christianity by the Roman Empire in the 4th century led to a Greco-Roman Christian majority which lasted not just until the 7th century when the area was conquered by the Arab Muslim Empires, but for another full six centuries. It gradually became predominantly Muslim after the end of the Crusader period (1099-1291), during which it was the focal point of conflict between Christianity and Islam. From the 13th century it was mainly Muslim with Arabic as the dominant language and was first part of the Syrian province of the Mamluk Sultanate and after 1516 part of the Ottoman Empire until the British conquest in 1917-18.

A Jewish national movement, Zionism, emerged in the late-19th century (partially in response to growing antisemitism), as part of which Aliyah (Jewish return from diaspora) increased. During World War I, the British government publicly committed to create a Jewish National Home and was granted a Mandate to rule Palestine by the League of Nations for this purpose. A rival Arab nationalism also claimed rights over the former Ottoman territories and sought to prevent Jewish migration into Palestine, leading to growing Arab–Jewish tensions. Israeli independence in 1948 was accompanied by an exodus of Arabs from Israel, the Arab–Israeli conflict and a subsequent Jewish exodus from Arab and Muslim countries to Israel. About 43% of the world's Jews live in Israel today, the largest Jewish community in the world.

Since about 1970, the United States has become the principal ally of Israel. In 1979, an uneasy Egypt–Israel Peace Treaty was signed, based on the Camp David Accords. In 1993, Israel signed Oslo I Accord with the Palestine Liberation Organization, followed by establishment of the Palestinian National Authority and in 1994 Israel–Jordan peace treaty was signed. Despite efforts to finalize the peace agreement, the conflict continues to play a major role in Israeli and international political, social and economic life.

In its early decades, the economy of Israel was largely state-controlled and shaped by social democratic ideas. In the 1970s and 1980s, the economy underwent a series of free market reforms and was gradually liberalized. In the past three decades, the economy has grown considerably, but GDP per capita has increased faster than the increase in wages.

The periodisation is subject to the progress of research, to regional, national, and ideological interpretation, as well as personal preference of the individual researcher. For an overview of a mainstream periodisation system for the wider region, see List of archaeological periods (Levant). Periodisation organized by the seat of the controlling state is shown below:

Between 2.6 and 0.9 million years ago, at least four episodes of hominine dispersal from Africa to the Levant are known, each culturally distinct. The oldest evidence of early humans in the territory of modern Israel, dating to 1.5 million years ago, was found in Ubeidiya near the Sea of Galilee. The flint tool artefacts have been discovered at Yiron, the oldest stone tools found anywhere outside Africa. Other groups include 1.4 million years old Acheulean industry, the Bizat Ruhama group and Gesher Bnot Yaakov.

In the Carmel mountain range at el-Tabun, and Es Skhul, Neanderthal and early modern human remains were found, including the skeleton of a Neanderthal female, named Tabun I, which is regarded as one of the most important human fossils ever found. The excavation at el-Tabun produced the longest stratigraphic record in the region, spanning 600,000 or more years of human activity, from the Lower Paleolithic to the present day, representing roughly a million years of human evolution. Other notable Paleolithic sites include caves Qesem and Manot. The oldest fossils of anatomically modern humans found outside Africa are the Skhul and Qafzeh hominids, who lived in northern Israel 120,000 years ago. Around 10th millennium BCE, the Natufian culture existed in the area.

During the 2nd millennium BCE, Canaan, part of which later became known as Israel, was dominated by the New Kingdom of Egypt from c.1550 to c. 1180.
The earliest recorded battle in history took place in 1457 BCE, at Megiddo (known in Greek as Armageddon), between Canaanite forces and those of Pharoh Thutmose III. The Canaanites left no written history, but Thutmose's scribe, Tjaneni recorded the battle.

The first record of the name Israel (as "") occurs in the Merneptah stele, erected for Egyptian Pharaoh Merneptah (son of Ramses II) c. 1209 BCE, "Israel is laid waste and his seed is not." William G. Dever sees this "Israel" in the central highlands as a cultural and probably political entity, more an ethnic group rather than an organized state.

Ancestors of the Israelites may have included Semites native to Canaan and the Sea Peoples. McNutt says, "It is probably safe to assume that sometime during Iron Age I a population began to identify itself as 'Israelite'", differentiating itself from the Canaanites through such markers as the prohibition of intermarriage, an emphasis on family history and genealogy, and religion.

The archeological evidence indicates a society of village-like centres, but with more limited resources and a small population. Villages had populations of up to 300 or 400, which lived by farming and herding, and were largely self-sufficient; economic interchange was prevalent. Writing was known and available for recording, even in small sites.

The first use of grapheme-based writing originated in the area, probably among Canaanite peoples resident in Egypt. This evolved into the Phoenician alphabet from which all modern alphabetical writing systems are descended. The Paleo-Hebrew alphabet was one of the first to develop and evidence of its use exists from about 1000 BCE (see the Gezer calendar), the language spoken was probably Biblical Hebrew.

Monotheism, the belief in a single all-powerful law-giving God is thought to have evolved among the Hebrew speakers gradually, over the next few centuries, from a number of separate cults, leading to the first versions of the religion now known as Judaism.

The Hebrew Bible describes constant warfare between the Israelites and the Philistines whose capital was Gaza. The Phillistines were Greek refugee-settlers who inhabited the southern Levantine coast. The Bible states that King David founded a dynasty of kings and that his son Solomon built a temple. Both David and Solomon are widely referenced in Jewish, Christian and Islamic texts. Standard Biblical chronology suggests that around 930 BCE, following the death of Solomon, the kingdom split into a southern Kingdom of Judah and a northern Kingdom of Israel. The Bible's Books of Kings state that soon after the split Pharoh "Shishaq" invaded the country plundering Jerusalem. An inscription over a gate at Karnak in Egypt recounts such an invasion by Pharoh Sheshonq I.

The archeological evidence for this period is extremely sparse, leading some scholars to suggest that this section of the Hebrew Bible, which includes texts written two centuries later, exaggerates the importance of David and Solomon. The earliest references to the "House of David" have been found in two inscriptions, on the Tel Dan Stele and the Mesha Stele; the latter is a Moabite stele, now in the Louvre, which describes an 840 BCE invasion of Moab by Omri, king of Israel. Jehu, son of Omri, is referenced by Assyrian records (now in the British Museum). Modern archeological findings show that Omri's capital city, Samaria, was large and Finkelstein has suggested that the Biblical account of David and Solomon are an attempt by later Judean rulers to ascribe Israel's successes to their dynasty.

In 854 BCE, according to Assyrian records (the Kurkh Monoliths) an alliance between Ahab of Israel and Ben Hadad II of Aram Damascus managed to repulse the incursions of the Assyrians, with a victory at the Battle of Qarqar. This is not included in the Bible which describes conflict between Ahab and Ben Hadad. Around 750 BCE, the Kingdom of Israel was destroyed by Assyrian king Tiglath-Pileser III. The Philistine kingdom was also destroyed. The Assyrians sent most of the population of the northern Israelite kingdom into exile, thus creating the "Lost Tribes of Israel". The Samaritans claim to be descended from survivors of the Assyrian conquest. An Israelite revolt (724–722 BCE) was crushed after the siege and capture of Samaria by the Assyrian king Sargon II.

Modern scholars believe that refugees from the destruction of Israel moved to Judah, massively expanding Jerusalem and leading to construction of the Siloam Tunnel during the rule of King Hezekiah (ruled 715–686 BCE). The tunnel could provide water during a siege and its construction is described in the Bible. A Hebrew plaque left by the construction team still exists.

Sargon's son, Sennacherib, tried and failed to conquer Judah, during Hezekiah's reign. Assyrian records say that Sennacherib levelled 46 walled cities and besieged Jerusalem, leaving after receiving extensive tribute. The Bible also refers to tribute, and suggests that Hezekiah was aided by Taharqa, king of Kush (now Sudan), in repulsing the Assyrians. The Twenty-fifth Dynasty of Egypt were Nubian Pharohs and they probably defeated the Assyrians. Sennacherib had a 12 meter by 5-metre frieze erected in his palace in Nineveh (now in Iraq) depicting his victory at Lachish, the second largest city in Judah.

The Bible describes a tradition of religious men ("prophets") exercising some form of free speech and criticizing rulers. The most famous of these was Isaiah, who witnessed the Assyrian invasion and warned of its consequences.

Under King Josiah (ruler from 641 – 619), the book of Deuteronomy was either rediscovered or written. The Book of Joshua and the accounts of the kingship of David and Solomon in the book of Kings are believed to have the same author. The books are known as Deuteronomist and considered to be a key step in the emergence of Monotheism in Judah. They emerged at a time that Assyria was weakened by the emergence of Babylon and may be a committing to text of pre-writing verbal traditions.

In 586 BCE King Nebuchadnezzar II of Babylon conquered Judah. According to the Hebrew Bible, he destroyed Solomon's Temple and exiled the Jews to Babylon. The Phillistines were also driven into exile. The defeat of Judah was recorded by the Babylonians (see the Babylonian Chronicles). Babylonian and Biblical sources suggest that the Judean king, Jehoiachin, switched allegiances between the Egyptians and the Babylonians and that invasion was a punishment for allying with Babylon's principal rival, Egypt. The exiled Jews may have been restricted to the elite. Jehoiachin was eventually released by the Babylonians. Tablets which seem to describe his rations were found in the ruins of Babylon (see Jehoiachin's Rations Tablets). According to both the Bible and the Talmud, the Judean royal family (the Davidic line) continued as head of Babylonian Jewry, called the "Rosh Galut" (head of exile). Arab and Jewish sources show that the "Rosh Galut" continued to exist (in what is now Iraq) for another 1,500 years, ending in the eleventh century.
In 538 BCE, Cyrus the Great of Persia conquered Babylon and took over its empire. Cyrus issued a proclamation granting subjugated nations (including the people of Judah) religious freedom (for the original text see the Cyrus Cylinder). According to the Hebrew Bible 50,000 Judeans, led by Zerubabel, returned to Judah and rebuilt the temple. A second group of 5,000, led by Ezra and Nehemiah, returned to Judah in 456 BCE although non-Jews wrote to Cyrus to try to prevent their return. Modern scholars believe that the final Hebrew versions of the Torah and Books of Kings date from this period, that the returning Israelites adopted an Aramaic script (also known as the Ashuri alphabet), which they brought back from Babylon; this is the current Hebrew script. The Hebrew calendar closely resembles the Babylonian calendar and probably dates from this period.

The Persians also conquered Egypt, posting a Judean military garrison on Elephantine Island near Aswan. In the early 20th century 175 papyrus documents were discovered, recording activity in this community, including the "Passover Papyrus", a letter instructing the garrison on how to correctly conduct the Passover feast.

In 333 BCE, the Macedonian ruler Alexander the Great defeated Persia and conquered the region. After Alexander's death, his generals fought over the territory he had conquered and Judah became the frontier between the Seleucid Empire and Ptolemaic Egypt, eventually becoming part of the Seleucid Empire in 200 BCE at the battle of Panium (fought near Banias on the Golan Heights). The first translation of the Hebrew Bible, the Greek Septuagint was made in 3rd Century BCE Alexandria, during the rule of Ptolemy II Philadelphus, for the Library of Alexandria.

In the 2nd century BCE, Seleucid ruler Antiochus IV Epiphanes tried to eradicate Judaism in favour of Hellenistic religion. This provoked the 174–135 BCE Maccabean Revolt led by Judas Maccabeus (whose victory is celebrated in the Jewish festival of Hanukkah). The Books of the Maccabees describe the uprising and the end of Greek rule, these books were not added to the sacred Jewish canon and as a result the Hebrew originals were lost (Greek translations survived). 
A Jewish party called the Hasideans opposed both Hellenism "and" the revolt, but eventually gave their support to the Maccabees. Modern interpretations see the initial stages of the uprising as a civil war between Hellenised and orthodox forms of Judaism.

The Hasmonean dynasty of Jewish priest-kings ruled Judea with the Pharisees, Sadducees and Essenes as the principal Jewish social movements. As part of the struggle against Hellenistic civilization, the Pharisee leader Simeon ben Shetach established the first schools based around meeting houses. This led to Rabbinical Judaism. Justice was administered by the Sanhedrin, which was a Rabbincal assembly and law court whose leader was known as the Nasi. The Nasi's religious authority gradually superseded that of the Temple's high priest, who under the Hasmoneans was the king himself.

The Hasmoneans continually extended their control over much of the region. In 125 BCE the Hasmonean ethnarch John Hyrcanus subjugated Edom and forcibly converted its population to Judaism.

Hyrcanus' son Alexander Jannaeus established good relations with the Roman Republic, however there was growing tension between Pharisees and Sadducees and a conflict over the succession to Janneus, in which the warring parties invited foreign intervention on their behalf.

In 64 BCE the Roman general Pompey conquered Syria and intervened in the Hasmonean civil war in Jerusalem, restoring Hyrcanus II as High Priest and making Judea a Roman vassal kingdom. During the siege of Alexandria in 47 BCE, the lives of Julius Caesar and his protégé Cleopatra were saved by 3,000 Jewish troops sent by Hyrcanus II and commanded by Antipater, whose descendants Caesar made kings of Judea.

From 37 BCE to 6 CE, the Herodian dynasty, Jewish-Roman client kings, descended from Antipater, ruled Judea. Herod the Great considerably enlarged the temple (see Herod's Temple), making it one of the largest religious structures in the world. At this time, Jews formed as much as 10% of the population of the entire Roman Empire, with large communities in North Africa and Arabia. Despite the fame of the temple, Rabbinical Judaism, led by Hillel the Elder, began to assume popular prominence over the Temple priesthood. The Romans gave the Jewish Temple in Jerusalem permission not to display an effigy of the emperor, the only religious structure in the Roman Empire that was exempt. Special dispensation was granted for Jewish citizens of the Roman Empire to pay a tax to the temple.

Augustus made Judea a Roman province in 6 CE, deposing the last Jewish king, Herod Archelaus, and appointing a Roman governor. There was a small revolt against Roman taxation led by Judas of Galilee and over the next decades tensions grew between the Greco-Roman and Judean population centered on attempts to place effigies of the Emperor Caligula in Synagogues and in the Jewish temple.

Jesus was born in the last years of Herod's rule, probably in the Judean city of Bethlehem. Jesus is thought to have been a Galilean Jewish reformer (from Nazareth), and was executed in Jerusalem by the Roman governor Pontius Pilate between 25 and 35 CE. All his key followers, the Twelve Apostles, were Jews including Paul the Apostle (5–67 CE) who took critical steps towards creating a new religion, defining Jesus as the "Son of God". In the year 50 CE, the Council of Jerusalem led by Paul, decided to abandon the Jewish requirement of circumcision and the Torah, creating a form of Judaism highly accessible to non-Jews and with a more universal notion of God. Another Jewish follower, Peter is believed to have become the first Pope.

In 64 CE, the Temple High Priest Joshua ben Gamla introduced a religious requirement for Jewish boys to learn to read from the age of six. Over the next few hundred years this requirement became steadily more ingrained in Jewish tradition.

In 66 CE, the Jews of Judea rose in revolt against Rome, naming their new state as "Israel". The events were described by the Jewish leader and historian Josephus, including the defence of Jotapata, the siege of Jerusalem (69–70 CE) and the desperate last stand at Masada under Eleazar ben Yair (72–73 CE).

Josephus estimated that over a million people died in the siege of Jerusalem. The Temple and most of Jerusalem was destroyed. During the Jewish revolt, most Christians, at this time a sub-sect of Judaism, removed themselves from Judea. The rabbinical/Pharisee movement led by Yochanan ben Zakai, who opposed the Sadducee temple priesthood, made peace with Rome and survived. After the war Jews continued to be taxed in the Fiscus Judaicus, which was used to fund a temple to Jupiter. An arch commemorating the victory was erected in Rome and still exists.

Tensions and attacks on Jews around the Roman Empire led to a massive Jewish uprising against Rome from 115 to 117. Jews in Libya, Egypt, Cyprus and Mesopotamia fought against Rome. This conflict was accompanied by large-scale massacres of both sides. Cyprus was so severely depopulated that new settlers were imported and Jews banned from living there.

In 131, the Emperor Hadrian renamed Jerusalem "Aelia Capitolina" and constructed a Temple of Jupiter on the site of the former Jewish temple. Jews were banned from living in Jerusalem itself (a ban that persisted until the Arab conquest), and the Roman province, until then known as Iudaea Province, was renamed Palaestina, no other revolt led to a province being renamed. The names "Palestine" (in English) and "Filistin" (in Arabic) are derived from this.
From 132 to 136, the Jewish leader Simon Bar Kokhba led another major revolt against the Romans, again renaming the country "Israel" (see Bar Kokhba Revolt coinage). The Bar Kochba revolt probably caused more trouble for the Romans than the better documented revolt of 70. Christians refused to participate in the revolt and from this point the Jews regarded Christianity as a separate religion. The revolt was eventually crushed by Emperor Hadrian himself. During the Bar Kokhba revolt a rabbinical assembly decided which books could be regarded as part of the Hebrew Bible: the Jewish apocrypha and Christian books were excluded. As a result, the original text of some Hebrew texts, including the Books of Maccabees were lost (Greek translations survived).

A rabbi of this period, Simeon bar Yochai, is regarded as the author of the Zohar, the foundational text for Kabbalistic thought. However, modern scholars believe it was written in Medieval Spain.

After suppressing the Bar Kochba revolt, the Romans exiled the Jews of Judea, but not of Galilee and permitted a hereditary Rabbinical Patriarch (from the House of Hillel, based in Galilee), called the "Nasi" to represent the Jews in dealings with the Romans. The most famous of these was Judah haNasi, who is credited with compiling the final version of the Mishnah (a massive body of Jewish religious texts interpreting the Bible) and with strengthening the educational demands of Judaism by requiring that illiterate Jews be treated as outcasts. As a result, many illiterate Jews may have converted to Christianity. Jewish seminaries, such as those at Shefaram and Bet Shearim, continued to produce scholars and the best of these became members of the Sanhedrin, which was located first at Sepphoris and later at Tiberias. Before the Bar Kochba uprising, an estimated 2/3 of the population of Galilee and 1/3 of the coastal region were Jewish. In the Galillee, many synagogues have been found dating from this period. The burial site of the Sanhedrin leaders was discovered in 1936.

Early in the 4th century, the Emperor Constantine made Constantinople the capital of the East Roman Empire and made Christianity an accepted religion. His mother, Helena made a pilgrimage to Jerusalem (326–328) and led the construction of the Church of the Nativity (birthplace of Jesus in Bethlehem), the Church of the Holy Sepulchre (burial site of Jesus in Jerusalem) and other key churches that still exist. The name Jerusalem was restored to Aelia Capitolina and it became a Christian city. Jews were still banned from living in Jerusalem, but were allowed to visit and worship at the site of the ruined temple. Over the course of the next century Christians worked to eradicate "paganism", leading to the destruction of the classical Roman traditions and eradication of its temples. By the end of the 4th Century, anyone caught worshipping "pagan" gods was executed and their property confiscated.

In 351–2, another Jewish revolt in the Galilee erupted against a corrupt Roman governor. In 362, the last pagan Roman Emperor, Julian the Apostate, announced plans to rebuild the Jewish Temple. He died while fighting the Persians in 363 and the project was discontinued.

In 380 Emperor Theodosius I, the last Emperor of a united Roman Empire, made Christianity the official religion of the Roman Empire.

The Roman Empire split in 390 CE and the region became part of the (Christian) East Roman Empire, known as the Byzantine Empire. Byzantine Christianity was dominated by the (Greek) Eastern Orthodox Church whose massive land ownership has extended into the present. In the 5th century, the Western Roman Empire collapsed leading to Christian migration into the Roman province of Palaestina Prima and development of a Christian majority. Jews numbered 10–15% of the population, concentrated largely in the Galilee. Judaism was the only non-Christian religion tolerated, but restrictions on Jews slowly increased to include a ban on building new places of worship, holding public office or owning slaves. In 425, following the death of the last Nasi, Gamliel VI, the Sanhedrin was officially abolished and the title of Nasi banned. Several Samaritan Revolts erupted in this period, resulting in the decrease of Samaritan community from about a million to a near extinction. Sacred Jewish texts written in Palestine at this time are the Gemara (400), the Jerusalem Talmud (500) and the Passover Haggadah.

In 495 Mar-Zutra II (the Exilarch), set up an independent Jewish city-state in what is now Iraq. It lasted seven years and after its fall, his son Mar-Zutra III moved to Tiberias where he became head of the local religious academy in 520.

The Jewish Menorah, which the Romans took when the temple was destroyed, was reportedly taken to Carthage by the Vandals after the sacking of Rome in 455. According to the Byzantine historian, Procopius, the Byzantine army recovered it in 533 and brought it to Constantinople.

In 611, Khosrow II, ruler of Sassanid Persia invaded the Byzantine Empire. He was helped by Jewish fighters recruited by Benjamin of Tiberias and captured Jerusalem in 614. The "True Cross" was captured by the Persians. The Jewish Himyarite Kingdom in Yemen may also have provided support. Nehemiah ben Hushiel was made governor of Jerusalem. Christian historians of the period claimed the Jews massacred Christians in the city, but there is no archeological evidence of destruction, leading modern historians to question their accounts. In 628, Kavad II (son of Kosrow), returned Palestine and the True Cross to the Byzantines and signed a peace treaty with them. Following the Byzantine re-entry, Heraclius massacred the Jewish population of Gallilee and Jerusalem and renewed the ban on Jews entering Jerusalem. Benjamin of Tiberias was converted to Christianity.

According to Muslim tradition, on the last night of his life in 620, Muhammed was taken on a journey from Mecca to the "farthest mosque", whose location many consider to be the Temple Mount, returning the same night.

In about 635, an Arab army led by Muawiyah I conquered Palestine and the entire Levant, making it a province of the new Medina-based Arab Empire. The Byzantine ban on Jews living in Jerusalem came to an end and Palestine gradually came to be dominated politically and socially by Muslims, though the dominant religion of the country down to the Crusades may still have been Christian.

In 661, Muawiyah was crowned Caliph in Jerusalem, becoming the first of the (Damascus-based) Umayyad dynasty. In 691, Umayyad Caliph Abd al-Malik (685–705) constructed the Dome of the Rock shrine on the Temple Mount (where the Jewish temple had been located). A second building, the Al-Aqsa Mosque, was also erected on the Temple Mount in 705. Both buildings were rebuilt in the 10th century following a series of earthquakes.
Jews consider the Temple Mount (Muslim name Noble Sanctuary) to contain the Foundation Stone (see also Holy of Holies), which is the holiest site in Judaism. Jews believe it is the site where Abraham tried to sacrifice his son, Isaac, while Muslims believe that Abraham tried to sacrifice his son, Ishmael, in Mecca.

A new city, Ramlah, was built as the Muslim capital of Jund Filastin, (the name given to the province). In 750, Arab discrimination against Non-Arab Muslims led to the Abbasid Revolution and the Umayyads were replaced by the Abbasid Caliphs who built a new city, Baghdad, to be their capital.

During the 8th century, the Caliph Umar II introduced a law requiring Jews and Christians to wear identifying clothing: Jews were required to wear yellow stars round their neck and on their hats. Christians had to wear Blue. Clothing regulations were not always enforced, but did arise during repressive periods and were sometimes designed to humiliate and persecute non-Muslims. A poll tax was imposed on all non-Muslims by all Islamic rulers and failure to pay could result in imprisonment or worse. Non-Muslims were banned from travelling unless they could show a tax receipt. There were also bans on construction of new places of worship and repair of existing places of worship. The system of requiring Jews to wear yellow stars was subsequently adopted also in parts of Christian Europe.

In 982, Caliph Al-Aziz Billah of the Cairo-based Fatimid dynasty conquered the region. The Fatimids were followers of Isma'ilism, a branch of Shia Islam and claimed descent from Fatima, Mohammed's daughter. Around the year 1,010 the Church of Holy Sepulchre (believed to be Jesus burial site), was destroyed by Fatimid Caliph al-Hakim, who relented ten years later and paid for it to be rebuilt. In 1020 al-Hakim claimed divine status and the newly formed Druze religion gave him the status of a messiah.
Between the 7th and 11th centuries, Jewish scribes, called the Masoretes and located in Galilee and Jerusalem, established the Masoretic Text, the final text of the Hebrew Bible.

In 1099, the First Crusade took Jerusalem and established a Catholic kingdom, known as the Kingdom of Jerusalem. During the conquest, both Muslims and Jews were indiscriminately massacred or sold into slavery. Jews encountered as the Crusaders travelled across Europe were given a choice of conversion or murder, and almost always chose martyrdom. The carnage continued when the Crusaders reached the Holy Land. Ashkenazi orthodox Jews still recite a prayer in memory of the death and destruction caused by the Crusades.

Around 1180, Raynald of Châtillon, ruler of Transjordan, caused increasing conflict with the Ayyubid Sultan Saladin (Salah-al-Din), leading to the defeat of the Crusaders in the 1187 Battle of Hattin (above Tiberias). Saladin was able to peacefully take Jerusalem and conquered most of the former Kingdom of Jerusalem. Saladin's court physician was Maimonides, a refugee from Almohad (Muslim) persecution in Córdoba, Spain, where all non-Muslim religions had been banned. This was the end of the Golden age of Jewish culture in Spain and Maimonides possessed extensive knowledge of Greek and Arab medicine. His religious writings (in Hebrew and Judeo-Arabic) are still studied by Orthodox Jews. Maimonides was buried in Tiberias. A Crusader city-state at Acre survived for another century.

The Christian world's response to the loss of Jerusalem came in the Third Crusade of 1190. After lengthy battles and negotiations, Richard the Lionheart and Saladin concluded the Treaty of Jaffa in 1192 whereby Christians were granted free passage to make pilgrimages to the holy sites, while Jerusalem remained under Muslim rule. In 1229, Jerusalem peacefully reverted into Christian control as part of a treaty between Holy Roman Emperor Frederick II and Ayyubid sultan al-Kamil that ended the Sixth Crusade. In 1244, Jerusalem was sacked by the Khwarezmian Tatars who decimated the city's Christian population, drove out the Jews and razed the city. The Khwarezmians were driven out by the Ayyubids in 1247. In 1258, the Mongols destroyed Baghdad, killing hundreds of thousands. For the next 30 years, the area was the frontier between Mongol invaders (occasional Crusader allies) and the Mamluks of Egypt. The conflict impoverished the country and severely reduced the population. Sultan Qutuz of Egypt eventually defeated the Mongols in the Battle of Ain Jalut ("Goliath's spring" near Ein Harod), ending the Mongol advances, and his successors eliminated the Crusader states. The last Crusader state, the Kingdom of Acre, fell in 1291, ending the Crusades.

The Mamluks ruled Palestine until 1516, regarding it as part of Syria. In Hebron, Baibars banned Jews from worshipping at the Cave of the Patriarchs (the second-holiest site in Judaism); the ban remained in place until its conquest by Israel 700 years later. The Egyptian Mamluk sultan Al-Ashraf Khalil conquered the last outposts of Crusader rule in 1291.

The Mamluks, continuing the policy of the Ayyubids, made the strategic decision to destroy the coastal area and to bring desolation to many of its cities, from Tyre in the north to Gaza in the south. Ports were destroyed and various materials were dumped to make them inoperable. The goal was to prevent attacks from the sea, given the fear of the return of the Crusaders. This had a long-term effect on those areas, which remained sparsely populated for centuries. The activity in that time concentrated more inland.

The collapse of the Crusades was followed by increased persecution and expulsions of Jews in Europe. Expulsions began in England (1290) and were followed by France (1306). During the 14th century Jews were blamed for the Black Death in Europe and the communities of Belgium, Holland, Switzerland and Germany were massacred or expelled (Black Death Jewish persecutions). The largest massacres of Jews took place in Spain where some tens of thousands were killed and about half the Jews in the country were forcibly converted. By the end of the 14th century, significant European Jewish communities only existed in Spain, Italy and Eastern Europe.

In January 1492, the last Muslim state was defeated in Spain and six months later the Jews of Spain (the largest community in the world) were required to convert or leave without their property. 100,000 converted with many continuing to secretly practice Judaism, for which the Catholic church's inquisition (led by Torquemada) now mandated a sentence of death by public burning. 175,000 left Spain. On the day set as the last day for Jews to legally reside in Spain, Columbus sailed to America. In return for a large payment, about 100,000 Spanish Jews were allowed into Portugal, however five years later, their children were seized and they were given the choice of conversion or departing without them. Most converted but continued to practice in secret. The economic success of the converts in Spain and Portugal and suspicion of their sincerity led to laws restricting the rights of Christians of Jewish origin. Escaping Jews were often maltreated by those shipping them and refused entry to various ports around the Mediterranean by communities afraid of being swamped. Expulsions also took place in Italy, affecting survivors of the original expulsion.

Many secret Jews chose to move to the New World, where they were temporarily able to practice Judaism freely (see History of the Jews in Latin America). Other Spanish Jews moved to North Africa, Poland and the Ottoman Empire, especially Thessaloniki (now in Greece) which became the world's largest Jewish city. Some headed for Israel, which was also controlled by the Ottomans. In Italy, Jews living in Venice were required to live in a ghetto, a practice which spread to the papal states (see Cum nimis absurdum) and was adopted across Catholic Europe. Jews outside the Ghetto often had to wear a yellow star. Secretly practicing Jews could not revert to Judaism inside Europe as this carried a death sentence. The last compulsory Ghetto was administered by the Vatican in Rome and abolished in the 1880s.

In 1523, David Reubeni tried to persuade Emperor Charles V to participate in a plan to raise a Jewish army to conquer Judea and set up a Jewish kingdom, using Jewish warriors from India and Ethiopia. He managed to meet with a number of royal leaders but was eventually executed by the inquisition.

Under the Mamluks, the area was a province of Bilad a-Sham (Syria). It was conquered by Turkish Sultan Selim I in 1516–17, becoming a part of the province of Ottoman Syria for the next four centuries, first as the Damascus Eyalet and later as the Syria Vilayet (following the Tanzimat reorganization of 1864).

The Ottoman Sultans encouraged Jews fleeing the inquisition in Catholic Europe to settle in the Ottoman Empire. Suleiman the Magneficent's personal physician was Moses Hamon, an inquisition survivor. Jewish businesswomen dominated communication between the Harem and the outside world (see Esther Handali). Between 1535 and 1538 Suleiman the Magnificent (ruled 1520 – 1566) built the current city walls of Jerusalem; Jerusalem had been without walls since the early 13th century. The construction followed the historical outline of the city, but left out a key section of the City of David (today part of Silwan) and what is now known as Mount Zion.

In 1558 Selim II (1566–1574), successor to Suleiman, whose wife Nurbanu Sultan was Jewish, gave control of Tiberias to Doña Gracia Mendes Nasi, one of the richest women in Europe and an escapee from the inquisition. She encouraged Jewish refugees to settle in the area and established a Hebrew printing press. Safed became a centre for study of the Kabbalah. Doña Nasi's nephew, Joseph Nasi, was made governor of Tiberias and he encouraged Jewish settlement from Italy.

Jewish population was concentrated in Jerusalem, Hebron, Safed and Tiberias, known in Jewish tradition as the Four Holy Cities. Further migration occurred during the Khmelnytsky Uprising in Ukraine, which was accompanied by brutal massacres of tens of thousands of Jews.

In 1660, a Druze revolt led to the destruction of Safed and Tiberias. In 1663 Sabbatai Zevi settled in Jerusalem, and was proclaimed as the Jewish messiah by Nathan of Gaza. He acquired a large number of followers before going to Istanbul in 1666, where Sultan Suleiman II forced him to convert to Islam. Many of his followers converted, forming a sect that still exists in Turkey, known as the Dönmeh. In the late 18th century a local Arab "sheikh" Zahir al-Umar created a "de facto" independent Emirate in the Galilee. Ottoman attempts to subdue the Sheikh failed, but after Zahir's death the Ottomans restored their rule in the area.

In 1799 Napoleon briefly occupied the country and planned a proclamation inviting Jews to create a state. The proclamation was shelved following his defeat at Acre. In 1831, Muhammad Ali of Egypt, an Ottoman ruler who left the Empire and tried to modernize Egypt, conquered Ottoman Syria and tried to revive and resettle much of its regions. His conscription policies led to a popular Arab revolt in 1834, resulting in major casualties for the local Arab peasants, and massacres of Christian and Jewish communities by the rebels. Following the revolt, Muhammad Pasha, the son of Muhammad Ali, expelled nearly 10,000 of the local peasants to Egypt, while bringing loyal Egyptian peasants and discharged soldiers to settle the coastline of Ottoman Syria. Northern Jordan Valley was settled by his Sudanese troops.
In 1838 there was another revolt by the Druze. In 1839 Moses Montefiore met with Muhammed Pasha in Egypt and signed an agreement to establish 100–200 Jewish villages in the Damascus Eyalet of Ottoman Syria, but in 1840 the Egyptians withdrew before the deal was implemented, returning the area to Ottoman governorship. In 1844, Jews constituted the largest population group in Jerusalem. By 1896 Jews constituted an absolute majority in Jerusalem, but the overall population in Palestine was 88% Muslim and 9% Christian.

During the 19th century, Jews in Western Europe were increasingly granted citizenship and equality before the law; however, in Eastern Europe, they faced growing persecution and legal restrictions, including widespread pogroms in which thousands were murdered, raped or lost their property. Half the world's Jews lived in the Russian Empire, where they were severely persecuted and restricted to living in the Pale of Settlement. National groups in the Empire, such as the Poles, Lithuanians and Ukrainians were agitating for independence and often regarded the Jews as undesirable aliens. The Jews were usually the only non-Christian minority and spoke a distinct language (Yiddish). An independent Jewish national movement first began to emerge in the Russian Empire and the millions of Jews who were fleeing the country (mostly to United States) carried the seeds of this nationalism wherever they went.

In 1870, an agricultural school, the Mikveh Israel, was founded near Jaffa by the Alliance Israelite Universelle, a French Jewish association. In 1878, "Russian" Jewish emigrants established the village of Petah Tikva, followed by Rishon LeZion in 1882. "Russian" Jews established the Bilu and Hovevei Zion ("Lovers of Zion") movements to assist settlers and these created communities that, unlike the traditional Ashkenazi-Jewish communities, sought to be economically self-reliant. Existing Ashkenazi-Jewish communities were concentrated in the Four Holy Cities, extremely poor and relied on donations (halukka) from groups abroad. The new settlements were small agricultural communities, heavily funded by the French Baron, Edmond James de Rothschild, who sought to establish economic enterprises. In Jaffa, a vibrant commercial community developed in which Ashkenazi and Sephardi Jews inter-mingled. Many early migrants left due to difficulty finding work. Despite the difficulties, more settlements arose and the community grew.

The new migration was accompanied by a revival of the Hebrew language and attracted Jews of all kinds; religious, secular, nationalists and left-wing socialists. Socialists aimed to reclaim the land by becoming peasants or workers and forming collectives. In Zionist history, the different waves of Jewish settlement are known as "aliyah". Pogroms in the Dnieper Ukraine of the Russian Empire inspired some of the earliest ideas propagating the idea of emigration to Palestine. After pogroms broke out in 1881, as remedial measures also set new restrictions on Russian Jews, 1.98 million emigrated from the Russian Empire, 1.5 million to the United States and a small number to Palestine, both forming the prospective new centers of Jewish life, though there was strong opposition to the latter option. During the First Aliyah, between 1882 and 1903, approximately 35,000 Jews moved to Palestine. After the Ottoman conquest of the central region of their country, from 1881 onwards Yemenite Jews were enabled by new transportation facilities and greater access to knowledge of the outside world, to emigrate to Palestine, often driven by Messianism. By 1890, Jews were a majority in Jerusalem, although the country as a whole was populated mainly by Muslim and Christian Arabs.

In 1896 Theodor Herzl published "Der Judenstaat" ("The Jewish State"), in which he asserted that the solution to growing antisemitism in Europe (the so-called "Jewish Question") was to establish a Jewish state. In 1897, the Zionist Organisation was founded and the First Zionist Congress proclaimed its aim "to establish a home for the Jewish people in Palestine secured under public law." However, Zionism was regarded with suspicion by the Ottoman rulers and was unable to make major progress.

Between 1904 and 1914, around 40,000 Jews settled in the area now known as Israel (the Second Aliyah). In 1908 the Zionist Organisation set up the Palestine Bureau (also known as the "Eretz Israel Office") in Jaffa and began to adopt a systematic Jewish settlement policy. Migrants were mainly from Russia (which then included part of Poland), escaping persecution. The first Kibbutz, Degania, was founded by nine Russian socialists in 1909. In 1909 residents of Jaffa established the first entirely Hebrew-speaking city, Ahuzat Bayit (later renamed Tel Aviv). Hebrew newspapers and books were published, Hebrew schools, Jewish political parties and workers organizations were established.

During World War I, most Jews supported the Germans because they were fighting the Russians who were regarded as the Jews' main enemy. In Britain, the government sought Jewish support for the war effort for a variety of reasons including an antisemitic perception of "Jewish power" in the Ottoman Empire's Young Turks movement which was based in Thessaloniki, the most Jewish city in Europe (40% of the 160,000 population were Jewish). The British also hoped to secure American Jewish support for US intervention on Britain's behalf.

There was already sympathy for the aims of Zionism in the British government, including the Prime Minister Lloyd George. Over 14,000 Jews were expelled by the Ottoman military commander from the Jaffa area in 1914-1915, due to suspicions they were subjects of Russia, an enemy, or Zionists wishing to detach Palestine from the Ottoman Empire, and when the entire population, including Muslims, of both Jaffa and Tel Aviv was subject to an expulsion order in April 1917, the affected Jews could not return until the British conquest. Shortly after the British Army drove the Turks out of Southern Syria, and the British foreign minister, Arthur Balfour, sent a public letter to the British Lord Rothschild, a leading member of his party and leader of the Jewish community. The letter subsequently became known as the Balfour Declaration of 1917. It stated that the British Government "view[ed] with favour the establishment in Palestine of a national home for the Jewish people". The declaration provided the British government with a pretext for claiming and governing the country. New Middle Eastern boundaries were decided by an agreement between British and French bureaucrats. 

A Jewish Legion composed largely of Zionist volunteers organized by Ze'ev Jabotinsky and Joseph Trumpeldor participated in the British invasion. It also participated in the failed Gallipoli Campaign. The Nili Zionist spy network provided the British with details of Ottoman plans and troop concentrations.

After pushing out the Ottomans, Palestine came under martial law. The British, French and Arab Occupied Enemy Territory Administration governed the area shortly before the armistice with the Ottomans until the promulgation of the mandate in 1920.

The British Mandate (in effect, British rule) of Palestine, including the Balfour Declaration, was confirmed by the League of Nations in 1922 and came into effect in 1923. The territory of Transjordan was also covered by the Mandate but under separate rules that excluded it from the Balfour Declaration. Britain signed a treaty with the United States (which did not join the League of Nations) in which the United States endorsed the terms of the Mandate.

One estimate places the number of pogroms in the Ukraine between 1918 and 1919 at 1,200: figures of those murdered or maimed range upwards of 100,000. Between 1919 and 1923, another 40,000 Jews arrived in Palestine in what is known as the Third Aliyah.

Many of the Jewish immigrants of this period supported the Bolsheviks and became known as pioneers ("halutzim"), experienced or trained in agriculture who established self-sustaining communes called Kibbutzim. Malarial marshes in the Jezreel Valley and Hefer Plain were drained and converted to agricultural use. Land was bought by the Jewish National Fund, a Zionist charity that collected money abroad for that purpose. A mainly socialist underground Jewish militia, Haganah ("Defense"), was established to defend outlying Jewish settlements.
The French victory over the Arab Kingdom of Syria and the Balfour Declaration led to the emergence of Palestinian Nationalism and upheavals in the violent Nebi Musa rioting of 1920 and in Jaffa the following year. In response, to placate Arab protests, the British authorities imposed immigration quotas for Jews. Exceptions were made for Jews with over 1,000 pounds in cash (roughly 100,000 pounds at year 2000 rates) or Jewish professionals with over 500 pounds. The Jewish Agency issued the British entry permits and distributed funds donated by Jews abroad. Between 1924 and 1929, over 80,000 Jews arrived in the Fourth Aliyah, fleeing Poland and Hungary, for a variety of reasons: anti-Semitism; in protestation at the heavy tax burdens imposed on trade; and the United States Immigration Act of 1924 which severely limited immigration from Eastern and Southern Europe. The new arrivals were mainly middle-class families who moved into towns and established small businesses and workshops—although lack of economic opportunities meant that approximately a quarter later left. The first electricity generator was built in Tel Aviv in 1923 under the guidance of Pinhas Rutenberg, a former Commissar of St Petersburg in Russia's pre-Bolshevik Kerensky Government. In 1925 the Jewish Agency established the Hebrew University in Jerusalem and the Technion (technological university) in Haifa. British authorities introduced the Palestine pound (worth 1000 "mils") in 1927, replacing the Egyptian pound as the unit of currency in the Mandate.

From 1928, the democratically elected Va'ad Leumi (Jewish National Council or JNC) became the main institution of the Palestine Jewish community (Yishuv) and included non-Zionist Jews. As the Yishuv grew, the JNC adopted more government-type functions, such as education, health care and security. With British permission, the Va'ad raised its own taxes and ran independent services for the Jewish population. From 1929 its leadership was elected by Jews from 26 countries.

In 1929 tensions grew over the Kotel (Wailing Wall), the holiest spot in the world for Judaism, a narrow alleyway where the British banned Jews from using chairs or curtains: Many of the worshippers were elderly and needed seats; they also wanted to separate women from men. The Mufti claimed it was Muslim property and deliberately had cattle driven through the alley. He alleged that the Jews were seeking control of the Temple Mount. This (and general animosity) led to the August 1929 Palestine riots. The main victims were the (non-Zionist) ancient Jewish community at Hebron, who were massacred. The riots led to right-wing Zionists establishing their own militia in 1931, the Irgun Tzvai Leumi (National Military Organization, known in Hebrew by its acronym "Etzel").

Zionist political parties provided private education and health care: the General Zionists, the Mizrahi and the Socialist Zionists, each established independent health and education services and operated sports organizations funded by local taxes, donations and fees (the British administration did not invest in public services). During the whole interwar period, the British, appealing to the terms of the Mandate, rejected the principle of majority rule or any other measure that would give the Arab population, who formed the majority of the population, control over Palestinian territory.

In 1933, the Jewish Agency and the Nazis negotiated the Ha'avara Agreement (transfer agreement), under which 50,000 German Jews would be transferred to Palestine. The Jews' possessions were confiscated and in return the Nazis allowed the Ha'avara organization to purchase 14 million pounds worth of German goods for export to Palestine and use it to compensate the immigrants. Although many Jews wanted to leave Nazi Germany, the Nazis prevented Jews from taking any money and restricted them to two suitcases so few could pay the British entry tax and many were afraid to leave. The agreement was controversial and the Labour Zionist leader who negotiated the agreement, Haim Arlosoroff, was assassinated in Tel Aviv in 1933. The assassination was used by the British to create tension between the Zionist left and the Zionist right. Arlosoroff had been the boyfriend of Magda Ritschel some years before she married Joseph Goebbels. There has been speculation that he was assassinated by the Nazis to hide the connection but there is no evidence for it. In Palestine, Jewish immigration (and the Ha'avara goods) helped the economy to flourish. The British used the taxes paid by the Jewish population to build a port and oil refineries at Haifa and to fund their government in Transjordan. Industrialization began to change the predominantly agricultural Palestinian economy.

Between 1929 and 1938, 250,000 Jews arrived in Palestine (Fifth Aliyah). 174,000 arrived between 1933 and 1936, after which the British increasingly prevented immigration, mostly due to the outbreak of the 1936-1939 Arab Revolt. Migrants were mainly from Germany and included professionals, doctors, lawyers and professors. German architects of the Bauhaus school made Tel-Aviv the world's only city with purely Bauhaus neighbourhoods and Palestine had the highest per-capita percentage of doctors in the world.

Fascist regimes were emerging across Europe and persecution of Jews increased. In many countries (most notably the 1935 German Nuremberg laws), Jews reverted to being non-citizens deprived of civil and economic rights, subject to arbitrary persecution. Significantly antisemitic governments came to power in Poland (the government increasingly boycotted Jews and by 1937 had totally excluded all Jews), Hungary, Romania and the Nazi created states of Croatia and Slovakia, while Germany annexed Austria and the Czech territories.

Jewish immigration and Nazi propaganda contributed to the large-scale 1936–1939 Arab revolt in Palestine, a largely nationalist uprising directed at ending British rule. The head of the Jewish Agency, Ben-Gurion, responded to the Arab Revolt with a policy of "Havlagah"—self-restraint and a refusal to be provoked by Arab attacks in order to prevent polarization. The Etzel group broke off from the Haganah in opposition to this policy.

The British responded to the revolt with the Peel Commission (1936–37), a public inquiry that recommended that an exclusively Jewish territory be created in the Galilee and western coast (including the population transfer of 225,000 Arabs); the rest becoming an exclusively Arab area. The two main Jewish leaders, Chaim Weizmann and David Ben-Gurion, had convinced the Zionist Congress to approve equivocally the Peel recommendations as a basis for more negotiation. The plan was rejected outright by the Palestinian Arab leadership and they renewed the revolt, which caused the British to appease the Arabs, and to abandon the plan as unworkable.

Testifying before the Peel Commission, Weizmann said "There are in Europe 6,000,000 people ... for whom the world is divided into places where they cannot live and places where they cannot enter." In 1938, the US called an international conference to address the question of the vast numbers of Jews trying to escape Europe. Britain made its attendance contingent on Palestine being kept out of the discussion. No Jewish representatives were invited. The Nazis proposed their own solution: that the Jews of Europe be shipped to Madagascar (the Madagascar Plan). The agreement proved fruitless, and the Jews were stuck in Europe.

With millions of Jews trying to leave Europe and every country in the world closed to Jewish migration, the British decided to close Palestine. The White Paper of 1939, recommended that an independent Palestine, governed jointly by Arabs and Jews, be established within 10 years. The White Paper agreed to allow 75,000 Jewish immigrants into Palestine over the period 1940–44, after which migration would require Arab approval. Both the Arab and Jewish leadership rejected the White Paper. In March 1940 the British High Commissioner for Palestine issued an edict banning Jews from purchasing land in 95% of Palestine. Jews now resorted to illegal immigration: (Aliyah Bet or "Ha'apalah"), often organized by the Mossad Le'aliyah Bet and the Irgun. With no outside help and no countries ready to admit them, very few Jews managed to escape Europe between 1939 and 1945. Those caught by the British were mostly imprisoned in Mauritius.

During the Second World War, the Jewish Agency worked to establish a Jewish army that would fight alongside the British forces. Churchill supported the plan but British Military and government opposition led to its rejection. The British demanded that the number of Jewish recruits match the number of Arab recruits, but few Arabs would fight for Britain, and the Palestinian leader, the Mufti of Jerusalem, allied with Nazi Germany.

In June 1940, Italy declared war on the British Commonwealth and sided with Germany. Within a month, Italian planes bombed Tel Aviv and Haifa, inflicting multiple casualties. In May 1941, the Palmach was established to defend the Yishuv against the planned Axis invasion through North Africa. The British refusal to provide arms to the Jews, even when Rommel's forces were advancing through Egypt in June 1942 (intent on occupying Palestine) and the 1939 White Paper, led to the emergence of a Zionist leadership in Palestine that believed conflict with Britain was inevitable. Despite this, the Jewish Agency called on Palestine's Jewish youth to volunteer for the British Army (both men and women). 30,000 Palestinian Jews and 12,000 Palestinian Arabs enlisted in the British armed forces during the war. In June 1944 the British agreed to create a Jewish Brigade that would fight in Italy.

Approximately 1.5 million Jews around the world served in every branch of the allied armies, mainly in the Soviet and US armies. 200,000 Jews died serving in the Soviet army alone. Many of these war veterans later volunteered to fight for Israel or were active in its support.

A small group (about 200 activists), dedicated to resisting the British administration in Palestine, broke away from the Etzel (which advocated support for Britain during the war) and formed the "Lehi" (Stern Gang), led by Avraham Stern. In 1943, the USSR released the Revisionist Zionist leader Menachem Begin from the Gulag and he went to Palestine, taking command of the Etzel organization with a policy of increased conflict against the British. At about the same time Yitzhak Shamir escaped from the camp in Eritrea where the British were holding Lehi activists without trial, taking command of the Lehi (Stern Gang).

Jews in the Middle East were also affected by the war. Most of North Africa came under Nazi control and many Jews were used as slaves. The 1941 pro-Axis coup in Iraq was accompanied by massacres of Jews. The Jewish Agency put together plans for a last stand in the event of Rommel invading Palestine (the Nazis planned to exterminate Palestine's Jews).

Between 1939 and 1945, the Nazis, aided by local forces, led systematic efforts to kill every person of Jewish extraction in Europe (The Holocaust), causing the deaths of approximately 6 million Jews. A quarter of those killed were children. The Polish and German Jewish communities, which played an important role in defining the pre-1945 Jewish world, mostly ceased to exist. In the United States and Palestine, Jews of European origin became disconnected from their families and roots. As the Holocaust mainly affected Ashkenazi Jews, Sepharadi and Mizrahi Jews, who had been a minority, became a much more significant factor in the Jewish world. Those Jews who survived in central Europe, were displaced persons (refugees); an Anglo-American Committee of Inquiry, established to examine the Palestine issue, surveyed their ambitions and found that over 95% wanted to migrate to Palestine.

In the Zionist movement the moderate Pro-British (and British citizen) Weizmann, whose son died flying in the RAF, was undermined by Britain's anti-Zionist policies. Leadership of the movement passed to the Jewish Agency in Palestine, now led by the anti-British Socialist-Zionist party (Mapai) led by David Ben-Gurion. In the diaspora, US Jews now dominated the Zionist movement.

The British Empire was severely weakened by the war. In the Middle East, the war had made Britain conscious of its dependence on Arab oil. British firms controlled Iraqi oil and Britain ruled Kuwait, Bahrain and the Emirates. Shortly after VE Day, the Labour Party won the general election in Britain. Although Labour Party conferences had for years called for the establishment of a Jewish state in Palestine, the Labour government now decided to maintain the 1939 White Paper policies.
Illegal migration (Aliyah Bet) became the main form of Jewish entry into Palestine. Across Europe Bricha ("flight"), an organization of former partisans and ghetto fighters, smuggled Holocaust survivors from Eastern Europe to Mediterranean ports, where small boats tried to breach the British blockade of Palestine. Meanwhile, Jews from Arab countries began moving into Palestine overland. Despite British efforts to curb immigration, during the 14 years of the Aliyah Bet, over 110,000 Jews entered Palestine. By the end of World War II, the Jewish population of Palestine had increased to 33% of the total population.

In an effort to win independence, Zionists now waged a guerrilla war against the British. The main underground Jewish militia, the Haganah, formed an alliance called the Jewish Resistance Movement with the Etzel and Stern Gang to fight the British. This alliance was dissolved after the King David bombings. In June 1946, following instances of Jewish sabotage, the British launched Operation Agatha, arresting 2,700 Jews, including the leadership of the Jewish Agency, whose headquarters were raided. Those arrested were held without trial.

On 4 July 1946 a massive pogrom in Poland led to a wave of Holocaust survivors fleeing Europe for Palestine. Three weeks later, Irgun bombed the British Military Headquarters of the King David Hotel in Jerusalem, killing 91 people. In the days following the bombing, Tel Aviv was placed under curfew and over 120,000 Jews, nearly 20% of the Jewish population of Palestine, were questioned by the police. In the US, Congress criticized British handling of the situation and considered delaying loans that were vital to British post-war recovery.

Between 1945 and 1948, 100,000–120,000 Jews left Poland. Their departure was largely organized by Zionist activists in Poland under the umbrella of the semi-clandestine organization "Berihah" ("Flight"). "Berihah" was also responsible for the organized emigration of Jews from Romania, Hungary, Czechoslovakia and Yugoslavia, totalling 250,000 (including Poland) Holocaust survivors. The British imprisoned the Jews trying to enter Palestine in the Atlit detainee camp and Cyprus internment camps. Those held were mainly Holocaust survivors, including large numbers of children and orphans. In response to Cypriot fears that the Jews would never leave (since they lacked a state or documentation) and because the 75,000 quota established by the 1939 White Paper had never been filled, the British allowed the refugees to enter Palestine at a rate of 750 per month.

By 1947 the Labour Government was ready to refer the Palestine problem to the newly created United Nations.

On 2 April 1947, the United Kingdom requested that the question of Palestine be handled by the General Assembly. The General Assembly created a committee, United Nations Special Committee on Palestine (UNSCOP), to report on "the question of Palestine". In July 1947 the UNSCOP visited Palestine and met with Jewish and Zionist delegations. The Arab Higher Committee boycotted the meetings. During the visit the British Foreign Secretary Ernest Bevin ordered an illegal immigrant ship, the "Exodus 1947", to be sent back to Europe. The Holocaust surviving migrants on the ship were forcibly removed by British troops at Hamburg, Germany.

The principal non-Zionist Orthodox Jewish (or Haredi) party, Agudat Israel, recommended to UNSCOP that a Jewish state be set up after reaching a religious status quo agreement with Ben-Gurion regarding the future Jewish state. The agreement granted an exemption from military service to a quota of yeshiva (religious seminary) students and to all orthodox women, made the Sabbath the national weekend, guaranteed Kosher food in government institutions and allowed Orthodox Jews to maintain a separate education system.

The majority report of UNSCOP proposed "an independent Arab State, an independent Jewish State, and the City of Jerusalem", the last to be under "an International Trusteeship System". On 29 November 1947, in Resolution 181 (II), the General Assembly adopted the majority report of UNSCOP, but with slight modifications. The Plan also called for the British to allow "substantial" Jewish migration by 1 February 1948.

Neither Britain nor the UN Security Council took any action to implement the recommendation made by the resolution and Britain continued detaining Jews attempting to enter Palestine. Concerned that partition would severely damage Anglo-Arab relations, Britain denied UN representatives access to Palestine during the period between the adoption of Resolution 181 (II) and the termination of the British Mandate. The British withdrawal was finally completed in May 1948. However, Britain continued to hold (formerly illegal) Jewish immigrants of "fighting age" and their families on Cyprus until March 1949.

The General Assembly's vote caused joy in the Jewish community and discontent among the Arab community. Violence broke out between the sides, escalating into civil war. From January 1948, operations became increasingly militarized, with the intervention of a number of Arab Liberation Army regiments inside Palestine, each active in a variety of distinct sectors around the different coastal towns. They consolidated their presence in Galilee and Samaria. Abd al-Qadir al-Husayni came from Egypt with several hundred men of the Army of the Holy War. Having recruited a few thousand volunteers, he organized the blockade of the 100,000 Jewish residents of Jerusalem. The Yishuv tried to supply the city using convoys of up to 100 armoured vehicles, but largely failed. By March, almost all Haganah's armoured vehicles had been destroyed, the blockade was in full operation, and hundreds of Haganah members who had tried to bring supplies into the city were killed.

Up to 100,000 Arabs, from the urban upper and middle classes in Haifa, Jaffa and Jerusalem, or Jewish-dominated areas, evacuated abroad or to Arab centres eastwards. This situation caused the US to withdraw their support for the Partition plan, thus encouraging the Arab League to believe that the Palestinian Arabs, reinforced by the Arab Liberation Army, could put an end to the plan for partition. The British, on the other hand, decided on 7 February 1948 to support the annexation of the Arab part of Palestine by Transjordan. The Jordanian army was commanded by the British.
David Ben-Gurion reorganized Haganah and made conscription obligatory. Every Jewish man and woman in the country had to receive military training. Thanks to funds raised by Golda Meir from sympathisers in the United States, and Stalin's decision to support the Zionist cause, the Jewish representatives of Palestine were able to purchase important arms in Eastern Europe.

Ben-Gurion gave Yigael Yadin the responsibility to plan for the announced intervention of the Arab states. The result of his analysis was Plan Dalet, in which Haganah passed from the defensive to the offensive. The plan sought to establish Jewish territorial continuity by conquering mixed zones. Tiberias, Haifa, Safed, Beisan, Jaffa and Acre fell, resulting in the flight of more than 250,000 Palestinian Arabs. The situation was one of the catalysts for the intervention of neighbouring Arab states.

On 14 May 1948, on the day the last British forces left from Haifa, the Jewish People's Council gathered at the Tel Aviv Museum and proclaimed the establishment of a Jewish state in Eretz Israel, to be known as the State of Israel.

Immediately following the declaration of the new state, both superpower leaders, US President Harry S. Truman and Soviet leader Joseph Stalin, recognized the new state.
The Arab League members Egypt, Transjordan, Syria, Lebanon and Iraq refused to accept the UN partition plan and proclaimed the right of self-determination for the Arabs across the whole of Palestine. The Arab states marched their forces into what had, until the previous day, been the British Mandate for Palestine, starting the first Arab–Israeli War. The Arab states had heavy military equipment at their disposal and were initially on the offensive (the Jewish forces were not a state before 15 May and could not buy heavy arms). On 29 May 1948, the British initiated United Nations Security Council Resolution 50 declaring an arms embargo on the region. Czechoslovakia violated the resolution, supplying the Jewish state with critical military hardware to match the (mainly British) heavy equipment and planes already owned by the invading Arab states. On 11 June, a month-long UN truce was put into effect.

Following independence, the Haganah became the Israel Defense Forces (IDF). The Palmach, Etzel and Lehi were required to cease independent operations and join the IDF. During the ceasefire, Etzel attempted to bring in a private arms shipment aboard a ship called "Altalena". When they refused to hand the arms to the government, Ben-Gurion ordered that the ship be sunk. Several Etzel members were killed in the fighting.

Large numbers of Jewish immigrants, many of them World War II veterans and Holocaust survivors, now began arriving in the new state of Israel, and many joined the IDF.

After an initial loss of territory by the Jewish state and its occupation by the Arab armies, from July the tide gradually turned in the Israelis' favour and they pushed the Arab armies out and conquered some of the territory that had been included in the proposed Arab state. At the end of November, tenuous local ceasefires were arranged between the Israelis, Syrians and Lebanese. On 1 December King Abdullah announced the union of Transjordan with Arab Palestine west of the Jordan; only Britain recognized the annexation.

Israel signed armistices with Egypt (24 February), Lebanon (23 March), Jordan (3 April) and Syria (20 July). No actual peace agreements were signed. With permanent ceasefire coming into effect, Israel's new borders, later known as the Green Line, were established. These borders were not recognized by the Arab states as international boundaries. Israel was in control of the Galilee, Jezreel Valley, West Jerusalem, the coastal plain and the Negev. The Syrians remained in control of a strip of territory along the Sea of Galilee originally allocated to the Jewish state, the Lebanese occupied a tiny area at Rosh Hanikra, and the Egyptians retained the Gaza strip and still had some forces surrounded inside Israeli territory. Jordanian forces remained in the West Bank, where the British had stationed them before the war. Jordan annexed the areas it occupied while Egypt kept Gaza as an occupied zone.

Following the ceasefire declaration, Britain released over 2,000 Jewish detainees it was still holding in Cyprus and recognized the state of Israel. On 11 May 1949, Israel was admitted as a member of the United Nations. Out of an Israeli population of 650,000, some 6,000 men and women were killed in the fighting, including 4,000 soldiers in the IDF (approximately 1% of the population). According to United Nations figures, 726,000 Palestinians had fled or were expelled by the Israelis between 1947 and 1949. Except in Jordan, the Palestinian refugees were settled in large refugee camps in poor, overcrowded conditions and denied citizenship by their host countries. In December 1949, the UN (in response to a British proposal) established an agency (UNRWA) to provide aid to the Palestinian refugees. It became the largest single UN agency and is the only UN agency that serves a single people.

A 120-seat parliament, the Knesset, met first in Tel Aviv then moved to Jerusalem after the 1949 ceasefire. In January 1949, Israel held its first elections. The Socialist-Zionist parties Mapai and Mapam won the most seats (46 and 19 respectively). Mapai's leader, David Ben-Gurion, was appointed Prime Minister, he formed a coalition which did not include Mapam who were Stalinist and loyal to the USSR (another Stalinist party, non-Zionist Maki won 4 seats). This was a significant decision, as it signaled that Israel would be in the Soviet bloc. The Knesset elected Chaim Weizmann as the first (largely ceremonial) President of Israel. Hebrew and Arabic were made the official languages of the new state. All governments have been coalitions—no party has ever won a majority in the Knesset. From 1948 until 1977 all governments were led by Mapai and the Alignment, predecessors of the Labour Party. In those years Labour Zionists, initially led by David Ben-Gurion, dominated Israeli politics and the economy was run on primarily socialist lines.

Within three years (1948 to 1951), immigration doubled the Jewish population of Israel and left an indelible imprint on Israeli society. Overall, 700,000 Jews settled in Israel during this period. Some 300,000 arrived from Asian and North African nations as part of the Jewish exodus from Arab and Muslim countries. Among them, the largest group (over 100,000) was from Iraq. The rest of the immigrants were from Europe, including more than 270,000 who came from Eastern Europe, mainly Romania and Poland (over 100,000 each). Nearly all the Jewish immigrants could be described as refugees, however only 136,000 who immigrated to Israel from Central Europe, had international certification because they belonged to the 250,000 Jews registered by the allies as displaced after World War II and living in displaced persons camps in Germany, Austria and Italy.

In 1950 the Knesset passed the Law of Return, which granted to all Jews and those of Jewish ancestry (Jewish grandparent), and their spouses, the right to settle in Israel and gain citizenship. That year, 50,000 Yemenite Jews (99%) were secretly flown to Israel. In 1951 Iraqi Jews were granted temporary permission to leave the country and 120,000 (over 90%) opted to move to Israel. Jews also fled from Lebanon, Syria and Egypt. By the late sixties, about 500,000 Jews had left Algeria, Morocco and Tunisia. Over the course of twenty years, some 850,000 Jews from Arab countries (99%) relocated to Israel (680,000), France and the Americas. The land and property left behind by the Jews (much of it in Arab city centres) is still a matter of some dispute. Today there are about 9,000 Jews living in Arab states, of whom 75% live in Morocco and 15% in Tunisia. Vast assets, approximately $150 billion worth of goods and property (before inflation) were left behind in these countries.
Between 1948 and 1958, the population of Israel rose from 800,000 to two million. During this period, food, clothes and furniture had to be rationed in what became known as the Austerity Period ("Tkufat haTsena"). Immigrants were mostly refugees with no money or possessions and many were housed in temporary camps known as ma'abarot. By 1952, over 200,000 immigrants were living in tents or prefabricated shacks built by the government. Israel received financial aid from private donations from outside the country (mainly the United States). The pressure on the new state's finances led Ben-Gurion to sign a controversial reparations agreement with West Germany. During the Knesset debate some 5,000 demonstrators gathered and riot police had to cordon the building. Israel received several billion marks and in return agreed to open diplomatic relations with Germany.

At the end of 1953, Ben-Gurion retired to Kibbutz Sde Boker in the Negev.

In 1949, education was made free and compulsory for all citizens until the age of 14. The state now funded the party-affiliated Zionist education system and a new body created by the Haredi Agudat Israel party. A separate body was created to provide education for the remaining Palestinian-Arab population. The major political parties now competed for immigrants to join their education systems. The government banned the existing educational bodies from the transit camps and tried to mandate a unitary secular socialist education under the control of "camp managers" who also had to provide work, food and housing for the immigrants. There were attempts to force orthodox Yemenite children to adopt a secular life style by teachers, including many instances of Yemenite children having their side-curls cut by teachers. The Yemenite children affair led to the first Israeli public inquiry (the Fromkin Inquiry), the collapse of the coalition, and an election in 1951, with little change in the results. In 1953 the party-affiliated education system was scrapped and replaced by a secular state education system and a state-run Modern Orthodox system. Agudat Israel were allowed to maintain their existing school system.

In its early years Israel sought to maintain a non-aligned position between the super-powers. However, in 1952, an antisemitic public trial was staged in Moscow in which a group of Jewish doctors were accused of trying to poison Stalin (the Doctors' plot), followed by a similar trial in Czechoslovakia (Slánský trial). This, and the failure of Israel to be included in the Bandung Conference (of non-aligned states), effectively ended Israel's pursuit of non-alignment. On 19 May 1950, in contravention of international law, Egypt announced that the Suez Canal was closed to Israeli ships and commerce. In 1952 a military coup in Egypt brought Abdel Nasser to power. The United States pursued close relations with the new Arab states, particularly the Nasser-led Egyptian Free Officers Movement and Ibn Saud of Saudi Arabia. Israel's solution to diplomatic isolation was to establish good relations with newly independent states in Africa and with France, which was engaged in the Algerian War.

In the January 1955 elections Mapai won 40 seats and the Labour Party 10, Moshe Sharett became prime minister of Israel at the head of a left-wing coalition. Between 1953 and 1956, there were intermittent clashes along all of Israel's borders as Arab terrorism and breaches of the ceasefire resulting in Israeli counter-raids. Palestinian fedayeen attacks, often organized and sponsored by the Egyptians, were made from (Egyptian) occupied Gaza. Fedayeen attacks led to a growing cycle of violence as Israel launched reprisal attacks against Gaza. In 1954 the Uzi submachine gun first entered use by the Israel Defense Forces. In 1955 the Egyptian government began recruiting former Nazi rocket scientists for a missile program.

Archaeologist and General Yigael Yadin purchased the Dead Sea Scrolls on behalf of the State of Israel. The entire first batch to be discovered were now owned by Israel and housed in the Shrine of the Book at the Israel Museum.

Sharett's government was brought down by the Lavon Affair, a crude plan to disrupt US–Egyptian relations, involving Israeli agents planting bombs at American sites in Egypt. The plan failed when eleven agents were arrested. Defense Minister Lavon was blamed despite his denial of responsibility. The Lavon affair led to Sharett's resignation and Ben-Gurion returned to the post of prime minister.

In 1955 Egypt concluded a massive arms deal with Czechoslovakia, upsetting the balance of power in the Middle East. In 1956, the increasingly pro-Soviet President Nasser of Egypt, announced the nationalization of the (French and British owned) Suez Canal, which was Egypt's main source of foreign currency. Egypt also blockaded the Gulf of Aqaba preventing Israeli access to the Red Sea. Israel made a secret agreement with the French at Sèvres to co-ordinate military operations against Egypt. Britain and France had already begun secret preparations for military action. It has been alleged that the French also agreed to build a nuclear plant for the Israelis and that by 1968 this was able to produce nuclear weapons. Britain and France arranged for Israel to give them a pretext for seizing the Suez Canal. Israel was to attack Egypt, and Britain and France would then call on both sides to withdraw. When, as expected, the Egyptians refused, Anglo-French forces would invade to take control of the Canal.
Israeli forces, commanded by General Moshe Dayan, attacked Egypt on 29 October 1956. On 30 October Britain and France made their pre-arranged call for both sides to stop fighting and withdraw from the Canal area, and for them to be allowed to take up positions at key points on the Canal. Egypt refused and the allies commenced air strikes on 31 October aimed at neutralizing the Egyptian air force. By 5 November the Israelis had overrun the Sinai. The Anglo-French invasion began that day. There was uproar in the UN, with the United States and USSR for once in agreement in denouncing the actions of Israel, Britain and France. A demand for a ceasefire was reluctantly accepted on 7 November.

At Egypt's request, the UN sent an Emergency Force (UNEF), consisting of 6,000 peacekeeping troops from 10 nations to supervise the ceasefire. This was the first ever UN peacekeeping operation. From 15 November the UN troops marked out a zone across the Sinai to separate the Israeli and Egyptian forces. Upon receiving US guarantees of Israeli access to the Suez Canal, freedom of access out of the Gulf of Aqaba and Egyptian action to stop Palestinian raids from Gaza, the Israelis withdrew to the Negev. In practice the Suez Canal remained closed to Israeli shipping. The conflict marked the end of West-European dominance in the Middle East.

Nasser emerged as the victor in the conflict, having won the political battle, however the Israeli military learnt that it did not need British or French support in order to conquer Sinai and that it could conquer the Sinai peninsula in a few days. The Israeli political leadership learnt that Israel had a limited time frame within which to operate militarily after which international political pressure would restrict Israel's freedom of action.

In 1956, two modern-orthodox (and religious-zionist) parties, Mizrachi and Hapoel HaMizrachi, joined to form the National Religious Party. The party was a component of every Israeli coalition until 1992, usually running the Ministry of Education. Mapai was once again victorious in the 1959 elections, increasing its number of seats to 47, Labour had 7. Ben-Gurion remained Prime Minister.

In 1959, there were renewed skirmishes along Israel's borders that continued throughout the early 1960s. The Arab League continued to widener its economic boycott and there was a dispute over water rights in the River Jordan basin. With Soviet backing, the Arab states, particularly Egypt, were continuing to build up their forces. Israel's main military hardware supplier was France.
Rudolph Kastner, a minor political functionary, was accused of collaborating with the Nazis and sued his accuser. Kastner lost the trial and was assassinated two years later. In 1958 the Supreme Court exonerated him. In May 1960 Adolf Eichmann, one of the chief administrators of the Nazi Holocaust, was located in Argentina by the Mossad, later kidnapping him and bringing him to Israel. In 1961 he was put on trial, and after several months found guilty and sentenced to death. He was hanged in 1962 and is the only person ever sentenced to death by an Israeli court. Testimonies by Holocaust survivors at the trial and the extensive publicity that surrounded it has led the trial to be considered a turning point in public awareness of the Holocaust.

In 1961 a Herut no-confidence motion over the resurfaces Lavon affair led to Ben-Gurion's resignation. Ben-Gurion declared that he would only accept office if Lavon was fired from the position of the head of Histadrut, Israel's labour union organization. His demands were accepted and Mapai won the 1961 election (42 seats keeping Ben-Gurion as PM) with a slight reduction in its share of the seats. Menachem Begin's Herut party and the Liberals came next with 17 seats each. In 1962 the Mossad began assassinating German rocket scientists working in Egypt after one of them reported the missile program was designed to carry chemical warheads. This action was condemned by Ben-Gurion and led to the Mossad director, Isser Harel, resignation. In 1963 Ben-Gurion quit again over the Lavon affair. His attempts to make his party Mapai support him over the issue failed. Levi Eshkol became leader of Mapai and the new prime minister.

In 1963 Yigael Yadin began excavating Masada. In 1964, Egypt, Jordan and Syria developed a unified military command. Israel completed work on a national water carrier, a huge engineering project designed to transfer Israel's allocation of the Jordan river's waters towards the south of the country in realization of Ben-Gurion's dream of mass Jewish settlement of the Negev desert. The Arabs responded by trying to divert the headwaters of the Jordan, leading to growing conflict between Israel and Syria.

In 1964, Israeli Rabbinical authorities accepted that the Bene Israel of India were indeed Jewish and most of the remaining Indian Jews migrated to Israel. The 2,000-strong Jewish community of Cochin had already migrated in 1954. Ben-Gurion quit Mapai to form the new party Rafi, he was joined by Shimon Peres and Moshe Dayan. Begin's Herut party joined with the Liberals to form Gahal. Mapai and Labour united for the 1965 elections, winning 45 seats and maintaining Levi Eshkol as Prime Minister. Ben-Gurion's Rafi party received 10 seats, Gahal got 26 seats becoming the second largest party.

Until 1966, Israel's principal arms supplier was France, however in 1966, following the withdrawal from Algeria, Charles de Gaulle announced France would cease supplying Israel with arms (and refused to refund money paid for 50 warplanes). On 5 February 1966, the United States announced that it was taking over the former French and West German obligations, to maintain military "stabilization" in the Middle East. Included in the military hardware would be over 200 M48 tanks. In May of that year the US also agreed to provide A-4 Skyhawk tactical aircraft to Israel. In 1966 security restrictions placed on Arab-Israelis were eased and efforts made to integrate them into Israeli life.

In 1966, Black and white TV broadcasts began. On 15 May 1967, the first public performance of Naomi Shemer's classic song "Jerusalem of Gold" took place and over the next few weeks it dominated the Israeli airwaves. Two days later Syria, Egypt and Jordan amassed troops along the Israeli borders, and Egypt closed the Straits of Tiran to Israeli shipping. Nasser demanded that the UNEF leave Sinai, threatening escalation to a full war. Egyptian radio broadcasts talked of a coming genocide. On 26 May Nasser declared, ""The battle will be a general one and our basic objective will be to destroy Israel"". Israel considered the Straits of Tiran closure a Casus belli. Egypt, Syria, Jordan and Iraq signed defence pacts and Iraqi troops began deploying to Jordan, Syria and Egypt. Algeria also announced that it would send troops to Egypt. Between 1963 and 1967 Egyptian troops had tested chemical weapons on Yemenite civilians as part of an Egyptian intervention in support of rebels.

Israel responded by calling up its civilian reserves, bringing much of the Israeli economy to a halt. The Israelis set up a national unity coalition, including for the first time Menachem Begin's party, Herut, in a coalition. During a national radio broadcast, Prime Minister Levi Eshkol stammered, causing widespread fear in Israel. To calm public concern Moshe Dayan (Chief of Staff during the Sinai war) was appointed Defence Minister.
On the morning before Dayan was sworn in, 5 June 1967, the Israeli air force launched pre-emptive attacks destroying first the Egyptian air force, and then later the same day destroying the air forces of Jordan and Syria. Israel then defeated (almost successively) Egypt, Jordan and Syria. By 11 June the Arab forces were routed and all parties had accepted the cease-fire called for by UN Security Council Resolutions 235 and 236. Israel gained control of the Sinai Peninsula, the Gaza Strip, the Golan Heights, and the formerly Jordanian-controlled West Bank of the Jordan River. East Jerusalem was arguably annexed by Israel. Residents were given permanent residency status and the option of applying for Israeli citizenship. The annexation was not recognized internationally (the Jordanian annexation of 1950 was also unrecognized except for the UK, Iraq, and Pakistan).

Other areas occupied remained under military rule (Israeli civil law did not apply to them) pending a final settlement. The Golan was also annexed in 1981. On 22 November 1967, the Security Council adopted Resolution 242, the "land for peace" formula, which called for the establishment of a just and lasting peace based on Israeli withdrawal from territories occupied in 1967 in return for the end of all states of belligerency, respect for the sovereignty of all states in the area, and the right to live in peace within secure, recognized boundaries. The resolution was accepted by both sides, though with different interpretations, and has been the basis of all subsequent peace negotiations. After 1967 the US began supplying Israel with aircraft and the Soviet block (except Romania) broke off relations with Israel. Antisemitic purges encouraged the remnants of Polish Jewry to move to Israel.

For the first time since the end of the British Mandate, Jews could visit the Old City of Jerusalem and pray at the Western Wall (the holiest site in Judaism), to which they had been denied access by the Jordanians in contravention of the 1949 Armistice agreement. The four-meter-wide public alley beside the Wall was expanded into a massive plaza and worshippers were allowed to sit, or use other furniture, for the first time in centuries. In Hebron, Jews gained access to the Cave of the Patriarchs (the second most holy site in Judaism) for the first time since the 14th century (previously Jews were only allowed to pray at the entrance). A third Jewish holy site, Rachel's Tomb, in Bethlehem, also became accessible. The Sinai oil fields made Israel self-sufficient in energy.

In 1968 Moshe Levinger led a group of Religious Zionists who created the first Jewish settlement, a town near Hebron called Kiryat Arba. There were no other religious settlements until after 1974. Ben-Gurion's Rafi party merged with the Labour-Mapai alliance. Ben-Gurion remained outside as an independent. In 1968, compulsory education was extended until the age of 16 for all citizens (it had been 14) and the government embarked on an extensive program of integration in education. In the major cities children from mainly Sephardi/Mizrahi neighbourhoods were bused to newly established middle schools in better areas. The system remained in place until after 2000.

In March 1968, Israeli forces attacked the Palestinian militia, Fatah, at its base in the Jordanian town of Karameh. The attack was in response to land mines placed on Israeli roads. The Israelis retreated after destroying the camp, however the Israelis sustained unexpectedly high casualties and the attack was not viewed as a success. Despite heavy casualties, the Palestinians claimed victory, while Fatah and the PLO (of which it formed part) became famous across the Arab world. In early 1969, fighting broke out between Egypt and Israel along the Suez Canal. In retaliation for repeated Egyptian shelling of Israeli positions along the Suez Canal, Israeli planes made deep strikes into Egypt in the 1969–1970 "War of Attrition".

In early 1969, Levi Eshkol died in office of a heart attack and Golda Meir became Prime Minister with the largest percentage of the vote ever won by an Israeli party, winning 56 of the 120 seats after the 1969 election. Meir was the first female prime minister of Israel and the first woman to have headed a Middle Eastern state in modern times. Gahal retained its 26 seats, and was the second largest party.
In December 1969, Israeli naval commandos took five missile boats during the night from Cherbourg Harbour in France. Israel had paid for the boats but the French had refused to supply them. In July 1970 the Israelis shot down five Soviet fighters that were aiding the Egyptians in the course of the War of Attrition. Following this, the US worked to calm the situation and in August 1970 a cease fire was agreed.

In September 1970 King Hussein of Jordan drove the Palestine Liberation Organization out of his country. On 18 September 1970, Syrian tanks invaded Jordan, intending to aid the PLO. At the request of the US, Israel moved troops to the border and threatened Syria, causing the Syrians to withdraw. The centre of PLO activity then shifted to Lebanon, where the 1969 Cairo agreement gave the Palestinians autonomy within the south of the country. The area controlled by the PLO became known by the international press and locals as "Fatahland" and contributed to the 1975–1990 Lebanese Civil War. The event also led to Hafez al-Assad taking power in Syria. Egyptian President Nasser died of a heart attack immediately after and was succeeded by Anwar Sadat.

Increased Soviet antisemitism and enthusiasm generated by the 1967 victory led to a wave of Soviet Jews applying to emigrate to Israel. Those who left could only take two suitcases. Most Jews were refused exit visas and persecuted by the authorities. Some were arrested and sent to Gulag camps, becoming known as Prisoners of Zion. During 1971, violent demonstrations by the Israeli Black Panthers, made the Israeli public aware of resentment among Mizrahi Jews at ongoing discrimination and social gaps. In 1972 the US Jewish Mafia leader, Meyer Lansky, who had taken refuge in Israel, was deported to the United States.

At the 1972 Munich Olympics, two members of the Israeli team were killed, and nine members taken hostage by Palestinian terrorists. A botched German rescue attempt led to the death of the rest along with five of the eight hijackers. The three surviving Palestinians were released by the West German authorities eight weeks later without charge, in exchange for the hostages of hijacked Lufthansa Flight 615. The Israeli government responded with an air raid, a raid on the PLO headquarters in Lebanon (led by future Prime Minister, Ehud Barak) and an assassination campaign against the organizers of the massacre. 

In 1972 the new Egyptian President Anwar Sadat expelled the Soviet advisers from Egypt. This and frequent invasion exercises by Egypt and Syria led to Israeli complacency about the threat from these countries. In addition the desire not to be held responsible for initiating conflict and an election campaign highlighting security, led to an Israeli failure to mobilize, despite receiving warnings of an impending attack.
The Yom Kippur War (also known as the October War) began on 6 October 1973 (the Jewish Day of Atonement), the holiest day in the Jewish calendar and a day when adult Jews are required to fast. The Syrian and Egyptian armies launched a well-planned surprise attack against the unprepared Israeli Defense Forces. For the first few days there was a great deal of uncertainty about Israel's capacity to repel the invaders. Both the Soviets and the Americans (at the orders of Henry Kissinger) rushed arms to their allies. The Syrians were repulsed by the tiny remnant of the Israeli tank force on the Golan and, although the Egyptians captured a strip of territory in Sinai, Israeli forces crossed the Suez Canal, trapping the Egyptian Third Army in Sinai and were 100 kilometres from Cairo. The war cost Israel over 2,000 dead, resulted in a heavy arms bill (for both sides) and made Israelis more aware of their vulnerability. It also led to heightened superpower tension. Following the war, both Israelis and Egyptians showed greater willingness to negotiate. On 18 January 1974, extensive diplomacy by US Secretary of State Henry Kissinger led to a Disengagement of Forces agreement with the Egyptian government and on 31 May with the Syrian government.

The war was the catalyst for the 1973 oil crisis, a Saudi-led oil embargo in conjunction with OPEC against countries trading with Israel. Severe shortages led to massive increases in the price of oil, and as a result, many countries broke off relations with Israel or downgraded relations, and Israel was banned from participation in the Asian Games and other Asian sporting events.

State funding was introduced for elected parties. The new system made parties independent of wealthy donors and gave Knesset members more power over party funding, however it also made them less dependent on existing party structures and able to take their funding elsewhere. Prior to the December 1973 elections, Gahal and a number of right-wing parties united to form the Likud (led by Begin). In the December 1973 elections, Labour won 51 seats, leaving Golda Meir as Prime Minister. The Likud won 39 seats.

In May 1974, Palestinians attacked a school in Ma'alot, holding 102 children hostage. Twenty-two children were killed. In November 1974 the PLO was granted observer status at the UN and Yasser Arafat addressed the General Assembly. Later that year the Agranat Commission, appointed to assess responsibility for Israel's lack of preparedness for the war, exonerated the government of responsibility, and held the Chief of Staff and head of military intelligence responsible. Despite the report, public anger at the Government led to Golda Meir's resignation.

Following Meir's resignation, Yitzhak Rabin (Chief of Staff during the Six Day War) became prime minister. Modern Orthodox Jews (Religious Zionist followers of the teachings of Rabbi Kook), formed the Gush Emunim movement, and began an organized drive to settle the West Bank and Gaza Strip. In November 1975 the United Nations General Assembly, under the guidance of Austrian Secretary General Kurt Waldheim, adopted Resolution 3379, which asserted Zionism to be a form of racism. The General Assembly rescinded this resolution in December 1991 with Resolution 46/86. In March 1976 there was a massive strike by Israeli-Arabs in protest at a government plan to expropriate land in the Galilee.

In July 1976, an Air France plane carrying 260 people was hijacked by Palestinian and German terrorists and flown to Uganda, then ruled by Idi Amin Dada. There, the Germans separated the Jewish passengers from the non-Jewish passengers, releasing the non-Jews. The hijackers threatened to kill the remaining, 100-odd Jewish passengers (and the French crew who had refused to leave). Despite the distances involved, Rabin ordered a daring rescue operation in which the kidnapped Jews were freed. UN Secretary General Waldheim described the raid as "a serious violation of the national sovereignty of a United Nations member state" (meaning Uganda). Waldheim was a former Nazi and suspected war criminal, with a record of offending Jewish sensibilities.

In 1976, the ongoing Lebanese Civil War led Israel to allow South Lebanese to cross the border and work in Israel. In January 1977, French authorities arrested Abu Daoud, the planner of the Munich massacre, releasing him a few days later. In March 1977 Anatoly Sharansky, a prominent Refusenik and spokesman for the Moscow Helsinki Group, was sentenced to 13 years' hard labour.

Rabin resigned in April 1977 after it emerged that his wife maintained a dollar account in the United States (illegal at the time), which had been opened while Rabin was Israeli ambassador. The incident became known as the Dollar Account affair. Shimon Peres informally replaced him as prime minister, leading the Alignment in the subsequent elections.

In a surprise result, the Likud led by Menachem Begin won 43 seats in the 1977 elections (Labour got 32 seats). This was the first time in Israeli history that the government was not led by the left. A key reason for the victory was anger among Mizrahi Jews at discrimination, which was to play an important role in Israeli politics for many years. Talented small town Mizrahi social activists, unable to advance in the Labour party, were readily embraced by Begin. Moroccan-born David Levy and Iranian-born Moshe Katzav were part of a group who won Mizrahi support for Begin. Many Labour voters voted for the Democratic Movement for Change (15 seats) in protest at high-profile corruption cases. The party joined in coalition with Begin and disappeared at the next election.

In addition to starting a process of healing the Mizrahi–Ashkenazi divide, Begin's government included Ultra-Orthodox Jews and was instrumental in healing the Zionist–Ultra-Orthodox rift.

Begin's liberalization of the economy led to hyper-inflation (around 150% inflation) but enabled Israel to begin receiving US financial aid. Begin actively supported Gush Emunim's efforts to settle the West Bank and Jewish settlements in the occupied territories received government support, thus laying the grounds for intense conflict with the Palestinian population of the occupied territories.

In November 1977, Egyptian President Anwar Sadat broke 30 years of hostility with Israel by visiting Jerusalem at the invitation of Israeli Prime Minister Menachem Begin. Sadat's two-day visit included a speech before the Knesset and was a turning point in the history of the conflict. The Egyptian leader created a new psychological climate in the Middle East in which peace between Israel and its Arab neighbours seemed possible. Sadat recognized Israel's right to exist and established the basis for direct negotiations between Egypt and Israel. Following Sadat's visit, 350 Yom Kippur War veterans organized the Peace Now movement to encourage Israeli governments to make peace with the Arabs.

In March 1978, eleven armed Lebanese Palestinians reached Israel in boats and hijacked a bus carrying families on a day outing, killing 38 people, including 13 children. The attackers opposed the Egyptian–Israeli peace process. Three days later, Israeli forces crossed into Lebanon beginning Operation Litani. After passage of United Nations Security Council Resolution 425, calling for Israeli withdrawal and the creation of the United Nations Interim Force in Lebanon (UNIFIL) peace-keeping force, Israel withdrew its troops.
In September 1978, US President Jimmy Carter invited President Sadat and Prime Minister Begin to meet with him at Camp David, and on 11 September they agreed on a framework for peace between Israel and Egypt, and a comprehensive peace in the Middle East. It set out broad principles to guide negotiations between Israel and the Arab states. It also established guidelines for a West Bank–Gaza transitional regime of full autonomy for the Palestinians residing in these territories, and for a peace treaty between Egypt and Israel. The treaty was signed 26 March 1979 by Begin and Sadat, with President Carter signing as witness. Under the treaty, Israel returned the Sinai peninsula to Egypt in April 1982. The final piece of territory to be repatriated was Taba, adjacent to Eilat, returned in 1989, after third-party arbitration determined it fell on the Egyptian side of the border. The Arab League reacted to the peace treaty by suspending Egypt from the organization and moving its headquarters from Cairo to Tunis. Sadat was assassinated in 1981 by Islamic fundamentalist members of the Egyptian army who opposed peace with Israel. Following the agreement Israel and Egypt became the two largest recipients of US military and financial aid (Iraq and Afghanistan have now overtaken them).

In December 1978 the Israeli Merkava battle tank entered use with the IDF. In 1979, over 40,000 Iranian Jews migrated to Israel, escaping the Islamic Revolution there. On 30 June 1981, the Israeli air force destroyed the Osirak nuclear reactor that France was building for Iraq. Three weeks later, Begin won again, in the 1981 elections (48 seats Likud, 47 Labour). Ariel Sharon was made defence minister. The new government annexed the Golan Heights and banned the national airline from flying on Shabbat. By the 1980s a diverse set of high-tech industries had developed in Israel.

In the decades following the 1948 war, Israel's border with Lebanon was quiet compared to its borders with other neighbours. But the 1969 Cairo agreement gave the PLO a free hand to attack Israel from South Lebanon. The area was governed by the PLO independently of the Lebanese Government and became known as "Fatahland" (Fatah was the largest faction in the PLO). Palestinian irregulars constantly shelled the Israeli north, especially the town of Kiryat Shmona, which was a Likud stronghold inhabited primarily by Jews who had fled the Arab world. Lack of control over Palestinian areas was an important factor in causing civil war in Lebanon.

In June 1982, the attempted assassination of Shlomo Argov, the ambassador to Britain, was used as a pretext for an Israeli invasion aiming to drive the PLO out of the southern half of Lebanon. Sharon agreed with Chief of Staff Raphael Eitan to expand the invasion deep into Lebanon even though the cabinet had only authorized a 40 kilometre deep invasion. The invasion became known as the 1982 Lebanon War and the Israeli army occupied Beirut, the only time an Arab capital has been occupied by Israel. Some of the Shia and Christian population of South Lebanon welcomed the Israelis, as PLO forces had maltreated them, but Lebanese resentment of Israeli occupation grew over time and the Shia became gradually radicalized under Iranian guidance. Constant casualties among Israeli soldiers and Lebanese civilians led to growing opposition to the war in Israel.

In August 1982, the PLO withdrew its forces from Lebanon (moving to Tunisia). Bashir Gemayel was elected President of Lebanon, and reportedly agreed to recognize Israel and sign a peace treaty. However, Gemayal was assassinated before an agreement could be signed, and one day later Phalangist Christian forces led by Elie Hobeika entered two Palestinian refugee camps and massacred the occupants. The massacres led to the biggest demonstration ever in Israel against the war, with as many as 400,000 people (almost 10% of the population) gathering in Tel Aviv. In 1983, an Israeli public inquiry found that Israel's defence minister, Sharon, was indirectly but personally responsible for the massacres. It also recommended that he never again be allowed to hold the post (it did not forbid him from being Prime Minister). In 1983, the May 17 Agreement was signed between Israel and Lebanon, paving the way for an Israeli withdrawal from Lebanese territory through a few stages. Israel continued to operate against the PLO until its eventual departure in 1985, and kept a small force stationed in Southern Lebanon in support of the South Lebanon Army until May 2000.

In September 1983, Begin resigned and was succeeded by Yitzhak Shamir as prime minister. The 1984 election was inconclusive, and led to a power sharing agreement between Shimon Peres of the Alignment (44 seats) and Shamir of Likud (41 seats). Peres was prime minister from 1984 to 1986 and Shamir from 1986 to 1988. In 1984, continual discrimination against Sephardi Ultra-Orthodox Jews by the Ashkenazi Ultra-Orthodox establishment led political activist Aryeh Deri to leave the Agudat Israel party and join former chief Rabbi Ovadia Yosef in forming Shas, a new party aimed at the non-Ashkenazi Ultra-Orthodox vote. The party won 4 seats in the first election it contested and over the next twenty years was the third largest party in the Knesset. Shas established a nationwide network of free Sephardi Orthodox schools. In 1984, during a severe famine in Ethiopia, 8,000 Ethiopian Jews were secretly transported to Israel. In 1986 Natan Sharansky, a famous Russian human rights activist and Zionist refusenik (denied an exit visa), was released from the Gulag in return for two Soviet spies.

In June 1985, Israel withdrew most of its troops from Lebanon, leaving a residual Israeli force and an Israeli-supported militia in southern Lebanon as a "security zone" and buffer against attacks on its northern territory. Since then, the IDF fought for many years against the Shia organization Hezbollah, which became a growing threat to Israel. By July 1985, Israel's inflation, buttressed by complex index linking of salaries, had reached 480% per annum and was the highest in the world. Peres introduced emergency control of prices and cut government expenditure successfully bringing inflation under control. The currency (known as the old Israeli shekel) was replaced and renamed the Israeli new shekel at a rate of 1,000 old shkalim = 1 new shekel. In October 1985, Israel responded to a Palestinian terrorist attack in Cyprus by bombing the PLO headquarters in Tunis. Growing Israeli settlement and continuing occupation of the West Bank and Gaza Strip led to the first Palestinian Intifada (uprising) in 1987, which lasted until the Oslo accords of 1993, despite Israeli attempts to suppress it. Human rights abuses by Israeli troops led a group of Israelis to form B'Tselem, an organization devoted to improving awareness and compliance with human rights requirements in Israel.

In August 1987, the Israeli government cancelled the IAI Lavi project, an attempt to develop an independent Israeli fighter aircraft. The Israelis found themselves unable to sustain the huge development costs, and faced US opposition to a project that threatened US influence in Israel and US global military ascendancy. In September 1988, Israel launched an Ofeq reconnaissance satellite into orbit, using a Shavit rocket, thus becoming one of only eight countries possessing a capacity to independently launch satellites into space (two more have since developed this ability). The Alignment and Likud remained neck and neck in the 1988 elections (39:40 seats). Shamir successfully formed a national unity coalition with the Labour Alignment. In March 1990, Alignment leader Shimon Peres engineered a defeat of the government in a non-confidence vote and then tried to form a new government. He failed and Shamir became prime minister at the head of a right-wing coalition.

In 1990, the Soviet Union finally permitted free emigration of Soviet Jews to Israel. Prior to this, Jews trying to leave the USSR faced persecution; those who succeeded arrived as refugees. Over the next few years some one million Soviet citizens migrated to Israel. Although there was concern that some of the new immigrants had only a very tenuous connection to Judaism, and many were accompanied by non-Jewish relatives, this massive wave of migration slowly transformed Israel, bringing large numbers of highly educated Soviet Jews and creating a powerful Russian culture in Israel.

In August 1990, Iraq invaded Kuwait, triggering the Gulf War between Iraq and a large allied force, led by the United States. Iraq attacked Israel with 39 Scud missiles. Israel did not retaliate at request of the US, fearing that if Israel responded against Iraq, other Arab nations might desert the allied coalition. Israel provided gas masks for both the Palestinian population and Israeli citizens, while Netherlands and the United States deployed Patriot defence batteries in Israel as protection against the Scuds. In May 1991, during a 36-hour period, 15,000 Beta Israel (Ethiopian Jews) were secretly airlifted to Israel. The coalition's victory in the Gulf War opened new possibilities for regional peace, and in October 1991 the US president, George H.W. Bush, and Soviet Union Premier, Mikhail Gorbachev, jointly convened a historic meeting in Madrid of Israeli, Lebanese, Jordanian, Syrian, and Palestinian leaders. Shamir opposed the idea but agreed in return for loan guarantees to help with absorption of immigrants from the former Soviet Union. His participation in the conference led to the collapse of his (right-wing) coalition.

In the 1992 elections, the Labour Party, led by Yitzhak Rabin, won a significant victory (44 seats) promising to pursue peace while promoting Rabin as a "tough general" and pledging not to deal with the PLO in any way. The left Zionist party Meretz won 12 seats, and the Arab and communist parties a further 5, meaning that parties supporting a peace treaty had a full (albeit small) majority in the Knesset. Later that year, the Israeli electoral system was changed to allow for direct election of the prime minister. It was hoped this would reduce the power of small parties to extract concessions in return for coalition agreements. The new system had the opposite effect; voters could split their vote for prime minister from their (interest based) party vote, and as a result larger parties won fewer votes and smaller parties becoming more attractive to voters. It thus increased the power of the smaller parties. By the 2006 election the system was abandoned.
On 25 July 1993, Israel carried out a week-long military operation in Lebanon to attack Hezbollah positions. On 13 September 1993, Israel and the Palestine Liberation Organization (PLO) signed the Oslo Accords (a Declaration of Principles) on the South Lawn of the White House. The principles established objectives relating to a transfer of authority from Israel to an interim Palestinian Authority, as a prelude to a final treaty establishing a Palestinian state, in exchange for mutual recognition. The DOP established May 1999 as the date by which a permanent status agreement for the West Bank and Gaza Strip would take effect. In February 1994, Baruch Goldstein, a follower of the Kach party, killed 29 Palestinians and wounded 125 at the Cave of the Patriarchs in Hebron, which became known as the Cave of the Patriarchs massacre. Kach had been barred from participation in the 1992 elections (on the grounds that the movement was racist). It was subsequently made illegal. Israel and the PLO signed the Gaza–Jericho Agreement in May 1994, and the Agreement on Preparatory Transfer of Powers and Responsibilities in August, which began the process of transferring authority from Israel to the Palestinians. On 25 July 1994, Jordan and Israel signed the Washington Declaration, which formally ended the state of war that had existed between them since 1948 and on 26 October the Israel–Jordan Treaty of Peace, witnessed by US President Bill Clinton.

Prime Minister Yitzhak Rabin and PLO Chairman Yasser Arafat signed the Israeli–Palestinian Interim Agreement on the West Bank and the Gaza Strip on 28 September 1995 in Washington. The agreement was witnessed by President Bill Clinton on behalf of the United States and by Russia, Egypt, Norway and the European Union, and incorporates and supersedes the previous agreements, marking the conclusion of the first stage of negotiations between Israel and the PLO. The agreement allowed the PLO leadership to relocate to the occupied territories and granted autonomy to the Palestinians with talks to follow regarding final status. In return the Palestinians promised to abstain from use of terror and changed the Palestinian National Covenant, which had called for the expulsion of all Jews who migrated after 1917 and the elimination of Israel.

The agreement was opposed by Hamas and other Palestinian factions, which launched suicide bomber attacks at Israel. Rabin had a barrier constructed around Gaza to prevent attacks. The growing separation between Israel and the "Palestinian Territories" led to a labour shortage in Israel, mainly in the construction industry. Israeli firms began importing labourers from the Philippines, Thailand, China and Romania; some of these labourers stayed on without visas. In addition, a growing number of Africans began illegally migrating to Israel. On 4 November 1995, a far-right-wing religious Zionist opponent of the Oslo Accords assassinated Prime Minister Yitzhak Rabin. In February 1996 Rabin's successor, Shimon Peres, called early elections. In April 1996, Israel launched an operation in southern Lebanon as a result of Hezbollah's Katyusha rocket attacks on Israeli population centres along the border.

The May 1996 elections were the first featuring direct election of the prime minister and resulted in a narrow election victory for Likud leader Binyamin Netanyahu. A spate of suicide bombings reinforced the Likud position for security. Hamas claimed responsibility for most of the bombings. Despite his stated differences with the Oslo Accords, Prime Minister Netanyahu continued their implementation, but his prime ministership saw a marked slow-down in the Peace Process. Netanyahu also pledged to gradually reduce US aid to Israel.

In September 1996, a Palestinian riot broke out against the creation of an exit in the Western Wall tunnel. Over the subsequent few weeks, around 80 people were killed as a result. In January 1997 Netanyahu signed the Hebron Protocol with the Palestinian Authority, resulting in the redeployment of Israeli forces in Hebron and the turnover of civilian authority in much of the area to the Palestinian Authority.

In the election of July 1999, Ehud Barak of the Labour Party became Prime Minister. His party was the largest in the Knesset with 26 seats. In September 1999 the Supreme Court of Israel ruled that the use of torture in interrogation of Palestinian prisoners was illegal. On 21 March 2000, Pope John Paul II arrived in Israel for a historic visit.

On 25 May 2000, Israel unilaterally its remaining forces from the "security zone" in southern Lebanon. Several thousand members of the South Lebanon Army (and their families) left with the Israelis. The UN Secretary-General concluded that, as of 16 June 2000, Israel had withdrawn its forces from Lebanon in accordance with UN Security Council Resolution 425. Lebanon claims that Israel continues to occupy Lebanese territory called "Sheba'a Farms" (however this area was governed by Syria until 1967 when Israel took control). The Sheba'a Farms provided Hezbollah with a pretext to maintain warfare with Israel. The Lebanese government, in contravention of the UN Security Council resolution, did not assert sovereignty in the area, which came under Hezbollah control. In the Fall of 2000, talks were held at Camp David to reach a final agreement on the Israel/Palestine conflict. Ehud Barak offered to meet most of the Palestinian teams requests for territory and political concessions, including Arab parts of east Jerusalem; however, Arafat abandoned the talks without making a counterproposal.

Following its withdrawal from South Lebanon, Israel became a member of the Western European and Others Group at the United Nations. Prior to this Israel was the only nation at the UN which was not a member of any group (the Arab states would not allow it to join the Asia group), which meant it could not be a member of the Security Council or appoint anyone to the International Court and other key UN roles. Since December 2013 it has been a permanent member of the group.

In July 2000, Aryeh Deri was sentenced to 3 years in prison for bribe taking. Deri is regarded as the mastermind behind the rise of Shas and was a government minister at the age of 24. Political manipulation meant the investigation lasted for years. Deri subsequently sued a Police Officer who alleged that he was linked to the traffic-accident death of his mother-in-law (a key witness), who was run over in New York by a driver who had once been in the employ of an associate of Deri.

On 28 September 2000, Israeli opposition leader Ariel Sharon visited the Al-Aqsa compound, or Temple Mount, the following day the Palestinians launched the al-Aqsa Intifada. David Samuels and Khaled Abu Toameh have stated that the uprising was planned much earlier. In October 2000, Palestinians destroyed Joseph's Tomb, a Jewish shrine in Nablus.

The Arrow missile, a missile designed to destroy ballistic missiles, including Scud missiles, was first deployed by Israel. In 2001, with the Peace Process increasingly in disarray, Ehud Barak called a special election for Prime Minister. Barak hoped a victory would give him renewed authority in negotiations with the Palestinians. Instead opposition leader Ariel Sharon was elected PM. After this election, the system of directly electing the Premier was abandoned.

The failure of the peace process, increased Palestinian terror and occasional attacks by Hezbollah from Lebanon, led much of the Israeli public and political leadership to lose confidence in the Palestinian Authority as a peace partner. Most felt that many Palestinians viewed the peace treaty with Israel as a temporary measure only. Many Israelis were thus anxious to disengage from the Palestinians. In response to a wave of suicide bomb attacks, culminating in the Passover massacre (see List of Israeli civilian casualties in the Second Intifada), Israel launched Operation Defensive Shield in March 2002, and Sharon began the construction of a barrier around the West Bank. Around the same time, the Israeli town of Sderot and other Israeli communities near Gaza became subject to constant shelling and mortar bomb attacks from Gaza.

Thousands of Jews from Latin America began arriving in Israel due to economic crises in their countries of origin. In January 2003 separate elections were held for the Knesset. Likud won the most seats (27). An anti-religion party, Shinui, led by media pundit Tommy Lapid, won 15 seats on a secularist platform, making it the third largest party (ahead of orthodox Shas). Internal fighting led to Shinui's demise at the next election. In 2004, the Black Hebrews were granted permanent residency in Israel. The group had begun migrating to Israel 25 years earlier from the United States, but had not been recognized as Jews by the state and hence not granted citizenship under Israel's Law of Return. They had settled in Israel without official status. From 2004 onwards, they received citizen's rights.

The Sharon government embarked on an extensive program of construction of desalinization plants that freed Israel of the fear of drought. Some of the Israeli desalinization plants are the largest of their kind in the world.

In May 2004, Israel launched Operation Rainbow in southern Gaza to create a safer environment for the IDF soldiers along the Philadelphi Route. On 30 September 2004, Israel carried out Operation Days of Penitence in northern Gaza to destroy the launching sites of Palestinian rockets which were used to attack Israeli towns. In 2005, all Jewish settlers were evacuated from Gaza (some forcibly) and their homes demolished. Disengagement from the Gaza Strip was completed on 12 September 2005. Military disengagement from the northern West Bank was completed ten days later.

In 2005 Sharon left the Likud and formed a new party called Kadima, which accepted that the peace process would lead to creation of a Palestinian state. He was joined by many leading figures from both Likud and Labour.

Hamas won the 2006 Palestinian legislative election, the first and only genuinely free Palestinian elections. Hamas' leaders rejected all agreements signed with Israel, refused to recognize Israel's right to exist, refused to abandon terror, and occasionally claimed the Holocaust was a Jewish conspiracy. The withdrawal and Hamas victory left the status of Gaza unclear, as Israel asserted it was no longer an occupying power but continued to control air and sea access to Gaza although it did not exercise sovereignty on the ground. Egypt insisted that it was still occupied and refused to open border crossings with Gaza, although it was free to do so.

In April 2006 Ariel Sharon was incapacitated by a severe hemorrhagic stroke and Ehud Olmert became Prime Minister.

Ehud Olmert was elected Prime Minister after his party, Kadima, won the most seats (29) in the 2006 Israeli legislative election. In 2005 Mahmoud Ahmadinejad was officially elected president of Iran; since then, Iranian policy towards Israel has grown more confrontational. Israeli analysts believe Ahmadinejad has worked to undermine the peace process with arms supplies and aid to Hezbullah in South Lebanon and Hamas in Gaza, and is developing nuclear weapons, possibly for use against Israel. Iranian support for Hezbollah and its nuclear arms program are in contravention of UN Security Council resolutions 1559 and 1747. Iran also encourages Holocaust denial. Following the Israeli withdrawal from Lebanon, Hezbollah had mounted periodic attacks on Israel, which did not lead to Israeli retaliation. Similarly, the withdrawal from Gaza led to incessant shelling of towns around the Gaza area with only minimal Israeli response. The failure to react led to criticism from the Israeli right and undermined the government.

On 14 March 2006, Israel carried out an operation in the Palestinian Authority prison of Jericho in order to capture Ahmad Sa'adat and several Palestinian Arab prisoners located there who assassinated Israeli politician Rehavam Ze'evi in 2001. The operation was conducted as a result of the expressed intentions of the newly elected Hamas government to release these prisoners. On 25 June 2006, a Hamas force crossed the border from Gaza and attacked a tank, capturing Israeli soldier Gilad Shalit, sparking clashes in Gaza.
On 12 July, Hezbollah attacked Israel from Lebanon, shelled Israeli towns and attacked a border patrol, taking two dead or badly wounded Israeli soldiers. These incidents led Israel to initiate the Second Lebanon War, which lasted through August 2006. Israeli forces entered some villages in Southern Lebanon, while the air force attacked targets all across the country. Israel only made limited ground gains until the launch of Operation Changing Direction 11, which lasted for 3 days with disputed results. Shortly before a UN ceasefire came into effect, Israeli troops captured Wadi Saluki. The war concluded with Hezbollah evacuating its forces from Southern Lebanon, while the IDF remained until its positions could be handed over to the Lebanese Armed Forces and UNIFIL.

In 2007 education was made compulsory until the age of 18 for all citizens (it had been 16). Refugees from the genocide in Darfur, mostly Muslim, arrived in Israel illegally, with some given asylum. Illegal immigrants arrived mainly from Africa in addition to foreign workers overstaying their visas. The numbers of such migrants are not known, and estimates vary between 30,000 and over 100,000.

An American billionaire casino owner, Sheldon Adelson, set up a free newspaper Israel Hayom with the express intention of reducing the influence of the dominant (centre-left) newspaper Yediot Ahronot and accelerating a right-ward shift in Israeli politics by supporting Netanyahu.

In June 2007 Hamas took control of the Gaza Strip in the course of the Battle of Gaza, seizing government institutions and replacing Fatah and other government officials with its own. Following the takeover, Egypt and Israel imposed a partial blockade, on the grounds that Fatah had fled and was no longer providing security on the Palestinian side, and to prevent arms smuggling by terrorist groups. On 6 September 2007, the Israeli Air Force destroyed a nuclear reactor in Syria. On 28 February 2008, Israel launched a military campaign in Gaza in response to the constant firing of Qassam rockets by Hamas militants. On 16 July 2008, Hezbollah swapped the bodies of Israeli soldiers Ehud Goldwasser and Eldad Regev, kidnapped in 2006, in exchange for the Lebanese terrorist Samir Kuntar, four Hezbollah prisoners, and the bodies of 199 Palestinian Arab and Lebanese fighters.

Olmert came under investigation for corruption and this led him to announce on 30 July 2008, that he would be stepping down as Prime Minister following election of a new leader of the Kadima party in September 2008. Tzipi Livni won the election, but was unable to form a coalition and Olmert remained in office until the general election. Israel carried out Operation Cast Lead in the Gaza Strip from 27 December 2008 to 18 January 2009 in response to rocket attacks from Hamas militants, leading to a decrease of Palestinian rocket attacks.

In the 2009 legislative election Likud won 27 seats and Kadima 28; however, the right-wing camp won a majority of seats, and President Shimon Peres called on Netanyahu to form the government. Russian immigrant-dominated Yisrael Beiteinu came third with 15 seats, and Labour was reduced to fourth place with 13 seats. In 2009, Israeli billionaire Yitzhak Tshuva announced the discovery of huge natural gas reserves off the coast of Israel.

On 31 May 2010, an international incident broke out in the Mediterranean Sea when foreign activists trying to break the maritime blockade over Gaza, clashed with Israeli troops. During the struggle, nine Turkish activists were killed. In late September 2010 took place direct negotiations between Israel and the Palestinians without success. As a defensive countermeasure to the rocket threat against Israel's civilian population, at the end of March 2011 Israel began to operate the advanced mobile air defence system "Iron Dome" in the southern region of Israel and along the border with the Gaza Strip.
On 14 July 2011, the largest social protest in the history of Israel began in which hundreds of thousands of protesters from a variety of socio-economic and religious backgrounds in Israel protested against the continuing rise in the cost of living (particularly housing) and the deterioration of public services in the country (such as health and education). The peak of the demonstrations took place on 3 September 2011, in which about 400,000 people demonstrated across the country.

In October 2011, a deal was reached between Israel and Hamas, by which the kidnapped Israeli soldier Gilad Shalit was released in exchange for 1,027 Palestinians and Arab-Israeli prisoners. In March 2012, Secretary-general of the Popular Resistance Committees, Zuhir al-Qaisi, a senior PRC member and two additional Palestinian militants were assassinated during a targeted killing carried out by Israeli forces in Gaza. The Palestinian armed factions in the Gaza Strip, led by the Islamic Jihad and the Popular Resistance Committees, fired a massive amount of rockets towards southern Israel in retaliation, sparking five days of clashes along the Gaza border.

In May 2012, Prime Minister Benjamin Netanyahu reached an agreement with the Head of Opposition Shaul Mofaz for Kadima to join the government, thus cancelling the early election supposed to be held in September. However, in July, the Kadima party left Netanyahu's government due to a dispute concerning military conscription for ultra-Orthodox Jews in Israel.

In June 2012, Israel transferred the bodies of 91 Palestinian suicide bombers and other militants as part of what Mark Regev, spokesman for Netanyahu, described as a "humanitarian gesture" to PA chairman Mahmoud Abbas to help revive the peace talks, and reinstate direct negotiations between Israel and the Palestinians. On 21 October 2012, United States and Israel began their biggest joint air and missile defence exercise, known as Austere Challenge 12, involving around 3,500 US troops in the region along with 1,000 IDF personnel, expected to last three weeks. Germany and Britain also participated. In response to over a hundred rocket attacks on southern Israeli cities, Israel began an operation in Gaza on 14 November 2012, with the targeted killing of Ahmed Jabari, chief of Hamas military wing, and airstrikes against twenty underground sites housing long-range missile launchers capable of striking Tel Aviv. In January 2013, construction of the barrier on the Israeli-Egyptian border was completed in its main section.

Benjamin Netanyahu was elected Prime Minister again after the Likud Yisrael Beiteinu alliance won the most seats (31) in the 2013 legislative election and formed a coalition government with secular centrist Yesh Atid party (19), rightist The Jewish Home (12) and Livni's Hatnuah (6), excluding Haredi parties. Labour came in third with 15 seats. In July 2013, as a "good will gesture" to restart peace talks with the Palestinian Authority, Israel agreed to release 104 Palestinian prisoners, most of whom had been in jail since before the 1993 Oslo Accords, including militants who had killed Israeli civilians. In April 2014, Israel suspended peace talks after Hamas and Fatah agreed to form a unity government.

Following an escalation of rocket attacks by Hamas, Israel started an operation in the Gaza Strip on 8 July 2014, which included a ground incursion aimed at destroying the cross-border tunnels. Differences over the budget and a triggered early elections in December 2014. After the 2015 Israeli elections, Netanyahu renewed his mandate as Prime Minister when Likud obtained 30 seats and formed a right-wing coalition government with Kulanu (10), The Jewish Home (8), and Orthodox parties Shas (7) and United Torah Judaism (6), the bare minimum of seats required to form a coalition. The Zionist Union alliance came second with 24 seats. A wave of lone-wolf attacks by Palestinians took place in 2015 and 2016, particularly stabbings.

On 6 December 2017, President Donald Trump formally announced United States recognition of Jerusalem as the capital of Israel, which was followed by the United States recognition of the Golan Heights as part of Israel on 25 March 2019. In March 2018, Palestinians in Gaza initiated "the Great March of Return," a series of weekly protests along the Gaza–Israel border.

In April 2020, amid the coronavirus pandemic and after three consecutive elections in less than a year, Netanyahu and Benny Gantz were able to establish a unity government with rotating prime ministership where Netanyahu would serve first and later be replaced by Gantz.



</doc>
<doc id="13810" url="https://en.wikipedia.org/wiki?curid=13810" title="Harvey Mudd College">
Harvey Mudd College

Harvey Mudd College (HMC) is a private residential undergraduate science and engineering college in Claremont, California. It is one of the institutions of the contiguous Claremont Colleges which share adjoining campus grounds. Harvey Mudd College shares university resources such as libraries, dining halls, health services and campus security with the other Claremont Colleges, although each college is independently managed, with their own faculty, board of trustees, endowment, and admissions procedures. Students at Harvey Mudd College may take classes (acceptable for academic credit at Harvey Mudd College) at the other four undergraduate Claremont colleges. The Bachelor of Science diploma received at graduation is issued by Harvey Mudd College.

The college is named after Harvey Seeley Mudd, one of the initial investors in the Cyprus Mines Corporation. Although involved in planning of the new institution, Mudd died before it opened. The college was funded by Mudd's friends and family, and named in his honor.

HMC offers four-year degrees in chemistry, mathematics, physics, computer science, biology, and engineering, interdisciplinary degrees in mathematical biology, and joint majors in computer science and mathematics; or in biology and chemistry. Students may also elect an Individual Program of Study (IPS) or an off-campus major offered by any of the other Claremont Colleges, provided one also completes a minor in one of the technical fields that Harvey Mudd offers as a major.

In 2018, the "Chronicle of Higher Education" reported that, in response to student "complaints first to mental-health counselors and then to outside evaluators", the college was "considering how to ease pressure on students without sacrificing rigor."

For the class of 2023, the college received 4,045 applications and admitted 553 applicants (a 13.7% acceptance rate). Of the 224 freshmen who enrolled, the middle 50% of SAT scores were 780–800 in mathematics and 710–770 in critical reading, while the ACT Composite range was 33–35.

Harvey Mudd, along with Wake Forest University, long held out as the last four-year colleges or universities in the U.S. to accept only SAT and not ACT test scores for admission. In August 2007, at the beginning of the application process for the class of 2012, HMC began accepting ACT results, a year after Wake Forest abandoned its former SAT-only policy.

In 2016, Harvey Mudd was for the second year in a row the most expensive college in the United States, with the total annual cost of attendance (tuition, fees, and room and board) being $69,717. About 70% of freshmen receive financial aid.

The official names for the dormitories of Harvey Mudd College are (listed in order of construction):

Until the addition of the Linde and Sontag dorms, Atwood and Case dorms were occasionally referred to as New Dorm and New Dorm II; Mildred E. Mudd Hall and Marks Hall are almost invariably referred to as East dorm and South dorm.

During the construction of Case Dorm some students decided as a prank to move all of the survey stakes exactly six inches in one direction.

South Dorm is in the northwest corner of the quad. "East" was the first dorm, but it wasn't until "West" was built west of it that it was actually referred to as "East". Then "North" was built, directly north of "East". When the fourth dorm (Marks) was built, there was one corner of the quad available (the northwest) and one directional name, "South", remaining. To this day "South" dorm is the northernmost HMC dorm.

The fifth, sixth, seventh, eighth, and ninth dorms built are Atwood, Case, Linde, Sontag, and Drinkward, respectively. They were initially referred to as "the colonies" by some students, a reference to the fact that they were newer and at the farthest end of the campus; these dorms are now more commonly referred to as "the outer dorms." The college had initially purchased an apartment building adjacent to the newer dorms to house additional students, but it was demolished to make room for Sontag.

Since any HMC student, regardless of class year, can live in any of the dormitories, several of the dorms have accumulated long-standing traditions and so-called 'personalities'.

A student-led organization, "Increasing Harvey Mudd's Traditional Practices" (IHTP), works to revive college traditions that have slowly faded over the years, and also starts new traditions that the group hopes to see take root on campus. It hosts annual events such as the 5-Class Competition, Friday Nooners, Wednesday Nighters, Frosh/Soph Games, and the Thomas-Garrett Affair.

Athletes from Harvey Mudd compete alongside athletes from Claremont McKenna College and Scripps College as the Claremont-Mudd-Scripps Stags and Athenas (CMS). The teams participate in NCAA Division III in the Southern California Intercollegiate Athletic Conference (SCIAC). The mascot for the men's teams is Stanley the Stag, and the women's teams are the Athenas. Their colors are cardinal and gold.

According to the Division III Fall Learfield Director's Cup Standings for the 2016-2017 year, CMS ranks 12th among all Division III programs, and first among SCIAC colleges.

There are 21 men's and women's teams.

Men's sports


Women's sports



The other sports combination of the Claremont Colleges, and CMS' primary rival, is the team made up of Pomona College and Pitzer College known as the Pomona-Pitzer Sagehens (PP).

The original buildings of campus, designed by Edward Durell Stone and completed in 1955, features "knobbly concrete squares that students of Harvey Mudd affectionately call “warts” and use as hooks for skateboards." The school's unofficial mascot "Wally Wart" is an anthropomorphic concrete wart.

In 2013, "Travel and Leisure" named the college as one of "America's ugliest college campuses" and noted that while Stone regarded his design as a "Modernist masterpiece" the result was "layering drab, slab-sided buildings with Beaux-Arts decoration."

The California Institute of Technology, another school known for its strength in the natural sciences and engineering, is located away from Harvey Mudd College. From time to time, Mudders have been known to amuse themselves by pranking Caltech. For example, in 1986, students from Mudd stole a memorial cannon from Fleming House at Caltech (originally from the National Guard) by dressing as maintenance people and carting it off on a flatbed truck for "cleaning". Harvey Mudd eventually returned the cannon after Caltech threatened to take legal action. In 2006, MIT replicated the prank and moved the same cannon to their campus in Cambridge, Massachusetts.

Harvey Mudd maintains the highest rate of science and engineering Ph.D. production among all undergraduate colleges and second highest (Caltech ranks first and MIT third) compared to all universities and colleges, according to a 2008 report by the National Science Foundation. 

"Washington Monthly" ranked Harvey Mudd 5th in 2020 among 218 liberal arts colleges in the U.S. based on its contribution to the public good, as measured by social mobility, research, and promoting public service. "Money" magazine ranked Harvey Mudd 136th out of 744 in its "Best Colleges For Your Money 2019" report.

In "U.S. News & World Report"'s 2020 "America's Best Colleges" report, Harvey Mudd College is tied for the 23rd best U.S. liberal arts college, is 2nd among undergraduate engineering schools in the U.S. whose highest degree is a Master's, and is ranked as tied for 6th "most Innovative School" among liberal arts colleges. "Forbes" in 2019 rated it 23rd in its "America's Top Colleges" ranking of 650 military academies, national universities and liberal arts colleges.

Notable Harvey Mudd College alumni include:





</doc>
<doc id="13811" url="https://en.wikipedia.org/wiki?curid=13811" title="Heaven">
Heaven

Heaven or the heavens, is a common religious cosmological or transcendent supernatural place where beings such as gods, angels, spirits, saints, or venerated ancestors are said to originate, be enthroned, or live. According to the beliefs of some religions, heavenly beings can descend to Earth or incarnate and earthly beings can ascend to Heaven in the afterlife or, in exceptional cases, enter Heaven alive.

Heaven is often described as a "highest place", the holiest place, a Paradise, in contrast to hell or the Underworld or the "low places" and universally or conditionally accessible by earthly beings according to various standards of divinity, goodness, piety, faith, or other virtues or right beliefs or simply divine will. Some believe in the possibility of a heaven on Earth in a "world to come".

Another belief is in an axis mundi or world tree which connects the heavens, the terrestrial world, and the underworld. In Indian religions, heaven is considered as "Svarga loka", and the soul is again subjected to rebirth in different living forms according to its "karma". This cycle can be broken after a soul achieves "Moksha" or "Nirvana". Any place of existence, either of humans, souls or deities, outside the tangible world (Heaven, Hell, or other) is referred to as the "otherworld".

The modern English word "heaven" is derived from the earlier (Middle English) "heven" (attested 1159); this in turn was developed from the previous Old English form "heofon". By about 1000, "heofon" was being used in reference to the Christianized "place where God dwells", but originally, it had signified "sky, firmament" (e.g. in "Beowulf", c. 725). The English term has cognates in the other Germanic languages: Old Saxon "heƀan" "sky, heaven" (hence also Middle Low German "heven" "sky"), Old Icelandic "himinn", Gothic "himins"; and those with a variant final "-l": Old Frisian "himel, himul" "sky, heaven", Old Saxon and Old High German "himil", Old Saxon and Middle Low German "hemmel", Old Dutch and Dutch "hemel", and modern German "Himmel". All of these have been derived from a reconstructed Proto-Germanic form *"hemina-". or "*hemō".

The further derivation of this form is uncertain. A connection to Proto-Indo-European "*ḱem-" "cover, shroud", via a reconstructed "*k̑emen-" or "*k̑ōmen-" "stone, heaven", has been proposed. Others endorse the derivation from a Proto-Indo-European root "*h₂éḱmō" "stone" and, possibly, "heavenly vault" at the origin of this word, which then would have as cognates ancient Greek ἄκμων (ákmōn "anvil, pestle; meteorite"), Persian آسمان‎ ("âsemân, âsmân" "stone, sling-stone; sky, heaven") and Sanskrit अश्मन् ("aśman" "stone, rock, sling-stone; thunderbolt; the firmament"). In the latter case English "hammer" would be another cognate to the word.

The ancient Mesopotamians regarded the sky as a series of domes (usually three, but sometimes seven) covering the flat Earth. Each dome was made of a different kind of precious stone. The lowest dome of heaven was made of jasper and was the home of the stars. The middle dome of heaven was made of "saggilmut" stone and was the abode of the Igigi. The highest and outermost dome of heaven was made of "luludānītu" stone and was personified as An, the god of the sky. The celestial bodies were equated with specific deities as well. The planet Venus was believed to be Inanna, the goddess of love, sex, and war. The Sun was her brother Utu, the god of justice, and the Moon was their father Nanna.

In ancient Near Eastern cultures in general and in Mesopotamia in particular, humans had little to no access to the divine realm. Heaven and Earth were separated by their very nature; humans could see and be affected by elements of the lower heaven, such as stars and storms, but ordinary mortals could not go to Heaven because it was the abode of the gods alone. In the "Epic of Gilgamesh", Gilgamesh says to Enkidu, "Who can go up to heaven, my friend? Only the gods dwell with Shamash forever." Instead, after a person died, his or her soul went to Kur (later known as Irkalla), a dark shadowy underworld, located deep below the surface of the earth.

All souls went to the same afterlife, and a person's actions during life had no impact on how he would be treated in the world to come. Nonetheless, funerary evidence indicates that some people believed that Inanna had the power to bestow special favors upon her devotees in the afterlife. Despite the separation between heaven and earth, humans sought access to the gods through oracles and omens. The gods were believed to live in Heaven, but also in their temples, which were seen as the channels of communication between Earth and Heaven, which allowed mortal access to the gods. The Ekur temple in Nippur was known as the "Dur-an-ki", the "mooring-rope" of heaven and earth. It was widely thought to have been built and established by Enlil himself.

Almost nothing is known of Bronze Age (pre-1200 BC) Canaanite views of heaven, and the archaeological findings at Ugarit (destroyed c. 1200 BC) have not provided information. The 1st century Greek author Philo of Byblos may preserve elements of Iron Age Phoenician religion in his "Sanchuniathon".

The ancient Hittites believed that some deities lived in Heaven, while others lived in remote places on Earth, such as mountains, where humans had little access. In the Middle Hittite myths, Heaven is the abode of the gods. In the Song of Kumarbi, Alalu was king in Heaven for nine years before giving birth to his son, Anu. Anu was himself overthrown by his son, Kumarbi.
As in other ancient Near Eastern cultures, in the Hebrew Bible, the universe is commonly divided into two realms: heaven ("šāmayim") and earth ("’ereṣ"). Sometimes a third realm is added: either "sea" (, ), "water under the earth" (, ), or sometimes a vague "land of the dead" that is never described in depth (, , ). The structure of heaven itself is never fully described in the Hebrew Bible, but the fact that the Hebrew word "šāmayim" is plural has been interpreted by scholars as an indication that the ancient Israelites envisioned the heavens as having multiple layers, much like the ancient Mesopotamians. This reading is also supported by the use of the phrase "heaven of heavens" in verses such as , , and and .

In line with the typical view of most Near Eastern cultures, the Hebrew Bible depicts Heaven as a place that is inaccessible to humans. Although some prophets are occasionally granted temporary visionary access to heaven, such as in , and , and , they hear only God's deliberations concerning the Earth and learn nothing of what Heaven is like. There is almost no mention in the Hebrew Bible of Heaven as a possible afterlife destination for human beings, who are instead described as "resting" in Sheol (, , ). The only two possible exceptions to this are Enoch, who is described in as having been "taken" by God, and the prophet Elijah, who is described in as having ascended to Heaven in a chariot of fire. According to Michael B. Hundley, the text in both of these instances is ambiguous regarding the significance of the actions being described and in neither of these cases does the text explain what happened to the subject afterwards.

The God of the Israelites is described as ruling both Heaven and Earth ( , ). Other passages, such as state that even the vastness of Heaven cannot contain God's majesty. A number of passages throughout the Hebrew Bible indicate that Heaven and Earth will one day come to an end (, , , , , , and and ). This view is paralleled in other ancient Near Eastern cultures, which also regarded Heaven and Earth as vulnerable and subject to dissolution. However, the Hebrew Bible differs from other ancient Near Eastern cultures in that it portrays the God of Israel as independent of creation and unthreatened by its potential destruction. Because most of the Hebrew Bible concerns the God of Israel's relationship with his people, most of the events described in it take place on Earth, not in Heaven. The Deuteronomistic source, Deuteronomistic History, and Priestly source all portray the Temple in Jerusalem as the sole channel of communication between Earth and Heaven.

During the period of the Second Temple ( 515 BC – 70 AD), the Hebrew people lived under the rule of first the Persian Achaemenid Empire, then the Greek kingdoms of the Diadochi, and finally the Roman Empire. Their culture was profoundly influenced by those of the peoples who ruled them. Consequently, their views on existence after death were profoundly shaped by the ideas of the Persians, Greeks, and Romans. The idea of the immortality of the soul is derived from Greek philosophy and the idea of the resurrection of the dead is derived from Persian cosmology. By the early first century AD, these two seemingly incompatible ideas were often conflated by Hebrew thinkers. The Hebrews also inherited from the Persians, Greeks, and Romans the idea that the human soul originates in the divine realm and seeks to return there. The idea that a human soul belongs in Heaven and that Earth is merely a temporary abode in which the soul is tested to prove its worthiness became increasingly popular during the Hellenistic period (323 – 31 BC). Gradually, some Hebrews began to adopt the idea of Heaven as the eternal home of the righteous dead.

Descriptions of Heaven in the New Testament are more fully developed than those in the Old Testament, but are still generally vague. As in the Old Testament, in the New Testament God is described as the ruler of Heaven and Earth, but his power over the Earth is challenged by Satan. Sayings of Jesus recorded in the Gospels of Mark and Luke speak of the "Kingdom of God" (; ), while the Gospel of Matthew more commonly uses the term "Kingdom of Heaven" (; ). Both phrases have exactly the same meaning, but the author of the Gospel of Matthew changed the name "Kingdom of God" to "Kingdom of Heaven" in most instances because it was the more acceptable phrase in his own cultural and religious context in the late first century.

Modern scholars agree that the Kingdom of God was an essential part of the teachings of the historical Jesus. In spite of this, none of the gospels ever record Jesus as having explained exactly what the phrase "Kingdom of God" means. The most likely explanation for this apparent omission is that the Kingdom of God was a commonly understood concept that required no explanation. Jews in Judea during the early first century believed that God reigns eternally in Heaven, but many also believed that God would eventually establish his kingdom on earth as well. This belief is referenced in the first petition of the Lord's Prayer, taught by Jesus to his disciples and recorded in both and : "Your kingdom come, your will be done, on earth as it is in heaven."

Because God's Kingdom was believed to be superior to any human kingdom, this meant that God would necessarily drive out the Romans, who ruled Judea, and establish his own direct rule over the Jewish people. In the teachings of the historical Jesus, people are expected to prepare for the coming of the Kingdom of God by living moral lives. Jesus's commands for his followers to adopt lifestyles of moral perfectionism are found in many passages throughout the Synoptic Gospels, particularly in the Sermon on the Mount in . Jesus also taught that, in the Kingdom of Heaven, there would be a reversal of roles in which "the last will be first and the first will be last" (, , , and ). This teaching recurs throughout the recorded teachings of Jesus, including in the admonition to be like a child in , , and , the Parable of the Rich Man and Lazarus in , the Parable of the Workers in the Vineyard in , the Parable of the Great Banquet in , and the Parable of the Prodigal Son in .

Traditionally, Christianity has taught that Heaven is the location of the throne of God as well as the holy angels, although this is in varying degrees considered metaphorical. In traditional Christianity, it is considered a state or condition of existence (rather than a particular place somewhere in the cosmos) of the supreme fulfillment of theosis in the beatific vision of the Godhead. In most forms of Christianity, Heaven is also understood as the abode for the redeemed dead in the afterlife, usually a temporary stage before the resurrection of the dead and the saints' return to the New Earth.

The resurrected Jesus is said to have ascended to Heaven where he now sits at the Right Hand of God and will return to Earth in the Second Coming. Various people have been said to have entered Heaven while still alive, including Enoch, Elijah and Jesus himself, after his resurrection. According to Roman Catholic teaching, Mary, mother of Jesus, is also said to have been assumed into Heaven and is titled the Queen of Heaven.

In the 2nd century AD, Irenaeus of Lyons recorded a belief that, in accordance with , those who in the afterlife see the Saviour are in different mansions, some dwelling in the heavens, others in paradise and others in "the city".

While the word used in all these writings, in particular the New Testament Greek word οὐρανός ("ouranos"), applies primarily to the sky, it is also used metaphorically of the dwelling place of God and the blessed. Similarly, though the English word "heaven" still keeps its original physical meaning when used, for instance, in allusions to the stars as "lights shining through from heaven", and in phrases such as heavenly body to mean an astronomical object, the heaven or happiness that Christianity looks forward to is, according to Pope John Paul II, "neither an abstraction nor a physical place in the clouds, but a living, personal relationship with the Holy Trinity. It is our meeting with the Father which takes place in the risen Christ through the communion of the Holy Spirit."

While the concept of Heaven ("malkuth hashamaim" מלכות השמים, the Kingdom of Heaven) is much discussed in Christian thought, the Jewish concept of the afterlife, sometimes known as "olam haba", the World-to-come, is not discussed so often. The Torah has little to say on the subject of survival after death, but by the time of the rabbis two ideas had made inroads among the Jews: one, which is probably derived from Greek thought, is that of the immortal soul which returns to its creator after death; the other, which is thought to be of Persian origin, is that of resurrection of the dead.

Jewish writings refer to a "new earth" as the abode of mankind following the resurrection of the dead. Originally, the two ideas of immortality and resurrection were different but in rabbinic thought they are combined: the soul departs from the body at death but is returned to it at the resurrection. This idea is linked to another rabbinic teaching, that men's good and bad actions are rewarded and punished not in this life but after death, whether immediately or at the subsequent resurrection. Around 1 CE, the Pharisees are said to have maintained belief in resurrection but the Sadducees are said to have denied it (Matt. 22:23).

The Mishnah has many sayings about the World to Come, for example, "Rabbi Yaakov said: This world is like a lobby before the World to Come; prepare yourself in the lobby so that you may enter the banquet hall."

Judaism holds that the righteous of all nations have a share in the World-to-come.

According to Nicholas de Lange, Judaism offers no clear teaching about the destiny which lies in wait for the individual after death and its attitude to life after death has been expressed as follows: "For the future is inscrutable, and the accepted sources of knowledge, whether experience, or reason, or revelation, offer no clear guidance about what is to come. The only certainty is that each man must die – beyond that we can only guess."

According to Tracey R. Rich of the website "Judaism 101", Judaism, unlike other world-religions, is not focused on the quest of getting into heaven but on life and how to live it.

Similar to Jewish traditions such as the Talmud, the Qur'an and Hadith frequently mention the existence of seven "samāwāt" (سماوات), the plural of "samāʾ" (سماء), meaning 'heaven, sky, celestial sphere', and cognate with Hebrew "shamāyim" (שמים). Some of the verses in the Qur'an mentioning the "samaawat" are , , . Sidrat al-Muntaha, a large enigmatic Lote tree, marks the end of the seventh heaven and the utmost extremity for all of God's creatures and heavenly knowledge.

One interpretation of "heavens" is that all the stars and galaxies (including the Milky Way) are all part of the "first heaven", and "beyond that six still bigger worlds are there," which have yet to be discovered by scientists.

According to Shi'ite sources, Ali mentioned the names of the seven heavens as below:

Still an afterlife destination of the righteous is conceived in Islam as "Jannah" ( "Garden [of Eden]" translated as "paradise"). Regarding Eden or paradise the Quran says, "The parable of the Garden which the righteous are promised: Beneath it flow rivers; perpetual is the fruits thereof and the shade therein. Such is the end of the righteous; and the end of the unbelievers is the Hellfire." Islam rejects the concept of original sin, and Muslims believe that all human beings are born pure. Children automatically go to paradise when they die, regardless of the religion of their parents.

Paradise is described primarily in physical terms as a place where every wish is immediately fulfilled when asked. Islamic texts describe immortal life in Jannah as happy, without negative emotions. Those who dwell in Jannah are said to wear costly apparel, partake in exquisite banquets, and recline on couches inlaid with gold or precious stones. Inhabitants will rejoice in the company of their parents, spouses, and children. In Islam if one's good deeds outweigh one's sins then one may gain entrance to paradise. Conversely, if one's sins outweigh their good deeds they are sent to hell. The more good deeds one has performed the higher the level of Jannah one is directed to.
Verses which describe paradise include: , , , , .

The Quran refer to Jannah with different names: "Al-Firdaws", "Jannātu-′Adn" ("Garden of Eden" or "Everlasting Gardens"), "Jannatu-n-Na'īm" ("Garden of Delight"), "Jannatu-l-Ma'wa" ("Garden of Refuge"), "Dāru-s-Salām" ("Abode of Peace"), "Dāru-l-Muqāma" ("Abode of Permanent Stay"), "al-Muqāmu-l-Amin" ("The Secure Station") and "Jannātu-l-Khuld" ("Garden of Immortality"). In the Hadiths, these are the different regions in paradise.

According to the Ahmadiyya view, much of the imagery presented in the Quran regarding Heaven, but also Hell, is in fact metaphorical. They propound the verse which describes, according to them, how the life to come after death is very different from the life here on Earth. The Quran says: According to Mirza Ghulam Ahmad, the founder of Ahmadiyya sect in Islam, the soul will give birth to another rarer entity and will resemble the life on this earth in the sense that this entity will bear a similar relationship to the soul, as the soul bears relationship with the human existence on earth. On earth, if a person leads a righteous life and submits to the will of God, his or her tastes become attuned to enjoying spiritual pleasures as opposed to carnal desires. With this, an "embryonic soul" begins to take shape. Different tastes are said to be born in which a person given to carnal passions finds no enjoyment. For example, sacrifice of one's own's rights over that of other's becomes enjoyable, or that forgiveness becomes second nature. In such a state a person finds contentment and Peace at heart and at this stage, according to Ahmadiyya beliefs, it can be said that a soul within the soul has begun to take shape.

The Bahá'í Faith regards the conventional description of heaven (and hell) as a specific place as symbolic. The Bahá'í writings describe heaven as a "spiritual condition" where closeness to God is defined as heaven; conversely hell is seen as a state of remoteness from God. Bahá'u'lláh, the founder of the Bahá'í Faith, has stated that the nature of the life of the soul in the afterlife is beyond comprehension in the physical plane, but has stated that the soul will retain its consciousness and individuality and remember its physical life; the soul will be able to recognize other souls and communicate with them.

For Bahá'ís, entry into the next life has the potential to bring great joy. Bahá'u'lláh likened death to the process of birth. He explains: "The world beyond is as different from this world as this world is different from that of the child while still in the womb of its mother." The analogy to the womb in many ways summarizes the Bahá'í view of earthly existence: just as the womb constitutes an important place for a person's initial physical development, the physical world provides for the development of the individual soul. Accordingly, Bahá'ís view life as a preparatory stage, where one can develop and perfect those qualities which will be needed in the next life. The key to spiritual progress is to follow the path outlined by the current Manifestation of God, which Bahá'ís believe is currently Bahá'u'lláh. Bahá'u'lláh wrote, "Know thou, of a truth, that if the soul of man hath walked in the ways of God, it will, assuredly return and be gathered to the glory of the Beloved."

The Bahá'í teachings state that there exists a hierarchy of souls in the afterlife, where the merits of each soul determines their place in the hierarchy, and that souls lower in the hierarchy cannot completely understand the station of those above. Each soul can continue to progress in the afterlife, but the soul's development is not entirely dependent on its own conscious efforts, the nature of which we are not aware, but also augmented by the grace of God, the prayers of others, and good deeds performed by others on Earth in the name of that person.

In the native Chinese Confucian traditions, heaven (Tian) is an important concept, where the ancestors reside and from which emperors drew their mandate to rule in their dynastic propaganda, for example.

Heaven is a key concept in Chinese mythology, philosophies, and religions, and is on one end of the spectrum a synonym of "Shangdi" ("Supreme Deity") and on the other naturalistic end, a synonym for nature and the sky. The Chinese term for "heaven", "Tian" (天), derives from the name of the supreme deity of the Zhou Dynasty. After their conquest of the Shang Dynasty in 1122 BC, the Zhou people considered their supreme deity "Tian" to be identical with the Shang supreme deity "Shangdi". The Zhou people attributed Heaven with anthropomorphic attributes, evidenced in the etymology of the Chinese character for heaven or sky, which originally depicted a person with a large cranium. heaven is said to see, hear and watch over all men. heaven is affected by man's doings, and having personality, is happy and angry with them. Heaven blesses those who please it and sends calamities upon those who offend it. Heaven was also believed to transcend all other spirits and gods, with Confucius asserting, "He who offends against Heaven has none to whom he can pray."

Other philosophers born around the time of Confucius such as Mozi took an even more theistic view of heaven, believing that heaven is the divine ruler, just as the Son of Heaven (the King of Zhou) is the earthly ruler. Mozi believed that spirits and minor gods exist, but their function is merely to carry out the will of heaven, watching for evil-doers and punishing them. Thus they function
as angels of heaven and do not detract from its monotheistic government of the world. With such a high monotheism, it is not surprising that Mohism championed a concept called "universal love" ("jian'ai", 兼愛), which taught that heaven loves all people equally and that each person should similarly love all human beings without distinguishing between his own relatives and those of others. In Mozi's "Will of Heaven" (天志), he writes:

Mozi criticized the Confucians of his own time for not following the teachings of Confucius. By the time of the later Han Dynasty, however, under the influence of Xunzi, the Chinese concept of heaven and Confucianism itself had become mostly naturalistic, though some Confucians argued that Heaven was where ancestors reside. Worship of heaven in China continued with the erection of shrines, the last and greatest being the Temple of Heaven in Beijing, and the offering of prayers. The ruler of China in every Chinese dynasty would perform annual sacrificial rituals to heaven, usually by slaughtering two healthy bulls as a sacrifice.

In Buddhism there are several heavens, all of which are still part of "samsara" (illusionary reality). Those who accumulate good karma may be reborn in one of them. However, their stay in heaven is not eternal—eventually they will use up their good karma and will undergo rebirth into another realm, as a human, animal or other beings. Because heaven is temporary and part of "samsara", Buddhists focus more on escaping the cycle of rebirth and reaching enlightenment ("nirvana"). Nirvana is not a heaven but a mental state.

According to Buddhist cosmology the universe is impermanent and beings transmigrate through several existential "planes" in which this human world is only one "realm" or "path". These are traditionally envisioned as a vertical continuum with the heavens existing above the human realm, and the realms of the animals, hungry ghosts and hell beings existing beneath it. According to Jan Chozen Bays in her book, "Jizo: Guardian of Children, Travelers, and Other Voyagers", the realm of the "asura" is a later refinement of the heavenly realm and was inserted between the human realm and the heavens. One important Buddhist heaven is the "Trāyastriṃśa", which resembles Olympus of Greek mythology.

In the Mahayana world view, there are also pure lands which lie outside this continuum and are created by the Buddhas upon attaining enlightenment. Rebirth in the pure land of Amitabha is seen as an assurance of Buddhahood, for once reborn there, beings do not fall back into cyclical existence unless they choose to do so to save other beings, the goal of Buddhism being the obtainment of enlightenment and freeing oneself and others from the birth-death cycle.

The Tibetan word "Bardo" means literally "intermediate state". In Sanskrit the concept has the name "antarabhāva".

The lists below are classified from highest to lowest of the heavenly worlds.

Brahmāloka

Here the denizens are Brahmās, and the ruler is Mahābrahmā

After developing the four Brahmavihāras, King Makhādeva rebirths here after death. The monk Tissa and Brāhmana Jānussoni were also reborn here.

The lifespan of a Brahmās is not stated but is not eternal.

Parinirmita-vaśavartin (Pali: Paranimmita-vasavatti)

The heaven of devas "with power over (others') creations". These devas do not create pleasing forms that they desire for themselves, but their desires are fulfilled by the acts of other devas who wish for their favor. The ruler of this world is called Vaśavartin (Pāli: Vasavatti), who has longer life, greater beauty, more power and happiness and more delightful sense-objects than the other devas of his world. This world is also the home of the devaputra (being of a divine race) called Māra, who endeavors to keep all beings of the Kāmadhātu in the grip of sensual pleasures. Māra is also sometimes called Vaśavartin, but in general these two dwellers in this world are kept distinct. The beings of this world are tall and live for 9,216,000,000 years (Sarvāstivāda tradition).

Nirmāṇarati (Pali: Nimmānaratī)

The world of devas "delighting in their creations". The devas of this world are capable of making any appearance to please themselves. The lord of this world is called Sunirmita (Pāli Sunimmita); his wife is the rebirth of Visākhā, formerly the chief upāsikā (female lay devotee) of the Buddha. The beings of this world are tall and live for 2,304,000,000 years (Sarvāstivāda tradition).

The world of the "joyful" devas. This world is best known for being the world in which a Bodhisattva lives before being reborn in the world of humans. Until a few thousand years ago, the Bodhisattva of this world was Śvetaketu (Pāli: Setaketu), who was reborn as Siddhārtha, who would become the Buddha Śākyamuni; since then the Bodhisattva has been Nātha (or Nāthadeva) who will be reborn as Ajita and will become the Buddha Maitreya (Pāli Metteyya). While this Bodhisattva is the foremost of the dwellers in , the ruler of this world is another deva called (Pāli: Santusita). The beings of this world are tall and live for 576,000,000 years (Sarvāstivāda tradition). Anāthapindika, a Kosālan householder and benefactor to the Buddha's order was reborn here.

Yāma

The denizens here have a lifespan of 144,000,000 years.

Trāyastriṃśa (Pali: Tāvatimsa)

The ruler of this heaven is Indra or Shakra, and the realm is also called Trayatrimia.

Each denizen addresses other denizens as the title "mārisa".

The governing hall of this heaven is called Sudhamma Hall.

This heaven has a garden Nandanavana with damsels, as its most magnificent sight.

Ajita the Licchavi army general was reborn here. Gopika the Sākyan girl was reborn as a male god in this realm.

Any Buddhist reborn in this realm can outshine any of the previously dwelling denizens because of the extra merit acquired for following the Buddha's teachings.

The denizens here have a lifespan of 36,000,000 years.

Cātummahārājika

The heaven "of the Four Great Kings". Its rulers are the four Great Kings of the name, , , , and their leader . The devas who guide the Sun and Moon are also considered part of this world, as are the retinues of the four kings, composed of (dwarfs), Gandharva गन्धर्वs (fairies), Nāgas (snakes) and (goblins). The beings of this world are tall and live for 9,000,000 years (Sarvāstivāda tradition) or 90,000 years (Vibhajyavāda tradition).




The Heaven of the Comfort from Others’ Transformations

The Heaven of Bliss by Transformation

The Tushita Heaven

The Suyama Heaven

The Trayastrimsha Heaven

The Heaven of the Four Kings 

Ou Yi Zhixu explains that the Shurangama sutra only emphasizes avoidance of deviant sexual desire, but one would naturally need to abide by the 10 good conducts to be born in these heavens.

Tibetan ltierature classifies the heavenly worlds into 5 major types:

Attaining heaven is not the final pursuit in Hinduism as heaven itself is ephemeral and related to physical body. Only being tied by the bhoot-tatvas, heaven cannot be perfect either and is just another name for pleasurable and mundane material life. According to Hindu cosmology, above the earthly plane, are other planes: (1) Bhuva Loka, (2) Swarga Loka, meaning Good Kingdom, is the general name for heaven in Hinduism, a heavenly paradise of pleasure, where most of the Hindu Devatas (Deva) reside along with the king of Devas, Indra, and beatified mortals. Some other planes are Mahar Loka, Jana Loka, Tapa Loka and Satya Loka. Since heavenly abodes are also tied to the cycle of birth and death, any dweller of heaven or hell will again be recycled to a different plane and in a different form per the karma and "maya" i.e. the illusion of Samsara. This cycle is broken only by self-realization by the Jivatma. This self-realization is Moksha (Turiya, Kaivalya).

The concept of moksha is unique to Hinduism and is unparalleled. Moksha stands for liberation from the cycle of birth and death and final communion with Brahman. With moksha, a liberated soul attains the stature and oneness with Brahman or Paramatma. Different schools such as Vedanta, Mimansa, Sankhya, Nyaya, Vaisheshika, and Yoga offer subtle differences in the concept of Brahman, obvious Universe, its genesis and regular destruction, Jivatma, Nature (Prakriti) and also the right way in attaining perfect bliss or moksha.

In the Vaishnava traditions the highest heaven is Vaikuntha, which exists above the six heavenly lokas and outside of the mahat-tattva or mundane world. It's where eternally liberated souls who have attained moksha reside in eternal sublime beauty with Lakshmi and Narayana (a manifestation of Vishnu).

In the Nasadiya Sukta, the heavens/sky Vyoman is mentioned as a place from which an overseeing entity surveys what has been created. However, the Nasadiya Sukta questions the omniscience of this overseer.

The shape of the Universe as described in Jainism is shown alongside. Unlike the current convention of using North direction as the top of map, this uses South as the top. The shape is similar to a part of human form standing upright.

The "Deva Loka" (heavens) are at the symbolic "chest", where all souls enjoying the positive karmic effects reside. The heavenly beings are referred to as "devas" (masculine form) and "devis" (feminine form). According to Jainism, there is not one heavenly abode, but several layers to reward appropriately the souls of varying degree of karmic merits. Similarly, beneath the "waist" are the "Narka Loka" (hell). Human, animal, insect, plant and microscopic life forms reside on the middle.

The pure souls (who reached Siddha status) reside at the very south end (top) of the Universe. They are referred to in Tamil literature as தென்புலத்தார் (Kural 43).

As per Sikh thought, heaven and hell are not places for living hereafter, they are part of spiritual topography of man and do not exist otherwise. They refer to good and evil stages of life respectively and can be lived now and here during our earthly existence. For example, Bhagat Kabir rejects the otherworldly heaven in Guru Granth Sahib and says that one can experience heaven on this Earth by doing company of holy people.

The Nahua people such as the Aztecs, Chichimecs and the Toltecs believed that the heavens were constructed and separated into 13 levels. Each level had from one to many Lords living in and ruling these heavens. Most important of these heavens was Omeyocan (Place of Two). The Thirteen Heavens were ruled by Ometeotl, the dual Lord, creator of the Dual-Genesis who, as male, takes the name Ometecuhtli (Two Lord), and as female is named Omecihuatl (Two Lady).

In the creation myths of Polynesian mythology are found various concepts of the heavens and the underworld. These differ from one island to another. What they share is the view of the universe as an egg or coconut that is divided between the world of humans (earth), the upper world of heavenly gods, and the underworld. Each of these is subdivided in a manner reminiscent of Dante's Divine Comedy, but the number of divisions and their names differs from one Polynesian culture to another.

In Māori mythology, the heavens are divided into a number of realms. Different tribes number the heaven differently, with as few as two and as many as fourteen levels. One of the more common versions divides heaven thus:


The Māori believe these heavens are supported by pillars. Other Polynesian peoples see them being supported by gods (as in Hawaii). In one Tahitian legend, heaven is supported by an octopus.

The Polynesian conception of the universe and its division is nicely illustrated by a famous drawing made by a Tuomotuan chief in 1869. Here, the nine heavens are further divided into left and right, and each stage is associated with a stage in the evolution of the earth that is portrayed below. The lowest division represents a period when the heavens hung low over the earth, which was inhabited by animals that were not known to the islanders. In the third division is shown the first murder, the first burials, and the first canoes, built by Rata. In the fourth division, the first coconut tree and other significant plants are born.

It is believed in Theosophy of Helena Blavatsky that each religion (including Theosophy) has its own individual heaven in various regions of the upper astral plane that fits the description of that heaven that is given in each religion, which a soul that has been good in their previous life on Earth will go to. The area of the upper astral plane of Earth in the upper atmosphere where the various heavens are located is called "Summerland" (Theosophists believe hell is located in the lower astral plane of Earth which extends downward from the surface of the earth down to its center). However, Theosophists believe that the soul is recalled back to Earth after an average of about 1400 years by the "Lords of Karma" to incarnate again. The final heaven that souls go to billions of years in the future after they finish their cycle of incarnations is called "Devachan".

Anarchist Emma Goldman expressed this view when she wrote, "Consciously or unconsciously, most theists see in gods and devils, heaven and hell; reward and punishment, a whip to lash the people into obedience, meekness and contentment."

Some have argued that a belief in a reward after death is poor motivation for moral behavior while alive. Sam Harris wrote, "It is rather more noble to help people purely out of concern for their suffering than it is to help them because you think the Creator of the Universe wants you to do it, or will reward you for doing it, or will punish you for not doing it. The problem with this linkage between religion and morality is that it gives people bad reasons to help other human beings when good reasons are available."

In "Inside the Neolithic Mind" (2005), Lewis-Williams and Pearce argue that many cultures around the world and through history neurally perceive a tiered structure of heaven, along with similarly structured circles of hell. The reports match so similarly across time and space that Lewis-Williams and Pearce argue for a neuroscientific explanation, accepting the percepts as real neural activations and subjective percepts during particular altered states of consciousness.

Many people who come close to death and have near-death experiences report meeting relatives or entering "the Light" in an otherworldly dimension, which shares similarities with the religious concept of heaven. Even though there are also reports of distressing experiences and negative life-reviews, which share some similarities with the concept of hell, the positive experience of meeting or entering "the Light" is reported as an immensely intense feeling of a state of love, peace and joy beyond human comprehension. Together with this intensely positive-feeling state, people who have near-death experiences also report that consciousness or a heightened state of awareness seems as if it is at the heart of experiencing a taste of "heaven".

Works of fiction have included numerous different conceptions of Heaven and Hell. The two most famous descriptions of Heaven are given in Dante Alighieri's "Paradiso" (of the "Divine Comedy") and John Milton's "Paradise Lost".




</doc>
<doc id="13812" url="https://en.wikipedia.org/wiki?curid=13812" title="History of Libya">
History of Libya

Libya's history covers its rich mix of ethnic groups added to the indigenous Berber nomad tribes. Berbers have been present throughout the entire history of the country, from Berber in Somalia to Timbuktu in Mali, since th era of Numidians. For most of its history, Libya has been subjected to varying degrees of scholar control, from Europe, Asia, and Africa. The modern history of independent Libya, as reflected in the many revolutions denoted under many moons began before Romantic time or Justinian scribing. 

The history of Libya comprises six distinct perspectives: Ancient Libya, the Roman era, the Islamic era, Ottoman rule, Italian rule, and the Modern era.

Tens of thousands of years ago, the Sahara Desert, which now covers roughly 90% of Libya, was lush with green vegetation. It was home to lakes, forests, diverse wildlife and a temperate Mediterranean climate. Archaeological evidence indicates that the coastal plain was inhabited by Neolithic peoples from as early as 8000 BCE. These peoples were perhaps drawn by the climate, which enabled their culture to grow, subsisting on the domestication of cattle and the cultivation of crops.

Rock paintings at Wadi Mathendous and the mountainous region of Jebel Acacus are the best sources of information about prehistoric Libya, and the pastoralist culture that settled there. The paintings reveal that the Libyan Sahara contained rivers, grassy plateaus and an abundance of wildlife such as giraffes, elephants and crocodiles.

The onset of the Piora Oscillation's intense aridification resulted in the "green Sahara" rapidly transforming into the Sahara Desert. Dispersal in Africa from the Atlantic coast to the Siwa Oasis in Egypt seems to have followed, due to climatic changes which caused increasing desertification.

The African ancestors of the Berber people are assumed to have spread into the area by the Late Bronze Age. The earliest known name of such a tribe is that of the Garamantes, who were based in Germa, southern Libya. The Garamantes were a Saharan people of Berber origin who used an elaborate underground irrigation system; they were probably present as tribal people in the Fezzan by about 1000 BCE, and were a local power in the Sahara between 500 BCE and 500 CE. By the time of contact with the Phoenicians, the first of the Semitic civilizations to arrive in Libya from the East, the Lebu, Garamantes, Berbers and other tribes that lived in the Sahara were already well established.

The Phoenicians were some of the first to establish coastal trading posts in Libya, when the merchants of Tyre (in present-day Lebanon) developed commercial relations with the various Berber tribes and made treaties with them to ensure their cooperation in the exploitation of raw materials. By the 5th century BCE, the greatest of the Phoenician colonies, Carthage, had extended its hegemony across much of North Africa, where a distinctive civilization, known as Punic, came into being. Punic settlements on the Libyan coast included Oea (later Tripoli), Libdah (later Leptis Magna) and Sabratha. These cities were in an area that was later called Tripolis, or "Three Cities", from which Libya's modern capital Tripoli takes its name.

In 630 BCE, the Ancient Greeks colonized Eastern Libya and founded the city of Cyrene. Within 200 years, four more important Greek cities were established in the area that became known as Cyrenaica: Barce (later Marj); Euhesperides (later Berenice, present-day Benghazi); Taucheira (later Arsinoe, present-day Taucheria); Balagrae (later Bayda and Beda Littoria under Italian occupation, present-day Bayda); and Apollonia (later Susa), the port of Cyrene. Together with Cyrene, they were known as the Pentapolis (Five Cities). Cyrene became one of the greatest intellectual and artistic centers of the Greek world, and was famous for its medical school, learned academies, and architecture. The Greeks of the Pentapolis resisted encroachments by the Ancient Egyptians from the East, as well as by the Carthaginians from the West.

In 525 BCE the Persian army of Cambyses II overran Cyrenaica, which for the next two centuries remained under Persian or Egyptian rule. Alexander was greeted by the Greeks when he entered Cyrenaica in 331 BCE, and Eastern Libya again fell under the control of the Greeks, this time as part of the Ptolemaic Kingdom. Later, a federation of the Pentapolis was formed that was customarily ruled by a king drawn from the Ptolemaic royal house.

After the fall of Carthage the Romans did not occupy immediately Tripolitania (the region around Tripoli), but left it under control of the Berber kings of Numidia, until the coastal cities asked and obtained its protection. Ptolemy Apion, the last Greek ruler, bequeathed Cyrenaica to Rome, which formally annexed the region in 74 BCE and joined it to Crete as a Roman province. During the Roman civil wars Tripolitania (still not formally annexed) and Cyrenaica sustained Pompey and Marc Antony against respectively Caesar and Octavian. The Romans completed the conquest of the region under Augustus, occupying northern Fezzan ("Fasania") with Cornelius Balbus Minor. As part of the Africa Nova province, Tripolitania was prosperous, and reached a golden age in the 2nd and 3rd centuries, when the city of Leptis Magna, home to the Severan dynasty, was at its height. On the other side, Cyrenaica's first Christian communities were established by the time of the Emperor Claudius but was heavily devastated during the Kitos War and almost depopulated of Greeks and Jews alike, and, although repopulated by Trajan with military colonies, from then started its decadence.
Regardless, for more than 400 years Tripolitania and Cyrenaica were part of a cosmopolitan state whose citizens shared a common language, legal system, and Roman identity. Roman ruins like those of Leptis Magna and Sabratha, extant in present-day Libya, attest to the vitality of the region, where populous cities and even smaller towns enjoyed the amenities of urban life—the forum, markets, public entertainments, and baths—found in every corner of the Roman Empire. Merchants and artisans from many parts of the Roman world established themselves in North Africa, but the character of the cities of Tripolitania remained decidedly Punic and, in Cyrenaica, Greek. Tripolitania was a major exporter of olive oil, as well as a center for the trade of ivory and wild animals conveyed to the coast by the Garamantes, while Cyrenaica remained an important source of wines, drugs, and horses. The bulk of the population in the countryside consisted of Berber farmers, who in the west were thoroughly "romanized" in language and customs. Until the 10th century the African Romance remained in use in some Tripolitanian areas, mainly near the Tunisian border.

The decline of the Roman Empire saw the classical cities fall into ruin, a process hastened by the Vandals' destructive sweep though North Africa in the 5th century. The region's prosperity had shrunk under Vandal domination, and the old Roman political and social order, disrupted by the Vandals, could not be restored. In outlying areas neglected by the Vandals, the inhabitants had sought the protection of tribal chieftains and, having grown accustomed to their autonomy, resisted re-assimilation into the imperial system.

When the Empire returned (now as East Romans) as part of Justinian's reconquests of the 6th century, efforts were made to strengthen the old cities, but it was only a last gasp before they collapsed into disuse. Cyrenaica, which had remained an outpost of the Byzantine Empire during the Vandal period, also took on the characteristics of an armed camp. Unpopular Byzantine governors imposed burdensome taxation to meet military costs, while the towns and public services—including the water system—were left to decay. Byzantine rule in Africa did prolong the Roman ideal of imperial unity there for another century and a half however, and prevented the ascendancy of the Berber nomads in the coastal region. By the beginning of the 7th century, Byzantine control over the region was weak, Berber rebellions were becoming more frequent, and there was little to oppose Muslim invasion.

Tenuous Byzantine control over Libya was restricted to a few poorly defended coastal strongholds, and as such, the Arab horsemen who first crossed into the Pentapolis of Cyrenaica in September 643 CE encountered little resistance. Under the command of 'Amr ibn al-'As, the armies of Islam conquered Cyrenaica, and renamed the Pentapolis, Barqa. They took also Tripoli, but after destroying the Roman walls of the city and getting a tribute they withdrew. In 647 an army of 40,000 Arabs, led by Abdullah ibn Saad, the foster-brother of Caliph Uthman, penetrated deep into Western Libya and took Tripoli from the Byzantines definitively. From Barqa, the Fezzan (Libya's Southern region) was conquered by Uqba ibn Nafi in 663 and Berber resistance was overcome. During the following centuries Libya came under the rule of several Islamic dynasties, under various levels of autonomy from Ummayad, Abbasid and Fatimid caliphates of the time. Arab rule was easily imposed in the coastal farming areas and on the towns, which prospered again under Arab patronage. Townsmen valued the security that permitted them to practice their commerce and trade in peace, while the Punicized farmers recognized their affinity with the Semitic Arabs to whom they looked to protect their lands. In Cyrenaica, Monophysite adherents of the Coptic Church had welcomed the Muslim Arabs as liberators from Byzantine oppression. The Berber tribes of the hinterland accepted Islam, however they resisted Arab political rule.

For the next several decades, Libya was under the purview of the Ummayad Caliph of Damascus until the Abbasids overthrew the Ummayads in 750, and Libya came under the rule of Baghdad. When Caliph Harun al-Rashid appointed Ibrahim ibn al-Aghlab as his governor of Ifriqiya in 800, Libya enjoyed considerable local autonomy under the Aghlabid dynasty. The Aghlabids were among the most attentive Islamic rulers of Libya; they brought about a measure of order to the region, and restored Roman irrigation systems, which brought prosperity to the area from the agricultural surplus. By the end of the 9th century, the Shiite Fatimids controlled Western Libya from their capital in Mahdia, before they ruled the entire region from their new capital of Cairo in 972 and appointed Bologhine ibn Ziri as governor. During Fatimid rule, Tripoli thrived on the trade in slaves and gold brought from the Sudan and on the sale of wool, leather, and salt shipped from its docks to Italy in exchange for wood and iron goods. Ibn Ziri's Berber Zirid dynasty ultimately broke away from the Shiite Fatimids, and recognised the Sunni Abbasids of Baghdad as rightful Caliphs. In retaliation, the Fatimids brought about the migration of thousands from two troublesome Arab Bedouin tribes, the Banu Sulaym and Banu Hilal to North Africa. This act drastically altered the fabric of the Libyan countryside, and cemented the cultural and linguistic Arabisation of the region. Ibn Khaldun noted that the lands ravaged by Banu Hilal invaders had become completely arid desert.
Zirid rule in Tripolitania was short-lived though, and already in 1001 the Berbers of the Banu Khazrun broke away. Tripolitania remained under their control until 1146, when the region was overtaken by the Normans of Sicily. It was not until 1159 that the Moroccan Almohad leader Abd al-Mu'min reconquered Tripoli from European rule. For the next 50 years, Tripolitania was the scene of numerous battles between the Almohad rulers and insurgents of the Banu Ghaniya. Later, a general of the Almohads, Muhammad ibn Abu Hafs, ruled Libya from 1207 to 1221 before the later establishment of a Tunisian Hafsid dynasty independent from the Almohads. The Hafsids ruled Tripolitania for nearly 300 years, and established significant trade with the city-states of Europe. Hafsid rulers also encouraged art, literature, architecture and scholarship. Ahmad Zarruq was one of the most famous Islamic scholars to settle in Libya, and did so during this time. By the 16th century however, the Hafsids became increasingly caught up in the power struggle between Spain and the Ottoman Empire. After a successful invasion of Tripoli by Habsburg Spain in 1510, and its handover to the Knights of St. John, the Ottoman admiral Sinan Pasha finally took control of Libya in 1551.

After a successful invasion by the in the early 16th century, Charles V entrusted its defense to the Knights of St. John in Malta. Lured by the piracy that spread through the Maghreb coastline, adventurers such as Barbarossa and his successors consolidated Ottoman control in the central Maghreb. The Ottoman Turks conquered Tripoli in 1551 under the command of Sinan Pasha. In the next year his successor Turgut Reis was named the Bey of Tripoli and later Pasha of Tripoli in 1556. As Pasha, he adorned and built up Tripoli, making it one of the most impressive cities along the North African coast. By 1565, administrative authority as regent in Tripoli was vested in a "pasha" appointed directly by the "sultan" in Constantinople. In the 1580s, the rulers of Fezzan gave their allegiance to the sultan, and although Ottoman authority was absent in Cyrenaica, a "bey" was stationed in Benghazi late in the next century to act as agent of the government in Tripoli.

In time, real power came to rest with the pasha's corps of janissaries, a self-governing military guild, and in time the pasha's role was reduced to that of ceremonial head of state. Mutinies and coups were frequent, and in 1611 the "deys" staged a coup against the pasha, and Dey Sulayman Safar was appointed as head of government. For the next hundred years, a series of "deys" effectively ruled Tripolitania, some for only a few weeks, and at various times the dey was also pasha-regent. The regency governed by the dey was autonomous in internal affairs and, although dependent on the sultan for fresh recruits to the corps of janissaries, his government was left to pursue a virtually independent foreign policy as well. The two most important Deys were Mehmed Saqizli (r. 1631–49) and Osman Saqizli (r. 1649–72), both also Pasha, who ruled effectively the region. The latter conquered also Cyrenaica.
Tripoli was the only city of size in Ottoman Libya (then known as Tripolitania Eyalet) at the end of the 17th century and had a population of about 30,000. The bulk of its residents were Moors, as city-dwelling Arabs were then known. Several hundred Turks and renegades formed a governing elite, a large portion of which were "kouloughlis" (lit. sons of servants—offspring of Turkish soldiers and Arab women); they identified with local interests and were respected by locals. Jews and Moriscos were active as merchants and craftsmen and a small number of European traders also frequented the city. European slaves and large numbers of enslaved blacks transported from Sudan were also a feature of everyday life in Tripoli. In 1551, Turgut Reis enslaved almost the entire population of the Maltese island of Gozo, some 6,300 people, sending them to Libya. The most pronounced slavery activity involved the enslavement of black Africans who were brought via trans-Saharan trade routes. Even though the slave trade was officially abolished in Tripoli in 1853, in practice it continued until the 1890s.
Lacking direction from the Ottoman government, Tripoli lapsed into a period of military anarchy during which coup followed coup and few deys survived in office more than a year. One such coup was led by Turkish officer Ahmed Karamanli. The Karamanlis ruled from 1711 until 1835 mainly in Tripolitania, but had influence in Cyrenaica and Fezzan as well by the mid 18th century. Ahmed was a Janissary and popular cavalry officer. He murdered the Ottoman Dey of Tripolitania and seized the throne in 1711. After persuading Sultan Ahmed III to recognize him as governor, Ahmed established himself as pasha and made his post hereditary. Though Tripolitania continued to pay nominal tribute to the Ottoman padishah, it otherwise acted as an independent kingdom. Ahmed greatly expanded his city's economy, particularly through the employment of corsairs (pirates) on crucial Mediterranean shipping routes; nations that wished to protect their ships from the corsairs were forced to pay tribute to the pasha. Ahmad's successors proved to be less capable than himself, however, the region's delicate balance of power allowed the Karamanli to survive several dynastic crises without invasion. The Libyan Civil War of 1791–1795 occurred in those years. In 1793, Turkish officer Ali Benghul deposed Hamet Karamanli and briefly restored Tripolitania to Ottoman rule. However, Hamet's brother Yusuf (r. 1795–1832) reestablished Tripolitania's independence.

In the early 19th century war broke out between the United States and Tripolitania, and a series of battles ensued in what came to be known as the First Barbary War and the Second Barbary War. By 1819, the various treaties of the Napoleonic Wars had forced the Barbary states to give up piracy almost entirely, and Tripolitania's economy began to crumble. As Yusuf weakened, factions sprung up around his three sons; though Yusuf abdicated in 1832 in favor of his son Ali II, civil war soon resulted. Ottoman Sultan Mahmud II sent in troops ostensibly to restore order, but instead deposed and exiled Ali II, marking the end of both the Karamanli dynasty and an independent Tripolitania. Anyway, order was not recovered easily, and the revolt of the Libyan under Abd-El-Gelil and Gûma ben Khalifa lasted until the death of the latter in 1858.

The second period of direct Ottoman rule saw administrative changes, and what seemed as greater order in the governance of the three provinces of Libya. It would not be long before the Scramble for Africa and European colonial interests set their eyes on the marginal Turkish provinces of Libya. Reunification came about through the unlikely route of an invasion (Italo-Turkish War, 1911–1912) and occupation starting from 1911 when Italy simultaneously turned the three regions into colonies.

From 1912 to 1927, the territory of Libya was known as Italian North Africa. From 1927 to 1934, the territory was split into two colonies, Italian Cyrenaica and Italian Tripolitania, run by Italian governors. Some 150,000 Italians settled in Libya, constituting roughly 20% of the total population.
In 1934, Italy adopted the name "Libya" (used by the Greeks for all of North Africa, except Egypt) as the official name of the colony (made up of the three provinces of Cyrenaica, Tripolitania and Fezzan). Idris al-Mahdi as-Senussi (later King Idris I), Emir of Cyrenaica, led Libyan resistance to Italian occupation between the two world wars.
Ilan Pappé estimates that between 1928 and 1932 the Italian military "killed half the Bedouin population (directly or through disease and starvation in camps)." Italian historian Emilio Gentile sets to about 50,000 the number of victims of the repression.

In 1934, the political entity called "Libya" was created by governor Balbo with capital Tripoli. The Italians emphasized infrastructure improvements and public works. In particular, they hugely expanded Libyan railway and road networks from 1934 to 1940, building hundreds of kilometers of new roads and railways and encouraging the establishment of new industries and dozen of new agricultural villages.

During WW2, since June 1940 Libya was at the center of destructive fighting between the Axis and the British empire: the Allies conquered from Italy all of Libya only by February 1943.

From 1943 to 1951, Tripolitania and Cyrenaica were under British administration, while the French controlled Fezzan. In 1944, Idris returned from exile in Cairo but declined to resume permanent residence in Cyrenaica until the removal of some aspects of foreign control in 1947. Under the terms of the 1947 peace treaty with the Allies, Italy relinquished all claims to Libya.

On 21 November 1949, the UN General Assembly passed a resolution stating that Libya should become independent before 1 January 1952. Idris represented Libya in the subsequent UN negotiations. On 24 December 1951, Libya declared its independence as the United Kingdom of Libya, a constitutional and hereditary monarchy under King Idris, Libya's only monarch.

1951 also saw the enactment of the first Libyan Constitution. The Libyan National Assembly drafted the Constitution and passed a resolution accepting it in a meeting held in the city of Benghazi on Sunday, 6th Muharram, Hegiras 1371: 7 October 1951. Mohamed Abulas’ad El-Alem, President of the National Assembly and the two Vice-Presidents of the National Assembly, Omar Faiek Shennib and Abu Baker Ahmed Abu Baker executed and submitted the Constitution to King Idris following which it was published in the Official Gazette of Libya.

The enactment of the Libyan Constitution was significant in that it was the first piece of legislation to formally entrench the rights of Libyan citizens following the post-war creation of the Libyan nation state. Following on from the intense UN debates during which Idris had argued that the creation of a single Libyan state would be of benefit to the regions of Tripolitania, Fezzan, and Cyrenaica, the Libyan government was keen to formulate a constitution which contained many of the entrenched rights common to European and North American nation states. Though not creating a secular state – Article 5 proclaims Islam the religion of the State – the Libyan Constitution did formally set out rights such as equality before the law as well as equal civil and political rights, equal opportunities, and an equal responsibility for public duties and obligations, "without distinction of religion, belief, race, language, wealth, kinship or political or social opinions" (Article 11).

During this period, Britain was involved in extensive engineering projects in Libya and was also the country's biggest supplier of arms. The United States also maintained the large Wheelus Air Base in Libya.

On 1 September 1969, a small group of military officers led by 27-year-old army officer Muammar Gaddafi staged a coup d'état against King Idris, launching the Libyan Revolution. Gaddafi was referred to as the "Brother Leader and Guide of the Revolution" in government statements and the official Libyan press.
On the birthday of Muhammad in 1973, Gaddafi delivered a "Five-Point Address". He announced the suspension of all existing laws and the implementation of Sharia. He said that the country would be purged of the "politically sick". A "people's militia" would "protect the revolution". There would be an administrative revolution, and a cultural revolution. Gaddafi set up an extensive surveillance system. 10 to 20 percent of Libyans worked in surveillance for the Revolutionary committees, which monitored place in government, in factories, and in the education sector. Gaddafi executed dissidents publicly and the executions were often rebroadcast on state television channels. Gaddafi employed his network of diplomats and recruits to assassinate dozens of critical refugees around the world. Amnesty International listed at least 25 assassinations between 1980 and 1987.
In 1977, Libya officially became the "Great Socialist People's Libyan Arab Jamahiriya". Gaddafi officially passed power to the General People's Committees and henceforth claimed to be no more than a symbolic figurehead, but domestic and international critics claimed the reforms gave him virtually unlimited power. Dissidents against the new system were not tolerated, with punitive actions including capital punishment authorized by Gaddafi himself. The new ""jamahiriya"" governance structure he established was officially referred to as a form of direct democracy, though the government refused to publish election results. Later that same year, Libya and Egypt fought a four-day border war that came to be known as the Libyan-Egyptian War, both nations agreed to a ceasefire under the mediation of the Algerian president Houari Boumediène. In February 1977, Libya began to provide military supplies to Goukouni Oueddei and the People's Armed Forces in Chad. The Chadian–Libyan conflict began in earnest when Libya's support of rebel forces in northern Chad escalated into an invasion. Much of the country's income from oil, which soared in the 1970s, was spent on arms purchases and on sponsoring dozens of rebels groups around the world. An airstrike failed to kill Gaddafi in 1986. Libya was accused in the 1988 bombing of Pan Am Flight 103 over Lockerbie, Scotland and the 1989 bombing of UTA Flight 772 over Chad and Niger; Libya was finally put under United Nations sanctions in 1992. Gaddafi financed various other groups from anti-nuclear movements to Australian trade unions.

From 1977 onward, per capita income in the country rose to more than US$11,000, the fifth-highest in Africa, while the Human Development Index became the highest in Africa and greater than that of Saudi Arabia. This was achieved without borrowing any foreign loans, keeping Libya debt-free. In addition, the country's literacy rate rose from 10% to 90%, life expectancy rose from 57 to 77 years, employment opportunities were established for migrant workers, and welfare systems were introduced that allowed access to free education, free healthcare, and financial assistance for housing. The Great Manmade River was also built to allow free access to fresh water across large parts of the country. In addition, financial support was provided for university scholarships and employment programs.

Gaddafi doubled the minimum wage, introduced statutory price controls, and implemented compulsory rent reductions of between 30 and 40%. Gaddafi also wanted to combat the strict social restrictions that had been imposed on women by the previous regime, establishing the Revolutionary Women's Formation to encourage reform. In 1970, a law was introduced affirming equality of the sexes and insisting on wage parity. In 1971, Gaddafi sponsored the creation of a Libyan General Women's Federation. In 1972, a law was passed criminalizing the marriage of any females under the age of sixteen and ensuring that a woman's consent was a necessary prerequisite for a marriage.

Gaddafi assumed the honorific title of "King of Kings of Africa" in 2008 as part of his campaign for a United States of Africa. By the early 2010s, in addition to attempting to assume a leadership role in the African Union, Libya was also viewed as having formed closer ties with Italy, one of its former colonial rulers, than any other country in the European Union. The eastern parts of the country have been "ruined" due to Gaddafi's economic theories, according to "The Economist".

After popular movements overturned the rulers of Tunisia and Egypt, its immediate neighbors to the west and east, Libya experienced a full-scale revolt beginning on 17 February 2011. By 20 February, the unrest had spread to Tripoli. In the early hours of 21 February 2011, Saif al-Islam Gaddafi, oldest son of Muammar Gaddafi, spoke on Libyan television of his fears that the country would fragment and be replaced by "15 Islamic fundamentalist emirates" if the uprising engulfed the entire state. He admitted that "mistakes had been made" in quelling recent protests and announced plans for a constitutional convention, but warned that the country's economic wealth and recent prosperity was at risk and warned of "rivers of blood" if the protests continued.

On 27 February 2011, the National Transitional Council was established under the stewardship of Mustafa Abdul Jalil, Gaddafi's former justice minister, to administer the areas of Libya under rebel control. This marked the first serious effort to organize the broad-based opposition to the Gaddafi regime. While the council was based in Benghazi, it claimed Tripoli as its capital. Hafiz Ghoga, a human rights lawyer, later assumed the role of spokesman for the council. On 10 March 2011, France became the first state to officially recognise the council as the legitimate representative of the Libyan people.

By early March 2011, some parts of Libya had tipped out of Gaddafi's control, coming under the control of a coalition of opposition forces, including soldiers who decided to support the rebels. Eastern Libya, centred on the port city of Benghazi, was said to be firmly in the hands of the opposition, while Tripoli and its environs remained in dispute. Pro-Gaddafi forces were able to respond militarily to rebel pushes in Western Libya and launched a counterattack along the coast toward Benghazi, the "de facto" centre of the uprising. The town of Zawiya, from Tripoli, was bombarded by air force planes and army tanks and seized by Jamahiriya troops, "exercising a level of brutality not yet seen in the conflict."

In several public appearances, Gaddafi threatened to destroy the protest movement, and Al Jazeera and other agencies reported his government was arming pro-Gaddafi militiamen to kill protesters and defectors against the regime in Tripoli. Organs of the United Nations, including United Nations Secretary General Ban Ki-moon and the United Nations Human Rights Council, condemned the crackdown as violating international law, with the latter body expelling Libya outright in an unprecedented action urged by Libya's own delegation to the UN. The United States imposed economic sanctions against Libya, followed shortly by Australia, Canada and the United Nations Security Council, which also voted to refer Gaddafi and other government officials to the International Criminal Court for investigation.

On 17 March 2011 the UN Security Council passed Resolution 1973 with a 10–0 vote and five abstentions. The resolution sanctioned the establishment of a no-fly zone and the use of "all means necessary" to protect civilians within Libya.

Shortly afterwards, Libyan Foreign Minister Moussa Koussa stated that "Libya has decided an immediate ceasefire and an immediate halt to all military operations".

On 19 March, the first Allied act to secure the no-fly zone began when French military jets entered Libyan airspace on a reconnaissance mission heralding attacks on enemy targets. Allied military action to enforce the ceasefire commenced the same day when a French aircraft opened fire and destroyed a vehicle on the ground. French jets also destroyed five tanks belonging to the Gaddafi regime. The United States and United Kingdom launched attacks on over 20 "integrated air defense systems" using more than 110 Tomahawk cruise missiles during operations Odyssey Dawn and Ellamy.

On 27 June 2011, the International Criminal Court issued an arrest warrant for Gaddafi, alleging that Gaddafi had been personally involved in planning and implementing "a policy of widespread and systematic attacks against civilians and demonstrators and dissidents".
By 22 August 2011, rebel fighters had entered Tripoli and occupied Green Square, which they renamed to its original name, Martyrs' Square in honour of those killed during the Italian occupation. Meanwhile, Gaddafi asserted that he was still in Libya and would not concede power to the rebels.

On 16 September 2011, the U.N. General Assembly approved a request from the National Transitional Council to accredit envoys of the country's interim controlling body as Tripoli's sole representatives at the UN, effectively recognising the National Transitional Council as the legitimate holder of that country's UN seat.

The National Transitional Council had been plagued by internal divisions during its tenure as Libya's interim governing authority. It postponed the formation of a caretaker, or "interim" government on several occasions during the period prior to the death of Muammar Gaddafi in his hometown of Sirte on 20 October 2011. Mustafa Abdul Jalil led the National Transitional Council and was generally considered to be the principal leadership figure. Mahmoud Jibril served as the NTC's "de facto" head of government from 5 March 2011 through the end of the war, but he announced he would resign after Libya was declared to have been "liberated" from Gaddafi's rule.

The "liberation" of Libya was celebrated on 23 October 2011, and Jibril announced that consultations were under way to form an interim government within one month, followed by elections for a constitutional assembly within eight months and parliamentary and presidential elections to be held within a year after that. He stepped down as expected the same day and was succeeded by Ali Tarhouni. At least 30,000 Libyans died in the civil war.

After the Libyan Civil War, the National Transitional Council (NTC) has been responsible for the transition of the administration of the governing of Libya. The "liberation" of Libya was celebrated on 23 October 2011. Then Jibril announced that consultations were under way to form an interim government within one month, followed by elections for a constitutional assembly within eight months and parliamentary and presidential elections to be held within a year after that. He stepped down as expected the same day and was succeeded by Ali Tarhouni.

On 24 November, Tarhouni was replaced by Abdurrahim El-Keib. El-Keib formed a provisional government, filling it with independent or CNT politicians, including women.

After the fall of Gaddhafi, Libya has been faced with internal struggles. A protest started against the new regime of NTC. The loyalists of Gaddhafi rebelled and fought with the new Libyan army.

Because the Constitutional Declaration allowed a multi-party system, the political parties, like Democratic Party, Party of Reform and Development, National Gathering for Freedom, Justice and Development appeared. The Islamist movement started. To stop it, the CNT (NTC) government denied power to parties based on religion, tribal and ethnic bases.

On 7 July 2012, Libyans voted in their first parliamentary elections since the end of Gaddafi's rule. The election, in which more than 100 political parties registered, formed an interim 200-member national assembly. This will replace the unelected National Transitional Council, name a prime minister, and form a committee to draft a constitution. The vote was postponed several times to resolve logistical and technical problems, and to give more time to register to vote, and to investigate candidates.

On 8 August 2012, the National Transitional Council officially handed power to the wholly elected General National Congress, which is tasked with the formation of an interim government and the drafting of a new Libyan Constitution to be approved in a general referendum.

On 25 August 2012, in what "appears to be the most blatant sectarian attack" since the end of the civil war, unnamed organized assailants bulldozed a Sufi mosque with graves, in broad daylight in the center of the Libyan capital Tripoli. It was the second such razing of a Sufi site in two days.

On 7 October 2012, Libya's Prime Minister-elect Mustafa A.G. Abushagur stepped down after failing a second time to win parliamentary approval for a new cabinet. On 14 October 2012, the General National Congress elected former GNC member and human rights lawyer Ali Zeidan as prime minister-designate.

Libyan Constitutional Assembly elections took place in Libya on 20 February 2014. 
Ali Zidan was ousted by the parliament committee and fled from Libya on 14 March 2014 after rogue oil tanker Morning Glory left the rebel port of Sidra, Libya with Libyan oil that had been confiscated by the rebels. Ali Zeidan had promised to stop the departure, but failed.

On 30 March 2014 General National Congress voted to replace itself with new House of Representatives.

Abdullah al-Thani served as the prime minister since 11 March 2014 in interim capacity. He resigned on 13 April 2014, after he and his family were victims of a "traitorous attack" but continued to remain prime minister since there was no replacement.Ahmed Maiteeq was elected Prime Minister of Libya in May 2014 but his election as prime minister took place under disputed circumstances, Libyan Supreme Court ruled on 9 June that Maiteeq's appointment was illegal and Maiteeq resigned the same day.

, the parliament building was reported to heve been stormed by troops loyal to General Khalifa Haftar, reportedly including the Zintan Brigade, in what the Libyan government described as an attempted coup.

House of Representatives elections were held in Libya on 25 June 2014.

On 14 July, the United States Support Mission in Libya evacuated its staff after 13 people were killed in clashes in Tripoli and Benghazi. The fighting, between government forces and rival militia groups, also forced Tripoli International Airport to close. A militia, including members of the Libya Revolutionaries Operations Room (LROR), tried to seize control of the airport from the Zintan militia, which has controlled it since Gaddafi was toppled. Both militias are believed to be on the official payroll. In addition Misrata Airport was closed, due to its dependence on Tripoli International Airport for its operations. Government spokesman, Ahmed Lamine, stated that approximately 90% of the planes stationed at Tripoli International Airport were destroyed or made inoperable in the attack, and that the government may make an appeal for international forces to assist in reestablishing security.





</doc>
<doc id="13813" url="https://en.wikipedia.org/wiki?curid=13813" title="History of Afghanistan">
History of Afghanistan

The history of Afghanistan (, '; ,') as a state began in 1747 with its establishment by Ahmad Shah Durrani. The written recorded history of the land presently constituting Afghanistan can be traced back to around 500 BCE when the area was under the Achaemenid Empire, although evidence indicates that an advanced degree of urbanized culture has existed in the land since between 3000 and 2000 BCE. Bactria dates back to 2500 BC. The Indus Valley Civilisation stretched up to large parts of Afghanistan in the north. Alexander the Great and his Macedonian army arrived at what is now Afghanistan in 330 BCE after the fall of the Achaemenid Empire during the Battle of Gaugamela. Since then, many empires have risen from Afghanistan, including the Greco-Bactrians, Kushans, Hephthalites, Saffarids, Samanids, Ghaznavids, Ghorids, Khaljis, Timurids, Mughals, Hotakis and Durranis.

Afghanistan (meaning "land of the Afghans" or "Pashtun land") has been a strategically important location throughout history. The land served as "a gateway to India, impinging on the ancient Silk Road, which carried trade from the Mediterranean to China". Sitting on many trade and migration routes, Afghanistan may be called the 'Central Asian roundabout' since routes converge from the Middle East, from the Indus Valley through the passes over the Hindu Kush, from the Far East via the Tarim Basin, and from the adjacent Eurasian Steppe.

The Iranian languages were developed by one branch of these people; the Pashto language spoken today in Afghanistan is one of the Eastern Iranian languages. Elena E. Kuz'mina argues that the tents of Iranian-speaking nomads of Afghanistan developed from the light surface houses of the Eurasian steppe belt in the Bronze Age.
Mirwais Hotak followed by Ahmad Shah Durrani unified Afghan tribes and founded the last Afghan Empire in the early 18th century CE. Afghanistan is inhabited by many and diverse peoples: the Pashtuns, Tajiks, Hazaras, Uzbeks, Turkmen, Aimak, Pashayi, Baloch, Pamiris, Nuristanis, and others.

Excavations of prehistoric sites by Louis Dupree and others at Darra-e Kur in 1966 where 800 stone implements were recovered along with a fragment of Neanderthal right temporal bone, suggest that early humans were living in what is now Afghanistan at least 52,000 years ago. A cave called Kara Kamar contained Upper Paleolithic blades Carbon-14 dated at 34,000 years old. Farming communities in Afghanistan were among the earliest in the world. Artifacts indicate that the indigenous people were small farmers and herdsmen, very probably grouped into tribes, with small local kingdoms rising and falling through the ages. Urbanization may have begun as early as 3000 BCE. Zoroastrianism predominated as the religion in the area; even the modern Afghan solar calendar shows the influence of Zoroastrianism in the names of the months. Other religions such as Buddhism and Hinduism flourished later, leaving a major mark in the region. Gandhara is the name of an ancient kingdom from the Vedic period and its capital city located between the Hindukush and Sulaiman Mountains (mountains of Solomon), although Kandahar in modern times and the ancient Gandhara are not geographically identical.

Early inhabitants, around 3000 BCE were likely to have been connected through culture and trade to neighboring civilizations like Jiroft and Tappeh Sialk and the Indus Valley Civilization. Urban civilization may have begun as early as 3000 BCE and it is possible that the early city of Mundigak (near Kandahar) was a colony of the nearby Indus Valley Civilization. The first known people were Indo-Iranians, but their date of arrival has been estimated widely from as early as about 3000 BCE to 1500 BCE. (For further detail see Indo-Aryan migration.)

The Indus Valley Civilization (IVC) was a Bronze Age civilization (3300-1300 BCE; mature period 2600–1900 BCE) extending from present-day northwest Pakistan to present-day northwest India and present-day northeast Afghanistan. An Indus Valley site has been found on the Oxus River at Shortugai in northern Afghanistan. Apart from Shortughai, Mundigak is another known site. There are several other smaller IVC sites to be found in Afghanistan as well.

The Bactria-Margiana Archaeological Complex became prominent in the southwest region between 2200 and 1700 BCE (approximately). The city of Balkh (Bactra) was founded about this time (c. 2000–1500 BCE). It is possible that the BMAC may have been an Indo-European culture, perhaps the Proto-Indo-Aryans. But the standard model holds the arrival of Indo-Aryans to have been in the Late Harappan which gave rise to the Vedic civilization of the Early Iron Age.

There have been many different opinions about the extent of the Median kingdom. For instance, according to Ernst Herzfeld, it was a powerful empire, which stretched from central Anatolia to Bactria, to around the borders of nowadays India. On the other side, Heleen Sancisi-Weerdenburg insists that there is no real evidence about the very existence of the Median empire and that it was an unstable state formation. Nevertheless, the region of nowadays Afghanistan came under Median rule for a short time.

Afghanistan fell to the Achaemenid Empire after it was conquered by Darius I of Persia. The area was divided into several provinces called satrapies, which were each ruled by a governor, or satrap. These ancient satrapies included: Aria: The region of Aria was separated by mountain ranges from the Paropamisadae in the east, Parthia in the west and Margiana and Hyrcania in the north, while a desert separated it from Carmania and Drangiana in the south. It is described in a very detailed manner by Ptolemy and Strabo and corresponds, according to that, almost to the Herat Province of today's Afghanistan; Arachosia, corresponds to the modern-day Kandahar, Lashkar Gah, and Quetta. Arachosia bordered Drangiana to the west, Paropamisadae (i.e. Gandahara) to the north and to the east, and Gedrosia to the south. The inhabitants of Arachosia were Iranian peoples, referred to as Arachosians or Arachoti. It is assumed that they were called "Paktyans" by ethnicity, and that name may have been in reference to the ethnic "Paṣtun" (Pashtun) tribes; Bactriana was the area north of the Hindu Kush, west of the Pamirs and south of the Tian Shan, with the Amu Darya flowing west through the center (Balkh); Sattagydia was the easternmost regions of the Achaemenid Empire, part of its Seventh tax district according to Herodotus, along with Gandārae, Dadicae and Aparytae. It is believed to have been situated east of the Sulaiman Mountains up to the Indus River in the basin around Bannu.[ (Ghazni); and Gandhara which corresponds to modern day Kabul, Jalalabad, and Peshawar.

Alexander the Great arrived in the area of Afghanistan in 330 BCE after defeating Darius III of Persia a year earlier at the Battle of Gaugamela. His army faced very strong resistance in the Afghan tribal areas where he is said to have commented that Afghanistan is "easy to march into, hard to march out of." Although his expedition through Afghanistan was brief, Alexander left behind a Hellenic cultural influence that lasted several centuries. Several great cities were built in the region named "Alexandria," including: Alexandria-of-the-Arians (modern-day Herat); Alexandria-on-the-Tarnak (near Kandahar); Alexandria-ad-Caucasum (near Begram, at Bordj-i-Abdullah); and finally, Alexandria-Eschate (near Kojend), in the north. After Alexander's death, his loosely connected empire was divided. Seleucus, a Macedonian officer during Alexander's campaign, declared himself ruler of his own Seleucid Empire, which also included present-day Afghanistan.

The Greco-Bactrian Kingdom was a Hellenistic kingdom, founded when Diodotus I, the satrap of Bactria (and probably the surrounding provinces) seceded from the Seleucid Empire around 250 BCE.

The Greco-Bactria Kingdom continued until c. 130 BCE, when Eucratides I's son, King Heliocles I, was defeated and driven out of Bactria by the Yuezhi tribes from the east. The Yeuzhi now had complete occupation of Bactria. It is thought that Eucratides' dynasty continued to rule in Kabul and Alexandria of the Caucasus until 70 BCE when King Hermaeus was also defeated by the Yuezhi.

One of Demetrius I's successors, Menander I, brought the Indo-Greek Kingdom (now isolated from the rest of the Hellenistic world after the fall of Bactria) to its height between 165–130 BCE, expanding the kingdom in Afghanistan and Pakistan to even larger proportions than Demetrius. After Menander's death, the Indo-Greeks steadily declined and the last Indo-Greek kings (Strato II and Strato III) were defeated in c. 10 CE. The Indo-Greek Kingdom was succeeded by the Indo-Scythians.

The territory fell to the Mauryan Empire, which was led by Chandragupta Maurya. The Mauryas introduced Hinduism and Buddhism to the region, and were planning to capture more territory of Central Asia until they faced local Greco-Bactrian forces. Seleucus is said to have reached a peace treaty with Chandragupta by giving control of the territory south of the Hindu Kush to the Mauryas upon intermarriage and 500 elephants.

Having consolidated power in the northwest, Chandragupta pushed east towards the Nanda Empire. Afghanistan's significant ancient tangible and intangible Buddhist heritage is recorded through wide-ranging archeological finds, including religious and artistic remnants. Buddhist doctrines are reported to have reached as far as Balkh even during the life of the Buddha (563 BCE to 483 BCE), as recorded by Husang Tsang.

The Indo-Scythians were descended from the Sakas (Scythians) who migrated from southern Siberia to Pakistan and Arachosia from the middle of the 2nd century BCE to the 1st century BCE. They displaced the Indo-Greeks and ruled a kingdom that stretched from Gandhara to Mathura. The power of the Saka rulers started to decline in the 2nd century CE after the Scythians were defeated by the south Indian Emperor Gautamiputra Satakarni of the Satavahana dynasty. Later the Saka kingdom was completely destroyed by Chandragupta II of the Gupta Empire from eastern India in the 4th century.

The Indo-Parthian Kingdom was ruled by the Gondopharid dynasty, named after its eponymous first ruler Gondophares. They ruled parts of present-day Afghanistan, Pakistan, and northwestern India, during or slightly before the 1st century AD. For most of their history, the leading Gondopharid kings held Taxila (in the present Punjab province of Pakistan) as their residence, but during their last few years of existence the capital shifted between Kabul and Peshawar. These kings have traditionally been referred to as Indo-Parthians, as their coinage was often inspired by the Arsacid dynasty, but they probably belonged to a wider groups of Iranic tribes who lived east of Parthia proper, and there is no evidence that all the kings who assumed the title "Gondophares", which means ”Holder of Glory”, were even related. Christian writings claim that the Apostle Saint Thomas – an architect and skilled carpenter – had a long sojourn in the court of king Gondophares, had built a palace for the king at Taxila and had also ordained leaders for the Church before leaving for the Indus Valley in a chariot, for sailing out to eventually reach Malabar Coast.

The Kushan Empire expanded out of Bactria (Central Asia) into the northwest of the subcontinent under the leadership of their first emperor, Kujula Kadphises, about the middle of the 1st century CE. They came from an Indo-European language speaking Central Asian tribe called the Yuezhi, a branch of which was known as the Kushans. By the time of his grandson, Kanishka the Great, the empire spread to encompass much of Afghanistan, and then the northern parts of the Indian subcontinent at least as far as Saketa and Sarnath near Varanasi (Benares).

Emperor Kanishka was a great patron of Buddhism; however, as Kushans expanded southward, the deities of their later coinage came to reflect its new Hindu majority.

They played an important role in the establishment of Buddhism in the Indian subcontinent and its spread to Central Asia and China.

Historian Vincent Smith said about Kanishka:

The empire linked the Indian Ocean maritime trade with the commerce of the Silk Road through the Indus valley, encouraging long-distance trade, particularly between China and Rome. The Kushans brought new trends to the budding and blossoming Gandhara Art, which reached its peak during Kushan Rule.

H.G. Rowlinson commented:

By the 3rd century, their empire in India was disintegrating and their last known great emperor was Vasudeva I.

After the Kushan Empire's rule was ended by Sassanids— officially known as the Empire of Iranians— was the last kingdom of the Persian Empire before the rise of Islam. Named after the House of Sasan, it ruled from 224 BC to 651 AD. In the east around 325, Shapur II regained the upper hand against the Kushano-Sasanian Kingdom and took control of large territories in areas now known as Afghanistan and Pakistan. Much of modern-day Afghanistan became part of the Sasanian Empire, since Shapur I extended his authority eastwards into Afghanistan and the previously autonomous Kushans were obliged to accept his suzerainty.

From around 370, however, towards the end of the reign of Shapur II, the Sassanids lost the control of Bactria to invaders from the north. These were the Kidarites, the Hephthalites, the Alchon Huns, and the Nezaks: The four Huna tribes to rule Afghanistan. These invaders initially issued coins based on Sasanian designs.

The Hunas were peoples who were of a group of Central Asian tribes. Four of the Huna tribe conquered and ruled Afghanistan: the Kidarites, Hepthalites, Alchon Huns and the Nezaks.

The Kidarites were a nomadic clan, the first of the four Huna people in Afghanistan. They are supposed to have originated in Western China and arrived in Bactria with the great migrations of the second half of the 4th century.

The Alchons are one of the four Huna people that ruled in Afghanistan. A group of Central Asian tribes, Hunas or Huna, via the Khyber Pass, entered India at the end of the 5th or early 6th century and successfully occupied areas as far as Eran and Kausambi, greatly weakening the Gupta Empire. The 6th-century Roman historian Procopius of Caesarea (Book I. ch. 3), related the Huns of Europe with the Hephthalites or "White Huns" who subjugated the Sassanids and invaded northwestern India, stating that they were of the same stock, "in fact as well as in name", although he contrasted the Huns with the Hephthalites, in that the Hephthalites were sedentary, white-skinned, and possessed "not ugly" features.
Song Yun and Hui Zheng, who visited the chief of the Hephthalite nomads at his summer residence in Badakshan and later in Gandhara, observed that they had no belief in the Buddhist law and served a large number of divinities."

The Hephthalites (or Ephthalites), also known as the White Huns and one of the four Huna people in Afghanistan, were a nomadic confederation in Central Asia during the late antiquity period. The White Huns established themselves in modern-day Afghanistan by the first half of the 5th century. Led by the Hun military leader Toramana, they overran the northern region of Pakistan and North India. Toramana's son Mihirakula, a Saivite Hindu, moved up to near Pataliputra to the east and Gwalior to central India. Hiuen Tsiang narrates Mihirakula's merciless persecution of Buddhists and destruction of monasteries, though the description is disputed as far as the authenticity is concerned. The Huns were defeated by the Indian kings Yasodharman of Malwa and Narasimhagupta in the 6th century. Some of them were driven out of India and others were assimilated in the Indian society.

The Nezaks are one of the four Huna people that ruled in Afghanistan.

From the Middle Ages to around 1750, Afghanistan was part of Iran. Two of the four main capitals of Khorasan (Balkh and Herat) are now located in Afghanistan. The countries of Kandahar, Ghazni and Kabul formed the frontier region between Khorasan and the Indus. This land, inhabited by the Afghan tribes (i.e. ancestors of Pashtuns), was called Afghanistan, which loosely covered a wide area between the Hindu Kush and the Indus River, principally around the Sulaiman Mountains. The earliest record of the name ""Afghan"" (""Abgân"") being mentioned is by Shapur I of the Sassanid Empire during the 3rd century CE which is later recorded in the form of ""Avagānā"" by the Vedic astronomer Varāha Mihira in his 6th century CE Brihat-samhita. It was used to refer to a common legendary ancestor known as ""Afghana"", grandson of King Saul of Israel. Hiven Tsiang, a Chinese pilgrim, visiting the Afghanistan area several times between 630 and 644 CE also speaks about them. Ancestors of many of today's Turkic-speaking Afghans settled in the Hindu Kush area and began to assimilate much of the culture and language of the Pashtun tribes already present there. Among these were the Khalaj people which are known today as Ghilzai.

The Kabul Shahi dynasties ruled the Kabul Valley and Gandhara from the decline of the Kushan Empire in the 3rd century to the early 9th century. The Shahis are generally split up into two eras: the Buddhist Shahis and the Hindu Shahis, with the change-over thought to have occurred sometime around 870. The kingdom was known as the Kabul Shahan or Ratbelshahan from 565–670, when the capitals were located in Kapisa and Kabul, and later Udabhandapura, also known as Hund for its new capital.

The Hindu Shahis under Rajput ruler Jayapala, is known for his struggles in defending his kingdom against the Ghaznavids in the modern-day eastern Afghanistan region. Jayapala saw a danger in the consolidation of the Ghaznavids and invaded their capital city of Ghazni both in the reign of Sebuktigin and in that of his son Mahmud, which initiated the Muslim Ghaznavid and Hindu Shahi struggles. Sebuktigin, however, defeated him, and he was forced to pay an indemnity. Jayapala defaulted on the payment and took to the battlefield once more. Jayapala however, lost control of the entire region between the Kabul Valley and Indus River.

Before his struggle began Jaipal had raised a large army of Punjabi Hindus. When Jaipal went to the Punjab region, his army was raised to 100,000 horsemen and an innumerable host of foot soldiers. According to Ferishta: 

However, the army was hopeless in battle against the western forces, particularly against the young Mahmud of Ghazni. In the year 1001, soon after Sultan Mahmud came to power and was occupied with the Qarakhanids north of the Hindu Kush, Jaipal attacked Ghazni once more and upon suffering yet another defeat by the powerful Ghaznavid forces, near present-day Peshawar. After the Battle of Peshawar, he committed suicide because his subjects thought he had brought disaster and disgrace to the Shahi dynasty.

Jayapala was succeeded by his son Anandapala, who along with other succeeding generations of the Shahiya dynasty took part in various campaigns against the advancing Ghaznavids but were unsuccessful. The Hindu rulers eventually exiled themselves to the Kashmir Siwalik Hills.
In 642 CE, Rashidun Arabs had conquered most of West Asia from the Sassanids and Byzantines, and from the western city of Herat they introduced the religion of Islam as they entered new cities. Afghanistan at that period had a number of different independent rulers, depending on the area. Ancestors of Abū Ḥanīfa, including his father, were from the Kabul region.

The early Arab forces did not fully explore Afghanistan due to attacks by the mountain tribes. Much of the eastern parts of the country remained independent, as part of the Hindu Shahi kingdoms of Kabul and Gandhara, which lasted that way until the forces of the Muslim Saffarid dynasty followed by the Ghaznavids conquered them.

The Ghaznavid dynasty ruled from the city of Ghazni in eastern Afghanistan. From 997 to his death in 1030, Mahmud of Ghazni turned the former provincial city of Ghazni into the wealthy capital of an extensive empire which covered most of today's Afghanistan, eastern Iran, and Pakistan. Mahmud consolidated the conquests of his predecessors and the city of Ghazni became a great cultural centre as well as a base for frequent forays into the Indian subcontinent. The Nasher Khans became princes of the Kharoti until the Soviet invasion.

The Ghaznavid dynasty was defeated in 1148 by the Ghurids from Ghor, but the Ghaznavid Sultans continued to live in Ghazni as the 'Nasher' until the early 20th century. They did not regain their once vast power until about 500 years later when the Ghilzai Hotakis rose to power. Various princes and Seljuk rulers attempted to rule parts of the country until the Shah Muhammad II of the Khwarezmid Empire conquered all of Persia in 1205 CE. By 1219, the empire had fallen to the Mongols, led by Genghis Khan.

The Mongol invasion resulted in massive destruction of several cities, including Bamiyan, Herat, and Balkh, and the despoliation of fertile agricultural areas. Large numbers of the inhabitants were also slaughtered. Most major cities north of the Hindu Kush became part of the Mongol Empire. The Afghan tribal areas south of the Hindu Kush were usually either allied with the Khalji dynasty of northern India or independent.

Timur (Tamerlane), incorporated much of the area into his own vast Timurid Empire. The city of Herat became one of the capitals of his empire, and his grandson Pir Muhammad held the seat of Kandahar. Timur rebuilt most of Afghanistan's infrastructure which was destroyed by his early ancestor. The area was progressing under his rule. Timurid rule began declining in the early 16th century with the rise of a new ruler in Kabul, Babur.
Timur, a descendant of Genghis Khan, created a vast new empire across Russia and Persia which he ruled from his capital in Samarkand in present-day Uzbekistan. Timur captured Herat in 1381 and his son, Shah Rukh moved the capital of the Timurid empire to Herat in 1405. The Timurids, a Turkic people, brought the Turkic nomadic culture of Central Asia within the orbit of Persian civilisation, establishing Herat as one of the most cultured and refined cities in the world. This fusion of Central Asian and Persian culture was a major legacy for the future Afghanistan. Under the rule of Shah Rukh the city served as the focal point of the Timurid Renaissance, whose glory matched Florence of the Italian Renaissance as the center of a cultural rebirth. A century later, the emperor Babur, a descendant of Timur, visited Herat and wrote, "the whole habitable world had not such a town as Herat." For the next 300 years the eastern Afghan tribes periodically invaded India creating vast Indo-Afghan empires. In 1500 CE, Babur was driven out of his home in the Ferghana valley. By the 16th century western Afghanistan again reverted to Persian rule under the Safavid dynasty.

In 1504, Babur, a descendant of Timur, arrived from present-day Uzbekistan and moved to the city of Kabul. He began exploring new territories in the region, with Kabul serving as his military headquarters. Instead of looking towards the powerful Safavids towards the Persian west, Babur was more focused on the Indian subcontinent. In 1526, he left with his army to capture the seat of the Delhi Sultanate, which at that point was possessed by the Afghan Lodi dynasty of India. After defeating Ibrahim Lodi and his army, Babur turned (Old) Delhi into the capital of his newly established Mughal Empire.

From the 16th century to the 17th century CE, Afghanistan was divided into three major areas. The north was ruled by the Khanate of Bukhara, the west was under the rule of the Iranian Shia Safavids, and the eastern section was under the Sunni Mughals of northern India, who under Akbar established in Kabul one of the original twelve subahs (imperial top-level provinces), bordering Lahore, Multan and Kashmir (added to Kabul in 1596, later split-off) and short-lived Balkh Subah and Badakhshan Subah (only 1646–47). The Kandahar region in the south served as a buffer zone between the Mughals (who shortly established a Qandahar subah 1638–1648) and Persia's Safavids, with the native Afghans often switching support from one side to the other. Babur explored a number of cities in the region before his campaign into India. In the city of Kandahar, his personal epigraphy can be found in the Chilzina rock mountain. Like in the rest of the territories that used to make part of the Indian Mughal Empire, Afghanistan holds tombs, palaces, and forts built by the Mughals.

In 1704, the Safavid Shah Husayn appointed George XI ("Gurgīn Khān"), a ruthless Georgian subject, to govern their easternmost territories in the Greater Kandahar region. One of Gurgīn's main objectives was to crush the rebellions started by native Afghans. Under his rule the revolts were successfully suppressed and he ruled Kandahar with uncompromising severity. He began imprisoning and executing the native Afghans, especially those suspected in having taken part in the rebellions. One of those arrested and imprisoned was Mirwais Hotak who belonged to an influential family in Kandahar. Mirwais was sent as a prisoner to the Persian court in Isfahan, but the charges against him were dismissed by the king, so he was sent back to his native land as a free man.

In April 1709, Mirwais along with his militia under Khan Nasher revolted. The uprising began when George XI and his escort were killed after a banquet that had been prepared by Mirwais at his house outside the city. Around four days later, an army of well-trained Georgian troops arrived in the city after hearing of Gurgīn's death, but Mirwais and his Afghan forces successfully held the city against the troops. Between 1710 and 1713, the Afghan forces defeated several large Persian armies that were dispatched from Isfahan by the Safavids, which included Qizilbash and Georgian/Circassian troops.

Southern Afghanistan was made into an independent local Pashtun kingdom. Refusing the title of king, Mirwais was called "Prince of Qandahár and general of the national troops" by his Afghan countrymen. He died of natural causes in November 1715 and was succeeded by his brother Abdul Aziz Hotak. Aziz was killed about two years later by Mirwais' son Mahmud Hotaki, allegedly for planning to give Kandahar's sovereignty back to Persia. Mahmud led an Afghan army into Persia in 1722 and defeated the Safavids at the Battle of Gulnabad. The Afghans captured Isfahan (Safavid capital) and Mahmud briefly became the new Persian Shah. He was known after that as Shah Mahmud.

Mahmud began a short-lived reign of terror against his Persian subjects who defied his rule from the very start, and he was eventually murdered in 1725 by his own cousin, Ashraf Hotaki. Some sources say he died of madness. Ashraf became the new Afghan Shah of Persia soon after Mahmud's death, while the home region of Afghanistan was ruled by Mahmud's younger brother Shah Hussain Hotaki. Ashraf was able to secure peace with the Ottoman Empire in 1727 ("See" "Treaty of Hamedan"), winning against a superior Ottoman army during the Ottoman-Hotaki War, but the Russian Empire took advantage of the continuing political unrest and civil strife to seize former Persian territories for themselves, limiting the amount of territory under Shah Mahmud's control.

The short lived Hotaki dynasty was a troubled and violent one from the very start as internecine conflict made it difficult for them to establish permanent control. The dynasty lived under great turmoil due to bloody succession feuds that made their hold on power tenuous. There was a massacre of thousands of civilians in Isfahan; including more than three thousand religious scholars, nobles, and members of the Safavid family. The vast majority of the Persians rejected the Afghan regime which they considered was a usurping power from the very start. Hotaki's rule continued in Afghanistan until 1738 when Shah Hussain was defeated and banished by Nader Shah of Persia.

The Hotakis were eventually removed from power in 1729, after a very short lived reign. They were defeated in the October 1729 by the Iranian military commander Nader Shah, head of the Afsharids, at the Battle of Damghan. After several military campaigns against the Afghans, he effectively reduced the Hotaki's power to only southern Afghanistan. The last ruler of the Hotaki dynasty, Shah Hussain, ruled southern Afghanistan until 1738 when the Afsharids and the Abdali Pashtuns defeated him at the long Siege of Kandahar.

Nader Shah and his Afsharid Persian army arrived in the town of Kandahar in 1738 and defeated Hussain Hotaki subsequently absorbing all of Afghanistan in his empire and renaming Kandahar as Naderabad. Around this time, a young teenager Ahmad Khan joined Nader Shah's army for his invasion of India. 
Nadir Shah was assassinated on 19 June 1747 by several of his Persian officers, and the Afsharid Persian empire fell to pieces. At the same time the 25-year-old Ahmad Khan was busy in Afghanistan calling for a loya jirga ("grand assembly") to select a leader among his people. The Afghans gathered near Kandahar in October 1747 and chose Ahmad Shah from among the challengers, making him their new head of state. After the inauguration or coronation, he became known as Ahmad Shah Durrani. He adopted the title "padshah durr-i dawran" ('King, "pearl of the age") and the Abdali tribe became known as the Durrani tribe after this. Ahmad Shah not only represented the Durranis but he also united all the Pashtun tribes. By 1751, Ahmad Shah Durrani and his Afghan army conquered the entire present-day Afghanistan, Pakistan, and for a short time, the Khorasan and Kohistan provinces of Iran, along with Delhi in India. He defeated the Maratha Empire in 1761 at the Battle of Panipat.

In October 1772, Ahmad Shah retired to his home in Kandahar where he died peacefully and was buried at a site that is now adjacent to the Shrine of the Cloak. He was succeeded by his son, Timur Shah Durrani, who transferred the capital of their Afghan Empire from Kandahar to Kabul. Timur died in 1793 and his son Zaman Shah Durrani took over the reign.

Zaman Shah and his brothers had a weak hold on the legacy left to them by their famous ancestor. They sorted out their differences through a "round robin of expulsions, blindings and executions," which resulted in the deterioration of the Afghan hold over far-flung territories, such as Attock and Kashmir. Durrani's other grandson, Shuja Shah Durrani, fled the wrath of his brother and sought refuge with the Sikhs. Not only had Durrani invaded the Punjab region many times, but had destroyed the holiest shrine of the Sikhs – the Harmandir Sahib in Amritsar, defiling its "sarowar" with the blood of cows and decapitating Baba Deep Singh in 1757. The Sikhs, under Ranjit Singh, eventually wrested a large part of the Kingdom of Kabul (present day Pakistan, but not including Sindh) from the Afghans. In 1837, the Afghan army descended through the Khyber Pass on Sikh forces at Jamrud killed the Sikh general Hari Singh Nalwa but could not capture the fort.

Dost Mohammed Khan gained control in Kabul. Collision between the expanding British and Russian Empires significantly influenced Afghanistan during the 19th century in what was termed "The Great Game". British concern over Russian advances in Central Asia and growing influence in West Asia and Persia in particular culminated in two Anglo-Afghan wars and "The Siege of Herat" 1837–1838, in which the Persians, trying to retake Afghanistan and throw out the British, sent armies into the country and fought the British mostly around and in the city of Herat. The first Anglo-Afghan War (1839–1842) resulted in the destruction of a British army; it is remembered by first-hand account as an example of the ferocity of Afghan resistance to foreign rule. The Second Anglo-Afghan War (1878–1880) was sparked by Amir Shir Ali's refusal to accept a British mission in Kabul. This conflict brought Amir Abdur Rahman, known by some as the "Iron Amir", to the Afghan throne. During his reign (1880–1901), the British and Russians officially established the boundaries of what would become modern Afghanistan. The British retained effective control over Kabul's foreign affairs. Abdur Rahman's reforms of the army, legal system and structure of government were able to give Afghanistan a degree of unity and stability which it had not before known. This, however, came at the cost of strong centralisation, harsh punishments for crime and corruption, and a certain degree of international isolation.

Habibullah Khan, Abdur Rahman's son, came to the throne in 1901 and kept Afghanistan neutral during World War I, despite German encouragement of anti-British feelings and Afghan rebellion along the borders of British India. His policy of neutrality was not universally popular within the country; however, and Habibullah was assassinated in 1919, possibly by family members opposed to British influence. His third son, Amanullah, regained control of Afghanistan's foreign policy after launching the Third Anglo-Afghan War with an attack on India in the same year. During the ensuing conflict, the war-weary British relinquished their control over Afghan foreign affairs by signing the Treaty of Rawalpindi in August 1919. In commemoration of this event, Afghans celebrate 19 August as their Independence Day.

King Amanullah Khan moved to end his country's traditional isolation in the years following the Third Anglo-Afghan war. After quelling the Khost rebellion in 1925, he established diplomatic relations with most major countries and, following a 1927 tour of Europe and Turkey (during which he noted the modernization and secularization advanced by Atatürk), introduced several reforms intended to modernize Afghanistan. A key force behind these reforms was Mahmud Tarzi, Amanullah Khan's Foreign Minister and father-in-law — and an ardent supporter of the education of women. He fought for Article 68 of Afghanistan's first constitution (declared through a Loya Jirga), which made elementary education compulsory. Some of the reforms that were actually put in place, such as the abolition of the traditional Muslim veil for women and the opening of a number of co-educational schools, quickly alienated many tribal and religious leaders, which led to the revolt of the Shinwari in November 1928, marking the beginning of the Afghan Civil War (1928–1929). Although the Shinwari revolt was quelled, a concurrent Saqqawist uprising in the north eventually managed to depose Amanullah, leading to Habibullāh Kalakāni taking control of Kabul.

Prince Mohammed Nadir Khan, cousin of Amanullah Khan, in turn defeated, and executed Habibullah Kalakani in October and November 1929 respectively. He was soon declared King Nadir Khan. He began consolidating power and regenerating the country. He abandoned the reforms of Amanullah Khan in favour of a more gradual approach to modernisation. In 1933, however, he was assassinated in a revenge killing by a student from Kabul.

Mohammad Zahir Shah, Nadir Khan's 19-year-old son, succeeded to the throne and reigned from 1933 to 1973. The Afghan tribal revolts of 1944–1947 saw Zahir Shah's reign being challenged by Zadran, Safi and Mangal tribesmen led by Mazrak Zadran and Salemai among others. Until 1946 Zahir Shah ruled with the assistance of his uncle Sardar Mohammad Hashim Khan, who held the post of Prime Minister and continued the policies of Nadir Khan. In 1946, another of Zahir Shah's uncles, Sardar Shah Mahmud Khan, became Prime Minister and began an experiment allowing greater political freedom, but reversed the policy when it went further than he expected. In 1953, he was replaced as Prime Minister by Mohammed Daoud Khan, the king's cousin and brother-in-law. Daoud looked for a closer relationship with the Soviet Union and a more distant one towards Pakistan. However, disputes with Pakistan led to an economic crisis and he was asked to resign in 1963. From 1963 until 1973, Zahir Shah took a more active role.

In 1964, King Zahir Shah promulgated a liberal constitution providing for a bicameral legislature to which the king appointed one-third of the deputies. The people elected another third, and the remainder were selected indirectly by provincial assemblies. Although Zahir's "experiment in democracy" produced few lasting reforms, it permitted the growth of unofficial extremist parties on both the left and the right. This included the communist People's Democratic Party of Afghanistan (PDPA), which had close ideological ties to the Soviet Union. In 1967, the PDPA split into two major rival factions: the Khalq (Masses) was headed by Nur Muhammad Taraki and Hafizullah Amin who were supported by elements within the military, and the Parcham (Banner) led by Babrak Karmal.

Amid charges of corruption and malfeasance against the royal family and poor economic conditions created by the severe 1971–72 drought, former Prime Minister Mohammad Sardar Daoud Khan seized power in a non-violent coup on July 17, 1973, while Zahir Shah was receiving treatment for eye problems and therapy for lumbago in Italy. Daoud abolished the monarchy, abrogated the 1964 constitution, and declared Afghanistan a republic with himself as its first President and Prime Minister. His attempts to carry out badly needed economic and social reforms met with little success, and the new constitution promulgated in February 1977 failed to quell chronic political instability.

As disillusionment set in, in 1978 a prominent member of the People's Democratic Party of Afghanistan (PDPA), Mir Akbar Khyber (or "Kaibar"), was killed by the government. The leaders of PDPA apparently feared that Daoud was planning to exterminate them all, especially since most of them were arrested by the government shortly after. Nonetheless, Hafizullah Amin and a number of military wing officers of the PDPA's Khalq faction managed to remain at large and organize a military coup.

On 28 April 1978, the PDPA, led by Nur Mohammad Taraki, Babrak Karmal and Amin Taha overthrew the government of Mohammad Daoud, who was assassinated along with all his family members in a bloody military coup. The coup became known as the Saur Revolution. On 1 May, Taraki became President, Prime Minister and General Secretary of the PDPA. The country was then renamed the Democratic Republic of Afghanistan (DRA), and the PDPA regime lasted, in some form or another, until April 1992.

In March 1979, Hafizullah Amin took over as prime minister, retaining the position of field marshal and becoming vice-president of the Supreme Defence Council. Taraki remained President and in control of the Army. On 14 September, Amin overthrew Taraki, who was killed. Amin stated that "the Afghans recognize only crude force." Afghanistan expert Amin Saikal writes: "As his powers grew, so apparently did his craving for personal dictatorship ... and his vision of the revolutionary process based on terror."

Once in power, the PDPA implemented a liberal and Marxist–Leninist agenda. It moved to replace religious and traditional laws with secular and Marxist–Leninist ones. Men were obliged to cut their beards, women could not wear a chador, and mosques were placed off limits. The PDPA made a number of reforms on women's rights, banning forced marriages and giving state recognition of women's right to vote. A prominent example was Anahita Ratebzad, who was a major Marxist leader and a member of the Revolutionary Council. Ratebzad wrote the famous "New Kabul Times" editorial (May 28, 1978) which declared: "Privileges which women, by right, must have are equal education, job security, health services, and free time to rear a healthy generation for building the future of the country ... Educating and enlightening women is now the subject of close government attention." The PDPA also carried out socialist land reforms and moved to promote state atheism. They also prohibited usury. The PDPA invited the Soviet Union to assist in modernizing its economic infrastructure (predominantly its exploration and mining of rare minerals and natural gas). The USSR also sent contractors to build roads, hospitals and schools and to drill water wells; they also trained and equipped the Afghan army. Upon the PDPA's ascension to power, and the establishment of the DRA, the Soviet Union promised monetary aid amounting to at least $1.262 billion.

At the same time, the PDPA imprisoned, tortured or murdered thousands of members of the traditional elite, the religious establishment, and the intelligentsia. The government launched a campaign of violent repression, killing some 10,000 to 27,000 people and imprisoning 14,000 to 20,000 more, mostly at Pul-e-Charkhi prison. In December 1978 the PDPA leadership signed an agreement with the Soviet Union which would allow military support for the PDPA in Afghanistan if needed. The majority of people in the cities including Kabul either welcomed or were ambivalent to these policies. However, the Marxist–Leninist and secular nature of the government as well as its heavy dependence on the Soviet Union made it unpopular with a majority of the Afghan population. Repressions plunged large parts of the country, especially the rural areas, into open revolt against the new Marxist–Leninist government. By spring 1979 unrests had reached 24 out of 28 Afghan provinces including major urban areas. Over half of the Afghan army would either desert or join the insurrection. Most of the government's new policies clashed directly with the traditional Afghan understanding of Islam, making religion one of the only forces capable of unifying the tribally and ethnically divided population against the unpopular new government, and ushering in the advent of Islamist participation in Afghan politics.

To bolster the Parcham faction, the Soviet Union decided to intervene on December 27, 1979, when the Red Army invaded its southern neighbor. Over 100,000 Soviet troops took part in the invasion, which was backed by another 100,000 Afghan military men and supporters of the Parcham faction. In the meantime, Hafizullah Amin was killed and replaced by Babrak Karmal.

In response to the Soviet occupation of Afghanistan, the Carter administration and Reagan administration in the U.S. began arming the Mujahideen, thanks in large part to the efforts of Charlie Wilson and CIA officer Gust Avrakotos. Early reports estimated that $6–20 billion had been spent by the U.S. and Saudi Arabia but more recent reports state that the U.S. and Saudi Arabia provided as much as up to $40 billion in cash and weapons, which included over two thousand FIM-92 Stinger surface-to-air missiles, for building up Islamic groups against the Soviet Union. The U.S. handled most of its support through Pakistan's ISI.

Scholars such as W. Michael Reisman, Charles Norchi and Mohammed Kakar, believe that the Afghans were victims of genocide by the Soviet Union. Soviet forces and their proxies killed between 562,000 and 2 million Afghans and Russian soldiers also engaged in abductions and rapes of Afghan women. About 6 million fled as Afghan refugees to Pakistan and Iran, and from there over 38,000 made it to the United States and many more to the European Union. The Afghan refugees in Iran and Pakistan brought with them verifiable stories of murder, collective rape, torture and depopulation of civilians by the Soviet forces. Faced with mounting international pressure and great number of casualties on both sides, the Soviets withdrew in 1989. Their withdrawal from Afghanistan was seen as an ideological victory in the United States, which had backed some Mujahideen factions through three U.S. presidential administrations to counter Soviet influence in the vicinity of the oil-rich Persian Gulf. The USSR continued to support President Mohammad Najibullah (former head of the Afghan secret service, "KHAD") until 1992.

Pakistan's spy agency Inter-Services Intelligence (ISI), headed by Hamid Gul at the time, was interested in a trans-national Islamic revolution which would cover Pakistan, Afghanistan and Central Asia. For this purpose the ISI masterminded an attack on Jalalabad in March 1989, for the Mujahideen to establish their own government in Afghanistan, but this failed in three months.

With the crumbling of the Najibullah-regime early in 1992, Afghanistan fell into further disarray and civil war. A U.N.-supported attempt to have the mujahideen parties and armies form a coalition government shattered. Mujahideen did not abide by the mutual pledges and Ahmad Shah Masood forces because of his proximity to Kabul captured the capital before Mujahideen Govt was established. So the elected prime minister and warlord Gulbuddin Hekmatyar, started war on his president and Massod force entrenched in Kabul. This ignited civil war, because the other mujahideen parties wouldn't settle for Hekmatyar ruling alone or sharing actual power with him. Within weeks, the still frail unity of the other mujahideen forces also evaporated, and six militias were fighting each other in and around Kabul.

Subghatullah Mujadady was elected as Afghanistan's elected interim president for two months and then professor Burhanuddin Rabani a well known Kabul university professor and the leader of Jamiat-e-Islami party of Mujahiddin who fought against Russians during the occupation was chosen by all of the Jahadi leaders except Golbuddin Hikmat Yar. Professor Rabani reigned as the official and elected president of Afghanistan by Shurai Mujahiddin Peshawer (Peshawer Mujahiddin Council) from 1992 until 2001 when he officially handed over the presidency post to Hamid Karzai the next US appointed interim president. During Rabbani's presidency some parts of the country including a few provinces in the north such as Mazar e-Sharif, Jawzjan, Faryab, Shuburghan and some parts of Baghlan provinces were ruled by general Abdul Rashid Dostom.
During Rabbani's first five years illegal term before the emergence of the Taliban, the eastern and western provinces and some of the northern provinces such as Badakhshan, Takhar, Kunduz, the main parts of Baghlan Province, and some parts of Kandahar and other southern provinces were under the control of the central government while the other parts of southern provinces did not obey him because of his Tajik ethnicity. During the 9 year presidency of Burhanuddin Rabani, Gulbuddin Hekmatyar was directed, funded and supplied by the Pakistani army. Afghanistan analyst Amin Saikal concludes in his book "Modern Afghanistan: A History of Struggle and Survival":

There was no time for the interim government to create working government departments, police units or a system of justice and accountability. Saudi Arabia and Iran also armed and directed Afghan militias. A publication by the George Washington University describes:

Meanwhile, the southern city of Kandahar was a centre of lawlessness, crime and atrocities fuelled by complex Pashtun tribal rivalries. In 1994, the Taliban (a movement originating from Jamiat Ulema-e-Islam-run religious schools for Afghan refugees in Pakistan) also developed in Afghanistan as a politico-religious force, reportedly in opposition to the tyranny of the local governor. Mullah Omar started his movement with fewer than 50 armed madrassah students in his hometown of Kandahar. As Gulbuddin Hekmatyar remained unsuccessful in conquering Kabul, Pakistan started supporting the Taliban. Many analysts like Amin Saikal describe the Taliban as developing into a proxy force for Pakistan's regional interests. In 1994 the Taliban took power in several provinces in southern and central Afghanistan.

In 1995 the Hezb-i Islami of Gulbuddin Hekmatyar, the Iranian-backed Hezb-i Wahdat as well as Rashid Dostum's Junbish forces were defeated militarily in the capital Kabul by forces of the interim government under Massoud who subsequently tried to initiate a nationwide political process with the goal of national consolidation and democratic elections, also inviting the Taliban to join the process. The Taliban declined.

The Taliban started shelling Kabul in early 1995 but were defeated by forces of the Islamic State government under Ahmad Shah Massoud. Amnesty International, referring to the Taliban offensive, wrote in a 1995 report:

On September 26, 1996, as the Taliban, with military support by Pakistan and financial support by Saudi Arabia, prepared for another major offensive, Massoud ordered a full retreat from Kabul. The Taliban seized Kabul on September 27, 1996, and established the Islamic Emirate of Afghanistan. They imposed on the parts of Afghanistan under their control their political and judicial interpretation of Islam, issuing edicts forbidding women from working outside the home, attending school or leaving their homes unless accompanied by a male relative. Physicians for Human Rights (PHR) said:

After the fall of Kabul to the Taliban on September 27, 1996, Ahmad Shah Massoud and Abdul Rashid Dostum, two former enemies, created the United Front (Northern Alliance) against the Taliban, who were preparing offensives against the remaining areas under the control of Massoud and Dostum. The United Front included beside the dominantly Tajik forces of Massoud and the Uzbek forces of Dostum, Hazara factions and Pashtun forces under the leadership of commanders such as Abdul Haq, Haji Abdul Qadir, Qari Baba or diplomat Abdul Rahim Ghafoorzai. From the Taliban conquest in 1996 until November 2001 the United Front controlled roughly 30% of Afghanistan's population in provinces such as Badakhshan, Kapisa, Takhar and parts of Parwan, Kunar, Nuristan, Laghman, Samangan, Kunduz, Ghōr and Bamyan.

According to a 55-page report by the United Nations, the Taliban, while trying to consolidate control over northern and western Afghanistan, committed systematic massacres against civilians. UN officials stated that there had been "15 massacres" between 1996 and 2001. They also said, that "[t]hese have been highly systematic and they all lead back to the [Taliban] Ministry of Defense or to Mullah Omar himself." The Taliban especially targeted people of Shia religious or Hazara ethnic background. Upon taking Mazar-i-Sharif in 1998, about 4,000 civilians were executed by the Taliban and many more reported tortured. Among those killed in Mazari Sharif were several Iranian diplomats. Others were kidnapped by the Taliban, touching off a hostage crisis that nearly escalated to a full-scale war, with 150,000 Iranian soldiers massed on the Afghan border at one time. It was later admitted that the diplomats were killed by the Taliban, and their bodies were returned to Iran.

The documents also reveal the role of Arab and Pakistani support troops in these killings. Osama Bin Laden's so-called 055 Brigade was responsible for mass-killings of Afghan civilians.<ref name="Ahmed Rashid/The Telegraph"></ref> The report by the United Nations quotes eyewitnesses in many villages describing Arab fighters carrying long knives used for slitting throats and skinning people.

Pakistani President Pervez Musharraf – then as Chief of Army Staff – was responsible for sending thousands of Pakistanis to fight alongside the Taliban and Bin Laden against the forces of Massoud. In total there were believed to be 28,000 Pakistani nationals fighting inside Afghanistan. 20,000 were regular Pakistani soldiers either from the Frontier Corps or army and an estimated 8,000 were militants recruited in madrassas filling regular Taliban ranks. The estimated 25,000 Taliban regular force thus comprised more than 8,000 Pakistani nationals. A 1998 document by the U.S. State Department confirms that "20–40 percent of [regular] Taliban soldiers are Pakistani." The document further states that the parents of those Pakistani nationals "know nothing regarding their child's military involvement with the Taliban until their bodies are brought back to Pakistan." A further 3,000 fighter of the regular Taliban army were Arab and Central Asian militants. From 1996 to 2001 the Al Qaeda of Osama Bin Laden and Ayman al-Zawahiri became a state within the Taliban state. Bin Laden sent Arab recruits to join the fight against the United Front. Of roughly 45,000 Pakistani, Taliban and Al Qaeda soldiers fighting against the forces of Massoud only 14,000 were Afghan.

According to Human Rights Watch in 1997 Taliban soldiers were summarily executed in and around Mazar-i Sharif by Dostum's Junbish forces. Dostum was defeated by the Taliban in 1998 with the fall of Mazar-i-Sharif. Massoud remained the only leader of the United Front in Afghanistan.

In the areas under his control Ahmad Shah Massoud set up democratic institutions and signed the Women's Rights Charter. Human Rights Watch cites no human rights crimes for the forces under direct control of Massoud for the period from October 1996 until the assassination of Massoud in September 2001. As a consequence many civilians fled to the area of Ahmad Shah Massoud. National Geographic concluded in its documentary "Inside the Taliban":

The Taliban repeatedly offered Massoud a position of power to make him stop his resistance. Massoud declined for he did not fight to obtain a position of power. He said in one interview:

and

Massoud wanted to convince the Taliban to join a political process leading towards democratic elections in a foreseeable future. Massoud stated that:

In early 2001 Massoud employed a new strategy of local military pressure and global political appeals. Resentment was increasingly gathering against Taliban rule from the bottom of Afghan society including the Pashtun areas. Massoud publicized their cause "popular consensus, general elections and democracy" worldwide. At the same time he was very wary not to revive the failed Kabul government of the early 1990s. Already in 1999 he started the training of police forces which he trained specifically to keep order and protect the civilian population in case the United Front would be successful.

In early 2001 Massoud addressed the European Parliament in Brussels asking the international community to provide humanitarian help to the people of Afghanistan. He stated that the Taliban and Al Qaeda had introduced "a very wrong perception of Islam" and that without the support of Pakistan the Taliban would not be able to sustain their military campaign for up to a year.

On 9 September 2001, Ahmad Shah Massoud was assassinated by two Arab suicide attackers inside Afghanistan. Two days later about 3,000 people became victims of the September 11 attacks in the United States, when Afghan-based Al-Qaeda suicide bombers hijacked planes and flew them into four targets in the Northeastern United States. Then US President George W. Bush accused Osama bin Laden and Khalid Sheikh Mohammed as the faces behind the attacks. When the Taliban refused to hand over bin Laden to US authorities and to disband al-Qaeda bases in Afghanistan, Operation Enduring Freedom was launched in which teams of American and British special forces worked with commanders of the United Front (Northern Alliance) against the Taliban. At the same time the US-led forces were bombing Taliban and al-Qaeda targets everywhere inside Afghanistan with cruise missiles. These actions led to the fall of Mazar-i-Sharif in the north followed by all the other cities, as the Taliban and al-Qaeda crossed over the porous Durand Line border into Pakistan. In December 2001, after the Taliban government was toppled and the new Afghan government under Hamid Karzai was formed, the International Security Assistance Force (ISAF) was established by the UN Security Council to help assist the Karzai administration and provide basic security to the Afghan people. The majority of Afghans supported the American invasion of their country.
While the Taliban began regrouping inside Pakistan, the rebuilding of war-torn Afghanistan kicked off in 2002 (see also War in Afghanistan (2001–present)). The Afghan nation was able to build democratic structures over the years by the creation of an emergency loya jirga to set up the modern Afghan government, and some progress was made in key areas such as governance, economy, health, education, transport, and agriculture. NATO is training the Afghan armed forces as well its national police. ISAF and Afghan troops led many offensives against the Taliban but failed to fully defeat them. By 2009, a Taliban-led shadow government began to form in many parts of the country complete with their own version of mediation court. After U.S. President Barack Obama announced the deployment of another 30,000 soldiers in 2010 for a period of two years, Der Spiegel published images of the US soldiers who killed unarmed Afghan civilians.

In 2009, the United States resettled 328 refugees from Afghanistan. Over five million Afghan refugees were repatriated in the last decade, including many who were forcefully deported from NATO countries. This large return of Afghans may have helped the nation's economy but the country still remains one of the poorest in the world due to the decades of war, lack of foreign investment, ongoing government corruption and the Pakistani-backed Taliban insurgency. The United States also accuses neighboring Iran of providing small level of support to the Taliban insurgents. According to a report by the United Nations, the Taliban and other militants were responsible for 76% of civilian casualties in 2009, 75% in 2010 and 80% in 2011.

In October 2008 U.S. Defense Secretary Gates had asserted that a political settlement with the Taliban was the endgame for the Afghanistan war. "There has to be ultimately – and I'll underscore ultimately – reconciliation as part of a political outcome to this," Gates stated. By 2010 peace efforts began. In early January, Taliban commanders held secret exploratory talks with a United Nations special envoy to discuss peace terms. Regional commanders on the Taliban's leadership council, the Quetta Shura, sought a meeting with the UN special representative in Afghanistan, Kai Eide, and it took place in Dubai on January 8. It was the first such meeting between the UN and senior members of the Taliban. On 26 January 2010, at a major conference in London which brought together some 70 countries and organizations, Afghan President Hamid Karzai said he intends to reach out to the Taliban leadership (including Mullah Omar, Sirajuddin Haqqani and Gulbuddin Hekmatyar). Supported by NATO, Karzai called on the group's leadership to take part in a loya jirga meeting to initiate peace talks. These steps have resulted in an intensification of bombings, assassinations and ambushes. Some Afghan groups (including the former intelligence chief Amrullah Saleh and opposition leader Dr. Abdullah Abdullah) believe that Karzai plans to appease the insurgents' senior leadership at the cost of the democratic constitution, the democratic process and progress in the field of human rights especially women's rights. Dr. Abdullah stated:

Afghan President Hamid Karzai told world leaders during the London conference that he intends to reach out to the top echelons of the Taliban within a few weeks with a peace initiative. Karzai set the framework for dialogue with Taliban leaders when he called on the group's leadership to take part in a "loya jirga" – or large assembly of elders – to initiate peace talks. Karzai also asked for creation of a new peacemaking organization, to be called the National Council for Peace, Reconciliation and Reintegration. Karzai's top adviser on the reconciliation process with the insurgents said that the country must learn to forgive the Taliban. In March 2010, the Karzai government held preliminary talks with Hezb-i-Islami, who presented a plan which included the withdrawal of all foreign troops by the end of 2010. The Taliban declined to participate, saying "The Islamic Emirate has a clear position. We have said this many, many times. There will be no talks when there are foreign troops on Afghanistan's soil killing innocent Afghans on daily basis." In June 2010 the Afghan Peace Jirga 2010 took place. In September 2010 General David Petraeus commented on the progress of peace talks to date, stating, "The prospect for reconciliation with senior Taliban leaders certainly looms out there...and there have been approaches at (a) very senior level that hold some promise."

After the May 2011 death of Osama bin Laden in Pakistan, many prominent Afghan figures began being assassinated, including Mohammed Daud Daud, Ahmad Wali Karzai, Jan Mohammad Khan, Ghulam Haider Hamidi, Burhanuddin Rabbani and others. Also in the same year, the Pakistani-Afghan border skirmishes intensified and many large scale attacks by the Pakistani-based Haqqani network took place across Afghanistan. This led to the United States warning Pakistan of a possible military action against the Haqqanis in the Federally Administered Tribal Areas. The U.S. blamed Pakistan's government, mainly Pakistani Army and its ISI spy network as the masterminds behind all of this. U.S. Ambassador to Pakistan, Cameron Munter, told Radio Pakistan that "The attack that took place in Kabul a few days ago, that was the work of the Haqqani network. There is evidence linking the Haqqani Network to the Pakistan government. This is something that must stop." Other top U.S. officials such as Hillary Clinton and Leon Panetta made similar statements. On October 16, 2011, "Operation Knife Edge" was launched by NATO and Afghan forces against the Haqqani network in south-eastern Afghanistan. Afghan Defense Minister, Abdul Rahim Wardak, explained that the operation will "help eliminate the insurgents before they struck in areas along the troubled frontier". In November 2011, NATO forces attacked Pakistani soldiers in the Pakistan border region. In 2014, Ashraf Ghani was elected to be the president of Afghanistan.





</doc>
<doc id="13814" url="https://en.wikipedia.org/wiki?curid=13814" title="History of modern Greece">
History of modern Greece

The history of modern Greece covers the history of Greece from the recognition of its autonomy from the Ottoman Empire by the Great Powers (Great Britain, France, and Russia) in 1828, after the Greek War of Independence, to the present day.

The Byzantine Empire had ruled most of the Greek-speaking world since late Antiquity, but experienced a decline as a result of Muslim Arab and Seljuk Turkish invasions and was fatally weakened by the sacking of Constantinople by the Latin Crusaders in 1204. The establishment of Catholic Latin states on Greek soil, and the struggles of the Orthodox Byzantine Greeks against them, led to the emergence of a distinct Greek national identity. The Byzantine Empire was restored by the Palaiologos dynasty in 1261, but it was a shadow of its former self, and constant civil wars and foreign attacks in the 14th century brought about its terminal decline. As a result, most of Greece gradually became part of the Ottoman Empire in the late 14th and early 15th centuries, culminating in the Fall of Constantinople in 1453, the conquest of the Duchy of Athens in 1458, and of the Despotate of the Morea in 1460.

Ottoman control was largely absent in the mountainous interior of Greece, and many fled there, often becoming brigands. Otherwise, only the islands of the Aegean and a few coastal fortresses on the mainland, under Venetian and Genoese rule, remained free from Ottoman rule, but by the mid-16th century, the Ottomans had conquered most of them as well. Rhodes fell in 1522, Cyprus in 1571, and the Venetians retained Crete until 1670. The Ionian Islands were only briefly ruled by the Ottomans (Kefalonia from 1479 to 1481 and from 1485 to 1500), and remained primarily under the rule of Venice.

The first large-scale insurrection against Ottoman rule was the Orlov Revolt of the early 1770s, but it was brutally repressed. The same time, however, also marks the start of the Modern Greek Enlightenment, as Greeks who studied in Western Europe brought knowledge and ideas back to their homeland, and as Greek merchants and shipowners increased their wealth. As a result, especially in the aftermath of the French Revolution, liberal and nationalist ideas began to spread across the Greek lands.

In 1821, the Greeks rose up against the Ottoman Empire. Initial successes were followed by infighting, which almost caused the Greek struggle to collapse; nevertheless, the prolongation of the fight forced the Great Powers (Britain, Russia and France) to recognize the claims of the Greek rebels to separate statehood (Treaty of London) and intervene against the Ottomans at the Battle of Navarino. Greece was initially to be an autonomous state under Ottoman suzerainty, but by 1832, in the Treaty of Constantinople, it was recognized as a fully independent kingdom. In the meantime, the 3rd National Assembly of the Greek insurgents called upon Ioannis Kapodistrias, a former foreign minister of Russia, to take over the governance of the fledgling state in 1827.

On his arrival, Kapodistrias launched a major reform and modernisation programme that covered all areas. He re-established military unity by bringing an end to the second phase of the civil war; re-organised the military, which was then able to reconquer territory lost to the Ottoman military during the civil wars; and introduced the first modern quarantine system in Greece, which brought diseases such as typhoid fever, cholera and dysentery under control for the first time since the start of the War of Independence.

Kapodistrias also negotiated with the Great Powers and the Ottoman Empire to establish the borders and degree of independence of the Greek state; signed the peace treaty that ended the War of Independence with the Ottomans; introduced the "phoenix", the first modern Greek currency; organised local administration; and, in an effort to raise the living standards of the population, introduced the cultivation of the potato into Greece.

Furthermore, he tried to undermine the authority of the traditional clans (or dynasties) that he considered the useless legacy of a bygone and obsolete era. However, he underestimated the political and military strength of the "capetanei" (καπεταναίοι – commanders) who had led the revolt against Ottoman Empire in 1821, and who had expected a leadership role in the post-revolution Government. When a dispute between the "capetanei" of Laconia and the appointed governor of the province escalated into an armed conflict, he called in Russian troops to restore order, because much of the army was controlled by "capetanei" who had been part of the rebellion.

George Finlay's 1861 "History of Greek Revolution" records that by 1831 Kapodistrias's government had become hated, chiefly by the independent Maniots, but also by the Roumeliotes and the rich and influential merchant families of Hydra, Spetses and Psara. The customs dues of the inhabitants of Hydra were the chief source of revenue for these municipalities, and they refused to hand these over to Kapodistrias. It appears that Kapodistrias had refused to convene the National Assembly and was ruling as a despot, possibly influenced by his Russian experiences. The municipality of Hydra instructed Admiral Miaoulis and Alexandros Mavrokordatos to go to Poros and seize the Hellenic Navy's fleet there. This Miaoulis did so with the intention of preventing a blockade of the islands, so for a time it seemed as if the National Assembly would be called.

Kapodistrias called on the British and French residents to support him in putting down the rebellion, but this they refused to do. Nonetheless, an Admiral Rikord (or Ricord) took his ships north to Poros. Colonel (later General) Kallergis took a half-trained force of Greek Army regulars and a force of irregulars in support. With less than 200 men, Miaoulis was unable to make much of a fight; Fort Heidek on Bourtzi Island was overrun by the regulars and the brig "Spetses" (once Laskarina Bouboulina's "Agamemnon") sank by Ricord's force. Encircled by the Russians in the harbor and Kallergis' force on land, Poros surrendered. Miaoulis was forced to set charges in the flagship "Hellas" and the corvette "Hydra" to blow them up when he and his handful of followers returned to Hydra. Kallergis' men were enraged by the loss of the ships and sacked Poros, carrying off plunder to Nauplion.

The loss of the best ships in the fleet crippled the Hellenic Navy for many years, but it also weakened Kapodistrias' position. He did finally call the National Assembly, but his other actions triggered more opposition and that led to his downfall.

In 1831, Kapodistrias ordered the imprisonment of Petrobey Mavromichalis, the Bey of the Mani Peninsula, one of the wildest and most rebellious parts of Greece. This was a mortal offence to the Mavromichalis family, and on 9 October 1831 (27 September in the Julian Calendar) Kapodistrias was assassinated by Petros' brother Konstantis and son Georgios on the steps of the church of Saint Spyridon in Nafplio.

Ioannis Kapodistrias was succeeded as Governor by his younger brother, Augustinos Kapodistrias. Augustinos ruled only for six months, during which the country was very much plunged into chaos. Under the protocol signed at the London Conference of 1832 on 7 May 1832 between Bavaria and the protecting Powers, Greece was defined as an independent kingdom, free of Ottoman control, with the Arta-Volos line as its northern frontier. The protocol also dealt with the way in which a Regency was to be managed until Otto of Bavaria reached his majority to assume the throne of Greece. The Ottoman Empire was indemnified in the sum of 40,000,000 piastres for the loss of territory in the new kingdom.

Otto's reign would prove troubled, but he managed to hang on for 30 years before he and his wife, Queen Amalia, left the same way they came, aboard a British warship. During the early years of his reign, a group of Bavarian Regents ruled in his name, and they made themselves very unpopular by trying to impose German ideas of rigid hierarchical government on the Greeks, while keeping most significant state offices away from them. Nevertheless, they laid the foundations of a Greek administration, army, justice system and education system. Otto was sincere in his desire to give Greece good government, but he suffered from two great handicaps: his Roman Catholic faith and his childless marriage to Queen Amalia. This meant he could neither be crowned as King of Greece under the Orthodox rite nor establish a dynasty.

The Bavarian Regents ruled until 1837, when they were recalled at the insistence of Britain and France. Otto thereafter appointed Greek ministers, although Bavarian officials still ran most of the administration and the army. At this time, Greece still had no legislature and no constitution. Discontent grew until the 3 September 1843 Revolution broke out in Athens. Otto agreed to grant a constitution and convened a National Assembly that met in November of the same year. The Greek Constitution of 1844 then created a bicameral parliament consisting of an Assembly ("Vouli") and a Senate ("Gerousia"). Power then passed into the hands of a group of Greek politicians, most of whom who had been commanders in the War of Independence against the Ottomans.

Greek politics in the 19th century was dominated by the "national question." The majority of Greeks continued to live under Ottoman rule, and Greeks dreamed of liberating them all and reconstituting a state embracing all the Greek lands, with Constantinople as its capital. This was called the Great Idea ("Megali Idea"), and it was sustained by almost continuous rebellions against Ottoman rule in Greek-speaking territories, particularly Crete, Thessaly and Macedonia.

When the Crimean War broke out in 1854, Greece saw an opportunity to gain Ottoman-controlled territory that had large Greek populations. Greece, an Orthodox nation, had considerable support in Russia, but the Russian government decided it was too dangerous to help Greece expand its holdings. When the Russians attacked the Ottoman forces, Greece invaded Thessaly and Epirus. To block further Greek moves, the British and French occupied the main Greek port at Piraeus from April 1854 to February 1857. The Greeks, gambling on a Russian victory, incited the large-scale Epirus Revolt of 1854 as well as uprisings in Crete. The revolts failed and Greece made no gains during the Crimean War, which Russia lost.

A new generation of Greek politicians was growing increasingly intolerant of King Otto's continuing interference in government. In 1862, the King dismissed his Prime Minister, the former admiral Constantine Kanaris, the most prominent politician of the period. This provoked a military rebellion, forcing Otto to accept the inevitable and leave the country.

The Greeks then asked Britain to send Queen Victoria's son Prince Alfred as their new king, but this was vetoed by the other Powers. Instead, a young Danish Prince became King George I. George was a very popular choice as a constitutional monarch, and he agreed that his sons would be raised in the Greek Orthodox faith. As a reward to the Greeks for adopting a pro-British King, Britain ceded the Ionian Islands to Greece.

At the urging of Britain and King George, Greece adopted the much more democratic Greek Constitution of 1864. The powers of the King were reduced, the Senate was abolished, and the franchise was extended to all adult males. Approval voting was used in elections, with one urn for each candidate divided into "yes" and "no" portions into which voters dropped lead beads. Nevertheless, Greek politics remained heavily dynastic, as it has always been. Family names such as Zaimis, Rallis and Trikoupis occurred repeatedly as Prime Ministers.

Although parties were centered around the individual leaders, often bearing their names, two broad political tendencies existed: the liberals, led first by Charilaos Trikoupis and later by Eleftherios Venizelos, and the conservatives, led initially by Theodoros Deligiannis and later by Thrasivoulos Zaimis. Trikoupis and Deligiannis dominated Greek politics in the later 19th century, alternating in office. Trikoupis favoured co-operation with Great Britain in foreign affairs, the creation of infrastructure and an indigenous industry, raising protective tariffs and progressive social legislation, while the more populist Deligiannis depended on the promotion of Greek nationalism and the "Megali Idea".

Greece remained a very poor country throughout the 19th century. The country lacked raw materials, infrastructure and capital. Agriculture was mostly at the subsistence level, and the only important export commodities were currants, raisins and tobacco. Some Greeks grew rich as merchants and shipowners, and Piraeus became a major port, but little of this wealth found its way to the Greek peasantry. Greece remained hopelessly in debt to London finance houses.

By the 1890s, Greece was virtually bankrupt. Poverty was rife in the rural areas and the islands, and was eased only by large-scale emigration to the United States. There was little education in the rural areas. Nevertheless, there was progress in building communications and infrastructure, and fine public buildings were erected in Athens. Despite the bad financial situation, Athens staged the revival of the Olympic Games in 1896, which proved a great success.
The parliamentary process developed greatly in Greece during the reign of George I. Initially, the royal prerogative in choosing his prime minister remained and contributed to governmental instability, until the introduction of the "dedilomeni" principle of parliamentary confidence in 1875 by the reformist Charilaos Trikoupis. Clientelism and frequent electoral upheavals however remained the norm in Greek politics, and frustrated the country's development.

Corruption and Trikoupis' increased spending (to create necessary infrastructure such as the Corinth Canal) overtaxed the weak Greek economy, forcing the declaration of public insolvency in 1893 and to accept the imposition of an International Financial Control authority to pay off the country's creditors.

Another political issue in 19th-century Greece was the Greek language question. The Greek people spoke a form of Greek called Demotic. Many of the educated elite saw this as a peasant dialect and were determined to restore the glories of Ancient Greek. Government documents and newspapers were consequently published in "Katharevousa" (purified) Greek, a form that few ordinary Greeks could read. Liberals favoured recognising Demotic as the national language, but conservatives and the Orthodox Church resisted all such efforts, to the extent that when the New Testament was translated into Demotic in 1901, riots erupted in Athens and the government fell (the "Evangeliaka"). This issue would continue to plague Greek politics until the 1970s.
All Greeks were united, however, in their determination to liberate the Greek-speaking provinces of the Ottoman Empire. Especially in Crete, the Cretan Revolt (1866–1869) raised nationalist fervour. When war broke out between Russian and the Ottomans in the Russo-Turkish War (1877–1878), Greek popular sentiment rallied to Russia's side, but Greece was too poor and too concerned about British intervention to enter the war officially. Nevertheless, in 1881, Thessaly and small parts of Epirus were ceded to Greece as part of the Treaty of Berlin.

Greeks in Crete continued to stage regular revolts, and in 1897, the Greek government under Theodoros Deligiannis, bowing to popular pressure, declared war on the Ottomans. In the ensuing Greco-Turkish War of 1897, the badly trained and equipped Greek army was defeated by the Ottomans. Through the intervention of the Great Powers however, Greece lost only a little territory along the border to Turkey, while Crete was established as an autonomous state under Prince George of Greece as the Cretan State.
Nationalist sentiment among Greeks in the Ottoman Empire continued to grow, and by the 1890s there were constant disturbances in Macedonia. Here, the Greeks were in competition not only with the Ottomans, but also with the Bulgarians, in an armed propaganda struggle for the hearts and minds of the ethnically mixed local population, the so-called "Macedonian Struggle".

In July 1908, the Young Turk Revolution broke out in the Ottoman Empire. Taking advantage of the Ottoman internal turmoil, Austria-Hungary annexed Bosnia and Herzegovina and Bulgaria declared its independence from the Ottoman Empire. On Crete, the local population, led by a young politician named Eleftherios Venizelos, declared "Enosis", Union with Greece, provoking another crisis. The fact that the Greek government, led by Dimitrios Rallis, proved unable to likewise take advantage of the situation and bring Crete into the fold, rankled many Greeks, especially young military officers. These formed a secret society, the "Military League", with the purpose of emulating their Ottoman colleagues to seek governmental reforms.

The resulting Goudi coup on 15 August 1909 marked a watershed in modern Greek history: as the military conspirators were inexperienced in politics, they asked Venizelos, who had impeccable liberal credentials, to come to Greece as their political adviser. Venizelos quickly established himself as a powerful political figure, and his allies won the August 1910 elections. Venizelos became Prime Minister in October 1910, ushering a period of 25 years where his personality would dominate Greek politics.

Venizelos initiated a major reform program, including a new and more liberal constitution and reforms in the spheres of public administration, education and economy. French and British military missions were invited for the army and navy respectively, and arms purchases were made. In the meantime, the Ottoman Empire's weaknesses were revealed by the ongoing Italo-Turkish War in Libya.

Through the spring of 1912, a series of bilateral agreements between the Christian Balkan states (Greece, Bulgaria, Montenegro and Serbia) formed the Balkan League, which in October 1912 declared war on the Ottoman Empire. In the First Balkan War, the Ottomans were defeated on all fronts, and the four allies rushed to grab as much territory as they could. The Greeks occupied Thessaloniki just ahead of the Bulgarians, and also took much of Epirus with Ioannina, as well as Crete and the Aegean Islands.

The Treaty of London (1913) ended the war, but no one was left satisfied, and soon, the four allies fell out over the partition of Macedonia. In June 1913, Bulgaria attacked Greece and Serbia, beginning the Second Balkan War, but was beaten back. The Treaty of Bucharest (1913), which concluded the Second Balkan War, left Greece with southern Epirus, the southern half of Macedonia (known as Greek Macedonia), Crete and the Aegean islands, except for the Dodecanese, which had been occupied by Italy since 1911. These gains nearly doubled Greece's area and population.

In March 1913, an anarchist, Alexandros Schinas, assassinated King George in Thessaloniki, and his son came to the throne as Constantine I. Constantine was the first Greek king born in Greece and the first to be Greek Orthodox by birth. His very name had been chosen in the spirit of romantic Greek nationalism (the "Megali Idea"), evoking the Byzantine emperors of that name. In addition, as the Commander-in-chief of the Greek Army during the Balkan Wars, his popularity was enormous, rivalled only by that of Venizelos, his Prime Minister.

When World War I broke out in 1914, the King and his Prime Minister Venizelos both preferred to maintain a neutral stance, in spite of Greece's treaty of alliance with Serbia, which had been attacked by Austria-Hungary as the first belligerent action of the conflict. But when the Allies asked for Greek help in the Dardanelles campaign of 1915, offering Cyprus in exchange, their diverging views became apparent: Constantine had been educated in Germany, was married to Sophia of Prussia, sister of Kaiser Wilhelm, and was convinced of the Central Powers' victory. Venizelos, on the other hand, was an ardent anglophile, and believed in an Allied victory.

Since Greece, a maritime country, could not oppose the mighty British navy, and citing the need for a respite after two wars, King Constantine favored continued neutrality, while Venizelos actively sought Greek entry in the war on the Allied side. Venizelos resigned, but won the Greek elections of 1915 and again formed the government. When Bulgaria entered the war as a German ally in October 1915, Venizelos invited Allied forces into Greece (the Salonika Front), for which he was again dismissed by Constantine.

In August 1916, after several incidents in which both sides in the war had encroached upon the still theoretically neutral Greek territory, Venizelist officers rose up in Allied-controlled Thessaloniki and Venizelos established a separate government there known as the result of a so-called Movement of National Defence. Constantine was now ruling only in what was Greece before the Balkan Wars ("Old Greece"), and his government was subject to repeated humiliations from the Allies. In November 1916 the French occupied Piraeus, bombarded Athens and forced the Greek fleet to surrender. The royalist troops fired at them, leading to a battle between French and Greek royalist troops. There were also riots against supporters of Venizelos in Athens (the "Noemvriana").

Following the February Revolution in Russia in 1917, the Tsar's support for his cousin Constantine was eliminated, and he was forced to leave the country, without actually abdicating, in June 1917. His second son Alexander became King, while the remaining royal family and the most prominent royalists followed him into exile. Venizelos now led a superficially united Greece into the war on the Allied side, but underneath the surface, the division of Greek society into Venizelists and anti-Venizelists, the so-called National Schism, became more entrenched.

With the end of the war in November 1918, the moribund Ottoman Empire was ready to be carved up among the victors, and Greece now expected the Allies to deliver on their promises. In no small measure through the diplomatic efforts of Venizelos, Greece secured Western Thrace in the Treaty of Neuilly in November 1919 and Eastern Thrace and a zone around Smyrna in western Anatolia (already under Greek administration as the Occupation of İzmir since May 1919) in the Treaty of Sèvres of August 1920. The future of Constantinople was left to be determined. But at the same time, a Turkish National Movement rose in Turkey led by Mustafa Kemal (later Kemal Atatürk), who set up a rival government in Ankara and was engaged in fighting the Greek army.

At this point, the fulfillment of the "Megali Idea" seemed near. Yet so deep was the rift in Greek society that on his return to Greece, an assassination attempt was made on Venizelos by two royalist former officers. Even more surprisingly, Venizelos' Liberal Party lost the Greek elections of November 1920, and in the Greek plebescite of 1920, the Greek people voted for the return of King Constantine from exile after the sudden death of King Alexander.

The United Opposition, which had campaigned on the slogan of an end to the Asia Minor Campaign in Anatolia, instead intensified it. But the royalist restoration had dire consequences: many veteran Venizelist officers were dismissed or left the army, while Italy and France found the return of the hated Constantine a useful pretext for switching their support to Kemal. Finally, in August 1922, the Turkish army shattered the Greek front, and took Smyrna in an operation that led to the disastrous Great Fire of Smyrna.

The Greek army evacuated not only Anatolia, but also Eastern Thrace and the islands of Imbros and Tenedos in accordance with the terms of the Treaty of Lausanne (1923). A population exchange between Greece and Turkey was agreed between the two countries, with over 1.5 million Christians and almost half a million Muslims being uprooted. This catastrophe marked the end of the "Megali Idea", and left Greece financially exhausted, demoralized, and having to house and feed a proportionately huge number of Greek refugees.

The catastrophe deepened the political crisis, with the returning army rising up under Venizelist officers and forcing King Constantine to abdicate again, in September 1922, in favour of his firstborn son, George II. The "Revolutionary Committee" headed by Colonels Stylianos Gonatas (soon to become Prime Minister) and Nikolaos Plastiras engaged in a witch-hunt against the royalists, culminating in the "Trial of the Six".

The Greek election of 1923 was held to form a National Assembly with powers to draft a new constitution. Following a failed royalist Leonardopoulos-Gargalidis coup attempt, the monarchist parties abstained, leading to a landslide for the Liberals and their allies. King George II was asked to leave the country, and on 25 March 1924, Alexandros Papanastasiou proclaimed the Second Hellenic Republic, ratified by the Greek plebiscite of 1924 a month later.

However, the new Republic was built on unstable foundations. The National Schism lived on, as the monarchists, with the exception of Ioannis Metaxas, did not acknowledge the Venizelist-sponsored Republican regime. The army, which had power and provided many of the leading proponents of both sides, became a factor to be reckoned with, prone to intervene in politics.

Greece was diplomatically isolated and vulnerable, as the Corfu incident of 1923 showed, and the economic foundations of the state were in ruins after a decade of war and the sudden increase of the country's population by a quarter. The refugees, however, also brought a new air into Greece. They were impoverished now, but before 1922 many had been entrepreneurs and well-educated. Staunch supporters of Venizelos and the Republic, many would radicalize and play a leading role in the nascent Communist Party of Greece.

In June 1925, General Theodoros Pangalos launched a coup and ruled as a dictator for a year until a counter-coup by another General, Georgios Kondylis, unseated him and restored the Republic. In the meantime, Pangalos managed to embroil Greece in a short-lived war with Bulgaria precipitated by the Incident at Petrich and make unacceptable concessions in Thessaloniki and its hinterland to Yugoslavia in an effort to gain its support for his revanchist policies against Turkey.

In 1928, Venizelos returned from exile. After a landslide victory in the Greek election of 1928, he formed a government. This was the only cabinet of the Second Republic to run its full four-year term, and the work it left behind was considerable. Alongside domestic reforms, Venizelos restored Greece's frayed international relations, even initiating a Greco-Turkish reconciliation with a visit to Ankara and the signing of a Friendship Agreement in 1930.

The Great Depression hit Greece, an already poor country dependent on agricultural exports, particularly hard. Matters were made worse by the closing off of emigration to the United States, the traditional safety valve of rural poverty. High unemployment and consequent social unrest resulted, and the Communist Party of Greece made rapid advances. Venizelos was forced to default on Greece's national debt in 1932, and he fell from office after the Greek elections of 1932. He was succeeded by a monarchist coalition government led by Panagis Tsaldaris of the People's Party.

Two failed Venizelist military coups followed in 1933 and 1935 in an effort to preserve the Republic, but they had the opposite effect. On 10 October 1935, a few months after he suppressed the 1935 Greek coup d'état attempt, Georgios Kondylis, the former Venizelist stalwart, abolished the Republic in another coup, and declared the monarchy restored. The rigged Greek plebiscite of 1935 confirmed the regime change (with an unsurprising 97.88% of votes), and King George II returned.

King George II immediately dismissed Kondylis and appointed Professor Konstantinos Demertzis as interim Prime Minister. Venizelos meanwhile, in exile, urged an end to the conflict over the monarchy in view of the threat to Greece from the rise of Fascist Italy. His successors as Liberal leader, Themistoklis Sophoulis and Georgios Papandreou, agreed, and the restoration of the monarchy was accepted. The Greek elections of 1936 resulted in a hung parliament, with the Communists holding the balance. As no government could be formed, Demertzis continued on. At the same time, a series of deaths left the Greek political scene in disarray: Kondylis died in February, Venizelos in March, Demertzis in April and Tsaldaris in May. The road was now clear for Ioannis Metaxas, who had succeeded Demertzis as interim Prime Minister.

Metaxas, a retired royalist general, believed that an authoritarian government was necessary to prevent social conflict and quell the rising power of the Communists. On 4 August 1936, with the King's support, he suspended parliament and established the 4th of August Regime. The Communists were suppressed and the Liberal leaders went into internal exile. Patterning itself after Benito Mussolini's Fascist Italy, Metaxas' regime promoted various concepts such as the "Third Hellenic Civilization", the Roman salute, a National Organisation of Youth, and introduced measures to gain popular support, such as the Greek Social Insurance Institute (IKA), still the biggest social security institution in Greece.

Despite these efforts, the regime lacked a broad popular base or a mass movement supporting it. The Greek people were generally apathetic, without actively opposing Metaxas. Metaxas also improved the country's defenses in preparation for the forthcoming European war, constructing, among other defensive measures, the "Metaxas Line". Despite his aping of Fascism, and the strong economic ties with resurgent Nazi Germany, Metaxas followed a policy of neutrality, given Greece's traditionally strong ties to Britain, reinforced by King George II's personal anglophilia. In April 1939, the Italian threat suddenly loomed closer when Italy annexed Albania, whereupon Britain publicly guaranteed Greece's borders. Thus, when World War II broke out in September 1939, Greece remained neutral.

Despite this declared neutrality, Greece became a target for Mussolini's expansionist policies. Provocations against Greece included the sinking of the Greek cruiser "Elli" on 15 August 1940. Italian troops crossed the border on 28 October 1940, beginning the Greco-Italian War, but were stopped by a determined Greek defence that ultimately drove them back into Albania.

Metaxas died suddenly in January 1941. His death raised hopes for a liberalization of his regime and the restoration of parliamentary rule, but King George quashed these hopes when he retained the regime's machinery in place. In the meantime, Adolf Hitler was reluctantly forced to divert German troops to rescue Mussolini from defeat, and attacked Greece through Yugoslavia and Bulgaria on 6 April 1941. Despite British assistance, the Germans overran most of the country by the end of May. The King and the government escaped to Crete, where they stayed until the end of the Battle of Crete. They then transferred to Egypt, where a Greek government in exile was established.

The occupied country of Greece was divided in three zones (German, Italian and Bulgarian) and in Athens, a puppet regime was established. The members were either conservatives or nationalists with fascist leanings. The three quisling prime ministers were Georgios Tsolakoglou, the general who had signed the armistice with the Wehrmacht, Konstantinos Logothetopoulos, and Ioannis Rallis, who took office when the German defeat was inevitable and aimed primarily at combating the left-wing Resistance movement. To this end, he created the collaborationist Security Battalions.

Greece suffered terrible privations during World War II as the Germans appropriated most of the country's agricultural production and prevented its fishing fleets from operating. As a result, and because a British blockade initially hindered foreign relief efforts, the Great Greek Famine resulted. Hundreds of thousands of Greeks perished, especially in the winter of 1941–1942. In the mountains of the Greek mainland, in the meantime, several Greek resistance movements sprang up, and by mid-1943, the Axis forces controlled only the main towns and the connecting roads, while a "Free Greece" was set up in the mountains.

The largest resistance group, the National Liberation Front (EAM), was controlled by the Communist Party of Greece, as was the Greek People's Liberation Army (ELAS), led by Aris Velouchiotis, and a civil war soon broke out between it and non-Communist groups such as the National Republican Greek League (EDES) in those areas liberated from the Germans. The exiled government in Cairo was only intermittently in touch with the resistance movement and exercised virtually no influence in the occupied country. Part of this was due to the unpopularity of King George II in Greece itself, but despite efforts by Greek politicians, British support ensured his retention at the head of the Cairo government.

As the German defeat drew nearer, the various Greek political factions convened in Lebanon in May 1944 under British auspices and formed a government of national unity under George Papandreou, in which EAM was represented by six ministers.

German forces withdrew on 12 October 1944, and the government in exile returned to Athens. agreed Tensions between the British-backed Papandreou and the EAM, especially over the issue of disarmament of the various armed groups, led to the resignation of the latter's ministers from the government.

A few days later, on 3 December 1944, a large-scale pro-EAM demonstration in Athens ended in violence and ushered an intense, house-to-house struggle with British and monarchist forces (the "Dekemvriana"). After three weeks, the Communists were defeated: the Varkiza agreement ended the conflict and disarmed ELAS, and an unstable coalition government was formed. The anti-EAM backlash grew into a full-scale "White Terror", which exacerbated tensions.

The Communists boycotted the March 1946 elections, and on the same day, fighting broke out again. By the end of 1946, the Communist Democratic Army of Greece had been formed, pitted against the governmental National Army, which was backed first by Britain and after 1947 by the United States.

Communist successes in 1947–1948 enabled them to move freely over much of mainland Greece, but with extensive reorganization, the deportation of rural populations and American material support, the National Army was slowly able to regain control over most of the countryside. In 1949, the insurgents suffered a major blow, as Yugoslavia closed its borders following the split between Marshal Josip Broz Tito with the Soviet Union. Finally, in August 1949, the National Army under Marshal Alexander Papagos launched an offensive that forced the remaining insurgents to surrender or flee across the northern border into the territory of Greece's northern Communist neighbors.

The civil war resulted in 100,000 killed and caused catastrophic economic disruption. In addition, at least 25,000 Greeks and an unspecified number of Macedonian Slavs were either voluntarily or forcibly evacuated to Eastern bloc countries, while 700,000 became displaced persons inside the country. Many more emigrated to Australia and other countries.

The postwar settlement ended Greece's territorial expansion, which had begun in 1832. The 1947 Treaty of Paris required Italy to hand over the Dodecanese islands to Greece. These were the last majority-Greek-speaking areas to be united with the Greek state, apart from Cyprus which was a British possession until it became independent in 1960. Greece's ethnic homogeneity was increased by the postwar expulsion of 25,000 Albanians from Epirus (see Cham Albanians). The only significant remaining minorities are the Muslims in Western Thrace (about 100,000) and a small Slavic-speaking minority in the north. Greek nationalists continued to claim southern Albania (which they called Northern Epirus), home of a significant Greek population (about 3%-12% in the whole of Albania), and the Turkish-held islands of Imvros and Tenedos, where there were smaller Greek minorities.

After the civil war, Greece sought to join the Western democracies and became a member of the North Atlantic Treaty Organization in 1952.

Since the Civil war (1946–49) but even more after that, the parties in the parliament were divided in three political concentrations. The political formation Right-Centre-Left, given the exacerbation of political animosity that had preceded dividing the country in the 40s, tended to turn the concurrence of parties into ideological positions.

In the beginning of the 1950s, the forces of the Centre (EPEK) succeeded in gaining the power and under the leadership of the aged general N. Plastiras they governed for about half a four-year term. These were a series of governments having limited manoeuvreability and inadequate influence in the political arena. This government, as well as those that followed, was constantly under the American auspices. The defeat of EPEK in the elections of 1952, apart from increasing the repressive measures that concerned the defeated of the Civil war, also marked the end of the general political position that it represented, namely political consensus and social reconciliation.

The Left, which had been ostracized from the political life of the country, found a way of expression through the constitution of EDA (United Democratic Left) in 1951, which turned out to be a significant pole, yet steadily excluded from the decision making centres. After the disbandment of the Centre as an autonomous political institution, EDA practically expanded its electoral influence to a significant part of the EAM-based Centre-Left.

The 1960s are part of the period 1953–72, during which Greek economy developed rapidly and was structured within the scope of European and worldwide economic developments. One of the main characteristics of that period was the major political event of the country's accession in the European Economic Community, in an attempt to create a common market. The relevant treaty was contracted in 1962.

The developmental strategy adopted by the country was embodied in centrally organized five-year plans; yet their orientation was indistinct. The average annual emigration, which absorbed the excess workforce and contributed to extremely high growth rates, exceeded the annual natural increase in population. The influx of large amounts of foreign private capital was being facilitated and consumption was expanded. These, associated with the rise of tourism, the expansion of shipping activity and with the migrant remittances, had a positive effect on the country's balance of payments.

The peak of development was registered principally in manufacturing, mainly in the textile, chemical and metallurgical industries, the growth rate of which reached 11% during 1965–70. The other large area where obvious economic and social consequences occurred, was that of construction. The policy of αντιπαροχή ("antiparochi", "property-swap"), a Greek invention which entailed the concession of construction land to developers in return for a share in the resulting multi-storey apartment buildings, favoured the creation of a class of small-medium contractors on the one hand and settled the housing system and property status on the other. However, it was also responsible for the demolition of much of the country's traditional and 19th-century neoclassical architecture, and the transformation of Greek cities, and especially Athens, into a "form-less, border-less and placeless urban landscape".

During that decade, youth culture came to the fore in society as a distinct social power with autonomous presence (creation of a new culture in music, fashion etc.) and young people displayed dynamism in the assertion of their social rights. The independence granted to Cyprus, which was mined from the very beginning, constituted the main focus of young activist mobilizations, along with struggles aiming at reforms in education, which were provisionally realized to a certain extent through the educational reform of 1964. The country reckoned on and was influenced by Europe—usually behind time—and by the current trends like never before.

The country descended into a prolonged political crisis, and elections were scheduled for late April 1967. On 21 April 1967 a group of right-wing colonels led by Colonel George Papadopoulos seized power in a coup d'état establishing the Regime of the Colonels. Civil liberties were suppressed, special military courts were established, and political parties were dissolved.

Several thousand suspected communists and political opponents were imprisoned or exiled to remote Greek islands. Alleged US support for the junta is claimed to be the cause of rising anti-americanism in Greece during and following the junta's harsh rule. The junta's early years also saw a marked upturn in the economy, with increased foreign investment and large-scale infrastructure works. The junta was widely condemned abroad, but inside the country, discontent began to increase only after 1970, when the economy slowed down.

Even the armed forces, the regime's foundation, were not immune: In May 1973, a planned coup by the Hellenic Navy was narrowly suppressed, but led to the mutiny of the , whose officers sought political asylum in Italy. In response, junta leader Papadopoulos attempted to steer the regime towards a controlled democratization, abolishing the monarchy and declaring himself President of the Republic.

On 25 November 1973, following the bloody suppression of Athens Polytechnic uprising on the 17th, the hardliner Brigadier Dimitrios Ioannides overthrew Papadopoulos and tried to continue the dictatorship despite the popular unrest the uprising had triggered. Ioannides' attempt in July 1974 to overthrow Archbishop Makarios, the President of Cyprus, brought Greece to the brink of war with Turkey, which invaded Cyprus and occupied part of the island.

Senior Greek military officers then withdrew their support from the junta, which collapsed. Constantine Karamanlis returned from exile in France to establish a government of national unity until elections could be held. Karamanlis worked to defuse the risk of war with Turkey and also legalised the Communist Party, which had been illegal since 1947. His newly organized party, New Democracy (ND), won the elections held in November 1974 by a wide margin, and he became prime minister.

Following the 1974 referendum which resulted in the abolition of the monarchy, a new constitution was approved by parliament on 19 June 1975. Parliament elected Constantine Tsatsos as President of the Republic. In the parliamentary elections of 1977, New Democracy again won a majority of seats. In May 1980, Prime Minister Karamanlis was elected to succeed Tsatsos as President. George Rallis succeeded Karamanlis as Prime Minister.

On 1 January 1981, Greece became the tenth member of the European Community (now the European Union). In parliamentary elections held on 18 October 1981, Greece elected its first socialist government when the Panhellenic Socialist Movement (PASOK), led by Andreas Papandreou, won 172 of 300 seats. On 29 March 1985, after Prime Minister Papandreou declined to support President Karamanlis for a second term, Supreme Court Justice Christos Sartzetakis was elected president by the Greek parliament.

Greece had two rounds of parliamentary elections in 1989; both produced weak coalition governments with limited mandates. Party leaders withdrew their support in February 1990, and elections were held on 8 April. New Democracy, led by Constantine Mitsotakis, won 150 seats in that election and subsequently gained two others. However, a split between Mitsotakis and his first Foreign Minister, Antonis Samaras, in 1992, led to Samaras' dismissal and the eventual collapse of the ND government. In new elections in September 1993, Papandreou returned to power.

On 17 January 1996, following a protracted illness, Papandreou resigned and was replaced as Prime Minister by former Minister of Trade and Industry Costas Simitis. Within days, the new prime minister had to handle a major Greek-Turkish crisis over the Imia/Kardak islands. Simitis subsequently won re-election in the 1996 and 2000 elections. In 2004, Simitis retired and George Papandreou succeeded him as PASOK leader.

In the March 2004 elections, PASOK was defeated by New Democracy, led by Kostas Karamanlis, the nephew of the former President. The government called early elections in September 2007 (normally, elections would have been held in March 2008), and New Democracy again was the majority party in the Parliament. As a result of that defeat, PASOK undertook a party election for a new leader. In that contest, George Papandreou was reelected as the head of the socialist party in Greece. In the 2009 elections however, PASOK became the majority party in the Parliament and George Papandreou became Prime Minister of Greece. After PASOK lost its majority in the Parliament, ND and PASOK joined the smaller Popular Orthodox Rally in a grand coalition, pledging their parliamentary support for a government of national unity headed by former European Central Bank vice-president Lucas Papademos.

From late 2009, fears of a sovereign debt crisis developed among investors concerning Greece's ability to meet its debt obligations due to strong increase in government debt levels. This led to a crisis of confidence, indicated by a widening of bond yield spreads and risk insurance on credit default swaps compared to other countries, most importantly Germany. Downgrading of Greek government debt to junk bonds created alarm in financial markets.

On 2 May 2010, the Eurozone countries and the International Monetary Fund agreed on a loan for Greece, conditional on the implementation of harsh austerity measures. In October 2011, Eurozone leaders also agreed on a proposal to write off 50% of Greek debt owed to private creditors, increasing the EFSF to about €1 trillion and requiring European banks to achieve 9% capitalization to reduce the risk of contagion to other countries. These austerity measures have proved extremely unpopular with the Greek public, precipitating demonstrations and civil unrest.

There are widespread fears that a Greek default on its debt would have global repercussions, endangering the economies of many other countries in the European Union, threatening the stability of the European currency, the euro, and possibly plunging the world into another recession. It has been speculated that the crisis may force Greece to abandon the euro and bring back its former currency, the drachma. In April 2014, Greece returned to the global bond market as it successfully sold €3 billion worth of five-year government bonds at a yield of 4.95%. According to the IMF, Greece will have real GDP growth of 0.6% in 2014 after 5 years of decline.

Following the May 2012 legislative election where the New Democracy party became the largest party in the Hellenic Parliament, Samaras, leader of ND, was asked by Greek President Karolos Papoulias to try to form a government. However, after a day of hard negotiations with the other parties in Parliament, Samaras officially announced he was giving up the mandate to form a government. The task passed to Alexis Tsipras, leader of the SYRIZA (the second-largest party) who was also unable to form a government. After PASOK also failed to negotiate a successful agreement to form a government, emergency talks with the President ended with a new election being called while Panagiotis Pikrammenos was appointed as Prime Minister in a caretaker government.

Voters once again took to the polls in the widely watched June 2012 election. New Democracy came out on top in a stronger position with 129 seats, compared to 108 in the May election. On 20 June 2012, Samaras successfully formed a coalition with PASOK (now led by former Finance Minister Evangelos Venizelos) and DIMAR. The new government would have a majority of 58, with SYRIZA, Independent Greeks (ANEL), Golden Dawn (XA) and the Communist Party (KKE) comprising the opposition. PASOK and DIMAR chose to take a limited role in Samaras' Cabinet, being represented by party officials and independent technocrats instead of MPs.

In wake of the austerity measures adopted by the Samaras government, Greeks voted the anti-austerity, left-wing SYRIZA into office in the January 2015 legislative election into office. Samaras accepted defeat and said that his party had done much to restore the country's finances.

SYRIZA government lost its majority in August 2015,when some of its MPs withdrew their support in favor of the governing coalition. SYRIZA won the September elections, but failed to get an outright majority.Later they formed a coalition with Independent Greeks, a right-wing party.

The party suffered heavy defeats at the 2019 European Parliament election, and prime minister and SYRIZA leader, Alexis Tsipras resigned to organize a snap election. It resulted in a majority for New democracy, and the appointment of Kyriakos Mitsotakis as prime minister.




</doc>
